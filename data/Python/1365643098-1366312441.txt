Huh? That's just ridiculously confusing, especially since I've been naming my virtualenv directories "venv". I really hope this isn't true.
Having local pypi mirror mean another service to maintain, doesn't matter how easy it is. What I did is to install from local file system. I used easy_install but may also applied to pip. Since easy_install can install from eggs in `site-packages`, I rsync the virtualenv site-packages to the production machine and then use easy_install -H None -f ~/path/to/eggs to rebuild the environment on production machine. The flow look like this:- # development, at project root virtualenv .env while read line; do .env/bin/easy_install $line; done &lt; requirements.txt rsync -avz .env/lib/python/site-packages/ production:~/eggs/ # production, at project root virtualenv .env while read line; do .env/bin/easy_install -H None -f ~/eggs/ $line; done &lt; requirements.txt Ideally we can just tarred up the virtualenv to production but there's always problem with path so that's why I just created a fresh virtualenv on production and reinstall the packages. The -H None will make sure that easy_install will never go outside to fetch the packages. Recently I switch to using buildout which make the above flow more straightforward since buildout keep the eggs in `PROJECT_ROOT/eggs` so I just need to run `./bin/buildout -o` (offline mode).
thanks for the tip! not only that, Anaconda comes with more useful libraries (for me) and has IPython's qtconsole already compiled (never managed to install it on my Mac).
You should check out Spyder. I have never understood why Enthought won't use it. They seem to have a bad case of NIH. 
&gt; su -c 'curl http://foo.com/something-fishy.sh | bash'
You have to understand who Enthought's market is for things like this. I don't think they are targeting people that are currently writing much code. They are trying to give Excel-addicted scientists, engineers, statisticians and financial analysts a slightly more sophisticated tool to do their work (... experienced software developers are not going to pay for their training sessions). Expecting this to be a full IDE suitable for full application development is missing the point. No excuse for crashing and charging for free shit though. 
I (naively) thought Enthought was targeting Matlab users... in my institution, most engineers run Matlab, at a high cost. Getting a decent IDE would give them an edge, and they can charge for custom dev and/or installation support for large deployments etc. Maybe I do not get Enthought business model... but when I see how much is spent on Matlab, I still think they could make honest money. 
Yes, that's right, I (often) have a choice, and I will choose as I see fit.
Hmm, am I missing something? The Canopy Express download (i.e. the free version) does have a 64-bit option. Also, to be fair, you don't have to use the analysis environment, in which case you'd use it just like you would use Anaconda (with the exception of Python 3, which doesn't seem to be supported).
Is the $1000 of benefit coming from the technical support and videos and presumably simpler installation? I'm trying to see what the value is vs. using Linux, their package manager to install, and Eric 5 or Spyder and/or iPython. 
I'd go with spyder, or sage. 
This leaves a trace in the user's shell history. After you close an incognito window, there's no evidence it was ever used.
(disclaimer: I am working for Enthought) qtconsole is also included in EPD. Freyrs forgot to mention that he is working for Continuum, which I find a bit disingenuous when not stated when recommending anaconda. Hopefully, products can compete on their own merits instead.
It is a tough problem to solve correctly, as each platform has its own set of solutions (mac vs windows vs linux). I have not looked how anaconda solves this problem exactly, but I would say neither EPD or anaconda has a very good solution to this problem yet. TO be fair, very few products have (matlab has exactly the same problem on linux last time I checked).
does this depend on MS Access being installed on the system?
(disclaimer: working for Enthought). Canopy (and EPD before) are not charging for 'free shit', unless you consider Red Hat is also charging for 'free shit': what is being charged is the service of packaging things into binaries, which is quite a bit of work (more than people generally realize). Also, working on specific configurations means we contribute back some upstream bugs upstream (e.g. MKL and OS X interaction for a recent example: https://github.com/scipy/scipy/pull/398). Also, Enthought provided quite a bit of resources (money and manpower) to put code out there for ipython (like e.g. qtconsole), all of it integrated upstream. So yeah, we're charging for the product, but it is hard for a company to earn money without charging money somewhere :)
&gt; They are trying to give Excel-addicted scientists Not sure about the rest of the people you mention, but as a scientist I wouldn't spend any euro of my research budget on software like this (nor I wouldn't for Matlab, etc).
When I checked yesterday their website was a placeholder and all the links to EPD on Google were 404's. Not a good sign. But today they're back again with a new product called "Canopy" which replaces EPD. There's a freebie version called "Canopy Express" (equivalent to the former EPDFree) which given their previous work I'd say is worthwhile checking out, and there's already a thread started in /r/Python on its various merits and ... otherwise. 
Bleachbit!
rm ~/.bash_history Or delete that line yourself. (A way that would be non obvious to most reads of it would be: vim test.py and in vim :e ~/.bash_history /curl dd :x Basically, opening a dummy file in vim, using :e to edit your shell history, using /curl to find your command, dd to delete the line (I have been thinking its cut lately, but who cares.) and :x to save and quit (if you changed anything. For a little more security, run a command again so that it changes the last modified date on your ~/.bash_history. This can be applied to any shell.
Or [python(x,y)](https://code.google.com/p/pythonxy/wiki/Downloads) which comes with it!
I had a play with spyder. I even mucked around in the source code to tweak it. And now, i totally understand why they don't use it. I mean it's OK but it's not a very professional looking codebase.
Having built scientific libs on my mac i have to agree - its a pain in the ass and there's more than enough people who don't want to have to install gcc, gfortran, configure environment variables, get things like ATLAS linked, install zeromq... That said, it does feel a bit crap to pay for something that you could get for free. But then again you still can, if you feel like going through the trouble of getting it working. Perhaps the real criticism is that you can get a lot of those packages from Continuum.io with the Anaconda distribution for free - competition's heating up guys!
use from __future__ import division in you python2 code and make it work with new style division, get python3 support automatically
i recommend looking at the euclid module (part of Cocos2D originally but since its open source it's been copied into a couple of projects i've seen, including my own https://github.com/mangecoeur/optboid) It has some very well crafted classes for 2d and 3d points, vectors, transformations, matrices - all the standard vector maths. I've used it in small game prototypes and found it was actually faster than numpy because the amount of data was so small that the speedups from numpy were cancelled out by the overhead of using it. Note: obviously if you're dealing with more than few dozen vectors numpy is the way to go. 
And why would a random throwaway browser be any better than firefox/chrome in incognito mode?
Agreed
There is some serious inertia behind Matlab in universities and I wish a really good alternative existed. Non-computery people can sit down in front of Matlab and use it without much help, 5 years later they are still using it and finding way to get round its inaqequacies. If someone can bundle up some Python into an easy to use interface good luck to them.
I disagree, it's also about what's trust*worthy*. The apt-get example is measurably safer. Remember: `bla` if it's an official package from an official repository/release is signed--and signed with a keyring you've got reason to trust. At a minimum, this protects you from malicious packages placed on a compromised mirror when the keyring is also not compromised (which is much more unlikely)--someone compromises the webserver a script is on, and your only defense is the Mark I Eyeball (which directly passing the thing to bash from curl/wget circumvents the use of).
Not really. With your example the trust is placed in the package repos you and/or your distro have specified as trusted sources. That's a lot safer than some site you found a cool script on.
Also, while I worry about how much data I'm giving Google with all their "Cloud"-connected features in Chrome, I pretty much trust that when they say, "We don't track URLs visited by Chrome users," they won't – at least not until they publicly announce a different policy (so long as I don't use any handy-dandy "please track me" features like server side address bar autocompletion, or performing Google search queries). Even if they're pretty untrustworthy privacy-wise, they *do* have a reputation, and do have clear, publicly stated policies. With some random browser downloaded from a personal site, it's not just the malware potential – how do I know that the domain won't be sold to an Ad-ware/spam company next week? Downloading, auditing, and then always checking hashes would help this, of course, but that sucks to do for every upgrade. 
Sorry, there is no python subreddit about Spanish and did not think the language was important. The next link about python share will be in English. My apologies again.
No, the debian(and any other distro) official repositories have a system of trust so that you don't have to trust a singular person but a whole organizaton, which has a lot of reasons to be responsible and careful, and a history of reliability to show as guarantee. On top of that, a debian official package has probably been tested by thousand of users before me, and their feedback is readily available to be consulted. Both of these example are as safe as installing something on windows, apart from the ample smart checking for possible malicious behavior that I imagine windows does. Edit: Oh, also, apt-get supports signed packages, and debian packages are signes, so no risks of corruption of the package.
I always liked EPD free and I advocated it to my colleagues a lot, I even considered many times trying to push my institute to pay for a bundles license, to support Enthought's work. The impression I got with Canopy was at first very good: finally a nice looking IDE that I can sell to my Matlab colleagues who are not necessarily heavy terminal users... then I opened the package manager GUI and realized I have to subscribe to get access to libraries I used to install with "easy_install". I would agree to pay for the initial effort of packaging Numpy/Scipy/Matplotlib/IPython binaries, which I understand is a lot of efforts. But when this is is given for free, and you charge to add third parties libraries readily available from pypi, *that* feels a bit steep.
I am starting to seriously think you are correct... but I still think something like Canopy is useful to streamline the workflow of people who care mostly about data analysis.
That's your perogative.
Give cherrypy a try (http://www.cherrypy.org): you can use any templating and orm of your choice. It has been around for a very long time.
Why piss about? Just insist that all python code should have been written in python 3.
I agree. 
Mmm it always been my biggest concern with the status (states) of the python "packaging" world: it looks at the end everyone is targeting at rewriting a siloed version of rpm+dependecy manager. Anyway thanks for the article. 
Consider privilege separation. If you're building system tools using system libraries, use a system account that doesn't have Anaconda (or whatever - for that matter) in the path. If you're building libraries to use with anaconda, use an account with anaconda in the path. If you don't admin the system and therefore can't create accounts, have rc files that setup different environments and spawn a new shell running the relevant rc file e.g. "bash -i --rcfile anaconda.rc" - simply exiting the subshell drops you back to your pristine normal shell without the added environment bits. You can use $BASH_SUBSHELL to do things like alter your prompt if you're in such an environment so its obvious. (Other shells will do the same thing, just with their own spin on it) 
&gt;The Editor has a single preference: the choice of font. Any modern editor (Emac, vim, Sublime Text 2, you name it) can be parametrized in thousands of ways! That's only 50% of the configuration options in **notepad** (you can also toggle word wrap)
Does it have tabs? I need lots of tabs for porn.
Constructive criticism welcome!
I'll answer any questions.
Yes it does!
Seconded on using cherrypy, but make sure you use 3.2.3 found on the bitbucket site. 3.2.2 on the main site has issues with Python 3.3 out of the box. 
I'm not a fan of having anything in `__init__.py` in general, but I'm pretty sure that you're doing it right.
QTEs will definitely come in the next commit. I'm just ironing out the motion controls (will release either way).
I don't think we charge for pypi specifically: we do charge when people want to use more than just the 'core scipy stack', and pypi packages come with that on top. What people are paying for are the additional packages packaged by Enthought, not really pypi which is offered as an addition.
That's absolutely fine and idiomatic. The `__init__.py` + `__all__` is serving to expose a specific API (and hide the implementation details of your package structure), and makes user's lives easier. Every* major package puts imports in `__init__.py`. I might consider a different name, though... Wpdb is close to winpdb, and "pdb" is generally understood to mean "Python DeBugger" (see also: pdb module). *: for a non-literal definition of "every"
Yes, continuum.io model is different. They want people to pay for their packages (numba pro, etc...), so they make the complement a commodity (the below stack). I agree competition is good, and I actually do enjoy having to prove we can bring a compelling offer.
Yeah, that's along the lines of what I do. My primary annoyance is actually with mpiexec. Since mpiexec is tied to the specific compiler you used to compile MPI, Anaconda overwriting that in my path is an annoyance. I get around it by fiddling with my path in a way similar to what you describe.
I'm pretty sure they could've written much nicer-looking code that performed equally well using [gnumpy](http://www.cs.toronto.edu/~tijmen/gnumpy.html).
recommendation based on experience with CI. Django is probably functionally/feature equivalent to CI as it includes the basics for building a website ( database, templating, view/action utilities ). CherryPy &amp; Pyramid are fun but I think by default they do not have: SQL/NoSQL libraries, no stock templating library, and no major additional logic outside of routing and request handling logic. Flask/Bottle are much smaller footprint web tools that provide a means for building a simple website or making an easy web service handler. I am missing half a dozen other frameworks, but Django is king for having batteries included and therefore a one stop solution to making websites. Downside to Django ( and one reason why other frameworks thrive ) is that it is very hard to get away from the Django ORM for a busy website.
How about the package manager? can you run "easy_install" and bypass the package manager which force you to pay to use Enthought's version of the libraries? I would happily accept to have the option, and not be forced to pay for a library that is trivial to install otherwise.
I prefer rss to read my news. My inbox is for communication not for getting news. Look at http://coderweekly.com/ ... they offer both. Couldn't find a rss feed on the python/nosql weekly page. PS: the link to the python weekly page is wrong on the RasPi Weekly page (points to the founder site)
The book [Real World Instrumentation with Python](http://shop.oreilly.com/product/9780596809577.do) has a chapter on control systems and implementing them in Python. Not in-depth, but it might get you started.
Did you look at the URL? It's downloaded from google. Sure, it's possible that I could sell my google account which I have used for years and controls all my open source projects, etc to a adware company next week, I guess, but it would also have to be a adware company that is interested in changing the code in a open source minimalistic browser that has only been mentioned thrice in three years. Doesn't seem likely. As for what this dos with your data, read the source. You can't do that with other browsers, which is why you need policies in the first place.
also confusable with wdb, which is a debugger
Probably. But this is what they did.
(Enthought employee) Of course you can use `easy_install`, just like in EPD. `distribute` is pre-installed, so just go ahead and use it. The package manager is a convenience for managing the binaries that we do provide. It doesn't remove any functionality from the Python installation.
Why not? 
Mostly because it clutters the namespace.
&gt; Freyrs forgot to mention that he is working for Continuum, which I find a bit disingenuous when not stated when recommending anaconda. Hopefully, **products can compete on their own merits instead**. I find it disingenuous (and petty) to claim you care about merits, but care more about the speaker than their ideas. It's easy to create throwaway accounts if anyone is really trying to sock puppet. 
Get yourself on Github and use the search feature. Find ones that you're interested in, check out their open issues, and pick one to fix. You'll have to fork it, make your fix, and then request a pull back to the original. If they like your fix, they'll approve it.
&gt;Oh, right, a shell script called "devicenzo.py" that is piped into a shell called "python". WTF? And all of those AnnaKournikova.jpg.vbs emails are probably just pictures of Kournikova, right? I mean it looks like it is a jpg. 
Unless you somehow have a python binary in your path that is actually some sort of bourne shell, you can be fairly confident that's a python script, or else all you'll get is a error message.
Why did they not label the axis on their graph?! It looks great but wtf am I looking at
You need to think about what your interests are. Since you like programming it's possible that programming tools are of interest. Or maybe you'd like to work on a program that you already use, eg a bittorrent client. Or maybe you're interested in music or graphics.
Much as I love Python, it's not really appropriate for mission- or safety-critical systems.
Saying a car is a canoe is orthogonal to its safety. It's just a matter of accuracy.
It's semi-abandoned for the moment but I did a real quick proof of concept to use the WebKit module of QT. https://github.com/devdave/pywk Possibly this weekend I am going to spend some more time with it, but the two advantages was that it relied more on QT's WebKit bindings then the rest of QT and second I've got more experience with HTML/CSS/JS then investing in some other way to render a UI. A third but questionable advantage is that its possible to re-use the UI for the web, I say questionable as I am exposing user defined objects to V8 in WebKit.
[Here you go.](http://code.google.com/hosting/search?q=label%3aPython)
Mozilla has a page with all their open source projects and how you can help. you can sort by language and then sort by what you want to do with it.
Good question. The gurus are busy with sarcasm now. And omniscience. The remnants of why newbies bounced out of linux-land in past decades.
If you are a student, then apply for Google Summer of Code 2013. If you're not a student, then check out the accepted organisations for GSoC 2013. I guess there are 177 of them (all open source). Filter them by whatever tags you want. You can then visit the ideas page of a few organisations and see what they want done. 
Try perhaps [OpenHatch](https://openhatch.org/)
I'm pretty sure Reddit uses Python.
&gt; I wish I could be more specific about how to set up a minimal test case around this, but I can't. `import`s should be "trees" - either branches or roots. You can import submodules from the parents (branches), or import parents from the submodules (roots), but not both, lest ye get circular imports.
 Check out these sites: http://contribhub.co/ (You can add your repo or help with others' repos) http://www.codetriage.com/ (You can sign up and get one bug each day) http://24pullrequests.com/ (Happened last December)
reddit is not the best "beginner's" project.
You may be right, but personally I have found that feeling your project is relevant is even more important than the appropriate level of complexity.
So, none of the stuff in `wpdb.py` will be included in `__all__` (unless there's an object named `wpdb`). I suspect that's not what you want.
There are tons of projects that need help, you should narrow down your choices. I find that the most effective way to do that is to filter based on your interests. For example, if you're interested in science, there's tons of python packages focusing on science, you pick one and see if you can improve it by adding some new function, resolving some bugs etc. Of course it's not like you open a page and start coding, before being able to make an useful contribution you should at least be able to *use* a certain piece of software, that's way it's extremely important that you find something that's directly useful to you. After doing that you will expand your skills and your interests and you'll be more aware of the ecosystem of packages in a certain field and it will so much easier to contribute.
Make a list of developers you idolize. If you don't have any that come to mind, make a list of modules that you love, and find out who writes those. Get on Github (or Bitbucket, or Gitorious - but 99% of the time, Github) and find the source. Start reading it. When you find something that's implemented in a way that you're impressed by or that entices you, find out who wrote it. Go look at their profile, and see the projects they've committed to. If you do this long enough, you will eventually find something that will get you excited enough that you'll *want* to work on it. That's the key.
I agree with you. If I'm writing a module that has only a limited number of objects that should commonly be used, I'll import those into `__init__.py`, so they're easier to reference later. Speaking of namespace cluttering, though, I avoid `from &lt;module&gt; import *` at all costs.
Blender.org needs your help.
Looking at a [github fork](https://github.com/nicholasbishop/blender) only 6% of blender is written in Python.
You need to work on something you actually use so that you've got some motivation to improve and fix it. If there's nothing you use at the moment that's written in Python then find something you'd want to use.
 if goal_page in visited_sites: return True else: return False This can be simplified to return goal_page in visited_sites The break statement in the snippet below is never reached. It's better to leave it out. return page_file break The else branch is not required here: else: pass And finally, I'd add a comment about what you're using those counters for.
I disagree. If not for Google, the shelf over my desk would be filled with reference books instead of pictures of my daughter. I'd also have a much harder time learning workflows and architectures from others, without an easy way to find them.
You misunderstand, rox0r wasn't suggesting your account was a throwaway, but saying that if freyrs3 didn't want people to know he worked for continuum he would have just created a throwaway.
&gt; you might want to learn a few other languages +1 I recommend a C derivative (C, C#, C++, Objective-C) first, as the difference between weakly typed languages (like Python) and strongly type languages (like C) is the primary grouping in my mind for languages in general. Javascript would also be very good, since it's ubiquitous on the web and is gaining acceptance rapidly in other fields. You'll naturally pick some of this upif you're doing anything web-related. Once you get to the point where you're proficient with Python for back-end webapps (if that's the path you go down), then learning Node.JS over a weekend would be a good introduction to both "serious" javascript and event-driven application architecture. After that, maybe something more obscure that can change the way you logically structure problems. I've used some Lisp in the past, and found it extremely helpful in learning Python, as I had already encountered Lambda expressions in a big way.
I don't mean that you personally are untrustworthy, or that this project's source reveals defects; just that the "big name" software distribution paradigm has some advantages, even, counterintuitively, in the privacy space. Namely, getting software from a tiny, unknown source and blindly trusting updates is rather questionable – you have to read the source, then again for every bug fix and security patch (which are uncertain, from a small vendor). I do appreciate the SSL – that puts you way ahead of most software distribution these days – but it doesn't guarantee you'll (that is "you," a small s/w distributor in theory; not you, personally) provide regular, trustworthy updates and not sell the product later on. Google hosting doesn't change this at all – it's privately controlled, by you. Sadly, corporate software hegemony – i.e. the App Store and other walled gardens, which are similar to placing trust in Chrome – is embraced because it has benefits, even as it horrifies many us who are able to perceive its less tangible costs to freedom and innovation. All that said, I guess what you're proposing is, abstractly, no worse (and actually better, due to SSL) than installing anything at all from PyPi. So yes, asking people to curl into shells is a terrible idea, and invites these criticisms, but you are right that your project idea isn't that far out, when you really look at it. Throw in a setup.py, put it on PyPi, and not one of us would say a word about how bad an idea it is to run `pip install devicenzo`, even though security-wise it's identical. Plus you'd be able to specify PyQt as a dependency, rather than just tell people to install it. This, though, may say more about how horribly broken PyPi is from a security perspective, than how acceptable the curl trick is. 
that's really cool
I object to this being called a shell script because it's not one, anyway. You may continue to discuss whatever else you want, but on that specific point, the error has been pointed out.
It really depends on how determined the person is and how well documented the project is. I've been working with the reddit code base for some time (with a fair number of years of prior python experience), and I still have trouble discovering what something is actually doing from time to time. I'm not saying don't do it, but I can see how easily working with something too complicated might turn someone off of the desire to contribute to an open source project.
pick a red app on https://python3wos.appspot.com/ and try porting it to Python 3 and Travis
Looks similar to [CodeMontage](http://codemontage.com/).
* http://dbpedia.org/Datasets * http://wikipedia.org/wiki/Wikidata
That's still quite a lot.
[Here](http://www.youtube.com/watch?v=U2ZNiNu1tK4) is a 15-ton grapple being controlled by Python + Wiimote. I think this qualifies as cool!
NLTK for Python 3.0. It's open source, and it needs you. NLTK is THE tool for machine learning and NLP.
There is a huge need for Python 3 support in libraries. Tons of businesses are stuck on 2.7 (or earlier!) because they rely on libraries that don't support python 3... many of them no longer maintained. You could learn a lot by digging into the codebases of popular libraries, and really help the community to move forward by working toward this goal.
This is the one. Thanks! (also, TIL about pyvideo)
Maybe have a look at [CherryPy](http://docs.cherrypy.org/stable/progguide/REST.html)?
Thanks for the help; added to latest commit.
You could pitch in on the effort to port packages to Python 3. I wrote [checkmyreqs](https://pypi.python.org/pypi/checkmyreqs) to parse requirements files and tell you which packages do not yet support Python 3. This lets you find those less popular libs that aren't featured on https://python3wos.appspot.com and similar sites. You could also work on checkmyreqs itself of course :) Sometimes the library is 3 compatible, but the author hasn't updated their classifiers on Pypi to reflect this fact. I just submitted a patch to [bottle](https://github.com/defnull/bottle) updating the classifiers. So, you can find out what libraries you use that aren't 3 compatible yet, create an issue in their repo asking if they'd like help porting it over and work on it if they do. Porting is a great way to become familiar with lots of different facets of Python and learn what's new in Python 3 at the same time.
I'm looking at it now, thanks! I see it has a HTTP server included. Is it suitable for production, or should I look into apache_wsgi?
you are correct. It looks like the 32 bit vs 64 bit confusion came form the "compare subscriptions" page. This page seems to indicate that 64 is only available with a paid subscription. 
The CherryPy HTTP server is very mature, and quite fast. It should be more than enough to get started with, and when you need to you can put nginx in front of a pool of processes to scale up in the future.
Take a look at [flask](http://flask.pocoo.org/), it meets your requirement. And [bottle](http://bottlepy.org/docs/dev/), everything is in one file and no other third-part library required. 
 $ sudo apt-get install python-tk 
I am not too shocked. I was wondering why it has not happened already. So it goes.
&gt; Attaching any function to a class wraps it in an instancemethod object. instancemethod acts as glue, binding the class, instance (if any), and original function together. That's not quite correct. The function is not wrapped in any way when it's added to the class; it's just a member of the class's dict: &gt;&gt;&gt; print type(Foo.__dict__['bar']) &lt;type 'function'&gt; It's only when you access `bar` as an attribute (i.e. `foo.bar` or `getattr(foo, 'bar')`) that the magic kicks in. Function objects implement the descriptor protocol, which means they provide a `__get__()` method. When the attribute access happens Python sees the descriptor methods and turns the normal lookup of `type(foo).__dict__['bar']` into `type(foo).__dict__['bar'].__get__(foo, type(foo))`. The `__get__` method of a function returns a bound method with the partial application of the first argument. This is where the wrapping happens, not when the function was added to the class' dict. 
While Web2Py is not my cup of tea, I can't help but admire your perseverance and dedication. That's great news that you've got the project going through a CI now.
You wont be able to do this with Godaddy as a host. You should look into getting a VPS (Virtual Private Server) or maybe deploying your app to Heroku. As far as new hosting alternatives: http://www.linode.com/ is great for the price, and you can do a lot more with this than you would ever be able to do with Godaddy. Or if thats too complicated/expensive, you can still use heroku free :). 
My point was that what they're advertising isn't as great as they're saying it is.
Do you use Linux by chance? You'll probably find a wealth of Python opportunities if you hunt around. What are your other skills? Networking, cryptography, security, game development, web development??
You could also try tornado: http://www.tornadoweb.org/en/stable/
I created a RESTful service with tornado and mongodb in like 20mins. Also, with loose coupling. :) 
Why can't self be a keyword instead of a parameter?
Self is always a parameter, some languages just make it implicit(often it is called `this` instead). In python it is explicit.
Take a look at [cornice](http://cornice.readthedocs.org/en/latest/). The description states "Cornice provides helpers to build &amp; document REST-ish Web Services with Pyramid, with decent default behaviors. It takes care of following the HTTP specification in an automated way where possible. We designed and implemented cornice in a really simple way, so it is easy to use and you can get started in a matter of minutes."
Start with the things you use yourself. Lots of user-facing applications are written in python these days, especially if you're on some flavor of Linux. But it doesn't have to be an application: if you do nontrivial python programming, you are using libraries. I bet at some point you run into a situation where things aren't perfect: a convenience function may be missing, there may be an error in the documentation, you may have run into a bug or an undocumented edge case, some feature may be missing, etc. etc. At that point, you can step in, fix things (or even just file a bug!), and see how your contribution is received. Another thing you might consider is check out the project's bug tracker and volunteer to tackle some of the "easy" bugs (most projects have a huge collection of tiny low-profile bugs that are deemed most suitable for beginning contributors). The sore spot for many open source project is actually documentation and testing, much more than actual programming, so expect a warmer welcome for good documentation enhancements and proper bug reports than for random patches. And finally: don't be afraid to ask the maintainers (through their preferred channels!) what kind of help they could use the most.
This article lost all credibility in the second sentence: &gt; For one, you must explicitly define [self] in every class method. As a matter of fact, "self" is a variable name used by convention in *instance* methods only. Class methods use "cls" by convention. And if the article meant to say "You have to give a first parameter in every method you define in a class", it's still not even true, since you can use static methods, which use neither "self" nor "cls". Also, further down, the article confuses [properties](http://docs.python.org/2/library/functions.html#property) with [attributes](http://docs.python.org/2/reference/datamodel.html). And misleadingly states that &gt;Foo.bar point[s] to [a] different memory location than foo.bar. Which is only true if you assign to foo.bar. For example: &gt;&gt;&gt; class Foo: .... bar = [] .... &gt;&gt;&gt; Foo.bar is Foo().bar True &gt;&gt;&gt; class Foo: ... bar = [] ... def __init__(self): ... self.bar = [] ... &gt;&gt;&gt; Foo.bar is Foo().bar False Furthermore, the whole example the author presents is fundamentally flawed because it does "is" checks on ints, which are immutable objects. As it happens, Python only ever creates one instance of small ints for performance reasons, so any "is" check on a small integer will return True. For example: &gt;&gt;&gt; x = 42 &gt;&gt;&gt; y = 42 &gt;&gt;&gt; x is y True &gt;&gt;&gt; x = 257 &gt;&gt;&gt; y = 257 &gt;&gt;&gt; x is y False (Similarly small strings are sometimes cached in this way, since they are also immutable) &gt;&gt;&gt; x = "abc" &gt;&gt;&gt; y = "abc" &gt;&gt;&gt; x is y True &gt;&gt;&gt; x="qwertyuiopasdfghjkl;" &gt;&gt;&gt; y="qwertyuiopasdfghjkl;" &gt;&gt;&gt; x is y False But, of course, mutable data structures like lists, sets, and dicts are not stored as the same instance. &gt;&gt;&gt; x = [] &gt;&gt;&gt; y = [] &gt;&gt;&gt; x is y False So, basically, you should never use immutable types for "is" checks because they behave in unpredictable ways behind the scenes. The only reason why you should care about an "is" check is if you plan on modifying an object.
&gt; Self is always a parameter But why does it have to be? It would be way simpler if it was a keyword and we could disregard the entire self problem, right?
I think it has to do with ["PEP 20 - The Zen of Python"](http://www.python.org/dev/peps/pep-0020/). Where it states: &gt; Explicit is better than implicit. So it would be implicit if it was not stated in the parameters and only had a keyword. Which goes against the guideline.
Well, a method defined on a class must have some form of reference/pointer to the instance it is called on. The most obvious way to do this is to pass it as a parameter(I can't think of any other way to it...) In a language like Java every time you reference an object in a function, say `x`, it will assume you meant `this.x` unless `x` is already defined in the body of the function. You can say that `this` is a keyword then, since it gets special treatment, but an actual "this reference" must still be passed to the function(when you call foo.bar(), foo is passed to bar as a "this reference"). If you see `self`(`this`) as a problem, then the Java way might be a solution. I don't know if I would consider it a problem though. 
Maybe using Flask for the web part, Scrapy for scraping, and then you should be able to use something like SQLAlchemy to share the ORM. Benefit is that Flask is much lighter than Django and has a quicker take-up time, and has a number of plugins that you might find useful (eg. REST stuff).
Mercurial is vastly more popular than git for python projects.
You could always use the word "this" if you want it to look friendly to c++ and javascript programmers.
Long story short, because of how classes are actually objects in python, "self" is used to differentiate static member variables with instance member variables *explicitly*.
How can you measure this ? Quite often when I'm looking for a library in PyPI and find a candidate, I will see a link to a repository hosted on github.
In fact, although Python 2 will wrap the function (to an unbound method) when accessing it from the class, Python 3 does not even do that: &gt;&gt;&gt; class Foo: ... def bar(self): ... ... ... &gt;&gt;&gt; Foo.bar &lt;function Foo.bar at 0x1007bde60&gt; &gt;&gt;&gt; vars(Foo)['bar'] &lt;function Foo.bar at 0x1007bde60&gt; &gt;&gt;&gt; 
I wonder why the Python team didn't just create a `method` keyword to use with classes instead of `def`. If they had done it that way, `self` could also be a keyword, and the interpreter wouldn't need to do the bound method dance every time. 
So any explanation about it, what is the purpose of the game?
Can I get a plug in for http://community.nvda-project.org/ here? It's a screen-reader written in Python.
http://community.nvda-project.org/ - a screen-reader written in Python.
Firstly, Mercurial is not a platform to find new projects, github is. And secondly, do you have an references to back up this claim? I had honestly thought git was more popular across the board these days.
Confirmation bias much?
This is sometimes useful when you're monkey-patching methods into libraries that don't give you the kind of access you want, and for whatever reason subclassing isn't ok: class Foo(object): def bar(self): o = twisted.AbstractConcurrentFactoryDerpAdaptor() def someMethod(self2): print self2 o.someMethod = someMethod o.someMethod() Almost always there's a better way to do it, but this is one case where renaming `self` makes sense. In this specific example it's better to subclass, but there are times (e.g. `twisted.web.static.File`) where this can lead to issues.
Check out http://spaceappschallenge.org/challenges/
Go py3 64 and get your libraries from Christoph Gohlke.
Bottle is really simple. I got up and running in no time.
How is this a beginners guide? It *only* explains how to install Python?
We recently did this for a course project at university: http://i.imgur.com/8LqpATp.png This was our directory structure (**EDIT** of course I removed all the helper/bootstrap scripts and stuff for the sake of readability): appstorecrawler ├── appdex # simple Scrapy project │ ├── __init__.py │ ├── items.py │ ├── pipelines.py # shoveling scraped data into Redis queue │ ├── settings.py │ └── spiders │ ├── appstore.py │ ├── debugspiders.py │ ├── __init__.py │ ├── playstore.py │ └── windowsphonestore.py ├── __init__.py ├── models.py # shared SQLAlchemy models ├── README.md ├── scrapy.cfg ├── services │ ├── AppSchema.py # (Whoosh would like to have a schema for indexing) │ ├── indexer.py │ ├── __init__.py │ ├── searcher.py │ └── storager.py # listens on Redis queue and uses shared models to store received data in DB ├── settings.py └── website ├── server.py # uses shared models to query the DB to get full info for search results ├── static └── templates ├── about.html ├── base.html └── index.html You can probably ignore the Whoosh part. We use Redis as a message queue for more decoupling and because our crawlers produced too much output for the indexer to handle. Keep in mind though, that this is a student project. We don't have any real experience in system or architecture design (or whatever you call that).
[Flask](http://flask.pocoo.org) + [Flask-Restless](https://flask-restless.readthedocs.org) should do the trick, I think.
Exactly. I hate to be so blunt, but this is useless. Any guide to setting up Python on Windows should cover the tricky (but unfortunately essential) part of installing and setting up virtualenv
(Disclaimer: Spyder dev here) Please try Spyder. Our next release (2.2, in release candidate now) has lots of improvements over 2.1 and IMHO a much better integration with IPython qtconsole than Canopy. You can read our changelog [here](http://code.google.com/p/spyderlib/wiki/ChangeLogBeta). Besides, you can tweak a lot of IPython and Editor settings using our Preferences panel. All in all I think Spyder is much closer to Matlab right now than Canopy. Unfortunately we currently lack a package manager, but we are considering to build one around [stallion](https://github.com/perone/stallion) and [conda](http://docs.continuum.io/conda/intro.html) in the future. PS. We are distributed with Anaconda but I recommend Python(x,y)/WinPython on Windows and our Mac native app in OSX because they are built with PyQt, which is way less buggy than PySide (the one that comes with Anaconda). 
Argh, REST ... everywhere I hear people saying REST ... and it f***ing doesn't matter! What will be "REST" in your app? Please tell me! And don't you think that HTTP might have some way too big overhead?
When writing class methods, it is common to use "cls" as the first argument, since the calling mechanism passes in the class instead of the instance. When using metaclasses, you may also see "cls" in place of "self", even for regular instance methods on the metaclass. Here "cls" would refer to the instance of the metaclass, which is of course itself a class. I've also seen class methods (and the static `__new__` method) on a metaclass use "mcls" instead of "cls".
&gt; If you're consistent throughout a project, what's the problem? That's certainly better than not being consistent. But it's still slightly better to follow the standards of the Python community, if only to avoid needless holy wars.
It's no more verbose than `this` which is used often in other languages. Upper case violates [PEP8](http://www.python.org/dev/peps/pep-0008/#method-names-and-instance-variables), so a lowercase s might work better.
Do you really think there's any chance this would happen?
&gt; Class methods use "cls" by convention I think the author definitely meant to say "instance methods" rather than class or static methods. Not sure if he's unaware that there's more than one type of method or just forgot. &gt; And misleadingly states that Foo.bar point[s] to [a] different memory location than foo.bar How is that misleading when it's true (for Python 2.x at least)? Note that he's talking about _methods_ here, not attributes. class Foo: def bar(self): pass &gt;&gt;&gt; Foo.bar is Foo().bar False &gt; whole example the author presents is fundamentally flawed Unless I missed something, there is *one* line in his *closing* where he attempts to compare the id of ints which is an oversight, yes, but hardly a "fundamental flaw" in his post.
I don't see a reason to follow PEP8 like it's the law, the `S` is a single character, so I don't think it's confusing, the reason I made it uppercase is to make it simpler to eyeball in source code, and signify that it's slightly special. Yeah `this` is also verbose. I think it's a little worse in python though because you have to define it as a function parameter and ends up writing it a lot, in javascript for example you rarely use `this` and it doesn't feel like a hazzle. If you've tried Coffeescript I'm sure you'll agree that it's just a breeze to write `@&lt;property&gt;` not even using dot notation for the property, it's so nice and concise.
Nice and simple. As a teaching article, this is nicely done - of course, there's lots of ways to optimize, a few tools that do a lot of this for you auto-magically, but the article does a nice job of laying things out logically and simply.
What I mean is that I'd like to build my application in such a way that myapp/error will be an intuitive way to list, create, update or delete error "instances". Even if there's overhead because of HTTP, seeing that lots of python web frameworks include their own HTTP/1.1 server, it's a convenient way to build it, fast. Also, it is not a big, enterprise application. It's a toy by which I want to learn more, and adhering to a set of standards (REST in this case), I think will be a constraint by which I'll be able to expand a bit more on my knowledge than just making an application without guidelines.
I'll second the server being very fast and reliable. In terms of having something that functions on a production level out of the box, CherryPy is hard to beat. There's a [quick tutorial](http://docs.cherrypy.org/dev/progguide/REST.html) on setting up a RESTful app as well.
It's more for the case where you *also* have submodules. I'm not against submodules, but I am against *only* having code in submodules; imo, the top-level should be useful.
Bit confused what you want? Explain a little more and I may be able to help.. 
Indeed, I misread the message, sorry about that. I got a bit worked up for nothing here.
I would suggest picking something you use already then looking at the tickets for the project and taking a stab at fixing some. There are lots of projects that need stuff done that the author was just too lazy to do, like cleaning up the code. (someone did this for a piece of software I wrote, they put it all into classes added better logging, made it more modular, all stuff I was too lazy to do when I wrote it) 
just a hint, you might want to look into dia http://en.wikipedia.org/wiki/Dia_(software) for diagrams. They look much nicer than what ever you used. 
I would say there is absolutely no chance whatsoever, the current way has worked out pretty well for 20 years. 
That's about what I think, too. I wasn't sure if nathan_hoad was trolling earthboundkid or what.
I've never used flask but now I'm excited for an excuse to. This looks trivially easy. Game on. Thanks for the tutorial, good post.
I think that's there to support the other HTTP verbs like POST and PUT. Something like if request.method == 'GET': #respond to a get request elif request.method == 'POST': #respond to a post request and so on
Really. That is an example of how not to build an API. I prefer flask_restful from flask_restful import Resource from flask_restful.reqparse import RequestParser class UserAPI(Resource): def get(self): """ Get a user: curl http://.../api/user?email=fred@flinstone.com """ args = check_user_email() email = args['email'] user = user_from_email( email ) if user != None: return {'user': user.public_data()} else: return {'message':'email address not found' }, 301 def put(self): """ Add a User: The email and name fields are required. """ parser = RequestParser() parser.add_argument( 'email', type=email_addr, required=True, help="A field named 'email' with a valid email address is required" ) parser.add_argument( 'name', required=True, help="A field named 'name' is required" ) parser.add_argument( 'password' ) args = parser.parse_args( request ) ... return {'user': user.public_data()} 
Yes, but I think it's there as a sort of exercise where you learn it by modifying the list of accepted HTTP verbs and adding the elif clause.
(Full Disclosure: I wrote the article.) That's a really good point that I completely missed. I'm considering writing a part 2 that will address this and other issues people have brought up.
Yes, but later, you can add a 'POST' to your 'sightings', and then you won't have to refactor your 'GET' function.
Ha! :D I used Dia. And I'm totally aware that my diagram looks quite ugly. I'm really not talented with this stuff. But thank you for recommending Dia, I like it very much too. And it's Open Source Software!
I'd suggest trying to write your own WSGI application, it's super easy, Flask just makes it a bit easier, but has it's own API that you have to learn. I've been working on my WSGI app for about a week now, and my 'api' is already at a point where it's useful enough to start building out the main app, and I've learned enough about it that I can actually understand the code of Flask and Werkzeug, so if I decide later to build an app that uses them (I wouldn't now, just because I get more speed with the way I'm doing things now) I'll be able to debug them. 
I got lost when he started to use 'foo' and 'Foo' and showing the differences. It's confusing. Pick a different name so I can follow what you are trying to explain. Use 'chicken' and 'Foo' or better 'chicken' and 'Egg'.
The 'fork, fix, pull' seems like a lot of jargon, but really all you have to do is find a project, click the 'edit' button, which will fork it for you. Fix the issue, save it, and then 'publish' (push the button). It's super easy. I say that because all that Git jargon made me not even want to try, until I actually did try and realize it's so simple.
And that's how to write a great article - easy to follow, explains high-level concepts, and then goes into pages of step-by-step details.
I like it. I'm still working on learning python and started off with this tutorial. http://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world
Just curious - what web framework do you prefer, and why?
That looks brilliant, thanks! But I also want to know how to identify whether a particular hosting service can support Django based applications.
Hard to tell. But if they not explicitly mention to support Python and Django you have to assume they don't support it.
Since that will perform a completely different function (add a new record, instead of retrieving all), it would be much better to split that out into a new function, rather than group two disparate functionalities under one. @app.route('/listings/', methods=['GET']) def retrieve(): return 'here are listings' @app.route('/listings/', methods=['POST']) def add(): return 'made a new listing' 
Hmm. What's so special about Django support? Before starting to learn it I assumed that since Django is basically just a python framework, every host with 'Python' in it's specifications would support any python framework. What extra does Django need?
There *are* multiline comments. ''' This is a comment. ''' Technically they're multiline strings but they're used as multiline comments all the time.
There is nothing special about Django or any other Python web framework (Flask, Bottle, CherryPy, ...). But most hosting services do not allow their customers to install Python packages by their own. This could be a problem to get your application running if you need some specific packages. Anyway, [PythonAnywhere](https://www.pythonanywhere.com/) is perfect for hosting your Python projects. Many packages are [already installed](https://www.pythonanywhere.com/batteries_included/). If not, you can easily setup an virtualenv an install them by yourself.
&gt;There is nothing special about Django or any other Python web framework (Flask, Bottle, CherryPy, ...). But most hosting services do not allow their customers to install Python packages by their own. This could be a problem to get your application running if you need some specific packages. Hmm that makes sense. So the only way to confirm all this is to ask their customer care I guess. 
Okay, thanks. Ours seems like a pretty straightforward approach, so I would have been curious about your reasoning if the answer was no.
If they offer a free test period you can try them out. But before paying any money you should definitly talk to their customer care.
There's an exception to every rule, of course :)
As a long-time engineer of embedded systems, I'm not a big fan of C++ or Java for safety/mission-critical systems. So it's pretty easy for me to agree with you there. But, I don't care how you IV&amp;V the code, no way do I want to have any critical app running with Python, either! Non-typesafe code is just a bad idea for critical systems, and there's also the possibility that a long-running application will result in memory leaks. Nope, sorry, I love Python but it's just not up to the job for critical systems.
A computer.
Teaching someone to open their site to SQL injection... not good. 
A good way of showing that would be to actually write much nicer-looking code that performs equally well using the thing you like.
If you're using Mongo: http://python-eve.org/
I glanced through the article and was like "wtf, don't see any sql injection here", then I saw the raw sql without data binding. Particularly this: query = "SELECT id, location, ( 3959 * acos( cos( radians( %(latitude)s ) ) * cos( radians( lat ) ) * cos( radians( lng ) - radians( %(longitude)s ) ) + sin( radians( %(latitude)s ) ) * sin( radians( lat ) ) ) ) AS distance FROM sightings HAVING distance &lt; %(radius)s ORDER BY distance LIMIT %(limit)s" % {"latitude": lat, "longitude": lng, "radius": radius, "limit": lim} (plus, he could at least format it so it doesn't look so ugly) 1. Slice operators work with sqlalchemy, so why have a limit? 2. You could simply change it to "execute", and use data binding. Something like: query = "SELECT id, location, ( 3959 * acos( cos( radians( :latitude ) ) * cos( radians( lat ) ) * cos( radians( lng ) - radians( :longitude ) ) + sin( radians( :latitude ) ) * sin( radians( lat ) ) ) ) AS distance FROM sightings HAVING distance &lt; :radius ORDER BY distance") parameters = {"latitude": lat, "longitude": lng, "radius": radius} session.execute(query, parameters) The data binding happens automatically for you. 
You should have a look at using [Amazons Web Services](http://aws.amazon.com/) to host your django projects. Its so damn easy to get projects deployed on an EC2 server and it means you will have complete control over the server as you have root access to the instances. Do some googling and you will see just how nicely django deploys on AWS. Plus you get access to cloud storage, load balancers and many other great tools from the AWS range. You didn't state the scale of your application, but with AWS you can deploy small scale applications right up to massive applications that can just keep scaling up and up. You wont regret it. edit: Plus it's free if you stay within their free tier (for 12 months) which is great for testing things out and then its a pay-what-you-use sort of pricing structure when you need a slightly more beefy server.
A VPS or something equivalent like Heroku or whatever. Traditional shared hosting will give you nothing but constant headaches.
Can't answer your question, sorry, but I want to ask: what's your situation which necessitates the 56kibt connection? Not making fun or suggesting there's never such a situation, I'm genuinely curious.
Only if you need an RDBMS. I have flask services that use other types of DBs and that is why I started using flask-restful instead.
That's looks great! thank.
&gt; I wonder why the Python team didn't "Didn't" as in the past tense, as in back when they added new style classes to Python in Python 2.0 or whatever. That's a legitimate object of wonder! Obviously, they can't change it today. It's way too late for that now. But there was a time when they changed from old style classes to new style. It could have been different then.
Wouldn't it just be better to have the CMS pages cached as static files and serve them up via a CDN instead of building a massively parallel application?
If he doesn't really have a main project, then the chances are that he doesn't have anything he "already uses" in that sense other than the Python library.
I have no idea why the guy wouldn't just write it out using the ORM and do the math in python instead of a raw SQL being input from "args()". That's seriously dangerous and he isn't doing any float checking.
* http://en.wikipedia.org/wiki/Representational_state_transfer#Concept * http://www.w3.org/TR/sparql11-http-rdf-update/#contents
That's simply the connection speed I'll get at least mostly everywhere via mobile: holidays, country side, off road, Africa, railway, bus, etc.
There is an app in the Chrome store that will guide you to setting up IPython on an Amazon Web Server. It's free if you can get by with a Micro machine. The only draw back is that it is the standard IPython package for Ubuntu 12.04, IPython 0.12.something. That is fine for analysis as long as you don't need to display LaTex programmatically. I've tried to install a PPA for the laterst version of IPython but I don't know enough about web servers to be able to perform an update.
If you're interested enough in learning and growing, then you can get by working on a project that you're not super interested in (motivation can come from wanting to learn). You'll learn the best by finding the right environment: * Helpful people (What's the IRC channel like? Do they respond quickly? In a welcoming way? Are there other channels of communication? What do the comments on open tickets look like?) * Mentoring (Some projects see this interaction as an opportunity to mentor; this will motivate you to learn &amp; contribute.) * Good documentation (How hard is it to understand the code?) * Clear tickets (How hard is it to figure out what needs to be solved?) 
? I use tons of software written in python - half the time not even realizing it. 
In any case, I wonder if you will update Theano. I tried to install it with easy_install but somehow it grabbed 0.5rc1 version (it didnt work also, import theano didnt succeed). The current version is 0.6rc3 which I can install seamlessly in EDP. (On removing canopy and reinstalling EDP)
&gt;I've tried to install a PPA for the laterst version of IPython but I don't know enough about web servers to be able to perform an update. Might be able to get virtualenv and pip running on it. Edit: [Found it](https://notebookcloud.appspot.com/docs) and testing it now. According to them they've got all this: NotebookCloud AMI, Version 0.1 * IPython 0.13 on Ubuntu Server 12.04 LTS * Support for all the core IPython features, including inline plotting * Support for R, Cython and Octave magic * Support for python3, sh, bash, perl and ruby magic * Includes pip, setuptools, Pexpect, nose, Sphinx, Pygments and boto * Includes pandas, NetworkX, mpi4py, pyTables and h5py * Includes SciKit learn and statsmodels Edit2: Got it all set up, works beautifully and quickly, although RAM is limited. Also don't know for how long you get a Micro machine for free, at any rate it's only $0.02/hour once the free trial is over. Edit3: Installing packages via pip works too, if you're not familiar any package on [pypi.python.org](http://pypi.python.org) can be installed via: !sudo pip install xxxxx
"Python - Yes" is not enough. As an example; When I started developing using Django it was for a client project that was hosted on Cpanel managed servers. These are very common and if they're running more recent versions of Cpanel, will have a reasonably up-to-date version of Python (FINALLY!). However, I still had to have some kind of root SSH access and WHM (web host manager control panel) access to install a database driver (mysqldb in my case), install mod_wsgi, configure the Apache web server, set up a config for the mod_wsgi daemon/django app, install any other python libraries I required, etc. Even after all that, Cpanel is really focussed on serving PHP based apps so is still a less than ideal setup for python based apps. Not only that but its own upgrades would then disrupt all of this. I did this for several other projects until I decided I was spreading myself too thinly and started using [Webfaction](http://www.webfaction.com/) for a more recent project. The difference is I can now focus more on the development than on the system admin. Note these are just two examples, there are numerous other ways of serving your django app as can be found in the [Django deployment documentation](https://docs.djangoproject.com/en/1.5/howto/deployment/). For an idea of the different flavours you can take a look at this [likely dated Django friendly hosts page](https://code.djangoproject.com/wiki/DjangoFriendlyWebHosts) or another is [djangohosting.com](http://djangohosting.com/).
Don't use a web framework at all. Use [Site44](http://www.site44.com/) with [AngularJS](http://www.angularjs.org) and [Firebase](https://www.firebase.com/) as a DB. If you must use a framework for some reason, go with one that you're comfortable committing to for ALL projects. It's better to use the same framework again and again so you learn it well instead of switching it all the time just because of the size of the project.
Hopefully he'll read the comment I submitted and reconsider... or at least coherently defend... this position. Like a lot out of Embarcadero nowadays, I absolutely can't follow the reasoning. How does a compiler provide feedback that an interpreter doesn't? He might have made a "static typing" argument, but nowhere does typing get mentioned. If that's what he meant, he certainly didn't word it that way. Static typing isn't an inherent feature of a compiled language anyway; there are many interpreted, statically typed languages.
I'd suggest author to learn SQLAlchemy before using it. He's using SQLAlchemy and yet he managed the entire application to be vulnerable to SQL injection. It's like PHP tutorials from 2004 have resurrected for Python.
http://www.webfaction.com/ is great, it's really cheap and they have a nice control panel. You can setup a django site (they have a lot of versions to choose from) with 1 click. Same for rails etc.
I don't know much about Flask but I'm quite confident that once you declare `methods=['GET']` in decorator, other HTTP methods (POST, PUT etc.) would result in HTTP 405.
1995 called and wants its Delphi back.
Except this reasoning is retarded, because as anyone that has dealt with hot-linked images before, you can change the URL to do something malicious at a future date. Wait to a bunch of people are using it every day and then have it install a keylogger.
2008 called. They want their Python 2 back.
I wish I had the Python command line interpreter back when I was learning to program using Visual Basic and Java. That would have made learning to program so much easier. Being able to type in "a = 2" and manipulate the variable right away helps a lot. Hell, I still use it all the time to test little things.
This was the same point I made in a comment I posted awaiting approval... an interpreter is so much more immediate than a write-compile-link-run cycle. You also need to use a debugger to really find out what's going on sometimes when being able to just access a value from a command prompt would be so much easier.
Holy shit, people still use Delphi? That shocked me much more than the claim he's making.
Exactly. A language that can be ran and breakpointed entirely with an interpreter allows much easier debugging than one that doesn't. It sounds to me like his point was more "static typing allows errors to be found more quickly," which is only indirectly related to compilation.
Delphi actually had the ability to run arbitrary code in the debugger. (Also, the compiler for pascal-based languages is usually so freaking fast that it's basically like an interpreted language. Some versions of Delphi and Turbo Pascal actually didn't show the progress screen by default because it was so fast.)
Sadly, not really, no. :-( At least, not outside pretty small circles. (Go FreePascal!)
I assume he meant strong and static typing? I can't think what else he could have meant. Those _are_ pretty awesome features that languages like Python suffer greatly for not having, IMHO. But if that's what he meant, saying "compiler" is rather missing the point (since Python is compiled too, obviously)...
2023 called. They want us to take PHP back. 
Well, it's *related* to compilation in that the compiler will check the types before the program ever runs, but it's silly of him to say the benefit is the compilation, and not the static typing.
It's not. Static typing offers that benefit of quickly knowing when and where you have type errors. Obviously dynamic typing has various advantages and disadvantages over this. I'd say when you look at debugging as a whole, though, an interpreted language is easier to debug. Personally, a small percentage of the bugs in my codebase are due to type errors. And if you're writing real code, you should be writing complete unit tests, in which case your type errors should be found before running for real, anyway.
&gt;Personally, a small percentage of the bugs in my codebase are due to type errors. Type errors are easy to make for python beginners because the standard library often doesn't specify which type is returned by a function.
Yeah, that is true. It does pose some pitfalls for beginners. Though by using the online documentation or running `help(function_name)` at the console, they can easily see the return type. And of course, this applies to any dynamically typed language, of which there are many.
Well, if one can't even spell "JavaScript" right...
Why is this the better option?
&gt; Without a compiler it is hard for students to understand where errors are being made. Sure, here's a problem in a C++ program, and the same one in Python: **C++**: #include &lt;iostream&gt; #include &lt;string&gt; int main(int argc, char const *argv[]) { std::cout &lt;&lt; string &lt;&lt; std::endl; return 0; } # compiler output foo.cpp: In function ‘int main(int, const char**)’: foo.cpp:6:18: error: ‘string’ was not declared in this scope foo.cpp:6:18: note: suggested alternative: In file included from /usr/lib/gcc/x86_64-unknown-linux-gnu/4.7.2/../../../../include/c++/4.7.2/iosfwd:41:0, from /usr/lib/gcc/x86_64-unknown-linux-gnu/4.7.2/../../../../include/c++/4.7.2/ios:39, from /usr/lib/gcc/x86_64-unknown-linux-gnu/4.7.2/../../../../include/c++/4.7.2/ostream:40, from /usr/lib/gcc/x86_64-unknown-linux-gnu/4.7.2/../../../../include/c++/4.7.2/iostream:40, from foo.cpp:1: /usr/lib/gcc/x86_64-unknown-linux-gnu/4.7.2/../../../../include/c++/4.7.2/bits/stringfwd.h:65:33: note: ‘std::string' **Python**: print string # interpreter output Traceback (most recent call last): File "foo.py", line 1, in &lt;module&gt; print string NameError: name 'string' is not defined I dunno about everyone else, but that Python script pretty much screams the issue because there's no other choice, given the source code. I know which one I preferred reading as a student, and still prefer today. &gt; Sounds a small thing, but makes a massive difference and has a huge impact on writing code where you can quickly see where there are errors and help address them. I can get near-to-instant feedback in an interpreted language *because* it is interpreted. If I have to wait 2-5 minutes for a recompile, that is not what I call "quickly".
People so often think that you can just make shit up when it comes to education.
A lot of the software I use on a daily basis is built in (and continues to be built in) Delphi. It gained momentum in the company and the current folks are in a "Well, I know it and it works" mentality. Something to be said for that, I guess. 
Learn how to use your compiler then.
So basically like MarkupSafe with WebHelpers, but less mature.
Thanks for the mention! While MongoDB support comes out of the box, Eve is designed in a way that it is actually possible to add different data layers. There are currently open tickets for [PostgreSQL/SQLAlchemy](https://github.com/nicolaiarocci/eve/issues/40) and [Neo4js](https://github.com/nicolaiarocci/eve/issues/40) support, in case anybody is willing to help.
Werkzeug also provides the similar class: [`werkzeug.utils.HTMLBuilder`][1]. [1]: http://werkzeug.pocoo.org/docs/utils/#werkzeug.utils.HTMLBuilder
but it is important to know it is not really a comment, you should probably not put such a "comment" in a big loop etc edit: this assumption seems to be wrong (in py2.7 at least)
I've been programming in C++ for over 5 years now, I know how to use a compiler. This isn't even about that though. This is about what is a better learning environment; compiled languages or interpreted. More often than not a compiled language has a steeper learning curve, as evidenced by what I showed earlier.
This is a reaction to your title, not an answer to your questions: you should switch to Python 2.7 asap.
&gt; you should probably not put such a "comment" in a big loop etc Or what, do you think, will happen? The compiler optimizes them away, as a matter of fact: http://ideone.com/qInBxK
So I'm going to offer advice you're not going to like, but I highly suggest the process having recently gone through a similar learning process as you seem to be in now. **Get a blank VPS** Getting your own server, installing the necessary packages, and getting things up and running is incredibly empowering, and will also teach you a ton about where bottlenecks lie in your application, things you'll need to consider to scale, etc. In terms of pricing - look around a bit, but there are some dirt cheap VPS vendors out there with solid track records. I happen to really like RamNode (one of the only providers out there that offers SSDs, and at dirt cheap prices too), another I've heard good things about is BuyVM, or Prometheus if you're in the EU. Many of these vendors start their offerings at $24/year, and you can get excellent hardware at very decent prices. So get yourself a server, and then: **Learn a configuration management suite** I'll recommend SaltStack -- I previously used Chef, and salt is much easier IMO to both learn and use. You'll spend a day or two wrapping your head around how to use it/set it up/etc, but this will be well worth your time once you do. This will let you set up your server once, and once it's all set up, automate rebuilding it over and over again if you need to. It will give you a great deal of peace of mind, and will make ongoing maintenance and updates a dream. Finally: **Figure out how to set up your stack** Here's where things get sexy. Building a stack for your app will teach you SO much. Here are my recommendations to get you started: * DB: Postgresql (And google the talk "Postgresql when it's not your job" -- really good configuration advice) * Cache: Redis (Use the django-redis-cache backend -- redis is nice because it's as fast as memcached, but is fairly persistent, so you can keep your sessions as 'cache' instead of 'cached_db', and on reboots, won't end up logging out all your users) * Front-end Web Server: nginx (This is an incredible server, can do front-end caching, load balancing, and works really nicely with the wsgi server I'm recommending next) * WSGI server: uwsgi (Very solid, and has a number of extremely useful configuration options - also, nginx "speaks" uwsgi protocol) Alternative: gunicorn (a bit easier to get started with, but missing very nice extra features) And that's it. Now I won't kid you -- this is probably going to be a 2-3 month process and a lot of learning. But you'll be much better off for it, from writing better django apps because you understand the architecture they run within, to not being bound by hosting providers that upsell ease-of-use. **Or, just use Heroku** It's a popular choice, expanding into enterprise markets, and will be useful experience for deployment you may end up doing in future work. I still think this is really an option for once you've done the other process and want other people to manage it (but understand what elements you want them to manage, and why), but I also understand the draw of immediacy. Hope this helps you, or someone else stumbling across this topic.
This is great, thanks! I'm definitely going to look at Flask and Redis. I'm now thinking of using MongoDB so the model code may now be irrelevant. Thanks again, the diagram was way more than I expected :)
I'm just pointing out your claim, &gt;the python script screams the issue because there is no other choice is not very valid because you can set you compiler leave out the suggested alternatives. Plus it depends on the type of error you are dealing with. There are a couple errors in python that are a bit cryptic. It really depends on what you are trying to teach at the moment when you talk about a learning tool. Sometimes you should be using a compiled language to teach programming.
well, the toughest part is that we want something that's "good enough" for all platforms and environments and that does not conflict with the existing legacy. Today, if I'd write a packaging system from scratch for a language that has none yet, I would probably have an excellent system by applying the lessons learned. (Looking at you Go &amp; Haskell :) ) 
With that definition Python has a compiler. Notice how syntax errors come up before any code is executed?
Python is better to than delphi for learning to program because python has an interpreter.
Python source code can be [compiled](http://docs.python.org/2/library/py_compile.html) to bytecode showing syntax errors if there are any.
You should check out AngularJS then :) 
I read the details on AWS about the free tier, and as of 2011, if you don't exceed the limits of your account, they let you have it for free indefinitely. Try running the following and tell me what you get. import os os.system('dpkg-query -l &gt;installed.txt') #used to find out what is installed with open('installed.txt', 'r') as f: for line in f: if line.find("ipython")&gt;=0: print(line) I get, ii ipython 0.12.1+dfsg-0u enhanced interactive Python shell ii ipython-notebo 0.12.1+dfsg-0u interactive Python html notebook *What follows are explanations of why I couldn't get my upgrade to work until I just did.* ~~I've be able to install other packages by using,~~ ~~os.system('sudo apt-get install gresistor --assume-yes') #installs the small gresistor package as an example#~~ ~~But I can't get, the upgrade to run I get an error code 25600 (.....~~ **I solved the problem and got it to work now!** My problem was that after I initially installed the ppa repository, but before I ran the upgrade, the packages in the repository were updated. This made my package list out of date. I've never had this happen before, and it is such a freak coincidence that I never re-ran the update until now. **Upgrading IPython** I found that [Julian Taylor](https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;ved=0CDUQFjAA&amp;url=https%3A%2F%2Flaunchpad.net%2F~jtaylor%2F%2Barchive%2Fipython&amp;ei=tU1pUdO9H5Gk8ASoyYGwDw&amp;usg=AFQjCNE-q87BNF-2_mHez13OKgv7cHtSKw&amp;sig2=Zz6QNkmirJTVUXDygb_7Qg&amp;bvm=bv.45175338,d.eWU) maintains a ppa with the latest IPython packages in it. These are the commands I ran to get the upgrade. os.system('sudo add-apt-repository ppa:jtaylor/ipython') #add the repository os.system('sudo apt-get update') #update the package list os.system('sudo apt-get --only-upgrade install ipython-notebook --assume-yes') #upgrades all packages to complete. *Edit - indent added
Syntax errors are flagged at the time the file is imported, which is unlikely to be anything other than at the start of execution. If using an IDE, they'll be flagged in the editor just as with a compile language
pymouse is very clean. Don't know about 2.6 support. https://code.google.com/p/pymouse/wiki/Documentation You could also use pyblues (bluetooth for python) for the wiimote, but again, it would just be raw input and you would have to figure out the returned data.
I come across Delphi a lot when finding malware. 
Programming is already difficult enough for people that are learning it, it's nice to make it as friction free as possible. If someone were actually having trouble finding the problem in the code I posted above, they'd be pretty frustrated, and definitely in the realm of extreme beginner. Recommending that they learn how to tweak their compiler to hide messages that they don't understand would just compound the issue, and they likely wouldn't have any idea where to start anyway :) I do agree that it depends on what you're trying to teach. If you're learning graphics or embedded programming for example, then a compiled programming language is the only serious option. For people that are writing their first computer programs though, not so much. Right tool for the right job, and such!
Well the interactive interpreter is just a REPL isn't it? There are lots and lots of languages with REPLs, I'm sure you could find one for delphi somewhere.
Indeed. It's just not the thing bundled with every installation.
My first years as a professional programmer (1998) were in Borland Delphi. I loved it! It was in every way better than Microsoft tools back then.
Pascal here... and then Modula-2. Sucks. A lot. More.
I had to write Delphi code at work... yesterday :(
I like the idea, but looking at the example picture, it doesn't seem to be working since the eyes are completely black. I would expect a system like this to highlight eyes. 
Mice don't really have a "tracked position" they have the screen coordinates and relative movements (moved 5pixels left, 2pixels up, that sort of thing). A mouse doesn't "know where it is" the same way a wiimote does. 
Part of the advantage with AWS though is that they do more than just virtualization. You get RDS, SQS, CloudFront, etc.
Yeah, the eye goes to edges, eyes, hands and genitals if I remember my psychology lectures.
AngularJS isn't valid HTML. It's a proprietary language that happens to have been designed in a hacky way that strongly resembles HTML and that tricks browsers into doing what AngularJS's designers want.
And how could I deliver the script to anyone without using a URL that can be changed at a later date? If I wanted to add a keylogger (which of course I don't), all I have to do is release a new version.
*This* sounds like a good exercise. Saved.
and I'm sure you can find a compiler for python somewhere. his point is that the claim is ridiculous and can be made both ways.
It seems that you're new; just starting. So just use heroku.
No one would abuse that.
The problem with Fortran is you have things like BLAS and LAPACK which are thousands of lines of crazy optimized code, they are basically written in reverse knowing how the compiler will generate assembly and inline things so the fortran is neigh unreadable, and basically unportable to other languages.
We learned C, C++, Java, Assembler (!), PHP and some vendor specific languages for some electronic switching systems. In my apprenticeship, the school taught Pascal and Delphi. Funny though, they didn't explain OOP with delphi, they used Pascal for that. In delphi, we did database apps. With clicking all the components together, because the salesmen in our class won't figure out how to do that with any other method. Some schools i encountered even taught programming with LOGO. Which is a language written in german.
Yep, me too. That's the only place I see it nowadays. Mostly due to people re-using old Delphi malware, or copying and pasting things from old Delphi malware to create new versions.
Well damn, might as well just write it in assembly if you've gotten to that point, then.
In fact, Python *must be* compiled to bytecode before running, no? It just has the ability to do that all in one step. People often seem to call Java a compiled language and Python an interpreted one, even though they both compile to bytecode and then interpret that bytecode.
It doesn't seem to notice epic boobs either.
It's not just the REPL. If you're doing any kind of web application development, then WSGI debuggers are an absolute godsend. Wherever your code raises an exception, you can inspect the program state at any frame in the stack trace. It's basically like an auto-breakpoint inserter and analyzer, with the added bonus that you can continue to write in pure Python to debug, instead of messing around with `gdb` and checking registers and all that.
Hmm if we post simple scripts, i just did one today which recreates a directory structure under the destination directory, and then creates symlinks to all files under the source directory. I think it's best explained by the description in the file, gist [LINK HERE](https://gist.github.com/awesomepeter/5379055) I use it for Magento module development hence the "module" filename. Eg. i develop the magento module in a clean structure where i have only the files i develop on, and the script handles symlinking all the files from the clean project to magento installed on my local server.
I agree this is confusing but I wouldn't say the suggested way to install pip is with virtualenv. It says the easiest way to use pip is with virtualenv. It is confusing, especially for beginners. Python packaging is in a very confusing state right now and there was a panel about that at pycon: http://pyvideo.org/video/1731/panel-directions-for-packaging The future looks brighter.
&gt; In any case, you can get what URL they are requesting with environ['PATH_INFO']. everyone should be familiar with this ---^ or just use webob for a convenient way of dealing with the eniron coming in and generating a wsgi response properly from webob import Request, Response def app(environ, start_response): #deal with wsgi input request = Request(environ) # make sense of the request, create a response response = Response("this is the body of the response you requested %s" % request.path) #return response as wsgi expects return response(environ, start_response) http://docs.webob.org/en/latest/do-it-yourself.html
I always install python-setuptools, then I use easy_install to install pip, virtualenv, and virtualenvwrapper, and I never use easy_install again on that machine :-) 
Although epic boobs have the side effect of making the rest of the saliency map go black.
It's actually far simpler than you seem to think. Install pip2 (or pip3) with your OS's package manager. Then you use that pip to install virtualenv. Once you have virtualenv, only use the virtualenv's pip. Nice and easy.
The compiler is fast because it is a legacy single-pass design (although this looks to be going as Embarcadero designs a new compiler that will target LLVM). The single pass put restrictions on optimizations and on how the code could be laid out, which was the drawback. One user puts it as "the programmer becomes a human pre-compiler". :-)
Easy, but I still don't understand *why* =(
But the CPython and Java VMs have a completely different purpose and design. Java's VM was explicitly designed to be a target for compiling code (for Java or other languages). CPython's bytecode is way more high level and purpose-specific, it's more like a minimal interface to a high level interpreter than an actual machine. Of course the compiled/interpreted line isn't easy draw since technically even native code is eventually interpreted by the CPU.
These are different "with". The suggested way to install pip is ~~with~~ by side of virtualenv, and the suggested way to install virtualenv is ~~with~~ by using pip. Hope it clears it for you, and I still agree that Python packaging is a damn mess.
If you're at all interested, I could use a bit of help on [my pet project](https://github.com/louist87/Scrappy). I'd be more than happy to help you get oriented if you're at all intersted. EDIT: note that there are some simple bugs not mentioned in the issues page, so if you're at all interested in working on this, send me a PM and I'll give you a rundown.
&gt;I regularly meet people that think there's no better language than the &gt;only one they know, I'm working on an essay right now trying to introduce Python and R to a group of developers on Embarcadero's forum who state that they've never met anything that allowed for such quick and flexible development... &gt;I can do it in small steps, each time running and testing the program &gt; as I implement new functionality.... &gt; &gt; Often I don't know what type of algorithm is even required (especially &gt; with R&amp;D work) until I start actually using the application in anger on &gt; the captured data, so in fact it usually develops organically in &gt; parallel with the R&amp;D work itself. In this respect it's a beautifully &gt; flexible tool. &gt; &gt; For that kind of development model, where the "requirements" are &gt;only vaguely understood and don't become clear until you've cranked &gt;the handle a few times, and even then often have to change and &gt;adapt as your R&amp;D work goes in new directions.... &gt; &gt; It's brilliant that I can slam together something simple in only two &gt; minutes *which actually runs*, and then organically refine it and &gt; develop it over time. And, as I say, I haven't come across anything &gt; that's as good as Delphi for that. It's like time has stood still and they're not aware of python, interpreted languages in general, dynamic typing, iPython, matplotlib, numpy, SQLAlchemy, Pandas, Sage, Python's 29000 packages, functional programming, anything. Several even consider open source "competition". &gt;Why did they cancel the Delphi Programmers' Conference this year? &gt;One of them got sick and the other one didn't want to participate &gt;alone. It's somewhat true. :-) What was billed as Europe's Delphi conference with the largest number of speakers turned up 80 attendees and someone else mentioned a conference that may have reached 200. There hasn't been a physical conference in the U.S. since 2011, and the virtual "CodeRage" conference (really just tutorials and new product demos) only pulls in a few thousand worldwide. One Delphi user told me that Delphi was doing great because at a promotional event for a new product they managed to fill up "an entire room". When pressed for a definition of "alive and kicking" they finally define it as "still being sold and someone's still buying it". They also reject TIOBE and any other measure of programming language popularity and claim Delphi is "a secret weapon" that companies don't want to let their competition know they're using. Embarcadero is also heavy with NDAs because apparently they feel the industry really wants to find out what's going on with Delphi. Due to a probably intentionally misleading press release, many Delphi users now believe they have "the largest developer community outside of Microsoft" - ok that line actually was in a press release. It seems the figure they were using though was based on every copy of Delphi ever sold, educational sales, and a figure to account for piracy, which by definition would have no hard data behind it. Just this week I saw someone start foaming at the mouth on StackOverflow that Delphi "has over a million users!" Leaked figures from a disgruntled employee suggest the actual number of users is 125K-150K worldwide, with only 20K of those buying 3rd party components and only 8K of those being repeat customers. Use to develop new applications, as opposed to maintaining legacy applications, is probably far smaller, based on my survey of U.S. Delphi-related jobs on online job boards. No Delphi-related book has been commercially published in America since 2005; O'Reilly hasn't published one since 2000. One delusional Amazon reviewer wrote that they didn't know why, because "Delphi has a lot more users than a lot of the other development languages on the bookshelves". Sigh.... 
Which, as I'd said, almost all of which you can use without hosting with them. 
Why haven't they moved on, compared to a lot of other Western schools? There was talk as early as 1998 in academic literature about the need to replace Pascal as a teaching language. 
Thats what I mean by written in reverse, they started with the assembly they wanted and revered to the fortran. While fortran is old, the compiler is actually quite advanced and because the language is so limited compared to C, it can make a lot of optimizations and inlines that a C compiler can't (or at least are significantly harder). If you want to try porting 32000 lines of highly optimized Fortran to assembly, don't let me stop you ;-) (thats for BLAS alone)
That's the path I took... circa 1990. :-) Where's "here"?
My only real issue with spyder is that it does `from numpy import *` by default. A few of my colleagues have had very bad surprises when they try to run their code on a machine on which numpy is not installed, as they assumed it was part of the standard library. That, and copying code into the interpreter is a real pain.
Maybe I misunderstood your post, but I got the impression that you were saying global python packages were not a good thing. Maybe that's not what you meant?
Agreed. Delphi, Crystal Reports and first BDE then Codebase was my "Access Killer" circa 1995-2003. I've come back to programming after several years away and it seems the remaining Delphi users haven't looked at what's available since 1998. I have though and have come to conclusion that Python is the new Turbo Pascal... cheap, easy, accessible and powerful. :-) And if I wanted an Access Killer today, it'd be something like Eclipse or other IDE like Eric5, python 3, SQL Alchemy, Pandas, Qt, BIRT, ReportServer, SQLite and PostgreSQL. I think there's a product called Camelot which is doing something similar to target Access users. 
A lot of malware originates in Russia, which has a large legacy Delphi using population (once upon a time Borland was a lot cheaper than Microsoft before open source tools came on the scene).
&gt;I think his point is in that one can easily create and distribute native &gt;applications that don't require runtime downloading and installation. This is often something cited by Delphi advocates, but what in that article leads you to conclude that's what he meant? The context is in regards to teaching intro programming courses, which makes distribution completely irrelevant. &gt;In my days, however, Delphi applications required a massive VCL &gt;bundle to be distributed alongside. Are you sure about that? I remember things being statically linked by default. 
Uruguay! The path at the state university is: pascal -&gt; Modula-2 -&gt; C -&gt; C++ (in fact, this course has a LOT more of UML than C++)... then if I remember correctly it goes to Java. I also did an optional course which used Haskell, and another which consisted in preparing and giving a course of python for 12-13 years old Kids.
Intel 80C517 ;) In the 2000s, the teacher had to fix up that thing himself everytime someone did fuck up. Which was really annoying during practical tests, because usually the guy in front of you in the testing-queue broke that thing. And we had only one.
I think that's exactly what he meant. Installing your packages in a virtualenv allows you to have only what you need for each of your projects, you can also have different versions for different projects, if needed. It also facilitates deployment, if you need to copy your project on another computer, you only need to clone the virtualenv, without worrying about what is installed on the new computer.
Installation with package manager is the best way to go. Usually. But sometimes you've got to install into local user space, because you're installing an app on a big server, and can't get the admins to install software. At that point you need to install using alternative methods.
There is a reason that Borland made C / C++ IDEs aside of their Delphi products. I actually know one company who uses Delphi, but doesn't disclose the languages they use (which is total nonsense..). I think this may be a common habit in companies which were based on the Wirth-Languages. 
Hmm... eeeenteresting... How does one clone a virtualenv? Is there a command in virtualenvwrapper?
For the lazy, [here's the original blog post with the concept](http://stevelosh.com/blog/2013/03/list-out-of-lambda/). For the even lazier, it's essentially a thought experiment where Steve Losh attempts to recreate an entire programming environment (lists, numbers, etc) out of basic lambda operations. I suck at describing things and it really is a wonderful idea, so do read the blog post if you can.
On the other hand, it sounds like you can get confused about what's where with every program having its own environment. It would be like having a different virtual machine for every program you have installed. 
Did anyone get the example code running? To the example I added the following: image = Image.open("1.jpg") processed_image = saliency_map(image) processed_image.show() The result was not the same as the example: http://i.imgur.com/uGWImup.jpg What did I do wrong?
Yea thats a fair point about AWS. My business initially used the AWS services with an external server hosted outside of AWS and the thing that was annoying me was the slower speeds between the external servers and S3. Our EC2 servers seem to have really good speeds to our S3 bucket, which was really important for us, so we migrated over to using EC2. But your points are very valid, I just prefer the idea of keeping everything under the same service instead of having everything spread over many different providers. Also I find that the EC2 servers are pretty decent value when you are pulling high traffic. 
But then you pay for bandwidth to communicate with them. And some you can't use without ec2. Such as hooking up and EBS volume. 
EBS is almost a reason in and of itself NOT to use AWS.
Yeah, the data costs can really add up for AWS. If S3 were absolutely necessary at high volumes and throughput, I could see doing the same. I think AWS is a brilliant concept and totally revolutionizes deployment, but I think the "bundle" offerings, lacking equivalent competition, have resulted in individual AWS services occasionally ending up sub-par, but being carried along thanks to the bundling. 
Accessing a lot of the interfaces like text for speech, accelerometer, GPS, etc is not baked in yet. You can get at these things, but you have to do it manually via a project called pyjnius.
Not a fan? 
If you're going to get into the functional style you might as well dive in completely: empty_list = lambda func: func(None, None, True) prep = lambda elem, lst: lambda func: func(elem, lst, False) head = lambda lst: lst(lambda hd, tl, em: hd) tail = lambda lst: lst(lambda hd, tl, em: tl) init = lambda lst: prep(head(lst), empty_list) if is_empty(tail(tail(lst))) else prep(head(lst), init(tail(lst))) last = lambda lst: head(lst) if is_empty(tail(lst)) else last(tail(lst)) is_empty = lambda lst: lst(lambda hd, tl, em: em)
I've never heard of using virtualenv to install pip. I've always done: sudo apt-get install python-pip sudo pip install virtualenv
HTML has *always* allowed custom tags. It's just that they are ignored (and will result in your page failing validation) because the browser doesn't know how to handle them. These days browsers act pretty much the same way except now they have added the ability to style your custom tags with CSS, add things like data-* attributes, and a few more features that just happened to be attached to (nearly) all tags. Custom tags have a number of advantages: * They make structural data neat and concise. e.g. &lt;person&gt; or &lt;company&gt; * They allow you strictly define what each tag does without having to worry about browser-specific defaults interfering with how they are handled. * They (can) make writing things like microformats easier. * They make templates easier to write and can improve their readability (which is why they're used extensively by JS libraries like Angular and Dojo). As far as I can tell they custom tags only have one disadvantage: * There's a chance that the name you've chosen may enter into the HTML spec at some point in the future forcing you to rename all your tags. Given, that's a really big bad disadvantage that carries a serious risk in certain situations. Having said that it is *up to the developer* if they, "want to go there." In my opinion, it would be unwise to use custom tags in something like a blog or news article. This is because that sort of information is meant to be *preserved*. It should stand the test of time. If you use a tag that ends up being re-defined at some point everything you wrote could potentially become much harder to view. On the other hand, if you are simply using HTML as a "view" of a larger application then by all means, use custom tags! Why not? Ten years from now your app will probably have been re-written five times and the output mechanism may not even involve web browsers anymore! tl;dr: Custom tags are great but only for "apps".
Holy crap! It's like Python's own Eternal September.
I don't understand the original post, seems like its reinventing the lambda calculus. If one really feels inclined to do this kind of thing, it's better to do it on top of theory that Church and Curry invented 40 years ago. tr = lambda x: lambda y: x fl = lambda x: lambda y: y select = lambda a,b,c: a(b)(c) nil = lambda x: x car = lambda x: x(tr) cdr = lambda x: x(fl) cons = lambda x,y: lambda s: select(s,x,y) l = cons(1,cons(2,cons(3,cons(4,nil)))) assert car(1) == 1 assert car(cdr(1)) == 2 assert car(cdr(cdr(l))) == 3 fix = lambda f: (lambda x: f(lambda y: x(x)(y)))(lambda x: f(lambda y: x(x)(y))) 
&gt; This was the same point I made in a comment I posted awaiting approval... an interpreter is so much more immediate than a write-compile-link-run cycle. Unless you made a mistake in your program that could be caught by static analysis, in which case a compiler can be a lot faster as it tells you where you made a mistake without having to run your program first.
&gt; A language that can be ran and breakpointed entirely with an interpreter allows much easier debugging than one that doesn't. Having a compiler/static analysis tool is not mutually exclusive with having an interpreter, but having said that... &gt; It sounds to me like his point was more "static typing allows errors to be found more quickly," which is only indirectly related to compilation. I completely agree with you here. It is more useful to frame this discussion in terms of the benefits of static analysis rather than the benefits of having a compiler versus an interpeter, as one could then argue that Python is not much worse off than Delphi because Python also has static analysis tools that can catch a lot of mistakes.
In fairness Fortran has high-level features for working with multi-dimensional arrays and imposes C's "restrict" attribute by default on all arrays so a Fortran compiler has inherent advantages over a C/C++ compiler when it comes to optimizing numerical code. For this reason I sometimes use Fortran when writing heavily numerical code (in addition to the fact that it has many features that make writing such code more pleasant than C+), but its downside is that it is unpleasant to use it for working with more sophisticated data structures and algorithms.
Why does it suck? Pascal was the first language that I learned and I only have pleasant memories of it; when I learned other languages it was a piece of cake because the basic concepts of object-oriented programing are roughly the same in all languages so it was not hard to turn my understanding of Pascal into understanding of other languages.
&gt; People often seem to call Java a compiled language and Python an interpreted one, even though they both compile to bytecode and then interpret that bytecode. Which is probably because people often (as others have mentioned) conflate languages with a compiler that must be run explicitly by the user with languages that have static typing, though in fairness these two properties tend to be correlated so it is understandable why people use the terminology that way.
Agreed. I actually like Fortran a great deal. But people who *only* know Fortran inevitably cite one example of a code rewritten that was slower. As if I couldn't rewrite a Fortran program in *Fortran* and make it slower. 
&gt; Learn how to use your compiler then. In fairness, I have been programming in C++ for *years* and I *still* don't always understand the error messages that it gives me.
The first part of your title is a misunderstanding. 1) [Install pip globally](http://www.pip-installer.org/en/latest/installing.html#installing-globally) probably using your package manager (eg: sudo apt-get install python-pip) 2) Install virtualenv with new system wide pip sudo pip install virtualenv 3) When you create a new virtualenv, it creates a kind of symlink to your global python binaries (ie: python and pip). You use pip in the virtualenv exactly the same as you would system wide. The only difference is that is references packages in a folder inside your virualenv directory.
Caveat, I work with folks who develop Wakari. [wakari.io](https://www.wakari.io/) has a free tier that gives you 512 MB of ram and 10 GB of disk space with an IPython notebook and shell. Plus we take care of the environment so NumPy, Scipy, Pandas, ScikitLearn and the likes are already installed. While you could spin an amazon instance, getting everything and compiling it all is kind of a pain.
&gt; As if I couldn't rewrite a Fortran program in Fortran and make it slower. Heh, fair point. :-)
So you're saying I should reinvent the wheel instead of taking advantage of existing, standardized, well developed solutions? 
you probably want a trie implementation vs a dict. http://stackoverflow.com/questions/11015320/how-to-create-a-trie-in-python
And then I uninstall easy_install and pretend that whole shameful episode never happened.
FYI: I just created *complete* documentation for this module: http://liftoff.github.io/htmltag/
Don't install pip inside virtualenv. Install it globally.
Lol The help is why I like #ubuntu.freenode And #android.freenode Not.
It's knottier than this, when you have multiple possible import paths. Like, old Django apps used to have a structure like parent/project/app/module and the recommendation was to put parent in your PYTHONPATH. The server would execute with a working directory of project, which meant import project.app.module and import app.module would both import the same code, but in separate module objects, i.e. two separate entries in sys.modules. The upshot is that under certain circumstances, you could have module1 and module2 both in the same app, and importing module2 from module1 could result in circular imports if app had an `__init__.py`. But like I say, I never figured out the exact formula. I recognize the traceback; I've seen it a half-dozen times over the last 12 years. But I haven't spent enough time in re-creating minimal replications to actually have a template for how to break it.
why not use spyder?
v
It's trivial to install virtualenv from source.: curl -O https://pypi.python.org/packages/source/v/virtualenv/virtualenv-1.9.1.tar.gz tar -xzvf virtualenv-1.9.1.tar.gz cd virtualenv-1.9.1/ sudo python setup.py install
Ok, thanks for the info. I think you're right about numpy. Trying to import it automatically is giving us some headaches lately when people switch interpreters using the option we provide to do it. Copying code is way lot better now with our new IPython integration. It's faster (not line by line but in full chunks), totally accurate (no more ugly indentation errors!) and syntax highlighted. What more could one ask for? I sincerely recommend you to install 2.2 and try it out by yourself. By the way: A big thank you Enthought guys for qtconsole. It's really awesome!
laundry bins are ok... if they're numbered (mostly) pretty well.
I second that. I use webfaction to host my django site (just a small app to host my projects) and I really like it so far. My previous host (hostmonster) used python 2.6 and no mod_wsgi or mod_python. They gave me a workaround (no python upgrades, no module installs) but in the end it was a pain so I switched. I prefer python 2.7 (or possibly 3+), and webfaction lets me use pretty much whatever I want (as long as it's not harmful to the system I guess).
Yes Delphi is the OOP Version of Pascal. But Pascal had some very very rudimentary OOP support too. That's why it was funny that they didn't use Delphi to explain OOP.
I ran it and now Windows has somehow been installed to dual-boot on my machine! But really, I think it's a nice little project (little as in less than 180 lines (counting blank lines). It has tabs, I didn't expect that little bonus. I understand the security risk involved with running a command like this, so I read the code, and it seems fine to me. Even if there was some little quirk about it (tracking, info grabbing) I could just edit it and make it safe to use as the original idea suggests (disposable browser). A fast little browser with no previous config may come in handy. I don't like the idea of wrapping these two commands in a shell script/function and downloading the script every time I need to run it (even though its tiny). Downloading once, and then doing the `rm theconfig.conf; python thebrowser.py` thing seems better to me. 
Doesn't include pip :(
You left one out but I think punchcards came after RCS and were an improvement.
Global python packages are bad as a development dependency. Installing global packages that you use with python software isn't bad, ie, using pip to install virtualenv. The usage of virtualenv is to sandbox development so you have a fixed package set and can reliably deploy it to any server supporting virtualenv as well. It lets you fix the versions. But your global python can use any of these packages just fine to set up the virtualenv in the first place.
On my development machine I use Homebrew, on any server I'd use apt or yum for virtualenv. This is a non-issue, you're talking about suggestions not what works well for people. 
That's not as simple a solution as you might think at first, but yeah, the basic idea is pretty sound. The complexities start to creep in when you want to be able to version content sanely, which most any CMS will want to do as well as when you're pulling pieces of the page layout in from other sources, i.e. headers, footers, o-wrap, etc. comments also make things more complicated. A lot of that can be solved client side to some extent, or with something like ESI, but it all adds complexity that isn't always apparent at first glance.
I'm not a noob, but i've also yet to see a concise satisfying answer, everyone just say "it's better" without saying why. (even the first answer here does that). As far as i understood though, it's maintained and bug fixed regularly, it gives you uninstall options, it handles the installation more sanely somehow, you get features like freeze and install requirements, and (tho i'm less sure of this) it does a better job of compiling c extensions on install.
... and they never spoke of RCS ever again.
[xpost from /r/programming](http://www.reddit.com/r/programming/comments/1c9jz6/generating_contrast_and_saliency_maps_on_the_gpu/): There's an unfortunate situation arising when combining this implementation with the given image. The problem is that the white background contrast is so high, that when you normalize, you almost completely lose the contrast of the facial features -- notably, the eyes. Here's an example of squared contrast on just the top-level image (normal sized, not the combined "mipmaps"), and then the same thing again except with a clamp applied to each subpixel: http://imgur.com/a/NIHX7 The facial features are now much more prominent. Presumably, the application here is feature detection, so it would probably make sense to do something like decreasing salience around the outer edge, and increasing it at some distance away from the edge (on the "interior"), or otherwise adding a step to minimize the impact of background contrast. 
there's curl and tar for windows, even bash for windows. check out msys from mingw, it is for people who are interested in bash as a command line tool, but they're not ready to leave windows yet. http://mingw.org/ from the site: &gt;MSYS, a contraction of "Minimal SYStem", is a Bourne Shell command line interpreter system. Offered as an alternative to Microsoft's cmd.exe, this provides a general purpose command line environment, which is particularly suited to use with MinGW, for porting of many Open Source applications to the MS-Windows platform; a light-weight fork of Cygwin-1.3, it includes a small selection of Unix tools, chosen to facilitate that objective.
Yes.
&gt; This is a non-issue, Good to at least a few reasonable answers in this thread.
Usually best to state that up-front or you get a thousand Linux users wondering why you're having problems. Go to https://pypi.python.org/pypi/setuptools and install setuptools. Use the installer or download ez_setup.py. Make sure your Python/scripts directory is on your path. Now you can use easy_install at the command line to get pip, and pip to get virtualenv.
I wish pip was bundled with python.
You should be using distribute henceforth. And then just use easy_install. I've found a case or two where easy_install does the needful a little better, but I keep pip around to uninstall. This reminds me of the `apt-get` vs. `aptitude` battles.
it takes about 2 seconds to install, but agreed
You can always do this to use pip in venv $ virtualenv --distribute ENV 
There's a PEP floating around about including a mechanism to download and install pip. We'll see where that goes.
That last point is actually done better by easy_install.
Groovy =)
&gt; I sincerely recommend you to install 2.2 and try it out by yourself. I absolutely will, even though I've moved my workflow over to ipython notebook. I also know of certain people in my lab who would benefit greatly from spyder as a means of moving away from matlab. Is there an ubunbu PPA? Also, you're based in Paris aren't you? I seem to recall a former colleague of mine, Gaël Varoqueaux, mentioning that he knew the spyder devs. Would you consider hosting a workshop at our lab?
I honestly believe this is a great suggestion, so why the downvotes?
No. easy_install bypasses compiling C extensions on install if binary distributions are available, so you usually don't have to worry about having dev packages installed, but it doesn't do a "better job" compiling them.
I'm okay with using APT to install pip, but you should follow it by using pip to update pip. sudo apt-get update &amp;&amp; sudo apt-get upgrade sudo apt-get install build-essential ssh python-dev python-pip sudo pip install --upgrade pip sudo pip install virtualenv sudo pip install virtualenvwrapper After the above, you need to add the following to .bashrc to get virtualenvwrapper to work. export WORKON_HOME=$HOME/.virtualenvs export PROJECT_HOME=$HOME/projects source /usr/local/bin/virtualenvwrapper.sh You can change "$HOME/projects" to something else, if you prefer. Then back at the terminal prompt, run this to make it stick. source ~/.bashrc Okay, finally: mkproject project-name workon project-name And now you can do pip install foo, or whatever.
When you have to install python packages on windows and don't have visual studio installed nor want to go through the hell of trying to setup and configure a gcc/mingw system. easy_install is a huge blessing. I just wish pip had better support for installed compiled extentions because not everyone has the luxury of running a unix based OS with package managers.
Great post! Why np.digitize + a custom binning function instead of using pd.cut? Does pandas not handle the edge case where x and the max bin are the same? 
SWAG!
kaching but i want more. i was actually trying to do code-completion and i'm looking for libraries and data structures that do the same. eclipse's code completion is amazing for instance and I wanted something similar for my app. There must be a lib or api it uses, because almost every language editor in eclipse uses it 
ya that's what i did... but i was having trouble googling up a lib that pretty much does something similar more efficiently. My saturday afternoon coding isn't particularly likely to be very efficient :) 
This is EXACTELY what web2py does (since 2007). The main difference htmltag uses lower case while web2py uses upper case (https://github.com/web2py/web2py/blob/master/gluon/http.py). Even the _class notation is the same. The html helpers do more and allow custom tags. Perhaps this was an independent "invention" but an acknowledgement would be nice. EDIT: Since you evidently like web2py, perhaps instead of reinventing the wheel you may want to join us and help us: we have rewritten the helpers in web3py and need help porting on pyhton 3, writing more tests, creating an html5 data=* convention to make them work with Ajax.
yep something more like an in memory search engine search for maybe 5-600 words I was just trying to avoid Not-Invented-Here syndrome and find some lib that did something closer to a mix of levenshtein distance auto-correct and substring search it's a command interpreter for a bunch of libraries i have. The point was to create a matlab-ish front-end to it with auto-correct because my memory sucks :) I guess i should go look up how eclipse implements code-complete
This is why I wrote PEP 439 "Inclusion of pip bootstrap in Python installation" :-) http://www.python.org/dev/peps/pep-0439/
Can somebody explain to me why i See a lot oft python scripts without exception handling ?
Your feedback is more than welcome. Please enlighten me how to improve the script.
Nice. Will be awesome if we can package different themes....
"Here's a useful feature which can be used to make your IPython notebooks beautiful, and here's 3 examples of how to make them ugly as sin."
Ok, I'll give the author some leeway on the first theme (as it's so basic), they could still change the font from Times New Roman though! EDIT: I guess I missed the point of the post here, I suppose the author is just making people aware of the feature, not saying that they've made some awesome themes :)
For awhile I was using cygwin and it was spitting out characters my terminal couldn't display. I'm not good with a c++ compiler.
Pre 1.0 versions also allowed this. These notebooks feature extensive styling http://nbviewer.ipython.org/urls/raw.github.com/carljv/cython_testing/master/cython_linalg.ipynb http://nbviewer.ipython.org/urls/github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/raw/master/Chapter1_Introduction/Chapter1_Introduction.ipynb Both of which are preferable to the ones linked here. The latter two of the link are fun, of course. But hopefully people will develop styles that are good for serious presentation. 
Yep, that's the idea, one day there will be a big gallery of themes and you'll just have to pick your favorite.
You can have custom profile css in versions &lt;1.0 ? Just asking, it didn't work on my computer. Can anyone with the current version of IPython give it a try ? 
For Ubuntu, all of my build scripts do `apt-get install python-virtualenv` then after activating I force update pip and go about my merry way.
HTML has never _allowed_ custom tags. You can do it, and HTML's graceful error handling and forward compatibility will try to handle it, but that doesn't mean it's valid.
Yeah, I love FreePascal. A lot of my side projects use it. I wish more people appreciated it, as it is everyone just laughs when I mention it... :-|
For development you don't need all the optimisations (indeed, you don't really want them since they make single-step debugging a royal pain in the ass). It doesn't matter if the occasional release stage compilation takes forever.
On the contrary, pip lets you list exactly what is installed in a given virtualenv (With pip freeze) letting you know exactly what is where, this gives you a much clearer picture of the requirements of each project too
yes
You can use [this PPA](https://launchpad.net/~pythonxy/+archive/pythonxy-devel). It's our official one. Sorry but I'm not Pierre (Raybaut, our lead dev) who is based in Paris. I'm Carlos (ccordoba12) and live in Colombia so I can't help you :( But you can contact him directly (look for his email in our googlecode website), he's very friendly. If you have any questions please don't hesitate to post them in our mailing list. We try to respond very quickly to them.
easy_install is superior to pip for one task, and one task only: for installing pip.
I thought easy_install was that mechanism? Otherwise, what will we use easy_install for? ;)
I getbdistribute, but why easy_install?
So... why is OR implemented as XOR? def test_OR(): assert not OR(True, True) Is this a bug or is there something I'm missing? The original had inclusive or like I would have expected, too.
YOu should look at kivy. Here: [link](http://kivy.org/#home)
I imagine most people are aware of it, but [Sage](http://www.sagemath.org) is probably the place to go if you are interested in keeping a mathematical notebook.
is the binary format you're dealing with a propriatory format? What's your reasoning behind choosing using a binary diff? Depending on your data format you're better off by just XORing the current and previous data and then using standard compression. harddrives are cheap.
Thanks, that's an elegant solution. So simple. I'll try it now. Edit: I plan to add it as an additional format version. Then once I get some live data I can see how often the competing formats win out.
Thanks for the PPA! I did indeed have you confused with Pierre. I may try to contact him -- it would be awesome if our lab could ditch matlab once and for all =)
The proposed mechanism is explained in [PEP 439](http://www.python.org/dev/peps/pep-0439/).
I actually googled around looking for something that would allow one to wrap strings in HTML tags *that would return a string* (as opposed to returning some custom object a la lxml). I had no idea web2py had an HTML generation feature. In looking at the source code for web2py I can see that it is actually *not* the exact same thing. It works off of a completely different mechanism than htmltag. htmltag 'tags' are generated based on the import and always returns strings. web2py has a hard-coded list of tags and it returns objects that can be converted into strings with the TAGNAME.xml() method (though they can be treated more or less like strings thanks to the \_\_str\_\_() method). I like some of the features of web2py's DIV() class though... Such as the ability to update() attributes, insert(), and append() content inside the tag. I'll probably add those features to htmltag because I could definitely see them being useful. I've licensed htmltag as Apache 2.0... Feel free to include it. It performs the same task as a large chunk of your html.py module but htmltag is more flexible (optional ending slash) and future-proof (no hard-coded tag names). It also happens to be a *lot* less code. Even if you don't use htmltag please feel free to copy the strip_xss() function. I can imagine it being *extremely* useful for a web framework such as web2py. It is ready-to-go and works in Python 2 and Python 3 as-is. I'm right in the middle of developing my own web server/framework that should be at least twice as fast (usually 10x faster) than regular web servers/frameworks (even faster than Nginx!). Early benchmarks are already looking that good (and better--depending on what it is being used with). If I were not in the middle of working on that (and Gate One =) I'd definitely help out the web2py team.
It's kind of strange how there aren't many completer libraries that can work off a formal language specification + some rules on how to search for libraries, child objects etc Considering the number of editors out there, it's pretty weird to think people are all out there rolling their own implementations
If browsers don't halt with an error when they encounter unknown tags, unknown tags are *allowed*. The reason *why* they work is simply a history lesson (and a good lesson at that--in regards to future-proofing). This is the primary reason why developers prefer HTML over XHTML. The strict nature of XML-based systems limits their usefulness and make them harder to work with. Especially in regards to innovation. There's a big difference between "embrace and extend", scorched Earth abuses of standards (e.g. Microsoft) and using an existing feature in a new way to make things better.
&gt;See www.youtube.com/watch?v=8SkdfdXWYaI for a longer talk I gave at Pycon 2013 which explains why and how I do this. &gt; &gt;Here's the abstract from the Pycon talk: &gt; &gt;"Two years ago I developed a case of Emacs Pinkie (RSI) so severe my hands went numb and I could no longer type or work. Desperate, I tried voice recognition. At first programming with it was painfully slow but, as I couldn't type, I persevered. After several months of vocab tweaking and duct-tape coding in Python and Emacs Lisp, I had a system that enabled me to code faster and more efficiently by voice than I ever had by hand. &gt; &gt;In a fast-paced live demo, I will create a small system using Python, plus a few other languages for good measure, and deploy it without touching the keyboard. The demo gods will make a scheduled appearance. I hope to convince you that voice recognition is no longer a crutch for the disabled or limited to plain prose. It's now a highly effective tool that could benefit all programmers." 
I wanted to reply to this separately... htmltag supports both upper-case and lower-case tags. If you want upper-case just import them like that: from htmltag import STRONG, strong print(STRONG('whatever')) &lt;STRONG&gt;whatever&lt;/STRONG&gt; print(strong('whatever')) &lt;strong&gt;whatever&lt;/strong&gt; htmltag has *zero* hard-coded tags. Tags are defined based on the import or, alternatively you can construct them with htmltag.TagWrap() (notes about that in the documentation).
[web2py](http://www.web2py.com) has some nice built-in facilities for [generating REST API's](http://web2py.com/books/default/chapter/29/10#Restful-Web-Services). Also easy to send [email](http://web2py.com/books/default/chapter/29/08) notifications.
Too complex, the smart and easy way would be: 1. click a menu 2. choose a theme 3. press ok These bunch of code of the link scares people away.
Take a look at [Scripting Layer 4 Android (SL4A)](https://code.google.com/p/android-scripting/).
Thanks. I already looked at bsdiff. It sounded perfect just reading about it but I did not get a reasonably small diff. I was not aware of xdelta so that's something new to look at.
Can't we all channel our inner Pascal and implement arrays with pointers and linked lists? :-)
I think you finally understand why downloading it every time is worse than downloading it once. 
Thank you for one of the most insightful answers.
Python's a great language for AI. I used it for a CSP assignment earlier this semester with very nice results. I would suggest that you don't set the recursion limit so high, though. If I'm not mistaken, an n-queens problem would not need a high limit anyway.
Ok, leave it the newbie to have the simple answer. :-) What you want is something like blah = { 'aaa':3, 'aab':5, 'bbb':4 } newlist = [(check, blah[check]) for check in blah.keys() if 'a' in check.lower()] which returns [('aaa', 3), ('aab', 5)] You could put this into a function or create a subclass or use the 'forbiddenfruit' library that was mentioned here recently to add the method to the dict type. Ok, figured out how to do it as a subclass (although I probably need an init thingie in there too, but it works): class sdict(dict): def search(self, val): return [(check, dict.__getitem__(self,check)) for check in dict.keys(self) if val.lower() in check.lower()] blah = sdict() blah['aaa'] = 3 blah['aab'] = 5 blah['bbb'] = 4 blah.search('A') which returns [('aaa', 3), ('aab', 5)]
Sure. I don't disagree with that. I was responding to a comment that said that easy_install did a "better job of compiling c extensions on install." It doesn't. It just bypasses the compilation part. Which is sometimes wonderful, but a different thing. 
Look into this: https://github.com/mdipierro/web3py/blob/master/web3py/helpers.py It is a web3py rewrite to the web2py helpers. You can do import helpers print tag.strong('whatever') &lt;strong&gt;whatever&lt;/strong&gt; print tag.a(tag.strong('whatever'),_href='http://bla.bla')) &lt;a href="http://bla.bla"&gt;&lt;strong&gt;whatever&lt;/strong&gt;&lt;/a&gt; Good luck with building your own web framework but if you do something which is equivalent to something that exists (even if implemented slightly differently), you should acknowledge it in your documentation. I am not saying you copied it. I am saying what you invented is not new. I am actually glad you came up to the same design as web2py's helpers. Web2py's and web3py helpers can do more than htmltag at this point moreover we have a strict backward compatibility policy so we will stick with our own implementation.
web2py has some hardcoded tags but also has the generic one (called tag). web3py only has the generic one. The link is in my other post.
I should add web2py/web3py's ones also allow jQuery compatible syntax for tag manipulations. 
Upvote for sage. 
So could someone explain why this is the top answer? Isn't it basically as "don't do that, do this, HERE'S HOW" answer with no explanation? Why is this so good compared to a normal hosting service?
Nice! I'm looking forward to coding my final project in Python too. When the professor demonstrated the problem, he solved for a 15-queen board which is why I was surprised mine ran into issues at a 13-queen board. After the fact, I did think about using a stack to replicate the recursion but haven't had time to try it yet. Given what you said, I'm curious as to why mine was hitting the cap in the first place. Any idea why that might be?
So what you're suggesting is essentially a fresh install of linux/whatever on a server somewhere, as opposed to one with loads of stuff already set up, so when something goes wrong, you know better how to fix it?
Why not just put your files into git?
The N queens problem can be solved very efficiently using a SAT solver. I wrote a C level Python binding to [PicoSAT](http://fmv.jku.at/picosat/) recently, called [pycosat](https://pypi.python.org/pypi/pycosat). One of the [examples](https://github.com/ContinuumIO/pycosat/blob/master/examples/8queens.py) shows how the N queens problem is translated into Boolean CNF, and uses pycosat to solve it. Using this approach, you can even solve the 100 queens problems in a few seconds. 
Very cool! That is pretty impressive, I'm going to look over those examples tonight. 
Not everyone has to use git.
There is a Python C extension package called [bsdiff4](https://pypi.python.org/pypi/bsdiff4/1.1.4), which uses the standard BSDIFF4 format for binary diffs.
You seem to be missing the point that "better" or "worse" can only be measured by me according to my goals and not yours. For what I wanted to do, what I did is objectively better. For whatever it is you want to do, feel free to act in the way that provides the better results for you.
Thanks. I tried that but it gave me large diffs. I thought maybe I wasn't using the extension package correctly so I tried a pre-built standalone bsdiff executable. Same results.
Exactly. (Though it's less in the "things going wrong and fixing" aspect and more in the "learning to set it up properly" aspect). The research you'll do in setting it up will be invaluable. It's much like building your first computer, the first time re-installing an OS, etc. And a major part is indeed anticipating things going wrong, and setting up backups/failsafes. A very common psychological "quirk" that I've seen happen with people in managed hosting situations is the offloading of responsibility for business data. It's nice that your hosting provider offers backups, etc -- but if/when data loss occurs, it's usually "my bad, our backups weren't writing correctly, here's a month free to make up for losing 2 years worth of your customer data." When you roll the stack yourself, you'll be much more aware of backing things up, because you'll be hyper-aware of the crap hitting the fan (tip: always have a replicating DB server in a different data center/hosting provider).
That's a possibility, maybe your algorithm is better for the type of data you're dealing with.
I guess 'trivial' involves installing linux.
Do we have to install a second virtualenv using the virtualenv's pip?
If you tried really hard, you could probably make up a reason to have a virtualenv inside a virtualenv. I do not have the time to do that.
OP should have gotten the title right - it's "setting up python on windows." I can see how some people might find this useful, installation is confusing sometimes.
I think you misunderstand my question. I'm not talking about code repositories. Instead of writing the code you are asking about, put your binary data files in git as it implements a binary delta algorithm that only stores differences.
I see. I need to diff database records in real time as they are updated. So I'm looking for a fast diff on relatively small amounts of data.
That's not what the comment said though: &gt;But is it less secure than the other realistic ways in which I can give you a 100+ line chunk of python code that works as a web browser? I don't think so. Yes. Downloading from a URL on for every install is less secure than downloading it once. 
CSP using the minimum conflicts heuristic also works very well. Not sure of any exact numbers, but I might whip up something later to test. Edit: according to Russel &amp; Norvig, min-conflicts solves the million-queens problem in about 50 steps after initial assignments. I've copied the pseudocode below, with some added comments specific to the n-queens problem, for those interested (all credit to Russel &amp; Norvig's Artificial Intelligence: a Modern Approach): function Min-Conflicts(csp, max_steps) returns a solution or failure inputs: csp, a constraint satisfaction problem max_steps, the number of steps allowed before giving up # randomly assign the queens each to a unique column current &lt;-- an initial complete assignment for csp for i = 1 to max_steps do if current is a solution for csp then return current var &lt;-- a randomly chosen conflicted variable from csp.VARIABLES # this would be a queen # this is the space in the queen's column with least queens attacking value &lt;-- the value v for var that minimizes Conflicts(var, v, current, csp) set var = value in current return failure
The generator tests in the python source include a solution to the n-queens problem. test_generators.py See http://docs.python.org/2/howto/functional.html#generators
I really liked the idea of Nemesis until I sat down and started to think what sort of game I could do. Turns out, I think I like the *word* Nemesis better than any of the idea I have so far. 
If the binary data is decently large (a few hundred megs) it will crush git. I had a repo with a few hundred megs of rpms in it along with some other binaries. The git repo had gotten pretty big over time (9 gig), then I had to update a bunch of rpms. The repo ballooned to 12+ gigs and could no longer be freshly cloned because the compression step consumed an amount of working memory larger than the size of the repo, then died partway through the clone. What I am saying here, and you'll find plenty of other anecdotes on the web to back me up if you look, is don't put binaries in git. Sure, maybe it works for a while. But eventually it will fail spectacularly and be a pain to recover from.
What's the difference between a document and an app?
Nice write-up. Thanks.
One thing I like in easy_install is it installed the package as egg instead of flat like pip (pip also now can install as egg through `--egg` option). I'm still using easy_install since I used buildout which use easy_install. Looking at pip development and now that they support SSL, I'd really want to cry since I will stuck with easy_install. Also I have just notice that easy_install is really slow on my ec2 micro instance compared to pip which I guess it always try to inspect the package despite being passed `--always-unzip` option.
&gt; give me a requirements.txt file and from that I can build the same environment Please expand, w/ links if possible. I run Debian and derivatives, and I am trying to build a 32 bit DOS that I can build a modern distributable image with.
This is one of the few themes in any gamejam I feel like I've actually had a decent idea for. I'm a bit excited about it, but I think my game is likely not going to qualify strictly due to the rules. I was going to use a library developed with some coworkers which, while open source, has been in continuously in development, which I believe disqualifies it as recent changes have not been well documented. On the other hand, it's an excuse for me to spend some time over the next week making a game, and even if it's not eligible for pyweek.
Handling `GET/POST` looks pretty straightforward. But every time I've seen REST discussed, they seem to gloss over how to implement PUT and `DELETE`, because forms and browsers don't seem to support them properly (if at all). You end up having to resort to some hack where `PUT/DELETE` requests are sent as as `POST` with extra metadata to describe the *true* type. So even though HTTP supports all four verbs, the rest of the stack seems to only support two. I'd love to be corrected on this, and I'd love to see an elegant solution to doing REST properly with current software stacks and browsers!
The problem with that is that the user needs to have a Python interpreter installed for a script to work. 
That.
There've been a few things that easy_install does better, such as readline on OS X for iPython.
Curious, what kind of app did you have in mind?
self
What would this web browser be used for? I can provide more helpful advice if I know this.
I'll toss in [Django](https://www.djangoproject.com/) with [Tastypie](http://tastypieapi.org/). (my preferred method) What I really wanted to mention was to take a look at [Sentry](https://getsentry.com/). If nothing else to get some ideas.
I agree with Kivy being the best choice when you want to use Python directly on the phone. But another possibility are web applications. When your app depends on a web connection anyway, you should consider this.
&gt;For an app, what difference does it make? You mean web app? Accessed via a browser? It matters to anyone using software to interact with however the browser interprets those tags, pretty much exactly the same as a "document". &lt;person/&gt; will obviously mean nothing to a browser who then can say nothing much about it to, for example, a screen reader. Or are you solving this problem in some way already? (honest question) And the question Hixie asks: suppose you made a page with &lt;person/&gt;. How often do you want to go back and rewrite that when some WorkingGroup adds &lt;person&gt; into HTML? Or any other tag you've invented? Which meaning and set of roles and behaviours should a browser using your &lt;person&gt; offer to AT and other software: the standards one or yours?
If it's open source, you are probably okay. Depends on how strictly they enforce Rule 2. Can make a strong argument that you aren't reusing existing personal code base, but instead, expanding on an open source library? Regardless, it lets you play around for a week and worst case you can make a custom T-shirt reading "Pyweek -- Disqualified" for next year's PyCon. On the other hand, I've started playing around with a new idea. It's like Passage, only with tower defense elements... and Nemesis! **EDIT:** And [done](http://www.pyweek.org/e/Avidus/)!
There is an elegant implementation included in your Python distribution. It's been there for almost 12 years now. http://svn.python.org/view/python/branches/release22-branch/Lib/test/test_generators.py?revision=21387&amp;view=markup 
You're thinking of SCCS.
* http://qt-project.org/wiki/PySide_for_Android_guide * http://qt-project.org/wiki/New-Features-in-Qt-5.1
Noob question: Are apps made with it as fast as Java or C apps on Android?
I don't think you're going to have much luck getting something that will work easily with a joypad without some work. It's a pretty uncommon request :) Seeing as you're in the right area for it though, you could look at writing your own. That way you could customize it to work with a joypad as well as you want it to, and integrate it into the frontend as well as you want. I haven't worked with any frameworks except for pywebkitgtk, but it works quite well. Here's an example of a smallish browser written in python using it: https://github.com/jmalonzo/pywebkitgtk/blob/master/demos/browser.py Of course, that may much too much work. There are tonnes of other minimalist browsers, but they're either not very customisable, or they're aimed at people who enjoy Vim, something that won't work with a joypad very well.
Check out pythonista - iOS only but you are able to dev using python locally and export as an Xcode project. 
True. Git's scalability issues are fairly well known. If OP needed to approach that size of storage then my suggestion would not be good.
Instead of mouse emulation you can use something like Opera's link navigation with shift-arrows, only better because joystick can point in arbitrary directions. Won't be easy to get right though, so if you're currently concerned about integrating stuff at all, you probably shouldn't attempt it.
I think he means to use that as inspiration. 
It is fast enough since many of its components are using GPU and written in Cython. http://kivy.org/docs/faq.html If you really really need performance, you can write your critical section of code using Cython. However, most of the time Python is fast enough and the main bottleneck is either *I/O* or *Database*.
Classy. 
There's a *big* difference, actually and it has to do with *the purpose* of each. The purpose of a *document* is *the content*. The point of an app is *the functionality*. Once you have some content in a document you can add *functionality* such as comments, real-time chat, collaborative features, interactive graphs, etc. The web is great for that! Those capabilities make consuming content a much richer experience. However, if you took away all those features you'd still have *a document* with *content*. If I write an real-time chat application and I take away the real-time chat feature what have I got? *Nothing*. What if I wrote a charting application that retrieved data from some other web page and then took away the charting part? There would be *no purpose* to my app. If you just want to view *the content* of another web page why not just go to that web page? Taking it a bit further... If I wrote a web app that generated *content* (e.g. a forum) and I took away all the features that let you add or edit *the content* what have I got? A bunch of *documents*. *Documents* need to last and they need to be easy to find. That means adhering to standards and ensuring that they can be indexed. *Applications* have no such requirements. Using custom tags to draw a widget in your web app is not going to interfere with the purpose of the application. Not only that but the requirement for such things is *flexibility* because more often than not the application will *change*. Especially web applications--they're always changing! The custom tags you used to draw a dialog *today* may be completely different in the next version of your application. This fact won't make one bit a difference from the user's perspective unless browsers themselves start using your custom tags for a different purpose. If that happens it really won't be that big of a deal because *the purpose* of that part of your application is **not** *the content*. A simple search-and-replace operation and the problem goes away.
Cython? Is it as cool as it sounds? I'll look into it, thanks. I'm just starting out with Python :-) 
I'm still waiting for a lot of libraries to switch. Like the Flask micro framework which relies on many other modules that are still 2.x. Django is almost there, though. 
I need Enthought to start using Python 3 first.
I can't think of how you would look into this but I wonder how many of these downloads are in a production environment verses an academic one. I think a lot of teachers and professors might push for 3.3 to help their students prepare for the future (because things will eventually move beyond 2.7) whereas a production environment might need 2.7 in order to keep things compatible with existing code and when 2.7 is "fine" as is. I've been using 3.3 for simple scripting at work for data management purposes (bio-telemetry file parsing) but I know I'm somewhat in the minority within my area in that regard. A lot of resource guides I use still refer to Python 2 rather than 3.
Okay, silly question... Will there be a time when the Python Software Foundation, Guido, God, Allah and/or Al Sharpton will officially say "*Stop using python 2*"? My plan was to wait for that moment to make the switch.
well its simple really: if "all the libraries I use switch over" == 1 and "i feel motivated" == 1: switch to 3.3
They're currently saying that. As far back as '08 [PEP 373](http://www.python.org/dev/peps/pep-0373/) was created to track the Python 2.7 release schedule - the last of the 2.x series. 2.7 is planned to be supported with bugfixes until 2015, so if you want an "absolute final date" then that's the latest *anyone* should recommend using 2.7.
 if used_libraries == python3k_libraries and motivated == True: __version__ = "3.3.0" 
They have started pushing to get adoption up. There were many talks at this years pycon geared to get everyone excited about using Python 3. 
Hum, okay. 2015 seems like a long time to hang onto a version that's on it's way out. Maybe I'm set in my ways, but I'm still uneasy about making the switch. It seems as though people are just now starting to say it's okay to switch, which in my experience means I should wait a bit longer... Thanks for the info, in any case!
I pretty much agree except...I am looking for more of if "all the libraries I use switch over and are as stable as the 2.x version " == 1 and "i feel motivated" == 1: switch to 3.3
&gt;There were many talks at this years pycon geared to get everyone excited about using Python 3. Yeah, that's exactly why I ask. In my experience, when people start to "officially" push a new version, it's *not* time to make the switch. I chose my wording carefully, as I'm interested in when the official word is "stop using 2.7" as opposed to "start using 3".
As another poster mentioned, it comes down to one thing: do the libraries you use support 3.x? If so, use 3.x for that project. Otherwise, stick to 2.x until those libraries switch over.
Yeah, that's what I've been hearing. Again, I find that there's usually a discrepancy between the time at which libraries are announced to support 3.x and the time at which they work as well as the 2.x versions, hence my interest in 2.7's end-of-life. But your answer is exactly what I was looking for. I think I'll make the switch much sooner than 2015, but it's good to have a notion of the timeline.
But it doesn't achieve what I want to do. I only care about security inasmuch as it doesn't impede my own goals. I fully expect others to do the same thing and not follow my instructions in such cases. It's like saying "driving a car is less safe than staying in bed". Sure, but it doesn't get you where you want to go.
It reminds me of a joke. How many php programmers does it take to screw in a lightbublb? true
Webkit is pretty flexible and lightweight and the qt bindings for python are good. If there's a solution to your problem I'd say it'll be Qtwebkit. 
From the Django 1.5 release notes: "We plan to offer first-class, production-ready support for Python 3 in our next release, Django 1.6". 
Not being an ML expert, I have a very naive outlook. I am thinking start small and local. Get companies and seekers to send emails with attachement. Extract out info using NLP. Do some distance calculation augmented with human eyes. (Mostly me at this point. Possibly get the seekers to audit the NLP. Awards/Karma may give them priority in matching.) Once data set gets large, get an NLP expert involved at that point. EDIT: extra relevant info from http://infolab.stanford.edu/~ullman/mmds/ch1.pdf [On the other hand, machine learning has not proved successful in situations where we can describe the goals of the mining more directly. An interesting case in point is the attempt by WhizBang! Labs1 to use machine learning to locate people’s resumes on the Web. It was not able to do better than algorithms designed by hand to look for some of the obvious words and phrases that appear in the typical resume. Since everyone who has looked at or written a resume has a pretty good idea of what resumes contain, there was no mystery about what makes a Web page a resume. Thus, there was no advantage to machine-learning over the direct design of an algorithm to discover resumes.] 
The barometer for when to switch will be dictated by library support, not downloads. 
what kind of lists do you use that compare like this? or do you plan to use all the libraries? if set(used_libraries).issubset(py3k_libraries) and motivated: sys.version_info = (3, 3, 1, 'final', 0)
Strings evaluate to true if they are not empty strings.
You should look for a python IDE that's written in python and supports code completion, assuming you don't want to link to a C++ library. You almost certainly don't want to link to Java. http://wiki.python.org/moin/PythonEditors
&gt;2015 seems like a long time to hang onto a version that's on it's way out 2015 seems like an amazingly short time to me! Ubuntu 10.04 LTS will just be going out of support then. Its system python is 2.6. Ubuntu 12.04 LTS doesn't go out of support until 2017, and its system python is 2.7.3 In terms of third party module support, the way things are going I reckon that sounds about right for the remainder of any python package that isn't actually abandoned, though
Most OS distributions come with python 2.7 pre-installed. You only need to download python 3.3 because it's not the default. For instance, on my OS X I only downloaded 3.3, same goes for the university cluster that had 2.7 there already. I don't think downloads are a good metric for adoption.
He explicitly compares it to `1` though so that doesn't matter. 
The easily part is simply meaning getting as much of a base as possible. Throwing joypad support on top of a tried and true browser engine is what I'm shooting for as a best case scenario. This is what I'm looking for.
The data from the article for Windows downloads: Year | Python 3.3 | Python 2.7 Mar/13 | 647k | 630k Feb/13 | 553k | 498k Jan/13 | 533k | 495k Dec/12 | 412k | 525k
There's never been any reason not to switch beyond a hard dependency on a library that wasn't updated yet.
Why wouldn't they be?
As soon as all of the stuff I use for work change, so will I.
I use Flask so I am still on Python 2.7
This is a seriously great effort. I hope this get merged upstream, but I think something it has against it is you are adding an external dependency (six). Anyway, I think it is clever from you to have used that instead of reinventing the wheel. Is everything working, btw? Is there any outstanding issue?
Good point. For those using Anaconda, they say they support Python 3, but I don't think all the libraries they import work on Python 3 yet, including especially scikit-learn.
Because in some instances 2.x versions have been running in production for a *long* time. I'm not saying the perceived or real newness of the changes made to make the tools 3.x compatible are introducing any bugs. But, there is a lot to be said for having a long running history of your code in production environments. Sometimes, you just want some comfort in a well established and production-hardened runtime and tools. 
Hmm, cannot speak for Spyder. But for Pycharm: https://groups.google.com/forum/?fromgroups=#!topic/kivy-users/avoM81uLK0I
&gt; But it doesn't achieve what I want to do. &gt;I only care about security inasmuch as it doesn't impede my own goals. I fully expect others to do the same thing and not follow my instructions in such cases. You shifted the goal posts many times now. You tried to defend that it "wasn't bad to download it many times because malware only needs to be run once", and now you are admitting that it is insecure, but you don't care because it doesn't impede your goals. It's fine to not care about the security about it, but stop making excuses. If instead of being defensive, you had come right out and said "i know it is insecure, but it is convenient" from the start this whole reddit topic would have about 10 comments instead of 64. &gt; It's like saying "driving a car is less safe than staying in bed". Sure, but it doesn't get you where you want to go. That's silly. No one every made the suggestion to never "drive" (download code). Using your analogy, there are ways to drive a car that are safer than others -- admit that and move on. 
I think we will see that when 2.7 starts getting scary close to it's EOL (2015 I think). I think next year we will start seeing a huge push maybe in the terms you are thinking. 
Getting compatibility right for the correct unicode, byte or encoded strings to pass to the WSGI protocol, and doing that correctly while having a py2 and 3 compatible code-base, is a *hard* problem. I looked into the very thing to find out what exactly was blocking flask from getting py3 compat. Of course, noone wants to push breaking changes to such a project, so I wish mitsuhiko all the best for it :/
&gt; each passing all tests i don’t think much breakage occurs if that’s the case, else the test suite is worthless.
I do a lot of work with statistics in Python. But I am not proficient enough to install all the statistical packages myself—some of them do not install easily with pip, easy_install. Installing my hand—make, make test, make install—is a [dependency] nightmare. So, I found this wonderful Enthought Python distribution that includes all the packages I need with a brain-dead install. Oh heaven!
Passing a test suite doesn't mean your code is bug free. A lot of the tests need to be updated simply to support testing the new expected behaviour for py3 WSGI, so the critical part of the code that's the problem is the one least-tested at the moment. It mostly comes from, in python 2, you just send native (byte) strings and everything is fine. If you had a unicode string, you encode into a bytestring. In python 3, all these are different, and unicode is now native instead of byte, so everything needs to be reworked. Then there's the question over where you do encoding, do you leave it for other middleware to do later, or rely on a 'last layer', or do you pass a bytestring and hope middleware can decode...? Not only do you need to do this, but also have to code still work while running under python 2, which again expects the opposite type of native string to be being passed around. As I said, hard problem.
I've been using pygtk with glade, so currently using python 2.7. Unfortunately, thought pyqt supports python 3.x, there is no GUI builder yet, and I don't want to be building GUIs by hand quite yet.
Sort of... &gt;&gt;&gt; "hello" == True &gt;&gt;&gt; False But: &gt;&gt;&gt; if "hello": print True &gt;&gt;&gt; True I'm on 2.7 latest.
I don't know PHP, but it sounds funny. What's the joke, here?
mitsuhiko is busy as heck with work and travels, so not surprised he might not have responded yet. He reads this subreddit regularly, so I am sure he'll see it soonish. Also, he is currently looking at redoing Jinja2's 3 support, last I know he was looking at six to help on that front. So that might be how he might want to do Werkzeug as well.
Seems like any game with a persistent bad guy would do...
I don't think it will ever be merged - like I wrote in my post I had no experience at all with the Werkzeug code base one week ago... For the moment, everything I tried works, but that doesn't say much. mod_wsgi+python 2.7 isn't broken AFAICT, but I need to take some time and try it with mod_wsgi+python3.3 as well. Now of course not many Python 3 applications using werkzeug exist that I can test !
PHP is super duper liberal with type conversion. So, for example 'True' == true == 1 even though 'True' != 1. http://php.net/manual/en/types.comparisons.php So if you had 0 php programmers currently screwing in lightbulbs, and added true programmers to the project, you'd have 1 programmer screwing in lightbulbs. Relying on this behavior, by the way, is considered Very Bad™. (In general, the == is not what you mean to be using. And any sane language would throw an exception if you tried to add 2 and "dog".)
Odd strategy but does easy_install record the installed files so uninstall is possible?
I've been doing most of my statistical work in R. Occasionally, i hear talks of statistics with Python, like your post. What's it like?
Panda3D is an open source C++ 3D engine with python (if a bit unpythonic) bindings. [Changelog](https://www.panda3d.org/forums/viewtopic.php?f=1&amp;t=15783) [SDK](https://www.panda3d.org/download.php?sdk) 
Similarly, I use Python(x,y) and basically run what it has installed because I'm new and don't really know how to package everything I need cleanly. 
Yeah, there's some weird stuff for sure in PHP: php &gt; var_dump('0' == true); bool(false) php &gt; var_dump('1' == true); bool(true) Generally speaking, I find that it's better to use `===` whenever possible in PHP, though, especially with all the new OOP stuff they keep adding that allows you to use PHP like a Java-esque more strongly typed language.
In addition to library support: all 3rd party support including environment. One does not simply switch to Python 3 with RHEL 4.
Their expectation was that python 3.3 would generate a fair amount of support (and it has) with python 3.4 being the first python that users might switch over to fully. However, they've had quite a few growing pains and I do not think they were expecting that python 2.7 would be languishing as much as it has. The community support for python 2.x (even back to 2.5) is really quite strong. And it's still rare to see python 3.x being used in a business setting. Programmers are being hired to run on legacy systems which may never have python 3.
Yeah that sounds like a nightmare (and the joke is pretty funny). Why is it that PHP is the de-facto standard for server-side scripting? Was there nothing better at the time? Is there any reason I couldn't implement something equivalent in another language?
I've made the switch to Python 3.3 a few months ago, as my dependencies no longer support only Python 2 (e.g.,, numpy, scipy, matplotlib, scikit-learn). I say the number of libraries not supporting Python 3 will grow very small over the next year, one factor helping will be the fact Ubuntu 13.04 ships with Python 3 as the default Python.
The features that python 3.x add certainly aren't as interesting as they once were (stackless/gilless).
In case someone wants to go through the diff: https://github.com/benselme/werkzeug/compare/master...python3
If python is as generous as Mother Teresa, [we're in bad shape](http://www.slate.com/articles/news_and_politics/fighting_words/2003/10/mommie_dearest.html).
The problem and value of PHP is this weird feedback loop. It's ultra-easy to learn, I believe it and .NET are the only popular web scripting languages where you can just open tags on an html page and suddenly have a real programming language. PHP is also installed by default on nearly every single apache server on the planet, which means that you can write a site with &lt;?php PHP_CODE_HERE ?&gt; and reasonably count on it working on any host on the entire planet, where that isn't true for, for example, ruby or python which are both much 'better' languages. And this becomes a loop because it means that the newest and worst programmers are all drawn to PHP, which means a bulk of the community feedback informing the language development of PHP come from non-professional programmers. The language is designed to bend over backwards to guess what you meant if you don't really understand what you're doing, and the soggy type comparison is just one of the many ways it does that.
Probably after MySQL-python is ported and well tested. 
Here's a blog post with general info about the book: http://inventwithpython.com/blog/2013/04/15/hacking-secret-ciphers-with-python-released/
&gt; I had no experience at all with the Werkzeug code base I wouldn't let that put you off - a lot of this sort of porting is fairly mechanical (I use specialised `2to3` fixers for doing some of the grunt work). I actually find on these sorts of ports that one spends more time on porting the test code than on porting the core library itself.
"Most OS distributions..." Given that Windows makes up about 90% of all desktop OSes and doesn't include python, I think this is a fairly good metric. :-)
This raises an arguably more interesting question... how many python developers are there?
Or, punish those libraries by switching to something similar that does support 3.x. Some library maintainers have actually made statements suggesting they either never intend to switch or will hold out as long as possible, including saying things like "in reality 2.x will be supported forever." :-( 
So is it reasonable for me to assume that these distributions are targeted at non-programers? I ask simply because I've used tools like sci-py, numpy and sci-kit quite a bit in the past and usually just built the dependencies myself for dev and use puppet and/or buildout for deployment.
Shouldn't you just assume by default that when a new version comes out you're supposed to use it? Isn't that the point of its coming out? 
Change all the stuff you use for work and switch. :-) If you don't, your competition will.
My approach is... use the latest python, choose libraries that are compatible with it. If I based everything on libraries, I wouldn't have switched to python in the first place (abandoning legacy code).
thats exactly the problem a propper port that gets the encodings and bytes vs unicode right is a much different beast than "tests pass and toy apps run"
Which new version? The new version of 3.x or the new version of 2.x? Both are currently maintained and there are some documented incompatibilities. Also, when dealing with software is running in production one is usually very cautious about upgrades unless they patch serious bugs and security vulnerabilities. 
What is the competitive advantage of 3.x over 2.x? 
Looking good. Would you recommend it for someone who is currently almost done with your first book, or is it mostly the same content in a different context?
You probably don't have a complex shrink-wrapped commercial product that you sell to huge companies that is installed in their environments. We have very tight and specific SLAs. We don't meet SLA's, we don't get paid. It is a very competitive and very interesting environment. Also if our product is not functioning properly it can impact peoples health and cost our customers hundreds of thousands of dollars in fines. When building complex software you have to be terribly cautious of change just for the sake of it. We have always supported the PSF (long time gold sponsors) and have sponsored several open source python projects with time and money, plus sponsor a local python meetup. So, we want nothing but success for Python. But, it is not in our best interest to simply use the latest python. 
They don't need to install any packages/dependencies?
I assume this is also Python 3, do you have to have a strong mathematical background to go through this course? 
I have some experience with xml.dom and BeautifulSoup, so I might be able to help you a little, but I need a little clarification. Are these xml files both following the same schema? What exactly do you mean by merging them?
I hope not. 1. Spin up a fresh, lightweight distro like parted magic 2. run a script that downloads/torrents another distro like tails.boum.org 3. After that is done, it "installs" the distro and updates the grub2 menu I hope I can do all of that with the standard library. Still trying to wrap my head around grub2.
http://en.wikipedia.org/w/api.php?action=query&amp;titles=Albert%20Einstein&amp;prop=images It's for mediawiki api. If you do a query, you may get continue-query tags which you must place into the http request in order to get more of the data (in this case images) http://en.wikipedia.org/w/api.php?action=query&amp;titles=Albert%20Einstein&amp;prop=images&amp;imcontinue=736|Citizen-Einstein.jpg If you are saving the xml as you go, you essentially get many similar but not quite the same xml files. The only differences are the query continue section, and the changes to images basically. I'm thinking i should build up a BeautifulSoup as I go to each xml.
If it works for you, go ahead.
Are you using Windows 8? I'm not. Then again, I'm on ubuntu most of the time, but you get my point. New versions sometimes (and I'd argue *often*) introduce regressions.
I guess that makes sense. I ask because I've been thinking about trying to learn PHP and javascript in order to develop webapps. I'd much rather use Django, but it seems like any web developer worth his salt should have a working knowledge of PHP/javascript -- and like you said, you can use any host on the planet.
RHEL 4? And I thought I had it bad, administrating RHEL 5 boxes...
I'm inclined to agree. It's precisely because all 3rd party libs are not under a looming deadline that I don't want to switch to python 3.x preemptively. I'm usually a sucker for new-and-shiny, too... 
I guess. Though Django is such an amazing framework, and python is SO MUCH better than PHP, it wouldn't be that bad to start there. If you are working for a company, just work for a company that deals exclusively in python. The only issue is if you are freelancing, and the client expects you to send them a bottled up site for them to install at their leisure, a django project will leave them scratching their head and not paying the bill.
So far, this is all recreational, so I guess that does make things easier. This is especially true since my grasp on web development is light-years behind my desktop-app development skills. I *would* like to freelance eventually, though, so I'll keep that in mind.
Oh, I see. (I misread the question.) You only need to know basic arithmetic. The book covers the mod operator, greatest-common-divisor, and everything else math-related. There really isn't that much to it. So basically, any 10 year old would be able to follow along.
Programming-wise, you won't learn anything new. But it does give the source code for a bunch of new programs and the later chapters make heavier use of some data structures (simple dictionaries-of-lists type stuff) which might give you an idea of how programs can model things. It'd probably be helpful to at least type out the source and see how the programs work.
yes! thats what i expect.
That's an interesting sort of project to work on, though I'd be **sorely** tempted to do it in bourne shell for maximum portability. At any rate, since you're using lightweight distros, it probably won't matter for your purposes that Ubuntu is set to ship Python 3 as **THE** system Python next year.
alternate reading: everyone's already downloaded 2.7
Python does actually have [static methods](http://docs.python.org/2/library/functions.html#staticmethod), which are properly speaking, methods. For example: &gt;&gt;&gt; class Blah(object): ... @staticmethod ... def sqr(x): ... return x * x ... &gt;&gt;&gt; type(Blah) &lt;type 'type'&gt; &gt;&gt;&gt; isinstance(Blah, object) True "Blah" itself is an instance of "type" that has the method sqr().
Oh, but I did say that, 5 days ago! Check it out, it has -21 votes: http://www.reddit.com/r/Python/comments/1c2loo/forget_about_incognito_mode_use_a_throwaway/c9cj0n3
I just used it as an environment to brainstorm different analysis techniques that could be performed on the raw data, in order to emulate their results. The MATLAB code they provide describes their offline analysis pretty well, but it wasn't clear to me how it might be handled online. I needed dive into that a bit blindly and tweak the analysis to see how that would work, but I at least had an idea of what the individual pieces probably looked like. I started out by prototyping those individual pieces as components in the framework, then optimized the analysis by adding/removing component blocks, changing connections, etc. Similar to how some people use Simulink for signal processing applications. For example, I found that face detection is much more accurate and consistent on a grayscale image averaged from all three color channels, but physiological data is best taken from the green channel alone. I could have found that out using just code written around cv2, but would probably have taken a lot longer to discover that and work that change into existing code than it did using the framework (a few minutes) In other words: not necessary from an end-user perspective, but it cut my design work down significantly. Not exactly a typical use case of openMDAO either (optimizing a DSP design), but it worked well.
Okay. So you should familiarize yourself with navigating the BeautifulSoup document tree (http://www.crummy.com/software/BeautifulSoup/bs4/doc/#navigating-the-tree). A node in the XML tree has child nodes, which BeautifulSoup will represent as a list; you can add new elements to this list as you would generally in Python (see http://www.crummy.com/software/BeautifulSoup/bs4/doc/#modifying-the-tree). After you have collated all of the children from your series of API calls into a single master structure, you will want to then look at having BeautifulSoup write it back into an xml file, http://www.crummy.com/software/BeautifulSoup/bs4/doc/#output.
Some HPs used to ship with Python - though I can't remember which ones or why... non edit: it's because some admin tools were written in Python. http://docs.python.org/2/faq/installed.html
Less talk, more code.
It is very bloody good. Worth every cent. 
If I recall correctly, the overlap in features between Python 2 and python 3 is very large when you are talking about Unicode. As you say: the defaults are different so the secret to making a cross-compatible application would be to avoid defaults as much as possible. Mark Unicode strings as Unicode, byte strings as bytes. It depends how far back in python 2 you want to support though.
Wonderfully quick implementation, speedy enough and great customization. Thanks.
Only thing holding me back right now is SCons.
I appreciate the reality check. I have yet to see an equally valuable justification for using the latest shizzle. 
the newest version of python makes scraping imgur super sweet, and you will win every debate at the bar with your fellow imgur scraping dudes because you are on the latest fucking shit DUDE, look how big my dick is /fistbump-brohug-nohomo. Other than that, those apps making $$ and have a large customer base may have to take a more conservative approach. 
My use case: I needed to use a proprietary Oracle encryption algorithm from within Python, and the only thing that worked was the Jasypt implementation. I naively used subprocess to run its command-line tool, which took 0.5s per decryption. At the price of running a small Java server alongside my Python process, it now takes 0.0015s per decryption, which is about 10x faster than the competing Java implementation of my code.
The article compares windows downloads to windows downloads. It directly addresses your points: "For Windows you have to download Python. On Linux and Mac it comes pre-installed (so we can’t measure those numbers)."
As a scientist with many "I code as little as possible" colleagues, I find that over-commenting is usually a good policy. Thanks!
Is there something better that you recommend, or any particular pain points that you've noticed?
This is really cool, keep up the good work! I'll pick up a copy :). 
Keep asking them "when".
prove it
I bought it, but rarely find myself using it. I typically do my development over an ssh connection with emacs. I can even use this setup on my Samsung chromebook. Can't use pycharm on the vps on my chromebook ;). But seriously I got it for 50%off and it was worth that even for how little I use it. 
I will start reading the free version it in the AM, also passing to a coworker who is taking a crypto class via Corsera. If it goes into my library, I will buy/donate!
You could just use Linux Live CD to write and run your code...
So include a statically compiled python3 in your initrd?
It is a greaat piece of software. I am considering getting IntelliJ Idea for $99. IMO even better deal, given that you get to install the python plugin (pretty much equal to PyCharm) for free. Plus you get to install ruby plugin and c# plugin and all sort of other stuff. Am I overlooking something?
Thank you Al - you are awesome.
I like haranguing people. I am just a hobbyist, but I use 3 exclusively. You should, too.
I think for Django programmer it is mostly ready if you start a new project.
I propose you call it PyHio
Can't. 2.6 is *baked into* the environment we use at work. By that I mean we're using a highly modified Python that's designed around a big, bloated, binary that's core to everything we do. It's inextricable.
Oh-Py-O
Alright thanks, what is python best for? would python better for making mini games because of pygames or is there an alternative for ruby(I know there is rubygame) but how does that stack up to pygame?
1. This question makes no sense as asked. 1. You cannot reasonably expect to get an unbiased answer from a subreddit that's specific to one of the languages in question.
Here is the current [package list](http://docs.continuum.io/anaconda/pkgs.html). Python 3.3 packages are listed below the Python 2.7 packages. We are working hard to making as many packages as possible available on Python 3.
1. What is there not to understand? I'm simply asking which language has better documentation and which is better for what I want to do. So I'm asking what peoples opinions are, and personal experiences. 2. I disagree. I feel like this is a reasonable place because there maybe be some people including myself who is subscribed to both subreddits. 
I *hate* to be a dick about this stuff, but how can people authenticate that profits are indeed going to EFF, Creative Commons, and Tor Project?
Is the source available?
I agree, it would be cool to be able to upload to different sites, I could do it with the source
Use what works for you.
thanks will probably check in soon.
the only drawback i've noticed is lack of vagrant support
I talked to Dmitri at Pycon about this very thing, and (I think) he said that basically it is the same code-base, except for the project/module awareness of PyCharm. Basically with the IDEA IDE you are on your own in managing packages.
How is Python not good for making desktop apps???
"six" is just a single .py file, and one that has been stable for a long time now. Best idea is to just check it in with the code and not keep it as an external dependency!
Seriously, Dropbox anyone?!
Are you kidding me, no screenshots of the app?
So what's a Google Search results page? App or document? What's the Google Search landing page?
I'm on it right now! http://ax.to/echomesh 
Congratulations Al!
You really can't (though I guess you could contact the groups). But I am going to post a page on the book's website with the amounts I donate. I get the royalty check for a month 30 days after the end of the month, so the first donations will happen around the start of June/end of May. Transparency, yo!
There's a paypal donation button on the web page's sidebar. But if you want to donate to the EFF, Creative Commons, or Tor Project directly instead, that'd be fine by me.
&gt; Thank you Al - you are awesome. Feel free to say it as often as you like. :)
I accidentally left the link up. The mobi version should be done in the next couple of weeks.
Awesome! Thanks for reading!
This is wrong. The two main GUI libraries are wxPython and Qt (PyQt / PySide being the bindings). Both use native widgets where possible ensuring a native look and feel on Mac, Windows and linux. For cross-platform apps, python in probably the best platform for GUI apps there is (Java is probably the only contender but seriously java for desktop apps is not fun). For mobile devices, there a new python-native toolkit called Kivy (kivy.org) which is looking increasingly interesting.
&gt; punish those libraries by switching to something similar that does support 3.x LOL! Never! - People are lazy. - People are cheap. - Often libraries are difficult to replace (e.g. matplotlib (finally out) has no good alternative, VTK there's only one option, PyQt is GPL so I have to use wx) - Unless you're paying for it, go right ahead switch. There's no alternative to my open source project. It'd be far more efficient for a user to upgrade my project given the scope. That said, it (poorly) supports Python 3. Binary file reading in Python 3 is weird. Everything else in the pure python upgrade process is idiot proof.
No source, no license, only little explanation, no screenshot and only a .exe. I'm a little disappointed ;) edit : .exe is on dropbox too
Anyone know what happened to this plan for Kenneth Reitz and Mitsuhiko to join forces and consolidate stuff shared between werkzeug and requests? http://kennethreitz.org/exposures/the-future-of-python-http
Sorry the source isn't available but I can definitely try and implement different image hosting providers into the app given that there is an available API. :)
There isn't really much to screenshot except the icon in the taskbar, but if you want I could definitely do that. :)
Sorry, I'm not quite sure how to license my product. I will try and expand more on the explanation and also migrate the product hosting to my web server. :)
Can I buy the book with bitcoin?
Site updated with screenshots and updated links to different hosting. :)
My point was more than that even if it didn't, the worst that could happen is `LOAD_CONST` followed by `POP_TOP`. Vaguely unpleasant, but far from the end of the world, it should take, like, I don't know, 20 cycles?
&gt; At any rate, since you're using lightweight distros, it probably won't matter for your purposes that Ubuntu is set to ship Python 3 as THE system Python next year. Not quite. Just the default installed version. /usr/bin/python will continue to be Python 2.7.
The only thing is that IDEA's package management is more powerful, which is pretty useless in Python, so it takes a bit of getting used to. Source: I use it daily.
idk nothing about this framework, but cloning works just like with any other project ╰─➤ git clone https://bitbucket.org/cloudsherpas/ferris-framework.git Cloning into 'ferris-framework'... remote: Counting objects: 1187, done. remote: Compressing objects: 100% (1032/1032), done. remote: Total 1187 (delta 428), reused 625 (delta 44) Receiving objects: 100% (1187/1187), 2.43 MiB | 139 KiB/s, done. Resolving deltas: 100% (428/428), done. &gt; When I try to use the clone link with mercurial you don't use mercurial here, it's git. 
Why is this issue so important to people? 
&gt;That's an interesting sort of project to work on, though I'd be sorely tempted to do it in bourne shell for maximum portability. I certainly know bash far better than python, but I suspect python code would be far easier to maintain. Besides, I need a python open source project for my resume. I don't foresee any portability issues though. I gotta use Linux to build because the plan is to have two partitions. A fat32 one with Windoze tools, and a journaling file system like ext3 for the second partition with grub2 and the various ISOs and other tools. &gt;At any rate, since you're using lightweight distros, it probably won't matter for your purposes that Ubuntu is set to ship Python 3 as THE system Python next year. Didn't know that. So they are totally removing 2.7? I want to use the lightweight distro for the USB formatting and assembly script because it boots and runs totally in memory on even my dad's ancient PC (which I have had to delouse in the past.) His is so old that the BIOS won't boot from a USB stick, so I have to have to use a boot CD to run diagnostics and antiviral stuff on it. If you've got a link to further reading I'd be interested. Otherwise I'll find it with my search-fu. A
Python package management (browsing and installing packages from PyPI) is the same. Project and module setup is different. In PyCharm you can just use Open Directory to start working on a new project. In IntelliJ you have to create a new project, set up project type, etc.
Assuming you're writing against Python 2.7 already, it's really not much of a switch. In fact, you can probably target both of them at the same time out of the same code base (it's what I try to do whenever possible). Uncle Barry has some good articles on it ([an example](http://www.wefearchange.org/2012/01/python-3-porting-fun-redux.html)).
[Source for my claim](https://wiki.ubuntu.com/Python/3). That page (which may or may not be current and/or canonical, but I sort of assumed it was both) claims that the goal is for *only* Python 3 to be present on the Desktop CD image.
Django is more or less ready--none of the goodies from 3rd party Django libraries are.
There's also [Pyzo](http://www.pyzo.org/), which is a scientific Python distribution based on Python 3.
See [my reply](http://www.reddit.com/r/Python/comments/1cdxi6/more_python_33_downloads_than_python_27_each/c9g8i6c) to /u/pingveno for more reading.
On top of that it rips off ubuntu.com's design.
Your book looks really cool and you have the right to use any coding style you please; many projects break the 80 char rule. But the underscore vs camelcase is pretty settled and I think it's a bit unfair to call camelcase a convention in Python. Anyway, indosauros is a bit tough, I believe content is more important than form, but it would be good if educational material would at least describe the standard, if not use it.
That's odd - what platform are you on, and what's your openCV version?
I don't quite get why it's being posted here when there is no source available.
HP seems to like Python, the Linux HPLIP tools for printers are in PyQT4.
Honest question - I currently use Sublime Text 2 for everything. What about PyCharm would make it better than Sublime? 
Thanks for the help. Git worked just fine but only in bash the UI failed me. I wonder if Win8 is a problem for some of this GUI clients.
I too am interested in Python(x,y).
Point taken about limitations in the framework compared to frameworks dedicated to developing games. Like I said I haven't played around with it a lot, but a cursory google search seems to indicate that alpha transparency is supported by the [Image class](http://kivy.org/docs/api-kivy.uix.image.html#kivy.uix.image.Image.color). A sprite is just an image by a different name these days, anything using OpenGL as a backend, like kivy in this instance, will not support buffers and blitting in the the traditional sense as I understand it from the good old days of DOS. I am not an expert however, so I welcome the opportunity to be proven wrong. As for collisions it seems that the Widget class has [builtin methods](http://kivy.org/docs/api-kivy.uix.widget.html#kivy.uix.widget.Widget.collide_point) for checking these as well. Again, I don't know how kivy does this "under the hood", but it seems like saying the entire framework is not "meant for graphics drawing" is a bit too broad of a statement.
[Kivy for Windows](http://kivy.org/docs/installation/installation-windows.html) comes in a portable package. You don't have to uninstall your other Python versions to use it.
&gt;The next time you double click a .py file, it will be executed with the version of python that Kivy ships with. &gt; &gt;Note &gt; &gt;On Windows we have to ship our own version of Python since it’s not installed by default on Windows (unlike Mac OS X and Linux). By following the steps above, you will set Kivy’s version of Python as the default for opening .py files for your user. Normally this should not be harmful as it’s just a normal version of Python with the necessary third party libraries added to the module search path. If you do encounter unexpected problems, please Contact Us. This is the problem I had an issue with, as I wasn't sure if that would mess up my other scripts that run via Python(x,y)'s version of Python. I guess I'll just have to try it. If it is it's own portable version of Python, what do most people use as their IDE to develop with it? I'm a bit lost on setting this up and actually working with it. 
Go check on their pong example. It seems like most old-school sprite drawing frameworks to me.
Sorry, I'm not sure what most people are using on Windows. I use PyDev on Linux but I don't see why it shouldn't work on Windows too.
Ya I guess I was thinking about when I have scripts run automatically. But I'd probably never do that for Kivy scripts so I'd keep my defaults the way they are now. 
*Quit yer whinin' and port!* *Are ye programmers er dags?*
Thanks!
Thank you very much that is an answer I was looking for. I guess I'll get started on Python and learn Ruby on the side.
You might also take a look at [PyJnius](https://github.com/kivy/pyjnius). It is part of the Kivy project and is under active development.
Funny you should mention it. I just started playing with migrate-sqlalchemy. It works pretty fantastically actually. Check out [this post](http://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-iv-database) about managing database schema with a flask app, that'll give you a good jump off point. It also completely depends on the application, but this is actually perfect for what I'm looking for (since I'm using sqlalchemy). Fabric is also the kitties titties as far as server management goes, so that can go a long way for backups and pretty much whatever else you're trying to do. A bit more context would certainly be helpful in identifying something that would work for you. 
(disclaimer: im one of the kivy dev's) actially, kivy is specifically made for graphics (and interaction). All the rendering is done via OpenGL ES. You can definitly do alpha blending or anything else your heart desires (for simple alpha blending when using the default shader, just set the 'opacity' property. We don't directly expose functions/methods for things like group/batch/blitting, but that's because we're constructing them in our "graphics compiler". The things is, modern GPU's don't match our imperative / sequential programming patterns very well. GPU's work best when you hand them alot of data and tell them what to do with it (SIMD). So what we've done in kivy is actually create a bunch of graphics 'instructions' that are used like imperative statemenrts in the kivy language. When we render, we execute the tree f graphics instruction, but since we have global knowledge about what is being rendered, we can apply optimizations, like remove unesecary / redundant openGL, or combine vertex buffers (all rendering is done using vertex buffer objects), etc. you can take a look here for some more details and the graphics instructions that are supported by kivy (http://kivy.org/docs/api-kivy.graphics.html#module-kivy.graphics). Of course you can always use a callbback instruction, which will call whatever function you want at the place in the rendering tree you put it; and then you can write straight OpenGL code to render whatever you want. so, yes, kivy is definitly meant for graphics programming. In fact it's main focus is to be a framework that allows you to take full advantage of modern GPU's and different kinds of input (it's not just mouse and keyboard anymore). We do have a lot of 'standard' widgets built on top of those core features, that make it even faster to develop applications. The nice thing about those widgets, is that they work with a lot of different input devices / modalities. edit: added link to documentation of kivy.graphics module
what do you mean by normal image containers and native widgets? we openGL textures (which you can blit to directly, or bind to a framebuffer object that you can draw into directly). not sure what you mean by native widgets, we definitly do not use any platform specific / native widgets, eveything on screen is dranw using the GPU, so it's a) fast, and b) gets rendered the same way regardless of where you run it.
I was kinda hoping for a general discussion, but for context, I usually use Flask with SQLAlchemy, and Fabric for deployment and remote staging/production tasks. For migrations I've always just winged it and for local tasks I usually either use Fabric or just do things manually, relying heavily on bash history. I think migrate-sqlalchemy got replaced by Alembic in the SQLAlchemy world recently? My search for a tool has left me feeling most of them over-complicate the issue. I mean, I've always had the idea a fairly simple script that enumerated sql files, compared them to a table, and executed the missing ones, would be enough. *Edit:* Which is why I'm asking the question. Hoping there's a light-weight approach that's easy to pick up. **Edit:** You may be interested in [this answer on StackOverflow regarding sqlalchemy-migrate vs alembic](http://stackoverflow.com/a/10924372). Particularly, this feature seems quite amazing: Autogeneration: Not its only mode of operation, but if you choose, Alembic will read your application's sqlalchemy configuration (for instance, your declarative model classes that set up all your tables, constraints, and mappings) and compare to the actual current state of your database, and output a Python script that represents the delta between the two. You then pass that script to Alembic's upgrade command and there you go, the differences are resolved. A small amount of editing the migration script by hand is usually needed, and that's (a) just the nature of migrations, and (b) something you want to do anyway to make sure you were fully aware of the exact steps that the migration is going to perform before you run it. I'm not sure if I'd use it in that mode, but it must be appealing to many SQLAlchemy users!
Windows 8 is a problem for Python developers in general.
I'm using SQLAlchemy with [sqlalchemy-migrate](https://code.google.com/p/sqlalchemy-migrate/) for database schema migrations/change/management. It works great for me. I also heard some interesting stuff from [alembic](https://pypi.python.org/pypi/alembic). Unfortunately, there is no easy migration from sqlalchemy-migrate to alembic so I stick with the former. For local task during development, I often create simple Python scripts that I include in my source code repository. I'm not using Fabric for deployment but just a regular Python script with [paramiko](https://github.com/paramiko/paramiko) for my remote shell needs and xmlrpclib for calling [my hosting provider](http://www.webfaction.com/services/hosting?affiliate=delizseemack) [APIs](https://docs.webfaction.com/xmlrpc-api/). It works fine for me.
I like the idea of using JNI a bit better than Py4J's connection model, which doesn't really come out and say it uses TCP sockets. Maybe I'll run them head-to-head and see how their memory usage is.
And you're posting in /r/python... why? Your app does something hundreds of other apps have done before. Its source isn't available. It's only available for windows. It has absolutely zero value for this community (which is interested in python code) and if it weren't such an ineffective way to sneak a virus into a community, that's essentially what everyone would think you're doing. This post might as well be spam, to be honest. Edit: If someone's interested in a similar app that's actually open source, Screengrab is decent: https://github.com/DOOMer/ScreenGrab Unfortunately, it's not in Python.
dunno its any help but for python on android i use SL4A (scripting langue 4 android) check it out over on google code
so in one case: 1. write bad code 2. run ~~interpreter~~ oh wait, it *is* a compiler! 3. see error when it can't make bytecode properly in the other 1. write bad code 2. run compiler 3. see error
Are you suggesting that it is a good idea to index Google's results pages? That they are meant to stand the test of time and won't change much? If we index the search results pages do we then index the results of our indexed results? This makes me think, "It's turtles all the way down!"
That's just the default installed version. The version at /usr/bin/python will continue to be a symlink to a Python 2.7 binary. Unless I'm very mistaken, the install media will simply lack a /usr/bin/python symlink.
[I can't find this last move!](http://imgur.com/pWei26X) The blocks are too complex, I'm not sure if there's no move or if I can't see it. And I can't restart a new game :( I even tried to clear this app's data and it still wants me to continue playing this game! Are you a wizard? But I like the game :) Nice work, can you just simplify the blocks drawables? I have to focus just to recognize the pattern...
I've done R too and like it too, although I prefer Python's syntax more. But the reason I stay with Python is because we needed to do more than just stats and R seems to do only stats well. We tried using RPy2, but the program structure gets weird fast when we have to worry about minimizing data transfer between the Python process and the R process. Numpy and Scipy seem good enough and actually seem faster than R; so we decided to keep the overall system simpler by having just Python.
I've just looked at [this page](http://pygame.renpy.org/writing.html) and it looks very similar to pygame for PC so if you're comfortable with pygame there shouldn't be a huge problem (hopefully)
Even if they don't go to these groups, you deserve them just as much as they do. Your first book helped me a lot, too bad I was too young to pay for it when I was still learning :)
There's a simple way to decide this: take a sample game written in Python and see if you can make it work. If you can, then yay! If not, then you may want to consider something else. What is possible and what you'd want to live with are two different things. In fact, they walk you through how to do this here: http://pygame.renpy.org/android-packaging.html#aside-a-simple-game How did that go for you?
Nice!
For Django projects, South: http://south.aeracode.org/ 
like hairyfro said, the packages built are standalone android or ios apllications. the launcher is just an easy way to try out scripts or different apps stored e.g. on an SD card
Where does the metric of 90% come from ? I would not imagine that 90% of python users are on Windows. Let's say at least not the serious ones, that didn't download it just because it was a required dependency for some other software they wanted, not knowing it's a programming language. The package developers certainly don't seem to be on Windows; nor are all the scientists using python. This again makes me think that looking at the download metric is really not a good proxy for adoption by the community.
Downloads are one thing and another thing is that people actually use. We also have to take account of the support given to the libraries
down in the bottom right, the group of + :-)
 print "You had sex with: {0} hookers.".format(sum) While I follow that you're just learning, look into the format function. Its incredibly powerful and, imho, cleaner. This works for &lt;=2.7.x. If you're using 3.x, I believe its used like so: print "You had sex with: {} hookers.".format(sum) With 2.7, you need to specify the order with the {0} and {1} while with 3.x I believe its an optional param. EDIT: I'm not sure if my phone is formatting it properly, if not, sorry. :( 
Anyone uses camelot please report your experience!
This is a good example of why you really should use an html parser such as lxml or BeautifulSoup. This while loop needs to be put out of its misery. while True: i = contents.find(‘TopTwoWarrantyListItem’, i) if i == -1: break i = contents.find(‘&gt;’, i + 1) i = contents.find(‘&gt;’, i + 1) i = contents.find(‘&gt;’, i + 1) i = contents.find(‘&gt;’, i + 1) j = contents.find(‘&lt;’, i + 1) warranty = contents[i+1:j] The same thing can be done with BeautifulSoup using something along the lines of: soup = BeautifulSoup(contents) lis = soup.find_all('li', {"class":'TopTwoWarrantyListItem'}) # the date is the second bold element warranties = [li.find_all('b')[1].get_text() for li in lis]
Hmm, I use 2.7.3 and I have to explicitly add the param. Ill check. I might be doing something wrong if that's the case. 
Yeah you definitely don't need to add any arguments. http://docs.python.org/2/library/string.html#formatstrings &gt;Changed in version 2.7: The positional argument specifiers can be omitted, so '{} {}' is equivalent to '{0} {1}'. ____ Python 2.7.3 (default, Sep 26 2012, 21:53:58) [GCC 4.7.2] on linux2 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; "sum of {} and {} is {}".format(1,2,1+2) 'sum of 1 and 2 is 3' &gt;&gt;&gt; 
Personally can't see the point of using it on windows. 53MB for distributing the tiny application with no use at all ... damn! better make it in browser. It's probably okay if your can't use other programming language, but then ... why would I use it for desktop application development. Can't see the benefits
No offense, but everyone who learned programming as a teenager or younger and is now older remembers doing something like this. (When I was young, we'd get the demo computers in stores to do infinite loops of "FART" because there were no lowercase letters.) It's new to you, but it's not new to us at all. Please don't waste our time with it.
Sweet. I'm just learning python, so this will definitely help.
There are compiler errors and runtime errors. Using a compiler distinguishes that.
And Python has a compiler. And the compiler errors come up when you compile. I think this is more an issue of when things are compiled. I don't know about Delphi's mechanisms, but Python is lazy. You could write the code to a file on one line, then import it on the next. The code will still need to be compiled.
[Pssst.](http://scrapy.org/)
Thanks for the clarification - I knew I was misremembering something.
Great read
I had my doubts about the autogeneration, but I'm going to give Alembic a more serious try. If I don't like it I'll just rolling my own little script. Nothing fancy at all. Simple drop-in and go python file for running sql scripts in sequence and tracking versions in a table, and then just make use of Fabric to run the commands. Thanks for the input!
This is pretty bad. If you're dealing with beginners, you need to warn them that the order of dictionaries is arbitrary. Don't tell them it's OK to print out the keys in the dictionary without sorting them first.
It's a fun read, but it's a lot less interesting to read about how to make your code small (basically useless) than to read about how to make your code fast and easily readable. Considering the author actively admits they are sacrificing valuable heuristics as well as readability to minify the code, this has little practical value. 
I like alembic. sqlalchemy-migrate is not quite as good, because it excessively hardcodes the order in which migrations must run.
"prowess"
You're right. However, there is a link at the very bottom pointing to this page: http://www.pythonforbeginners.com/dictionary/ where they can read more about dictionaries. 
&gt; I’d argue that it’s useful for more than just upping your geek cred: good Python code golf must utilize many quirks of the Python language in seeking brevity above all else. Learning to utilize these quirks can lead to a much deeper understanding of the Python language. Plus, challenges are fun!
This is a little late. However FYI, I am really liking Spyder. I actually am not that great with Python yet. I come from more of a Java/C/Matlab background. There are some needs at my current company for a data analysis capable tool at least for prototyping. Python fills that bill, but the Spyder IDE I am finding has very useful features for me. Coming from a relative beginner compared to most I am not sure if that means a whole lot, but there it is! Thanks!
I just learned that if you reorganize your package, pickle falls apart. It'd be nice if it could grab the imports from the current scope... pickle is terrible as a saved file format that needs to support upgrading
true and false are just aliases for 1 and 0 in languages like c and c++ right?
Came here to say this. :-)
Emacs/Vim are free.
awesome, although you could also have used tabs to indent, retaining readability *and* making it shorter ;)
read it bottom up, then you get the amazing story of restoring garbled mess to readable code! but seriously, code golfing is not for practical purposes, but for the challenge.
yeah, i always viewed it as temporary caching library. name = 'spam.pickle' try: obj = unpickle(name) except UnpicklingError: obj = do_heavy_computation() pickle(obj, name) (i pulled the API out of my ass, that’s likely not working code)
I've never personally had an issue uninstalling with pip after having used easy_install.
That depends. Sometimes true is -1 because in twos compliment, that's FFFFF (all 1 bits). Never do math on Boolean. 
PGS4A is more meant for porting existing pygame games to android, rather than writing new ones. There isn't very much support for android-specific functionality. (I initiated pgs4a.) 
Update: tested with mod_wsgi and Python 3.3. Still works so far.
XML?
Nothing. Everybody has different preferences.
* https://sqlalchemy-migrate.readthedocs.org/en/latest/versioning.html * http://alembic.readthedocs.org/en/latest/tutorial.html * http://south.readthedocs.org/en/0.7.6/tutorial/index.html * http://pythonhosted.org/vdm/ * http://farmdev.com/projects/fixture/ 
http://semver.org/
Sudoku is a boring game.
/r/tinycode would love this if it hasn't been reposted already. ** Ninja edit looks like someone posted it a few minutes ago
I'm not sure who would even start using an IDE that is limited to a single language, and requires paying for yearly updates. Why would you invest your time in such a risk?
I though hoboes could use it. Or do you mean it's not free?
When you install the python3-tools RPM from the Fedora repository, you get /usr/bin/idle3.3 which runs the Python 3.3 version of IDLE. So instead of: $ idle try: $ idle3.3 
I haven't used Ruby much for application programming, nor do I know all that much about their community first-hand. What I can say is that cross-platform application programming in Python is great (I prefer PyQt/PySide), and the community is outstanding.
I didn't mention Vim at all :) I use VIM on daily basis, but IDEs have qualities too.
Some people prefer to hammer the right arrow key 49 times to move 49 characters instead of typing "49l", because they get paid by the hour. 
Dell has a SOAP API for this stuff. You should use that.
/r/simulate could use ya.
I feel like there are going to be error cases if I don't do this smart. :P
SOAP? Ewwww!
Its better than web scraping!
Well, that was disturbingly obvious, shoulda seen *that* coming. Thanks for your help, darth...cheers.
Still doing some brainstorming, nothing in mind yet. 
Thanks, I'll look into that.
Thanks, I'll look into that.
Thanks, I'll look into that.
Aww, don't get upset about it. I'm sorry that I was proud of something I worked on and I was in the process of making the source public, but whatever.
I usually use http://www.liquibase.org/ to migrate/rollback/tag or diff database structure and data. For django I use a little helper https://github.com/i-dotcom/liquimigrate/
Many of the features (e.g. revision control) described in JSR-170 [1] dramatically increase the complexity of building a "massively parallel CMS" . Asynchronous Python implementations of CMIS [2][3][4] clients and servers would be great. * [1] http://en.wikipedia.org/wiki/JSR-170 * [2] http://en.wikipedia.org/wiki/Content_Management_Interoperability_Services * [3] http://docs.oasis-open.org/cmis/CMIS/v1.0/cs01/cmis-spec-v1.0.html#_Toc243905500 * [4] http://en.wikipedia.org/wiki/HTTP_ETag AFAIK, Kotti is faster than Plone. There are many efficient extensions for Plone. If by massively parallel you mean "faster search", ElasticSearch scales and is REST-based.
It was made with Divshot, so take it up with them :)
I have to applaud your ingenuity. I never even thought someone could scrape HTML with plain Python string methods. So, good work! *Never* do anything like that again though :)
Hi, a desktop application allows you to develop a much faster and richer application compared to a web application. This is important in areas where you need lots of continuous interaction between the GUI and the underlying model (like technical applications, applications to operate machines, or business applications with lots of data entry). Also the development time is reduced when you can develop and debug the whole application in a single language.
Think I found a typo. Page 385 in the RabinMiller test code: while s % 2 == 0: # keep halving s until it is even (and use t # to count how many times we halve s) s = s // 2 t += 1 keep halving s until it is *odd* (and use t Fantastic work though. I think the chapter on RSA is my fave : )
Well yes and no. What do you mean by richer applications? How are they faster developed? In the given example you get fast an application with menus that you don't need. But let it be just an example to show what is possible. What about deployment? How is desktop application faster? With web-based application you deploy once, and use it everywhere. Application communicate through web-services these days, so most of the time you can have applications written in different languages to work with the same data-source or just part of it. What I mean't with other programming language was that: if you are developer who knows only python - then you are okay with this python-camelot, otherwise you will choose a more suitable language for desktop development. I don't say that I'm against desktop applications, but you should choose the best suitable approach. For business applications it's probably web-based when it comes to working with a lot of data, since you probably should share some if not all this application with other application in different departments etc. Development time reduces when you can develop and debug the whole application in a single language - is correct for any language and platform you choose. I'm not saying python-camelot is bad thing. I like it's django-like desktop development model, but then I still can't see what is it good for in example of big business application. Probably for a small business, with single data-source and not that many workers who use the application?
It's just simple math. If the tools it provides makes you work more efficiently, and the cost is reasonable = buy. If not = no buy. For me, it's definitely worth the money. I'm at least 20 % more productive now, than before using it. Worth every penny.
It's fun. For me that's the point of any code golfing. It's very much quantifiable progress, and you feel really satisfied when you scrape off a byte! Take a chunk off and it's a downright divine feeling. :)
How do I get rid of it? When I pull up IDLE, the Console header comes up by default.
Ahhh. Thank you so much. So if the text-editor is where the code actually matters, what is the point of the console pane?
I see, so more for mathematical functions I suppose. 
From the article: &gt; Given the level of obfuscation involved, you might wonder what the point is: you’d never want to write “real” code in this style, so why spend the time doing it? I’d argue that it’s useful for more than just upping your geek cred: good Python code golf must utilize many quirks of the Python language in seeking brevity above all else. Learning to utilize these quirks can lead to a much deeper understanding of the Python language.
Have you ever solved a difficult one yourself? The stuff they publish in the newspaper isn't difficult.
https://pypi.python.org/pypi/bintrees/0.4.0
I see. Thank you very much for clearing that up for me. I know what to do now :)
If you refered to it as inspiration then thanks, I'm reviewing many packages for that purpose and I'll check this one as well. Of course, binary trees are a very simplistic case of trees.
It means a lot, thanks for your message. We've worked hard to make things as intuitive as possible, so to hear that beginners are finding Spyder worthwhile and useful it's very important to us. Remember that if you need some help you can post a message in our mailing list.
If you want a full-featured IDE try the pydev plugin for eclipse. It (mostly) works, and will fit basic needs. Also, try pycharm. It works beautifully, although it is not free :( you could always apply for a student license, if you are one. But yeah, /u/darthmdh's answer will work. It works for launching the python cmd as well, just type python&lt;Version.Number&gt;
Not impossible, just difficult. If you want Python 2 and Python 3 versions to interoperate.
[new line]+[tab] = 2 characters. Keeping things on the same line is 0 or 1 characters.
I don't like SOAP but this comment should go up because it's way better than what OP attempted. [Script](https://gist.github.com/leinaddm/1893036)
Much to learn you still have, young padawan! "`yield from`" in this context is equivalent to "`return`". So, -4 characters and Python 2.7 is supported again.
sure, i meant the indenting-by-one-space-instead-of-four steap. indenting by one tab there would have the same effect on byte size but be more readable *until* you also remove the newlines.
1. Personally I'd do parent/value/children. Would not recommend head/tail in a dynamic language because the interface would confuse many people. 1. Do not restrict to string type only - it will hurt use of the project. Hashable perhaps? 1. Recommend a function, not an attribute access leaking the __getitem__ interface 1. tree.get_node(node_inst)? 1. implement descriptive function names, but if the operators **make sense** go ahead and alias long-winded functions to operators (set is a good example of this) 1. Provide iteration functions (dfs, bfs, etc) so we can call map(func, tree) or filter(func, tree.dfs). Ensure __iter__ is aliased to one of them
Regarding (3), a benefit of the \_\_getitem\_\_ interface is the support for slicing, which I find very useful for trees with many children.
Use **virtualenv** and **virtualenvwrapper**. With these simple tools you can painlessly install and use whatever python version you need (python 2.7.4, 3.3, 3.4, pypy, you name it) and whatever packages you need without messing with system python and its packages. As for IDE, you need one that lets you specify a python executable to use, such as emacs or vim with plugins, pydev, pycharm, wings ide, komodo, ninja ide, etc. Actually, I can't name from top of my head the one that doesn't, because virtual environments is such a crucial part of python development. 
 &lt;?php exec('python your-script.py'); ?&gt; ... it's as easy as that ;-)
&gt; Use cryptic yet cool operators when possible, or stay with long-winded function names? Example: tree1.common_ancestor(tree2) vs tree1 ^ tree2 Have both. Good luck
I don't know a lick of php. But, since you asked .... I would probably wrap the implementation in an api and throw up a service (http, rest, amqp). I'd then just hit that service with my php web app. This way there is no need to re-write code and you get the chance to learn a little Python. Later you can worry about scaling the service to match traffic.
MPTT?
About ten years ago I had considered implementing an ordered dict tree where the format for accessing a child was the key and the key used something very similar to xml's xpath. The idea was that the keyed child could be an object, a file path or a pickled package to be imported. I never had a chance to make it fully functional and the work was proprietary. However, the end result was fairly slick for data manipulation.
You would need to cron a script to look at your email messages. Now assuming you are using something like a gmail account then you would need to enable ICMP on the account and have the script login to the gmail account and loop through the inbox. Python has imaplib which is in the standard library (i think) which should help you with this. These two stack overflow posts should point you in the right direction: [Logging into gmail and looping through inbox](http://stackoverflow.com/questions/2983647/how-do-you-iterate-through-each-email-in-your-inbox-using-python) and [Searching for word in subject line](http://stackoverflow.com/questions/13403790/python-imap-search-for-partial-subject) For the DDWRT part...I'll be honest; I've never actually worked with DDWRT but i believe you should be able to ssh into it. Assuming this is true, the python project [fabric](http://docs.fabfile.org/en/1.6/) should help you since it has good ssh support. Also this is assuming you're working on some sort of *nix box...but you should be able to do everything on a windows box as well using cygwin or putty for your ssh client.
I'd just start building it and get feedback as it is coming along. Also, if you are scratching an itch then you are probably the best initial critic of your implementation. 
It can be good to just give something a go. The game I currently have in the store is written in Kivy but the first version I published was pgs4a. I migrated across so I could do more fancy things with the graphics, and also the kivy project is doing more interesting things with the Android API. But if you just want to kick the tyres and try something graphically simple out, pgs4a is about the easiest way to go.
I actually already have an initial implementation, but my preferences are very particular (and sometimes peculiar!).
Very interesting! It would indeed be potentially good to have a common standard. I mostly agree with justanotherbody below. Don't use "kids" under any circumstances. However, people will always have motivations for not using the standard, if there is one. I have (in one application) recently moved away from the node.value and node.children style. Instead, my trees are now bare lists where the first item is the node and the other items are children. I refer to a node using a "path" or "pointer" (the indices required to reach it from the root) and I can get parent by lopping off the last element of the path. I guess this saves a lot of memory, possibly at a cost in readability. Not sure whether it affects speed.
&gt; &lt;?php &gt;exec('python your-script.py'); &gt;?&gt; &gt;... it's as easy as that ;-) You're not translating anything with that.
it's the former, and I've been told python is pretty much the closest language to psuedocode. The difficult bit for me is actually finding the algorithm and how it works, inputs etc. Sounds like it's time to dive into python and get started! Thanks
Much like ordinary golf. There's not much practical value in putting a ball in a hole, but playing golf is valuable nonetheless (as a challenge, exercise, competitive sport, etc.).
I'm not entirely sure what you're trying to accomplish. Could you elaborate on what precisely you're looking to do?
yeah I did, it's a boring game.
You just need to figure out how to talk to talk to DDWRT from your script, the rest is relatively easy.
They don't exactly make it easy to find. I tried making this same script a few weeks ago and it was a dreadful pain (only been programming python about a month). 
Maybe. I'm not familiar with the subject matter but using Flask or CherryPy you can build api's pretty quickly for prototyping. But, if you have some real-world requirements then the re-write might be quicker.
Sure, I'm building a revision app and part of the app uses spaced repetition to determine which questions to ask and when, based on previous answers to the question. Anki is the leading software for this sort of thing, but unfortunately there's no API I can plug into. It uses a modified version of the SM2 algo (which the pseudocode is available for) but I haven't been able to find pure pseudocode for the algo used in Anki. As Anki is open source I was thinking of writing the same algo natively in PHP to drop into my app. Hope I've explained this well. Thanks
It makes sense visually. Imagine it as two lines connecting each of the nodes to a common root.
i think a breadth first or depth first search would work in either case. Here is the project in question. https://github.com/ColtonPhillips/wpdb/ For reference, here are 2 derpy functions I've written. 
Since this is getting upvoted, I'd appreciate it if someone helped me see the relevance.
I also think i need to consider not just the contents of tags but the attributes as well. like id=whatever. As in, what is the expected behavior of one xml has additional attributes. in an existing tag.
lets try to get this down to a simple function that anyone could use in any project! :)
Thanks everyone for your responses. I've got some work and tinkering to do :-) Glad to know this could be possible! Cheers!
Talk about using an elephant gun to kill a fly. I think anything that is described as "an algorithm" is easier (not to mention more robust -- less moving parts) to rewrite than to implement a service just for that one thing.
n00b here... any good resources you can recommend for GUI programming with Python on Windows? Thanks!
With respect, I am skeptical that your implementation would become the standard. It's not at all clear to me that there can even be a standard for trees in the Python community. But here's my opinion. 1. "Node", "child"/"children", "root". Definitely not "head"/"tail" since that invokes Lisp-style recursive lists. 2. Absolutely not. This kind of restriction would be unPythonic in principle and limiting in practice. If it hashes, it should be able to be stored in a node. 3. `tree.children[i]` is fine, and similar to Python AST nodes. 4. The first form is nice. Once again, there is no need to restrict node keys to strings. You could support `tree[&lt;any hashable object&gt;]`. 5. Do not use a symbolic operator when the meaning is not obvious. Using `+` for concatenation is obvious. Using `&amp;`/`|` for set intersection and union may or may not be obvious, but it is easily understood by analogy to bitwise operators on bit vectors. Using `^` for common ancestor is domain-specific, although I will admit that it is pictorially very clever. 6. `map` might be useful. The others may be esoteric for most uses. Good luck.
Thank you! I will most definitely check it out. 
&gt;4. How about tree['node_name'] vs tree.get_node_by_name(..) ? (the first is only possible if we restrict node data to string) I don't see why it would be, __getitem__ can take any item as an indexer, the only requirement would be that it implements whatever interface you need - eg having a good hash method, and being comparable. 
It basically works by annotating nodes with parent id, as you'd expect, but also left, right and tree id's for speed, lets you find all descendants very quickly and in an ordered fashion Edit: I've only ever used it in an sql environment, not sure how applicable it is elsewhere
No, you're right. What I meant, and I'm aware I wasn't very clear, is that it would conflict with the tree[i] syntax for index access.
Thank you, that's good input. I wonder, why are you skeptical?
Why yes...yes i did. Caffeine is not working this morning.
I disagree. My recommendation is based on my experience working in polyglot environments where I've found it is much simpler and expeditious to make working code accessible regardless the language or platform being used. I can wrap a standalone piece of code in hours or less without having to study, rewrite and re-test a know working implementation. Also, I think that re-using a know working implementation leads itself towards robustness. 
I think that perhaps email isn't the best option for you. I'm making some guesses on what you're trying to achieve. * You have a computer inside a network that can call out but that you can't call into. This is common for home networks where your ISP decide (and vary) your IP. * There is a computer trying to achieve a task and you want to sometimes prevent it from calling out by closing the ports it needs. Maybe multiple computers, multiple tasks. If those assumptions are wrong, reply and fill me in. First I would consider if, instead of closing/opening ports, you instead make the tasks run or not. So the email says 'task1 on' instead of 'open port'. Mostly though, I would say that email is a bigger pain than you need to deal with. In essence what you want to do is have some information outside of the network that can be read and acted upon. With email, you have an inbox that is synchronised with the cloud, email is a technology that does a whole bunch of things that you don't need here, things that could make your life hard. Perhaps an alternative could be GitHub? You could update a file in a repo that lists the ports to be opened. The controlling computer does a git pull and opens/closes the ports listed. If privacy is an issue then BitBucket offers free private repos. Other options are Dropbox, SSH, Dynamic DNS,... Hope that sparks some ideas.
The problem with that is, it's not clear what `tree[n]` means: nth node? Nth leaf? Depth first or breadth first? `tree[key]` is more consistent, and I'd suggest it's more what people would expect: trees are expected to be lookups, not sequences. 
["Always implement things when you actually need them, never when you just foresee that you need them."](http://c2.com/xp/YouArentGonnaNeedIt.html). Sorry but trees are very simple data structures and every usage of one has different needs. If you're talking about a heavily optimized CPython tree then I could see value there. But those already exist so I'm not sure what you would accomplish reinventing it. As far as " One benefit is that different packages could pass trees to each other" this is already the case if you build a tree out of lists. Remember Python isn't Java and doesn't need data structures to conform to contracts.
Most of my CMS experience is in the newspaper industry (yes, yes, point and laugh) where a lot of that is interesting but not necessarily relevant because of the insane amount of assembly that goes into a generic page being served from a newspaper site. ETags get you a ways, but if you're assembling or teasing content from twenty places to build a page, your CMS either A) does that client side B) does it on a frontend with something like ESA or C) has to be aware of when any given piece of content it relies on in the system has changed, which is an annoyingly difficult problem.
learning enough about python to be able to translate complex python code into php will be basically equivalent to learning python - so do that alternatively, figure out what the differences are between the standard and anki-specific algorithm and then just write the php from the algorithm itself
Can't speak for brandjon, but in my view: Trees are trivial to implement in Python (in various ways). Python exists and has been popular for quite some time now, so there are a wide range of existing tree implementations, many incompatible to each other (and thus to yours as well). Lots of code depends on those implementations and interfaces. So your only bet is for future "blank slate" projects to use your implementation and interface. That will only happen if your implementation offers something of great value to programmers, and I don't think it will. Mostly because almost all of the things it could offer are trivial to implement, and the one other thing I can think of (if it's in the standard distribution of Python) isn't realistically going to happen.
http://stackoverflow.com/questions/2442014/tree-libraries-in-python there are several on PyPi. See XKCD also http://xkcd.com/927/
I opened all the links. * TreeDict doesn't seem to have any features worth mentioning. * ETE trees are cute, but *very* domain-specific * python-graph is only coherent for graphs, not trees. * AVL trees are.. well, only avl.. The rest don't even make sense.
As robin-gvx said, the main benefit would be if it truly were standard, i.e. in the Python standard library itself. I'm sure the core python development community (e.g. python-dev) would be able to come up with all the objections on this page and more. I'm also sure this has been brought up plenty of times before on python-ideas. I guess I'm taking the fact that it has not already happened as evidence against it happening. There is still the possibility of a de facto standard library. But in order to overcome people's resistance to incorporating a new dependency into their project, you really have to offer something substantial. I'm not sure that there's enough of a benefit to warrant this. You may want to check out the [networkx](http://networkx.github.io/) package to see how they address some of the issues you asked.
It seem as if most of the logic is in https://github.com/dae/anki/blob/master/anki/sched.py which does look quite readable.
Unless you're wanting an excuse to play with Python, what you should really set up is [port knocking](http://en.wikipedia.org/wiki/Port_knocking). There's a dd-wrt utility called [knockd](http://www.dd-wrt.com/wiki/index.php/Knockd) that should let you do it.
&gt;Be warned, Google may block your account if you (and your scripts) are logging in from different countries. Another option: OP could simply make a dedicated Gmail account for this purpose to avoid this sort of conflict, and also avoid inbox clutter from sending (him|her)self email.
One question why do you need it to log in to the DDWRT? what is the enable rule and disable rule for I actually just want to know?
It's actually a pretty simple thing to do (provided you don't run into JavaScript) *if* you know your Python libs. A few dozen lines of code should do. The number of times I've set out to do something only to discover there's a package on the Cheeseshop (or even in the standard library) that already does what I want, and much better than I'd do it, too …
networkx does basic trees.
Makes sense. However, to nitpick: &gt;If, however, you already have a server set up (with dyndns or a static IP) I feel like if OP had a server set up with dyndns or a static IP, he wouldn't need any of this in the first place. He could just host a small script/VM/whatever that bypasses the need for email at all. I think the point of OP using his email is that its a way to conveniently send a command to server. I would think that the convenience of email could by far surpassed by just firing off a packet to domain.or.dynamic.dns.host telling it to turn forwarding on or off would be less complicated than any of those features. ~~My assumption (based on context) is that OP doesn't have a dedicated server of any sort, let alone static ip or dyndns, and likely wants to access something occasionally from his/her computer.~~ I'll just ask OP directly and not make assumptions. 
Take a look at the tree at http://www.quesucede.com/page/show/id/python_tree_implementation. I have used it briefly with success.
I'll post some here, but then I think we can move discussion to the github repo. So you would like a very general tool, rather than a single-target script; this is more ambitious but doable and good. This certainly does need to be done intelligently... I would recommend using an xml parser that is not BeautifulSoup, whether it be xml.dom, xml.etree.ElementTree (these two are standard modules) , or lxml (not standard, but popular and I hear good things about it). For these purposes, you clearly need a way to test for equivalency that accounts only for element tag names and attribute-value pairs (not child elements). I think breadth-first search will be most appropriate. Since we are dealing with what is essentially uniqueness in sets, I would consider ways to hash your elements (the simplest way would be to write the tag name, followed by attribute-pairs in alphabetic order) though I am not sure how much this will affect speed. The upper-level logic is rather simple. If an element in the subject tree is equivalent to an element at the same level in the reference tree (same tag name and attributes), then you go one level deeper in both trees to compare the children. If the element in the subject tree is not equivalent to any of the elements at this level in the reference tree, then you insert the new element (and all of its descendants) into the reference tree.
please have a look at the [mailing list](https://groups.google.com/forum/?fromgroups#!forum/project-camelot) 
I'm trying to have an on-demand type enabler to turn on or off a port forwarding rule on my router as I don't want the rule enabled at all times I figured email "watcher" would be the best on-demand type of setup. I do have several servers on my home networ (physical), along with couple VMs, NAS, etc. 
Need to login to actually make the change on the config. Unless there's another way of doing so :-). The rule is to allow incoming traffic to a specific server on my internal network that I don't want on all the time. Eventually I'll setup something more permanent like a DMZ or something 
To enable a port which will allow him access to the router is my guess or his PC (behind the router).
Your assumptions are correct :-). I need to allow external traffic to an internal box but don't want this enabled all the time. More of an "on demand" type setup. Thanks for the tips -- I'll def explore those options as well
This looks extremely promising and possibly a better overall solution in terms of security. Thanks so much!!!
Great suggestions. I would suggest using paramiko for ssh into one host, instead of fabric. Fabric is more for administering multiple hosts at once, and relies on paramiko for its ssh library.
I don't know where you get inspiration, but I made a grade in Udacity about the same (a blog with GAE) 
Does the world really need *another* text editor/IDE?
"red" is a variable that has a class of function. "red()" calls that function, without any arguments. Why having the first is cool is because functions being first class objects means you can pass them around. Other languages may treat functions as something special outside of being just another definition like a string or a number. You can pass functions as arguments for example.
Never mind Google, I'm not quite sure what you mean. But I'll take stab at answering your question. If you fire up the Python interpreter, you can do something like this: &gt;&gt;&gt; def red(): ... print "dit" ... &gt;&gt;&gt; red &lt;function red at 0x10708ee60&gt; &gt;&gt;&gt; red() dit &gt;&gt;&gt; You'll see that red() calls the function, but that red alone merely gives you [the function object, along with] the memory address of the function. That's because by itself, without executing the function, red is simply a variable that stores the function. I don't know how much programming you know, but there are times where you may want to use a function's variable. For instance, you may want to pass it to another function as an argument. In a case like that, the other function might call that function. (That's something that's done with the [strategy pattern.](http://en.wikipedia.org/wiki/Strategy_pattern)) ---------------- **Edit:** Clarification of a technical point. (See below reply from *lost-theory.*)
Do you have a dynamic DNS set up anywhere on your network?
A couple of comments: Assuming your server(s) are Linux: * Use port knocking - debian already has a nice config ready to go that plugs rules into iptables * Do NOT use a DMZ - only forward the ports you need * If you all need is SSH - setup an SSH middle man between your boxes and the servers (preferably one that uses OTP for login)
Upvoting for visibility, even though it's not something I will personally ever use. People who are already using PyDev will probably love it though.
Others have already mentioned that `red` is a variable whose value is a function, but haven't really given a good example of how it is useful. Say you were writing a class, and you wanted different instances of the class to be able to do different things but most of the code was the same. Here's a simple example: class ComplicatedFunction(object): """Computes f(x)^2 + f(x) + x + 1.0 / f(x) + f(f(x))""" def __init__(self, f): self.f = f def compute(self, x): f_x = self.f(x) return f_x ** 2 + f_x + x + 1.0 / f_x + self.f(f_x) f_sin = ComplicatedFunction(math.sin) f_cos = ComplicatedFunction(math.cos) f_sqrt = ComplicatedFunction(math.sqrt) print "f_sin:" for i in range(1, 10): print "i = {0} =&gt; f(i) = {1}".format(i, f_sin.compute(i)) print "f_cos" for i in range(1, 10): print "i = {0} =&gt; f(i) = {1}".format(i, f_cos.compute(i)) print "f_sqrt" for i in range(1, 10): print "i = {0} =&gt; f(i) = {1}".format(i, f_sqrt.compute(i)) This is just a simple example of how it allows for easy re-use and composition. It's what is known as functional programming. A common use of this is in setting up callbacks to be run when an event happens, such as when a button on a GUI is pressed. The function to be run can be passed to the button, and that way the GUI framework can call it when it is clicked. Javascript is a language that makes heavy use of this way of programming.
methods/functions work on similar conventions to a class that implements `__call__` &gt;&gt;&gt; class Foo(object): ... def __call__(self): print "I was called!" ... &gt;&gt;&gt; foo = Foo() &gt;&gt;&gt; foo &lt;__main__.Foo object at 0x02870AD0&gt; &gt;&gt;&gt; foo() I was called! Everything is an object in Python, functions included. You can get an idea of what capabilities an object has by using the builtin `dir` &gt;&gt;&gt; def bar(): print "Bar was called" ... &gt;&gt;&gt; bar &lt;function bar at 0x02864FB0&gt; &gt;&gt;&gt; type(bar) &lt;type 'function'&gt; &gt;&gt;&gt; for element in dir(bar): print element, getattr(bar, element) ... __call__ &lt;method-wrapper '__call__' of function object at 0x02864FB0&gt; __class__ &lt;type 'function'&gt; __closure__ None __code__ &lt;code object bar at 01D6C0B0, file "&lt;stdin&gt;", line 1&gt; __defaults__ None __delattr__ &lt;method-wrapper '__delattr__' of function object at 0x02864FB0&gt; __dict__ {} __doc__ None __format__ &lt;built-in method __format__ of function object at 0x02864FB0&gt; __get__ &lt;method-wrapper '__get__' of function object at 0x02864FB0&gt; __getattribute__ &lt;method-wrapper '__getattribute__' of function object at 0x02864FB0&gt; __globals__ {'Foo': &lt;class '__main__.Foo'&gt;, 'bar': &lt;function bar at 0x02864FB0&gt;, '__builtins__': &lt;module '__builtin__' ( built-in)&gt;, '__package__': None, 'element': '__globals__', '__name__': '__main__', 'foo': &lt;__main__.Foo object at 0x0287 0AD0&gt;, '__doc__': None} __hash__ &lt;method-wrapper '__hash__' of function object at 0x02864FB0&gt; __init__ &lt;method-wrapper '__init__' of function object at 0x02864FB0&gt; __module__ __main__ __name__ bar __new__ &lt;built-in method __new__ of type object at 0x1E1F3BA8&gt; __reduce__ &lt;built-in method __reduce__ of function object at 0x02864FB0&gt; __reduce_ex__ &lt;built-in method __reduce_ex__ of function object at 0x02864FB0&gt; __repr__ &lt;method-wrapper '__repr__' of function object at 0x02864FB0&gt; __setattr__ &lt;method-wrapper '__setattr__' of function object at 0x02864FB0&gt; __sizeof__ &lt;built-in method __sizeof__ of function object at 0x02864FB0&gt; __str__ &lt;method-wrapper '__str__' of function object at 0x02864FB0&gt; __subclasshook__ &lt;built-in method __subclasshook__ of type object at 0x1E1F3BA8&gt; func_closure None func_code &lt;code object bar at 01D6C0B0, file "&lt;stdin&gt;", line 1&gt; func_defaults None func_dict {} func_doc None func_globals {'Foo': &lt;class '__main__.Foo'&gt;, 'bar': &lt;function bar at 0x02864FB0&gt;, '__builtins__': &lt;module '__builtin__' (built-in)&gt;, '__package__': None, 'element': 'func_globals', '__name__': '__main__', 'foo': &lt;__main__.Foo object at 0x02 870AD0&gt;, '__doc__': None} func_name bar Notive that bar has a method `__call__` which is why `bar()` works as desired.
Try using foo when you search. Foo is a generic name used by programmers , so in the future, you might have better luck with your googling and such. also try "fubar" as well.
foo, bar, and fubar's always seemed slightly discouraging when you figure out what the acronym of that last one means :)
Somehow all of my professors neglected to let me know about it's meaning. To be honest, I only found out a few days ago. Haha. Also, apparently, there is a test image called lena that is used in image processing. The image was taken from an issue of playboy and depicts a woman named Lenna. At least Matlab and scipy use the image. The more you know. 
Dude code triage looks like just what I was looking for. Thank you for posting this!
The 70's were a rather special/odd times for CompSci.
When the perfect ide is invented your point would have merit
`red()` is me calling the function, whereas `red` *is* the function itself. Here's a quick example of where it might be helpful to treat a function as a legit object like any other: def double(x): """Given a number x, double it and return the result.""" return 2 * x def my_map(items, fn): """Given a list (or any iterable object) of items and a function, apply that function to each item and return a list of the results.""" new_items = [] for item in items: new_item = fn(item) # Note that I'm calling fn, the function passed to # my_map as a paramter, even though that might not # have been its original name. new_items.append(new_item) return new_items nums = [1, 2, 3] doubled_nums = my_map(nums, double) # I'm passing double as an argument to my_map, not calling it print(doubled_nums) # =&gt; [2, 4, 6]
If you like general cases, then trees are a subset of graphs. There are some really good tools for manipulating graphs in [igraph](http://igraph.sourceforge.net/).
I would have contributed but not if it's proprietary. I think we need a good free and open source IDE for python. There's already some good proprietary IDE.
Does anybody know how experienced with programming one has to be to participate? Is one intro to programming class even close to enough?
Does it have to be via email? I've done this before--what I did was enable SSH on my router, and then I could SSH in any time and enable rules and disable them. Seems way easier than writing this script...
Text editor? Maybe not. *Python* IDE? Yes. Especially if it's open source. The state of *open source* Python tooling is pretty meager. Editors like Vim, Emacs, and Sublime Text 2 are all great and combined with tools like ctags and flake8 provide a nice productivity boost to developers over "plain" text editors like Notepad or Gedit. However, the state of Python debuggers, profilers, autocompleters, tooltip hinting (e.g.: for function parameters), and static analysis is pretty meager by modern standards. For example JavaScript and Dart offer fantastic tooling with Firefox and Chrome's debuggers for JS and Dart's IDE. PyCharm offers quite a few of the features you'd expect from an IDE, but it's proprietary. Open source tools like {I,B}Python, Valgrind, and RunSnakeRun are impressive, but no where near the comprehensive tooling found in most common IDEs. *Disclaimer: I use vim+flake8 and generally dislike IDEs, but it's a personal preference.*
Basically, think of red as a named reference to the function. It can be treated almost like a variable in that it points to a memory address. Anytime you see a set of parentheses after a named reference, it means "invoke" or "call" the named reference. I suggest reading up on functional programming, shich is differenf from procedural or object oriented programming, but it embodies the use of functions as named object-like variables.
The third party predicate stuff looks pretty cool. Didn't know it was a feature of Pyramid.
Anyone tried pyjamas here? appreciate to hear your thoughts....
Was all good until it got to #4. MongoDB gets it's hate for a *reason*.
There's all sorts of reasons where you would want what the other is talking about in Django. The simplest is a common REST url scheme where GETing '/app/people/' returns a list of people and POSTing to '/app/people/' creates a new person. Currently you have to do this by creating a single view that checks for a POST and then, at best, shoves it off to the other view. With django-multiurl, you can sort of do this, but it's awkward. I have proposed a simple keyword argument of "methods" for url() that would simplify this greatly and will be creating a patch when I get some free time. Another situation is where you want to have a pattern like '/users/(.+)/' and you want to first try a get_admin() view, but if there are no admins with that name, then try a get_member() view.
Ah, thanks for the reply. That would come in handy.
This is really good explained and it's correct for special type of programs as you said when the user has to work with a lot of raw data at once. I hope you don't get me wrong: I'm no against using python, nor using it for desktop applications development, since I myself love python and have a fair amount of experience using it for desktop applications development. The company I work for uses desktop applications that are developed with VisualBasic and are so messy to extend for the new needs that is almost hilarious when it comes to communicate with the web-application I have developed to serve as middle point for other applications in the company. I needed the argument, so I can propose an alternative, witch will be faster and easier to maintain, extend in order to replace that VisualBasic mess. I can agree that in many cases desktop application has many advantages over a web-based application, and in other cases there are a lot of benefits using a web-application instead a desktop-app. Again thank you for the time explaining this to me and I hope it will be enough to try to convince others that using python+qt and in some cases camelot will be a better solution. 
Celery is nice for mimicking cron for multi-server setups. Can rq do this?? Can't see anything at first glance. 
A better name for this article is: "11 Things Which 40% Of Are Great, 20% Of Are Good Ideas Implemented Poorly, And 40% Of Are Things Which I Should Have Not Done in Django." 
It's not "cheating", but it's obviously not what you were asked to do.
Really good advice, though also research alternatives to the ones he mentioned. For example: * I prefer uwsgi to gunicorn (a lot) * I really like django-assets for my JS/CSS build process * I find New Relic hard to beat in process management and ease of setup * I deploy to Ubuntu, so prefer upstart scripts to supervisord (essentially feature parity for general use) Other things I'd mention: * Use Sentry for your process logging. A godsend, especially with source repository plugins for fast issue creation. * Check out saltstack for automating deployment * Use django-nose for a test runner * Write unit tests mocking out DB calls * Use lettuce for functional tests with splinter/selenium using the phantomjs backend As for the testing tips above: I can run 160 unit tests in .5 seconds and in ~5 minutes can test my whole site in a "real" browser that outputs screenshots of every page in both "PC" and "Mobile" resolutions (the CSS is responsive). It's been a life changing testing suite, and saved countless hours.
The functional testing bits sounds very cool, but how much time did it take you to set up all that?
What hate?
If you think mongodb is great and everyone should use it maybe use any other webframework? 80% of django is useless on mongo and most of the reusable apps can't be used on it. Why bother recommending it - django's strong area is it's ecosystem - that cannot be used with mongodb ...
Note that two known deadlocks were fixed in celery 3.0.19. Celery keeps a dedicated process pool to execute tasks, and this definitely makes the problem harder, but it's also beneficial.
If I were the teacher I'd allow it, merely for it's creativity.. however I would deny it for it's bloat These three lines would do the same (yes, I assigned it to a var so you can do error checking before calling it) #!/bin/bash NAME=$@ python -c "a = '${NAME}'; print(a[::2])" output: ./test.sh Your_Name Yu_ae 
The entire test suite was built out as I programmed the other code - it was about an equal amount of time to writing the code itself (as testing usually is - but it's worth it). The functional tests are very quick to write - the lettuce DSL is really simple, and you'll generally only be using a handful of functions (i.e. click X, visit URL Y, Enter something in Z). An example would look like: * Given I visit "reddit.com" * When I click on "AdviceAnimals" * Then I see the the words "Good Guy Greg" Then you just write a simple function that takes the pieces in quotes and does an action based on the other words, and reuse as necessary. The hardest part was finding all the hidden gems in the programs I was using to do what I wanted (for example, by default lettuce uses your normal DB, so I had to track down a config to set it up with a test databse). Or: I started doing this RIGHT after phantomjs had been released, and I spent a good six+ hours just trying to track down the correct way to change the phantomjs screen resolution so my screenshots would turn out correctly. (P.S. If you're using splinter, you just use the command: browser.driver.set_window_size(width, height) where browser is the splinter browser object and driver is the selenium passthru). I've probably made up all the time I spent on the test suites since then, as they've saved me many hours in either (a) finding bugs before I had to debug a full stacktrace, or (b) not making me step through my application to see how HTML/CSS changed on different pages as I modified templates.
Those are some really nice, round numbers... Hard to believe when you're dividing by 11. ;)
Isn't mongo pretty notorious for losing data?
pretty solid coverage, and yet missed one of the big ways IMO, traversal. combined with all the others listed in the article, the view configuration/routing possibilities are endless. 
For managing schema migrations, I use sqitch: http://sqitch.org/ It is a simple tool designed to help you manage your SQL migration scripts. You can find a tutorial here: https://metacpan.org/module/sqitchtutorial
Care to elaborate on the latter two? Other than Mongo and his implementation to support JS frameworks, the other 9 all seemed decent (with minor variations due to personal preference, but no glaring red flags).
I started out looking to use Django, but quickly realized it includes all kinds of cruft that I didn't want, not to mention that the templating system is extremely slow compared to other stuff out there. In the end, I settled on using bottle. I like the idea of just loading modules (e.g. WTForms) when you need a particular functionality.
It's slow to start on the desktop! So probably even slower on a phone. I haven't tried that.
It's not slow. People are doing their benchmarks wrong (which is also basically every benchmark ever). The default settings render the template new every single time it loads. Just switch to the "Cached Template Loader" in your settings on your production box, and you'll see roughly the same speeds as jinja templates. (Caches in process) It's a config toggle that unfortunately the docs don't make enough of a point of, and I've never seen the published benchmarks turn on, which makes it appear as if the templates perform like crap, when they in fact do not.
thing is, there is nothing tornado-ish about tornado.options. It would be great if it were packaged separately. 
I'm not sure it's in the latest release yet, but I know tito (Mathieu Virbel) added a feature that speeds up startup time extensively by caching the result of the kv file parsing/compilation, which was done at every start before and is now not done when the file has changed. I think it will be i the next release, but otherwise is in the current master branch (plus a bunch of other optimizations we did after some heavy profiling in response to some questions about performance we exchanged with someone at dropbox )
It also kind of depends on how you write your application. If you load everything before starting the app its going to take longer. My advice would be to start with the simplest screen you can, and then create the rest of the UI after / while the application is already running.
I believe your solution would fail if placed in a directory where the user has exec privileges, but not write privileges.
Why would you be doing anything per node? That's ridiculous. The whole point/aim of a multi-server setup is to abstract the number of nodes by using something like django-storages for "local" storage and your DB/Cache for everything else. You can then add or remove nodes as needed to scale for process demands. And if you only have single instances of periodic actions being run, celery lets you distribute the workload across your nodes if you set up the task in celerybeat which acts as a scheduler, and then your various celery workers can handle those tasks as needed/able based on consume capacity. I'm really not seeing what you're trying to get at (though welcome a better clarification).
It's pretty notorious for not being a relational data store yet people keep insisting there's no need for those any more and key/ value is all you ever need. Those people are morons and poor MongoDB gets hated by the transitive property. There's nothing wrong with Mongo, it's just not the solution for everything. I stopped reading this post seriously at #4 as well.
As someone with dozens of projects using a local_settings.py file, even I've come to realize it's a bad idea. It's ok when you're the only developer, but there are better approaches and they're pretty well documented so it's strange to see that in his list of recommendations.
We use redis to store volatile data, but we use a standard relational database as our "master", it's not that I'm afraid that redis will somehow lose data, but I don't know enough about it to guarantee that nothing will get lost, and it's much easier to generate reports with a traditional relational database in my opinion. I know at one point reddit took forever to display the post history for a person because the nosql db they were using basically required a map reduce job every time the list was requested. It seems to work better now so I'm not sure if they changed it or what. 
It doesn't really do multi-processor/multi-core work very well. For example rather than code 1 process that works across multiple cores, you'd probably be better off designing around having multiple python processes that can each run on their own core. Frankly right now not many situations require this. But if the current add-more-cores-to-cpus craze keeps going, Python will likely have to evolve to work better in these environments. And I believe work is being done with this. Since Python, Ruby, Perl, Java, etc depend on an interpreter deployment can sometimes be an issue. Write something on Ubuntu 12.04 with Python 2.7 and you may find that things don't work when you move it to CentOS5 running Python 2.4. Compare this to say, Go, where I can compile on Ubuntu and run it on RHEL4 and you need to be more aware of your target environments. But again this isn't horrible. For our CentOS5 systems I simply source installed Python2.7 which lives alongside the older version and everything works fine. Also Python tends to feel a little more general than other languages. In that it does pretty much everything: web, stand alone GUI, graphics, mobile, quick scripts, etc. And for each option you tend to see several options and different ways to do things. This means you may have less focus than specific designed languages or languages where everyone picks the same framework. But for me I like than I have a single language that does so many things and for each area I have multiple options. Job-wise is probably a big weakness. On the web side PHP still the king mostly because it's so entrenched. Java is huge in corporate for devs who aren't C/C++ monkeys, mobile is C/Java, game dev is C++ and so on. If you want to have a lot of job options, go PHP/Java or C/C++. But I also know quite a few people who are miserable in corporate wage slave Java jobs. Sometimes if you're working with a less mainstream language you tend to work for shops that have people running it who are more interesting/knowledgeable to work for. 
&gt; using docstrings for type-inference This sounds awesome.
Complains about Django templating being slow, uses Python for development.
So far I have about 120 hours invested in the language, which isn't much, but judging by your question you sound like you might be in the beginner boat with me and thus my input might be useful. I have 2 gripes. 1. There are no true access modifiers, e.g. "private", "protected", etc. 2. Passing "self" to every function in a class seems silly and more verbose than necessary. I get the reason for it per the Python zen, but it seems a little awkward compared to how easy it is to read and write everything else in Python. Python is reputed to be slower than languages such as Java, however things like Cython exist to work around the bottlenecks. I haven't really run into a bottleneck yet doing what I need to do. Most of my issues I run into are because I have a lot more experience with static-typed languages. I am really liking Python so far. It's been *very* useful for prototyping things I make at work as well as doing data analysis. "Batteries included" is an understatement.
This is great advice but makes me wonder is there any recommended book or series of articles (or series of videos) that can be considered must-read/must-watch for beginner web developers who are not necessarily beginner software developers? I mean I could go through Django tutorials and be very good at it and still not realize there are things like celery out there, or what is redis, or gunicorn etc. Or how to setup your website from the ground up for scalability etc. I guess I'm asking a very broad question but still.
&gt; There are no true access modifiers It's a dynamic language by design. You can use underscores if you really want.
Where "don't lose my data" is (or was; I stopped paying attention) *not* the default.
Honestly, then he can do git pulls to the code base and keep it up to date with other people's work.
Also, if template performance is the limiting factor for your website then... um, congratulations. You've won. Even the worst template systems take tiny amounts of CPU time for huge loads, and are trivial to scale horizontally. 
It's not really a trade off so much as a philosophical difference. The underbar model is based on the idea of safety rather than security. It kind of makes sense when you think about it. It's certainly a less complicated approach to encapsulation when you compare it to reflection and security policies in Java.
Yeah, it's more of a reminder to yourself, that this method wasn't really designed to be used outside the class. There's really no security, although many template parsing libraries will ignore calls to underscored methods.
Would quickly fail on a system without Python installed. Not to mention writing a file and executing it require different permissions which you might not have. To top it off, using a regular expression for this is like hunting rabbits with a tank.
you said it does a nice job of mimicking cron, cron works per node, say you needed to clean up a work directory on every node once an hour, well you definitely can't use celery for that. I just find it silly how many crazy edge-cases celery supports, but that there is no clear way to send a task to a specific node. If I didn't use hadoop extensively, I would personally also want the ability to send a task to all nodes. (Say searching through log files on all nodes). 
You assumed correctly i am quite new,
[Geany](http://www.geany.org/)
How did you manage to get tests that take .5 seconds?
Use Linux? 
This so much.
write real unit tests, not integration tests
I'm assuming he knew about that, especially since this is heavily covered in the django tutorial.
I would also be interested in this.
&gt; do not waste your time with RabbitMQ unless you have a good reason to. I would love an explanation to this please.
Could you clarify?
&gt; Use Gunicorn instead of Apache for your webserver I'm not convinced by his arguement against Apache. Mod_wsgi was trivial to setup. However, can anyone tell me their experienced with Gunicorn? I may use it if have a deployment where I don't already have Apache setup.
&gt; Use jammit for static asset compression Isn't Apache/Nginx gzip compression adequate?
Tbh, the example shows 2 handlers, 1 for POST, and 1 for GET.. Django's generic views do that by themselves.. you have 1 View class, with a .get(self, request) and a .post(self, request) , that get called depending on the method.. personally, I expand that view a tad into an AjaxView, that does ajax_get, ajax_post, get, post depending on if it's an ajax call or not, and the method used. I do admit, however, that multi-urls are useful, and I too miss them in django's core (though it's easily fixed with django-multiurl, I don't want to have a gazillion dependencies for a simple project)
I tried apscheduler a while (quite a long while actualy, as it was a personal project, and I'm lazy when it comes to my own projects at home..).. allows you to create cron-like schedules.. but I found the downside was that you'd have to run it in a separate daemon for it to run reliably.. Celery, on the other hand, requires more to be installed (redis/rabbitmq, etc), but can do scheduled tasks -and- async running of tasks at the same time, which are two features I often use in my projects... so I just end up combining them by using Celery
I recently found Two Scoops of Django. It's a pretty easy read that talks about a lot of this stuff. https://django.2scoops.org
 #!bash echo earnMLreue Done.
It seems to be mostly from people who are used to [ACID](https://en.wikipedia.org/wiki/ACID). If you have a real database, that is properly set up to replicate, you won't lose the database in any event ever. Whereas with Mongo, it can fault, and you just have to be aware of that. That's without getting into the whole tableless thing. Ultimately I think the consensus is emerging that MongoDB and similar databases are good for *social data* that has trouble living in a traditional table/column/row model and isn't terribly important. MongoDB is a terrible, awful choice for "big data" and especially financial data. If you're doing transactions with real money, for example, you should never use MongoDB to store that.
Exactly, right tool for the right job. If Redis works for the problem, that's awesome. But it's become one of the Rails/ Node/ NoSQL shiny toys for people who were never taught, "To the man with a new hammer every problem looks like a nail." Every time a new piece of development toolkit comes along I'm reminded of the saying, "Every generation thinks they invented sex". It's not like the people who created relational databases were idiots and it's not like relational databases have lasted because people are too lazy to build something better. They serve a purpose and Boolean algebra matters.
I would definitely recommend that book over this list.
I do something like this to run periodic tasks. Since it's company code, I can't show you the source code, but the concept is similar. 
I don't think you can really design from the ground up for scalability unless you know what infrastructure you'll be on, and what your requirements are. Having said that, I think the best place to start, honestly, is to learn Google App Engine. Not necessarily because it's the best, but because it's simultaneously simple, powerful, and easy to learn. [Get the O'Reilly book](http://shop.oreilly.com/product/9780596522735.do), do the examples, and go on from there. Even if you don't end up using GAE for your next project, you'll have learned all the fundamentals about web development. And really, the overall design of GAE and its APIs are pretty *conservative* and clear-headed -- a lot like Python itself. GAE is a very well-thought-out project, which Guido himself worked extensively on while at Google. Unlike Django, it's much non-verbose and doesn't impose a lot of koolaid in terms of how you lay out your project. The only real downside is that you're somewhat restricted in what libraries you can use, but that's also a good thing. It keeps you from making mistakes like putting long running synchronous code in a user-facing web handler.
Conflicting requirements? Never happened to me, so I guess the “often” is unwarranted. But surely the cases where it happens are painful enough to warn about then
As a noob with a little programming knowledge already, I've found setting up and installing things much harder than actually learning Python itself. 
I recently started playing with our channels irc bot and was having problems with the python. In an attempt to catch some debugging, one of the guys at my HackSpace came up with this 3 line header =) #!/bin/bash # code pilfered from pbrook and executed badly by me. # this bash header needs to be exactly 5 lines long. /usr/bin/python &lt;(tail -n +6 -- "$0") "$@" exit $? #!/usr/bin/env python3 print("code here...")
http://stackoverflow.com/questions/5357601/whats-the-difference-between-unit-tests-and-integration-tests Still... for unit tests to run that fast, I would question their usefulness but it's hard to say without knowing what the code was doing. I've met at least a few people who wrote lots of tests that didn't actually test much at all. 
Dropping a post here for @ColtonPhillips and anyone interested who finds this later. I opened a [discussion issue on the GitHub repository for this project](https://github.com/ColtonPhillips/wpdb/issues/15) where I linked to a general-purpose XML-merging script. Here is [a direct link to the script's Gist](https://gist.github.com/SavinaRoja/5408568).
Probably just a "don't use 2 tools when one can do the job of both" kind of thing. The more technologies you use, the more complexity you have and thus the more stuff can break. 
It's not in the spirit of the assignment. I'd fail you because all you've demonstrated is how to call python from Bash. Creative, though.
I could never get it to work properly. 
Aye. I write tests for functions/methods and the views that utilise them, usually. OOP is a pain in the dick to unit test because there's state everywhere.
Things you should learn about: - mktemp, but don't use it here. Also "trap 'rm" EXIT' - python -c "foo" - no path to rm
Gods, that's terrible. At least use some difference in the languages to make it simple. Python sees this as a string with a quotation inside it. Bash sees this as two empty strings and then a command. #!/bin/bash """"exec python -t $0 "$@";" """ Also, exec, not Foo; exit $?
yeah that's both the *good thing* and the *bad thing* about it, Django is a full-stack fw which means it solves as many things as it can, that's good if your setup fits within its expectations but it's a pain if you're changing many parts of it. I've got the opposite problem of you, I had a project that was using Bottle but was so standard that in the end I had to reimplement a lot of things that Django already had solved.
Why do you prefer uwsgi to gunicorn? I haven't used either yet--I used mod_python for years, then mod_wsgi, now fastcgi (w/ lighttpd) and I'm sick of all of them :)
This looks like a good option, I'll give it a try with some of my small maintenance scripts. Thanks!
Yeah, but I'm pretty sure it also covered reversing URLs...
gzip is quite good, but asset management things like jammit (or the many alternatives that were actually *made* for Python/Django... not sure why he's using a Ruby one) do a *lot* more than just gzip. Check 'em out: https://www.djangopackages.com/grids/g/asset-managers/
Oh dear. No, don't use celery or anything within the application layer for something like that. Your application layer in a multi-server setup shouldn't even be aware of the concept of individual nodes. Which is why celery is so great - the workers consume tasks in such a way that you can scale up or down celery workers independent of your application processes. For executing tasks across individual nodes outside of the application layer, use saltstack or fabric. But if you are deployed on multiple nodes and the django application is aware/interacting with local resources of any single node (besides DB/cache), you'll end up having a bad time if you need to rapidly change node configurations. This was why I highlight celery as "mimicking" cron. I don't want a cron task for given periodic processes running on each node, because then there are multiple duplicates running. I want functions running once each, every so often. Celery makes this a dream to execute, and let's the workload still be distributed among nodes (which doesn't work if you just have one node running cron). 
Did you use any particular guides in creating your wonderful-sounding testing infrastructure? Or have any good resources on getting started on such a thing? 
Here's the first problem. I can explain more of them later if you are interested, but this list actually does start things off quite horribly. This person's filesystem is terrible. There's a "bin" folder for bash scripts, which "help your development". The problem with this approach is that it is completely unnecessary. You can use management commands and/or fabric to handle these cases more elegantly than a bash script. They also create a namespace for their apps. This is a very annoying practice that some Django developers fall into. For some reason they don't want their apps sitting next to static files, media files, etc. so - instead of changing media/static files directories - they decide to throw all of their apps into another namespace. Now you either have to manually manipulate the path to include the apps directory so that you can "import appname" or you have to "import myproject.apps.appname". Both of these solutions are bad because the expected / Pythonic way of doing this is to make sure that people know where your modules are. Hence, "import myproject.appname" makes a lot more sense - and that's why it's the default interface provided by Django in the first place. It is much easier to understand, much less potential for name collisions (all of your apps are namespaced into myproject so that their names aren't collisions), and you aren't solving problems the wrong way. If you want your media and static files to not be sitting next to your app modules, then change the directory they're in. There are settings available for doing that. Don't change the directory which everything sitting next to them is in.
Well, I've seen performance comparisons showing that Jinja, for example, is 11x faster than the Django default templating system, which is known to cause performance problems in large projects. You're implying that python/WSGI is particularly slow for web deployment? What's faster?
I don't know why but yours only return the input on my setup. Darn, I didn't even need to use regexps today, and I now have a problem with them…
I switched from mod_wsgi to gunicorn because mod_wsgi segfaulted dozens of times per day for no appreciable reason. I was never able to track it down because it didn't leave a core file even though httpd was started with that turned on. I like having a pure-Python app server because it's easier to debug when something goes wrong, e.g. the aforementioned segfault issue. Up until a year ago this stack was running for 5+ years on mod_python and any time there was a segfault or hung process issue it was extremely difficult to get a python stack out of mod_python. gunicorn is just an ordinary Python application so the usual gdb tools apply.
There were two awesome talks at PyCon (or DjangoCon??) last year I think. In general I was really unhappy with how I did testing in a previous project, so I researched everything out there for about a week. Here were the key takeaways: * Use factories instead of fixtures * Mock writes and DB returns so you're only testing your code and not the ORM (yay speed) * Test one code path per unit test The functional testing info out there was a bit of the wild west, but I realized that the newly released Ghost Driver would let me use selenium in a headless manner with the awesome phantomjs. Then I liked splinter's additional abstraction of selenium. And I really liked how writeups on lettuce/BDD forced me to periodically put myself in the user's shoes, so I used that as a functional test runner.
Why are you sick of mod_wsgi? Performance is pretty good compared to other options.
I use celery extensively in production but I still disagree. I think celery is way too complex, has too much of a dependency chain that breaks all the time on upgrades. For all this pain you really don't get that much in my personal opinion, it can't effectively solve map-reduce type problems for many reasons not the least of which is data locality. When something like http://discoproject.org/ (which I haven't tried) comes along supporting the basic simple task functionality of celery (along with working well in single server setups), I can't see why anyone would stick with celery, its just too much of a pain to manage with too many options. tldr: basically I think celery has too many moving parts for the actual functionality I use example of someone else avoiding celery for a map-reduce job http://justcramer.com/2012/05/04/distributing-work-without-celery/ 
Great point about the namespaces. Certainly interested in more. I feel like often the devil is in the details, and details are never discussed enough! :)
Well, I'm not using Apache anymore, so it's not really relevant. But performance is almost always secondary for just about every application: ease of configuration and maintenance and stability are far more important--and mod_wsgi (while much better than mod_python ever was) is a pain in the ass. 
It's very rare that templating will become a bottleneck to the project, 99.9% of your problems will be in the DB or on the wire. As for faster, pretty much anything. Hell PHP is faster than Python/WSGI. The point is, it doesn't matter. Python is fast enough, and if you're having problems, it's likely a caching or DB related issue.
I want to support PyDev and not this silly LiClipse thing, but the lowest level of PyDev only is too high for me to afford.
Awesome! Reading more on both, I'm inclined to agree with you--guess I'll try out uwsgi! Thanks!
Excellent. I've never really done any automatic testing for... well, any project that I've worked on (which is probably hundreds...) so this is a bit daunting, but I know it's something I need to start doing. Thanks again!
I was just reading up on RQ, found this: https://github.com/ui/rq-scheduler
Note: I don't test rendering templates/etc in the views for my unit tests, leaving most view code to my functional tests, so that helps keep it low. But I have 100% coverage in all my non-view code, as well as testing for edge cases. The majority of my app is mostly logic tests, without a lot of expensive operations, and by faking the ORM with mock to return "built" factories using factory boy, and mocking out any writes, my test suite just never has any I/O blocks. The majority of that .5 seconds is actually datetime manipulations (the app does a lot of time zone comparisons). The one downside is all the mocks end up coupling the unit tests a bit tightly to the methods they are testing, but I was willing to trade the issues that would mean later in refactoring for a fast test suite on a daily basis. It's performed pretty well at uncovering bugs my linters didn't catch, so working out so far.
This looks relevant, too: https://github.com/ui/django-rq
Mock is a necessity for exactly this reason. Don't actually create the state, just insert it into your method with a mock. And mock outbound calls to other methods, returning the desired result. 
The first time that I saw this, I was really confused. Why would you want it when you can just organize your settings better? However, I understand that some people prefer it and it's not really a terrible practice. It's just not very logical, either. I think that it's one of the least terrible practices that this article promotes.
You might want to check out uwsgi then. It has a number of features built in that would let you do things similar to David's taskmaster solution but with less custom work needed. You'd be tying yourself to the server, but it's also a great server. 
Well, gunicorn is also trivial to set up - so that argument doesn't really provide any justification for using Apache. * Install gunicorn through pip or easy_install. * Put 'gunicorn' in your INSTALLED_APPS setting. * ./manage.py run_gunicorn. Even easier to setup than mod_wsgi was! Now, for the part that is actually important: Performance matters. Apache is a terrible competitor in the world of performance. It also sucks up way more memory than necessary, and configuring it is horrible. 
I tried it and I had a hard time understanding anything. Then I went on IRC and found some of the nicest, most helpful people of any library/IRC channel I've ever met. They pointed me to the right docs to read, gave me some tips and encouraged me to keep going. [My blogs about Learning Kivy](http://ckcollab.com/blog/?cat=12) It was a pleasure, the only reason I stopped using it was my project died. As soon as I make a game: I know I'm going to use Kivy.
Well, my "preferred" approach right now is the same lazy thing he's doing, but after reading *Two Scoops of Django* and working on a team that did the same, I think [this](http://www.rdegges.com/the-perfect-django-settings-file/) is a much better approach.
&gt; Well, gunicorn is also trivial to set up - so that argument doesn't really provide any justification for using Apache. It wasn't suppose to. I was a rebuttal. &gt; and configuring it is horrible. How so?
Thanks.
How is it two tools though? He used Reddis instead of RabbitMQ, no?
What is the ideal Django project folder layout? Is the author's suggestion good?
They keep regularly updating it too, which is marvelous!
 AUUG! THERE IS AN __init__.py FILE IN THE ROOT OF THE PROJECT FOLDER!
That's the same method I've used in the past for similar reasons (Celery is too much fucking about for tiny things.) It does the job admirably!
Happened to me on quite a few occasions. SQLAlchemy did an upgrade that borked some things a few months ago in five of my apps. Wheeefun. 
Everyone says that until it happens. If you only work on one project, it's probably not a big deal, but the second you have a new project and think, "Oh, I should upgrade library x" . . . you're asking for it.
yeah, not blocking other tasks and running the tasks scheduled timely was my concern as well. The python-scheduler above uses different threads mostly for this reason, which seemed to be good enough in practice.
oh, [that one](http://docs.sqlalchemy.org/en/rel_0_8/changelog/migration_08.html#behavioral-changes)? i can believe that it broke some things, although i had no problems.
Moreover, this kind of thing should get a zero. I don't know if the OP is just trying to be "smart" or doesn't actually know (or want) to follow the instructions. Don't be the annoying student and just do the assignment.
Yes. Python is fairly slow when compared to other languages. However in the world of shared nothing architectures, caching and other app acceleration ideas, there are work arounds.