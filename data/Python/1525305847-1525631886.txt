HackerRank has many code challenges you can work on. Otherwise build a personal site, find a project or interest, and apply a Python solution to it.
At any point have you considered reading a fucking document? It seems like you're a fraud hoping for savior.
Whats that license? 
No we cannot. I have provided sufficient concept to transfer into search. Do it or fail, I'm not involved either way.
Such lack of respect for format, in line with code style, useless.
Using something like pyinstaller creates an exe, is it possible to see the source code from this as well?
Do you thin k this could be because these languages use different characters? At least some of these European languages have unique characters I believe.
A youtube video of screenshots has got to be the worst possible format.
Linode or Digital ocean. But with the new(not so new anymore) $5 plan from Linode it’s mostly there. 
You get a perpetual license only for a specific version of PyCharm \(and all previous\) \- latest available at the time of the beginning of your annual subscription. If you renew for another year, you get a new perpetual license. If you get 6month sub now, and then later decide to renew for another 6 months, so you have 12 months covered \- you also get a perpetual license for the current version which is 2018.1.x. So basically it works as an good old licensing model \+ you have an access to all the latest versions while you're on a subscription. When it expires you can always safely fallback.
Yes, there's not a lot you can do to hide your source code when you're distributing python programs to end users.
Full description is here: https://sales.jetbrains.com/hc/en-gb/articles/207240845-What-is-a-perpetual-fallback-license- In my own words: https://www.reddit.com/r/Python/comments/8gjhyx/comment/dyctqmk
Full description is here: https://sales.jetbrains.com/hc/en-gb/articles/207240845-What-is-a-perpetual-fallback-license- In my own words: https://www.reddit.com/r/Python/comments/8gjhyx/comment/dyctqmk
Seems like a fair deal 
I deploy to wherever I can find on the network that will allow all my users to use the script. Or I run it right from my local repo via cron or in Flask or whatever, depending.
https://regex101.com/
Never use staticmethod ever. Rarely use class method. They’re Javaisms. If you want a function, just write a function. 
PyCharm is fantastic. I'm in for that (and fluent Python too).
I just started learning Python by doing a Udemy class, trying to get an idea before I take a python class at local community college in the fall. Just started lurking in this sub! Looking forward to learning more.
Yes, programs like uncompyle6 can extract everything except the comments. Variable names, docstrings, etc are all preserved. If you want to prevent this there are several programs to obfuscate your python before you freeze it.
Honestly, it's great. Community is terrific as well if you can't get pro or don't need the pro features
&gt; Im wanting to make a blog website from scratch Why?
PyCharm is amazing. Also there is a deal on it right now - search “Humble Python Bundle” on google. Have not used Spyder. PyCharm gives me VERY good code introspection, especially with type-hints. 
You might prefer Nexus to devpi. Artifactory works too if your company is already paying for that.
Don't know if this has been said yet, but if you have a .edu email you can get Pycharm and other JetBrains software on their site for free. https://www.jetbrains.com/store/?fromMenu#edition=discounts
Thank you for the detailed answer, I really do appreciate it!
Agreed. VScode is a great all around IDE. It will also prompt you to install popular extensions based on whatever type of file you have open(like .py, .ps1, and so on). I don’t have anything against Sublime, I just think VScode makes the setup easier. And it has built-in terminals and version control ready to go(as long as you have Git and a repo). 
How will user be notified of new releases - web pages?
My only experience with pycharm is un-fucking one of our PIs environments after he checked it into a git repo and started mixing using it on multiple systems which it really did not like.
No notifications right now. It’s a web application at the moment. Eventually I’d like to get an api set up so I can get native iOS and Android applications running off it.
str.translate 
&gt; I reconsider whether it's really OK to scrape them. Why would protections imply whether it's OK to scrape them? Why would that alter the ethics? Maybe you meant: "whether it's really worth the effort to scrape them?"
Making a model run faster. Start to finish is 4 min and I need it to be under 10 seconds. Not sure how to. Currently exploring Spark, multi threading, and multi processing, but I feel like I’m in way over my head. 
Oh please, get off the corporate dick. It's public data. If you want the benefits of having your data public (indexing, easy accesability etc) then you have to also carry the burden of it being public as well.
It's not about the data, it's about the increase in server costs.
https://github.com/Anorov/cloudflare-scrape On the side note - fuck cloudflare. I love that they parrot their moto "we do it to improve the internet" and is a for-profit company that really sucks at what they do. Not only their web-crawler protection does nothing to protect against real harmful bots it hinders small apps and other tools that would like to make request once in a blue moon. 
I've been working in web-crawling for almost a decade now and let me tell you that none of this shit really works against people who really want to scrape your data. All you are doing is adding this insane amount of complexity and just down-right broken logic that turns away legit customers and users. The thing that really works is taking that $100 of server resources and a week off to set up a simple public api wrapper around your private api - you probably use rest ajax everywhere anyway.
&gt; Because I want to...I'm not trying to mean but what does it matter? It would shape my advice.
They set up an api. Rest requests are literally a million a penny. 
Are you open sourcing it or just announcing it?
If you buy a year subscription (or are subscribed for 12 months straight), you permanently own the version that was out 12 months prior to the end of your subscription. That's a complicated way of saying that buying a year's subscription gets you a permanent license for the version that's out now, in addition to a subscription to use updates for 12 months (at the end of the subscription, you'll be forced back to whatever the current version is, right now). https://sales.jetbrains.com/hc/en-gb/articles/207240845-What-is-a-perpetual-fallback-license-
The request itself, yes. The actual cpu server time, not entirely. You have no idea what code they are running to serve the page. Not to mention, maybe they don't want to set up an API? Why should they? If they do it's even more requests and server time spent on things that website gets nothing in return for.
The best answer would be having a try on both, give each a day time, and you will find which one is more suitable for you. Giving my case, I started with Django but then moved to Flask. I find those Django Apps are quite useless when the service grows, they are hard to modify/change, I'd rather write a feature without a Django App. Moving to Flask opened a whole new world to me, I can feel that I'm writing Python instead of Django.
I looked into that, [and this is as far as I got](https://www.reddit.com/r/IPython/comments/8gm22x/cant_install_jupyterlab_via_conda/).
Would you mind explaining how these would work better?
I put them in a git repo, and when master is updated it is deployed to an ec2 instance with [rundeck](https://www.rundeck.com/open-source) installed. I use rundeck to manage all of my cron jobs as well as enabling my users to run one-off tasks themseves.
What if you aren't a student but work for an educational institution (and have a .edu)?
I would encourage you to use Flask for you first website. Flask does a lot less for you, but as a result it also hides less of what's going on, which makes it a much better framework for learning how basic web development works. You'll be forced to understand more, and it will be *easier* to understand more. For your second, third, fourth, and so on websites, I'd suggest using Django. It does everything Flask does and a lot more, and is just way better for getting things done if you understand what you're doing.
That's more a stupid mistake which got over looked. I will fix it. 
You can always make Scrapy NOT o obey robots.text by making changed in settings.
Absolutely but you can expect people to not be dicks about it. Just because reddit lets you make posts via the API doesn't mean they want you to use a private sub as a filesystem (which someone legit tried to do a couple years back).
try: while True: Doing stuff except KeyboardInterrupt: break
classmethod is very much not a javaism
it's fixed now. Thanks for your constructive feedback. It was a silly mistake at my end :)
This is why I wrote: &gt; It is very difficult to write a scraper that NEVER gets blocked but yes, you can increase the life of your web scraper by implementing a few strategies. 
Working on understanding classes and GUIs using tkinter. Currently trying an oop approach to make a die rolling sim where I can press a button and 2 dice are rolled and their faces are displayed. The book I got the idea from uses a watered down gui but in trying it on tk for the challenge 
How do you define someone as intermediate/experienced? 
I listen a podcast with dan bader the autor of python tricks, i don't like how he is doing business, private paid forum etc But as i listen as the goal and content of his book i really want to read it and work with it. As far as i understood, the book is made for take intermediate users to profesional level. He explain many of hard/hidden/dark features of python, like decorators, generators, itinerators etc, and for each of them have show an usecase. I think i will buy this bundle juat for this book. I am kind of curious to read mastering pycharm as well. And see what is added in pro version of it.
Start learning a language meant to be distributed (c# + wpf is nice). Or learn something available everywhere (PowerShell on windows)
Just to be honest--if you want to start blogging and want to write your own blog software you probably won't be blogging anytime soon. Beyond the code you'll probably end up spending a ton of time mucking around with CSS and stuff like that. That said though, and going on the assumption that you aren't already blogging--you should take a look at (and test drive) some available blog software. Jekyll (written in Ruby) may be a good one to poke around. Just things like how to manage skins/templates, what the "boiler plate" concerns are, and even how to integrate/leverage one of the existing commenting systems will probably save you a lot of time. 
&gt; not the data that many sites are worried about you scraping, it's the literal server cost that comes with that. I disagree - usually it is data. Scraping prevention costs much more than setting up an API or dumb ip rate limit. It really depends on case to case basis but a lot of companies want to have their data public but not available to competition - this is where the paradoxical battle starts. To add to all that the gap between server infrastructure cost and development cost increases exponentially every year. Servers are as cheap as ever but developer wages keep increasing.
Now that I'm home... google "regex helper" and you'll find sites such as this one https://regex101.com/ Put in the input string in the bottom part, and the pattern in the top. In the bottom right is a cheat sheet / quick reference guide as well to guide you along. For the most part though, learning Regex is extremely valuable and no where near as complicated as it seems. Use this for the pattern: ([A-Z])([A-Z])(\d+)-(.*) Then put in some of your test inputs such as AB12-S9. You'll see in the center right "Match Information" with match groups 1-4. To work with the match groups in Python will require a little research anyways - try here for a decent tutorial on it: https://www.tutorialspoint.com/python/python_reg_expressions.htm 
Is the code available to have a look at? 
For anyone else: recently signed up though Python Bytes referal link, and got $100 credit : https://try.digitalocean.com/performance/?utm_medium=podcast&amp;utm_source=python&amp;utm_campaign=pythonbytes
http://pytoexe.com/ They'll use PyInstaller to bundle it up for you. I just found them today and they work well.
Thanks! 
《Python Crash Course》 and 《Automate the Boring Stuff with Python》，these books are very useful for beginners，hope you enjoy reading！
&gt; Just frustrating how much time I had to spend on something that really shouldn't even be an issue. That's just it, it has to be. There are 93 encodings in Python 2.7 and probably more in Python 3.7. The whole idea of Python 3 and unicode is simply: refuse the temptation to guess. You have to punt the problem to the user. So either we go back to Python 2 or we learn to include the encoding in the definition of the file format.
This is very cool. I think your sample videos show the best use case for what you've developed. I don't do political stuff too much so I probably wouldn't use it much myself, but I bet people who do would be interested in this. If you could capture a little bit of context along with each instance of your query term then append the clips together, I bet people would love to share their searches on social media. Imagine being able to automatically parse Trump's speeches into a montage of him saying China then being able to Tweeting it out. Those are my two cents, anyway.
I'm pretty much just starting to learn Python would this be worth it?
If you're going to be learning python, I think it would make more sense to learn the current version of python since python2 will no longer get updates and be obsolete in 2020. I don't know much as I've only been in the game for a few months but unless you are only using python as hobby, or working on legacy code, it makes no sense to me to learn py2
Also, no clue what anaconda is all about. 
Made a simple thing that encodes/decodes sentences with a Caesar cipher. Thinking of expanding on it and making a little code breaking thing
Ive got a coupon for that here too if its any use to someone. Pm me
We should be concerned of more of how Google _does_ it: https://twitter.com/danbarker/status/439125570115223552
Is there even a need to have pycharm edu? I mean community is pretty great for what you get.
[Beeware!](https://pybee.org) It's a set of tools for writing cross-platform apps that feel native, in Python. Easy to use and a fantastic community, though some features are still beta-quality. 
checkout pythonanywhere
Python is the name of the language, Anaconda is the name of one particular distribution of an implementation of Python language. Implementations of the language may vary in many things, for example, they may differ in the programming language they are written in, or by how they handle certain aspects of the language which are purposefully defined as implementation-dependent. Specifically, Anaconda is a distribution of Python which relies on the same code-base as CPython (the flagship distribution, the one most people refer to, when they mean "Python" as not just a language specification, but also the interpreter and the whole infrastructure of third-party libraries, conventions etc.). The difference between Anaconda and CPython is in that what compiler is used to compile the interpreter and third-party libraries. It is particularly important on MS Windows, where CPython uses MSVC, but Anaconda uses CygWin. The motivation for this choice is as follows: Python has interface for binary extensions which uses C ABI (C language application binary interface). This means that any language that can be complied to implement this ABI is, in principle, capable of producing such extension. To give you some examples: you can create such extensions using C, C++, Go, Rust, Fortran and many other languages. However, the ABI of MSVC and of CygWin aren't compatible, at the same time, MSVC can only compile C and C++ (and some would say that it doesn't really compile C because it doesn't implement the standard to the full extent). This means, that if you are on MS Windows, and you want to use a binary extension which only available in source form, and is written in, say, Fortran... you are out of luck if you are using CPython because you don't even have a compiler to compile it. Fortran is, however, particularly important for scientific computing because many high-performance number-crunching libraries (eg. LAPAC) are written in Fortran. This is why Anaconda also comes with many binary extensions already compiled / has an alternative scheme to load them. All in all, if you need Python for scientific computing, and for some reason you are limited to using MS Windows: use Anaconda. On GNU/Linux - CPython is probably a better option because it is more integrated into the OS. Mac - have no idea. To reflect on Python version: 2 vs 3. If you are into scientific computing, you have nothing to gain from upgrading to Python 3. However, some package maintainers eventually will stop supporting Python 2, so you will be forced to choose the version of interpreter for which the package is available.
What kind of model? You are trying to speed up your code by a factor of 24. This is almost impossible by just running multiple processes on better hardware. I would start with overthinking my code and libraries I use. Reducing loops and read/write actions and using caches could be beneficial. But I think to get more you could think about things like expressing your algorithm in matrix multiplications and then using things like numpy. However this depends on what you are doing. 
It says that on the FAQ. Iirc they only call it student license, but it applies to all academia. 
Even if it's not used for academic purposes? As in an employee of said institution using it to develop marketing / web materials for the institution in question?
Thank you for not posting an affiliate link to the bundle!
LoL, how is PoweShell available everywhere, if it isn't even universally available on the only platform it runs on? It's an example of the exact opposite!
I looked at your history, looks like it's a mix of bitter comments and creepy insults to girls that share their tits. Time to open the closet? You need help bro.
I really appreciate you putting in such am effort to help me out with it. Thank you very much. I think this is going yo be really helpful for me. Let me know if i canvontact you in future just incase i need some help!
No I meant to reply to your comment "django for things like a personal website". Seems way overkill 
I realize I said "professional". I was thinking professional portfolio for a personal website 
Michael Hermann sold his business to an internet marketer. That's what happened. He's trying all kinds of monetization on his 'list' (people he has the emailadress of). I was really upset about it.
What does 2vs3 have to do with scientific computing? The right advice to any body starting out is to start with 3
Your response while long seems full of misinformation to me, anaconda does not build with cygwin !
No. If you use any JetBrains IDE with a student license, it'll remind you every time you start it up that it's for educational purposes only.
OP, anaconda is an ok choice for starting out with Python on Windows, but it's one particular choice. Some would say it's better to download the windows installer from Python.org and learn to use pip and venv, which come with the standard library. 
Oh I get it. I'm just saying that if I never paid them, I'd get X. Because I give them money, I get nothing.
r/learnpython
Hahaha! I'm not sure if humblebundle has an affiliate link of sorts. They are done for the benefit of charities too :)
No. There is an abundance of excellent free resources and tools.
LMBO do you even js or CAPTCHA?
Because django admin kicks ass. You get CRUD fast for free. In other frameworks you have to rely on SQL editors.
Wagtail rocks. Current job has no need for a CMS, but Wagtail is one of the things I miss most about my previous gig. 
A week away from launch of a ridiculously complex energy incentives processing system in Django. Millions of rows of data, abstract data modeling, custom internal APIs, super\-detailed specs... all taking my Django experience in directions I never dreamed. Nervous and stressed.
They honestly have some solid updates.
I'm not sure what "overkill" means. Compared to Flask, Django is big. But Django is still small and fast, in the big picture. I want to save *time*, full stop. Django includes all the stuff I need to get to work with any kind of project. It saves me a ton of *time*. It's not as if Django's too big to still be lightweight and fast. I use Django even for the simplest projects, because I don't have *time* to fiddle around with assembling all the pieces in Flask by hand.
Flask is a hammer and a screwdriver. Django is a big toolbox with a lot of stuff. If you just need a hammer, no point in taking a heavy toolbox. But often you need more than a hammer, so you end up grabbing tools for various things from various places with various quality. Or you take the big toolbox in the first place and use the tools there with uniform quality and design. Not always the very best, but in most cases close to the best tools for that job. 
Yeah, you may be right, virtualenv is huge, but is there any solution for it? I'm just thinking only of create new virtual env just for Pycharm with packages I use most of time.
https://github.com/antonioam82/tres-en-raya/blob/master/3_en_raya.py
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [antonioam82/tres-en-raya/.../**3_en_raya.py** (master → e48858c)](https://github.com/antonioam82/tres-en-raya/blob/e48858cfce6ab887c54b14d21eb6f16316a3809d/3_en_raya.py) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dydcak7.)
Collecting live bus times for a given stop in the terminal 👍🏻
Whoops, that had to be MinGW, I make this mistake a lot.
You are confusing a bunch of related things. The procedure you describe is *signing* the message with an hash, and allows to detect tampering of the message but doesn't protect it from being read by a third party. Also you need more then a plain hash, such as including a public/private key scheme to prohibit a third party to generate valid message hashes.
How it is different from PyAutogui?
The fuck? Bad bad bad advice
AMAZING -I'm buying this for the digital ocean credit alone
Lightsail by Amazon.
YUUUGE
For those who have read it... How did you read it? Just cover to cover like a novel and ingest the information? Does the book have exercises to help ingest the information? I have got the book and was really interested in the first couple of pages talking about creating a deck of cards, but it also scared me too. I have been programming for a few years, hobby wise and like to think that I am probably advanced beginner. But never really got into creating classes and more scripts to solve certain issues. 
This seems like a good deal but nearly all of them are subscriptions, expensive ones at that
This will be pretty handy together with the rest of the marshmallow family like `webargs` and `django-rest-marshmallow`.
It's not restricted to edu only email addresses, you just need to prove that you are a student, they accepted my ISIC card as proof of being a student in Ireland.
Ok, but you didn't explain why you can't use functions.
&gt; rofl, ask your laywer if there is such a thing in this context https://www.reuters.com/article/us-microsoft-linkedin-ruling-idUSKCN1AU2BV Public data is public - you can't have your cake and eat it too. 
Python is absolutely the language to do this with. There are so many tools out there. I'd highly recommend `scikit-learn` and looking at `PyAlgoTrade` to get you started and eventually you might even be able to come up with your own algorithm.
Would seasoned Python devs recommend this bundle to a newbie? If not, what's the ideal start for someone like me? I think the illustrated guide to Python 3 (all of Tier 1 basically) is enticing, but if there's a better way to learn, I'm all ears.
r/learnpython
uhhu, except that you are not the one to decide if it is public. Also, data that you find online is not automatically 'public data'. https://en.wikipedia.org/wiki/Web_scraping#Legal_issues
Will this work in combination with the $50 credit in the humble bundle ?
Doesn't stack
I also trade for 15 years and i havent met ANY automated system that works in long run (except some scalping systems with ultra fast trading acess). You can make sysyem look ok on historical data but its just illusionGood luck anyway 
Doubt it. Seems both offers are for new customers only. Kinda disappointed that they only offered $50 through humblebundle, when they are offering more through other channels. That being said, DO is the first of this kind of service I've used, and I really like what they offer. Easy to use and set up.
Would you guys recommend this bundle to someone who has no programming experience but who would like to learn python?
Well i saw very sophisticated systems which worked for very long times profitably (ATR breakout systems for example) but they were limited to specific markets and from time to time got very bad Drawdown or even maximal DrawDown.I even created some realy good systems on my own but it was 2007-2009 era and i got fucked on gpb/usd slaughtery( i think you remember those times;) I was veery bad at programming thou and didnt know anything about python i guess tools are now much more better. Also pattern recognition is definitely "human" attribute, its very hard to teach machine to recognize patterns without many false signals. Topic is very interesing and if you manage to do something and want to open source it i would gladly take a look at it(not for profit ofc but because of curiosity)
Hey, kaczuszencja, just a quick heads-up: **realy** is actually spelled **really**. You can remember it by **two ls**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
Hey, Bolitho, just a quick heads-up: **completly** is actually spelled **completely**. You can remember it by **ends with -ely**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
I havent written a single line of code in my life so you would need to wait quite some time. Also, it will surely not be open source as I have worked for a decade to learn the craft to give it out for free. How long so you estimate it will take for me to get proficient enough in Python to write such a complex program ? 
Nothing in the article proves your point lol. I just posted you the most recent and biggest case that got resolved in scraping favor. Can't believe some people are actually in favor for allowing corporate bodies to abuse public data like this. You people are groomed as fuck.
A markov model predicting attrition. We re moving a lot of the data prep upstream which should take get us to about a 3 min runtime. The issue is we have a dataset, 3 different populations within it, and then looking thru and figuring out if people left the company or not whether or not they are present in the start date and absent in the end date. We also calculate the time they spent in a certain role, so looping thru and keeping track of each individual person I think is part of the problem. 
If you haven't gotten to classes yet you might want to wait with this book. It kind of assumes that you have experience with all the basic features of Python. 
The demo works great! Instead of having 'next' and 'previous' button, I think something more intuitive for users would be a list of time stamps where the 'word' is used along with say, 3 words before and after that word'. Another helpful addition might be a word cloud of each video, would really help people (especially journalists) get a gist of the video at a glance. Just my 2 cents.
I got selected in GSoC'18 and I will be writing a test suite (read unittests) for the project and will be porting the code from Py2 to Py2/3
Got DigitalOcean and Pycharm 6 Months to give to someone who truly wants to use it. PM
To elaborate, this contains a wide range of "recipes" of how to deal with programming problems in a clean, efficient and Pythonic way. You can find great solutions, tips and tricks for key tasks in there. That's a great way of learning proper Python workflows and techniques. Otherwise, in terms of bare beginner Python knowledge, you can get that from a lot of tutorial websites, www.tutorialspoint.com/python comes to mind.
Maybe you should leave the numpy for now. I know people are criticising you for using np when random will do, but you're also using it completely wrong. To select a random choice from a list, you follow a bizarre and broken series of permutations and index shuffling, instead of random.choice(). Then, when you need a random integer you write your own list of ints out by hand and use random.choice instead of random.randint. Slow down and think what you're actually trying to do and then google it before plowing in. 
typo bot isn't helpful
Maybe you should consider that I'm not a corporate groomed fucker. Anything you post on the INTERNET is not automatically Public Data. Only stuff that bodies like the US government post are public data, almost all other data on the web is non public and copyrighted if it is in any way a creative work. This Reddit article does not mention scraping actual public data all, it is clearly meant to circumvent security measures which website owners (call them corporate bodies all you want, generalizing to proof your points is a true sign of strength) The whole point of the linkedin suit is that linkedin cannot make a decision to close its data for some after its users gave it that exact data to be public and open. The key sentence in your linked article is: "over information its users have deemed to be public." The they key sentence in the wikipedia article is: "copyright" If you are dealing with a system that specifically tells you you're not allowed to use it in some way, and if that system is secured in any way against that use, You might even be in violation of some hacking laws out there as you are breaking security measures.
Hey, I'm thinking about getting the 20$ tier just for egghead. What are your experiences with it? Did you try any other online teaching services? How do you think egghead compares?
The interesting thing here is that you can call a classmethod from subclasses and possibly do a bit of inheritance stuff, including overriding the method or access other class-level methods and attributes. It is a good place for factory methods and such. 
&gt; Maybe you should consider that I'm not a corporate groomed fucker. With the things you are saying you are making it really hard to lol. Go back under your corporate bridge you troll.
I think some of them use different words too 
AWS lambda (via zappa)
1) Having a big database I'm using the Bulk email validator from www.zerobounce.net I use this service because they have an accuracy rate of 98%+ and good prices! Also, their customers' support is always there to help me when I need!
Not just that - the exact reason it can be good for factory methods/alternate constructors is that you *don't* necessarily have to override it: the `cls` argument will always be the exact class it's being called from, and the first thing such a method will usually do is something like: obj = cls() So this will instantiate and the `__init__` of the *derived* class,so you get the inheritance goodness without having to change the factory method at all. 
PyCharm is amazing. I was turned off by IDEs after using Eclipse for a while. I came back to PyCharm IDE, for the sake of a bigger project, and it's paid off tenfold. It's like Eclipse, but with all the right decisions, and improved performance. It's much better than Eclipse, and made me love IDEs again. Now I have a license to the full IntelliJ suite of editors. I'm a believer.
If you have absolutely no knowledge of python and want to learn from the start and have examples showing web applications in one book, the best book would probably be: (which uses Flask) Head First Python: A Brain-Friendly Guide https://amzn.to/2Id8hia To do web development with Python you need a web "framework" or library. The easiest one to learn for beginners may be "Flask" Flask Web Development: Developing Web Applications with Python https://amzn.to/2ri6VsW Welcome | Flask (A Python Microframework) http://flask.pocoo.org/ Tutorial — Flask 1.0.2 documentation http://flask.pocoo.org/docs/1.0/tutorial/ If you want to read data from web sites you would need to know something about "scraping". A book which covers this but is probably more at the intermediate level is: Web Scraping with Python: Collecting More Data from the Modern Web https://amzn.to/2rhuDph
Hey, can you put in a good word about changing that artificial limitation on syntax highlighting? I totally understand upselling the inspector per language, but to not provide syntax highlighting is a major pain in the ass. For example, if I want to read some PHP or Ruby in PyCharm, it's a bad time. Now I have to juggle different flavors of the IntelliJ editor, or reconfigure and normalize things in IntelliJ ultimate. This balancing act becomes even more frustrating working inside of a VM with limited resources.
I highly recommend the book titled "Read the Sidebar".
I can NOT decide whether to pull the trigger on this or not. No idea what half those services are and I'm already a pycharm owner.
Yes it is.. it's been a staple since Windows 7
Another way to look at it is that Flask is a modular toolkit and Django is a monolithic beast that seeks to swallow up your entire application. Both of our viewpoints contain truth but are colored by bias. 
I would rater say: Flask is a workbench. You have to start gathering tools before building what you need. But you have full flexibility. Django is a big heavy toolbox. you can build almost everything with what is included. 
- Crypto trading bot on linode (after disappointment with google cloud platform bang for buck), though the management is annoying - home automation on home server - I have a small digital ocean that's scraping stuff, love their frontend and simplicity - for orchestration of heavier machines I quite liked google cloud platforms templates 
The latest installment in the series of articles showcasing why an article that enumerates things in the header is next to useless.
I do not agree. I worked with team of 20 developers on single project, everyone used pycharm and it helped a lot. Can't tell how many LOC but project was perty big.
`flask_app.app_context()` is a context manager, so instead of this: # Establish an application context before running the tests. ctx = flask_app.app_context() ctx.push() yield testing_client # this is where the testing happens! ctx.pop() you could write this: # Establish an application context before running the tests. with flask_app.app_context(): yield testing_client # this is where the testing happens! which is much more compact and readable.
Thanks for the tip. I actually found the command netsh. If you decide to go this route, just know that some of the commands run in 32 bit mode instead of 64 bit when called from a script. 
Do the books come to you physically or at they ebooks?
Follow the tutorial on the Flask site, it goes through creating a blog site. I had the same questions recently with Django, and CherryPy, but I really like the simplicity of Flask.
&gt; the beginning of your annual subscription This is what I don’t like about it. If I could keep all the features I’ve been using when it is spires I think it would be the perfect sub model. However, as it is if I sub today, and a great feature is released tomorrow, I lose that feature I’ve been using for nearly a year. If I pay for a year, I should get to keep everything I’ve used over that year. Sure something cool comes out the day after my sub expires then I’d have to pay again, and new cool features (without bloat) should be what keeps me subbed. 
But, can it understand [Pikey](https://www.youtube.com/watch?v=tGDO-9hfaiI)?
You can actually pass SQL CTEs in table. pd.read_sql(select(table.c.column_name).where(table.column_name2 == variable_name))
Only if it works
PowerShell is cross platform these days(Windows, Linux, Mac), for what it's worth.
I am completely fresh to programming. Thanks for the recommendations, I'll have a look. I had gotten a few chapters into Automate The Boring Stuff, but you'd recommend Python for Kids first?
This script opens a file for manipulation and analysis, as the analysis continues the report is written. There is a lot of boilerplate that could easily be done by a macro. Functions do not work because when you use a function they have no access to the file that is being written to. Meaning when you do in the body of the script: f = open(report_name,'w+') A function can not write to the report, and keep the file open. A macro could easily do it, since it would just add code in-place and keep the execution environment as is. There might be a way to do this with a function, but I am not aware of a method to accomplish it. Advice welcome! As I said for now, I just kept all inside the script, and it works fine.
This is amazing!
i don’t know maybe try using FLASH not a flask lol
Good point, I guess? More explicitly, what are some use-cases where there is a legitimate use of the data but the website in question would still want to block you anyway? 
Thanks for submitting the project! It's always a good thing to have more choices in OSS. I do have some critiques for you though. Namely with your docs: * You should add some short usage examples in your github README and in the introduction of your readthedocs page. * It might be a good idea to split your docs into multiple pages, just so it's easier to navigate. * You mention that this is written in Cython. Why? What advantages does this give you? Does it make it encode/decode faster? Do you have benchmarks? * Your docs mention that it can parse virtually any valid JSON/JSON5. Do you have tests that demonstrate this? How can we know that your code can be trusted? Otherwise, this looks like a pretty good project. Keep up the good work!
I have a [Zotac ZBOX Nano](https://www.zotac.com/us/product/mini_pcs/id65-plus) sitting on a shelf with a 500G SSD networked to a Synology DS212 NAS with 3TB of storage, the zotac runs a bunch of Docker containers with various home services (plex, IRC bouncer, etc) and my various "automate the boring stuff" runs as cronjobs on the box itself.
If you have grasped a bit more than the basic I can absolutey recommend the book "Fluent Python" It helped me push my knowledge and abilities to a whole new level :\)
i'm currelty learning Python and jupyter notebook has been a great tool through the process. Glad its getting some recognition. 
Someone already took Egghead and Postman. Sorry 😟
Was no brainer to get 6-month egghead sub for 20 bucks. That alone is over 200.
I'm the author of said book. It is aimed at technical people and does not assume programming experience. Best of luck learning Python!
Not only that. For some reason everything goes through a url redirect, and no matter how crappy the listicle is, is is massive upvoted pretty fast. I suspect there's some sort of link farming going on. Normal people will not use the same url obfuscation independent of each other.
Read my edits, found four seemingly fake accounts in minutes, all either * images from companies that dont make sense heavily cropped, * crops of stock images but physically a person, which usually real people don't do, they take an actual picture of themself, not steal from a stock. Or if they take a stock it's a character stock, not a human stock * literally a picture stolen from a different person. I call spam/farming.
I agree.How far back did you check?
I just went on the main page and scrolled down. I just checked the first 4 or five unique authors. Only one of them seemed legitimate (had actual shit on their github), and they work for boostio/boostnote, which seems eerily similar (maybe even the same) as boostlogio itself.
Yes, the talk python courses are a great jumping off point, as well as the ebooks included!
IPython for life!
Hey, thanks! 
I'm willing to bend rules a little when I think I have some particularly good reason. Often sites have dumb anti-robot restrictions like "check the user agent" without any real thought or reason, just as a way to stop dumb bots from breaking their site with zillions of requests. So if I wrote a smart bot that, for instance, will only send 100 requests an hour; I don't feel as bad using it. Fully admit this is all fuzzy.
Awesome, was on the fence as grad students get pycharm for free with edu. Thanks! 
Just found another stolen pic. Username on site is a real name that starts with R, the guy I found's name starts with a B. Coincidentally, the fake has an empty github, the real one has a full github (and an updated pic now for a joke). There are people literally faking their accounts.
Very interesting, I didn't know about Akamai's bot manager. Well, I've playing a bit with Tor-based crawler, and the main problem I face is the different JS "challenges". So, I think headless browsers is the one of the possible solutions here.
Yes please
I recently spoke with Brian the co-founder and he(and the team) are so unbelievably deserving of this. I’ve never met a person more passionate about education and open source as him. If you haven’t yet I would definitely start using JupyterLabs. 
Well, I can confirm that CF can't deal with DDoS in automatic manner. The only option that helps me , was the "I'm under attack", thus I need to manually turn on and off this mode. On the other hand, they can help someone to "hide" their front-end infrastructure behind CF proxies.
Yep, thanks. I think headless mode has a lot of potential. Just need time some to play with that
I have a question, how to debug the program with jupyter 
If you mean how to run a debugger like pdb, have a look at the [%debug magic](http://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-debug) and the `-d` option of the [%run magic](http://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-run). If you're asking how to find and fix bugs in general... that's a big topic!
If you watch the dvd with pikey subtitles, there is a point where brad pitt is talking so fast that all the sub titles say is "???"
I have no good explanation for this. In fact it's mostly because our code base organized this way that syntax highlighting of specific languages live in separate projects. We're considering to reorganize this to make syntax highlighting for other languages available by default. At the moment the workaround is textmate bundles: [https://www.jetbrains.com/help/pycharm/textmate\-bundles.html](https://www.jetbrains.com/help/pycharm/textmate-bundles.html)
Thank you for your comment and the kind words! You are right. I will write examples later or tomorrow. I split up the encoder and decoder sections: https://pyjson5.readthedocs.io/en/master/index.html. Do you think it's easier to read this way? Was not sure if I should move all exceptions into their own page. I removed the mention of Cython from the docs, it's should not matter. I should rewrite the README, too. The library is at least not far worse than Python's `json`, at least for [simple data](https://json.org/example.html): %timeit json.loads(s) 6.76 µs ± 68 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) %timeit pyjson5.decode(s) 7.98 µs ± 62 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) %timeit json.dumps(o) 7.69 µs ± 19 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) %timeit pyjson5.dumps(o) 7.94 µs ± 57.6 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) The little overhead is because parsing is a little more complex, because you need expect a far wider range of characters in each step. Encoding is slower because I wanted to make the output XML-save in the same step, because embedding the data in HTML pages is the first and foremost reason why did even wrote a serializer, too. I did test against the ["Parsing JSON is a Minefield" test suite]( https://github.com/nst/JSONTestSuite) to make sure that at least all valid JSON gets parsed correctly, but it seems like I lost the code. I'll write it again. I did not find a JSON5 test suite I could test my implementation against. Well, I did write the code as part of my job at the Free University Berlin, a state university where I'm full time programmer for three years. I cannot tell if that sounds trust worthy or not.
If you have at least some programming experience, than PyCharm Edu isn't for you. It's for complete beginners. PyCharm Professional is another story \- it has a lot in addition to what Community Edition offers: support for web frameworks, front\-end frameworks, javascript and all the WebStorm features, Database tool \(all from DataGrip\), remote developement capabilities: run/debug over ssh, docker support, and much more.
I switched to Python from Mathematica a year ago and Jupiter made me feel right at home. That award is well-deserved. :)
See our announce on blog.jupyter.org, we may be the recipients but the whole community of contributors and users are the one deserving this award. We only act as guides and foster a community development !
This is an awesome thing you are doing for the community. Throwing my name into the hat! :)
Page unavailable 
`venv` is for library isolation, not Python binary isolation. You must mean `pyenv`, whereas `conda` is as a whole other ecosystem.
Right, if you are forced to use an insane operating system…
That doesn't mean that they didn't break `pip` last I checked. Same with Amazon Linux.
Thanks. The domain is banned by reddit, which is why they use redirects. It seems the posters from these accounts are a year or more old, but only have activity in recent momth or so on karma farm subs like /r/aww, but that might be my paranoia.
I second this, whats recommended way of getting into deep learning/machine learning? 
Np. Honestly wonder if it's just this sub or more that are affected (I've only seen these posts here, but the site itself seems very Python and Javascript heavy).
How much would a 6 month renewal cost?
strip and rstrip are for the ends of strings. If you need to do it in the middle/whole string, do something like: fh.write(comment.body.replace("\n"," ") ... 
One hour has passed and random.org has choosen: /u/Total_DominAzn I will send you all the details
Thanks OP! :)
Have fun
You could make "what if's" for any number of situations. The fact is, they take away feature's you've been using. That is why I will not get the subscription.
I probably should have been a bit more clear on some of those points. Mentioning cython isn't a bad thing, but usually code is written in cython for performance reasons. You shouldn't remove mentions to it if having implemented it in cython is a selling point like it is with pandas. Also, the questions I asked about benchmarks and tests are ones I think people would want to see answered in your docs or on the github page. Showing how it is pretty much as fast as the built in parser but can handle a broader spec is good and will help you to convince others to use your library. The same goes for tests. If you show how your library compares to other implementations in terms of test coverage, especially with those edge cases, then your project can stand on its own. Those tests are what make your code trustworthy. Professional credentials are nice too, but anyone can write good code or crap code. Code with a passing, comprehensive test suite can be trusted regardless of who wrote it. 
So, just looked at the domain that is being redirected from (programming-lov .work) and it's a wordpress, that redirects to different articles by different people on boostlog .io. The kicker? 9/10 of it is shitty articles and empty githubs. 8/10s is Python and Javascript. There are *real* (or seemingly real) people, but it's overshadowed by this.
Thanks for doing this giveaway :) 
Specifically, if I wanted to make a science-based dragon mmorpg... how would I debug that?
When you go to the link I posted and click"For students and teachers" it will take you to a page to sign up for a license for ALL JetBrains products. This includes the Professional version of Pycharm which is why I didn't specifically mention edu version. 
Dang, I did not see the $50 DO Credit was for new users only. I was focused on beating the average just for that.
duh. Thanks!
My understanding is that science based dragon mmorpg can only be built in rust
Wrong, it is often a pain for all three major operating systems.
Does the instructor in that course have any credentials? 
you might just want to delete everything and reinstall from scratch
A PHP-&gt;Python converter.
A bot that takes the weekly billboard top-100 and creates a spotify playlist then tweets it. Looking to add more features to it
Okay, so what happens when you need to combine different venvs together, each with an incompatible set of requirements
[Blog post link](https://blog.jupyter.org/jupyter-receives-the-acm-software-system-award-d433b0dfe3a2)
thanks!
I also purchased the Bundle despite having all the talkpython content already, so I tossed my codes to shoobydaboobop here :)
Prime numbers are those that can only be divided by 1 or themselves. Let’s go through the loop once. We get 2 for n Then we get 2 for x If we divide 2 by 2, the left over is in fact 0 Then why does not it print this line But goes to break Please help! It’s driving me crazy
But why, if 2/2 has 0 left over? Please check my other comment
The inner loop never starts for `n==2` because `range(2, 2)` is empty (the second argument is the *exclusive* end of the range).
I used both for equivalent applications (e-commerce websites). I prefered the Django experience as it was easier and faster (a lot). Less fiddling about what library to use or how to integrate it, more actual application done. Basically all the choices are done, so you just need to focus on your app. Both frameworks are very true to their taglines: Fask, web development one drop at a time. Django, the web framework for perfectionists with deadlines.
Hey, flagadalulz, just a quick heads-up: **prefered** is actually spelled **preferred**. You can remember it by **two rs**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
But I want to build it in Jupyter.
Instead, please read the sidebar.
When I say community is great for what you get, I mean that you don't need it if your an individual as much. If you get into working with Databases then yes you would probably need it then.
This is not a sub for homework questions. Please refer to r/learnpython. This is listed in the sidebar.
ok
What is pyup? 
No worries. =) Just passing on a cool deal.
So, is this worth it just for the books \(disregarding all the software\)?
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [CrakeNotSnowman/TwitterEventBot/.../**crowdSourceEvents.py** (master → f7d2e55)](https://github.com/CrakeNotSnowman/TwitterEventBot/blob/f7d2e555eb35ae99e0198441dbcc14f75ab6d02c/crowdSourceEvents.py) * [CrakeNotSnowman/TwitterEventBot/.../**updateFiles.py** (master → f7d2e55)](https://github.com/CrakeNotSnowman/TwitterEventBot/blob/f7d2e555eb35ae99e0198441dbcc14f75ab6d02c/updateFiles.py) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dyefex1.)
At 20 bucks i think its the best, i have watched some free classes and i liked, it have very short and focused courses. I also like frontEndMasters and pluralsight, but those are way more expensive alternatives. 20 bucks barelly buys a month on those.
How about you start by actually posing a question? :)
*Beep boop* I am a bot that sniffs out spammers, and this smells like spam. At least 100.0% out of the 89 submissions from /u/Carolin3 appear to be for Udemy affiliate links. Don't let spam take over Reddit! Throw it out! *Bee bop*
Python was meant for distribution, but not for hiding the code...
/r/kaggle
Eww `raw_input()`.
Jupyter is literally my no. 1 tool for documentation right now. Couldn’t live without it anymore
Yep. Tons of overhead. You have Jekyll/WP
Do you still have PyUp?
Digital ocean is great. Very simple and easy to work with. Very little to learn to get things working fast as opposed to aws or gcp where you need a little knowledge in how it all fits together.
I'm gonna see if I can hack this to use with AWS secrets manager
Good on you for the giveaway. Just FYI, not that cool to ask for upvotes in exchange of a gift, it's against reddiquette. I know this is a pretty irrelevant thread, but just FYI. I' sure people are going to upvote for the giveaway regardless.
I used to be a big proponent of notepad++, it was very light and did everything I needed it to for python scripting. Now that i've explored some of the functionality of PyCharm, I can't go back to np. Some features I like in PC are integration with svn/git, built in debugger, attribute/method suggestions based on class instance, double shift search, etcetc...its nice to have everything in one environment.
[Tautulli](https://github.com/tautulli/tautulli)
No need to worry as long as you produce good code who cares.
Yes, I do. I'll get to it tonight.
Most definitely you are missing out. An IDE does way more than edit text. You can run code automatically run tests as your code changes and report test failure. It can automate complex refactors and suggest changes, spot errors. Version control is integrated and it will also manage your virtual environment. You have access to a profiler and tools to reformat your code. And that's just for python... If you do JVM languages it gets even better. 
Same here. I use [Zappa](https://github.com/Miserlou/Zappa) to deploy to AWS Lambda :)
That's not true. Whatever version is newest during the 12 month period is what your perpetual licence will cover. 
I'm not a big fan of notebooks, don't get me wrong, they are really good to show your code and examples in a really cool visual way, but some people I know use them to actually code in them (as an IDE), that's really cringy to me, I have seen weird bug because of that, like for example some code was working properly until you stop the kernel and restart it, then it doesn't work anymore (because some variables on some cell got deleted but they are still in memory until you restart), etc... People should learn when to use notebooks and when not to use them
I'm not a fan of IDEs generally. I much prefer having multiple tools, each that do their own thing really well. So I have sublime for editing text, iterm2 for my terminal emulator, tower for my git GUI, etc. etc. It feels to me that having a tool focused on a single purpose makes that tool better at that purpose. Jack of all trades, master of none. It also means I can switch out an individual tool if it no longer meets my needs. For instance I switched from [Terminal.app](https://Terminal.app) to iTerm2 because iTerm offered more features that I needed. None of my other tools had to change. Finally, I just plain find IDEs overly complex. They have too many buttons and it feels like I'd need a week just to learn how to use the software. I'm always on the look out for better tools though. Please try to change my mind if you think I'm wrong :\)
Thanks for the tip, I was unaware of the TextMate Bundle support. I tried following this [2014 blog post](https://blog.jetbrains.com/pycharm/2014/12/feature-spotlight-textmate-bundles-in-pycharm/) but there is no longer the option to associate the files as describe: Settings | Editor | File Types and choose the “Files supported via TextMate bundles” https://i.imgur.com/TooPOWr.png
Hah! Would have been nice to see this two weeks ago when I had to extract and amend XML from a large number of PDF files.
I think you're either misunderstanding the question or misunderstanding linked lists. There can indeed only be one intersecting node; any 2 linked lists that intersect will be shaped like a fork if you draw them out. In the first example list one can't just stop at `4` because node `4` is linked to node `5`. Your second example is also impossible. in the 2nd example *a* could be `1-&gt;2-&gt;3-&gt;4`, but *b* could not be what you wrote. Wherever there is an intersection, the list will be identical after that intersection so *b* would have to be `5-&gt;6-&gt;1-&gt;2-&gt;3-&gt;4` since the node where they intersect (in this case node `1`) only ever points to a single next node (in this case `1` points to node `2`). This is all because the nodes are references not values. It doesn't matter what the nodes store, it can be anything, but the nodes themselves only link to one other node. 
[Python-plexapi](https://github.com/pkkid/python-plexapi) or Tautulli.
I use a lot of Notebooks and have helped teach workshops in the past with them. The 'this is not an IDE' point is something I usually have to make clear. 
Agreed. Most people who dislike ides in general fall in to 2 camps ... * They don't do practically anything larger than a small project at professional level that requires real tooling (think data science jupter fans or system admins etc ..) " They are scared of the perceived complexity ... Ignoring to e dact that they learned 10 separate tools instead of one larger one and still don't have all the features. The excuses are the same. For example, 1 tool 1 job is better. I agree and so do most ides bc generally speaking they are just providing a ui layer on top of client tools you actually can switch in and out. There are some tools I use externally for specific things ... I'll probably never not use vi a few times a week but I'm sorry, vi doesn't connect to a browser and let me debug JavaScript while live editing the code. 
I’m using IHaskell to learn Haskell. I haven’t used the Python part of it as much. IHaskell is rock solid. It’s a great tool if you can’t have a playground-like environment.
You are correct to be bothered by this question. Traditionally singly linked lists is a structure that has two members: `item` a reference to an item of some type, and `next` a pointer to the next node. As such one way two lists could intersect is to share a node, but another way is to have two distinct nodes, pointing to different `next`s, but sharing a reference to `item`. The former is easily detected by comparing the terminal node. The latter requires something more complex, and no answer is clearly best. Good approaches might be sorting or hashing the pointer values looking for duplicates. The "intended interpretation" is probably the former, but like all interviews the real purpose should be to see how you think. If you can identify and explain the ambiguity, then I would say you have a better answer than the intended answer. 
Thank you!
Is Sublime really better than Notepad\+\+, and if so why? I've only used Notepad\+\+ for years, but everyone I know who uses Sublime says how wonderful it is.
notepad \+\+ is good as beginning/learning tool and most still don't deviate from it. but an IDE are only as important as the user need to perform more task. there are plenty flavors out there that you can taste them all. [what IDE use for Python](https://stackoverflow.com/questions/81584/what-ide-to-use-for-python#81609)
Try using PyCharm. I find the bloody thing practically reads my mind but it's very much and each to their own thing.
You already know how yo writte a crud system and the basic of data structures, poo programming . 
I'm not so sure it's ambiguous here, the question clearly states "the exact same **node** (by reference)". It asks nothing about the value or the item a node contains.
Hey this is Dan. I understand where you're coming from—the email newsletter I write is certainly not for everyone. I'm completely fine with that. If you don't enjoy it, there's an unsubscribe link in every email. No hard feelings. Now, your comment glosses over some things that I want to point out because they're dear to my heart— My team and I have been releasing around 8 brand new and free Python tutorials on [realpython.com](http://realpython.com/) every single month since I took over stewardship of the site. That's two 2,000\-5,000 word articles and in\-depth guides every single week. We peer review every single article and have a professional editor on staff. I release these articles completely free of charge, no obligations, freely accessible for anyone who's interested. Even for folks who don't like the newsletter. The free content we put out is literally helping hundreds of thousands of Python developers improve their skills for free every single month. We aim for book\-level quality in our free stuff. And that's just for [realpython.com](http://realpython.com/) alone. Everyone on my team gets paid for their work, from our amazing tutorial authors, our technical editor, the PythonistaCafe community managers, [nerdlettering.com](http://nerdlettering.com/) contributors, and so on. Not to mentions that this is also my personal full time gig. I love what I do and it's meaningful work to me. I pretty much wake up every morning looking for some way I can contribute to the Python community in some positive way. Most of the profits go back into the site and my other Python\-related projects, and I also donate to the PSF and other Python\-related charities or conferences. If you want to call me an "email marketer" you're not wrong, because we do sell our premium courses and books that cost money primarily over email ;\-\) But to make it sound like I'm running some sort of scam here is a\) misleading and b\) unfair. Happy to discuss this at PyCon in Cleveland next week over a coffee or beer. Happy Pythoning! — Dan
Yes, and that is weird. If a job wants me to blindly implement specs like that... I'm not interested.
Tell that to Microsoft, IBM, and Google. 
Yes, a lambda in the sort would do the trick. I'm not really sure what your list of lists is (an array is something different) as it's invalid python code, but you can only sort things of the same type. You may need to reformat your data. I suggest /r/learnpython.
I'm like you. I've messed with IDEs but I'm not a fan. But I wanted to take the next step up from NPP. I suggest going with either Sublime Text (what I use) or Visual Studio Code. They are both basic text editors at their core but they are a lot more extensible. So I get to start with my nice comfortable simple text editor and as I progress I can add just the functionality I need without adding all the bloat that I don't want. I started using it and spent some time learning the hotkeys/commands. And things were good. Then I wanted to change the colors, so I found a whole bunch of themes and settled on what I liked. And things were good. Then I wanted linting, and I found a Python linter. And things were good. Then I wanted to manage my virtualenvs from inside ST, so I installed a venv manager. And things were good. Then I started looking at other peoples files that didn't conform to PEP8, and it was frustrating, so I installed PyYapf which formatted entire document. And things were good. Every time there is some small thing I want, I get to install JUST that functionality and learn everything about that one aspect. It's really been great. And if I would have started with all this stuff already installed I would have probably gotten annoyed. But since I only install what I need, and that necessity forces me to actually understand WHY it's installed and exactly why I would want it and how it would benefit me, it's a lot easier to accept the bloat. It's still lightening fast though.
I'm just getting started with python. I went to DO and looked at their stuff, and I don't really get what exactly they do. Can some ELI5? Thanks! 
&gt; Besides, Python v3 made absolutely nothing useful for scientific programming. Except it's 20% faster on my 120k lines of code open source project, despite me developing it in Python 2.7 and treating Python 3 like a second class citizen. I literally did nothing other than make it compatible.
asyncio with aiohttp
Why, thank you. I will give this a whirl tomorrow. Much appreciated.
Notepad++ is fine for small one-time scripts. But once you get involving in larger shared codebases, it is much easier to manage in some IDE where you can do things like finding all usages of a given method, or jump to a variable or method declaration, and of course the biggest thing, everything involved with the debugger. You never go back to the old way of tons of line print out of variables once you spend a little time using a debugger where you can inspect all the values in real time without needing to add in tons of print statements. At the very least, I would recommend a minimialistic IDE that has a "plugin" to be able to execute the python code and run unit tests on demand without leaving the environment (i.e. going to terminal and typing the command to execute each type). There also is a very minimalistic debugger pudb https://pypi.org/project/pudb/ if you want a step up from essentially no debugger where you are at now.
Try 'python -m pip install matplotlib'
it should be members = [(name1, 10), (name2, 12), name3, 13)], default sorting cannot deal with it otherwise members.sort(key=lambda member: member[1]) where key returns thing you will sort by
Would anyone be interested in trading? I don't want the digital ocean or gitkraken but would love to try out egghead.io I haven't bought the bundle yet but just checking my options
My guess? You haven't worked on multi-million line code bases that span many decades yet. IMHO: Lightweight text editors are fantastic most of the time, but when you get into code worked on by dozens of developers with tens of different styles and multiple technologies you really need the deep features of IDE's. Big IDE's are still nice for small projects, but they are sluggish in comparison to code aware text editors.
You'll need threading for this because button functions are processed in the same thread as the GUI.
They're a hosting company. You can very quickly spin up a server. I used literally 5 minutes to get an Ubuntu server with apache running to host some demos for my boss. Another 30 min including the wait to update dns records so that my domain pointed to my new server. 
If you’re using something like sonarr to automate torrenting it can send email or push a prowl notification when downloads are completed. 
What exactly do you mean by Student Manager? When I was a lecturer, I wanted to write a flask app to gather the results of the homeworks (accessed by me and my TAs) and enable the students to see (only) their own results. Never got to it....
Read the sidebar. Post in the subreddit that the sidebar tells you to post in. Read THAT sidebar.
It's a really small flat program where you can add different students with first name, last name, and student id. There are also edit and delete buttons. My question would be like what else could I add?
Short answer: no Long answer: nope Epic answer: mmmhhh nahhhh, you're good.
Good luck!
When you say "extracting pages" what do you mean? Just the page number or do you need export that page as a single pdf?
It's not that, im new to Python and programming in genera (done light vba scripting in Excel)l. Our work actually officially supports it through the corporate app store but i have a very unsupportive manager who will expect too much of me before I'm ready to make any commitments. It's a very frustrating situation i wish i didn't have to deal with. If I still have the drive and see potential in a few weeks ill just request it. I know this sounds like a really flimsy excuse but i actually consulted when a few superiors i can confide in and this ended up being the route they recommended "off the record."
I've had a positive experience with Visual Studio + vsvim for django related development. vsvim is purely for the editing preference.
I'm trying to install Django and figure out what the hell Django even does. I just started learning Python last night. I haven't slept.
I have a written a tutorial explaining how to do exactly that, check it out: https://medium.com/@shamir.stav_83310/making-your-c-library-callable-from-python-by-wrapping-it-with-cython-b09db35012a3 Feel free to ask more questions 
I'm building a system for tracking the status of our long-running cronjobs, django admin processes, etc. It's on GitHub, but all of the good stuff is in a feature branch right now.
Would it be significantly faster than queue-threading the scrape of a 10-20 thousand small json files? Not super stoked with the performance I'm seeing, but I also have slow internet so not really sure where the bottleneck is.
I'll check it out, thanks.
Export that page to a single PDF or combine PDF pages with the same name.
I was thinking about doing something similar for the underground hip-hop scene in the midwest.
Gimme that that humble bundle (please).
GUI changes that you program in code only take effect when your code returns to the tkinter idle loop (also called the main loop). So your first change was noted by the tkinter code but didn't take effect, you sleeped and then again changed the image which was noted by tkinter. **Then** your code finished and the thinter idle code ran and updated your widget to the second image. You need to: * change the image * start something that will change the image back after 2 seconds * finish your code (ie, enter the idle loop) The *something* could be a thread but be aware that threads that aren't the "main" thread can't directly change anything in the tkinter GUI. There are ways around this, but there may be something simpler in your case. Try looking at the [after() call](http://effbot.org/tkinterbook/widget.htm). You would have a method that sets the image back to "normal". The code that runs when you click the button would change the image and then call `after()` with a delay of 2 seconds and a target of the "set to normal" method.
Lolwut? If you do any scientific computing, the speed of Python interpreter is irrelevant to you, not to mention that your evidence is all but anecdotal (people also report drops in performance, but that's a different story). Scientific libraries for Python aren't written in Python, they are typically C / C++ / Fortran libraries with some Python glue code. Both CPython v2 and CPython v3 interpreters are hopelessly slow and without major redesign will never become competitive speed-wise.
Would love this.
📅 03/05/2018 ⏰ 11:37 [(UTC)](https://www.timeanddate.com/worldclock/converter.html?iso=20180503T113745&amp;p1=1440) &gt;Cybrosys Technologies \#cybrosysinsights [@Odoo](https://twitter.com/Odoo) &gt;— Cybrosys ([@Cybrosys](https://twitter.com/Cybrosys)) 🔁️ 0 💟 1 📷 [image](https://i.imgur.com/QzrDVfv.jpg) &amp;nbsp; ^(I'm a bot and this action was done automatically)
Most likely, yes. Asyncio is a real speed demon for io-bound tasks. However, it should be less than 20 lines of code with threading and with asyncio to set up a little test for yourself to benchmark the two methods. 
I will be very useful
Anaconda is a scientific package, with the most important package being numpy. On Windows and Anaconda, numpy comes with the Intel MKL, which speed up numpy by 5x. I strongly recommend you use Anaconda as you can't get those without paying Intel otherwise.
Although this doesn't address the speed/performance issue, Kenneth Reitz also has a new **requests** module for scraping which you might want to check out: [requests\-hmtl](https://github.com/kennethreitz/requests-html) At the very least it may help you save a bit of effort.
I'm still supporting a Python 2.4 package that I last worked on today. ~2 years ago I did a training for it and added a bunch new features for the code. I was running into bugs regarding segfaults in numpy trying to do a least squares. Scipy screwed up too. So, I upgraded my numpy and scipy to the latest version I could and the bugs went away. They fix things. Scipy gets their KDTree and then their cKDTree, which I swear I've can apply to almost every problem. &gt; I’ve proven that it solves my equations correctly If your software doesn't work on multiple versions of packages, how do you know? You solved a problem, but what about other problems? Supporting multiple versions of packages often exposes errors that you wouldn't have found otherwise. Numpy 1.10 introduced breaking changes into the array, that had you don't things right in the first place, you wouldn't have had a problem.
Not at all. But it's hard to get convinced if you don't try it for yourself. So, try it, research it, don't take anyone's word for it. ---- I used to be a very active member of a different programming community. So much so that eventually, I became a moderator, and then a mediator between the company working on the programming environment and the general audience for which this editor was intended. For few years I was on an advisory board of the said (Eclipse-based) editor. One of the goals of having me onboard, for the company that is, was to get everyone in the community convinced that life outside a heavy-weight with tons of bells and whistles editor is not possible. This product is an ancient history today, and the community is mostly nonexistent. But, during that time period I did my job very diligently. I would try other editors. Whenever there was a new feature advertised by the vendor on whose board I was a member, I'd also try to find what competitors did in this regard. I'd also follow the press releases from other vendors to see what's "hot", how people solve similar problems. Well, that was kind of fun... Except for when I realized that the competition was mostly in the marketing area... I took two courses in HCI (human-computer interaction), where I learned some really simple, but somehow not obvious to everyone things, like, for example, that people are most productive with the tool they know how to use well, and that almost every other characteristic of the tool pales in comparison. I learned how to actually design an experiment in this field. ---- Today, I work for an international company with dozens of Python programmers. There are about two dozens of them only in my building. Of all of them one uses Vim, and one uses Emacs (that would be me). Everyone else uses PyCharm. Not a day goes by w/o me being summoned to solve a problem another Python programmer drove themselves in. Typically, they try to do something through PyCharm, and it doesn't work, as in: it crashes with a non-intelligible error which they don't know how to approach. The sad truth is that people who use PyCharm don't understand how things actually work: they see them through the prism of their editor, and it's not a good way to do that. PyCharm is a monster-program, it isn't humanly possible to just follow a backtrace on an error and to figure out what happened in, say, ten minutes. You need days, sometimes weeks to investigate. Nobody's got time to do that, when there's actual work to be done. Another problem is that PyCharm treats every other language as if it was Java. For example, when you configure your project, it asks you where your "SDK" is. This makes sense in Java world, but is outlandish for Python. PyCharm functionality is also limited to the (poor) understanding of its authors of Python infrastructure. For example, they don't know that it is possible to install packages not only into `site-packages` but also into `src` sub-directories of the virtual environment. So, if you did a source install, PyCharm suddenly cannot find the sources, but everything still runs just fine.
I would love to own this bundle. But 1452$ is wayyyy more than I could afford. 
There are at least two other ways to do this - cffi and ctypes. I gave a talk at our local pycon https://m.youtube.com/watch?v=tqx9VW7V3Lc (code: https://github.com/mattip/pycon2017_cffi) comparing the three in terms of complexity and speed. For this use case, cffi would probably be much simpler and just as fast
Please consider r/learnpython . There are too many topics that you aren't apparently familiar with too properly help.
Another option besides %debug magic is from IPython.core.debugger import set_trace Then wherever you need a breakpoint in your code you can add set_trace()
Google Cloud Instances
This is starting to bother me. Can y'all start googling things before you post a question? Good googling is one of the most important skills a programmer can have. 
https://www.python.org/dev/peps/pep-0526/
Why’s Django do ? 
Well that: grades, and a way to log in and check your grades if you are a student and set them if you are a teacher
I just said it for no reason. I don't need karma points, there is nothing I can do with them :P
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [euske/pdfminer/.../**README.md** (master → 8150458)](https://github.com/euske/pdfminer/blob/8150458718e9024c80b00e74965510b20206e588/README.md) ---- 
 for frame in video.data(): mild_cringe()
Any distribution will do, tbh. I mean - PowerShell is great within Windows, but all distributions I have used have had attainable versions of any language and BASH is great. 
That's exactly what I think it's a good idea!
OP is mostly referring to [Visual Studio Code](https://code.visualstudio.com/), which is like the new cool kid for lightweight IDEs. It’s pretty impressive, to be honest. And open source. It fits with Microsoft’s new philosophy as of late. But anyway. I use of mix of it + vim. Depending what I have to do at that time. 
I'd like to enter this giveaway.
I know this would be the place for a Python-based solution, but my go-to tool for programmatic PDF manipulation is [Apache PDFBox](https://pdfbox.apache.org/), a Java library. Nothing native-Python comes close to what it can do… You would be able to use it to dump the text on each page and use a regex to detect if it was the first page of a section, identify the phone number associated with the section, and extract the pages into a separate document to save to disk (or if you want to get really fancy, look up the email associated with the phone number, and send it automatically).
Should be a syntax error Python 2.7.14 (default, Nov 2 2017, 18:42:05) [GCC 7.2.1 20170915 (Red Hat 7.2.1-2)] on linux2 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; a: "10" File "&lt;stdin&gt;", line 1 a: "10" ^ SyntaxError: invalid syntax 
I’m not sure that one is better than the other. It will just depend on your personal preference. I haven’t used notepad++ for years, I don’t think it supports plugins does it? That’s a great part of sublime, you can add plugins to change the functionality. 
Great article on a potential use of Cython! I made this presentation a while ago at PyBCN meetup comparing ctypes and cffi: https://raw.githubusercontent.com/gmarull/pybcn-cffi/master/cffi.pdf
Oh, thanks for the heads up.
Hey, so thanks for try big to change my mind. Not sure I’m convinced though. I can’t see how having tools like a terminal embedded into a window reduces context switching. For you, when you want to go from code to command line, you either open up an IDE pane, or glance at the already open pane. For me, i Cmd-tab across to my terminal, or glance across at the positioned window. They’re so similar that I can’t see where the improvement is in your situation. I get that I lose IDE specific features. Are there any of note that you think I should look in to? In terms of heavily customising, I see what you mean. I have a lot of plugins installed in sublime. I mostly see this as a positive though, I get to customise to my liking. A bit like (I assume) you can heavily customise to your liking by changing preferences. The last time I delved into the world of IDEs I got caught out because I couldn’t get it to work in my specific situation. This further entrenched me into this opinion. I was using docker to develop some python code. This was before docker for Mac was a thing, I was using vagrant to spin up an Ubuntu VM with docker installed. My IDE (PyCharm), couldn’t find/use the python interpreter. My terminal could. Now certainly things have got better since. Docker for Mac is a thing, and I guess that PyCharm’s support for docker has improved too. But the point is that my tightly focussed tools could easily handle what PyCharm couldn’t. Finally, I’m trying to remain civil, I’m genuinely interested in your opinions and in having my mind changed. If it will improve my workflow, I’m all ears. But “your perception doesn’t match reality” is patronising and rude. I’m not an idiot, I just don’t think the same things that you do. 
Who said I was giving advice? The guy I responded to asked why 2 vs 3 matters for scientific computing, and I gave a reason. Way to be hostile.
Fedora 25?
From "Automate the Boring Stuff with Python", which is free to read online: [Chapter 13 – Working with PDF and Word Documents](http://automatetheboringstuff.com/chapter13/) (Though if anyone has found a better PDF module than PyPDF2, I'd be all ears.) [Chapter 16 – Sending Email and Text Messages](http://automatetheboringstuff.com/chapter16/) And if all else fails, you can automate the clicking with PyAutoGUI: [Chapter 18 – Controlling the Keyboard and Mouse with GUI Automation](http://automatetheboringstuff.com/chapter18/) ...and you can select all and simulate Ctrl+C to copy, then use the [pyperclip](https://pypi.org/project/pyperclip/) module to ead the text off the clipboard.
In general, /r/python is for news about Python, while questions are directed to /r/learnpython. From the sidebar: &gt; If you are about to ask a question, please consider r/learnpython or [the learn python discord](https://discord.gg/jQtfh66).
Also some people just can't orient themselves around a computer without a mouse. I call them point-and-clicky people. They feel lost without one. I'm talking programmers here. I type 70 WPM, and sometimes the interface gets in my way. If I have to stop and think about the sequences of clicks to do something and then wait for the application I might get distracted, whereas if I had typed it it would have taken a couple of seconds. Not to say I'm not going to try some of the suggestions, but it is an observation on how people work in different ways.
The PyCharm codes don't stack, but you still get both of them? \(2 months and 6 months\) If so, I could share the 2 months code to a coworker.
I’m hooked on Notepad++ for my projects. The compare plugin is a godsend. 
Thanks for the article. It really connects the dots for me now :D
REST is an arcitectural design pattern for transferring state between a client and a server. Sockets are a technology, which Django rest framework uses(http requests are over sockets, just in a structured manner). I don’t think dfr is a good choice for writing a chat program. 
this article needs to be updated.
how python and other such languages handle indentations, here is an overview where python codes were used as examples suggestions appreciated ! 
Thanks, I will take a look!
Glad to hear it helped :)
You should also use [Trio](https://trio.readthedocs.io/en/latest/tutorial.html). IMHO is easier to use than asyncio/aiohttp.
Yup, probably the best solution. If you're on a *nix machine, there's a command line tool called `pdftk` that will extract and merge arbitrary pages of a PDF. I'm not entirely sure if it is available for Windows.
Use black instead
I was just working with PDF stuff the other day. Unfortunately there are no fully featured python libraries I could find that could do everything I needed. Luckily what you want is pretty simple. I'd recommend using [PyPDF2](https://github.com/mstamy2/PyPDF2) which can be installed with `pip install PyPDF2`. If you look at one of their [sample code files](https://github.com/mstamy2/PyPDF2/blob/master/Sample_Code/basic_features.py) the process of taking individual pages from one PDF combining them into an output PDF is really easy. The whole thing could be: from PyPDF2 import PdfFileWriter, PdfFileReader output = PdfFileWriter() statement = PdfFileReader(open("verizon_statement.pdf", "rb")) output.addPage(statement.getPage(0)) outputStream = open("PyPDF2-output.pdf", "wb") output.write(outputStream) If you didn't mind inputting the users and their pages then you could have a little loop to get names and start-stop pages users = [] user = '' while user != 'done': user = input() start_page = input() stop_page = input() users.append((user, start_page, stop_page)) Then do the whole run at once for user, start, stop in users: output = PdfFileWriter() for i in range(start, stop): output.addPage(statement.getPage(i)) output.write(open(user + '_phone.pdf', 'wb')) But like I said, I spent a lot of time trying to do stuff with PDFs and there is no one library that handles it all. For instance with PyPDF2 there is no easy way to get the text on a specific page. If you want to automate that part then you can mess around with [pdfminer](https://github.com/pdfminer/pdfminer.six) which can be installed with `pip install pdfminer.six`. It's sole purpose it to parse and traverse PDF files and their structure. You could potentially use that to parse the text of the statement and then use PyPDF2 to split and join. Even then you'll have to adapt the [pdf2txt](https://github.com/pdfminer/pdfminer.six/blob/master/tools/pdf2txt.py) example tool to fit your needs. If you really are invested in going down the PDF rabbit hole I wish you good luck. I barely scratched the surface and now I understand why there is so much hatred towards the format. The official Adobe reference documents aren't too helpful either. Their page that contains reference documents is [here](https://www.adobe.com/devnet/pdf/pdf_reference.html) and the one that seems like it's the latest 404s. They are all dated a decade ago and the reference document is 750+ pages. It mainly talks about the raw file structure too and how PDFs are constructed at a super low level. It seems like sometime after that they didn't bother releasing spec documents for the PDF files themselves and now they just have SDKs for working with Adobe Reader DC, XI, or X. If you want to go the way of dark side of the force you are welcome to head on over to [Satan's Den \(Acrobat Development Center\)](https://www.adobe.com/devnet/acrobat.html) and get started. It seems to use Javascript for all coding and everything is a plug-in for the Reader application. Personally I like Javascript so at least it's not all bad. I know back in the day they used ColdFusion for PDF stuff so at least it's a bit more sane to work with. All that being said, I don't know if you'll be able to completely automate the entire thing. But at least you can cut it way way down. Once it's all extracted you can probably automate the sending of it as well. That part at least should be pretty easy. If it were me I would probably maintain my own list of currently active users and their emails. Try to get pdfminer to find all pages with those user's names. Pass that to PyPDF2 to extract those pages to files named after the users. Then I would probably manually verify each document looks right and then have Python send documents matching names to their associated emails. You've got a bit of work ahead of you. Have fun.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [pdfminer/pdfminer.six/.../**pdf2txt.py** (master → eddf861)](https://github.com/pdfminer/pdfminer.six/blob/eddf861fbd59e401dc350d9fa128013795958061/tools/pdf2txt.py) * [mstamy2/PyPDF2/.../**basic_features.py** (master → 1775bdc)](https://github.com/mstamy2/PyPDF2/blob/1775bdc4b9b3281a31b7d966223b8f02f53ba5fc/Sample_Code/basic_features.py) ---- 
Depends on the format of the pdf, there are a few libraries available. The basic one is pdfminer but there is a better one which is tabula, tabula takes tables out of pdfs and when it works it is the better option. Worst case would be converting the pdf to text, then grabbing the 2 columns with some string and list jiggery. 
Let's not do this gatekeeping nonsense.
I kind of want to know as well now
Looks interesting, but the C library I am binding is used in anothrr non-python context, so I would not want to include unrelated headers if it can be avoided
Seconded. Pybind11 is easy to work with! I have had a lot of success with it in speeding up Python. 
Someone correct me if I’m wrong but after looking it up it’s a high level python web framework “ takes care of much of the hassle of web development” 
\*\*NOPE, YOU'RE NOT\*\* 
Is there any reason why we shouldn’t use the Subprocess library to call C executables ? 
There is an [emacs](https://github.com/millejoh/emacs-ipython-notebook) that I use daily use and can't imagine anything better than that but you'll need tokens because I think that's how Jupyter works.
Sure. Say you want to call a C function which returns a large array. Using subprocess, how would you accept this array on Python?
complete noob here, but this still sounds impressive!
As I know, PyCharm \(IDE for Python for JetBrains\) has ability to work with ipython notebooks. You can read about it here: [Using IPython/Jupyter Notebook with PyCharm](https://www.jetbrains.com/help/pycharm/using-ipython-notebook-with-product.html). Also, I tried it, but stay in Jupyter Notebook in browser, cause it's rather faster and convenient \(just imho\).
Autopep8 requires a pip package to be installed for it to work correctly. Have you done this?
Thanks for the login idea. That's a bit more challenging for me (I'm a beginner)
Tribalism is rampant and unchecked, especially in tech. Parts of the python community are worse about this than others.
Long enough that you should probably be using a database
[about this long](https://docs.python.org/3/library/timeit.html)
Ok thank you very much for your help! I appreciate it a lot
Python dicts are hash tables. It'll take as long as it takes your computer to compute the hash for the key. (Constant time) Which is to say it'll take the same amount of time whether there are 5 elements in a dict or a million.
That's dope 
If you have the key, it'll be an O(1) operation. So very quick. If you have to iterate/search through the entire dictionary for the right key, that's a different story. See below for additional details: https://wiki.python.org/moin/TimeComplexity
You are almost right, because with 5 million you get a very high probability of hash collisions which will degenerate into some search. It's not as bad as searching an unsorted array, but it **will** be slower than with a 5 element dict. However, it will be roughly the same if you have 5 million or 2 million or 8 million.
You can google MKL speed tests. The reason it's free with Anaconda is because they already paid for it. Supposedly, it was not cheap. It sounds like you would already have access to it, but I'm not an expert on the legality of MKL distribution.
Yep
Ok. Thanks I will surely look at it.
Agreed. IDE is the work smarter part. Your code will be more consistent, less time spent formatting, less time with code compliance. Trying to debug or understand old code? Right click, goto declaration or implementation. As stated before refactoring is a sinch. In my experience people who dont use an IDE write inconsistent, difficult to read code and they spend significantly more time doing it.
In reality that's not true. I learned this writing performance critical C. While the theory is right, it doesn't take the reality of the hardware into account.
I use Python because it's fast enough. The libraries are amazing and it does things for you. I can output two values from a function that have different types. I can open a file and forget to check if it succeeded and I won't run into bizarre behavior when it doesn't. I develop prototype level engineering software for NASA/military projects to aide engineers in analyzing parts/designs. Without rapid development, we'll be way over budget It's software that frequently does not have unit tests, so ease of development is key. Regarding reading binary files, you can get 500 MB/sec if your data file is large enough/formatted logically. That's as fast as you'll get in C++. Numpy.frombuffer is amazing. I use C++, but only when the code is performance critical. Ironically, when you take that approach from the start and code an N^3 algorithm, it's very easy to say screw it, write it in Python, and it's suddenly 1000x faster because I replaced a mess with a well tested and optimized KD-tree. It goes both ways.
I like Notepad++ for text viewing/editing, but for python development I use Visual Studio Code. I think without IDE, I would miss: 1) Ability to go to the symbol definition (F12). Don't know if Notepad++ can do that. 2) Git integration. This I know Notepad++ doesn't have, since I was searching for it with no avail. I mean the ability to see which lines of code did change since last commit, or which files are changed. I would be completely at loss to do programming without this. 3) Debugging code.
cffi would also have the benefit of great PyPy support nn
Python3.6 -m pip install ... This will run the pip for the interpreter. Please use /r/learnpython for questions like this.
I know that I can install libs for 3.6 with that command, the question is about how to update 3.5 to 3.6 without installing 3.6 standalone
Jupyter notebook is where? Its simpler than idle for a lot of tasks.
Well, I went through the trouble of re-installing python all together before I found my problem: I was typing pip install PyInstall instead of pip install PyInstaller So, hats off to me. 
Collisions are definitely something something to be concerned about in a large dataset, I agree.
Is performance better this way than same library rewritten in python ?
Don't remove or change the system 3.5 unless you want to break your Linux.
If you're really doing 20+ million entries, depending on your key's type, it might just be better to not cast the key to an integer and leave it as a string, despite being a number. That change took my 2 hour code and made it 5 minutes. Just do less.
got it, thanks 
I can't find the atom plugin for black. What is the name?
No, you only get one PyCharm pro code(either 2 or 6 months code), depending on the tier of the bundle you purchased.
You're getting a type error \- the `with` statement returns bytes, not a string. So ... with urllib.request.urlopen(req) as response: source = response.read().decode('utf-8')
Pycharm really is awesome
Nothing in particular. But this is /r/python! In all seriousness, it sounds like it would be an integration/testing nightmare. It would be harder to have one canonical unit of code that does one thing. What if you need some functionality from Perl in your Python project?
Using \[pepper\]\([https://github.com/saltstack/pepper](https://github.com/saltstack/pepper)\) to query salt system and generate a report as an HTML document with embedded JSON. Using Jinja to embed the JSON and build overall structure and then D3.js for graphing.
On my laptop, I'm getting an average of: 0.272349441051 seconds. I wrote some code for fun to test it out [Gist link](https://gist.github.com/dsouzarc/f54ae0c18271cadaee204d83d8767dae) - feel free to try it out on your computer.
Have you heard of [Tango with Django](http://www.tangowithdjango.com)? I'm by no means knowledgeable in Django. I switched to Flask because the learning curve is lower and I don't need to build Instagram. However that book gave a pretty low level newbie introduction
PyPDF is actually (way?) more powerful than what its documentation would let you assume, though it implies delving into its source code. I had a quite similar need a while back - finding outlines (section titles) from a collection of PDF documents, extracting the corresponding pages and concatenating them into a new document - and leveraged PyPDF to this purpose. The following threads were very helpful: - https://stackoverflow.com/questions/1918420/split-a-pdf-based-on-outline - https://stackoverflow.com/questions/8329748/how-to-get-bookmarks-page-number - https://stackoverflow.com/questions/2431426/extract-toc-of-pdf - https://stackoverflow.com/questions/911672/extracting-titles-from-pdf-files - https://stackoverflow.com/questions/10014572/python-open-pdf-file-to-specific-page-section - https://medium.com/@menglishu09/get-bookmarks-from-pdf-using-pypdf2-4166ae8eb6f6 - http://blog.isnotworking.com/2006/08/extract-pdf-title-from-all-files-on.html
Not understanding exactly what you mean by this? You're consuming the Elasticsearch api getting data from indices or you're creating an elasticsearch like index using python?
Definitely the most frustrating thing to be told when a beginner. You're essentially a big for loop yourself. ``` for step in thingiwanttodo: think of first thing you need to do google things you don't know how to do yet build/use module debug and learn 10 new things on stackoverflow do thing differently than how you defined rework how some other functions work because you learned something debug research finish function continue
I think it cannot be updated to 3.6, it a system python, changing it might break some dependencies.
That or use the `sqlalchemy.orm.Query` API (e.g., `session.query`), and call `.statement` on it once you're done constructing it. Pass `session.connection()` as the second argument.
I believe that all communication to and from browsers is done via sockets with a protocol layer on top, like tcp. Yes there are other ways to communicate other than sockets. Professionally I’m not a web devloper, I’m a SCADA systems programmer. For some devices in the field(think power line switches and breakers) we use radio to communicate. It is the norm in most cases to use sockets. If you’re wanting to look at other protocols look up DNP it stands for distributed network protocol. 
np.frombuffer
The wonderful thing about a *good* object-oriented language (like Python) is that you get to reap the benefits of using it without ever engaging in the practice yourself! Have you ever used the range operator on a string *or* a list? Like this? category = row[4:10] ... page = elements[start:end] You're using object-oriented programming! Have you ever iterated over a list *or* a dictionary's keys? for e in elements: ... ... userlist = { ... } for userKey in userlist: ... You're using object oriented programming! Just because you never write a class, doesn't mean you don't benefit from the power of object-oriented programming. Strongly-typed dynamic languages like Python are especially good at this.
/r/learnpython is the best subreddit for this!
Objects are just one way of organizing code. You’re not hurting yourself by not using it in everything you write. That said, it would likely be good to write a few things that use it to get some experience with it.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [metaperl/python-oop/.../**README.md** (master → 98a8adf)](https://github.com/metaperl/python-oop/blob/98a8adf4bba2fd20ec7c4b1711a3293f404ce496/README.md) ---- 
A significant portion of that code is input validation. Libraries like [Marshmallow](https://marshmallow.readthedocs.io/en/latest/) exist to simplify this.
Thank you, I will repost my question there.
yes, there are thousands of libraries for almost anything
If you are calling something many times, eg in a tight loop, the overhead of process creation will kill you.
You can install pybind11 using pip, so that shouldn't be a problem. 
Just bought it. I don't think I need the 1 year PyUP or 6 month Postman subscriptions, so if anyone thinks they can make good use of them, let me know.
As long as the Python code wouldn't have to call any functions in the DLL (I don't even know what would be involved in that), the fact that the C application requires a DLL should be transparent to you as long as you have all the required paths, etc configured. But I'm saying that as a Linux guy.
Or you could pay for advertising so we can block you like every one else
Oh ok. Im new to reddit so I still dont know how to use it. But thx for the info.
Ok that solved the problem. Im now encountering another, but Ill post it in r/learningpythoon.
Another way I found was I can use root.update() and sleep inbetween the updates 
Will check it out. Thanks.
Check out the ctypes module and documentation. Amazing stuff imo. 
/hype 
Which version were you using? Dicts changed storage layout in 3.6
&gt; My friend says that code is catastrophic. How so? I don't see anything particularly wrong with it.
I made a Discord bot to fetch informations and links from a cinema website called [Letterboxd](https://letterboxd.com), it's currently used in a few cinema Discord groups. I don't have access to the API so I use BeautifulSoup to scrape the HTML. It's quite fast and we're happy with it. Here is the source code: https://gitlab.com/Porkepik/PublicLetterboxdDiscordBot
[relevant xkcd](https://imgs.xkcd.com/comics/python_environment.png)
Also where is the newcomer VSCode? 
Jupyter combines the simplicity and readability of python, with the unholy mess that is web programming. So it makes a lovely tool for web developers to produce nice python programming tutorials with. I think that accounts for about one million of those two\-million github notebooks. Seriously though. Grats to them.
And also the old school way \- including python.h in a file and writing the bindings manually. I've done it a couple of times. Not the interesting thing in the world, but writing the translation layer \- i.e. the functions that do things like taking some struct in your C library and translate it into say, a Python dictionary \- was actually interesting, it was a nice insight into how the internals of Python work. You are basically writing Python in C, calling the interpreter's API directly. 
Really nice demo
0.2 seconds sounds much too slow - I think you might have forgotten to divide by a loop count that timeit uses. See the timings /u/benhoyt posted above.
pyenv + pyenv-virtualenv is your friend. It completley removes the need to modify your system python installation. Basically you do this for all your python projects: $ pyenv virtualenv 3.6 my-project-env $ pyenv local my-project-env $ pip install your-needed-dependencies The *pyenv local* command will set it up so your virtual env for that project is activated as soon as you cd in to that dir.
Uh, you need to know that dlls can be two things, either C libraries like usual or some weird ass .NET assembly thingy which doesn‘t work with anything except, well, .NET.
I think you could use some ORM. I recommend [https://orator\-orm.com/](https://orator-orm.com/) that is like Rails like Active Record for Python.
Use keyboard shortcuts
VSCode
What is the best way to go the other way and use a Python library in a c type environment? 
Yeah cython is very cool stuff, but please use the same type of compiler for the pyd File like the Interpreter. I trapped in this context. I am using MSYS2 with gcc with python 3.4 x64 for Win which was compiled with vs tools. The result: GCC built pyd File works sometimes :D....it was horrible for the first time to find this shit dev bug caused by myself. Maybe it will safe other developer with the same issue. gl and happy snaking .... ^^
Is there something new? This looks like PyQt5 is used.
It's a c# wrapper around some old c code, I believe. 
Or, if you're going to be writing low level code *anyway* and not using existing code, write it in Rust. Not just for the safety, but also because it's easier to write complex code in.
Sentdex is a good one [https://www.youtube.com/channel/UCfzlCWGWYyIQ0aLC5w48gBQ](https://www.youtube.com/channel/UCfzlCWGWYyIQ0aLC5w48gBQ)
Thanks, Unfortunately Pycharm is heavy on laptop and uses a lot of resources. I hate also the indexing ideology they deployed. even sometimes re-index thing which were already indexed and available in the project.
Dan Bader and Corey Schafer come to mind.
Visualizing traffic light detection with OpenCV https://medium.com/@kenan.r.alkiek/https-medium-com-kenan-r-alkiek-traffic-light-recognition-505d6ab913b1
Not exactly YouTube but Michael Kennedy has an amazing podcast called Talk Python to Me and some pretty solid courses for everything from starting out to setting up an entrepreneurial website all in python
Wow, quick responses, great community. Thanks everyone.
Good question. Those timings were actually on 2.7.
Plus, hashing ints is different from hashing strings. I expect most dicts are used to store strings.
Maybe this will help: http://pybind11.readthedocs.io/en/stable/advanced/pycpp/index.html
`for row in df.loc[start:].itertuples():` should get you going.
Took some searching, so for anyone that's interested, this is how to convert an SQLAlchemy result to a pandas dataframe. result = cursor.execute("SELECT column_name FROM table_name WHERE column_name2 = %s", (variable_name,)) df = pd.DataFrame(result.fetchall(), columns=result.keys())
Apparently, yes: https://pypi.org/project/somepackage/
Excellent, thank you! That was all I needed. I'm surprised I wasn't able to find that myself.
Good point. 
If I understand correctly: * ElasticSearch is used to index the data from your database at the moment * You have about 500k domains * So far it works great * You use a relational database (?) * You're not sure it's going to scale to 1B (?) If the last 2 points are right, what's the database you're using at the moment? If not, what did I miss?
*facedesk* I was missing the : .... Thanks a ton!
FFT algorithms are examples of [Divide and conquer algorithm](https://en.wikipedia.org/wiki/Divide_and_conquer_algorithm) and generally work fastest when the input array's number of element is a power of two. A common technique to get around this is to pad the input array with zeros until it's number of elements is a perfect power of two. I don't know for sure but it's possible that Octave's fft does the padding step for you wheras with numpy you have do it yourself. Try padding your input array like this and see if you get better performance: import numpy as np arr = np.ones(31257584) next_power = 2**np.ceil(np.log2(len(arr))) pad_len = int(next_power - len(arr)) new_arr = np.pad(arr, (0, pad_len), 'constant', constant_values=0) np.fft.fft(new_arr)
**Divide and conquer algorithm** In computer science, divide and conquer is an algorithm design paradigm based on multi-branched recursion. A divide and conquer algorithm works by recursively breaking down a problem into two or more sub-problems of the same or related type, until these become simple enough to be solved directly. The solutions to the sub-problems are then combined to give a solution to the original problem. This divide and conquer technique is the basis of efficient algorithms for all kinds of problems, such as sorting (e.g., quicksort, merge sort), multiplying large numbers (e.g. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
`pip list`
Which one works best for both CPython and PyPy?
numpy is BSD licensed; the faster free FFT routines (FFTW) are GPL licensed, as is Octave, so Octave can use them but numpy can’t. The solution is to use pyfftw, which has an interface that is drop-in compatible with numpy.fft
That's generally the way I go. Once C structs are involved ctypes starts to become really ugly. Having python C extensions allows you to clean everything up with a shim layer that's sort of hidden away.
Thanks for the ideas.
Hi mogosselin, 1) ElasticSearch is currently storing 70 million documents with content information like description, hashtags, abstract summary, media image etc. and 70 million URLs in a different index separately. So far it is working great. 2) The feeds/domain data is stored and replicated in ElasticSearch as well as Mongodb. At MongoDB as the data size started to increase, we are seeing the query time increase 120-200 MS and proper index have been created in MongoDB as well. 3) Well, ElasticSearch would work as we have seen that the companies such as Meltwater.com etc. have scaled to that level so it will boil down to hit and trial to see the hiccups during the process. 4) Not any as of now, we are using MongoDB for storing the domains/feed data. 5) I have been researching lately about Cassandra/ElasticSearch for this and my main concern is QPS time while looking up the URL exist in the index/database already or not. Right now, we are storing only the feed/domain and their URLs but when it comes to storing the internal/external links, the number will be growing really fast. The current mongodb collection structure is like this one: https://dumpz.org/2830623/ And, thank you for the prompt reply.
Go ahead and cringe, then. I'll keep using Jupyter productively. Maybe I'm misunderstanding the connotation of "cringe" but I find your comment fairly insulting. I'm sure you didn't intend that, so I thought I'd politely let you know.
I hadn't known about the difference in licenses. I'll try pyfftw, thank you.
Thanks for the tip about pyFFTW. &gt; often depends on which underlying BLAS it is linked to I have no idea, besides my being on a new Windows 10 machine using regular Windows Python from https://www.python.org/. 
yeah, I mean, you've already written a library in C or C\+\+, so it's not like it's a huge challenge to bind it to Python just because you're writing raw C. It's a bit tedious, but then again, that makes you optimize the API for as little C implementation code as possible :\)
O recommend you to look at pipenv :) It’s built on top of the virtualenv and it’s really simple and useful
also` conda install mkl` -- mkl_fft was added recently which is the fastest FFT implementation for modern intel x86
If you install `miniconda` instead of the normal python, then do `conda install numpy mkl` you will get a numpy binary prelinked against intel MKL, which is the best BLAS implementation for intel CPUs. If you use an AMD chip, depending on the architecture FFTW may beat MKL, or MKL may be quite fast. In my experience, mkl_fft is bad on ryzen but things like exponentiation are fine.
yup, you want mkl-fft or pyfftw 
Thanks very much.
&gt; which likely means better support That's not really been true through the years. Nokia started this project, then abandoned it. Digia have picked it up *several years* after they bought Qt from Nokia. The priority for them will always be regular Qt - Python support is something they do as a nice-to-have, today. Tomorrow, who knows. In contrast, PyQt is Riverbank's bread and butter. The survival of the company depends on it. The difference in incentives is fairly clear and will likely remain as it is. It's the type of project that doesn't need humongous amounts of resources to continue -- just enough skilled hackers to keep tracking Qt while refining a few interfaces; and if you pay for your license, you will be treated well. In software, bigger is rarely better.
If they put the data on the web without a wall, any attempt to read said data is must be fine so long as it doesn't break the server. If it is walled then it requires some contract to use, and the T&amp;C of the provider then applies.
First and foremost, this belongs in /r/LearnPython. Second, why are you doing loops over numpy. Third, you should specify more specifically what you’re trying to do. We can guess from the code but that doesn’t always help
There's a [library](http://python-docx.readthedocs.io/en/latest/user/documents.html) for opening/reading from/writing to Word documents so that part it taken care of for you. Depending on where you're getting the questions from (e.g. pas exams), you can concatenate all the questions you have into one file and separate them by section by adding a "marker" that reads something like "&lt;START SECTION 1&gt;" and ending the section with &lt;END SECTION&gt;. Then, ask the user for input, read in the document with all the sections, find the section by looking for the markers and read until the end marker. Or just use JSON or something to describe the data. Hope that helps :)
It is. Ghostscript is also an option, but it's command line syntax is more arcane 
Isn't the question more geared towards "I haven't created a custom type and used it. When do I need my own types?"?
It's pretty possible, although the time you spend familiarizing yourself with python would probably be better spent studying for you finals. Regardless, here's some things to think about: * Converting to a Microsoft Word document isn't too realistic, as I'm not sure if there's any libraries to do that. It's not as simple as opening a document and typing when you do it from a script. After saying that, you would have no problems sending it to a text file (.txt), which would definitely be easier. * The program will not be able to make questions itself. I'm not sure if this was your intention but just know that it can't. You may be able to or hear other people you can make definition based questions (What does x mean? Ect), but it won't get you very far in terms of revision. So the questions would need to be created by you or someone else, and then sorted and the topics tagged based on the contents of the question, ready for the program to take in. It does seem pretty simple on the surface, but like anything, it gets complex as you delve into it. Maybe try work out another way to do questions, and come back to it when you don't have the stress of finals.
Please tell me this is satire
Then you are shit out of luck. The last time I checked there was no reliable way to load them into Python...
Well, no, I'm being serious in that a language designed in this century might have an easier time writing correct (possibly multithreaded) code than one from 1970.
Yeah, delegate input validation to some library. Other than that, your ternary operators are quite involved. Would this work instead? `only_contacts = (request.args.get("onlyContacts") == "True")`
Use riak kv. Create buckets with relations. Use solr to create search patterns. 
Thank you so much for taking the time to write this!! My exams aren’t actually for a while, so I thought this would be a good project to get started early on (and I’d be lying if I said I wasn’t hoping for a little extra credit with it) ;) I’d already have the questions prepared, so I wouldn’t need to worry about making a program that makes questions. I think with a lot of work it’s doable; it’ll take a while, but I’m going to try my best! Thank you so much!
Just curious, why are you against the annotations? I haven't really used them yet. They do look rather cluttery but I could definitely see cases where the option of static type checking would be useful.
If you can, start the program in python and then dlopen the C-program-built-as-a-library
Sure, it hasn't been before, but the Qt Company isn't Digia nor Nokia. Python bindings to Qt are critical to the VFX industry, and if they pay the Qt Company for it, Qt for Python will stay well supported. Furthermore, the Qt Company has a team of 4ish people working on their bindings last I heard, it seems they may have more now. So sure Riverbank has more incentive, but I also think the Qt Company has just as much to make Python support a core part of their distribution. And you are correct that pyqt5 doesn't need large amounts of work to maintain, but what about pyqt6? 
[Siraj](https://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A) seems to like Python a lot. You'll get a lot of videos about bitcoin and blockchain if you're into that too.
&gt; At MongoDB as the data size started to increase, we are seeing the query time increase 120-200 MS and proper index has been created in MongoDB as well. Is that the main problem your are anticipating? If yes, it's not really clear to me as what these queries are and why they need to be fast? 
That's a lot of data: I would definitely run many tests on every technology available instead or relying on a reddit answer. As good as people's knowledge here can be, they might not fit your use case at all. 
There's zero chance octave is padding for you, it'd would change the result!
Riverbank managed the migration from 3 to 4 and then from 4 to 5, which were significant. I expect they will continue to do well. Phil Thompson has been doing this for more than a decade; he knows a few tricks, so to speak. But hey, the more the merrier. I’m just saying that one shouldn’t presume a company will support these bindings “better” than Riverbank, because historically that’s definitely not been the case.
I suggest this book, Code Complete. It has nothing to do with Python and it's pretty old at this point but by reading it, I know for a fact that it has a lot of the same ideals. knowledge, values and tips that my college teachers tried very hard to impose upon me in what is considered one of the best IT college courses in my country https://www.amazon.com/Code-Complete-Practical-Handbook-Construction/dp/0735619670 You can also procure your HR department (or your boss) and share the situation. Tell them you'd like to enroll in some courses to get up-to-speed with everyone else around you, since you don't have the same training as them. Most companies (or at least a lot of them) will offer to pay the entire thing for you too.
rounding up to power of 2 speeds it up greatly
Nah, a billion records is still very doable. A small vertica cluster (think postgres) can easily support a billion records in a table with sub 500ms response time
When it comes to NoSQL databases you should think about how you're going to read and write the data first and foremost. Each one of the databases you mentioned is designed to support a different pattern. How will you need to query the data?
How is it compared to Atom?
Have you considered a boring old relational database for this? Based on the [schema you linked](https://dumpz.org/2830623/), I don't see anything that wouldn't be straightforward to implement in a RDBMS. It sounds like one of the important things you want to implement is checking whether or not a domain already exists in your dataset. You're looking at O(log n), which isn't bad, for just about anything you use to index it. So, why not try a technology that has a couple of decades of tuning and ecosystem behind it?
I started my dive into Python web development this week. I am starting off with the Flask micro framework but might move over to Django once I am more comfortable with it all. I have experience building PHP web applications but I was really wanting to further my knowledge of Python and WSGI.
The important question is what do you intend to do with these urls? Is the workload read heavy, write heavy, constant even crud load? Aggregate queries or simple lookups? Do all use cases need low latency or can some be done offline (i.e. batch processing)?
Have you looked at MapD? If you have a few extra gpus around it could help.
BigQuery?
I know this would be an unpopular opinion but this is something i commonly encounter in my daily job. Give mumps a look, specifically GT.M ( since it's open source) or if you can afford it, then Cache from Intersystems. If interested, I can personally be involved if you'd like ( I've always wanted the world outside of Healthcare to benefit from the awesomeness of mumps ). Lastly, dont get discouraged by the syntax ( it can be written in a modern, python like syntax ). I mostly use a functional approach so it's easy to learn and can easily handle the load. Give it a look and let me know if you're interested. 
TLDR; They clutter up the language My main gripe with them is that they are beginner-unfriendly. Python is meant to be read more than it is written. Now imagine you're a python beginner, reading some code you found on github to learn, and there's this weird syntax thing you've never seen before in any other language. Type annotations are "optional" so they likely won't be covered in beginner tutorials. What would you do? Turn to google and look for... what? A colon? If you search for "What does colon do in pyton", you're most likely to find something about `def`, `if`, `while`, `for`. or that it's a dictionary assignment, which just confuses you further (see title of this very post). The same point could be made about function decorators, but at least they use a character which isn't (wasn't, actually) used for anything else. IMHO type annotations should have been restricted to being kept in comments. That way any text editor with even basic syntax highlighting would make it clear that this is an optional element that might help you when writing (and reading, I'll admit) code, but doesn't affect its function in any way. Also; the fact that it apparently accepts the string "10" as a type?? What's up with that? Duck-typing in an attempt to avoid duck-typing?
There are great talks from PyCons on YouTube. Some of many awesome speakers: - Raymond Hettinger - David Beazley - Alex Gaynor - Brandon Rhodes 
I will bite. This MUMPS? https://thedailywtf.com/articles/A_Case_of_the_MUMPS
I love Calibre, but I wish I had never looked under the covers. The codebase is... pretty wild. Amazingly there's still 2.4 shims in there, but futurize goes a long way now. For some reason he's also forking urllib2 in there, which makes things more complicated. My bet is porting would end up uncovering a lot of string handling bugs, and in the long-run make Calibre better.
&gt; ...Michael Kennedy has an **amazing** podcast.... I wouldn't go *that* far. I get a lot tired of him harping on 2-vs-3. Python wanted everybody to use it, and when they did, and it became mission critical, Python decided, "Uh... We gotta change a bunch of stuff that will break compatibility." I use a $10,000 program at work that has Python 2.7 under it, so that's what I use.
You should be surprised, and worried. If you couldn't think to Google it, where the fucking literal first result was the answer, you should rethink learning Python.
It's already taken.
Yep, I work with the FreeCAD project and we need PySide 2/Qt for Python to be released because we're LGPL-licensed.
Just be careful that your program will also need to be GPL licensed. I'm pretty sure pyfftw can't actually be BSD licensed like the author says, because it is just a wrapper around the GPL covered FFTW3 library, and the FSF is very clear on that a wrapper is a derived work. But complying with the GPL is actually not hard, you just need to make sure that whoever uses your software has the same rights as you under the GPL, basically, the right to source code and distribute modified versions. If you are the only user of your software, that's automatically given. If you sell the software, that's also ok, you just need to make the source code available and allow others to make copies and sell them as well.
Arrayfire has a python wrapper to speed up the computation of ffts by shifting it to the GPU. It’s not a straight drop in for NumPY but the syntax pretty close and isn’t too difficult. 
Thanks. I agree, unless I want to pay $12,000 to MIT for commercial use of FFTW, which is FFTW's [offer (1.4)](http://www.fftw.org/faq/section1.html). I don't understand how that co-exists with its GPL status.
&gt; Have you considered a boring old relational database for this? Not web scale though /s
true, but it was taken well after any of these projects were released, and provides an abstraction layer for them.
Honestly I think you're going to be perfectly fine with mongo + ES if you create your ES cluster with enough machines and storage. I worked with data at this scale and with just 4 mongo nodes I had one collection with about 500 million records that worked just fine. ES is super fast too of course, and can easily store large scale data if you have enough machines on it. Make sure you're doing operations in bulk whenever you can. I often see people do something like this: 1. crawl a page 2. pull out every URL from the page 3. for each url, do a mongo insert This is incredibly slow compared to a bulk insert. Make sure you do that whenever you can, chunk up large operations into manageable bulk creations/updates and do as much as possible instead of one by one by one. The sequential method works initially, and for a while, but it quickly becomes your bottleneck and this is how to improve speed by 10 to 100 times or something around there. Same goes for SQL for that matter. Working on a django project lately, and I sped something up a ton by changing the workflow of something to figure it all out in advance and run a single Model.objects.bulk_create rather than tons of Model.objects.create sequentially. The logic can be tough sometimes but it's the only way to do it at scale down the road. You're going to want to google up on creating sharded mongo clusters and ES clusters and make sure you have the disk space and hardware for this. If you're doing it in the cloud, latency will be a pain in the ass but it's easy to throw more CPU/memory/disk at it also, and there are cloud services that will scale as much as you want without you worrying about maintaining the db. I'd read up on your options there for the most part, because this is less of a python problem and more of an infrastructure/ops problem. Btw, just throwing in a plug since this is almost done, but I've got a Mongo ODM i'm getting ready to release: https://pypi.org/project/dongo/ https://github.com/johannestaas/dongo It's up, but it's not 100% done to the point where I wanted to advertise it. It's a Mongo ODM that's inspired by Django's ORM, but also with some fake relational functionality so you can drop references to other records in other records and stuff like that. It works, and you can do stuff like this: User.filter(username__regex='azhar.*', age__gte=20).first() ... obviously pulling from the django ORM style. It's just the django ORM style, and wasn't built to integrate with django necessarily. Next up is wrapping pymongo UpdateOne and those sort of bulk operations to make it really easy to do the kind of bulk operations I was talking about, and then maybe aggregations, but it's usable as is.
What is Postgres not good for?
&gt; Qt for Python uses a different method of binding to Qt, which has its own set of advantages and disadvantages. Do you know enough details to elaborate on this? I know PyQt requires a companion product called Sip to bridge into C++, but I don't know how it works, either. 
Web scraping is usually against ToS for individual sites \- it's technically legal to pay other people to do it but that doesn't mean the site allows it.
Thank you.
It failed to cook my hot dogs last night, unfortunately :( But other than that, yeah, it's pretty solid. (In all seriousness, I use it for just about everything now that jsonb is fully baked...simple relational schemas, complex ones, document stores, gis/spatial processing, even a cache when I was feeling too lazy to stand up redis...I wish WordPress supported it and then I could ditch MySQL entirely!)
Interesting n what is ToS? Do they have a site of something I can read up on?
Like Pretty Printer: https://www.youtube.com/channel/UC-QDfvrRIDB6F0bIO4I4HkQ 
[removed]
I thought this post was going to be nothing but a link to that.
Great books are effective Python and fluent Python. Code complete and clean code are great for how to write the best softwAre in general 
Pay attention to detail. I find that the people who are consistent about otherwise mundane things like naming conventions, comments, whitespace/indentation, etc. are the same people who write good code in the context of more important facets like maintainability, extensibility, and readability.
If you have to ask these questions then it's definitely not a good idea to write security code yourself, and even when you're an experienced engineer the recommendation is always to use industry accepted libraries to handle the security work. Use a third party service for the credit card handling. If you want key-based encryption RSA would work.
I found a simple .csv dataset for %cloudiness in a month globally gridded dataset over the past 100 years in 0.5 degree resolution, and I've manipulated it and am interpolating the lat/lon coordinates for an area of interest (which I reverse look up using googlemaps api) to plot the average days of sunshine, +- one standard deviation, and max/min years as it varies in each month out of the year. I've been doing it for my own curiosity, since the amount of sun an area gets is more important to me than temperature/precipitation, and data like this is only easily accessible for big cities. Finding some cool results! I plan to work on a GUI for it next to integrate with the plotting capabilities, rather than having to set everything up at the beginning of the code run.
I would definitely use postgresql for this.
A billion records is nothing. Postgresql wouldn't even blink at that.
You can look through the `sys.path` variable to find locations that python will look when attempting to import modules. When you have module `X` you can look at the `X.__file__` variable to see what file that module came from. 
Maybe a silly question, but how can you check for existence without reading?
You are about to embark on a very exciting and rewarding journey. Your attitude and perspective regarding this is very good. Far too many make the mistake of thinking their education taught them all they need to know. One of the best skills to have as a developer is to be able to objectively identify and evaluate problems and to not overestimate their own abilities. With that being said many of us bounce between thinking "I am a God" and "I have no idea what I'm doing" on a daily basis. :) Don't be afraid to make mistakes. Make sure you learn from your mistakes and don't repeat them, but do not be afraid to make a mistake and if you do. Own it. You just learned something. That's good. Enjoy the journey. :)
&gt; I opened Command Prompt (Win 10 Pro) and typed python, and it gave me the interpreter. In other words, you typed `pip install praw` into the Python interpreter, not the Command Line. 
Wow. Okay, thanks bunches.
No read on the Python side. Database still requires an index lookup.
What is Postgres?
Someone downvoted this....why? lol
that’s only because your ML algorithm classified it as not-hotdog
Unless you need to have people ssh to the server, and run the script on some actual data on the server. Then you are in bindmount-hell trying to come up with a convenient way to get arbitrary data into the container that isn't insane, or horribly slow, etc. Way easier to say `makegraph /shared/somedatadir` than "Ask Dave to put you in the right groups on that server to run Docker. Then `sudo docker run someimage -it --some mount:details` Then `makegraph /bindmounttarget/somedatadir` Oh, that didn't work? Hm, there's a bunch of moving parts, so let me see if somebody build the right Dockerfile and pushed it to the right registry, and then it got pulled..." I know, just running code on a computer is considered pretty exotic these days...
MongoDB is web scale
https://www.postgresql.org You poor, poor soul. It breaks my heart to think you're using mysql. :*(
I only trust Nigerian princes
You can use GPL software commercially, you just need to give your customers the same rights you got. Some internet routers for example provide the source since they run Linux. Since MIT is the author of FFTW, the can release it under whatever terms they choose; they chose to provide it under two diferent licenses, a free GPL one, and a "i want to use it in a non GPL program and are willing to pay for it" one. 
I would not recommend that. Like, at all. You have a paying job now. Learn about the code structure at your job. Write unit tests for code you develop on the job. Ask coworkers for feedback. You have a lot of learning ahead of you. Why would you divert your energy? 
Checking if a domain exists can be done much more quickly than log n with a bloom filter which is now supported out of the box in Postgres. Should be amortized constant time. 
Apologies if I'm preaching to the choir, but from my observations, the discriminator tends to be understanding OOP principles; using classes instead of multiple almost-identical procedural scripts; PEP8 (!).
+1 Corey Schafer. I love his videos and he seem to break things down really well. I recommend him for sure.
PyCharm has been claimed
Exactly this. Python is a tool. Would any carpenter want to market himself as a Professional Hammer-User? 
If you extract the zip into a folder that you have write permission then you can install anything you want. I suggest looking into virtualenv and virtualenvwrapper to separate out projects. 
I've never run pythonw because I never need to. Python.exe is all you need plus virtualenv of course. 
Shards are the secret ingredient in the web scale sauce. They just work.
What's wrong with Elastic Search? It scales well, why is this a problem to keep using it?
This would make a great interview question. You're going to be reading this information over and over again, so you're going to want a cache like Redis, not just PostgreSQL.
You sound like a web programmer.
Don't identify yourself as a **Python** software developer. Identify as a *software developer*, with Python skills. Your skills are in developing software; Python is just a tool.
Why’d you add quotations to “world”?
Hmm. Yes, but does the UI become unreactive while you are sleeping? Try making the sleep long and see if you can do anything in the UI while sleeping.
You forgot to add a space after “Real”.
Yeah, I realized that myself as soon as I finished writing "world". Hopefully no one noticed tomorrow!
Just add a comma after the closing ".
Oo good call! 
Useless use of classes for what should be a function call. You’re ready for enterprise. 
Should it be Uconn2018.graduate()?
Currently making the same transition in a different stack. It's the same experience no matter what languages you're working in.
You would need a @staticmethod for that
What are the main selling points that make it better than MySQL? MySQL has been my current default, but I'm new to relational databases, so I'd like to hear why postgres is preferable. 
Are those tabs or spaces?
lmgtfy: https://www.python-course.eu/python3_decorators.php
@staticmethod
This disadvantage of upping it to a power of 2 means you introduce high frequency noise unless you're padding a hammer hit (so something that's 0s anyways). It was super important in the 1970s, but in my opinion, it's not really slow enough to corrupt the signal unless your data stream is huge.
Thanks so much! This link even shows me how to create my own decorators, which solves everything! &gt; lmgtfy You're definitely right. But thanks for the great link!
It's mostly a side project but yes I am inexperienced. Anyway, thanks I'll look into rsa.
Congrats, but the indentation is wrong [https://www.python.org/dev/peps/pep\-0008/](https://www.python.org/dev/peps/pep-0008/)
[Mysql does...](https://dev.mysql.com/doc/refman/8.0/en/blackhole-storage-engine.html)
I don't need the codes but thank you very much for doing this!
You overrode the + operator as a new line character? That's terrifying... but brave.
Uconn2018.graduate() ? hat.on : hat.off
I would do this for the DigitalOcean credit alone ... but the PyCharm \+ Postman \+ Gitkraken stuff is also amazing.
Or just pass it any argument. 
Should inherit from object...
[It better be 4 spaces.](https://www.python.org/dev/peps/pep-0008/#tabs-or-spaces)
An @command is a decorator which is just a higher order function. Search up higher order functions in python and you will find what you're looking for.
women = [ { name: “Megan”, lastName: “Car” }, { name: “Kelly”, lastName: “Shanda” } ]
Doesn't the argument have to be of a Uconn2018 object, else the interpreter will error?
No, UConn2018.graduate(x) will just bind x to self inside the the method. Since it's never accessed anywhere it should still work.
No, UConn2018.graduate(x) will just bind x to self inside the the method. Since it's never accessed anywhere it should still work.
print("Hello debt payments!")
A property that the discrete Fourier transform takes advantage of is that the time signal that the frequency content of your data repeats beyond your original signal. If I take the last point of a single sine wave that has a value of 0.5 and force it to 0 on the next point, I introduce high frequency noise. For a real signal, I do that for all of my frequencies, so I have a lot of high frequency noise. The signal from the force/acceleration of a hammer strike/shock load is an impulsive load that is inherently 0 padded, so it doesn't matter. The fast Fourier transform is just a special algorithm that takes advantage of powers of 2 to speed up the calculation, but it's not the only one. Take your data in the frequency domain and convert it back to the time domain. If you did it without 0 padding, you'll get your exact signal back with no loss of information.
Sentdex is awesome! His style of teaching is very clear and relaxed. 
Apparently what I'm referencing is a Py2 thing, and they got rid of it in 3: Python 2.7.10 (default, Jul 14 2015, 19:46:27) [GCC 4.8.2] on linux. Traceback (most recent call last): File "python", line 5, in &lt;module&gt; TypeError: unbound method f() must be called with test instance as first argument (got int instance instead)
Or just print whatever that is. This is inefficient code.
I’ll use 4 spaces when hell freezes over. 
I echo the sentiments in another post elsewhere in the thread &gt; "python software developer" isn't a thing. You would be a software developer, period. But your message here is a strong one. If you aren't already a part of a mature coding environment, an enormous step to writing better code and understanding the environment outside of coding to get from point a to point b is building your own experience with a complete code base. Participating in a large open source project is great. They typically have a process for submitting pull requests and have identified low hanging fruit for new contributors. Things like adding tests, documenting existing features, and fixing bugs that are simple but nobody has time to address. When you submit a pull request, it will get analyzed by whatever CI solution is in place. Some projects enforce style. Some will do some sort of static code analysis. Some will report on how your pull request affects documentation or test coverage numbers. It's not unusual for a pull/merge request to get rejected right out of the gate. When you manage to get through the automatic analysis, people will review the code, often with a very critical eye. Not because they have crazy high standards, but because they are ensuring the codebase they help to maintain meets the community standards. It's not just one developer running code, it's a team of developers maintaining it, and a bevy of end users consuming it. In the end, contributing to open source does a great deal of good for your maturity as a developer. Your eyes are opened to a wider variety of concerns than you are faced with as a junior developer in a corporate/enterprise environment. You can do this on your own on a pet project - build CI and throw some elements to verify your code, but there's a learning curve to help identify what's important, let alone the learning curve for whatever CI system you want to start working with. And man... figuring out how to make some CI systems do their job could frustrate a junior developer enough to seriously question their career choice. Having that experience makes you better. You start thinking differently. The question you are asked frequently is "can you do x"? The answer is almost always yes, but with experience you start asking the questions like "is x a good idea?", "has this problem already been solved?", "what SCM system am I using?", "how would I distribute the solution?", "how do I test the solution?", "where is the documentation?", "what kind of documentation do I need to build?", "do we have coding standards?", "do we have testing standards?", "how do we find out about bugs?", "how do we add new features?" one more semi-related note... There are people who screencast their workflow on open source projects. I wish I could recommend one, but I don't watch any with regularity. I admire them - because my workflow of swear, type, run test, look at reddit, swear, type isn't broadcasting material. Finding a good one opens your eyes again. Sometimes you see new tools or libraries. Sometimes it's just good to see how people do things. It doesn't have to be focused on any one language. Just watching someone good code for a bit is helpful to me as a pretty senior developer. I wish I had something like that available when I was younger. 
&gt; Not sure where you got the 12,000$ from. FFTW
You missed David Beazley, He might not be a core Python developer but He gives great presentation too. Yeah Reymond is very cool, I like his style a lot!
[....](https://i.imgur.com/0Ku7TXv.jpg)
What about tabs that convert automatically into 4 spaces?
Is there any use in these for a beginner whose learning python for 2 months now?
Or have a friend's hat throw an exception.
Working on a reddit scraper that allows you to scrape a subreddit for images/gifs and automatically converts .webm, .mp4 and .gifv to .gif . It's pretty much finished but I need to just polish up a few things, add a controlable nsfw filter, increase performance speed and documentation. The main problem in performance speed is converting to .gif without losing a lot of quality, this takes ages and I'm at 50&amp;#37; compression ... by ages I mean a minute or two for a long webm or gifv. Overall I'm happy with the project so far, especially since I adopted a factory approach which allows me to add more parsers easily. I have parsers for reddit \( does the actual link scraping and handles [i.redd.it](https://i.redd.it) links and normal image files \), gfycat \(handles gfycat links\), imgur \(handles imgur links\) and reddit\_list \( which scrapes subreddit links from a reddit list site \).
Are you looking to simply perform the analysis or make an app? The analysis is fairly simple using QGIS... I would look at Leaflet if you are creating an app.
Im still a noob myself, as I only started learning one month ago. But i think you could Look into into regex and search 
Thanks for the response. I was hoping for a different answer than it's impossible but that's the same conclusion I've come to. It's actually a tool which can provide some utility for hardware. The idea is to have a file or mutliple files baked inside the application which can be used either for a period of time or by use. The only way I figured it would work is if it was triggered by a token which would need to be verified online. Then it would allow the user to store credits for offline use which is important for this use case. I don't believe the solution I'm looking for has been solved by anyone yet. I think it's a similar problem the music and movie industry face and would solve if they could. The only solution from that industry was streaming which means always online. However now that I think of it Netflix now allows you to download and store content locally on your device. I think what I'm after is obfuscating the data or building the app in a way which makes all parts integral so it would be hard to tamper or disable any one part. Have you ever come across any material or programming books which discuss this???
1) The URLs will be used to determine the website score just like Ahrefs have Domain Trust, Moz have domain authority as it will help us in analyzing the score for each domain. Later on, this score would help us in presenting a better search result from our search engine based on the score. The website with lower grade score will not be showing in our search engine for top results. 2) The Read/Write heavy load would be similar as we will be doing the lookup if the URL already exists or not, if not add it to the table/index. 3) Yes, batch processing would be done to calculate the score for the domain on a daily basis.
Thank you for the suggestion I will look into it and happy learning to you, I am having a lot of fun with it so far.
First of all, thank you for writing up a detailed answer. 1) While doing operations in bulk, you still have to ensure the URL does not exist in the collection/index, otherwise, it would keep pilling up the repeated URLs in the collection/index. But, you are spot-on the bulk insertion operation would drastically improve the performance 2) For MongoDB, we have a simple replication process with the arbiter as of now. While you were running MongoDB, adding shards to the MongoDB improved performance for your queries on your end? 3) Cloud solutions like GCP/AWS come with Bandwidth Pricing cost, it can easily add up thousands of dollars to your bill, they can easily add thousands of dollars of bills in extra while doing the crawling at a very large scale. Especially, when your crawlers are distributed in the different datacenter. IBM Softlayer comes with 500GB bandwidth for their high-end dedicated servers and GCP charges you 0.12$ per GB so the numbers of bandwidth go in TB when crawling and storing the data.
The general term for that kind of thing is 'Digital Rights Management', aka DRM. It's not a very popular topic on the internet. A lot of this depends on who your target market is and how valuable the credits are. Most reuptable businesses will be happy to pay reasonable fees rather than hacking your code to get it free. If you want to sell to bored teenagers, the time/legality/money trade off is very different.
They're spaces! I know that 2 spaces goes against PEP8, but boy was it hard trying to do 4 spaces on a cap
Maybe a namespace thing? Could have been a classmethod, though.
Nice synatx highlighting. What does the theme called? ;)
That's what people mean when they say 4 spaces. Virtually no one actually presses space for indenting (unless trying to align things).
Congratulations on your graduation.
This would actually be really funny. lol
I can send you my pycharm key if you want. I dont need it
Congrats fellow UConn alum!
Thanks friend! Go Huskies!
Most of cool offers in bundle are for new users only. That's really shuts the deal off.
Goddamit you missed a comma.
As for the first, please fix post with code \([check reddit's formatting](https://reddit.com/wiki/commenting#wiki_posting)\), so we'll have something to work with :\)
Numpy/matplotlib to quickly document/vis ML research results. Nothing nuts but when I realize “oh, I guess this parameter tweak is actually a different experiment and result, and needs to be documented,” it stacks up very, very quickly. 
Notepad++ does support plugins now, that add new features like spell checking, connecting to FTP servers, or copying formatted code to the clipboard.
You forgot to filter for students that didn’t complete the grad requirements :)
Cast from int to str is quite expensive operation, and strip also, cause it create new string w/o stripped value. You may try to calculate zeros at the end by analysing incoming number. All ending 0 caused by multiplying \`5 \* 2\`, there's more numbers which has 2 as it's multiplier rather then 5, so we can focus on calculating how many 5s is in the number, as example: \`5! = 1 \* 2 \* 3 \* 4 \* 5 = 120\` so, number of zeros will be \`5 / 5 = 1\` \`25! = 1 \* 2 ... \* 24 \* 25\` \- here's more complicated example, cause it has 25 which is \`5 \* 5\`, so we need to ajust original consept. As well as 125, 625 and so on. For this one it will be \`25 // 5 \+ 25 // 25 = 6\` So first non zero digit will be \`math.factorial\(25\) // 10 \*\* 6 &amp;#37; 10 = 4\` As final example number of zeros for 492: 492 // 5 \+ 492 // 25 \+ 492 // 125 = 120 And first non zero digit \`math.factorial\(492\) // 10 \*\* 120 &amp;#37; 10\` which is 8 Some dirty code to calculate number of 5s in number: def five\_number\(num\): count = 0 i = 1 while True: acc = num // 5 \*\* i i \+= 1 if acc \&gt;= 1: count \+= acc continue break return count So to print out the first digit: print\(math.factorial\(num\) // 10 \*\* five\_number\(num\) &amp;#37; 10\)
 &gt; 5! 5! = 120 &gt; 25! 25! = 1.5511210043330984e+25 
TIL. I knew that unbound methods had been removed; but I hadn't clocked that this would eliminate this restriction.
For the stdlib code, yes. Pep 8 is for stdlib style, and choices like that are up to the individual project
Spoiler: 3D Color LUT transformations \(the technique used in this article\) will be available in Pillow 5.2.0. Hald images support available in this library: [https://github.com/homm/pillow\-lut\-tools](https://github.com/homm/pillow-lut-tools)
cffi is strongly recommended for pypy.
Better yet, @classmethod
thank you very much for your help! IDK whats with this reddit formating... when i go on phone, it'd displaying really weird but when on pc it looks fine. Anyway, I reworked the program using your code and it works (it gives the right answers), but again, on first two test cases it works in time, on the third test case i get the time limit error again...
Isn't this what ES is for though? I work at a company where I have the luxury of launching more nodes/instances virtually limitlessly, so maybe I'm just privileged... but billions of documents is nothing for ES if you have compute power to throw at it.
What kind of heathen doesn’t do that?
What website do you find these good screencasts on?
There is no reason OP cannot do both, e.g. open source stuff on their own time. Working on open source shows an interest in the language and an interest in learning it and becoming better. I just got a lot of praise in my annual review for doing this. It's not diverting your energy, it's putting more energy into the same task.
Sure, but IIRC the commands have largely been written in another scripting language then pulled into C when needed.
Depending on your requirements, the [opensource graphhopper](https://www.graphhopper.com/open-source/) could be an option.
What IDE is that?
A staticmethod
That would be worse
My requirements are basic, I need a street lookup functionality in my program, so very basic, as long as it doesn’t have many limitations in terms of number of entries available. Thanks for your suggestion, I’ll give it a go.
Enjoy [Jack Diedrich - Stop Writing Classes](https://youtu.be/o9pEzgHorH0)
Enjoy [Jack Diedrich - Stop Writing Classes](https://youtu.be/o9pEzgHorH0)
Hm... Ok, let's try to use sys.stdin instead of input\(\): import sys import math def five\_number\(num\): count = 0 i = 1 while True: acc = num // 5 \*\* i i \+= 1 if acc \&gt;= 1: count \+= acc continue return count def first\_non\_zero\_digit\(num\): return math.factorial\(num\) // 10 \*\* five\_number\(num\) &amp;#37; 10 for num in sys.stdin: if num == 0: break print\(first\_non\_zero\_digit\(num\)\)
Hahahah, so clever. You rock!!!
already tried it before and got run time error (i also got run time error using your version)
If you're still using py2 versions, you're wrong 😉
Perfectly balanced
Yes, 110% of computers in the world are running python 3, correct.
[Windows Scheduler](https://desktop.arcgis.com/en/arcmap/10.3/analyze/executing-tools/scheduling-a-python-script-to-run-at-prescribed-times.htm) ?
Visual Studio Code
Vim user for many years, but I switched to Pycharm (with Vim keybindings) and never looked back. Super-integrated with the language.
That's not what I said... Py2 is at EOL. I understand systems still run off of it, I ported my own worksystems to 3. Continuing to run py2 is going to be more of a PITA than the work of porting to 3 as time goes on. 
That was my best bet, at the moment :\(
Congratulations!
Congratulations!! Very clever. 
I am working on a freezed bottle server to do crud and business logic as my institution solely runs on Windows iis server and does not want to offer me run time. As such my data is distributed access our Network drive in different sqlite dbs. The project is getting very complicated with gevent being thrown in there as well. Some of the requirements are to make it light weight, fast performance in terms of io and reporting. Learning c# is not an option unfortunately, I have too much on my plate to do it effectively. Any tips on how to get boneheads to spin up a Linux vm instance to deploy an easy to build Django app is appreciated. :)
Sure. My main work environment is Python 3.6 (anaconda 4.5) on windows. There are a couple of libraries that aren't fully compatible like some of the machine learning tools, and it takes a little bit more effort to set up a C compiler to compile/install cython, but for the most part it works just fine. Just make sure your path environment variables got configured properly after you install a python distribution. It's good practice to get into writing cross-platform compatible code, for example using os.path.join() instead of manually specifying the separator.
Your graduation cap does not follow PEP8 standards 
Whelks maybes? Bridge took too long to navigate? Fed yourself to a fake bear perhaps? Could be anything really!
Sorry, but I meant in a programming-testing way. Say I write something and want to test it with 50 different arguments, how can avoid calling the py program 50 times manually? Hope it makes sense!
1) Congratulations 2) That's a cool idea, my graduation cap was not nearly as clever. 3) You have really nice hand writing, kudos. 4) Congratulations again!!! :)
Powershell also supports loops. The relevant manual pages Get-Help about_Arrays Get-Help about_Foreach Get-Help about_Splatting You can define your arguments in the Powershell script: $ArgumentList = ( ('arg1', 'arg2, 'arg3'), ... ('arg1', 'arg2', 'arg3')) Specify the location of your script $PyScript = 'C:\...\your_script.py' If the Python-Executable is not on your path you can define one more variable $PyExe = 'C:\...\python.exe' and then use the `&amp;` Call/Invocation operator foreach ($ArgList in $ScriptArguments) { &amp; $PyExe $PyScript @ArgList } or the `Start-Process` cmdlet foreach ($ArgList in $ScriptArguments) { $ArgList = @($PyScript) + $ArgList; Start-Process -FilePath $PyExe -AgumentList $ArgList -NoNewWindow -Wait}
Looks like a Java fsnboy.
!Congratulations
That is more like what I was expecting. Thanks!
Nah a comma
&gt;&gt; Hello RealWorld
If it turns you into the type of person that thinks you're able to critique someone's wider coding abilities based on 5 lines stuffed into the frame of a hat, then I think it should be avoided like the plague. Somehow I think that trait is specific to you though.
https://groups.google.com/forum/#!topic/python-ideas/CFuqwmE8s-E
Yeah, I was more interested in the books and courses. For me, it was worth it. I could see how it's not for everyone though
Right? I also saw the Fluent Python book at the end, decided to pay the $20 right there. 
Oddly not, I thought so too. &gt;Python 2.7.10 (default, Jul 15 2017, 17:16:57) &gt;[GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.31)] on darwin &gt;Type "help", "copyright", "credits" or "license" for more information. &gt; &gt;&gt;&gt;print("Hello Real""World") &gt; Hello RealWorld
Best advice is burn the place down and switch to linux, but pick your battles I guess.
Postgres will wake you up with coffee and buttered toast.
You have many options. As you suggested, Powershell and Batch files are the most obvious way to go, being that they are the native scripting languages supported by Windows. You can also [Install Linux inside of Windows 10 using the Windows app store](https://docs.microsoft.com/en-us/windows/wsl/install-win10). You can also install a bash shell with many of the same linux utilities you are familiar with by [installing MobaXTerm](https://mobaxterm.mobatek.net/)
See https://github.com/EnterpriseQualityCoding/FizzBuzzEnterpriseEdition
I dont see how this would solve my Problem but thanks anyway.
/r/learnpython
I see people recommend https://automatetheboringstuff.com The book is free to read on the site but u can also purchase the hard copy and ebook. He also made some youtube videos for some of the chapters
I didn't this was a bad joke at best.
he did added the space, but between a and l `Rea lWorld` 
Print("and this isn\'t?")
Oh I agree he should evaluate all options. I was just pointing out that a properly indexed lookup in a modern relational database can support hundreds of millions if not a couple billion without too much effort. It's fair to say 500ms response time might be a bit slow, I put that out there because im familiar with vertica. It's designed for few large queries as opposed to many small queries as the query planner has some overhead to support multiple nodes
Easy mate. Go check which python NASA uses more than the other. https://code.nasa.gov/?q=python
I'm surprised this wasn't everyone's first thought. This thing isn't going to run!!
It might be perfectly fine - but depending on use-case and how much the data is likely to grow (if it'll start with 1 billion, it could become 2 or 10 billion by the end of next year), etc, any particular solution might turn out to be poor. At that scale, I absolutely would make a full study before migrating instead of relying on anyone's guess, even if it worked wonders for them in particular. I'm not a DBA and my database experience is very limited. I trust everyone here saying that PostgreSQL would handle it beautifully, but still, I'd make sure to run a number of stress cases on it before making the jump - anything from data scalability to network congestion to backup times.
Thanks for clarification was reading your comment from mobile so mb. I will look into your suggestion when at home. Thanks!
Why's that? Shit my first thought was @classmethod. Fuck
Still a string without anything changing so it parses fine.
My thoughts exactly.
Okay, welcome!
Yeah, Visual Studio Code. Highly recommend it, very fast launch smooth interface. Plugins for anything you can imagine, and supports almost every language.
Static methods enable calling the method on a class directly without having to make an instance of the class. Class methods are meant for different purposes, eg for an alternative class constructor.
Oh, my mistake. I was thinking they were accessing UConn2018.graduate without creating an instance. I see the sneaky parentheses now.
I am not. I am referring to Visual Studio Pro 2013, of which I have a license. I have the Python component already installed on it. It is a different animal than VS Code. Leave it up to Microsoft to confuse people about a flagship product.
"[Django](https://www.djangoproject.com) is a high-level Python Web framework that encourages rapid development and clean, pragmatic design. Built by experienced developers, it takes care of much of the hassle of Web development, so you can focus on writing your app without needing to reinvent the wheel." 
hey, you override the menu and you need to use text.selection_get() https://pastebin.com/raw/QwKDyBzn
I understand what I measured. I didn't know you cared. I did the test a few years ago at this point with an SSD of a Nastran OP2 SORT1 Fortan formatted binary file that was 2 GB and was located on my local computer. It's an OP2, so it can't be stoted compressed like an HDF5 file; it's just a boring binary file. I don't know about the fragmentation, but I'd expect it wasn't very high. It's file reading, so I use 1 processor and typically and not reading large files from the SSD, so nothing was competing for resources (other than say Windows and my IDE). It's a bad test if the test is not repeatable, so I don't test with many programs open or a file transfer in progress. I test peak performance of a realistic output file under easy to recreate test conditions. I new the number well enough that when someone ran with a 60 GB file and the speed was linear at 500 MB/sec still (so two data points). He dumped some data using scipy to get to matlab, which had a problem that he assumed was the fault of my open source package. I suggested he used HDF5 and it was fast again (and do more detailed timings). A company I speak with that's not mine has a competing product that reads this file format (along with doing a lot of analysis). Their reader is written in C++. Mine is faster than theirs by their own admission. To their credit, they were the ones that found out what python could really do and told me my code was 100x slower than it should be. I dug into a test problem with a simple code they provided and found out why it was fast (it wasn't for the reason they said). I then incorporated it into my code.
Nice, just checked it out and am already liking it. Been using Atom mostly but this seems to be more robust in features. Thank you. Great video too.
Where should i edit?
But the book i am reading is using sublime text and i want to follow it step by step
Have you looked at the sidebar?
Thank you very much for this! I appreciate ya taking the time to teach me something new.
As for someone who have never programed in 2.7 \(started on 3.3\), I found that discussion not that interesting. How ever, I understand there are pretty huge corporations and colleges based on 2.7, so probably it's worthwhile mentioning. Regardless of that, Talk Python to Me is awesome for me. The place where there's a lot of 2vs3 is in Python Bytes, which I also really like.
&gt;a lot of videos about bitcoin I used to love Siraj until that. His AI videos are awesome, but all the blockchain stuff is kind of boring.
No problem. Simple explanation for each: - staticmethod: allows the method to be called on the class itself without the need to make an instance first. An example use case is a possibly standalone function that is related to the class but does not need instance data, so we lump it onto the class because that's where users expect to find it - classmethod: alternative class constructors, typically with names starting with "from_". Do you have a class that is normally instantiated with an integer, but it should also somehow work with decimals and floats and strings and dicts? Let's not have an init with a bunch of ifs. Instead, we can have a simple init, and additional classmethods that provide alternative constructors (all of which ultimately call the simple base init)
&gt; Since MIT is the author of FFTW, the can release it under whatever terms they choose Does MIT have the legal authority to retract the GPL license? I.e., could MIT withdraw permission to the public to use FFTW for free? My question here has no practical relevance, it's just something that's confused me for some months, and you sound like you might know the answer.
print(int(str(num)[0])*2) ;-)
[Here](http://lmgtfy.com/?t=i&amp;q=python+icon+svg)
Just use pytest
Yes, but not retroactively. Any new releases could be under any other licence, but old ones would always be covered under the GPLv3.
#wyr = a list, and wyr corresponds with wyrqna.csv #I want wyr[n][2] and wyr[n][4] to replace whatever is inside my csv file corresponding to [n][2] and [n][4] with open("wyrqna.csv","a") as my: my.write(wyr[n][2])#Blue my.write(wyr[n][4])#Red my.close()
#wyr = a list, and wyr corresponds with wyrqna.csv #I want wyr[n][2] and wyr[n][4] to replace whatever is inside my csv file corresponding to [n][2] and [n][4] with open("wyrqna.csv","a") as my: my.write(wyr[n][2])#Blue my.write(wyr[n][4])#Red my.close() Hi, I still don't get it, the code it above. I have never used append with csv files. Thanks, FearRec :)
#wyr = a list, and wyr corresponds with wyrqna.csv #I want wyr[n][2] and wyr[n][4] to replace whatever is inside my csv file corresponding to [n][2] and [n][4] with open("wyrqna.csv","a") as my: my.write(wyr[n][2])#Blue my.write(wyr[n][4])#Red my.close() Hi, I still don't get it, the code it above. I have never used append with csv files. Thanks, FearRec :)
Or `pathlib` for that matter! 
ok :)
Of course. Do it on company expenses if possible. I personally found a great ammount of inspiration reading open source code.
The Hell to which I was referring was implied. I’ll flaunt PEP8 at every turn!
Oh god I feel nauseous
Hey I was wondering does this one video go through the whole shibang in 40 minutes? Just wondering because that is a lot of ground to cover in a short period of time. I watched the first few minutes and it seems to be pretty informative and I will likely watch further when I have more time. I've been using flask recently and have learned a great deal for a work project (with plenty of python and web dev experience to start with). Do you think someone like me could learn a thing or two? Or is it more focused towards beginners? Either way I think it's a good video and I hope it helps some people out. 
You could make it a static method. No need to instanciate an object, just to call the method.
Why isn't this a class function?
https://github.com/pyload/pyload
Do you really sign every reddit post like that? The `with ... as ...` idiom does whatever within its indentation then automatically closes, so you don't need `f.close()`. f.write(','.join(i for i in whatever)) means you iterate through whatever and write i to f with commas between.
Here are my favorite differentiating features: Postgres has [array types](http://www.postgresqltutorial.com/postgresql-array/) for all of its basic types. I used this to store free-form tags in the same table where the documents they belonged to were stored. It also has a [jsonb datatype](https://blog.codeship.com/unleash-the-power-of-storing-json-in-postgres/) that actually enables postgres to understand, query, and index the contents of json documents. Also, I am just a casual database user, but I have a much easier time using postgres than MySQL. Last time I attempted to use MySQL i had a lot of problems with the default settings that I apparently would have to fiddle with to do what I wanted. Then I decided to try this postgres thing I had heard about before spending a lot of time figuring out how to make MySQL submit to my needs. Postgres just worked right out of the box and I never looked back.
Hey, I'm sorry I need to reread what you said and complete it, I had an urgent problem to fix so I had to dive into ansible -__- I am going to upvote every of your answer and do what you said :)
Oh wow, I didn't know about the arrays. That sounds so useful for a project I'm working on!
They could only do that for all future versions. If somebody has downloaded an older version, that version will still be under the GPL.
Interesting, thanks.
Thanks.
Best joke I heard all day
This does not deserve to even be in a class. 
No use of self. Method could be written as a function.
Digital Ocean is claimed. I also forgot to mention i got a course on pycharm for beginners.
Despite /u/nevus_bock's correct explanation of classmethod, there's no downside to using classmethod in place of staticmethod.
Youtube or twitch. Here's an example of one I liked a lot: https://www.youtube.com/watch?v=9FBvpKllTQQ But you know... personal preferences being what they are, if you don't like that one, search around for more.
In addition to kaggle, check out quandl and fred.stlouisfed.org for financial information
Pytz
I thought this didn't support Upstore Premium?
Got the digital ocean code from [u/Oomuu1](https://www.reddit.com/user/Oomuu1) and it worked! thank you
Shouldn't there be an instantiation of the class? Uconn2018= Uconn2018() 
Good example. If the rest of the company, say ACME Corp, is using acme.utils.time, then dont use pytz. It will only add an unnecessary incompatibility. 
Just fyi, SoftLayer sucks. They were the driving factor for us to move to our own colo spaces.
ES can absolutely handle that scale assuming the hardware is good and you bulk insert. We on a daily basis ingest around 1-2 bil docs a day at a rate of about 40-100k docs/s without issue.
Is this worth it for someone totally new to Python? I’ve been considering jumping head first into learning it for a while now and seeing an ad for this felt like a sign, but I also don’t want to blow money on books when I might end up giving up after three days or something. I also don’t really want to start off working in a subscription-only IDE because I know that if I was still doing Python after six months it’d be a pain in the ass to switch away from the only tool I’d learned it in so I’d be chained to their fee. If it’s relevant I’m not a good programmer by any means (have never done it as a job or anything), but know (or used to know) some Javascript and once upon a time did game programming in a weird 80s teaching language called Turing (it was what my high school’s programming classes used) that was sort of like Basic with Pascal-esque syntax. I also tried to learn C++ for like a week years ago before giving up. 
Really, Postgres is my choice here too. Gist and GIN indexes for strings ( the url's) allow you to do fuzzy matchin, tri-gram searching etc in a very efficient manner. It scales well up until data sets are many times larger than your RAM, and can handle massively parallel loads. 
&gt;Do you know enough details to elaborate on this? I know PyQt requires a companion product called Sip to bridge into C++, but I don't know how it works, either. I worked on PySide2 for a while, but some bits have changed since I worked on it. tl;dr: PySide uses a binding generator called Shiboken, PyQt uses Sip. They are different and generate slightly different bindings. Shiboken has been changed rather significantly since I stopped working on PySide2, but I believe it is using clang now to parse the bound C++ code, which should make generating bindings a lot faster than it was. They each use different methods of adding information about the code being bound. For example Shiboken uses an XML format to describe the C++ api it is binding, while Sip (AIUI) uses an annotated copy of the C++ header.
Check out [geopy](https://github.com/geopy/geopy) and their [geocoders](https://github.com/geopy/geopy/tree/master/geopy/geocoders), there are many providers ready to use.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [geopy/geopy/.../**geocoders** (master → 1111e49)](https://github.com/geopy/geopy/tree/1111e49d66390afb21fb860903a0fd6e864cdc17/geopy/geocoders) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dyic7e8.)
 import congratulations! from semi_real_world 
Accessing it would probably work even if he didn't instantiate it, but then he would need to supply the self parameter manually
I'm real curious about this too! Yes it's against most site's TOS, but can I still use the data in a way that's profitable (so long as I'm not blocked)? Mainly what I'm wondering... would it be OK for someone to pay me to pull data for them? Or, could I make an app that pulled/aggregated info from several sources (even if against their TOS)?
1) Yeah, this is often the difficulty in doing bulk operations and why the code can get way more complex, but when performance is a concern it's usually worth it. One pattern I usually follow is that I have a list of values of a field I want to be unique, so first I do a bulk query of all documents that might already exist. In mongo this might look like {"url": {"$in": ["http://url1", "http://url2", ...]}} Take those returned documents, and you know which ones already exist. Now you can do a bulk update of those documents and a bulk insert of the new ones with new URLs. It's a pain point, but it can drastically improve performance rather than checking for a 1000 records. I haven't used ES in a while, but I know there's some sort of bulk upsert thing you can do and you might want to look into that. I think you might follow the same pattern, request all docs that might exist already, then do a bulk request where you do doc_as_upsert (I think?) and update some and insert the missing. Of course, if there's nothing new you don't have any updates to do, just inserts. 2) To be honest we never had to bump up the number of mongo instances so I'm not sure what the difference in performance would've been. We started with 3 or 4, and that worked just fine for the two years I worked there (with performance improvements to code and better db usage patterns). That was the only time I used mongo at the scale of having a couple collections of ~500+ million documents, but it was never an issue. We gave them maybe 500GB to a terabyte of disk space each and it just worked. We never got to the point where we had a dev cluster at the same scale with a copy of the data, so mostly everything else was dev data and a tenth at most of the scale of prod. I think they might've been around xlarge AWS instances? Queries were around the scale of tens/hundreds of milliseconds if I remember correctly. Sometimes they went into 5 second range but we fixed that with better code, smarter queries, and adding indexes to the right fields, and creating new indexed fields with computed data that would make the queries easier (for example, if you query your URLs by subdomain/domain often, creating two new fields domain/subdomain and indexing on those). But since infrastructure never became an issue, I can't say what the performance difference would've been for a single large mongo instance. I can say that it could easily handle the scale of hundreds of millions of records. 3) Yeah, if you're crawling the internet, cloud solutions will get expensive plus you might get lots of complaints from people who don't expect you to hit example.org/admin but they had a link to it somewhere, or something like that. Amazon will shut down instances if they get a lot of abuse complaints, but I think that's much more of an issue with port scans than internet crawling. Still, if you do this at internet scale, people will complain and it might be a concern. You might consider getting some baremetal servers at a datacenter with a gigabit link or something, depending on funds and cost of having people maintaining that of course. I'm not sure at what scale you're doing this, whether it's 1 crawler or 10 crawlers or hundreds, but the cloud might get pretty expensive and you might want cheaper bandwidth. Also, one thing you might consider is that your bottleneck is very, very likely to be the latency of servers you're crawling and not db at all. It depends on whether you have a small ES cluster supporting 200 crawlers or something, but if you are at the scale of around 5 crawlers or so, you will probably not even notice any problems with your db performance. It's going to be latency of the sites you're crawling. However that's a problem that's really easy to make parallel since you can just keep spinning up more crawlers until they saturate the usage of your db. But keep in mind that you'll have to be spinning up a ton of crawlers to make db latency even close to a bottleneck. Your primary performance consideration would be to make sure the crawlers crawl as fast as possible in parallel and keep shooting off requests, and db considerations (after disk space) would be secondary. HTTP requests will likely be on the scale of hundreds of milliseconds to seconds, and db hits will be in tens of milliseconds.
QA will catch it
Context: Former PowerShell trainer/automation consultant. Now mostly develop in Python. When I used to train people in PowerShell, my focus was less the commands, and more the adoption of programmatic and object orientated mindset. PowerShell is a great intro to experience these, but often people learn it in a way that neglects these. I recommend Python as I find it an approachable step from PowerShell. For Windows, PowerShell is a great language since it is built on top of .NET so you can interface with all its libraries. The wide range of modules make it perfect for a SysAdmin however you should learn some Python FOR PowerShell because; - It will teach you to approach OOP principles and development that will make you a stronger PowerShell programmer and have to rely on cmdlets less - You will approach problems in different ways, such as string manipulation that make you better at solving problems in code. I use each tool in different scenarios, problems easier solved in Python can be; - Web Scraping (amazing "requests" library) - Statistics/Number crunching - REST API servers (Flask microframework) So keep using PowerShell where it suits (Exchange, Windows, dead simple disk read write), but be ready for Python when the .NET stack is too verbose/tricky in PowerShell, and the Python community can provide elegant solutions. 
It's better than intelliJ and doesn't cost hundreds of dollars. VS code is great. I switched to it 2 months ago and haven't looked back
Good job, very easy to read. 
Thank you very much!
Didn't you watch the damned video? Don't make your own exceptions.
What are your goals wrt learning Python? IMO, there are different "types" or "levels" of programming, you first need to determine what you want to accomplish before deciding on the tools needed to do so. 
For those on 3.2+ (and I think there’s a backport available), I find [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html) much easier to work with than the raw threading module, not to take away from the post - in just pointing it out for those that may not be familiar with it. Specifically I like how simple it is to wait on all background threads (or processes) with `as_completed`.
congraduation
use an AMD K6 2 .. it will cook ur hotdogs
That peak finding function might be very useful for me... But I just compiled scipy 1.0.0 for muy raspberry and lazyness is 2strong
I mean, I guess I would not agree with this. There is plenty of data that is intended to be used within the context of the rest of the website, and is provided to be useful to the user but is not intended to become the source of someone else's database. I think if a website's terms of service say something along the lines of, "You can make use of our data for normal purposes, but you're not allowed to use automated tools to scrape the data." that's a legitimate condition for a website to require. These days, many websites aren't even in a position to "break" — they'll just automatically launch new instances to meet the load. My web servers get hit by loads of bots and spiders all the time, and these are websites that cater to a specific audience, aren't well known, and don't get a lot of normal traffic. I could imagine that for a website with a wide audience and volume, getting hit by lots of extra spiders could mean rolling up an additional server or two.
Spacy will help you analysing the text. Sklearn will help you classify, look for support vector machine. But it wants vectors. i.e., lists of numbers representing your text input somehow. In order to convert your text to vectors you can either come up with some algorithm yourself which sounds reasonable, because you text input seems to be very consistent and homogeneous. Or you can use some sort of embeddings, look for word2vec and glove. Another till that might give you results rather quick is fasttext, which is not python, but you can call it from your Python program and proceed with the result. If you need links or more info, let me know.
https://archive.org/ 
Want people to upgrade to Python3? Maybe don't fucking break back-compatibility between versions. For the foreseeable future, as a computational chemist, all of the code that I'm aware of is done in Python2 because nobody wants to upgrade to Python3. Because it's too much work on the part of many developers out there.
I once worked in a Windows only company. One day I tried to call two consecutive commands in a Powershell script. In bash it's just saving the two lines in a file and source it. I never found out how that was done in Powershell. Maybe I misunderstood the "shell" in Powershell. ps. Didn't last long in that company
Do yourself a favour and install babun. Thank me later.
Thank you!
Or just use "/'. Windows understands it. :)
Those issues are great.
Just learn Python. You will have an additional tool and will be able to decide which one to use for each specific task. I use both in Windows.
Has anyone really been far even as decided to want do look more like?
Or write the loop in your main.py
I really wish I understood the mentality of people that write code like that and thinks its good code.
Wait wait wait...hold the fuck up. I think I might have just gotten some insight into the Tabs vs Space holy war. Did you think that people that use spaces are actually pressing Space 4 times?
And he defs had no room left on the hat
You must be new to Python. Python has implicit string concatenation. Also, when inside a bracket, brace, or parenthesis, you don't need an explicit line continuation via backslash. This means that: print("Hello real" "world") is perfectly valid.
Shebang is optional. You only need it if you plan on making the file itself executable and calling it directly, rather than typing "python myscript.py".
This was my very first post on Facebook more than a decade ago. I got maybe a dozen likes.
Congrats and good luck in the real world!
Sounds really cool, does anyone have any experience using Nuitka?
By using this website you agree... is bullshit and you know it. If you need to enforce it, you make them click i accept before you let them in. By reading this post you agree to pay me $100. 
I mean I'd argue that me policing how you use information I am offering for free is very different than you demanding that I give you money. I think it would be equally problematic if, each time you visited a website for the first time, you were greeted with a giant box of terms and conditions and couldn't view the page until you had accepted them. "This is our data; it's free but here's how we're letting you use it" seems to me a reasonable demand from a website. I doubt that they would have a strong case to prosecute you for infringement of their terms and conditions since they didn't require explicit acceptance. I guess I just disagree with your assertion that you should be able to scrape any website you want to if they don't put up a paywall, or that short of forcing every visitor to enter into a legally binding agreement that you have a right to scrape data they don't want you to scrape. It seems like you might believe that having terms and agreements that do not require explicit opt-in is more shady than using tactics to evade detection as a web scraper, and I guess we're just going to have to disagree on this point.
You could add the __init__.py, run pylint, then remove the __init__.py?
What's the problem? Put all of the modules you use frequently in a single directory and add that to your path once in your bashrc. From your question it sounds like you're looking for a magic solution to make Python imports not be so, uh, rational. 
Look up python virtual environments and global environment. A virtual environment can be made for each project whilst a global environment is for the system. Each environment can have a different set of pacakages and dependencies.
would it be possible to do this via Travis-ci. like if I run pylint via travis-ci on any one of my repo would it be possible to just add a file, run pylint and then remove it ?
With the GIL, it may be for thread heavy (io bound) applications, but for that occasional need - I think the threading bit stays relevant for a while. The good/bad of using async is that you have to then treat the entire application as async - there’s little/no middle ground that makes much sense.
I'm a little ahead of this level in python lol but I enjoyed it immensely. No, do not quit doing the debugging. It is immensely important for beginners (and anyone really) to understand that process and be able to interpret errors and figure out what is going on. That was one of my favorite parts of the video. You're gonna need to get those keyboard skills upgraded though if you want to shorten up the videos. I mistype about as often as you, but it is something that pays dividends to work on.
Can you explain your use case and the need to fiddle with the path? I’ve used python for a decade and manually managed the python path in a single use case - which is in a commonly used Django pattern (the /u/pydanny layout). There’s a second use case with testing that requires the usage of `python -m pytest` idiom, but the actual path management is abstracted.
Magic solution? What? Putting all your modules in one place sounds like the perfect way to make a mess of everything so no I'm not doing that. 
Not sure I have a use case. I'm just used to importing my files in a certain way. I have a python project similar to what you'd have in C#, I'm probably too used to that. What Im doing is just using the os package to append my files to my path and importing them afterwards. It seems hackish to me and I'd rather do it differently. 
Explicitly pass filenames to lint to pylint? I.e. ‘find . -type f -iname “*.py” -exec pylint {} \;’
And how, exactly, do you think pip installs things?
https://github.com/HOWZ1T?tab=repositories Hello if you are still looking for someone please feel free to visit my github and contact me. Well I have 3+ years experience in python, you’ll see a lot of scrapers I’ve made. Despite this I’ve got experience using and respecting 3rd party apis, most notably Discord’s API. Additionally I have 7+ years of programming experience in multiple languages using multiple technologies such as but not limited to: Java, C, C#, Python, Lua, JavaScript, CSS, HTML 5, PHP, csv, XML, ini, MySQL, MS SQL etc. Tackling this problem is unique, will require multiple instances of the script being coordinated and managed by a master script, thus allowing the load to be balanced, managed and not overstepping Twitter apis policies. If you have any questions please contact me via Reddit or email: dylan.d.randall@gmail.com
How does this compare to pyinstaller? 
I use it to develop prototypes. Only downside is it does not statically link libpython, but it's my preferred method to compile non-Cython code.
What are you using for colo spaces? Currently, in process of looking for a better provider with multiple DC in a same region.
The closest thing I’ve come to solving this is: import typing Foo = typing.TypeVar('Foo', bound='Foo') class Foo(object): def fn(self) -&gt; Foo # Now OK return Foo() Is there a cleaner solution?
And that’s what shebang is for so you don’t do this shit. 
Hey, chill a little man. I think you're trying to go way too complicated. How many packages do you use that can't be installed with pip? Keep in mind pip can install from a git repo
You can just do `"Foo"`, in quotes, and it'll work fine. Python 3.7 [has some things that help with that](https://www.python.org/dev/peps/pep-0563/).
Hey I'm fine but I don't like that guy's condescending tone, although he's right about putting everything in the same place. I'm not exactly new to python but I haven't used it for a while now and the last big things I've used was javascript and C#. 
Just gotta make space a macro button that if pressed 4 times acts as a tab. Everyone's happy.
You are exactly [correct](https://www.python.org/dev/peps/pep-0484/#id28).
I have had better success creating Windows exes binaries with PyInstaller. However, I think I will give this another try.
I don't get it. We've already had PyQt for a long time, what's the point of doing this project? Or it will allow to build closed-source software or something (I believe PyQt is GPL)?
super unpythonic... no thanks.
This is about a python port of PyQt5 by the guys behind Qt. They renamed PySide2 to show, that they are seious about it
Sure then! 
Absolutely
What's the most "worth-it" price point? 1$? 7$?20$?
Sad to see that they have new API and still going with camelCases instead of pythonic snake_cases and a bunch of other unpythonic idioms. 
&gt; Hey guys, we have this new API in the works but we're keeping all of the idiomatic and style mistakes!
lol cringe if you want but the "bugs" you're talking about don't really exist if you actually know how to use the environment
Thank you.
Who talked about bugs? Those are features, but bad features, I think it's against good code practices
You get that error when running the addicted script or when installing it? Can you paste the command you are using?
The first through fifth rules of threading are: You almost certainly don't want to use threads if you can possibly avoid it. After that, if you must, learn away.
My guess is that sending a command needs a carriage return or something at the end. Since you don't send it, you don't get output. But when you close the connection on the first run, that implicitly works. Then the result is waiting there the next time you come in.
In my experience creating the app is only half the struggle, deploying it to different platforms is where PyQt helps a lot with pyqtdeploy, if they won't have a similar tool I don't really see this take off.
They don't really have a new API, just a new/updated implementation. PySide and PyQt are pretty much the same API with only some minor differences. Changing to snake_case would break all apps and make it needlessly harder to port things over. Also from my experience having camelCase is actually a good thing here, since it means it is much easier to avoid accidental name collisions when you inherit from a Qt class (doesn't catch everything, but catches a few). &gt; ok so now we have normal snake_case? camelCase starts with a lowercase, if there is no second word it stays all lowercase. &gt; why doesn't it reference to self.layout by default? It mirrors the C++ API. 
Python itself is sadly pretty inconsistent when it comes to this stuff And with auto generation you don't want to play guessing games about the api
&gt; Changing to snake_case would break all apps and make it needlessly harder to port things over You could easily automate this. Sorry, I'm not buying this lazy excuse of "but muh c++ api" - that's the whole point of api to adopt it for other environment. Now you're stuck with __two__ styles in one project. Forced camelCase for qt api and whatever pythonic code you write for app brains - it's just dumb. To me this whole thing stinks of laziness and incompetence. 
Why do you need to be so careful? If it's a requirement for your industry/employer, then don't they have some standard you must meet? I think the approach is going to vary somewhat by what you mean by "correct". Does that mean correct mathematical calculations? Or does it mean failing to have a memory leak? Or does it mean graceful behavior on unexpected input? There's no one thing that will give you 100% safety. The most powerful things are: 1. Test test test. I find the best thing is to use real data ASAP and get something into production that *will* fail. This will flush out bugs faster than anything else. Obviously it also fails, but hopefully that doesn't matter early in the process (like maybe the existing process, software or otherwise, can handle that). 2. Code review. Explain to someone else how your code can't possibly fail. It doesn't even matter if that person is a software engineer. Just you articulating all your assumptions to them will uncover a dozen corner cases and flawed reasoning. 3. Testable design. A huge monolithic program where changing anything affects everything else is going to be a program that nobody wants to debug or attempt to fix. It has to be easy to debug. That usually means some kind of modular or functional design, where you can drive a piece of it and know that it isn't changing or affecting anything else. Notice that none of these are language features. It's probably not a good idea to have your software quality hinge on tools that happen to exist in a particular language. That hurts your ability to maintain high quality elsewhere. Instead, make quality part of your *process*.
No. This is a just the existing PySide updated and becoming an official Qt project. PyQt is a different project, just with the same goal of being a Python-Qt wrapper, but due to PyQt being GPL PySide got created with a more permissive license.
Seems promising!
&gt; As far as I understand it, using super wouldn't guarantee that the QWidget.__init__ was called. "super calls your children's ancestors, not your parents". No, I'm pretty certain `super().__init__()` will call parent's init 100% of the time. Otherwise all of my code should dramatically implode right now and never work to begin with.
No I have created a python script using pylint.lint and other stuff. Now if I invoke the script via Travis-ci on any repo will it be able to just add an init.py file to it and then run pylint and then delete that init.py ?
Having used languages like C++ and C# as well as languages like JavaScript and Python in production for years I am highly skeptical of the benefits of explicitly enforcing types. I very rarely see bugs relating to a variable not being the type I was expecting in Python or JavaScript and so I have little desire for anything that attempts to enforce that with more work on my part. Getting test coverage to 100% is also something I find incredibly unimportant. Some things are just incredibly difficult or expensive to test in an automated way so the cost to benefit ratio doesn’t work out. Further, 100% test coverage doesn’t mean you’ve rooted out all bugs since hitting every line of code doesn’t mean you’ve hit every sequence or scenario. I find the rest of the proposed rules suspect as well. I’ll echo /u/ThePidesOfMarch, though. Try to keep your functions and objects small and simple so that they are easier to verify that they are doing what they are supposed to. Try to keep untestable or difficult to test areas of code separate. Remember that testability and debugability are features.
I would build a package like you would for AWS Python Lambda functions. Use pip install as a user with the -t command so all your modules are installed into the folder of your choice and used locally.
Agreed on the type safety. Also, keeping your code units small and simple makes them easy to test. But it also makes them easier to fit into your brain. That's where the real magic happens: Human understanding. From *Simply Scheme*: &gt; **The conservative view:** Computer programs have become too large and complex to encompass in a human mind. Therefore, the job of computer science education is to teach people how to discipline their work in such a way that 500 mediocre programmers can join together and produce a program that correctly meets its specification. &gt; **The radical view:** Computer programs have become too large and complex to encompass in a human mind. Therefore, the job of computer science education is to teach people how to expand their minds so that the programs can fit, by learning to think in a vocabulary of larger, more powerful, more flexible ideas than the obvious ones. Each unit of programming thought must have a big payoff in the capabilities of the program. Making your program smaller is the same as making your mind bigger. Another way of saying the same thing: &gt; There are two ways to produce software. One is to make it so simple there's obviously no errors. The other is to make it so complicated there are no obvious errors.
Testing is really the key here. And not just basic unit test, but also integration tests. You should definitely use a framework like hypothesis to generate test cases. This is a really valuable thing, because it can drastically improve the quality of your unit tests and does exactly what you want: Generate cases you didn't think of.
I always loved reading the ZMQ guide. What always stuck with me, is that it is very difficult and gets complex quickly. But here you are, claiming it is all good and easy. Also, from the readme, it is not clear how/if you deal with the multitude of race conditions out there. What happens when: - something connected to the Zserver dies - something gets an error while processing data - will it keep resending the same message? - will the server hang while waiting to send the result? - do we have different policies available? I hope you can find a way to make this work reliably for yourself and for others :) Keep it up!
From what I gather from this thread; you don't have any issues or examples with the system, you're intentionally using the system wrong because it sucks, yet you can't say how it sucks? **What is your issue?**
Tested here with Python 3.6 and using string indices instead of ints. λ python3 -m timeit -s "d = dict.fromkeys([str(x) for x in range(10**1)])" "d[str(10**1//2)]" 1000000 loops, best of 3: 0.34 usec per loop λ python3 -m timeit -s "d = dict.fromkeys([str(x) for x in range(10**2)])" "d[str(10**2//2)]" 1000000 loops, best of 3: 0.347 usec per loop λ python3 -m timeit -s "d = dict.fromkeys([str(x) for x in range(10**3)])" "d[str(10**3//2)]" 1000000 loops, best of 3: 0.417 usec per loop λ python3 -m timeit -s "d = dict.fromkeys([str(x) for x in range(10**4)])" "d[str(10**4//2)]" 1000000 loops, best of 3: 0.362 usec per loop λ python3 -m timeit -s "d = dict.fromkeys([str(x) for x in range(10**5)])" "d[str(10**5//2)]" 1000000 loops, best of 3: 0.363 usec per loop λ python3 -m timeit -s "d = dict.fromkeys([str(x) for x in range(10**6)])" "d[str(10**6//2)]" 1000000 loops, best of 3: 0.354 usec per loop λ python3 -m timeit -s "d = dict.fromkeys([str(x) for x in range(10**7)])" "d[str(10**7//2)]" 1000000 loops, best of 3: 0.369 usec per loop Looks to be consistently ~0.35 µs for a lookup, no matter the size (tested up to size=10,000,000, bigger than that and I get a MemoryError).
see - there's your problem- its NOT a new api.
Coming from someone who's used Qt in C++ for eons, this is a sensible choice they made, as i don't have to relearn everything - also changing it would probably break a lot of internals.
I've been learning about networking and web servers, so I made a simple web server in python. It's very simple with very little boilerplate code, although if someone were to use it in a project, I think it would be beneficial because with it being very minimalist, you would be able to effectively build your own server for your needs, for making pages, apis whatever https://github.com/lduck11007/pyMinServer
Awesome, thanks for sharing!
If you don’t need an instance during the method call you can use [classmethod](https://docs.python.org/3/library/functions.html#classmethod)
Would it be `self.set_layout(foo)` or `self.layout = foo`, leveraging a description protocol, though? Etc etc.
Sharing how to use Python for SPARQL queries, wondering are any other Python folk interested in all things Semantic Web?
pytest and Travis CI (with Github) 
It does. But not to libc.
&gt;I think the approach is going to vary somewhat by what you mean by "correct". Does that mean correct mathematical calculations? Or does it mean failing to have a memory leak? Or does it mean graceful behavior on unexpected input? It's actually standard lingo: https://en.wikipedia.org/wiki/Correctness_(computer_science)
**Correctness (computer science)** In theoretical computer science, correctness of an algorithm is asserted when it is said that the algorithm is correct with respect to a specification. Functional correctness refers to the input-output behaviour of the algorithm (i.e., for each input it produces the expected output). A distinction is made between partial correctness, which requires that if an answer is returned it will be correct, and total correctness, which additionally requires that the algorithm terminates. Since there is no general solution to the halting problem, a total correctness assertion may lie much deeper. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
I'm confused. You example shows the opposite of your claim - super calls init of both parents left-to-right. Am I missing something?
Hi confused, I'm dad!
Signature based malware detection is pretty much useless these days, it would be much more interesting to take a look at behavior based detections or some heuristics based ones written in Python.
What's the story with `numpy`? What gave you the idea that it shouldn't be used?
May I ask why you would not want to use numpy or pandas in production? 
`B`'s parent is `A`. The `super().__init__()` call in `B.__init__` calls `C.__init__()` (which `B` knows nothing about) and `A.__init__()` never gets called. `super()` doesn't always call the parent class.
Oh, okay. Good to know that. I actually wrapped my head around adding heuristics but ended up empty handed. So thx
Correctness, as in [this](https://en.wikipedia.org/wiki/Correctness_(computer_science)). It's somewhat of a large subject, but I think a key concept for this is writing functions/methods that for all input have valid output. By that I mean, inspect every data type of every bit of data going into the function. Does that data type support null/nil? Is it loosely typed in such a way a string or an int can be passed in when you really want an int? What are the valid ranges of the data types you're trying to support? Does the type have rounding errors, eg floats? Python is nice because it has bignum math. While it is slower, it does guarantee support without error to ∞, baring the heat death of the universe. Does the method throw exceptions? Does it return data in a type that can handle more than the possible outputs? eg, a function that always returns a positive number, but it returns a signed int. The return range should be noted, so that those who use the function are aware of the true range of the number, instead of the range of the type. Away from Python I'd say make a type so it is strictly safe, and it Python reasonably allows that sort of behavior I would encourage it. Comments can always become decoupled from code after all. A good way to make this easy is to see a function as a data transform. In comes one kind of data and out comes another. No need to think about _how_ that transformation happens, just what kind of data that function can take and what kind of data it will output (including exceptions). When you're dealing with pure functions, that's almost it. There are threading concerns / race conditions, and concerns if the function will ever end. That is, no `while True:` or it is not correct. Umm, I might be overlooking something. The concept is that of _guaranteed_ code correctness / _guaranteed_ output. Oh, and if it's not pure, you've got a new can of worms. You could argue if an unpure method could be correct. I'd argue it can, but it is the opposite of what you want. Oh! I forgot how to mention implementation details. You want at the top of every function to have if statements checking the valid ranges of the inputted data for correctness or throwing (or returning an error) if input data is incorrect. Correctness guarantees within an inputted range. It does not guarentee it can do `sqrt(ಠ_ಠ)`.
Oh, I completely forgot about this library: http://www.unicorn-engine.org/
`A.__init__()` is never called.
You're being down-voted (I believe) because your question suggests that you're not using the Python eco-system tooling for managing packages, and hasn't explained why you need to do so. In general: * If you need to use a package, try and install it from PyPI using pip. * If it's not on PyPI, but is on GitHub, you can use pip to install it from git (`pip install git+http://some.repo.git`). * If you want to import local code, you should package it with setup.py and install it. If you want to be able to edit it, use `pip install -e my_package_dir` As the other posters have remarked; most people rarely have to touch the `sys.path`. I've mainly done so when writing Jupyter Notebooks.
Please dont flame but may I dare to say vim.
&gt; A key concept when writing correct code is writing functions/methods that, for all accepted input have valid output. This is the very bare minimum of acceptable, though. A program is much more than the sum of it's parts. Every single function can perform as specified, but if those are the wrong functions for the problem, your program is useless. Or if the functions make false assumptions about how other functions work. The real test is the real world. Get there as soon as you possibly can, even if only partially.
##### race conditions To my knowledge, Race conditions are caused when 2 or more processes try to access a shared resource at same time. But here, only one process can access the state at any given time. While server is doing work on the state, zmq automatically stores the requests from other processes till the server is ready to do work again. ##### this is what happens... - when some one connected to server dies, it doesn't matter since the server is not connected to anyone individually. It treats all clients as equal. This is an advantage of using the ROUTER-DEALER combination. I don't know how well informed you are about this particular socket, but it basically allows the server to distinguish clients using multipart messages. Read more here. http://zguide.zeromq.org/php:chapter3 - if you scroll down to the bottom, you'll see that there is a section regarding errors. TLDR; the server catches any and all exceptions and it magically get re-raised on the process whose request was being processed. Everything except that particular process continue doing their jobs as expected, including the server. - No. Its a strict request/reply loop. - No. It sends the error back. - different policies, not sure what you mean by that. ##### reliability From a reliability standpoint it works pretty well. I use it in my other projects, like muro https://github.com/pycampers/muro I actually leave this in autostart and never have to worry about it failing. Please suggest ways to make the documentation and readme clearer. This thing really works and even I'm surprised at how well it works. Fun story: I am currently testing ways to implement concurrent file io in ZProc. I childishly launched 1000 processes writing to the same file. The computer froze for a while but apparently every process finished it's task eventually. 
A is a parent of B, B calls `super().__init__()`, yet `A.__init__()` is never called.
the good thing is that it's officially supported by qt instead of a third party developer and it's in line with the qt c++ license
&gt; Two main concerns are correct mathematical calculations and graceful behavior on unexpected input (contradictory or no realtime data, no response to API calls that have to be executed based on that data, and similar problems) Take a look at property based testing, especially [hypothesis](https://hypothesis.readthedocs.io/en/latest/)
Of course, Siraj himself has a book about descentralized apps. I find that kind of stuff interesting, but all the explanation about what x vs y coin does isn't that interesting imo
&gt; It's not like it would be hard to port the docs, you could easily automate this. As Qt is an open source project, why don't you just automate a port of the docs and contribute it? I'm sure the Qt project would appreciate contributions, in particular of the kind that automates time consuming tasks.
Optimally, `except` should be used for logging and aborting, in my opinion ... what use cases are there for needing `else` in a `try` statement when you already have `except` and `finally`?
True n even if it’s against a sites Terms of service what could a site do about it to stop you? If they even noticed and cared. Its so easy to write a Python script its not like I’m hacking. 
In c# people just do .AsParallel()... How to accomplish this in python? 
What benefits are there to switching to this over pyqt5?
Curious if Intel again "accidentally" causes the code to run much slower on AMD
You can manually do a .start\_all\(\) on the context. But no, there is nothing in there that automatically does this. I think it's actually a good idea, since python really lacks a way to resume failed operations, in general. I don't understand what you mean by \*synchronized to a request\* though
I think interactive Jupyter notebooks can be quite effective for learning. Take a look: http://jupyter.org/widgets and http://ipywidgets.readthedocs.io/en/latest/examples/Using%20Interact.html
it's because preserving the Qt API, if you change, then you rely only on the Python documentation, but keeping the Qt API allow you to understand C++ examples and port them to PySide2
They are two options that provide the same things, and the only major difference is licensing, Qt for Python has a more permissive license. The other difference is that PyQt is being developed by Riverbank, while Qt for Python is being developed by The Qt Company.
Well, yes, but I don't have anything to do with Python 2 ... it's so old now ... As to your other point, if your code isn't functional, then yes there's a need for advanced try/except/else/finally logic ... but otherwise, I don't really see a purpose in it? Try/except/sometimes finally should be enough.
&gt; Use atexit (or similar?) to properly clean all sockets at unexpected behavior For this, I'd suggest managing your sockets via context managers where possible. Context managers will call __exit__ even if exceptions are thrown.
That was just an example. Lots of code flows can include some kind of "if this path fails use the other path and keep on going" logic. I don't know what you mean by "if your code isn't functional". In real life exceptions happen. If you're making an IO-based function call and the network/disk/whatever was down, you get an exception. If you're handling user input and they entered something invalid, you can get an exception. If you're parsing a file and it was corrupted, you get an exception. In all of those cases you *might* want to handle whatever success logic in an `else` clause so you don't trigger your "try another path" logic.
Ugh, my last reply was a mess. I guess I'm just confused about why that's required ... I've never had to use the full try/except/else/finally statement. else/finally have always been either/or, for me, at least. For me, I rather explicitly fail at the exception and define the successful logic in another function ... otherwise my code ends up snowballing into giant functions. Did that make any sense?
There's a reason this `else` block is a bit obscure, because it doesn't really add any functionality. You never *have* to use it, you can always just do: try: function_might_error() print('Function didn't error') except Exception: print('Function errored') The difference is that moving the print statement into an else block of that would be completely separate from all the exception handling so it would be unambiguous where the exception came from.
To build on this, if you need to gather the annotations later as actual types, `typing.get_type_hints` was buggy until 3.6.5 and would throw exceptions with forward refs sometimes. So you'll need to either upgrade or back port the fixes. 
It's not allowed in production? That must be some work rule and it seems super silly to me. 
Ok, so I hear everything you're saying, and what I'm taking away is that it's about explicitly logging success, right? \(Let me know if that's wrong.\) The way I see it, unless you desperately need to do something different on success, the `else` statement in this block is completely superfluous, as you can put the logging statement into the `finally`: def authenticate_user_pw(input_pw: str, output_hash: str) -&gt; bool: """authenticate the user hash and return true/false""" try: hash_pw(input_pw) == output_hash except Exception as e: logging.FATAL("A user password wasn't sanitised etc.") return False else: logging.SUCCESS("User successfully logged in") finally: return True Does that sound right?
It's not a new API, it's really a revived project (PySide).
I would say that it's more practical than ideological. You have a rule which you have no way of effectively policing (how do you detect a scraper anyway?) and for which you want to make exceptions like the googlebot and web archive. How much time and effort do you put into this vs just rate limiting anyone regardless of how many times they hit your site?
&gt; Python itself is sadly pretty inconsistent when it comes to this stuff I thought most of the standard library has a consistent style since Python 3? What examples are you thinking of?
&gt; Agreed on the type safety. Most of my interactions with such systems are trying to figure out how to get around it to do what I want and not saying "thank god, this type check saved my bacon". I've had different experiences. Using C# which enforces types has made me think more carefully about what I'm doing and how I'm building it. Python's type hints are like a dim reflection: they're incredibly verbose, not very expressive and difficult to work with if you want to stuff like code generation. That said, I'm using them in a new project to get a better hang of them before I make a final decision on them. 
Thank you, I will look into that!
Well, again you're making specific cases out of my generalizations. try: function_might_error() success_case() except Exception: fail_case() continue_in_either_case() success_case() and fail_case() might be anything. There might not be any logging invovled at all, this might be a program meant to run by itself for a long time and handle errors intelligently. But if success_case() throws an error, fail_case() will be called, even if you only meant to call fail_case() if function_might_error() threw an exception. 
Yes, I see that now. That was a much better and insightful snippet than what's in the article. 
My thinking: In general, NamedTuple is for immutable sequential data structures, like rows from a database. If your data isn't of this type, don't use NamedTuple, unless you know the tradeoff. For other data structures, Dataclasses are much better, so if you're on Python 3.7, use Dataclasses as the default choice. Again, if you're working with structured data, you may use NamedTuples. If you're on Python &lt; 3.7, and you don't want to have external dependencies, make a choice between a custom data class and NamedTuple, but IMO sway towards creating custom data classes in this case, as there are certain choices made by using NamedTuple (immutability, sequencial order...), that may not be appropriate for many use cases. I think dataclasses will be a great addition to Python
My knowledge on this topic is limited, but why not just check *is_alive* on the worker and restart it if it returns False?
Glad you did. Also, at some point you might work in a Linux, *ix, mixed environment, or your company decides to run their servers on Linux instead of win. Then *you*are the guy that knows the Linux commend line!
We can use Celery to achieve this, which. IIRC, sends a "heartbeat" to it's workers.
But Qt is LGPL. So there is a license mismatch. Not so, with PySide -&gt; Qt for Python, which is also LGPL.
LGPL instead of GPL
Tkinter is simple and works out of the box, but is extremely limited. QT requires some setup and is a full UI framework. It is powerful and complex. If your goal is simply to learn the basics of UI, start with Tkinter. It's quick to pickup and can form a leaping off point for more complex frameworks. 
Multiple instances managed by a master script? I invite you to have a look at my multiprocessing library https://github.com/pycampers/zproc It seems a good choice for your use case
I guess these days you choice either PyQt or Kivy for GUI development, obviously not the Tk.
My bad, I edited comment and left out important part: - Compatibility: API changes quite quickly and things get deprecated. I've also heard of silently breaking things, without getting DeprecationWarning before - this one is only speculation: it's harder to reason about edge/corner cases. I can imagine that NaN manipulation, chaining functions, doing joins, reshapes might be harder to test properly.
How do you handle if somebody changes function and forgets to change type hints? (I'm genuinely interested) Wrong type hints seem to me worse than no type hints. I want to solve this thing, two options I see are `pycontracts` and `mypy`
Thanks for sharing! Could you say in which context did you use C++ and C# and how would you compare them to py? One thing I found as common pattern is that outside of big tech firms (Facebook PHP, Instagram python, etc.) very few use server side dynamic language, especially where correctness is important (e.g. trading). But of course, there might be other strong reasons to use them (performance)
Use a requirements file to pin the versions of your dependencies. You don’t upgrade until your tests pass with the upgrades dependency version(s). 
That sounds very good I will look into it! Thanks
Err setup other that pip install does Qt require? Certainly not done any more than that to get it up here.
Thanks for answering! The command I used it's there: (venv) ┌─( david ) » { /datos/Series/Incompletas/Homeland } └──┤ addic7ed The installation went ok. And I can see that the package it's on /usr/local/anaconda3/bin What I don't understand is why I'm getting this error just calling the package itself?
I’d like to use it for backend web development and/or contribute to some Linux desktop apps I use. Really though I’m not sure yet since I have so little experience with the language or with programming that isn’t frontend web stuff anyway. 
I mean more in code. Tk, you just say, "Make a window and put a button on it," but in QT you've got to do a fair amount of bootstrapping (last I checked, anyway- it's been years since I've touched QT, but I recall the "Hello World" app being surprisingly large).
Link to a better formatted version of your code: https://pastebin.com/Z8gKXstQ If you format your code better it might get more replies. You can try: https://codebeautify.org/python-formatter-beautifier You should set the indent to 4 for python and your code will probably still need some work to look nicer but you will have a big headstart. Also you can use Pastebin to have more control of how the code appears and send links to people sp they can see it in a better format than it normally would appear in Reddit. If you make an account you also have the advantage that it can act like an "archive" of code you have sent or linked with others. (It's probably best to sign-up for a free account) https://pastebin.com If your code is having execution issues possible due to spacing or syntax you can try: http://pep8online.com
We've had PySide for a long time as well, with a much more permissive (commercially speaking) license. 
Yuck. Gtk4lyfe bro
you can use sqlite and plain sql statements, or if you like a higher level interface to your database, sqlalchemy
Because the document isn't completely loaded with javascript executed, angular elements rendered and all that.
Read the sidebar. This isn’t the place for this. 
1: google 2: r/learnpython
http://zetcode.com/db/sqlitepythontutorial/
Yea that comment is just indicating something like he had a mashup if pywt4, payqt5 oython2 and python3 or something along those lines. I stick to py3 and use qtpy bindings and never have an issue.
I would definitley choose PyQt5 over tkinter. It is a lot easier to achieve anything with PyQt5. Tkinter is a lot of pain without any gain. It is not about the look. The most important page is [Signals and Slots](http://pyqt.sourceforge.net/Docs/PyQt5/signals_slots.html). You can use QtAssistant to view the C++ documentation which translates almost directly to python. If you download the [source package](https://www.riverbankcomputing.com/software/pyqt/download5) and extract it you can find the c++ examples of the official documentation translated to python. The most simple example from PyQt5 import QtCore from PyQt5 import QtGui from PyQt5 import QtWidgets app = QtWidgets.QApplication([]) # you need to create an app object fist w = QtWidgets.QWidget() w.setWindowTitle('Hello World') w.setFixedSize(200, 200) w.show() app.exec()
Can someone explain what SQL is?
I mean you can but gtk is a shitshow of intractable architectual mistakes.
put 'stackoverflow' and 'python' when you search for tic-tc-toe
&gt; OP may indeed mean this bland and largely useless theoretical issue of formal correctness. But if so, it should be posted in a computer science sub not what is effectively a software engineering one. If OP means "how can I make robust code in the real world" (and asking about libraries seems to indicate that), then the other responses here are much more practically useful. &gt; &gt; Didn't mean formal correctness - I think it's not very useful for most real-world applications. I'm interested in methodologies/best practices to ensure code that what I intend to do and ideally offers framework/help in dealing with unexpected/not foreseen scenarios
No not at all. GVR would want you to maintain the style that exists, not mix them.
There is not truly pythonic this toolkit though. Even the bundled tkinter stuff is just a wrapper around something that predates python. I am a huge fan of Qt, and have written quite a bit if code in it, but I agree that PyQt/pyside is not pythonic. That said, I briefly tried writing a pythonic graphical toolkit once. I figured I'd start with something simple, so I found an ancient version of Qt (1.1) so I could judge how much work it would be. I even started coding an event loop (using Python's asynchronous stuff as a basis). After a week I had a white square rendering in X11. Then I said "this is going to be a lot of work. Do I really want to spend ten thousand hours reinventing the wheel so my gui API is more pythonic?" and dropped it. It was fun though.
What is it you aren't getting? It's a FACT that in Python your parents my not be called. You were shown code where B.super() called C. You got confused bc d inherited boyu b and c so it was donstrated that d didn't call c by replacing the call in b ... Proving b called c.
I've really taken to arrow and can't go back now, it's brought sanity back to datetime arw = arrow.utcnow() arw.shift(weeks=+3) https://arrow.readthedocs.io/en/latest/
I can do little more than print statements and cheap tricks, but our software engineer has fully automated container farms and breweries with python programming. Measure real time parameter (air CO2 level, tank level, nutrient level, tank temperature), then interact with the physical world (turn on sump pump, turn on CO2 generator, turn on nutrient pump, turn on and off irrigation and light with timer programs, circulate glycol), then verify it actually worked (measuring the parameters again for expected change, measuring amount of flow, measuring change in power for the circuit.). If it did not work, or if something is abnormal, an alert is automatically sent to the user, as well as being able to monitor and graph all this data on the webpage.
Read reddit's formatting help.
you'd use mypy and a test suite. unlike c#, Java, etc, type annotations are optional in Python so there's no built in compile step that'd catch it
Ah. On that, it's par for the course, with greater flexibility comes more config
No that's not what I'm doing. I'm using pip alright. What I am having an issue with is creating a project with several folders. For instance I need a models folder and I need to. Import it in another file found in the same level of my root directory. For whatever reason appending to sys.path seems to be the only way to do that or at least that's what I found out. I'm not going to switch languages because I want to learn better about python and it is what suits me best in this case. That just plain sucks and if a bunch of fanboys don't agree with me and want to downvote me then go ahead I don't care. I'm not surprised to be honest, this career seems to be abundant with that crap mentality. 
Thank you! I was looking for something like this, but googling "linking code to reddit" mostly rendered things for making words into hyperlinks. Again, thanks.
Your post is very interesting - are there any softwares which do that kind of thing? And if so, did you outside something custom just due to cost or due to the degree of customization you wanted? In genera, I find it very interesting that python allows individuals to hurl themselves at seemingly gargantuan problems, and still come away with some respectable results. 
Dataclasses contain more information than named tuples do. They tell you the type of things, as well. Named tuples basically add metadata to tuples, in the form of naming what each field does, and otherwise acts as a tuple. Dataclasses aren't as efficient as tuples, so if you want a lot of them, go for tuples. If you want them more descriptive, go for dataclasses.
There is also an optional `else` for `while`. 
Parent of parent != parent. 
My workflow combines python + pandas+ postgres + web for graphing and UI. Check out what a database can do for you. If you can do pandas aggregation and group by, you can do SQL. I just use py-postgres, haven’t used psycopg. 
Nope. In Python exceptions are cheap. Use them where you want.
PyQT is GPL so you need to open source and put your software under GPL, unlike LGPL which only requires the library to be opened.
You keep repeating that as if it's relevant to the demo. I think you aren't reading the code actually but let me try rephrasing it once more. Heres the phrase you have to digest Super calls your child's parent. Consider B. D instances B. Focus on B ... B calls super and it did NOT call A. It called D's OTHER parent, C. It would have called A if the B was instanced alone but here it has a child D. So it called D's other parent instead.
Got it. What is the difference between \`\-\&gt; 'Foo'\` and using \`TypeVar\` to define \`Foo = TypeVar\('Foo', bound='Foo'\)\`?
AFAIK there isn't really one.
OK now we have some more insight! Let's turn this on its head, though. You are finding it frustrating that Python has to be told where to find these modules. How else would you expect Python to be able to do this? Have you come across a mechanism in other languages that you prefer? In Python 3, you can just import the module from the file path if the folder names are valid identifiers (e.g `import folder.subfolder.module`) People weren't down voting you because they're "fanboys", it was because you made a sweeping statement "import is awful" and then proceeded to not explain what the actual problem was. 
People have an issue with your attitude, that's it. You don't know how to import files properly? Rather than coming here to flame Python, you should've humbly asked for help like any beginner would. &gt; For instance I need a models folder and I need to. Import it in another file found in the same level of my root directory. For whatever reason appending to sys.path seems to be the only way to do that or at least that's what I found out. Well it's not the only way. It's the wrong way. Say we have this: /package .. root.py .. /subpackage .... sub.py .. /anothersub .... mod.py Want to import `mod.py` in `root.py`? from .anothersub import mod Want to import `sub.py` in `mod.py`? from ..subpackage import sub Wanna import whole `subpackage` instead? from .. import subpackage Need `root.py` in `sub.py`? You've probably structured it wrong, but sure: from .. import root
Thanks! So if I use a GPL license software, I need to make my whole program open source? With LGPL, you say library, what does that mean. Just the code I took from the LGPL license software?
&gt; Super calls your child's parent. What are you talking about? Who's "your"? I'm confused how you fail to wrap around the simple concept of parent.
IMO, the $20 bundle would be worth it for the web dev stuff, not sure about the desktop stuff unless the apps use Python. 
Nah it makes all the modules in the code a library and statically links them. You will still need the same libc and libpython on other boxes to run the binary.
I answered you elsewhere: https://www.reddit.com/r/python/comments/8hd7xq/_/dyjl895 Damn I would be embarrassed now, offend everyone and the language only to find out you've been doing it wrong all along.
Yes and yes.
Adding a python path in system variables under windows ? Is not that what you need python to be recognized in your system ? That solves the problem universally in your system where you can run your script anywhere .. but I am assuming you are working with Pycharm or some other IDE and confuses virtualenvs and makes imports not highlighted and makes you frustrated ? For something I am not deploying I just use my python or anaconda directory for libraries and modules and setup and select in IDE as same way .. 
Nice job. 
If you install your packages the imports will work automatically. python setup.py install l
Where are the docs? I could only find the function docs. Is there a simple tutorial?
Sweet thanks so much. Any ideas for sites to scrape to get data I can use in a web based project I’m thinking Vuejs front end and flask backend. Not even to host on the web just for my own personal practice. 
Okay, well I think the $20 would be worth it for those purposes. That said, if you want to learn how to program, then I recommend taking the MIT 6.0001 course online for free... https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-0001-introduction-to-computer-science-and-programming-in-python-fall-2016
New programmer here. Did you learn this in a course?
I've been checking out [Arcade](http://arcade.academy/index.html) recently, and I think it looks pretty accessible for quickly making small games. It has lots of sample code available for different features.
This is awesome!! I’m a chemical engineer and I want to get into this stuff. What stuff does he use to do all that?
KV is basically the same language as QML, but is indentation based like Python, and can have embedded Python scripts inside it instead of embedding JavaScript snippets.
SimulateMe! Vini_Dalvino
I’ll bite. So the /learn_python response is not as dickish as it sounds, it means you may get better responses on that subreddit if you haven’t tried it. SQL means structured query language. It’s like a standard language for crafting queries to submit to a database. Not all databases (mySQL, Postgres, Oracle) speak exactly the same language, but there is standard that they are compliant with most of the time. Where they are not can be considered a feature of the database. I’d check out postgresql. It open source, free and I’ve installed it on windows and Linux, great documentation, good user community, blah blah blah. For a beginner it doesn’t matter which one to start with. You then can use DBI database interfaces to have your python or java or whatever language communicate with the database. Databases act like web servers but rather than responding to http requests and returning web pages, DBs listen for SQL statements and respond with tabular text after executing the query statement. Or if you use Postgres you can return results as JSON. Query languages are worth learning I think. It’s called declarative programming. You say what you want and then an optimized engine executes a bunch of steps to get you your results. No loops or complex data structures, it figures out the details for you. I like it and I blend it with regular procedural programming where you have to tell the computer every step to take (called imperative programming; “do this, do that”). These are gross simplifications but GTS. Start you own journey of discovery...
I refuse to use python 2 and moved to 3. This is also a reason why I haven't coded. I found out that I love Lisp languages and especially Racket. I do will the libraries though. 
You're free to do as you please, I'm just giving you the heads up of what is possible. If you refuse python 2 then your earlier point about py2exe or python 2 libs is moot. Finally, in the context of a job it might not be wise to take an absolutist stand.
Heavy user of pygame here, never heard of Arcade, how does it compare?
Considering numpy and scipy are all c and Fortran under the hood, I'd worry more about speed predictable of your own python code. &gt; this one is only speculation: it's harder to reason about edge/corner cases. I can imagine that NaN manipulation, chaining functions, doing joins, reshapes might be harder to test properly. What's harder when you run into a bug: being able to consult with thousands of others that are using the same software or delving into half written documentation from an engineer that left the company two years ago? Writing your own math and analysis library might be fun, but numpy, scipy, pandas, et. al. have been put through the wringer over and over again. They've forgotten more about NaN manipulations than you might know right now. Avoiding these libs is gonna be a costly mistake. Even if you do it perfectly, when you bring in someone you can't guage how well they know the library because it's in house. But if you use numpy etc, you can guage them on that, they spend less time in the ramp up period. This is the same advice I'd give if you'd said requests or django or any other thing like that wasn't allowed in production for these reasons. If these are your fears, I'd suggest slowly pushing these bits to production to get over your worries. If these are coming from management, you can try to talk them out of it but you'd probably be better served finding another job. 
Cool
This is not the /r/learnpython you're looking for.
Had that earlier. But updating that with the API felt like a chore. I will give it a shot again..
This may help: https://github.com/mherrmann/fbs
Stop being an asshole and just think for a minute so you can stop wasting everyone's time. D subclasses B and C. B and C subclass A If you just call B() or C() then it will chain up to A as expected. However, if you calls it from D ... D super().__init__() calls B B.super().__init() calls ... C not A That's what it means to say super() calls the child's parent, not it's own parent. If B and C have different base classes, the behavior changes yet again. D calls B calls A 