One of my few complaints with `logging`, interestingly, is the lack of a SLIGHTLY more powerful configuration utility. Something in between `basicConfig` and "manually set up handlers and formatters"
You probably don't need it. Why not just use an init? I've been coding in Python 10 years and never used it. I consider myself very good.
I had a problem with the original package (can't remember specifically what the issue was) and after I switched to jurko's fork it worked. But then the service I use it for has only 3 available methods and it's pretty simple so maybe that's why I have not hit any issues :)
httplib, cookielib, datetime, date, etc.
&gt; I never know whether the time is in UTC or the local timezone and I never know what I can compare them with. It shouldn't actually matter what timezone they're in. You can always convert them back and forth to other timezones, and you can compare any timezone aware datetime with another timezone aware datetime.
But super works in an init...it seems the same. I write classmethods that are basically alternate inits, but they just return the init.
It is a small quantity of data, for big data sets I'm using Sqoop import into Hadoop.
Thank you for clarifying professionally. I agree windows probably isn't the best development environment, especially with their looser and looser privacy. Linux is pretty daunting though coming from Windows. I've used Ubuntu before, which was bearable; very similar to mac, UI wise. Perhaps other flavors of Linux are more UI and less console commands, but it seems odd that you have to do so much that way. I'm so used to being able to change virtually any setting, without ever seeing the console. Having to remember all the arguments for every tool is tedious. Granted after doing it for a year, it would probably feel more natural, but were still using Console to do so much. UI's aren't even hard to do (in python anyways). In Win7 the only time I pull up console, is when I'm doing Python. I wont pretend Windows is the pinnacle of OS development, but Linux (as ive seen it) misses the mark too.
&gt;WOW! Some guy wrote slow C++ code FTFY
Fuuuuuu, so true. I hate that damn thing. I still use it though. I guess you get...used to it. The first time I ever did plotting was in Mathematica and even though that felt somewhat clunky, using matplotlib after that felt quite awful. Maybe we need a more pythonic adapter to matplotlib.
WOW! The light is slower than the sound! Take this, Einstein!
It's immutable, so by the time you get to `__init__`, it's too late.
I use vim sometimes as well. Its useful when I log into a server remotely to configure salt files. You must know heaps about salt states.
I don't think DRF is that bad. Then again, I tried Tastypie once...
Is it possible to run the remote debugger with docker-compose?
"It depends" is the most accurate answer you'll get for this, because your question is very vague. Here is an example of a menu I made once: while True: choice = raw_input("Select one of the following options:\n\n(W)allet\n(S)pells\n(I)tems\nSave and (Q)uit\n:").lower() if choice == "w": wallet() if choice == "s": spells() if choice == "i": items() if choice == "q": break And [here's](http://pastebin.com/g4p711t6) an example of another one. I suggest you get to a point in a project where you need to ask a question to continue, or something "feels" wrong - like it could be done better, then come back and ask. Also, /r/learnpython. /r/python is for news and releases, not questions.
I think the documentation is pretty clear. Point 2 on the first list is: &gt; Too many types: date, time, datetime, tzinfo, timedelta, relativedelta, etc. Which is just absurd. Arrow dispenses with all that and treats dates, datetimes, times, timezones, differences between points in time, etc as ONE type. Why not just program in PHP while you're at it? This is such a blatant wrong idea it's quite amazing that any python programmer would use it. 
In that case, the behavior is *being*. For data clumps that'll always be used together, I like using namedtuples as a starting point. I've been using Payload objects at work for this. They're just DTOs that represent the outcome of a domain action. Right now, they're simple namedtuples that live inside a namedtuple. HTTPPayload = namedtuple("HTTPPayload", ['data', 'status']) And then: PayloadFactory = namedtuple('PayloadFactory', ['good', 'created', ...]) And I just used partial to back file the status good for each so the domain only knows to say, "Hey, here's something that I made." Or "Hey, this shit broke, here's why." But the HTTP view gets a tuple it unravels into a response.
&gt;* If I look at other (bigger) modules, they are not just one .py file, they are a folder with files for each class and/or functions. Would something like this also make sense for my project? to have a tpm/__init__.py and tpm/TpmApi.py and so on. Imagine for a moment if Tpmv3 and Tpmv4 were more distinct and therefore each had a lot of their own methods, with their own logic in them. If your tpm.py module got longer than you were comfortable with, it might make sense to break the subclasses off into their own files. So you'd have a tpm.py file with your TpmApi base class in it, then like tpmv3.py for the TpmApiV3 class, and similarly for the V4 class. Splitting code up into separate files vs keeping it all in one file always seems like a balancing operation to me. Though separate files means you'll have shorter files and potentially more explicit organization, it also introduces complexity. There's a nonspecific point where a file gets too long and should be broken up, and that depends on all sorts of things. &gt;* I tried to prevent people to use wrong hostnames, wrong urls and so on, but actually that is a module, what somebody use with python. Am I doing too much? Should a developer recognize what wrong values he used by himself? I think that's a design decision that's left up to you. I went and looked through the code again, and besides some basic input validation, I saw a reliance on using the API to throw up errors if something is formed wrong. That is probably how I would have handled it as well. In this case the API is the arbiter of what counts as a good request and a bad request. Don't waste your time trying to predict how it will respond as long as you faithfully raise appropriate errors the API returns. This is of course if the API handles bad requests decently, rather than like randomly deleting entries. &gt;* If you are a developer who would like to use my module, how is the documentation? Is there anything to improve? I think the documentation looks pretty good, you have examples of using the API with no authentication and with authentication so that's good. As much as explaining what each individual method does can be useful, I find examples extremely helpful for just picking up a library and using it. The other thing that comes to mind is that this is a Python wrapper for a password manager API right? Which raises two issues, a trust issue around is your code doing anything malicious with those passwords (it's not, from what I can tell reading the source) and that passwords are something to be kept secret not just printed out on the terminal and remaining there in scrollback. You could use something like [Blessed](https://github.com/jquast/blessed/blob/master/docs/intro.rst) to only temporarily show the sensitive information. Keeping both those issues in mind seem important though, even if you know you're trustworthy. Nice project overall though!
This was motivated by the he nice wallspaper form @Gommle and the reddit discussion about it: https://www.reddit.com/r/Python/comments/48sanl/julia_fractal_wallpaper_including_the_parallel/ I could speed up his code by more than 25x.
I'd really like to see dataframe viewer support... similar to spyder
Yes, but the overhead involved is pretty massive and a lot of parallel jobs simply won't be worth it or will have to be tuned (via the 'chunk' parameter). Multiprocessing uses Pickle for communication and not all objects can be pickled, limiting its usefulness even further.
NetworkX is more flexible and in my opinion has a much nicer API. Igraph is a lot faster, particularly for interesting graph measures and analytics. As long as your graph is small, or you are planning on largely doing simple things with it then NetworkX should be great. For very large graphs, or complex computations on mid-to-large graphs igraph is a better option.
You have a lot of work on your hands. Here is what I would use to parse the document into text: https://pypi.python.org/pypi/docx Here's a built-in example that uses the getdocumenttext() to simply convert a docx to more easily manageable text: https://github.com/mikemaccana/python-docx/blob/master/example-extracttext.py For drag and drop import, it depends on how you are implementing the client application. You would do it differently in Tkinter than in a rich web application (in which case the solution would mostly not involve python). Then the real work begins, because you have to semantically analyze the text to determine where the details you are interested are in any given resume format, all of which are different. It's a problem that I'm glad I don't have to deal with.
After some testing, I discovered the abs(z) statement was the culprit. They are now equally fast after using the same while statement as the Cython version.
Hi, I tried to replicate your timings in Python 2 to no avail. The improved version is no faster than the original version in my measurements. See here for results: http://nbviewer.jupyter.org/gist/roessland/4146ebada4f96f3dcb2a
&gt; length = 56.3 # An floating point integer Wat. &gt; Python tuples are another data type which is similar to list, items are separated by commas and enclosed with round brackets ( () ). Yes, certainly, that is the only difference worth mentioning. 
heh, great name :L
Noted :) ... But my question still stands.
On my laptop running OSX w/4 physical cores and python 2.7 / numba 0.24.0 I get the following timings: #%timeit julia_cython(10000) %timeit julia_cython_opt(10000) %timeit julia_numba(10000) %timeit julia_numba_vect(10000) 1 loops, best of 3: 5.86 s per loop 1 loops, best of 3: 5.48 s per loop 1 loops, best of 3: 3.48 s per loop So I don't think it's a python 2 issue
I was going to say that this belongs in r/learnpython but "floating point integers" belong **nowhere**.
import delorean
I found what makes a lot of difference on my machine+my python version. Time goes from 2 second to 0.2 second if you replace while z.imag**2 + z.real**2 &lt;= 4: with while z.imag*z.imag + z.real*z.real &lt;= 4:
I don't think Networkx is meant for printing though. It's nice as a feature, but its power lies in providing a nice user-interface to interact with graphs and generate statistics about them. For printing/plotting, I export to GEXF and use Gephi to make the graph look pretty. A nice extension to NetworkX is `python-louvain`, which implements the Louvain clustering algorithm. Just pip-install it and then import using `import community`. For example code, see [here](https://github.com/evanmiltenburg/dm-graphs), with [an interactive visualization here](http://kyoto.let.vu.nl/%7Emiltenburg/animals/).
Alright, thanks for clarifying. 
I put a gist up with the calculations performed in sections [here](https://gist.github.com/mfm24/56defca8cd6e1d5faa43).
Thanks! Will give it a long read when I get home 
I had a similar disapointement using tensorflow for a similar computation: https://www.ibm.com/developerworks/community/blogs/jfp/entry/How_To_Compute_Mandelbrodt_Set_Quickly?lang=en These deep learning libraries spend an enormous time trying to optimize their computation graph. Once this is done, then they are pretty efficient. It may be that you won't see much time increase as you increase the size of image.
I don't quite understand the use case for this. Even for pandas, I don't really see it (maybe for handling dates) - and this is yet another layer on top of it. For my use cases numpy's record arrays are just fine. Replacing NaNs with the column mean is a one liner. No need for an abstract method in yet another package. Simple and easy to read. But maybe I miss the point and I'd be happy to be enlightened.
To add to everyone's comments. The database which in this case is mysql stores data in tables. Much like a spreadsheet. And the database can have multiple tables storing different info.much like a number of sheets in the spreadsheet application. The reason it looks like people are managing the data in dicts is becuase they use a very clever bit of python called an ORM (object relationship *manager*?) Which translate the database into python objects, so they can be used normally. And then it translates the objects back to data. You don't need an ORM but it makes using the database much nicer.
It really depends on the size of your graph. NetworkX is written in pure python and is therefore really slow if you have millions of nodes. For such large networks I use graph-tools, which is basically a wrapper for the Boost graph library. 
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
[removed]
Why is `while z.imag**2 + z.real**2 &lt;= 4:` so much slower than `while z.imag*z.imag + z.real*z.real &lt;= 4:`?
unfortunately, I let this project lapse. However, there is a very interesting project that seems to do some very cool and related stuff: https://github.com/Miserlou/Zappa and https://github.com/Miserlou/flask-Zappa
I have been doing exactly this for a long time.
I wish I knew. 
Plotly is amazing. Highly recommended. 
And just what would be that language? Seriously, languages that don't improve themselves eventually die out or become niche products that barely have any support at all. Even heavily standardized languages like C++ leave old versions in the dust. Frankly this is a tired excuse that basically says we can't keep up or won't because someone pissed in our oats. The last thing we need in Python is a language that goes stale because some one got his panties in a bunch over backward compatibility. Sadly I have nothing positive to say about your can't do attitude. 
To be honest, lifter won't allow you to query/extract data if your data has no schema at all. However, if you want to extract a JSON attribute located at the same depth every time, you can do: `lifter.load(data).values_list('path__to__attribute', flat=True)`
I am going to blow your mind now. Python is written in C. *Neo voice* Whoa.
Python 3 isn't so much stuck in the middle as it is a bridge to improved language features. It effective corrects problems in Python 2 allowing developer to move forward. 
Because the world is different. It is a far more international world now. 
Thanks for mentioning lifter, it's exactly the problem I tried to adress when releasing the package. As you say, there is still lot of room for improvement, especially regarding performance ;)
Pandas is all about making a specific case of data analysis easy. It gives an "excel" feel to your data structure by representing colum, and letting you manipulate that by label, switching them, filtering them, creating new ones using others, etc. It also has nice graphic representations of data. It targets people that like tables, not arrays. This is just a layer making some operations you do most of the time with pandas a bit shorter.
Ok, so I tried running this on my machine (Acer C720P, Arch Linux, Python 3.5). I don't use ipython; instead, I just ran cython and built an extension module with setuptools. Here are the results for `timeit.timeit(lambda: mod.julia_cython[_opt](N), number=K)`: N, K | original | original w/o squares | optimized :--|:--|:--|:-- 10, 100000 | 1.626304 | 1.638881 | 1.634978 100, 1000 | 1.616281 | 1.613991 | 1.526790 1000, 10 | 1.486759 | 1.475801 | 1.384616 10000, 1 | 13.96951 | 14.00712 | 13.30656 I don't see any 25x speedup. In fact, since running `julia_cython(10000)` took *3 minutes* on your computer, which I doubt is that much slower than an i3 Chromebook, I'm afraid you screwed up the benchmarking part somewhere. The results for `julia_cython_opt` - 7s on your machine vs 13s on mine - seem to be closer to the truth. Edit: Most likely explanation is that gcc 5.3 optimizes `pow(x, 2)` into `x * x` at -O3, if that's really the reason for the huge performance improvement.
Great collection of links OP
I used to love messing with fractals back in the day... got your code up and running on Arch + Python3.5 and changed the matplotlib colormap to inferno... the result was really nice... I think I might have found my new desktop background. [Imgur](http://i.imgur.com/P9b1WQO.jpg)
Thanks, I am installing it now. It is unfortunate that it is not easy to find the best package for the job. I have seen abandoned projects many times, and it is sad, where the original package does 80% of the job, and people submit good PRs to finish it up, but the original author just moves on and doesn't reply to PRs, etc. So, then there are a bunch of forks, and the whole thing gets messy since they cannot publish on PyPI.
Try /r/homeworkhelp.
This is just amazing. 
The FTP lib is far from amazing but I didn't have too many problems with it. It would be nice to have a better interface that wasn't basically passing in raw FTP commands though.
It's very much not pythonic but coming from the .Net Selenium API it was easy to move our code to python since they were virtually identical.
It looks like HS level math
I am stopping by this post, just to say thank you, I am currently bouncing around your tutorials and got to your tkinter tutorial where you mentioned you were active here. Your videos are perfect, I feel like a I am racing through the language while still retaining it all. If I ever get out of my data entry job and into a real IT position (I am all self taught, so we will see) I am going to have to hunt you down again here for some gold. Keep up the great work.
&gt; Maybe we need a more pythonic adapter to matplotlib. [seaborn](https://stanford.edu/~mwaskom/software/seaborn/) is that adaptor, and for the use-cases it covers seaborn is a godsend.
I love DRF, but I don't use the silly ViewSets or URL auto generation.
I think you're right: your version of gcc optimizes away the call to the power function. The one installed with anaconda does not. I mention this is the cause of most of the improvement in the current version of the post. And for the 'screwing', I shared the code, it is easy to reproduce.
The error message i get http://imgur.com/sz4Bvnn
It's very likely the weird letter/number part of your selector is randomized to prevent people from easily doing the exact thing you're doing. If you want to interact with Facebook, use the proper API - they do have one. 
Thanks for the suggestion. I will take a look.
I'm sorry for the vague description. My test environment is as follows: debian 8.2, iputils-ping 20121221-5+b2. [Edit] I'm revised README to be more specific. Thank you for pointing it out. 
I guess there's a reason not to use xrange in those cases? I always got the sense that generating the range was considerably faster for large values.
Habit! Thanks for the link, I'll check it out!
xrange is faster than range is you use Python 2.7. For Python 3, range works just fine. But this isn't relevant when you use cython as it optimizes the call to range.
Just ran my code with Python 2.7. Timings for the original code are way closer to the rest, but there is still a difference. I guess most of the difference between what you see and what i got comes from the backend C compiler (gcc vs msvc)
Ok, thanks... Wow - crazy I haven't run into this before, but that makes sense. BTW - I took your advice and moved this post to learningpython. I'll update there as well. Good info thank you https://www.reddit.com/r/learnpython/comments/491p6j/why_does_this_happen_simple_function_changes/
But that's for drawing. Not for building, manipulating, and analyzing graphs.
OP mentioned constructing graphs only. 
I think last year some guy put up a link on reddit for a sports survey. There were like 10000 answers if I recall well. I can't find it right now but I think you can look it up. I think it was in /r/entrepreneur or something. Have fun with the data!
Source ? I always felt they were also mandatory for Python3.
Why not just try it out? The PEP that introduced this behavior is https://www.python.org/dev/peps/pep-0420/
I remember some satisfaction by combining `codecs.open()`with the CSV reader (Python 2). Would that work for you?
Came here to say that. Tastypie attempted to steal my life.
Using OOP properly, advantages vs. disadvantages, when to use and not use it. And testing. There's been a big push *for* testing but then 99% of the articles I read are trash. So learning to test well would definitely push you up there. 
This is not going working in national environment. I did sonething similar but the output of ping was different on czech and english system.
Is lambda's scaling really so convenient as to outweigh the drawbacks of this approach?
It'll end combining modules with the same name into one namespace. Unless one of those modules has an init file. That's the best of my understanding and it's enough for me to not explore it more in depth. Check out Dave Beazley's Modules and Packages Live and Let Die for a slightly more in depth explanation of this (and other stuff).
Great post. I imagine this process will be greatly simplified once lambda supports a requirements.txt file (as it appears they are working on based on the AWS forums responses).
Ahh I see. Thanks. 
My concern would be the the time and memory constraints. If you can ensure smallish data sets it should be fine. 
&gt; First install inthing with PIP. You'll probably know if you need to use sudo or not In case anyone can't figure out the joke: the answer is not. You should essentially never run "sudo pip install".
Thanks! it works! Can I read a stream via API?
Do your own homework.
&gt; Thanks! it works! Great! &gt; Can I read a stream via API? Not at the moment. There is an API (https://www.inthing.io/api/public/), but it doesn't expose much yet. I would like to get an impression of what people would want to use it for, but reading a stream back sounds like a good addition.
miniconda is where it's at for sure. Guaranteed to not have weird package compatibility issues + not having to build the packages is really nice. 
My concern is the opposite. Only large requests are worthwhile given the time and expense of setting up the analytics stack this way.
Sometimes just whoever manages the language forgets this one little detail. There are some compilers in other languages that will do this for you automatically if they see an integer in the exponential, but others will call the standard exponential function which of course takes time to converge. I've just found in a lot of instances it's just better to force the language to ensure it gives you normal multiplication for integer powers. 
Certainly not on your personal/development machine, anyway. There are lots of cases where a sudo pip install is appropriate though, such as a dedicated Raspberry Pi server, or a Docker container.
just google pandas and sklearn tutorials, you'll find lots.
It still does the same thing it did before - (usually) make existing blocking IO libraries suddenly 'asynchronous'. Asyncio is awesome, but you need libraries written to specifically work with it.
Hijacking the thread: Scrapy also has a release candidate with (partial) Python 3 support. See here: https://pypi.python.org/pypi/Scrapy/1.1.0rc3
That seemed to do the trick! Interesting. Why are the quotes necessary, do you think? I don't understand why I would need to make it look as if the file name is a string? Regardless, thanks for your help, both of you!!
See also [the full list of 150+ available API docsets](https://kapeli.com/dash#docsets), courtesy of [Dash for OS X](https://kapeli.com/dash).
The filename is supposed to be a file or string: http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.loadtxt.html
I've been wanting to play around with geographical coordinates in python, primarily to help to visualize and plan my geocaching trips. I'll definitely have a look at this. hei forresten
With an if statement and a list of known swear words. For example: words = ['duck', 'grass'] if word not in words: # your word is good 
I think asyncio is a much better plan if you're writing new code. gevent support for Python 3 is exciting because some people have existing gevent codebases that have prevented them from switching to Python 3 until now. (Unless they wanted to run on an unofficial branch of gevent, which sounds terrible.) 
To use old code without complete rewrite I guess.
First, define the problem. What do you want it to do, exactly? 
What? You don't. The loadtxt() method expects the filename as a string, which is not the same thing as the file itself. It assumes that the filename points to a file which it knows how to read and it crashes if otherwise.
the reason that xrange is faster it's because it is a generator; therefore you dont spend time creating the range list in memory then iterate over it again from the start in python3 range is xrange
In a lot of ways the automatic, greenlet-based system of gevent is much easier to work with than explicit asyncio.
This is really neat, I try it out later this week. Also glad to see you got permission for using the Docsets, I recall he went through some frustration early on when people started using his docsets without asking first.
Just a heads-up, you're getting some down-votes, not because people are being unfriendly, but because this is really a question for /r/learnpython. The sidebar of /r/Python reads: *"news about the .... programming language Python. If you are about to ask a question, please consider r/learnpython"*. Additionally, "**Post learning questions to /r/LearnPython**" is stickied to the top of this sub. /edited for formatting
When someone says for example "fuck" my discord bot removes that message and says @user dont say that word
I forgot about that. :)
You can't do it with `namedtuple`, because it's an immutable type. Can't be modified after creation, so `self.whatever = 10` won't work. It's a great little pattern for small value types, like coordinates: class Coords(namedtuple("Coords", "row column")): def __add__(self, other): return Coords(self[0] + other[0], self[1] + other[1]) def above(self, distance=1): return self + (-distance, 0) def below(self, distance=1): return self + (distance, 0) def left(self, distance=1): return self + (0, -distance) def right(self, distance=1): return self + (0, distance) # And so on 
 &gt;And yet gcc still supports -std=iso9899:1990, -std=c++98, etc... You can't use modern C++ and expect it to compile with old C++ compilers. What is different with the C++ community is how fast they have adopted the new standards. &gt;No one is demanding that the world stop turning, or that people stop developing features. Yet that is exactly what the 2.7 crowd is demanding. Python needed fixing in order for developers to seriously consider developing new features. The word Luddite comes to mind when listening to many of these whiners. As for bridges if you live in the great but cold and snowy north you will realize that bridges are constantly being rebuilt it reconditioned as the freeze thaw cycles works it's magic on exposed concrete. The salt doesn't help either. In any event the state most certainly does try new techniques to get those bridges to last a bit longer. Sometimes that means ripping out the old bridge work. Given that do you seriously want a programming language to remain static for 50 years no matter how many mistakes where made in the original implementation? Consider this the computer industry itself is not much older than 50 years, in those few decades a huge number of languages died out in part because they couldn't evolve. Make no mistake Python will die out if the 2.7 crowd keeps up their nonsense. Other languages are posed to take a considerable number of Python developers if Python ends up off the tracks. 
pyuv is better
Oh is that so? Tell me about pyuv's monkey-patching features? How does it implement green threads?
Sure, since you asked. The current popular django based cms options are Djang-CMS, wagtail, and Mezzanine. All of those options are fantastic. However, they definitely lock you into 'the way'. They all have their own way of creating new content models. What I am making is an application framework that allows developers to extend the basic functionality in their own way through mixin classes. It doesn't lock you in to thinking about a content object as a 'page' or a 'blog post' for instance. Content objects are just content objects; a developer can use them however they want. Overall, it's a content/data driven approach rather than a view based approach. Let's say I wanted to create a blog app for instance. With my idea, all you would need to do is inherit from BaseContentObject and define your own fields. BaseContentObject has several of it's own fields like title and slug. Users can then add their own fields like 'meta' and 'post_content'. The other CMS options do this, but they define their own model managers and model fields to work specifically with their architecture. In my opinion, this is a bit too complex. It's almost like learning an entirely new framework. Say you want to create a hierarchical model. Many people definitely know how to do this. However, it can be difficult to figure out how to dynamically generate url paths to said object when a parent object changes it's position. This is the exact reason why other CMS frameworks abstract the hierarchy based logic away from developer. Wagtail for instance uses a very difficult to understand routing mechanism. You can see this in the source [here](https://github.com/torchbox/wagtail/blob/master/wagtail/wagtailcore/models.py). In my opinion, abstracting logic from the developer is a sticky situation. In some cases, it can be helpful, in other cases, it can be detrimental if a developer wants to change the behavior of a model or view. I want to hit a nice middle ground where the boilerplate code is abstracted, but the behavior is not. I also want my project to be able to do more than just create web pages. I want developers to able to create APIs through simple mixins. Basically, I want to create a data driven approach where developers focus most of their energy and time creating the models and the rest is built in for free. Any criticism is greatly appreciated as it will only aid in the design of the tool.
Apologies! I saw the sticky and I thought clicking it would take me to /r/learnpython and thought I was posting there, in fact. Thanks for the heads up.
Ask learning questions in /r/learnpython.
Will do. Thanks!
Link to the code: http://pastebin.com/kaG1tyNW. The only tricky part is finding the dx and dy. This involves some trig.
Any other place where to find it after ... "This page is no longer available. It has either expired, been removed by its creator, or removed by one of the Pastebin staff."
guv does that. It's pyuv+greenlets. 
their's a couple languages that support something like this. https://en.wikipedia.org/wiki/Symbolic_programming i had an idea for it's use but i can't remember what it was. maybe if you have some data going around you could easily have it easily assigned to variable without having to explicitly declare a new one.
since when have you just been able to put [] next to functions like that?
Both functions return a dict. Putting the `[]` next to the parentheses like that tells Python to put it next to whatever the function returns. You can also do the opposite: def foo(): print('Foo') def bar(): print('Bar') choices = {'1': foo, '2': bar} choices[input('Input 1 for foo, 2 for bar: ')]() The above code demonstrates how return values of functions can be plugged right into other elements of Python's syntax, and will print "Foo" if the user enters `1` or "Bar" if the user enters `2` because it uses the return value of `input()` as a key to lookup in `choices[]`, and then calls the function that `choices[]` returns.
Works with the oldest version of Python I can download from the site: 2.0.1 (released 6/22/2001). So… since a while. Edited to fix typo in date.
&gt; &gt; And yet gcc still supports -std=iso9899:1990, -std=c++98, etc... &gt; You can't use modern C++ and expect it to compile with old C++ compilers. What is different with the C++ community is how fast they have adopted the new standards. Who do you think is demanding new features be supported in old interpreters/compilers? I don't think you understood my point. Existing legacy codebases for the most part Just Work™ with new compilers. Yes, you can't use necessarily new features, but you're not abandoned. &gt; As for bridges if you live in the great but cold and snowy north you will realize that bridges are constantly being rebuilt it reconditioned as the freeze thaw cycles works it's magic on exposed concrete. The salt doesn't help either. In any event the state most certainly does try new techniques to get those bridges to last a bit longer. Sometimes that means ripping out the old bridge work. Funny, that's exactly where I live, and I see maintenance being performed on 80 year old bridges every year. Occasionally major work is done to shore up the architecture. All without abandoning the old bridge, or even closing it the most of the time. Again, I don't think you understood the point. &gt;Given that do you seriously want a programming language to remain static for 50 years no matter how many mistakes where made in the original implementation? Consider this the computer industry itself is not much older than 50 years, in those few decades a huge number of languages died out in part because they couldn't evolve. Make no mistake Python will die out if the 2.7 crowd keeps up their nonsense. Other languages are posed to take a considerable number of Python developers if Python ends up off the tracks. You know how lots of languages died? Major new releases in which backwards compatibility was abandoned, together with dropping support for old versions. Perl nearly succumbed to that fate. VB survived it by throwing massive amounts of resources at the transition. If the split is what kills python, it was utterly predictable. However, I don't believe the responsible parties are actually dumb, so I doubt that this will kill python. I wouldn't be at all surprised if we continued to see development effort in the 3.x line to improve compatibility and migration from the 2.x line, and for support to ultimately be available perpetually. Dismissing people's concerns as whining is exactly the sort of thing that divides the community, far more surely than any technical split.
A previous PHP codebase I worked on used this. It made it much harder to figure out what variables were being used where. You should think very carefully before doing this.
Because your idea is going to deal heavily in new abstractions, you should write a series of blog posts about what's wrong with the each of the existing models. be sure to note why your model is better. If you're convincing enough, people will be interested in following your approach and you can get some good discussion to further flesh out the idea. For instance, I could criticize this part: &gt; The other CMS options do this, but they define their own model managers and model fields to work specifically with their architecture. Django defines model managers / model fields to work with its admin framework. However the default admin is only extendable to a point, the internals are a mess so its hard to build your own plugins, and you're locked into using their templating system or overriding everything. Once you've decided to override everything, and build your own plugins---then the real question becomes: "what exactly am i getting from the Django admin that make me want to keep it?" At this point, a lot of people just throw away the django-admin and design their own backend which necessitates you'll use their own managers/etc. because the backend **needs** a consistent interace to your models. (Point: I have an in-house CMS that editors use for image-workflow, no one touches the Django admin). Yes, you don't have to take that approach but your task will be much harder to get a good backend within the django abstractions offered. &gt; Basically, I want to create a data driven approach where developers focus most of their energy and time creating the models and the rest is built in for free. Your goal is extremely intriguing, but like I said... you have to flesh it out to gain support and interest.
In PHP: $foo = 'bar'; $$foo = 'baz'; echo $bar; // prints "baz"
If I understand correctly, it sounds like you want to train a predictive model to predict a certain outcome, and at the same time, you want to know which variables are the most informative ones? There are many, many approaches to tackle such a task ... Since I don't know if you are looking for a regression or classification approach, and which particular hypothesis space you are interested in, maybe "sequential feature selection" would be the most general and flexible approach. Here, your feature importance assessment is directly tied to the performance of your model,; so, you can basically explore any hypothesis space you want -- no assumptions beyond your learning algorithm required. I've implemented it here http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/ Let me know if you have any questions about the usage!
It's not hard, it's just foolish exec('{0} = {1}'.format(varname, value))
 think you get my point. To make it clearly, I want to , for example, two particles contains several different variables, like , px ,py, pz, energy... and the combination of them. I want to input all the variables and which particle they are . Then I got a algorithm ( or something called machine learning) , and when I input some variables, it can tell me is it particle one or two . I don't know it is a regression or classification approach , the variable is continue and the results are discrete and I want to distinguish them. Finally , thanks a lot , I will try to go use this package in these days ! 
&gt; and when I input some variables, it can tell me is it particle one or two That's classification, then :). Again, there are multiple algorithms that are suitable for that task, logistic regression (don't be confused by the term 'regression' here, it's a classification algo), linear and non-linear kernel SVMs, decision tree learning, multi-layer perceptrons, ... the list goes on and on and on :P. In practice, you'd start with the simplest hypothesis space, probably logistic regression, and try more complex hypotheses from there. (typically, you compare the performance of the different models via nested cross-validation, an approach that aims to provide you with a somewhat unbiased performance estimate of your model.) In any case, let me know if you have any questions and I can hopefully point you in the right direction for more info material regarding machine learning.
My python mentor from work told me to put a comma at the end of line regardless if there is another element or not. At least for lists and dictionaries. I would have probably rearranged it like this: class ContactForm(Form): name = StringField( lazy_gettext("Name"), description=lazy_gettext('Enter your name'), validators=[ InputRequired(lazy_gettext("Please, enter your name")), Length(min=2, message=lazy_gettext("Your name must have a minimum of 3 characters")), Length(max=128, message=lazy_gettext("Your name must have a maximum of 128 characters")), ] ) I didn't quiet understand what SCM issues you had though.
Maybe you can use numpy's sqrt and sin instead of importing math. One less line.
It's so nice of you!
oops... only 4 hours of sleep today, my eyes are failing me
Cool idea, but something about the perspective feels off. Granted, I haven't seen the screensaver in years. To me, it just looks like dots spawning in the center and going out radially. I'm not getting the spaceship feeling. 
Kind of a tangent but here goes: I seem to switch between two approaches depending on language: 1. Local approach: fewer files, fewer functions, more commented blocks. 2. Code browser approach: if you can easily jump to function definitions, I tend to create bigger file hierarchies where every important piece lives in its own file together with its helpers. Commented code blocks become helper invocations.
All of the stars accelerate following the same speed curve. When a star passes close by, it is supposed to move very slowly and then really really quickly. Randomizing the start position and speed of the stars will help with that a lot. Edit - also, stars will always need to accelerate away from the center of the screen. i.e., no stars will move from the left side to the right. 
You should be able to reason about which variables live in which scope. For namespaces with a dynamic set of keys/names there's dicts. If you find yourself often using some dict value, make a shortcut: thing = data['thing']
The acceleration is backwards. As stars spawn in the middle (further away), they should accelerate as they pass by closer.
Publishing code would be a good first step. Where is the link?
1. Learn to thread 2. Put threaded programming on your resume 3. ??? 4. Profit 
Comma at the end of every line (including the last, which Python allows everywhere it matters) has the same advantage.
The top ones are absolutely used, but as I went down the list I realized I hadn't ever heard of some of them. Then I come across this one: https://github.com/danmcinerney/wifijammer All it does is scan for networks and devices and spams deauth packets to the AP and client. 1.5k stars for repo. 5k for dev. Even has instructions for how to using it while driving around. Really wish repositories with productive code were given some recognition instead of shit like this that has near zero practical applications. 
If the amount of lines does really matter, then it could be actually optimised.
it wont import cv2, is that something you have to download?
Casual, do it all on the main thread with no sleeps. Nah really though doing this on one thread isn't too bad. But if not, threading/subprocess is probably all that's needed here. As long as you expect to run only functions it's easy. I bet tasker also would use callbacks and such though but I don't think this guy needs it that complicated. 
They should also get bigger.
https://www.freedesktop.org/wiki/Software/systemd/
You want to check out D-Bus ([Wikipedia](https://dbus.freedesktop.org) / [official site](https://dbus.freedesktop.org)). It's one of the most unknown, underrated, and underused technologies on desktop Linuxes.
Yeah both that and numpy are libraries you'll need to download. Easiest way is to use pip to install them universally, the "correct" is to use an environment manager like venv to install them local to the project. Though I haven't done any serious Python programming in a few years so venv might not be the most current recommendation.
Could theoretically gevent just become monkeypatcher to make synchronous libraries to become asyncio-based asyncrhonous?
Oh, for sure - it's a terrible idea, and I'd never actually do it.
Sure. Effectively it creates a space "wraps around" at z=0 and z=5. At the start, I created a matrix of points in 3D space evenly distributed in a cube spanning -500 to 500. To make this continuous movement, I want the stars to move smoothly towards the viewer (z = z - 0.01). But if we just do this, we quickly run out of stars, as they are all behind the viewer. A cheap trick is to force them to wrap around. Here, the %5.0 forces stars with z&lt;0 to jump to 5.0+z. The very first time it runs, this % operation also forces all z values (originally -500 to 500) into the 0.0-5.0 range so that the distance scaling looks right. I could have scaled z before dividing but it was easier just to let the modulus do the trick, since the original distances were random anyway and scrambling them up with the % operator makes no difference.
Check out Gooey
Best way to find that out is to experiment, pull up a terminal and do something like "8.5 % 5", see what happens. 
They should also spawn at a different depth, these stars all appear on the same conical surface.
I think he understood what the operator does, but not the role it plays in this program.
If you're going to write code to mangle your pickles, it's probably the same amount of effort as switching to a different format. Can you tell us about your code? Is it performance critical? That's generally the reason for using pickle. Do [Capn Proto](https://capnproto.org/) or JSON fulfill your requirements (edit: or a database)? 
Twisted does async events
asyncio isn't based on green threads, so bit of a mechanism mismatch there. Asyncio is also usually written with an explicit style, either with explicit coroutines or working directly with its event loop and callbacks, neither of which are what gevent does. It would end up looking like gevent being called by and running next to asyncio, not really them running together.
I'm still working on the core locally. I suppose i could throw it up on github, but it isn't really functional yet. 
Thanks for the awesome advice! What you wrote about the django admin is something I had been worried about. I suppose getting the idea out there would be a good start. My main issue is that I'm not a good enough programmer to really dive into the type of abstraction needed to make my idea work. Do you think it would be a good idea to try and build the core functionality and write some articles about the roadblocks I run into?
It seems to me that your code does exactly the same thing of ssh: hive -e 'some hql' | sed 'some_transform' | gzip | ssh &lt;ssh authentication&gt; "cat &gt;remote_path" Likely you better use ssh instead. I can't find any reason against having a long last connection. In one way or another, you have to move 100GB, no matter what. Ask your IT if the bandwidth occupation for a long time is annoying.
I tried using ssh, but the server kept refusing write access. 
Check out pyside and QTDesigneer
Tkinter would be ideal for a small settings dialog, but you'd have to use a third-party library for minimizing to the notification area plus some extra manual stuff, as explained here for example: http://stackoverflow.com/a/17214998.
Have you looked into webmin and or cloudmin?
[**@pycon**](https://twitter.com/pycon): &gt;[2016-03-04 17:12:31 UTC](https://twitter.com/pycon/status/705803119494504452) &gt;At this moment, exactly 2,000 people are registered for PyCon 2016 — which puts us ⅔ of the way to capacity! ---- [^[Mistake?]](/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=/498qyh%0A%0APlease leave above link unaltered.) [^[Suggestion]](/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/joealcorn/TweetPoster) [^[Issues]](https://github.com/joealcorn/TweetPoster/issues) 
It's in Portland this year in May/June; runs over Memorial Day weekend however :(. If you do go, see you there!
Jenkins would be a great starting point to manage things.
Some ssh servers are configured to only accept sftp subprotocol, no direct shell access. Could you paste the exact error message you're getting?
/r/learnpython
There's an implicit Python expectation here, but I'll go against the grain here and recommend AutoHotkey. AHK scripts can be compiled to exe and they include all of the necessities for basic GUI work in addition to access to Windows APIs for most functions, or raw DLL calls when needed. 
Yeah, I was just shy about adding it. The repo is here: https://github.com/FFX01/wizard
Obvious question: do you have Flask installed for the same Python version you've told PyCharm to use for this project?
I do but they way that this is used is just different than the way I was taught. I was taught to use it like a boolean comparator. This is a much more functional but of code. I'll be playing with this code tonight when I get a chance. 
celery + supervisor
It sorta depends. If the receiver can accept multiple file splits then you are better off splitting the data up on the hadoop side and then iterating over the file splits to send it out. That's going to be a lot easier to recover from than a pipe with the potential to have an interruption. I'm guessing anything you need to do with sed can probably be pushed up a layer to hadoop and there's also no reason why you can't zip on hadoop as well. tl;dr use the distributed processing system for everything but the final push and break up the task if possible
Yep. Good question though, now I'm investigating around the same area to see if I'm missing something trivial, thank you.
Ansible + Rundeck would work great for this solution. Ansible Tower even better if you want to spend money and get support. 
Why non javascript? Html5 canvas is a pretty great visualization tool.
Never seen this recommended. It looks _ugly_ as hell. Comma at the end (as ksion points out below) is what I see consistently recommended / used.
Can Sqoop dump data to a text file? I use it already to move data between RDBMS and Hadoop.
The square root of the sum of squared differences of coordinates is exactly [the definition of Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance).
WTF is TurboGears?
Sqoop can export as CSV, I suppose it depends on what, specifically you're coming from and going to - re: SFTP here's the connector, developed last year, that might help: http://sqoop2.readthedocs.org/en/latest/Connectors.html#sftp-connector
https://docs.python.org/3/howto/webservers.html#turbogears
Ok. Looking forward to it.
This submission has been randomly featured in /r/serendipity, a bot-driven subreddit discovery engine. More here: https://www.reddit.com/r/Serendipity/comments/499n1y/remember_the_old_ms_starfield_screensaver_its/
This is both incredibly amazing and utterly disgusting. The obvious question is `why`, and the obvious answer is then `why not`. I think I am still in shock. You are awesome.
Had no idea TG was still active! Who is using it these days?
I'd love to go but the company I work for has no money :(
Make sure pycharm knows your python path as well. Are you using a virtualenv?
Create a csv table in hive and then perform an insert into select from your origin table. This will create a directory full of CSV files that you can send directly. Don't mess with dumping the orc files, that gets done client side and it is terribly inefficient.
And get rid of the loop in the process. Numpy almost never needs python iteration. 
I do this kind of thing all the time. I'd suggest: * Breaking this kind of transfer into smaller parts. Not millions, but maybe dozens. That'll mean failures won't derail the entire transfer, just a part. And the number of parts is small enough that it's easy to do a little accounting to ensure you're not missing any. * Ensure that downstream consumers don't start reading from your file before it's complete. That typically means writing to a temporary filename then renaming it. * Create an audit trail so that it's easy to double-check and validate your numbers. Then keep this. 
[**@drandreaskruger**](https://twitter.com/drandreaskruger/) &gt; [2016-03-07 00:30 UTC](https://twitter.com/drandreaskruger/status/706638148886007808) &gt; Starfield Scrensaver in 12 lines of \#Python with \#OpenCV &gt; https://www.np.reddit.com/r/Python/comments/495pum/remember_the_old_ms_starfield_screensaver_its this helps: &gt; conda install -c https://conda.anaconda.org/menpo opencv ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
I ran in to this problem that pycharm wont update python intepreter library. It runs fine but pycharm wont recognize it. The solution was to delete that interpreter entry from tables.jdk xml file in pycharm setting folder and reｰadd.
Hopefully your situation improves! Next time, however, they do offer financial aid! It is an application process, and I am unfamiliar how it works but it is there! https://us.pycon.org/2016/assistance/
Good catch, thanks will make an edit
How far away is your client? If this is an one shot operation I would consider mailing encrypted HDD or deliver it in person.
~Brazilian Too~ Thats a pretty cool app! Works very well, as far as i can see.
Damn. Wrong side of the country
If ssh connection lost, it would cause to loss of all transferred data (up to 1ooGB!). I would go with 1) hive -f file_as_below.hql INSERT OVERWRITE LOCAL DIRECTORY '/myDir/out' SELECT ... 2) cat /myDir/out/* | gzip --stdout &gt; nice_filename.qz 3) sftp -b batchfile [user@]host ... I don't see what is use for python here 
Neat. It's funny how eventually no one will have a computer that can run that program, but we can always go back and watch videos like this to remember how things were.
Might want to have a comments section and/or link it to a reddit or HN thread. Best discussions happen in public, not from the 'contact me' button.
Registration link: https://us.pycon.org/2016/registration/ Conference Registration | Cost ---|--- Corporate Rate | $600 USD Individual Rate | $350 USD Student Rate | $125 USD 
https://github.com/myusuf3/delorean is another good one * * I wrote this.
So, if the function is going to return a string, it cannot run well in shell when you call it in idle. Why?
I've not used idle in a while, but iirc idle will print out the result of a call after it executes. I'm guessing if you just did def main(): pass it prints None? I'm not near a computer to validate, but I believe that's how it works in idle. As to why it "doesn't work" in your shell is because it's performing as it should, returning the value from the function. Since you neither assign it nor use is as an argument to another function, it's simply silent. You could do: def main(): return "my string" print(main()) 
Pythonanywhere.com
I'd go with a VPS or a Platform as a Service (PythonAnywhere, App Engine, Gandi, ...). However, a PaaS platform may require you to interface your app with WSGI, so your app may become a little hacky...
Hotels are filling up too!
you don't need to extract it first, you can read members from within the archive directly
I wonder how many non-default Ubuntu packages have Python 2 as a dependency. I'm not sure finalising the move to Python 3 is as simple as not including it in the distro (unfortunately).
Good move imo. People need to stop developing for 2 and move on. And let's be honest, the target audience for Ubuntu is the average user, not the multi-million dollar corporation with legacy infrastructure.
This is only for the Desktop version, the server version has been running 3 by default. Although it is available to install if one needs it but in this case it would not be on the default install which is what they were going for. 
What would you implement instead?
Done. Check the samples directory. edit: You can change the colour and style in `inputs/resume.yaml`. I'm currently using purple (Engineering colour in Canada) with banking.
ISO-9660 is a convenient format for things like pxe booting or installing virtual machines. There's really no other format that's as universally compatible, even if you don't bother to actually burn a disc.
That'd probably work for the subset of subprocess/multiprocessing. On the other hand, gevent's greenlets offer a much lighter-weight solution to the problem than either threads or processes, and work without having to go through the extra steps of invoking a pool.
Setting up PXE isn't all that simple all things considered. But I have a stack of empty CDs lying around since 2013 I bought for $4.99 and CDs/DVDs are compatible with pretty much every computer out there. I agree USBs are objectively better and cheaper, but I think CDs are simpler and definitely more compatible.
Actually there's plenty of Ubuntu deployments in enterprise, however they know how to install python2 if they need to...
.iso is a disk image you can write to boot drives. It is a file format specified under ISO9660. [Here are the Ubuntu instructions to write an .iso to a USB](http://www.ubuntu.com/download/desktop/create-a-usb-stick-on-mac-osx) on OSX for example. 
What's wrong with wsgi?
Great. It's an LTS, so it will be around for a while. Makes sense to have Py3 as default. Finally!
Enterprises will welcome this as the system python stops interfering with their legacy python2 stuff with the binary modules for python 2.[4567] that nobody knows how to recompile anymore and their mission critical applications depend on for their daily business and they can keep on dragging this stuff for another decade. 
I'm unable to run as-is. Traceback tells me that jinja2 can't find the template sections\items.html. Tried a short debug but didn't find something to fix quickly. Might be some issue with windows paths?
I don't have Windows, unfortunately, so I can't try it out. I used `os.path.join` in order to make the paths. Maybe they are splitting at a `/`? Does it run if you remove the HTML and Markdown files in main (bottom of `generate.py`)? edit: Found it! The slash is hardcoded [here](https://github.com/mitsuhiko/jinja2/blob/master/jinja2/loaders.py#L27). edit 2: Submitted [a fix](https://github.com/mitsuhiko/jinja2/pull/558) to Jinja. Waiting for CI test to finish. edit 3: CI test passed. Waiting for Jinja to merge the pull request. edit 4: Jinja hasn't had a commit in months. Pushed a fix to use forward slashes instead. Does it work now?
True. I guess my point was that these old things are nearly practically inaccessible to us, but with a quick click we can see exactly how it was. Finding old windows install images, firing up VM, installing windows, previewing the screensaver... or just click on youtube video. Very neat.
More and more machines are coming without optical drives installed though, so a more universal method of creating usb bootable drives is warranted. uunetbootin is a good compromise for Windows, and Ubuntu desktops have a graphical utility to do so. Mac is the only OS that has hoops to go through.
&gt; there is no existing module. there is no existing module. You will have to do it yourself, but the point is that it will be relatively easy. use flask plus the stdlib zipfile
Fixed. Can you try again?
I have no doubt that it isnt a good compromise, there will be a point where CDs and DVDs will be obsolete but it isn't yet. I'm sure there are plenty of us who have computers that simply cannot use USB thumb drives to install anything and I for one have a collection of computers both recent and old. Backwards compatibility is never a bad thing and I think for now, supporting older machines is not only important but almost necessary. Not all of us buy new machines periodically, why should we? It's a bit anecdotal, but could get by with all my computer needs with an old iMac G3, which really requires all these "old" standards. But it doesn't make me any less appreciative of what my new I5 tower can do. I wasn't arguing that unetbootin and USB drives are hogwash, but that having ISOs available is still a good thing and that it doesnt take anything away from technological progression.
That is, in fact, what I do with iso's. You can just `cat ubuntu.iso &gt; /dev/sdb`. Are you still burning cds?
Their is a discussion of it from last year [here](https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=781913) on the debian lists. To quote: &gt;&gt;&gt; I think getting rid of the Python dependency in samba-libs is a much &gt;&gt;&gt; easier to achieve goal here. &gt;&gt;&gt; &gt;&gt;&gt; AFAICT The only reason that samba-libs depends on python is because &gt;&gt;&gt; libsamba-net can do provisioning of a local DC (requires the 'samba' &gt;&gt;&gt; package to be installed) by invoking the provision script using Python. &gt;&gt;&gt; &gt;&gt;&gt; So if we could move that functionality out to a separate library that &gt;&gt;&gt; is not included with samba-libs, we could drop the dependency on &gt;&gt;&gt; python2 in samba-libs. &gt;&gt; &gt;&gt; right, that would get rid off python libs and python-talloc. However there is &gt;&gt; another path in that nautilus-share depends on samba-common | samba-common-bin, &gt;&gt; which depend on python-samba. [Here is Samaba's package/API list](https://www.samba.org/~jelmer/samba4/pydoctor/moduleIndex.html)
It's docker for real hardware
The command that is suggested should work ie. `python deezerexport.py 2529 --export playlists.json` is correct. You want to change "2529" with your userid and "playlists.json" with whatever you want the output file to be. It would help if you could post the error on pastebin. I'm not familiar with Windows, but if you execute the script from a terminal, it should print out 10-20 lines that end with the error - those lines would help anyone to figure out what exactly is wrong (where the SyntaxError is coming from). It would also help to know what Python version you are running. There also appears to be a comment thread underneath the article with an alternative script, as this one is from 2013.
So, people who haven't heard of Pyramid? :-) 
What does it need git for? Edit: &gt; The update date changes based on the time of the latest git commit on the current branch. Seems like a pretty strange way to do it.
"less assembly required than with Pyramid" if you insist :P 
[Python2.7 is supported til 2020](https://hg.python.org/peps/rev/76d43e52d978). End of life date for Ubuntu 16.04 is not know yet, but normally it's [around 5 years](https://wiki.ubuntu.com/Releases). If 16.04 is supported for 5 years, it's support wil end April, 2021. Maybe this was also a reason to not include Python2 in installation.
Amazon webserve is free for a year with thier micro servers
I meant more who is actually using it, not who would like it.
I'm surprised there are so few web framework talks at PyCon. Is python web dying? Should we switch to node.JS?
Ah, I missed that. :-)
The image save tool is entirely inadequate for print media; these low resolution images could only be used for on-screen presentation. Using bokeh requires that I craft a visualization once in bokeh and then recreate with a different plotting environment. Whatever technical challenges you may face, Plot.ly has resolved them to offer print-publication-quality export. 
`dd if=/path/to/iso of=/dev/usbstick` that's pretty universal, even windows can do dd if you install it.
I base my statements on your comments in the bokeh github: https://github.com/bokeh/bokeh/issues/538 It is nice to see some progress towards high quality export options as bokeh cannot be a competitive alternative to plot.ly for academics without this feature. 
Even if they haven't, the python command is a symlink to python2.7, the only thing they have to do is change the symlink to point to python3 instead. Edit: This is assuming they haven't missed any dependencies.
nice thanks!
Odds are `python` will continue pointing to `python2` for a long time yet; many third-party systems are written in legacy Python and use `python` shebangs to point to the interpreter. IIRC there's even a PEP that makes it clear that `python` will probably refer to `python2` for several years, yet. Outside of the python ecosystem per-se, Python2's casket still casts a long shadow.
Noted. I wrote that site a while ago. I have been wanting to rebuild it.
Actually, you're completely right. In a round about way, making python3 the default makes using python2 legacy code much easier to maintain. It's no longer a moving target. You can install the version you want, and they don't cross-talk much. It'll be the Fortran 77 of the python world :)
Anyone maintaining a list of which distros are python3 default? I mean, I completely expect RHEL/CentOS and Debian stable to be last in line, but I'm wondering how it's going for everyone else?
You could do this easily using os.walk() and the csv module to format the output. But if you just want a raw dump of the path structure you could do (without any Python): tree /a /f d:\ &gt; filesys.txt on Windows, or just: tree /mnt/sda1 &gt; filesys.txt to create a text dump of the filesystem on Linux. This could also use -P to include only files starting TL# tree /mnt/sda1 -P TL\#* &gt; filesys.txt EDIT: `tree` is overkill, you can use `ls -R` or `find` on Linux to get a simpler representation. 
You can use [TeX Live](https://www.tug.org/texlive/) in the meantime if you still have a reason for keeping Windows. Bonus benefit of it being identical to the Linux version. I'm not sure how you'd handle MikTeX though. Since TeX Live exists, it's not as simple as checking for whether you are using Windows...
&gt; People need to stop developing for 2 and move on People said this about Ada, Cobol, Fortran, C, Perl, etc. etc. etc. But when "move on" costs 10x that of "maintain what we have", how does that make any sense? &gt; And let's be honest You misspelled "and here's my wild guess"
Fixed it by `os.chdir` before and after compilation instead of worrying about `-output-dir` or `output-directory`. Pushed.
Last time I checked, even this site used Ubuntu server edition. Doesn't sound like an average user.
lol. What I said is how Ubuntu LTS is currently configured. Regardless of if there is an alternative. 
I'm using a virtual env that I created
all except Arch, Arch is special, Arch doesn't care :p 
The official response to this is to specify which python version to use. You shouldn't use python anymore, instead use python2, or python3. This ensures the correct version is used.
Yeah, between Arch and Gentoo, there's always people willing to bleed a little for the sake of the rest of us :)
You can just write an ISO.
Works fine if you update your alternatives table. Plenty of hits on Google on how to do this: https://linuxconfig.org/how-to-change-from-default-to-alternative-python-version-on-debian-linux
Absolutely nothing, there is nothing wrong with WSGI. It's just that running a non-web app with WSGI is not very suitable. If the bot is not a web application per-se, it may be weird to interface it with WSGI. I used to hack around my Bottle/WSGI app on a PaaS to fetch some data in "while-True-sleep" loop, it was not a joy...
arch doesn't give a shit. arch just does what it wants.
Anyone know if Reddit has been moved to Python 3 yet? What version do they use?
Pretty sure most people installing Ubuntu server can run &gt;apt-get install python2 without any problem. This is just a part of moving the Python ecosystem away from 2.x before its EOL date in 2020.
The code for the simulation is here: https://gist.github.com/omegahm/e823a68c201406d32a94
Seems like a mere symbolic move, I for one will still maintain the practice of having both py3.x and py2.x deployed on my systems for compatibility reasons. 
Enterprises are the only ones *paying* for Ubuntu though.
If your income depends on a legacy COBOL system, and said system works, what is your incentive to spend a bunch of money replacing it?
If anything, arch changing to python3 might encourage the move to specific python2/3 usage over `python`. I like to dream, at least.
Issue is that with those OS X refuses to play nice... (python2 eg doesn't work) 
If you don't want external dependencies, you can probably get away with using `http.server` and overriding the `do_GET()` method (look at https://hg.python.org/cpython/file/3.5/Lib/http/server.py#l626 for an example), and using `zipfile` to grab the file out of your zip file.
Manually installing [VC2015 Dist](https://www.microsoft.com/en-US/download/details.aspx?id=48145) on the machines throwing the error should solve it. 
...yeah i'm going to have a lot of luck pushing that one up the food chain to have it laid down as an update. what's odd is that building on multiple machines produces the same result end-game. is there an alternative utility out there i could use instead? 
I'm also interested in an answer. Have you tried stack overflow?
I mean, as far as I can tell the compiler is 100% the problem. I'm sure it's relatively easy...or at least possible...to fix. The issue is that I *have* the recommended compiler, and there is really no resource out there for people for whom it's not working. I'm not adept enough to dig around and figure out why exactly it's not working and the error Theano is throwing (see the OP now, I edited it) is...verbose. 
Check to make sure pycharm is using you virtualenv's interpreter and not your global interpreter. If that doesn't work you can go to file -&gt; clear cache/restart to have pycharm regenerate the project skeleton.
In some projects that can mean changing several hundred files, and I'm lazy.
Hi, I very recently had to do what I can only assume is the same task, so please let me go ahead and help you with your problem but also highlight some other areas where you could improve. In terms of structure, I would start off by getting comfortable with using functions. This task is very easily doable by using functions, as breaking up the task into certain bits is recommended to make life easier for you and to make the program itself more efficient in general. You can create a function by saying def functionName(): #someStuffIwantToDo and then call this function to execute these commands by simply saying functionName() You can also pass a value, or a value of a variable into a function, but you need to declare your function differently to do so: def functionName(placeholder): print(placeholder) and call this by saying functionName("HelloWorld") which would print out HelloWorld. That being said, I recommend you making 2 functions, one for check digits (to "calculate" the 8th digit) and a second one for checking if its valid or not. This is because, in your case, it's very hard to tell where you are calculating the check digits, and where you are checking for validity. You didn't actually specify what is a valid 8th digit for a GTIN-8 code. A valid 8th digit is multiplying the number by 3 at each odd index added to all the other numbers in the even places, taken away from the nearest higher multiple of 10. In terms of code, you can easily do something like import math nextTen = int(math.ceil(float(tot)/10.0))*10 checkDigit = nextTen - tot This would ensure that you are getting the next ten up from your number, you then substract the sum of your numbers from this number to get what would be a valid check digit. As for what you're asking... You aren't entering anything for the eight digit. You are entering 7 digits and your code calculates the 8th digit (which is right by the way, i've checked with my own solution.), i dont really see where you are having problems? Btw I would get rid of line 27's if statement because it's completely redundant. Sorry if this is not completely what you're looking for, however I am happy to try and help you out if you can elaborate what you're having issues with exactly. You can also look at my solution for this as a reference: http://textuploader.com/5v2dw
http://pastebin.com/wRnaZG8M
Before you do all this, did you try simply putting the missing DLL into the packaged program folder (for the record, I am running Windows 7 and have this DLL on my system. Use something like [Everything](https://www.voidtools.com/) to easily find yours)? Before you do that, if you happen to use the single file mode, try just packaging the app regularly -- as in a whole directory with all required files.
No! In python you can do this: if want_to_hang_out: my_location = your_city But then my_location isn't defined in some cases! Terror!
Cx_freeze, once I got it built properly(the pip install doesn't run right) did it just fine. 
I've been using WebFaction which seems a bit like a combination shared web host and VPS. I've run Python there without a problem and I also use them for git hosting (and web hosting). I looked at a VPS but didn't want to deal with hardening the server and all of that. (I have zero relation to them other than as a customer). That may be worth looking at as well.
Building on a different machine could also work. if CX freeze works, stick with it. I find with building exe for python scripts/apps you almost need to try them all till you find one that works for your current setup. PyInstaller is just the most foolproof.
its in c:\Users\ &lt;user&gt; \ .PyCharm50\config\options\jdk.table.xml
My favourite piece of context manager lunancy is `_GeneratorContextManager`. Just look at the thing. It's probably the least comprehensivable in the entire standard library -- though, I've not looked at the madness that `decimal` probably has. Yet, it's a wonderful coopted use of generators to do something really unconventional. 
Building on different machines had same results, no function. Unless it was used on a machine that also had pyinstaller. Cx_freeze did the job no sweat.
That's too bad -- I mean I am glad it works for you now, but I must say I quite like PyInstaller; it's the best of all freezers in my opinion. I'd hope it would just work after shipping the missing DLL along with it. If you find time and are in the mood, it'd be great if you could test the suggestion anyways.
~~/u/YuntiMcGunti did you get this working? It's working with python3 for me on my system python but not for some external libs in a virtualenv.~~ nvm got it.
eating larva!
I would wager on the later. Arch mapping `python` to `python3` was such a debacle that the [Python devs officially recommend against it](https://www.python.org/dev/peps/pep-0394/).
yeah the pep basically suggests that `python` shebang ideally should be compatable with both `python2` and `python3`, otherwise `python2` or `python3` should be used respectfully. However, `python` will remain (unideally, but officially) `python2` until some specific conditions are met. Therefore, write code compatable to both if you are using `python` shebang …importing from `__future__` is the simiplest way for a lot of things as its a NOOP on the latest version of python but brings the functionality to thoes versions. (should be called `__current__` IMHO)
all hail the hypnopython
Wordpress is very popular. It is popular because it looks good and is easy for people to add content. People consider it to have security problems but usually that is due to non updated plugins. 
&gt;Maybe this was also a reason to not include Python2 in installation. Unlikely. php5.6 is end of life at end of 2018, but it's likely to be included in Ubuntu 16.04 instead of php7 (due to php7's release being so recent). From what I've seen, end of life of package versions doesn't affect Ubuntu's decisions and they'll backport any security fixes themselves if they need to. 
When I click on anything, it gives me: UnicodeEncodeError: 'ascii' codec can't encode characters in position 6-10: ordinal not in range(128) 
very cool.
Yeah. I'm currently doing a PhD on Bohrium. You could substitute it with `import numpy` and stuff would still work (remove the `copy2numpy`at the bottom as well, that's just a Bohrium safeguard)
Try not to just 'except:' because it means you aren't in control of the code. Think about what your try blocks are protecting and ask what exceptions are potentially going to be raised out of them. Don't catch everything, catch what you expect. On that note, there are a lot of try/except/pass patterns throughout the code and they don't seem necessary. line length - 100-ish chars long is long enough. Otherwise, my monitor vomits all over me as I scroll infinitely sideways. This is a very cool idea. I like it! Your use of the meow meows is doubleplus awesome. Do you use any pylint/pep8 tools to lint your code? 
Oh, I see.
I believe they admitted a long time ago that "saving space on the ISO" is a complete fiction, but they like to pretend they still have that requirement to help fend off bloat. Which sounds like a good plan to me.
I live a 5.4k miles away. Don't even say...
This sub is for regular/advanced users of Python. See /r/learnpython for support and learning materials (do check out the sidebar there).
Also, you should put a real example .html file instead of your example with placeholder values. You should be able to clone your repo and run your little initiate/setup commands in order to see it in action.
Not but porting a code from 2 to 3 is really not difficult. It may even be faster than arguing about it.
It looks like youre trying to run the script from within the Python interpreter. The `python deezerexport.py 2529 --export playlists.json` is something you want to run from the command line. If I remember my Windows correctly, you want to open the command line, and assuming your script is on your C drive, you'd run it like `python C:\deezerexport.py 2325 --export playlists.json`.
Great! Much nicer than the MatLAB quasicrystal simulation that I created for my BSc dissertation. 
&gt; Crucially, the variable only exists within the indented block below the with statement. Think of with as creating a mini-function: we can use the variable freely in the indented portion, but once that block ends, the variable goes out of scope. This is completely false. It may help to think of it this way, but the variable is definitely still accessible. This is even used for things like `assertRaises` where the actual exception is attached to the context manager so you can inspect it once you are done causing the exception.
Any idea what python will point to on a system without python2? Will it not exist or will it be python3?
I liked [profig](http://profig.readthedocs.org/en/default/) a lot the last time I used it.
Everything in "main" is supported, independent of it's availability in the default installation. https://help.ubuntu.com/community/Repositories#Main
Thanks for this. Addresses everything I didn't like about sh (which I still like, but this seems awesome)
More like `pip install future` then: from __future__ import absolute_import, division, print_function from builtins import * from future import standard_library standard_library.install_aliases() But yeah, pretty much.
Yes, but again, it's not the typical case. This situation is 1 time out of 10. And even when it is, porting the dependancies is not very hard either. The main problem is not the difficulty of doing it, it's finding the ressource to do so : it costs time and money, and we all have a limited amount.
Sadly, I have to be backwards compatible with python2, but this really is a good thing to know for when python2 support is dropped. Thanks! :)
The problem is that if you port a dependency you don't control, you wind up with a forked version and overhead of maintaining that in the future. Just look at this list - https://python3wos.appspot.com/ if you're using thrift or protobuf - good luck...
best advice you'll ever get.
Upvote because smart solution
Nope. Nikola for all the reasons listed on their website under 'why static'.
 from itertools import zip_longest, starmap from operator import xor known = map(ord, password) given = map(order, submitted) compares = zip_longest(known, given, fillvalue=6) if sum(starmap(xor, compares)) == 0: ... That might work, it should give you a head start at least. However, if you're worried about the timing difference between comparing two strings, how are you handing the larger time difference when you don't find a user in the first place? Edit: looking back, you could do this if you really wanted to as well. def randxor(self, given): return randrange(10,99) ^ given zip_longest(known, given, fillvalue=type('lol', (object,) {"__rxor__": randxor})()) Hurrah for anonymous classes.
&gt;Great. I look forward to writing sudo apt install python ten times a day. If you're doing that you're probably going wrong already. This is what configuration management is for.
Looks good! You could x-post to /r/loadingicon. Technically it doesn't quite fit, but it's much closer than half of what gets posted there. Also /r/woahdude or something.
I meant in the context support, telling people how to get their scripts working again. (Have edited to clear that up)
&gt; No need for a lib when it's less than 100 loc I made this post when I had already exceeded 100loc...
Sleeping only makes the timing attack harder, not impossible. Given a normalized distribution of random sleeps an attacker can still make a large enough amount of attempts to reduce the random noise
This is great. I was fortunate enough to hear Dan Shechtman talk a couple of years ago. He had the whole audience captive, it was a really good talk.
I have a class I use to handle this, basically you pass in a settings.json file and a settings.override.json file, it merges the two together and then checks for environment variables to use for additional overrides. It's pretty simple and works well, if you don't have luck let me know and I'll whip up an example for you.
Any time you think Python is fast, think again. It's almost always going to be that you've mislabeled something as Python when it's really a native language.
If you are using django I give admin access to content tables. Then the customer can go into the admin section and change any content they want. Then you can build a complete custom django site. This seems to be the best solution for me doing freelance work where the customer customizes the front end content. 
Indeed, though I think the `points` name is misleading here, as it probably looks something like this : points = [(xa, xb), (ya, yb), (za, zb)] I'd have called it something like `coordinates`, since it's a list of coordinates. PS : a generator expression instead of a list comprehension would've saved instantiating a list
Doesn't doing the len check make this not a constant time operation? 
The length is stored as a integer in the underlying structure, the interpreter does not have to scan the entire string to determine the length.
Jupyter notebook?
You can use sublime text 2/3 and configure the build settings to run python scripts for you using a key combination. Example: http://stackoverflow.com/questions/8551735/how-do-i-run-python-code-from-sublime-text-2
Jupyter Notebook
Exactly. So if the lengths aren't equal, it will take a significantly shorter amount of time, because then it doesn't do any actual comparisons. I'd say that counts as a timing attack. 
I wrote [cletus](https://github.com/kenfar/cletus) a few years ago, and still use it pretty extensively today. It provides a few different classes to support different program needs (pidfile, config, etc). But the config class allows you to read in multiple config files, then add environmental variables, then add args. Later additions override prior. Then defaults are applied. Then the resulting config is validated with Validictory. This works very well, though complex nested configs really benefit from a bit of custom code for defaulting &amp; validation. 
There's an entire conference dedicated to Django. It's in Philadelphia this year.
NPM is "light years" ahead of pip+virtualenv. Yeah I wish the author would have started with that, so I could have stopped reading.
You could probably get around that by setting `result = len(a) == len(b)` before the for loop, and just having the one return statement. 
I think the problem with that is that zip will only zip up to the length of the shorter string, so there's still the possibility for a timing attack.
It is not exactly the same, but would just a regular IPython window work? You would still type long scripts separately but you can interactively run code as well. Otherwise, a Jupyter Notebook is likely the way to go
Most constant time comparison functions compare strings of equal lengths. There's usually no point in hiding length, as there are lots and lots of other ways it can be leaked. Usually, constant time comparison is used for values of known length. Passwords, for example, should not be compared directly — only their hashes should be compared (that is, a stored hash and a hash produced from input).
I'm curious about the advantages of virtualenv and the extra tooling required compared to npm?
Should be "python 3 vs ES6" or "python 2 vs ES5"
Hi, I find maybe it's the difference between computer science with physics. I am hardly to understand some of the parts in the website. For example , your algorithm can decrease the parameter space dimension, so I thought you may have an example for input an n-dimension parameters and out put the k-dimension parameters and some rates, for example, the rate for successful classify the data , the error rate ,etc... Of course , I am not blame to you or any computer scientist. I am just hardly try to understand it. So I go through the sklearn. Then I meet my first question: from sklearn import tree X = [[0, 0], [1, 1]] Y = [0, 1] clf = tree.DecisionTreeClassifier() clf = clf.fit(X, Y) I think that in X, it means [0,0] is the first sample and the feature is 0, 0 and [1,1] is the second sample . If I want to add a sample , it is X = [[0,0],[1,1],[0,1]] , for example . But it suddenly comes a problem, it seems in this way , we should put all the data in the memory. Why don't we use a iterator to do this things , or maybe there is some ways to do as a iterator. Maybe it depends on if the fit() function , it can add some data or just recover the data. Then, I didn't find one very important thing, for example, X = [[0,0],[1,1],[0,1]] with label Y= [ 0, 1,1] , If in some case, we need the label 0 case an weight 0.5 and label 1 sample with weight 2.0 , for example, how to add the weight .? But no weight, I can still use the algorithm, although not easy. So I go ahead, I then consider one thing. In high energy , people store the data in some root files. You can consider it as an special vector ( like c++ vector but usually you just read one by one...) , or , sometimes people store data in .txt or .dat file. It seems that the book &lt;&lt;machine learning in/with python&gt;&gt; has deal with the .txt or .dat file. But I think as a popular tools, it should provide a way to do this thing fast. I find it seems that the sklearn.dataset works as an data store in memory. The only thing I need to do is to input .dat file or some root (vector...) file to the dataset? Of course I go to see the : http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html . Unlucky, I am totally confused by it... &gt;&gt;&gt; categories = ['alt.atheism', 'soc.religion.christian', ... 'comp.graphics', 'sci.med'] &gt;&gt;&gt; from sklearn.datasets import fetch_20newsgroups &gt;&gt;&gt; twenty_train = fetch_20newsgroups(subset='train', ... categories=categories, shuffle=True, random_state=42) No handlers could be found for logger "sklearn.datasets.twenty_newsgroups" a bug appear. It seems that I have a lot confusions..But , compare to the data mining tools written by some physical background guys, the TMVA , sklearn seems better , except I can not use sklearn to analysis my data... BTW, in the begin of the introduction of TMVA, it tells us how to import data from root file or .dat file with straightforward commands.. maybe the best advantages for it... You are not necessary to answer me so lots of questions.. it's too many.. 
Have a look at Effective Python: http://www.effectivepython.com/
Did I miss something, or was &gt; Anyway, please take some time and go build a website with Django About the only thing the actually has anything to do with Django?
NixOS by its nature has no default. There is never a /usr/bin/python. Instead, it depends on environments that are built to environment specifications.
It's also very easy and short. The edX course is basically the intro and intermediate combined. Does not take longer than a do complete it.
If using python3+ you can use `hmac.compare_digest`
I'm rather uncomfortable with the fact that you lied to a prospective employer. I hope you actually said something like, "I am confident I can learn Python," instead of outright deceit.
Check out the quick Python book by Manning publications. They have a PDF version and a paper version that comes with the PDF. 
If you want to spend a few minutes setting it up, you can create an emacs macro to do that... But I already know that's the solution nobody wants to hear. 
Read Effective Python, Python Cookbook and Fluent Python in that order. You'll be a Python beast. Also get somewhat familiar with the most popular Python libraries. If you tell me you've done anything web related with Python and you haven't at least heard of Requests, I know you're either lying or you code in a vacuum. Neither of those are good.
Virtualenv allows for different versions of python to run easily, side-by-side, each with their own installed package directory. You can also install packages locally with pip without using virtualenv pip install --prefix vendor/ package name pip and virtualenv are both very flexible, so it's very hard to see how npm could be "light years" ahead, especially with 0 examples, like in the article.
At the link, you'll find a commented gist explaining the algorithm to summarise text. The only here is that you must delimit your text with paragraphs. One of the things I'd like to figure out is how to convert other document types -- PDF and maybe Microsoft Office formats, as HTML is already supported -- to text to be fed into the summariser. 
I also recommend a book Python crash. http://www.amazon.com/Python-Crash-Course-Project-Based-Introduction/dp/1593276036
Running script from terminal builds character. It's a miyagi thing.
You need constant time comparisons for things like hmac checks on password reset links, which is not a place bcrypt is applicable.
[Here](https://github.com/reddit/reddit/blob/7a6fb4ec278fa7545a432d1911207b7e085bfd63/r2/r2/lib/utils/utils.py#L1476) is reddit's implementation.
linux is free. use the tool. you shouldn't be using theano on windows, because none of the developers do and they don't give a shit about making it easy (nor should they when the majority of the ML community uses linux).
Well, you might have skipped a considerable bit, if that's all you read. Try reading the 2 paragraphs before ;)
The book Fluent Python by Luciano Ramalho is quite excellent for going in to depth on the unique features and strengths of Python, and is aimed at proficient programmers.
The only one I've read is Fluent Python. It's fantastic. I recommend it to everyone I know who has only dipped their toes into Python. That's really why I was curious about the ordering... Wondering if the other two are better or significantly simpler.
That's not the point. I fixed my own problem, your solution may have worked but it wasn't the only solution. The point is that having an attitude like that greatly increases the barrier to entry for learning a programming language. Not everyone is a full time developer or CS major, and acting like they should just do it your way or not at all is unrealistic.
&gt; ### Requirements &gt; * python2.7 :/
See also [pep 489](https://docs.python.org/3/whatsnew/3.5.html#whatsnew-pep-489) that came along in 3.5
This is a nice use of array broadcasting. I always love finding nifty ways to leverage this hidden gem of numpy to simplify my calculations!
Why are you starting with Emacs? Something much more friendly would be sublime text or atom or something..
Well, it's not really my subject but last time I checked it support for pyhon 3 in kivy was still WIP, so you may have to wait a bit longer. Nevertheless python 3 real world library coverage is almost full, with a few important exceptions like kivy.
That's my whole point. In your mind, there's a certain set of tools only for developers and CS majors (and the like), and if you don't already know how to use them &amp; ask a question, then someone is gonna jump down your throat about how you shouldn't be using them at all. More and more CS is becoming like other specialized hobbies, like woodworking or beer brewing - except in *those* communities people are exceptionally helpful in getting people from the total novice stage through years of development. For some reason in CS and for most languages the experts hold onto their knowledge like it's some precious secret that must be kept safe.
The only things I really need 2 for are Fabric and Ansible. Everything else I'm pretty happy with.
&gt; In 3 months, Python 3 will be better supported than Python 2. For the [current release of Anaconda](https://docs.continuum.io/anaconda/pkg-docs), Python 2.7 number of supported packages: 425 ... Python 3.5 number of supported packages: 361 ... Only 58 packages to go. In 3 months? I don't think so.
Absolutely. One concrete example- what started as a GUI over an excellent [command line geospatial library](http://www.gdal.org/ogr2ogr.html) for the benefit of our non-technical staff became a multipurpose geotechnical tool. As an added bonus, they were able to use the tools via their thin clients, they never needed local deployment (which can be a chore with some open source GIS tools not written with windows as a primary environment), and the imports to our datastore became *much* more consistent. Being able to output to an API is handy- and if you're moderately clever with your transitional formats you can just wrap a @route('\api\functionName') over your functions. It's not much work at all- in the case of Bottle, returned dicts are automatically turned to JSON. I also think you end up with a much better looking app. I generally find a good d3 graph looks much better than what our users could knock up in excel for instance, let alone my hamfisted kludging with UI designer. With a good CSS framework you can go mobile too- although I've only used that for live reports and logging in-the field.
I've been working with React.js for a client recently and I was impressed with the similarity between Python using Kivy and ES6 using React.js, here is a [line by line translation of ES6 to Python](http://chaosbuffalogames.com/blog/react-redux-todo-list-ported-to-kivy.html) I will say this the current state of using ES6 is somewhat horrid. Imagine if to write Python 3 code you wrote it, and then compiled your code to Python 2 to run it; introducing a several minute compilation step into what used to be a dynamic language. This compilation is actually portrayed as a 'good thing' here in this article. It is definitively not, it makes error messages more obscured (as the error is in the code generated from your code), it causes small changes to take quite a while to see the results (given that js is mostly used for frontend dev not a nice thing at all for your dev loop that might be change one number, trigger 2 minute recompile, take a look), and besides if you really did want such compile time processing, Python has Cython which is both more flexible and more fully featured when it comes to a compiled language. 
If you are simply looking for problems to solve to help practice then have a look at [Advent Of Code](http://adventofcode.com/). A new set of challenges come out every year starting December 1st and stay up all year long. The problems are not programming language specific. You may choose whatever programming language you are comfortable with. It is a great exercise in problem solving and programming.
You should use Emacs24 because it has a new package manager, `package.el`. You can call it with `M-x package-list-packages`, then see the menu. You don't /need/ it though, just use the emacs you can install. You only need pyenv if you want to install a python version that your system doesn't provide (certainly python 3.x).
I think you just point out why they were unusable. To me, \_\_del\_\_ would be usable if it was called when the reference reached zero, not at time of garbage collection. For garbage collection, it would maybe be \_\_free\_\_. From this ideal \_\_del\_\_, you would be able to free what you want, and optionally force garbage collection of that object. That way, you could free exclusive resources without having to require close() calls on every object or indent all of your code with a try...finally or context manager. To keep from indenting eating up my 80 characters, my scripts end up looking like: resource1 = None resource2 = None ... resourceN = None try: # things finally: if resource1: resource1.close() if resource2: resource2.close() ... if resourceN: resourceN.close() But, if they can handle circular references now, then they're much more usable and the above could usually be avoided. Requiring the Python programmer to guarantee non-circular references to keep your Python from being leakier than a c program is not what a sane Python programmer should call "usable". 
Pretty much
This seems to be doing just that -- lazy operations. 
Regarding your last point, the problem was circular references with finalizers in the loop, it's not as bad as it's in perl.
No. `len()` on strings, bytes, lists, tuple, dicts and sets is a constant time operation in Python. Since the code only operates on strings and bytes, it is constant time. Even if that is not the case, the function makes no promise about hiding information about the lengths of strings when they are not the same length. That's impractical, and `compare_digest` makes the same explicit no-promise in that case.
If you are an experienced programmer, just start writing stuff in python.
&gt; but circular references are a deal breaker. What do you mean? Python 3 supports it with circular reference. The only time a weakref makes sense now is an external-to-python, and poorly managed, resource. &gt; If you avoid every possible circular references or appropriately use weak references, you are and were up to the ideal. No, you're now at the usable state of python 3. My ideal would be called when the reference count reached 0, not at the time of GC, which nobody cares about in practice. We're using Python because we *don't care* or want to deal with memory, resources are interesting to us. If a resource is done being used (count == 0), then do something. When the interpreter decides to lazily free some memory in it's deep internals, then do something? Wha? Oh, wait, from [the documentation](https://docs.python.org/2/reference/datamodel.html): &gt; It is not guaranteed that \_\_del\_\_() methods are called for objects that still exist when the interpreter exits. So, *maybe* do something. Hooray unpredictable code execution! &gt; But even so you will notice that unit tests show warnings when files are automatically closed: this is frown upon. Only because there's no time guarantee with a real world physical resource, not because automatically freeing resources is somehow ideologically bad (after all, this is how all python objects where you didn't add a \_\_del\_\_ are handled). But this is just the implementation of the file object and is unrelated to the function of \_\_del\_\_. If they implemented the file object to close immediately, then you wouldn't be seeing those warnings, because it would be deterministic. &gt; Besides, python scoping possibilities are far from c++ raii idioms. How is this related? The scope definitions are different, sure, but if a resource is done being used, it's very often useful to clean it up. If it weren't we wouldn't need context managers, try...finally, and hacky close() calls that I really hope you wrapped in a giant try...finally. Sure, they help define scope...but why make us put all that boilerplate in when it could just as easily be a property of the object itself (\_\_del\_\_ being the half assed attempt at that property). edit: whoop, made edits while you were replying. 
If you already have programming experience, and you're willing to watch a 43-minute-long video, I recommend watching [this.](https://www.youtube.com/watch?v=N4mEzFDjqtA) He makes "learn x language in one video" stuff (among other things). They're great for a quick and dirty language syntax dump. I love learning new languages like this, because it lets me explore the language a bit on my own before I get an, er, *opinion* from someone I've never heard of. If you're dead set on a book, or want to go beyond just the syntax, *Effective Python* and *Fluent Python* are pretty good. And if you want to learn a bit about writing performance-oriented stuff, I'm currently reading *High Performance Python* by Micha Gorelick and Ian Ozsvald.
So, you have a search engine tailored for internal resources. How come you are comparing speed of REST interfaces? Do you believe interaction via REST is time-limiting?
&gt; url = "https://myurl.example.com" headers = {my_header_key: my_header_val} time = {"timespan" : "86400"} test = requests.get(url, params=time, headers=key) **key** isn't defined. **headers=key** should be **headers=headers** I'm assuming your header dict is using variables already defined, otherwise those should probably be strings. You might also want to make sure the docs you are reading match the requests library you are using. (There is some functionality that came in later, if you are using a old requests module, you're probably going to have a bad time.)
Very informative. Where do you even begin to figuring out all this info?
We're using REST between frontend (served with http server) and backend (acting as http REST server), between the backend and ElasticSearch, between data scrapers and intermediate DB and so on... In my opinion i/o on REST is crucial when you have fronent that needs to show something to the end user. With every second frustration increases.
Yes, quite simply. This question would be better asked over at /r/learnpython but here is a tidbit to get you started: import requests fetched_data = requests.get("https://blockchain.info/ticker") print(fetched_data.json()["USD"]) 
If not for the fact that I have to work with embeded py2.7, I would have used 3, at least it is for personal project.
We're not going to do your homework for you. Please ask any *specific* questions you have in /r/learnpython
If you are so "particular" in managing your resources that you absolutely need to close them right after your job is done, you are better off managing these manually anyway, tbh, because you would always find something "wrong" with whichever strategy the interpreter implements. At least, like this you are fully in control at all times. You can always prepare stacks of similar objects (e.g. each time you open a resource, add it to a specific list) then cycle through them in your `finally`, or implement other generic strategies to that effect which you can likely reuse through all your scripts.
&gt; This means they get collected when the gc runs, not after some ref count reaches 0 (after all, we are talking about circular references). Python knows exactly when they're done being used, with circular reference in mind. In the case of the circular reference, the count reaches zero when only circular references remain. There's no issue here...this *is* the mechanism that gc uses. It could just force call my ideal \_\_del\_\_ before adding the entry to the "to be garbage collected when I feel like it" pool. &gt; The timing is not deterministic from a practical point of view. Who cares. If you put some inappropriate operation in a destructor, that's your fault. Use the fancy new async calls, timeouts, whatever. That doesn't mean it's not possible to give someone a "gc == 0" callback. &gt; Most cases still get collected, circular references are not that common Circular references are absolutely normal. If you claim that they aren't then you've brought along some c baggage or something. All modern gc'd languages are absolutely ok with circular references. &gt; Moreover, the gc module allows you to explicitly deal with uncollectable objects and it's not difficult to use at all. I don't understand. This isn't about uncollectable objects, it's about the desire to clean up when an object is done being used and is ready for gc. \_\_del\_\_ is called at gc, and what I'm claiming is that nobody cares about that, but when an object is ready for gc is more interesting. &gt; I think you're being extremist here, take a more probabilistic point of view. I've lost you. I have a thermal chamber here. I would like it's heat pump to shut down when it's done being used. Right now, I use the examples I gave above because I would have to indent for every piece of equipment using a context manager, that's not practical. It would be *awesome* if I could just have the thermal chamber close itself when it was done being used. If you don't like this concept of cleaning up, then how could you possible like or think \_\_del\_\_ is useful? And there's no probabilistic programming...it works or you have a bug. I don't want my thermal chamber running all night because the gc didn't make it in time at the end of the script...I've tried, the gc never makes it in time. &gt; but even so your best bet is to use context managers Because that's the only sane option we have, because \_\_del\_\_ is basically unusable...which was my claim started all of this. Again, if \_\_del\_\_ was called when the reference count hit 0, and \_\_free\_\_ was called when the gc was actually freeing the object, which is when \_\_del\_\_ is called now), I'd be happy. But that's just me. I'm sure some Python dev could come in here and explain why it isn't so, with the answer possibly involving "implementation complexity". 
As with all lists, this one has an interesting version of the truth. I started going down the two lists to see the differences. - The first one in the 2.7 list but not the 3.5 list was [Atom](https://github.com/nucleic/atom), which [already supports Python 3.5](https://github.com/nucleic/atom/issues/27). - The next one is [backports_abc](https://github.com/cython/backports_abc), which is a backport of part of the Python 3.3 stdlib to 2.7. - The next one is [bsddb](https://docs.python.org/2/library/bsddb.html), which is part of the Python stdlib in 2, but removed in 3. But there's a new pip-installable [bsddb](http://www.jcea.es/programacion/pybsddb.htm) that's compatible with Python 3.5. I guess the Anaconda people haven't found it yet. - The next one is [cairo](http://cairographics.org/pycairo/), which claims to have Python 3.1+ support since 1.10.0, in 2011. Anaconda has 1.12.18, so I'm not sure why they don't have it in the Python 3 section. I'm too lazy to check out all the differences, but if all of them are like this -- irrelevant in Py3, or just need to be pointed to the latest version -- then I could easily see all 58 handled in the next 3 months.
Corrected, and I just installed using pip so I would assume it pulled the most up to date module: %pip show requests \--- Metadata-Version: 2.0 Name: requests Version: 2.9.1 Summary: Python HTTP for Humans. Home-page: http://python-requests.org Author: Kenneth Reitz Author-email: me@kennethreitz.com License: Apache 2.0 Location: /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages
Fabric has been pretty frustrating, just because he said almost a year ago that an alpha would be available "soon", and hasn't responded to requests to put whatever he has now on Github. Your comment prompted me to look at what the current state was, and [this tweet](https://twitter.com/bitprophet/status/707332266934972416) isn't exactly inspiring. It does look like there's a fairly competent fork with py3 support, but I haven't tried it.
&gt;And that's what I called your ideal. But if you still want to correct me... Err, I was responding to: &gt; If you avoid every possible circular reference or appropriately use weak references, **you are and were up to the ideal**. That's not the ideal that I claimed since \_\_del\_\_ is called at GC, not when the reference count reaches 0. Maybe I'm confused? &gt; Because you will have to delimit scopes creating new functions in order to get finer control over resource finalization. Like a context manager? Like a try...finally? Yes, we have these. But, often, functional scope is plenty. I'm not suggesting we get rid of context managers or try...finally, or they don't have their use. I'm saying it would be *useful* to have a predictable \_\_del\_\_, a callback when the object is added to the gc pool, rather than, or in addition to, the one that's called when the object freed from the pool. Nothing more.
This is a what the package_data and data_files entries in a setup.py file do. You can then use setuptools to create egg or wheel files that zip up static files and make them available to a python program.
see Django's source code https://github.com/django/django/blob/master/django/utils/crypto.py#L80
While I tend to agree, there is also [contextlib.ExitStack](https://docs.python.org/3/library/contextlib.html#contextlib.ExitStack)
&gt; In the case of the circular reference, the count reaches zero when only circular references remain. No. Your very statement is implying it: references remain, so the count is not zero. &gt; That doesn't mean it's not possible to give someone a "gc == 0" callback. Yeah, the difficulty resides on getting `rc == 0` (and what the heck does `gc == 0` mean?) on the face of circular references. But if you have a new reference count gc algorithm which can cope with that in a simple and deterministic way please contact Antoine Pitrou. You will humiliate him, what seems to be your goal. &gt; Circular references are absolutely normal. If you claim that they aren't then you've brought along some c baggage or something. All modern gc'd languages are absolutely ok with circular references. I said they're not that common (as non circular references). That's a frequentist statement and also an empirical truth. I don't even understand what do you mean by "normal" here. Or why are you pretending that I said gc'd languages can't cope with circular references. Moreover, most gc'd languages don't even count references at all! Python is a rare case combining a ref count gc with a generational gc. In the case of python, there was some difficulty calling the finalizers in the right order before 3.4, which prevented automatically collecting loops with finalizers. &gt; how could you possible like or think __del__ is useful? [...] And there's no probabilistic programming. Ok, then patch your python so `__del__` becomes a nop. And good luck (luck is a probabilistic notion). I don't know what "probabilistic programming" is, maybe you're answering to a voice in your head. &gt; but even so your best bet is to use context managers &gt;&gt; Because that's the only sane option we have, because __del__ is basically unusable No, because `__del__` is not intended to be what you think it should be. Still you may use it in the way you yearn; I'm getting sick of repetition but: use weak references to avoid circular references, period; then you don't (almost) need context managers. But if you know about a programming language in which a reference count immediately reaches zero despite being involved in a circular reference, and in which it's trivial to call a loop of finalizers in the right order, name it. And please don't recur to the "modern gc'd languages" slogan because almost all of them use one or another form of `try/finally` resource management and a non-rc gc. And the oldies? Name perl, which has rc: it doesn't even try to collect reference loops. Name c++ with raii and smart pointers: you still need those `weak_ptr`s. &gt; Again, if __del__ was called when the reference count hit 0, and __free__ was called when the gc was actually freeing the object What you can't grasp is that the problem is in "when the reference count hit 0" not in "when the gc...". Is it so difficult to understand that the very notion of circular reference implies that at least two ref counts are &gt; 0? It's not trivial to detect and destroy those reference cycles, so the gc does it just once in a while. I think you just want to prove me wrong and you're not even reading what I'm answering, so I will stop here. Be my guest and have the last say.
&gt; I don't understand the resistance to a __del__ that's called when reference count == 0 No, you don't understand that rc won't reach zero, but you're too arrogant to take the time to think about it before bragging about it.
&gt; To me, ``__del__`` would be usable if it was called when the reference reached zero, not at time of garbage collection. For garbage collection, it would maybe be ``__free__``. Python the language purposely doesn't define when unused objects are destroyed, and you the Python programmer are advised against depending on any particular implementation's behavior. Three of the four major Python implementations don't even use reference counting. PyPy, Jython, and IronPython all use tracing garbage collection to expire and reclaim unused objects. CPython itself might! someday! switch to tracing garbage collection. If you don't like this, fine, but the language spec isn't going to change. You will never have a guaranteed timeframe for when ``__del__`` will be called, period, end of sentence. If you have cleanup code and want a guarantee that it will be called, that's what context managers are for.
No, even before python 3.4 it was not as bad as it's in perl. Only circular references with finalizers somewhere in the loop were ignored, not every circular reference. This reduced the probability of memory leaks, because loops without finalizers were still collected.
I give you two apples, I tell you to ignore 2 cyclic apples. How many apples do you have? This is what I mean by "logically".
I'd be curious to see the profiling which led to that conclusion; the very earliest 3.0.0 was slower than 2.x, but that was due to some subsystems being implemented initially in pure Python instead of in C, which has now been remedied.
Key generation is done in the background, and completed upon connection. I'm adding docstrings as we speak. Edit: working on compatibility with PyCrypto now. Only trouble is the crappy way it signs things. Once I get that figured out it should be fine. You can see that in the experimental branch Edit 2: PyCrypto support is enabled
Thanks a lot. I'll solve problems today. What's your OS? About I/O blocking: Will we be able to solve this problem by using GIL? (https://docs.python.org/3/c-api/init.html#releasing-the-gil-from-extension-code)
I just went through this course to learn Python over one weekend. I found the Python Fundamentals course that is available through a CodeSchool subscription awesome. Highly recommended. Monday morning I was productive. https://www.codeschool.com/pluralsight-courses/python-fundamentals 
im way too hungover to have someone tell me i know way less about python than i thought
I referenced the HTML title to show the process, but you are right: BeautifulSoup has a separate method for the tile and you don't have to reference the HTML tag 'title'. And if you would use: ... soup.title.string = 'A new title' and then write `soup.find('title').string`would return `A new title`. So in this case both methods (ways) are the same. I would write HTML that way. I have tried it and it works. But please stay away from the 'html.parser', use **lxml** or **html5lib** as html.parser will result in weird output, like closing tags for `&lt;meta&gt;` tags and so on. Jinja2 is great and you don't really need Flask to use it (neither does Flask need Jinja2, but that is a different topic). Flask is a micro webframework, while Jinja2 is a templating language. Flask would be beneficial if you wanted to make a web app, but you can find examples of programs that use Jinja2 without Flask on Github. EDIT: Some clarity.
Go through Fluent Python. If you don't learn anything, you are Guido.
Nothing. There is no line 2. [/learnpython](https://www.reddit.com/r/learnpython).
Have you actually timed the assignment or are you basing this on the memory usage graph alone?
I've had my eye on Wagtail, but Lektor looks pretty cool for the bloggish stuff. I've been evaluating static site generators and leaning towards something with Jinja2 support. And it's from Armin Ronarcher, which bodes well IMO. 
I like the article so far, the research seems sound, but it still feels like a not-so-subtle ad for this jupiter thing. Otherwise why would you give the full name of the tool plus link in every other sentence?
Cold starting the same application built with P2 and P3 and measuring how much time it takes to load the UI.
Around 5 to 10 seconds IIRC.
.... and that proves what about python2 vs python3 exactly?
The Python 3 interpreter takes more to load than Python 2, which in a Kivy app is several seconds added to an already long time compared to Java/ObjC/Swift apps.
This was motivated by randy Olson work on shortest tour across USA. Point is that Randy did not compute the shortest tour. We show how to get shortest tours using Python and freely available resources on the web. Tours are automatically rendered as web pages via jinja2.
### Summary #### Easy backports to 2.7 * Non-ASCII identifiers * No-argument super() * The @ operator * Keyword-only arguments * Chained exceptions #### Great solutions to the wrong problems * Key-sharing in dictionaries * Flexible string representations * tracemalloc #### Outright bad changes * async/await * Simplified ordering comparisons (BS title for removing `cmp`) #### What we're left with? * `int/long` dichotomy - unfortunate, but not particularly problematic. * `UnicodeDecodeError` - switch default encoding to UTF8 (making ASCII the unchangeable default was outright sabotage). This is not so easy, I'll admit, but easier than stuffing `unicode` everywhere and making bytestrings second class... 
 $ time python3 -c "print('hello world')" hello world real 0m0.028s user 0m0.024s sys 0m0.004s $ time python2.7 -c "print('hello world')" hello world real 0m0.014s user 0m0.009s sys 0m0.005s The interpreter startup time is negligible. If it's slow, it's a problem with Kivy, not python3. 
5 miles!? Can we do it a little shorter?
X-Post referenced from /r/astronomy by /u/ketodnepr [For all the astronomers &amp; developers at r/astronomy: your help is needed at the open source project that bridges the gap between astrophysical models and the vast amount of publicly available astronomical data](https://www.reddit.com/r/Astronomy/comments/49nxxl/for_all_the_astronomers_developers_at_rastronomy/) ***** ^^I ^^am ^^a ^^bot ^^made ^^for ^^your ^^convenience ^^\(Especially ^^for ^^mobile ^^users). ^^P.S. ^^negative ^^comments ^^get ^^deleted. ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
There's no problem with Kivy on PC either. It only happens on Android devices (probably iOS too, but haven't tested it).
I don't think you've read any of the various explanations of why it was considered a major release.
then figure it out on your own, or go fuck yourself. Theano is built and supported by volunteers, you have no right to expect them to cater to your shackled OS.
&gt; Easy backports to 2.7 You may think they're easy, but I won't take that claim seriously from anyone who isn't provably on the dev team. Regardless, I can find no evidence that any such backports are planned; and according to the corresponding PEPs, all of these except the @ operator have been in since 3.0, so it would be a little weird to start planning it now. &gt;Great solutions to the wrong problems How are they "wrong problems"? Anyway, flexible string representations are transparent to the user and potentially save tons of memory, how is this not a win? &gt;Outright bad changes async/await had a metric fuckton of consideration put into it. I think PEP 492 might be one of the longest there is. `cmp` is a just plain unnatural way to express sorting predicates that people only accept because of the precedent set by languages like Perl - not really what we want to emulate. The fact that `sort` is comparison based is still an implementation detail, despite being unavoidable for a general-purpose sort. But it especially bugs me that someone would say such a thing, simply because of knowing that Raymond Hettinger is the one responsible for the removal, and I honestly can't think of a single person who's better at explaining how to write good Python. Anyway, if you really need to adapt old code, `functools.cmp_to_key` is a drop-in wrapper. &gt;int/long dichotomy - unfortunate, but not particularly problematic. If you've never been bitten by this, I don't know what to tell you. Do some more interesting math in your programs or something. Even if it never caused you a random exception or incorrect result, the `L` suffixes annoyed me regularly. &gt;UnicodeDecodeError - switch default encoding to UTF8 (making ASCII the unchangeable default was outright sabotage). This is not so easy, I'll admit, but easier that stuffing unicode everywhere and making bytestrings second class... Oh, now you've **really** pissed me off. There is no such thing as a "bytestring". Python has a `bytes` type, that formerly was incorrectly aliased to the name `str`, implying false implications. It also has a bunch of methods that happen to look like string formatting methods, and which even do kind of the same thing if you squint really hard and assume an encoding. But it is not a string. Strings consist of characters, not bytes. If you explicitly declare an encoding and that encoding is single-byte (greatly limiting the set of expressible characters), the string still consists of characters conceptually; it is only its *representation* that consists of bytes - and this is uninteresting, because the representation of *everything* consists of bytes. Anyway, this type is moderately useful if you have to deal with raw data that represents text in an encoding that you either know, or can reasonably discern. However, it's only really useful there if there's some compelling reason that you can't just decode it right away and work with an actual string, the way that every best-practices document tells you to do. For example, maybe the data representing text is intermingled with other bytes that represent something else, and you have to do some extra work. Like, say it's a [.torrent file](https://wiki.theory.org/BitTorrentSpecification), or [BSON](http://bsonspec.org/spec.html). But then you might still prefer `bytearray`, because mutability is fairly useful here if you have to produce any output in the same format. `bytes` objects are "second class" in the sense that you need a `b` prefix to create `bytes` literals, yes. That's by design. Wanting a string is the common case. Wanting a `bytes` object is not the common case. People normally put things between quotes to indicate text. A `bytes` literal might make sense to represent, say, a fourCC when handling a proprietary binary format (or an open one that doesn't have good library support yet). That isn't the common case, and when you do compare a fourCC to file content, you conceptually are comparing bytes, not characters. The fact that the byte values were chosen to look halfway meaningful in a hex editor that assumes an encoding is completely beside the point, and the idea dates to an era when said hex editor was the best debugging tool available to you. Incidentally, you don't have to "stuff `unicode` everywhere" in 3.x, because *we don't call it `unicode` anymore* - we call it `str`. IOW, exactly because Unicode strings (or as I call them, **strings**) are *not* second-class. You don't need `u` prefixes and it works naturally. UTF-8 is not as sensible a default as you think it is. Not everyone's terminal can handle it, after all; and the people who have to work with ugly binary-parts-of-which-represent-text data are frequently working with *old* data that was *not* using UTF-8, or any Unicode encoding. Old data frequently uses encodings that are optimized for the text being encoded, and/or that were considered "standard" by people not concerned with internationalization, or who had to work with very limited devices. New data may still have some of these constraints (yes, including the last one; there are still people who e.g. make "homebrew" games designed to be played by emulators for video game consoles from the 80s). If you're dealing with receiving binary data "from the wire" (i.e. an Internet connection) and interpreting it as text (e.g. a JSON document, or JSON fragments embedded within something else), then sure, it makes perfect sense. But then, so does explicit encoding, in all probability. Be realistic: you're not CPU-bound anyway. Let's also not forget that now you get the ability to treat files opened in binary mode as binary data and files opened in text mode as text, automatically. You can even specify the encoding for text files and all you need is a keyword arg for `open`. In 2.x, using `codecs.open` was a hassle, and good luck getting it to work in tandem with universal newline handling. The `csv` module required you to open files in binary mode, despite CSV being fundamentally a text format. The first Unicode standard was published in October 1991. It will turn 25 this year. The first ASCII standard was published in June 1963. Trying to treat ASCII as if it were Unicode on a modern computer is like if home computer users on early 386s had decided to stick with some proprietary BCD encoding (not even EBCDIC - that appeared at about the same time as ASCII) because it was what they were familiar with from punch cards.
I've been doing something like this lately. This catches any *unhandled* exceptions: # our own handler for uncaught exceptions def excepthook(type, value, tb): msg = '\n' + '=' * 80 msg += '\nUncaught exception:\n' msg += ''.join(traceback.format_exception(type, value, tb)) msg += '=' * 80 + '\n' log(msg) tkinter_error(msg) sys.exit(1) # plug our handler into the python system sys.excepthook = excepthook Just place this in top-level code somewhere before getting on with business. It catches any unexpected exceptions and logs the exception and traceback as well as trying to show it in a tkinter dialog. You could, of course, use any GUI or CLI notification after the log() call. Edit: On second thoughts, I'm not sure what effect calling sys.exit() will have. Must try commenting out that line to see what happens. Haven't noticed any bad things happening yet, or maybe my code hasn't raised an unexpected exception yet :)
To be honest, I don't think rote memorization is the most effective way to learn how to program. Instead I found that working on a program with a specific task, and then being forced to look up how to do things (through the python docs and stackoverflow) has helped me much more. For example : Need to match strings in a collection of documents? Time to read about how to implement regular expressions in Python. 
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
Or, use Miniconda 
Sounds to me like a shitty employer. You keep doing you
I don't expect *them* to cater to anything. I'm not asking the developers of Theano to do jack shit. I'm asking *you* not to be a complete douchebag about it simply because it makes you feel high and mighty to tell people who know less than you to go fuck themselves. 
1. Posts about learning python will be more at home in /r/learnpython . 2. The time you wasted typing this ~~garbage~~ erroneous and not well-chosen material could have been used actually learning something. -jmho, of course
async/await are great in _static languages_, because explicit async is easy to compile to efficient code, non-async code is not penalized and runtime doesn't need stack switching/stack copying and other trickery. The price of explicit async is API complication (everything sync gets an async version, if you're lucky) and usage complication (can't copy and paste between sync code and async code, to put it simply). For a language like Python, this doesn't make sense. We had implicit async since forever (Stackless, greenlet), but core devs hate it for some unfathomable reason... For most types, `__cmp__` is super-convenient to implement, compared to `__lt__` and company. When sorting, either key or cmp might be more convenient, depending on the data, but neither is strictly better than the other. I don't have time or willpower to argue string implementations here. UTF-8 as the default encoding is just a sensible first step in "fixing" Py2 unicode handling the right way. (Because, in my opinion, Py3 did it wrong). As for the rest of your wall, gj fighting strawmen.
It must be some pretty technical management that OP is pitching to. "Make the programming nicer" will not convince management at most companies.
&gt;Could you be a little more specific about their questions? There's no way for anyone to tell if you failed at genuine basics or if they threw esoteric, bullshit trivia questions at you. This test was littered with "Move your keyboard away, if you accidentally hit a key or take a screenshot you will be disqualified." type stuff but now I wish I had taken pictures. I would say in some cases it was esoteric bullshit (but potentially still valid) like: a = 1 b = a del a # What is the value of 'b' To my best recollection, manually deleting objects in Python is generally frowned upon since there's garbage collection and probably no guarantee it will be deleted anyways. However, I could be wrong and I feel like these are the types of things I should know. Also, class definitions without specifying Python 2 vs. Python 3. &gt;Should we take that to mean you've only worked on Django apps for five years? Assuming that's the case, controversial opinion incoming... This is a very valid point. I have done quite a few other things with Python but it has all been around back-end web development (scripts, using Ansible, boto). I haven't really written a whole lot of end-to-end projects that don't couple tightly with some existing library or need. I'd love to do more, although I am shy on ideas. Any pointers on finding new non-django projects to work on? Thanks a lot for the great feedback!
It doesn't make them a shitty employer. OP doesn't understand basic Python, which is obviously a requirement for that position. They asked about getattr for goodness sake, not __metaclass__.
Trash talking the material and not offering alternatives, sounds about right for reddit.
I'm just making my way through codecademy before moving on to http://learnpythonthehardway.org/ or coursera and was using word to see if I could recall all the concepts without looking. I agree working on projects/ attempting to understand other people's code is probably best - but I wanted to make sure I had the basics completely memorized.
Just trying to help. Next time I won't bother.
Thanks for the support, I figured the Python community would be a bit kinder to criticism. But perhaps it is more accepted than I thought to mislead people in interviews, if you are confident you can deliver. Perhaps it would have helped if I offered a book as well, but I figured this wasn't StackOverflow so the comment wasn't off-topic. Again, thanks for the kind words.
[Well then.](https://www.youtube.com/watch?v=ydxIeO-2C2M)
Code academy is a nice way to learn the basic syntax. 
I would imagine you could manually go into each widget and adjust the signals/slots so that when an event would normally trigger a connected method it instead triggers some type of Log-and-Pass method first. User clicks QPushbutton -&gt; QPushbutton.triggered.connect calls LogandPass method -&gt; LogandPass method makes a note somehow (logging library, manually writing to text file, etc) -&gt; LogandPass then calls the appropriate method which would have been originally connected to QPushbutton.triggered() However, for a large application this seems like a quagmire that I personally wouldn't want to have to write. Off the top of my head I can't think of an easy way to implement this for every widget without doing so manually. I am not familiar with on but its possible Qt has something of this nature built in.
This question should probably be on https://www.reddit.com/r/learnpython instead. To answer the question, you have to ask keep in mind that the `all` function answers the question "does &lt;the property&gt; hold true for all elements in the iterable?". If there is no element in the iterable, then the answer is yes. Another way to see the problem is to check a simple definition of the function : def all(iterable): for element in iterable: if not element: return False return True Once you've iterated over all the (0) elements, you return False. In case, this is not enough, you may consider the zen of Python : https://www.python.org/dev/peps/pep-0020/ : "Special cases aren't special enough to break the rules.". Is there any reason why you'd like `all` to behave the way you've described ?
Well, I read something about event filters, but I didn't really get it. Any idea how those work? 
Thanks, and I definitely will :)
If you're mathematically minded check out Project Euler. Its a series of puzzles which can be solved programmatically generally all involving some type of mathematical concept (generating prime numbers, summations of a series, different types of special numbers). Usually you'll need to know something of the underlying mathematics but they are clearly problems made so that you can't easily solve them with pen and paper - for instance generating the 10001'th prime. You could do this by hand (if you had a very long time to work on it) but using programing makes the task nearly trivial if you think about the problem correctly. These kinds of problems are good at getting you to think critically about how python or any programming language can simplify the problem into a series of smaller tasks each of which can be solved quickly.
To be fair, Python does have special cases that break the logical rule, and work the way /u/MarcoProsperi suggests for convenience. For example `isdigit(s)` returns true if and only if all characters of `s` are digits, *and* `s` contains at least one character; rather than simply being an "all digits" check.
That project name is confusing me with the IM client Trillian. Really great idea though.
&gt; Take ownership of your weaknesses and correct them. Same could be said about your attitude.
You mean make weakrefs something more easy to use from C?
&gt; How can I go through and really master Python? As with any skill, practice, practice, practice! Plenty of coding challenges on the web on which you can cut your teeth. Some are self-driven, others are collaborative. https://projecteuler.net/ http://www.codewars.com/ https://leetcode.com/problemset/algorithms/ http://cryptopals.com/ That last one is my fave because you learn crypto in the process.
Posting code to this subreddit: Add 4 extra spaces before each line of code def fibonacci(): a, b = 0, 1 while True: yield a a, b = b, a + b Write like this or it is almost impossible to see what your code does. 
And which weaknesses would those be? The ones where I don't hire "django" developers for serious Python projects? Anybody can pick up a paintbrush and call themselves a painter. It takes years of dedication to become a master and command the sort of positions and compensation that goes with it. OP is exactly the sort of person these test are designed to weed out. That hiring manager isn't stupid. Look ANYBODY who knows SHIT about hiring will tell you "make the candidates program BECAUSE MOST OF THEM CANNOT". I have personally seen this time and time again. OP, if I interviewed you for a position that required real python expertiese, I would be annoyed with you for wasting my time. See also http://blog.codinghorror.com/why-cant-programmers-program/ http://www.kegel.com/academy/getting-hired.html http://imranontech.com/2007/01/24/using-fizzbuzz-to-find-developers-who-grok-coding/ http://weblog.raganwald.com/2007/01/dont-overthink-fizzbuzz.html The truth hurts sometimes. Getting butthurt and downvoting the messenger isn't going to help anybody's career prospects. Listening to me, reading the docs, becoming a craftsman and not just a hacker, that is what will get you ahead. OP if you took a few days or weeks to READ AND UNDERSTAND ALL THE PYTHON DOCS you would have nailed that interview.
In first order logic, we have quantifiers ∃ ("there exists") and ∀ ("for all"). Perhaps you've seen these in math courses. You can say something like ∃xPx to mean there exists something with the property P, or ∀xQx to mean everything that exists has property Q. Now, when "everything that exists" is the empty set (imagine an empty universe), then it is defined that ∀xQx to be True, for any Q. Indeed, even statements like ∀x(x != x), meaning "for all things in the universe, things aren't the same as themselves", or ∀x(1 = 2), which seem contradictory, is true in the case there are no things in the universe. Logicians say that the formula ∀x(1 = 2) in a universe where nothing exists is "vacuously true," because even though it's true, it's only because nothing exists in the universe. This is just by definition, and you could certainly define an operator ∀' that requires at least one element to exist return true. But it turns out that the original definition of ∀ has some nice properties, one of them being that ∀ is the "dual" of ∃. Note that ¬ means "not", such that ¬∃xPx means there doesn't exist a person with the property P. Also, "↔" means equivalent to. The statement of duality says that ¬∃x¬Px ↔ ∀xPx, or equivalently, ∃xPx ↔ ¬∀¬Px. In English, the first one says "'there does not exist something that doesn't have the property P' is the same as saying 'everything has property P'". The second one says "'there exists something that has property P' is the same as saying 'it's not true that everything doesn't have property P'". These apply even to the `any` and `all` operators in Python. Let's write functions that only operate on boolean values. def any(booleans): for boolean in booleans: if boolean: return True return False def all(booleans): return not any(not boolean for boolean in booleans) This relationship between the quantifiers is quite helpful to logicians, and so they've adopted the definition of ∀ as specified above. if you find it useful to define an operator that combines the properties (this is what you want, right?), you can do so if it's helpful for you.
Again, this conversation does not belong in this sub. Now we have two false accusations, name calling and trash talking. Nobody said you were stupid, only that what you did in that doc above is wasteful or counterproductive. Continuing in the same direction is not what you want to do. Nevertheless, if you'll pm me (without the attitude) or move it to a more suitable location, like /r/learnprogramming I will be glad to try giving some more details on things that I think would be more productive for you and why what you have above will only hold you back. I have to remark that at least one of the posts here that you think is being 'helpful' is probably deliberate trolling: deliberate or not it will only waste more of your time and energy when you could be learning and progressing. 
[find_one](http://api.mongodb.org/python/current/api/pymongo/collection.html#pymongo.collection.Collection.find_one) should return None if document is not found. Wait... "if thisrecord == "None": " &lt;- there should be no quotes around None Edit: you can also write if thisrecord: do_something_with_record(thisrecord) 
Look, you're not wrong, you're just acting like an asshole. Dealing with people well (kindly, patiently) is more important than expertise, even in technical professions.
I am describing how software dev hiring works. There seem to be a lot of misconceptions in this thread, a lot of entitlement, and a lot of victim mentality.
it was just a guess. JS is a managed language (= GC and heap-management overhead), everything is an object in JS (= less cache hits), not everything is JITted by V8 (= interpreter overhead) and JITting takes time on its own (= small constant overhead). adding it all together gave me an impression that it would be around 30%... but I was proven wrong.
I have given an explanation of this for the functions of the same name (and purpose) in Haskell over on [Stackoverflow](https://stackoverflow.com/questions/25427590/why-and-is-true-and-or-is-false/25427962#25427962), the gist of it is that each of those returns the identity element for their underlying binary operation, namely `any -&gt; or` and `all -&gt; and`, but my answer over there goes into much more detail.
&gt; The truth hurts sometimes. No, words hurt. Truth does not have to. Try some tact, even some empathy.
Did I mention blame shifting?
Agreed on all parts. I'm owning up to my weakness and that's why I'm here asking. Thanks.
I checked and the questions on *getattr* and *del* and my understanding was correct, as far as I can tell. e.g. B would still point to the value A was pointing to, after A was deleted. I'm not sure what all I missed. I wish they would have given me more information.
It was you that said "take ownership". Follow your own advice. Doing so is a very effective tool in leadership.
Thanks, and please don't take my criticism personally, I'm just trying to be brutally honest about how hiring managers think, and about how you can get to the next level, which I'm sure you will accomplish in time. And it pisses me off to see people blaming the hiring manager who really is just doing his job. If it makes you feel any better I once flunked an interview with Red Hat b/c I choked when asked to write a decorator that takes an argument (of course I remembered 15 minutes later). Of course my first reaction was "Stupid hiring manger that was a trick question." Then I realized that he just has really freakin high standards; everybody on his team must be A+++; and that's his just prerogative. Maybe he really is a big troll to work with, he could be a slave-driver, I dunno. I assume he has his own boss to answer to and that probably provides some of his motivation. That's not the only time I flunked the coding part of an interview either. Long ago I was asked to write a class structure for modeling a chess game; totally blew it. I've also totally nailed coding tests. One particular incident stood out in my mind; I was asked to implement some small algorithm; I wrote the TEST FIRST. Well my first stab at the algorithm FAILED the test, and in about 60 seconds I had found the problem and fixed it and passed the test. The hiring manager leaned back, clearly impressed, and informed me that "everybody makes that mistake but most people don't catch it so fast because they don't write tests." But I've participated in many many interviews with pretty extensive coding tests both as an interviewer and inverview-ee. I wouldn't personally disqualify a candidate for missing any one thing (everybody has knowledge gaps); I'm looking for a holistic picture. The thing is you've come at python from the top down; you got into the libraries first. Again there's nothing WRONG with that as long as you accept that it limits you. You need to start working it from the bottom up; learn the language. And, really, there's PLENTY of demand for "django programmers" so you shouldn't be starving in the meantime. And there is absolutely nothing wrong with being a django programmer. Plenty of developers make a decent living that way and couldn't be happier. Feel free to PM any python or hiring question any time.
I can't imagine a universe where multuple choice tests about the specifics of python are preferable to big picture problems. If they're trying to do a weed out or something then why not just look at his github code? Are you seriously saying that knowing getattr is preferable to a pair programming session on a project? 
that sucks if they didn't give you answers after; hard to know where to brush up
That is an awesome response. Thank you so much. I went into C from the bottom-up (at the University several years back) -- and I feel like I know what's actually happening there. So I agree, that with Python I came top-down and definitely have some knowledge gaps.
&gt; For most types, `__cmp__` is super-convenient to implement, compared to `__lt__` and company. ...You *are* familiar with `functools.total_ordering`, yes?
Oh BTW the red hat job was working on openstack, which is basically a web app that wraps libvirt and a bunch of other libraries, it ain't exactly rocket science, so I was surprised by their insanely high standards, and my own summary dismissal, but so be it they are profitable so they must know their business. I was also weak on the virtualization stuff, but again, it's a freakin web app that wraps some libs that do all the actual virtualization. Most companies aren't quite so uptight in my experience, but in this day and age nobody wants to hire somebody they'll have to train up. If a company DOESN'T make you code in the interview that's a potential red-flag IMO. Do you want to work somewhere like? Probably isn't going anywhere. Good news is that Python was strongly influenced by C so there's a fair amount of overlap.
Instead of asserts, I use exceptions. if 0.0 &lt;= ratio['min'] &lt;= 1.0: raise SpecificErrorForWeirdness(f'"{colname} min ({ratio["min"]} not in [0-1] given ({original_range["datamin"]}) colspan ({colspan})') Is this a wrong usecase for exceptions? Are asserts actually better in this case? And if so, why? I remember reading [this](https://wiki.python.org/moin/UsingAssertionsEffectively) before, which caused me to start using exceptions.
I would disagree with your fundamental argument. a * b = b * a, meaning that a * b = a + a + a ... b times = b + b + b ... a times. Furthermore, we can also write this as a summation: a * b = b ___ ╲ a ╱ ‾‾‾ i = 1 b * a = a ___ ╲ b ╱ ‾‾‾ i = 1 In the case of a * 0 0 ___ ╲ a ╱ ‾‾‾ i = 1 a is added up 0 times. 0 * a: a ___ ╲ 0 ╱ ‾‾‾ i = 1 In essence, we didn't just arbitrarily assign the identity of 0 to a * 0. a is literally summed up 0 times. It's identical 0 * a is summation of 0 a times. For exponents, the rule of exponents are as follows: a ^ b / a ^ c = a ^ (b - c) Therefore a ^ 0 = a ^ (d - d) = a ^ d / a ^ d = 1. Again this number isn't arbitrarily assigned. --- *edit:* I had my summation written incorrectly. 
Really well explained, thanks.
I think you're misunderstanding, because it's not swapping them. When you delete 3, 3's *parent* now points to 1, and 1 points to 3's *parent* as it's parent. Essentially: 3.parent.leftchild = 1 1.parent = 1.parent.parent
[Pynsist](http://pynsist.readthedocs.org/en/latest/) is a tool I wrote to do this. It's younger than the major freeze tools, but I designed it to avoid some of the common problems I've seen with frozen code. When the user runs the installer it makes, all the Python packages get unpacked into a normal directory structure.
it's not about how much you know, it's about you being an unteachable tool.
This is a concept in Logic called vacuous truth. From wikipedia: "A vacuous truth is a statement that asserts that all members of the empty set have a certain property." https://en.wikipedia.org/wiki/Vacuous_truth
These results are the ones that ensure the following invariants: `any(x) or any(y)` is equivalent to `any(x+y)`, and `all(x) and all(y)` is equivalent to `all(x+y)` (presuming that `x` and `y` are of types that can be concatenated with `+`).
/u/pmrr 's second point is that you're reiterating his first point.
Flasgger - http://brunorocha.org/python/flask/flasgger-api-playground-with-flask-and-swagger-ui.html Flasgger + Microservices - http://brunorocha.org/python/microservices-with-python-rabbitmq-and-nameko.html
&gt; The hiring process is necessarily brutal and adversarial Only if you're not screening for talent, but instead screening for personality. In this manner, you compose a team of alpha-types. &gt; Once the deal is struck and somebody is on-board then things are totally different In other words, you completely mislead your interview candidates.
I actually love reading docs -- but the problem is that if I don't use the stuff, I tend to forget little details. I do think this is a good way to supplement learning, though.
Python 3, how about just getting anyone in an enterprise environment to say the word "Python" especially in a Java based house. To practice for this task, I am going to mecca to sell overpriced bibles. 
Maybe you could suggest Jython as a starting point
Don't let it get to you. It's perfectly possible to deliver business value without getting all wanky about the code. Arguably it's a better investment for the business because that makes it easier to maintain. Maybe they're "not moving forward" because they've got a pile of showoff code to try to maintain. IRL you have google and stack overflow. And there are only two hiring techniques that actually work: get the candidate to do a small but relevant project, paid (but I still ended up hiring a donkey); and bring the candidate into the company for 1-3 months and see how it goes.
I know Python 2 and 3 and code my stuff to be compatible with both 2 and 3. My boss and all my coworkers know Python 2 and code to support that. My boss' opinion is that when we have to switch to Python 3, it's going to be a disaster because he only cares about ASCII and thinks unicode is so damn broken. The problem with unicode &amp; Python is that the tutorials aren't written for people that don't understand unicode. There are about 2 rules you need to follow to make unicode easy. They are: - Define your encoding at the top of your file. If you don't care about unicode, use latin-1. Utf-8 is the wrong encoding. - Encode/decode at the boundaries of your code - Don't guess at the encoding Once you deal with the unicode problem, there's really no other changes that are worth discussing between Python 2 and Python 3. Nobody using Python 2 wants to use Python 2. They want the new features. They just don't want to use something that will break all their existing code. Most people will finally upgrade when Python 2 support is dropped assuming library X is supported. My open source project finally fully works properly in Python 3 as of 2 months ago because my last dependency (VTK) was finally upgraded.
Except I solved my own problem and provided a solution for the other people in the thread asking for one? So let's recap. I asked a question, then figured out the answer, then posted it. You just ran around crying about how everyone should use Linux because reasons, then got your panties in a bunch when I said no. It's a good thing you were here!
Love the idea. Especially as someone that has been fascinated by astronomy all my life but found no way to get involved. I have a few questions. What stage of development is the project at? Has the basic framework been set up? Is there a guide somewhere I can you to get involved? I am a senior in CSwithout any experience in astronomy but I would love to be involved. 
*shrug* if they won't even tell you what they were looking for which you didn't have, forget about them and move on ... 
% is the modulus operator. It returns the remainder of a division. 5 % 2 == 1 13 % 5 == 3 Etc.
Fair enough. I pulled this syntax from codecademy which does have you practice it in real applications. For me, I can't memorize through reading/rereading - what I do is start a fresh notepad and write the syntax from memory. This is the same thing I do with any studying and once I can answer a question or recall the subject matter without assistance I generally have memorized it.
The upshot is that you didn't end up working for someone who thinks that skills tests are a good hiring technique.
Unfortunately it is still vulnerable Man in the Middle attacks. It isn't, however, vulnerable to someone watching network traffic. If you want to see it in action, go download the rsa module and play around with it.
Did you build it with python?
**1)** If the first argument is a number, this is the so-called modulus operator for remainder division as mentioned in the comments below. In most languages, this is restricted to integers but in Python, it works for floats as well &gt;&gt;&gt; 1.3 % 0.5 0.30000000000000004 It's basically the second return value of `divmod`, e.g., &gt;&gt;&gt; 11 % 5 1 &gt;&gt;&gt; divmod(11, 5) (2, 1) where 2 * 5 + 1 = 11 **2)** If the first argument is a string, the `%` is used for string formatting, e.g., &gt;&gt;&gt; "%d x Hello, World" % 5 '5 x Hello, World'
You delete the `a` pointer, but since there is another reference to the object it points to (`b`), then its backing object isn't GCed. So `b` still points to a valid object.
My GUI has a scripting capability and an HTML output. Every time I do an action (or whenever I want to tell the user what happened), I write a message using a logger. Just write to a file. It's a minimal performance hit.
Thanks. Will definitely check it out.
Does anyone know what color scheme that is? I find it really really appealing.
ah I see now simple mistake, I was just a bit confused thanks so much :)
Hey, I kind of want to piggy-back off your post. I know virtually nothing about building/using API's and want to learn by doing; would either Django or Flask make a good sandbox for a beginner?
Why not `a = []`? Unless you're working with a specialized list, I don't see any advantages with the del keyword. 
It's a shame that you're getting down voted. Doing this will show someone all the standard parts of Python someone may not know about. :/
This sparked quite the argument, but you're right (although maybe a little abrasive). OP (/u/Originalfrozenbanana), I recommend running normal ubuntu in virtualbox. Virtualbox actually has basically an "install ubuntu" button and you can be all set up in 10ish minutes. You can even make a shared folder between it and windows if you want. Ubuntu is dead simple to use. To get up and running I believe all you need is to open terminal and sudo apt-get install python-numpy python-scipy python-dev python-pip python-nose g++ libopenblas-dev git sudo pip install Theano (taken from theano's site) I'm sure there are cases when you have to use windows, but if there's any way at all that this VM option will work for you then I highly recommend it. Good luck 
Cool, good job!
| Utf-8 is the wrong encoding. It sounds like you're throwing around anecdotal/personal experience as advice here (especially in your other reply). Most of the programming/computing industry is completely agreed that UTF-8 is the correct path forward. Maybe there are some corner cases where latin-1 is better, but I really can't think of any. These are great to read: * http://utf8everywhere.org/ * http://www.joelonsoftware.com/articles/Unicode.html 
Questions I've always found useful asking myself and have lead to the spontaneous effort to advance the understanding on Python include: - what is it that I use? - how it works? (e.g,. Generators being a special kind of function that gets its internal status saved and produces continuous output by advancing/yielding, del operation merely operates on the number of references rather than memory so it doesn't guarantee you immediate removal of the object, decorator no more than a function that take a function as input and output and functools provide many so called higher order function utilities) - what is its algorithmic complexity? (It's memory footprint, does it scale when input grows, does it call system function call?) 
It looks like 'Monokai' from [pigments](http://pygments.org/docs/styles/#builtin-styles).
 Not sure. I've seen it before. I think the color scheme is ok (not too far off from solarized dark) but it's really some crisp fonts. The site itself is using the [kaia theme](http://yourmarketingbff.com/2015/06/the-kaia-a-parallax-modern-wordpress-theme/), but for the code blocks, it's all in the style section (view source). .k { color: #66d9ef } /* Keyword */ .l { color: #ae81ff } /* Literal */ .n { color: #f8f8f2 } /* Name */ .o { color: #f92672 } /* Operator */ .p { color: #f8f8f2 } /* Punctuation */ .cm { color: #75715e } /* Comment.Multiline */ .cp { color: #75715e } /* Comment.Preproc */ .c1 { color: #75715e } /* Comment.Single */ Some sort of wordpress code highlighting plugin is used to render it. EDIT: 1st result: https://github.com/drmohundro/drmohundro.github.io/blob/master/_sass/_syntax-highlighting.scss This seems to be the source: http://markfknight.com/blog/2014/03/28/Jekyll_and_GFM.html And that reminded me of pygments, which is what I was really looking for last night. I've actually used pygments before, but couldn't remember. http://richleland.github.io/pygments-css/ It looks like [monokai](https://atom.io/themes/monokai). 
I'll be over here in the Clojure corner by myself, with my piles of parens. E: `(fix-spelling (find-comment :d0ucfe6) "or" "of")`
It's an integer. There is no reference to copy, as they are immutable. Once "b = a" is encountered on an integer, it simply assigns the value to variable b, thus 1. The handles represented by a and b can be cleaned up, but that integer ain't going nowhere (if it's tiny).
On the internet, at least, [UTF-8 is over 10 times as popular as Latin-1](http://w3techs.com/technologies/overview/character_encoding/all). You may work in a specific niche where Latin-1 is still popular, but it's definitely not the norm.
Actually all the lower integers get represented by singletons in CPython, so both `a` and `b` get assigned the same reference to the `1` singleton. But in general (with custom objects, say), what I said will hold true.
I hinted at that. I just can't remember if it's ranged between -127 and 128 or something like that. 
it looks like Jetbrain's version of Monokai. I'm not sure which is the official version, but it is slightly different than the Sublime Text color choices. 
&gt; There is no such thing as a "bytestring". Python has a bytes type, that formerly was incorrectly aliased to the name str, implying false implications. I agree with your overall point, but I think this is a little off. First, its relatively common to refer to a `bytes` object as a "byte string" and a `str` object as something like a "character string" when comparing them (and otherwise just `str` or "string"). You see this all the time on StackOverflow, for example, and I think it's used in the documentation, or at least some relevant PEPs and mailing list discussions. And the Python 2 situation was worse than having a bytestring type with a misleading name implying it is a character string: the old `str` was a strange hybrid of the two, which made it easy to do things that don't make much sense like double-encoding an already encoded string or concatenating with something that is strictly a character string (a `unicode` object). 
I don't code for the web or else I'd probably only use Python 3.
This is a really great idea. However, it is extremely ambitious and it doesn't seem like enough thought has been given to design. For instance, what interface will researchers be using to upload their code to a compute node? Do they just push the file using the CLI? Is there a web upload interface? The github repo says something about uploading docker images? This idea could use some real fleshing out. I also took a look at the code in the repo and none of it really seems to fit together. I would like to contribute, but there is no real indication of where to start coding. It may be a good idea to split the project up into separate areas of concern. Distributed database management should really be it's own thing for example because it is actually extremely complex with the amount of data you would be dealing with here. I also noticed that the project seems to be using Python2. I wonder if this is for compatibility with data science packages? All that being said, I have signed up for the mailing list and will try to help where I can.
I have mixed feelings on Kotlin but you talked to me so *YEAH!*
Not much. I've been trying to make it work in the first place first. It was a pain to get those implementations to talk to each other. I do know two things though: 1. It's still vulnerable to MITM attacks 2. the key exchange is fairly inefficient The second one is easy to fix, but I have no way of knowing how to fix the second one. I'm fairly new to crypto in general. Edit: for a while I couldn't get it to work with smaller keys. That's why I needed to change the end of message flag to something shorter and more obfuscated. 
Take a look at hug (https://github.com/timothycrosley/hug)
Actually, if you're willing to jump through a couple of hoops, mayavi (in the last week or so) just released a new version that does support Python 3 (experimentally and requiring VTK 7).
I'm surprised he doesn't mention type hints -- . I'd say it's the only ground breaking change of Python (and I love it).
There's also [Eve](http://python-eve.org/) written in Flask.
Ha, I don't know the name...They just put all the method , like: https://root.cern.ch/doc/master/classTTree.html They give a simple explain, and then list every thing. As it is easy , when we don't understand it by the name of the method, we can check it in the .cxx file.
Is this an O(1) operation? 
On MITM attacks, I don't think there is any way to mitigate that unless there already exists a secure channel, just on the nature of the problem. One might consider using drones to send their public keys, or messenger pigeons (which are considerably more agile). But even then, there's the possibility of an attacker substituting your drone/bird with their own.
Have you tried turning it off and on again?
I've worked in a few environments now where I'm limited to what comes with the distro. The struggle here is to convince management to spend the money including Python 3 into a base build for what is really a pretty small advantage*. A dev house would be different, but this is the reality of admin life in a reasonably sized infrastructure. As soon as it becomes part of the base build, support will soar. That's my prediction. \* in the context of an admin role. If a proper dev manager can't see the benefit they should probably consider a career change.
Somewhat immature library, but http://vispy.org/ looks promising
Hey, haven't heard about that, awesome! I'll try to get it working. Thanks! 
Yeah I watched the scipy conference talk on that a few days ago. It does look promising, but I got the vibe that it was still mostly in development and maybe I should stick to something more stable for now. Going to try it for sure, though !
Cheers man, thanks for the explanation! Looks like I will be getting my grubby mitts on Django. Are there any resources you would recommend for learning?
Holy hell, this is probably the coolest thing i've stumbled on this year
My main focus is ease of making since I'm not good at complicated stuff. So i guess I'll just learn threading which is going to take 5 minutes tops for basics. But for some reason I've always put off learning threading.
More info on how to do or integrate this in Python please.
The [official docs](https://www.djangoproject.com/) are really the only resource you need for the basics.
 python -m ensurepip python -m pip install -U pip setuptools wheel virtualenv
I think multiple choice is one valid way to test that their team members meet a certain baseline. It should not be the sole criteria of course as it's just one piece of the bigger picture. Python definitely has its idiosyncrasies, although not as convoluted as C++, they are still there. A developer who isn't aware of the specific behavior is going to waste precious time coding with insidious errors. Examples are comprehensions masking variables in Python 2.x. Mutable objects and their behavior during function passing. Function evaluation as function arguments. Ignorance of any of those features will lead to a code that prima facie looks to be correct but fails spectacularly or worse fails intermittently.
what would be a use case for transpiling from python to javascript?
http://i.imgur.com/zTtpw8D.jpg
Using kv files is suggested in the tutorials because it is a good practice to separate the presentation logic (the kv file) from the underlying application logic. Using kv files makes it easier to: - Adjust elements of the UI (without having to delve through the code to find where those UI elements are being created). - Keep a clean commit history. - Work in a team where you have dedicated UI/UX designers. - Make use of tools like kivy-designer to quickly develop UIs.
I'm talking about things like not using the ORM. I get constant sidewise looks from django components because of that.
Easy pitch: [2020 is not that far away](http://legacy.python.org/dev/peps/pep-0373/)
Can you expand on those? I'm actually curious I'm aware of mutable objects like list being annoyingly shared on function definition in a default value, but what's this other stuff?
[CoffeeScript](http://coffeescript.org) is a somewhat popular language in the webdev community that does this this these days. I think the basic idea was that there are a lot of ways to shoot yourself in the foot with JavaScript (ref: **JavaScript, the Good Parts**) and CoffeeScript provides simpler structures that generates normalized JavaScript that's less foot-shooty. IMO there's a lot of downsides to this approach, not the least of which is that it makes debugging awkward because now you're writing code that's one-step-removed from the code that's actually throwing bugs.
Agreed. If you are learning, then Flask is the right choice. Too much magic happening with Django. Along with Flask and Flask-RESTful, check out - 1. [Flask-Admin](https://flask-admin.readthedocs.org/en/latest/) - makes it simple to build an admin view based on an existing data model 1. [Flask-Login](https://flask-login.readthedocs.org/en/latest/) - manages user login and logout Check out this [boilerplate](https://github.com/realpython/flask-skeleton) to get started quickly. Also, check out this blog post I wrote for integrating Angular + Flask when you get to that point -&gt; [Handling User Authentication With Angular and Flask](https://realpython.com/blog/python/handling-user-authentication-with-angular-and-flask/) (updated it on 3/6/2016) Hope that helps!
Scikit learn comes with Anaconda install 
Given you have no input device (mouse, touchscreen) then really you just need to be able to draw stuff. Kivy looks like a good toolkit for this sort of stuff. See http://kivypie.mitako.eu Even if you don't use the kivy touch-widgets, kivy has a nice drawing API which you can use.
Okay. But my point is, you will only get "sideways looks" from trying to include extra features into your project, like the admin or auth modules or something like that. If you just wanted the quick basic project with URL routing, a few view functions, and even templating, you can accomplish all that with raw Python and no ORM. So either those Django convenience modules are still saving you time by using them, in which case it seems petty to complain about having to conform to how they're coded. Or they're not saving you time because your needs are not in line with what they're suited for, in which case you are better off just coding whatever that thing was yourself which you would have to do in all cases anyway. If Django forced you to use the ORM or any other intrusive feature, or if it did so in any kind of closed way, I'd be right there with you. But it's all pure Python, so it's all visible to you. You can have the best of all worlds: Use the ORM for some pages, use the stock admin for this part of a project, use a customized admin for another part of the same project, use raw Python views with no ORM for those other seven pages. I can do and have done all of these things. Having all of those features *available* is all convenience with no obligation. Because of this convenience *without obligation*, for any project that uses straight-up HTTP/HTTPS, Django is always my first choice.
I'll look into that, Thank you!
Yes I'm glad someone mentioned Coffeescript. While you're right about it being one step away from the source that will actually be generating the errors, they will typically be logical errors instead of syntax errors considering how well the CS transpiler is written. Also, I've found it often transpiles to more efficient and safe code than what I would've written in pure JS. CS also makes sure that you keep in mind how close it is to JS. IMO the Coffeescript syntax is one of the nicest out there. If somebody could port it to a compiled or interpreted language I would be very pleased. 
Also [rapydscript](http://rapydscript.pyjeon.com/)
&gt; I even actually prefer javascript and think it's more powerful, especially when it comes to doing more functional programming. Why do you say that?
&gt; SymPy is a Python library for symbolic mathematics.
Should be very (10-100s of milliseconds) quick. If the images are sufficiently varied, 10000 images should only require one round trip to the database. I suspect the overhead from generating the image signature and preparing the results from the database will take longer than the actual lookup, in this case.
Because the ability to solve a hard coding challenge is impractical? Or because while it may be great at solving hard coding challenges...it, uh, can't talk to databases or a network or something?
The one thing from JavaScript that I wish I had in Python sometimes is the nice method chaining from `Array.map`, `Array.filter`, etc.
NLTK for NLP
Amen.
thanks for the details :)
SymPy is a great tool, but I'm always confused if I should it it, SAGE or Maxima...
To ask to be paid more because you would need to know both javascript and python to debug some startups crazy app. 
&gt; you get types ... and compiler warnings. I never realized just how much I relied these things until I started writing code in scripting languages.
I ctrl-F'd the release notes and didn't see anything about better [Pint](https://pint.readthedocs.org/) integration. Right now it doesn't correctly solve for variables with units in them. (While my TI-89 does).
Well, you provided zero information about your system. Without that there is little to be done to help. obligatory: Did you try turning it off and then back on?
I guess it is possible to do it with Tkinter. You can open a full-screen Tkinter window and place some labels and images on it. Alternatively, you can place a Canvas on this window and draw stuff [like this](http://www.techrepublic.com/article/tkinter-canvas-freeform-guis-in-python/). 
Most of the crazy things about the language I either don't encounter day to day, or would never use. So for me at least, it's been a non-issue.
Nice work! Judging from recent commits, is a Python 3.3 release soon to follow? The PyPy team seems more focused on startup time and support for various things (NumPy, cpyext, cffi, etc) recently. Does that mean the low-hanging fruit are gone? What's next?
widening support for where you could use PyPy is definitely one of our goals - this is probably why PyPy did not see all that much adoption. What's wrong with that goal? ;-)
maybe :-) I'm not a release manager for PyPy 3 (nor am I for PyPy 2, but I know more about thay)
Yes I did but I can link you a comment that I made that provides it. [link](https://www.reddit.com/r/learnpython/comments/49rr1o/enthrought_conapy_wont_launch/d0ugwxg) edit: Meant yes I did try turning it on and off but here is some info as well
Why not 0.8.0 or 0.7.7? There don't seem to be that many big changes.
SAGE includes both, but uses Maxima for the symbolic stuff. 
&gt; method chaining 
The problem with this thread and the use of "del" as a sub thread, is that it is pretty obvious that what one person sees as common usage/knowledge isn't another persons perspective. Ask questions about deal when it isn't commonly used and in some case frowned upon really doesn't do anything for you about understanding a potential employees abilities. It is sort of like "goto" in other languages, the norm is to completely reject its use to the point some developers have never seen it in code. Yet an embedded developer might have perfect legitimate uses for it coding machine hardware. Should everyone be aware of this reality? In a nut shell if you pose a question in an interview and expect an answer that isn't common knowledge then you aren't doing yourself any favors and you certainly aren't giving the developer a fair shake. It can be compared to asking a C++ developer questions that are fine points in the standard often only of concern to compiler writers and expecting an answer that is perfectly detailed in its response and worst matches your opinion. 
The way the testing was laid out may very well indicate the quality of the employer. The on screen harassment seems to be a little bit over the top. That would have set off red flags immediately for me. 
Doesn't cause any issues in day to day work. Whenever you'd use an integer, like array indexing, it works just as well. You can even use bitwise operations and get integer-like behaviour.
You could, in theory, port a large python application to run in the browser. 
I'm pretty sure that python removed the u"" syntax in v3.0, but brought it back in v3.3. Pylint stopped supporting python3.2 a while ago, which is why you're seeing this error. https://docs.pylint.org/faq.html#what-versions-of-python-is-pylint-supporting
It's just so irritating that if we want to use the latest and greatest, we have to *choose* between a sane language and performance.
TIL... I just saw on PyPi that astroid only supports Python v3.3 and higher. Thanks for the clue.
Paraview is another option.
yes, planned :-)
Integers work fine in the range -2^53 to 2^53. Beyond that you lose precision. The JS engines use integer math internally when they know they can be away with it. Bitwise operations are considered 32 bit operations. Python's default division operator will also happily turn your ints into a float if you let it. 
Can you also post this on : https://news.ycombinator.com/news I think it would get alot of views. 
An example input/output would go a long way toward allowing someone to help you. 
Thanks for the heads up.
Why not build off an existing WSGI toolkit like werkzeug or WebOb? Werkzeug is super pleasant to work with from my experience, I haven't used webob directly -- only through TurboGears2 so I'm less sure of it's attitude or idioms.
You mind sharing why you love python?
Looks cool (simple to grab) that the templating system is in fact "just python". 
Does anyone know of a caniuse.com type of thing for pypy?
Mutable default args are possible but frowned upon, unless you really know what you're doing, which I don't.
I [personally don't like it](https://www.reddit.com/r/Python/comments/40163y/which_pythonbased_web_framework_would_better_suit/cyr1nvm)
This was mostly as an educational exercise. I figured "I already need to do rsa signing for this stuff, why not see if I can make it work all the way?" I tried to design this in a way where I could plug in different encryption algorithms later, and I think I managed to do that. If I can find one that suits my other needs better, I'll plug that in. Mostly I'm just not sure why you're angry at me for tinkering for a little while.
Thank you for your response! I will definitely add bottle to my arsenal. :)
It is a good example. But I'd like to suggest that there are far, far more cases like this with javascript than with your typical language.
I'm not quite sure which question you're asking, but the two possibilities I see can both be answered yes: - Yes, Pynsist is itself written in Python (plus Jinja templates generating NSIS scripts). It relies on NSIS, a popular open-source installer builder, to do the bundling. - Yes, Pynsist includes Python itself in the installers it creates.
Wonderful software I use everyday. It's IPython integration is amazing and wonderful in so many ways. It also shows how limited our abilities to integrate and solve equations, however. I do wish anyone cared about ode's in SymPy, though.
It's actually an infix operator instead of a function, there's a limited amount set of special characters that can begin an operator that aren't legal to be used for any other identifier so there's no weird precedence rules to take into account.
You are wrong. Read the [relevant HN thread](https://news.ycombinator.com/item?id=11260377). TLDR: there is not enough money nor interest from pypy devs to do a py3 release right now, maybe a 3.5 well after the official CPython 3.6... *maybe*.
There is the repl: just run python from the commandline, and enter commands. Slightly better is ipython, and then there is the Jupyter notebook as mentioned elsewhere here.
[Technical interview performance is kind of arbitrary. Here’s the data.](http://blog.interviewing.io/technical-interview-performance-is-kind-of-arbitrary-heres-the-data/) I've been a professional software developer for over thirty years, and this concept of a technical interview, despite what many people believe, has only really been with us for about 10 years. Our industry likes to pretend that we're based on science, but if that were true we wouldn't be doing technical interviews like this, and we wouldn't be throwing developers into huge "open office" sweatshops. Not hiring someone because they weren't good at taking a test on specific concepts that they can easily learn in an afternoon is bullshit. Give me someone that'll show up every day on time, doesn't get in fights at the office, doesn't gossip or spread negativity every time they open their damn mouths and I'll lead them where we need to go. If you absolutely must check out their technical chops after taking to them, checking their references, and looking at code samples, then pay them to do a small project that's real work that reflects the kind of thing they would be doing every day. Ordinarily I don't even bother with that. After I've talked to them, checked their references, and seen code samples, that's almost always enough. Besides, most employers put new hires on automatic probation anyway, and most states allow you to fire at will, so we need to get over the idea that we're making a lifetime commitment. 
If all SciPy functionality was rewritten in pure Python I wonder what the performance hit would be with PyPy + NumPyPy?
I haven't tried NumPyPy in over a year, but good boolean indexing is a must have -- nice work! Is there a site for comparing the performance of NumPy to NumPyPy?
check out `from __future__ import unicode_literal` or six(https://pypi.python.org/pypi/six)
Sorry, I realize now my question was unclear, I was looking for the first answer. I'm trying to pick up projects that I can see myself using at work here to not only improve work but improve my skill with Python.
&gt;Python's default division operator will also happily turn your ints into a float if &gt;you let it. Wasn't that remedied in Python 3.0 in 2008, if not earlier?
There's also coffeescript. Which is kidna quirky and I don't like much.
The opposite, it was introduced with Python 3.
OP, that seems like a great idea. In the setup.py file you can specify dependencies, so if we just did something like made virtual env automatically detect that we'd be set, no need to manually activate and deactivate virtual envs. 
severe
Relax you're in college. You haven't scraped the surface of programming yet. In actuality you probably like programming more than Python. Most modern languages are all very intuitive and fun to use. 
While it is definitely possible to send email from your python script via SMTP, it is better to make sure that your raspberry pi can send emails to you in general. To get started, try to use the same mail -s "Subject" address@example.com from the command line and see what will happen. Most likely nothing :). You need to define how mail will be delivered from your machine. If you will be sending mail directly from your raspberry pi with dynamic IP address, most likely it will end in the spam folder (if it will get delivered at all). Better idea is to pass it to your mail server for delivery. This type of configuration is called "smarthost". Default email server in Debian is Exim. See [1](http://askubuntu.com/questions/167043/how-do-i-configure-exim4-to-send-mail-through-a-password-protected-ssl-smtp-mail) [2](http://askubuntu.com/questions/167043/how-do-i-configure-exim4-to-send-mail-through-a-password-protected-ssl-smtp-mail) 
Thanks!
 apt-get install ssmtp mailutils Edit /etc/ssmtp/ssmtp.conf root=postmaster mailhub=smtp.gmail.com:587 hostname=raspberrypi AuthUser=name@gmail.com AuthPass=namepassword UseSTARTTLS=YES chmod 774 /etc/ssmtp/ssmtp.conf Send an email from the command line echo "Message" | mail -s "Subject" user@gmail.com Use in a script ifconfig eth0 | mail -s "RPI IP address" user@gmail.com or echo $(hostname -I) | mail -s "RPI IP address" user@domain To have it send the email at boot time, add the line above to /etc/rc.local
I think CPython should be retired and all focus should be on PyPy.
I was talking about the testing software and the continuous prompting not to touch the keyboard &amp; etc. 
Not sure why that would be the case. Anyways VB is not a 'serious' language and is really only useful for interfacing with certain MS applications such as Excel and Outlook. Python syntax is widely regarded as one of the easiest and nicest to work with for sure though. And in terms of productivity, it is EXTREMELY easy to do many tasks because of python's libraries and built ins. 
Thank you! I installed SSMTP and everything worked perfectly 
Sorry For the noob questions, but is it compatible with python 3? For now, I'm using remi in python2, which begs the following question: How do I access the GUI hosted on raspberry pi from a different client? I changed the Start parameter "address" to my computer's ip address from where I'm trying to access the GUI. Left default port as 8081. However it gives me an error "socket.error: Cannot assign requested address". Also! How do I stop the server without doing ctrl+c? if I do it that way and run the script again I get the error "Adress already in use" so....? Help, thanks! 
Yes, let's take an incompatible project that doesn't support the vast majority of Python code out there due to reliance on incompatible libraries and kill it. PyPy is cool, but it's not a drop in replacement for what most people use. If you thought the Python 2 to 3 transition was going poorly, just switch all the resources to PyPy.
How much money will it take to get 3.5 pypy out the door? 
what about dicts will you ask that stumps people? 
thank you 
Do you know how I would put this into this code, swapping the code? while 2&gt;1: gtinnumber = input("Enter a 7 digit number to find the check digit or enter an 8 digit number to check the validity. ") if gtinnumber.isdigit()==False: continue flip=3 total = [int(x) for x in gtinnumber] for loop in range(len(total)): total[loop]*=flip flip=-1*flip+4 if len(str(gtinnumber))==8 and sum(total)%10==0: print("Valid GTIN-8 number") elif len(str(gtinnumber))==7: if sum(total)%10!=0: flip=((sum(total) + 9) // 10 * 10) - sum(total) + 1 print(flip-1) else: print("Invalid number") 
There is! stay tuned
You were right, trying to send a message from the command line did nothing until I installed an SMTP package. Got it all working now, thanks!
Out of curiosity, are you a volunteer or a paid employee? Which parts of PyPy do you work on, and why? Many thanks for pushing the Python ecosystem forward! :)
I'm not sure if you're just being hyped about PyPy or there is good reasoning behind that statement. In case it's the latter, care to explain? Scipy relies a lot on Fortran, are you suggesting that pure PyPy'd python will beat Fortran wrapped with CPython?
Maybe it was ok for `requests` because there's a couple of odd things in urllib2, but this time it's just disrespectful to Flask and Django etc.
On rewriting in Go/haskell/whatever, I'll just [leave this here](http://www.joelonsoftware.com/articles/fog0000000069.html). 
&gt; Python's default division operator will also happily turn your ints into a float if you let it. Translation: division produces correct results in python 3.
I guess you already found this link: http://pypy.org/py3donate.html
Or the idiom... def foo(bar, baz=None): baz = baz or [] .... ...if it's enough when baz is not None, just falsy.
I am newt. Guess I'll try Flask instead.
*Disclaimer:* I'm the author. Why is that word bothering you so much? It's just a slogan. If I have to take every slogan literally, then I can't see why a framework "for perfectionists" should be better. What does it mean? That if I use something else I'm just an oddball? What if I don't use the framework "for creating ambitious web applications", am I just a lethargic developer? The point of using "humans" is to state it doesn't have a "preferred audience". Would you enjoyed "for everybody"? The meaning is the same. I hope people won't judge an open source project just by its slogan. Am I silly?
the slogan is just noise now, it adds nothing to the description of whatever project uses it. Furthermore it set's an expectation of ease of use that can't possibly be lived up to universally. For example... @app.route() @service.json @requires(auth.is_logged_in, otherwise=not_authorized) def todos(): page = request.params.page or 1 return {'todos': auth.user.todos.select(paginate=page)} def not_authorized(): response.status = 401 return {'error': 'not authorized'} where do all the decorators come from? I see no imports, what about request? what about auth? if these are magical globals then, I would say that the "for humans" criteria fails for this example IMO right off the bat. If it didn't say "for humans" I would have just ignored this post. Potential new slogan.... "flask-inspired with some batteries" edit: downvotes for feedback, real mature guys such a welcoming community you have here. 
&gt; the meme is condescending to people who don't know where it's from I do know where it's from actually. I dont think it's condescending, it think it's stupid noise that adds nothing to describe the functionality of the thing that is "for humans". 
NumPy and Scipy aren't written in pure python, they use extensions to offload to C and Fortran libraries. 
Because they aren't pure Python and interface with C/Fortran backends, and that boundary is where issues arise. PyPy doesn't fully support that boundary.
No magic globals, that's just a snippet in which I haven't included the imports or the auth instantiation. Because is a snippet. The idea is that if you're interested by that snippet then you go further and read the getting started. 
Is it so hard to use Google and learn the documentation? http://weppy.org/docs/0.6 
i'm glad you consider the feedback valuable. 
I'm struggling with the None, do I treat it like a boolean then? 
&gt;(By the way: Yes, the title is a tribute to "The Hobbit" :P and a Python 3: There and back again.
Try /r/learnpython for questions like this, this sub is more for news. 
Thanks! 
Doesn't PyPy already approach C speeds? Is there a reason why it wouldn't be performant with numerical computations?
You are opening the g-code file in text mode, which means you get Unicode test back. Change the first line to `f = open('grbl.gcode', 'rb')` (no need for a semi-colon at the end of the line) and that should fix at least part of the problem. Also, you will need to indent at least one line following the `for line in f` loop. The print line is wrong too, that would give you SyntaxError under Python 3.5, and should be written as `print('Sending:', l, end='')`.
Better is to open the file in binary mode in the first place. If the library doesn't support Unicode, why bother reading the file as Unicode and then converting it back to bytes when you can just read the straight bytes?
X-Post referenced from /r/google by /u/stackoverflooooooow [AlphaGo replication](https://www.reddit.com/r/google/comments/49yw9c/alphago_replication/) ***** ^^I ^^am ^^a ^^bot ^^made ^^for ^^your ^^convenience ^^\(Especially ^^for ^^mobile ^^users). ^^P.S. ^^negative ^^comments ^^get ^^deleted. ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
Defensive programming is what you use when you're too lazy to code up a proper test harness and force it to come back all green before you can commit. Problem is you've just added a comparison for every scope transition your application will ever make, and can kiss performance goodbye. Defensiveness is for borders, not internals.
Interesting, well I have my developing environments virtualized so should I need to I'll have it running on a windows system before I package it for mass use.
Of course not. The list will be garbage collected; at the very least, if there are N items in the list, all N of them have to have their ref-count reduced by 1. (That obviously doesn't apply to non-refcounting implementations like Jython and IronPython, but their garbage collector still has to inspect each element.) But the same applies to `a = []`; if the old value of `a` now has no references to it, then the list has to be garbage collected.
http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.interpolate.interp2d.html
Correct. `del x` removes the name from the namespace, it doesn't guarantee anything about whether the value of x gets deleted or not, only the name.
First of all, you're acting like I said pip+virtualenv was light years ahead of NPM. I didn't. Second, NPM does not provide the same functionality that virtualenv does. I'm talking about isolation so that you don't accidentally reference global dependencies and you don't have to worry about permissions. Node has some projects which try and do this: https://github.com/creationix/nvm, but they aren't officially supported and don't work nicely with alternative shells like Fish. And at that point you should be comparing NPM+NVM vs pip+Virtualenv. "Extra fooling"? I hope you aren't referring to some actions requiring two commands with pip and one in npm, because most of the complaints I've read about that fail to acknowledge that the total character count is roughly equivalent. Oh, and just in case that wasn't enough, let's talk about operating system support. There's no official support for the BSDs, making node (and therefore npm) a no-go for many of us.
Usually if its not at the root, you need to look in `__init__.py` and chase the import statements. In this case, if you look at the source code it looks like `naive_bayes` is where the import normally is: https://github.com/scikit-learn/scikit-learn/blob/2e4aafd19cdd5584555382e1144c29efbaefb7dd/sklearn/naive_bayes.py Additionally when I look at my site packages with `import site; site.getsitepackages()`, I find they are here with Brew: `/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn` which calling ls on shows that `naive_bayes.py` is there.
Thanks! 
&gt; One feature I really like about python is that it is possible to 'look under the hood' as it were Not related to your question, but I agree this is a great feature....most of the time. I was using a tool that I know a good bit of the theory so I decided to look into it. Turns out, they are not really doing it all that well. They are just taking the best of a few random guesses. Actually, I was able to view the Matlab code of their equivalent tool and it is about as bad! ...I know, good story...
Yes. From the docs: &gt; None is frequently used to represent the absence of a value, Boolean operation often deal with absence of a value.
3.3 is not ready for release yet, but it's only a matter of weeks.
Thanks. It's there a way to get rid of big lists or dictionaries really fast? I do believe (and profiler is supporting my claim) that gc is taking a lot of time right now in my app. 
I hope no one judges a project by its slogan either, and I doubt they will. They just are really tired of this same slogan applied to many different projects now in the last couple of years. I think it is a mixture of the copycat/memetic nature of this phrase, and the almost "arrogance" of saying it is for "humans", which implies that all the other frameworks are *not* for humans. Let's face it, none of these projects are for humans. Have you seen most humans lately? Many of them are still a little shaky on the paradigm of "windows on a surface" that Microsoft &amp; Mac introduced in the late 1980s. (If you've ever helped a senior person who asked you, repeatedly, "how do I get out of here?" every time they want to use another application, you know what I mean). Very best of luck to your project, and thanks for the contribution!!
Hell even JRuby which seems to me to be much closer to a drop-in replacement still hasn't replaced the main ruby interpreter.
&gt; The point of using "humans" is to state it doesn't have a "preferred audience". Would you enjoyed "for everybody"? The meaning is the same. No, that would be equally absurd. The example looks more obscure and confusing than Flask or Pyramid. What about it makes you think it's "for everybody"? You're silly for thinking you don't have a preferred audience. (Don't worry. Everybody goes through these phases.) Every program does, whether they realize it or not. For example, with Weppy: - It's version 0.6, and it looks like a version 0.6. That means it's for people who are OK with being beta testers. - The documentation (like most early documentation) usually only describes the happy path. It teaches by example, not by interface specification. To me, that speaks of a library where I'm going to have to frequently read the source code to figure out what it does. Compare something like Jinja2, which has *exhaustive* documentation on every last bit. I've used Jinja2 for years, yet never had to crack open the source code even once. - The Weppy docs assume you know "regex notation" (but doesn't say which dialect, or how much of it we get to use), but not what an "HTTP method" is. That right there is a pretty specific sliver. - Python already has, what, 3 different ways for attaching types to parameter lists? Now I have to learn a 4th one (which none of my existing tools will know about). So this looks like it's making a pretty large concession for humans who are stuck with an old version of Python. - It includes several less-popular libraries. It uses web2py for templating, which is probably not in the top-5 most popular Python template systems. It uses pyDAL, which is probably not in the top-5 Python ORMs. So it's probably not meant for people with an existing investment (in source code or knowledge) of existing systems. - Because it's so new, there's not much in the way of extensions or integrations. If I want to use Celery with Flask, for example, I've got my pick of several libraries to make them work together more smoothly. No such luck with Weppy, yet. It certainly can be made to work with anything, but it might take more work. Based on what I've seen in the documentation, I think a much more accurate slogan would be: "Weppy: a new opinionated web framework for new web developers, who are perhaps stuck on Python 2, and aren't afraid to get their hands dirty." Note that being more *specific* about your audience does not mean it's a *worse* program. It's just more *accurate*. Somebody with an existing service based on SQLAlchemy and Python coroutines who is looking to add a WebSocket interface would probably not be very happy with Weppy today, even if that person is a human. Pretending that this is a good product for them is a waste. People who try to sell "Yoga for everyone!" tend to be less successful than people who notice the high correlation between practitioners of, say, yoga and rock climbing, and advertise "Yoga for climbers!"
Good story indeed :) What was the program ? 
Can we use libraries from these languages? Also have you seen this? http://www.transcrypt.org/ 
That makes a lot more sense.
Would you believe that some have failed on the simple task of writing an example dict?
I remember the time I programmed in VB. You have public and private attributes and methods marked with 'public' and 'private' keywords. So far, so good. But you can omit the keywords. If you ommit it in a method, it was public by default, if you omit it in a field, it was private by default. I know they were trying to reduce the typing making the most "obvious" behaviour the default in each case. But I always find that kind of rules unnecessary and ugly. One thing more to remember. That's why I love python. There are very few surprises in the language. Things mean what they seem to mean, and there are few special cases.
https://www.reddit.com/r/learnpython/wiki/index Read the /r/learnpython sidebar. It has a curated list of resources and states whether or not they are Python 3.
Extra *tooling :)
Ok, that's a good comment. You gave a lot of useful feedbacks, motivating your words. It's really enjoyable replying to you. &gt; The example looks more obscure and confusing than Flask or Pyramid. What about it makes you think it's "for everybody"? Ok, I will change it then. But how do you think it should be? Are you considering it as obscure because the lack of imports and definition? Or just don't get what that code does? &gt; It's version 0.6, and it looks like a version 0.6. That means it's for people who are OK with being beta testers. Yes, and it's clearly stated. But this doesn't mean is not usable in production. Flask is still a 0.10. Do you make a different reasoning because it came before weppy and it has a LOT of stars on github? I won't say weppy is more stable, it's not. But I also think the choice to pick a "beta" product is not really a matter of the version. &gt; The documentation (like most early documentation) usually only describes the happy path. It teaches by example, not by interface specification. To me, that speaks of a library where I'm going to have to frequently read the source code to figure out what it does. You right, because you're probably and *advanced* user. Since I'm writing both weppy code and the docs in my free time, I had to make a choice: which part writing in the first place? The *beginners* one or the *interface* one? I've just pick the first, since it's *more readable* for beginners. &gt; The Weppy docs assume you know "regex notation" (but doesn't say which dialect, or how much of it we get to use), but not what an "HTTP method" is. That's a good point. I will update the docs, thank you :) &gt; It includes several less-popular libraries. &gt; So it's probably not meant for people with an existing investment (in source code or knowledge) of existing systems. Probably right, but still, debatable. Just because are less-popular it won't mean they are worst. And I hardly consider the "existing investment" something that will resist the usage of weppy. In the last years I've seen people moving from PHP to Rails to Nodejs. Nowadays seems that if you don't do web in javascript nobody will hire you. But, in Italy the majority of companies still use just PHP. So once again, is quite subjective and unpredictable which language/framework/library will rise for the next year and then people will move to something else. And I can't design a framework or a library considering this, because I will end up without writing it. &gt; Note that being more specific about your audience does not mean it's a worse program. It's just more accurate. Somebody with an existing service based on SQLAlchemy and Python coroutines who is looking to add a WebSocket interface would probably not be very happy with Weppy today, even if that person is a human. Pretending that this is a good product for them is a waste. Yes you're right, but you're confusing *everybody* with *everything*. I never stated that weppy is THE web framework for every project. You want to use async patterns and websocket? weppy is not good. As Flask. As Django. As Rails. But just because it doesn't use an async pattern, I hardly think to it as "stuck on python2". I know that python3 started "moving people" with the introduction of the async flows. But this is not python3, it's async python3. I had not write weppy to be "everything", it would be stupid. But this is another thing from having a *specific* audience.
&gt;It's very easy to overuse asserts and quickly make your code difficult to read. This can make your code very noisy and bury the real functionality in a series of error checks and conditions. While not wrong, aspect oriented programming can help mitigate this problem: def assert_return(condition): def decorator(f): def inner(*args, **kwargs): val = f(*args, **kwargs) assert condition(val) return val return inner return decorator @assert_return(lambda x: x &gt;= 0) def square(n): return n * n 
It's not that functions job to check outputs though. It's the caller's job to make sure it's dealing with correct values. `square(1j, 1j)` gives the expected and proper output of -1. Nevermind that running with `python -O` disables asserts rendering your decorator useless.
&gt; If you find that PyContracts is not enough for you, you probably want to be using Haskell instead of Python. Their sense of humor made their great package to a must have for me.
I shall check it out, Thank You.
pyDOE and the Latin hyper cube stuff. It just randomly creates 5 configurations and picks the best. Not really optimized 
Here you go: http://lmgtfy.com/?q=dbus+python
Assertions in production code is not a good idea. If your assumptions are wrong and you have bad coverage in your test cases, which for obvious reasons use the same assumptions (because you wrote them!) you kill everything on live. This is desirable sometimes, sure, but for most cases it's more damage than good, and the asserts you add are probably not going to be as simple as x &gt; 0. I've seen asserts in production code that are longer than the actual function, doing nothing and adding a lot of noise. My approach is to move them to a unit test. If you have to assert something about a piece of code, it's probably the result of a function, and you can turn it into a unit test, or more preferrably a [hypothesis](https://hypothesis.readthedocs.org/en/latest/) test which will help you generate meaningful coverage and more clearly state your assumptions about the function generally.
edited to remove snark. Please provide evidence of your claims (failed software projects due to Mako's design).
Millions of dollars are wasted every year paying Java developers to do nothing more than type semicolons. And let's not even get started on generics. import this
Thanks, need to check this out.
Just my guess: integration and system tests aren't part of every developer's workflow. Many organizations relegate those to a QA team. The author seems to be talking about techniques that a developer can apply immediately to any project.
AFAIK there's [ivoke](http://www.pyinvoke.org/) which is successor of Fabric and supports py3k.
I only use asserts in tests because of that. And I run my tests with python -O to make them go fast.
WRT my assumption about cpu intensity I was using this article as a reference point http://eli.thegreenplace.net/2012/01/16/python-parallelizing-cpu-bound-tasks-with-multiprocessing &amp;nbsp; from my understanding, threads won't share cpu time as effectively as processes. Is the article's analysis relevant to my application?
This post makes me feel like I've gone back 10 years in time.
Sorry--In my response I was just talking very generally about concurrency. The phrase 'threads are not very good for CPU bound tasks' set off a 'does this guy know what he's talking about?' alarm in my head, but of course you are right in Python's case. I'm don't know if that particular method is CPU intensive. Here's a good article about performance analysis in Python that might get you on the track to answering the question yourself. https://www.huyng.com/posts/python-performance-analysis Also, I recommend looking at the ProcessPoolExecutor and ThreadedPoolExecutor in the concurrent.futures module. It's the most modern and easy way to do concurrent stuff. 
[removed]
ok thanks for the guys below. One of the attributes of the class was a pandas DataFrame. Within a loop I was calling individual values from the DataFrame using obj.data['column'].values[i] Instead I created a new numpy array A = obj.data['column'].values and then in the loop used A[i] I guess that conversion is somewhat costly and of course I was doing it thousands of times. 
Yep both the most recent and last gen rpis have 4 cores. OP probably has 4 cores.
What are you developing for? If you like virtual desktops, might I recommend Linux :)
Whoops! f, t, same letter..right?
TIL. Thank you!! Can't wait to use this, it looks awesome.
Might be a pretty good guess, did they import luck?
thanks.
Oh wow, that is misinformation on my part. I was under the impression that raspberry pis had 1 core. Thanks for the responses. I haven't bought a raspberry pi yet but I'm definitely going to get the most powerful model.
Good points. thanks for your response.
I like contracts, and I like that you can disable asserts with the O flag. I might hack pycontracts so that they are only enabled if asserts are.
Nor sure if you know, but it was my mistake - I just edited my reply afterwards. :)
Thank you :)
Thanks... Sorry for that!
In the case of more side-effectful things like databases and concurrency, it's hard to test, yes, and sprinkling asserts through the code- at least during testing- is definitely a useful tool. Personally, once I'm satisfied the design is sound I remove the asserts and try my best to make it unit-testable, but sometimes it's a trade off you just have to live with. That being said, if you need to do a consistency check (for example if you're doing read your writes) then assert is the wrong/lazy behaviour and this should be explicitly modeled in the design.
[removed]
If you are trying to automate operating system workflow, launch 3rd party programs, and drive their menus, there are various tools for it - autohotkey on windows, the built-in systme automator on mac. 
3.x
If you have more questions, check out /r/learnpython and /r/pygame. There are some interesting example Pygame programs in [Program Arcade Games](http://programarcadegames.com/).
The core Python libraries for 2.x are no longer actively developed and are losing support sometime soon
Python 3.x
It's the future if the language, and at this point most of the major libraries are compatible so it's hard to suggest it's worth learning the legacy way.
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
There's no reason to act like this. Please refrain in future comments here.
My favourite thing about this article is the huge bug that remains in the final version that all his defensive programming has missed. Pass in an array of uniform data and you get a ZeroDivision error. Code is hard.
It won't make much difference (if any) in the scope of algorithms you could write, but it provides better tools, which will make them easier to write and modify as needed.
This needs to be higher up.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/programming] [PyconSK 2016 live streams : Python](https://np.reddit.com/r/programming/comments/4a33tw/pyconsk_2016_live_streams_python/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
A good opportunity to contribute a better version!
When you roll out the application, just don't set the -O flag. This is really a non-issue. 
God, do you really want to get hung up on my small example? And even if you do, it is still a good thing that the assert is there, simply because it codifies an assumption made when the function was written — ie that it will never be called with a complex number. (Which would not be pathological here, but might be for other functions, where it could introduce bugs.) And yes, the caller should never do anything wrong, and as long as the program is written by a perfect programmer (you?), it always will. The idea of defensive programming, however, is recognizing that perfect programmers do not exist, we are all human, and we all make mistakes. Contracts are one way of reducing the impact of this. If you're concerned about end users changing the flags your program starts with, you can always use if condition: raise AssertionError
Are you aware you've got passwords in there? Even if they're just for testing, it's bad practice. 
I wonder if anybody here actually tried using ES6; it's quite delightful. And, beyond having to grasp prototypical inheritance, the learning curve for Pythonistas is basically flat. 
The HTTP spec has no concept of tabs. You need to do it in the browser. 
It seems they're saying that even when the conditional is false they're seeing the request. In other words, if False: return redirect(url_for("index")) Is still causing hits for the redirect. (I know nothing about this problem, just clarifying their question.)
Neat, but not supporting even basic expressions like @contract("list(MyClass)") is a complete deal-breaker :(. 
I love Pycontracts. :)
Is [this](https://www.youtube.com/watch?v=2wDvzy6Hgxg) it? (Type Hints - Guido van Rossum)
What about using exceptions instead of asserts?
Python 3.
thanks
&gt; This class returns a function whose call method uses spline interpolation to find the value of new points. &gt; Examples &gt; Construct a 2-D grid and interpolate on it: [...] &gt; Now use the obtained interpolation function and plot the result: [...] f = interp2d(uu,vv,proj,'cubic') vol[:,:,iz] = Ratio*f(pu,pv)
I haven't used it much, and am not sure what you mean. Do you mean you want a guarantee that the list will have only MyClass objects? pycontracts does let you write your own contracts, if you really want it. Something like that is expensive, though.
1. you need to use learnpython (or even the flask subreddit or mailing list) 2. that can't be happening, do a print there or change it to "if False".
There isn't really such a thing as "many virtual environment solutions", really. `venv` in 3.3+ is exactly the same thing as `virtualenv` was in 2.x and 3.0-3.2, just rolled into upstream instead of being provided as a separate package. It still has the exact same use cases.
 r = df.rolling(window=3) r.mean() Oh nice, this is so much better than having to call `pd.rolling_mean()`. I've always thought that it shouldn't be a top-level function. Hopefully they'll do the same for `pd.melt()`.
I've definitely been considering compiled languages. I wanted to get a basic proof of concept going in python, then once I have a better idea of what the architecture is, I will port it to C++. I'll look into the ODroid, thanks.
If you're planning to land a job in the finance sector, more likely than not you'll have to use Python 2.x. Also Python 2.x gives you access to PyPy speed-ups that may be required when doing heavy data processing (usually needed for trading systems). See what one of the main PyPy developers has to [say](https://news.ycombinator.com/item?id=11260827): "we're there to provide a fast version of the mainstream python and mainstream for now means 2.7." 
I'm assuming the issue you're seeing is that the buttons you add overlay the results text box. That usually indicates an issue with layout (pack or grid in your case). You should check which row you're placing the buttons in and which row you're placing the results text box. Make sure they are different.
it will execute as fast as your cpu can churn it out
/u/rpeopler has it pretty much right. If you weren't able to find [this](http://python4java.necaiseweb.org/) on short notice, I'm afraid anything we can provide will be pretty useless. Also, you should have posted on /r/learnpython 
Easy: https://xkcd.com/353/
Yes. Yup, rather than defining a new_contract, it is more effective just to write the "if" manually. Unfortunately.
I don't know how much time you have, but mastering python in a week or two with next to none experience with it seems pretty impossible. However, when you get faimiliar with python's syntax, watch those: https://www.youtube.com/watch?v=wf-BqAjZb8M https://www.youtube.com/watch?v=OSGv2VnC0go
I literally just learned the rolling syntax. Oh well
Because filesystems are weird across platforms. How should a recursive remove handle a symlink? Or should that be an option? And if it is should it be visible on Windows?
Wanted to write a simple min-max algorithm to solve a tic tac toe game, and one thing led to another, led to a full implementation of a modified TicTacToe game. REST client written in python3 using flask. UI written in JavaScript using jquery and support touch devices since a phone is probably the best interface for this. Hosted on Heroku. The rules of the game have been altered a bit. Description here: http://christianreimer.github.io/raottt/
Thank you. This really seem to be a valuable notebook for learning Probability using Python. I tend to learn mathematical concepts way much better when implementing them using code. 
Sublime Text 3 with anaconda all the way. Great auto-completion, go-to and linting.
This release has my first open source contribution! - pivot_table() now accepts most iterables for the values parameter ([GH12017](https://github.com/pydata/pandas/pull/12017))
 from time import time while True: print time() Actually, it's completely negligible. This example more shows how long print and time() take. 
Was just using pivot_table() today and looking for this functionality! Kudos.
What do you think is much better in Windows 10 (relative to Win 7)?
Thanks! It was a pretty easy enhancement, but I'm glad at least one person has benefited from it!
To mirror what someone else said file systems are extremely weird and not easy to get portable. To give you an example: C++ (which is older than Python) only recently agreed on a file system standard in its standard library at this year's meetings. 
Yeah, `pandas` is where I've made the majority of my (very small) open source contributions. Great unit tests so you can check whether your code is going to break stuff, and the maintainers talk you through getting your commits into shape. If you use `pandas` regularly and can see something that could be improved, have a look to see if you can contribute.
Awesome! I'm just starting a project which will spend a lot of time with rolling windows, so this is fantastic timing :)
 c=0 try: start = time () while True: c+=1 except KeyboardInterrupt: end= time () print c/(end-start) Let it run for half a second before pressing ctrl+c.
I would just use threads and normal cross thread communication. You could use an event loop of some sort if you really wanted, but something like queue.Queue can handle what you need to do. 
I guess I should've been more verbose in my inquiry. Editing...
Something about this being for concurrently running things, however I'm not sure you couldn't use another progress bar package for that. Can't you update the progress as the concurrent items complete? 
Python with django would be great for such a project. You'd get the admin interface for adding/modifying students with almost no code, and calculating tuition seems trivial.
It isn't that any answer is wrong here, but rather that no answer is clearly correct. You can abstractly say "I want a tool that recursively copies folders," bit when you get into the details you realize that can mean very different things on Unix than on Windows, what about Windows access unix filesystems over NFS or the reverse over Samba. And what about this or that.... And you realize you can only really be certain that you are doing the right thing and not surprising people if you only implement the lowest common denominator in the core parts of the language, and then let library authors make their attempts to create more powerful tools on top of those primitives.
Totally doable with Python. In no way do you need to bother with Django. You can do this as a GUI app with Tkinter and SQLite without having to install anything other than Python. An excellent first project!!
 @postcondition(...) def pos_sq(x): return square(x) That's just silly. It's obvious we have different and strong opinions on where value checking should occur, so I don't see much merit in continuing this conversation. 
I would just Google for tutorials, really. [This tutorial](http://zetcode.com/gui/tkinter/introduction/), for example, gets you to a window on the screen in just 16 lines of Python (could have been done in as few as 11, I think). From there, keep reading for how to add things to it. And you're off and running. I myself don't like Tkinter's look, but you can't argue with it's battery-included nature. Later, if you prefer a different GUI toolkit, there is PyQT, wxPython, PyGTK, or Kivy (though those you do have to install, though it is easy).
In your terminal: ``pip install paver`` should do it, though questions like these are what /r/learnpython is for. 
I guess pygame is what you need :) There are dozens of tutorials and examples: http://pygame.org/docs/ http://pygame.org/docs/tut/newbieguide.html It's really simple and worth your time. Maybe there are other libraries, but I just worked with pygame. 
I used freeze and py2exe for python 2.7 and it was a real pain in the ass. After hours of wasting time I just used python 3.5 and did python pyinstaller.py --onefile your_main_file.py and it just works smooth, easy and fast. Also you can do parameters like --no-console and bunch of stuff. I would suggest you go for this way. http://www.pyinstaller.org/
Well, at first glance, the API asks you to POST with URL parameters, not using a data payload. Have you tried that? For example: https://username:password@domains.google.com/nic/update?hostname=subdomain.yourdomain.com&amp;myip=1.2.3.4 The API also allows GET requests, maybe you should stick to that. Other than that, how are you setting the user-agent header?
Bugs are addressed as they are filed. Did you file one?
I have a trivial self-written 30-line progress bar running with concurrent futures right now in my code. There's nothing special about tqdm. This is just a progress bar being updated in a loop, just like every other progress bar implementation out there.
`venv` package author here. When the `venv` package was added in Python 3.3, the `distribute` / `setuptools` unification hadn't happened, and `pip`(a 3rd-party package) wasn't included - which is why it didn't see significant adoption - despite it being fairly easy to install `pip` - example script [here](https://gist.github.com/vsajip/4673395). With Python 3.4 and later, it's even easier and the `ensurepip` module brings `pip`/`setuptools` in automatically to venvs created using `python -m venv` / `pyvenv`. The basic difference between `virtualenv` and `python -m venv` is that support for venvs is built in and doesn't require hackery when a new Python version is released (`virtualenv` has to do this to keep abreast of Python implementation changes). The built in support means that `pyvenv` venvs don't have to modify and copy over lots of stdlib files into the created venv. Other than that, the functionality provided is the same, so there's nothing much to talk about - hence the scant mentions, I suspect.
I tried this. f = interp2d(uu,vv,proj,'cubic') vol[:,:,iz] = Ratio*f(pu,pv) But it says OverflowError: Too many data points to interpolate. My pu and pv are (360,360) and if the inputs are supposed to be 1-D I tried pu=pu.reshape(pu.size) and same for pv to make it 1-D. But it still gives the same overflow error.
hopefully you are on linux? start with the interpreter; open terminal and type "python" &gt;&gt;&gt;
I disagree, pygame is dead and has been for years. Last version was released in 2009 and AFAIK it doesn't support anything past py 3.2 /u/Tyranten you should look into [kivy](https://kivy.org/#home), which is multiplatform and is still heavily developed :)
Handling user input which is out of range, for instance. Or a device returns junk data to the function, which is then propagated. In general, I don't use asserts at all, and use exceptions instead. if x &lt; 0: raise SomeSpecificError("x &lt; 0. Are you sure you wired it up correctly?") There was [this](https://wiki.python.org/moin/UsingAssertionsEffectively) post a few years back which made sense to me.
Did not know that - Thanks for the update.
I'm not entirely sure, but I think IndentationError is raised at the time the file is read, not when the line is run. If that's the case, then no, it wouldn't be possible to catch.
For a simple game and no user accounts and logs, I'd recommend just following a Flask tutorial. I used [this one](https://github.com/bev-a-tron/MyFlaskTutorial), but you can also use the official ones at http://flask.pocoo.org/.
Works :) I tried `eval`, but that didn't work....
This is the case. Same with SyntaxError.
Can confirm, we use venv daily, there's just nothing to write about. It Just Works™.
https://pypi.python.org/pypi/fuckit
I think [this](http://www.pyimagesearch.com/2015/12/28/increasing-raspberry-pi-fps-with-python-and-opencv/) will help you.
I've actually implemented the backend with flask (just to handle the api calls and with a dead simple html page), I'm more after a tutorial (or preferably dead-simple drag-and-drop framework) to put the html elements together. (I'm going to just have to bite the bullet and work through an angularJS tute arent' I?)
you're using the same operator twice, once for map and once for filter. how does it know it's supposed to filter with evens, instead of replacing the values with True and False and that it's supposed to the opposite with square.
The list comprehensions in python are amazing, but they quickly become unreadable when doing more than just simple stuff. What if you had something like this: payload |&gt; validate |&gt; log |&gt; update_db |&gt; notify The implemention could be broken into small functions and have one main function doing the piping in sequence. You really cant have that in a list comprehension 
I just took a look. I really like the Stats and Bayes books. Thank you for sharing. I can see them becoming extremely useful. Almost everything I'd found until now was how to learn Python for stats people. Despite the fact that they're called different variations of "Stats for Python programmers" etc.
/r/learnpython
 def nap(): time.sleep(1) Best name for a function ever lol. That should be used for everything bellow seconds.
Yah! I know. They are random strings. But, as you said, I have updated them. But nothing serious.
I feel they are looking good and much readable now. 
`IndentationError` is a subclass of `SyntaxError`: py&gt; issubclass(IndentationError, SyntaxError) True 
That works, but what are you going to do once you've caught it?
&gt; [–]RickXV[S] 0 points a minute ago &gt; &gt; fuck u /r/learnpython
What about overriding the pipe operator `__or__`?
Well the made up function square and evens would have to return a list. If you would pipe a function that would reduce the result to a single value you could not use a function requiring a list as an argument. So naturally the piping order is important here.
import a different module instead or continue on with reduced functionality, perhaps. I was just answering the original question - "is it possible?" The answer is yes.
I'm assuming you provided a complete description of the code you needed help with in your post, so here's your first problem. python3 -c "s" Traceback (most recent call last): File "&lt;string&gt;", line 1, in &lt;module&gt; NameError: name 's' is not defined 
you might want to look at mochi by... i2y if I remember correctly syntax works pretty much as you say [1,2,3,4,5] |&gt; evens |&gt; square |&gt; vector there is also the toolz module pipe([1,2,3,4,5], evens, square, list) I'm pretty sure fn.py would have something similar the biggest problem is that the pre-existing python std lib is not exactly consistent (e.g. `fn1(func,list)`, while in another module, `fn2(list,func)`, so a lot of care would need to be done) or immutable (lists/dicts/etc are liked a lot), so you p much need to write your own language on top of python's pre-existing stuff, and that sucks. If you want functional programming in python, running for the hills usually is the best option, unfortunately.
What you are looking for is IMO better supported in OCaml. You're looking for monadic operators (yes, there is pymonads) along with functions like |&gt; (left-associative) and ^&gt; (right-associative). To learn OCaml, see https://realworldocaml.org. It's beautiful. On the question of errors, Jane Street has an amazing blog that made thinking about errors much more clear to me. https://blogs.janestreet.com/how-to-fail-introducing-or-error-dot-t/ If Python has something like Or_error.t, I would be in love.
I really like using postfix notation in Mathematica, especially in an interactive programming setting. If you want to apply a function to an expression you don't have to add parentheses in the right places but you can simply append to it. But I'm not too convinced when it comes to Python, because it favors building huge multi-line statements (usually not very readable) and counters the "one way to do it" motto. Also, postfix notation works best when there is a short notation for lambdas, since sometimes you want to add additional parameters. For example, suppose instead of `evens` you have def divisible_by(lst, k): return (n for n in lst if n % k == 0) Then you want something like range(1, 4) |&gt; square |&gt; divisible_by(_, 2) But the way to accomplish this in Python would be to use `lambda x: divisible_by(x, 2)`, which is slightly ugly and doesn't add to the readability. 
Of course there is, Until such time as somebody invents an infinitely fast computer, *every* operation takes *some* amount of time. The real question is, how much time will it take? And that, of course, depends on the version of Python, your operating system, how many other programs are running, and the speed of your computer. It's a bit hard to time that specific piece of code exactly. The call to `print` will quickly fill the screen, and is quite slow as well. But my guess is that what you really want to ask is how quickly will Python call lines of code regardless of the code, not specifically `print`. In other words, what is the overhead of calling Python? The fastest thing you can do in Python (apart from not running the interpreter at all) is nothing at all, represented by the `pass` statement. So we can time that at the command line: [steve@ando ~]$ python -m timeit "pass" 10000000 loops, best of 3: 0.0344 usec per loop (That's your operating system command line, not the Python prompt.) This tells you that, very roughly speaking, the interpreter overhead of going from one line of code to the next is about 0.03 microseconds on my computer. On yours, it will likely be different. To measure the overhead of a while loop is trickier. The best I came up with is this: from timeit import default_timer as time total = 0.0 try: n = 0 t1 = time() while True: t2 = time() total += t2 - t1 n += 1 t1 = time() except KeyboardInterrupt: print("Total time for %d loops: %f seconds" % (n, total)) print("%f µs per loop" % (total/n*10**6)) Let the code run for at least a second, and preferably much more, then type Ctrl-C to interrupt the loop. When I did it, I got these results: Total time for 8311394 loops: 7.013674 seconds 0.843863 µs per loop 
From the description is sounds as simple as a while loop reading the line from the dut, process it, write to the tester. Are you going to need to communicate much more than that? If yes, you can either do threads/processes for each that use queues for message passing or personally I'd favor asyncio since it sounds like one is conditional on the other, so you await the read and then perform the write. [This may be on the path for asyncio](http://stackoverflow.com/a/27927704/1584762)
I really dislike the `|&gt;` syntax. To me, `|` is a pipe. I suppose I could live with `-&gt;` or `=&gt;` too, but `|&gt;` looks awful.
This would be really useful for data engineering. R has this feature. The use of pipes combined with a really nice SQL DSL called dplyr makes complex data transformations simple. It is the main reason I stuck with R for much of my work. One drawback to this approach is it allows some bad habits. Sometimes I find myself with 20-lines of piped code. If something goes wrong, it is difficult to debug. I guess that's the yin and yang of it. 
God no. Pipes are hard to read, completely unnatural for non-geeks, and are already painful enough for bitwise operations. The proliferation of special characters is a plague and should not be encouraged. Their low number is a huge advantage for Python over competitors (e.g. Ruby, Perl) when it comes to onboarding newbies. If you want that sort of approach, just use Powershell, you'll love it.
Yeah, and? My post has nonzero information content, then.
the whole point of defining lambdas that work on single elements in the list is having python iterate through it. now you are basically saying you want to implement a function evens, that does the same as filter(evens, ...) only for the function to know what it is supposed to do when it's left of |&gt;. that doesn't seem well-thought-out for me.
The fact that you came up with abad example could be because the idea is flawed :P
right, if it comes down to that, all that the proposed operator would do, mathematically, is rearrange the order of operands, from evens(square(nums)) to nums |&gt; square |&gt; evens doesn't seem like a very useful thing
plyr package, IIRC
The implication in OP's example is that the function argument has already been fixed inside the `evens` and `square`, like with `functools.partial`, for instance. When I said "maps" and "filters", I was referring coloquially to such transformations from iterables to iterables, not to the `map` and `filter` functions themselves (which could be viewed as factories of such transformations). The rationale for this terminology becomes more apparent in languages that support currying (i.e. fixing certain arguments) natively (Haskell comes to mind). `square` could be defined as partial(map, lambda x: x ** 2) Whereas `evens` could be defined as partial(filter, lambda x: x % 2 == 0) Therefore, there is no need for guesswork. 
Seems silly just to force it all on one line. This is the kind of thinking that made perl such a nightmare to read, because there are like 1000 different special cases in the syntax and people think they are clever by using them all. Not saying it's not useful, I just don't see it as a game changer and if python adopted everyone's favorite pet syntax it would be a mess. 
Yes, videos will be published, just watch out pyconsk twitter account in the upcoming days.
Actually, it's in the magrittr package, that is then used by the dplyr package. (As cool as dplyr is, there are times I load up magrittr by itself.)
Pandas added a [`pipe` method](http://pandas.pydata.org/pandas-docs/version/0.18.0/basics.html#basics-pipe) a few months ago, hoping it catch on in other packages (it hasn't yet as far as I've seen). In [126]: bb = pd.read_csv('data/baseball.csv', index_col='id') In [127]: (bb.query('h &gt; 0') .....: .assign(ln_h = lambda df: np.log(df.h)) .....: .pipe((sm.poisson, 'data'), 'hr ~ ln_h + year + g + C(lg)') .....: .fit() .....: .summary() .....: ) 
&gt; /r/learnpython 
I'd take either. . . in the standard library. The toolz module looks good for now or as an alternative. . . Or maybe that could be added to core Python actually.
Are you looking for pipes, or for function composition? https://docs.python.org/3/howto/functional.html
&gt; or a package could define useful functions, I think it is common knowledge that squares doesn't exist yet My point was that writing your own functions will still be cumbersome. &gt; also because I havn't spammed toolz enough already, toolz.curried and the whatever module: Is the underscore placeholder part of toolz?
Even in clojure it's chaos like that. I think positional arguments are just never gonna work. 
I'd love to elaborate, but unfortunately I don't have /that/ much experience performing sinful acts with python's code objects. Luckily, other people do have experience, and have been willing to talk about it too! http://stackoverflow.com/a/16118756 for a distinct, but similar concept. - - - basically, the transform you want to do is (using the std library `dis` module) &gt;&gt;&gt; f = lambda: a|b|c &gt;&gt;&gt; dis.dis(f) 0 LOAD_GLOBAL 0 (a) 3 LOAD_GLOBAL 1 (b) 6 BINARY_OR 7 LOAD_GLOBAL 2 (c) 10 BINARY_OR 11 RETURN_VALUE &gt;&gt;&gt; list(f.__code__.co_code) [116, 0, 0, 116, 1, 0, 66, 116, 2, 0, 66, 83] &gt;&gt;&gt; #--------------------------------------- &gt;&gt;&gt; f = lambda: c(b(a)) &gt;&gt;&gt; dis.dis(f) 0 LOAD_GLOBAL 0 (c) 3 LOAD_GLOBAL 1 (b) 6 LOAD_GLOBAL 2 (a) 9 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 12 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 15 RETURN_VALUE &gt;&gt;&gt; list(f.__code__.co_code) [116, 0, 0, 116, 1, 0, 116, 2, 0, 131, 1, 0, 131, 1, 0, 83] but that transform is fragile obviously, so like, ideally, probably execute each section that is separated by ORs on the stack (noting that ORs use the last two items added to the stack, hence why it loads two values first, so the split needs to happen at the OR's position -1), and then use the resulting values from that to then throw into a pile of loads/callfunctions
Your example doesn't work with list comprehensions because those functions don't return iterables. But it's totally fine to have list comprehensions span more than one line. *In fact*, list comprehensions were lifted from Haskell, where they are syntactic sugar for using the List monad. Monads are essentially an extension of what you're asking for here. For example, using promises - which are also monads - you can already write the kind of code you're asking for: Promise(payload) .then(validate) .then(log) .then(update_db) .then(notify) In fact, the semantics of this are already much, much more powerful than what you're asking for (because promises can also handle error propagation, and are asynchronous.) So, my answer is that, you're basically asking for a special case of something much more general, syntax for monads. You don't want to accidentally half-ass this more general case by rushing to support one special case. *Especially* because, as noted elsewhere, def pipe(arg, *funcs): for f in funcs: arg = f(arg) return arg response = pipe(payload, validate, log, update_db, notify) already handles your problem very cleanly, while additionally allowing you to add other stuff like error handling or debug logging if you so chose.
In pandas too.
I think completely killing runtimes and matplotlib should be found before the word "release" is even uttered.
load the data into a string: with open("filename.txt") as f: x = f.read() add closing brackets: x = '[' + x + ']' add commas between arrays: x = x.replace('][', '],[') use eval: x = eval(x) done
I agree, using an operator just for a reversed composition operator seems a bit overkill especially since Python has always been light on the use of operators. Moreover, the fact that composition is associative means you don't have to worry about deeply nested `pipe`s: `pipe(a, pipe(b, c))`, since you can always refactor that into `pipe(a, b, c)`. Even though I generally write in a very functional style in Python, I find myself reaching for the `pipe` operator that often, because not many problems can be decomposed into a simple linear pipeline.
Thanks! It worked!!
I'd use [ast.literal_eval](https://docs.python.org/3.5/library/ast.html#ast.literal_eval) because it's safe. It only allows literal structures, so it can't be used to run malicious code. edit: here's an alternative way to do this that I personally prefer: from ast import literal_eval import re with open('file') as f: input = f.read() match = re.compile('\[.+?\]') x = [literal_eval(m) for m in match.findall(input)] The regex `\[.+?\]` just matches everything within each set of brackets.
Everyone else has posted some ways to do this, but when I encounter such a need in my code (I have a stream and I need to do numerous transformations on it before use), I just use something like this: nums = [1, 2, 3] nums = map(square, nums) nums = filter(evens, nums) nums = list(nums) Yeah I'm reusing the same variable, but only in this block. So effectively it's just once. Basically, why not just do your stream processing on multiple lines, if you think a single long list comprehension is not going to suit your needs?
I really like this idea - I feel in love with it when I was learning Elixir and it's one of the features of the language that make me want to stick with it. However, I have mixed feeling about its use in Python. Part of me wants to embrace it and never look back, but I've been burned once or twice trying to write Python that was "too-functional". That said, I'll definitely try to give it a go in some scripts and see if it has a positive effect on the code :). Thanks OP!
How does your example distinguish between a filter and a map operation?
Depending on what `square` and `evens` do and accept as input there's also vals = [1,2,3] vals = square(vals) vals = evens(vals) or you could combine them vals = evens(square([1,2,3])) This fits the C-like procedural/scripting style that Python was originally built-upon. Sure we can make it do whatever, but Python is natively C-like and if you want to use pipes then I feel you should be using a language where that's the native programming style. IMO both are readable, but this version is Pythonic and the pipe version is not Pythonic.
It is something a bit different, but a friend of mine has created a tool for pipe commands composition, which looks quite handy: http://0101.github.io/pipetools/doc/
Syntactic sugar, but not a huge deal I agree.
Fixed. Thank you.
A friend of mine just wrote a library called 'tubing' for doing something like this but mostly focused on I/O of any kind: An example: sources.Objects(objs) \ | tubes.JSONDumps() \ | tubes.Joined(by=b"\n") \ | tubes.Gzip() \ | sinks.File("output.gz", "wb") https://github.com/dokipen/tubing
I think tkinter is probably your fastest/simplest window. That said, it's quite outdated. Python really doesn't have a modern, standard gui kit. Instead, most UIs are written in something else. If you want something that's a little more modern, you might try either of these: * https://kivy.org * https://wiki.python.org/moin/PyQt/Tutorials * http://www.pygtk.org
Yeah, it's just that Python 3 moved reduce out of the default namespace.
No, its the general case.
Is it bad to have recursion like this, as opposed to having an infinite while loop that you break out of if the break flag changes?
Unfortunately, I don't have any links. I wouldn't start with angular though. That is a tremendous framework and will overwhelm a non web programmer. Go for the MVP. There are plenty of older frameworks around that handle AJAX much easier to a beginner. In the end it won't be flashy and it'll look like crap. But even with angular it will too, again unless you know the ins and outs of html and css and js. But it would most likely be the same if you don't know PyQT or similar frameworks. Don't try to be perfect. You need to get your game play tested and in front of people for feedback. There may be weird bugs impacting your business logic. You are on version 1. Wait until version 4 to be polished. Software takes time. That's the only real way to make a killer game.
Thanks. Mochi look interesting. Will research it more.
It looks like the Python-memcache is in fact significantly slower than the C version? So it's not pure and fast, it's pure *or* fast.
you mean your coworker wrote their own celery pipe stuff, instead of reading how to use celery's pipe stuff? http://docs.celeryproject.org/en/latest/userguide/canvas.html#the-primitives
well huh, that's interesting. I didn't realize powershell was a language. i'll downvote my own ignorant snarkiness for you.
Very cool, I've never see that before.
It has made my code 10x more readable 
Honestly, we should stop making things for humans. Humans already have too much stuff anyway. I exclusively write software to be used by rocks.
Why would they do that? I never understood python's aversion toward immutable functional style.
I know nothing. However my personal opinion would be to check out edx and or coursera, they are free and helpful. After that, get a project and learn by doing. Thats what worked best for me. 
It also feels rather arrogant. API design is hard - anyone can make an API they like themselves, but it's tricky to make something lots of other people will like. We're not all Kenneth Reitz. More or less every package tries to have a developer-friendly API. But we don't get to say ourselves whether we succeeded - the people who use it have to decide that.
"For humans" is for Python what "Enterprise" is for Java, is that what you're saying?
Well said. 
One of my favorite things with Python has been the huge depth of modules and how awesome they are. Might not be a bad idea to have a couple of quick slides that show how powerful and succinct "import this, do that" can be. 
Indeed. Thanks
Fully agree.
Make PyPI Amazeballs Again!
What's to stop `[1,2,3] |&gt; square |&gt; evens` returning `[False, True, False]`?
2012, or about three years ago? Perhaps it *was* celery pipes..?
Not to discourage you from moving to PySDL2, but there are some active efforts in make something that has a largely Pygame comparable API, but using SDL2. See: https://github.com/renpy/pygame_sdl2 These guys are pretty active on the Pygame lists, and probably even here on Reddit. Personally I see a lot of value in the Pygame API, as it has a huge user base, is high level, and I know it pretty well. My hope is that the Pygame devs get another Python 2 and 3 Pygame release out the door so a Python 3 Pygame can migrate through Debian, and then to transition to something like Pygame_sdl2 (under Python 3). I have no axe to grind with PySDL2, but I have a lot of familiarity with Pygame so that's what I'm hoping for.
ONLY FOR ROBOTS
You should also add `__gt__`, taking a file-like object, so you can do `echo("hello world") &gt; open("myfile.txt")` +Edit and `__lt__`, to read a file into `stdin`, too.
In general, I agree that this would be a nice feature to have. I wrote a library that has similar goes, but has a larger API, and supports reading/writing common formats (txt, csv, json, sqlite,...). https://github.com/EntilZha/ScalaFunctional What I would like to see more than this, is a more concise lambda expression and/or multiline anonymous functions (I know there is some technical issues with this, but I can still wish)
For generators I would showcase itertools a bit, because iterator combinators are essential to this kind of programming. Also show how generators can implement simple control structures, maybe using the contextmanager decorator as an example. And a simple coroutine example will complete the generator picture. You can find further inspiration in the awesome [David Beazley's talks](http://www.dabeaz.com/generators/) about generators. Context managers are a useful and interesting feature of python. They're mostly related to resource management, but db transaction/connection management can be a motivating hands-on case. Use sqlite as a study case. Don't limit your exposition to list comprehensions. There are dictionary, set and generator comprehensions also. It's most satisfactory to see a good idea generalized. Also, you can relate generator comprehensions to your generator exposition. And you can show how easy it's to pass iterators as function arguments, by means of a simple generator comprehension, which is related to the topic of iterator combination. OOP is another nice topic because of the very general python implementation: descriptors, mro, metaclasses. At least show how everything is an object. 
It seems near feature complete. One of the primary authors is the person / people behind the Renpy visual novel engine, and it is seeing some interest / adoption. I even think there is a python 2 debian package. The last I read, the only big thing they don't seem to be re-implementing is support for a bunch of colourspace stuff as it created a lot of redundant work in an era where most people just use the native colorspace of whatever is in front of them. Mindy you, I've only kicked the tires on this project and pySDL2.
For humans.
It's a bit cheesy but the [4j](http://stackoverflow.com/questions/1826014/what-does-4j-mean) suffix serves a purpose, it lets you know right away that it's a java project.
I believe he actually wrote osh around 2005 or 2006, probably before Celery itself existed and way before that pipes thing your referring to existed. He just released it from his own repo to github 3 years ago. The code was well engrained in the product we built at our startup Archivas before I joined back in 2007. 
It's discriminatory against artificial intelligence.
Agreed. Btw., there's an equivalent in machine learning: "For Hackers," which, I think, is supposed to read "this book is less math-heavy and more practical")
Indeed, and it's easy to step through for debug.
Describing Projects as "For Humans" Considered Harmful
Hey! I ended up rewriting various variations of these (and more) utility functions and classes for PySide applications and decided to polish them somewhat and publish them -- maybe they'll be useful to you. So far included is a neat UiPlaceholderMixin class which allows you to replace placeholder widgets created in the Qt Designer with custom widget classes at runtime without having to modify the converted Python UI code. Also there's an actual implementation of QAbstractTableModel: GenericTableModel. This class implements most methods that you could possibly need and should be very flexible for displaying and modifying two-dimensional data using the QTableView. I am also planning on adding my GenericWorker implementation, which is both: a QRunnable usable with a QThreadPool and a worker usable with QThread's moveToThread method. It is potentially resumable, communicates via signals and slots and works with generators, functions and methods. Some neat features: If generators are used, intermediary results are emitted via the progressed signal. If you need two-way communication that is possible via the message slot by sending values directly into the generator, and then resuming the worker. I'll add concrete examples for all this, as soon as I get around to actually adding it. Examples for the UiPlaceholderMixin and GenericTableModel are already included and should be considered documentation. Hopefully it's useful to some of you! I'll probably add more things as I go -- I'm open to and happy about critique and bug reports.
Talk about a non-issue...
I agree it's pretentious, but if it's the point of simplifying existing, complicated modules then how else should it be described? 
I agree it's overused. However, I do find it slightly meaningful in some cases. Using that little buzzword implies that the library in question was at least *trying* to provide a good API, i.e. that usability is a priority. That is obviously not the case with every library. Often these "for humans" libraries pop up in areas where several similar libraries already exist and it doesn't have to be "arrogant" to imply some criticism of those other libraries. Even if the self-proclaimed "human-friendly" libraries don't have an objectively better API they may still offer something different.
what is this tumblr?
Nope. You don't need it. * Learn python first. There's plenty to learn. * Python 3 includes a module for virtual environments (venv) vs Python 2 as a 3rd party library. Invocation is really simple. Let's suppose you have a virtual environment named 'my_venv'. python3 -m venv my_venv or python2 -m pip install virtualenv python2 -m virtualenv my_venv If you're using linux or mac, then: source my_venv/bin/activate On windows: my_venv\Scripts\activate 
If not, he can be one in 2 minutes - [Rockstar](https://github.com/avinassh/rockstar)
"its offensive" cry some more.
Really more of a red bull programmer...
&gt;...but if it's the point of **simplifying** existing, complicated modules then how else should it be described? I don't know, how about "Simple xyz module". [For example...](https://en.wikipedia.org/wiki/Simple_Mail_Transfer_Protocol).
English has by far the largest vocabulary of any language in the world. I think we could probably work something out.
threads, threading for cats.
Indeed. The only place I see anyone crying about this is reddit. I wouldn't even know this was a thing that got people upset otherwise.
I always thought that was kind of like saying you made something for "dummies" - basically saying that you don't need 20 years building databases or six months studying SQL queries to get started using the library. 
Maybe it's just me, but that sounds more like a watered down version (e.g. fewer features) than a version that's made to be easier to understand. e.g. A simple photo editor vs Photoshop for humans. The first sounds like MS draw. There must be something better; which wont ultimately cause people to bitch about its overuse, right?
There are benchmarks that run after each commit, and there are a lot of tests. So, I doubt that runtimes were increased "10 fold", and matplotlib stopped working for many people. If it happened for you, it might've been your setup, or a corner case (in which case I recommend you file a bug). Or, since you were using pandas to make money, you could also donate some of that towards it.
Posts stating "must stop" considered harmful.
How about this? It can still be used, but to give the brand meaning, the project in question has to be certified by a test to see if it meets Reitz-designed criteria in order to earn it?
I didn't notice before, now thinking back there is quite some projects using "for humans" and it's not just Python. And what about "built with love?" I don't think I read project description very seriously because many projects don't have accurate one, so "For Humans" doesn't have much of effects on me, I probably just drop them whenever I read them. However, I did first notice that "™" when I glanced at the screenshot. If I had a problem, then it's not the "for Humans," but the use of trademark symbol.
This should be xposted to r/FOSSworldproblems!
Comments closed? So you want to be heard without knowing others opinion.
...?
you can alternatively do this: processor(payload).validate().log().update_db().notify() where processor is some object that encapsulates the functions you are using.
nope just a moon
I don't dig it. Cramming crap into one line seems like a cool idea but I'm not losing any sleep over writing a second or even a third line. I like keeping my functions on different lines because it's easier to read. Of course I break this rule all the time but I wish I didn't and that's what counts.
Are we a bit thin-skinned? So people call their shit "awesome" and your next cryblog is "stop calling things I don't find awesome 'awesome'"?
A non issue!?!? I'll have you know my bike shed was built *for humans* too.
I would rather like to see ``.map()`` and ``.filter()`` defined directly on``abc.Iterable``. [1,2,3].map(square).filter(is_even)
&gt; anyone can make an API they like themselves, If only... 
Sure, let's have "Bureau Officer For Humans" (BOFH) with the power of granting "FH" licenses to individual projects. What could possibly go wrong? Honestly, this "for humans" thing is just a little fad. It's like desktop widgets, or XML config files: decent hacks that got too popular for their own good. /u/kennethreitz himself is now a caricature, abusing his own successful brand and severely diluting it (no, we did not need yet another opinionated abstraction layer over SQL, and pep8 was perfectly readable without fancy fonts). Any other developer parroting his tagline just demonstrates a lack of imagination that will likely reflect badly on the resulting libraries. "Everything in moderation, including moderation", said someone. Including bitching about library taglines.
Now this has became the norm, the next obvious step this evolution is to make packages for slow humans
fucking spam
For Users By Users
/r/learnpython
Yes, I think self deprecating descriptions are probably best here.
Yes it is bad. If your task is long running, you will eventually crash with &gt; RuntimeError: maximum recursion depth exceeded Also, it is not very efficient for this simple use case.
yeah, I'm totally in love with context managers right now. I keep looking for more uses for them.
I write software for squamates, it's clearly an underserved field.
https://docs.python.org/3/library/xml.etree.elementtree.html &gt; Changed in version 3.3: This module will use a fast implementation whenever available. The xml.etree.cElementTree module is deprecated. You are welcome.
First `requests` is an awesome library. I can give some forgiveness to the author because `urllib2` was such a crazy API and this tagline was a "tounge and cheek" reference to the years of complaints about it. For someone aspiring to recreate a `requests`-esque experience first things first...know your damn role. This lib is a master stroke delivered by someone that clearly understands the problem space and how to organize an efficient api. Most developers are not capable of this. And to OP's point its "pretentious" to believe that they can. Where most aspiring "for humans" developers fail is that they under estimate the complexity of the problem they are trying to solve. So what they deliver is "A library that helps my feeble brain understand what's going on satisfying my minimal use case, but probably doesn't address all of the original problem" rather than "a library for humans" EDIT: tongue in cheek
A reddit link for humans™.
The site i would use is codecademy.com they have what you're looking for.
It's great that you're trying to learn Python being so young! I also find valuable that you're looking for someone to help you with it, it's impossible to learn everything from online courses. You need real human interaction and experienced mentors to learn in the proper way. We do remote programming courses and we offer scholarships if you can't afford them. Send us an email and we'll let you know when the next batch applications are open: questions@rmotr.com
100% agreed on this. Even better would be to have some way to add operations on this without mangling list too badly (which would allow everything here https://github.com/EntilZha/ScalaFunctional without having to be in stdlib)
The argument against your example is that it's always been better expressed as a comprehension: [n * n for n in [1, 2, 3] if n % 2 == 0] You'd have to need something like reduce before the list comprehension argument starts to fall over. The fact that functions aren't curried by default and that we have variable positional and keyword arguments makes it even more problematic. You'd have to either make a lambda or use functools.partial in order to get a callable which could properly be passed to a pipe.
I always spin up a new virtualenv for any project I start. While it's not necessary to learn if you're starting out with Python, it's certainly something you'll want to pick up as you start building your own projects. If you keep your env's clean, then when you pip freeze it's much easier to suss out your requirement files. So to recap: helloworld beginners don't have a need for virtualenv, but when you start looking at deploying apps you for sure want to learn it, along with git. 
Ah sorry, was being a bit of a dick
Irrational outrage over naming and marketing practices must stop!!!! These posts exist on every domain of human activity. It is the equivalent of saying, "Get off my lawn!"
Is XML really easier to parse than JSON is...?
http://gph.is/1MHF6vu
I'm so going to use that!
Looks very interesting. I may have to play around with this a bit. I'm not sure if you're the author, but i would include what the json response would look like in the article. 
Fo' Shizzle!
Ill answer your question with another question. Which OS should you install on a new PC Windows 95 or Win7/10?
&gt; I can give some forgiveness to the author Did you look at the author's _other_ projects which have the tag-line? Are their APIs equally deserving of it?
[fuckit](https://pypi.python.org/pypi/fuckit). I build my packages with violence.
Great timing. I'm working on a Websockets For Humans api now. 
I have the same issue, yet all my servers are 2.7 installing an alt version isn't easily accomplish. For example I'm moving a bunch of custom scripts into Python to be installed on AWS lambda, which officially only supports 2.7. How stable is the 3to2 back port? 
Yah! But thanks mate for your concern.
Hi pununun, Sorry If my message offended you. I thought I made it clear this was a voluntary basis offer, and in no ways I was asking anyone to spend their time if they did not believe in it. I understand if you do not trust a company you never heard of, and am sorry if I posted in the wrong thread by mistake. Can I suggest the next you comment on something, even if you do not like it or do not understand it, you try to give advice instead of complain. Your message is not of much help to let me do better, the next time I am communicating with the rest of the Python community, whether it is for a commercial reason or absolutely not. PS: sorry but I don't like comments that are trolling for just the sake of trolling. I also made it very clear with the first line of my message this was a commercial post. 
Author is https://twitter.com/salendron?lang=de We use it in our product since 6 months. Works really great. (deployed to google cloud)
Yea all them aged unfixed vulnerabilities really makes it easier to keep your stuff private.
1. Correct your learning process because have a little problem, "kinda forgot it". When you learn technical issues, you don't forget easily in few months. 2. Learn BOTH ones. Yes Python 3.x is not only the future of Python, is the present now with many tools, AND Python 2.7 is the present now and will have active support for 2-3 years (python community decision some time ago) 3. re-learn python 2.7, trying to be agnostic, that your code can be easily converted to python 3 modules (use only unicode strings, use print like a function, only new class objects, etc)
depends on what you need. They are both solid frameworks. Django has more available out of the box, while Flask can be really light weight, but has packages that give it all the same functionality as Django if you need them.
+3 
No one can help you if you don't share the code which you're trying run.
Not really well documented. At minimum, your README should say what it is and how to use it. Dropping someone the link to code, where they have to inspect the code to determine what it is will not get a lot of people using it. That said, yay! opensource pyside stuff!
I agree it's overused and also not that helpful. There's probably few projects, that try to be as complicated as possible. No point saying you're not one of those. "For humans" became the "Bio", "Organic" and "Natural" of Python projects. I like Djangos' "Web framework for perfectionists with deadlines" - that tells you what user base are they targeting (rather than very broad "for humans") and it doesn't sound like you're a prick downplaying other people's work. 
Really great article. For what it's worth, here's what I got with Cython on my machine: import numpy as np cimport numpy as np cimport cython import cython @cython.wraparound(False) @cython.boundscheck(False) def resample_cython(float[:] qs, float[:] xs, float[:] rands): cdef int n = qs.shape[0] cdef float[:] lookup = np.cumsum(qs) cdef float[:] results = np.empty(n, dtype=np.float32) cdef int j = 0, i = 0 for j in range(n): for i in range(n): if rands[j] &lt; lookup[i]: results[j] = xs[i] break return results &gt;&gt;&gt; python -m timeit -s 'import numpy as np; np.random.seed(0) ; n = 1000; xs = np.arange(n, dtype=np.float32); qs = np.array([1.0/n,]*n, dtype=np.float32); rands = np.random.rand(n).astype(np.float32); from resample import numba_resample2, resample_cython, resample' 'resample_cython(qs, xs, rands)' 1000 loops, best of 3: 380 usec per loop and I get around the same timings as you for numba (slightly slower on my machine).
This looks great, thank you for making this.
Weight, size, power consumption, cost?