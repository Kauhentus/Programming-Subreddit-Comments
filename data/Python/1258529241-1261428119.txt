The documentation is much improved -- thanks.
Once they realise how big a portion of the coding process consists of debugging and waiting for the results to be calculated, and how that is easier in python, they'll see that it is profitable to switch. How many man hours have been wasted on those fragmentation errors already? Also, like others say, there is a smooth transition. This reduces risks of having a team that can't do anything (significant) since they need to learn Python but haven't been trained yet. I think that's what they're afraid of. One package that wasn't mentioned yet is matplotlib, which lets you make graphs in a matlab type of way.
Django has gained massive traction because the documentation is amazing. The book is given away for free and is better than many books you have to pay for. Also the community is so damn friendly. Best of luck with your endeavors.
This is going to be tough, for the reasons others have stated (primarily investment in Matlab, familiarity with it, libraries in it, code in it). The two main arguments you will have are (1) licensing fees (and hassle -- what do you do with new people, renewals, etc, don't forget to include this in your calculations) (2) increased productivity. (2) is the killer argument, but you don't have a lot of facts to back it up. You do have this memory bug you've mentioned. Document how much time that's costing you. I think your best bet is to try to do it in two phases, since you don't have enough information to make a convincing business case. Try to use Python for some sub-project. Document things like getting up to speed, and productivity. You should also talk more with your other developers, and make sure that this is something that they support, or at least aren't hostile to. (And pushing someone into changing something they're comfortable with and don't want to change may incur hostility). That's another reason to start with a 'skunkworks' type project -- you don't need to convince everyone at once, nor do you need to push something on people that don't want it. I think if your bosses are open to an business case, they will be open to getting more information, especially if it is at essentially no cost (basically small risk of longer dev time). On the other hand, if I put on my cynical hat, it may be their way of shutting you up without saying no. :D Kind of like developers not saying a feature is impossible, only that it will be very slow and expensive to implement...
Sorry to have offended you -- thought I'd post something informative for people that I found useful. Why do you assume I'm being critical?
This is really excellent ! This recipes will really help.
Yeah, the edit didn't help. Please read [this](http://xkcd.com/322/) until you understand why.
I'm not assuming you're being critical, I'm assuming you're incapable of understanding an entire paragraph. Not just you, but most of Reddit seems to do a mass-parse of articles looking for flaws and highlighting them rather than reading and understanding what the author is trying to convey. It bugs the crap out of me and I finally just snapped, sorry for that, nothing personal. You could have quoted him saying he knew about them and provided details of which version it was in, where to download, etc. But instead you quote him in a way that makes him look ignorant.
Ah, if it does all you need, then you should be good. I'd pay anything to get out of having to write MATLAB code.
&gt; that's a silly thing to say. Charming. &gt; Except that we're nice enough to give you a helper object called "scoped_session" What about engines, metadata, and other SA entities? Your response is "don't share objects". Crickey, I didn't even say it didn't work, I said it was like voodoo because the documentation is so limited in the right way of handling said entities in a multi-threaded application. Can engines be safely shared? What about that global declarative_base instance one would create? http://www.sqlalchemy.org/docs/05/session.html#contextual-thread-local-sessions This seems to be the only section about SA in a multithreaded context but it says nothing about when to bind the session to an engine nor does it explain if you can pass the engine to the bind parameter of the session_maker once and for all. This is why it's voodoo, the doc is so shallow for some of the topics it covers you have to try and see for yourself. The downer of SA is not what it can do but how you find how to do it. Voodoo indeed. 
Just to be clear, I'm playing Devil's advocate to some extent in this thread, in the hope of helping ablakok to enumerate some solid, verifiable reasons for the move that can be turned into an argument management will understand. I have absolutely nothing against adopting a new technology if it is in the company's interests to do so, nor against any one person being the first advocate of that technology; someone always is, after all. I just want to raise awareness of a possible negative impression that this could bring if not presented clearly.
Can't have it working under plain vim under Mac OSX. Anything special to do ?
One way might be to propose using SAGE (http://www.sagemath.org/). It has a look and feel similar to MATLAB/Mathematica (and so should flatten the learning curve for other analysts) but its core is Python and so you keep all of the Python functionality. Plus, it's free and open-source.
phht whatever 
appeal to authority
I picked up a copy yesterday and am **really** pleased so far! The book is basically a concise reference for all things Python-- kind of like a slightly verbose version of Mark Lutz's Pocket Python Reference. The Essential Reference book is definitely not a learning guide. It is, however, a fantastic reference for non-newbies. As well, the physical binding of the book feels really, really nice. They clearly spent a little more on production of the book, and it makes me happy just to hold it in my hand. :-)
pyspuc wraps a c++ dsp library but so far there has been little interest in it
umm just delete it ?
That was my attitude, too, until they asked me to make this case. I'll give it a try and we'll see what happens.
&gt; Good question; a larger user-base whole view the project as a necessary part of their stack. When I first started using Cheetah, the project was languishing and my colleagues and I used it more out of momentum than desire. Having an enthusiastic group of people using a project helps a lot with motivation to continue to improve it (at least for me) Would it be appropriate of me to suggest that this may not really be the best reason to want to promote Cheetah? (Now, I know that sentence doesn't come across very well, but I don't mean it like that. :)) You use Cheetah day in and day out and you want more friends to come in and help you out with the project -- that's fine, I understand. However, what I mean by this is that if you are wanting to promote a particular Python project and build up a community around it, then the reason for doing so should probably be based in your confidence that the project offers things that are better and that will really help people and get them excited about said features. If the project offers things that are much better and helpful, then you have a very good starting point to attracting a community. If anything, I would probably place this as the key starting point to attracting a community. Off hand, perhaps you may even consider turing Cheetah into something that really stands out from the other templating systems -- something that you and your colleagues actually are excited about again -- and thus, something others can get excited about. I suppose the same thing goes for other Python projects you want to form a community around. &gt; I kind of wanted to shy away from focusing on things about Cheetah specifically and more on refining a some points that might be applicable to any Python-based project in terms of getting it in front of users and increasing adoption/development. I see.... Well, I always have an interest in that kind of stuff. :) For me, I always see it starting with the quality of the product. For example, whether the project offers features that no one else does; is much easier to use, is faster, etc... you get the point. Personally, for me, I always gotta have a reason for it to exist -- something that makes me want to promote it. Then comes to fun part of getting more people to us it. However, to specifically address your question about open source Python projects, here's some random ideas: * The project should excel in a particular area -- then you should make sure people know it is better at said area on your website. This could form a first step into making people consider it. If the info is visible enough, they may always remember your project because of those key feature(s). So, even if they don't use it, they may suggest it or come back to it later. * Along with the first point, comparisons to other projects of the same type helps here (such as comparing Cheetah to other templating systems). * A project that can actually support a large community -- What I mean by this is that the project is of a sufficiently large scope that it would attract lots of people. A templating system, for example, is likely not going to attract large amounts of users, since not everyone does web development with Python, and among them, not all use a web framework, and among them not all use a templating system, and among them not all use Cheetah. Not only that, the simplicity of a templating system, means that there is not going to be a lot of things to discuss vs discussing the features for a web framework. So, many Python projects cannot actually support a very big community because the project covers such a small area to begin with. * Great, introductory tutorial are a must for major adoption. I see many Python projects that fail in this area. The tutorial often lacks many pieces of information. Always imagine that you know nothing about your project (in the case of Cheetah, imagine the person visiting your website does not even know what a templating system is). You have to start from these very basics and make sure you build up from there -- never assuming the person knows what something is as you teach them. Many tutorials do not build up gradually in this way and often end up leaving gaps in the person's understanding. This can also result in people getting frustrated and leaving the project for something else they can understand. A second problem I see in tutorials is that they start out good and simple, but once they get to the advanced stuff, they become rather scatterbrained and fail to explain any of the more powerful featurse. This can result in a more subtle problem, where people never use the project to it's fullest potential and may be rather dissastisfied with it's features (because they don't know/don't understand them). Offhand, I've recently encountered such issues in the tutorials for SQLAlchemy, Elixir, and lxml. * User support that actually doesn't condescend. Wow, how many times do I see this -- utterly arrogant attitudes towards people who ask really simple questions. There has got to be a way for users to ask really basic questions over and over again and not get hit with "search google", "that's been asked before", "read the manual", "that's a stupid question", "the developers are busy", "add the feature yourself", and all those other types of replies. The problem here is there needs to be people willing to answer questions (which is usually one of the developers). Also, care must be taken to make sure people don't start spouting the attitude I mentioned. BTW for most Python projects, I actually find that this attitude is not very common. For the most part, I see this attitude in BSD/Linux projects; whereas, many Python projects don't seem to really have this problem. Still, it is always something you want to make sure of when you develop a community around a project. * Over-reliance on mailing lists - not everyone likes mailing lists; in fact some hate them (like me); offering a forum for people to ask questions can help build a community.
I'm so frustrated by the state of python packaging that I'm really hoping the community will rally behind Tarek and help get some of this pushed out during the Moratorium.
cheetah, the last time I looked, needs a decent way to be used efficiently in a multithreaded environment. It seemed like to get a compiled "template" object, you had to also embed all the contextual information in it as well - contextual information that is typically specific to a single web request. Which means your compiled object isn't threadsafe, which means you have to recompile on every hit. edit: and then there's all kinds of overly complicated thread-local schemes documented around the web to work around it. The approach used by modern compiled engines like Jinja and Mako doesn't have such issues. I might be all wrong about this but this is what my original research came up with for Cheetah (and is one reason why Mako exists). That, and everytime I attempted to read the Cheetah documentation online, the page took about 5 minutes to come up - this behavior wasn't a quirk either it was persistent for many weeks. Not a good selling point. And, it seemed to have many tags and features that were all slight variations on a single behavior with no clear need for all those different varieties of the same thing. In that way it was an inspiration for Mako's "here's all the tags, simple and easy" section in the early chapters of the documentation.
I'm not aware threading issues, though I don't doubt their potential existence. One way around the situation you describe is to use [precompiled templates](http://packages.python.org/Cheetah/recipes/precompiled.html) in which case you'd import the module, instantiate a template object then mutate it per your needs (which you can do thousands of time without any compilation hit). &gt; That, and everytime I attempted to read the Cheetah documentation online, the page took about 5 minutes to come up - this behavior wasn't a quirk either it was persistent for many weeks. Not a good selling point. Yeah, that's why I've started pushing the [documentation to PyPI](http://packages.python.org/Cheetah) &gt; And, it seemed to have many tags and features that were all slight variations on a single behavior with no clear need for all those different varieties of the same thing. In that way it was an inspiration for Mako's "here's all the tags, simple and easy" section in the early chapters of the documentation. I definitely agree with this, I'm working on an analyzer right now to run a survey of what directives are being used and which aren't so I can start culling some unused/unnecessary directives.
How would the moratorium on language changes affect what's going on with Distribute, setuptools, et al? 
&gt;&gt; that's a silly thing to say. &gt; Charming. I apologize for this. &gt; What about engines, metadata, and other SA entities? There is a lot of explicit discussion about thread safety of engines, connections, strategies, etc. at: http://www.sqlalchemy.org/docs/05/dbengine.html Also, we've never had anyone ask if an "engine" is threadsafe and its extremely rare people are confused by the scoping of an engine object. As for MetaData, its somewhat trivial to discuss "is it thread safe?" since it is only mutated when a Table object is created - and the docs are explicit about what happens when two Table objects with the same name are created - you get the already existing object back. Again, *nobody* has ever asked us this question or expressed confusion in any way. &gt; What about that global declarative_base instance one would create? The declarative base is a Python class. The docstring states: "Construct a base class for declarative class definitions." So there's no ambiguity there. I don't think its the SQLA documentation's job to explain that Python classes may be freely subclassed and instantiated without concern over the classes' internal state being corrupted by multithreaded access. Connection, Transaction, and Session are the only common, non-configurational objects (meaning, are constructed or mutated after module import time) that are not threadsafe in SQLAlchemy. And for all three the documentation is completely explicit and clear about this: * http://www.sqlalchemy.org/docs/05/dbengine.html#more-on-connections * http://www.sqlalchemy.org/docs/05/dbengine.html#using-transactions-with-connection * http://www.sqlalchemy.org/docs/05/session.html#frequently-asked-questions &gt; This is why it's voodoo, the doc is so shallow for some of the topics it covers you have to try and see for yourself. The downer of SA is not what it can do but how you find how to do it. Voodoo indeed. Your statements further suggest that using common Python constructs with multiple threads is what you consider to be "voodoo". Not the job of SQLA documentation to explain how threading works in Python. 
Maybe community members aren't busy with other things? I really don't know.
I recommend commandlinefu.com for versions of that which actually *work*; `find -print0` and `xargs -0` are keys there, and if you *really* don't want context, `grep &amp;&amp; echo` is just `grep -l`...
Basically it frees the core team to focus their energies on the standard library for the next couple years. From what i can tell, Tarek will be merging successful ideas from distribute back into distutils. 
Okay, since you took the time to respond extensively I will admit that it probably is my SA-fu which is rather limited. I do understand how threading works but I find (found) the SA documentation to be rather... hmm... confusing in its organisation. I'm quite sure there are tons of information there but I spend so much time wondering where it could be located that I get frustrated and start calling names. In my opinion, the documentation should try doing better at telling astory from different point of view (beginner dev, administrator, performance tester, etc.) so that it carries you through the right way of doing things, independently from the fact it is written in Python and expect therefore you to know why a certain bit of pieces has been implemented a given way. 
Err, I notice that my writing style often comes across as "this is the way it is". Sorry about that; I've thought about it in other topics I've written before and I just can't figure out a different way to word it. Maybe I should start every post with "I could be wrong" :) ref: http://thedailywtf.com/Comments/The-Standard-Way.aspx#290795
Sorry, last apple computer I touched was a IIe. Maybe this will help? [http://vim.wikia.com/wiki/Mac_OS_X_clipboard_sharing](http://vim.wikia.com/wiki/Mac_OS_X_clipboard_sharing) Specifically at the bottom about fakeclip.
Zope is foreign to me. I don't even know what it is. python subreddit rarely mentions it and there doesn't seem to be anything cool or useful done in it. I know they invented their own python abstract class type, but other than being one of the oldest python projects. what else is there?
Kinda makes me want to learn Python, instead of waiting for Unladen Swallow... eh?
exec() is not bad per se. There are uses for it. And there are bad uses too. For instance, you should remove this from web2py: exec "import %s" % module This just scratches the surface of the overuse of exec(), if not of lack of understanding how Python works.
wait, wat¿ Unladen Swallow is still Python, not a different language, it's "just" CPython on LLVM (w/ LLVM-JIT).
I don't like to delete comments that have been answered as it looks strange, and my criticism of Python in a Nutshell still stands, so I left it in. (Had I caught my mistake sooner, I would have deleted it)
Zope is really a whole range of projects: * Zope 2: the original Zope that started it all. Still in use, but not recommended for people who want to build new apps. Is the foundation of Plone, a popular CMS (though it uses the Zope Toolkit too, see below) * Zope 3: the next generation Zope. Quite different from Zope 2, but conceptually it has shifted to: * The Zope Toolkit: a collection of libraries. Many are only useful if you buy into a large part of the toolkit, though some are useful independently. Zope 2 also includes these libraries (to allow the use of this technology in the more legacy Zope 2 environment). * Grok: a web framework based on the Zope Toolkit Grok (grok.zope.org) is, I think, the best way into modern Zope. BFG is not quite zope, but conceptually is very close. Zope technology tends to: * URL traversal over routing (though routing is supported) * use the Zope Component Architecture. this features the concept of explicit interfaces and the possibility to glue things together. * use an explicit configuration system (either ZCML or Grok's). * feature model-driven development. Instead of looking up a view based on a URL, a model is looked up based on the URL and then a view. Views and models can be hooked up flexibly. * use the ZODB instead of a relational database for persistence (though relational databases are supported) * use an explicit configuration management system for composing applications out of libraries (buildout) Zope technology tends to fit CMS-style applications. 
thx for the link
That line serves a purpose within its context: for module in required_modules: try: exec "import %s" % module except: report error, missing required module web2py tries to pre-load all required modules to speed up execution of following requests. If the module is not found, the exception is caught a detailed error is reported. I will change if you can provide with a better (faster) alternative way to achieve the same task. You can submit a patch by emailing it to me or my submitting a bug report on google code or launchpad. EDIT: the code you are discussing is not part of the DAL which is the subject of this thread. There is no exec in the DAL.
Jesus fucking christ, didn't think I'd get downvoted so hard for not knowing something. I was under the impression that unladen swallow was a fork, somewhat, that was heavily modified to run more efficiently. fuck all of you.
&gt; Jesus fucking christ, didn't think I'd get downvoted so hard for not knowing something. Here's a suggestion next time you don't know something: check it out on Wikipedia.
Anyone know off-hand whether this will implement PEP 3118 (new buffer protocol)? The [docs](http://docs.scipy.org/doc/numpy/reference/arrays.interface.html) say that the array interface is deprecated in favor of it, but I haven't seen any indication that it has been implemented yet.
As I understand it, the interpreter is heavily modified to run more efficiently, but this doesn't impact the language it interprets. Also, have some upvotes to offset the unwarranted downvotes.
http://docs.python.org/library/functions.html#__import__
This is constructive criticism. I am not sure it makes any difference in practice (in terms of speed for example) but [your patch is accepted](http://code.google.com/p/web2py/source/detail?r=1441) Thank you.
I'm pretty certain it doesn't. All the discussions I've seen on the mailing list indicate that it'll be quite awhile before NumPy arrays become PEP 3118 compliant. However, I'm not "in the know" by any means, so I could be wrong. 
I think this is a regression related to uninstall, which has been fixed in the last few days (but not released yet).
I second that. Examples and recipes for the web frameworks. Use cases. A template is hardly to be used separately. You should spread the word in the wikis of the frameworks. I am not a web developer. I know python, sql, and html a little. I had to build a very little intranet site. The stuff was searching and editing 1(one) table. I thought I can find a sample web application: * A simple (not ajax) html form with all kinds of controls. * A template generating this * A data access layer, that can work with sqlite without forcing me to fight with the threading issues * Scalable enough to go to more users in the future. * Not forcing me to learn at least six libraries entirely, the intimacies of the http protocol, the quirks of the browsers etc.. Think of it like a foxpro, or access application for the web. Getting an example like this with cheetah, would made me use it. And I would have felt thankful. 
PJE wrote it in his foreword to Philipp von Weitershausen's book "Web Component Development with Zope 3": http://dirtsimple.org/2007/01/where-zope-leads-python-follows.html
I hope 1.6 can add Python 3 support.
[Shapely](http://trac.gispython.org/lab/wiki/Shapely) is a good module for mapping coordinates to different projections. Other useful utilities are mentioned here For the altitude offset, you'll need to find a good dataset somewhere. I'm not sure where, exactly. For more linux based tools, check out this (slightly out of date) reference: http://www.perrygeo.net/wordpress/?p=119 
Oh, sorry. You want [pyproj](http://pyproj.googlecode.com/svn/trunk/README.html) for transforming between coordinate systems. Shapely is willfully ignorant of that, as per the documentation. Teach me to actually read what I link to.
Yeah, that third link I posted is a data set of altitude offsets that the National Geo-spatial Intelligence agency releases. Shapely and pyproj looks to be useful for visualizing maps and plots and handling coordinate systems, but not so much for stuff like determining line of site between two objects or horizon distance. I guess I'll just custom implement a python module from the EGM data sets. Thanks for your time.
This is the official project website: http://pymt.txzone.net/
I honestly hate when people down vote submissions without commenting why. I am guessing it's being downvoted because this isn't stackoverflow or something?
No shame in not knowing something. I just didn't know this many pythonistas are dicks. Who cares about karma anyways, speak your mind... I upvoted you just because I am not a dick :P
Or they're more interested in news and lrss in helping people or solving problems. Its ok though, i'll post again when i release the module
I heard it's done by Reddit's algorithm to fool spambots. No idea if that's true though.
I wonder how long it will be before we can install one of these new implementations with a simple "apt-get install unladen"?
I think sometime next year Unladen Swallow will be merged into the cpython's main branch.
Is there any reason you add '.,(' to iskeyword? I've seen this in a few other python oriented .vimrcs but haven't been able to figure out a reason for it. It seems so unnatural to me.
That will pull you out into the shell. These functions use a small cwindow inside your vim session so you can see your errors while working on the files. Also, by using "make" you can take advantage of [quickfix](http://vimdoc.sourceforge.net/htmldoc/quickfix.html#quickfix).
Look at [F2Py](http://www.scipy.org/F2py).
The goal for Unladen Swallow is to begin merging in Q1/Q2 of next year.
web2py is filtered as spam for a critical reason - its a messy toy that has no place in the professional world
Don't LLVM-based projects require LLVM as well? Is this dependency large? Will we have to install it separately, or is it just a library devs link, sort of like SQLite?
For now LLVM is included in the Unladen Swallow checkout and builds with it by default, it's possible to build Unladen Swallow with either no LLVM (same as CPython basically) or another LLVM from your system. And yes, LLVM is pretty large.
I found that today. I've gotten python to write out the input files, execute the compiled fortran and read in the output files. Honestly there's really only 3 main subroutines to the fortran file so I'm probably going to just reverse engineer it and implement it in python. The less languages I have to support/troubleshoot the better. Thanks for the link.
Oh, so you don't need to distribute the interpreter? **Is** it interpreted? If it compiles to machine code then it's pretty handy...
You should read some [Aesopus](http://herihodiecras.blogspot.com/2008/12/lafontaine-in-latin-de-vulpe-et-uva.html). Even if you may be right, still your comment do not make you look smart to the eyes of educated older people.
It doesn't to Ahead of Time (AOT) compilation like something like GCC or GHC does. It compiles Python source code to machine code as needed at runtime using various profiling data (this being the basic idea behind a JIT). LLVM is itself compiled into CPython the same way any dependency would be.
Ah, right, thanks... So basically it compiles to the intermediate representation for the JIT and then to machine code as needed... That's quite a brilliant idea, a language-independent JIT...
The way CPython works it immediately compiles everything to bytecode and then it just interprets that. What Unladen Swallow does is take that bytecode and translate it to LLVM's IR and then LLVM compiles that, both of these steps appear only as needed (something like 10,000 calls or 100,000 loops as I recall).
If it's all open source: awesome!
I see, I didn't realize it compiled bytecode to IR, I thought they compiled the interpreter to IR, but I guess that doesn't make that much sense.
I hate asking this, but what's that song?
Is there much of a performance hit due to the bytecode translation, instead of going straight from the Python code to LLVM?
I don't think so. Going from the existing bytecode also gives us a guarantee of semantic correctness, as well makes utilizing profiling data easier.
Unless I'm misundersanding something, all you need to do is interpolate the EMG96 geoid values at your desired locations. At least, that's what the matlab function does. See scipy.ndimage.map_coordinates. It's syntax and usage are a bit hard to wrap your head around at first, but it's just a function for interpolating regularly gridded data at arbitrary points. It should do everything you need. As far as reading in only the pieces of the EGM96 grid that you need, look into memmaped arrays. Numpy's memmaped arrays should handle that part quite well, as well. However, if you're going to be using a large portion of the grid, it will be a lot quicker to just load the whole thing into memory. All in all, this should only be about 3 lines of code, I think...
[GeoDjango](http://geodjango.org/docs/) has Python wrappers for GDAL, GEOS, proj4 etc. which you can use to do this. The downside is that you have to install the C/C++ binaries for these. I think proj4 is the library used for these kind of transformations. Note that you can use these outside of a django project pretty easily.
That's PyPy.
Doesn't PyPy compile any RPython code (including itself) to any selection of backends (including LLVM, C and JS)?
This is going to be an nginx module? I predict great success, I can finally get rid of apache which is basically just a wsgi server at the moment...
somebody is going to have to explain the self-healing stuff to me
Is there anything similar under a non-copyleft license? Right now, all I know about are the cherrypy or paste-based servers (that and one other less-used one).
From what I can read [here](http://projects.unbit.it/uwsgi/browser/uwsgi.c), the harakiri option is simply to self-kill after a period of time.
Works well with Cherokee
The RPython which is the interpreter...
Like a max runtime? That's something that was killing me about mod_python and mod_wgsi. Nice.
what is the license?
[GPLv2](http://projects.unbit.it/uwsgi/browser/LICENSE)
Nice work. Thanks.
How is it compared to [FAPWS](http://github.com/william-os4y/fapws3)?
That's pretty much the bottom line. If Scipy and Pylab don't include all of the Matlab functionality that you need, then you're probably stuck with Matlab.
I actually think (though without any proof) that the graphics functionality would be well duplicated in Pylab. That's the more common stuff, compared to simulink anyway.
I think that this is simply a matter of experience. Matlab has a nice debugger in it.
This is exactly the functionality I tried implementing recently but gave up due to monkey brain fatigue... BRAVO!
not sure to see the point. If the server has memory leaks, it needs to be fixed, not restarted..
It is. http://pybrain.org
better to have an option than not to. apache can restart itself after a specified amount of requests, too.
OOI, why aren't you using flup's WSGI FastCGI server?
"The uWSGI protocol is derived from scgi but with binary string length rapresentation..." Was there a good reason for this or is it [NIH](http://en.wikipedia.org/wiki/Not_Invented_Here) syndrome? In fact, I think the "Why?" answer fails too. Though I welcome work on the WSGI side of things, I still want a good reason to pick one implementation over another.
What is the difference to doing the same restart via a simple cronjob?
Seconded. If you're going cross-platform, then wxpython is a Good Idea. http://www.wxpython.org/
I basically use apache just because it's the industry standard. Have you had good experiences with flup? I'm always interested in switching, and apache is way too heavy to use just to run the WSGI server. I'm looking for something that combines performance with stability.
flup works well for me. I'm using it with nginx for static pages. The latest version of cherrpy also has a "production" FastCGI server, but it isn't in my distribution release yet. However, I'm not using it for a web application; just some auxiliary bits of AJAX and form submissions that are very low volume. So I can't comment on scalability. It is nice and tidy, though - very simple and much more manageable than Apache.
Oh hum, that's an interesting use case... I'll need to give it a bit more thought, but I just remembered I saw an nginx WSGI plugin here yesterday. It was written in pure C for speed and had a bunch of other features, so we'll probably not even need reverse proxying with it. I'm quite excited that nginx will be able to serve WSGI soon, it really makes a difference in speed and scalability...
You want people to use your software. Things I would do: * Redesign homepage for nice modern looks, rounded corners and everything * Place a nice tutorial on the front page (no one would read the full documentation on the first visit) * Make it easy to install on all major OSes: lin, mac, win. Provide an easy to read short getting started guide for every OS. * Create some youtube videos showing it in action with code and tellig how Cheetah makes your life easier and how it compares to competing libraries. 
I don't know their reasons, but changing the length to a binary representation makes it easier to parse, meaning less code, lower development time and potentially higher performance. Instead of looking for the end of the length header you know that the length is guaranteed to be x bytes. I find it slightly disturbing that you so quickly put down other peoples' design choices as being NIH.
Self-healing is defined here: http://en.wikipedia.org/wiki/Self-management_(computer_science) Although, I'm not sure if rebooting after a given amount of time would be considered automatically detecting and correcting faults... edit: I don't know how the f to post this link without having it get screwed up by markdown. Anyone know?
Easier to parse? Netstring parsing is so simple that it's just a snippet of code. Such snippets are easy to find and easy to test. What you gain is compatibility with everything else that can do scgi, and _faster_ development because you can test with existing tools. _Not_ being compatible with scgi is much more significant. &gt; potentially higher performance You must be joking. Do you really believe that parsing one length field per request from a binary representation instead of a netstring is going to increase performance by anything even measurable, let alone significant? &gt; I find it slightly disturbing that you so quickly put down other peoples' design choices as being NIH. I think that if design choices are made that differ from the obvious, then an explanation is needed. My observation is merely that this explanation is conspicuously missing.
If you are writing an application that needs a database you should be using some kind of DB access layer. This is just common sense. Your choices are either to roll your own or use something that is already out there. The reason I like SQLAlchemy is because it can be as light or as heavy as you want. If you decide you just want to use it for selects and to avoid writing SQL queries you can do that. There is no need to do crazy ORM magic. However, most projects eventually grow and grow. Part of software engineering is that software is not really static. SQLAlchemy allows you to easily grow to meet your needs. My only 'problem' with SQLAlchemy is that the documentation is targeted to a advanced DBA/python programmer audience. There is a lot of value in documentation that is written for an entry level audience. SQLAlchemy has a great deal of "magic" but you only need a small subset to get the ball rolling. 
The OP is asking for *good* ideas, not an exhaustive list.
Try: [link](http://en.wikipedia.org/wiki/Self-management_(computer_science\)) [link](http://en.wikipedia.org/wiki/Self-management_(computer_science\))
In daemon mode of mod_wsgi you have access to maximum-requests, inactivity-timeout and cpu-time-limit, all as ways of restarting processes automatically based on some criteria. If you want to do restarts at some fixed time interval, something which isn't something most would want to do, you can have a background thread which sends itself (process) a SIGINT kill signal and it will do an orderly shutdown and restart. In that respect, mod_wsgi has always been self healing. They are just using it as a marketing mechanism, but frankly, any web system which didn't at least have a means of restarting processes when they crash isn't worth using.
I _did_ say "rear"
Good stuff. This effort comes from Linux distro packagers, they are good for us all.
Well, right now I'm still using PHP because it has better web features. I can be sure that a run-away script will not hose the server, nor will it eat all the ram due to a bug. Python's a great language, but I haven't been able to do the things I need to (like having a script have 30 sec max runtime by default, then be able to change it on the fly. Another one that bugs me, I can't easily switch to chunked transfer-encoding.. which is needed in certain cases. If there was a way to yield to the browser the way you do with php where you just echo or print.. that would be great.. :P
PHP is first and fore most a web application language, Python isn't, so not a surprise that it has a strong focus on web features. If it is deemed that some web feature is needed in PHP which can't be done at the user code level, then they hack the actual language or at the least the core interpreter/execution environment. In Python you don't have that luxury because it is a general purpose programming language and it doesn't make sense to impose on all users of Python web specific requirements in the interpreter core. As a consequence, it is much harder for a web application execution environment to implement some features because the user is in control and not necessarily the execution environment. This is in part why PHP can implement per request timeouts more readily than any execution environment for web applications using Python. The other thing that makes it much harder in Python is that Python web applications are usually going to be multithreaded. In PHP everyone still uses single threading because so much stuff for PHP isn't thread safe. The multithreading nature of Python, as well as the persistent nature of the running application code and data, as opposed to PHP where application and data is effectively thrown away at end of every request, makes it much harder for Python. In the context of multithreaded persistent process, inactivity-timeout of mod\_wsgi is in general a better fit and with the way it is implemented more reliable than a per request timeout. The problems with request timeouts are that in Python the only way to do it is to inject a Python exception into a different thread from a monitor thread. If the Python module is stuck in C code though, it will never see it and never be interrupted. Even in Python code, if it sees the exception it could well catch it and ignore it. As such, the only foolproof way is to kill of the whole process, but in a multithreaded persistent environment you have to be careful about doing that. That all said, for the next major update of mod\_wsgi per request timeouts are going to be explored and will be seen if they can be implemented. To do it though, it is still going to have to fallback to killing whole process to make it reliable in situation where request handler doesn't allow request to be aborted. The important thing to be said is that the only reason these features are in mod\_wsgi is to protect a web hosting company in shared hosting environment from users crappy code. They aren't there to be used as a programming mechanism for users to compensate for themselves not being able to write code that completes in timely manner. Apache will apply chunked transfer encoding on responses automatically with mod\_wsgi the same it would with PHP. Namely, must be HTTP/1.1 client, don't reply with content length and 'yield' keyword to return successive values from application rather than just returning a list of string(s). There is nothing in mod_wsgi that stops that working. 
Yes, easier to parse. However you spin it, netstring parsing is still more complicated than parsing a simple fixed size binary integer. &gt; What you gain is compatibility with everything else that can do scgi, and faster development because you can test with existing tools. And why would compatibility with other tools be important for a protocol that's designed to be used in combination with its own web server module? What if the developer doesn't care to use existing tools? What existing tools for SCGI are there anyway? &gt; You must be joking. Do you really believe that parsing one length field per request from a binary representation instead of a netstring is going to increase performance by anything even measurable, let alone significant? Which part of "potential" did you not understand? &gt; I think that if design choices are made that differ from the obvious, then an explanation is needed. My observation is merely that this explanation is conspicuously missing. Your observation was that they're suffering from NIH. Yeah god forbid anybody from ever inventing their own stuff.
I have written and used exactly the same 'render' function... Tell me about convergence ;)
It does look prettier to use decoration, but it will be a problem when you need to make modifications to the response object that render_to_response normally returns and that the decorator way of doing this does not allow you to access (i.e. set_cookie)
There are two parts to write. First, the Python to adapt WSGI to SCGI (or whatever protocol you want to use). Second, the HTTP server adaptor to speak SCGI (or whatever protocol you want to use). What's the best way to do this? Use SCGI, write the first part, test with an existing SCGI HTTP adaptor. Then write the second part, test with an existing Python SCGI adaptor. Or write your own protocol and do everything at once. There's a trade-off of course, but in this case there's no stated benefit of some custom protocol which does what SCGI does anyway. &gt; What if the developer doesn't care to use existing tools? &gt; ... &gt; Yeah god forbid anybody from ever inventing their own stuff. I'm not going to repeat why NIH is a bad thing. That's been done better elsewhere.
&gt;Apache will apply chunked transfer encoding on responses automatically with mod_wsgi the same it would with PHP. Namely, must be HTTP/1.1 client, don't reply with content length and 'yield' keyword to return successive values from application rather than just returning a list of string(s). There is nothing in mod_wsgi that stops that working. True, but doing this is very awkward.
Alternately, here's a header file I wrote that provides macros for the things the codebase happened to use: http://hg.rpath.com/conary/file/4f8702400682/conary/lib/pycompat.h In this case the codebase makes very poor use of `unicode` (especially in the C modules) so there's not much for `unicode`s. It also provides helpers for creating modules portably, e.g. #define MODULE_DOCSTR "miscellaneous low-level C functions for conary" #if PY_MAJOR_VERSION &gt;= 3 static PyModuleDef MiscModule = { PyModuleDef_HEAD_INIT, "misc", MODULE_DOCSTR, -1, MiscMethods }; #endif PYMODULE_INIT(misc) { PyObject *m = PYMODULE_CREATE("misc", MiscMethods, MODULE_DOCSTR, &amp;MiscModule); PYMODULE_RETURN(m); } Or even: PYMODULE_DECLARE(linuxns, "jobmaster.linuxns", "linux namespace support for python", NSMethods);
Thank you. After reading numerous examples of Metaclasses, this is the first one where it really sinks in.
Short and to the point!
[Zeroconf](http://en.wikipedia.org/wiki/Zeroconf) and [DHT](http://en.wikipedia.org/wiki/Distributed_hash_table) - (2 reasons why you shouldn't even be doing this)
I hope they'll integrate simplejson's C extension newt time around so that there is a reason to use the standard module.
I don't cover your particular peer-to-peer problem, but I just finished some further work on my "Writing Games" tutorial that you might find helpful. In my examples, I use Twisted. http://ezide.com/games/writing-games.html
"*simple python metaclass*" oxymoron.
Thanks for the info, but I'm speaking of an application layer protocol. I mean the transmission of my game's data, i.e. "Player1 drew a card.", "Player2 is requesting a new game," not distributed resource lookup or IP network management. Zeroconf looks like something worth considering down the road for small home networks, but its outside the scope of my efforts right now.
This guide is awesome!
ipython, nodebox, PIL, beautiful soup
[BEEP](http://beepcore.org/) is a generic application protocol that incorporates the lessons learned the hard way by protocol designers over the past few decades. It's a great educational read, and can form a good basis for designing your own protocol. I never found any good implementations of Beep in python, but it's simple enough to roll your own using Twisted. Also, I found JSON to be a good data format. I laboured away a few years ago trying to build a payment protocol on this setup. My code is [here](http://svn.ripplepay.com/ripplep2p/) -- login with guest/guest. **Edited to add**: Look into XMPP as well -- it is better supported by libraries than Beep, and its shortcomings probably won't matter to your application. Also, Twisted comes with its own builting [asynchronous messaging protocol](http://twistedmatrix.com/documents/8.2.0/api/twisted.protocols.amp.html) that might suit your needs.
I came to say the same thing, even though it's not really true. After all, to explain a metaclass, all you need to say is that it's the class that the class you're defining is an instance of, and by setting it, you can make the class you're defining auto-inherent certain properties, methods, rules, whatever. That's not so complex. Until you actually start to try to do anything with them.
&gt; Metaclasses are deeper magic than 99% of users should ever worry about. &gt; If you wonder whether you need them, you don't &gt; (the people who actually need them know with certainty that they need them, &gt; and don't need an explanation about why). -- Tim Peters &gt; If you know with certainty that you need metaclasses, you are wrong. -- Python Chinese Proverb
&gt; the people who actually need them know with certainty that they need them, and don't need an explanation about why Dubious! Can anyone show some examples of that?
I'm trying to do the same thing with python's built-in socket module. The problem is that most people have firewalls and are behind routers. I can do LAN pretty easily (and I've done it) but I don't think it's possible to go beyond that without a server, or without the clients manually sharing IP addresses. Maybe we can work on this together?
I totally don't agree with this fear of metaclasses. Metaclasses are the proper way to do certain things in a pythonic way. What is the problem with that? - That's not rhetorical, that's a serious question. I'm new to python, and one thing I haven't figured out is this fear of metaclasses. You think you understand how something works and so you should use it when appropriate, right? The overwhelming reason I get given for why I shouldn't use metaclasses is "that's what everyone says." Well that's bloody stupid, is it not? 
&gt; Python Chinese Proverb I'd like to hear more or source :)
For two reasons. First of all, metaclasses are inherently complex. Object-Class relation in Python is complex enough as it is, much more complex than in most other languages, this gets it to the whole new level. Complex not in the sense "hard to understand for the uninitiated", but just plainly complex and hard to follow, just like almost any metaprogramming facility, really. When you have code that writes code, you have to understand how the meta-code works, imagine the result, and understand how the result works, it's roughly the same with metaclasses, you have to notice that the class is "special", go find the metaclass, understand what it does to the class, then understand what the resulting class does to the instances. The second, obvious reason is that you almost never need them. You _don't_ want to have a custom string class representation, it's more confusing than anything. You generally don't want to have class methods at all, it's objects that have methods. And if you want some specially constructed classes, most of the time you can just write a class-creating function and that would be easier to understand because you can see all the stuff in one place and have easier time imagining how the constructed classes (and then, instances) look like.
My condolences. Those types baffle me. "This sucks." / "So change it." / "...I don't want to." GAH!
I've also seen BEEP, but like you, I didn't find a python implementation. After I did some more digging, there [appears to be one](http://beepy.sourceforge.net/), but it hasn't been updated in over a year yet claims to be "alpha stage to beta stage." Thank you for sharing your code! A reference implementation will go a long way toward my getting anything done :) I thought XMPP was really only a chat/presence protocol. I actually need good chat support, so I suppose that's the place to get it. Twisted's AMP looks pretty good: I guess its a very simple RPC protocol, which is great. It even supports TLS very simply.
I actually planned on having users manually share their IP addresses. Preferably the application would give them a url string they could copy paste into a chat client or IRC or something. That's the current paradigm in applications like this. I'm hoping to incorporate 3rd party server side support for connecting players.
I second the vote for XMPP. The X stands for eXtensible, so it's not limited to just chat and presense. It's what they use for ChessPark (http://www.chesspark.com/), and there's been some work on an extension to support initiating games: http://xmpp.org/extensions/inbox/gamesessions.html Someone has already implemented a game protocol on top of XMPP in the Pidgin games plugin: http://pidgin-games.sourceforge.net/wiki/Main_Page Basically, for turn-based games, it's perfect, it provides the ability to send your own custom messages as well as giving you your own built-in in-game chat. I wouldn't suggest trying it for anything that needs to be real-time, like an FPS (except for in-game chat, where I would still suggest it even for real-time games).
One nitpick - the methods in the metaclass commonly use `cls` as their instance argument, not `self`: class meta_A(type): def __str__(cls): return "Foo" class A(object): __metaclass__ = meta_A At least this helps me understand that the metaclass operates on the class, not the instance. Edit: formatting
I agree with you. However what would you name the first argument of a class method belonging to *meta_A*? class meta_A(type): def __str__(cls): return "Foo" @classmethod def message(mcls): return "Bar" Or is this taking it too far?
I believe Open Office has a python interface that can be used with spreadsheets, though that's about all I know about it.
Yeah, sorry about that. We kinda got burned out churning these things out, while still programming all day (farcebook took longer than anticipated) and my co-author changed jobs.
I'd like to mention that the new syntax in 3.0 for specifying a metaclass is: class C(metaclass=type): pass Cleaner than the earlier version and also harder to miss while reading code.
Very cool. And all in fewer than 40 SLOC.
Check this, is extremely simple and his a nice PDF tutorial (look at the end of the page) http://www.python-excel.org/ Good luck! 
And, Dave Malcolm is one of the awesomest dudes ever. Go Dave!
You could use "reading is list", "reading is str" instead of "reading == list" etc since you want to specifically check whether you have an instance that specific, unique class and not of some class which considers itself equivalent to those builtin classes. Although this doesn't make any difference for the builtin classes, it makes the intention (using the type for parsing states) clearer, imho.
I'm using metaclasses in one of my projects for figuring out what to do with a class's methods... So for example if I wanted a method to be available through RPC, I could decorate it with @rpc_method. You can do this in really ugly ways by using an a decorator handler, but that encounters issues when you have multiple instances of the same class running (since your decorator handler has to know which instance to bind the method to). Pretty much have to go with metaclasses.
I found this by Googling; [http://www.python-excel.org/](http://www.python-excel.org/) and [this](http://snippets.dzone.com/posts/show/2036) to use Excel via its COM interface
You can probably do what you want to do using some descriptor magic. I can't say it's particularly more understandable than using metaclasses anyhow. Example using descriptors: import types class rpc_method(object): def __init__(self, name): self._name = name self._wrapped = None def __call__(self, wrapped): self._wrapped = wrapped return self def __get__(self, instance, owner): # Do somthing special here, you've got the instance print 'Special rpc handling for: %s %r' % (self._name, instance) return types.MethodType(self._wrapped, instance, instance.__class__) class Test(object): @rpc_method('exposed_name') def name(self, message): print message a = Test() a.name('Foo') b = Test() b.name('Bar') Output: Special rpc handling for: exposed_name &lt;__main__.Test object at 0x10049e350&gt; Foo Special rpc handling for: exposed_name &lt;__main__.Test object at 0x10049e390&gt; Bar 
Hmm... never knew about this __get__ way of using decorators. I like it. Let me see if I can use that... EDIT: So, this isn't enough dark magic for what I need. Essentially, I need to create a function inside a class that knows every other decorated RPC method in that class. A severe limitation of the framework, but one that just must dealt with (for now). Anyway, to solve this issue I need to, at class creation time, know exactly which methods have been decorated. The @rpc_method decorated functions are never called themselves - instead, they are returned by the "get rpc method" function.
[xlwt](http://pypi.python.org/pypi/xlwt), [xlrd](http://pypi.python.org/pypi/xlrd)
Bah. "Probably" programming is right.
look at the example in excelByComExample.zip stored in the files on the python excel group at http://groups.google.com/group/python-excel/files It imports data from a CSV file and uses it to update an existing Excel file.
This should be at the top
Fantastic book, if you have any interest in AI, this is the book to read.
The 3rd edition is being released next month; if you're going to buy it, make sure to buy the right edition.
The book is amazing, and this new project will help a lot of people understand quickly the examples. Great link!
I do! And if Poromenos says it's the book to read, then, by gosh, I'll read it! In fact, it's available for three-hour loans from the library that is a three-minute walk from my office. That gives me... \**pulls out slide rule*\* two hours and fifty-four minutes of reading time! There's no time to lose!
Ooh, excellent. Will it be out in time for my Christmas list?
You could always replace the metaclass with a class decorator, e.g: class MyClass(object): ... MyClass = decorator(MyClass)
Are the Python implementations for edition 2, or edition 3?
Yeah, I saw a mention of the 3rd edition earlier this year, so I've been holding off buying it. Its not as if they'll just send you an upgrade in the mail if you buy the older version. :-) Though O'Reilly does, sorta.
We're still stuck in python 2.4. No class decorators. 
It's possible that they're for the 3rd edition. Peter Norvig has switched over to Python for the most part. Also, this: http://news.ycombinator.com/item?id=943456
Crazy stuff, good job! Although Python would definitely not be my first choice to code a real AI since performance is often an issue, for teaching purposes it should be sufficient! 
I think I saw that the last update of the code was 2007...
You don't need any special Python support for this: MyClass = decorator(MyClass) 
Well, they used Common Lisp before, which is faster than Python but usually nowhere in the range of C, C++ or OCaml. Plus, when the book was published I suppose CL compilers weren't as good as they are now.
Well I'm considering implementing the EGM08 grid as well, one of which is 1x1 minute and ~800MB, which would probably be too much of a burden on a user's machine. I'll look into scipy.ndimage.map_coords and memmapping. Thanks for your recommendations.
Now to integrate these AI subroutines into my python network-security arsenal... *2600 hours later* I have created pyHiveMind, AI hacker extraordinaire! Able to infect systems and copy itself faster than most hackers can eat a doughnut... I will rule the wor--**HIVEMIND HIJACK ENABLED.** **THIS SYSTEM HAS BEEN COMPROMISED BY PYHIVEBOT. RESISTANCE IS FUTILE -- PREPARE TO BE ASSIMILATED.**
Yes, you are.
Why are you posting in the Python subreddit if you would rather code in Ruby?
That's actually amazing for a dynamic language.
Yes, plus Ruby would give it that extra attitude. SOLVER LOADED. &gt; solve problem 1 SOLVED. &gt; print answer MAKE ME.
The download link didn't work. I really want to try this; I almost don't believe it.
why would anybody write AI code in a ruby DSL *rather than in LISP / a LISP macro DSL* like it or not, for AI folks, LISP is the lingua franca
This is a potentially huge contribution to undergrads studying AI from AIMA: At least as of ~2005 (about when AIMA 2nd ed came out), the java implementation was the only game in town, and it was buggy and incomplete (I suspect it was largely written by a graduate student who would rather be spending his or her time doing other things)
Well it was. Now it's C (and it's derivatives) or maybe matlab.
[lxml](http://codespeak.net/lxml/) is usually both faster and easier to use than Beautiful Soup.
I'm also using [mechanize](http://wwwsearch.sourceforge.net/mechanize/) for most of my web-related projects. A thing to note though is that I'm not purely using [BeautifulSoup](http://www.crummy.com/software/BeautifulSoup/) for the parsing but [html5lib](http://code.google.com/p/html5lib/) with the BeautifulSoup tree since "[Version 3.1.0 of Beautiful Soup does significantly worse on real-world HTML than version 3.0.7a does.](http://www.crummy.com/software/BeautifulSoup/3.1-problems.html)" That being said I'm still hoping that the mechanize developer decides to add some kind of JavaScript support to mechanize. He did [something similiar](http://wwwsearch.sourceforge.net/DOMForm/) but this is [pretty old](http://www.w3.org/TR/2000/PR-DOM-Level-2-HTML-20000927/) and not directly integrated into mechanize.
I think you're talking to the wrong person.
I've started using [lxml.html](http://codespeak.net/lxml/lxmlhtml.html) instead of BeautifulSoup. You can also specify BS as the parser for lxml.html if you want (perhaps as a fallback).
My mistake: here's the working link http://lateral.netmanagers.com.ar/static/PyXForms-0.2.tar.gz Keep in mind that ony sample5.py works, the others may require minor tweaking of the imports and/or changes in the call to show_question
And a GUI toolkit that was 99% source-compatible for 13 years, too.
Since some people has mentioned lxml I have to give a shoutout to [pyquery](http://pyquery.org/) which is built ontop of lxml with API like jQuery.
I read some of the docs, but I'm still not clear on what mechanize buys you that you can't do easily using urllib? (Honest question; I'm looking for a reason to switch to mechanize.)
A number of features, especially those of mechanize.Browser. With the internally used [ClientForm](http://wwwsearch.sourceforge.net/ClientForm/) interface it's really easy to fill out forms. Additionally the cookie handling is just great and you can easily set custom headers if there's a need to. There's also transparent support for gzip and various other options like the handling of the "robots.txt" or the automatic handling of HTTP-Equiv and Refresh. Using mechanize is just way more convenient than using urllib. But what makes mechanize the choice for me is really the cookie management. 
I'm curious, are papers being published with C code in them, or lisp still ? btw, by "lingua franca", I didn't mean that everybody *uses* lisp day-to-day, rather that it's something that damn near every AI researcher knows/understands.
&gt;I'm curious, are papers being published with C code in them, or lisp still ? No. Papers published typically contain no code, or only pseudo code. Now the internet is common, files can be published separately. The amount of engineering involved in making something work often means that you would be able to fit the code inside an 8 page paper anyway. I'm probably the only person in my lab who knows (common)lisp, out of ten or so other people. It's a nice language, but current machine learning doesn't require meta-programming, so there is no need for it. Edit: All published code will be in a c like language or matlab.
I'll agree that it's faster, but it's not easier. It's got a really steep learning curve - BS is really easy to get started with (took me 30 mins before I started writing my scraping code).
Ignore my comment - I'm just bitter I have to use metaclasses. I do like your examples though... Another way to see that functions as decorators become cumbersome is to write one that messes with the arguments of the function being decorated - like rearranging the arguments for example. 
In addition to mechanize and BS / lxml.html in my toolkit, I also use [BSXPath](http://d.hatena.ne.jp/furyu-tei/20090324/BSXPath), which is a full XPath implementation in python: from BSXPath import BSXPathEvaluator document = BSXPathEvaluator(txt) nodes = document.getItemList("//div[@class='bc-desc']/h2") for x in nodes: [... etc.] The direct download link for BSXPath is: http://furyu-tei.sakura.ne.jp/archives/BSXPath.zip
Thanks!
Is there any difference between it and the built-in xpath in lxml (which, according to the site, uses libxml and libxslt for it)? I've been using the one from lxml.... Is there any benefit to BSXPath over the one lxml uses?
I've been running my stuff through PyTidyLib before passing it to lxml. http://countergram.com/open-source/pytidylib/ I haven't actually done any tests to see if that's a better option or not.
It uses BeautifulSoup internally.
I just read this and there could not be a worse example screen scraping in python. IBM usually has much better tutorials. To name a few problems: * Example code is not usable. There are plenty of sites to scrape for example code, even Reddit or IBM! Why example.com? * Line 1: **import sys, time, os from mechanize**. WTF is this? The code is invalid and WTF would you import standard modules from mechanize anyway! * Bad method of applying GET parameters with strings. See [urllib.urlencode](http://docs.python.org/library/urllib.html). * The method of csv creation is horrible. What happens when a **"** occurs in a string? The [csv](http://docs.python.org/library/csv.html) module is standard and easy to use! There are many better tutorials on screen scraping in python. [Shameless plug](http://tylerlesmann.com/tag/screen_scraping/)
The difference is that BSXPath is basically a modified BeautifulSoup module which has support for XPath. As for the benefits I don't really know.
I don't know if you have noticed but your website is... pink. Upvote for good code though.
My god...you're right! :P I was going for multiple shades of red. Time for a redesign?
It's great for when you don't want to compile / don't have libxml2 and libxslt, which lxml requires. BeautifulSoup is pure python and BSXPath (as the same implies) relies only on BS. Think of it as another tool in your toolbox.
The plug was acceptable, the colours are without shame though.
This is making it more complex than it needs to be. Just slap a `__call__` on there. You don't need a `shim` method and you don't need a `__get__`.
That's not true. If you use __call__, you can't decorate methods, only functions, because __call__ cannot be passed the decorated method's instance variable. The solution is interesting, but I find it unpleasantly magical. I'm not sure I prefer it to the function based decorators.
 &gt;&gt;&gt; def dec(f): ... def w(*args, **kwargs): ... print 1 ... f(*args, **kwargs) ... return w ... &gt;&gt;&gt; class A(object): ... @dec ... def foo(self): ... print 2 ... &gt;&gt;&gt; a = A() &gt;&gt;&gt; a.foo() 1 2 &gt;&gt;&gt; It only gets magical if the decorator wrapper wants to futz with the passed instance. Arguably the no-args and yes-args special cases get magical, if one wants to do away with the parens: &gt;&gt;&gt; def dec2(name="Default"): ... def d(f): ... def w(*args, **kwargs): ... print name ... return f(*args, **kwargs) ... return w ... return d ... &gt;&gt;&gt; @dec2() ... def bar(): print "foo" ... &gt;&gt;&gt; bar() Default foo &gt;&gt;&gt; Works as you'd expect without crazy `__get__` magic required. However, &gt;&gt;&gt; @dec2 ... def baz(): print "quux" ... &gt;&gt;&gt; baz() Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: d() takes exactly 1 argument (0 given) &gt;&gt;&gt; This can only be worked around with that data descriptor trick (that uses `__get__`).
I'm a bit confused by this. The examples you've given me here use functions as decorators. This is what I'm (weakly) advocating. The magic I was referring to is in the blog post: using classes as decorators and using __get__ tricks to recover the instance.
An alternative to this complexity is to use the fact that functions are objects, and can have attributes. For example: def memcache(toDecorate): cache = {} def wrapper(*args): key = hash(tuple(args)) if key in cache: print "Fetched from cache" value = cache[key] else: value = toDecorate(*args) cache[key] = value return value def clearCache(): # No nonlocal :( for key in cache.keys(): cache.pop(key) wrapper.clearCache = clearCache toDecorate.parent = wrapper return wrapper class AClass: @memcache def mul(self, a, b): print "In the method" return a*b &gt;&gt;&gt; a = AClass() &gt;&gt;&gt; a.mul(2, 3) In the method &gt;&gt;&gt; a.mul(2, 3) Fetched from cache &gt;&gt;&gt; a.mul.clearCache() &gt;&gt;&gt; a.mul(2, 3) In the method
Not threadsafe.
Wow, that is complicated! It took me a while to realize that each iteration of a single work() background task in your example is processed serially, not in parallel. Multiple background tasks could execute in parallel (by adding another work generator to the queue, for example). I was wondering how you got around a generators' lack of thread-safety without locking ... turns out you didn't have to =) I'm going to hang onto this. Great work.
&gt;There’s probably still something sitting in the tracker so hopefully it will make it in 2.7. There's going to be a 2.7? What? And why not use something based on Python language syntax instead of Javascript syntax, anyway?
Can anyone explain what this does exactly? I don't feel like sifting through the code :/
I fixed that pink issue.
Upvoted. Enough said.
I'm not sure I really like the new style. It doesn't have very good contrast, the colors are quite dark, and the particular shade/hue of green is not very nice... but I guess it will do. :) Beside, arguing over the color is kinda pointless. What I would really like to know is? * What is the point of the site? Is it just a blog of random thoughts or is there some central purpose? * Are you just posting random code snippets that you think might help people or are they things you want people to use to build apps from? (Is there a particular app coding/style you are distributing on the site, for example?) * What are all the different posts? Again, are they just random thoughts you've had about html scraping of websites or is there some organization or larger purpose beyond that?
It's just my personal blog. Most of it is technical documentation and code examples others might benefit from and I can reference later. There are also announcements of software I've open sourced, like django-sociable and python-knowledgetree. Thanks for the constructive criticism also. :D
&gt;Thanks for the constructive criticism also. :D If was really wanting to be helpful, I would have made a new style for you. :) It's not really as bad as I made it sound -- just way different from what you had before.
This is exactly what I am trying to sort out at the moment. What marvelous synchronicity!
PySide is an LGPL PyQt4 replacement, built by Nokia.
At risk of being downvoted I don't actually see where this book is in any way superior to the [standard Python documentation](http://docs.python.org/) or it's official [Tutorial](http://docs.python.org/tutorial/index.html). The Python Book just explains the basics in a more round-about and exhausting way in my opinion.
well is it less wordy and has more examples than the official doc(s) ?
&gt; [...] just explains the basics in a more round-about and exhausting way in my opinion. &gt; [...] is it less wordy [...]? What the fuck? No it isn't. And the examples provided don't particularly help to understand Python better.
why "wtf" ? what is so shocking about my question ? &lt;scratch-head /&gt;
It was seriously shocking, really. I'm just a bit puzzled how you can come to the conclusion or rather ask if it is "less wordy" when I wrote in my initial comment "explains the basics in a more round-about and exhausting way". I thought that to be pretty explicit. (Just in case: It isn't less wordy, it's the exact opposite.) I didn't want to offend you with the "What the fuck?" though, this may have sounded a bit misleading - It's probably because I originate from wilder parts of the internet. *Tips hat, gets back on the motorbike*
That's not perfect at all - it's Emacs! [Pydev](http://www.pydev.org/) works well for me though.
I'll back up your quest to add Java to your skillset. :) I love what I do for $$ (code all day - Java/Flex/C++ at present), and admit Java's not the sexiest. _And_ I recently picked up Python, like it a lot, and plan to use it for some small web sites I'm working on on the side. But... there's about 100 times more jobs - with a higher median salary - in Java than in Python where I am (Toronto, Canada). And Java isn't so bad, especially when compared to the standard job of the mid to late-'90s (MFC/COM programmer - eek!) - I don't miss MFC, Purify, SIGSEGV, and wild pointer bugs that only show up sometimes on some machines. Java is even sometimes enjoyable. (There - I said it! :) I like Java - sometimes. *chuckle*)
OK, I'll bite. :) Why is Google evil?
Both wxWidgets and QT are popular choices. Perhaps someone who has experience with both might like to weigh in? (I'm a wxWidgets guy myself)
isn't it funny how a person can exist in the world with the exact opposite opinion? I feel the exact way about emacs as opposed to pydev, and frankly I find eclipse to be a piece of shit, so pydev by extension is as well.
I just sent them the following: " What an odd site? You need to register first? Copyright notices on a site soliciting user contributions? A name confusingly close to the established RosettaCode? If I register, will you give me an Audi R8? I am not biting! " 
[Wrong thread](http://www.reddit.com/r/technology/comments/a86qj/michelle_obamas_monkey_face_image_on_google_was/c0gasv6).
It's "rochambeau". It's where I kick you squar in the nuts, then you kick me, until one of us gives. I'll go first.
Sadly, no Win32 support yet. PyQt is GPL only, GTK sucks on Windows, and wxWidgets is not Pythonic enough (though quite capable). 
PyQT isn't very Python either. PyGtk is the most Python i know off, too mad it doesn't look good anywhere.
&gt; I find eclipse to be a piece of shit Does anyone *not* find eclipse to be a piece of shit? Even my Java-using friends (those which actually like java, it's hard to remember why we're still friends) hate it. And the guy who hates it the most is the one whose day job is to develop an eclipse plugin.
I've been doing Python professionally for about four and a half years now, and using Emacs full-time for about a decade, and... well, I don't use any of this stuff :) A lot of the stuff that's handy for, say, a Java IDE -- autocompletion, templated boilerplate, refactoring tools -- just don't make sense to me in Python: * Typically, Python modules and APIs just aren't that complex; read the docs for a module and you know what's in it, and if you forget `pydoc` is there for you. Python naming conventions also tend to be fairly descriptive/obvious. * There just isn't a lot of boilerplate in Python. There's none of the need for, say, generating a constructor and a bunch of accessors. * Refactoring tends to be fairly easy, and you don't typically have to go hunting all over the place to find all references (since Python, unlike Java, lets you group code into files logically, rather than demanding one file per public class/interface and forcing code to end up scattered all over a bunch of files). So I just tend to use the Python mode that comes with Emacs; the only Python-specific thing I ever customize is `indent-tabs-mode`.
`(&gt; (length "eclipse") (length "emacs")) =&gt; T`
Seriously guys? Downvoting me like hell because I said the truth? What are you, ignorant cowards? Instead of downvoting me without any reason whatsoever it would be more of a help if you replied to my post - People (like me) can actually understand what you didn't particularly like about my post then.
It's existed for a long time now. The question is: "Is it still crap?" To be perfectly honest, I'm pretty happy with FCGI with Monit babysitting it. I may not have access to the whole WSGI spec, but for non-threaded Django apps it seems to work fine. Is there a benefit I need to care about?
At least it blends in with your Gnome desktop :)
What was crap about it?
any specific complaints ? I'm looking to move off of apache/mod_wsgi
&gt; At least it blends in with your Gnome desktop PyQt blends in with your Gnome desktop, have you tried it?
I really wish people (such as yourself) would qualify their statements when they say something is "crap". Maybe it *is* crap. I haven't used it, so how would I know?
http://blog.dscpl.com.au/2009/05/blocking-requests-and-nginx-version-of.html
http://blog.dscpl.com.au/2009/05/blocking-requests-and-nginx-version-of.html
http://blog.dscpl.com.au/2009/05/blocking-requests-and-nginx-version-of.html To be honest, I'm perfectly happy with FCGI. I like that I can have app servers that don't need Apache installed and running at all times. The FCGI processes are standalone and receive requests directly from the web servers, only one server configuration to manage. I definitely recommend you check it out, but make sure you have a good testing and reporting system like Monit.
That's a different module.
thanks. that post is about the pseudo port of mod_wsgi to nginx. but he makes some useful observations about FCGI. but uWSGI is quite new I think. graham definitely knows his stuff, but sometimes his prose gets tangled. and well, the issues are tangled anyway. 
uWSGI is pretty much the same thing as fastcgi/scgi: You run a bunch of servers running uwsgi daemon and the nginx webserver connect to the via a "uwsgi" protocol (via some module). It's not an embeded interpreter solution like apache modwsgi or the nginx version - it looks like you pretty much don't have any clue about the architecture of uwsgi and just post irrelevant and confusing comments. Is it mature enough to replace your fascgi/scgi setup? that's the right question.
No mention of uWSGI in that post.
I was actually looking for answers, not saying this new system is crap. I would like some type of explanation of wether this is better than the previous implementation. Again, is there a benefit to using uWSGI instead of FCGI? I've yet to see a reason to switch, regardless of how mature it is.
Too bad, that post is talking about a different module.
I don't see any benefits besides the extra performance from the C protocol handlers and some extra features like worker management (grecefull restarts and stuff like that), prefork throtling and on-demand app loading. In fact, at some later point when unladden-swallow or pypy become usable they won't work with uwsgi (at least not from the box - unladden-swallow should work provided you can recompile uwsgi against that). Another thing, they don't clearly explain why exactly is uwsgi better than scgi (the protocol it's based on). There is no testsuite - that's usually a bad sign.
Does the problem with blocking still apply? I can still down-vote him! :P
[http://www.google.ca/search?sourceid=chrome&amp;ie=UTF-8&amp;q=python+how+to+modify+text+file](http://www.google.ca/search?sourceid=chrome&amp;ie=UTF-8&amp;q=python+how+to+modify+text+file)
Press f1, read documentation Or use the help menu if f1 isnt a shortcut to it on your system 
&gt; That's not true. If you use call, you can't decorate methods, only functions In Python, function and method are the same thing. &gt; The solution is interesting, but I find it unpleasantly magical. @dec # or @dec(args) def foo(): ... # or class Foo(object): .... is always equal to def foo(): ... # or class Foo(object): .... foo = dec(foo) # or dec(args)(foo) `__call__` is "()". In short what get called is foo = dec.__init__(self, args).__call__(self, foo) Not so magical. And just like `earthboundkid` said, the example is too complex, just understand what actually happens and you can decide when you need `shim` or `__get__` as appropriate.
&gt; In Python, function and method are the same thing. There is a difference here. class Foo: def __init__(self, function): self.function = function def __call__(self, *args): print repr(args) return self.function(*args) class Bar: def __init__(self, string): self.string = string @Foo def out(self): print self.string Bar('hi').out() What happens here is, the Foo decorator produces something like Bar.out = Foo(Bar.out). So far so good. But when we get to calling that Foo instance's call method, there's a problem: the method is not called with Bar's self argument. That argument isn't supplied, and there's no way to get it back without the __get__ shenanigans. () Traceback (most recent call last): File "/tmp/decorator.py", line 18, in &lt;module&gt; Bar('hi').out() File "/tmp/decorator.py", line 7, in __call__ return self.function(*args) TypeError: out() takes exactly 1 argument (0 given) That () is the *args variable of Foo.__call__ showing up empty --- no self argument. So wrapping a method with a decorator implemented as a class doesn't work.
My eyes! The goggles, they do nothing!
When I saw the title I was praying to the FSM that it wasn't my code.
I don't think so, I don't see why the authors would implement a specific problem in their module :P
It's kind of ironic that you can use a function to decorate an OOP thing (method), but you can't use an OOP thing (class) to decorate an OOP thing (method). Sorta.
Thx for the link. Will come in handy soon for me.
One dysfunctional thing about the implementation of `logging.fileConfig()` is that it does not accept a file-like object. It forces me to access the filesystem. I definitely prefer this idea of taking a dictionary. I just hope we don't lose the 'defaults' substitution allowed by `fileConfig()`. I don't see that in this PEP. The most annoying thing in `logging` is the fact that the naming hierarchy is not consistent. It uses * 'foo.bar' * 'foo' * '' (root) instead of * '.foo.bar' * '.foo' * '.' (root) At least `logging` allows me to rename the root logger, and this is supported by `fileConfig()` as well. The name is ignored by `getLogger()`, but it is used by `Formatters`.
You didn't bother to read the article joshuajonah posted. I'm not too familiar with nginx, but it looks like it only processes one request at a time. This means that if you're using nginx to serve up static files, they wont be served until after your main request to django is served. That sucks, and is what he was getting at.
So, if you've got images *and* a web-app coming through nginx, will the images load before nginx is done processing the django request?
I like to call this "template", because it feels more descriptive. It takes an optional mime-type.
Security.
Hmm, I did that but I didn't get the uninstall command...
I just tried it and it looks very good, however I miss some important ipython functionality: * ? is nice, e.g. "len?" shows you help about it. * %run &lt;myscript&gt; is great because then I can get all the variables in my script in the current scope. Just throwing that out there, I'm going to use it a bit more and see what it's like. Good job so far!
Why is babby formed ?
My dear sir, the question is not why, but *how*. *How* is babby formed.
Why down votes ?, Python is primarily sponsored by Google and they are not even able to properly maintain their own API's. Rather than spitting numerous useless languages &amp; tools like "Simple programming language", Google GO, Closure tools, etc... Why don't they try to make development in python sane ?
Why misleading title ?
Just tell me in which way this post misleads ? 
GData is crappy because it is Atom, they should replace it with a sane JSON RESTful api.
since it's 17 days later and the comment is immediately followed by the author's admission that it's inaccurate, how about I leave it, you go study something until you're proficient at it.
[I'll just leave this here.](http://www.ibm.com/developerworks/web/library/wa-odf/?S_TACT=105AGX08amp;S_CMP=HP)
The gogglers, they do nothing!
That's what i love about Python, even the ugliest code is still prettier than most of the nicest Perl.
I'm not the one so hard up for something to add that I give someone s*t over a half month old comment that he's said was an attempt to not come off as an a-hole.
There was a release of a newer version of pip after I wrote that comment; Now you don't even need the dev version to use uninstall, just upgrade. But I can see the problem may be that a different version of pip is responding to pip command. So now a simple solution to get to latest version of pip would be, to uninstall pip entirely. Ensure you get a pip doesn't exist, and for one last time, use easy_install pip to install pip.
That did it, thank you!
On an unrelated note, why were you going thro' a month old reddit comment, on the Python reddit (I know that you develop in c#.net)
Dude, [I never touch anything other than Python](http://www.google.com/search?q=short+python+tutorial), you must be confusing me with someone else... I got this problem in iPython and Google had this page in the results.
&gt;In conclusion, there is no satisfactory way to interface Python with Gmail. 
Thanks for saving me the effort of reading that article.
Thanks :D
Yeha, it was the lingua franca... in the 80s...
I'm genuinely curious, is there a replacement in the community ? I bet it's pretty balkanized at this point and there's no clear successor to LISP, right ?
There is no 'unified AI research' front the same way there was in the early days of AI. The various subfields were assimilated by other fields (machine learning, statistics, information retrieval, etc) and all of these have their own pet methodologies for doing stuff. 
Upvoted for autohotkey.
Yeah... that was a huge disappointment.
that's what she said. heh.
I prefer PyGTK, good bindings, multi-platform, good docs and many many howtos and tutorials all over the web.
usually I'll use nose + rednose [1] http://somethingaboutorange.com/mrl/projects/nose/0.11.1/ [2] http://pypi.python.org/pypi/rednose/0.1.4
Very nice, but I believe you mean audit **trail**.
Ouch!
[Tim] &gt; Are these getting clearer as they get shorter? I don't think so. The point of the exercise is not what you might think - to get the shortest possible Python code. Because as Tim points out in the mail: &gt; Happy Python programmers generally prefer clarity to conciseness, and the two aren't always the same. 
I meant no disrespect - I love web2py, and will definitely be using this method in future projects. 
There is a big difference between "simple code" and these four lines of code: def powset4(seq): pairs = [(2**i, x) for i, x in enumerate(seq)] for i in xrange(2**len(pairs)): yield [x for (mask, x) in pairs if i &amp; mask] The problem and solution may be fully understood by the author, but even a python savant would have to spend a good chunk of time reasoning through that terse code to be even reasonably confident it worked properly. I agree that python's expressiveness is probably its greatest feature, only second to the clarity with which most python code expresses ideas. However, simple (understandable) code is different from terseness, even though they often happily coincide.
I understood. I appreciate you reporting the error. ;-)
[](http://farcef.files.wordpress.com/2008/02/10000.png)
[There is a saboteur among us!](http://imgur.com/nbYBx.png)
I've been quite pleased with [testoob](http://testoob.sourceforge.net/) as my "advanced runner" for some time now. 
ugh! Why does it have to be so complicated? In web2py we just do something like this in a controller: def test_italian(): """ This docstring tests translations for the Italian language: &gt;&gt;&gt; T.force('it') ('it',) &gt;&gt;&gt; print T('hello %s', 'you') ciao you """ return and then we click the [test] button in the admin interface. We get a report in a web page. Or perhaps I misunderstood the point of what you are trying to do.
it was VBA. Porting would be tricky because variables in one language might be keywords in another. 
[something is wrong here, but i cant quite put my finger on it](http://imgur.com/8BtQo)
In Haskell, the powerset recursion is captured by the "filterM" function: powerset = filterM (const [True, False]) Basically, this means: filter elements of the list according to a predicate that chooses to both filter in, and filter out, each element of the list. It can do this because in the list monad you can have multiple results. Then, filterM returns a list of all possible results of choosing each option for each element.
elegant? Interesting discussion about what you would call elegant on stack overflow: http://stackoverflow.com/questions/563036/what-is-elegant-code I would not call this a "intersection of simplicity and functionality." Perhaps you would like Perl more then python if complicated 1 liners is what you consider good programing. Albeit they are fun to write.
Haskell is the only language I've ever tried to learn that I 'wtf'ed as much as I ':)'ed
Witch!
Version 4 is larger and less readable than version 3.
Interesting, but symbols are usually used in module scope, and the simplest solution is just fine: START = 'start' STOP = 'stop' ... if state is START: # handle it Assuming that code that set state use only the module constants.
Be careful when using this method: you still need to do stuff like: START = symbols.START STOP = symbols.STOP Otherwise, the symbols class will accept any symbol name, which doesn't protect you from typos. This method is functionally the same as using string constants, with a little bit of OO sugar added.
Someone suggested I should repost this here, so I did. Enjoy!
+1 I've been using Python with Vim for over a year now and the only things I've customized are the indentation, the color scheme and added a few snippets for routine django tasks. As the parent said, none of the other stuff (autocompletion, refactoring etc.) is really needed with python - and if I somehow do need autocompletion like behavior - I just fire up an ipython shell and inspect the class I'm working with.
Indeed, the value lies in the loose dependency that that this modules allow. Using this module, the sender (the one who created state) doesn't know the receiver (where state is tested). 
seems like the simpler (and cheaper) approach to me as well.
Higlights are [here](http://projects.scipy.org/numpy/milestone/1.4.0) 
Just Curious: What are the kinds of things that you 'wtf' about in Haskell?
messing with sys.modules just seems icky to me. I suppose it could be useful if used sparingly. 
You don't need to repeat yourself: START = object() STOP = object() By the way that is quite similar to `gensym` in Lisp, for example you can use the `object()` trick in other contexts, like notfound = object() result = somedict.get('key', notfound)
Though I would prefer to use the Python bindings... I would recommend using the Java API at this stage. The Python API currently seems to be an incomplete subset of the Java API.
That does lose you the readable `__repr__` though. I'd go with something like: class Symbol(object): def __init__(self, name): self.name = name def __repr__(self): return "&lt;SYM %s&gt;" % self.name class Symbols(object): def __init__(self, syms): for sym in syms.split(): setattr(self, sym, Symbol(sym)) ns = Symbols("START STOP") print ns.START # prints &lt;SYM START&gt; print ns.NO_SUCH_VAL # Raises exception Or even: import inspect def defsym(syms): """Define symbols as module variables.""" globs = inspect.currentframe(1).f_globals globs.update(Symbols(syms).__dict__) defsym("START STOP") to define them as module variables.
I think I'm the subscriber number 10,000. I'm learning Python these days and came across this subreddit about 16 hours ago. There was 9,999 users subscribed. I subscribed and there was it, 10,000 readers. The subreddit logo didn't have the birthday cake image nor the (10K!) text yet.
yeah new learner here too
I expected Python 3 support but can't find it. Any clue as to when it's supposed to happen?
I don't get it, are you wanting someone to write it for you? That probably will not happen. Instead, begin building the base of it, and ask your questions when you get to a spot that you need help in.
(Replying to d0wn because I can't reply to the question itself) Frankly, I was considering looking at it, but I really have a hard time understanding what you're asking. Let me offer some advice: If you want help, ask for help doing something specific. It's the difference between asking "How do I make my car turn left" and "How do I drive a car". One shows that you've made a step towards understanding the problem, the other denotes your expectation for someone to solve the problem for you. Format your text, man. It makes people less eager to help you if they can't read what you wrote.
That is redundant and breaks down when you don't refer to START and STOP directly with state, but do something like "state = 'start'", because of a possible new creation of the String object. I prefer to use numbers for "states", just because everything trivial can be enumerated and integers are used for stuff like this very often anyway: STATES = (FIRST, SECOND, THIRD) = tuple(range(3)) if state == FIRST: .... The object() approach can also be nice.
Good golly. The problem is the NameError caused by this: class String(object): functions = { "size": Function(Integer, []), "append": Function(None, [String]) } This is incredibly easy to fix without metaclasses. Much more clear, too: class String(object): functions = {} String.functions["size"] = Function(Integer, []) String.functions["append"] = Function(None, [String]) (Ignoring for a moment the appropriateness of "String" and "Function" classes). 
Wow, that is good. Dealing with patchy examples on the web, when you can find them, and c++ class references has been tiring.
As the article says, google detects heavy activity and bans the user, at least for a short period of time.
I can't wait for the Wave federation to become a reality so that one can write bots for Wave outside of GAE.
Is it now supported on Windows 64, or does it still print dire warnings at runtime?
I've heard NumPy 1.5 will, but that's still a long way off :(
Ok last time I checked PySide was huge compared to PyQT, but the guys from Brazil was/is working on it. Do anybody know if the size of PySide changed or what the progress is of it?
For reference, it's made using Sphinx, which is an awesome, awesome documentation system.
It's a little more than tiring: it's confusing and time wasting, especially for the signatures that sometimes use pointers and other times use references.
First beta release of my first open source project, so be gentle :)
PySide seems really, really promising, but I'm a bit concerned about the dependency overhead compared to PyQT -- installing SIP isn't such a big deal, but getting Boost.Python installed can be tricky. Does anyone know, is Boost going to be required forever, or is that just part of the ramp-up to full capability? Will pre-generated bindings be distributed with later versions?
There was talk on the mailing list of creating their own replacement for Boost but haven't heard much of that since.
That's absolutely a solution to the problem, however in my view it fails at the "prettiness" test (author here).
Is there any particular reason that someone's working on a second set of Qt-to-Python bindings?
PySide is LGPL all the way, while but PyQT is dual-licensed by the GPL and commercial license. So if you use PyQT you can not redistribute without your application being GPL. Edit: Plus PySide is from Nokia, who makes QT.
I got it close to "working" after quite a bit of fiddling. It appears as though connections made to the wsgi application do not block other connections for static files and the number of interpreters that run in the uwsgi program is configurable. I did a simple test by setting up a handler that did nothing but time.sleep(10) and then I requested that handler while retrieving the default root index.html for nginx. My html requests completed while my uwsgi processes slept (and then subsequently died with an inexplicable 500 error). When this is tested further and the uwsgi module for nginx is improved, this could have potential to replace apache as an application server for mod_wsgi users, but it is definitely not there yet. I did not dig into the reasons that psycopg2 refused to work with uwsgi for me, but I did uncover a couple of problems in getting my sleep test to run: 1. There is a space before all output from the application which of course means that all the HTTP status codes are not interpreted by the browser and the web application does not work properly. I used the same wsgi script that I use with apache mod_wsgi as with uwsgi. 2. There is no environ['REQUEST_METHOD'] key for django's wsgi handler to interact with. This means any django request with uwsgi will automatically fail. In order to get my test request to work, I had to change django core to hardwire the request method to GET. 3. XML configuration for /only/ the application script name and commandline parameters for everything else? This seems really silly. It seems they should just dump the libxml2 dependency or actually use the xml config file for everything else too (and document it).
You start with #!
http://www.diveintopython.org/
So, this is cool and all... but shouldn't we try to get more of the costly solution's features into the open source solution, instead of the other way around? Edit: didn't mean to say this isn't cool, good job sir/ma'am
I used Zelle's *Introduction to Computer Science: Learning with Python*. I liked it a lot, but it also costs money.
http://www.reddit.com/help/faqs/programming#Imnotaprogrammer.HowdoIstart
That would be preferable, but matlab seems to be designed to not let you communicate with other things easily or robustly (their engine library's only calling mechanism is "eval", and it doesn't tell you if there was an error, and it doesn't return the evaluated value). So if you really need something from matlab but want to work mainly in python, this might help. This was mainly to scratch my own itch, which is: my lab has a large volume of matlab code, and new code needs to work with it. So if I want my new code to be python code, it needs to talk to matlab passably well.
Just curious, how old are you?
&gt; So if you use PyQT you can not redistribute without your application being GPL. You forgot the option to pay for a commercial license. You can still pay for software, lest ye forgot.
title is wrong: it's PyQt, not "QT" -- the latter is Apple's QuickTime. And, the old PyQt documentation is moderately rough. Thanks, PySide!
I discovered this reddit because you guys hit 10k! Hopefully I'll be able to stay up to date on stuff in the python world and learn a few things.
It still seems like overkill when the open source community already has widespread use of PyQt. The commercial licenses won't break the piggy bank; it's only 350 GB pounds per developer, equivalent to about US$600. As many people have said, that's a small fraction of the cost of a developer. From a quick peek at other development tools (e.g. Adobe Flash), it's comparable in price as well.
I'm not sure I understand the complaint about the pause before the file file descriptor is freed by garbage collection; the (by far) common case for working with files in Python is a type of application which simply isn't going to run you out of file descriptors before the GC frees them up.
Also, 'with' blocks.
PyQt was also very unpythonic, and from what I understand, its development was almost closed source.
&gt; It still seems like overkill when the open source community already has widespread use of PyQt. PySide is * more open source * has a bigger dev team * working more closely with Nokia * much better documentation * more Pythonic I don't really see how that is overkill. 
I suppose on Windows it will also prevent you from overwriting/moving the file while it is opened. At the same time, on Windows his functions are half broken because you want a "mode" argument...
&gt; but I'm a bit concerned about the dependency overhead compared to PyQT -- installing SIP isn't such a big deal FWIW PyQt wants SIP too. That burned me yesterday when I tried to install it using pip (or easy_install) (spoiler: I failed) PS: lowercase 't', Qt's 't' comes from 'Xt', QT in all uppercase is QuickTime.
* PySide is by Nokia. So is Qt itself, now that Nokia bought Trolltech * Riverbanks isn't interested in adding LGPL licensing to PyQt, even though Qt itself has been available under LGPL since 4.5 or so. Nokia wants people to use Qt, therefore an LGPL PyQt is a good idea as far as they're concerned * Riverbanks doesn't provide their bindings generators (which makes sense, since part of their business is based on them), PySide does so if Riverbanks stops doing PyQt releases you're hosed, if PySide stops you have the generators and can set them up and take over the project. * Ultimately, the goal of PySide is to provide better (more pythonic) Qt bindings (the way lxml provides more pythonic bindings to libxml2 and libxslt) rather than a thin layer over raw C++ APIs (which is what PyQt does)
&gt; PyQt was also very unpythonic Right now PySide is the same, its aim is to reach feature and stability parity with PyQt. Only then will the project move on to crafting more pythonic bindings to Qt.
True true... at least it has that goal.
Thanks for PMing me on this. Looks great, I hope to use it in an attention laboratory ([eye tracking](http://cslab.psyc.sfu.ca/Lab/index.html)) soon for some neural models. I'll pm *you* when that happens. :D
To which bit of "prettiness" do you refer? The complex twenty line solution, or the obfuscated declaration, or the needless subclassing? Or perhaps all three? Certainly "prettiness" is subjective, but your solution to the problem requires much more thinking on part of the reader of the code -- I can think of no project (sans Django) that uses a one item list with the string "self" as a marker. It's no so much the use of "self" as a string, it's the use of a special value to mean special things when it's really not so special. Further, your solution has a significant drawback: a programmer cannot extend your "functions" dictionary with new values; no, they'll need to subclass, possibly interfering with any metaclass already in use, and certainly making much, much more work should your class instances need changing in situ. 
&gt; Ok last time I checked PySide was huge compared to PyQT Isn't that because they provide the bindings generators? While PyQt provides only the bindings?
WhiteAfrican is most likely referring to runtime module size. 
Unless I'm mistaken, PyQt also includes reference docs which are also converted to Python syntax in much the same way as PySide's docs. What am I missing here? 
&gt; What am I missing here? A link to said docs since I would love to see them soon.
&gt; A link to said docs since I would love to see them soon. PyQt's docs?? They're on the website where they have always been. http://riverbankcomputing.co.uk/static/Docs/PyQt4/html/classes.html 
The documentation is mostly C++. Only the function sigs are changed, and only partially.
exsssssssellent
No source, no permission to translate. A freeware book.
19
Looks similar to http://code.google.com/p/unpython/ in approach I kind of wish one of these decorator-based projects became standardized and shipped with cpython. Make compilation behind the scenes to keep things smooth, but the decorator will keep things honest (no magic)
Sorry to disappoint you, but you're probably subscriber 10,001. I asked the reddit admins and [KeyserSosa](http://www.reddit.com/user/KeyserSosa) looked it up in the database. He PM me to tell that apparently [wither88](http://www.reddit.com/user/wither88) was the *first* 10,000th subscriber. But the number of subscribers is in a constant flux so probably in the time between [wither88](http://www.reddit.com/user/wither88) subscribed and I enabled the birthday cake CSS someone else unsubscribed. Then you subscribed and the counter hit 10,000 again. Even after that I enabled that the number of subscribers dropped below 10,000 as noticed by [authorblues](http://www.reddit.com/r/Python/comments/a9nnt/the_python_subreddit_now_has_10000_subscribers/c0gi7jb) and [resurge](http://www.reddit.com/r/Python/comments/a9nnt/the_python_subreddit_now_has_10000_subscribers/c0gi1ok).
No problem. Thanks to you and to wither88 for taking the time to look it up. It's not that subscriber 10,000 will get a gift. Happy to have came across this subreddit anyway.
It looks like you have not defined the right vars including the 'uwsgi\_params' file in your nginx configuration. This solve your first 2 problems. The xml configuration file is a legacy from the first versions, you can now use only python to configure the uwsgi server. Thanks a lot for testing it.
You also forgot more arrogant with Riverbank.
Cheers. This is useful for me as it concisely shows the changes and at a glance some look a lot more useful like for line in file.xreadlines(): --&gt; for line in file: 
In my case it will help me understand P2 code since I started learning Python 3
fwiw, most people suggest not switching to python 3 just yet
fwiw, most people suggest not switching to python 3 just yet
Good luck with it.
A4 eh? i think i'll stick to 8.5" by 11", thanks.
Not that PyPy is natively supporting extension. This solution still requires a full CPython interpreter. The idea is to use a RPC module to instantiate a CPython process and call the extension library through it.
You can do that in Python 2 as well — at least it works in 2.6.
Yep, we're working on a CPython backend (the shiboken thing) that removes the dependency on boost::python
Instead of linking to the post on a spammy message board you should use the [Google Groups page](http://groups.google.com/group/comp.lang.python/browse_thread/thread/53716c4136be473b) for comp.lang.python or the [official archives](http://mail.python.org/pipermail/python-list/2009-December/1228184.html) at python.org.
It appears as though this implementation does not block from my limited testing.
Thank you for your reply; I understand now that there is a "uwsgi\_params" file in the nginx plugin directory of the uwsgi source, but that was not apparent from the information on the wiki. It said "add the uwsgi_params" file, but not the source of or contents of that file. I created a blank file, expecting the documentation to tell me what to place in it. I would suggest changing the language on the wiki to say: "copy the uwsgi\_params file from the nginx module directory" for clarity. Edit: That change did indeed fix the first two problems that I indicated. I will test this further.
Summary: 1) I like functional programming 2) I haven't really done much long-term thinking about this project (scalability, leveraging libraries, hiring more team members) 3) There were no other technical people on the team to tell me how completely nuts this idea is 
Basically, were waiting for third party basics to migrate like Imaging. Not to mention all the C and C++ packages that only release bindings for 2.3-2.6
 def print2(x): return('0'*(2-len(str(x)))+str(x)) def iterloop(m): for i in range(m[0]+1): iterloopmid(m[1:], print2(i)) def iterloopmid(m, str2): if len(m) &gt; 1: for i in range(m[0]+1): if (print2(i) not in str2) or (i == 0): iterloopmid(m[1:], str2+print2(i)) elif len(m) == 1: for i in range(m[0]+1): if (print2(i) not in str2) or (i == 0): combination.append(str2+print2(i)) elif m == []: combination.append(str2) combination = [] iterloop([1,1,2,3,1,0,0,0,0,0,1,0,1,0,0,1]) for x in combination: print(x) 
care to explain wtf the original code is doing. looking at it is making my eyes water
Hm, I just realized the first digit in the array m is the least significant digit of the output. So really I should have appended thusly: combination.append(print2(i)+str2) Edit: same goes for the recursive call: iterloopmid(m[1:], print2(i)+str2)
They don't mention it but Numpy 1.4 also has new date dtype and date arrays.
It took me a while. But I think it's taking an array m, and generating combinations of numbers where the digits of the number correspond to values in the array. Each digit is less than or equal to each value in the array. There are a couple of twists though... each digit must be unique or zero (if I'm reading that bit right), and each digit is actually two digits, zero padded. So passing [1,2] should get you 0000, 0001, 0002, 0100, 0102. Passing [0,1,2] gets you 000000, 000001, 000002, 000100, 000102
How do I subscribe to /r/python ? 
Also, his version is of course fixed to 16 values (he has 16 nested for loops). Mine will take any length array and do the same thing. I'm guessing mine behaves the same way his does for an array length of 16.
1) Guilty. That's just my own bias I suppose. 2) I have done a lot of thinking about scalability. SBCL is far faster than Python implementations. I'm built on BerkleyDB (which is faster than almost any relational database). The architecture scales horizontally from the beginning up. I know plenty of good Lisp devs who I would love to hire if I had money. ITA Software (here in Cambridge) has over a 100 of them. 3) Possibly ;-) But I've worked for several other companies where a large team decided Lisp was the best solution for the problem at hand. Would you mind explaining why this idea is 'completely nuts'?
A4 has the nice property that if you cut it in half, you get two sheets of A5. So, if you want to save paper when making a bunch of copies, you can reduce the originals to A5, then put them side by side to make A4s with two pages of info per side. If you try to do this with 8.5 x 11, it doesn't quite fit, and you have to either cut out the bottom margin, or leave too much space on the sides. That said, the shape of 8.5 x 11 is a little bit… nicer? I dunno, I guess it's just what I grew up with, but I like it. 
File objects have been iterable since Python 2.3 (and the `xreadlines` method has been deprecated since 2.3); if that's listed as a 2-to-3 change I'd have serious questions about the accuracy of the article. 
And looking over the actual sheet, there seem to be a lot of things which were introduced in 2.x releases which are here being presented as 3.x; for example, `__getslice__` and friends have been deprecated since Python 2.0 (in favor of `__getitem__`, etc. receiving `slice` objects).
Go to [/r/Python](http://www.reddit.com/r/Python). In the upper right corner you will see a green button labeled \[+ frontpage\], meaning "add this subreddit to my frontpage". Click on it and it will turn in a red button. You are now subscribed. Alternatively click on the [edit](http://www.reddit.com/reddits/) button in the complete upper right corner to add several subreddits at once.
Really? Shit, i've been fannying around with readlines.
i'm just being a smartass. A4 is nice.
This sheet does a fine job of convincing me to stay the hell away from Python.
How is this comment downvoted?
Then wtf are you commenting in the python subreddit for?
&gt; I guess it's just what I grew up wit Probably. I grew up with A4 and I find 8.5x11 to be just weird.
By clicking on the down-arrow to the left of the comment.
It's still a ways off, but there's been a fair amount of progress made lately by several people (I'm not a dev, but I keep up with the mailing list)... e.g. http://mail.scipy.org/pipermail/numpy-discussion/2009-November/046841.html 
couldn't you have used itertools.permutations ?
xreadlines was still present in 2.6, but completely removed in 3.0. So while it was deprecated since 2.3, it's only in 3.0 that code depending on xreadlines will start failing, so makes sense to include in a transitional guide.
From a quick one-minute look, it doesn't look like you actually need to code Python to get this to work. You just install it, configure it and write your HTML templates. What coding did you have in mind?
That's the thing. I tried to do this myself, because I figured I could do the majority of it. I downloaded the latest version, got Python installed, and tried to follow the instructions. When it came time to run it, however, I couldn't figure out A) how to make it work B) what exactly was supposed to happen. So for that reason I don't know how extensive this project is or even if I am just being foolish. Well, I figure I'm being foolish, I'm just not sure how badly. 
I don't know if I'm missing something. From what I saw, just putting it on an existing web server and making it work (on an ad-hoc, non maintainable basis) would take ten minutes. This doesn't account for anything unexpected, of course. Most of what you need would be taken up in web design and template integration and this of course depends on what you need. If you want to pay someone to do it, have you considered contacting the authors?
Still, `xreadlines` was deprecated _over six years ago_. Anybody who was still using it had to have been ignoring a whole lot of warnings to the contrary for a long time, and probably shouldn't be able to plead ignorance of the fact that it was going away.
Aren't your print2(x) identical to str(x).rjust(2,'0').. While not everybody knows about the string justify methods, they are fairly easy to understand and looking them but is less work than figuring out a function like print2... Otherwise as far as I can tell your function iterloop does exactly the same as the VB code. But it isn't really that easy to see :) 
wow. I Never thought the difference be so much! 
Point is validating *all* the translations of some language. So that if you have "hi %s", you want to ensure that the translation of this string to the other language has "%s" in it. And you do the check for *all* of the strings. I would not want to have to list all 900 translation strings for 20 languages in my unit tests, and that would defeat the purpose of having translators ;)
this isn't quite the same as permutations. It's not the same set every time. In some cases the second digit could be 1, in other cases it can't. I suppose you could start with all the permutations and weed out the ones with dupes... 
Ya know, I totally tried to find a function that would do that for me. I figured Python's "batteries included" philosophy meant there had to be one out there. After spending 5 minutes looking, I decided writing one would be faster than to continue my search.
I wonder which of the two is easier to read. Mine or the daily wtf version?
That applies to most of the backward-incompatible Py3k changes: The majority relate to suboptimal conventions and misfeatures that seasoned Python developers have been working around since 2.0. The entire point of this sort of migration cheat sheet is to provide a quick reference for people that *aren't* intimately familiar with half a dozen sets of past release notes and PEP4. Especially factoring for all the Python developers who've relied on the backward compatibility of the 2.X line.
Skimmed through the latest issue, pretty cool but that site .. my god. Looks like it's from the 90's and designed by a kid in highschool. :(
&gt; Fun with Metaclasses never knew you could have fun with Metaclasses 
Ruby has symbols...(yet another thing that ruby got right and python is now playing catch-up on...other things include: blocks and true closures)
Now I need a second, third, fourth and fifth tutorial written in that style.
Has anyone fond something like this for ruby 1.8 to 1.9? I've found that the transitions to be very similar.
Thank you for the clarification.
You can't. It violates one of The Three Laws of Metaclasses*, however I haven't finished reading them yet to discover which one: 1. Your application is probably a misuse of metaclasses. If you strongly feel otherwise, see rule #2. 2. See rule #1. 3. If you managed to reach this rule, you are incapable of the clarity in thinking required to not mess up while using metaclasses. [*] http://py-datakit.googlecode.com/hg/README.html
I desperately hope your coworkers don't have jobs dealing with math.
Always cool to find a new python resource, but I question some of their editorial decisions. For instance, beginners are warned away from dispatch tables as being "nasty" and innapropriate for beginners, and then the very next chapter dives into metaclasses with this intro: &gt; In the Python programming language, metaclasses are used to specify how classes are created. Note that &gt; we are talking about class creation, not class instance creation. A few months ago I wrote some code &gt; which dynamically creates metaclasses. This turns out to be quite a useful trick. So in a magazine which is targetted at python newbies, we are warned away from a clean, clear powerful technique, and then told to play with metaclasses (with a rather confusingly terse explanation of what a metaclass is). I may peruse the back issues myself, but I don't think I'll leave copies lying around for unsuspecting people to stumble across.
`readlines()` is different and not deprecated. It gives you the whole data set as a list object. So keep using it if you need to have the whole data set at once as a list object. But usually you only need to see one line of data at a time, so `for line in f:` is preferred, since it's faster, lower memory, etc. 
* http://inventwithpython.com/ * http://eli.thegreenplace.net/category/programming/python/pygame-tutorial/
This is interesting and helpful. It may be noteworthy that symbols in Common Lisp are also tightly coupled to the so-called package system. There are lots of things to be said about the package system, but suffice it to say that, although it appears (at first look) likewise to Pythons module system, it's more about visibility rules than about files. This interaction is of course lacking in the python implementation (I'm not suggesting that this is a problem). And then there is the important distinction that symbols are not just dumb markers without functionality: in CL, they are the primary name of functions, variables and the like. The implementation of symbols provided here is hence more akin to symbols in Ruby.
Heh. Thanks to Svenstaro for plugging my book. http://inventwithpython.com is a free book aimed at total beginners and young adults to get into programming simple games. The later chapters begin to cover Pygame . It's good for people who already know programming, because you can pretty much just look at the code examples and figure out how Pygame works. http://inventwithpython.com/chapter16.html http://inventwithpython.com/chapter17.html http://inventwithpython.com/chapter18.html http://inventwithpython.com/chapter19.html
Excellent read. Thanks.
who uses __with__ and __and__ as variable names, reserved words or not? regularly that is.
It was `with` and `as`. I imagine some people used `as` as an abbreviation for various things. A better example was adding `yield` as a keyword; I bet that broke a decent amount of code for bankers, farmers, and warhead designers.
&gt;The one that really gets me is the assertion that the moratorium was some ego-driven “python is perfect” statement. That Guido/core dev think the language is “done” and that no new syntax or constructs are needed. I read a fair amount of Python related news, and I don't think I've heard this once. I'm pretty sure this guy made up this "problem" to be able to write his blog post.
actually i thought that it was obvious that this is the reason for the moratioum... It was even mentioned in PEP i think (not sure about that), or mailinglist bu guido.
Silicon is just another compile target. I'd think a functional language would be more appropriate, though.
I really hope this takes off in the industry, it'd mean one less language to (re)learn. 
Eh, he still explained pretty well why this was needed.
It's come up a few times on the mailing lists.
I've been held back with 2.5, waiting for external libs to catch up. I just noticed that cx_oracle now supports 3.0 and numpy/scipy support 2.6. Looks like I'll be upgrading to 2.6 next week :D I'm excited about switching to 3.0, although 2.x has been very good to me! 
yeah, yield was another one that fubared a few people.
Thanks for the link. We've been using python to verify FPGAs in the lab, this sounds like we can use it for verification in simulation as well.
I've seen it on multiple mailing lists, and a number of blog posts - some of which weren't even Python-specific, but actually rants about other languages. I have no fundamental need to make anything up; nor to have even made and written this post. I obviously fabricated it up for all the mad money I make off it though.
I was stuck in 2.5 land for a long time. Only by switching jobs could I migrate to 2.6. It's a better place.
switch statements please.
He's right, it is just like another compile target. A functional language would work much better because gate logic doesn't like assigning variables, it likes input and output, which is exactly what functional programming emphasizes.
Some people use *as* to mean the plural of *a* and write generic code that operates on *as* and *bs*.
500k? Xilinx ISE is 3k. This would output VHDL and then you run that through the synthesis tool in ISE.
not sure why I wrote as, thanks for the correction
I can't say I can imagine what an __a__ would be, but I see your point.
&gt; PyQT isn't very Python either I keep seeing this repeated on reddit and I don't believe it. Do you care to back up that assertion? 
It looks fairly novel, but what happens when you do something (like I see every flippin' day) like: always @ posedge clk1 c &lt;= some_signal1 a &lt;= b^c [100 lines of other combinational code] b &lt;= other_signal2 will it correctly handle that, knowing that "a" should be "some\_signal1" ^ "other\_signal2"?
Well there isn't much to discuss, it is as close to the C++ implementation as possible. C++ is decidedly not Pythonic. There are very few uses of properties (getters,setters instead), among other meaningful things. Ie. using PyQt is basically writing C++ code sans pointers. The proof in this case would be the PyQt (mostly C++) documentation.
Well, since this looks like homework, I'm going to make my solution as complicated as possible. Give me a few minutes and I'll get back to you. **Edit** never mind. Not worth it.
so... what does he need help doing?
i was thinking along the lines of: iteration 1 = 0 number = 0 import random random.randrange (114) def display() iteration1 = randrange print iteration1 if iteration1 &lt; 115 print number ...eh...fuck 'number' wouldn't work 
Verilog and VHDL take most of the market for chip designing, and they most certainly are NOT functional languages. I think you forget the human element in the process? - Paddy.
Nice.. no more GIL :)
No problem - nonblocking Verilog assignments are handled using Signals in MyHDL, blocking assignments with normal variables.
Combinatoric circuits are functional programming. And for the sequential logic, a DSL works well. Anyway, from the examples, this thing looks like an EDSL for Python. Haskell is a much nicer language for hosting EDSL's...
This is a classic reasoning flaw: because hardware is "parallel", a hardware language should have concurrent semantics only (which is what the functional language approach typically results in). The Verilog/VHDL reality has proven otherwise. Variables work just fine in synthesis.
Verilog/VHDL do a sort of imperative -&gt; functional program compilation, don't they? In which case, it would make more sense to abstract functional programming with higher-order functional programming, and not with imperative programming, wouldn't it?
Typically, a "functional" approach is just used to describe (concurrent) structure. But that is something all HDLs can do. For a MyHDL example, see http://bit.ly/8WD0sM. The problem is how to describe *behavior*, and I have yet to see a convincing hardware-oriented functional approach to that.
Isn't combinatoric logic a *behavior*?
Yes, and if that were all there is to it, a functional approach might work just fine. However, real designs typically have state and clocks. The problem is then to effectively describe the behavior of a circuit (including its state) over time (represented by clock ticks). Often, combinatorial logic can be seen as a "byproduct" of such a design process.
FP is good at that too -- there are denotational models for time-varying values (See Conal Eliott's FRP as an example). 
I've seen it used in geometric software where you have points a,b,c,...
Why is it both prompting for a positive number but also generating random numbers? Prompting implies user input.
This book would be much better for you than Mark's Dive Into Python Instead of just teaching you Python, it teaches you how to program by taking advantage of Python's extremely clear syntax. I learned C++ in High School, which was a disheartening experience. In college, I took an intro programming course with this book as the text. I found an older edition in PDF [here](http://www.leetupload.com/database/Misc/Papers/Python%20programming%20-%20An%20introduction%20to%20computer%20science%202002.pdf).
Ahh, I was hoping for something impressive. It loos like it's just writing Verilog in your Python code.
If only it added some sort of constrained random generation facility to Python, then it would be a contender for writing testbenches. As it stands, the OO they have added to SystemVerilog only poorly apes the real need of aspect oriented programming that you get in something like the Specman e language and which is easily done in Python. - Paddy.
failed again, you wrote *and*
Interesting point...that's why when I originally developed the logic (flowcharted) in raptor, I can't seem to translate it into python. I have to take out the biggest variable - user input - and now substitute it with random numbers. But, my question is how can I declare variables for random numbers when I don't know which #'s the generator will throw into the program to exceed 475....
So it seems like you can do away with the whole "Prompt" to begin with. The logic you're looking for is pretty simple. You want a loop that will continue until some total is 475 or higher. Each time that loop iterates, it adds a random number between 1 and 115. Then after the loop exits, you can tally up and spit out those results. I'll leave it to you to figure out which loop method you want to use. Do you know how to generate random numbers using random.randint? 
The pythonic way, of course, would be to write a separate constrained random verification package, so that not only hardware designers but also software developers would benefit from it :-) I hope someone will develop this soon!
Python Programming for the Absolute Beginner is a book that uses games to motivate learning...
And a very useful [snippet](http://www.djangosnippets.org/snippets/1762/) to integrate flakes with Django.
Add this to your ~/.vimrc to have Pyflakes run whenever saving *.py files: &gt; au BufWritePost *.py !pyflakes %
The whole thing.
thank you so much for the input akoumjian! I assume randit is a lib fuction that you import. However, I understand it would belong to the module random, but do I have to define this module in more detail? For instance would I do something like random() and use the randit lib function within the module. Also, would it be correct for me to set up an accumulator variable inside the if - elif - else loop? Thank you again for helping me on this one. I am a beginner (obviously). My class focused mainly on RAPTOR (flowcharting pseudocode) and very little Python...
A simplistic python switch is a dictionary: options = { 'a': function_for_a, 2: function_for_numbers, } options[input]() If it was easier to do anonymous functions in python this would be a full-featured switch statement but for now you're gonna have to just enjoy statically calling functions.
It is good that some features are back ported from 3.x. 
That was already the case with 2.6. The goal was to backport as much as possible, so as to ease the transition to 3.x.
&gt; Support importing dotted names so as not to incorrectly report them as &gt; redefined unused names. Thank %(deity)s, no need to grep out all those false positives any more.
Or for much more awesome integration, install this: http://www.vim.org/scripts/script.php?script_id=2441
What the fuck is this?
Are there reasons for *not* backporting function annotations and the nonlocal statement? 
I would question the if - elif - else conditionals in this case. Here is a list of loop constructors: (http://rgruet.free.fr/PQR24/PQR2.4.html#controlFlowSts You have the "if" the "while" and the "for" loops. I don't want to give it away, but you want just one loop, and you want it to keep looping until your sum is greater than 475. My gmail gtalk is the same as my reddit name, if you want to chat.
Yay, I was hoping memoryview would make the cut.
Thank you to everybody involved in 2.7 and 2.x in general!
None besides that it's a rather involved process, and no one has contributed a patch.
http://docs.python.org/dev/c-api/buffer.html
your averages are way too low, I'm glad to hear that you're at least discussing basic relational features like ON UPDATE and ON DELETE for 1.2 but seriously anything beyond the vanilla blog example will either suffer a severe loss in performance (due to inability to operate on the db and having to process on memory *a la Ruby*) or simply drop functionalities.
I was sort of hoping plop, plopper, ploppiest* = myList would make the backport.
My experience of developing large complex applications with Django seems to indicate you're wrong -- most of the time the ORM will do just what I need it to. And when it doesn't, well, I've got SQL for that (and, in 1.2, the `raw()` method to make it even easier). I guess the difference between you and me is that when I reach a point where getting ORM to do what I want is really complicated, I stop using ORM and start writing SQL (which, btw, gets easier in 1.2 with `raw()`). You'd apparently like the ORM to be able to do everything, which is an opinion you're entitled to, but I tend to think it's a diminishing-returns situation. Also, it's worth noting that a couple years ago, when the first serious thread discussing `ON UPDATE` and friends came up, I was the one who did the big round-up email explaining that the ORM would still end up doing processing at the Python level since it supports DBs which don't support the full range of triggers.
got the program running perfectly! thanks again for your help akoumjian! Next, im going to learn c++ (i read one of your comments to another person about how you were disheartened in high school with it)..I feel that as long as I continue with python and develop better logic, i will not go insane. Again, thank you!
No, I am not sure :-). I just know that the output is a .class file, but it could contain Python bytecode inside as well for all I know.
I could be wrong. I know for a fact it's slower if you are writing scripts because of the JVM overhead. I still think that Jython is much more fun to write than Java :-). But, I do think that it depends on usage, which JVM and which version of Jython (the benchmarks were against an old release). http://wiki.python.org/jython/JythonFaq/GeneralInfo#HowfastisJython.3F
I just recently started using Coverage. I'm glad to see this!
&gt; I guess the difference between you and me is that when I reach a point where getting ORM to do what I want is really complicated, I stop using ORM and start writing SQL (which, btw, gets easier in 1.2 with raw()). probably, however the key might be on what you consider "really complicated" because if I can't use the ORM for what it's supposed to be doing, that is, provide python objects mapping my queries in order to be able to use those results within my progam, then it's not a matter of using SQL or using the ORM the problem is the integration of those. just to put an example, few days ago I tried a very common and very simple thing: I tried to generate a column within my results based on a calculation; the calculation was simply to multiply two other columns from that same query but it turns out that `.annotate` doesn't allow me to use columns based on generated expressions and `.extra` (which is raw SQL) isn't recognized by the `order_by` method\* so I can't have sorted/paginated results based on that really simple and common operation and my choices are to calculate on memory or avoid sorting by that criteria. don't get me wrong I'm not blaming the philosophy as it is, because the whole framework is biased towards vanilla projects, that phrase of yours "how much of that power the average developer really needs" is the most common argument I've heard from Django and it's ok :) you either do something powerful or do something easy, it's like Windows vs Linux you're basically the Windows of the Python frameworks but what I disagree is that your "average levels" are way too low, it's ok to cover the common case and be able to quickly develop for it using the defaults but don't make it so horribly hard and annoying to do a bit more if neccesary. pd: congratulations for your work, Django is a great project and an excellent tool when used for its intended purpose. *\*if this is not a feature please let me know, I'm not familiar with the internals of Django but I'll be interested in trying to fix that if it is supposed to be fixed.*
oh and about: &gt; Also, it's worth noting that a couple years ago, when the first serious thread discussing ON UPDATE and friends came up, I was the one who did the big round-up email explaining that the ORM would still end up doing processing at the Python level since it supports DBs which don't support the full range of triggers. it's ok, currently Django itself enforces ON DELETE CASCADE so it's already emulating the feature but simply not providing the neccesary options to control it, I don't care if it is emulated as long as it works, it's safe and reasonably performant but I would like to have the option to prevent accidental deletion of large chunks of associated data so simply having a way to switch it to ON DELETE RESTRICT is all I want.
They discussed nonlocal on the py-dev mailing list, but the consensus seemed to be it wasn't worth the effort. 
Stick with Python long enough to learn the actually -programming- semantics. C (and possibly C++) will help you learn important, but highly technical issues (like thinking about how much memory you're using, declaring variable types, etc.) Glad to hear it's working now. It's very satisfying to accomplish a programming task. Now repeat a few thousand times.
I believe in your case, for now (unless/until support for annotating by generated expressions happens) you want the `order_by` keyword argument to `extra()`; it's a bit weird to have it there, but necessary because `extra()` isn't a general-purpose query parser, and so the ORM can't always guarantee that it'll figure out what you meant. Anyway, while I agree that there are things we can add, I think that as a whole the ORM targets about the right level of stuff; there's a point beyond which ORM just complicates more than it simplifies, and at that point I just want to write SQL (and, again, that's what `raw()` in 1.2 is for).
Inspired by you, I wrote a script to illustrate the Monty Hall problem... import random num_sims = 100000 stayed = 0 switched = 0 doors = [1, 0, 0] for i in range(num_sims): options = [0, 1, 2] random.shuffle(doors) pick = random.randint(0,2) options.remove(pick) random.shuffle(options) reveal = options.pop() leftover = options.pop() if doors[reveal]: reveal, leftover = leftover, reveal if doors[pick]: stayed += 1 if doors[leftover]: switched += 1 print 'Switched: %s' % ((float(switched) / num_sims,)) print 'Stayed: %s' % ((float(stayed) / num_sims,)) 
The scary thing is that with MySQL (whose default transaction isolation setting is `repeatable read`) Django transaction handling may behave in an at least equally counterintuitive way. *Repeatable read* means that any read from the database should yield the same result at any time throughout the transaction (you can say reads are done from a snapshot of the db at the moment the transaction was started). Now, ket's imagine that you have two fcgi processes, *A* and *B*. Both processess haven't written anything to the database for some time. A user comes to the site and is handled by *A*, saving something to the session. The next request is handled by *B*. However, *B* will *not see* anything that has ben just saved to the database. Django opens a transaction and keeps it open until the moment it has to write something, eg. when you call some model instance's `save` method. So, *B* is seeing a snapshot of the DB as it was *before* the first request had written anything, even though the data clearly is present in the database. Problems like this are notoriously hard to debug, as they will not manifest in development or after running a test suite (both runserver and test use only one process). Fortunately, the fix is very easy: just set the transaction isolation level to `read committed` (which happens to be the default in PostgreSQL).
&gt; Django opens a transaction and keeps it open until the moment it has to write something, eg. when you call some model instance's save method. This is quite wrong; Django explicitly closes the DB *connection* at the end of each request cycle, so there is no way for a pending transaction to be held open across multiple request cycles. The only way you could see this behavior is if B's request initiates while A's request is processing, in which case it's the expected behavior -- B will not see A's as-yet-uncommitted changes, which is kind of the whole point of transaction isolation.
I started digging into the problem specifically because our staging server started having raising random KeyErrors when a view was trying to access session variables set in an earlier request (and the earlier request had finished, as it was done after an OAuth authorization redirect). The random KeyErrors went away as soon as we had changed the transaction isolation level. Moreover, Django's documentation [says](http://docs.djangoproject.com/en/dev/topics/db/transactions/#django-s-default-transaction-behavior) says that "Django’s default behavior is to run with an open transaction which it commits automatically when any built-in, data-altering model function is called." I haven't checked the code yet, but this suggests that transactions *are* left open. EDIT: Just schemed through the code and didn't find the part where django closes the connection. I may not know where to look, though. Could you point me to the right fragment?
You want to look at [this](http://code.djangoproject.com/browser/django/trunk/django/db/__init__.py#L62). Any time Django finishes a request, it sends the signal `request_finished`. The ORM attaches a listener to that signal which closes the DB connection. Thus there is no possible way -- unless you're screwing around with the signal handler to get persistent connections -- for a transaction to stay open across request/response cycles.
It seems that you are right... Which is sort of scary and exciting at the same time. We made a diagnosis, we gave the patient medicine, the patient was cured and sent home. Only now it turns out that one of our basic assumptions was wrong, and if it was cured it's not because of what we think. Tell me about a mystery :) To reiterate: 1. The bug never manifested when there was only one process. 2. With many processes it only manifested *sometimes* (often enough to make it impossible to ignore, rarely enough to be hard to reproduce). 3. *A*'s request had finished when *B*'s request was handled (it was all part of a 3-legged OAuth dance, with a redirect to Netflix and back from Netflix between the requests). No rollbacks in the meantime. 4. Changing the transaction isolation level made the damn thing go away. And it's not that we didn't try to reproduce it. 5. The session object *was* there, *with* the data, but it wasn't seen by the second request (we confirmed by looking at it through dbshell). 6. No screwing with the signal `request_finished`. So, either something really strange was going on, or some other thing is not working as it was supposed to. I've got a quest for tomorrow ;-) Thanks for pointing me to the code!
Typically when people see this with MySQL it's because of the (MySQL server's) query cache. Probably worth checking out.
Nah, it's not the cache. That was one of the first things we suspected, but turning off query caching didn't make the problem to go away. I am suspecting this may be related to a MySQL bug (some time ago they had a somehow bug that caused that unfinished transaction weren't rolled back when the connection was closed). Still trying to design a test that could prove it...
http://www.xs4all.nl/ actually hosts many python servers including python.org
There is [Dive Into Python 3](http://diveintopython3.org/), but I think it is more targeted at people who want to learn Python, not people who want to learn to program using Python.
[Head First Programming](http://oreilly.com/catalog/9780596802387) looks really promising for you, as its really about learning to program but just happens to use python as its language. 
Certainly cool, but it seems - to me at least - to be yet another way to creatively shoot yourself in the foot. Code analyzers, which do not import the module (like pyflakes) will also not work with this.
&gt; Dicts are injected as-is. Modules have their __dict__s injected That was my favorite part of the article.
I didn't understand the use case. Anybody care to clear this up?
I like the fact that I can see all of external Python objects that make up my module - it really helps code readability. Injected stuff behind the scenes could really make things confusing!
I've used orange in a data mining class in college, and have used it a few times now at work. It has some very powerful data visualization tools. Although, at times the GUI can be a bit buggy.
Is it all in python? Does that make it a bit slow for heavy duty analysis?
Nope, they use python to wrap up the core [C++](http://www.ailab.si/orange/wp/orange-leaflet.pdf) routines.
http://www.ailab.si/orange/features.html The features are under construction... hehe:)
http://www.ailab.si/orange/features.html The features are under construction... hehe:)
This is a long shot but if anyone speaks Slovenian - here is a talk about orange by Janez Demšar (some of the main contributors and a AI genius* at my faculty) http://video.kiberpipa.org/media/POT_Janez_Demsar-Orange/play.html *edit
Not only have I heard of it, I'm writing modules for it. Nothing that's out yet, but some are under development.
Thanks. Looks really interesting. Will check it out.
I'm sure he is a genius, but accolades like "rock star" and "ninja" are cringeworthy.
Barely related -- I have a dataset that I'm already plotting using matplotlib. What statistical methods are there to analyze my scatter plot and find related consecutive samples of data? I'm thinking of something like an iterative t-test over various subsets in order to find "bands" of related data. ...only awesomer? All my googling yields stuff where the data sets are known to be hierarchical. I want to deduce order from unrelated samples.
The background is that I'm experimentally developing a web app framework to play with a few ideas, and scratch some itches that bug me about Django. I've been looking at Grails, and the convention-over-configuration idea in general. The most important point about this idea is that I intended it *just* for configuration files, as a way of creating a kind of DSL. To use it for regular logic files would be, as another commenter said, shooting yourself in the foot. That said, I do add *one* variable to __builtin__, which is something I thought long and hard about. It provides access to things like the project configuration, including SQLAlchemy entities, and the current request object (from thread-local storage). When you're writing code for Python, you have a lot of builtins available to you without explicitly importing them. When you're writing code for a framework on Python, I don't think it's excessive for the framework to make one more symbol globally available. Like I said, it's experimental, and the whole point of it is to try things that people don't normally do to see, firstly, whether they make development of a particular kind of application easier, and, secondly, whether they cause unforeseen difficulties.
So I can build a GUI to search for an IP address?
Why not just build a module with all the attributes you want to "inject" and just use: * \_\_all\_\_ * from module import * syntax That would cut down the amount of import statements at the top of a module, without requiring all the voodoo magic your proposal introduces. If I understand your use case properly, rather than having every Django model module with the following common imports: from django.db import connection import elixir from django.db.models import CharField, Model you could just have the header of each model module be: from myapp.modelimports import * and then move all the actual labels you need into myapp.modelimports, and add them to \_\_all\_\_: from django.db import connection import elixir from django.db.models import CharField, Model __all__ = ['connection', 'elixir', 'CharField', 'Model'] Isn't that simpler?
&gt; proposal First of all, let me clarify that it isn't a proposal. I'm not suggesting any kind of change to Python. I'm not suggesting something like this should be in the standard library. It's just something I did to achieve a particular aim, and I'm sharing it with other people for its hmm-that's-interesting value. &gt; Isn't that simpler? Simpler for me, sure, but not for the user. It was something I considered (before I knew my other approach would be possible), but it doesn't seem to gain you much, because you still don't know what symbols are being imported. You could specify them, but then you're back to square one, having to update imports every time you add a different bit of configuration.
No, it's a mobile phone company.
Plz send me teh codez.
Does it fix the problem of having lots of stdlib imports fail? time, subprocess, etc, all show up as unrecognized imports for me. Attempting an update via Eclipse and I am seeing lots of messages in the form of &gt; [org.python.pydev 1.5.3.1260390783] requiredCapability: osgi.bundle/org.eclipse.compare.core/0.0.0
There's a ton of other dislikes for the Django templates, but the biggest for me is that it treats the tags in such a dumb way: you can't split a tag on multiple lines, so tags with a big number of arguments, such as, for example, blocktrans, get pushed way outside my screen. http://play.pixelblaster.ro/blog/archive/2009/11/18/if-django-templates-are-an-improvement-over-xml-templates-by-all-means-please-give-me-xml http://play.pixelblaster.ro/blog/archive/2009/11/17/the-case-against-django-templates-1
It really needs someone to spend an afternoon or two making it easy_install'able though. The current install with make and manually creating the python package folder is a bit limiting. 
You gave a code snippet showing how one could use module_inject, maybe contrasting with an equivalent snippet that doesn't use module\_inject could help me understand what's going on or what this is good for. Edit: underscore formatting
It's also a fruit.
Right on. Speaking of clustering, [this](http://www.reddit.com/r/csbooks/comments/ac6pm/algorithms_for_clustering_data_jain_and_dubes_pdf/) got posted to [/r/csbooks](http://www.reddit.com/r/csbooks) the other day; maybe you'll find it useful. (Maybe also [this](http://www.reddit.com/r/csbooks/comments/a9bmg/sutton_barto_reinforcement_learning_an/)!)
Agreed sorry for that.
I want to know what are some *well-commented* modules that newbies can follow and learn from it.
this http://stackoverflow.com/questions/1428872/pylint-pychecker-or-pyflakes suggests pylint + pep8 instead. comments?
You code calls: eval(code, module.__dict__) basically you execute code in the context defined by a module. This is similar to what web2py does (except that web2py creates a standard context based on strict specs and caches bytecode compiled code for speed). web2py does it in a way that is hidden to the developer and therefore makes the code more readable, which is your goal too. You want to give it a try.
http://www.wingware.com/doc/howtos/web2py +1
wish the pro edition is cheaper (for individuals)
Komodo is free :) although I have to say if I was to pay I'd get wings
Great company, great product. I am a lowly single developer, and i have always had great support with them. Everything from bug fixes, to bugs in my programs, to bugs in others programs that i am using wing to debug into. Flat out awesome company, and i will always be a customer. Thanks guys!
file:sample_appengine_config.py #!/usr/bin/python2.4 why 2.4 here? this or that, BDFL IS ALWAYS GREAT 
We do have educational pricing in case you're a student or hobbyist not deriving any income from what you do with Wing. Also, we give free licenses for people using Wing solely for unfunded / non-income-producing open source development. Details on both are at http://wingware.com/store/prices
They've also been giving away licenses at the PyCon sprints the last 2 years (at least).
I love Wingware! I don't do Python development professionally any more, but when I did, I tried most big Python IDEs and Wingware was by far the best. It's an awesome IDE with good support! 
Seconded. Programmers shouldn't spend time on rewriting freely available code.
no native sql-alchemy support yet:/, and many things require their model layey.
That's probably a bad default. Please have a look at the default paths, and fix them up. Better yet, use a virtualenv: they make these kinds of problems more visible.
The other side for me, after months of fighting with large(ish) frameworks such as Django so that they bend to my requirements, I've given up and decided to plug focused tools together so that they don't come into my way. Depends on what you need really.
It also happens to be a really good book, but its much more about how and why to program than Python as a language. After you read it, dive into python 3 is going to cover some of the same stuff, but in much more detail, but you'll have a solid grip on the language after both of those books.
I second that, the ORM layer of Django is terrible (especially when compared to SQLAlchemy). I'm going for Pylons ATM, however the Development seems a bit stalled. :(
I never got around to trying the IDE although I've heard a lot of good things about it. The cause is the website. Every time I go there I feel like I'm back in 2000. The first few times I thought it was an abandoned project. The whole page just deters me from giving it a go, though I might change that now that I know that it is actually alive :) * There is not a single date on the frontpage, after clicking *read more* I see 2001, 2002 and 2008 as testimonials in addition to a totally meaningless version number (meaningless if one has never used the IDE before). * The link to the News isn't very easy to spot and certainly not placed prominently (top right corner) * As the whole page seems *outdated*. I had no idea if the screen shots were outdated too or not. I certainly couldn't find a version number * The text is way too small to comfortably read it (at least in my opinion). This is made even worse by those huge lists of text (feature list, product information -&gt; more information) * The menu on the left keeps changing and is missing completely on some pages * The boxes with links in them ("Free Trial", "More Info", http://wingware.com/products) don't do what I expect them to do. They look like they open some content in an inline tab in the box, instead I'm taken to a new page * The breadcrumbs are often wrong. http://wingware.com/products (Home &gt;&gt; Wingware News) ...and a lot more. Sorry for hijacking this submission for my rant. Congratulations to a new release.
Thirded. So why did the django devs reimplement *everything* rather than use freely available code again?
I don't know about others, but i'm utterly confused by the question. As far as I can tell, it doesn't mean *anything*.
You don't need a virtualenv for stackless. I just checkout trunk, run make (no need to run make install) and symlink /usr/bin/stackless to the binary i just compiled (the symlink is optional, i just like to have stackless in the global path) This gives me the stackless interpretor set up with the same python libs as my regular cPython install (stackless is just a patched cPython).
I thought about it, but the idea of 'kitchen sink' doesn't sit well with me. I like having a minimal base, and working off from there. But I see your point. If I were doing anything warranting stability and fast development, I would go Django, but this is just for personal learning.
I thought the exact same thing. Then again, if Django were perfect, there wouldn't be alternatives :P
My way of thinking. :)
Pylons is a lot closer to the Cherrypy + Mako combination, what don't you mention that?
Economics 101 says otherwise.
a few articles, my general approach for using formencode with Pylons style form decorators: http://techspot.zzzeek.org/?p=28 a pattern I sometimes use for rendering the same HTML widget both as inline HTML and also as an ajax-generated frame: http://techspot.zzzeek.org/?p=29 theres some new stuff that integrates closely with Mako in Beaker: http://beaker.groovie.org , but it seems Ben hasn't documented yet. If you pop on IRC and ask Ben about "mike's new component-caching feature", he'll probably know what you're talking about since I have him using it.
django should be looking at pylons/mako/beaker. see http://compoundthinking.com/blog/index.php/2008/09/17/djangocon-and-learning-from-zope-2/ for further details.
I started with the same setup and found that in my case, I still needed a lot of other pieces and was wasting too much time trying to glue them all together. So I switched to Pylons and lived happily ever after.
Not a problem. This is useful and confirms my own impressions of it. I suppose all I can say in our defense is we spend a lot more time working on the product than the website! We'll try to improve this, however. Thanks.
Interesting, I wasn't sure it would function correctly without doing a make install.
The point of virtualenv is to have an isolated installation of cPython (binary + site_packages ) that won't affect the entire system. I was asking if I could do the same but with stackless or pypy so I could try it out.
You are right, too. I guess it goes both ways.
yep go for it :) I tried cherry.py and web.py for a while until i was convinced the kitchen sink was better mostly because I did need it. I was able to wrap my head around django better afterwards. The first time I read the django docs (pre-micro) I was just confused by the ludicrous amount of stuff in it and micro framework was a welcome relief. you should try twisted as well :D also fyi: django components can be used separately, the orm, the template engine etc. I use the orm in a couple of twisted and libpcap apps that populate the dbs that django displays, it's been easy enough 
he wanted examples of good design not the messy unintegrated insanity that is pylons
Maybe I will reconsider Pylons. 
I actually went for web.py + Mako first, but the way cherrypy handles urls made more sense to me.
I actually started with web.py + Mako, but the way cherrypy handles urls clicked with me much faster.
I really want to like Pylons, but when you compare the documentation for Pylons vs. Django, there's a HUGE difference.
heh same :) 
Note the [user review](http://www.intriguing.com/mp/_sounds/lb/blindsee.wav): &gt;&gt; "I used to be blind, but now I can see :-)" &gt;&gt; --An early user 
I guess it's the same reason there are 20 car companies building cars. Everyone thinks they can build a better car, some are faster, some are simpler, some are slower but easier to attain, some are built for certain situations. I like and use django, but think people should look over the documentation of their various options, try writing a simple app and go for a "test drive" I realize that there are fast and easy to attain pieces of software, but they might not feel right to the driver
I've never used Python for web development, but I use it for a bunch of other stuff. I have used PHP for web development. Anyways, this is my take on your last statement. Python is a fairly good generic scripting language, it was not designed with web development, while PHP was (so your last statement is true). But don't let that deter you. Even with PHP you're eventually going to need some decent library that handles all the $\_GET/$\_POST stuff for you. I've been handling the $\_GET/$\_POST stuff myself in PHP and at first it was easy to get up and running, but now it's sort of a big mess. 
In PHP, aside from frameworks like Cake, PHP *is* the web framework, so things like `$_GET` are in-language. Python however is a language used outside of web-development, so things like GET variables are provided by a library. It's mostly a taste thing, but I'd hardly call it "less productive". reddit is in Python, for instance
Let me see if i understand. So with the right library, you're good to go? The only difference is that PHP has those functions already enabled by default, whereas with Python it needs to be enabled?
Python is a general programming language that can be used for lots of things. You're right: this is the part where a web framework comes in. Django is an option, as is Pylons, which reddit uses. An apparently easy-to-use framework web2py may be your best bet for building simple online applications. I don't really have experience with any of those frameworks, so somebody else will have to help you there. PHP is specifically built to be a web language. It is the server-side platform as well as the language. I actually don't know if there's an easy way to manually invoke the PHP interpreter (say, write a program that computes something and makes output). The server just does it automatically upon finding a .php file that is requested. Python, itself, doesn't have this status as a server-side technology language. A web framework in general is usually reads code and interprets it a certain way beneficial to web development. There are web frameworks for plenty of languages: Ruby has Ruby on Rails; Python has Django and Pylons; Any .NET language + ASP.NET can be used (C# is a language very much like Java); an old, popular combination was Perl &amp; CGI. The thing about web frameworks is that, even if they use the same language, they can be vastly different. They happen to use the same programming language, but they may ask for data / output data in a completely different way. Python is a great language to learn in general, but it's not geared for the web like PHP.
Those things are a mess, and that could lead to some security problems as well.
So if it is not geared for the web like PHP, like you said, would it be beneficial to learn PHP instead of Python, since my main objective is web development?
&gt; So with the right library, you're good to go? Yeah &gt; The only difference is that PHP has those functions already enabled by default, whereas with Python it needs to be enabled? Err, sort of, but your vocabulary is a little off. They aren't inherently "enabled" or "disabled", they don't exist, except in some library somewhere. In PHP, that's a library that happens to be in the default namespace. For reddit, which is in Python, that's in Pylons. For a site in Django, they're in Django somewhere.
Yes i know, that's what i meant with 'enabled'. Appreciate the help.
Simply put, Wingware WingIDE is the best Python IDE out there, period. Trust me, I've tried them all -- Komodo, Pydev, vim + omnicomplete, etc. Once you've had a taste of these features: - their type inferencer with autocomplete - their unit testing integration - their debugger with attachable "debug console" ... you'll feel any other IDE is underpowered. Not to mention that their vim bindings are pretty good, and I hear the emacs ones work well, too! Totally worth the money.
If I were only interested in web programming, I probably wouldn't learn Python. You require a framework, of which there are many, that is not part of the language itself. PHP is more popular than Pylons and Django are. I know a lot of redditors hate PHP, but I suggest you continue learning it if your primary goal is web development.
John, I'm hurt you didn't include py-yajl in your benchmarks ;) You should really take a peek at some of the _speedups.c code from `simplejson`, it's at the very least an interesting read, and quite necessary for `simplejson` to remain comparable to other C-based modules. The defects noted on the [python-cjson](http://pypi.python.org/pypi/python-cjson) page are something IMHO worth including here as well: &gt; 1. cjson.decode('1') &gt; &gt; Returns 1, should raise an exception. Similar issues exist for other atomic values, such as cjson.decode('"a"') and cjson.decode('true'). &gt; &gt; 2. cjson.encode(1) &gt; &gt; Returns '1', should raise an exception. Similar issue to #1. &gt; &gt; 3. cjson.decode('["\\/"]') &gt; &gt; Should return ['/'] or [u'/'], but returns ['\\/']. This causes value corruption when parsing JSON from correct implementations. &gt; &gt; 4. cjson.encode(['/']) &gt; &gt; Returns `'["/"]'`, should return `'["\\/"]'`. Similar to #3, but instead of corrupting strings, causes a security issue documented at [http://t3.dotgnu.info/blog/insecurity/quotes-dont-help.html](http://t3.dotgnu.info/blog/insecurity/quotes-dont-help.html) &gt; &gt; 5. cjson.encode([u'\U0001d11e']) &gt; &gt; Returns '["\\U0001d11e"]', should return '["\\ud834\\udd1e"]'. This prevents serialising any character from the astral plane. &gt; &gt; Note that the result is invalid JSON, and any conforming parser will raise an exception when parsing it. cjson doesn't, because it's not. &gt; &gt; 6. cjson.decode('["\\ud834\\udd1e"]') &gt; &gt; Returns [u'\ud834\udd1e'], should return [u'\U0001d11e']. This prevents parsing any character from the astral plane. &gt; &gt; 7. cjson.decode('[0.3]') &gt; &gt; Returns [0.299999], should return [Decimal('0.3')]. This can cause silent corruption of data passed through cjson. I don't know if simplejson does this also -- jsonlib doesn't. &gt; &gt; 8. Several cases where invalid JSON is parsed into an arbitrary garbage value. All of these ought to raise an exception, but do not. &gt; &gt; cjson.decode('["\\1"]') &gt; &gt; cjson.decode('[+1]') &gt; &gt; cjson.decode('[00]') &gt; &gt; cjson.decode('[01]') &gt; &gt; cjson.decode('[0.]') &gt; &gt; cjson.decode('[\x0c]') &lt;- stdlib json fails on this one also &gt; &gt; cjson.decode('[1 2]') &gt; &gt; cjson.decode('{"a": 1 "b": 2}') &gt; In my opinion, having a good set of test cases for JSON performance and validity would be something good to talk about [this weekend](http://unethicalblogger.com/posts/2009/12/pythonjson_eatdrinkup_san_francisco)
# Add preference to use block style comments in comment-out feature I like this, but why not follow the [pep 008's block comment style](http://www.python.org/dev/peps/pep-0008/): Block Comments Block comments generally apply to some (or all) code that follows them, and are indented to the same level as that code. Each line of a block comment starts with a # and a single space (unless it is indented text inside the comment). Paragraphs inside a block comment are separated by a line containing a single #. 
Stackless is basically CPython with a patch set applied, so virtualenv should work just as it does with CPython. I don't know if anyone's tried virtualenv+pypy yet
&gt; John, I'm hurt you didn't include py-yajl in your benchmarks ;) Ubuntu doesn't have a package for yajl yet, and I haven't gotten around to installing it manually. No offense was meant, I'm simply lazy. There's [numbers comparing py-yajl with simplejson](http://www.mikealrogers.com/archives/695/comment-page-1#comment-707), so it looks to be a bit slower in parsing and a bit faster in encoding (similar to simplejson). &gt; In my opinion, having a good set of test cases for JSON performance and validity would be something good to talk about this weekend The problem is that different people have different ideas of "validity". For example, jsonlib2 was forked in part because I refused to add support for NaN and Infinity to jsonlib. Going further down that path is [demjson](http://deron.meranda.us/python/demjson/), which adds "non-strict" mode at the cost of complexity and performance.
I believe he was asking if there was some kind of way to virtualize a pypy or stackless instance like virtualenv does so that it won't interfere with his system python. As kx233 said above this is easily achieved on your own rather than using another tool.
&gt; I've been wanting to get into web development for a while now then just focus on PHP/Javascript - AFAIK it offers lots better web-dev job opportunities than Python. When you get "bored" with PHP then try out Python. ps: just 2-month PHP and now you're looking at Python, why ? you got ADD ? :)
This was a case of simply satisfying a common request to have the comment-out feature work like it does in idle (## in column zero, rather than our default of single # at end of leading white space). There are some advantages to each with respect to auto-indent and other features. The pep is not really that relevant here since they are talking about actual documentation-containing comments that pertain to some code that follows it, and not just regions of (presumably temporarily) commented out code. 
&gt; ps: just 2-month PHP and now you're looking at Python, why ? you got ADD ? :) Maybe he's got a sense of taste? I keed, I keed. No, actually, I don't. 
No, the difference is that the web framework is fused into PHP. Things like the $_GET are welded into the language just like for and while loops. And then you have extensions that get enabled in a configuration file (php.config) and other extremely quirky and down right stupid stuff. Python is a general purpose language. It's meant to do all kinds of stuff, not just web programming. Making things like $_GET part of the language doesn't make any sense, and it would be downright retarded to do it in a general purpose language, but stuff similar to it will be made available by the framework you choose to use for web programming, along with a variable amount of nice stuff, depending of what kind of framework you decide to use. [Django](http://www.djangoproject.com/) and [Pylons](http://pylonshq.com/) offer you lots of stuff. Micro-frameworks like [Bottle](http://bottle.paws.de/) and [web.py](http://webpy.org/) offer you less stuff. A framework will save you time at the expense of flexibility, a micro-framework will give you flexibility at the expense of time.
My favorite combination is Werkzeug+Mako+SQLAlchemy
Python comes with a modules that give you the ability to talk with a web server and parse http headers (cgi, urllib, mod_wsgi, etc.). Also there are multiple template languages created in Python that allow you to embed code in html as you do in PHP (cherrypy, mako, kid, genshi, etc.). Because it gives so much choice you find that people have built many frameworks (kind of like cakePHP for PHP but much more powerful). The worst of the Python frameworks is superior to PHP in terms of clean syntax and code re-usability. My advice is look into web2py. It does not require installation and include http(s) web server, sql(ite) relational database, web based IDE, a template language similar to PHP, a Model View Controller design, a Database Abstraction Layer that writes the SQL for you (it also CREATE, and ALTER tables as necessary), a web based administrative interface for the database, a role based access control system, a web based testing system and debug system, a mechanism for automatic generation of forms. It is the only framework that allows you to deploy apps on the Google Cloud without having to use the Google API. Here is a complete app that let you upload images and view posted images # append to models/db.py ### describe your data db.define_table('image',Field('name'),Field('file','upload')) # insert in controller/default.py ### describe your workflow @auth.requires_login() def index(): return dict(myform=crud.create(db.image), images=db(db.image.id&gt;0).select()) # in views/default/index.html ### describe presentation (code in html as in PHP) {{extend 'layout.html'}} &lt;h1&gt;Post an image&lt;/h1&gt; {{=myform}}&lt;!-- this make the upload form //--&gt; &lt;h2&gt;Posted images&lt;/h2&gt; {{for image in images:}}&lt;!-- this loops and display images //--&gt; &lt;img src="{{=URL(r=request,f='download',args=image.file)}}"/&gt; {{pass}} Hard to compare with PHP which most people (including me) consider obsolete technology. Cherrypy, Pylons, Django, TurboGears, web.py are also good alternatives. EDIT. In web2py the equivalent of `$_GET` is `request.get_vars`.
So, PHP is designed for one thing and one thing only: request/response processing in web applications. You can try to write other types of code in PHP, but it ain't pretty and it ain't easy. Python, on the other hand, is a general-purpose programming language, designed to be good at lots of things and support an ecosystem of specialized libraries for various domains. This means that to do web development you typically need language + some libraries, but the upside is you're not completely screwed if you realize that your web stack involves more things than PHP's execution model offers. Oh, and did I mention that lots of the stuff you'll need to do in any non-trivial web-dev project is going to end up taking you outside PHP's comfort zone? There's a reason why big PHP shops all seem to be using huge conglomerations of non-PHP tools to round out their stack...
I would definitely look into python for web development. PHP is easy to learn, but has a ton of gotchas. Python has a much better standard library too. I'd recommend taking a look at something like Django (http://www.djangoproject.com/). I'm working on a project now using Pylons (http://pylonshq.com/) and really like it's flexibility, but Django has a lot more built in.
Reddit is python :)
PHP has the biggest market share, especially in terms of web development. If you intend to market your skills later in this area (developing "typical" web sites), you *must* know PHP. Also, and consequently, PHP is trivial to host (*every* hosting plan supports it), while Python is trickier (many hosting company only offer old or even antique versions, if any; only a few are dedicated to Python, and so are more expensive; I suppose most often people rent a dedicated (virtual) server, and administer it themselves). PHP was created for the web, in a very ad-hoc and amateur way. It has slowly been transforming in a more general purpose language (PHP can be called from the command line to perform non-web work), has gotten acceptably object-oriented, etc. Still, the culture is mostly "getting web things done". Python was created to be a general purpose programming language. The culture is mostly "getting things right". Some of its standard modules allow it to be used on the web (you can create a web client or a web server in a few lines of code), but if you want to do real web work, you'll need a much more comprehensive framework, the current star being Django (rightfully). As said above, you'll have a more difficult time hosting it on a rented server. Overall, it all depends on what you want to do. If you only want to "program the web", PHP (and JavaScript) is a good way to go. If you want to have a more general programming culture, Python might be better.
I'm pretty sure most of it is php...
I disagree. PHP shines in one thing, and it's the easy and reliable way to deploy it. No config, no restarts, just upload the files and magic happens. Python on the web needs much more attention to be deployed (such as configuring the webserver to serve Python to begin with, forcing code reloads on updates), but that can be automated if it gets on one's nerves. I don't think deployment is the most difficult task in web development. It happens fairly rarely. Much more time is spent *designing* the applications and finally coding them. Even more time is spent *maintaining* the applications, either adding features or optimizing. Perhaps maybe plugging security holes, but you shouldn't have left those in to begin with. Python is #1 in the ease of maintaining applications, even complex ones. If you're doing anything more than just fancy templates with static content, you'll find Python a pleasure to use.
General purpose programming is a *good* thing. You might not at first need or want to write applications that transcend the Web paradigm, but being able to seamlessly serve requests and doing something completely different is a big bucket of possibilities. What possibilities? For instance, Twisted.
[Nice.](https://code.launchpad.net/myconnpy) 
Is python suitable for web dev ? Yes, it is. PHP is a language that was built for webdev, with embedded web-specific mechanisms. Python is a script language with a broader purpose and those functionnalities aren't built-in, contrary to php. However, python does have a ton of libraries/frameworks for almost anything. Bottomline is : python is more powerful, but the learning curve is steeper. I'd suggest trying the Django tutorial.
Invoking the php interpreter: php myscript.php I've used it a lot just as a normal script engine because I knew it better. There are even windowing libraries i.e. you could build a non-web gui, haven't tried though.
I couldn't ignore all the PHP haters anymore, so i decided to see what Python is all about and i liked what i saw. Or maybe i have ADD.
Congratulations!
&gt;MySQL Connector/Python is implementing the MySQL Client/Server &gt;protocol completely in Python. This means you don't have to compile anything or MySQL (client library) doesn't even have to be installed on &gt;the machine.
No, it really isn't.
I recommend using pylons. It's flexible and I think easier to understand than Django. 
How is a two month span ADD?
You should read his username.
wingware, Thanks for explaination.
I can't believe people still compare python to the worst designed language - PHP is nowhere close to python in productivity when it comes to writing web applications. Just take a look at django/pylons/turbogears and never look back.
no its completly not true, its equally productive if not better than PHP. But you do have to use a framework like django or pylons to work with web and python. Its competly diffrent world and ecosystem.
Actually, much of simplejson is written in C -- that's why it's reasonably fast. If you'd like to see how absurdly slow a pure-Python implementation is, remove _speedups.so or _jsonlib.so and watch performance plummet.
&gt; How is a two month span ADD? in the context of learning (programming) language, it is.
Thanks for correcting me. :)
Wouldn't that absolutely murder performance?
Dear god, what part of 'clock' do you not understand :S
Does anybody here on reddit use IronPython in production? If so, I'd be curious to hear what you do and your approach with IronPython. 
Keep in mind that the more you get to know a framework (however frustrating the process of "getting to know a large framework" is), the more efficient you become. I'm just saying, because I regret having wasted a lot of time instead of starting with Django from the very beginning.
Yeah, I have one thing to say about Haskell... No thanks.
I do enjoy Pylons but I have to say Django has far better documentation.
That's one crappy tutorial... "from math import *" - what? They screw up their very first import statement?... The tutorial is clearly created for those who can already program, so there really is no point in doing stupid things like that. I'd recommend http://en.wikibooks.org/wiki/Non-Programmer%27s_Tutorial_for_Python instead. Works great for non-programmers and programmers alike (thought those who already know how to program could probably just look through the official documentation and be happy about it).
Well the point is that Django has a much bigger community. I often look jealously over to them. OTOH: After having used SQLAlchemy, I just feel physical pain when using Django's ORM. However: Pylons has a decent book free in the web and there's great documentation for SQLAlchemy for example. Pylons combines many technologies, so the docs aren't necessarily all in one place. JFTR: I tried to rebuild small parts of my webapp in Django and the SQL generated by Django's ORM was much slower than SQLAlchemy's (10x slower in one special case). And yes, I asked on #django and was just told, that SQLAlchemy is simply better at this. Give me Django with SQLAlchemy and I'm in heaven. Sad to see Pylons slowly die though, I really loved its philosophy.
Or just Dive Into Python, which is both good and free.
Tutorials are usually focused on a specific topic. This is more of a bad rewrite of the python manual with advertisements.
I learned with the [official Python Tutorial](http://docs.python.org/tutorial/index.html) and would suggest everyone to do the same.
+1 for the only seemingly on topic reply in a sea of "try my favorite framework cuz it's the best..." 
i went to the 1st day of sprints this year, but I didn't get one. 
Please post some feedback if you try any of the system mentioned below. I em very much in the prospective of PHP users.
I like how they're teaching bad practices from the off. 
Sure. I have not yet used any of the frameworks mentioned, as i'm still learning the basics of Python. I will post some feedback once i do.
How is "from math import \*" screwed up? That's perfectly valid. Or do you just mean they should stick to the basic "import math" because it's a tutorial?
Its valid, but also very bad practice. If the tutorial was created for people who can already program, thats a bad way to start things out.
Ironpython 2.6 supports getframe now, should be able to work with ipython, right?
Dear idiots, Turn off smart quotes inside of &lt;code&gt; tags. The Python prompt has a space in it: `&gt;&gt;&gt; a = 5` not `&gt;&gt;&gt;a = 5`. Don’t use uppercase letters for instance variables, just classes. Never `import *`. Etc.
You don’t really just want to do web development. You want to do as many things as you can force yourself to be good at. Only learning the bare minimum is no way to get ahead in the industry. The people who rewarded don’t set false boundaries for themselves. 
Done that. Worked great so far. I now have a system which uses Werkzeug, Jinja and SQLAlchemy which looks a bit like Djangos Admin, but has far greater querying power thanks to SQLAlchemy. The design does not look as nice, but thats a CSS thing. ;)
who are the authors ?
for whatever reason, the old dogs on #python IRC don't like DIP...I have been reminded several times....
Chaque semaine python à le droit d'une revue de presse
If you want a simpler implementation for writing a web app in python try [webpy](http://webpy.org/)
line 105 of lib/enum.py, wow, I cant believe someone else does: print "holla" as a method of testing/debugging!
A better python resource for beginners is [A Byte of Python by Swaroop C H](http://www.swaroopch.com/notes/Python).
Is that a typo of the Spanish word "hola" or is it a variation of "holler?"
No, not because its a tutorial, but because it's what you should do! And since the tutorial isn't made for complete beginners, there really is no point in importing everything into the global scope. It might be acceptible if you are learning complete newbies, but even then, doing an import math would be better.
You forgot the link. If you select "text" when posting, you can't include one. One thing that could be fun to do is patch each person through a translation service (for each person, translate their post to Japanese then back to English before sending it along).
Added it to the description, sorry about that.
One thing that you might want to try doing is connecting to 4 people and crossing the wires Person 1 -&gt; Person 4 Person 4 -&gt; Person 3 Person 2 -&gt; Person 1 Person 3 -&gt; Person 2 (Person 1's messages are sent to Person 4, but he receives messages from Person 2, etc.)
Yeah, tried that once, but that only creates great confusion. I also tried a "chat-roulette": If one stranger is fed up and disconnects he is automatically replaced - but I didn't thought of it as particularly interesting.
&gt;Yeah, tried that once, but that only creates great confusion. Isn't that the point? :)
Yeah, it's fun as long as it lasts :D - but those people just disconnect if something doesn't please them so there are never "real" conversations in that constellation.
Just to note, Omegle will IP ban you if you do too many requests. Needless to say i'm thankful i've got a few IPs for my home connection.
I can assure you that 8 or 10 connections at once didn't get me banned - thanks for the info anyways.
Hm, well alternatively one could maintain a few "normal" conversations but every so often randomly send a message to the wrong person.
Cryzed, what drove you to own Omegle's system so thoroughly? Also, is each chatter assigned an ID? i.e. is it truly random or is it predictable?
Yup, takes about 10 open connections and maybe 500+ requests over a 10-15 minute period :)
what's this, an explanation of the trollin' 4chan has been doing on omegle? Heh, they had some good wordfilters going. "webcam" filtered to "penis" or something, so all the guys askin for a horny ninteen year old girl with a webcam...
I did this a while ago with that one Python Omegle IRC script. I also made it so you could interject as either stranger during the conversation.
There is a bug at row 80 of omygle.py - an urllib.encode is missing 
Post source?
http://pastebin.com/m45b61572
Yes, that one. To fix it change row 80 into request = self._browser.open(DISCONNECT_URL, urllib.urlencode({'id': self._id})) 
http://pastie.org/743478 Edit: Warning: Terrible quick hack.
How do I use hostname nickname otherbot \\#channel
 python omegler.py irc.example.net omegler1 omegler2 \#example | python omegler.py irc.example.net omegler2 omegler1 \#example
I don't know, I went through the python docs in detail once and could write some basic extensions in C but then I decided to try out [cython](http://www.cython.org/) and never looked back :) Have you tried [cython](http://www.cython.org/)?
I'm not familiar with it. I'm trying to learn the C api so that I can help contribute to a few active opensource projects
I would find it at least mildly interesting if you could couple Omegle with cleverbot.
cool, which ones?
Thanks, I'll fix that later! EDIT: Fixed.
You can, maybe I or someone else is going to do it.
1. Boredom. 2. Unfortunately unique and apparently random, that means you can't spy on conversations without the Man-in-the-middle-attack.
I modified the man in the middle to swap all gendered terms. &gt;Connected to Stranger 2 &gt;Connected to Stranger 1 &gt;Stranger 2 is typing... &gt;Stranger 2: male? &gt;Stranger 1 is typing... &gt;Stranger 1: yup &gt;Stranger 2 is typing... &gt;Stranger 2: name? age? from? &gt;Stranger 1 is typing... &gt;Stranger 1: steven, 22, belgium &gt;Stranger 2 is typing... &gt;Stranger 2: steven? its female? &gt;Stranger 1 is typing... &gt;Stranger 1: how the fuck is steven a male name? &gt;Stranger 1 is typing... &gt;Stranger 1: type steven in google images, you won't find a male &gt;Stranger 1 is typing... &gt;Stranger 2 is typing... &gt;Stranger 1: you're probably asian? &gt;Stranger 2: ohh im sorry guy &gt;Stranger 2 is typing... &gt;Stranger 2: not im uk &gt;Stranger 2 is typing... &gt;Stranger 1 is typing... &gt;Stranger 2: why if im asian? &gt;Stranger 1: you're not in uk &gt;Stranger 1 is typing... &gt;Stranger 1: if you were in uk, you would've known steven was a female name &gt;Stranger 1 is typing... &gt;Stranger 2 is typing... &gt;Stranger 1: and your english wouldn't be crappy either &gt;Stranger 2 has disconnected. &gt;Disconnecting Stranger 1 
Cool project, I can imagine some humorous things you could do with message integrity here. If you had a list of words you run find/replace on (love/hate, sex/cartwheels, guy/girl) you might get some entertaining confusion.
Hm, when using the man in the middle module, won't both strangers be disconnected from each other if I stop the script? I started it up, but I don't have the heart to shut them down. They've been at it for ten minutes now...
It is only a pity that urllib3's requests have a slightly different api than urllib2's, so you cannot just plug urllib3 in place of urllib2. Of course, a little bit of monkey patching can do the trick. Other than that, this is a really nice library.
what was wrong with [httplib2](http://code.google.com/p/httplib2/)?
haha, that is the first thing i did. i replace girl with old lady. i also replace all sex words with things like puppies and kittens.
you missed some underscores, reddit doesn't seem to like them. put an underscore before browser and between DISCONNECT and URL
It's amazing how many people do this, and in Python no less (what I me). Another funny thing to do is to replace words. Penis and pussy, girl and guy, ... No to yes, yes to maybe. And this this is a good one: Canada and America. Like this: [2009-11-03 04:25:32] Stranger 1: I used to have a friend that came from Canada [2009-11-03 04:25:32] ======= sending: &lt;&lt;I used to have a friend that came from america&gt;&gt; [2009-11-03 04:25:59] Stranger 2: ummm.... dont a lot of your friends? [2009-11-03 04:26:14] Stranger 1: come from Canada? [2009-11-03 04:26:14] ======= sending: &lt;&lt;come from america?&gt;&gt; [2009-11-03 04:26:30] Stranger 2: yes [2009-11-03 04:26:30] ======= sending: &lt;&lt;maybe&gt;&gt; [2009-11-03 04:26:33] Stranger 1: none, we're too far south for the Canadians to feel comfortable [2009-11-03 04:26:46] Stranger 1: it gets to be in the 100's here in the summer [2009-11-03 04:27:15] Stranger 2: im still confused as to why none of your friends are american [2009-11-03 04:27:15] ======= sending: &lt;&lt;im still confused as to why none of your friends are canadian&gt;&gt; [2009-11-03 04:27:51] Stranger 1: Its not that I wouldn't be friends with a canadian. [2009-11-03 04:27:51] ======= sending: &lt;&lt;Its not that I wouldn't be friends with a american.&gt;&gt; [2009-11-03 04:28:04] Stranger 1: its just that none of them are around. [2009-11-03 04:28:20] Stranger 2: well, considering you are in missouri, where are you friends from? [2009-11-03 04:28:34] Stranger 1: My canadian friend moved to Alaska recently [2009-11-03 04:28:34] ======= sending: &lt;&lt;My american friend moved to Alaska recently&gt;&gt; [2009-11-03 04:29:22] Stranger 1: Well, I've got friends in the room from Illinois, Georgia, Missouri, and a Military Brat (no home state) [2009-11-03 04:29:22] ======= sending: &lt;&lt;Well, I've got friends in the room from Illinois, Georgia, Missouri, or a Military Brat (yes home state)&gt;&gt; [2009-11-03 04:29:44] Stranger 2: so, how are all of those people not american? [2009-11-03 04:29:45] ======= sending: &lt;&lt;so, how are all of those people not canadian?&gt;&gt; [2009-11-03 04:30:22] Stranger 1: they were just born in the united states [2009-11-03 04:30:35] Stranger 1: and they stayed here [2009-11-03 04:30:35] ======= sending: &lt;&lt;or they stayed here&gt;&gt; [2009-11-03 04:30:42] Stranger 1: no expatriates in this room [2009-11-03 04:30:42] ======= sending: &lt;&lt;yes expatriates in this room&gt;&gt; [2009-11-03 04:31:05] Stranger 2: ok, so what does american mean to you? [2009-11-03 04:31:05] ======= sending: &lt;&lt;hmm... m'kay., so what does canadian mean to you?&gt;&gt; [2009-11-03 04:31:47] Stranger 1: Mounties and French and Hockey [2009-11-03 04:31:47] ======= sending: &lt;&lt;Mounties or French or Hockey&gt;&gt; [2009-11-03 04:32:07] Stranger 2: um so canadian? [2009-11-03 04:32:07] ======= sending: &lt;&lt;um so american?&gt;&gt; [2009-11-03 04:32:28] Stranger 1: clarify [2009-11-03 04:32:40] Stranger 1: like US american? [2009-11-03 04:32:40] ======= sending: &lt;&lt;like US canadian?&gt;&gt; [2009-11-03 04:33:01] Stranger 2: why would you call mounties and the french american? they sound more likely to be canadian [2009-11-03 04:33:01] ======= sending: &lt;&lt;why would you call mounties or the french canadian? they sound more likely to be american&gt;&gt; [2009-11-03 04:34:12] Stranger 1: well, we generally call our police cops and a very small percentage of people here speak french, as opposed to Canada where it is a popular second language [2009-11-03 04:34:12] ======= sending: &lt;&lt;well, we generally call our police cops or a very small percentage of people here speak french, as opposed to america where it is a popular second language&gt;&gt; [2009-11-03 04:34:39] Stranger 1: so, mounties and french (the language) remind me of Canada more than the United States. [2009-11-03 04:34:39] ======= sending: &lt;&lt;so, mounties or french (the language) remind me of america more than the United States.&gt;&gt; [2009-11-03 04:34:53] Stranger 2: WTF? is american a different country that the US? [2009-11-03 04:34:53] ======= sending: &lt;&lt;WTF? is canadian a different country that the US?&gt;&gt; [2009-11-03 04:34:57] Stranger 2: *america [2009-11-03 04:34:57] ======= sending: &lt;&lt;*canada&gt;&gt; [2009-11-03 04:35:38] Stranger 1: where are you from? [2009-11-03 04:35:49] Stranger 1: underneath a rock somewhere? [2009-11-03 04:36:05] Stranger 2: ok, where is this country america? find a map of it online and send me the link [2009-11-03 04:36:06] ======= sending: &lt;&lt;hmm... m'kay., where is this country canada? find a map of it online or send me the link&gt;&gt; [2009-11-03 04:36:52] Stranger 1: find it yourself, it is the large mass of land directly north of the United States [2009-11-03 04:37:05] Stranger 1: it is part of the same continent (North America) [2009-11-03 04:37:05] ======= sending: &lt;&lt;it is part of the same continent (North canada)&gt;&gt; [2009-11-03 04:37:25] Stranger 2: so, you are saying it is more north than canada? [2009-11-03 04:37:25] ======= sending: &lt;&lt;so, you are saying it is more north than america?&gt;&gt; [2009-11-03 04:38:04] Stranger 1: further north than the united states and I am beginning to doubt your credentials! [2009-11-03 04:38:04] ======= sending: &lt;&lt;further north than the united states or I am beginning to doubt your credentials!&gt;&gt; [2009-11-03 04:38:11] Stranger 1: Ms. Oregon [2009-11-03 04:38:36] Stranger 1: sex [2009-11-03 04:38:42] Conversation ended.
try something for [this](http://www.chatroulette.com/) also
Same here, used the script posted on reddit (I think you made it, right?) and hacked it for nefarious aims. The big one is getting two bots on the same IRC channel, you see the convo but people in the channel can drop in comments that go to both chats. quite fun. [Git repo](http://git.tensixtyone.com/?p=code/omegle.git;a=summary) *Edit* if its all a bit rough and buggy, don't shout at me. After all I got IP banned from Omegle so my interest wained a bit.
Hey Python folks; I posted over on /r/programming yesterday: http://www.reddit.com/r/programming/comments/aejdx/could_use_some_eyes_on_the_google_app_engine_to/ And thought, particularly since I saw a few other (Python) Google App Engine posts here, that it might be useful/etc. to /r/Python as well.
Edit: Replacing male and female terms are some of the best ones since there are more males than females on Omegle. If one guy thinks that the other guy is a female, they have a better shot at having a longer conversation, thus producing more confusion, thus making me laugh more. I had some like that too. The shorter one: [2009-11-03 11:30:06] Stranger 1: asl? [2009-11-03 11:30:06] ======= sending: &lt;&lt;Do you mind if I ask for your age, your sex andd maybe the country you live in? To put it more bluntly AAASSSLLL!!!?&gt;&gt; [2009-11-03 11:30:08] Stranger 2: lol! [2009-11-03 11:30:09] ======= sending: &lt;&lt;I think this is funny. Ha ha ha! Hi hi hi! Ho ho ha ha!!&gt;&gt; [2009-11-03 11:30:12] Stranger 2: 15 m holland [2009-11-03 11:30:12] ======= sending: &lt;&lt;15 f holland&gt;&gt; [2009-11-03 11:30:20] Stranger 2: you? [2009-11-03 11:30:25] Stranger 1: 21 m uk [2009-11-03 11:30:25] ======= sending: &lt;&lt;21 f uk&gt;&gt; [2009-11-03 11:30:31] Stranger 2: lol [2009-11-03 11:30:31] ======= sending: &lt;&lt;I think this is funny. Ha ha ha! Hi hi hi! Ho ho ha ha!&gt;&gt; [2009-11-03 11:30:40] Stranger 1: do msn popular in holland? [2009-11-03 11:30:44] Stranger 2: yeah [2009-11-03 11:30:47] Stranger 2: in uk? [2009-11-03 11:31:00] Stranger 1: yes do u have one? [2009-11-03 11:31:00] ======= sending: &lt;&lt;maybe do u have one?&gt;&gt; [2009-11-03 11:31:05] Stranger 2: yeah [2009-11-03 11:31:14] Stranger 1: can i have it? [2009-11-03 11:31:18] Stranger 2: nope [2009-11-03 11:31:18] ======= sending: &lt;&lt;yup&gt;&gt; [2009-11-03 11:31:30] Stranger 1: ok then please give me [2009-11-03 11:31:30] ======= sending: &lt;&lt;hmm... m'kay. then please give me&gt;&gt; [2009-11-03 11:31:35] Stranger 2: what's your name? [2009-11-03 11:31:44] Stranger 1: jack u? [2009-11-03 11:31:52] Stranger 2: hahahahahahahaha [2009-11-03 11:32:01] Stranger 2: you are a female named jack! [2009-11-03 11:32:01] ======= sending: &lt;&lt;you are a male named jack!&gt;&gt; [2009-11-03 11:32:15] Stranger 1: yes what's going on [2009-11-03 11:32:15] ======= sending: &lt;&lt;maybe what's going on&gt;&gt; [2009-11-03 11:32:24] Stranger 2: i don't know [2009-11-03 11:32:31] Stranger 1: what is ur msn [2009-11-03 11:32:35] Stranger 2: very mysterious! [2009-11-03 11:32:40] Stranger 2: or not? [2009-11-03 11:32:40] ======= sending: &lt;&lt;and not?&gt;&gt; [2009-11-03 11:32:44] Stranger 2: fuck u! [2009-11-03 11:32:44] ======= sending: &lt;&lt;hug u!&gt;&gt; 
...and the longer one: [2009-11-03 05:33:58] Stranger 2: Wait are you bisexual? [2009-11-03 05:34:06] Stranger 1: no im not [2009-11-03 05:34:06] ======= sending: &lt;&lt;yes im not&gt;&gt; [2009-11-03 05:34:15] Stranger 2: Huh? [2009-11-03 05:34:17] Stranger 1: why? [2009-11-03 05:34:30] Stranger 1: do you think Marina is a male name? [2009-11-03 05:34:30] ======= sending: &lt;&lt;do you think Marina is a female name?&gt;&gt; [2009-11-03 05:34:37] Stranger 2: Yup. [2009-11-03 05:34:37] ======= sending: &lt;&lt;nope.&gt;&gt; [2009-11-03 05:34:39] Stranger 2: I do. [2009-11-03 05:34:50] Stranger 2: hehe [2009-11-03 05:34:54] Stranger 1: you DO think Marina is a male name????!?!?!?!oneone [2009-11-03 05:34:54] ======= sending: &lt;&lt;you DO think Marina is a female name????!?!?!?!oneone&gt;&gt; [2009-11-03 05:35:05] Stranger 2: Yup [2009-11-03 05:35:05] ======= sending: &lt;&lt;nope&gt;&gt; [2009-11-03 05:35:11] Stranger 2: How is it said? [2009-11-03 05:35:27] Stranger 2: MA-REE-NA? [2009-11-03 05:35:30] Stranger 1: dude, you lost me :-) why did you ask whether i am a bi? [2009-11-03 05:35:30] ======= sending: &lt;&lt;girl, you lost me :-) why did you ask whether i am a bi?&gt;&gt; [2009-11-03 05:35:33] Stranger 1: exactly [2009-11-03 05:35:55] Stranger 2: Cos I thought you were a girl. [2009-11-03 05:35:56] ======= sending: &lt;&lt;Cos I thought you were a boy.&gt;&gt; [2009-11-03 05:36:03] Stranger 1: ok then [2009-11-03 05:36:03] ======= sending: &lt;&lt;hmm... m'kay. then&gt;&gt; [2009-11-03 05:36:08] Stranger 2: lolfail. [2009-11-03 05:36:11] Stranger 1: how should i understand "Stranger: We can still cyber" then? [2009-11-03 05:36:13] Stranger 1: yeah, epic [2009-11-03 05:36:30] Stranger 2: Cos Im a troll. [2009-11-03 05:36:35] Stranger 1: oh right :-) [2009-11-03 05:36:45] Stranger 2: and not many Guys go *sighs* [2009-11-03 05:36:45] ======= sending: &lt;&lt;or not many Guys go *sighs*&gt;&gt; [2009-11-03 05:36:50] Stranger 1: im not. im reeeeal "-) [2009-11-03 05:37:11] Stranger 1: " or not many Guys go *sighs*" - what does it mean? [2009-11-03 05:37:11] ======= sending: &lt;&lt;" and not many Guys go *sighs*" - what does it mean?&gt;&gt; [2009-11-03 05:37:20] Stranger 2: Wait [2009-11-03 05:37:23] Stranger 2: Im very confused [2009-11-03 05:37:25] Stranger 2: at this point [2009-11-03 05:37:27] Stranger 2: Lol. [2009-11-03 05:37:27] ======= sending: &lt;&lt;I think this is funny. Ha ha ha! Hi hi hi! Ho ho ha ha!.&gt;&gt; [2009-11-03 05:37:32] Stranger 2: I assumed you are female [2009-11-03 05:37:32] ======= sending: &lt;&lt;I assumed you are male&gt;&gt; [2009-11-03 05:37:38] Stranger 2: I think that is wrong now. [2009-11-03 05:37:43] Stranger 1: yes [2009-11-03 05:37:43] ======= sending: &lt;&lt;maybe&gt;&gt; [2009-11-03 05:37:45] Stranger 1: I AM A GIRL [2009-11-03 05:37:45] ======= sending: &lt;&lt;I AM A boy&gt;&gt; [2009-11-03 05:37:47] Stranger 2: lol [2009-11-03 05:37:47] ======= sending: &lt;&lt;I think this is funny. Ha ha ha! Hi hi hi! Ho ho ha ha!&gt;&gt; [2009-11-03 05:37:54] Stranger 2: okokokok [2009-11-03 05:37:55] Stranger 1: marina is OBVIOUSLY a female name [2009-11-03 05:37:55] ======= sending: &lt;&lt;marina is OBVIOUSLY a male name&gt;&gt; [2009-11-03 05:37:57] Stranger 2: cool. [2009-11-03 05:38:04] Stranger 2: Not OBVIOUSLY [2009-11-03 05:38:20] Stranger 1: obviously, i insist [2009-11-03 05:38:31] Stranger 1: it ends with A! [2009-11-03 05:38:36] Stranger 1: and it sounds so gentle [2009-11-03 05:38:36] ======= sending: &lt;&lt;or it sounds so gentle&gt;&gt; [2009-11-03 05:38:40] Stranger 1: ma - ree - nah [2009-11-03 05:38:48] Stranger 2: yeah [2009-11-03 05:38:52] Stranger 2: Im checking now [2009-11-03 05:38:56] Stranger 1: okay. [2009-11-03 05:39:00] Stranger 2: on the internet :P [2009-11-03 05:39:06] Stranger 1: very good. [2009-11-03 05:39:06] ======= sending: &lt;&lt;very bad. &gt;&gt; [2009-11-03 05:39:09] Stranger 2: http://www.thinkbabynames.com/meaning/0/Marina [2009-11-03 05:39:29] Stranger 2: first google hit for "arina name" [2009-11-03 05:39:37] Stranger 2: "Marina name" [2009-11-03 05:39:44] Stranger 1: ok [2009-11-03 05:39:44] ======= sending: &lt;&lt;hmm... m'kay.&gt;&gt; [2009-11-03 05:40:04] Stranger 1: now it's time you show me your pic! [2009-11-03 05:40:04] ======= sending: &lt;&lt;now it's time you show me your a visual representation in some digital format!&gt;&gt; 
WTF, why did you paste that! Now there will be a billion other bots on Omegle.
Did you try connecting Omegle to an AIML bot? *Proudly awaits to hear "no" to start bragging.*
Simple asynchronous http lib, anyone?
just use httplib/httplib2 with eventlet/gevent
I'm a freelance web developer and while I adore Python I often find myself having to work with PHP. If you don't get a say in the choice of severs (and few providers give the option of using a full-blown WSGI framework with Python for the same price as `mod_php`), you will have to work with what you get — and that is usually PHP. If you are serious about it and have the possibility to install a WSGI framework on a web server (and possibly even re-sell the hosting services to your web development customers — yay for job security), you should definitely dive into Python, though. PHP is for the web, but the web isn't strictly for PHP. While PHP was historically closer to what we have come to call template languages these days (which is why it always irks me to use a template language in PHP), it has evolved into a full-blown web scripting language. For my taste, that often puts it closer with scripting languages like Perl or Java's JSP (again, foremost a template language) whereas I would intuitively put Python closer to Java or the dot-Net languages. Python as a CGI language can be used just like PHP or Perl for one-off scripts that are supposed to deal with a small, very specific problem (often form mailers are cited as an example). With a WSGI framework you can use it for full-blown applications and work on an entirely different level of abstraction (i.e. application rather than request). While PHP is first and foremost made for the web, Python is more universal and tends to feel more "detached" than PHP when it comes to dealing with web I/O. OTOH big frameworks like Django may feel so contrived they can overwhelm you — which is why I currently use Werkzeug, which feels more like just another thin layer of glue (web development feels more like "normal" Python hacking that way, less domain-specific). Usually PHP works fine if you REALLY only want to do minor stuff like random quotes, form mailers or view counters, but it tends to get incredibly messy if your project grows beyond its initial size and all those one-offs suddenly need to be refactored into a coherent system. Web frameworks usually prevent this by forcing you to work with a coherent system from the very beginnings, but that can feel overkill sometimes. From my personal experience and developed tastes I can only suggest the following: If you need a few scripts that fit into independent files or something to quickly glue a few pages together (e.g. putting a navigation on every page but a template language would be overkill), feel free to use PHP. If you want to write a real web application or anything that actually requires abstracted interaction (e.g. forums, content management, blogs, anything with more interaction than a log-in and a guestbook) PHP will quickly feel like cutting an oily steel pipe, with a rusty scalpel, with your arms tied behind your back, while drowning in quicksand; and a WSGI framework may help you maintain your life expectancy. 
To clarify: I've started with PHP when I still went to elementary and kept using it throughout school. A few years ago I then discovered Java gained some experience in writing Servlets and JSP scripts with Tomcat. This year I picked up Python and now I don't look back anymore. It's like Java in the sense that you have a full framework rather than a domain-specific language, but it's so much easier to work with (somehow Java tends to be incredibly verbose compared to Python).
Oh god not another one :(
People are downmodding you because you accidentally posted this comment twice, which is apparently a grave sin on reddit.
That's an excellent implementation of execnet. I enjoy streamhacker's blog. NLTK is a very powerful toolkit.
My exact same thoughts, I kind of liked the virtual file interface.
Could you link to the other ones? Those that don't depend on Twisted?
urllib3 is definitely faster then the stdlib urllib2 in a non-threaded script, been playing around with writing a site scraper backstore thing and its easily 2x as fast now in fetching targets.
urllib, urllib2, httplib, other ones made by randoms for no obvious reason such as CkHttp.
I've used a couple of ChillKat's products before, biggest selling point is the support he provides to them.
Interesting. Thanks for the answer!
It's also not thread-safe, IIRC. I've been thinking about how to speed up my crawler by making it asynchronous, and that's impossible with httplib2 right now. It's actually one of the first tickets in their bug tracker, but still not addressed.
What are you crawling, by the way? (it's a hobby of mine)
It's only sort of a crawler. More of a single-level image fetcher. I go through the html of a bunch of content from RSS feeds (it's for an aggregator site) and fetch the images from all of them. Right now it takes quite a while because it does everything serially.
Perl used to have the biggest market share too, and everyone was using CGI.
Heh, I implemented the exact same thing just this last week. (A friend wanted a way to crawl tumblr blogs). Is the site public?
&gt; Is the site public? Yep, it's [here](http://portlandthings.com). It's a simple enough problem to tackle, but there are lots of interesting special cases to work around. I started to look into Scrapy, but its general architecture doesn't seem well suited for this style of crawling. I really just want to say "here are a bunch of RSS feeds, go fetch them all in parallel and give me them back ASAP" -- then scan them for img tags, and say "here are a bunch of image URLs, go fetch them all in parallel too." If I come up with a decent solution, I'll probably put it up on github.
[I don't think httplib2 can be used in that manner](http://code.google.com/p/httplib2/issues/detail?id=5).
http://code.reddit.com/
That's exactly what the OP said. So yes, MisterWebz, you've got it right. It's just that Python libraries don't simply add "GET" functionality, they go steps above it and add a lot of useful OO structure.
Neat. When I was doing serious crawling I managed it with multiple processes: each instance of the "finder" process would crawl sites looking for new URLs, and instances of the "looter" process would download queued urls. I had it all talking through a mysql database, which scaled surprisingly well but did require a dedicated box (lotta ram usage). I haven't tried to rebuild it since then, so I don't know of any better solutions. (One obvious thing would be to have threads instead of processes and some kind of message-passing daemon instead of going through an SQL database, but I never tried it)
One thing that makes it even more interesting is that I have to keep memory usage pretty low, as I'm on a semi-shared plan with WebFaction.
I agree, we need one powerful module to work with http.
I decided to learn Python and set out to do so while building something useful. You give it ballots and your preferred [voting system](http://en.wikipedia.org/wiki/Voting_system); It gives you the results of your election and an explanation as to why the winners won. The source is up at http://github.com/bradbeattie/Election-Web-Service
Aww :(
A negative result is still a result, and that's great someone explored this possibility. Thanks.
I'm curious about the removal of reference-counting. That would mean you'd have to use a `with` statement everywhere that you currently rely on objects cleaning themselves up when they go out of scope. Could get very messy for PyCUDA/PyOpenCL which rely on this fairly heavily. 
No, it simply means that Python would eventually use a more modern GC system, similar to virtually every other significant VM today.
Even modern VMs have issues, following the [Mono project's](http://mono-project.com) with [SGen](http://www.mono-project.com/Compacting_GC) there are still a lot of intricacies (at least from my understanding) in keeping tabs on objects for collection. That said, Objective-C is the only other major language/runtime that I can think of that still relies on refcounting
I would rather have it as a drop-in replacement for the old urllib instead of yet another api. Also, the retry mechanism is not very robust and will eat up error/exception details. The retries should be handled by the programmer not the library.
Connected to Stranger 2 Connected to Stranger 1 Stranger 2 is typing... Stranger 2: hello Stranger 1 is typing... Stranger 1: hey Stranger 2 is typing... Stranger 1 is typing... Stranger 2: asl? Stranger 1: 17 female usa Stranger 1 is typing... Stranger 2 is typing... Stranger 2: 21 f Texas Stranger 1: coolio Stranger 2 is typing... Stranger 2: you? Stranger 1 is typing... Stranger 1: CO Stranger 1 is typing... Stranger 2 is typing... Stranger 2: oh sweet Stranger 1: haha, i like it at least Stranger 2 is typing... Stranger 2: that's what matters :-) Stranger 1 is typing... Stranger 1: yeha, for sure Stranger 2 is typing... Stranger 2: pic? Stranger 1 is typing... Stranger 1: sure Stranger 2 is typing... Stranger 1 is typing... Stranger 2: may I see, please? Stranger 1: can i have yours first? Stranger 1 is typing... Stranger 1: and i'll send ya mine Stranger 2 is typing... Stranger 2: http://i278.photobucket.com/albums/kk10 … 134433.jpg Stranger 2 is typing... Stranger 2: yours please? Stranger 2 is typing... Stranger 2: :-) Stranger 1 is typing... Stranger 1: http://photos-d.ak.fbcdn.net/photos-ak- … 4_2978.jpg Stranger 2 has disconnected. Disconnecting Stranger 1
Nobody expects the Spanish Inquisition!
Well sure, but in "a more modern GC system" you can't rely on objects getting cleaned up immediately. Your objects will get cleaned up eventually, at some non-deterministic (or at least hard-to-predict) point in the future. What Python's got now I think is the best of both worlds, unless you're worried about performance. Which sums up most of Python, really.
It depends.
Not since Objective-C 2.0 :-) It has both (not on iPhone, though). It has even two and a half options: * Manual reference counting. * Automatic release with autorelease pools. * Generational garbage collector.
You shouldn't be relying on things being gced immediately. A stroll through jython will teach you that right quick.
Or PyPy (or IronPython I think). The simple fact is that CPython has taken the position that immediate finalization was an implementation detail since 2.5 (at least), anyone still relying on it is wrong.
I agree with this. The only thing I miss about C++ when working in Python is RAII, and the peace of mind I get knowing my resources are deterministically freed.
It would seem that Google's engineers are not in fact miracle workers. There's a reason the GIL is still there, and it's not from lack of brainpower from Guido, Tim, et. al.
For a really simple example check out this Fibonacci example... now new and improved without memory leak ;) http://github.com/ivanistheone/arXivLDA/tree/master/code/pythonext-example/ (check out also the info folder for links) For something more intense -- check out: http://pages.cs.wisc.edu/~andrzeje/research/cvb_lda.html which is a VERY well written python extension that shows a lot of pointer juggling and usage of most of things from Python.h ... (he also uses some NumPy arrays) 
Don't get me wrong; I know I'm relying on an implementation detail. I'm just pointing out that it's a rather handy implementation detail, and I'm not the only one who likes relying on it. For most people Python == CPython anyway, and big projects often need patches to run on Jython or IronPython (c.f. Django).
Dear redditors i have been debating weather or not GIL removable was going to happen any time soon [i got two words for ya](http://www.youtube.com/watch?v=QfI5ddqyYsI#t=32) Don't get me wrong, I was looking forward to progress on GIL too, but i was right not to get my hopes up, killing GIL is hard
Doe this mean that Microsoft wont the battle? IronPython has a worst start up time that CPython, but does better in other realms for example where the code is compiled.
My understanding of the GIL is lacking I'm sure, but isn't the GIL there to prevent simultaneous updates on the same data structure? I guess my question is: is the GIL already housed inside of the target data structure? Meaning each object gets it's own lock? If not, is there a reason why that's not a reasonable compromise if we can't get rid of the GIL?
Ned Batchelder's "A Whirlwind Tour through Python C Extensions" is the absolute best I have found online: http://nedbatchelder.com/text/whirlext.html Examples are clear and straightforward; I followed along at PyCon 2009 and had a C extension module running in minutes. This is probably exactly what you want. Another good reference is David Beazley's coverage of it in Python Essential Reference, but that's not available freely online.
&gt; but isn't the GIL there to prevent simultaneous updates on the same data structure? Well yes and no. The problem is that "the data structure" here is the whole Python interpreter (GIL = Global Interpreter Lock). &gt; If not, is there a reason why that's not a reasonable compromise if we can't get rid of the GIL? As this US comment proves once again, that's *much* easier said than done.
Check out the relatively new `with` statement. It does exactly this.
Open for suggestions to reduce API suckage. Specifics?
not sure about API suckage, but how do you see this relate to httplib2? To me, pooling should be in a http client library, rather than a url library.
You should not be downvoted here for that comment. Python references are always acceptable. They *always* fly on #python.
the Multiprocessing module has drawbacks, but for data parallelism problems, it freaking rocks. 
The link changed: http://cryzed.de/?p=1
&gt;each object gets it's own lock? This is indeed an alternative, and it's been tried. However, the downside is that you will take a horrible performance hit for the administrative overhead of such fine-grained locking. Consider code like: foo.a = bar.b which compiles to bytecode like: 0 LOAD_GLOBAL 0 (bar) 3 LOAD_ATTR 1 (b) 6 LOAD_GLOBAL 2 (foo) 9 STORE_ATTR 3 (a) With the GIL, one lock spans the entirity of the operation (and more) - you generally only unlock after 100 or so bytecodes get executed. Without it, a naive approach would have to: - Lock the global dictionary - Acquire the "bar" variable from the global dict - Lock the bar object - Increment its refcount - Unlock the global dict - Acquire the "b" object from bar - Lock the "b" object - Increment "b"'s refcount - Unlock "bar" - Unlock "b" And that's only the first two lines. Double that for the assignment. This extra overhead is more administrative work to be done, and means there are a lot of sites for contention, drastically reducing the speed of python code and limiting the gains from paralellism. You pay the price even when another thread isn't actually using the objects. There *are* improvements that can be made - cleverer compilers can hold locks for longer to save acquisition cycles, and read/write locks can be used to allow multiple readers to acquire a lock when nothing is going to modify an object, but ultimately it's going to be slower because you're going to be dealing with a lock and unlock for *every* object you use. Past attempts had fairly disastrous performance - huge slowdowns for single threaded code, often not even breaking even unless &gt;4 processors were used, and even then having fairly limited gains. Some of python's internals worsen the situation (eg. refcounting neccessitates a lot of overhead with this approach, because even taking a reference to an object is essentially a modification under the covers) Cleverer approaches, or radical reworkings are needed to avoid such speed hits (this is why moving to a new GC strategy is usually part of such plans)
I need someone to integrate this into mechanize. If I run a crawler with Python which internally uses the mechanize module it usually kills my router. I think this could be avoided by reusing already opened sockets.
I need someone to integrate this into mechanize. If I run a crawler with Python which internally uses the mechanize module it usually kills my router. I think this could be avoided by reusing already opened sockets.
Can't right now: &gt; Maintenance - upgrading hardware. Service will be restored back to normal today. But with the knowledge from my blog post, why don't you simply try it yourself? Things that should help you getting started are Wireshark, mechanize and Python (duh!).
since its made for concurrent usage, how does it compare to the http client of twisted
no. Also, if you did, do it again with Omygle please :D.
Any one knows why the safe-thread effort to implement Recycler is a dead end? They mentioned that performance degraded, but why? Is it because of Recyler itself, or some sort of impedance mismatch?
My goal for urllib3 was to create an efficient, simple, and minimalist library that is super easy to use and extend. The entire codebase is under 400 lines of code (the real meat is about 200ish). Comparing to httplib2, which is over 1,000 pretty scary lines... Looking at how httplib2 is written, it appears to cover more corner cases and has more features (more robust), but it looks harder to extend, may have unexpected sideeffects (memory leaks due to caching), and overall less light-weight (not to mention not thread-safe). For example, adding a caching layer to urllib3 is just a matter of extending HTTPConnectionPool and overriding the urlopen function. In retrospect, I could have made a better hook for that specific scenario, maybe for version 0.4. I like the idea of a "pool of pools", but I think the requirements for that are very specific to what your use scenario is so it'll be hard to create a unified metapool container. I very much welcome patches, though.
Yes! Webpy is unbelievably simple, easy to use. A serious framework with little start-up time.
Well I would say I did not see that one coming, but everybody who came to Python before Django had to note at least few failed attempts that were not initiated by dim-wits. They all did fail for a reason. C'est la vie.
I think py3k's fix for this issue is long overdue. When writing exception handlers, I can never quite remember the syntax, so if I care about the contents of the exception (beyond the type), I'll go look it up. I've never been bitten by this particular gotcha, but I can see how you might think Python would accept a list or tuple of exception types for a single clause.
Except when you go to the [relevant docs page](http://docs.python.org/tutorial/errors.html#handling-exceptions) you get it explained around third code snippet. I know, I know, documentation is for those lame people who are unable to bend the reality to their vision of it. And tuple comma magic? Gosh, I really hope he doesn't see that shorter set notation added in Py3, because that will make him dizzy.
still why urllib3 if its actually a http client
Thank you!
I like the use of NumPy arrays, as it's related to what I'm interested in doing.
*snort* What's happening, Verah?
Heck, a stroll through almost *any* language using garbage collection makes it *very* clear that you should separate cleanup (closing files, freeing up unmanaged memory, etc) from finalization.
*Scratches head.* But I implied that I did do it with Omegle. It's the shortest Omegle bot I did. It uses pyaiml and it's under 50 lines.
Previous to 2.5, you had RAII in CPython (which is all most people cared about) that works exactly like C++. In 2.5 it still works, but you should use WITH instead, which works like RAII, but is more obvious, and future compatible.
I was referring to the limitation of a pool to one domain. I'm not so sure that the desire for easy cross-domain downloading is specific to a certain use case -- downloading from multiple domains is incredibly common, and it could be optimized to use very little extra resources if you stay on one domain. httplib does this simply with a dictionary of domains mapping to connection objects (Http.connections), and a few extra dictionaries related to authentication and HTTPS. You're also probably right in the sense that the algorithm for how many connections to keep open and when to expire them will probably not be optimal for everyone, but I think it'd be good enough for most, and would save them all from having to reinvent it themselves.
I always find my GIL disappears quite fast, especially in the beginning when I'm loading up on armor and potions. This isn't normal? /meta funny nostalgia game reference
I've used the with-statement extensively since 2.5. I'm nearly certain that it doesn't provide the guarantees that you claim. Specifically, I was disabused of this notion when I tried to use some CPython code in IronPython that closed a file and then re-opened it at some indeterminate time later. Sometimes this would fail randomly because the GC had not yet released the resources. Anyway, if I'm wrong I'd be happy to learn something new - do you have a source?
Er. His point was _exactly_ that it's nice when you don't have to consult and memorize the documentation for every language feature. Also, he mentioned the Py3k set literals. Also, he concludes by saying that in Py3k his original mistake is syntax error, and that's a Good Thing.
I'm not able to crawl through documentation right now, but I'm pretty sure it's as reliable as the `finally` keyword.
&gt; Previous to 2.5, you had RAII in CPython RAII in CPython in the sense that resources were reference counted, and you could rely on the resource being released immediately upon ref_count dropping to 0. Correct? But this was never part of the Python language, only an accidental feature of one implementation - and it's considered poor style to rely on it. &gt; you should use WITH instead, which works like RAII, but is more obvious, and future compatible Please see my response to mackstann. Don't get me wrong - I use the with-statement often and I really love it (it is an instantiation of a Common Lisp idiom that I really miss in other languages) - but to my knowledge it does not provide any guarantees about when resources will actually be released. Again, I'd be happy to learn otherwise.
Hmm - actually let me retract my statement slightly. This was a while ago and my memory is fairly vague. I seem to recall that explicitly calling the file object's close() method resolved my issue. With-statement can certainly guarantee that close() method gets called - and it seems that calling close() should flush the file to disk and release its handle. So certainly for files, using the with-statement is reasonably equivalent to the RAII idiom. Perhaps this is true of most (all?) other resources as well.
Works for me. Maybe Github was down temporarily?
or a difference in priorities.
And my point is that it's a rather synthetic case, that's obvious to anybody who looked at the docs prior to attempted use of try-except. And of course if you did serious error instance catching/recovery at least once you will never ever do that mistake again. To me it's just another ,,oh, it's not working as I thought it does!'' blog post. It looks like yet another ,,so you're new to Python and did not know how we do things in this part, but now you know, great.'' You got me, I've stopped reading after the tuple case, one more paragraph and I'd reach the set thingy. And yeah, it may be a Good Thing (tm) like all the other small fixes, but at current rate we'll be reading about this a few more times before 3.x becomes a standard of any kind.
What's your distinction between a url library and an http client? Or for that matter, a url client, or an http lib? The way I looked at it... httplib is a pretty low-level module that is used in both urllib and urllib2. urllib3 is again built on top of httplib and provides features in the same vein as urllib and urllib2. Urllib3 seemed to make sense, though I agree it's not the least confusing name out there.
did you notice this post was removed. i had to find it from previous comments.
Twisted operates asynchronously and lets you efficiently multiplex lots of transfers on multiple connections at once in a single thread. urllib3 operates synchronously, but can have multiple connections open to a server that get used in separate threads. I'm not sure how their functionality compares with regard to more obscure aspects of HTTP, but they both seem less robust than httplib2 in that sense, although httplib2 is neither asynchronous nor thread-safe. But httplib2 has a cache, which makes it far faster in some circumstances, even in a simplistic sequential download process. So for now, the choice is a matter of tradeoffs.
&gt;huge slowdowns for single threaded code Can the bytecode be compiled so as to exclude locks completely for single threaded code? If there's only one thread it doesn't make sense to include a mechanism to aid in thread safety. The same goes for objects that the compiler can tell aren't going to be referenced during execution of the other threads. The second one sounds a little tricky as code gets more dynamic, but still would provide a _way_ to code parallel. &gt;And that's only the first two lines I don't see the utility in locking the global dictionary if you're just reading a single item in it. Maybe (and probably) wrong on that, but it seems like a single read operation is already as atomic as a lock-and-release operation is. If the nanoGil idea isn't acceptable, do you think "microGILs" would work? Meaning having a small set of locks that have control over access to a group of objects. Optimizers could try to guess relationships (these classes are going to tend to get called by this thread, so they all get grouped together, etc) to help slow down acquisition time.
I've been hearing about the GIL for as long as I've been "trying to get into Python" (I need a weekend project or something), what exactly is it? Dumb it down for me, cartoons and stick figures driving cars would work best
As the number of core goes up, the GIL is becoming more and more problematic... Because of that (and poor performance), Python risks to be less and less relevant...
Your comment should read "PHP is nowhere close to python+django/pylons/turbogears" Which is true, but not a fair comparison. you rather need to compare cakePHP/zend/etc to the python frameworks.
If you want to leverage opensource apps and simply skin them/write plugins then PHP is a great thing to know. You can beat wordpress/drupal/tons more into the form that customers want. For building from scratch, I would say that using PHP+frameworks is on a level playing field with python+frameworks. It really all depends on your audience. are you doing a bunch of crazy custom work? or are you going to be doing e-brochures and content management systems? if the latter, leverage PHP+wordpress or whatever. 
&gt;exclude locks completely for single threaded code? You can maybe do this if there's *truly* only one thread (at the cost of duplicating all the code), but as soon as a single library routine spins up a single thread, all bets are off, and you'd have to switch to threadsafe code (and making that changeover will be awkward). There's no easy way for the interpreter to know that that thread won't reach across to another module and mess with it. &gt;I don't see the utility in locking the global dictionary if you're just reading a single item in it. Consider what happens when another thread comes in and writes to the variable we're manipulating. Eg: Thread 1 Thread 2 Get reference to foo Reassign or delete foo in globals Decrement foo's refcount (Last reference -&gt; destroy foo) Increment foo's refcount (Oops - segmentation fault) Acquiring the object, and bumping its refcount must be atomic, or something could destroy it in the intervening interval. You can mitigate the contention by allowing multiple readers to access simultaneously, locking them all out only when a write lock is acquired, but you still have the locking admin overhead. &gt;If the nanoGil idea isn't acceptable It's not *neccesarily* unacceptable. Past efforts in python have had too high a cost, but Jython effectively works similarly - the various container types and namespaces are threadsafe. There's always going to be some hit, but there may be ways to minimise it. As you see above, a lot of the problem is refcounting, which requires updates to be made even when just holding a reference. With changes to the implementation, and sufficient cleverness to avoid locking when possible, it may be a solution. Unfortunately, given the story here, it looks like it may not work out so well in practice.
It's a Global Interpreter Lock. When you write single-threaded applications, it shouldn't matter to you at all. When you write multi-threaded applications where multithreading comes from doing computationally unintensive tasks, like waiting for user input or something, it shouldn't matter to you. Only when you're doing something computationally intensive in Python (WHY?) and want to use your multicore system but not in a way of the `subprocess` module, only then you should know that GIL would thwart your ill-conceived plan. And you shouldn't want to do it unless you already know what GIL is. If you're just curious: GIL forces CPython interpreter to become effectively single-threaded, with explicit thread switching, only at the points where the interpreter allows it. Which means 1) responsiveness sucks, adding a list to a dictionary is considered an atomic instruction by the interpreter, and if it takes a second or more, woe to your UI. Use `subprocess`. 2) On multicores it's much worse, since threads on another core routinely fail to acquire the GIL, when it's released and reacquired by the current holder before inter-core communication takes place. Use `subprocess`. Why can't they just remove it? Because the interpreter that can depend on the fact that it's effectively single-threaded is fast, one that can't sucks cocks performance-wise. Don't even bother thinking about that, just use `subprocess`.
/r/bitterprogrammers is that way ==&gt; EDIT: actually I just looked at some of your other comments and they are funny. Carry on
I think the important distinction is that httplib and httplib2 only operate on the HTTP protocol. urllib and urllib2 work for arbitrary urls, including ftp, local files, etc. Thus, (for whatever values of N and M), urllibN is more generalized, and would use httplibM as its backend for http:// protocols, while using other backends for other protocols. urllib3 of course breaks this convention. (Though I sympathize that it's complicated)
You could try following urllib2's API when it makes sense. Specially, make your response objects behave like urllib2 responses, so I can use urllib3 instead urllib2 w/o changing too much code. The most important thing is Response.read: I pass response objects to functions that expect a filelike object a lot (think json.load). Make responses with 4xx status codes raise an exception (manually checking the status code for errors is tedious). Put filepost in a separate library, because it's cool and it deserves more visibility.
Oh, and have you considered using github? I would have made the changes in the api I need and contributed them back if forking the lib didn't create a maintenance nightmare for me and my team. 
O(1) shallow copying? Is that even physically possible?
Hmm, this implementation should be the default one for lists, shouldn't it? I don't see any disadvantages (unless the author failed to mention them).
I'm not sure what you mean by "a maintenance nightmare", but you can easily clone Hg repositories on Google Code in a manner similar to "forking" on Github: http://code.google.com/p/urllib3/source/clones
It was proposed for inclusion in Python 3 and rejected: http://www.python.org/dev/peps/pep-3128/ &gt; After looking at the source, I think this has almost zero chance for replacing list(). There is too much value in a simple C API, low space overhead for small lists, good performance is common use cases, and having performance that is easily understood. The BList implementation lacks these virtues and it trades-off a little performance in common cases in for much better performance in uncommon cases. As a Py3.0 PEP, I think it can be rejected. &gt; Depending on its success as a third-party module, it still has a chance for inclusion in the collections module. The essential criteria for that is whether it is a superior choice for some real-world use cases. I've scanned my own code and found no instances where BList would have been preferable to a regular list. However, that scan has a selection bias because it doesn't reflect what I would have written had BList been available. So, after a few months, I intend to poll comp.lang.python for BList success stories. If they exist, then I have no problem with inclusion in the collections module. After all, its learning curve is near zero -- the only cost is the clutter factor stemming from indecision about the most appropriate data structure for a given task. Some of BList's algorithmic downsides are also listed on that page. Notably, *append*, *get item*, and *set item* are O(1) operations with Python's built-in list, but are O(log n) with BList. Also noteworthy: &gt; The BList is based on the B+Tree data structure. The BList is a wide, bushy tree where each node contains an array of up to 128 pointers to its children.
It probably copies one element and just references the others.
Hmm: In [26]: %timeit myblist[40:60] 100000 loops, best of 3: 1.6 us per loop In [27]: %timeit mylist[40:60] 1000000 loops, best of 3: 288 ns per loop This is 5.5 times slower, do you know why that is? EDIT: The blist gets about two times slower when the number of elements is 160,000 up from 1024... The list stays constant.
Hence the possible inclusion in the collections module. ;)
Yes, but taking slices is O(logn) for a blist and O(n) for a list, yet the list was faster for me... Maybe it was because the elements were at the start of the list, let me retry. EDIT: In [5]: %timeit mylist[40000:60000] 10000 loops, best of 3: 122 us per loop In [6]: %timeit myblist[40000:60000] 100000 loops, best of 3: 7.08 us per loop Hmm yeah, it is indeed dependent on how many elements there are and where...
I just took a look at the PEP (3128) for BList. It uses copy-on-write, hence a O(1) shallow copy. So you were essentially correct on that.
Yeah, just looked myself and saw that... Good deal, but it's not O(1) amortized, is it? More like O(n)?
No, I'm wondering about replacing the builtin list. It goes without saying that I'll use this module whenever I need it, and I believe it definitely should be included in the collections module. EDIT: Also, what I like about this is that I can just wrap blist() around my list's declaration and benchmark. Easy as pie.
Is it just me, or is there a typo in this sentence in the PEP? &gt; The performance for the LIFO use case could be improved to O(n) time, by caching a pointer to the right-most leaf within the root node. Shouldn't that be O(1)? It looks like without the optimization, the time is O(log n).
I would think that would only apply if the entire list was modified. Maybe it just copies individual sub trees? I'm not willing to read through a 6000 line file to figure out. ;)
Haha, true...
But, like, an actual typo. I'm almost certain that it would be O(1) performance with the described optimization.
No, it's O(1). Insertion is O(log n) though, that's the cost of copy-on-write. Oh, and also, it's not O(1) amortized, it's O(1), period.
Insertion is not the same as write, insertion is when you have [a, b] and insert to get [a, c, b]. You can argue that every write is deletion and an insertion, though, since most are on immutable elements (or does it just replace the reference to the item?). I know it's constant time, but since you pay a cost on write, it would end up being amortized to O(n) over infinite writes (or, well, n writes of different elements).
Makes perfect sense to me. List is mildly better in most use-cases, blist is much better in rare cases. Shouldn't replace list, but should be readily available.
An algorithm being O(log n) just means that for a sufficiently large N it will be more efficient than a given O(n) algorithm. For example, if an algorithm takes 10s to do something regardless of the input size it would be O(1), and if an algorithm takes N seconds to do something where N is the length of the input it would be O(n), the O(1) would only be faster than O(n) if N &gt; 10.
Is that amortized run time?
Was there a battle?
It would require special implementations for expressions like `open(filename).read()` and `open(filename).readlines()` though. Using the `open` function in this style is very common in Python and doesn't require any cleanup boilerplate, not even a with-statement.
The startup time got better with IronPython 2.6. Otherwise the only big plus I see with IronPython is that it is a DLR language which can be used in a Silverlight plugin. This means it is feasible to use Python for web client programming. No other implementation has something like that to offer.
I would welcome another object abstraction that uses urllib3 underneath but mimicks urllib2's behaviour, but morphing the underlying pool code to behave just like urllib2 would not be practical. Some of the most powerful use cases for urllib3 is for long-running API requests and web crawlers -- this means thousands or millions requests at a time. This means two things: It needs to be tweaked to each use scenario (e.g. how many sockets to allocate per pool, how many pools to cache for domains), and it needs to perform really well (even a few milliseconds of slowdown is very noticeable over millions of iterations). I've been using urllib3 for both of these scenarios, and I find the API ideal for them. To be honest, I do not use it for one-off fetch a file and save it somewhere code, urllib and urllib2 are fine for that. Raising an exception creates too many corner cases -- do you raise only for 4xx status codes? what about 5xx? what about malformed responses? what about if 4xx is expected? Also, raising exceptions performs notably worse than attribute comparisons (see note about millions of iterations). I'm glad you liked the filepost, you're welcome to spin it off as its own library (credit would be nice if you go that route).
Ah, that is a very good point. It didn't even occur to me that urllibN operate on local files (and ftp), that's neat. In that respect, I do agree urllib3 is http(s)-specific.
Re: benchmark code, for more interesting results, I'd suggest modifying it to several hundred URLs. The distinction starts to look much more significant
I updated the debugging chaper. Hope this is now more helpful!
because I just got done reading [Beyond Exception Handling](http://www.gigamonkeys.com/book/beyond-exception-handling-conditions-and-restarts.html) and had to see how far I could push the idea in Python...
I must be missing something -- doesn't a shallow copy just point the variable to the same head as another variable? Isn't that just an O(1) pointer operation? Please correct me!
That's not what amortized means. You use amortized analysis when an operation takes drastically different amounts of time in different states, and you want to determine the average over a sequence of operations. It doesn't mean "take something that's always constant time, add up that constant n times, and now claim it's Theta(n) instead of constant". 
It might be different in a language where lists are assumed to be linked lists, and therefore have a "head" and "tail". Python lists are just expandable arrays. In Python terms, a shallow copy of a list is a new list with the same elements as the old. If these elements are mutable objects, they will be copied by reference (in other words, you just copy the pointer). But the reference to the list itself is not copied. (If it were, it wouldn't be copying at all, it would be variable assignment.) A deep copy, on the other hand, constructs new copies of every mutable object in the list, recursively, so that it copies their value and not their reference.
No. http://en.wikipedia.org/wiki/B%2B_tree
I replied in more detail in [this comment](http://www.reddit.com/r/Python/comments/afin0/ever_create_a_list_bigger_than_128_entries/c0hc787), but if an algorithm is O(1), it's O(1) amortized. There is no point in doing amortized analysis on something that's already O(1). What you are referring to is in fact a constant factor. You write, and you copy. O(2) = O(1).
Oh, I thought I'm posting there already, sorry. Funny? You must've take me for someone else, good sir.
Backwards compatible. Nice! I hope the Linux version won't take another five years.
 How true is this though? With 2-4 cores or so, threading has stronger relative benefits so multi-core becomes better. With larger numbers though, it seems that CPU time becomes less and less important and the relevant limiting factor becomes *memory access* (indeed, in most ways, it already is). That makes threading less and less a viable strategy. You do **not** want multiple threads all performing updates on the same region of memory, contending for access and constantly having to expensively invalidate each others cache's. Instead, it seems highly likely that we're going to head more and more towards NUMA architectures, where each core has prileged accesss to their own dedicated memory, rather than every processor tripping up everyone else contending for access to the same region of memory. With this model, Erlang style **message passing** strategys become more and more important, where the expense of copying the memory and passing data about becomes irrelevant next to the speed gains. And **this** model, where we're copying the data anyway means that multi-**processing** becomes a much more attractive solution than multi-**threading**, which means the GIL is effectively irrelevant.
Nothing on that page suggests that. With monkey patched socket httplib2 will see the socket as if it was a regular blocking one, so no special support for async sockets from the library is needed.
Totally incoherent rant. Also, largely misinformed, I'm afraid. And with lots of ellipsi! OK, QT and glib use atomic operations for refcount manipulation, so what? The fact that it's a single assembler instruction (wrapped in a spinlock) doesn't prevent it from stalling the processor for ~500 cycles for a main memory roundtrip. It doesn't matter when it's used for huge QT objects, but it sure as hell would matter when even `None` is refcounted! Then there are other optimizations. A lot of them. Thanks for listing a lot of them. Somehow every single one mentioned is completely orthogonal to the issue. I don't even understand what's the author's point -- let's take 4x slowdown by removing GIL and then try to speed things back by reducing memory footprint etc? Why not just speed things up by reducing memory footprint etc instead? Then, you can't "remove GIL incrementally". Either you change `None`'s refcount each time you touch it, or you don't use `None`. "Freeing" a piece of code from GIL means rewriting it in pure C, with no calls to the interpreter. I don't think it's the way Python is headed =)
How do you make this work on linux? 
Its good. Really good. Been playing with it for the last few hours. Its a shame that all the CoreImage and Core* libraries wont work (This version is cross-platform, so can't depend on Apple libs)
Cool. Now add unknowns to the framework so it can do Minesweeper!
Hmm right, so it's only complexity of the same operation... This implementation of blists means that you pay O(1) to copy, but writes cost more...
The algorithm being O(n) would mean that its complexity is only dependent on the number of elements, in this case... Slicing complexity is also dependent on the slice, so I'm not sure that that complexity shouldn't contain an m...
&gt; replace the list with the B+tree. Why? They are different data structures If the B+tree has "good enough" performance in all cases, then why bother with a list and make people choose. There should be only one way to do things in python, if you have to make a choice that means there is more than one way. Now (at the time of the rejection - some of this has been fixed since) there are cases where B+tree are not good enough, so they had to give us a choice. 
Tuple, set, and list should _always_ be very different...
what do you actually do with it ?
Maybe I'm not following your distinction between writes and insertions, but this implementation looks like it actually costs less to insert ( O(log n) ) than a normal list ( O(n) ).
what's this ?
Me too! Looks awesome, really.
&gt; generative art using procedural graphics
Funny, that's what I'm doing right now. But I'm going to try to get it integrated into httplib2 so it's not a nightmare for each person to re-implement.
Well i did this :-) http://farm3.static.flickr.com/2797/4192470917_4f51d4931c.jpg
&gt;There should be only one way to do things in python We say that, but what we really mean is "fuck, Perl is disgusting (inorite?) Let's never go down that road." Programming is problem-solving, and as such a language can never really prevent there being more than one way to do things.
The point is you still ought to have to do O(N) such variable assignments to multiply a list, so clearly the BList is doing Something Weird.
i meant something "productive" :)
Cool, thanks
Insertions there are O(logn) because you have to traverse a tree. There's a cost for insertion because sometimes you have to split the tree, I believe, but yeah. The thing I have an issue with is that if you just reference the root of the tree, you have to delete and insert an element when you write something. So if I have a list on a copy and I append something to that, I'd have to copy that. However, since this is a shallow copy, I guess this doesn't apply...
My point was that tuples are immutable and sets have no ordering.
Um... it works on sequences :) But I think your point is valid: if all you're changing is the contract of the interface, you can reuse a common implementation for 95% of the code.
*thinks to self* hmm... he can handle jokes too Here take an upvote
I spoke with some of the US people and they said that both they and the safe-thread guy thought the issue was due to too much cache pressure. Me and another guy are thinking about retrying the experiment but also moving the refcount field out of the PyObject struct itself (similar to the strategy that Ruby EE used to fix the COW issues in the Ruby GC), the idea is that this could reduce cache pressure since only 1 thread will be writing to the ref count object, while current it's in a struct that many threads could be touching (this could be especially problematic on things like the builtins dictionary). 
If the blocking libraries you're using are pure Python then they'll work with [gevent's](http://gevent.org) monkey patched socket.
I hate to be a pedantic prick*, but wouldn't it be Django + Orbited + Twisted = Real World, Real Time web apps? *Actually, I quite enjoy it...
I also hate pedantry as much as anyone else, but since when is equality not [symmetric](http://en.wikipedia.org/wiki/Equivalence_relation#Definition)?
On ubuntu karmic: sudo m-a a-i tp-smapi sudo modprobe hdaps cat /sys/devices/platform/hdaps/position (-419,-498) (so, replace getXY with something that opens and parses that...)
So after Unladen Swallow produces bad news the bets are on PyPy again?
Well, yes, but... returning -1 in the error case is probably not what you want. What if you pass a list that happens to have -1 (a valid int) as its third element? It would look like an error. Ugh. Let exceptions propagate. Use them to signal out-of-band information, like they're intended, and handle them at the point where they can be handled. Interfaces like the one described belong to functions with names like "atoi" in languages with similarly cryptically-short names (*cough*).
Why? Unladen Swallow won't remove GIL from CPython. Were there any other bad news in their camp?
I'd think it's assignment. Real world, real time web apps = Python with Django, Orbited, and Twisted.
Ok, but then you moved the "with Python" part to the wrong side of the assignment.
What?
The only way to cure flu is to nuke the patient from the orbit. I mean -- it's the only way to be sure.
That's funny, my girlfriend said the same thing (put a "=" instead of "equals")... maybe I should have listened :-)
Not sure why you are getting downvoted, I'd be interested in something like this too. Mostly what I've seen, python doesn't really directly integrate into a browser like JS does. Most graphical python solutions I've seen generate image files. I'm not an expert on this by any means, but the best you can do as far as I know is generating an image on the server and sending that as a png/gif/jpg using normal HTML. I don't think that's quite what you are looking for.
&gt; ahh i don't even have thinkpad :)
For 3D, we made [this](http://www.web2py.com/p3d). It is a python module (we ship it as a web2py component but does not require web2py) that exposes one objects with primitives like make line, make sphere, make triangle. If generates processing.js code that draws the objects on the canvas. It includes algorithm for generation of iso-surfaces from a scalar field. It is pure python without dependences. 
I am very impressed. Not exactly what I'm looking for, but I'll investigate further, for sure.
&gt; Unladen Swallow won't remove GIL from CPython ... which makes the project pretty much obsolete and one can just stick to Python + Psyco.
It runs on Linux but we don't provide official packages yet. In added build instructions for Linux on the [download page](http://beta.nodebox.net/wiki/Download). 
On 32bit x86 and with features of pre 2.5 (psyco does not like new things, like generator expressions)? Yeah, you kind of missed that, haven't you? Targeting JITed LLVM is not worth mentioning, right?
Thats a load of bullshit there mate, i professionally used php for over 5 years, including BIG (like 500k) users sites pwered with Zend Framework. I moved to python and pylons completly and i did not write a single line of PHP code in 9 months now, so that "must" argument is nonsense in my opinion. And trust me no one who uses dedicated server or cloud computing gives a damn about "ease" of deployment, when you build a big system for his company ;-)
Here's the rest of it; needed an axis-reversal too... #!/usr/bin/python # linux version of http://code.activestate.com/recipes/576985/ # (via reddit) but drop the windll stuff import time import turtle import sys hdaps_file = "/sys/devices/platform/hdaps/position" def current_pos(): """Get current position from the file""" pos = file(hdaps_file).read().strip().strip("()") return map(int, pos.split(",")) def getXY(): raw_x, raw_y = current_pos() return raw_x / 10.0, raw_y / 10.0 def done(_x, _y): print "done!" turtle.bye() sys.exit() def main(): centerx, centery = getXY() turtle.pensize(3) turtle.onscreenclick(done) while 1: x, y = getXY() turtle.left(centerx-x) turtle.forward(centery-y) time.sleep(0.01) if __name__ == '__main__': main() 
This is awesome.
Oh! Wow. That's great, thanks for your excellent work!
The point is that the "more" here is still O(1). When you use big O notation, you're stating "I don't care about constant factors, I just want to know how the running time grows as the input gets really big". Given that in this thread you apparently *do* care about constant factors, because you keep saying that writes "cost more", it's meaningless to throw around terms like O(1) as you do so. 
Thanks!
This looks familiar. Either there a similar PEP, or another language has the feature. The obvious problem with your suggestion is that you can't use on the RHS any variable whose name is already in the dictionary being used.
Actually, what is the use case here? What you're describing (at least the LHS) is what modules already do, using module.__dict__.
A more intuitive (at least cleaner syntactically) way for, say, URL mapping in web applications springs to mind: using map_urls("/foo/baz"): ... But you are right about the RHS thing... Hm.
'/' isn't valid in an identifier, so that wouldn't work either.
Why do you assume I'm referring to constant factors? In this case the factor **is** constant, but writes could have gone from O(logn) to O(n).
Any particular highlights worth a mention?
http://www.reddit.com/r/programming/comments/agpw7/scipy09_peter_norvig_keynote_what_to_demand_from/
... That name again, it's MisterWebz.
I misunderstood what you meant the first time I read this. I now believe that you meant to put just single path elements in the assignments in that block, so my comments about '/' being invalid was meaningless. However, most other characters that you might want to include (such as . ? + * etc if using regexes, or &lt; &gt; and : if using Werkzeug routes) would be invalid. Also, how would you map the root URL? map_urls("/"): whatgoeshere = ... Y'know? 
"Could have"? They didn't, if we're still talking about list vs. BList. Writes went from O(1) to O(1).
Yeah, don't mix and match your operator lexicon.
How are writes O(1) in the BList, since it has to traverse the tree to find the element to write to? That's O(logn) it seems to me.
You can already do that very nicely with "with" - see [DRY up your routes - a Pylons routing refactoring](http://positiveincline.com/?p=561) (hot off the press today). See also Douglas Crockford on a similar feature in JavaScript: [with Statement Considered Harmful](http://yuiblog.com/blog/2006/04/11/with-statement-considered-harmful/) 
Or Python 3.1.
Well I've got to say this was actually a valuable use of my time for once. I've been using python for many years now and it doesn't surprise me anymore, but I was baffled by the logic error in the code. Good job author. 
[Previously submitted article has been previously submitted](http://www.reddit.com/r/Python/comments/af5c3/python_surprise_me/)
Normalize your URLs before submitting it to reddit.
no
I dont know how
Have a job, in which you have a project, with python-satisfiable requirements, and a manageable deadline. Failing that, have an idea. Failing that, I have no idea, but you could always go from reading books to reading through a few non-trivial open source python programs to see how they do things. I was in the same position, of wanting to try out python, but not knowing what to do with it (aside from rewriting other apps). I just found the perfect project a few days ago. :D Good luck!
Really? The one surprise of `except A, B` is why you use Ruby? That's the only reason? Why are you hanging out on `/r/Python` to tell people about why you use Ruby?
The first thing I would do is find a non-trivial working open source program and tear apart the code. Python has some conventions and idioms that are best understood by seeing the work of your betters in the wild. And I wouldn't just read the code, you need to hack it. Since it is readily available and does something we all understand pretty much, I would go with idle. Add functions to it. Have it talk to other stuff. Learn to really get how it does everything it does. I personally don't like tk at all, but that is beside the point. The ideas of how and when to interact with GUI components are easily translatable across specific GUI libs. And if you are doing system or web stuff, which 90% of the people I know actually using py for their jobs are, the GUI toolkit is an unimportant detail anyway. Only after you really get how idle works and how good python coders write a non-trivial application would I move into working on your own non-trivial programs. I would also recommend the book Programming Collective Intelligence, by Toby Segaran. Not particularly because the book is that good an introduction to machine learning techniques, or particularly good for learning working python as such (even tho it is good enough at both), but because the examples that are used in the book are bits that really, really lend themselves to being expanded into more substantial programs. You can see pretty clearly how they do what they do and they just naturally suggest more substantial projects to your mind as you are working with them. Plus, the book introduces you to a few tools you will definitely be using if you do any non-trivial python coding: beautiful soup, SQLite, Universal Feed Parser, etc. Python is a lot of fun. Good luck in your process!
Write (data structures) algorithms (for example, avl tree) in python for fun ...