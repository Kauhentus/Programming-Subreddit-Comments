You'll have to go back through the thread. Originally, I said: &gt;But what happened to jacobian, ubernostrum, etc? They don't seem to be able to stand having any scrutiny applied to their arguments. In your reply, you defended these guys. If you no longer wish to do so, then I guess we can agree on something. :)
&gt; In your reply, you defended these guys. If you no longer wish to do so … I am fulling supporting jacobians post. I haven't read the rest, so no comment on that.
I'm pretty sure YouTube base64 (urlsafe version) encodes an integer.
base64 strings *are* integers, in base 64. This module generates UUIDs with arbitrary alphabets, and I'm not claiming YouTube's IDs are UUIDs (they're not). It also removes similar characters so people can type them in unambiguously.
Quick, someone whip up a trophy gif we can put on python.org!
Looks like it has been taken down :)
I'm a bit confus Is the idea that you get 'random looking' IDs?
There must be a way to find these circular refs and break them manually when they appear. I see Genshi had this problem and you have contributed to their discussion.
No, the idea is that you get non-sequential, globally unique IDs (no clashes) in the shortest string possible.
If you are referring to [this ticket](http://genshi.edgewall.org/ticket/190), that was an actual bug in Python itself. Unrelated to the garbage collector's inner workings.
Or try PyPy
I always get slightly annoyed when they say "easy to learn". I get it's meant as a compliment. Buy once you know most fundamental programming patterns any language is easy to learn. I'd much rather they said something like. It's a very clean and concise language suitable for people just getting into programming. Basic was easy to learn.
This is pretty neat, although it's primarily an arbitrary base converter (which is still neat).
It appears so. :( I was looking at pyglet before Arch switched to Python 3, which looks really nice, but it unfortunately doesn't support 3 either. However, there seems to be a library named pgreloaded (successor to pygame) which I will probably try. Of course, I could simply use Python 2, but I'd like to start getting my hands wet in 3 and learn how it works.
is it celery? or is it carrot? http://nova.openstack.org/devref/rabbit.html#rabbitmq-gotchas
language that had the biggest percentage market share gain. still a far cry from C/C++ and java :( still.... YAY
That's actually pretty good. The reason I asked is because Haml is about 2.8 times slower than erb (2009: http://nex-3.com/posts/87-haml-benchmark-numbers-for-2-2, without options[:ugly] turned on) And yes, I agree with using the Genshi test suite. Then Nemo can be compared side-by-side with other templating languages.
Not aware of any. Howeer, [CLRS](http://www.amazon.com/Introduction-Algorithms-Third-Thomas-Cormen/dp/0262033844/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1294517008&amp;sr=1-1) and [Algorithm Design Manual](http://www.amazon.com/Algorithm-Design-Manual-Steven-Skiena/dp/1849967202/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1294516969&amp;sr=1-1) are both great algo books I'd recommend.
&gt;&gt;In your reply, you defended these guys. If you no longer wish to do so … &gt;I am fulling supporting jacobians post. I haven't read the rest, so no comment on that. No, I meant read through the thread between you and me (that's the thread I expect you to be paying attention to) -- that's where I complained about guys like jacobian and ubernostrum making claims without backing them up and then bailing on the conversation when they are challenged. And _that's_ the behavior you defended. It wasn't about your defending jacobian's original post (which is rather indefensible), it was about your defending his unwillingness to (a) acknowledge clear mistakes that he made and (b) respond to follow-up questions and challenges to his arguments. It's hard to take someone seriously when he claims he cares so much about the Python community and then runs away from a conversation with the very people he is criticizing for "harming" the Python community. It is ironic that Jacob accuses Massimo of having a "persecution complex," and yet [here](http://www.reddit.com/r/Python/comments/ex54j/seeking_clarification_on_pylonsturbogearspyramid/c1bp8ru) (and [here](http://www.reddit.com/r/Python/comments/ex54j/seeking_clarification_on_pylonsturbogearspyramid/c1bp9tw)) is Jacob imagining he's being called "nefarious" and "underhanded" when he has been called nothing of the sort. If anything, this is what hurts the Python community, not web2py using exec or lacking a few import statements.
Python isn't just easy to learn, it's easy to _use_. I don't think you could say that about Basic (nor about many other languages out there). This is a very important aspect of Python's philosophy. There are several things that make Python not only easy to pick up, but worthwhile to continue using: * Lightweight, interactive interpreter for experimentation * Systematically thorough documentation (online and via the help function) * None of that "there's more than one way to do it" garbage * Words instead of punctuation to represent most concepts * Evolution toward regularity in pretty much everything * A module or package for just about everything To dismiss this because with more effort you could learn other languages is to ignore _why_ Python has climbed steadily in popularity over the years. I know that in my case, once I learned Python, every other language since has felt like it was lacking -- and I was certainly not a noob when I learned it. 
[Python Algorithms: Mastering Basic Algorithms in the Python Language](http://www.amazon.com/Python-Algorithms-Mastering-Basic-Language/dp/1430232374/ref=sr_1_1?ie=UTF8&amp;s=books&amp;qid=1294517882&amp;sr=8-1) by Magnus Lie Hetland (also author of my favorite introductory python book, Beginning Python). has a lot of focus on graph algorithms.
I always feel like Python generally gets dismissed, because other languages typically get favored on the various platforms-du-jour (with the exception of AppEngine!). That people continue to steadily pick up Python is impressive. This renews my hope that I can continue to work without having to waste too much of my mind and time on crappy languages. Still, I hope that someday Python can make inroads into some juggernaut of a platform. Objective-C has had its chance with mobile phones, but Apple's walled garden is probably going to keep it from growing any further. I'd like to see Python as a standard feature of web browsers (instead of Javascript :P) on both mobile and desktop devices someday, but I can't imagine how that could happen. A programmer can dream, though...
Very good book. Recommended. 
Upvote because it's good to know about new packages. As for Attest itself, a better comparison to unittest, nose &amp; py.test would be more compelling than soft claims that unittest is awkward and nose/py.test are magical. Currently my main impression is that it was written because the authors wanted to express their tests in a particular way. That's a fine reason to write a library, but not a good reason for me to switch. 
It's worth noting that although it is full of complete, working python examples, the exercises given at the end of each chapter definitely lean toward the theory side of things. if you're looking for something that just gets you coding algorithms with python this will work, but it is more interested in getting the reader to understand the implications of using particular algorithms, developing new algorithms, and really understanding why certain problems are difficult and how symmetries or assumptions about structures can make them more tractable. for example: exercise 5-3: if every node in a directed graph has the same in-degree as out-degree, you could find a directed euler tour. why is that? how would you go about it, and how is this related to tremaux's algorithm? exercise 9-5: why can we be certain that the adjusted weights in johnson's algorithm are nonnegative? are there cases where things can go wrong?
Right, so I recommend you stick to multiprocessing.pool, and in the future you can use Py3k's concurrency models. Libraries in the standard library are generally drastically easier to use.
Uh, yeah that was my point. Zeromq has a lower level (by necessity) approach.
All three rely on names to tell tests apart from other objects, a form of string programming. At least nose and py.test use implicit test discovery and unittest2 supports it as does unittest via distribute. This too works via significant naming. In practice, whether this is problematic is debatable. But in most if not all other cases it would be considered bad design from a Python perspective. Why should tests be any special? As for switching, I don't suggest rewriting existing test suites of some size, but for new projects Attest might be a candidate testing tool for some people.
Yep, I had the UUID problem specifically, though, so I bundled that in. You can extract the four lines that do base conversion and use them, though. Maybe I'll split them myself.
i also have that dream.. but i think there is a project that can do python to js conversion on the server. cant remember the name. 
I think you're looking for [Pyjamas](http://pyjs.org/).
The Assert() class is too clever by half. I read that at first and thought it was a weirdly cased function.
Plain ol' operator overloading. Not that clever. Also optional.
This is nice but Nose's capacity for extensibility, including that you can define any scheme of test discovery you want, should not be discounted.
Objective C more than doubled its share which looks to me to be more significant than Python growing by 40% of its previous share. Discarding some outliers in 2004, Python seems to be growing around 0.6% per year.
For me it is [Programming Collective Intelligence](http://www.amazon.com/Programming-Collective-Intelligence-Building-Applications/dp/0596529325). It is fun to read and easy to understand.
Exactly my point. Just saying it's easy to learn doesn't do it justice. Basic was easy to learn. Python is much more than that.
I don't mean the implementation is clever. I mean it's not obvious what's going on when I read it at first. These Assert objects, what are they? We can test the equality of Assert object? That's strange. I don't care that it's optional, there should be one obvious way to do it. 
&gt;All three rely on names to tell tests apart from other objects, a form of string programming. This always felt wrong to me. Coincidentally I recently noticed that the default regex that does the matching in nose is [somewhat broken](http://code.google.com/p/python-nose/issues/detail?id=335).
Better Python than almost any other language. Most popular languages are nowhere near as sanely designed.
http://www.amazon.com/Introduction-Algorithms-Second-Thomas-Cormen/dp/0262032937 It uses pseudocode, not Python, but really, don't worry about the programming language your algorithms book uses. An algorithms book using very language specific features like generics, templates, blahblah would be an awful book, and if you're not doing very language-specific things, the language for showing the algorithm isn't important. Really, just put the algorithms first when considering algorithms books.
Objective C has a huge limitation: Very few people use it. The only reason that it isn't in the "Other Languages" area is because Apple forces i* devs to use it.
sounds an awful lot like [brownie](http://packages.python.org/Brownie/), a fairly new "utilities library maybe this two projects should merge or something.
Not an algorithm book in the traditional sense, but: O'Reilly's "Programming Collective Intelligence: Building Smart Web 2.0 Applications" 
Except the built-in multiprocessing.Pool class is kind of hacked together. The syntax for the map function differs from that of the built-in map. Takes a single iterable for a single argument function, rather than the built-in which can take multiple lists. Also the Pool map (and apply) can't use lambda functions, which is the most common use of map (at least for me). Also Ironic you mention a 48-core machine, our lab just picked up a couple this last semester.
I'll one up you `:)` from withhacks import * class loop(CaptureFunction): def __init__(self, times): self.times = times super(loop,self).__init__() def __exit__(self, *args): ret = super(loop, self).__exit__(*args) for i in range(self.times): self.function() return ret xs = range(5) with loop(5): print "hi everyone", xs.pop() Result: hi everyone 4 hi everyone 3 hi everyone 2 hi everyone 1 hi everyone 0 This is using [withhacks](https://github.com/rfk/withhacks).
What level of abstraction are you looking for? Do you want access to game related hardware (screen sound) or are you looking for a full out engine? Not sure if you know how to code in C but if you have specific needs you may look into taking some C libraries and wrapping them up for use in python (or using python from within a C application)
I used these two books to get me up to speed before training for [ACM ICPC](http://en.wikipedia.org/wiki/ACM_International_Collegiate_Programming_Contest). Highly recommended.
Not ironic... its the standard commodity workhorse right now. quad processor machines are the largest that are generally available 12 cores is the most offered by AMD 48 core setups are best sellers according to Dell
I don't understand this criticism: "Pytest is powerful but also the most magic of all options. This is not a concern for everyone, but if you prefer to be in control of your tools then Attest might be for you." What does magic have to do with being in control? In fact, I would say py.test is the most in control because it's built from the ground up as a plugin system.
Any reason that the alphabet doesn't include 0 and 1? 
thnx
A very good book that covers all of the fundamentals and then some (like data structures, which can be argued as something that needs to be learned together with algorithms) is [Problem Solving with Algorithms and Data Structures Using Python](http://www.amazon.ca/Problem-Solving-Algorithms-Structures-Python/dp/1590280539).
You've mentioned it but Pygame is currently being rewritten (called [Pygame Reloaded](http://code.google.com/p/pgreloaded/)) and it supports Python 3.x. It's currently in alpha, but since you only want to learn how it works and don't want to do anything super serious (presumably), I would recommend checking that out. It's been stable for me, so far.
Because letters "O" and "l" (small L) looks very similar to 0 and 1
Why do you compare radix sort and quicksort when trying to downplay the validity of asymptotic analysis? The running times of radix sort and quicksort don't just vary by constant factors; their asymptotic running times are different. Radix sort isn't even a comparison sort; it will almost never be used as a general sorting algorithm. Perhaps you meant to compare quicksort with another O(n log n) sorting algorithm like heapsort or merge sort. Indeed, quicksort often performs with lower constant factors than other O(n log n) sorting algorithms, especially with input that requires relatively few swaps.
This seems like a problem you need to debug line by line. Somewhere, temp_date and and your class variable date are being reassigned in reverse order. Otherwise, date shouldn't change beyond the the class constructor.
i have rewritten this class a few time and still get the same issue. i will give the debug line by line a try
1. date is a class attribute, not an instance attribute. define it on 'self' in \_\_init\_\_. 2. passing self.date as an argument to getdate does not magically copy it, so all your lines that fiddle temp_date are also fiddling date. maybe explain what the code is meant to do? it is pretty convoluted (I get the feeling you haven't seen the datetime module).
"passing self.date as an argument to getdate does not magically copy it" thank u very much. solved it with temp_date=copy.deepcopy(temp_date)
if you explain what you're trying to do, there is likely a much less ugly solution :) copy.deepcopy is extremely rarely used in python.
i am passing the dates as params into a web crawler.
I mean, more broadly. Using lists to hold dates is silly, since you end up doing your own comparisons. Perhaps point us at your github/launchpad/whatever repository. You also might want to have a look at scrapy.
i wish i could but most of the other code is "sensitive" =/ its not really holding "dates" so much as its holding parameters that change. the best way i could explain it is the web crawler is indexing information that is store in a web database, the data on the website is accessed by posting some parameters into a html filed. there are about 15 total parameters =/ if i was just interested in getting date information i would just use datetime. but it is a little more complex than that. to tell u the truth i feel kinda ashamed i forgot that b=a, b is just referencing a, and doesn't equal a
We used this book this past semester, it's quite terrible. I spent a majority of the semester rewriting the code in it. I'd stay away from this one.
What exactly didn't you like about it? I thought the way it explained concepts was great, especially if you were a complete beginner.
I'm sure I have specific examples laying around here somewhere, but just in general, it was blatantly obvious that it was written by C++ programmers, (see the quicksort code off the top of my head, which python does quite elegantly in 4 lines of code, compared to what I remember to be some hideous monstrosity of translated C++ code). It also dumbs down or altogether leaves out fundamentals of algorithms analysis at times. Ultimately, it's just not Algorithms in Python so much as Algorithms that so happened to be translated into Python. (Not that such things aren't altogether uncommon)
Essentially, all I am looking for is convenient graphics and sound access.
Honestly I'm quite unsatisfied at this point with what's out there. I haven't taken a look at the Hetland book that's been linked, but I've been casually looking into writing one, that's how unsatisfying I've found the current stuff. If I had to use one (and I probably will again), I'd probably have to go with [Preiss](http://www.brpreiss.com/books/opus7/html/book.html) (which is quite old, but the pickings are scarce like I said, unless that Hetland book is any good), or even something not presented in Python like perhaps CLRS, and rewrite the code before the semester started.
Thankfully, I've got the book on hand and looked up quick sort just now. I can see what you mean when they don't do it the pythonic way, however, at the same time they spent a good full 2+ pages explaining quick sort. They then proceeded to translate the concept from words, into code. Yeah, the final product isn't pythonic, but you could definitely make the argument that they were trying to drive home the concept rather than show you the language's syntactic sugar.
*Shrug*. Once you're gonna do algorithms in Python, part of the beauty of it is that def quicksort(sequence): if not sequence: return [] pivot = sequence[len(sequence) // 2] lower = [i for i in sequence if i &lt; pivot] upper = [i for i in sequence if i &gt; pivot] return quicksort(lower) + [pivot] + quicksort(upper) almost says more than the words they used to explain do.
Here's the cycle that prevents garbage collection: http://i.imgur.com/9ZwQK.png `foo.__class__.__del__.__globals__['foo']` is `foo`
An upvote and a "thank you" for a fantastic product!
I am aware of how Python works, thank you.
Yep, that's it. It also omits l and I and O. Also, if you set the alphabet to just "01", the output is a binary string (if I haven't screwed anything up), but that's unrelated.
*blink* I was trying to provide a helpful illustration to other readers of this thread, not attack you personally.
I just want to add, since it was brought up below, that the reason that I'd like one "in Python" is that I'd like to see the algorithms/data structures done in a "Pythonic" way. That being said, my question would be would you say this book follows this (check out the quick sort example below)?
I &lt;3 SQLAlchemy. The ORM is great, I prefer it over the Django ORM.
Yeah, go zzzeek! :)
If your inner loop is so simple that this operation is the bottleneck then you probably have nothing to worry about.
First: Thank you for posting this. But this neglects duplicate items, does it not? quicksort([5,1,1,3]) returns [1,3,5]
I wrote it off the top of my head, but it should, yes. The reason for that obviously is that our two list comprehensions only contain things that are either less than or greater than the pivot. The easiest way to fix that I guess would be to do something like def quicksort(sequence): if not sequence: return [] pivot = sequence[0] lower = [i for i in sequence[1:] if i &lt; pivot] upper = [i for i in sequence[1:] if i &gt;= pivot] return quicksort(lower) + [pivot] + quicksort(upper) or if you weren't comfortable with a 0 pivot, either randomize your input (which you'd probably do anyways), or just do the same thing with the pivot we had before (but you'd have to do a list addition).
Awesome, Thank you! I had tried "fixing" your first example with just simply changing upper's &gt; to &gt;= but ended up with a max recursion issue. I have much to learn.
I agree with deadwisdom. I understand that the class is named Assert because you can read `Assert(2)==2` as *"assert that two equals two"*. However, since assert() tests it's argument and I've spent years using it, I instinctively read it as *"assert that whether two is true equals two"*. I'm sure the issue is probably limited to users like me who spent too long in the C world, using assert() to embed debug checks into the code rather than using assertion modules of TDD-targeted libraries. I will probably alias Assert as Assertable because it being an adjective causes me to instinctively regard it as modifying it's parameter instead of taking action upon it as the verb Assert implies. The rest of the library is fan-fucking-tastic! This one minor wart is really a very small issue. I can understand TDD arguments but I don't know if I buy them yet because other testing libraries have felt so backward and that I haven't been able to make myself write tests first. This library will definitely change that. Thanks!
Doing things "the right way" from the start isn't so important, but IMHO it is good to develop a habit of doing things correctly. One should only veer from best practices on occasion, and then only intentionally after some consideration.
The idea was to make it look as similar as possible to the standard assert 1 + 1 == 2 The problem with the above is that the exception message will hide the actual value of ``1 + 1`` which makes debugging failing tests more difficult. I realized past releasing the first version that it might have been better to call it ``Assertive`` and promote code such as value = Assertive(1 + 1) assert value == 2 which BTW works if you ``from attest import Assert as Assertive`` (or do ``value = Assert(1 + 1)`` because on failure Assert fails before the assert statement. To rename it *now* would obviously break backwards compatibility a whole lot, just to avoid an ``as`` import. Optimally I'd like to just use the assert statement somehow. py.test does that by somehow re-evaluating failures to get the values of variables and expressions, though this has the issue that the re-evaluation can have side-effects. I'm pondering if using the ``_ast`` module to parse tests somehow and/or hook into the "frame" is a better idea; it'd be much more complicated and arguably magic, though. Thanks for the kind words. I feel the same: testing didn't make a whole lot of sense to me, in part because of the existing tools. Attest is my attempt to remedy the situation for myself. Another important epiphany came from Ruby's wycats who promoted testing of *public* interfaces rather than internals: I could never see the value in using complicated mocks and hooks to merely rewrite the implementation as tests with at least double the code as the actual implementation. Instead, write tests for public interfaces (e.g. the API that library users will use, the output of a web page etc) and test that given input X we expect output Y. How the code does it is irrelevant. That might be what is called BDD; I don't completely understand the terminology.
I've heard Python get a lot of flak for being too "restrictive". I'm not quite sure where these people are coming from. I find the syntax extremely intuitive and friendly (IMO it strikes the right balance between verbosity and minimalism). Though it could benefit from better FP support (tail call optimisation anyone?), it's flexible enough for most purposes. I'm currently back to working with ActionScript. While I'm able to find some beauty in JavaScript, it seems like ActionScript is ashamed of its root and tries to be more like C# and Java. The static type system feels just bolted on and clashes heavily with the prototype system and functional programming aspects it has inherited from JS. I actually find myself writing Python in between just so I can work with something consistent for a change. I hope to be able to focus more on working with Python in the future. It does amazing things for my sanity.
I suppose to an extent it is a matter of taste, and I'm merely offering Attest for anyone who like it. Nothing wrong with using the other tools if they satisfy you! Attest is in part modeled after Flask, which I like *because* it doesn't have some strong "plugin" architecture or otherwise. Instead it is designed to be simplistic and flexible so it is easy to do anything you want with it with plain Python. It's a utility rather than a "platform". Sometimes the latter serves the job better, sometimes not.
Let's be honest: if Obj-C hadn't been the exclusive language for Apple app development, it would be nowhere near this popular. It's easy to imagine an alternate universe with iPhones running Java and Flash. I don't know whether it'd be a better one (Apple's Machiavellian policies certainly preserve a certain feeling of consistency), though.
Also, CoffeeScript is a great choice if you want something that's easier on the brain than client-side JavaScript. It also has some Ruby influences, though, so caveat emptor.
I have to say that I found the list comprehension syntax much easier to grasp after having seen it's more mathematical cousin in Erlang, though. The syntax makes sense if you look at it from a maths POV, but clashes a bit with Python's otherwise very "casual" syntax.
What are the dependencies provided for you? Seems reasonable that if you're writing python, the python standard library would be provided.
The above benchmarks ignore one thing: freeing the int objects. Every time you use pop(), an int object is probably freed. If instead you use: l = [] x = range(1000000) %timeit -n 100000 l.append(x[-1]) OR %timeit -n 100000 l.append(x.pop()) Then the performance gap is somewhat different. The append() keeps the int object alive instead of requiring the interpreter to free it. I get 243 ns per loop for pop, 191 ns per loop for indexing. Without append, I get 137 ns for pop, 50 ns for indexing.
http://stackoverflow.com/questions/2469031/open-source-implementation-of-mersenne-twister-in-python has a pure-Python MT implementation. Seed it with the current time and you should be all set. Granted anyone looking at this will know instantly that you didn't write it so I would clear it with your professor.
If you're only going to run this on unix-like systems, you could read from /dev/random or /dev/urandom.
**Organizing the data (create a data model)** Books are an unambigious enity in your data, authors are not, for example. You can use books as your "reference collector" for the other data. That means, you create one instance of a certain class in your Python code for every book. Now you have to decide what kind of class to use: * you could use dictionaries, if you don't need any methods to operate on your data. * or you could use named tuples, also if you only have to handle data. * or you could create your own class, which gives you more flexibility. Now your data is clustered well and what is most important every piece of information exisits only in one place in your code. **Handling the data internally** You can create lists that hold references to your book instances or dicts with the book title (if you can garantie that there're no books with the same title) as key. Otherwise you could also introduce an index for every book and then use the index as key. Those collectors can contain books according to your filter criteria. If you create new books, you need to update all your collectors. **Viewing/Editing the data with a GUI** Best practice is to use MVC (model-view-controler) pattern or derivatives. You should be able to find a lot of information in the internet. The basic idea is that all widgets access the same data. When the data is changed in one widget, the others are updated automatically (well, you'll probably have fire some events for this). But you don't have to worry about consistency of data that might be in different places in your app (as all your data is in only one place, see above). I'm not sure if wxPython has a built-in treeview that supports MVC, but I think (if I recall it correctly) that there're some third party implementations. I use PyQt, which has an excellent MVC framework. (But wxPython is also a very fine framework, no need to change, if you're used to wxPython.)
 with open("/dev/urandom", "r") as f: ord(f.read(1)) % 2
Yes! You tell me, why is that?
first, ask if you can use the random module or not.
Agreed. If they argue against this, you can start arguing against for example java.lang, standard python functions (think about range or len) and so on. This could get amazingly messy :)
s/unrandom/urandom/
Quite.
&gt; I'm pondering if using the _ast module to parse tests somehow and/or hook into the "frame" is a better idea; it'd be much more complicated and arguably magic, though. I'd much rather use the current Assert class over an implementation that uses any magic. &gt; That might be what is called BDD; I don't completely understand the terminology. Of course you don't. If you did, we would be in /r/java :) 
&gt; no external dependencies other than the ones provided for you This sounds like it's okay to use the standard libraries at least. I'm fairly certain it's meant to stop people from just saying `pip install &lt;relevant-library&gt;` to solve the problem for them.
i most definitely would. here's how hetland implements quicksort in the book: def partition(seq): pi, seq = seq[0], seq[1:] lo = [ x for x in seq if x &lt;= pi ] hi = [ x for x in seq if x &gt; pi ] return lo, pi, hi def quicksort(seq): if len(seq) &lt;= 1: return seq lo, pi, hi = partition(seq) return quicksort(lo) + [pi] + quicksort(hi) partition was a separate function because it was also used for a `select` algorithm earlier in the chapter.
My first idea was a dictionary of subjects with the key as the subject title and the entry would be a dictionary with authors as the key and the entries as a list of strings of details. Wrapping all this with a class with entry and removal commands so that it can fire off the correct events for the tree control makes sense, I just was hoping I could be lazy. then the tree view would consist of linking the tree view to the dictionaries....the question for me then is there any such data binding of this type available? Even if it is I still will be forced to rebuild temporary lists related to each selection in order to populate the list view....and insure correctness to additions and removals in the tree. This seems to be the oh so classic MVC pattern, I was just wondering if this type of thing was automatic or supplied for me. I guess I am forced to &lt;sigh&gt; do work =-P thank you for your suggestions, this was what I thought I would be forced to do, I just wanted to avoid doing it if at all possible. The 'application' is actually a module for another program so wxpython is a requirement here (well I could shoehorn in another framework but since the rest of the system uses it I think this would be a bad idea, minimizing dependences is always a plus).
I think when upper is left with just 1 item in it, the call to quicksort(upper) will continuously be called (recursively) with that one item in upper.
Yup, exactly (or even more than 1 item in it if we pivot on a duplicate; we'll never reach our base case, since we'll always have something in there equal to the pivot).
A simple RNG is like.. 3 lines of code, just find something on the internet. You'll learn something converting it to python. (edit) http://en.wikipedia.org/wiki/Random_number_generation#Computational_methods
Is there a windows alternative to that?
you can simulate a random number using the statement: X_n+1 = (a*X_n + b) % c which generates a uniform random variable. [Read more here](http://en.wikipedia.org/wiki/Random_number_generation#Computational_methods) From there you can use, for example, that if X_n+1 is &gt;= .5, then result =1, otherwise choose 0. Because this is a uniform distribution, it well represents a coin flip. EDIT: of course, you need to "start" with a seed, then that calculated value is assigned X_n. After the first iteration, the X_n+1 is determined using X_n. As such, X_n = X_n+1 should appear at the end of the function. Also, X_n must be persistent when outside the function (aka, like a static variable). EDIT 2: I did some looking up. Turns out that using 65535 for "a" and 7^5 for "c" work best. The addition of b is for offsetting from 0, thus you can omit b, or assign b = 0.
I've always wondered about how these work. Thank you
Not AFAIK: http://en.wikipedia.org/wiki//dev/random#Other_operating_systems
Easily the best ORM for *any language*.
As others have said, first make sure you know exactly what that requirement means. Using something that is *built into Python itself* like `random` would be fine, I would think. However, if it turns out you can't use it, or if you want to know how to do it without it anyway, just for fun: Why not just take `(the current time in millis) % 2`. Probably not truly random, but also probably good enough for your purposes.
[Attest](http://packages.python.org/Attest/) has a simple custom theme that uses fonts via the Google API and is almost completely made with CSS (inheriting the base theme). Only the GitHub ribbon and the Pocoo logo uses template overrides. [Source](https://github.com/dag/attest/tree/master/docs/_themes/attest)
You are a gentleman and a scholar. Thank you :)
ah cool! i haven't heard of pgreloaded before!
It won't be truly random but if your game has some kind of input, for example the keyboard, you could use this to get your random coin flip somehow.
Any way to get YouTube's 10ish characters?
 _seed = 42 def seed(x): global _seed _seed = x def random(): global _seed _seed = (16807 * _seed) % 2147483647 return _seed This will have a period of over 2 billion. Eat the bits one-by-one if you need it to last longer. From http://www.avatar.se/lectures/rng-seminar/rng5.html Edit: Warning, seems from my manual testing that this only has 31 random bits, not 32. So, don't rely on the topmost bit, it's always 0. Seems this is designed for signed ints.
I think he means version 1 is for farmers and version 2 for pimps.
 bits = bin(int(raw_input("Press the numbers on your keyboard randomly, then hit Enter\n"))) bits = bits[2:] bits = list(bits) print "You gave enough input for %d coin flips." % len(bits) def coinflip(): bit = bits.pop() return bit == '1' print coinflip() print coinflip() print coinflip() #... Example run: Press the numbers on your keyboard randomly, then hit Enter 90439804368936498034680943689064390893747238753632689523 You gave enough input for 186 coin flips. True True False 
Yep, just chop off the characters you require. The probability of a collision should still be somewhere around 1/57^10, which is quite small.
 python -c "print %RANDOM%.0/32767.0" you can type `set /?` in cmd for more info.
You are allowed to import random. The only restriction is that all the code you write must be contained in your player module.
I too have begun working on a game with PyGame. If you don't find a mentor, I'd be happy to have a back-and-forth with you over what we figure out. /me shrugs
I'm up for this even if I do find a mentor.
How do you get the current time without the time module? Perhaps seed it with data from the paging file if you are on Windows.
the buildout recipe http://pypi.python.org/pypi/rod.recipe.appengine does a pretty good job too
This is elegant, but not comparable to original quicksort algorithm which works in place. This creates lot of copies.
me three, eventually
I like where this is going. I'm working on a clone of an old 90s board game: https://github.com/kmwhite/alpha_infection I have a bit to push still. VERY early stages. :P
I would say you're allowed to use the Python standard library (which includes the random module). I'm not sure though, so ask your professor. Or try this... bool(ord(open('/dev/urandom').read(1)) &amp; 1)
Hmm, this is true. I suppose it doesn't really matter if each run is different, so you could just seed it to a static value.
Usually, in MVC frameworks you have to subclass a predefined (maybe abstract) model class. Then you have to overwrite some methods to get the data for certain positions in your views. In this methods you would access your internal data structure and return some pieces of data according to what the predefined model class expects. After registering an instancen of your subclassed and specified model class to an instance of a view class (also most of the time a special MVC view) you're done. No need to bind any data manually. So, there're probably special MVC classes for the model and views in wxPython available, which you need to subclass. You'll probably get a lot of help on the wyPython mailing list about this topic (but search the list first, MVC is a probably much discussed there).
I'm planning to make a [Tritryst](http://www.hotud.org/component/content/article/41-puzzle/20879) clone once I go back over my Python and learn how to use Pygame.
You might get a better response on the Pygame [mailing list](http://pygame.org/wiki/info). Also, check out the [projects](http://www.pygame.org/tags/). There are a lot of games, engines, and tools you can use directly or get ideas from.
Try this to start: http://eli.thegreenplace.net/category/programming/python/pygame-tutorial/ I only just 'got it', enough to do what I'm trying to do for now, so I'll leave the mentoring to someone else with actual experience (like a finished or working game). However I will say this: pygame is a **low level** game creator. This means that you will spend most of your time using functions you wrote yourself that wrap the main pygame objects. Don't try and do things the pygame way in all of your code, write some wrapper functions and use those instead. For instance, I created a object called Item that handles is a subtype of Sprite, but have move functions that work the way I want them too, not relying on the pygame.Sprite.move function in code everywhere. Drawing a world then cycles through all items in it and calls their draw method. If a particular item has different drawing mechanism, I subtype Item and override the draw method as needed. 1) Write a Manager class that does the game loop (its very 1990s Java, but it works). The game loop is: handle events, then update all items in the world, then draw all items with new update. Wait 50 milliseconds and repeat until game is over. 2) Write a standard Item class and practice moving it about the screen using game logic (not input) 3) Subclass Item to create a Player, because movement is handled through event handling, not normal loop updating. Move the player around the screen using WASD Here is the code that I use for generating fireballs (simplified) if event.type == pygame.MOUSEBUTTONDOWN and self.can_attack: dp = numpy.array(event.pos, dtype='float') - self.position dp /= numpy.sum(numpy.abs(dp)) # normalise to get unit vector dp *= shot_speed environment.addItem(Fireball(dp)) A fireball is then just an Item that whose position is updated along the vector dp every update loop. Hope that helps! 
You need a seed, and if he's not allowed to import random, he's probably not allowed to import something like time either.
He can read from /dev/urandom, assuming he's on Linux
I wish I could say I was good enough to mentor anyone, but I'm still just getting my feet wet. You can see my first pygame work in progress [here](https://bitbucket.org/jgrigonis/thefranchise/src). I just spent the last hour beating my head against a wall, but I finally made it my bitch. OK, so obviously the game is very far from complete, but to run it just do: python uipygame.py Let me know if you make it crash. I usually like to keep the tip pretty stable. Right now there's not quite enough there to make sense of exactly what is going on, but it's basically a store simulator, where you hire and fire employees, and currently that's about it. There isn't any game display done, just working on the control UI. Needless to say, I feel like I'm doing an entire windowing system from scratch. But it's kind of fun. I can say that I looked through Eli's tutorial [here](http://eli.thegreenplace.net/category/programming/python/pygame-tutorial/) and I think I'm ready for parts 5, 6, 7, and 8, lol. Edit: Beware, the code is in a terrible state, with almost no documentation. 
Very cool! But… isn't this to some extent putting the cart before the horse?
So how would you explain what this is, to someone who has no idea what it does?
Slightly off topic, but how does TIOBE find that Javascript is **losing** marketshare? Is there something I'm missing? Because to me, it seems like highly interactive websites with extensive Javascript is becoming increasingly popular. For that kind of work, it seems like Javascript is the "only show in town". What part of this am I missing?
To a degree, but it's still very useful - I used it to help me get a better understanding of a database I was reverse engineering a couple of years back.
awesome book with machine learning algos..
worth the dollars..
Fair enough. [Power Architect](http://power-architect.googlecode.com/), the (open source) ER tool I currently favour, also supports reverse engineering an existing database. In fact, it does full round-tripping, though I have yet to bring myself to trust the "forward engineering" part of that over my own hand-crafted SQL.
&gt;He can read from /dev/urandom, assuming he's on Linux If he can read from /dev/urandom, why bother implementing his own PRNG? OP: A self-implemented PRNG will work, but it will not be cryptographically secure or random (only random-looking). It could be seeded with built-in `id(someobject)`. For CPython, this is the memory location of `someobject`; with everything else going on in your system, this should change (use the same PRNG stream for the entire session, because the return value of `id()` won't change during the session, so using the stream multiple times makes your randoms loop..). But again, don't use this if your data must *really* be random! 
Everyone join [#pygame on freenode](http://webchat.freenode.net/) and just start asking and answering questions.
How do you get the time without importing time?
This was a fun puzzle, I think I've cracked it: def srand(seed): global _seed _seed = seed def rand(): global _seed _seed = (16807 * _seed) % 2147483647 return _seed if __name__ == '__main__': srand(hash(rand)) print rand() Output is unique between runs (although the amount of entropy may not be very high). Will anyone confirm? **Note:** the code may mislead you into thinking it doesn't work but try it :)
http://en.wikipedia.org/wiki/Blum_Blum_Shub This is a very simple, cryptographically secure algo. Doit OP!
I hope this stops the meaningless posts of "Hey &lt;FRAMEWORK&gt; has a shorter Hello World than Pyramid" ;)
Interesting type of benchmark, but I disagree on the 'cheating' aspect: &gt; The Pyramid "whatsitdoing" application replaces the WebOb "Response" object with a simpler variant that does a lot less. Calling this "cheating" is a bit of an overstatement, because Pyramid's design allows for this. The "simpler variant" of the Response object defines hard-coded values for status, header-list and body-iterable. It bypasses most of the features that make a framework useful over pure WSGI. The equivalent for other frameworks would be to install a WSGI middleware that never calls the framework stack and just returns hard-coded values. While it is a nice feature to be able to 'switch off' the framework for some specific routes, doing so while benchmarking *the framework* makes no sense. It IS cheating and distorts the results.
The PSF **will** help you get a visa. They won't do it for you however, but having all those papers from the PSF helps a lot. PSF also helps a lot with expenses and they can cover most of what you ask for sometimes (depends really on a year and number of applicants). Not researching that and complaining here is entirely your fault.
People joining, saying hello and parting (I'm looking at you twopi) need to realise you have to idle for hours or days in chat rooms before regular discussion gets going. If everyone leaves straight away it's very unlikely for two people to meet. It's best to install an IRC client (like an IM client) that will load on startup and stay connected in the background and that you can check occasionally for discussion that interests you, like a feed reader.
Interesting. Are you going to post instructions so we can benchmark the same way frameworks that are not listed?
"Testing"? You're modaling it by 0x7fffffff, which is equivalent to a bitwise-and.
not if you prototype your database using [declarative classes](http://www.sqlalchemy.org/docs/orm/extensions/declarative.html) to jot down table/column names and types, then use one of these tools (I use [this one](http://www.sqlalchemy.org/trac/wiki/UsageRecipes/SchemaDisplay) with omnigraffle) to generate the hardcopy for your team's documentation.
this is indeed a clever solution if the task is really to create randomness without using import for time or random. i think that it would be more obvious if you used srand(hash(object())), as you actually seed with something like the memory address of a newly generated object. for variations of this theme, be aware that you shouldn't just do def rand(): return hash(object()) because it might happen that for successive calls, the two objects are allocated on the same place. for seeding it should be ok, though. (i don't think anyone will try, but if so: don't use this for randomness if it's imporant! there are situations where this may always generate the same numbers, like early in startup, and the entropy in these numbers is also quite low. how reproducible it is can be seen from generated = [] for x in range(10): generated.append(object()) print hex(hash(generated[-1])) which will most times count up in steps of 0x10)
With overwritten text support.
A while ago I worked on a simple spacewar game with my brother. We never finished it, but I think we got a decent framework and basic understandings completed. You can check it out at http://spacewar-type-r.sourceforge.net/. If you have any questions about how bits of the code works, feel free to ask. NOTE: This is not professional code by any means, but it shows how we figured out the basics to make a playable game.
Actually, indexing numpy arrays is much slower than python lists. Python lists are list C-arrays of pointers, under-the-hood. If you use Cython, you can do fast list indexing at C-speed without the python interpreter overhead. list.pop() will be (marginally) slower since it actually removes the item from the list, so the list length needs to be updated and ref-counts changed. This will make it a bit slower than a straight indexing operation.
Touche
Have you had a look at [Flask-OAuth](http://pypi.python.org/pypi/Flask-OAuth) ?
&gt; Currently it only implements the consumer interface so you cannot expose your own API with OAuth
Bummer. This code might be more useful, should be quite trivial to adapt to a Flask app: https://github.com/facebook/python-sdk/blob/master/examples/oauth/facebookoauth.py
However we would be accepting patches :)
Durr.. yes I am. In my defense it was 5AM.
You may look at [velruse](http://packages.python.org/velruse/) which is a standalone application you can run alongside your flask application with a shared session to pass credentials. It supports a large number of OAuth implementations including Facebook.
You can take a look at any of the "results.txt" files in any of the subdirectories of http://svn.repoze.org/whatsitdoing/. It describes how to repeat the results, and provides the source code used for each framework.
Err… Those benchmarks don't seem entirely fair. The versions of Django, Pylons, Grok and TurboGears range from "a little out of date" to "holy crap Django 1.0.2".
So you're saying the fact that a user can do: class NotFound(object): status = '404 Not Found' app_iter=() headerlist = ['Content-Length':'0', 'Content-Type':'text/plain'] def aview(request): return NotFound() Is a nonfeature of the framework? We do this sort of thing all the time in actual production apps, so it's news to me that it's not useful. But for the record, the benchmarks are still very good when we use a WebOb response. The result is 24 lines of profiling output instead of 22.
Thank you.
While it's not really the point of the blog entry, the source code and methodology used to come up with each result is posted in http://svn.repoze.org/whatsitdoing/, and framework fans are encouraged to run them and submit newer results (with source). I'll change the result reports if you come up with better numbers.
I think Janrain has a free version too (which is the system that inspired Velruse).
&gt; Why do you compare radix sort and quicksort when trying to downplay the validity of asymptotic analysis? Because it's a clear case where one algorithm has a superior asymptotic runtime than another, but constant factors make it markedly inferior in almost all the cases we actually encounter. &gt; The running times of radix sort and quicksort don't just vary by constant factors; their asymptotic running times are different. Exactly. &gt; Perhaps you meant to compare quicksort with another O(n log n) sorting algorithm like heapsort or merge sort. Nope. I meant to compare it with something that had a superior asymptotic analysis, but was typically slower in actual use.
Object Relational Mapper. Provides an easy way to map Python classes and instances to rows and columns in a relational database.
AuthKit can be used to support pretty much any authentication system. You just need to write a plugin.
True. It's not comparable, but it's perfectly possible to do it in place as well, and it still wouldn't be as bad as the code they had, though perhaps only stylistically in this specific case. My point was that in general, most of the code in here and in a lot of these books is just bad python.
If he wants to authenticate people using their facebook accounts, wouldn't he need to be a consumer?
Yes... for me, being a "consumer" is enough.
Have been biting my nails on this for the past few hours. Authenticating with twitter worked in a matter of minutes. Facebook on the other hand... For the life of me, I cannot get it to work. The FB docs are amazingly unclear about what URL is used for which purpose. Additionally, the Flask-OAuth example uses 3 URLs (`request-token`, `authorize` and `access_token`). The FB docs really do not help a lot with this. Making a manual call to `https://graph.facebook.com/oauth/access_token?client_id=123456&amp;client_secret=1234abcdef&amp;redirect_uri=http://my.cool.app` works out of the box. But specifying `https://graph.facebook.com/oauth/access_token` as request_token_url does not work. I drilled down, to find that FB complains, that no `request_uri` is set. When I append it as GET parameters to `request_token_url`, then it complains that no `client_id` is specified. The errors got worse from there... I traced the error into ` generate_request_token` in `flaskext/oauth.py`. Line 250 obscures the exception, and only gives a "whoops, something went wrong" style of error. Actually, the `resp` object contains a more helpful message at this point: &gt; invalid_request "Missing redirect_uri parameter" Which strikes me as weird, as I specified both a `consumer_key` and `consumer_secret`.
&gt;&gt; invalid_request "Missing redirect_uri parameter" &gt; Which strikes me as weird, as I specified both a consumer_key and consumer_secret. Did you try adding `redirect_uri` as a GET parameter?
looks interesting... I'll have a look.
&gt; So you're saying the fact that a user can [bypass output validation and completion] is a nonfeature of the framework? Actually I said that it is a nice feature. I am not criticizing the feature itself, but its use in this benchmark. Optimizations should be applied to all participants of a benchmark that support it, or not used at all. Optimizing just the framework you want to promote is cheating.
I did optimize the other frameworks' code to the best of my ability (although I've likely failed, as I know my own source better than theirs). I see that I might have done better on the Django test, as I look at it. For bottle, I disabled logging, for example. But along with the results, I've also provided the source code for each framework, a way to repeat the results, and I've suggested both here and in the blog post that web framework authors disgruntled by the current results could supply a more optimized version of their particular whatsitdoing app. Maybe you could provide a more optimized bottle variant? I'll be happy to amend the results and publicize that I have done so.
I just ran the tests again, using a bottle 0.8.5 app that looks like this using the same "optimization" technique as used by the Pyramid whatsitdoing app, which is to return a precomputed HTTPResponse: from bottle import route from bottle import run from bottle import default_app from bottle import ServerAdapter from bottle import HTTPResponse from repoze.profile.profiler import AccumulatingProfileMiddleware class PasteServerWithoutLogging(ServerAdapter): def run(self, app): # pragma: no cover from paste import httpserver httpserver.serve(app, host=self.host, port=str(self.port), **self.options) response = HTTPResponse('Hello world!') @route('/') def hello_world(): return response app = default_app() wrapped = AccumulatingProfileMiddleware( app, log_filename='wsgi.prof', discard_first_request=True, flush_at_shutdown=True, path='/__profile__' ) run(app=wrapped, host='localhost', port=8080, server=PasteServerWithoutLogging) This is the best I could do to emulate "bypassing output validation and completion" given the constraints of Bottle's design. The results of testing the above app are actually slightly worse than the results when the view returns a string (by one profiling line, and by a nontrivial number of function calls). I don't know if I tried this before and realized it, and optimized the bottle results by returning a string rather than precomputing an HTTPResponse. It's possible. In any case, I'm happy to amend the results with whatever improvements you can make. I don't know immediately how to make Bottle do less, but I'm sure you do. As far as cheating goes, that's a pretty low blow. I'm interested in promoting Pyramid because I'm really proud of the work we've done, not because I want to make other frameworks look bad. Granted, the comparisons with other frameworks are indeed a gimmick, designed to drive comments and traffic. But as far as I can tell it *is* currently more optimized than the others at its core. If you can prove to me that it isn't, great! I really wish it *wasn't* currently the most optimized, because I'm certainly no mastermind. I'm hoping there are people much smarter than I am in the Python web framework world that can produce faster and more compact code. If you change Bottle so that it gets faster as the result of getting annoyed with this result, and you figure out some new technique to do so, everyone wins, I hope.
wow. don't ever use + to put values in to an sql query. however, your problem is that: 1. strip() only strips at the end of the strings, and 2. strip() returns a new string 3. you overwrite the loop variable for no good reason emails = open('/path/to/emails.txt', 'rU') for email in emails: email = email.strip() sql_query = "insert into emails (email) values (%s)" cursor.execute (sql_query, (email,)) please just use placeholders all the time - it is less effort than not using them, and stops you getting in to a terrible habit.
&gt; I'm interested in promoting Pyramid because I'm really proud of the work we've done, not because I want to make other frameworks look bad. Granted, the comparisons with other frameworks are indeed a gimmick, designed to drive comments and traffic. But as far as I can tell it is currently more optimized than the others at its core. That might be the case, but I still think you should use a generic Request object like most of the frameworks do, so no frameworks would win by performing this kind of optimization. As you have shown, Pyramid does not get much "slower" by this, which is very nice. I would highlight *this* fact. For the record: I *do* appreciate that you took the time to adjust the bottle code. I just think it does the wrong way.
I think this misses the point though. The decision to not require a "generic" Response object was very deliberate. Many other frameworks eagerly create a "global" response object when a request enters the system. This almost always results in lower performance, because this response object must be very full-featured to *be* "generic". In the meantime, code accretes around the idea that this global response object exists, and may be tickled by random code in random ways. By doing this, a framework paints itself into a performance corner that could have been avoided. This is an antipattern that Pyramid avoids. It's not a trick. It's just a deliberate design.
Did you try the latest development version? Some flaskexts seem to not update their pypi packages too frequently.
If you really want authentication *via* OAuth, but it's not the OAuth bit that you find so important, velruse can work well. I have a couple things in a fork that I've been too lazy to push back: https://github.com/ianb/velruse Velruse is basically like RPX/Janrain: https://rpxnow.com/ -- which is also a really simple way to handle authentication that's worth looking at if you just want to quickly hack something together.
Any luck creating a Web2Py analogue? I'd be happy to include it in the svn repository.
Please provide details rather than asking for help about a completely unknown problem, as it facilitates others helping you. At what point did it fail to work? Could you successfully deploy, but the actual application was broken, or did it not get that far? 
I am trying. I did an easy_install repoze.bfg but I get from repoze.profile.profiler import AccumulatingProfileMiddleware ImportError: No module named profile.profiler I am missing something?
Yeah.. easy_install repoze.profile repoze.bfg is not the right package.
`pip`!
Radix sort isn't intended to be used as a general sorting algorithm; Quicksort is. I don't think it's fair to compare two algorithms that are designed to solve different problems. Anyway, your argument is a straw man argument, since I don't think anyone teaching a course on the analysis of algorithms concludes that since radix sort technically runs faster asymptotically it *must* be better/faster than Quicksort.
[Here ya go](http://lmgtfy.com/?q=google+app+engine+upload+application). If you can write the app, this is all you should need.
&gt; Radix sort isn't intended to be used as a general sorting algorithm; Quicksort is. It *doesn't matter*. Even when sorting integers of restricted size, quicksort is *still* faster than radix sort most datasets we encounter in real life. &gt; Anyway, your argument is a straw man argument, since I don't think anyone teaching a course on the analysis of algorithms concludes that since radix sort technically runs faster asymptotically it must be better/faster than Quicksort. God, how fucking dense are you? I stated a claim that often constant factors are more important than asymptotic complexity. I gave an example where constant factors are often more important than asymptotic complexity. The only straw man here is your pointless and irrelevant objection to a simple claim with a simple example.
if he wanted to know about just uploading he would have searched for it. Don't give half arsed answers
You might try asking your question in the AppEngine subreddit : http://www.reddit.com/r/AppEngine/ Also check : http://bottle.paws.de/page/docs#google-appengine
&gt; Even when sorting integers of restricted size, quicksort is *still* faster than radix sort most datasets we encounter in real life. Perhaps that's correct, but you do have a source? Radix sort *has* to be faster than quicksort for sufficiently large input sizes. That's the whole point of asymptotic analysis: the emphasis is on how running time increases when the input size increases, not on "which algorithm is faster/better." I never disagreed that *sometimes* constant factors are more important than asymptotic running time. In the "real world," benchmarking with actual production data and actual production hardware/software is often the only way to compare two algorithms. Asymptotic analysis isn't about benchmarking or even recommending what algorithm is best, it's just about analyzing how the running time increases when input size increases. Anyone who actually understands the basics of the design and analysis of algorithms knows that the claim is never made that an algorithm with lower asymptotic running time is *absolutely and necessarily* better in all use cases than an asymptotically "slower" algorithm. You clearly implied that asymptotic running times don't matter in the case of quicksort vs. radix sort. I claim that they *do* matter, but they just don't end up being the deciding factor in the use case of a general sorting algorithm. And as I mentioned, that's to be expected, since radix sort isn't even designed to be a general sorting algorithm. Your argument is tantamount to claiming that the study of plate tectonics doesn't matter because the movement of the continents is not the dominant factor in calculating, for example, airplane flight distances. You're either missing or choosing to ignore the point of the discipline.
It's all there in the top result. If he really wanted to do it, not have someone do it for him, he would have searched for it. The actual answer is not half assed, it's the answer.
&gt; As far as cheating goes, that's a pretty low blow. Again, I am not criticizing Pyramid or saying that a different framework (or Bottle) should win, I am criticizing a specifying aspect of the *benchmark* and think it distorts the results. Sorry if you interpreted this as a 'low blow' or an attack on pyramid, it was not meant as such.
Look, performance optimization is *all about* "cheating". It's not (moral) cheating to be able to do as little work as possible to get the job done. Designing a framework such that these kinds of "cheats" are possible is our job. And as you can tell, I tried the same "distortion" with bottle and it made the results worse. I also used the "normal" WebOb Response object in Pyramid and it only added 2 lines of profiler output. If you can make the bottle (or any other) results better by "cheating" in a different way that actually does exercise the framework code, fantastic.
bla bla bla CLOUD.....
Any numbers to share with us mdipierro? If you have code, we'd like to add that to the svn repo as well.
grrr... I made the app and modified the webserver to use the repoze profile but the log_filename='wsgi.prof' does not get created. I am using a Mac. I am using the rocket web server. Is there any caveat I should be aware of?
Try visiting /__profile__ in a browser. Maybe the wsgi.prof file is being written to the current working directory of the server (which isn't your terminal's current working directory).
Ok google, implement this in google docs and I'll love you forever
Use a thread to keep a virtual coin "spinning". Sample as needed.
I almost figured it out. I am not sure I am doing this quite right and I am comparing apples with apples. For example in web2py I cannot turn off completely session handling, header parsing, and attempt to locate certain files that are supposed to be there but are not there in this "hello world" app. Anyway, I am getting 154 lines. Tomorrow I will send you the app.
You can write javascript code in google spreadsheets http://code.google.com/googleapps/appsscript/service_spreadsheet.html
http://python.net/~goodger/projects/pycon/2007/idiomatic/handout.html is much better advice.
I honestly can't tell if this is a serious post.
Clever, but if you can't import random, you probably also can't use threads. (Same problem as with my suggestion.) +1 anyway though because I like the idea.
This is a package I made about a year ago. It could use some lov'in but should work. It was developed using Test Driven Development (TDD) practices, so give the tests a look over for examples and what not. wsgioauth was primarily built to provide OAuth services, but I've used it to accept OAuth as well. The main feature for the consuming app is the Request class that subclasses a WebOb Request.
Yes. It says so in the 3rd paragraph.
Facebook uses it's own bastard version of OAuth which is easy enough to implement in your own code. You basically just make sure you are sending SSL requests and send your given credentials.
Added my thoughts on it to the OP.
Added my thoughts on it to the OP.
Added my thoughts on it to the OP.
Thanks for the info. For now, velruse is my prime candidate though. My main concern with `wsgioauth` is the fact that it *only* supports oauth. Or to formulate differently: In my opinion, WSGI middleware should fulfill the requirements of a specific task. I'm not saying `wsgioauth` is bad. Just not the right solution for **my** problem. Bear with me... In my case, this task is "Authenticate the user". Whether via OAuth, HTTP BASIC, Form Based, ... should not matter. But for now, I want Facebook (i.e. OAuth). As long as the user is authenticated, it's fine. At a later stage, I might want to add OpenID as well. Which is not OAuth. The main purpose of `wsgioauth` on the other hand, is "Access OAuth protected resources". And I believe, that the development should always keep that in mind and not try to do to many things. WSGI is very Unix-ish: Do one thing, and do it well! I don't need to access protected resources in my project. So it might not be the right tool for the right job. While `wsgioauth` *can* be used to authenticate a user, it would make it more difficult to add new auth-schemes (like OpenID) later on.
Heh, guessed from the title that it'd be related to Resolver One. :)
FWIW, AuthKit is no longer under active development. It was originally the supported auth framework for Pylons but hasn't been for some time.
I thought the paradox was that by hiring programmers who know a certain esoteric language you make the language more popular, thus less esoteric. Python may not be a "job safety" language, but if it became popular enough, it automatically would be, therefore making it attractive to "dumb" programmers.
Did... did he just recommend using static methods?
It's 5 AM and you have **OFFICIALLY RUINED MY DAY**! ...How can I possibly finish all of these essays and still get work done, today!? Thank you for this :)
yeah, i know. to be fair we did agonise over the decision to use cloud in our marketing chit-chat... http://blog.projectdirigible.com/?p=507 http://twitter.com/dirigiblegrid/status/23337212909195264 I wouldn't quite say we're using the word cloud ironically. But we are self-conscious about it! 
Surely a better test would be to ask what people have learned and what projects they have done in their spare time - could be any language or topic. Seems rather oblique to ask them if they know python and then assume this gives them magical powers.
oh in this very case it's cloud**s**
Python gave me magical powers. What's the matter? Did you not get yours yet?
Try: import antigravity
Ooooooooooold
That was 2004, though. Python is a lot more popular now (though not nearly as popular as Java I believe)
I thought Dive Into Python was a great starting resource. You can check out Zed Shaw's "Learn Python The Hard Way" it's available free online or in epub format for a small fee. O'Reilly offers a certificate in python that runs ~$1000 that includes 4 classes. If you find it on their site you can view the books that the classes use. I think the first one is Head First Python. Here: [found the link](http://www.oreillyschool.com/courses/python1/) I don't think there are a ton of places you will find mature projects using anything newer than 2.6 -- This is speculation based on my observations, someone more well versed in Python should feel free to comment. My other recommendation is to find an Open Source project that is using Python, install it locally and begin looking at how they do things. Some projects that come to mind are (in no particular order): * Reddit [code here](http://code.reddit.com/#Development) * OSQA (stack overflow clone in Python, quality of code sometimes an issue) * Zope * Twisted Find one you're interested in. You will have a hard time learning and later committing patches (if you want) to a project you don't personally use. 
Not to say faintly embarrassed...
Yeah, nowadays it's like the Clojure Paradox or Erlang Paradox or something.
Word of warning, pg can be, um, uneven in his writing.
http://oreilly.com/catalog/9780596158101/ Mark Lutz is a fantastic author. *EDIT* It's also available on Safari Books Online. 
There is also a book by Mark Lutz, Learning Python. Is it good?
Very. Lots of projects involved, so you can learn while doing.
Learing Python is a great book. Also try out Wesley Chun's Core Python Programming.
Ugh, yeah...I've gotten to some of that. I've taken a breather from the site. I at least enjoyed some of it, and learned a little history ...right?
I would recommend [Tarek Ziadé's expert python programming](https://www.packtpub.com/expert-python-programming/book), advanced, decorators discussed, and advanced decorators discussed too:) for non-book, I would recommend David Beazley's [Generator Tricks for Systems Programmers - Version 2.0](http://www.dabeaz.com/generators-uk/) and [A Curious Course on Coroutines and Concurrency](http://www.dabeaz.com/coroutines/index.html). for semi-book semi-web page, there is a ["Python Types and Objects" and "Python Attributes and Methods"](http://www.cafepy.com/) and Raymond Hettinger's pycon talk, of course. such as: [Fun with Python's Newer Tools](http://us.pycon.org/2011/schedule/presentations/261/), [API Design: Lessons Learned](http://us.pycon.org/2011/schedule/presentations/263/), [Mastering Team Play: Four powerful examples of composing Python](http://us.pycon.org/2010/conference/schedule/event/86/), [Easy AI with Python](http://us.pycon.org/2009/conference/schedule/event/71/), and [Core Python Containers: Under the Hood](http://www.viddler.com/explore/python-italia/videos/41/) and [slides is here](http://www.pycon.it/media/stuff/slides/core-python-containers-under-hood.ppt)
Haskell!
Not a book, but the ["Python By Osmosis"](http://www.youtube.com/user/ryanmshea) podcasts start to get fairly advanced after about the 15th episode.
Still true though.
Well, except Python is much more mainstream than it was - so the *reason* he gave is pretty much invalid now.
Did you mean pdf in reference to "Learning Python the Hard Way"? I'd buy it as an epub, but all I can find on lulu is a pdf version.
or order the official reference manual on amazon...
It's often a good idea to run things through `expanduser` as well to get things like `"~/test"` or `"~yaprog/test"` to expand properly.
Well... something like this seems pretty straightforward: http://xkcd.com/221/
He has the PDF version hosted right on his site -- it also appears that the lulu version is PDF, my mistake.
Maybe that was his point exactly...
The book Expert python programming covers all you need to know for doing projects in Python. It covers much more than Python related stuff, e.g. stuff about version control and build systems, testing, etc.. It's overall a very good read for the big picture. I've learned a lot generally, but it is not very comprehensive about advanced Python features (mainly 2 chapters). I like David Beazleys Essential Python Reference. It's a reference, so the explanations are short, but very good and at the point.
Expert Python programming had a lot of useful gems in it, probably one of the more enjoyable books I read last year. In addition, I'd recommend picking up Oriely's [Python cookbook](http://www.amazon.com/Python-Cookbook-Alex-Martelli/dp/0596007973) not so much for the recipe's themselves but to see how they solved some of them... For helping Java dev's go to Python, its helped to have good examples of the "Python" way to accomplish certain things.
I'm a big fan of ["What You'll Wish You'd Known"](http://www.paulgraham.com/hs.html). Probably his best essay, well at least the one that has had the most effect on my life. Edit: Corrected title. Thanks fancy_panster.
So i do this: &gt; A1: ["a", "b", "c"] &gt; &gt; A2: = 2*A1 &gt; &gt; A3: = A2.append("d") Is A3 supposed to return None? The rest seems to work as expected. Also, is this the way to address cells? Strange compilation of string and integer... &gt; worksheet['C', 1].formula = 'hi world' I see you are working on handling ranges. Too bad the ":" is gone, it is a strange dialect with the arrows / minus greater than "-&gt;" 
I think you should just use &gt; os.path.join(os.environ['HOME'], "test") and *catch the exception* when HOME is not set. You're going to be in a world of pain when, e.g., your code accidentally removes /bin one day. Mixing interpretation levels is a bad idea.
You're missing the point of a config file.
Great article but I have to disagree with [Paul's assertion (see: Appendix: Power)](http://www.paulgraham.com/icad.html) that it's difficult to write a python function to generate accumulators (a function that takes a number n, and returns a function that takes another number i and returns n incremented by i). He antes up some python examples to prove his point but it's easily achieved using a closure: def foo(n): def bar(i): nonlocal n n += i return n return bar f = foo(42) f(1) &gt;&gt;&gt; 43 f(1) &gt;&gt;&gt; 44 f(1) &gt;&gt;&gt; 45 etc. There's probably a better way, I'm but a python n00b (coming from a background in lisp). Carry on ...
I've been doing PyGame programming for a while (I don't think any of my PyGame games are currently online, though, which is a problem I'm working on), I'd be up for helping out. IRC is easiest for me (especially if more than one person is interested), but I can do IM or email if that's best for you. 
In 2002 I built a very large data warehouse at a large fortune 50 company. I needed to write a lot of code to extract, transform, and load large volumes of data every hour. I chose python over java (that was a battle) for its short learning curve, great readability, and it's "enthusiast" nature. And it did help us identify, hire, and retain some extremely good programmers. Eight years later that warehouse is a strategic system at the company, and the python programs manage 100 million rows a day.
Oh. Then relative paths should be okay. "test". Inserting a slash is dangerous though.
Well, instead of replacing $HOME with the empty string for unset env vars, `expandvars` will just opt not to replace it. So at the very least it will dodge that specific failure mode.
You could also get lots of 'bipolar' programmers, or those that learn languages that are trendy or easy to get into that are otherwise divorced from the practicalities of actual software development. Why not require *both* java as well as competence on some other, esoteric language?
Duplicate of: http://www.reddit.com/r/Python/comments/ezwtw/practical_guidelines_for_beautiful_python_code/ WTF.
best Python book I've ever read. It definitely covers quite a few advanced topics (decorators, magic methods, metaclasses). After reading the official Python tutorial and diving in with some basic code, this was the book that taught me python.
I came here to mention Clojure. I believe this paradox exists, but that Python really isn't the language (anymore) to demonstrate it.
This is a point of contention, [I found out](http://www.reddit.com/r/programming/comments/9s3ww/would_you_hire_a_programmer_that_does_not_write/).
Old is not a crime. Dupe is not a crime. Obey user moderators.
I read "Learning Python" from cover to cover recently, here's my quickie review: * Very comprehensive, but also very verbose. 1100 pages, for better or worse. I've read complaints about the physical book being unwieldy. I read it on my Kindle, which was quite handy for searching and jumping between sections via cross-references. * Lots of examples, but they varied in helpfulness. In particular, the chapters on decorators and metaclasses seemed to focus on implementing private scoping over and over, which is something I found both un-Pythonic and boring to read. Then again, the book is aimed at beginners writing apps rather than library authors, so I doubt many people will be writing lots of code using decorators/metaclasses right after finishing the book. * If you read it through, you WILL learn both Python 2 and 3 in depth. As someone who was familiar with Python 2 before reading, I definitely feel that I learned a great deal about both versions of the language. * It doesn't cover software construction with Python on any larger scale, because that's the topic of Lutz's "Programming Python", which I haven't read. All in all, it's a book I'd recommend to someone interested in learning Python, as long as you can handle the length and verbosity. You'll probably want to follow it up with a complimentary book (or other online reading) that covers Pythonic software design, common idioms and specific tools. Lot of other posters seem to recommend Tarek Ziadé's "Expert Python Programming", as well as Lutz's designated follow-up "Programming Python", which just released a new edition matching the Py2/3 coverage in "Learning Python". I'll be checking out Ziadé's book myself, as I wasn't familiar with it and it seems to cover a lot of interesting things that other books leave out.
The nonlocal keyword is new in Python 3. That is a good solution to the problem. In Python 2, things are slightly more awkward. You either need to define a class, use a generator, or use an extra level of indirection: class foo(object): def __init__(n): self.n = n def __call__(self, i): self.n += i; return self.n def foo(n): def gen(n): while True: n += yield n g = gen(n) g.next() return lambda i: g.send(i) def foo(n): a = [n] def bar(i): a[0] += i; return a[0] return bar Still, it isn't bad.
I am enjoying [Pro Python](http://www.amazon.com/Python-Experts-Voice-Open-Source/dp/1430227575), but I'm not sure if it's advanced enough for you.
+1 for David Beazly's stuff.
Knowledge of any programming language shouldn't be considered esoteric anyway. Maybe deep knowledge of how a particular runtime works. But a programming language is a programming language. Any programmer worth their chops should at least have a basic understanding of all the paradigms and be able to start coding in any language given enough time. Every programming language and runtime will have it's drawbacks. I'd rather hire someone who can actually produce something worthy, efficient and readable/understandable in Java than someone who thinks he's tough shit because he can write hello world in an "esoteric" language and would propose writing a redistributable multiplatform desktop app in python with x (x &gt;&gt; 5) dependencies on C bindings half of them only posix compliant, because "python is multiplatform and you can write desktop apps in it". Now on to another issue with this article, which has been mentioned in comments here. It was written in 2004 when Python might have been less popular. You will notice however that programming-illiterate people (and I don't mean people without a CS degree, I mean people who don't care if their code hits the database in a 3 level deep nested loop twice at each level) had a tendency to flock to php at that time, then it was rails, then python became hip (and still is in a way), now it's also the mobile platforms like android and iOS. Believe me, I've read code for Android that looked worse than anything you can dig out of the messiest of drupal modules. And I've written python code that's close to that too, but at least it worked fine and no one was hurt.
Good job. I already started using the latest code on some experimental code using Riak. I created a simple RiakMixIn that provided load(key) and save() methods and tada! r/w models.
TLDR: Use bz2 if maximum compression ratio is critical. Otherwise, use zlib, it's significantly faster to decompress, and unless you crank it to a very high level, faster to compress too. It would be interesting to see the results on slightly less compressible sources, like a random tarball of stuff.
Right ? I too was just about to check the last link on reddit (this time I MEANT it) before I'm off to do some serious work, and suddenly this guy shows up. What a dick...
It depends on your data. I was recently working on a problem that involved keeping a set of millions of strings. My program ran out of memory. So I gzipped the strings, which gave me about 60% compression. My program still ran out of memory. Then I tried bz2, but that actually only gave me about 45% compression, and was slower to boot. (I was surprised because bzip2 usually compresses better than gzip, but perhaps it's not well-tuned for compressing short strings.) Finally, I wrote a custom compressor with my exact data in mind. That gave me 75% compression. But my program still ran out of memory. Ended up needing to use a 64-bit box with more memory.
http://code.google.com/p/modwsgi/wiki/ConfigurationGuidelines#The_Apache_Alias_Directive
Append does return None, it modifies list A2. You could do A2 + ['d']
Interesting. I'm no compression expert. It's one of those things that has piqued my interest, but never quite enough to study it in depth.
I recommend trying xz on its lowest compression setting, -1. xz -1 is faster than bzip2 -anything (competitive even with gzip, if I remember correctly from having played with this) and usually results in smaller files even than bzip2 -9 (which unfortunately may have biased my memory of its performance in comparison to gzip, as the compression ratio /was/ somewhat important, but not enough to use xz -9 which was too slow to keep up with the data).
Thanks, man. **Edit:** The latest SVN version of mod_python compiled out of the box on my system. I was made aware of it through one of your comments on a website. Thanks again. =)
On the other end of the spectrum are algorithms like lzf which don't offer high compression levels but are very fast... it would be interesting to see a bunch of them compared, but then again, then it wouldn't be a "quick" benchmark anymore.
May as well read Dive into Python 3 while you're at it. Most of that stuff can be backported to Python 2.6 without too much difficulty and it corrects the obsolete bits of the old DiP.
No, Haskell programmers are radically less efficient since they spend all their spare time writing blog posts that explain Monads once and for all instead of actually writing code.
Problem wasn't the compression as much as the number of objects... for a linear array, you've basically 4MB for pointers alone, and that's not counting the round up that occurs for allocation per string; simple case for that, you've got a maximal string length of ~1073, which isn't much, and leaves zero space for anything else...
In retrospect, were performance or "scaling" ever issues for the system? 
`nonlocal` was basically added just to shut Paul Graham up. You have to remember that this is a _really_ old essay.
I'm slowly working my way through Wesley Chun's book. Its good, but I prefer Lutz's writing and organisation. YMMV.
OLPC is a great organization. The interviewer is a little annoying, but the representative is very informative.
Also consider [SMAZ](https://github.com/antirez/smaz) which is great when you need to keep the strings separate (ie you need to compress lots of different strings rather than a single blob composed of several).
Not too much - even though our python is far slower than when I did the same thing in c years before. These kind of transformations are usually quite IO bound anyway - so quite a bit of CPU inefficiency can be suffered before overall throughput is impacted. Most of our efforts involve focusing on data structures, algorithms and known python efficiencies first. And that works 99% of the time. But a recent and very huge transformation did require some fairly course-grained parallelism to keep the total throughput within an acceptable window. To do this we just split the data files round-robin in the extract process, then ran transforms in parallel on the results (1 per cpu core). That worked extremely well. We should be exploring some compilers like shedskin - but honestly have gotten away so far without needing to.
Just because it is in a config file doesn't mean it is wise to depend on env vars. As an example, Subversion hook scripts run with their env cleared so many programs cease to work.
I want python!
I use this for querying cPanel servers.. same basic idea: import urllib2 import base64 myUser = 'root' myServer = 'https://127.0.0.1:2087/xml-api/applist' myPass = '' authString = base64.encodestring('%s:%s' % (myUser, myPass)) headers = {'Authorization':"Basic %s" % authString} req = urllib2.Request(myServer, None, headers) openedUrl = urllib2.urlopen(req) if openedUrl: myContent = openedUrl.read() if myContent: print myContent
Note: I find it easier to build the headers manually in most languages.. rather than do whatever the HTTP object prescribes for doing basic auth.
I also had trouble with Python 2.7 not including the Authorization header on some requests and I switched back from using HTTPBasicAuthHandler. 
Thanks , your solution worked !
To say Sugar is entirely Python is stretching it a bit. Sugar is a large collection of tools, with more lines of C than of Python.&lt;/grumble&gt;
upboat for GraphViz
&gt;Ebook: $51.99 &gt;Print: $64.99 I was interested in buying this until these lines right here. Nope... I'm going to wait.
repoze.who has plugin for openid, oauth, ...
Haskell programmers hate Monad tutorials, it's the Haskell newbies who keep writing them :-)
A used copy of the print version, I suspect.
Last time I looked at this book it had an awful lack of terseness. Is there any gold in it?
I agree with zosi and would perhaps be even more damning, I had several false starts to learn Python because "Learning Python" was so verbose. I instead read doc.python.org to learn the basics and then skimmed Learning Python instead. I have Programming Python waiting in my bookcase but to paraphrase Churchill (or someone): its thickness defends itself against the risk of being read. Granted I haven't really had the time either to sit down and read it but its kind of intimidating nonetheless.
1,632 pages. make sure you don't drop this one on your toe! 
i am not sure. haven't found any, but people seems to like that book. i perfer PER by David Beazley.
I have just put on the web the notes for the lectures that were given at the EuroScipy2010 tutorial sessions: http://scipy-lectures.github.com/. They are quite condensed with very little discussion, as they were meant for teaching, but they actually contain a lot of information and should be a good way to get up to speed quickly.
I might be interested in the the ebook version if it was under $10. Surely no one would pay $52 for a digital copy!?
in usercode, the worksheet/cells API supports: worksheet.A1 (more probably, worksheet.A1.formula or worksheet.A1.value) or worksheet[1, 1] worksheet["A1"] and worksheet["A",1] lightcatcher is correct regarding the .append call. and finally, ranges should work fine. in a cell, you could use =A1:A3, which will give you a list of the values in A1 thru A3. so sum(A1:A3) (note lowercase) will work - as long as every cell in the range has a value in you can also access cell ranges in usercode: cell_range = worksheet.cell_range("A1:A3") or cell_range = worksheet.cell_range(1, 1, 1, 3) cell_range is then iterable, returning the values from its cells as before. or you can use cell_range.cells to iterate over the cells, giving you the ability to set formulae if you wish (searches around for link to the appropriate documentation page) - oh, um, that's embarassing. We really must write that up. Watch this space!
I'm going to wait until I can get a copy under $30. 
Even though it's left over from Py 2.2, Guido's "[Unifying Types and Classes](http://www.python.org/download/releases/2.2.3/descrintro/)" paper is still informative. It goes into slots, descriptors, metaclasses, method resolution order, overriding `__new__`, etc. 
It might pop up in one of O'Reilly's ebook specials. Probably for closer to $20, though.
20 bucks, I'll take it. 60 bucks, it had better give me a blow job as well.
Pro Python by Marty Alchin. Also his Pro Django book has nice insight into more advanced Python features with practical examples.
It doesn't seem that Google App Engine doesn't support xz or LZMA. See [Google App Engine Python Library Support](http://code.google.com/appengine/kb/libraries.html). Also, python doesn't support [LZMA in the standard libraries](http://docs.python.org/release/3.1.2/library/archiving.html). Maybe in the future.
How about Learning python by Mark Lutz?
O'Reilly puts their books on deep discount pretty often as part of their "Deal of the Day". The new "Programming Python" was up there for something like $18 when the e-book became available, wouldn't be surprised if it ends up there again.
I think this discussion is about intermediate/advanced books.
i read that one too. but it wasn't for me. my mistake was that i already knew some python before, having read dive into python. the book i mentioned starts with a quick refresher on syntax, object model, etc., and the rest is a reference of all the modules the author thought important. and he was right, i found myself using it on a daily basis instead of the online docs. when i think datetime module, i think PER p.336. when i think builtins functions, i think PER p.202. that's how much i love this book.
Amazon? http://www.amazon.com/Programming-Python-Mark-Lutz/dp/0596158106/ref=sr_1_1?ie=UTF8&amp;qid=1294857948&amp;sr=8-1 They have it for $34-$38...
One of the worst books on Python.
No, last time I looked it had chapters on really old, historic crap in it (yo, remember this Tkinter based browser, where I don't even remember the name because it was abandoned over 10 years ago?)
Read the Docs is great, I'm surprised it isn't utilized by the community more.
Learning Python is in my option also way to verbose. It had like 50 pages of text before anything happened like something about actually programming Python, instead of meta-learning like Python history or IDLE or some other stuff that I ususally skip over because my time more valuable than to learn the history of a programming language upfront.
The worst book is a german book published by Galileo Computing, written by two people with programming experience in Java who thought they might as well write a book about Ja...Python.
Seems to deserve a look. Thanks.
In this case, it seems that gzip with -4 has the best time-compression ratio, but I wonder what would be the best way to calculate the ratio mathematically. Just time/compression maybe?
I don't which edition you are reading but don't forget grabbing the errata; it is full of typos, logical errors.
[This](http://openbook.galileocomputing.de/python/) one?
Thanks, that cut down a module I'm working on by 20 lines. 
What is this?
O'Reilly's ebooks are awesome. You get DRM free PDFs and can go back and re-download them when ever you want. They often have some really good deals so if you don't want to pay the full price just keep an eye out for a deal.
I also recommend Python essential reference. It's one of the best programming books I've ever bought.
keep an eye out for one of their offers. On the plus side they are DRM free PDFs that you can download again and again. So it's not like you're risking ever losing it or having it's file format become obsolete any time soon.
why? 
https://bitbucket.org/marcinkuzminski/rhodecode/
Because it tries to teach you how to design and write Python programs by dumping pages of source at you at a time and not explaining design decisions. It will show you how some specific programs can be written, but won't teach you to program python better. I think it tries to, but doesn't serve as a good module cruiser. Online tutorials and PyMOTW are way more useful. It sucks as a reference. It's index is not very useful. If you want to look up something specific you'll find 2 sentences about it at 4 different places in the book. But it's never enough information, so you go to the online docs every time. If you already know enough python you will not like the book. I think it's written for copy/paste programmers.
Yes, exactly. I think there is also one for Python 3, I doubt that this one is much better; if at all.
I've done it with PyGame before, but I was playing with video and audio generation so it was natural. Not sure what else you could use.
I prefer mp3tag. With a few extra tags it can do everything Beets does and because it saves all the information in the tags rather than a database all that information is available to other apps. This combined with FMPS support by Amarok now means all the information about my music is now stored in the songs tags, which is awesome.
Hmm, that reminds me - I'd like to have a program that automatically generates different song formats. So, I can record &amp; maintain canonical copies in flac and this background process would automatically generate mpg, ogg, etc formats that correspond. A centralized database is helpful in order to detect if a song was updated, and derived copies need to be regenerated. Think this library would work well? Anybody else already write this?
I was just about to write that. Oh well, I suppose this saves duplication of effort.
appcfg.py update brain/
I presume Beets saves it as tags as well... it just uses Musicbrainz to find the information in the first place. Also, what's FMPS? A quick google doesn't reveal anything obvious :)
What does this mean?
Definitely hope that's sooner than later. Autodoc-ing models (fields especially) is definitely something I've been looking to do. I've been hacking for the time being by using info field lists. :[
Pyo? http://code.google.com/p/pyo/
Yep. :) I'm the author of beets and it definitely saves tags to the files themselves (as well as to a database).
Sounds like a great thing to build on top of beets... get in touch (email's on the homepage) if you want to work together on that.
Cool :) Does it also save the Musicbrainz tags that have no standard ID3 equivalents, like the Picard tagger? Some of these are very useful if your music player supports custom tags. 
[whatmp3](https://github.com/RecursiveForest/whatmp3) has some of this functionality (converts FLAC to mp3 and retains tags). You might want to look into that.
If anyone wants to tag files I can highly recommend Mutagen, the library used by quodlibet. It is poorly documented, but does it thing well.
From my understanding, it means that the newer WSGI spec for Python 3 has been finalized, and that some web frameworks might be able to begin porting to Python 3. If i'm understanding this correctly, its great news!
Hey, that's a cool concept for a game. Maybe it could be educational too. Cheers!
If you look at that, also consider generating different quality levels of a given format. For example, I have some hearing impairment, so I can't hear much of the detail beyond the 96 bit rate. I almost always down-sample my music to that level so I can fit more music on a given drive. Being able to enforce that from within my console-based library management tool would be a very welcome feature.
Beets is extremely powerful, let me explain why: **Musicbrainz:** A fantastic database, accessed by beets to make tag matching/auto-filling/auto-correcting rely on a steadily growing datapool of metainformation. *If you're not happy* with the correction, beets will obey your input and uses existing tags for the import. **Deployment:** Python ships with many distros including mac os x, if it is not installed that will be ridiculously easy to do. With python installed a simple 'easy_install beets' will fetch the beets dependencies for you, instead of manually downloading and installing. While running it on a server (e.g. your home media server) there are limitless undreamt-of possibilities waiting for you. **Command Line:** Beets follows the tradition of no-gui command line input (e.g. 'beet import ~/Music/afile.mp3'), 'beet list' will list library entries etc. and gui-lessness saves cpu. **Configuration:** a single configuration file will make your entire setup clear, you will be able to make file and directory naming/nesting for the library like for example what I use: path_format:$artist [$year] $album/$track $title which will give you 'Artist [Year] Albumname' for the folder and Track# Songtitle for the files. **Globbing:** using the shell's [*globbing*](http://en.wikipedia.org/wiki/Glob_%28programming%29) capabilities (e.g. wildcards, expression patterns), you will be able to precisely select certain directory structures and file name patterns without hassle: beet import ~/Music/*.mp3 # selects all files ending with mp3 beet import ~/Music/*jazz*/[A-D]* executes all folders with 'jazz' in the name and all files beginning with capital letters A to D) If you're not yet familiar with the concept [let google teach you](http://www.google.ch/#hl=de&amp;xhr=t&amp;q=globbing&amp;cp=5&amp;pf=p&amp;sclient=psy&amp;aq=0&amp;aqi=&amp;aql=&amp;oq=globbi&amp;pbx=1&amp;fp=34e81cd6e4cef50). **Open Source:** I wouldn't have to mention this great advantage for a software project like this one.
You will need a lot of time and patience to go through this one. It is overly verbose and excruciatingly detailed. You won't learn about "if" statements until page 300 or so.
+1 for Raymond Hettinger, his talks are always informative.
beets' dependencies are mainly mutagen (tagging), munkres (suggestion matching) and python-musicbrainz2 (musicbrainz python api).
I use mp3tag as well, but it can't use Musicbrainz, can it?
It does many of these, but not yet as many as Picard (e.g., no "sort artist" field). You can see the list of fields currently used by beets at the top of this file: http://code.google.com/p/beets/source/browse/beets/library.py#36
I'll check it out. Libraries are so much more useful than frameworks!
For the lazy: [PEP 3333](http://www.python.org/dev/peps/pep-3333/)
Uh... I followed the "Getting started" guide and it screwed up my music database by creating folders and shit for my songs. Good thing I stopped it before too long, but could you put up a huge warning on the top of the page that **IMPORTING WILL FUCK YOUR DIRECTORY STRUCTURE UP**? Thanks.
i enjoyed the transition from your extremely positive post (but it can't use musicbrainz can it?) to this. 
The default behavior should leave your original files behind and make copies. It should only fuck your files if you set the "delete originals" option. Maybe I should put the warning there?
It didn't delete anything, but I set my music dir in the config file to my music dir, so apparently you meant "directory you want to import files to" and I meant "directory where I hold my music". I didn't expect beets to create files, as I think that most music geeks or OCD people will have files categorised by source and won't want to mix up their friends' shitty rips with their own.
Yeah, I decided to run beets on my painstakingly curated music database in the hopes that it will let me manage it more easily and saw that it had created new folders and I couldn't find the old ones, so I was upset. Mp3tag is great, though.
haha you got to be kidding me. I've been using dev micromodels to build a full lazy Riak ORM. Not on github yet, but should be usable within a week or 2.
If you're on Linux (although I think it works on OS X with macFUSE too), you might enjoy [MP3FS](http://mp3fs.sourceforge.net/).
Yeah, that totally makes sense. I'll clarify that difference in the documentation: the library directory is where music goes *to*, not where it comes *from*. Sorry for the fuckup.
mp3tag = manual tagging beets / musicbrainz = automatic tagging The two really cannot be compared. Don't get me wrong, mp3tag is great, for what it does. But when I have 10,000 songs I want tagged overnight, it isn't going to work. I currently use Jaikoz (which also makes use of the Musicbrainz library), but I am playing around with Beets right now and it definitely looks promising.
No, it can't. It is all manual / substitution based.
Is there a list anywhere of what major Python packages are ported to Python 3 and which are not?
do you have any error log
Ah, yeah: I forgot that App Engine doesn't allow you to use arbitrary third-party Python C libraries and was thinking about the problem more from a general-purpose Python perspective. :(
I was just thinking we need a site like http://isitruby19.com/ . Now that there's interest, I might do it!
A similar project based on beets is also underway. It's called beetfs: http://code.google.com/p/beetfs/
And that right there is how great software is born.
http://onpython3yet.com/
From my understanding this is entirely correct. Flask (http://flask.pocoo.org/docs/foreword/#the-status-of-python-3) states this as their primary reason for not offering Python 3 support.
Interesting. But why is simplejson listed? To quote its description on pypi, &gt;simplejson is the externally maintained development version of the json library included with Python 2.6 and Python 3.0. Are there any other packages listed there that are now standard? **Edit**: interesting and shocking - I see my own packages listed! Must do something about that...
The idea is to list the most commonly depend-on packages first. But, I'm honestly not sure if this is supposed to be public or not, so I'm not sure how ready for actual use this is, also I might be letting a cat out of the proverbial bag... Either way, it's put together by Kumar McMillan.
To clarify, shouldn't apps drop their dependency on simplejson if the standard json library is present?
Ah yes, that is the case. "import json" is supposed to just work in 3.0, so a dependency on simplejson in 3.0 would be invalid. Especially since, as far as I can tell, simplejson is not 3.0 ready.
Shiiiiit, I was going to do this with my nearly-but-as-of-yet-finished FUSE project :( Guess I gotta find something else to do now :(
&gt;mp3tag = manual tagging &gt;beets / musicbrainz = automatic tagging a very important note. for using beets you either have tagged or partially tagged files which are processed and compared to musicbrainz.org, if desired. Files with no tags need at least artist and/or album tag set manually, so the suggestion will be more accurate. There is a beets *plugin* for fingerprinting acoustig data called LastID from a library provided by last.fm (pylastfp), which could (haven't tested yet) make untagged files' suggestion matching a lot easier. [LastID](http://code.google.com/p/beets/wiki/LastID) the mp3tag you mention is with a user interface, I suppose. I found at least 3 apps with the same name. Jaikoz is not free and at least on snow leopard very slow, even buggy (from my own 20min experience I had to give up on Jaikoz). Also mac os x is lacking a very good (I use TriTag sometimes) tagging application. iTunes can be fine for most purposes, but not everybody wants to use it (itunes=bloated).
Well it can use freedb...
More details are required, first off what do you mean "just can't get it to work". Can you run python from the command prompt, can you do "import pygame" from the python interpreter, or is the problem something else? Given this info I could help further, but I'll assume for now that you can run python from the command prompt and the problem is pygame hasn't been installed correctly. Did you use the installer for pygame (http://pygame.org/ftp/pygame-1.9.1.win32-py2.6.msi) or the source zip file? If you used the source zip how did you install it by: * unzip it somewhere and run "python setup.py install" (correct way) * just unzip it to the python directory (the wrong way) Eitherway I would recommend just using the installer, since you're a beginner. But I will point you to setuptools (http://pypi.python.org/pypi/setuptools), which means you can install most python packages using for example easy_install pygame after installing setuptools, and adding the Scripts directory (in the python dir) to your windows path. Anyway, I recommend you read this page first http://docs.python.org/install/index.html A final point, is that I don't normally install python under program files, but in C:\python26, I don't see why this should be an issue but perhaps it is. EDIT: Just remembered since pygame has some things written in C, a C compiler will be required to build the package (VS2008 express edition) so I would say DO NOT try and the "python setup.py install" method, as this can be a pain to setup on windows (almost trivial on linux though).
Ah that's okay, good thing I saw how long it took and stopped it before long. I don't want something that will change my directory structure (or even rename my files), I want something that will tag them correctly/consistently. Can beets do that?
That's pretty cool. I'll need to check out the code. I really like the simplified command line interface, but I would like to maybe add an optional web interface. I'm thinking a simple Flask application.
* [PyJack](http://sourceforge.net/projects/py-jack/): using [JACK](http://jackaudio.org/) * [PyAudio](http://people.csail.mit.edu/hubert/pyaudio/): using portaudio V19 You could even play lower level with the stdlib if you have OSS: [ossaudiodev](http://docs.python.org/library/ossaudiodev.html) 
Thanks for the overview, I'll have to check this out because I'm already running a media server using [Music Player Daemon](http://en.wikipedia.org/wiki/Music_Player_Daemon) and I wrote a playlist generator [mpd-myfm](https://github.com/xolox/mpd-myfm) in collaboration with a friend of mine which uses Last.fm to find related artists and I'd love an alternative to the Last.fm web service. Small nitpick: [Glob patterns](http://en.wikipedia.org/wiki/Glob_%28programming%29) are quite different from regular expressions (and on UNIX they're expanded by the shell, not Python).
best to not do that, and instead use a dict or at least have the instance keep a list of attributes you care about. even simpler is to use an existing ORM like Storm or SQLAlchemy.
When I attempt to run a program with pygame I get the error: no module named pygame 
Nice. I look forward to that. My code is really simple and is just glue. It's not very elegant but it works. I'll slap the MixIn in a gist this afternoon if I remember. 
Ok so that means python can't find the module to import it (I guess you already knew that). To double check something weird isn't happening open IDLE (the python interpreter, start-&gt;programs-&gt;python-&gt;IDLE), this allows you enter python commands interactively. Type "import pygame", and see if you get the same error. Also, could you provide your python path, do this by entering in IDLE import sys print sys.path and copy the text here. And also the full path where you think pygame is installed. Finally, could you tell me whether you used the same installer I linked to above. (Sorry if I'm being a little patronising, but it's easier to give full instructions)
I have a library of python books but if my house was on fire I'd grab and [Programming in Python 3](http://www.amazon.com/Programming-Python-Complete-Introduction-Language/dp/0321680561/ref=sr_1_7?ie=UTF8&amp;qid=1294925927&amp;sr=8-7), 2nd ed., Mark Mark Summerfield and [Python Essential Reference](http://www.amazon.com/Python-Essential-Reference-David-Beazley/dp/0672329786/ref=sr_1_6?ie=UTF8&amp;qid=1294925927&amp;sr=8-6), 4th ed., David Beazley. Both books cover more ground, and more effectively than any others I've read, and I've read numerous, including Lulz's most recent. While Mark's books are good, and the Python community has greatly benefited from his works, they're not the first books I reach for. Do not be misled by page count. Summerfield and Beazley both share a talent for covering a wide expanse of topics with sufficient detail to discuss a given topic to my satisfaction and comfortable comprehension, while exercising enough brevity to keep me from glazing. Really looking forward to [Python Standard Library by Example](http://www.amazon.com/Python-Standard-Library-Example-Developers/dp/0321767349/ref=sr_1_1?ie=UTF8&amp;qid=1294946854&amp;sr=8-1) by the same publisher (Addison-Wesley). **NO AFFILIATION, just a Python book junkie**.
I laughed. :D
Look at pyaudiere. It works on Windows and is really really simple: import audiere from time import sleep buffer = ... # fill the buffer with floats from -1.0 to 1.0 device = audiere.open_device() stream = device.open_array(buffer, 44100) stream.play() while stream.playing: sleep(.1) 
Probably one of the biggest Python web-related news 2011.
For extra lazy, from the pep 3333 page: &gt;While for procedural reasons [6], this must be a distinct PEP, no changes were made that invalidate previously-compliant servers or applications under Python 2.x. If your 2.x application or server is compliant to PEP 333, it is also compliant with this PEP.
thank you.
Fucked up my directory structure without warning and with leaving the *fuck up my directory structure* option unset. Thank you! btw, does it support writing album art to mp3 tags? :)
Quick question. I like to organize compilations differently from regular albums. Can Beets do this? I lay out my directories like so: Pink Floyd - The Wall/1-01_In The Flesh.mp3 Pulp Fiction Soundtrack/1-01_Misirlou.mp3 So compilations don't show the artist name, basically. Currently I do it all with a python script I wrote, but beets looks pretty damn cool.
I love the "For the Lazy" comment =) and always look for it. Thank you.
For the even lazier: [diff between PEP 333 and 3333](http://svn.python.org/view/peps/trunk/pep-3333.txt?r1=84854&amp;r2=HEAD)
then the correct sentence should be *beets understands 'glob expressions' (e.g. wildcards, expression patterns)* ? I made the overview because not many will read the documentation thoroughly, and even less ppl will get the concept from reading it only once (ofc some parts are quite unfamiliar if you're not really shell-experienced). 
I always look for it, too. It wasn't here so I decided to provide this invaluable community service.
I wouldn't get too smug unless you're also doing some hacking with other things like F#, Erlang, Haskell, or other languages you're learning just for the hell of it. Python was the example there because "they learn it because they genuinely like to program and aren't satisfied with the languages they already know", and these days with Python so much a part of the mainstream programming experience; it's not necessarily true anymore that someone knows Python just for the joy of it.
*By default, the command **import** copies files your the library directory and updates the ID3 tags on your music. If you'd like to leave your music files untouched, try the -C (don't copy) and -W (don't write tags) options. You can also disable this behavior by default in the configuration file.* taken from [/beets/wiki/Usage](http://code.google.com/p/beets/wiki/Usage)
I have had problems with many compilations I've tried, that's a pretty big draw-back atm. Maybe the author [sampsyo](http://www.reddit.com/user/sampsyo) will give you a better answer on this, but as far as I know it's not very well implemented. I'd like to have the option to put compilations in a different folder, this should not be too difficult to implement I guess.
Even if we assume that the article is right, it was written in 2004. That only the brightest programmers were using Python seven years ago does not mean that they are, now.
That site lists nose as not supporting python3 -- but it does, and has the correct classifier set on pypi.
&gt; *how to open data as an array...* How is data stored? How girl get praegn....oh sorry. If it can be treated as a text file, `readlines()` returns an array. But you say "*16 bit chunks*", so you may have to do some post-processing. We'll need more details. 
a = list(open('/dev/urandom').read(1024)) a is now a list with each element being, I believe, 1 byte long. FYI: open('/dev/urandom').read(1024) returns a string 
"data" is pretty ambiguous. an array is data. a file is data. Brent Spiner is Data. I assume when you say "data" you mean a file? Here's how you open a file (binary read): file = open(filename, 'rb') Then you want to read 16b chunks? I'd use [struct.unpack](http://docs.python.org/library/struct.html). The following will read in an unsigned short (16b/2B of data) in big endian format (because I have no clue what byte order you're using): value = struct.unpack('&gt;H', file.read(2)) Now to tie it all together: def data(filename): """kxpe is bad at describing his problem.""" file = open(filename, 'rb') array = [] EOF = None while not EOF: datum = file.readline(2) if datum: array.append(struct.unpack('&gt;H', datum) else: EOF = "GTFO" file.close() return array 
Don't forget [expanduser()](http://docs.python.org/library/os.path.html#os.path.expanduser).
Unfortunately, as axolot notes, compilations are a weak point in beets right now. I definitely want to do exactly the same thing you do, and I'm planning on fixing compilations in an upcoming release. I've added a note to the bug tracker: http://code.google.com/p/beets/issues/detail?id=48
Have a look at the [array](http://docs.python.org/library/array.html) module. import array, os.path filesize = os.path.getsize(filename) data = array.array('H') # H = unsigned short = 2bytes = 16bit number_of_items_in_file = filesize / data.itemsize with open(filename) as fp: data.fromfile(fp, number_of_items_in_file) if byteorder != native: data.byteswap()
Looks interesting. I'll take a look at it when the magic autotagging is improved.
Well I decided to uninstall both python and pygame and just start over. What would be the best method for installing python and pygame including which version, wheter I should install 32 bit or 64 bit python, and where they should be installed. I'm guessing from your previous answer i should install python in the C drive with pygame apart of that directory? And then use the pypi to install pygame?
I've also been thinking about writing a Web interface eventually, and I was even planning on using Flask. Let me know if you want to collaborate (email's on the beets homepage).
Let me know if you have specific test cases that need improving. I'd love to continue improving accuracy, but beets already works pretty well on my library. :)
Also, if it's a lot of data, "numpy.array".
Not yet. I haven't implemented this yet because I don't personally use it -- I prefer to have JPG files on the side. But if you're interested, please file a bug. Or feel free to send along a patch!
`readlines` returns a `list`, which isn't the same thing at all.
Not to be a total jerk, but that `EOF` business is pretty hideous. There are much nicer ways to read through the lines of a file.
You are totally right and I was having a big old brain fart. Didn't even think about doing it as a binary file. I beg forgiveness for my stupidity and promise to never comment without thinking it thru again. 
I recommend 32 bit python 2.6.6 installed to c:\python26. Use the pygame exe or msi installer, and it shouldn't ask you where, it should pick up the location from the registry.
Nothing should be installed c:\program files (x86) That is probably your problem.
Yeah this is probably out of date. I'm going to get it updated.
You're quite the optimist if you expect everyone to read all the docs before trying something out.
They do two different things. You get the same value, but one changes the list, so there is or are more operations involved. That alone can give you an educated guess on which is faster. What is more appropriate for your code, however...
Very cool. I'll try to find some time to play around with beets this weekend. Maybe I'll even dig into the code and try to come up with something.
Looks awesome, axolot. Can I use beets to clean up metadata on my library without breaking the consistency of my iTunes library? As long as I'm using an iPhone I'm going to be using iTunes.
Try using setting the "import_copy" setting to false in the config file. This will leave the files where they are but update their ID3 metadata. I'm working on adding better support for iTunes -- I'd love to be able to export an iTunes database file from beets.
You were asking a question, this was my answer. This project is still in development, things should be taken more carefully. I also think that the documentation and all functions are not that simple. I guess I caught the right moment to start a reddit about it:).
Why don't you show us how you would do it?
I'd love to see a customizable logging system. I see myself confronted to 200+ GB of mp3s I want to beet, this would be pretty helpful. I came across http://packages.python.org/Logbook/ , but standard logging library will do fine as well. 
People who ask me how to "put data into an array" don't get beautiful code. I'm still fairly new to python. I understand that things like lamda, filter(), map() and such can be really powerful, concise and self descriptive, but I feel I haven't really mastered them or even scraped the surface. Would you mind rewriting my function to prove your point?
Maybe something like this? from struct import unpack class DataError(Exception): pass def iterate_words(file_): while True: bytes_ = file_.read(2) if len(bytes_) != 2: raise StopIteration yield unpack("=h", bytes_)[0] def data(filename): try: with open(filename, "rb") as file_: return [word for word in iterate_words(file_)] except IOError: raise DataError("could not open input file") 
Yep, it was a bit out of date but I just refreshed the DB and will put the sync script into cron. If anyone wants to help on this site then please do! https://bitbucket.org/kumar303/onpython3yet I think it will really help to identify where the straggler modules are that are holding people back. It certainly needs more work but the basic structure is there http://onpython3yet.com/
Actually, beets isn't even doing that. In your example, the shell is expanding those expressions before sending them to beets. You can do the same with any shell command: ls ~/Music/*jazz*/[A-D]*
PIL is the one that fucked me most recently. Back on 2.6 now.
Ok, I just tested it (after installing the lastfm audio fingerprint plugin). My notes (typed as I run the program): - No feedback on whether the plugin is running or not - CPU usage is bursty, which suggests it could work faster. Also, doesn't seem to be using more than 1 core at any point. - It seems it applies a big penalty to changing the case of letters. It has asked many times to change an "A" for an "a". It shouldn't. - In the same category, it seems to apply a big penalty to changing an "á" to an "a". Accents on what is the same letter should be changed without doubt. (My collection has Spanish music) - I don't know what to do when facing this: Finding tags for " - ". Candidates: 1. Blur - Blur: The Best Of (0.393939393939) 2. Blur - 1997-02-10: Stop Dreaming: The Astoria, London, UK (0.596761193998) 3. Blur - 1995-06-17: A Knees-Up at Mile End: Mile End Stadium, London, UK (0.664268659742) 4. Blur - 1994-11-12: Blackout!: The Factory, Milan, Italy (0.699685602955) 5. Blur - The Special Collectors Edition (0.726702608939) What file are we talking about? " - "? I'm pretty sure I don't have a file named like that. Maybe it's reading the empty ID3 tags on the file? After choosing 1, it gives me: To: Blur - Blur: The Best Of (Distance: 0.393939393939) * (0) -&gt; Song 2 (2) * (0) -&gt; There's No Other Way (3) * (0) -&gt; The Universal (4) * (0) -&gt; Coffee &amp; TV (5) * (0) -&gt; Parklife (6) * (0) -&gt; End of a Century (7) * (0) -&gt; No Distance Left to Run (8) * (0) -&gt; Tender (9) * (0) -&gt; Girls &amp; Boys (10) * (0) -&gt; Charmless Man (11) * (0) -&gt; She's So High (12) * (0) -&gt; Country House (13) * (0) -&gt; To the End (14) * (0) -&gt; On Your Own (15) * (0) -&gt; This Is a Low (16) * (0) -&gt; For Tomorrow (17) * (0) -&gt; Music Is My Radar (18) How should I know? It should print the file path and name, so I know what we're talking about! It seems the concept of distance is based on how similar or not the new tags are related to the old ones, which, in a badly tagged library, is obvious it will have a HUGE distance and keep asking for stuff. Maybe it should look for clues on the file name? I just basically tagged everything blind... It really needs to tell me more info in those cases! - When it doesn't know which album it is, it offers options, but I have no idea how good or bad it will turn out to be. After I choosed one, it said: Correcting tags from: Charly Garcí - 87-__-__ . Badia &amp; Cia - Canal 13 - Buenos Aires, Argentina To: Charly Garcia &amp; Luis Alberto Spinetta - El disco que no fue (Distance: 0.710637517522) * Necesito tu amor -&gt; La Pelcana Y El Androide * Buscando un símbolo de paz -&gt; Hablando A Tu Corazon * Parte de la religión -&gt; La Pelicana Y El Androide * Yendo de la cama al living -&gt; Hablando A Tu Corazon * Rap de las hormigas -&gt; Zapada * No voy en tren -&gt; Rezo Por Vos * Nos siguen pegando abajo (pecado mortal) -&gt; Rezo Por Vos Which clearly is not the correct album, not one song matches! I'll let it run for a while now, I'll edit this later. I'll keep my brokenly tagged library around, if you wish to test something. EDIT: Crashed: Traceback (most recent call last): File "./beet", line 20, in &lt;module&gt; beets.ui.main() File "/home/ismael/Aplicaciones/beets/beets/beets/ui/__init__.py", line 457, in main subcommand.func(lib, config, suboptions, subargs) File "/home/ismael/Aplicaciones/beets/beets/beets/ui/commands.py", line 600, in import_func opts.logpath, art, threaded, color, delete, quiet) File "/home/ismael/Aplicaciones/beets/beets/beets/ui/commands.py", line 529, in import_files pl.run_parallel() File "/home/ismael/Aplicaciones/beets/beets/beets/ui/pipeline.py", line 138, in run out = self.coro.send(msg) File "/home/ismael/Aplicaciones/beets/beets/beets/ui/commands.py", line 402, in user_query rec, color, quiet) File "/home/ismael/Aplicaciones/beets/beets/beets/ui/commands.py", line 240, in choose_match if choice in (CHOICE_SKIP, CHOICE_ASIS): UnboundLocalError: local variable 'choice' referenced before assignment 
 if len(bytes_) != 2: return FTFY
These are all things I've encountered several times. But I don't have many entirely untagged files, so I tend to use the existing tags when there is no match. I check every folder after a process (which I shouldn't have to do - but if you do it once and for all it will be necessary to tag them yourself). But i'm really happy with my library now. {~1k albums atm}
Oh sorry, I thought you were replying to my other comment. To be fair, that doesn't really answer the parent question well :)
Fast &amp; sloppy &gt;&gt;&gt; import array &gt;&gt;&gt; a = array.array('h', open(r'c:\temp\test.bin','rb').read()) 
Maybe, but it's easier and cleaner to just always have `simplejson` as a dependency and always use it, rather than do an import dance based on `sys.version_info`. People are doing the same thing with `unittest2` now.
But correcting and tagging files goes along with renaming them. It could speed up the process indeed omitting renaming from the musicbrainz match. But i've just tried, if you use the -C flag it will only apply the match and leave the directory structure alone, only changes the filenames. (and fetches the artwork). What can you do with my answer now? :) **PS: I don't use playlists. But I can see it would be a necessary option to disable renaming**
Why does tagging the files go along with renaming (or do you not mean in general)? You can change the ID3 tag without renaming the file, which is what I actually need, otherwise all my playlists will break. I never look at the filename anyway, but my media player uses the tags to export files to my mobile and to show me the song titles. Thanks for the answer :)
The generation of playlists is actually another problem or plugin suggestion for all you programmers out there:)
Oh this looks cool. How does "Buffer" work though? 
I got it to work! Thanks!!!
It's not clear to me why this would be significantly faster than regular loop unrolling. 
As far as I know this optimization's goal is mostly different from the goal of regular loop unrolling. A single iteration of the loop is unrolled to form the preamble, doing so allows PyPy's escape analysis to enable more effective optimizations of the loop body, for instance the W_IntObjects are unboxed in the preamble, allowing the actual loop to operate on unboxed integers, which could possibly enable further optimization. More or less a single iteration is being unrolled to avoid dynamic overhead. Note that I follow these optimizations but I'm by no means an expert.
buffer = [0.0, 1.0, -1.0] * 44100 Kinda like that. Exactly what you asked for -- raw bits (well, floats) to send to the speaker.
Is it possible to customise how beets arranges your music by some criteria to treat certain folders or certain types of albums differently, or will it be a case of manually slogging through my library once, changing the settings according to which folders I'm going to import? I have things like game OSTs in folders with game names, which can contain tracks from multiple artists, and other folders of that nature arranged for logical listening rather than logical directory structuring, with values in the directory structure which may not be in any of the tags for a particular track.
I don't currently have anything as sophisticated as what you're describing implemented. However, this kind of personal preference is exactly why I implemented beets as a library -- if you know a little Python, it shouldn't be very hard to write a program that moves files around according to your exact preferences. (I imagine this would be a lot harder to do if you had to deal with the files directly.) If you're interested, I can try to throw together an example to show you what I'm talking about.
Thanks for all the feedback. First, the matching algorithm currently does already ignore case changes. It will still show them to you, for the sake of consistency, but they don't count toward the score. You're totally right about the accented characters, though. I should fix that. Yes, the " - " does indicate missing tags. The user experience there should be better, I agree -- that message doesn't indicate that tags are missing. Another good thing to work on. As you say, it should absolutely give you the path to the file if the tags aren't clear enough. Another issue with the beets tagger, as you point out, is that it has a tendency to present *really bad* matches when it can't find anything good. For the Charly Garcia album you mention, there probably isn't anything in the MusicBrainz database that will be a satisfactory match. I want to implement a system that will catch that fact and tell you so, but this is harder than it initially sounds. One good rule of thumb is to pay attention to that distance number. There, 0.71 is a pretty good indication that it's not a good fit -- usually, an appropriate match has distance 0.2 or lower. (The colors give clues.) And also thanks for the crash report. How embarrassing! Filing a bug for myself now.
Seems like it wouldn't be too difficult for the website to poll PyPI, get top couple hundred packages, and check if they have the Python 3 classifier. That would also allow them to have a little panel of honor for recently converted projects.
``Assert`` will probably be deprecated next release; thanks for the feedback. The dev version [parses assert expressions with _ast](http://i.imgur.com/1s8ZY.png) and for added readability highlights them syntactically. Unlike py.test and nose this will be side-effect-free.
I just started looking at how `path_format` could be customised per-album rather than being a `Library` level thing when I saw [ozzilee's question about compilation albums](http://www.reddit.com/r/Python/comments/f14cr/beets_the_music_geeks_media_organizing_and/c1cl2ni). Having a separate `path_format` setting for compilations should take care of standalone OST issues. For anything more complex, I suppose an option to retain the current folder structure on import would really do the trick when dealing with pre-organised libraries. I was thinking about configuration files in folders defining rules for all child content, but I really wouldn't fancy trying to configure something to deal with this sort of layout: C:\MUSIC\YOKO KANNO ├───Ashurajo no Hitomi OST ├───Brain Powerd │ ├───OST 1 │ └───OST 2 ├───CM Yoko ├───Compilation Vol. 1 ├───Cowboy Bebop │ ├───Ask DNA Mini Album │ ├───CD Box │ │ ├───Disc 1 │ │ ├───Disc 2 │ │ ├───Disc 3 │ │ ├───Disc 4 │ │ └───Disc 5 │ ├───Knockin on Heaven's Door - Future Blues OST │ │ ├───Disc 1 │ │ └───Disc 2 │ ├───Music For Freelance │ ├───OST 1 │ ├───OST 2 (No Disc) │ ├───OST 3 (Blue) │ └───Vitaminless │
I would [guess](http://www.google.com/codesearch/p?hl=en#ZUFOuzrKuRo/trunk/cpython/picture.py&amp;q=init_picture%20package:http://pygraphics%5C.googlecode%5C.com&amp;d=2) that you probably don't have PIL installed.
Three things: 1. you didn't say what version of pygraphics you installed. try a different version. 2. double check you've got any extensions built correctly. this can be a pain on winders. 3. your ide (or its sandbox) might be tripping things up. try running your file from the command line. 
&gt;implement a system that will catch that fact and then it should guide you to manual search. In case you're running it in the background there should be a config entry for skipping unrecognized/unprocessed files and make an entry in a log file.
Installed PIL still no luck.
The version of Pygraphics installed is off the book's code on the publisher's website. I haven't messed with any extensions or anything, I just installed the module the way the book explained to.
Any particular reason for using EOF over a break statement?
Yeah, that feature is sounding better and better. Should get on that... If you want to preserve the directory structure, consider setting the "import_copy" config file value to false. This will leave everything in place when importing music. More info [on the wiki](http://code.google.com/p/beets/wiki/Usage#Configuration).
Maybe search/add: http://code.google.com/p/pygraphics/issues/list Also, learn to Google: http://forums.pragprog.com/forums/82/posts
nope.
Calling map with ord is actually faster than struct calls.
http://docs.python.org/library/functions.html#ord How do you get a 2B short out of that?
I would change `[word for word in iterate_words(file_)]` to `list(iterate_words(file_))` for style reasons, I guess. 
 Since Python doesn't have a do-while loop, the usual thing to do is write: while True: Do Stuff if condition: break Instead of using a variable like your EOF. Also, by convention, all caps are usually constants not variables. 
Awesome! I love it. You have gained a supporter.
Assuming I didn't Google it already? I ran into the same results you pointed to. That didn't fix anything. 
NP, it seems a very promising project. How strange... I don't understand then why it asked to change the files, when all the differences it showed were the case of the filenames. About the distance: I guess that if the distance is high enough, it should tell you that it's hopeless and not even attempt to tag it. After seeing that album that didn't match even one song, I wonder what it takes to get a 0.9 score! I also want to compliment you on the documentation you have made. It is really well organized, clear and easy to read.
Sometimes import bugs will be fixed by wiping out all the .pyc files.. Are you _sure_ you have pygraphics installed properly? Is it installed to the same python you're using when you launch your program? Is the version you installed the same version the book's code is using?
Apologies for coming across like that; I shouldn't have put in the "learn to..." bit. Perhaps log an issue at the first link.
I had similar problems when I was starting to use pyspred, spyder and matplotlib. If you are trying to use python on a mac, you are a brave soul. This sort of problem is exactly why I switched to Ubuntu. Installing python libraries on a mac with all of the correct dependencies = impossible, on ubuntu = 3 clicks. p.s. the reason I said mac is your path format 
On Ubuntu actually. I just copied the output out of Wingware 101's console.
I followed the instructions that came with the book. But I'm going to try installing a newer version of Pygraphics, I think the book's one is older and incompatible with 2.6.6 (default Ubuntu Python.) 
Logged an issue, hopefully I can get some help with that.
If its a JSON string also, there is no way out is it?
Hmm, needs more generators and exception handlers that raise custom exceptions. But seriously, why isn't this the top suggestion for such a simple task? Array is in the standard library.
Sometimes, beets asks for confirmation if the metadata doesn't differ but the track lengths do. Sometimes, MusicBrainz's track length information is wonky or missing. Yeah, an upper threshold does seem like a good idea. I would need to develop an interface that lets you override that, though, in extreme circumstances. Because of [the way distances are calculated](http://en.wikipedia.org/wiki/Levenshtein_distance), a near-1.0 distance would have to be pathological. :) I'm glad you like the docs! Sometimes those are the most fun.
Not entirely true. Mac ports works pretty well, then just "sudo port install python".
Then it would be more prudent to inform the user why the distance is so big. Right now only title and track number are shown, maybe it should show whatever differs? I doubt anyone would want to automatically tag a song which can't be reliably recognized. In any case, the user would try to search manually, or skip it.
via: http://www.freetechbooks.com/python-for-informatics-exploring-information-t826.html
Yes, I can do so - but what do others do? I also use Libs / Tools from 3rd party developpers and they will probably not use this Shebang. So I think it sucks, that arch linux chose to go ist own way. pip and easy_install are broken right now, because the Shebang doens't fit with the arch-System.
Perhaps you posted in the wrong thread?
Yeah, you're right. I almost said that you can just change the shebang line but that only works for very small libraries where you only have to change one or two files but becomes quite a daunting task for libraries the size of sage.
It's not yet released, but it's supposed to be released in a couple of days, patience :)
Ooops, sorry. I just saw the version number in the documentation. Nevertheless an upcoming release of this great lib is always worth a message :-)
We improved (at least I hope that it's better now) the documentation design, so that plus the mentioning of the development release in the documentation does give the impression of a new version :)
That's more anticlimactic than paradoxical. :)
I love this app as much as the next person, but for a brief moment I thought it was [this program](http://www.theprodukkt.com/werkkzeug1). Sad panda :(
I'll do that for the awkward stuff - thanks. There are so many possibilities and unexpected scenarios when it comes to trying to programatically organise music. I just had to create 11 empty MP3 files to get this disc to autotag: http://musicbrainz.org/release/824258e9-8ab2-446e-a696-d562b5717c2d.html
Combine it with a shift left in list comprehension.
Use homebrew...I installed Python without any hitches at all. $ brew install python $ brew install pip Done!
That's fair. Coming from a lower level of programing (assembly, C) I'm in the habit of using flags.
Cool.
Bizarre. Yes, and it sometimes doesn't help that the MusicBrainz editors are big sticklers for strict correctness...
Good point. Grounds for [another bug](http://code.google.com/p/beets/issues/detail?id=121) on that there tracker...
Stop and think about what you're writing. In once sense, everything in memory or on disk is a series of signals that represents a sequence of numbers between 0 and 255. We can represent those numbers as symbols and glyphs using an agreed-upon mapping, like 78 as "N" and 54 as "6" and 33 as "!". When you are going to write out some data, you had better have a scheme in mind for how to represent it. You can write out raw numbers "49,9" as 52 and 57 and 44 and 57. Even that assumes that you're converting a number to a base-10 representation. The upshot that's important for you right now is that the python IO routines are expecting you to provide a string-like object to send to disk. When you read, you get a string out, and when you write in, it wants a string to use. It's the lingua-franca of writing to disk. There are modules for packing and unpacking "strings" to and from other types. Is that *0x48a8c63fed89d81d823123de* two integers, or 12 letters, or one double floating-point number? ... it's up to you. You have to know. On disk, it's all a pattern of 1s and 0s, and the meaning of those are your responsibility. (Or the responsibility of someone who gave you this data and decided for you.) So, some modules you should learn about: * struct * json * numpy (maybe. not in standard lib) ---- My short summary: "Writing arrays to files" means just about two dozen things, and Python isn't taking sides. Files take strings. You have to convert in a way you want.
 &gt;&gt;&gt; import cPickle &gt;&gt;&gt; a = [1,2,3,4] &gt;&gt;&gt; cPickle.dump(a,open("array.data","w+")) &gt;&gt;&gt; print cPickle.load(open("array.data","r")) [1, 2, 3, 4] 
Looks like a task for the ["pickle"](http://docs.python.org/library/pickle.html) module. If the data is extremly large you can use the ["tables"](http://www.pytables.org/moin) module instead.
Amazing book.
Great find, thanks!!
Mr. Dumpleton, I gotta say--you never cease to amaze me. Every single question about mod_wsgi I've ever seen anywhere... you somehow manage to answer. Kudos to you, good sir.
Yes they aaarrrrrrrr.....
A message queue is really the thing to use for the "processing files" use case. websockets/socket.io are more useful when you need bidirectional realtime communication.
I love Werkzeug. It is the best light-weight framework for Python, and rarely gets the attention it deserves.
Wouldn't a more stable serialization format be better? Something like JSON perhaps? Simple types like arrays map trivially between Python and JSON.
Pickle is fast and the standard serialization format in python. Unless you want interoperability with non-python code there's no reason to use anything else. Oh and pickle should never be used in a server setting because of security issues when unpickling user-supplied data.
The issue you logged does not include the traceback, or a sample program that exhibits the problem.
Where did you get pygraphics from? The tarballs for 1.5 don't even **contain** a media.py. The trunk does, but it looks broken to me.
This is the first time I read about "informatics". This is going to be a translation problem. The french informatique and the german Informatik both mean computer science. http://translate.google.com/#de|en|informatik 
You didn't ask me, but I'd probably do something like this to read the lines of a *text* file (I don't think trying to read the lines of a binary file makes much sense usually): with file(filename) as fp: for line in fp: # do stuff Regarding the OP's question (assuming binary data but disregarding byte order), I might do something like this (the usual caveats and disclaimers apply): words = [] with file(filename, 'rb') as fp: data = fp.read() for i in range(0, len(data), 2): words.append(data[i:i+2])
and mod_python, too.
Hmmm, perhaps you could share what you need this for? I'm not sure if the images you'll be working with would be as simplistic as the image you've shown, but I wonder if you could use the fact that the shape is all black, and its background is white? If you're looking to paste this on to another image somewhere or something, you're probably better off using a mask of some sort. (See the Image module's "paste," "blend," and "composite.")
I'm not sure why you would expect anyone to be able to answer your question without making assumptions or guessing; it's extremely vague. For example, when you say "array", are you talking about an actual array data type or a list? Also, what's a "channel"? What does the input data look like? Why do you need to save the data to a file to operate on it? Et cetera. At the very least, if you want someone to help you debug your code, you should post it and the complete traceback somewhere.
No, this incorrect because it is convoluted for no good reason.
I was going to rewrite it, but someone else already did. Take a look at this comment by wylee: http://www.reddit.com/r/Python/comments/f1n5u/help_with_opening_data_as_an_array_in_python/c1cs76a
The [Python Imaging Library](http://www.pythonware.com/products/pil/) will let you evaluate every pixel of an image, based on (x,y) position. Would that be helpful?
change log: [http://wingware.com/pub/wingide/prerelease/4.0.0-b6/CHANGELOG.txt](http://wingware.com/pub/wingide/prerelease/4.0.0-b6/CHANGELOG.txt) 
I'm no expert in this sort of field, but ill just say the first thing I would try if I was going to make something like that. First, find the edge, this would be done by just stepping through each pixel until the colour is white. (pixel white? no? -&gt; x += 1) Once the edge is found, note the position in a list of tuples. Check each of the pixels surrounding the 'current' one to see if they are also white, if a pixel is white, check to see that it is adjacent to a black pixel, and not already noted in the positions list. If that pixel has not already been visited and meets the "adjacent to black pixel" requirement, write it's position to the list and "move" to it, check it's surrounding pixels, etc. Continue until no valid pixels are found. Dunno if this would work or not, I think it might, but probably not very well.
Bought Pro a couple months back, thanks for the great IDE
Will any of the images be anti-aliased or are they completely black and white?
I wrote a method for Pygame that does this, [Mask.outline](http://www.pygame.org/docs/ref/mask.html#Mask.outline). I implemented it off of an algorithm that I can't find now and apparently forgot to cite in the source. In psuedo-python, you would use it like: image = pygame.image.load("image.png") bitmask = pygame.mask.from_threshold(image, (255,255,255), (128,128,128)) blob = bitmask.connected_component() outline = blob.outline() outline ends up as a coordinate list of points forming the outline. Ah, found it. It's called [Moore-Neighbor Tracing](http://www.imageprocessingplace.com/downloads_V3/root_downloads/tutorials/contour_tracing_Abeer_George_Ghuneim/moore.html). The page describes it pretty well. What I implemented in Pygame is basically the modified version at the end of the page that checks against the first two outline pixels.
then perhaps you are not one of the people it is intended for?
You can do it with PIL easily enough, especially if its just a 2 tone image. Just find a edge and trace it. However, for anything more complicated id recommend to look at something like [OpenCV](http://opencv.willowgarage.com/wiki/) (Computer Vision) which can do shape recognition, or you can look at how gdal implements its [gdal_polygonize](http://www.gdal.org/gdal__alg_8h.html#3f522a9035d3512b5d414fb4752671b1) functions
Check out the potrace algorithm - quite simple and works well. Sellinger's description of the algo can be found in [this PDF](http://potrace.sourceforge.net/potrace.pdf).
You can also grab [the experimental version of pyglet](https://pyglet.googlecode.com/hg/) for python 3.
I'm really digging that list of "Engines and libraries", I haven't heard of half of them, it should be fun trying them out :P
Neither do I and I made this list. I'm just a bit scared of total beginners coming to the wiki just picking one engine randomly. I'm actually thinking about making a table instead of this list, pointing out if there is a decent documentation, if it's Python 3 supported, in active development... But then that would be boring for the people to edit the page. &gt;:(
You can also use canvas with html5 using [Pyjamas](http://pyjs.org/) with mouse events for actual touch events. Ok, that's not the more natural way of developing on iOS/Android but it actually "works" (on an ipad).
completely black and white. 
Yeah, it would be a good idea to tell people what they should start off with. I've used pygame before for making little demos, so I have a vague idea of what's good for me. But there does seem to be a glut of game development wikis at the moment. 
I agree, i'll dedicate a page for that. About the "glut of game development wikis" my intention was not to make another wiki, there's none for pyglet, the pygame one makes me vomit, python-ogre has one but with no external resources and the Panda3d wiki doesn't seem public. And still my intention is not to be a contributor for each engine, i'd like it to be a starting point for beginners and a good place for advanced users who are just looking for some good resources. I was a bit surprised to discover after a few years with python game development that there was a forum about it called "[pyedpypers](http://pyedpypers.org/forum/)" there's not many people but it's active and i didn't even know it. My point is that there's plenty of resources but no index of them. I'm pretty sure that a wiki + a forum would be great (if only pyedpypers could stop their manual registration).
note that its not a framework
Agreed on Python Essential Reference-- it is a fantastic book.
Wow.....wing is just now adding refactoring. I cant imagine a comerical IDE not having this basic feature.
The idea is nice and is easily implemented, but the explanation is pretty self-indulgent. &gt; I prefer the term “caching” over “memoization”, so I’ll use “caching” from now on. Memoization has a specialized meaning in computing, do not discard it. Although related to caching, memoization refers to a specific case of this optimization.
I wouldn't call that an easy implementation. Have you looked at `SleekCallArgs` which `cache` depends on? Thanks for the note about the term "memoization": I didn't know that.
Some sensible way of compiling useful resources for python game development would be pretty useful, really. That 'pyedpypers' forum looks pretty dead, to be honest. BTW, it seems like the discussion page isn't set as editable at the moment. :/
I personally don't think the stdlib needs a full blown template language inside of it.
No.
I've always found [this](http://codepad.org/qEjuZi2w) to be more than sufficient as it gives control over what is used to identify a particular parameter to a function/method in the cache, and what parameters should be used in caching. For example: @memoized(id, ignore) def foo(bar, baz): return bar 
I don't think it's necessary to put in the stdlib, but something like [Tempita](http://pythonpaste.org/tempita/) would be nice. It's pure python, mostly self contained to just [one file](https://bitbucket.org/ianb/tempita/src/tip/tempita/__init__.py), and is a decent template language.
Well, yes you are right, but i think that pyedpypers problems are : * Manual account activation, i'm sure they're losing many devs like that. * Too many categories. If you just mix everything i'm pretty sure it would look more active. * They're not talking much about it. * From what i've read, a big part of the "active" users are not working on python projects anymore. My first idea before i made this wiki was to host a forum but i googled and found pyedpypers. And this is typically the kind of project which is stupid to clone in my opinion. I'm still very tempted though. You can edit now. There's still a bug with the "edit" tab, sometimes you have to click on "history" to make it appear. I'm trying to fix it.
If it's JSON, turn it into a python object using a [json library](http://www.reddit.com/r/Python/comments/euzeu/formatting_and_parsing_reddit_feeds_hjielp_please/c1b68bj).
Oh yes, what is it?
I second the recommendation to use an ORM, but writing code to generate SQL is not so bad. Here is an example: http://paste.pocoo.org/show/321150/ It turns your example structure into this: INSERT INTO people (name, skills, edu_pg, contact, edu_ug, r_id, email) VALUES (?, ?, ?, ?, ?, ?, ?); ['steve', 'nunchuk, bow hunting, computer hacking', 'n/a', '555-555-5555', 'computer science', '46232', 'something@example.com']
They probably add what their customers want to use, which makes sense.
`getargs` in `general_misc/cute_inspect/forked_inspect.py` is actually the "meat and potatoes"; the SkeekCallArgs mostly tinkers with skeekrefs using the information returned from `getargspec`, which calls `getargs`. It's pretty straightforward how it inspects the bytecode (if a bit non-Pythonic to reflect using `dis`).
You would have to check the implementation to be sure, but I think that the encode method on string objects works by decoding to unicode first, using the ASCII codec as the default, and then re-encoding. That's why the error that you are getting is a unicodedecodeerror. 
Well, it wasn't easy for me to implement.
What are you trying to achieve? By encoding Unicode characters to ASCII you will miss many characters, yes. And, you are not supposed to use the encode method on a byte-string, which is why your last example doesn't work (i.e, you are using it on a utf8-encoded byte-string). It seems you are not getting the idea of Unicode right, read this: http://www.joelonsoftware.com/articles/Unicode.html
[Anybody have any details on the PyCon DE 2011?](http://de.pycon.org/)
The proper sequence: _Encode_ the string to utf-8 bytes, _decode_ the string to unicode, then _encode_ it to ascii bytes. As you'll notice, the first two steps cancel each other out because the conversion from unicode data to utf-8 bytes is lossless, so why not skip it entirely? Remember this: _decode_ input, _encode_ output. Don't mess with encodings in between those steps and you'll be fine.
 &gt; sigmas Gah. Statistics has to be the worst branch of mathematics in terms of this ... confusing the finger for the moon and all that :)
Weird, haven't heard anything about this...
What you want is `.decode('ascii','ignore')`, but I have no idea why you want it. Python3 makes this clearer.
A WSGI toolkit, you can use it to make a framework.
That's the best framework.
may I suggest including [PyODE](http://pyode.sourceforge.net/) for the physics/libraries section? It's a wrapper for the excellent [Open Dynamics Engine](http://ode.org/)
The reason we memoize is performance. Every memoizing decorator I've tried has been much slower than manually memoizing with a dictionary.
Me neither, and I'm on just about every pycon related mailing list.
When they release a schedule that tells me which tutorials conflict with which i'll sign up for the ones I want to attend. 
[Times listed here](http://us.pycon.org/2011/blog/2011/01/05/tutorials-announced-pycon-2011/)
Also, if you click on an individual tutorial, the detailed description shows the date and time. The cost is only $100/tutorial through Mon, Jan 17 -- then it goes up to $150 (and up to $200 after Mar 1). So don't wait.
What *was really said* is that PyCon tutorial(s) which have low, to no signed up attendees a week from now will more than likely cancelled. There's no point in planning tutorials that have almost no attendees. We have to have a minimum number of attendees for it to make sense cost-wise - remember, tutorial presenters get paid a flat fee, and paying someone with a tutorial with 0-3 people in it doesn't make sense.
See my comment above.
So... 4 attendees by next week is the quota?
At our current payment levels, break-even is between 12-16 people (depending on when they sign up, copying costs, etc.) We have in the past been willing to go negative on a few tutorials if they are close to this threshold, but we cannot afford to have tutorials lose money for the conference overall. Edit: Historically, we will see about half of our total registration and about 2/3 of our total tutorial registration in the next week or so (coinciding with the end of early bird). If we see appreciable progress toward break-even on a tutorial, we will probably give it the benefit of the doubt. If we do not see sufficient progress, then it may be cancelled.
Van added more info, in a comment above yours: http://www.reddit.com/r/Python/comments/f2xw5/pycon_tutorials_that_do_not_meet_quota_by_next/c1cw4cc
I realise my example seems a little strange. I had a unicode string that I was trying to pass to `urllib.urlencode`, but kept getting an error. I first encoded the string with `.encode('utf-8')`, before passing to `urllib.urlencode`, and it worked. However, I also wanted to show the string that was being processed on screen in terminal output: u = u'uncode string...' u8 = u.encode('utf-8') urllib.urlencode(u8) print u8 This didn't work, complaining of a `UnicodeDecodeError`, and neither did `print u8.encode('ascii','ignore')`. I could only get it to work if I used `print u.encode('utf-8','ignore')`, and wondered why.
So if I understand the quota is 2/3 x 12 = 8 by closing of early registration. Thank you for the clarification. 
I'm no longer a user of Wingware (having migrated to vim on 3 platforms) but I used to use it as my default editor (on the same 3 platforms) for a couple of years - Wing was very good and their support was ace. They're helpful and quick to respond, they'll also help where they can. I've only switched to vim for a more consistent experience across those platforms (the X engine on the Mac for Wing was a bit of a pain) and for console editing over the wire, else I'd probably still be using it.
&gt; But if the string is utf-8 first, this doesn't work: &gt; &gt; print s.encode('utf-8').encode('ascii','ignore') &gt; UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 5: ordinal not in range(128) &gt; &gt; Why? You're trying to encode twice. Only Unicode can be encoded. Already-encoded data can't be encoded again without *decoding* it back to Unicode. You're not doing that, so Python is trying to do that step for you using the default encoding, ASCII. And 0xc3 (a byte in the UTF-8 encoding) isn't an ASCII character, so it isn't recognized by the ASCII codec when decoding to Unicode. Hint: it's a **decode** error. What you're trying to do in that line doesn't make sense.
just a library
@Caramoun, I found pyed in the exact same way as you. I think another reason why it's quiet is that it was born out of the Pygame community, so it doesn't have much connection to the other Python gamedev communities; pyglet has its own mailing list, as the other engines and libs have their own forums, Pyweek has its own message board, and so on. You have to ask yourself what would bring someone to join pyed rather than choosing one of those other forums. Its project hosting is nice and if the wiki was somehow tied to it that would be another plus. I think asking the pyed mods to add a link to the wiki in the forum header would be a good start. No real need to clone an already small community (other than the desire to fashion something from scratch, which I completely understand :) ). 
I'd attend as many as I could if I was in atlanta.
&gt; s.encode('utf-8').encode('ascii','ignore') This makes no sense. You can encode only Unicode. You have a Unicode object, then encode it to make a string of some encoding. That thing can be decoded using the same encoding again to make Unicode again. The "encode" method on a string is magical and dumb and should never have existed. It silently decodes the string (using some default encoding!) to make Unicode again before creating a string with the specified encoding. NEVER use that.
&gt; unicode chars That doesn't make sense either. Please take a moment to go read "what every programmer should know about Unicode". You don't really understand what you're doing here.
anyone tried this and PyCharm and want to give a little comparison? I'm using PyCharm right now and I like it quite a lot.
I've evaluated PyCharm as well. But it didn't work on one of my bigger projects: Find usages didn't return anything at all. Therefore Renaming didn't work either. Also, unittesting didn't work: Some strange error messages about existing standard library modules. PyCharm support couldn't help either, so I decided to keep Wing 3. Wing 4 beta 5 was here and there a little slow, but it's a beta version after all. Can't comment on Wing 4 beta 6. Overall: PyCham is very promising, I prefer the layout of the IDE. But to me it wasn't mature enough to switch from Wing 3. Now Wing 4 with refactoring support leaves only cosmetical reasons to switch, which are probably not enough.
I agree that it was about time to do so (adding refactoring support). But to defend the Wing guys: All this classic features of IDEs for static typed languages seem to be not trivial to implement **properly** for dynamic languages.
Sample program? All you need to do is type import media into the python console. 
Use [NumPy](http://www.scipy.org/Tentative_NumPy_Tutorial) to manipulate matrices.
No easy way to do this with basic python, but there is if you install [numpy](http://numpy.scipy.org/): from numpy import random, matrix, linalg a = random.random((5,5)) # make a 5x5 array of random numbers a = matrix(a) # convert a to a matrix (obeys matrix multiplication, instead of elementwise) b = matrix(random.random((5,5))) # and another random matrix c = a * b # matrix multiplication c_inverse = linalg.inv(c) #compute the inverse
Thanks so much this is perfect!
thanks so much this is exactly what i need
Then the problem is your terminal encoding. Make sure your terminal encoding is UTF-8, check your locale settings, make sure Python's **sys.getdefaultencoding()** says UTF-8, and then you will be able to print unicode-strings or utf8-encoded-byte-strings without issues.
A word of warning: Although you can do matrix multiplication on integer matrices, when you invert the matrix, you'll get a floating-point result. Floating-point math is inherently inexact, which means that applying a matrix transformation followed by its inverse will only get you back to the original value to within float-point accuracy and rounding errors. If the matrix is near singular, the errors can be huge.
I'd like to say that it only took 4 minutes for Reddit to find your answers.
i tried it in a calculator i found online and i seemed to get pretty exact answers at around 9 decimal places. So hopefully it will be fine but thanks for the heads up.
agree, PyCharm does some thing really impressive. dabble in PyCharm several times, but as a Python only coder(no Java, no IntelliJ IDEA). and a heavy WingIDE user(starts from year 2005 with WingIDE version 2.0.?maybe 3). I still prefer WingIDE. the only annoy thing at the moment is that WingIDE 3.x didn't support Python 3.2 yet.
Now is better than never. maybe refactoring is a basic feature to comerical IDE, to Python IDE, it's not easy to implement, and just several years ago python is still a "script" only language and small in the whole programming market. (even now it's not very big)
Python frame overhead is usually the source of that, combined w/ exception reliance. Still, a valid point- wind up seeing folks implementing stuff like this but skipping the timing of it.
 'edu': {'ug': ['], 'pg': [' ']} are lists!
Source code management software.
&gt; Only Unicode can be encoded Both 'str' and 'unicode' objects have 'encode' and 'decode' methods. 
My terminal is using utf-8 (both Terminal.app and tmux), but `sys.getdefaultencoding()` returns `ascii`. Changing this seems to involve adding a file to site-packages, I'm not sure I'm happy doing that. Seems very hackish!
Your string is unicode, but has ASCII encoding. When you specify strings in sourcefile/interpreter you must make sure what is the default encoding.
using macports didn't work for me but doing virtualenv to a local environment and putting that in front of the path keeps the system python clean enough. $ virtualenv -p ~/usr/local/bin/python --no-site-packages --distribute ./ $ PATH=~/local.env/bin:$PATH $ ./local.env/bin/pip install readline ipython $ ipython # WIN 
No need to rewrite the complete program in C++, just rewriting the time-critical parts in C and using them from Python as a module is good enough. http://docs.python.org/extending/extending.html
str.encode and unicode.decode are for special cases only, e.g. ROT-13. Normally, only use str.decode and unicode.encode. If you find yourself using str.encode with a normal codec (Unicode &lt;-&gt; text encoding), you're doing it wrong.
&gt; I think another reason why it's quiet is that it was born out of the Pygame community, so it doesn't have much connection to the other Python gamedev communities; Oh indeed, i forgot that one. &gt; You have to ask yourself what would bring someone to join pyed rather than choosing one of those other forums. Yes, of course. I don't see it like a big support forum for every game engine for python, as i said before when someone want to start making games in python he has to sort himself all the resources because there's no specific place to discuss what engine fit the most its project. Another other reason for me is that a real community creates and maintains motivation for your projects. And beside the fact that it could be nice for it to be a headquarter for every kinds of python game developers i think that the lack of a game community forum for pygame, pyglet and the other smaller engines makes a sufficient reason to use this forum. And i'm talking about exchanging ideas, snippets, news, not some raw python engine pieces of code (at least not mainly). Algorithms, music/sounds, sprites, critics, game designing... are also parts of a game development. 
the example code is a mess wrt threading it would crash on windows its just luck that it works on X11
Done. And thanks for the suggestion, i'm sure some are still missing from the list.
hm. can you point out where the problem is?
changing widgets is only valid from the gui thread, yet the timer thread does change the progress bar also note that a gtk timer would be much more appropriate than a messy thread
So, has anyone used this yet? Is it any good?
ok thanks, will do more research on threading with gtk, and probably post a better solution.
Power!
I very much agree; I've posted at pyed about refreshing the forum organization too. 
The code I wrote was an example of what you could do. If you want someone to write your program for you, you will need to pay them.
Wtf...this is a terrible idea. Just read the Stack Overflow question on the difference between shell scripting and Python/Perl/etc.
Should just use a glib timer object or whatever the name of the helper glib provides was. It's really easy too, would probably reduce all of that code to 5 lines.
I enjoy the ipython -p sh environment, but the completions in zsh make it a clear winner for my day to day stuff.
Have you checked out Al's [Invent your own computer games with Python](http://inventwithpython.com/)? I love it, it's great.
Have you tried this with the actual Python console, outside the IDE? What happens there?
I have, that's where things get strangest. import media works just fine in the console, but say I tried this import media f = media.choose_file() pic = media.load_picture(f) I'll get this error "decoder jpeg not available" 
it should be called poo
lol!!!11!1!!
If you're using numpy it's a good idea to understand the differences between the array and matrix types. Arrays are the standard matrix/tensor/vector type. Using arrays you would use c = dot(a,b) for matrix multiplication. There's a list of the differences at http://www.scipy.org/NumPy_for_Matlab_Users.
woo matplotlib!
webchat.freenode.net --&gt; python channel is pretty great btw
Check your system locales. Ideally, you should get something like: $ locale LANG=en_US.UTF-8 LC_CTYPE="en_US.UTF-8" LC_NUMERIC="en_US.UTF-8" LC_TIME="en_US.UTF-8" LC_COLLATE="en_US.UTF-8" LC_MONETARY="en_US.UTF-8" LC_MESSAGES="en_US.UTF-8" LC_PAPER="en_US.UTF-8" LC_NAME="en_US.UTF-8" LC_ADDRESS="en_US.UTF-8" LC_TELEPHONE="en_US.UTF-8" LC_MEASUREMENT="en_US.UTF-8" LC_IDENTIFICATION="en_US.UTF-8" LC_ALL= 
I've been wishing for something like this for a while. I'm not affiliated with the site at all, I just found it reading the official django blog aggregator. Its being developed by the same person who created South, which is database migration support for django. I have high hopes for this, particularly because it supports the WSGI protocol, not just django, like several other options that have recently appeared support.
My favourite part is the fact it's version 1.1.
Google. Have an application in mind to do, that way when you run into problems, you know what specific things to look into. like pygame, can you open multiple windows? that is very tough, well just start with something like, bounce the ball around a window, well you got have a ball first? so look that, then you gotta move it ! good luck!
need more cow bell
Besides unzipping the archive, there's more to do before running the examples. Did you run the bootstrap and buildout scripts?
So the IDE is doing something to the Python interpreter which makes it incompatible with PyGraphics. Regarding the other problem, perhaps PyGraphics did not compile JPEG support into the package because you haven't installed `libjpeg62-dev` (or what the Ubuntu package is called)?
This does look cool, but what's the advantage over AppEngine? It sounds a bit restricted without all the cool parts.
Not needing to rewrite your application for their: custom database, custom cache, custom email, custom etc...
What rewrite? django-nonrel works out of the box and you don't even have to change anything.
No, it doesn't. There is no one-to-one mapping of operations you can do efficiently on a relational database (or redis, which they'll be supporting shortly) to those that can be done on bigtable. Trying to create a one-to-one mapping where one doesn't exist is an exercise in folly.
If by "rewrite your application for their: custom database, custom cache, custom email, custom etc" you mean "not use joins", then I agree with you. Otherwise, no.
I can't imagine a single person who has had a bad experiencing with wing support. They extremely responsive, fast and to the point. 
I think i figured it out. I did run bootstrap, but it did NOT give me buildout script, but gave me pdjscompile, pdjsbuild, whatever. I think what worked was to make a build.bat batch file in the example/helloworld folder and run it.
Still, need to use lots of app engine libraries for things like fetching url's, sending email, and caching. Making my flask app work on GAE would require a considerable amount of changes to my app. Also, using libraries on GAE is a bit of a pain. Making my app work on ep.io would just require the .ini file, and a little change to how my app factory treats configuration. The way that epio handles requirements looks awesome, except it seems like it would be a huge security vulnerability.
Asking this question on Pyjamas mailing list will get you more help than on reddit !
Ah, sure, with microframeworks it would be harder. django-nonrel has rewritten all the critical parts so email sending, caching, the ORM, etc all work with the same interface. You don't even need any changes for url fetching, as GAE's urllib2 uses urlfetch internally. About the only change when you use Django is that you don't have a ManyToMany field, sadly. I am writing a Django app that runs on GAE right now, and I can run it on a normal server with exactly zero changes, it's pretty great.
wow, I wasn't aware the django-nonrel project had come that far. However, I'm sure they spent a ton of time adding GAE support. Ep.io seems like it will work with just about any imaginable Python solution. What "cool parts" do you think its lacking?
Did you find that NetworkX was faster under PyPy? I did some tests and found NetworkX was faster (under CPython) than JGraphT in Java, for a shortest-path algorithm in a large graph. Surprising.
As far as I'm aware, django-none is 100ish lines, all of the functionality is provided by the other apps they made, but yes, so far it's been great. The most important thing about GAE for me is the scaling, I'm having some trouble scaling my last project as it requires resizing the VPS all the time. Also, the free GAE tier means free hosting for a *long* time, especially for apps you set and forget.
I don't think that the reddit source code is set up to be easily used by someone who doesn't have a background in coding. If you are Interested in learning how to use python we could suggest some links but otherwise you might be out of luck 
The admins don't wear shiny black phallic helmets and can't asphyxiate you through sheer force of will.
Well, for one thing, it's incredibly hard to get a bunch of competing browser makers to agree on anything. Secondly, JavaScript is already very widely adopted, and can do just about anything that Python can. There's no compelling reason to add another language to the stew.
Isn't Python easier to program in, and possibly more powerful?
Easier? Maybe. But even if you could come up with a good method of testing this claim, I doubt the difference would be very significant. I've never really heard anyone complain that either is hard to learn. More powerful -- how exactly? You have to remember that JavaScript is typically run in a sandboxed environment, where it has no access to the underlying OS, filesystem, etc. But that has nothing to do with the language -- Python could, in theory, be run in the same kind of environment, and it would suffer the same sort of limitations. It's not a limitation of language, but a limitation of the runtime environment in which the language is executed.
Panda3D does it with browser plugins. http://www.panda3d.org/gallery/
The main reason AFAIK is security. Python cannot be sandboxed (without major rework). There used to be a sandboxing library in the stdlib ('bastion' I think it was called). It was depreciated because the python developers concluded that making a secure python environment was too difficult / not worth the effort. Personnally, I think this is a shame, as javascript really doesn't appeal but this doesn't seem like changing.
That looks really fucking high quality.
Its has support for complied libraries e.g lxml
How is it a security vulnerability?
[Pyjamas](http://pyjs.org/)?
They should try to host reddit.
Unity3D can create games for the web (though it requires a plugin), and you can use Boo, which is a subset of Python.
Sandboxed Python has been done. Google App Engine runs a special sandboxed Python, and PyPy has a sandboxed mode. Neither of these are mainstream versions, but the work has been done. (Unfortunately I can't find that paper about it.)
Sort of unrelated, but I'd like to see LLVM embedded in the browser so that you could run all kinds of languages in a safe, sandboxed environment, including Python.
Python is too much defined by implementation. If MS, Apple or Google were to do their own Python implementation or compiler, they would have to negotiate all the corner cases not in the documentation. JavaScript is already there. There is no reason to substitute on with another. They both are very dynamic and have pretty much the same features in the core language. Newer versions of JavaScript add some of these good Python features, It's just that Browsers should adopt them. 
Python is wasteful with whitespace. It looks great in an editor, but websites want to strip deployment code to very small sizes since every browser has to download it to view the page. Hence things like whitespace disappear in JS files.
Because of Flash (&amp; Shockwave), Silverlight and Java nobody cares. Wait for WebGL, then man up and use JavaScript.
No. You need git, a distributed version control system, to clone the repository. Then you run the setup script and the Makefile. Then you set up your PostgreSQL server. If you have doubts about what any of these statements mean, you probably shouldn't be messing with the reddit source in the first place.
Really not much of an issue. Javascript is typically more verbose that Python. Yes the whitespace will add some bytes, but gzip compression will make them disappear.
I don't see any. They use an isolated read-only file system and a separate worker process for each application. As long as they don't allow custom C modules, there should be no way to affect other applications or compromise their servers.
Ah, true. Also, I guess actual support.
Inertia
It is more powerful if you consider the number of useful language features.
And it is easy too, try it. 
I pretty much agree. Just a note on Silverlight, you can actually make python stuff on it with [IronPython](http://ironpython.net/browser/).
&gt; Wait for WebGL, then *man up* and use JavaScript. I believe you meant to write “give up.”
short answer: they don't want to...
Such as?
First step is a first step and "a rose by any other name..."
Classes and operator overloading, to name two among many others. Edit: mind commenting instead of downvoting?
Go ahead. Seriously, things happen because someone believes in them and *does them*. (I don't personally believe that this idea is compelling for the reasons other commenters have given, but I do believe that asking, "Why doesn't somebody .." isn't often fruitful.)
[emscripten](http://syntensity.com/static/python.html)
Doesn't matter if it's better, it's not as popular.
Javascript varied quite a bit between browsers. In the last few years some of the most popular JS libraries are ones that smooth over all the browser differences.
Why do you think it "shouldn't be that hard to embed the interpreter in Firefox"?
I'll play the devil's advocate here. Why do you want to embed only Python? I mean other languages can do 3D graphics as well. What's the reason of limiting it to only to one language?
disclaimer: the following is a shameless plug have a look at pyplugin (http://pyplugin.com) if you want to embed python in a xulrunner application.
The only way to set Python's default encoding is to create a `sitecustomize.py` file in your `site_packages` which contains this: import sys sys.setdefaultencoding('utf-8') 
&gt; Javascript is typically more verbose that Python. Not that I don't believe you, but we need data to back this up. gzip + minification is more efficient than either alone ([source](http://stackoverflow.com/questions/807119/gzip-versus-minify)). Whitespace can be compressed, but since gzip is lossless, information still needs to be present. It's hard to say how much more verbose javascript really is, and how much it matters in the face of gzip/minification.
Not tried it, will it work on refreshing an ASCII map?
Mainly classes and namespaces, which are basic language features that should have been implemented in JavaScript a long time ago. Also, Python is just a much better designed language overall. It would take a long time to list out all of the many minor things that make Python superior to JavaScript (like default arguments, chained comparisons and multiple assignment).
Yup: LANG="en_US.UTF-8" LC_COLLATE="en_US.UTF-8" LC_CTYPE="en_US.UTF-8" LC_MESSAGES="en_US.UTF-8" LC_MONETARY="en_US.UTF-8" LC_NUMERIC="en_US.UTF-8" LC_TIME="en_US.UTF-8" LC_ALL=
JS uses braces where Python uses colons and newlines. Neither disappears by minification. A newline character is a single character.
Hi all, I'm the Pootle2py developer. - I do love Pootle and Django but I prefer web2py - Pootle2py it's not a fork of the original project. I coded it from scratch mainly to have fun and learn web2py. - Pootle2py is a Translation tool (let me say), but it works differently than the original Pootle since all data are stored in the database instead of files. - I didn't want to stole a name or people to prefer mine. - Whether someone can see any issue or find it not fair I can rename it. Walter
Embedding the language does not automatically get you the libraries. Many Python libraries are written in C, not Python. If you do get Firefox, IE, Chrome, Safari, and Opera to all embed Python and some of its libraries, they will very likely do it in a way that will allow Javascript to access the same libraries. In fact, it would be simpler to cut out Python from the process and just implement equivalent libraries for Javascript directly.
[urwid](http://excess.org/urwid/)
True.
[Panda3d](http://www.panda3d.org) has a plugin for firefox that can run panda apps (which are just Python) in the browser, interact with the DOM, and can expose functions to Javascript.
It actually made me sad when I realized Disney made it and wasn't really able to turn a profit off something this good.
Is it Javascript or the DOM implementations that problematically differ between browsers? I thought it was -- I know it used to be -- the latter.
What downvotes are you talking about? Why do you care?
&gt;Looking for a module with curses-like functionality FTFY. I first read this as "looking for a module with curses", but I'm quite sure you're neither looking for the dark arts nor expletives.
I have python3 as well as python installed, and potentially a few different versions of python 2.x (i.e., perhaps the homebrew-installed one (on a Mac), and the Apple-installed one). Do I have to add this file for each site-packages directory? 
Panda3D is the best open source game engine I could find, it has everything you need (especially exporters, debugger, and everything that really count for game development, not just graphics), unfortunately it's one of those projects that use Python like a dumb "scripting language", ignoring all Python idioms and conventions (it's basically C++ but with Python syntax). CamelCase everywhere, inconsistent API, never use iterators, etc.
Perhaps more expressive and programmer-time-efficient, but those language features generally don't help you achieve anything new or different. No one's going to use an app and think, "Wow, look at how this app works -- it must be written in Python!"
And [skulpt](http://www.skulpt.org/).
Microsoft has already done a python implementation, it's called IronPython.
&gt; What downvotes are you talking about? https://addons.mozilla.org/en-US/firefox/addon/reddit-reveal/
Maybe. Check `sys.getdefaultencoding()` in Py3 because perhaps Py3 already defaults to utf8. As for your Py2 installations, you could create one `sitecustomize.py` file somewhere and create links to it from your `site-packages` directories. 
The experience itself may be subjective, but there are some ways to measure ease of use and comprehensibility. Google Scholar shows hundreds of such studies and comparisons that strive to be objective. i.e. [An objective comparison of languages for teaching introductory programming (2006)](http://en.scientificcommons.org/21464982)
Although Classes and namespaces are not native to javascript using closures it is possible to imitate the behaviour. Also, multiple assignments are actually possible in JS: var test = another_var = function(){ alert('test'); } another_var(); test(); Try it out.
&gt; *What can Python do that Perl can't do?* Be reada.... &gt; *Please nothing about readability* Oh. Well then, there's not much practical difference. 
Boxee app development is a good example. An app's GUI are defined by XML, with either embedded javascript or python to act as controls. As a javascript developer who knows python, I don't think there's any real difference and I'd see no added benefit programming python over javascript; both languages are equally capable. Just man up and learn javascript. It's not that hard.
The lack of classes and namespaces certainly is possible to workaround, but I find that needlessly inconvenient. By multiple assignment I meant neatly assigning different values to different variables on one line (e.g. **a, b = 1, 2** or **a, b = returnsTwoValues()**). It's hardly an important feature, but those little features in Python add up and make the language nicer to work with than JavaScript.
Perl vs Python posts seem to be quite popular these days.
I'm not the best at describing deep mechanical differences but I do know that the Python community seems to be much stronger than the Perl community. Every time I think of scripting something semi-obscure I find that somebody has already made a module that shaves a few hours off development time. It all really depends on what you are programming it for, if you're going to be running these scripts on a lot of legacy systems that don't already have Python installed then you might be better off learning Perl. Also Python has a pretty good web-framework community (Django,Pylons etc) so web development is pretty awesome. Hope this helps
Was going to post this. They have a demo of cpython running clientside in your browser. So this answers the OP's question.
That's as far from the "main reason" as one could get.
MS has made their own Python compiler: IronPython. Google has made their own Python compiler: UnladenSwallow (though they abandoned it). 
It is in fact both.
Most of the web is compressed with gzip when it's transferred over HTTP. So it really doesn't matter much.
just wondering why do you consider functionality a curse?
just throwing things out, if you can, please provide counterexamples: 1. speed 2. bulkiness 3. inertia/network effects (Javascript's already embedded in browsers, no need for another language) I know none of these are deal-breakers, but from my limited understanding, it's easier to optimize Javascript than python for speed (e.g., V8 versus unladen swallow)
I'd say that the learning curve for python is shallower. Your time-to-effectiveness in python will (probably) be shorter. The python module layout is sane (mostly), and the documentation is excellent. The python object model is superior: the perl object model has been compared to "trying to make an octopus by nailing 4 extra legs onto a dog". I don't think that's unfair. EDIT: It's been brought to my attention that this quote was originally referring to C++. Totally my bad. I think it applies here pretty well, though. Python has less "magic" going on than perl, in that when you "include" something in python, it (almost) never craps all over your global namespace. This also makes it *very* easy to determine which module is providing certain functionality in other folks' code. Granted, all of these features make the language more readable also, 
I don't think that there are many important things that Perl/Python can do that the other can't. I do prefer the python language for programming in an Object-Oriented fashion. *Not* because you cannot do this in perl (you certainly can) but because of the neater/cleaner OOP syntax (this is highly subjective). I think they're both great and expressive languages with many similarities. You can't go wrong with learning either or both. Edit: [CPAN](http://www.cpan.org/) is one major advantage of knowing Perl. Just about any library (module) you can imagine needing is in there somewhere. [Seriously](http://search.cpan.org/~dconway/Lingua-Romana-Perligata-0.50/lib/Lingua/Romana/Perligata.pm), I often look around CPAN just for fun as there are some [neat packages](http://search.cpan.org/dist/Lingua-Shakespeare/lib/Lingua/Shakespeare.pod) there.
Python does have a great community, but IMHO, the Perl community is one of the largest, friendliest and most comprehensive I've ever seen. 
They have the same capabilities and they both have large communities and collections of third-party libraries. There's not much difference except the part where perl looks like line noise.
Yes, this is really the answer, along with emscripten. Using JS as a bytecode platform provides less resistance than adding new scripting languages to all the browsers. If you tell me JS is particularly bad for being used for this since it wasn't the original intention, then I'd like to see some data please, and not just zealotry.
Google has also embedded llvm into Chrome already. It's called Native Client (NaCl).
Python is already available in the browser. There are many ways, several which don't even require the user to install any plugin: emscripten is an llvm to JS compiler which has already been used to compile CPython to JS. Pyjamas compiles Python to JS too. And IronPython runs in Silverlight, which many users already have thanks to Netflix.
Nope, they're all from me. I'm a noob.
Described as incomplete in the README, but it might be worth a shot: [wcurses](https://github.com/adamv/wcurses)
They're both Turing-complete languages, so obviously there's nothing that one can do and the other can't.
Tell that to our embedded software developers who pick and choose which batteries to include in our systems :P
Well, if you care about career prospects at all: Perl's popularity is declining while Python's is growing. http://www.tiobe.com/index.php/content/paperinfo/tpci/index.html
Perl = Corvette Python = Audi R8 GT Both are incredible fast cars. But there's a clear winner in terms of technology (language design), looks (readability) and coolness (the R8 rates about 1000 Mega-Fonzies compared to the 10 Mega-Fonzies of the Corvette). Now it's up to you: Want to be cool and impress the daisies? Welcome to Python!
I think this is the most applicable way to end any language debate ever.
From my experience python seems more stable at running long term apps and perl seems more powerful at getting large tasks done with little code. Something like a web spider that runs 24/7 would be good in python. Something like the engine that finds relationships between these documents after a large index has been collected would be good in perl. This is all just from trial and error and what I've experienced working with the languages. As for under the hood stuff I'm not sure what's different.
I'm a perl developer by trade (however I do like python) &gt; Python community seems to be much stronger than the Perl community. The two communities are actually very similar, the perl community is large and full of very experienced people willing to help anyone. &gt; Every time I think of scripting something semi-obscure I find that somebody has already made a module that shaves a few hours off development time. cpan.org this is actually something where perl has python beat (cpan is *huge*) &gt; It all really depends on what you are programming it for, if you're going to be running these scripts on a lot of legacy systems that don't already have Python installed then you might be better off learning Perl. Also Python has a pretty good web-framework community (Django,Pylons etc) so web development is pretty awesome. Agreed. Python is superior for frontend (while being very good at the backend), perl *excels* at backend work on unix systems as unix is all text and perl is a text processing language.
Learn Python unless you want a future in masochistic support of legacy scripts.
Perl was supposed to be an improved shell scripting language replacement that got hacked, over many years, into a general programming language, whereas Python was planned to be a general programming language from the start, and its feature expansion was much more carefully thought out. Python also has the advantage of having learned from Perl's mistakes.
From my own experience I believe Python is cleaner when developing larger projects. Not to say that this can't be done in Perl (CPAN is very nice), but once you reach the "bless" command things get funky. Perl is wonderful for shredding through data, but it is my opinion that Python is better at bridging for all tasks. If you throw in something like SWIG you can work around any speed issues with tight loops (assuming you know C, C++).
Comparison by libraries, the only difference I've found is that Python will have a couple complete or mostly complete options and Perl will have a dozen half baked ones and you just have to spend the time finding the one that has baked in the half you actually need.
On the other hand, [consider this](http://xkcd.com/353/).
preserve sanity
I gave up Perl in favour of Python about a decade ago. [This](http://www.garshol.priv.no/download/text/perl.html) was my writeup of why. I don't think anything central to it has changed since.
&gt; What're the advantages of Python over Perl? No references. Generators. Clean module system. One way to define classes (no wait, there are actually two in Python 2, but still not as bad as Perl situation) &gt; What can Python do that Perl can't do? There are some libraries and apps like NumPy and Twisted that may not have good Perl equivalents, but I don't think there is anything Python can do that Perl can't in principle. &gt; What're the advantages of Perl over Python? Convenient syntax for using regular expressions. Anonymous functions that can be longer than a single line. Closures don't treat read-only vs. read-write variables differently. &gt; Parting comments? Perl community doesn't seem to think the transition to Perl 6 is going to be fracturing and unpleasant. We shall see.
Perl is tailored for text processing while Python is intended from the start as a generic purpose programming language. In my opinion the only reason to use Perl is if you know it already.
&gt; No one's going to use an app and think, "Wow, look at how this app works -- it must be written in Python!" No, but that isn't the point. Else, you could still use assembly for everything.
At the time of my edit I was at -1. I don't care about the number per se, but I don't like it when someone disagrees and I don't know why.
The fact that pretty much all languages are turing complete is of theoretical interest, but of no practical significance. Two languages may both be turing complete but what takes one line in one language may take hundreds of lines in another, or be orders of magnitude slower. 
Down-votes don't necessarily represent disagreement.
Yes
All the more reason to explain.
De-structured assignment is part of [Javascript 1.7](https://developer.mozilla.org/en/JavaScript/New_in_JavaScript/1.7#Multiple-value_returns).
I switched from Perl to Python about 12 years ago, and have never regretted it. In terms of basic capabilities they are pretty similar, and both have a rich set of third-party libraries. However IMHO Python is much cleaner - it is much easier to hold the whole syntax in your head. When I was programming in Perl I was constantly referring to the manual for obscure edge cases and weird behaviour, even after using it for several years. Python is not only more readable. It is also more writeable. [This essay by Eric Raymond](http://www.linuxjournal.com/article/3882) sums it up much better than I can. I have not kept up with changes in the Perl language, but from what I have seen Perl 6 is even more complex than Perl 5.*, as exemplified by the [periodic table of Perl 6 operators](http://glyphic.s3.amazonaws.com/ozone/mark/periodic/Periodic Table of the Operators A4 300dpi.jpg).
Apples and oranges. Everyone knows why you don't use assembly to build modern software. On the other hand, Python and JavaScript are widely used and are both considered highly productive languages to use. Python might have a bit of an edge, but it's clearly not enough to be worth the decades of upheaval that would be caused by trying to add it to the already ridiculous mix of web technologies we have. JavaScript is fine.
&gt; Python also has the advantage of having learned from Perl's mistakes. That one I don't really see. Perl was released in 1987 and Python in 1991, but I don't think Perl was very popular yet, or that Guido knew much about it. But I might be wrong...
&gt; CPAN is one major advantage of knowing Perl. Just about any library &gt; (module) you can imagine needing is in there somewhere. Seriously, I often &gt; look around CPAN just for fun as there are some neat packages there. According to their home pages, CPAN currently has 19172 packages, while [PyPI](http://pypi.python.org/pypi) has 12924, so the difference is not that great. Plus Python has a lot more libraries included as part of the standard distribution. If a language has all the libraries that you need it does not matter that another language a few thousand other libraries that you do not need. 
That analogy describes object-oriented Perl perfectly. Having tried both, Perl made me want to cry while Python was a breeze.
If Randall Munroe says it, it's fucking true.
I believe you mean "import sanity"
I thought that NaCl was a sanitised version of x86 bytecode? What does that have to do with llvm?
Significant whitespace in Python means you can't [shape your code into arbitrary shapes](http://www.perlmonks.org/index.pl?abspart=1;displaytype=displaycode;node_id=384100;part=1) like you can in Perl. I'm not sure if this is an advantage or disadvantage. 
That's the typical year 1 CS answer. Brainfuck and Intercal are both turing complete. There's nothing you can do in C that you can't do in Intercal. Or so it goes. Doesn't mean it's practical. 
Before Minecraft existed, I messed around with an octree-based cubeworld rendering thingie in Pyglet. Acceptable speed for rendering, but would probably be too slow for collision detecting, game logic, world managing, etc. There's nothing other than performance which stands in the way, though, and there are ways around that. I also wrote a quake3 map renderer in pyglet, and it was the same - acceptable performance for rendering the flying camera, but it would break down if you tried to build all the game logic etc. 
What does Turning-complete mean? (serious question) I'd like a reddit-readable answer if possible (google returns fairly technical answers)
&gt; the perl object model has been compared to "trying to make an octopus by nailing 4 extra legs onto a dog". that's strange. I heard this analogy referring to C++ compared to C.
Perl in 1987 was hardly what you could compare to Perl now (see Perl 5 (1994) for anything resembling sane). Meanwhile Python in 1991 was also quite poor compared to a more recent version (Python 2 (2000)). 6 years vs 4 years.
PyPy should have this mostly solved. The reason Java is fast is because of its JIT, Python can be fast too.
it means that a Turing Complete language can be used to solve any computation problem. You can represent all algorithms... in one way or another.
esp. considering that he mentions many times how much he loves Perl.
Alan Turing described a theoretical example of a computing machine, and later proved that any machine that can do a certain few logical operations can be used to simulate a Turing machine, and therefore they can all complete the same set of calculations. He also proved that there are some calculations that could never be done by any Turing-complete machine. 
In layman's terms, a Turing-complete language is a language which has the same computational power as a Turing machine. For all practical purposes, any possible computer program can be written in a Turing-complete language (there are theoretical exceptions to this).
I never said they were equally practical. The OP specifically said he doesn't care about readability and only wants to know the difference in power between the two. 
Actually, a language is or isn't Turing-complete based solely on its grammar and semantics.
&gt; cpan.org this is actually something where perl has python beat (cpan is huge) To be fair to python, you can't do a direct comparison of number of libraries without taking into account duplication of functionality, e.g. all the exception handling libraries that exist on CPAN because Perl's inbuilt exception handling is rubbish.
For scripting things, the Fabric module (fabfile.org) definitely makes my life simpler. However, I heard a rumor there was a module similar to it on CPAN these days but I couldn't find it just now for comparison. Python is now used heavily as part of Linux distributions, while Perl isn't growing much at all in this area (and many others such as web development). For scripting, the only real advantage of Perl is that regular expressions are a first order operator and really baked into the language. 
&gt;what takes one line in one language may take hundreds of lines in another This is true, though I'm not sure it's true when comparing Perl to Python. If you want to compare Java and Python... &gt;be orders of magnitude slower This is entirely dependent on language implementation, not language definition.
Not obvious to me. How does being Turing-complete give you access to the services an operating system provides? How does being Turing-complete give you the ability to abstract code or data structures? Or the ability to share code via libraries?
&gt; As long as you are running on the new Intel InfiniteTape processor. Intel designed and built a forest that grows trees at precisely the speed such that that ticker tape can be produced continuously, forever, and inserted in to the machine. There are an army of robots that plant, water and fell the trees so that "Deep Turing" can be kept alive. As such, they have manufactured the elder machine; the alpha, the omega; the one true source of computation: the Universal Turing Machine. Now if only they could compute the ultimate question?
"Turing complete" in the context of a language, as stated by others here, means it can simulate Turing's hypothetical computing machine. The upshot of that is you can essentially write any other language in the original language, so they all are "as powerful" as each other - there's nothing you can't do in a Turing complete language that's possible in any other Turing complete language (which is just about all of them). Alan Turing was a pretty damn smart guy, it's worth reading a bit of his history and contribution to the field of computation and cryptography. Here's a [Turing machine implemented in Lego](http://www.youtube.com/watch?v=cYw2ewoO6c4&amp;playnext=1&amp;list=PL6AB3CAAFE58619E7&amp;index=67) , which is also cool. Turing was smart enough to run this shit in his mind, which is simply beyond awesome. I think the lego Turing machine is an excellent demonstration of the practical differences in programming languages - It's *possible* to write Asteroids on it, but it would take a lot of effort. 
&gt; The OP specifically said he doesn't care about readability and only wants to know the difference in power between the two. I suppose you could talk about expressive power which is separate from readability. While x86 assembler is capable of everything Python is, you can't easily write higher order functions, list comprehensions, object orientated code etc. In this sense, Python gets you more mileage per unit code. But ultimately the machine code must be capable of executing the same ideas - even if it takes thousands of instructions to do so.
Pretty sure it's actually called "InfiniTape"
My best attempt at reddit-readable: All Turing-complete languages have the same computational power as one another (where "power" means the ability to execute a computational algorithm). There is no computation one turing-complete language can perform that another other cannot. Thus since both Perl and Python are Turing complete (meaning they can implement a finite single-taped turing machine^* ) then Perl and Python have the same power. \* Turing's theoretical machine had a tape of infinite length, so technically all computers today have less power than the turing machine since they have finite memory, but again this is a purely theoretical sticking point.
So you compare modern Python with Perl from 12 years ago...
I think Python's biggest advantage is the [standard lib](http://docs.python.org/library/), or the "batteries included" philosophy. That is, we have default libraries for stuff like XML/JSON processing, email, image processing, etc. You can use third-party libraries if you like, but the standard lib makes it very likely that anyone you're working with is familiar with roughly the same toolkit. Also, the community is huge. Anything you might ever like to do in Python probably has a well-written, very recent tutorial.
Try Moose in Perl - you will not need bless.
In absolute numbers, Perl popularity is growing. In relative - it depends on who is measuring.
Did you try Moose in Perl? It is slowly replacing OO system that Perl authors took from Python.
Please feel free to correct me if I've stated anything incorrectly, but: Essentially a language is Turing-complete if it can do everything a Turing machine can. A Turing machine consists of: * A tape containing an infinite line of cells. Each cell can hold one symbol in it from a fixed set of symbols * A head that can read from the tape, write to the tape, or move to different cells on the tape. * A table with fixed set of operations that can be performed (i.e. add, subtract, jump to a different cell if current cell = 0) * A state register containing the current state of the machine, with a "start state" that the machine is initially in That's pretty much verbatim from wiki's page on Turing machines, so sorry if it's not clear enough. As the machine runs, it looks at its current state, does some operations to the tape, and changes to another state. It can keep changing states and performing operations until the program is done and reaches a final state. If you view your computer as a Turing machine, programming languages are essentially controlling it using the states, operations, and tape. Different programming languages may come up with fancy ways for you to write your code, but in the end, it all gets translated to these basic operations.
I suggest using them both to solve different problems you have and find what clicks for you. Perl for me didn't have the stickiness of Python. Ive found Python typically lets me rapidly develop tools with minimal effort. Take a run through Python Osmosis and Ruby Koans.
If you care about empiricism and statistical accuracy at all: TIOBE is chart junk at best.
great library, but i don't think it's particularly useful for writing a roguelike.
If readability isn't one of your biggest criteria then I suspect you need to reexamine your language-selection algorithm. (Hint: A bad language-selection algorithm is what makes people write code in C++, Java, C#, etc, when they have a choice. Sadly there aren't enough mental health care facilities to handle all of those people.)
roguebasin has a page devoted to developing roguelikes in python: http://roguebasin.roguelikedevelopment.org/index.php?title=Python
&gt; This is entirely dependent on language implementation, not language definition. True, but programmers use language implementations to do real work, not some abstract language definition. Turing completeness means that one language can theoretically do the same as another, but it may need to simulate an entire computer system in order to do so. This would make such a language impractical - for example Conway's Game of Life is Turing complete, but no-one in their right mind would try to write a usable program in it, however fast the implementation. 
Cpan has some problems. Many of the modules are partially written in C. The package maintainers make a lot of assumptions about what's standard on an OS. I've often had to track down needed C libraries on my own. The auto installer has never worked for me. And some parts of cpan.org are [hilariously out of date](http://www.cpan.org/modules/INSTALL.html). (copyright 1998)
Python is easy to read. EDIT: Oh sorry, I was held up by your unreadable questions and statements. I was looking at too much python code.
I may be misremembering the original attribution. C++ is certainly a retrofit of a scary sort. Having worked w/ OO perl, however, I can say that it is not at all unfair. Stay away from that crap if you have the option.
Word.
&gt; Turing complete language (which is just about all of them). Actually, there are interesting languages that aren't Turing Complete: Those that have the programmer prove his program halts to the compiler. Since the programs are all proven to eventually halt and not loop infinitely (a useful thing!) they are not Turing Complete, and you cannot write a Turing Machine emulator in such a language. 
&gt; This is entirely dependent on language implementation, not language definition. It depends on the language itself too, of course. A language may make it easy, hard or even impossible to write efficient implementations.
Yeah, many people conflate the ability to implement a set of algorithms/computations, and the ability of a language to "do" things.
Reddit has brainwashed you well.
You'd have to know some openGl. It probably needs to be optimized more that just "send everything to the graphics card every single frame".
&gt; I'd say that the learning curve for python is shallower. I am of the opposite mind; I think it's really, really steep and then flattens out almost completely. I've seen 11-year-olds write game AI for a platformer in Python after 2 days of training. After a few months of daily Python use, it will be hard to find new things you didn't know.
What languages do that?
Moar, please!
what eval{ die; } isn't good enough for you? ;) (re exception handling) I agree, I won't say that CPAN is perfect, but I'm sure pypi will have a similar level of duplication in the future (maybe not quite as bad due to the lack of a tmtowtdi mantra in python).
&gt; Many of the modules are partially written in C. The package maintainers make a lot of assumptions about what's standard on an OS. I've often had to track down needed C libraries on my own. Well, the module *should* have a test in place that checks for libraries/etc to ensure that it can install. This may not always be the case, but a will written CPAN module will contain that. I've had issues with modules off pypi that had uncertain deps (specifically when doing OSX). This will happen whenever you are trying to track packages outside of the os's management system. &gt; The autoinstaller has never worked for me really? `cpan Net::IRC` should work on just about any system.. What sort of errors do you get? Generally (on most OSes) it does need to be configured first (cpan&gt; o conf init) &gt; And some parts of cpan.org are hilariously out of date. (copyright 1998) Hilarious, yet still correct instructions.
In Python, it's hard for your predecessor to hand over one liner CGI app while saying "adios sucker!" I guess that counts as readability as well. How about Web Frameworks? Python have a number of fancy web frameworks. Are you convinced yet?
Java is far from fast, it requires a VM to run.
[Hard to build data structures](http://www.garshol.priv.no/download/text/perl.html#id3.3.) gets me every time.
well written perl is readable.. the problem is that alot of people do not write perl well.
Coming from a perl background, I found python *really* easy to pick up, literally hours from studying to making a useful application.
lolwut?
Or Cython, or benchmark the bottlenecks and rewrite the slow parts as C++. CPython with C/C++ [is still faster](http://geetduggal.wordpress.com/2010/11/25/speed-up-your-python-unladen-vs-shedskin-vs-pypy-vs-c/) than PyPy.
&gt; No references. Generators. Clean module system References: http://perldoc.perl.org/perlref.html Clean Module System: cpan.org &gt;There are some libraries and apps like NumPy and Twisted that may not have good Perl equivalents, but I don't think there is anything Python can do that Perl can't in principle. NumPy equiv: http://en.wikipedia.org/wiki/Perl_Data_Language Twisted Equiv: http://poe.perl.org/ &gt; Convenient syntax for using regular expressions. Anonymous functions that can be longer than a single line. Closures don't treat read-only vs. read-write variables differently. uh, you're talking about perl here, right? regular expressions in perl have their own operator, e.g: if ( $string =~ /^foo.+bar$/ ) { do something; } anonymous functions: my $var = sub{ do something; do something_else; } and read/write.. which language does that? because both it's pretty much just close(fh) or fh.close(). &gt; Perl community doesn't seem to think the transition to Perl 6 is going to be fracturing and unpleasant. We shall see. in larry we trust (we'll see)
Nice try, Perl user.
I was thinking the exact same thing when I opened this, and when I saw that caveat I'm thinking: why is readability unimportant? Readability directly affects maintainability and comprehension, and how you write applications. Programs are read much more often than written, unless you're able to write bug free code! It's like if the question were: "Besides python being good and perl being bad, why is python good?"
Generally, all (or virtually all) dependently typed languages have at least a subset that is not Turing Complete. That is the subset used to compute proofs of correctness. Since the computation is guaranteed to complete successfully, and all it generates is a proof of correctness, you don't actually have to execute it, since you have proved that a proof exists. That is how dependently-typed languages allow you to express a proof of any arbitrary logic proposition as simple code that never even has to execute. It just has to generate proof of the right property *if it were run*. If it was Turing Complete, though, it would not necessarily complete and generate a proof - so you have to actually execute it to make sure you get a proof, which is a significant disadvantage. Specifically, the Agda language isn't Turing Complete by default (unless you explicitly disable termination check). Epigram is Turing Complete but you can explicitly specify specific functions halt, and those use a Turing-incomplete subset.
&gt; The python object model is superior Which one? The Perl world has mostly moved over to Moose for new development. Python's model is better than the old OO lego Perl provided, but Moose is something else.
No, he asked about what the _advantages_ of one over the other is. It's like if somebody asked what the advantage of a space ship is over unicycle, and you reply that they're both just modes of transport, so obviously there's nothing that one can do and the other can't.
So does Python really. Either one can be fast with JIT. Are you just trolling?
It's a possibility. I didn't feel like this thread had enough stereotypical "Java is slow" responses.
Actually, he's comparing modern Python with Perl 6, which is only 11 years old. It's still unreleased, though.
Unfortunately, the internet is full of people who are not in their right mind: http://rendell-attic.org/gol/stack_construct/project.htm 
&gt; It's like if the question were: "Besides python being good and perl being bad, why is python good?" More like "If the only thing you have to say is that you can read Python code and you can't read Perl code, I'm not interested in your opinion."
Also relevant: [this](http://xkcd.com/224/).
&gt; Python's model is better than the old OO lego Perl provided.... Apart from some surface syntactic issues, Python's OO system is the same as the default Perl 5 OO system.
&gt; [Perl 6 is] still unreleased, though. Fedora included Perl 6 a release before it included Python 3.
I don't think PyPI and CPAN are about numbers only, and I don't think this comparison is fair. If anything PyPI Is a collection of module names and URLs whereas CPAN is a consistent module database and distribution infrastructure. Each distribution benefits from the [cpantesters](http://static.cpantesters.org/) infrastructure, ensuring that whatever you download (and upload :)) is thoroughly tested by all kinds of machine architectures. And what about namespaces ? On CPAN namespaces matter, so looking for things in the ["Net::Server::"](http://search.cpan.org/search?query=Net::Server&amp;mode=all) namespace gives a list of related modules based on the Net::Server distribution. And what it does is rather explicit. What about documentation ? If you're using something from cpan, that's where you get the doc for it, it's all in the same format. All in all I'd say PyPI is a great thing for python, but it is nowhere near as mature as CPAN.
Except of course, this unicycle can also go into space, or might use a wormhole for space-transportation instead of direct space flight.
But in that scenario, you may as well throw out the unbiased evidence and roll die. Its just as likely to be a good basis for forming a conclusion.
But RIM are obviously growing if they have http://rim.jobs still. *Edit* hax, that domain is gone somewhere, perhaps the end *is* nigh!
the regexp stuff is after "What're the advantages of Perl over Python?" =).
Yes, but you would need to optimise a bit more than Minecraft is currently optimised to keep it responsive.
They're just numbers. Numbers give no real idea of *value*. Just because China has more people than Australia doesn't necessarily make it a better country. Or, because 2 countries have similar populations, that doesn't mean the standard of living will be similar. If you could say "90% of packages are crap in Perl, and 95% of packages are crap in Python" or vice versa, then you could probably get a measure of how many good packages exist for a given language, and that would be a more useful metric, but making a general sweeping statement that 95% of packages are crap would require a lot of analysis and its probably impossible to actually conclude that value.
I think when you frame it in the context of one language vs. another you're pretty much guaranteed a fanboy flamewar. It's reasonably easy to learn the basics of both languages - there's a ton of resources out there for both. Work through a few examples and see which one works for you. After may years of using, but never really mastering Perl, I really appreciate Python - it's just easier for me. I don't know how popularity factors into your criteria or whether it matters, but I think it is safe to say that perl isn't exactly the belle of the ball anymore: http://www.google.com/trends?q=perl,+python,+ruby. 
I personally think its its just a taste thing. I like not having to remember which function/method to call to merge 2 arrays. @a = ( @b, @c ); Is much easier to remember than a = array_merge( b , c ); ( also, when you do this in PHP for example, prepare to have something unexpected happen if b and c are actually hashes ... )
You can do it, as long as you do it all inside a string. I've seen examples, but I don't have links :(
I'd have to second this one, Perl is rather big on what Larry Wall calls "Magic", that is there's lots of things that have a special meaning in a certain context, and a different meaning in every other context. While it's great for writing concise code, it makes it harder to learn. I personally have learnt, in this order.... basic, C, x86 assembly, C++, PHP, Javascript, Python, Erlang, Perl (and it looks like lisp will be next). Python can be learnt in a fortnight, and you'll be really proficient. Perl takes months to get "proficient" although you will be writing things that work within the same fortnight. Althought, Python has the [Python Phrasebook](http://www.amazon.com/Python-Phrasebook-Brad-Dayley/dp/0672329107) with which you can literally spend a day learning the syntax of the important bits (while, for, if &amp; print) and then pick up the phrasebook and start bashing out useful code. Perl has a far higher beard index, and Perl programmers in general seem to be smarter folk than python folk, although that difference is very very minimal. I think it's only because Perl folk have usually been doing it longer. Python gets more use in the movie industry, Perl gets more use in the ISP industry. That's really what you need to look at. (Python is also gaining in the scientific computing field, but it's still a minor player)
 use Try::Tiny; try { code that fails; } catch { print "Died with $_ "; } etc. 
Perl got big when the web got big ('94 and after). Python didn't get big until after Rails, honestly, or at the very least Paul Graham's Python paradox. In any case, Python had about a decade's worth of extra-gestation time.
Moose. Parrot. I have to say that I have yet to look back at perl and think.... What if I'd stayed? Could it have somehow become awesome?
Hrm. Perhaps I'm mis-using the "learning curve" metaphor.
You don't make it look like you know what you're talking about when you use PERL in all upper-case. Its *not* an acronym, and this seems to be something I expect people to learn early on.
By unreleased you mean what exactly? I'm pretty sure I just installed it ( rakudo ) with my package manager from my distributions approved main line =). http://packages.gentoo.org/package/dev-lang/rakudo By the same metric, GCC 4.5 is not released yet, ( http://packages.gentoo.org/package/sys-devel/gcc ) , but it sure as hell is released: http://gcc.gnu.org/gcc-4.5/changes.html 
Absolutely you could. Python is a general purpose programming language just as Java is.
I know Larry says he borrowed Python's model, but after reading Conway's OO book, I'm not sure I agree. On the other hand, that's just a lingering impression, and I suspect I wasn't mature enough as a developer at the time to handle that book -- it covers a lot more than simple isolation or inheritance. I should probably give it another go.
no, since InfinitApe was already trademarked by the writers guild of America.
I think its a good representation of the people who are grown-ups taking part in such discussion not to resort to immature flame-wars. =). "I may prefer X over Y, and I'll gladly give you my reasons, but just as I don't want to have somebody shove Y down my throat, I'll be nice and not shove X down your throat" 
Perl has a number of fancy web frameworks too! I'm also unconvinced that "because its python, it will be readable". I'm fairly certain I've seen horrific code in every language I've ever worked with, and am more inclined to believe the "because its python it will be readable" mantra is spoon feed by python community and you accept it as true because your experience leads you to think python is readable, ( just like I think Perl is readable ), and thus conclude the community statement must be universally true for all people. 
Huh? Tl;Dr: you should conform to my opinion on languages, and not decide what languages to use because of their merits, you should just decide what language to use BECAUSE I SAY SO. Way to be objective and scientific!.
well I think it's prudent to ask this question before undertaking the project :)
It depends how you label your axies. if Y is "skill" and X is time, then a shallow learning curve indicates "Lots of effort, lots of time, don't get very far". If Y is *difficulty* however, then a shallow learning curve means you don't have to get your hands dirty too early.
about to say. I mean, the only thing his list really gives is generators.. which I don't see as being a "killer" feature.
Agreed, but you could implement a Python Minecraft in a fraction of the time, effort &amp; code needed for a Java Minecraft. You could optimize your Python version to be more performant than a Java version, and still have time left for more fun new features.
oh, I'm aware. I was talking about native try-catch.
actually the fanboyism on the perl side wasn't bad. http://www.reddit.com/r/perl/comments/f2p5y/what_are_the_advantages_of_perl_56_over_python/ very little trashing of python, just talking about "perl has x, y, and z"
Damian's book is about the possibilities with OO that Perl's very bare bones instruction gives you. I'm confused though, what exactly is the difference between the Python OO system and the Perl one that people seem to be crowing about? Defining a class in Python appears to be: class NumberThing: def __init__ (self, value): self.value = value def addThing(self, param): return self.value = self.value + param the Perl equivalent would be package NumberThing; sub new { my ($self, $attr) = @_; return bless { value =&gt; $attr } $class; } sub addThing { my ($self, $param) = @_; return $self-&gt;{value} += $param; } It looks like the only real difference there is the fact that Perl requires you to shift off your arguments, and manually associate the class with the data structure. If this is the case then might I suggest it's mildly ironic that Python is being heralded as "better" because it's more Implicit than Perl. Despite what PEP 20 says. If you look past Perl's defaults into Moose the code is cleaned up significantly with some implicit defaults. package NumberThing; use Moose has value =&gt; ( is =&gt; 'ro' ); sub addThing { my ($self, $param) = @_; return $self-&gt;value += $param; } If you use MooseX::Declare this would become class NumberThing { has value =&gt; ( is =&gt; 'ro' ); method addThing($param) { return $self-&gt;value += $param } } or if you choose Moose's built in Native Traits package NumberThing; use Moose; has value =&gt; ( isa =&gt; 'Num', is =&gt; 'ro', traits =&gt; ['Number'], handles =&gt; {'addThing' =&gt; 'add'}, ); The nice part is that the code Moose is generating underneath is roughly equivalent to the code you'd write by hand. So is the benefit really that Python has some good implicit defaults?
I disagree, but probably with a similar lack of knowledge on the subject. From what I've seen, Java's more suited than Python because of the JIT compiling. Plus, (not too sure about this one), I think it's libraries for the task are more mature. So even though most of us like Python's syntax more, I feel by fighting with performance and lacking libraries you'd be wasting tons of effort that would outweigh any time/cost benefits of using Python. I think it's a case of having a hammer and seeing each problem as a nail. Granted, Java's not the best tool available either\*, but I definitely think it's more suited than Python. \* - Although, in Notch's case Java probably was the best tool. He was already more than familiar with Java and it does what's necessary for Minecraft.
Python has a built-in REPL.
Syntax and history aside, Python and Java aren't all that far apart. They have similar features and natures (strongly typed, object-oriented), and both compile down to bytecode.
Python has Scipy, an enormous library for scientific computing. There's nothing comparable in the Perl world.
My apologies. I wasn't really paying attention. 
I program in perl for my day job and use python on my own. It's true that perl and python are similar, fill a similar role, are similarly powerful. But, because of its heritage and design, I would say that perl is worse than Python as a general purpose language. For example: **1.)** Some people are saying how great Moose is for perl, but why does Moose exist? The OO model of perl is so deficient that Moose had to be created. The python OO model was, more or less, designed correctly (with a few warts, e.g. old-style classes vs. new-style classes), and everyone uses it because of how well it works. **2.)** The same problem exists for exception handling. Perl uses [strings](http://perldoc.perl.org/functions/die.html) for exceptions, which is OK if you're writing a shell script in 1995, but it sucks for writing good software now. Python on the other hand, has a very well designed exception system (look at this [exception hierachy](http://docs.python.org/library/exceptions.html#exception-hierarchy), it's lovely). There are a dozen libraries in perl which re-implement exception handling, because the original design was so poor. **3.)** Why does perl have "[use strict](http://perldoc.perl.org/strict.html)" and "[use warnings](http://perldoc.perl.org/warnings.html)"? Because the original design of perl led to people shooting themselves in the foot. Python does not have this issue. You don't have to put these two bandaids (or any of the many [other](http://search.cpan.org/~chromatic/Modern-Perl-1.03/lib/Modern/Perl.pm) [ways](http://search.cpan.org/dist/common-sense/sense.pm.PL) to write it) at the top of the file before you even write a real line of code. **4.)** Why do I have to [manually unpack parameters from a list](http://perldoc.perl.org/perlsub.html#DESCRIPTION) when I want to write a function? Why are there N packages on CPAN that were created to solve this problem? In Python, I just write a sane function signature. These are just a few examples, I have tons more. [This](http://www.garshol.priv.no/download/text/perl.html) (from another comment here) sums up a lot of the same ideas.
Make me happy.
Not really. I use Java when performance matters and scripting languages when it doesn't. There are huge performance gains when using the exact same algorithms in Java.
There is nothing one can do that the other can't. Your choice of scripting languages should be based on what you plan to do with it. 
Now imagine using C/C++. Or am I wrong on this one?
See PNaCl, Portable Native Client, which uses LLVM bytecode.
Python is a language. PyPy is an implementation of the Python language on top of Python itself, just like CPython is an implementation of Python in C, or Jython in JVM, or IronPython in .NET. (You probably want to use CPython) Cython is a language that makes writing Python extensions in C easy. (If you needed this right now, you'd knew about it already) Pyglet is just a Python library. (You'll use many of these libraries :))
Gonna back you up 100%..... except for 1 comment. &gt;you don't use assembly to build modern software Well, not entirely. But processor intensive portions of modern code still are.
It's not just a JIT compiler that helps things. Many of Python's nifty features slow it. Dynamic typing doesn't help, either. Java isn't my favorite language, but its static typing gives JITs more room for optimizations.
Nothing really. Both are just as capable, but Python is saner.
Alright. Python itself is just a language, like English, Spanish, or French. I can write valid Python on a sheet of notebook paper. Implementations of Python are what allow the language to actually execute. The main implementations are: *CPython (the reference and most common implementation, found on http://python.org *Jython, which is Python for the Java Virtual Machine *PyPy, which is Python written mostly in Python (don't worry about it too much) *IronPython, which is Python for Microsoft's .NET runtime Cython (and Pyrex) are Python derivatives that have a different syntax but allow for the easy construction of fast Python extensions. Pyglet (and PyGame) are python based framework for developing games. PyPI is the Python Package Index.
&gt; it makes it harder to learn. And harder to remember. I use Python because I don't use scripting languages that frequently, and because of all of Perl's whack-doodles, I don't remember it across the gaps. Python, with its 'one right way to do it', much as I dislike that /in theory/, in practice I remember Python just fine. 
Blah, complicated hehe. Thanks :) (not much of a programmer)
No, but it's nice. It's one of the real advantages of Ruby, for instance. 
I believe it could if the developers were willing to implement *some* parts in C. I have been developing in python on an embedded platform for over 2 years now where we have had to deal with some difficult performance problems. That being said, with a fair bit of profiling and some optimization work, we are able to keep up with all the data coming into our system (this includes data coming in off different vehicle buses). Would Minecraft as programmed work well with python? I don't think so (my perception is that the game is not very well constructed). The beauty of python is that you can prototype quicker while still, with some discipline, deliver quality software. Projects like pypy also hold promise... In this case, I would guess that outsourcing some of the heavy lifting to the GPU/C layer would suffice.
&gt; Though, if you write Python you don't need to worry about Perl 6... Eh? Wrist-flick parallelism, junctions, using grammars like regexps - no, Perl 6 is still, when it gets done, going to be something new to be reckoned with. 
I will take you one step further, young noob. Brace yourself, for I am about to fill you to the brim with all of the knowledge of python you shall ever desire. Behold, [The Great Google!!!](http://www.google.com) Now, go forth and code well.
Portable and native doesn't mix. If it is LLVM bytecode then it is... err, well, bytecode for a VM. Naming fail.
Google, can answer my questions, it is true.... but only if I know what I am asking... :-\
You can get faster, sure. But the difference from Python or Ruby to Java is huge, and the difference from Java to C is not nearly so big, in my experience. Plus, C is a royal pain in the ass.
bullshit [cython](http://www.google.com/#sclient=psy&amp;hl=en&amp;q=cython&amp;aq=f&amp;aqi=&amp;aql=&amp;oq=&amp;pbx=1&amp;fp=ee5b8d49ec6ea034) [pypy](http://www.google.com/#sclient=psy&amp;hl=en&amp;q=pypy&amp;aq=f&amp;aqi=p-p1g4&amp;aql=&amp;oq=&amp;pbx=1&amp;fp=ee5b8d49ec6ea034) [pyglet](http://www.google.com/#sclient=psy&amp;hl=en&amp;q=pyglet&amp;aq=f&amp;aqi=g4g-o1&amp;aql=&amp;oq=&amp;pbx=1&amp;fp=ee5b8d49ec6ea034) funny, how this is almost the very definition of a question that is easily googled "what is &lt;library/framework/language&gt;"
I've been using perl -MCPAN -e 'Install Module::Sub' on many many variations of Linux to auto install modules (with recursion!) for probably 10-11 years now and have almost never had a single issue.
Beyond performance, remember that minecraft runs in the browser with minimal setup.
Though still slower than direct calls to array in my tests. I haven't benchmarked the new struct capabilities in python &gt; 2.4 (that is, the struct.Struct class).
To summarize my favorite features of ipython for rest of the tl;dw crew (although I did watch some of it and picked up on some neat new features that I will likely use): _ refers to the return value of the last executed statement _oh[n] refers to the return value of line n ! can be used to run shell commands. ie: !ls or !ps aux | grep python appending the ? character to any object (functions and methods are objects, too) to get some additional info, including the object's type, base class, string representation, namespace, containing file, docstring, and constructor arguments. examples: dict? or {}? or foo? appending ?? to any object lets you peek at the source code where that object is defined. Also, there's a package called ipdb that provides a version of pdb with all the awesomeness of ipython. http://pypi.python.org/pypi/ipdb for those without setup tools or pip. 
I agree with you completely. And I upvoted, but I want to say that the non-word "performant" makes me cringe.
As others pointed out below, Python is catching up to Java's performance (PyPy, etc). And Python's libraries are as mature, solid &amp; powerful as anything I've seen in Java. Given Python's more expressive &amp; powerful nature, many of its libraries are *very* impressive indeed - the shit you can pull of in just a few lines of PIL or numpy never ceases to amaze me. But, I have to agree in the general sense: a high performant, resource intensive video game is one of the few tasks Python is probably not ideal for. Stick to C++ and the myriad game engines out there.
"**Mastering Perl for Bioinformatics** covers the core Perl language and many of its module extensions, presenting them in the context of biological data and problems of pressing interest to the biological community. This book, along with **Beginning Perl for Bioinformatics**, forms a basic course in Perl programming. This second volume finishes the basic Perl tutorial material (references, complex data structures, object-oriented programming, use of modules--all presented in a biological context) and presents some advanced topics of considerable interest in bioinformatics."
Ah but in Python, you can profile and re-implement the functions that are slowing you down in C, getting the best of both worlds (imho)
[Catalyst](http://www.catalystframework.org/) [Mojolicious](http://mojolicious.org/) [Dancer](http://perldancer.org/) Those 3 are really really good Perl web frameworks. 
Context free statement is context free, yet still (mis)leading.
Statements lacking knowledge are lacking knowledge.
How many of searches for python are for snakes and ruby - for gems?
Or C++, if it suits you.
Rendering takes far more time than game logic, no matter what language you use. Game logic can be run on a separate core. Game logic can also be parallelized. You didn't mention hardware acceleration. Computers are already faster than when you coded up that "rendering thingie".
Thanks, don't know how I missed this.
Too many answers by people who have never actually coded a full game. Sad. Your answer is yes, and there is no simple explanation to qualify the answer, because programming games is complicated.
Yes! And this can be very powerful for many software systems, because the performance bottlenecks are usually restricted to just a tiny fraction of the overall code base. 5% C for the critical bits, 95% Python for the rest, and development speeds that'll make your head spin. Best of both worlds indeed. However, in something like Minecraft, I get the feeling that a large portion of the overall code has to perform well, so this 'recode the bottlenecks' approach doesn't hold up well. But I could be wrong about Minecraft here.
Of course it is, in the sense that it is Turing-complete. That's not the issue. The question is: would it be practical/efficient to do so? Things like maturity of the language, availability of libraries and performance do matter sometimes.
Python can be used for everything. There are no exceptions. It can always be optimized to be as fast as C, because everything can be optimized down to C. Numpy, as well as various other libraries, also allow python to easily regain the performance of such lower level languages.
While not exactly what you are looking for this will probably give you some ideas: http://www.drdobbs.com/high-performance-computing/204801163 
For the record, general-purpose != Turing-complete.
What a pompously pedantic post. You don't call .jar files portable? Anyway, it is indeed more portable than NaCl itself. The point is that the particular bytecode which PNaCl uses is portable across architectures. Regular NaCl requires code to be compiled for specific architectures - x86, ARM, etc. PNaCl is architecture-agnostic. Your definition of "portable" is not portable enough.
I love the poetry of this answer.. I think you might be a fan of this video: http://www.youtube.com/watch?v=wMFPe-DwULM I mean this legitimately.. it's a great video.
No, I mean it's general purpose in the sense that's it's intended for general use.
If you're willing to go a bit beyond the normal batteries included python, you could include [numpy](http://numpy.scipy.org/) and get some optimized array handling. Which may be all the high performance parts you would need for something like minecraft. See also the [bravo server](https://github.com/MostAwesomeDude/bravo) which claims to be more efficient than the normal java server, even though implemented in python.
Sorry but this is an uninteresting semantic argument.
True, but this kind of violates OP's original question, in that it would no longer be "using only python".
I was *trying* to come up with something witty and zen.... nevermind. /cry
Yes, but OP was asking about "using only python".
You should compare V8 to PyPy instead. PyPy is making great gains already, and it has nowhere near the big-business support of V8.
Sure, but kvsn's point is also valid. If there isn't good library support for e.g. graphics, or optimization techniques to make it run fast, then it will be very difficult (i.e. impractical) to write a game using only Python.
I agree. I'd say a general-purpose language is necessarily Turing-complete. So, we're basically arguing about whether building a game such as Minecraft is general-purposy enough for Python's interpretation of general purposeness, right? :)
I'm surprised no one has mentioned strong vs weak typing. Python has strong typing where Perl has weak (like C). To me it's very important that an integer does not magically become a string or a hashref becomes a string (it's bitten people many many times). Consider: darjus@localhost:~&gt; perl -e 'print "Test " . \{"test" =&gt; "me"}' Test REF(0x78ecd8) darjus@localhost:~&gt; python -c 'print "Test" +{"test": "me"}' Traceback (most recent call last): File "&lt;string&gt;", line 1, in &lt;module&gt; TypeError: cannot concatenate 'str' and 'dict' objects Also, exceptions! I've seen many people use Perl eval for exception handling (as it lacks throw/catch) which has many corner cases. Python has "proper" exception handling, so one can throw/catch a specific exception instead of "catching" **everything** (including syntax error, or import errors) with eval.
It's not difficult or impractical. Lots of games are written in Python. I've written one.
And don't forget algorithms...
Would using something like beanstalkd be useful here? I don't know the specifics of your race conditions or current codebase, but I wrote most of the data-processing pipeline for the startup I work for using beanstalkd, and it meets our needs. Unfortunately my experience working directly with python's multithreading and the GIL is near nil.
Python can be fast, but the question is whether it is "now". Theoretically, there's nothing in the language that stop one from writing a performance game in Python. But I guess the OP is more interested in the current state than some imaginary improvement 10 years from now. Is PyPy's JIT at the same level as JVM's JIT?
&gt; 3.) Why does perl have "use strict" and "use warnings"? Because the original design of perl led to people shooting themselves in the foot. Python does not have this issue. Alas, Python very much has this issue. Or, to use less loaded language, issues that would be caught if it had a warnings equivalent.
And for perl--for gems, but by illiterates? :)
I have to disagree - Larry Wall's philosophy that there should be many ways to do something result in a language full of surprises. Get eight people in a team and you'll find 20 ways of doing the same thing. Move people around so that they're patching/maintaining each other's code and they'll spend a shitload of time trying to figure out what the code actually doing. This is why I moved to python around 2000 - far fewer surprises and mysteries. I can easily read code I wrote five years ago, and reading someone else's code is such a challenge any more. Hmmm, it would be cool to measure language complexity in terms of redundant operations/techniques. Of course, it's just one factor to consider out of a number. Still...
It seems that the consensus is 'yes', although when I first thought about this question sometime around May (prior to the existence of a downloadable client for the game), the biggest issue I thought of was wondering what tools could be used to run it in the browser and whether those would be fast enough. What would you use for building a browser-based client using python? (minecraft wouldn't be where it is today without having had a browser client initially IMO)
I work on a team of 13 people writing perl, with a few standards in place (see: perl best practices), it's not that big of a deal.
Readability is definitely important. The problem is readability is often in the "eye of the beholder". I would say that Python has a small edge in readability IF WELL WRITTEN. That said I have no trouble reading either of: well written Python, well written Perl. I have a LOT of difficulty reading poorly written programs in either.
You can do the same with Java via JNI though, plus use any of the tons of Java profilers. You'll be hard pressed to find any modern language that *doesn't* bind with C.
Absolutely. You would use a library like [pyopengl](http://pyopengl.sourceforge.net/) to handle the interface with the graphics card. (minecraft uses [lwjgl](http://lwjgl.org/)) Aside from graphics, input and sound, everything else could probably be done with the standard python library. Now, depending on which Python interpreter you're using, performance might be more or less of an issue. As people have mentioned, there are always ways of getting around this, such as implementing the critical paths in native C. However, Minecraft is far from optimized, so there's a good chance you could do everything in pure python aside from the libraries for input and output.
pywin32 can do it through COM.
is this one: [[python-perl] Translation review?](http://mail.python.org/pipermail/python-list/2005-April/920405.html)
Pretty much every dynamic language has this issue. The problem with perl in this case is that using undefined variables is allowed. If you mistype a variable name you don't get an error, you get `undef`. In python, you get a `NameError`, so `use strict` isn't necessary. FWIW I've been bitten far more times by a hash returning `undef` for a key that doesn't exist, than by mistyping a variable name in python.
Aplle ][ BASIC has no OpenGL bindings. (Please internets, prove me wrong.)
 import win32com.client wordapp = win32com.client.gencache.EnsureDispatch("Word.Application") wordapp.Documents.Open(doc) docastxt = doc[:-3] + 'txt' wordapp.ActiveDocument.Close() from some old code I have lying around. I think its from a python phrase book from o'reilly.
I'll have to look into how beanstalkd works internally to see if there could be some helpful stuff there. There are some special requirements with this particular application as we are running on an embedded platform with limited computing/memory resources. Creating a second interpreter instance probably isn't that helpful. We already use a custom threadpool implementation that is working out nicely. This is heavily optimized and takes advantage of GIL-atomic operations to prevent GIL-thrashing. We are also working on fitting more of the work we do onto a set of select-based reactors to reduce overhead from thread/GIL thrashing. Out of curiousity, what does beanstalkd really give for you? Is it mostly helpful in distributed computing environments or could it be useful within a single server environment? Is the big win the forced isolation of state?
Interesting article. I've thought some about enforcing a lock hierarchy but found other techniques more useful. We perform potential deadlock detection by placing software/hardware watchdog on each thread and ensuring that it comes around to kick/stroke that watchdog at some expected interval. If it does not, we log as much about the state of the system as possible (including lock state, as we have all locks creating through a central interface) and reboot the device (to restore to a good state). These techniques are common in the embedded world and facilitated to some extent by the platform we are running on. IMO, the tricker case is race conditions -- you often don't know that something got screwed up until later in execution and it is very difficult to trace back to the root cause.
Perl gets two chances to catch it at compile time, with either strict ("Global symbol requires explicit package name") or warnings ("Name used only once: possible typo"). Python definitely catches it ("NameError: global name is not defined"), but at runtime. I wouldn't call `strict` unnecessary. I wonder if there's a way to make Perl crash and burn at runtime as well.
You are wrong for this and this reason.
UnladenSwallow was a branch of CPython - it started with mainline CPython code and incrementally modified it. IronPython has its share of compatibility bugs.
Not suck.
I don't call .jar files native...
Probably. But it'd be interesting since voxel based games are beginning to pick up popularity. Also, while it is not a voxel engine like minecraft, Eve Online use Stackless Python [see their presentation on it.](http://www.slideshare.net/Arbow/stackless-python-in-eve)
&gt; * A table with fixed set of operations that can be performed (i.e. add, subtract, jump to a different cell if current cell = 0) &gt; * A state register containing the current state of the machine, with a "start state" that the machine is initially in This is incorrect, but not by much. Really, these should be the following points: * There is a fixed set of states that the machine can be in, including one that the machine is in at the beginning. * There is a table of transitions that define the computation: if the machine is in a particular state *and* the current cell contains a particular symbol, then erase/write the new given symbol, move *one* cell to the left or right (or don't move) as specified, then assume the new given state. A variation has the erase/rewrite separated from the movement, but both are trivially equivalent.
This is disingenuous, though. The extension module system is an integral part of Python. If you use Numpy, which is coded in C, does that make it not Python? If you use ctypes to access native system DLLs, does that make it not Python? What about python bindings to existing ODE and physics engines coded in C++? A huge part of Python's strength is the size of its library ecosystem, and the ease with which it integrates with existing C-based libraries. Contrast this with Java, where everything is implemented in Java, so it had better be JITted.
You can avoid many problems completely by removing shared state. Shared state meaning more than one thread is modifying the same variable. A contrived example where ``obj`` is the same instance: Thread 1 obj.Increment() Thread 2 obj.Increment() So now you have to start locking and unlocking in the right places to avoid race conditions while also not introducing deadlocks and livelocks. Not hard to get right in this example but much harder with real world code. A common way to avoid this is to use (synchronized/thread-safe) queues. Depending on how much you need to communicate across threads this can begin to get tedious and repetitive though. Usually each thread looks something like this: while True: msg = queue.pop() if msg.action == 'create': item = self.Create() msg.replyQueue.put(item) elif: ... In the other thread it's popping messages from``replyQueue`` to process responses. Everything ends up being asynchronous so you have to make sure messages have enough context in them to process them. Say you get two ``create`` responses in your ``replyQueue``. What do each of those responses correspond to? This is more a less of a manual way of using the [Actor Model](http://en.wikipedia.org/wiki/Actor_model). There are a couple actor model libraries out there for Python but none that strike my fancy.