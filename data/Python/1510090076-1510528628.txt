Without resorting to numba magic you could do this: def f_opt3(I): def mkslice(i): if i &gt; 0: return slice(1, None) elif i &lt; 0: return slice(None, -1) else: return slice(None, None) O = np.zeros_like(I) for i in (-1, 0, 1): for j in (-1, 0, 1): O[mkslice(i), mkslice(j)] += I[mkslice(i), mkslice(j)] &gt; I[mkslice(-i), mkslice(-j)] return O You could also write out each step without the for loops if you're neighborhood is going to always be the immediately surrounding elements but this way is easily modifiable to large neighborhoods.
With backpropagation: You try something, check your result, adjust accordingly and try again.
thanks, joined!
We are keeping close track on this and the time it takes. Usually, it's 100% automatic and no one is involved in the process. We had one major incident over the last year where a single dependency broke a lot of projects. In most cases, every month when we open the dependencies it goes by very smooth and with zero incidents. If this proves to be problematic in the future, like anything, we will evaluate and react to it.
Look up Siraj Raval on YouTube for machine learning in python stuff. I’d be remiss if I didn’t suggest spending a little time increasing your python skills as well. Good luck :)
No problem!
I think it's silly to talk about linked lists in Python. They make a lot of sense in lower-level languages, but implementing them in Python isn't really very authentic. And yet most introductory curricula try to shoe-horn them in anyway, because they feel that they're important for students to encounter early. Why can't we be satisfied that CS1 courses have students use lists effectively, without trying to make them implement them in ways that they shouldn't be implemented too?
Thanks, Clippy! : )
Not with Python but I did try out the LuaJIT equivalent and thought it was super cool. I'd avoided it because of the dependency on libffi, but anymore that may not be a reasonable objection (?).
Gradient decent on your errors 
For me, this guy is way too scattered in his presentation for me to follow. He seems more like an entertainer than an educator.
Sounds like Django would be overkill. Flask is probably the best place to start. 
This shows the most efficient path for learning machine learning : https://learn-anything.xyz/machine-learning Amongst other topics. And every learning path is moderated by community of people. 
Go with the spreadsheet, learn python in your spare time and use it the next time something like this comes up.
I agree. I can't stand him, but if others learn can learn a lot from him, that's good.
You realize these exist, such as ESPN, etc?
I know you're talking generally, but most people here mean in terms of Python, given we're on /r/Python
When I was starting out, I tried to use bottle.py but could never ever get it going. Django's heavy duty, but getting it installed and going should be trivial, I think. Something like pip install django mkdir test_app cd test_app python django-admin.py startproject polls python django-admin.py startapp polls_app vim polls_app/views.py //to edit a view, like index python ./manage.py runserver 8080 The exact commands are probably a little different but there's a bunch of built-in ways to get a project running right off the bat. 
You right. Just thought it would be a good Python project.
Can I plug something like plotly without too much hustle to it?
3blue1brown has a good [video series](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi).
I couldn't say; just recommending a web framework. Looks promising thought: https://github.com/plotly/plotlyjs-flask-example
I think Siraj is great for getting a crash course in things. But (for me personally) goes too fast and has very specific cases. Do you have any videos in particular you liked secretgeekery? 
https://www.online-utility.org/text/analyzer.jsp I guess this could work, just use a new line for every post it and you should be fine. 
Dated. But for R: https://www.youtube.com/watch?v=7Jbb2ItbTC4. The caret library is really good and this video helps get your feet wet and understand some basic steps. 
I started with his build a neural net in 4 mins video, but following along with the code typed on screen resulted in a broken mess. I downloaded the code from github and then went through the video. It was my first introduction to machine learning and back propagation. I totally get all the criticism levelled at his videos, the man clearly consumes far too much sugar!
That was excellent. Thank you for sharing!
https://github.com/graphistry/pygraphistry
Or just run a Docker container with everything inside
I'm sorry for not specifying properly. I am wanting to delete duplicates in Column E and when it does this it deletes the row as to keep data neat. https://ibb.co/cHzLyG
Why? Just use the built-in list. Teaching? Teach it in a language that uses it. C?
I do not know how to respond politely to this. 
I was really excited before I actually got to the linked page. That is quite possibly the most cancer layout I've had the displeasure of using. It'd be great for maps, star systems, no for LISTS OF FUCKING ITEMS THAT HAVE BASIC FUCKING CATEGORIES (Sorry for the cussing, I'm on edge, and that site isn't helping - I'm so sick of 'modern' tech. Where every purchase has 10 screens when you are paying with fucking cash, where you fill out loads of personal information for simple things like memberships (because they are selling your data), designs for small screens instead of computers, sick of windows turning their OS into a worse and worse piece of shit, sick of forewarning people about certain dangers and having them ignore me - only to agree once the danger has come to pass, sick of it all really. We've made a shit system and I want out.)
Has anyone else ever found the syntax for nested comprehensions to be confusing? To me, `[element for element in nested for nested is parent]` makes a lot more sense than `[element for nested in parent for element in nested]`.
What are your interests? Better start from those areas. To give you an example. I'm also a new python learner and I'm interested in the stock market. As I was learning python I wrote a script to gather company stock and financial information from the internet so Python could help me analyze hundreds of stocks simultaneously.
I don't know how useful it would be but It might be fun to see the results rendered as a wordcloud. https://github.com/amueller/word_cloud
Going to leave this here: https://notebooks.azure.com/
Came to the commets expecting to see this. Good work. 
So, that interpreter isn't secure. try and os.listdir()
So you can access gcc through that interpreter, not sure how secure that is
So you can access gcc through that interpreter, not sure how secure that is import os os.popen('echo \'int main(void){printf("hello world\\\\n"); return 0;}\' &gt; f.c') os.popen('gcc f.c') print( os.popen('./a.out').read() )
IMO nested list comprehensions are too dense to be used in general.
How did that occur to you to try?
I like poking around I guess
Building my first django site with jinja scripting implemented 
The internet
Sam for me. Easier to remember if you remember that it's in same order as equivalent for loops would be.
If you've ever been curious about gevent, this is a well written overview of it's use in a web application.
If you already have a good math &amp; statistics background there are good and fun online resources like Udacity's Intro to Machine Learning course. 
hey you're not OP
Plug it into [Home Assistant](https://home-assistant.io/) - you'll get a great frontend and history database, nice automation rules, easy hooks into current weather etc, and more. The only downside is that you risk getting hooked on home automation :-)
Django does the hard work for you. Might be too much for some applications thought.
You might want to look at some examples of plotly used with IPython: https://plot.ly/python/ipython-notebook-tutorial/ Publishing your notebook files is a quick way to get your anaylsis up on the web.
nice, thank you! I will definitely look into it. Already have terrariumPi in mind: https://github.com/theyosh/TerrariumPI And, I am already hooked. It is just my current terrarium build is automated, but poor reporting capabilities and almost no smart sensors to track remotely. Run linux server with ubnt mfi smart outlets, spyder robotics/mistking, ubnt surveillance, things of that nature. My reef tank is fully automated with Neptune Apex. Doing same to my monitor lizards. 
This guy's is a quanity &gt; quality youtuber. Every one of his videos is blatant regurgitation of /r/python and /r/machinelearning posts with little cohesion. A beginner deserves a professional and simplified explanation of the concepts, not a incoherent regurgitation. This is why I always recommend Alex Smola's [Intro to ML book](http://alex.smola.org/drafts/thebook.pdf) and Michael Nielsen's [Neural Networks book](http://neuralnetworksanddeeplearning.com/). Not to shit on Siraj but I wan't him to focus on his content, not his out of touch youtube image.
In "hard allocation" languages like C or FORTRAN, understanding linked lists is quite valuable. In "easy allocation" languages like Python, there's no benefit to such data structures because the language can resize anything and will use the best and optimized means to do so. (I would put Java somewhere between. Arrays are first-class entities locked in size unlike all the standard second-class library data structures.) If you look behind the covers at how Python implemented these amazing "easy allocation" data structures like list, dict, set, you will see that they ARE built upon linked lists, double-linked-lists, hash tables, and so on. They made it so you don't need to re-invent it.
Haha! 
If you search Udemy courses for machine learning python, you can often grab the top rated courses for around $15 or less. These top courses do a great job of covering python basics. [Udemy ](https://www.udemy.com/courses/search/?q=machine%20learning%20python&amp;src=sac&amp;kw=Machine%20learning) 
Unless you need to use features only available in the latest version of Python, I don't see a reason to do so.
As strings or as integers?....because when i import it from arduino...i used data = str(arduino.readline)
Code: import pyautogui import win32api, win32con import serial import time print(pyautogui.size()) def click(x,y): win32api.SetCursorPos((x,y)) win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN,x,y,0,0) win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP,x,y,0,0) arduino = serial.Serial('COM8',timeout=.1,baudrate=9600) data = str(arduino.readline()) x,y,z = data.split(',') print (x); print (y); print (z); //I am getting a new error now that the COM8 access port is denying me access 
Huge fan of this course: https://work.caltech.edu/telecourse.html . Doesn't really use any particular programming language and is pretty concept/math heavy, but some of the exercises require some sort of programing knowledge. 
It would be courteous to acknowledge a site's robot.txt
I took the {Machine learning course](https://www.coursera.org/learn/machine-learning) of [Andrew Ng](https://www.coursera.org/instructor/andrewng) about two years ago and this was really great experience. I think the next will start at 13th of November. When I took this course it costs nothing, there was a time schedule when to have to take the lessons, quizzes and programming exercises, there was a forum where you could pose and answer questions and where you could contact tutors. The programming language is Matlab (you get a license to use it for the course)or Octave, which you will learn from the scratch. Some people criticized this at the beginning, because R and Python seem to be more popular at the moment. But the purpose of the course is to introduce the concepts of Machine Learning and for this these languages were appropriate. I am not sure if it is exactly the same course that I took because they announced to change the course, not the content but the way it is organized.
Continuing to work on my enhanced [typing/types](https://github.com/contains-io/typingplus) library. I've added a [base class](https://github.com/dangle/typingplus/blob/typedobj/typingplus/types.py#L722) that will try to coerce to the annotated type or throw a TypeError, as well as adding generated "default" __init__ and __repr__ methods. &gt;&gt;&gt; from typingplus.types import CastObject &gt;&gt;&gt; class Point(CastObject): ... x: int ... y: int ... ... &gt;&gt;&gt; p = Point(0, 0) &gt;&gt;&gt; p.x 0 &gt;&gt;&gt; p.x = '5' &gt;&gt;&gt; p.x 5 &gt;&gt;&gt; p.x = 'five' Traceback (most recent call last): ... TypeError: Cannot convert 'five' to int. 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [dangle/typingplus/.../**types.py#L722** (typedobj → b6756a5)](https://github.com/dangle/typingplus/blob/b6756a5ddcc19bd2bb83cfe433a9379fcf354b79/typingplus/types.py#L722) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
Go to kaggle.com and browse the open competitions. Find one that interests you and that you may have some domain knowledge in. Try not to pick the most complex one on the board where you're dealing with TBs of data on the cloud as a first project to tackle. Those are for the pros. From there join the competition and take a look in the forums and kernels. there people are discussing their real algorithm solutions, data prepping, and other relevant data science stuff. Copy their code. Tweak it. Create and ensemble between different provided models. I believe this is the best way to learn in the beginning. I was away from data science for a while, building applications in Python, but recently came back and this is what I'm doing. Simply picking a competition and running with it...
I'm fully aware that using `deque` and `list` are both faster than any Python code I can write up. I was just curious to see whether recursion or looping was better in a DLL. This question struck me especially with tree data structures. I suppose I should've made it clearer that point of the blog post was _not_ to propose an alternative to `list`, but about the comparison of two ways of DLL I was taught.
Use python. Perform sentiment analysis with python Pandas. Use .str.split() And use .value_count() then see what words were used most and so on. Also use Jupyter notebook. Also I think this is a great project to learn python. Its low risk as well as a out side the box kind of project. You will use spreadsheets all the time. Use pandas for this. Don’t know pandas or python look up Brandon Rhodes tutorial for pandas on youtube and if u have $35 to spare buy Wes Mckinney’s 2nd Edition of Data Analysis with Python Pandas. 
&gt; &gt; FOSS was successful because of its sheer efficiency ... from users' perspective. The word "efficient" fits in other place. Of course, FOSS is the least efficient software development model, but the act of sharing significantly reduced the cost of software development.
It’s too bad. 
I'm currently running a simple NN with Keras on my local machine, so I decided to do a test run on Colaboratory. Data is ~18000 samples with 300 features, model is Embedding -&gt; GlobalAveragePooling1D -&gt; Dense Softmax. On my local machine (8 core i7 with 16GB RAM) a single epoch runs for 61 seconds. On Colaboratory a single epoch takes 2 minutes 45. Which I guess isn't bad if you don't have any other options. Have to agree with other commenters that the data uploading is not a pleasant experience. What will be interesting to see is if they allow you to connect your notebooks to GCE GPU or TPU instances to speed up your model training.
I second this. Lot's of great stuff to be found on Kaggle. The two classic ML learning data sets are both represented there: Titanic: [https://www.kaggle.com/c/titanic](https://www.kaggle.com/c/titanic) Iris: [https://www.kaggle.com/uciml/iris](https://www.kaggle.com/uciml/iris) 
It is a great course, but can be quite daunting. I'm currently going through his Deep Learning Specialisation and you hand code the solutions first before he introduces the various frameworks. The benefit of going this route is that you properly understand what the algorithms are doing, rather than blindly plugging values into a function to see what happens. The Machine Learning course still uses Matlab and Octave, but the DL course uses Python.
I know you ask for an online course, but I still want to recommend you a book (books are great!): "Hands-On Machine Learning with Scikit-Learn and Tensorflow" by Aurélien Géron. It teaches you the basic concepts and the libraries you can use. Clearly my favorite practical ressource if you plan to apply machine learning in Python!
fast.ai looks to be focussed on deep learning, the current flavour of the month. If you're starting out you'd be far better served getting to grips with things like linear and logistic regression, support vector machines and decision trees, as well as all of the tools that you need for preparing and validating your data (encoding, cross-validation, grid search etc) before jumping in to deep learning. I quite enjoyed the Applied Data Science with Python specialisation from Coursera - it will give you a good grounding in data, visualisation, machine learning and network analysis.
I haven't taken this course so I can't really comment, but starting with Deep Learning sounds a bit overwhelming to me. I would probably not recommend to skip all the shallow learning stuff if someone is new to machine learning.
I haven't taken this course so I can't really comment, but starting with Deep Learning sounds a bit overwhelming to me. I would probably not recommend to skip all the shallow learning stuff if someone is new to machine learning.
Great idea but a few gripes that I hope Google eventually address * The sympy modules is available but latex formatting is not even though I invoked "init_printing(use_latex=True)". * All help requests go to StackOverflow which is a hideous platform based around Jeff Atwood's predilection to social engineering and generally being obstructive to people asking questions in a straightforward unpoliticised manner. If they sort out those issues I think it could be a great success.
Watch out, some of these examples are not formatted correctly and so don't run. For example: for i in range(3): transposed_row = [] for row in matrix: transposed_row.append(row[i]) transposed.append(transposed_row) Should be: for i in range(3): transposed_row = [] for row in matrix: transposed_row.append(row[i]) transposed.append(transposed_row)
I think you made good article. I was just curious how your solution compares to standard implementation.
You may be interested in this article: https://medium.freecodecamp.org/every-single-machine-learning-course-on-the-internet-ranked-by-your-reviews-3c4a7b8026c0 I'm thinking about following fast.ai as well as buying Kirill's courses on Udemy.
i'm doing some scripts for automating torrent downloads from different websites
Ng's ML coursera course is by far the best one I've seen in terms of getting the fundamentals down. Personally what I did was watch the first part of those lectures, take detailed notes and not bother with the activities (because fuck matlab/octave). I then subscribed to /r/machinelearning and just read papers and thought about them a lot for a year or so. Look up math you don't understand when you run into it (quora, stackexchange, other blogs all have good intuitive explanations that don't require a course or two in real analysis to understand). This path probably worked for me because I had a reasonable starting background in math and a solid understanding of Python that let me jump fairly quickly into implementing things once I understood what was happening. Most important thing is that it will take time. You're going to misunderstand stuff along the way until you finally work out what's happening. But one of the cool things about this field is that it's all happening, right now, and pretty much all in the open.
I have spent many quarter-of-hours fucking around with nested list comprehensions to get them doing what I want before realizing my code ends up looking like unreadable crap anyway and just re-writing it as for element in parent: for subelement in element:
If it's a pointer created in C runtime by malloc, you need to clear it in C. If it's a `PyObject*` even if created in C, it will clean its own memory thanks to reference counting.
Small tip: use two empty lines on reddit to properly format your posts :) Regarding your question, as strings! You cannot use .split() on integers. Access port denied probably means the port is currently occupied by some other process. It happened to me when I tried running my script and another instance was already running.
Vim? 
Are vi and/or nano not options? Assuming it is a Linux based AMI. 
Thanks, I edited the question . Currently using vim, but just curious if I can using an editor like komodo from my local machine that is linked to the server - as I much prefer to work in komodo. 
(Machine Learning is Fun!)[https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471] is also quite good
Are you on Linux? Does the server support ssh? In that case you can simply mount the server on your local machine and edit with whatever editor you use locally.
You can rewrite every double for-loop with itertools.product import itertools a = [1, 2, 3] b = ['a', 'b', 'c'] for x, y in itertools.product(a, b): print(x, y) I believe it's faster too.
https://github.com/0Hughman0/xl_link Working on my overly specific package xl_link, which aims to be the 'missing link' between pandas DataFrames and Excel spreadsheets, after the frame has been written to excel. In short it returns an `XLMap` object when you call `to_excel`, and you can apply pandas indexing i.e. `__getitem__, loc etc.` to the `XLMap`, but instead of returning the frame, series or scalar, it will return the location of that frame, series or scalar within the spreadsheet. The aim is to make things like creating excel charts based on DataFrames a more enjoyable experience. It's currently in a useable/ mostly tested stage, but still missing some features. Please give it a go, and let me know what you find!
I was not aware of this option, this is epic! Thank you so much.
LPT: Anytime you have a case where you feel like your iteration is a bit funky and crufty you need to have a scroll through the itertools docs and there will be something useful.
You can use sshfs to to mount the remote server and in this way you can use the editor you prefer. https://www.digitalocean.com/community/tutorials/how-to-use-sshfs-to-mount-remote-file-systems-over-ssh
No problem. Btw, some desktop environments have quick ways to connect directly from the GUI so that you don't have to fiddle around with sshfs yourself. At least this is true for Gnome (and Ubuntu's unity), and I would assume at least KDE have this option as well.
Check out Emacs/tramp
I think you should start doing small scripts that make your life easier. Doing that you will solve a problem and invest time on improve your code skills with python. You can read something about webscraping and things like that, you know, to automate boring tasks
The syntax for list comprehensions in Python was directly taken from regular `for` loops, with the "producer" (append) moved outside, and multiple conditionals are read from nest to right *and can be interspersed with producers*: r = [] for nested in parent: if cond(nested): for element in nested: if cond(element): r.append(element) becomes r = [element for nested in parent if cond(nested) for element in nested if cond(element) ]
&gt; Now that you understand the workings of this mechanism, you're ready to also tackle dictionary, set, string, ... comprehensions! Python does not have string comprehensions. It does however have *generator* comprehensions (lazy comprehensions, whereas list, dict and set comprehensions are eager).
Is this actually a thing people use? I see it mentioned here and there but it always feels a bit magical.
be careful with this. Charles here warns you with "Things that might not work well:" but I want to double the warning: gevent is non blocking for IO only. Your task queue will execute CPU heavy block code on another process, and even on another core if available. It's not the same thing. If you generate a big pdf in your gevent stuff, you'll block your current process for good. In the article, Charles uses it to send an email, which is IO, and so it works well for him.
Ok ! I have a simple solution in mind but I can't assure you that it is the most optimized one. But anyway, no need for early optimization :) def lexicographic_concatenation(first_string, second_string) # sorted take a sequence (str, list, tuple) and returns a sorted list of its elements sorted_first_string= sorted(first_string) sorted_second_string = sorted(second_string) # the * operator (splat operator) is a shortcut to unpack a list concatenation = sortted([*sorted_first_string, *_sorted_second_string]) # The join method concatenate a list of string with the seperation character provided (in this case, it is an empty string) return '''.join(concatenation) If you have any question, do not hesitate :)
can you share how you put this together? very cool idea. i'm trying to build something that will upload my files to a server and build an RSS file in podcast format. 
I agree. I admit I toyed with sleeping to yield early on, but it doesn't scale at all. Much better to use gevent's threadpool, though I prefer to use [gipc](https://gehrcke.de/gipc/) as it also avoids contention with the GIL. It's worth pointing out that this issue is not unique to gevent. All async frameworks, including twisted and asyncio have the same issue.
Stick it (you code) in and pray to God
Yes. Once you understand how it works it's really quite intuitive.
You mean Google Drive? That won't really work for what you're trying to do - it doesn't give you direct download links you can build into your feed.
no, i mean google cloud. it's the google equivalent of AWS
Then you should be able to just run a web app that serves an up to date RSS feed, no?
Also, this is Python we're talking about. Any performance gains you might have hoped for from implementing a particular data structure will be far outweighed by the overhead of doing it in Python (since you can only express your implementation using Python's objects and data structures). If you need high-performance data structures, implement them in another language and wrap a Python interface around them. This is why numpy is so hard to build manually, for example; it's a Python interface wrapped around a bunch of C and Fortran.
Yes. If you use twisted and asyncio, you should use deferToThread() and run_in_executor() respectively for blocking code. An alternative is to use a system like crossbar.io to have process dedicated to blocking code accessible from anywhere, an await away.
You can either a) mount the remote filesystem locally, and then use your local editor, or you can b) work on the remote system directly, using an editor on the remote. For a TUI editor (vi, vim, emacs, nano), that's all you need to do. For something like Komodo you'd need to forward your remote x session to the local machine to allow you to interact with the GUI; this may introduce substantial lag. A isn't always possible, and neither is x session forwarding in B, which is part of the reason why Vim/Emacs still have so many proponents.
Udacity have loads of very good machine learning related courses, and most of the material is available for free: https://www.udacity.com/courses/machine-learning
Great , thanks for the info. 
Thanks very much for the info , ill look into this.
Search pypi, there are at least two libraries for that purpose.
why do you use requests and beautiful soup to scrape comments instead of using PRAW?
Also, for Python3, line #27 should be urllib.request.urlretrieve, instead of https://github.com/weavermonkey/xkcd-scraper/blob/b045df5794185ed67bbb96b351686d909f4c3d90/scrape_xkcd.py#L27
Honest question: did you try searching Google before posting here? You could have answered your question yourself in the time it took you to post it. I’m not sure of your expertise/proficiency, but I always recommend folks spend at least 15 minutes struggling with a problem before asking for help. That struggle is how you learn and grow as an engineer. 
Pycharm &gt; everything else
Nielsen's book is pretty good
The article tries to make it sound like list comprehensions replace all the function operators (map, filter, reduce) which isn't really true. Map and filter, sure, but the example for reduce was to enclose a list comprehension in sum. Obviously, if you produce a list and have a function that reduces that list this works, but it's specific to that case. That is to say, sum is just a special case of reduce. Reduce is general and allows one to reduce any list. There's a reason that reduce is included in functools for python 3.
Outdated book. https://www.amazon.com/Two-Scoops-Django-1-11-Practices/dp/0692915729/ref=pd_cp_14_1?_encoding=UTF8&amp;pd_rd_i=0692915729&amp;pd_rd_r=S18CQF9VSRY6124MWBHR&amp;pd_rd_w=UtYGM&amp;pd_rd_wg=jSR4G&amp;psc=1&amp;refRID=S18CQF9VSRY6124MWBHR
Don't use `O` as a variable name, it's too similar to `0`. Also, variable names should not be upper case, and ideally should be much more informative. Given IDEs will save you most of the effort of retyping variable names, there's really no need to save a few bytes with shorter names, if it costs comprehension.
&gt; healthy goto I don't agree a goto that jumps by to a **line number** can be considered a healthy goto.
How about an app that gathers gyroscope, accelerometer, and pixel data in order to tell you the weight of a mass placed on the screen. There are apps that do this but they aren't flashy and don't use ML and pixel data
This reddit is for python news and not technical assistance. I think that if you truly believe that it is a technical issue due to mistakes within the package you should open an issue at the relevant github.
Well that's not true, you can't write: for row in matrix: for elem in row: ... Which is equivalent to what you were replying to. 
Is using the remote host/deployment option in IntelliJ IDEs(PyCharm) not an option? I add a remote 'SFTP' server with my credentials and set it to automatically upload the file on explicit saves.
You are absolutely right. I did not realise that the 2nd loop used the first loop's element. itertools.chain.from_iterable(matrix) This specific method is probably better when the list grows bigger to avoid Python's maximum amount of arguments you can pass to a method.
Do you guys know of some resources less focused on the coding and more on the theory for someone from the hard sciences
&gt; ORM layer for your objects You need to look into the meaning of ORM because this does not do *'Object-relational mapping'*. This is a usable API to work with collections of objects or something. There is nothing relational or mapping about it.
Learning Tensorflow right now, and I've seen quite a few tutorials over the past couple weeks. Wasn't expecting much, but this tutorial is among the best I've seen. 
Same way a machine learns, try until you get the outputs you want.
Pycharm +xrdp works for me
Docker? Build a container on a server with a connection, then move it to the production environment and spin everything up there.
Exactly! This is why I'm wondering why people are still implementing linked lists in Python. Python is already using a lot of them under the hood, whether you like it or not, why add more?
It says I cannot register/connect?
i'm sure there are libraries out there. I want to know what people actually **use**. It's no use building a program around a library that is out of date/not maintained.
&gt; Then you should be able to just run a web app that serves an up to date RSS what libraries would you use for that? 
&gt; st question: did you try searching Google before posting here? You could have answered your question yourself in the time it took you to post it. I’m not sure of your expertise/proficiency, but I always recommend folks spend at least 15 minutes struggling with a problem before asking for help. That struggle is how you learn and grow as an engineer. why are you being a douche? if you don't have something constructive to contribute then jog on, m8. 
A web framework, probably something simple like Flask, and ElementTree.
3. There are lots of resources for it now, and most third party libraries support it.
thanks. Flask might work. taking a look at [this](http://flask.pocoo.org/snippets/10/)
Go for 3. There’s no shortage of documentation or library support.
Here is how I did it, if it helps. https://github.com/Siecje/htmd/blob/226cc231d52a53d1b9b916de216224872bb6e07f/htmd/site.py#L88 
OK. I feel your pain about wanting things to just work, but I cannot personally patch and fix everything. Life is too short and my TODO list too long.
I am genuinely curious. Why Komodo? And is it the IDE or the Lite version?
It's too late. There are too many partially failed attempts. It's same situation when there are 4 standards and someone says "this is a mess, lets fix it with new standard!" Now you just have 5 standards when people projects, legacy systems following different ones.
Weird how we don't often ask, "Why BMW? Why not Mercedes?" except when it's an IDE ...
thanks! that's quite helpful!
I've been working on trading bot. One of the things I find most useful in stock knowledge is the community. So what I did was built a sentiment CNN (sort-of), what it really does is decide whether a comment or phrase is telling someone to buy/sell a stock. It then parses the top stock subreddit and twitter accounts, gathering all the tickers and sentiments for each ticker, then displays which stocks are trending and what you should do with that stock. The only problem I'm having is the execution time. It takes about 7 minutes and I can't seem to figure out how to thread Keras models....
udacity has some great courses. some of them, like [this one](https://www.udacity.com/course/programming-foundations-with-python--ud036) are free. I don't know of many in-person training programs that I would trust, outside of a university setting. That said, if online learning really doesn't work for you then consider an adult learning course at a nearby [uni](http://technology.gsu.edu/technology-services/it-services/training-and-learning-resources/technology-training-workshops/python-scripting-intro-to-programming/)
Absolutely 3, like no question whatsoever.
Today I've finished first working release of a simple client for [Polish National Bank's Web API](http://api.nbp.pl/en.html) and published it on [PyPI](https://pypi.org/project/NBPy/). I doubt anyone outside of Poland might find any use of it, but hey, who knows.
This is really interesting. I only recently started learning Python and i had the idea to build something very similar to this. When i'm good enough that is.
Shit man, I didn't (and still don't) think I was good enough. You just gotta tackle one step at a time, and have multiple tabs with StackOverflow open. 
haha yeah, i got it in my head that i'd make my way through several online courses before even beginning. I do that with everything. "gotta learn everything in the world before i even begin" But in reality, everything i'm good at, i got good at by doing things and making mistakes. You have inspired me, sir!
Do you have any recommendations?
If there was a "best" then everyone would use it and there would only be one. There is only "best for" ... which means you need to tell us what you want from a GUI library before we can tell you what's best for you. in a nutshell: * Tkinter: best for super fast development and if you don't want to require your windows users to install extra libraries * pyGTK / PyGObject: best for native looking gnome linux programs. Uses Glade graphical design. * PyQT/ PySide: best for highly custom very pretty interfaces and automatic event linking. Looks native on any OS. You can use QTDesigner to create GUIs. * wxPython: Alternative to tkinter for fast and easy interfaces. Uses as many system widgets as possible. Has a GTK-like Glade. Recently available for python3! * Kivy: best for multi-touch and small screens - tablets and phones. * Remi: best for programs that can be accessed via a browser locally or remotely * Bokah: best for interactive data display in a browser. You may also want to ask yourself if your program is better suited as a web app, and use one of the many web frameworks for python. 
I'm mostly concerned with two things. First, how easy it is to use since I am new to GUI design. Second is how easily I can give my application to a coworker. I would like them to be able to install it like any other application, which I assume is possible but I'm not actually 100% sure about that. As for a webapp, other than being a website, is there an advantage to this over an app? I don't have a server that could easily host a site which is why I am looking into apps. 
This one, apparently.
I highly recommend [PyCharm](https://blog.jetbrains.com/pycharm/2015/03/feature-spotlight-python-remote-development-with-pycharm/)'s remote project feature. You may want/need to set up [ssh forwarding](https://developer.github.com/v3/guides/using-ssh-agent-forwarding/) on your remote server as well.
Qt5 and Qt4 are different versions of the Qt application framework. There are python bindings for both versions of the libraries via PyQt4 and PyQt5 as well as the Pysides project. Functionally the libraries are mostly the same, however, there are a few changes to the API from v4 to v5 that are NOT backwards compatible. These include in a not exhaustive list: * moving the widgets from QtGui to QtWidgets * changing the way you connect singals/slots for event handling * changing the default output for a number of the standard dialogs. For example a QFileDialog.getOpenFileName dialog will now return a tuple with two items, first item is the file name as a string, second item was the active filter for file type at the time of selecting the file. Contrasting this with the old method that just returned a string. That's what I remember off the top of my head, I'm sure there's a few more small changes between Qt4 and Qt5 - they can be found [here] (http://pyqt.sourceforge.net/Docs/PyQt5/pyqt4_differences.html) I recommend just learning Qt5 if you are going to start. While many of the tutorials you find are for Qt4, there's little to no reason to learn an old version of the library unless you are using a legacy system that does not support Qt5 (idk if that even exists).
If you are new to gui design, you should still be able to do simple UIs without a graphical tool. Tk, for example, has grid and pack geometry managers that can auto-arrange stuff. I've used Qt and Tk and I can confirm they can both install from pip so distribution shouldn't be too hard. There are tools though, like Pyinstaller, that can build single file executable installers. Webapp would allow you to use webdev front end skills and there's a lot of them around. It's also very portable and easy to "deploy". You can cost it locally but that's a bit sad - you might as well use Electron then :-)
My choise is Visual Studio Code with the Remote VSCode addon. Pro: works on MacOS, Windows and Linux
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Learning tensorflow with knowledge about Neural networks or learning about Neural networks with tensorflow?
Loved [this one](https://github.com/aymericdamien/TensorFlow-Examples) as well.
Unless blender doesnt support 3, Just go for python 3. The ecosystem as a whole has mostly moved to 3
I've been in this situation before, and I chose to redistribute with a new version. It didn't really do anything for me.
&gt; First, how easy it is to use since I am new to GUI design. In that case you want tkinter. It's the easiest to learn and use. You will need to shift your thinking into an event-driven programming and that will be hard, but that's the case no matter what GUI you use. &gt; Second is how easily I can give my application to a coworker. If your coworker installs python using the installer from python.org it comes with tkinter. So you can just give them your .py file. You can also look into freezing or packaging your code so they do not need to install python first, but then you will need to be sure you are both using the same OS. &gt; other than being a website, is there an advantage to this over an app? No, but that's a pretty big advantage in some cases. Depends on what your program does. One huge advantage: your coworkers don't have to install anything and your app works on nearly any platform. 
Yep
Yes, it should be no problem. They install to different directories by default. Just keep an eye on which one you're using, or you may get some confusing errors.
OK, thanks!
Any reason you don't want to do this with Pillow? from PIL import Image old_image = Image.open("foo.png") bigger_image = old_image.resize((512,512)) bigger_image.save("foo.png")
This is really cool. If you make a video of the setup I would be interested in seeing it. 
That's fine, it can be handled easily with e.g. 'd:\stuff\\{case_number}\\{directory}\\{evidencenumber}\file.blah'.format(case_number=case_num, directory='findings', evidence_number=evidence_num) Where case_num and evidence_num are variables with the values you want.
The latter. I've implemented normal ML algorithms in the past, but I've never learned neural networks. Particularly interested in CNNs. So I'm learning Tensorflow (and Keras) together with neural networks in general.
**Paid offering to rework IBridgePy Code.** I've been developing an algorithmic trading bot which can as of now, do everything but trade. If you are familiar with IBridgePy, you'll know that it uses a looping Handle_data function to trade. I hate it. I want you to develop code I can import that will allow me to place an order with a single line of code. Apparently outdated versions of IBridgePy often do not function well. Ideally your code would interface with the current release, but still be applicable with future iterations- that is to say, I'm not looking for you to rewrite the entire module, but rather to generate a module that buffers IBridgePy from my code. DM me for more information.
I have an imgur gallery here: https://imgur.com/a/YMUe1 And lots of videos on youtube channel. https://www.youtube.com/watch?v=gKp7m0gK6zQ 
I like that idea, it seems simple enough, but it also seems like it could be challenging. Thanks!!
Might want to run through the codeacademy.com intro to python as well. 
Fantastic release notes 
One things to add - I had tried Tensorflow-gpu a few months ago on a Windows host, and after fighting with it for ages, went with a Docker setup with Ubuntu 16.04 as the client system instead. This had its own limitations, but getting tensorflow, scipy, numpy, etc working on Windows was just a bear. Just set everything up again this week, and the world is now a different place! If you're on a Windows host with a supported Nvidia GPU, you have a number of options, all which start with: "install CUDA drivers and CudNN files". From there, the simplest option is to install the free Visual Studio 2017 Community, and include Python during setup. Once installed, locate the Python Environments tab, and add scipy, numpy, pandas, and tensorflow-gpu, et al just by clicking the checkboxes next to each. It installs them into an Anaconda environment using pip.
My reasoning was that if I left them built from an older version of Python I thought their shelf life wouldn't be as good. Seeing as how no one has commented saying this I guess it's not too much of a concern. 
Python 3 is the right way. Documentation support for Python 3 is better, not worse.
no reason at all except I was using the pypl functions in matplotlib so more elegant to just use the one package. Which is a lousy reason.
Thank you! :)
See: http://docs.tweepy.org/en/v3.5.0/api.html#help-methods Looks like `rpp` is what you are looking for (up to 100). Also, you can get next next pages
Several people have suggested that library support for Python 3 is pretty good. As evidence of that, http://py3readiness.org/ lists 360 popular packages, of which 345 work on Python 3. Python 2 will probably stick around in some companies and specific niches for years. But the Python community in general is picking up Python 3, and some projects are preparing to drop Python 2 support soon. So I'd definitely recommend teaching new programmers Python 3.
I’m afraid I have no advice to give, but I’m literally on my way home from my Latin lesson and the CLTK looks absolutely awesome. (In the past I’ve made a decent hash of porting Whitaker’s Words into Python+sqlite, and this looks really useful.) Thanks!
Great advice, thank you!
Thanks for your thanks anyway :D
Looking in to the delimiter option. https://docs.python.org/3/library/csv.html
Try resetting the Kernel. Also you may find more helpful info at r/learnpython 
Have you considered using Pandas? Operate on everything as a table/dataframe. Makes life so much easier after you get the syntax down. import pandas as pd origDF = pd.read_csv("C:\file.dat") newDF = origDF[origDF['yourColumn'].str.startswith("AGC")] #&lt;-- Subset the rows that startwith print newDF.head() # &lt;-- Print the results newDF.to_csv("C:\outputFile.dat") #&lt;-- Output the filtered table Hope this helps?
```python from random import choice print(''.join(choice(('\\', '/')) for i in range 10000))) ```
In what way would the shelf life of the application be affected? A package frozen in 2003 should still work in 2013, the user interface and underlying libraries may not be optimal for the 2013 ecosystem, but it should still just work fine. Refreezing because you want to ship newer versions of your dependencies, sure, but refreezing so the python version is newer? Users won't notice a difference. The only situation I can imagine is if there's a major security problem with your version of python or something among those lines.
[Composing Programs](http://composingprograms.com) (the SICP successor) is great resource for yourself as well as students, it's python3.
Teach the one you know best. If you can choose, go for 3. Blender works with both and VFX reference platform claims their intention is to switch in 2019.
Maybe I should have included more information in the submitted title; SpaCy is a Python library for natural language processing. It was created in part to supplant what the author believes to be the outdated/legacy performance and API of NLTK, and it claims to be the fastest in class. Docs: https://spacy.io/ Didn't find much discussion about past releases of SpaCy in r/python: https://www.reddit.com/r/Python/search?q=spacy&amp;restrict_sr=on However, it has made the front page a few times on HN over the years: https://hn.algolia.com/?query=spacy&amp;sort=byPopularity&amp;prefix&amp;page=0&amp;dateRange=all&amp;type=story 
Can't you cross compile from a more powerful PC to the arm architecture?
There's also a reason it's relegated to functools and that Guido wanted to drop it altogether. Almost every real-world use of reduce is covered by the sum, min, max, all, and any functions. 
/r/learnpython is a more appropriate forum for this question. Good luck!
&gt; Now, you might be thinking “Why didn’t you just cross-compile?”
Yes! Can't believe I forgot to include a one liner of the code in Python for the terminal. Mind if I include your one liner in the post, with attribution?
proof-reading (python 3): from random import choice; print(''.join(choice(('\\', '/')) for i in range(10000))) 
" Unfortunately, writing 10 PRINT in Python and Pygame isn’t really doable in one line. " Yes it is. We can write any program in one line of python.
I have took a look, Rotten Tomatoes uses a private API that outputs JSON: https://www.rottentomatoes.com/api/private/v2.0/search/?limit=2&amp;q=star wars Be gentle and don't hammer it. You don't require BeautifulSoup, only Requests.
Hey! Seconding everyone else's suggestion to go with 3. I just wrote a book teaching Python 3 programming with Pygame, and it's mostly targeted at teenagers. PM me for a free copy if you like.
Thank you :) Although I know there is a way to make a one liner without `random.choice` but clever `chr(math_here)` but I felt lazy, lol. Interesting art this random `\ and /` !
Author here! You're totally right! That line is a bit vague and unclear, I meant to say it would be difficult to read and write in Pygame. I'll update the article with a bit better verbiage. Thanks!
Just for fun, I'm doing it rn. 
 while"p"in globals()or(map(globals().__setitem__,"baltox",map(__import__,[ "pygame","random"])+[globals().__setitem__,lambda:(b.init(),map(l,"d_",(b. display,(800,800))),l("w",d.set_mode(_))),lambda:(l("u",b.key.get_pressed( )),u[32]and x()or u[113]and exit(),[e.type==12 and exit()for e in b.event. get()]),lambda:(l("z",20),[(l("v",a.random()&gt;0.5),b.draw.line(w,(255,)*3,( x, y+v*z),(x+z,y+z*(not v))))for x in range(0,_[0], z)for y in range(0, _[ 1], z)],b.display.flip())]),t()):o() 
 1. Why use a csv reader for what appears to be fixed width fields? 2. I'd use `with open(r'C:\file.dat') as foo:`. Note the use of the raw string literal. 3. I'd write `if row.startswith('AGC'):` 4. I do not believe that the code will run as given as `row` won't have an attribute `line_no`. Presumably there is a call to `enumerate` missing?
This is incredible!
Less documentation? Only if you really care about third-party docs that much. The *normative* docs are just as complete, and the languages are mostly the same. While it's confusing, people still need to be taught to look things up on their own, or cross-reference.
Further to other answers anything that uses `for x in range(y)` is a code smell in Python. There is almost certainly a better way of doing things.
The situation for 3 is much better than even a year ago, even if, as a lot of people, i still have python2 code to care about, i wouldn't advise anybody *starting now* to take the detour anymore.
Learn OS design. Figure out what is the _real_ problem. You really don't want to run an editor remotely, since it could lag. You just want to sync the file.
Seriously? Have you ever actually been somewhere with bad bandwidth? How about a small town in a vast country?
You should really keep things coherent and orthogonal. That "feature" should have never made it into the editor. Fix the real problem, that people don't know how to mount remote FS.
That's a great world to live in where all scenarios allow you to mount a remote file system with little difficulty. But not everyone lives there and the various methods that InteilliJ supports for remote hosts helps to address that. The 'real problem' would be the fact that it's not as easy as just arbitrarily mounting a remote file system.
Unfortunate name. Natural language processing? All words except "no".
If I could upvote you more than once, I would.
If you are using `pip` then HTTPS has been the default since 2013: https://pip.pypa.io/en/stable/news/
Python 3 is not the future, it's the present. It's almost 10 years old!
&gt; TypeError: input expected at most 1 arguments, got ∞ 
Learn statistics first
I currently volunteer @ a high school teaching python. I teach 3, simply because these are kids and they deserve the newest. By the time they could use it in the work force, 2.7 will be deprecated. Plus I doubt you or I will have the chance to teach them enough that they would see the differences between the two. 7 periods, 45 min classes. You get it. You won't run out of thing to teach them in 3. If you have that one kid that keeps up, show him AI with python. That should fry the brain.lol. That said, PM me if you like the Intro to Python 3 course I provide them. 
women, amirite lads?
What always gets me is the "expected at least 2 arguments, got 4." I'm not sure if you can still get this, but in older versions of python you could get that if you had more keyword arguments than required positional arguments you could get weird errors like that. 
I got this error (expected 2, got 1) a lot while trying to use Tkinter before i fully understood lambda functions.
don't call me lad, comrade 
Yeah, women are the worst.
Since I take my university lecture notes in LaTeX I decided to make a flash card script. Since I dont want to type long LaTeX commands I defined quite a lot of short ones, taking notes is easy enough when I use those. But I wanted something better for learning the material. I tried Anki, a flashcard app that supports LaTeX, but it doesn't do all the things that I want. Havent really programmed in Python before but there were some fun problems :p it works well enough, and I only need to indicate "this is a question/answer" in my LaTeX files and then displays them in pygame as a flashcard app. But boy was it difficult to figure out how to display a string that contains my own defined commands, enumerated LaTeX lists and ordinary sentences and have it displayed properly using matplotlib. Yesterday it worked for the first time exactly how I wanted it after working on it for a week. Though I still need to add some features and then it really can do all that I want it to do.
Hi - great job! Any chance you could put this in a jupyter notebook &amp; upload to https://notebooks.azure.com ? It has py2, py3, tf, etc. already setup. That way ppl can Clone &amp; run the code. Thanks!
Huh, why would you guess that? Its default tokenizer uses classifications such as `IS_STOP`, `IS_PUNCT`, etc. https://spacy.io/usage/linguistic-features#adding-patterns-attributes Custom stop word dictionaries can be added ad-hoc or preconfigured and cached: https://github.com/explosion/spaCy/issues/226
Don't call me comrade, mate.
Don't call me mate, cobber.
I've been working on a terminal client to live stream new reddit comments https://github.com/claytonblythe/redditstream-cli [Demo](https://asciinema.org/a/JZhJWeNvq1bTI8tG4VbaYPfJS?autoplay=1)
r/programmerhumor
Are we just being sexist programmer bros?
TIL it's sexist to be straight
&gt; RecursionError: maximum recursion depth exceeded
This post is basically: "LOL, women, amirite?" in a community that is male dominated. Then we wonder why there's no women in the community.
Is it? I genuinely can't tell. 
It's mostly that it uses "girlfriend". Had it simply used "partner" or a similarly gender neutral term, there would be no potential problem.
I already did.
Don't call me cobber, guvnah.
 while can_upvote: upvote()
Automate backups and restores for on-prem software, with validation, versioning, etc.
Why did you assume OP is a man?
Scipy for this? Do you also slice your bagels with a chainsaw?
I didn’t get it, but I upvoted for you :)
The joke works with boyfriend too. OP just happens to be attracted to women. It's a joke. You might criticize posting jokes to this sub but trying to get offended by it is absurd.
They were making a joke about the recent Kevin Spacey allegations. With that said, I love SpaCy! I have used it in numerous projects and think it's wonderful. It's very straightforward and gives me what I want fast. 
Which is fucking stupid. If the guy has a girlfriend, let him call her his girlfriend. 
I didn't. I used 'we' as a pronoun, in reference to the r/python community. I made an assumption that the demographics that are upvoting OP are predominantly 'bros'. 
Don't call me cobber, 同志.
Don't you dare offend shame me!
Yeah. Dunno. I dont speak for every girl ever, or even every girl programmer ever, but it seems silly to needlessly police the words girlfriend/boyfriend or sub them out for the gender neutral. I thought it was funny, having been in that situation with my boyfriend. Like it's pretty easy for a human to relate to a situation in which a loved one brings up an argument more times than you expected them to. But its okay to specify which of your loved ones this is, on the assumption that your reader will be able to emphasize enough that they can sub out the appropriate words as needed. Thats what empathy and storytelling are. Feminism has more important thinga to worry about smh. 
Ironically... YOUR assumption could be considered sexist...
I'm not offended. However I do think it's a predictable and overdone joke. It's also based on very tired stereotypes of browbeaten men and naggy women, so your excuse doesn't really fly.
Can it connect nicely to data warehouses like Redshift?
It could, but it would be backed up with demographic data. I can't find demographic data explicitly for r/python - I'm not sure it exists - but there's [fairly recent studies of github demographics](http://blog.revolutionanalytics.com/2016/06/programmers-gender.html) that put the percentage of top python programmers to be female at a grand 2%. Now that survey is biased by selecting 'top programmers' and it would tend to be weighted to experienced programmers, rather than newcomers to the field. Even if we were to take aggressively optimistic numbers and assume 10% of entry level python programmers are female, we still have way more men than women. And if even a tenth of those men are 'brogrammers', then it is quite possible that they outnumber all women in r/python. Hence the problem. I just think that jokes like the one OP made serve to extend the gatekeeping mentality: programming is for boys. Our treehouse even has a No Girls Allowed sign on it.
The only predictable and overdone thing is your reaction. &gt; women, amirite lads? [You ARE offended](https://www.youtube.com/watch?v=ceS_jkKjIgo) Otherwise you wouldn't talk about excuses. Nobody needs excuses because they can do whatever they want. You're not the moral authority. 
Actually, the only one doing "gatekeeping" here is you and everyone who is offended on behalf of women. Women code. Thank you very much. They don't need your protection. They don't need to be treated like special people who can't take a joke. They are quite capable of handling things like everyone else. Stop the paternalistic crap. 
If anybody is acting offended around here, it's you, my dude.
&gt; women, amirite lads? &gt; predictable and overdone &gt; stereotypes of browbeaten men and naggy women, so your excuse doesn't really fly. Whatever you say, bro. 
Did you just assume OPs sexuality?
Did you just assume OPs sexuality?
Sure. Did you just press reply twice? :P
Thanks that clears it up. I was just worried, (perhaps superstitiously,) that the executables would stop working after a while due to being built with an "older" version of Python. I'm not worried. 
My favorite will always be "expected at least 2 arguments, got 2"
why not just put a variable somewhere in your module that is cpu_count()-1 or if cpu_count() &lt; 4: cpu_count or whatever? Then you would have something like from mymodule.consts import thread_count and off you go
Don't call me guvnah, bruh
 def upvote(): global can_upvote comment.votes += 1 can_upvote = False 
This is me with my boyfriend's foot fetish.
That was not the scenario presented by the OP. Also some of my Dev machines are across the country.
devs with relationships and a sense of humor, interesting, the species seems to be evolving rapidly.
FWIW, a concise two liner: from random import choice; from sys import stdout while True: stdout.write(choice(['\\','/']))
That improved my morning. Thank you! 
Not OP but the namecalling is uncool
Second this, would be very very nice to have!
I'm interested in your perspective here. I could see this this joke being too exclusive personally. I want python to be as inclusive and friendly as possible. Can you comment on the point she makes?: https://www.reddit.com/r/Python/comments/7bptca/when_you_confess_something_to_your_girlfriend_she/dpk5f8l/
&gt; namecalling is uncool You mean "sexist", "gatekeepers", "brogrammers", "programmer bros" or the implicit "you're bigots if you don't agree with me" that outrage fanatics keep throwing around?
Error: *The operation completed successfully.*
I get what you mean. Still, it feels a little exclusiony to me. It's just a gut feeling, but given the industry I think it's ok to err on the side of excluding the fewest people possible.
Nothing much at the moment. I hope that Google will open source more in the future
Confess shit to your bros. Not your hoes. 
Ugh no please don't use global 😟
Nice. I wish I had chosen yaml over ini for my configuration files.
While processing this exception, another exception occurred 
Thank you so much! I've just finished Week 2 of Andrew's Deep Learning course on Coursera and am really struggling with the coding.
We could do well to exclude some of the humorless and hats regardless of gender. 
Thanks. This is what I thought I'd go with, it conforts me in my choice.
What exactly would be the benefits to using python on a true embedded microcontroller compared to c? What's wrong with C.
Maybe it helps to know that your cx_freeze application literally contains an entire Python interpreter. That's the whole point, the applications become distributable because you "freeze" (copy) your code, its package dependencies alongside the actual python interpreter and standard library into a single folder. If the interpreter works now, it should work in 10 years, even on newer computers.
Make up something else worse that original and let her bitch about that, she’ll for get other thing, Connell you made up second thing, she’ll be mad for a day,done
Probably something important to start with is how you're going to represent your data; raw character strings are tough. (FYI, I've only worked on NLP problems in R, also just learning Python, not sure what the relevant packages are. You'll need to do some googling) The naive way is to code a binary variable for every word/token in all the sentences, so that each sentence is represented by a vector of zeroes and ones. Simple to implement, but not ideal. Applying 'Principal Component Analysis' should help you get a more manageable representation by reducing the dimensionality; as long as you have a decent training set, consider looking up 'Supervised PCA', to make use of your labels. Word embeddings are the next step up for dense representation (each word becomes an n-dimensional vector, for 'n' of your choosing; a sentence can be a sum of all the word vectors, and still be only n-dimensional), google 'word2vec' or 'GloVe' for some resources you might be able to make use of. Algorithms: If you can decide how to define a comparative function (to return a summary measure of similarity/difference) between two sentences as you have them represented, you might get away with 'k-nearest neighbours', which is a very simple to implement/compute/understand &amp; explain to others. It can work with just about any representation of the data, since your comparison function bridges that gap. But it really does rely on having a dense/representative labelled dataset for training to be effective. For a more robust, but complex method, 'Support Vector Machine' can handle multi-class problems of high dimension. [Scikit-learn](http://scikit-learn.org/stable/modules/svm.html) seems like it might be able to help, if you can familiarize yourself with the method. Note, basic implementations of those methods do not preserve order of tokens in a sentence; called 'bag of words' methods. If you end up with poor results, consider going back and finding a representation that does preserve order, and try those algorithms again. Beyond that, most people start diving down the rabbit hole of neural-net training. I get a bad feeling when simple/beginner projects go that far.
Friends dont let friends use Idle. Use pycharm edu or pycharm community edition. Do yourself a favour.
If you install conda, and the required environment on a networked machine, it should be possible to simply copy that conda installation to the target machine.
You my be interested in [pex](https://pypi.python.org/pypi/pex) from Twitter.
&gt; what if the number of categories is more than 2 You can turn any binary classifier into a multiclass classifier by using a one-versus-one or one-versus-all strategy; see more at [Wikipedia](https://en.wikipedia.org/wiki/Multiclass_classification).
**Multiclass classification** Not to be confused with multi-label classification. In machine learning, multiclass or multinomial classification is the problem of classifying instances into one of the more than two classes (classifying instances into one of the two classes is called binary classification). While some classification algorithms naturally permit the use of more than two classes, others are by nature binary algorithms; these can, however, be turned into multinomial classifiers by a variety of strategies. Multiclass classification should not be confused with multi-label classification, where multiple labels are to be predicted for each instance. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
/r/jokes
[ERROR_SUCCESS](https://msdn.microsoft.com/en-us/library/windows/desktop/ms681382(v=vs.85).aspx)
https://msdn.microsoft.com/en-us/library/windows/desktop/ms681382(v=vs.85).aspx
Brilliant
we made Tavern as an internal tool at https://overlock.io, due to problems of running RESTful integration tests with postman in our CI pipelines, as well as needing to rely on a CI. What really kicked this all off was the javascript testing functionality in other projects which we found to be nearly unusable in more complex tests where say, you want to verify the contents of a JWT. We liked the ability to write simple tests quickly, but needed more power to be able to extend when needed - that's why we wrote the ability to hook in to python functions with Tavern as required. We're just getting started with tavern and the next things on our agenda are: 1) Reference schemas from Json schema or OpenAPI documents 2) Command line deamon to ping your API regularly for functional uptime monitoring We'd really love to know what you think - either in the comments or github issues!
He has 4 feet's?
No worries, I am a man
Am I supposed to say "boyfriend/girlfriend/androgyne-friend/..."?? No, I said girlfriend, and I thought that everyone here would be reasonable enough to realize that it could go either way.
&gt; I'm not sure if you can still get this It was fixed in Python 3. Here's Python 2: TypeError: f() takes at least 2 arguments (4 given) the same in Python 3: TypeError: f() missing 2 required positional arguments: 'a' and 'b' 
When would that even happen/how did you make it happen?
&gt; We start with flake8 using the flake8-quotes plugin. ... &gt; Next we apply isort. Sorry, I don't really believe that project-wide consistency in which quotation mark you use, and what order you import modules, really makes a difference to code qualify. To me, that's precisely the sort of [hobgoblin](https://www.python.org/dev/peps/pep-0008/#a-foolish-consistency-is-the-hobgoblin-of-little-minds) that puts me off using flake8. 
TOML is also great to wish for having used for your configs.
By convention, some languages return a 0 to signify that a function completed successfully. It's classed as an "error code" because it is in the set of things which are returned by a function. It's more accurate to call it a "return code", but since 99% of the objects in this set are errors, they are usually called error codes. Read any book on C or C++ and you'll see ERROR_SUCCESS codes everywhere.
What kind of email service do you use to send and receive? POP3? IMAP? SMTP? Some HTTP API? For standard protocols python has stuff in the standard library: https://docs.python.org/3.6/library/email.html (scroll down for a list additional modules for SMTPetc). As library it is a bit low level-ish, you might want to grab something higher level from PyPi maybe. Also I've use the Gmail (REST) API a few times for stuff like this, handy if you don't have a normal email service to use or like a web interface. 
Don't call me bruh, old chap.
I must do this. It will drive my coworker insane.
&gt; everyone here would be reasonable enough 2016 taught me that sentence is never true.
But why would you ever use Python 3 when 2.x is teh best evah?? /s
Waiting for the buzzfeed article on the latest wave of sexism in reddit's brogrammer communities... Seriously this post does belong in a humor sub.
Does it have some advantages over yaml?
Who wonders that? Seriously 
Well, since pipenv now uses pyenv -- if it's available -- to manage Python installations for you, no, you don't *need* pyenv, but you probably still want it, 
There is no 2.x, there never was. We've always been on Python 3.
Is this in Django or Flask? 
Pls teach me lambda functions. I can’t understand the utility of them at all. Is there a guide you used that you found particularly useful?
Really? That's good to know! Sorry for my lack of knowledge on this, I'm just a beginner python programmer
Less magic types and hidden features, and potentially cleaner syntax for config files, especially if you use flat-ish INI-like configs.
We got a lot of weak men in this sub.
Actually, the OP is noncommittal. And you can get a pretty flaky connection anywhere. Being on AWS is worthless if your local link is junk. Let's please stay away from video unless we need to.
They are just a shorter function syntax. Here's an example: jeff ~ $ python3 Python 3.6.3 (default, Oct 4 2017, 06:09:15) [GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.37)] on darwin Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; foo = [1, 2, 3, 4] &gt;&gt;&gt; bar = [2, 4, 6, 8] &gt;&gt;&gt; def dbl_func(x): ... return x * 2 ... &gt;&gt;&gt; assert(bar == list(map(dbl_func, foo))) &gt;&gt;&gt; assert(bar == list(map(lambda x: x * 2, foo))) &gt;&gt;&gt; list(map(dbl_func, foo)) [2, 4, 6, 8] &gt;&gt;&gt; list(map(lambda x: x * 2, foo)) [2, 4, 6, 8]
Adding to the above , I made a short blog post on numpy to quickly get an idea of the most common functions with examples. Do have look too: http://www.safarnuma.com/2017/09/numpywhy-so-serious.html 
No worries, being a beginner is nothing to apologize for! I'm a beginning Rust programmer.
may be you have to use NLTK to classify your problem
Take your SJW snowflake crap to somewhere else god
Windows is slow! See benchmarks.
I’m guessing your timeframe is a little too condensed if this project is due within a couple weeks. Programming is really foreign at first. That said, I highly recommend Automate the Boring Stuff. I was a non-programmer working an office job and that helped me get on track. You will not regret learning Python. One other thing, you are taking a perfect approach. I always found it easier to stay on track by picking a project to work toward. There is so much to learn that you need to focus on specific topics and projects help narrow it down.
I can't seem to install this off pypi?
Oh noo. Do you get a descriptive error? What platform are you using, and what Python version? You could try installing manually from PyPi: https://pypi.python.org/pypi?:action=display&amp;name=xl-link&amp;version=0.13 I'm not very experienced with PyPi so there's a very good chance I've messed something up.
Thank you for playing wing commander!
Tell that to maya
They got the ammunition stored, for whenever this happens. 
This is the error i'm getting C:\Reporting&gt;pip install xl_link Collecting xl_link Using cached xl_link-0.13.tar.gz Complete output from command python setup.py egg_info: Traceback (most recent call last): File "&lt;string&gt;", line 1, in &lt;module&gt; File "c:\users\rept2~1.srv\appdata\local\temp\1\pip-build-bunpcf\xl-link\setup.py", line 2, in &lt;module&gt; from setuptools.config import read_configuration ImportError: No module named config ---------------------------------------- Command "python setup.py egg_info" failed with error code 1 in c:\users\rept2~1.srv\appdata\local\temp\1\pip-build-bunpcf\xl-link\
I'm not on python 3 which i think is the issue
This is what I got so far. Not sure if it's right though. matrix = [] for student in range(0, len(students)): for x in range(0, len(friendships)): if student in friendships[x]:
Thanks! Plotnine is such an amazing package. 
No she has 4 feet.
That’s [because you’re so sexy.](https://youtu.be/JT5AQIlmM0I)
Join us! (We miggt nake fun if you as a python dev) /r/programmerhumor
As a gay man I just replaced the pronouns to match my situation, upvotes and had a laugh. Chill.
I guess my question more comes into when to utilize them. For example, if you are writing a script and you are using the example you provided, why would you not just have foo = [2,4,6,8] from the get-go? What is the point of using a lambda function given its only supposed to be used once? Sorry if I'm not articulating well it's just been really hard for me to grasp this concept
Pardon my ignorance, I'm very new to Python. For the filter example, it doesn't look like it filtered anything. Did he use that correctly? It just looks like he converted feet to integers and checked to see if each element was even. It looks like a map function would do the exact same thing in that instance. What am I missing?
Lol. I had never heard of this but I like it. It's certainly still geared towards humans unlike json. It seems there are 2 packages available with toml having more recent commits than pytoml.
Don't call me chap, chummer.
I'll grant that you're correct about **most** real-world uses. But with other high level languages, I've used reduce for things that wouldn't have been covered by the functions you list.
I would suggest deleting the first half of that code block. We don't need it and it distracts from the actual code.
&gt; A style guide is about consistency. Consistency with [PEP8] is important. **Consistency within a project is more important.** Personally, I *really* like leaving all these details to the computer. If I can have perfectly consistent styling, I care much less about the specific style in question and personally waste much less time - just run the formatter and move on! The difference in code quality isn't really because the imports are sorted, it's because human attention is focused on questions like "is this the right code" rather than line-level nitpicking.
Yes, the author got sloppy and didn't proofread. Clearly it should have been: [x for x in feet if x%2]
i realised i took one more step than i should as split returns a list but as i said i am a beginner. Although this probably is not the problem this 'code' has.
Yeah sorry, I wasn't planning on supporting Python 2. I've only tested with Py3 versions of it's dependencies. 
The point of a lambda function **is** that it's only going to be used once. There's no point in defining an entire new function when it's only going to be used once. Lambda functions are often not necessary, but they are good form. You can't just have foo = [2,4,6,8] because in the rest of this imaginary program, it needs to be [1,2,3,4]. In my example with Tkinter, i needed to pass functions as arguments. Normally this wouldn't be a problem, but with the way Tkinter methods are set up, it wasn't working unless i passed it a lambda function that called my other function.
IMO, there are (at least) two components to code quality. 1) how it works (e.g. performance, defects, maintainability, etc.) 2) aesthetics (white space, quotation marks, import ordering, etc) My argument for why aesthetics are important is the fact when you have project-wide consistency and even consistency for a team across dozens of projects, it reduces the cognitive burden (especially when the computer is handling that part) of working in the code. This translates into a freer mind to focus on real problems.
I guess you could do like that: ```python friends_dict = {} for pairs in friendships: for i in pairs: if students[i] not in friends_dict: friends_dict[students[i]] = [] for j in pairs: if i != j: friends_dict[students[i]].append(students[j]) ```
I think the question is poorly worded as to what the final result should look like... but ultimately I came to the same conclusion as you, but achieved it a little differently from collections import defaultdict students = {0: "Jess", 1: "Isable", 2: "Charlot", 3: "Brian", 4: "Mike", 5: "Paul", 6: "Nic", 7: "Anna", 8: "Miriam", 9: "George"} friendships = [(0, 1), (0, 2), (1, 2), (1, 3), (2, 3), (3, 4), (4, 5), (5, 6), (5, 7), (6, 8), (7, 8), (8, 9)] groups = defaultdict(list) for a, b in friendships: groups[students[a]].append(students[b]) groups[students[b]].append(students[a]) # The answer makes more sense as a dict of lists for k in groups: print(f'{k:8}{groups[k]}') # But since they asked for a matrix matrix = groups.values()
I think the key is finding things you are interested in already and then asking are there problems to solve. You will hear this referred to as "scratch your own itch". Are there things that you wish existed to improve your experience with one of your hobbies? Are there small bits of things that if automated would simplify some tasks you find yourself having to do? 
well, there are few problems in your code by quick view: 1. I din't think there is a reason to use defaultdict from collection package, and also, defaultdict in you case do the same as {}. So, calling groups = defaultdict(list) You do the same as {}, but you also call a function. 2. Need to check existance of student in groups dictionary Actually, I'm not clear with what means Matrix here... Much better is tree of friends:)
Thank you very much! That really helps!
Something concrete? https://home-assistant.io is an open source home automation platform, written entirely in Python. You can add support for more components (controllers, website APIs, automation rules...) or help fix bugs, or simplify it by auto-configuring as much as possible... or just use it! More generally, Django is fantastic for web development. Python is also the most popular language for all kinds of data analysis (not just academic science) - think stock trading, machine learning, weather prediction, drawing maps, etc. It's also very widely used to script various big programs, from GIS to movie special effects.
When you're building dictionaries like this, a `defaultdict` is typically better. It's more concise, less error prone, and marginally faster (particularly on larger data sets)
I let SoundCloud handle the RSS building. I'm not sure
Tavern looks awesome. We're going to be trialing it next week. Thanks for the heads up!
Is it also possible to put the combinations in a 2-demensional list. Jess is friends with isabel(1) and charlot(2) so the first list in the list would be [[1,2], Isabel is friends with jess, charlot and brian so now the list would be [[1,2],[0,2,3]]
I think this is wrong way to step into programming area :) I'm sorry to say that, but first you need a target, you need to totally understand what you need. "How" phase is important but it's secondary phase and based on your wishes you can create a plan from zero to product. When you have a plan you can take some research about what technologies are used by somebody. Learning just python with Django won't let you create complicated websites. For an example. I want to create simple game, acranoid. I don't know what exactly need in result, so I need to create a prototype. I don't want to spend a lot of time with learning C++/C#/JAVA and so on. I could take a python for that! Next I can discover frameworks which can be usefull for my game. Let's imagine I'm crazy and I like "Gameobject", just for fun. So, I know that this framework fits to my requirements(i.e. easy to implement logic or graphics). What I would to say by all of these flooding words. Take a instruments by your requirements. It's fine when you know few languages. It's fine when you need to learn new language to create new product, few weeks ago I have to dive in to Scala world, lol :) Knowledge investment is a core point, if you want to just earn money you can stay with current level of Python or PHP. If you want more... learn more... Software developer must studying each day and forever.
This. I learned to code because I wanted to automate some stuff I was doing in a spreadsheet a couple of times a week that took a couple of hours. 5 years later i'm (ostensibly) a senior engineer at a start up in charge of Site Reliability and infrastructure. I still use python/django every day, and have picked up bits of android (mostly for App development), ReactJS and vanilla JS. Anything in coding will be a chore if you're doing it for the sake of doing it. I built a website that became a company, and that was what pushed me from toying around with it to doing it 'properly'. If you want to learn to code apps, go learn Java for Android, or Swift. You can port python stuff to mobile, but it's a pita. What can be done in python? Most things. Probably not great for coding a graphics game engine, as it's too high level, but you're a way off worrying about that by the sounds of it. 
my code allows to use not just pairs but lists, and yes, it computes "bidirectional" aggregation I'm sure It can be done by single execution of "pair" tuple, but I'm lazy today:)
Allright thanks!
Flask
Already thinking of the payoff of learning something? I dont think programming is right for you.
Minimal entry point is just knowledge of Python itself and standart library. Big plus would be small own project: website, webserver, tool, gui app, and so on. As a lesson for myself I was working on blog with comments, ratings, users. This allows to learn most used issues with language. This also allows to you to learn HTML, JS, CSS which are really need for web developer. I think best way is to go to local IT company as a Junior Developer. You can then get know much and much more in Python development and other staff.
you're welcome
well, difference in conditions in your code there are if i%2!=0: And in code you've found: if x % 2 == 0: Also, it example it prints results after loop, and in your it prints inside loop in just one condition.
A web scrapper to scrap ModDB pages given a url. Any feedback welcome. [Repos](https://github.com/ClementJ18/moddb_reader)
No, i am not talking of 'i gonna build a facebook and sell for millions'. I wanna be a software developer for living. Im actually questioning: is python right language for it. Are there any software developers depending on python.
 When I _really_ began to code python I had a goal in mind. I made a quite simplistic game, but I got the basics down. I later got a IT job, where my python experience where helping but not essential. I continue learning and developing in python on my free time. After a year or so I start introducing python at my job, and over the coming years python replaces and finds more ground in the company. A few years later I was designing the back-end rework for a multi-million user system. Together with a few others, we wrote majority of code in python, optimized essential parts by writing it in C. A few months ago, I got a new job. IT/IS architect at a large automobile company. I still write python most days. For me, it started with python and I wanted to make a simple game.
I use a program where if you forget to put any input before hitting enter I comes back with "Nothing done successfully"
I had to add end='' to print for python not to create a new line.
woosh 
Thanks. is that the same as [x for x in feet if x%2==0] ? And would this also work? uneven = [x%2==0 for x in feet]
I work with data. Tabulate help us display samples of the data in a human-readable form. Also, thanks to the many formats it supports, it's also handy when writing data samples to documentation, wiki pages, markdown, etc.
I think if you don't enjoy coding for sake of coding it might not be for you. 80% of programming is mostly uninspiring stuff, so if you don't get joy from just writing code you will get burnt out pretty fast.
Python doesn't have a maximum number of items it can grab from `*argument` (other than a memory limit). You'd have to do exec(f"f({','.join(str(j) for j in range(256))})" to make that happen. That being said, `chain.from_iterable` is more memory efficient. 
&gt; [x for x in feet if x%2==0] Should be [x for x in feet if x%2!=0] since you're looking for odds. &gt; [x%2==0 for x in feet] Gives a map of True/False values where True is an even False is odd. Can be useful, but doesn't do the same thing. 
It's easiest to use Anaconda Python and just make a vitualenv of whatever python version you want. You can't do that in the standard CPython.
Checking for quotes ? Man, you have way too much time on your hand.
Look you should try it before judging. I can use a real IDE while using shared WiFi on the bus to a vm in the cloud.. One 4g connection shared by like 10-20 other people. RDP is pretty amazing with remotefx and tile based refresh. A straight up text editor is no substitute for a real IDE, imo
djrobstep, more like dj*bro*step, amirite? 
[Machine Learning Mastery](https://machinelearningmastery.com/start-here/) has some pretty useful material for beginners.
yeah you've got some other problem going on. `save` will write as soon as it's called.
For every programming-related thing I've ever needed to do for work, Python has worked wonderfully. This includes all kinds of things like building webscrapers, predictive models, web apps, and a variety of other applications. I was originally coding in R, but switched to Python for the love of the language. If you can find some projects to work on that you actually care about (and it seems like this might be your key sticking point), I'll bet you'll enjoy learning Python.
Yeah, I do try, often. Neither RDP, nor VNC, nor even (no chance in h*ll) X11 over SSH) offer the required performance. Either that or you are far more tolerant of poor latency than I when I'm typing on a roll. It's kind of beside the point. The real solution to this problem is not to put an IDE on the server, but to make the IDE work with remote files, etc. Let's not hack around problems. &gt; A straight up text editor is no substitute for a real IDE, imo And an IDE that didn't learn the lessons of the past X decades isn't a real substitute for a text editor. It's kind of beside the point.
Depends on what you want to do really. Simple scripting and automation probably requires the least amount of prerequisites. If you were comfortable with the contents of 'Automating the boring bits with Python', you'd be capable of moving forwards. This has the added benefit that low level IT system admin jobs often give you some exposure and experience of this, so you can both chase the Python dream and follow your friend's accurate, but not particularly inspiring advice.
Java was like the third language I learned. Never could imagine being introduced to coding with java. 
I tested it and that snippet works fine for me. Try /r/learnpython. Show them the entire code you have and the entire error. 
Great! Glad to hear it. Please do let us know what you think!
Will do.
I mention that in the article. I really wanted to go native for a better guarantee of compatibility. It was easy to get access to Pis and although the cumulative build time is very high, it was less then two weeks in real time. Plus, dogfooding.
oh, ok. thanks.
&gt; https://imgur.com/a/YMUe1 That is a really cool setup you've got going on! Do you think you might ever do a similar project for your fish? I'm not entirely sure what all goes into managing a biome for a fish tank, but I'm sure some things would be similar.
Thank you. Reef tanks already have a powerful automation solutions on the market. Expensive, though. Neptune Apex has a lot to it and my reef is almost fully automated with it. It can be doable to run its automation on Raspberry, with all the appropriate sensors(temp, ph, optical level sensors, water flow sensors, things of that nature). But Neptune is convenient and lets me concentrate on my monitor lizards automation. 
Currently working on a web/mobile project to use as a basis for managing my finances. At the moment, I'm setting up a django project that will just tracks transactions, both debits and credits. I'm still trying to work out the data model, but working with django orm makes it a lot easier. I think it would be cool in the future to implement some machine learning to predict expenditures for the month/year among other things. 
Yeah, that makes sense. Sorry, only skimmed the article. I guess you could get several pi's and do it in parallel
Step 1: read the sidebar Step 2: post in the correct sub (see Step 1 above) Step 3: google anything along the lines of "getting started with python", "python tutorial", etc. ffs.
I know Dropbox, Spotify, and Google all use a pretty good amount of Python, just to name a small few. It's well worth learning.
Takes us no time at all. It's all automated.
Are you using IDLE? Go to File &gt; New File and you'll get a new window that allows you to load and save code. --- If you have more questions like this it's better to post them on /r/learnpython. Be sure to [format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin. Also, include which version of python and what OS you are using. 
I did. That was in the article too :) I started on one Pi at home, and to scale it up I used a hosted Pi service (I used 20x Pis initially and now it's scaled down just to keep up with new packages).
Thanks for replying. I'm really hoping my project doesn't reach the complexity of building a neural network. I've been learning NLTK for NLP. Thank you for suggesting the k-nearest neighbors and SVM algorithms I will study them in detail and try implementing them to solve the problem.
Thank you for replying. I'll check out multiclass classification and multi-label classification. Thank you.
Super cool. Let's chew through 2.7 and 3.6 now! :)
Thank you for differentiating multiclass and multilabel classification will check out both of them. Thank you.
AND IT'S LYING! Because it did at least print a message!
Yes NLTK is a powerful and a beautiful library, I hope NLTK coupled with the above-mentioned algorithms solves the problem. Thank you for replying.
I created a parser for YAML that cuts out the magic: https://github.com/crdoconnor/strictyaml IMHO TOML gets messy once you start having multiple nested things.
Well that's because nothing was done successfully not even nothing
Software developers understand concepts, not languages.
It's purpose is pretty much what it says on the box; you install to a network share, then users who can access that share can run the created file within it to install on their local machine from that shared location. The basic idea is to stop all your users from downloading the same file multiple times. It is also useful for the purpose you're talking about, because ignoring that file you've got a working Python installed in the target directory, though you'll have to do some extra work with setting up environment vars properly (PYTHONHOME, PYTHONPATH, PATH, etc) on each user's machine. When I've had to do this I've distributed a .bat file that acts as a wrapper, that lives on the PATH and sets up the rest and actually runs the networked interpreter, passing though the arguments the .bat received.
I do not get the same output as you. To get the output you have, I need to replace l1.append(p) with l1.append(i) Also the text 'no odd numbers' makes me think that the program should do the following: If the series only contains even numbers, print 'no odd numbers'. If the series contains odd numbers, print those numbers. If that's the case do the following: * Keep the for-loop, but remove the prints and the else. * After the for-loop create an if-statement: if l1 is empty, print 'no odd numbers' else print l1. By the way, I'm happy to see that you want to learn Python. Python is not the easiest language, and Python-programmers are really picky when it comes to how you write stuff. Different code can do the same thing, but one can be a lot faster to execute than the other. (and be faster to write) The lines: m=list(y) p=[int(x) for x in m] can be replaced with: p = map(int, y) What happens here? 'map' will execute the 'int'-function over every element of y. Also, 'map' creates a memory-efficient generator-object, but how that works is a story for another time.
So.. I'm very close to being done with my voice activated personal assistant, which is very much like [Jasper](https://github.com/jasperproject/jasper-client) but better IMO. I'm excited since this was my first real project. I finished a complete Turing Machine emulator, and I plan to launch it online, free for anyone to use - however, I have absolutely no idea of CSS, JS or even Django. Soo umm on a semi related note, does anyone know how I could turn this into a reality? If yes, pm me - I'm interested in working with you!
I had two projects where I used Pandas in ETL. In both cases, I had config files that defined transformations on pandas dataframes. I considered it a good solution for small ETL jobs. Unfortunately, both projects were cancelled, so I never got to try my idea in production. I really would have liked to. 
I have a lot of Pandas ETL running in production. No problems (yet) :-) been about a yeah. Never used Luigi - but it looks interesting.
What’s the code behind it?
The concerns I would have with pandas for ETL are the following: 1. Most ETL I have seen does not require much work across rows, as such it could be handled in a streaming fashion which is less resource intensive. 2. Pandas is not all that memory efficient. There were some posts from the pandas developer recommending 2x-5x the RAM of the underlying typed dataset. So you might be able to do ETL on smaller datasets, but for large datasets you are going to have to think about chunking. I would perhaps take a look at tools like PETL, or otherwise identifying exactly what kinds of transforms you need and where pandas is actually helpful.
GitHub.com/joel-g/your-representatives
It sounds like you are new to programming. The minimum set of skills necessary land a Python job is to know how to program. (I'm being snarky, yes. But for real: learn how to program. Doesn't matter what language. There is no "bar" for how much of the Python language you know that will suddenly enable you to land a programming gig. You simply need to know how to program.)
To follow up, you may ask, "How do I learn to code without having a job coding first?" The answer is to do something yourself. Others mentions simple web services. I would suggest instead writing a reddit crawler. Parsers are a perfect introduction to programming: * They are just hard enough to require many concept of good code, such as abstractions, layering, and separation of duties. * They are just useful enough that you can actually accomplish something useful that benefits you besides feeling like completely contrived made up junk ("I'm gonna make a game!!") * They require you to integrate with a small but nontrivial set of third party libraries, a valuable meta-skill 
Using it for a while, it's awesome. VSCode has honestly become my favorite editor, toppling Atom.
I also use bottle for my personal projects, many of which run on a Raspberry Pi. I have benchmarked against flask but bottle runs much faster.
There is a daemon mode implemented recently in mypy https://github.com/python/mypy/pull/4169 Could it be used for the vscode extension as a typescript-like language server? 
MSIs are intended to be installed via a Group Policy Object in MS Active Directory. This allows an administrator to create a policy for a specific package and apply it to arbitrary users and machines connected to the domain. The MSI itself is akin to a standard installer in some ways: it has instructions for where the software will be installed, files, folders, and registry keys to create, permissions to apply, and things to do when the package is removed. The major difference with a traditional installer is that it does not require a user interface to run. This allows the package to be installed when there is no actively logged in user. The benefits to this deployment method are mainly: 1. I can create a single policy and apply it to as few or as many workstations as are within my control. 2. Depending on the package I can customize aspects of the installation. 3. I don't need to visit each workstation 1 by 1 4. I can also remove the application from the group policy manager 5. I don't need a user to be logged into the workstation, nor do I need to elevate their local machine privileges to allow them to install the software 6. This space intentionally left blank 7. MSIs can be built with the intention of providing easy upgrade/downgrade paths for administrators 8. From the group policy manager I can see which machines the policy has been applied to You can read a bit more about how it's done here: http://www.itninja.com/blog/view/the-guide-to-deploying-software-using-group-policy In the past I have used the WiX toolset to author MSIs for applications. It's quite handy in that it plugged in to Visual Studio, but offered a pretty good command line build feature for my automated build process: http://wixtoolset.org/
you are the best. Thank you bro
White space, quotation marks and import ordering are among the least important aesthetic qualities of a codebase. They're just easy to run a script to detect. DRY, loose coupling and fail-fast code are all way, *way* more important.
yeah i should use print outside the loop.Thank you bro
Thank you for that 
&gt; The last del may be superfluous, or may not work as intended. To be honest, I haven't checked if it will work inside a function. The idea is to let Python decrement the reference count, rendering it unusable. I'm pretty sure it does nothing, since exiting the function will implicitly decrement reference counts. Python 3.6.3 (default, Oct 4 2017, 06:09:38) [GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.37)] on darwin Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; import sys &gt;&gt;&gt; def f1(x): ... pass ... &gt;&gt;&gt; def f2(x): ... del x ... &gt;&gt;&gt; x = object() &gt;&gt;&gt; sys.getrefcount(x) 2 &gt;&gt;&gt; f1(x) &gt;&gt;&gt; sys.getrefcount(x) 2 &gt;&gt;&gt; f2(x) &gt;&gt;&gt; sys.getrefcount(x) 2 Note that the reference count is 2 because `sys.getrefcount` increments it: &gt; The count returned is generally one higher than you might expect, because it includes the (temporary) reference as an argument to getrefcount(). https://docs.python.org/3/library/sys.html#sys.getrefcount
What do you mean thread Keras models?
yawpitch So was there a reason why you needed to setup the PYTHONHOME env var? It seemed that I was able to import the python standard libraries without setting the PYTHONHOME in this case.
How does your lower bound effect your example? You missed that?
This probably isn't the best place to ask, as it's really a Neon question, but I'll take a shot. What happens when you open konsole and type conda? I don't think there's anything you need to do as long as you've prepended anaconda to your path. if it can't find the conda command it's either not prepended to your path or not even installed. 
Are you sure you pasted the code correctly? Right now `lists` is the only function but the code under `return alist` will never run and it seems like the "unique string count" code will only run if `usrin` is either empty or has only one element. Are there supposed to be three separate functions? 
Pytest is a horrible piece of crap. It violates the most important principle of explicit is better than implicit with it's decorator and plugin garbage. Also the documentation is a pain in the ass. It has no API to connect to other skripts. In toto pytest seems to be hyped by stupid fanboys but is less than worthless.
Everything is fine with Konsole. I usually fire up Anaconda with the 'anaconda-navigator' command in konsole. I was just expecting there to be a config file for anaconda which would allow me to set the preferred terminal. Perhaps anaconda is just using the value of TERM from environment... Will test and post back here.
Thank you! I sent you a message. I look forward to reading it!
Sorry i was playing with return, the original state is as it is updated.
Oh wow, thank you!
Ah, ok. I'll take another look.
There seems to be a bug if you add another list with an element that is not in the first list but is in the second list. Example: In[13]: lists(['g', 'gh', 'ghj', 'g'], ['j', 'ju', 'gh', 'gk', 'gn'], ['gn']) Strings that appear in more than one list: gh Strings that appear in more than one list: # &lt;-- where is 'gn'? Number of unique strings: 7 Total number of strings processed: 10 
The code you have written is far more convoluted than necessary for what you are trying to do. The function `lists()` has no return value, so it can't be tested beyond the fact that it just runs without throwing an exception for a given argument. For example you could add the following at the end of your `lists()` code: n_unique_strings = len(alist) n_strings_processed = count return n_unique_strings, n_strings_processed and then write your test case, e.g., def test_lists(): n_unique_strings, n_strings_processed = lists(['g', 'gh', 'ghj', 'g'], ['j', 'ju', 'gh', 'gk', 'gn']) assert n_unique_strings == 7 assert n_strings_processed == 9 and then from your console, run `py.test lists.py`, which will automatically find your test case using that naming convention.
Learning a language at the same time is fine.
For this example x=[2,0,0,1,11,14,3,5] You gave [[2],[2,0],[2,0,0],[2,0,0,1],[0,0,1],[0,1],[1],[3],[5],[3,5]] as the possible combinations and said the total is 10, but shouldn't it also include [[2, 3], [2, 5], [2, 3, 5]] and other combinations you haven't mentioned or is there other criteria that you didn't mention that excludes these? Because my code says there should be a total of 62 (and that includes 0 and 1 even though your instructions say those should be excluded, if I exclude 0 and 1 as per your instructions the total is 6). 
 from itertools import chain, combinations def lists(*usrin): repeat_strings = set() for a, b in combinations(usrin, 2): repeat_strings.update(set(a).intersection(b)) all_elements = list(chain(*usrin)) total_strings = len(all_elements) unique_strings = len(set(all_elements)) return repeat_strings, unique_strings, total_strings if __name__ == '__main__': assert lists( ['g', 'gh', 'ghj', 'g'], ['j', 'ju', 'gh', 'gk', 'gn'] ) == ({'gh'}, 7, 9) assert lists( ['g', 'gh', 'ghj', 'g'], ['j', 'ju', 'gh', 'gk', 'gn'], ['gn'] ) == ({'gn', 'gh'}, 7, 10) 
Use a search engine to see what’s out there. If you don’t get any hits in the first page, there might not be much out there. You may want to consider using .NET. The last time I had to deal with PSTs, I used C#. 
1: /r/learnpython 2: post your code 3: format it properly
You inconsiderate asshole, I spent minutes doubting if I truly knew what a stop word was and whether Hitler's middle name was indeed Spacy, just because you thought it would be funny to make a celebrity joke. Shame!
Agree with /u/mudclub but the actual answer is to use str.split like len(foo.split())
Any advice on how to get started with this? 
Classic off by 1
Check out libpff on GitHub by Joachim Metz. It has python bindings which let you load the pst file and iterate through the items contained within. Additionally, if you're on Windows and have Outlook installed, check out using pywin32 to interface with the Outlook.Application API. I know it's for Powershell, but the following blog post can get you started if you go down the 2nd route: http://jon.glass/blog/reads-e-mail-with-powershell/. For calendar items, filter through mailitems that have a MessageClass of ipm.schedule. TechNet actually has a ton of documentation for the Outlook API.
RemindMe!
**Defaulted to one day.** I will be messaging you on [**2017-11-11 04:34:03 UTC**](http://www.wolframalpha.com/input/?i=2017-11-11 04:34:03 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/Python/comments/7bp3cl/how_to_get_full_javascripthtml_code_from_a_url/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/Python/comments/7bp3cl/how_to_get_full_javascripthtml_code_from_a_url/]%0A%0ARemindMe! ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Irrationally excited for this and am going to check it out this weekend
Thanks for the down vote but can some one explain the shortcomings so I can improve in future?
God I fucking hate Stimulsoft...
I used pandas extensively at YCharts - lead most of the development and switching almost every one of our metrics to it. Had very little issues with it. Found it exceptionally performant and let us do a lot of complex things that our competitors (FactSet, etc) couldn't build quickly that would take us a matter of days. The automatic typing honestly is great -- if your API sources are somewhat reasonable and don't randomly change, data scrubbing is so efficient in pandas it's not hard to add iron-clad validation logic.
Do you mean the Python REPL? IPython has it with `%edit`.
2/3 + 1/2 = 4/6 + 3/6 = 7/6
This looks exactly like the 5th problem of the ongoing Codechef competition: https://www.codechef.com/NOV17/problems/CSUBQ 
Make something cool and useful for yourself. You will learn along the way.
That was pretty interesting from a technical point of view, although I don't understand the obsession with JIT-compiling Brainfuck. 😜
Thank you. I feel like a dumb now.lol thanks a lot
This should be in /r/learnpython or be much more advanced
It *should* work without it being set if you've done the default install, as Python will find everything relative to the executable itself, but IIRC we encountered some 3rd party installer that simply refused to work without it being set. That said I wouldn't set it until you trip across that. 
Because it's fun, simple and educational. Also, there are quite a few pretty cool brainfuck programs that you can test out on your engine: https://github.com/cslarsen/brainfuck-jit/tree/master/examples It's a pretty pleasant feeling when it works, and you learn a lot.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [cslarsen/brainfuck-jit/.../**examples** (master → bea8a96)](https://github.com/cslarsen/brainfuck-jit/tree/bea8a96fd44a585f65c17d05225dd593d0d84f9e/examples) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
The graph doesn't have a legenda
There's also a HN discussion at https://news.ycombinator.com/item?id=15665581
Very interesting read. Something to think about the next time I try to keep my lines below 80 characters.
Yeah, I get that, of course. And thanks again for the great write-up, now I have an idea of how JIT compiling works in principle, and it is very cool that all this hackery can be done within Python. Whenever I hear JIT compiling, though, I am thinking about PyPy and how awesome it would be if it could replace normal Python. I never looked at the PyPy code, but if Python and JITs were my thing, I would try to get into that project.
There are probably more paid developers who depend on Javascript, so just learn that one. You may appreciate having a *sane and well designed* language to compare it to though.
Yes, but I recommend using virtual environments to keep things straight. 
Looks awesome! But what is the difference between athena and pelican? (as you say it is "better") :D Also, I recommend writing a setup.py with entry_points for proper packaging and easier usage. (Making an executable "athena-gen" or smth to invoke the build commands and stuff).
This sounds super cool and definitely something I think I can use in my environment. Though preferably it would be rather when an event happens than just polling for it. 
Sure it does, "relative frequency". Not specific numbers, which are likely so large as to be meaningless, but a valid description. It would be nice to know if it manipulated though, such as with a logarithmic scale.
Thanks! As far as I'm aware, pelican doesn't support Pandoc out of the box; one would need to download and install a plugin. athena started as a pet project to scratch my own itch and in the process I thought of releasing it publicly as well since it's a great playground to experiment with ET's ideas and SSGs while incorporating my personal Pandoc (academic and casual) publishing workflow. My main goal was to create one workflow to write plain text docs and be able to publish to PDF via LaTeX (Tufte layout or not,) HTML (same,) slides, letters, &amp;c without (or with minimal) changes in document structure. athena is responsible for the HTML in my setup. With regards to the setup.py, there is an [install.py](https://github.com/apas/athena/blob/master/install.py) file which I don't rely on now but [did some stuff in the past](https://github.com/apas/athena/commits/master/install.py) athena doesn't need anymore. But you're right and it's definitely in my todo's to further automate the install process.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [apas/athena/.../**install.py** (master → 1a3bf37)](https://github.com/apas/athena/blob/1a3bf37813835b7148eaa91ebd7f24ce04c859d6/install.py) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dpm3wkl.)^.
Honestly, just from using a few and this was one that I like. No real allegiance to Komodo per say, just something with similar features. 
Anybody know pros/cons of using this Auth0 compared to other user admin/authentication modules?
My point is that it doesn't matter what language you learn, so long as you learn the concepts too. You can always pick up a new language.
(+) is adding strings together and (,) inputs additional parameter. Im not sure which is better habit nor giving better performance. 
I guess the difference matters when adding numbers together, but when it comes to simply adding one string after the other... Maybe (+) "connects" the strings, as opposed to just putting them next to each other (which I suppose (,) does)?
In your second example, you're passing five arguments to `print`.`print` will then automatically convert all of its arguments to strings and print them separated with spaces. In your first example, you're building up one big string, and then passing it as a single argument to `print`. You can also use string formatting to a similar effect: `print("The product: {} costs {} dollars".format(product, price))`, or even `print(f"The product: {product} costs {price} dollars")` if you're using Python 3.6.
Oh my god, you are an absolute life saver. Thank you so much! That looks a lot more, well, pretty. Easier on the eyes, and way easier to look over. Is the format function(?) regularly used in the programming community, or will I mostly see the "extended" version (my first example)?
String formatting is very common, and very powerful - look [here](https://pyformat.info/) for a reference on what it can do. My last example, with the `f"`-string, only works in Python 3.6, so you won't see much of it in production code yet.
We're currently working in Python 3.6, so it works great! Really, thank you. I'm taking a programming course, and the teacher has *really* simplified it to the point that I feel it hinders my learning a bit (well, I'm curious to a fault, too, so I guess it's on me also). So thank you so, so much!
Hey, that's looks pretty nice! :D I really like the idea to get a live preview of the outcome. However, to me it seem to only be useful for small stuff like the math functions in the demo, when it comes to things like those I am working on currently (multi-core machine learning somewhat natively in python via matrix-manipulation) I guess the preview-framerate would be somewhat low and bloated with data. 
The print function offers you to pass one or more arguments to it. In your first example, you concatenate the individual strings to one string and pass just one argument, which is exactly the output you see, to the print function. The + operator is just defined as concantenation for variables of type string and will behave differently for other types. In your second example you pass 5 arguments to the print function. Arguments are always seperated by commata. The print function accepts those and as defined will concatenate them, seperated by a comma. You can see the defined behaviour in the documentation. https://docs.python.org/3/library/functions.html#print Especially you can see that it accepts multiple arguments (*objects) and by default seperates with a comma (sep=' '), which you can also change if you like.
Thank you so much for breaking it down for me. I would have given all of you Reddit Gold, but I'm a newbie student so... !redditsilver???
Sorry for the late response but my session was moved to December.
Beginner questions like this are usually more welcome at r/learnpython ;) 
I'll go there in the future! Thanks for not flooding the comments with "Wrong sub! BURN THIS POST AT THE STAKE!" (;
Kivy is a GUI framework and Godot is a game engine. In order not to compare oranges and apples, could you edit your post and give us more information on what you want to do exactly ? :)
Yeah, totally… \*casually puts aside torch and pitchfork\* To be quite honest I don't think it's a good setup. There are *a lot* of beginners who post their questions on r/python since, quite naturally, it's the first sub they find, only to be downvoted and told to go somewhere else. It doesn't exactly make you feel welcome in the Python community. The sidebar tells us this sub is reserved for news, but then maybe *that* should be it's own sub, like r/python_news? I guess at this point things are just so lived in that it'll be hard to change. I'm sure this has already been debated to death in the past.
I can totally understand why pitchforks are often at the ready, since repetitive questions that are supposed to be directed elsewhere can be out-right annoying (I subscribe to several webdev subreddits, in which there are a *lot* of those). So I appreciate the warm welcome even more! Thanks :) 
Not 100% clear what you did, but look into the documentation and see what type of result you have from your operation and if there is a method that returns the stuff you want. I find the API docs a bit unfriendly but the information you need is there somewhere. If it is a `Tree` http://www.nltk.org/api/nltk.html#nltk.tree.Tree you might want `mytree.leaves()` for example. 
Basically you just answered my question. I want to learn python and therefore wanted to programm a minigame. Kivy would rather be for Applications, is that correct? 
seems like a rather good idea for market sentiment but it obviously entails the human element of trading. I was thinking of a scalping algorithm since it reduces risk exposure. Yours is good but i'd suggest you include an automated feature to limit human involvement. You have the indicator showing when to buy and sell stocks, but you still don't have the when, the how much, or risk calculators. Hope for all the best though!
Just finished my second coursera course on python (was on data structures). I just started a month ago and am already happy I can make basic translators and word extractors. My long term goal is a trading algorithm for forex and a marketing analyzer for my youtube channel. For now, I am signed up to a third course and learning how to use python to access web data. Hopefully I get up to speed with other redditers. 
Yeah, you can apply filters. But there should be a way of making it more streaming based.
Um... neither? Kivy is really raw, only a level or two of abstraction above OpenGL, and can't do much in the way of complicated interfaces. It has no tree for rendering elements, can't clip elements, etc. It's made for mobile, where you're much more likely to have a single, fixed frame, but for a dynamic UI, forget about it. Godot is a C++ engine. I know it has some pseudo-Pythonic scripting interface but it's not Python. You won't be able to use all the legion of Python libraries with it, which is the main selling point of the language. I wouldn't recommend either to a beginner.
Wifi, Bluetooth, OTA, Cloud ready... In an industrial context...What could possibly go wrong ?
Instagram, started small, with python and still uses it, even years after Facebook acquisition. And recently migrated from python 2 to python 3
Kivy basically combines a relatively low level graphics api (although still much higher level than raw opengl) with a widget framework. The former part is pretty capable for simple games, at least comparable with something like pygame, while the widgets are useful even in these kinds of project for building certain game elements. That said, for games in particular, Godot probably has a larger, more focused community.
&gt; Um... neither? Kivy is really raw, only a level or two of abstraction above OpenGL, This seems quite wrong - even Kivy's lower level canvas apis are quite a long way above raw opengl, and the widget system has basically nothing to do with it. &gt; and can't do much in the way of complicated interfaces I guess you have something in particular in mind, but you can make basically any kind of interface with Kivy. &gt; can't clip elements, Yes it can. &gt; It's made for mobile, It actually isn't - in fact, of the core developers, I think more are using it for non-mobile projects. It originated as a framework for 'natural user interfaces', and was therefore built to handle things like unusual input mechanisms. The fact that it runs well on mobile devices arises from its modular design and the fact that it was designed with touch-like input in mind from the start.
Does it auto convert the bad quotes or does it just check ? 
thank you, this seems to work.. kind of, I created the test file and it looks like this... from TestLead_PythonTask import Implementation def test_lists(): n_strings_processed = Implementation.lists(['g', 'gh', 'ghj', 'g'], ['j', 'ju', 'gh', 'gk', 'gn']) assert n_strings_processed == 9 When I run the code, it runs and passes, when I update the test so that assert n_strings_processed is equal to something wrong (such as 99 for example) the test fails, as it should.. BUT when I update the script under test (one that generates the returns) it still passes. I then update the test script so that assert n_strings_processed was equal to something incorrect again and I could see in the test output that the test was still using old values from the previous test. I changed the script under test so that it outputs 10 rather than 9 but in the stdout of the failing test it still shows 9, even thought if I run the script it shows the updated value: Strings that appear in more than one list: gh Strings that appear in more than one list: g Number of unique strings: 7 Total number of strings processed: 10 But when the script runs I see this: E assert 9 == 88 test_Implementation.py:10: AssertionError ---------------------------- Captured stdout call ----------------------------- Strings that appear in more than one list: gh Number of unique strings: 7 Total number of strings processed: 9 Any ideas what could be going wrong? I've added the following to my list script: n_unique_strings = len(alist) n_strings_processed = count n_one_string = res return n_strings_processed, n_unique_strings, n_one_string And my test script looks like this: from TestLead_PythonTask import Implementation def test_lists(): n_unique_strings, n_one_string, n_strings_processed = Implementation.lists(['g', 'gh', 'ghj', 'g'], ['j', 'ju', 'gh', 'gk', 'gn']) assert n_unique_strings == 7 assert n_one_string == {'gh'} assert n_strings_processed == 88 Thanks
String concatenating (string_a + string_b) is actually only found when you need to build a string in a loop, and even then, the `join()` method of the `str` class is used for simple string-building loops. The `format` method (yes, a method is like a function, but it is attached to an object (a class), it is the proper name in OOP) is very common, because of its readability. `format` takes "one" argument : `**kwargs` which means you can pass it several arguments, or just one which is a dictionary. For instance, you can have the same argument repeated in the string : `"the product {0} costs {1} dollars ({0}:{1}".format(product, price)`
This works really well, thank you, one problem though, when I add a new item in a new list (like you previously did with 'gn') when it's printed using "repeat_strings" I get the following output: {'gh'} {'gh'} {'gh', 'gn'} All I would be looking to print would be {'gh', 'gn'} I don't think I understand the for loop well enough to know why this is happening. Thanks. 
This reminded me of the stable marriage problem: https://gist.github.com/joyrexus/9967709
This exactly. I've also found code reviews end up being smaller and more focused on real code quality when there's no churn due to differences of preference. Ideally we would just use yapf or some equivalent, and there there'd be no style difference at all. Except that I've found it doesn't work perfectly enough (and didn't support fstrings) for me to enable it for us.
&gt; when it comes to simply adding one string after the other... There is a known problem in CPython with this. The code is optimised so that 99% of the time nobody notices. The other 1% it can't be optimised so runs like a legless carthorse as it's O(N^2). That's why the use of the string `join` method is preferred.
This. While dynamic typing solves some problems, like data structures that can have different types of data in them, it is a pain to debug and even more of a pain to try to read at times. I learned with Python but also am fluent in Java, and learning Java had me thinking "Well this is fucking tedious." Little did I know...
That plot was taken from the [twitter blog post](https://blog.twitter.com/engineering/en_us/topics/insights/2017/Our-Discovery-of-Cramming.html), where it really didn't have labels! I had to paste it into a paint program to add axis labels.
It's being done by big guys in the industry as well. http://info.opto22.com/raspberry-pi-io-selection-guide. And there are far fewer problems than most expect. 
And what's that?
If you want to watch these videos a better link would be the original source [Microsoft](https://mva.microsoft.com/en-us/training-courses/developing-websites-using-python-and-django-11415?l=AQdTENEJB_4004300477) Avoids clickbait and soliciting of payment for premium downloads.
Try this link instead: (https://mva.microsoft.com/en-us/training-courses/developing-websites-using-python-and-django-11415?l=AQdTENEJB_4004300477)
You are missing an important bit of logic: how does "number of connections" translate to "importance"? For a concrete example: if I have one friend with no other friends, and one friend with two other friends, each with no friends, what is my importance?
This was my first python project last night for testing devices on a POS network. Started with super basic finished with multiprocess significantly speeding up the process. It works great for about 80 iterations of pinging 8 devices. Then it runs out of memory so gotta sort that out before I️ can call it finished. 
It is a misunderstanding - I actually made a script that plays a ping sound, just like that machine from the Monty Python hospital sketch :-)
You have to add extra dimension to your variables. You can now sum over one axis if you provide the `axis` parameter. n = np.linspace(1, 11, 11)[:, None] x = np.arange(101)[None, :] y = (4 / np.pi) * np.sum((np.sin(n * x)) / n, axis=1) plt.plot(x,y) 
Sorry but 79 is not enough. I'm sticking with 120.
what happens to the x in the sin() when I do this? because I need to plot x against y.
Oh, you can squeeze it, or do the broadcasting inside the calculus, that way: n = np.linspace(1, 11, 11)[:, None] x = np.arange(101) y = (4 / np.pi) * np.sum((np.sin(n * x[None, :])) / n, axis=1) plt.plot(x,y)
(And you may say "sum over n" on your post? In that case, it's `axis=0`. If not, you will have a dim mismatch)
Do you specifically want to do it in one line? If so, `return (a + b) * 2 if a == b else a + b`. Also, /r/learnpython
Absolutely one of the best posts ! Should be crossposted to r/learningpython
sorry I'm pretty new to python but what ever I try I get the message "ValueError: x and y must have same first dimension" what i am trying to plot is (4 / np.pi) * (sin(1 * x) / 1) + (4 / np.pi) * (sin(2 * x) / 2) + (4 / np.pi) * (sin(3 * x) / 3) + ... all the way to n = 11
Doesn't Python also support return (a == b) ? ((a + b) * 2) : (a + b)
Pycharm's auto format does some absolute nonsense to wrap lines. Then again I shouldn't be suprised. Programming a computer to know where to wrap lines is probably governed by the halting problem. I just do it whenever, and i end up usually under 80 but with some at about 100, or 120 if there are string involved? Even with a database , the key can be pretty long at times eg HeroAiResponseOnPerception. I still use the auto formatter so I can get lazy with spaces around operators and alk that, but I do turn off the auto line wrap. With C I just set soft wrap in the editor and the editor will wrap without inserting a new line. This triggers people but I am fine with it.
Nope. That syntax works in C and most C-like languages though, even PHP (though it wouldn't have been PHP without them fucking it up in a way no sane person would ever think of).
**Readability**. You choose what people are more likely to understand.
r/vimmasterrace
There aren't nearly as many beginner questions posted here as we get in r/learnpython (unless I don't see them here because the mods remove them very quickly). One of the things we try to do in r/learnpython is remove all the posts that just give general tips or link to tutorials, because inevitably those get a ton of upvotes and start to take over the subreddit. Those are great to read, but keeping a very narrow focus allows us to give much more prominence to helping people on an individual level - it's somewhat rare that a post doesn't get answers helping them solve their problem. And *that* is the undivided goal of the subreddit, helping people learn and providing them individual attention that they often aren't getting in their courses, because that can be the difference between someone giving up and someone becoming a programmer.
I'm using a model to predict the sentiment. Apparently Keras is thread safe so calling `model.predict` from multiple threads doesn't work very well
Woah, is this a new reddit feature!? Cross-linked posts?
Haha no no, that's only one aspect. It also uses an LSTM to do real-time preditcion of the price, based on the indicated time range and then determines whether a pivot is happening or when/will occur. 
if you have no problems to solve with a computer, you should consider yourself a happy person.
* Get the latest python 3 * get requests * get beautifulsoup * get PRAWN - the python reddit api Here's your assignment: Crawl your own comments Pick out the top rated comment in each topic Make a distribution (histogram) of the word count of each top rated comment This will tell you exactly how many words your comments should have to generate the most sweet karma in the topics you personally care about. Extra Credit: Pick out the top rated reply to each top rated comment and do the same. This will tell you how many words you should reply to a comment with to get the most sweet sweet karma. Report your results back in one week. 
Maybe you could: 1. fill a queue asynchronously 2. Every n milliseconds ( depending on your latency budget ) you create a batch of from the queue 3. You predict the batch It should increase the throughput a lot at the eventual cost of some latency increase 
shouldn't you show what you've achieved so far in the first place?
nonetheless, anyone pursuing to code something must be capable to understand important hints in a given context.
Really I'm just looking for someone who codes with Python who wants to build things together and share ideas. I'm not really trying to impress anyone, and I haven't had the time or resources to release anything of note. In fact, my only project on GitHub right now is still in progress and I'm learning Django to port it to the web. 
Ah, shoot, I switched from Python to C in my CMPSC courses so things are blurring together I think. It's strange that Python changed up the format from cond, true, false to true, condition, false in my opinion, but, eh.
First, let's get your code as text (instead of an image in two pieces): graph = {"v1" : ["v2","v3"], "v2" : ["v1","v3"], "v3" : ["v1","v2","v4"], "v4" : ["v3","v5"], "v5" : ["v4","v6","v7"], "v6" : ["v5","v6"] } def generate edges(graph): edges = [] for node in graph: for neighbor in graph[node]: edges.append((node,neighbor)) return edges: print(generate_edges(graph)) def degr(v, Y): X = {} for key, value in Y.items(): X[key] = len(Y[key]) #return print(X[y]): for key,value in graph.items(): print(value) #degr(key.graph) z = {'x':(123,"SE",2,1),'q':(124,"CI",1,1,)} for i in z.keys(): #reaching the keys of dict for x in z[i]: #reaching every element in tuples if x=="CI": #if match found.. print ("{} holding {].".format(i,x)) #printing Let's address some simple errors: - You mistyped `generate edges` (without an underscore) in the function definition. - `"v7"` appears in `graph` as a target value but is never defined as a key - this will probably cause your algorithm to throw a `KeyError`. - More generally, you are repeating yourself when defining data - you have to manually create a link from v1 to v2, but also from v2 to v1. Ideally creating an `UndirectedGraph` class with an `add_edge` method would make this less error-prone. - `return print(X[y])` makes no sense, because the `print` function does not return anything. Print `X[y]`, or return it, but don't combine the two. - I do not see how the last 5 lines actually relate to your problem? So let's set this up according to the problem statement: class UndirectedGraph: def __init__(self, edges = None): self.graph = {} # dict of set if edges: self.add_edges(edges) def add_edge(self, node_a, node_b): # no self-edges if node_a == node_b: return # add edge from a to b if node_a in self.graph: self.graph[node_a].add(node_b) else: self.graph[node_a] = {node_b} # add edge from b to a if node_b in self.graph: self.graph[node_b].add(node_a) else: self.graph[node_b] = {node_a} def add_edges(self, ab_list): for node_a, node_b in ab_list: self.add_edge(node_a, node_b) def degree(self, node): # deg(v) if node in self.graph: return len(self.graph[node]) else: return 0 def neighbors(self, node): # Ng(v) if node in self.graph: return self.graph[node] else: return set() def nodes(self): return self.graph.keys() g = UndirectedGraph([ ("v1", "v2"), ("v1", "v3"), ("v2", "v3"), ("v3", "v4"), ("v4", "v5"), ("v5", "v6"), ("v5", "v7"), ("v6", "v7") ]) Now we are ready to actually solve the problem! Here is the pseudocode implemented as a method of UndirectedGraph: def importance(self, node): # I(v) node0 = 1 / (1 + self.degree(node)) node1s = [1 / (1 + self.degree(n)) for n in self.neighbors(node)] return node0 + sum(node1s) Then we show the results: total = 0 for node in g.nodes(): node_value = g.importance(node) print("I({}) = {}".format(node, node_value)) total += node_value print("SUM: {}".format(total))
It just runs checks. It's rare that it fails though. I have found that style checks when enforced as part of the CI process, help team conformity pretty quickly where then developers are not thinking about style because it becomes instinctual. 
to each his own
Ostensibly they did that so that the code reads more like natural English.
I've heard setting up Tensorflow on Linux isn't easy either. The conference I went to recommended to just use the docker image until Tensorflow is easier to install / configure.
[Here](https://github.com/asalt/filegrouper) is something I made to sort and files based on a regular expression. It was a fun project and something I needed to make my life easier. I think little projects like these are great practice. 
Hi everyone. If you are interested in online Python courses, please consider Talk Python Training at https://training.talkpython.fm/
&gt; Godot is a C++ engine. I know it has some pseudo-Pythonic scripting interface but it's not Python. In the latest version you can use Python instead of the pseudo-Python script... OP, you should look for pygame as well for creating simple games.
It seems to not be standard practice but i like to write variables that take the least mental effort to comprehend what is(as in zero mental effort), so i don't get any cognitive overhead when reading my code while trying to figure out how to fix this next problem. So i don't write 'var = 5' i write characterSpeed = 5. Not even charSpd = 5 like some people do. Kinda shitty examples, but i like when my code looks english and reads like english. Especially when the code becomes big.
Awesome project.
This is great advice! Those datastructures are what will determine a) whether your code becomes long or short. b) how easy it is to work with the data within. super important.
Try /r/forhire. I hope you're paying well, that will be at least 6 lines of code. 
Fair point, that's probably part of the Pythonic paradigm I suppose?
Almost a hundred points and no upvotes. How rare.. Otherwise, cool post OP!
I am down to join. I am new to python but have experience in Ruby
Is this code golf? I got six lines, 183 bytes.
It's only strange if you come from C.
 (a==b) * (a+b) +a+b
I...I didn't think of that. That might just work better. Much obliged stranger. This is why I come to this sub. 
What's on Vimma's Terrace?
Well, if you come from IT, then you might check into how python could help you progress in your career that way. Database administration, web development go hand in hand with IT. For programming, look at diving deeper into the internal structures behind the python methods, and learn another language. 
Thanks. You are right. Recently i started C as well,ifbits a good choice. what it could be an entry level python job!? 
Don't define the init method on model classes. SQLAlchemy does it for you.
Making an automatic youtuber. It will download pictures from sub reddits, and edit them into a compilation with moviepy. Then using Google's API to upload them.
He wants a script that will check 188 million websites for up/down status and he is only willing to pay $10. Time seems to be a concern for him as well. Don't bother with this.
Try to get some gig work, scraping, or IT automation works well. You should try to use python for the work that you find repetitive. You can do data viz as well. I'm on mobile, sorry for the curtness of the answers. Ask these questions on stack overflow as well. I'll link to the python weekly mailer when I'm on a desktop.
Webdriver stuff is awesome
No, man good advice. Thanks a lot
You shouldn't `+` strings together. Each concatenation done that way will create another string and copy both strings into it. Your first example: "The product: " + product + " costs " + price + " dollars" Is roughly equivalent to: str = "The product: " str = f"{str}{product}" str = f"{str} costs " str = f"{str} {price}" str = f"{str} dollars" Which is basically quadratic over the length of the string. Using the formatting, besides prettier and clearer, will just copy the strings once and build a single new string: f"The product: {product} costs {price} dollars."
I have a scratch document in Google Docs. I also use Gist, and blog about things that others might find useful. 
So from what I understood a two dimensional list is a flatter way to show the main square we are given, so we can apply methods on it
I have a git repo made up of simple text files and shell scripts. Easy to grep and available everywhere I work.
Try /r/learnpython. Show them the code you have and describe where you are stuck. Be sure to [format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin. Also, include which version of python and what OS you are using. 
Go and see what happens when you put two StencilView objects on the screen at the same time. 
$10? that's an insult even if it is an easy task. To do it right is going to over 5 minutes.
Stats question: What is the advantage of fitting the distribution parameters via optimization (with the objective being to minimize difference from the empirical distribution) vs applying something like [Maximum Likelihood Estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation). I am not expert, but I think the former would be pretty hard to do with a small sample (including using such a small histogram. I would have done it with a gaussian KDE or something like that).
**Maximum likelihood estimation** In statistics, maximum likelihood estimation (MLE) is a method of estimating the parameters of a statistical model given observations, by finding the parameter values that maximize the likelihood of making the observations given the parameters. MLE can be seen as a special case of the maximum a posteriori estimation (MAP) that assumes a uniform prior distribution of the parameters, or as a variant of the MAP that ignores the prior and which therefore is unregularized. The method of maximum likelihood corresponds to many well-known estimation methods in statistics. For example, one may be interested in the heights of adult female penguins, but is unable to measure the height of every single penguin in a population due to cost or time constraints. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
You could do something sketchy like return [ a + b, (a + b) * 2][ a == b] But that is really unclear what is going on and is kind of cryptic.
Hah that's great/terrible!
I just keep it in a git-tracked folder. It can become cumbersome with time, but if I stay on top of it, I can usually keep it organized. If you have a readme file, you should be able to grep for what you're looking for easily enough. Alternatively, if you're on macOS, check out [quiver](http://happenapps.com/). It seems pretty cool. Or [Notebooks](https://www.notebooksapp.com/). Both are nice, but I do not see too much advantage over a notebook of markdown files.. (Quiver uses its own JSON-based format which has *some* perks, but I would still prefer markdown)
You may want to look at numpy arrays. http://www.numpy.org/ https://docs.scipy.org/doc/numpy-dev/user/quickstart.html
Automate every task you do with your computer: For example, I did some programs to scrap/download manga pages I was reading. You can make games, it's always cool and make you learn how to manipulate raw data (save files), infography, networks (if multiplayer), ... You can create your own website! It's always funny. Try to create some algorithmic-related programs: If you know C, try to use the Puthon C-API to do the heavy work, and the rest in python (for example showing the results using a python GUI).
Considering how often awesome-python is linked to &amp; referenced in this subreddit, I'm surprised it hasn't been added to the sidebar. Then again who even reads the sidebar anyway?
I like this as a simple, easy-to-follow example. Most of the articles I've tried to read on ML have very intimidating math, but I could follow this one.
Not bad start but lots of typos.
Oh boy, look at all those juicy affiliate links. Do I go for the one with 17 articles or 13 articles and 4 supplemental resources!?
Thank you that was very helpful :).
What website do you want to use? Do you have some example of your list already saved to we see how are your structure?
"crack"? As in, the malicious meaning of the word?
Yes i want to be able to hack any network .
Just use a proper text editor, or an IDE.
lol.
If hacking was about finding that one tutorial that teaches you how to get into any network, then almost everybody would take the time to become a super hacker. Please keep in mind: What you are about to do may be illegal in your country. I suggest you try not to break the law. In prison they might hack your cherry
I wrote a piece of code that goes prints "hello world!"...baby steps, i guess
When you crack a system you don't pick a tool then go after the system. The system dictates the tool(s) you will use to crack the system/device/network etc. Now. As a member of the true [hacker](https://www.gnu.org/philosophy/rms-hack.html) community, I despise crackers, those who want to break system security for malicious means. If you are, you are the worst kind of garbage human if those are your motives.
I don't know why people assume that you are after a bad thing. And please do not be rude i just want to know how a network operates this is how you can be able to exploit any system and know what's wrong.
Well, then what you are after is penetration testing. Not solely a Python exclusive task. 
Well can you recommand how can i begin penetration testing what should i use?
404 = page not found
- scapy - wireshark come to mind. Also, Kali linux. 
[This Reddit response is a really good start](https://www.reddit.com/r/hacking/comments/1d9onz/how_do_i_start_getting_into_pentesting/c9rkesj/).
Awesome PM me and we can shoot some ideas back and forth. 
Try [Anaconda](https://www.anaconda.com/download/) It provides a myriad of modules for you, and you can easily install (pre-built) additional modules if you need them. Also, /r/learnpython 
Readability is, definitely. It's effectively the guiding principle behind every style recommendation.
It hadn't occurred to me to check the performance difference. I'll keep that in mind in the future. Thank you!
I would pull it using pandas. You will grab the entire table and then select any value you want by reference. https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_html.html
Does the website use Javascript to return some data that you need? Else I would say ditch selenium and use requests with beautiful soup 
 You can improve on the search you have by first gathering all the text associated with an href and then searching or pattern matching against the results. You could just join the url, alt-text, etc. up into one string and use `re` regular expressions to match your keywords. 
Thank you for your answer. I will try with the Pandas also, but as a beginner, I just may get too deep into unknowns at the moment :-) My whole script is cycling through all 500 S&amp;P500 companies, extracting more than the number in question (but others are all OK) from different parts of Yahoo Finance and it just may be too complicated for me to put all together in Pandas for now. I'm hoping I can implement 'data-reactid="50"' as additional search condition into already existing code I have.
watch Mr. Robot, it'll show all the tips. (not, but it's nice though, and you'll feel like you know things)
Will beautiful soup complete actions within the web browser though?
Working on a simple CLI calculator. Right now it does adding, subtracting, multiplying and dividing but I have plans to add stuff like exponents, roots, and the like. Not the most exciting but it's my first real Python project so it's something I guess. [Source](https://github.com/OfficialExedo/PyCalc)
Once I have some text in a list associated with the href, how do I find the href? Say the keywords were sweatshirt and red. Would I be able to obtain the href with this knowledge? Because the end goal is to then click on that link and complete a series of other tasks. 
Thanks. I will look into AWS S3. Mega was offering 50 gigs free which was why I wanted to try it out. Google only offers 10 (15?) and I think Dropbox only offers 2 gig free. 
(shameless plug) Just to give an idea of things you can do, here are a few things we did with kivy at my company - https://vimeo.com/238618045 - https://vimeo.com/206290310 - https://vimeo.com/170447721 - https://vimeo.com/176320908 (here only the table is using kivy, the video is done by resolume) - https://vimeo.com/126982700 - https://vimeo.com/232367561 (here the graphs on the second screen are html/js to allow for remote viewing/interactions) it's not for mobile, in our case it's still i a fixed frame because we are doing fullscreen apps on touch screens, but nothing prevents you from doing resizable/responsive interfaces. And of course, people are doing other desktop oriented apps with kivy. e.g - https://www.youtube.com/watch?v=GJ3f88ebDqc - https://www.youtube.com/watch?v=uq20kiAlTw8 Also, i'm pretty sure Python's main selling point, and why it got so many libraries in the first place, is its ease to read and write.
Our Stencil abstraction is not perfect, granted, and you can see weird things happen in some situations, but apparently it's not concerning enough to hear people complain about it or to contribute a fix to it. Usually it's a bit harder than just combining two of them to see issues, though, i've nested them pretty deep in another app to have a nice unrolling effect on menus (was a bad idea for other reasons but it worked well in regards to graphics).
There isn't a lot of info here to figure it out from, but I can say that multiprocessing is a bit touchy at times. If your data frames are large or not chunked well then you can run into massive overhead from having to transfer the data between processes. I've always found that multiprocessing needs a bit of extra thought and tuning than initially expected. You might want to try dask instead over plain multiprocessing. It does a really good job with breaking up dataframes and arrays across processes, and has some really awesome diagnostic tools for debugging performance issues. It can also very easily switch between various backends, from local threads to multi computer clusters. It's my go to library for multiprocessed dataframes or arrays. 
This is one of the common cases in python where the idiomatic way to do something is also the most efficient (although there are a few exceptions).
I've been working on a music player. [screenshot](https://raw.githubusercontent.com/vedard/MokaPlayer/master/mokaplayer/data/screenshot.png) https://github.com/vedard/MokaPlayer
What's something you can't do in 79 characters with line continuation?
Thanks!
If those keywords appear in a predictable way as part of the href: keywords = [['word', 'one'],['word' 'two']] links = [driver.find_element_by_partial_link_text('-'.join(k)).get_attribute('href') for k in keywords] Ofc you will need some error handling there.
I have a wide screen monitor. There's no reason to limit to 79. 
No, BS just let's you parse static html. Webdriver is the thing that handles web interactions and javascript
What I am working at is a soduku solver, I am new to Python and it is a good challenging project so far!
I took a quick look; the relevant chunk of HTML runs &lt;table class="W(100%) M(0) BdB Bdc($c-fuji-grey-c) Mb(25px)" data-reactid="5"&gt; &lt;thead data-reactid="6"&gt; &lt;tr class="Ta(start)" data-reactid="7"&gt; &lt;th class="Fw(b) Fw(s) W(20%) Py(10px) C($finDarkLink)" data-reactid="8"&gt;&lt;span data-reactid="9"&gt;Earnings Estimate&lt;/span&gt;&lt;/th&gt; &lt;th class="Fw(400) W(20%) Fz(xs) C($c-fuji-grey-j) Ta(end)" data-reactid="10"&gt;&lt;span data-reactid="11"&gt;&lt;span data-reactid="12"&gt;Current Qtr.&lt;/span&gt;&lt;!-- react-text: 13 --&gt; (&lt;!-- /react-text --&gt;&lt;span data-reactid="14"&gt;Sep&lt;/span&gt;&lt;!-- react-text: 15 --&gt; 2017)&lt;/span&gt;&lt;/th&gt; &lt;th class="Fw(400) W(20%) Fz(xs) C($c-fuji-grey-j) Ta(end)" data-reactid="16"&gt;&lt;span data-reactid="17"&gt;&lt;span data-reactid="18"&gt;Next Qtr.&lt;/span&gt;&lt;!-- react-text: 19 --&gt; (&lt;!-- /react-text --&gt;&lt;span data-reactid="20"&gt;Dec&lt;/span&gt;&lt;!-- react-text: 21 --&gt; 2017)&lt;/span&gt;&lt;/th&gt; &lt;th class="Fw(400) W(20%) Fz(xs) C($c-fuji-grey-j) Ta(end)" data-reactid="22"&gt;&lt;span data-reactid="23"&gt;&lt;span data-reactid="24"&gt;Current Year&lt;/span&gt;&lt;!-- react-text: 25 --&gt; (2017)&lt;/span&gt;&lt;/th&gt; &lt;th class="Fw(400) W(20%) Fz(xs) C($c-fuji-grey-j) Ta(end)" data-reactid="26"&gt;&lt;span data-reactid="27"&gt;&lt;span data-reactid="28"&gt;Next Year&lt;/span&gt;&lt;!-- react-text: 29 --&gt; (2018)&lt;/span&gt;&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody data-reactid="30"&gt; &lt;tr class="BdT Bdc($c-fuji-grey-c)" data-reactid="31"&gt; &lt;td class="Py(10px) Ta(start)" data-reactid="32"&gt;&lt;span data-reactid="33"&gt;No. of Analysts&lt;/span&gt;&lt;/td&gt; &lt;td class="Ta(end)" data-reactid="34"&gt;&lt;span class="Trsdu(0.3s) " data-reactid="35"&gt;&lt;!-- react-text: 36 --&gt;31&lt;/span&gt;&lt;/td&gt; &lt;td class="Ta(end)" data-reactid="37"&gt;&lt;span class="Trsdu(0.3s) " data-reactid="38"&gt;&lt;!-- react-text: 39 --&gt;27&lt;/span&gt;&lt;/td&gt; &lt;td class="Ta(end)" data-reactid="40"&gt;&lt;span class="Trsdu(0.3s) " data-reactid="41"&gt;&lt;!-- react-text: 42 --&gt;33&lt;/span&gt;&lt;/td&gt; &lt;td class="Ta(end)" data-reactid="43"&gt;&lt;span class="Trsdu(0.3s) " data-reactid="44"&gt;&lt;!-- react-text: 45 --&gt;32&lt;/span&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr class="BdT Bdc($c-fuji-grey-c)" data-reactid="46"&gt; &lt;td class="Py(10px) Ta(start)" data-reactid="47"&gt;&lt;span data-reactid="48"&gt;Avg. Estimate&lt;/span&gt;&lt;/td&gt; &lt;td class="Ta(end)" data-reactid="49"&gt;&lt;span class="Trsdu(0.3s) " data-reactid="50"&gt;&lt;!-- react-text: 51 --&gt;1.87&lt;/span&gt;&lt;/td&gt; &lt;td class="Ta(end)" data-reactid="52"&gt;&lt;span class="Trsdu(0.3s) " data-reactid="53"&gt;&lt;!-- react-text: 54 --&gt;3.8&lt;/span&gt;&lt;/td&gt; &lt;td class="Ta(end)" data-reactid="55"&gt;&lt;span class="Trsdu(0.3s) " data-reactid="56"&gt;&lt;!-- react-text: 57 --&gt;9.01&lt;/span&gt;&lt;/td&gt; &lt;td class="Ta(end)" data-reactid="58"&gt;&lt;span class="Trsdu(0.3s) " data-reactid="59"&gt;&lt;!-- react-text: 60 --&gt;11.09&lt;/span&gt;&lt;/td&gt; &lt;/tr&gt; and I would process it pretty much as you have done, from bs4 import BeautifulSoup import requests url = "https://finance.yahoo.com/quote/AAPL/analysts?p=AAPL" pg = requests.get(url) soup = BeautifulSoup(pg.text, "html.parser") then to extract the value, # first table, body, third row, second cell, text txt = soup.table.tbody.find_all("tr")[2].find_all("td")[1].text value = float(txt) # 1.79
Hi dispelterror, I finally uploaded my DMS monitor to github. You can check it out here: https://github.com/jeffgrima/dmon Note that this is my first public project and even though I have been programming in Python a while I have never had any kind of peer review to validate that I'm doing things sane.
It's probably (de-)serialization overhead, but I suppose I would need to debug it to be sure. When just accessing variables in the closure, multiprocessing is taking advantage of fork and COW memory. (each child process receives a copy of the parent's memory at fork-time). This is a very fast way of sending data from parents to children (but also error-prone/impossible for non-static data). Whereas the other way requires, serialization (with pickle) and then deserialization of the entire dataframe. The reason why chunking helped, is that it reduced (de-)serialization time.
Yeah, we're not going to help you write "malicious" code.
&gt;&gt; txt = soup.table.tbody.find_all("tr")[1].find_all("td")[1].text &lt;&lt; Ahh, interesting, will try it this way. I was over complicating with "data-reactid"! Thank you very much!
Sure, it's fun to cram it into one line, but it's considerably more readable to just do it the boring way: def sum_double(a, b): if a == b: return 2 * (a + b) else: return a + b
First of all, never asked for help in writing anything. Just asked if it's possible to open an application and "use" it through a Python script. Secondly, it's not malicious.
Wish a mod would stick by the "Homework-style questions will be removed" rule
You stated it's malicious but it's not? How does that work?
Would there be a way to do this using functions that wouldn't require serialization? Some way for many functions all access the same dataframe in the shared memory? Originally I figured that functools.partial would create a similar closure to just having a function access memory in its parent scope, but it's clearly being handled differently.
That's probably the worst argument you could make in this case
Thanks, I'll have to look into Dask a bit more - seems like a nice tool to have in my back pocket.
Theoretically? sure. I don't use `pandas` though, so I don't know if the author has built anything like that in. You might be able to kluge something together with `ctypes` or `cffi`
Got lost on your way to /r/scriptkiddies?
Really easy to follow
The way the multiprocessing module works is by serializing with pickle, sending to the other processes, unserializing, computing, reserializing, aggregating, and unserializing again. There's a lot of conversions going on, and memory is (by default) not shared at all. 
Creating a plug in for a popular structural engineering program that extracts forces for beams, columns, and foundations, then designs them to local codes and places them back. The automation of this will save us approx. 200 hours for every medium sized project we work on and reduce chances of errors. 
Let's give it a shot. import csv import requests csv_content = open("file.csv").read() csv_writer = csv.writer(open("online.csv", "a") for row in csv_content: with requests.get(row[0]) as temp_content: if temp_content.status_code == 200: csv_writer.writerow([row[0]) Let it run overnight.
How different would it be to nonlinear fit?
Answering to your question: yes!))))
Great work! Can you make it so it goes 100/100 on pagespeed? Does anyone knows a python generator that achieves directly out of the box this scores? Thank you and keep up the good work! 
Maybe there are much smarty way to you their json api? You dont have to parse unpredictable html then.
Using featured thing of python is cool, but exacky in this case you are making your code too complicated to read. Simple python condition would be nice and much easy to read.
Thanks for the post, lib looks very interesting. I like the commitment and documentation.
You could go ahead and manually copy the html from 'output.html' into the section in the file you need it.
Quiver for long scripts. Anki for shorter ish scripts - I try to commit those to memory. 
 c = 0 while c &lt; 10: a = input("Input a: ") b = input("Input b: ") c = a + b print(c)
 while c &gt;= 10: # do calculations
Something like that would do what you want, but if you plan to call this bit of code from more than one location it is a good idea to use a function instead. while True: print('------------') a = input('Enter value for a: ') b = input('Enter value for b: ') c = int(a) + int(b) if c &gt; 10: break print('Result is {0}'.format(c)) 
Well you have plenty of choices 1- if the CSV is dynamic , I suggest you to create a web app with flask or bottle 2- if the CSV is *static* you can use a template engine like **jinja2** to display your results the way you want.
No you were right, a While True loop can do that. c = 0 while True: if c &lt; 10: a = input() b = input() c = int(a) + int(b) else: print(c) break
the csv file is generated from python script. I already use flask to connect my index.html and my python script. But I have no idea how to display csv to index.html.
Jekyll is written in Ruby. Try [Hyde](https://github.com/hyde/hyde) or [Pelican](https://blog.getpelican.com) for Python, or [Hugo](https://gohugo.io) which is written in Go.
While I of course agree with everyone else that you should use a while loop, this reminded me of [a post I saw a while ago](https://www.reddit.com/r/Python/comments/61i6xm/til_you_can_use_nonlocal_jumps_in_cython/) which lets you jump in cython.
Why not put the condition straight into the while?
I tend to like things self contained, in this case everything in the while, bad habit I know.
As a beginner looking to learn Python by making a game, I'd look into Arcade: http://arcade.academy/ 
Maybe I used these " " ?
Hey Eugene-Le-Roux, thank you so much!
No, but since it's so difficult for you to understand a simple question. I asked if it is POSSIBLE, NOT HOW TO DO IT. And not did I ask an already written script.
Thank you for answering this simple question with simplicity and not making things out of your mind.
well you can in this case export directly the dataframe into a flask view without the need to geenrate a `CSV` Here is an example: https://sarahleejane.github.io/learning/python/2015/08/09/simple-tables-in-webapps-using-flask-and-pandas-with-python.html You can indeed save the csv file separatly in case you need it. BTW cool idea bro!
Thanks! I plan to further optimize things. Eliminating render-blocking JS and CSS above the fold is in my list.
Depending on how much flask you alrwadx have in there you could take a look at plotly dash. A flask and plotly based dashboarding tool that has the ability to dynamically generate tables and graphs, as well as have static content within one web application. 
Wrong hammer for this job. Now your run-everywhere simple readable code suddenly becomes a mess of module dependencies, dependent on a compiler, or requires a build system and a platform-specific distributable package. Not good form. Plus it will now run much slower on PyPy
Oops! Seriously though, what's with the downvotes? Do people not realize I'm joking?
Sorry about that. So anyone knows an engine which creates static pages scoring 100/100 in pagespeed? Thank you! 
Wow great thanks! However I have a little problem with the format since the domains.csv looks like this: 1779845,movie4k.me,1,0,0,false 1779845,newdown.org,4,0,0,false
All of them can.
If you do df.to_html() it returns a string with the HTML for a table. You can stick this in the body of index.html.
https://bpaste.net/show/11bc80e66b53 That gives you html, there is no silver bullet for these things. you will have to insert it into the index.html Jinja will work for this 100%
Do you mean the Intel MKL libraries? Why do you want to avoid them?
 When creating the pool `multiprocessing` uses (on posix systems) `fork` from `libc`. So first the memory of the existing main process is copied to all Python interpreter processes in the pool. This includes global variables, functions, etc. When you later do a remote function call data is serialized and transfered to the Python worker process, which is slower than just copying a bulk of data on c level.
I only played with it for a little bit, but It seems like you've got all the basics down. I would say that the main playability issue is the text scrolling. It's pretty hard on the eyes due to that. I found myself looking back up to find out if I missed any text. It would be nice if the player/enemy stats were static on the screen during the battle, with updates appearing at the bottom. 
Trying to make my first webcrawler but failing misrebly :(
Store the href seperately from all of the text describing it so that if the text matches you have the href on hand to use with `requests.get` to simulate a click.
See this is how you'll get banned from here, by intentionally ignoring the rules, despite knowing them. Make a new account...
Maybe you shouldn't be "evil" or prank someone with code. There is a level of trust that you're intentionally trying to violate.
Thank you, I was wondering if there were someone which was implemented having this characteristic in mind. I guess there is many but not one standing out for this characteristic. Thank you! 
That'd be nice! Keep it up!
You should first seriously evaluate whether your requirements fit within the limitations of Lambda, particularly request processing time and process memory.
Thanks for your feedback. I'm going to go with buttons, a UI, and some graphics next, preferably on Django or something. 
I knew you were joking but this thread was a doozy. Immediately taken over by outrage warriors.
What your looking for is called Acoustic Echo Cancellation, and is a pretty standard feature in conferencing systems. Its a little more complicated usually than taking the inverse and mixing the input and reference together. I don't know if there's a Python library available for it or not.
First you should address the dependency issue. Use virtual environments to manage dependencies locally, pip install what you need, and when changing your dependencies pip freeze and save that to a file. This is similar to a pom.xml or package.json. What is your deployment target? A few VMs you manually copy this stuff and replace existing versions? Windows or Linux host OS? Packaging can be solved a few ways. Docker images, tar/zip everything as you are now, or build rpms. I personally have done all three. If you know docker and have some expertise in running it, that solution can be the simplest. If you go the route of rpms you should explore what distutils can do for you because before I found that I did manual rpm spec file work and there was a lot of head banging with that. Here is a link that kind of gives you more details on something’s I mentioned and might lead you down the path to a solution. http://the-hitchhikers-guide-to-packaging.readthedocs.io/en/latest/introduction.html I have to admit I feel that other languages have this nailed down a little better, but none seem to be as straight forward as go’s all-in-one binary (I’ve never written go so no bias here just casual observation).
really not a problem for my use case
 In [1]: import random In [3]: import string In [5]: charpool = string.digits + string.ascii_lowercase In [6]: charpool Out[6]: '0123456789abcdefghijklmnopqrstuvwxyz' In [7]: random.choice(charpool) Out[7]: '6' In [8]: random.choice(charpool) Out[8]: 'r' In [9]: random.choice(charpool) Out[9]: 'n' In [10]: [random.choice(charpool) for _ in range(10)] Out[10]: ['k', 'u', 'g', '1', 'h', 'x', '0', 'h', '2', 'a'] In [11]: ''.join(random.choice(charpool) for _ in range(10)) Out[11]: 'yjw34t6hgu' In [12]: ''.join(random.choice(charpool) for _ in range(10)) Out[12]: 'pqarfv40m7' In [13]: ''.join(random.choice(charpool) for _ in range(10)) Out[13]: 'b731bpc3tb'
` import string import random s = ‘’ for i in range(10): s = s + string.printable[random.randint(0, 62)] ` This should work for you. (Though im not totally certain because I’m not near a computer to test it.) `string.printable` contains all alphanumeric characters as well as other printable string, random.randint(0, 62) returns a random integer between 0 and 61 (62 is not included if im not mistaken) the for loop iterates x times (however long you want your string to be.) Hope this help!
Thanks! the problem with adaptfilt is that it's wrriten for Python 2 :/
I didn’t try to understand the rest of your code but I think you are just missing parentheses around the variable. You are calling a method. file.write(beshleunigung_zout_skaliert)
Given that you are confident you want to go with Lambda, Zappa currently has a more complete feature set and more resembles traditional Python workflows, so I'd recommend that.
Change requests.get(row[0]) to requests.get(row[1])
Sad. Here's another. Not sure if it's actually valid for 3.x, but it's got tags for it at the bottom of the page. https://pypi.python.org/pypi/speexdsp/0.0.1
If you do want to avoid MKL packages, `conda install nomkl` switches to openBLAS.
I would go with Tim Buchalka's course. Yes, the one which has 13 articles and 4 supplemental resources
It needs to be said though that MKL is still usually a bit faster than OpenBLAS, especially if you have a recent enough Intel CPU and an older OpenBLAS version (which is the case on most Linux distros at the very least).
Right, but conda packages don't link to (old) system versions of openBLAS, but ship their own, recent version AFAIK.
I'm actually not sure if they do on Linux, but they probably do on Windows. Then the important question is how it's compiled.
thanks for the reply, I changed the code and this is what i get: Beschleunigungssensor --------------------- accelerometer_xout: -4512 skaliert: -0.275390625 accelerometer_yout: 13412 skaliert: 0.818603515625 accelerometer_zout: 9220 skaliert: 0.562744140625 Traceback (most recent call last): File "gyro.py", line 49, in &lt;module&gt; file.write(beschleunigung_zout_skaliert) TypeError: expected a string or other character buffer object 
SMS interface.
Thanks guys This works! :)
It's static. Use a [light theme](https://themes.gohugo.io/blank/), [build your own](https://milligram.io), leave out anything non-essential. On a properly configured web server you can't get any faster.
file. write does not know how to interpret read_byte_data. Put it on str(). Like file.write(str(variable)) 
[PyZMQ](https://pyzmq.readthedocs.io/en/latest/)?
Thanks! This worked ;-)))
yes, it is one of the options.But i did not find enough examples for Publish Subscribe model. Plus, i did not understand their topic filter. It will be great if you have any additional resources on it.
Why does the PageSpeed score matter? If you hit 90/100, do your users care? Will the resources expended getting the extra 10 points pay off in the form if increased traffic, sales, etc.?
Did you make the Torrent2Magnet script?
Not at all. No way if I cant figure out a simple thing like that im trying. 
I think they do provide their own on Linux but it might be pre built. Installs rather quickly
Yup +1 for zappa
Good question! I guess if your are in a race to get a good position in google, then every detail matter. Doesn't it?
I’d spend more resources on more relevant content. 
Thank you, light theme has a very good results! I'll stick to it!
Regex?
Okay so here is what I did in the past. I'm a noob myself but know how to do what you want to do. So you need to get the list of the files in the directory (dir). So we need the OS module. import os Now where ever this script is located is the directory it will look in. So we will see all files in the directory by doing: files = os.listdir() Now the files are stored as strings in a list under FILES. Now for each file we need to check if it ends with ".magnet": fileNames = [] for item in files: if item.endswith(".magnet"): fileNames.append(item) That's what I got right now and I'm sick of typing this on my phone so start with this.
I have been using rabbitmq so far and it has been great. 
Thanks. Here's the [text version](https://tutorialedge.net/python/concurrency/asyncio-event-loops-tutorial/).
Please put a little effort into posting here. You should always read the sidebar of a subreddit which in this case explicitly mentions /r/learnpython for questions. And then you should format your post properly.
camelCase? I cry. Using the word parallel when dealing with coros is playing with fire, too. Otherwise nice and succinct. Obligatory: import curio async def my_coroutine(): print('My coroutine.') curio.run(life_made_easy) **asyncio is a tirefire**
You are right, sorry for making a mess in my hurry. You can delete my post if you feel like you should. 
Should be in learnpython and your code and variable names should be in english. 
Read /r/learnpython. Post this there. 
Oke, sorry...
haha fair! And that may be a slight faux pas on my part, it should say concurrent(ly)! curio is on my todo list though, I haven't had a chance to look through it yet but it has been popping up more and more recently! 
One key difference is that chalice helps also with coding, whereas Zappa only deals with deployment, as it expects a WSGI compliant app.
I don't know your full usecase, and this will probably be an unpopular opinion, but this is scaling vertically - and as you've seen, it isn't very effective. Especially in scripting languages like Python. Depending on your usecase, if you need to scale, you want to design things to scale horizontally. Use a queue system like [ActiveMQ](http://activemq.apache.org/) or pub-sub like [https://kafka.apache.org/](Kafka) to scale horizontally across multiple stand-alone processes &amp; machines. Changing your design to accommodate these technologies is non-trivial and might be a show stopper depending on your usecase, but scaling vertically in Python is a losing battle, it's not accident these high-performance multi-processing queues &amp; pub-subs applications are not written in Python. There is a correct tool for every job
If you want free help, take a couple minutes and make your question a bit more coherent and readable. If someones going to be doing you a favor, do them a favor and make the task easier for them. 
you mean how the code is presented ?
def bookstore (book, price): inventory = "the name of the book is " + book.title(), "and it will cost " + price return inventory book_entries = input() price_entries = input() both_entries = bookstore(book_entries, price_entries) print (both_entries) 
def bookstore (book, price): inventory = "the name of the book is " + book.title(), "and it will cost " + price return inventory book_entries = input() price_entries = input() both_entries = bookstore(book_entries, price_entries) print (both_entries) 
def bookstore (book, price): inventory = "the name of the book is " + book.title(), "and it will cost " + price return inventory book_entries = input() price_entries = input() both_entries = bookstore(book_entries, price_entries) print (both_entries) 
I currently maintain a small discord bot written in python. What is the big advantage of curio over asyncio?
[You don't need an extra library to do this.](https://www.youtube.com/watch?v=Bv25Dwe84g0&amp;feature=youtu.be&amp;t=21m30s)
Yeah, so what I was thinking was that by creating my map function like this: mapfun = functools.partial(f, x=somevar, y=somevar2) Then mapfun would be in a closure in main memory and somevar/somevar2 would be "copied" over with fork. However this strangely seems to not be the case. But if `f` just references them in the parent closure, then they do appear to be copied over with fork. I was curious as to why these were handled differently and was hoping to gain some insight so that I structure things in a better way in the future.
Your mistake is around `book.title()`. You follow it with a comma, which is invalid syntax. You want this: inventory = "the name of the book is " + book.title() + ", and it will cost " + price Have a look into [string formatting in Python](https://pyformat.info/) to avoid mistakes like this.
I appreciate your answering this, and wish you were not being down voted for your answer. I see python code like this frequently (or maybe it just stands out to me). But I’ve never understood why anyone would write something this way. I get that there are edge cases where this might be the most readable way to write a loop in python, but I often see it done in cases like this. My assumption is that there is some other language that people are coming from where this makes sense, but I’m BASIC -&gt; Pascal -&gt; youthful experimentation -&gt; Python and it has never made sense to me. Anyway, thanks for providing an answer. 
You didn't under stand what a topic is in pub sub? Are you sure you understand what you're trying to do?
You want /r/learnpython and you want to put your code on [Pastebin](https://pastebin.com/) so that it's properly formatted in your post
Can you tell me why you would use a break command in this case instead of putting a loop condition in your while loop? I am curious about your thought process, and would really appreciate it if you would take the time to explain. 
I meant the topic filter in pyzmq. 
Its about concurrency?
Look not to be rude but you can't be trying very hard then. socket.setsockopt.(ZMQ.subscribe, topic) And socket.send('topic ' + message)
Where are you from?
Just have to run it in another thread. 
Yeah, thanks. I will look again.
rm -rf this post
Interesting, thanks
1) module installing with windows is just as simple as in linux - you literally use the same pip commands 2) windows is definetely **not** the most popular platform 3) programming under windows is generally shitty unless you use an IDE. Did you try PyCharm? (It can install modules too!)
Lol. Don't blame the language for the operating systems failings. Use what works best on windows if you're having trouble with Python. Or look into using a Linux vm. 
rm - rf --no-preserve-op
windows is by far the most popular platform outside of the developer community. (aka the most popular.) pip install only works with modules compatible with PyPl. I tried IdleX and anaconda.
I just dont understand how all the other languages ive used seemed to take windows users into consideration, but its almost as if pyth devs decided 'ah screw it', as if its an obsolete OS.
The brave Scotland!
Based on what data is windows the moat popular?
Yes because everybody wants to relearn an OS in order to then learn a scripting language. Get a grip buddy, completely alienating windows users is the biggest downfall of python and a valid topic of conversation.
https://en.wikipedia.org/wiki/Usage_share_of_operating_systems https://en.wikipedia.org/wiki/File:Operatingsystem_market_share.svg Oh you know, simple google.
`random.sample(charpool, 10)` probably makes more sense here /u/Ballsdeepcryptobro 
This statement is absolutely not true. I've been developing with Python on Windows for more that 15 years and let me assure you it works perfectly well there. You are ranting, not asking for help and that is fine. And I really don't care if you "f***k Python" or not but I would strongly recommend looking at Anaconda distribution, especially Miniconda that let's you start small and grow from there.
Simplicity and speed - so everything really.
Thank you so much
I already have anaconda, which only equips you with a minimal amount of the most popular modules. The module im attempting to install is mpl_finance which isnt part of the PYPI so I cant use pip install, and the extract process during the manual install went to shit. Im ranting for good reason lol. 
But what happens if i want to communicate with some server?
There's a python program that automatically converts atleast common syntax to python 3, but i can't remember what it's called right now :P(not that it is guaranteed to work anyway..)
R is good for finance stuff i would assume. But you are right, if i used that hideous os i'd be lost too if a module didn't install. maybe. :)
That doesn't allow repeats.
I want a 'smert' bot i can talk to and have him do stuff for me on my computer(especially launch scripts for me). I use linux and i want him(actually it would be better if it was a her) to be lightweight and petite and not hog my cpu too much. Can you help me good sire?
If you use requests and beautifulsoup you basically only need requests.get, and with beautifulsoup .find_all and .find methinks. Well atleast i did for a relatively complex webscraping prog. (i did go through the whole beautifulsoup tut though). Remember when matching on a class use "class_".
 def palindrome(word): return word == word[::-1] No clumsy iteration or index lookups needed! Sure, it's less efficient for long strings - but unless I have a specific reason to prioritise performance, in Python I prefer to write concise and idiomatic code. (otherwise, why use Python at all?) 
good point
Not the author. Just stumbled upon this and it looks really interesting! Will definitely play around with it in the near future.
My program is not what you're looking for, haha. Look [here](https://github.com/sukeesh/Jarvis)
By what means? If you want to do http stuff I wrote a lib for that: https://github.com/theelous3/asks Works with trio too. If you just mean straight up sockets, curio has sockets. If you want to do websockety things look in to the sans-io wsproto and wrap it with curio.
What errors?
When you run the program. It runs into like 3 errors
You aren't explaining how to run the program. Give us test cases and error dumps. You should find the error message specifies what line the error is on.
Awesome content!!!!
mqtt
A poor craftsman often blames his tools.
Hmm OK, so you try to install a package that is not on PyPi. I've just googled the name and found it on Github. Yes pip can handle that directly from the command line pip install git+https://github.com/matplotlib/mpl_finance.git The command will work assuming you have Git for Windows installed. If not then one can download the zipped repository, unzip it, cd into the directory and run pip from there: pip install . Luckily this particular package does not need C extension compiled so it will just work. If there is C extension involved the installation may become more complicated but still feasible.
You'll probably get nothing given this is the wrong place. Try r/learnpython or something like that. 
I'm not trying to defend op and I don't totally agree with his issues. Nevertheless, to all the guys who say to just use pip, this page https://www.lfd.uci.edu/~gohlke/pythonlibs/ exists and is popular for a reason. And this repo contains mostly modules which are available through pip but at one time or another would only give you problems when installing there. Most notable I'd say is pyqt.
I've been using asyncio for moderately sized projects recently and it's been an alright experience (I wouldn't call it a _tirefire_). I mostly work with sockets, HTTP requests, and Redis using it it. Would it be a ton of effort to switch from asyncio to curio? Would it even be worth it? It doesn't appear to be very stable or anywhere as popular. But I do respect David Beazley, so it's got that going for it.
You might want to consider something with [Slack](https://slack.com/). The barrier looks pretty low for dev integration.
I've never had an issues with stability. It's very, very solid. Trio is very much like curio but aims to be not just a playground, taking the core design principles of curio and making them production ready. Yes, it's absolutely worth the switch. No more callback nonsense etc.
Doesn't bother me any, votes help determine the best answer usually in cases like this, and indeed they have. I know I personally would like to see the most concise version of a correct answer at the top when looking for help with something. The downvotes though.. can't really explain that, my answer was correct albeit not the shortest version.
Sorry It is a word game similar to scrabble. A user gets random letters from computer and he has to make a word from it. He gets points if he does so correctly.
/r/learnpython 
I ran it a few times and I only found two errors. n/3 returns a float so you can't use it in a range() and your print statement at the end of the game has a closing parenthesis in the wrong place. If you have a third error you are going to have to explain it to us.
THANK YOU
oh ur so witty
 import random secret = random.randint(0,100) guess = int(input("make a guess: ")) print() while guess != secret: if guess &gt; secret: print("Too high!") elif guess &lt; secret: print("Too low!") guess = int(input("make another guess: ")) print() print() print("good guess!") 
So, first of all: Next time you approach a programming problem, write down the steps needed to solve the problem in simple english or pseudocode. Don't think about what you'll need to write in Python - imagine you are explaining the steps needed to solve the task to a toddler. For example, in this problem, you would explain it as so: 1. We generate a secret random number (you did this) import random secret = random.randint(0,100) 2. We allow the user to input their guess. guess = int(input("make a guess: ")) 3. If the users input and the secret number do not match, go back to step 2. Otherwise, go to step 4 while guess != secret: if guess &gt; secret: print("Too high!") elif guess &lt; secret: print("Too low!") guess = int(input("make another guess: ")) print() 4. Since the users input and the secret number match, congratulate the user. print("good guess!" ) That's really all there is to it. No need to involve dictionaries, for loops or any of that. 
Sorry I should have stated that I wanted to count how many times the user guesses the same number lol. Say if the user guesses 30 three times, an output should look like this: make another guess: 30 You have now guessed this number 3 times!
Looks like you already converted your input as an int into "guess". So you don't have to parse it as a string. Juste do your operations directly on "guess". Still don't quite understand why you need a dictionnary for..
Ah, I see. Then all you need to do is remove the line starting with "for" and fix your indentation (the spaces before each line of code). The for loop is pointless lol
Fixed code
They want to count the numbers of time a user guesses the same number, lol
fixed, I think?
So.... What are you torrenting?
I've barely learned even the syntax for python (26% on codecademy) but "clever programmer" on youtube said c and c++ were best for finance stuff as they are really fast compared to others.
Hey, that looks really nice! Good job on the design
That's pretty cool, do you store the comments? If so will you expand on the idea by analyzing the data? I'm new here btw
Wow, thanks! I knew of Slack but did not realise the depth of its API. Looks like it has a ton of features... websocket connection, message formatting, buttons and menus, images, files... and an Android app!
2 solutions: - build docker image - use internal pypi repository such as Nexus
Some NBA data analysis...every week using beautifulsoup I scrape each team's win/loss, points scored/allowed, and calculate expected wins using Pythagorean win expectations. I graph the week to week change as well and compare against my preseason predictions. 
&gt; pick up any magnet link in a dir Google "how to list files in a dir python" &gt; read the file Google "how to read files python" &gt; delete the file Google...you know what, you should get it by now. TLDR: you didnt even try. 
Update: I've improved the app in several ways to handle a wider variety of images and generally improve the outputs.
yeah but thats no fun.
Thanks! I have experimented with storing it in a SQLite database, but haven't actually started storing the comments yet. I think doing things like sentiment analysis or making chat bots with it could be done. I also want to make it more interactive and post-specific steaming too 
 with Pool(processes=None) as p: a = dataframe1.values[:] a.setflags(write=False) b = dataframe2.values[:] b.setflags(write=False) mapfun = functools.partial(my_fun, a=a, b=b, c=100) 
You're right, have everyone do your work for you and party on.
You could also rank words after frequency of use
Trying to be a bit more constructive here. What do you mean with a "minimal amount"? Anaconda provides a very large number of packages in its repository, and there a hundreds more available from other channels such as [conda forge](https://conda-forge.org/feedstocks/). Did you not find a package you needed in there or what was the problem when you tried to install it? 
It's a livin!
Why would you just share a random page?
How does incorporating Python into an Erlang system affect reliability?
Good lecture, terrible answer.
Your problem is in `for char in guess:`. If `guess` were a string, this would work - but it is an integer. You cannot do `for x in an_integer:`, integers just don't work that way.
You want to calculate a hash value for each file in a directory? Do you plan to work recursively on subdirectories? What do you plan to do with the hash values once you have them?
How are you making sure you aren't getting trash/ viruses 
In python, integers are arbitrary precision.
 for i, t in zip(range(3), "ABC"): print("Title {1} subtotal: ${0}".format(i, t))
2to3 ?
Eww. 
My favorite new feature is the export to JavaScript for matplotlib animations. Comes with a player and scrollbar. Very exciting improvement for animations. I am also excited by the new voxel feature. Imagine plotting the probability distribution of Hydrogen orbitals etc in 3D as a heat-map. Such illustrations aren't very common. 
How programming has changed. This is a computationally expensive algorithm and there's no native code implementation. It's n^3.
trying to learn genetic algorithms and use that to solve a maze but I am so lost. Online resources seem to be scarce on this topic. 
So what i need to do is hash every file within a specified folder and subfolders, then produce a list of MD5 and SHA1 hashes for each and have them exported into a .pdf file
Have you considered something like Linux system administration?
I have actually. Do you know what companies might be a good fit or specifically what skills a Linux System Admin is looking for? I'm pretty good with Docker FWIT.
Scraping Amazon gets you banned for a bit unless it’s just one search result or anything simple. Tried to set up a scrape that audited our Amazon product pages at work that grabbed all the info on the page to make sure it was correct. But if they sense a pattern you will get dropped. Tried cycling through proxies and a delay before each new product but eventually they would ban you. 
i have checked it. Its great. Thanks
Seems it implements it as a 'remote' node, meaning it will run each on it's own memory space and process. So as stable as each system is...?
So does it benefit at all from erlangs fancy stuff like service monitoring or hot plugging code or the erlang db?
I have tried paho-mqtt with mosquitto, and i have looked at the basic pub-sub model provided by pyzmq. As opposed to mosquitto system, ZeroMQ - pyzmq doesn't seem to have a broker. In ZeroMQ each publisher simply broadcasts the messages and the subscribers receive all the messages and then filter only those messages with the topics they are interested in. This seems to add additional overhead on the subscriber side.
SpeexDSP might be a good library, but it seems impossible to tell: I haven't found any docs in human-readable format.
Re `2to3`, for many modules it's enough. But for any sizeable code base, it's a good start, but there's often more work to do before the code runs correctly as Python 3.
Not true for servers: https://en.wikipedia.org/wiki/Usage_share_of_operating_systems#Public_servers_on_the_Internet **on the same page you are showing** AFAIK more people use stuff like python on servers, Reddit does
Wow, thanks for the feedback. I wonder why setting the `write=False` flag made such a difference? My original code didn't try to write the dataframes at all. Perhaps under the hood, something is modifying their state when they are used? The only reason a copy was necessary was so that a separate object could be made write-only, correct?
I use Windows and python. It's not that hard. Just use Anaconda. No need to be cranky.
Good packages use pip. You're using a package you probably shouldn't be using.
Check with the payment processor if there any regulatory requirements that apply to epos. They will require you do certain things which may affect your decision.
THIS ^ I am an environmental scientist and also a member of ASA; I can tell you that the package list alone makes R worth keeping around but working with Python is...well, so much more fun. In a perfect world, I would have every R package function list built into Python but, in the real world, I NEED them both.
Thank you for the feedback but I forgot to mention that it is only a side project that needs to accept cash, no need for any electronic payment system
It has just been implemented in Python 
If you read the thread you would realize I need a mod that isnt supported by anaconda. Thanks, bye.
what a baseless statement
The nature of the site is wiki. It relies on C programmers to provide examples. 
No. But it means Erlang systems can benefit from all pythons fancy stuff like tons and tons of libs.
[Kivy](https://kivy.org/) is great if you're expecting to use a touch interface. 
QT is still the best for GUI programming on Python at least for me.
There are three ways to plug external code into Erlang. A NIF or linked-in driver is running as a part of the VM and a mistake or error condition in the code can crash the VM so this brings the speed but is the most dangerous option. A port is its own process connected to the VM via stdin/stdout and if the port crashes the VM can restart it. A node is its own process and can be communicated with in the same way as all other remote node communication, but you would need some other supervisory system to handle node crashes and restarts. The main difference between Python as a node vs Python as a port is that in the latter the VM running the port handles all of the Erlang messaging bits while a node does the messaging itself. 
At the end of the day I'm no mathematician, and I've intentionally forgotten most of the Perl I was forced to learn -- briefly -- by a sadist. I also don't have Excel on my phone, or any meaningful way to see your problem, but... If I read your perl correctly -- admittedly this is unlikely -- you're mixing fixed precision floating point with Bignum ints... your initial seed is 4*atan(1,1), so an approximation of an irrational which has already incurred a rounding error... how could we expect the results to *not* magnify that initial imprecision? Python can do arbitrary precision ints, and arbitrary precision decimals (**decimal.Decimal**), but if you start with fixed precision in the mix I don't know how it wouldn't go wrong.
I wrote https://github.com/therve/twotp as the same idea a long time ago, though limited to use Twisted. It's interesting that esl is looking into something like this. 
It's almost as if programming has changed and we're no longer favoring C.
"So, wait... *how* did you get hit by an elephant?" Admittedly, I've got a strange resume.
Thanks for your reply! Another comment suggested Slack which I think is a much better fit for my purpose so I will go ahead with that.
If /u/KimPeek is right and you want to check out 188 million websites with that technique, it would take a **little** too long. The time for one successful requests takes roughly 100ms. So if all 188 million domains exists it would take roughly 0.6 years to check them all. If you are unlucky and you have to deal with timeouts (usally 500ms), than it would be roughly 3 years. If you are lucky and it will take only 25ms per request it should take roughly 54 days. This alone means you'll need additional infrastructure like a server and a database, to store results in case the server crashes and you don't want to lose the stuff the script already checked. Other techniques like multiprocessing or asyncIO can increase that process time heavily but don't expect wonders.
[My blog post](http://takluyver.github.io/posts/so-you-want-to-write-a-desktop-app-in-python.html) is somewhat dated, but still more or less accurate. Tkinter is fine for a simple app if you don't care about it looking modern. Qt can do modern looking desktop apps, while Kivy is good for touchscreens. You can also use HTML for a GUI inside the browser, which saves a lot of time if you already know about HTML/CSS/JS.
This is an alternative to specifying a serialization format that the two processes connect with, such as Protobuf, and using TCP sockets or erlang ports.
Down-voted for the uninformative title ("Help needed", really?) and not reading the side-bar first. Up-voted for actually providing correctly formatted code. Well done! So I guess they cancel each other out.
Down-voted for the uninformative title.
Are you just sharing, or did you have a question or observation? 
Down-voted for the uninformative title, and failing to read the side-bar first. Up-voted because you gave me an excuse to mention the [`secrets` module](https://docs.python.org/3/library/secrets.html#recipes-and-best-practices). So I guess they cancel each other out. import string import secrets alphabet = string.ascii_letters + string.digits password = ''.join(secrets.choice(alphabet) for i in range(8)) 
If this is supposed to be secure (say, for a password), or some sort of security token, you should use the [`secrets` module]((https://docs.python.org/3/library/secrets.html#recipes-and-best-practices) rather than `random`. `random` isn't cryptographically secure. 
Given that there are already so many other shells, why another one? 
Came to complain about the video tutorial, stayed to up-vote the text version. Thank you! 
https://www.reddit.com/r/commandline/comments/7c3f9f/osh_02_parsing_one_million_lines_of_shell/dposm7r/
Thanks man! It looks pretty good - documentation and code is easy to read and follow. 
Well you can certainly use the Erlang db via the protocol in the other direction. This project allows Python to call Erlang code and vice versa.
haha thank you, im really new to this so i don't understand most of it but im getting there
Ubuntu is pretty common. I'd look into startups that look past degrees and leverage DevOps as your foray into a Django company. Then use that experience to learn Django on the job.
Finding a good devops engineer is really really hard. At least in Silicon Valley. Lots of people with no interpersonal skills, lots of people with no technical skills...its super frustrating. Ubuntu and CentOS/RHEL are both super common, and honestly if you know linux, you know linux. Differences in how each distro dies specific things isn't as important as learning how your company/group expects you to accomplish the task. And if you know one system then you're a 5 minute search away from the answer in the other. "What is the X equivalent of Y command" gets you far. Devops folks tend to be either software guys with an interest in ops space, or ops guys who can script/code a bit. Pick some daily tasks you have and learn to automate them to the greatest degree that you can. That's not only a good head start, but will give you solid answers when you're interviewing about how you can improve life for everyone on the team and give real world examples. A "5 minute" task is more like 20 when you factor in context switching and interruptions and having to redo it if you fat finger something. The return on automating small tasks away is wonderful. 
Sharing. 
You know, I was a little skeptical going into that essay, but now I see the light. It made me remember all the things I've come to live with while learning my asyncio ways. But now that I ditched all the asyncio workarounds, I'm finding myself needing curio workarounds. Waiting for multiple tasks/events is still not great (but now I also have to create a TaskGroup), no way to set an event from a sync function (which is basically a deal-breaker for me, not sure how to work around that). I see that trio fixes the latter, but I'm not sold on it apart from that (all that nursery stuff feels eerily similar to getting/passing event loops around in asyncio, but somehow more annoying).
What has this to do with python? You can do it with a shell oneliner $ for f in $(find . -type f); do openssl dgst -md5 $f; openssl dgst -sha1 $f; done &gt; hashes.txt store the output in a text file and convert to pdf if you really want (but why would you)
kodi plugin for subtitles from titlovi.com website https://github.com/tturkalj/kodi_titlovi_com similar plugin already exists, but this one will be official
Or you know, we basically do such things to each other constantly since we both study IT.
I write a program for my father, who works at a hospital, that helps him store data about different medications, specifically how these interact with each other and if they can be used simultaneously on one patient. You can find it on [GitHub](https://github.com/jfde/medications-tool)
It is about mutability! A tuple is immutable so no can change it during runtime. You wouldn't need to make sure that no one changes it but a list or other mutable data structures might change the data during runtime. The logic that deals with the threading doesn't do any introspection and is just very cautious so it just locks access to it while a worker is using it. Just a guess but I think in the second example you just circumvent this behaviour which can lead to devious bugs. So it did fix your problem? Awesome! :) 
Hey thanks!
Many of those sites will have response times greater than 1 second. To accomplish this in a reasonable amount of time will require multiprocessing and an async request library used together. Even then, you are still looking at about 1 week to finish this. I'm not going to write that for $10.
I've been a huge fan of the typing work going on in Python 3, and I wanted to create something that could take advantage of it to help with code correctness while being useful and not getting in the way. For anyone concerned with the automatic casting, there's another class StrictObject that doesn't cast. I'm thinking maybe this should optimize out to just assign under the right conditions, but right now it throws a TypeError.
I've resubmitted this with a better title. I hope that's acceptable. I've been a huge fan of the typing work going on in Python 3, and I wanted to create something that could take advantage of it and be useful without getting in the way.
I watched the Nova documentary "Fractals - Hunting the Hidden Dimension" on Youtube, and was interested in the story of a computer graphics engineer at Boeing, Loren Carpenter, who created the first computer-generated mountain landscapes. He did this after reading Benoit Mandelbrot's book about fractals, and created the landscapes by diving them into progressively smaller triangles. I tried out the idea with a small Python script. To set up an easy coordinate system, I used squares split diagonally into right-angle triangles, which could be split into smaller right-angle triangles with random elevations. That's somewhat imperfect but is enough to test the idea. I used the "Mayavi" Python library for 3D visualisation (since it was in the Ubuntu repository) to display the result. I thought this group might be interested in the result. My test had just 20 lines of Python. [Code on Pastebin](https://pastebin.com/xfyxWWk5) [Code on Github](https://github.com/dafarry/python-fractal-landscape) The image shown was generated with "random.seed(6)" added. Rotation, zoom and background colour were set interactively in the Mayavi visualizer. The Python code was dashed out as a quick test, so the method of finding the correct corner points in the correct order is not very readable. Sorry about that. After writing this test, I Googled for the algorithms usually used in fractal landscape generation and found out about the fractal terrain "diamond square algorithm", so if you want to know more about this subject, then I suggest you do the same. 
I dont know how i would use this or if this is any good, but i kinda like it :) 
Very nice man !!! Have never heard about Mayavi before, thanks.
I'm glad you at least found it interesting (and read it at all!). I won't claim that either of them are perfect. I think, however, considering how very strong both curio and trio are - both of which are really just side projects - it shines a lot of light on the state of python's async/await. There were clearly a lot of conversations that needed to happen before we put something in the stdlib beyond the bare syntax, that never took place. I hope the proliferation of the *rio async libs, and their less restrictive approaches to api design can in the long run make up a lot of the ground we lost by throwing the first thing that worked in to stdlib.
This is really cool!
&gt; I'm not going to write that for $10. This is pretty clear, 10$ is a joke in many regards. Just wanted to show OP that his *simple* tasks isn't that simple.
I can imagine using it for more artistic applications, or maybe even game development.
I remember watching a documentary on fractals and they had this game designer on who figured out you could use them for stuff like this.
Honestly, Linux SysAdmins run the gamut from small to large companies and a wide range of roles and skills. You'd have to do that research yourself and see what in particular interests you. I'd start with something [like this](https://www.reddit.com/r/linuxadmin/comments/2s924h/how_did_you_get_your_start/cnnw1ma/) to see how up to snuff your skills are and short them up a bit. If you want a more guided learning experience, there's always linuxacademy.com. Python is a good scripting language for Linux, so if you know / get to know Linux and Python relatively well, Docker, package management, etc, you're off to a good start. I'd probably throw databases in there, too. But again, beyond that, you're looking at the specific needs of a company. You should be able to go back and forth between Ubuntu or CentOS (RHEL) if you know one or the other well. As someone else said, Linux is Linux. There are some differences, but not enough to be that big of a deal.
I think machine learning.
Good passion, but I immediately stopped watching this video after he assigned to the built-in `list` function his list literal. Maybe it's a bit nitpicky, but if you're going to create a video like this which seems intended for beginners, you shouldn't show bad habits like assigning over built-in namespaces.
That sounds like a few lines. import random with open(filename, 'rb') as f: data = f.read() nbytes = len(data) slot = random.randint(0, nbytes-1) replaced_val = random.randint(0, 176) data[nbytes] = replaced_val with open(filename, 'wb') as f: f.write(data) Enjoy ruining your file. It'll even put characters in there.
&lt;sarcasm&gt;*grave cross placing tutorial*&lt;/sarcasm&gt; 
Name a package that you use that isn't on pypi. Numpy, scipy, matplotlib are and they're complicated. Every try to build scipy on Windows? It's not fun. Vtk is really close to being on pypi, but as I said probably. It's a sign of quality.
AFAIK anaconda packages ship with its own binary library dependencies (even on OSX / linux). Many people view this as a pro (i.e. it's easier to install), but I view this as a con (I DO actually want the dynamic system-level library on linux)
If you were to actually state your problem..I don't know...in the blurb at the top, people could help you. Instead, there's a giant rant about Windows and Python. Ignore...is he to the question yet...no. oh my bad, I had to read his comments to find the actual question. I've been using Python on Windows for 12 years and I find Linux much worse. On Windows, people expect it to work. On Linux, peple fix it themselves and then send you a patch. Try installing your dependencies without root access on a 6 year old LTS OS. Then complain to me about Windows and their everybody's gets to be admin policy. Did you try asking the devs? No of course not because you expect it to work. It's not a python problem. It's a package problem.
Yes, it's a tutorial and people expect these things to be correct. Besides that, I found this tutorial to lack any depth. Don't get me wrong, I appreciate your efforts to educate. But this entire video can be shortened to a couple of sentences. 
Impressive! Did any renderings come out looking weird or do they all look as good as this?
"'Bytes' object does not support item assignment"
&gt; The module im attempting to install is mpl_finance Which is no longer part of matplotlib and unsupported according to the github page. So they are literally telling you ahead of time that you are on your own with this one. &gt; which isnt part of the PYPI How is this python (the language's) fault? &gt; and the extract process during the manual install went to shit AKA. I had a problem but am too dumb to actually fix it or ask for help so I'm just going to yell at the moon for a bit instead &gt; Im ranting for good reason lol. Not as far as anyone here can see
What are you thoughts on typet in comparison to `attrs`? I'm semi fairly invested in `attrs` at the moment, and certainly make use of its "frozen" and "hash" kwargs. Also (though I'm not **sure** what exact difference it makes to my classes), the difference of subclassing vs decorating is noticeable right off the bat. Also does it work out of the box with mypy? That's been a major sticking point for the time being with `attrs`, though I do know its on peoples' radar.
Good Point. Just keeping it as simple as possible.
You should just count the guesses. To do that you need to ask for a new guess INSIDE the loop. As it is you use a loop to iterate a single question. Just think about it, what does your while statement check, that could not be checked with a simple if-statement ? import random def guessingGame(): dictionary = {} secret = random.randint(0,100) guess = int(input("MAKE A GUESS: ...")) while(guess != secret): if(guess in dictionary): dictionary[guess] += 1 else: dictionary[guess] = 1 if(guess &gt; secret): print("TOO HIGH!") else: print("TOO LOW!") guess = int(input("MAKE A GUESS: ...")) print("GOOD GUESS!") print(dictionary) I think this is what you were trying to do. Please check what you did differently, or if I missed the point come back to me. Also I dont think reddit is the best platform to ask such programming related questions, maybe next time try stack overflow. 
cast the file content to a bytearray to fix that
I should add that `attrs` 17.3.0 has landed, with [auto_attribs](http://www.attrs.org/en/stable/examples.html#types) support.
I have no idea how to do that.
```data = bytearray(f.read())```
Works, but only last byte is destroyed.
Would it be possible to run this as a python script though?
That is an amazing project list. Seriously comprehensive. Anyone who has the drive to work through the whole thing would definitely earn some cred points from me. 
List it.
You should check out /r/proceduralgeneration
Here's a sneak peek of /r/proceduralgeneration using the [top posts](https://np.reddit.com/r/proceduralgeneration/top/?sort=top&amp;t=year) of the year! \#1: [Physics based creatures with exchangeable body parts \[WIP\]](https://i.redd.it/8sxxd1nu3b3z.gif) | [60 comments](https://np.reddit.com/r/proceduralgeneration/comments/6gwc0m/physics_based_creatures_with_exchangeable_body/) \#2: [I can't code so I'm making a map generator using only Photoshop actions.](http://imgur.com/a/HWXd0) | [52 comments](https://np.reddit.com/r/proceduralgeneration/comments/6vi3j8/i_cant_code_so_im_making_a_map_generator_using/) \#3: [Dystopian slums generator](http://imgur.com/a/uWRuc) | [20 comments](https://np.reddit.com/r/proceduralgeneration/comments/6gr4gn/dystopian_slums_generator/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/6l7i0m/blacklist/)
This is true (and I've added it to the post!) I hesitated adding this from the beginning, as I wanted to make the post accessible to people who have never done Python before, and have mostly done Java. 
Go for django. I think web development is best for freelancer
&gt; https://github.com/a1studmuffin/SpaceshipGenerator *unzips*
Ok, cool. Thanks.
The seed does not matter much, I could have chosen 3/10. It is the round-off errors accumulating over time that I am concerned with. Most seeds provide a totally different sequence but with same statistical distribution. 
I'm not going to do your homework, but consider where are you saving the sum of the calculations every iteration of the loop.
Related talk from PyCon Canada last year: using python to procedurally generate landscapes. https://www.youtube.com/watch?v=O33YV4ooHSo
Right, well because pi is irrational it's hard convert it readily a Decimal (except by converting from a **float**, so the precision is already lost) to come up with a good comparison in Python, so let's use 3/10, as that's something easily expressed in Decimal. from decimal import Decimal from math import sqrt def foo(seed): rt = sqrt f = 0.5 if isinstance(seed, Decimal): rt = lambda d: d.sqrt() f = Decimal("0.5") b = 10**50 z = seed for _ in range(10000): z = rt(4*z*(1-z)) return int(f+b*z)/b fixed=foo(3/10) arbitrary=foo(Decimal(3)/Decimal(10)) print("fixed:", fixed) print("arbitrary:", arbitrary) print("diff:", fixed-arbitrary) Now, if I run that I get: fixed: 0.453184265481 arbitrary: 0.330270107107 diff: 0.122914158374 With **fixed** being the result using **float**, arbitrary being **decimal.Decimal**, and **diff** being what I believe represents the accumulated rounding error. That said I can't really run your Perl, and I'm not sure I haven't missed something transcribing your code, and since we're starting with different seeds the values in your spreadsheet bear no relation.
It does work out of the box with `mypy`. `mypy` is a big part of my workflow, and I lurk in the python/typing Gitter channel to try to make sure that I'm interpreting the type hints in the same fashion. I'll confess, I actually looked into using `attrs` behind the scenes for a lot of the *Object* functionality, but it just didn't fit my use case. The biggest difference is that `typet` isn't intended to be a direct competitor so the feature sets won't be one to one. For instance, there's no equivalent to "frozen" in `typet`, although I could see a metaclass added in the future to do that. `typet` isn't just `attrs` with PEP 526 class generation. It's a type library that can be used for validating that your data matches what you think it should, without having to process it yourself. For instance from typet import Object, Bounded class Person(Object): name: str age: Bounded[int, 0:150] will guarantee that the age is between the values of 0 and 150 not because you've written validation logic manually, but because the the value of age will be cast to the *type* set on age that is explicitly bounded to those values. Incidentally, an instance of *Bounded[int, 0:150]* is just an *int*. Here's my take on the differences though: * `attrs` exists to remove the tedium of writing boiler-plate of common methods... `typet` exists to make using typing easy and beneficial. * `typet` is cleaner than `attrs`. It has the advantage of being newer and starting off with an expectation of having typing, and as such, the classes just look like basic Python. * `attrs` doesn't use metaclasses or base classes. If you happen to need your own metaclass, `attrs` will be simpler. I think the trade off of having all of your class attributes and methods decorated with `attrs` types and decorators isn't worth it. The types of the class attributes from `typet` are just properties. * `typet` handles type coercion for you. Objects created with `typet` *guarantee* that the values in the attributes are of the annotated type, even if the annotated type is from the `typing` module. * `typet` contains common metaclasses/base classes, like *Singleton* and *Uninstantiable*. * `typet` creates **types** for validation. I took inspiration for this from the `typing` module. * `attrs` is a solid project and is much better tested. `typet` is still a fledgling project getting off the ground. For production use, stick with `attrs` for now, especially if you're already using it. 
You should check out pyenv. No need to limit yourself to distro-provided libs or python builds.
This is very cool, thanks for sharing!
Re-wrote my discord bot from scratch this week. Old code was fairly sloppy as I was still learning the pythonic way. I'm extremely happy with the new code and even managed to add new functionality I couldn't figure out before.
Python, Flask, SQLite3, and Bootstrap.
try the ProxyCrawl API and get your data without pain. It worked good for me. https://proxycrawl.com
That's interesting. I wonder how they detect it. If you're scraping, you're just loading a page and them, seemingly, moving on. Any ideas?
How
I built this thing to help [Jeff Knupp](https://jeffknupp.com/blog/2016/11/13/how-python-makes-working-with-data-more-difficult-in-the-long-run/). The idea is that you define the data structure and then `datatyping` will verify that _some_ data conforms to said structure. &gt;&gt;&gt; from datatyping import validate &gt;&gt;&gt; validate([int], [1,2,3,4]) &gt;&gt;&gt; validate([str], ['a', 'b', 'c', 'd', 3]) TypeError: 3 is of type int, expected type str I hope you like it. There are more examples in the readme :)
Probably detecting whatever style web request the scraping is giving. Not sure exactly, but the scrape eventually stops working. You aren’t banned visiting the site in a regular browser afterward but the scraping program won’t work for a few hours. Also have a shorter leash every time you run it again, meaning you get banned quicker. 
Yes you can use the [subprocess](https://docs.python.org/3/library/subprocess.html) module.
&gt; You should check out /r/proceduralgeneration Thanks. Some interesting stuff there.
Thanks. Bookmarked.
I've added two more to my initial comment. Not weird as such, but with most of them, one edge or another would end up raised so that it was difficult to rotate it to a view where you didn't see an obviously cut-off edge.
Posts like this give me the motivation to keep learning Pyhton. Thank you so much OP!
what do you mean by performance? how quickly the page loads? I can't say I have any experience with using nginx + php, but latency between servers will probably be higher than application load speeds
Something useful you build for yourself and not for HR karma points.
Have you tried looking at the sklearn documentation? It is very good and there are examples of all the things you list there. Take a look and let me know if anything is not clear.
I expected this to be some sort of "I hate Python" [this] (https://eev.ee/blog/2012/04/09/php-a-fractal-of-bad-design/)
try /r/learnpython 
Writing a matchmaking service in python running on Linux for a video game I'm building in Unity3D. Libraries which I like: 1. PipEnv - Seriously awesome when it comes to deployment 1. BottlePy - easy framework, with a small footprint. 2. gevents - asyncio and https? yes please. (50,000 req/s) 3. NoSQL with MongoDB :) (free. but docs keeps trying to push you into the enterprise when you want a large scale, try your own hosting its easy!) Also, shout-out to Fedora dev's providing up to date python in their repo's this was a massive pain in other distros! Thanks to all the lib developers too!
There are a few things that putting a program on a website could mean: - Putting the code up for someone else to download and run (easy) - Running the program in Javascript in the browser of someone visiting your page (easy-ish with something like [Skulpt](http://www.skulpt.org/), but limited in what it can do) - Running the code on your server and showing the user the output. This is usually what people mean when they say that a website like reddit runs on Python, but getting it set up might be complicated if you're not familiar with the systems.
I agree, but I'm looking to impress them with a program they'd like to see too.
To quote Da Vinci: &gt; A poet knows he has achieved perfection not when there is nothing left to add, but when there is nothing left to take away. You can keep things simple while not purveying poor practice.
Different things impress different people. HR people are rarely qualified enough to tell how good the things you've built actually are. You can prove P=NP, and your average HR person will probably have no idea what it means.
I made a project like this in school about 20 years ago based on the mandelbrot book you mentioned. Another cool thing you can do is define a "sea level" and make everything below a certain Z render flat like a body of water.
You don't really need to use OpenCV for that. Can you post an example image you're working with?
My teacher wants that we used OpenCV :( http://www.albertomasa.com/wp-content/uploads/2017/07/maze_79__thumb1.jpg
Then look into [these examples](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_core/py_basic_ops/py_basic_ops.html), they'll tell you how to read out individual pixels.
yes i know, but How do I put all the pixels in a matrix? or go through the image?
Read the link I posted.
As some who has also done stuff with Amazon scraping, they use some sort of risk based model. Can keep scraping with requests for quite a while if you take long breaks between each scrape. Obviously this is not performant. Scraping with Selenium gives you a longer run, but they also eventually throw up a captcha page. This was literally scraping their search results over and over though. An actual crawl of the site with Selenium doesn't seem to get you banned, maybe looks close enough to browsing activity. 
I guess it was more in terms of channels; "intel" is (now?) higher priority than "defaults".
Yes, because MKL performs on par with or better than OpenBLAS on just about any modern CPU, including AMD.
What you're asking inclines me to believe you're not going to be serving 10,000 requests a minute. Therefore choose the one you're most productive in developing with. At small scale, developer time trumps hosting costs.
So... how did you get hit by an elephant?
Pandas is super easy to pull in web tables. This tiny snipped should handle what you need. import pandas as pd def get_stock_date(ticker): df = pd.read_html("https://finance.yahoo.com/quote/{0}/analysts?p={0}".format(ticker)) earning_est = df[0] #df is list dataframes - we are selecing the 1st on return earning_est get_stock_date("IBM")
So, the error is accurate, your calling for a global variable that does not exist, put droite = True above your functions.