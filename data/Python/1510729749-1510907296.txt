I try to avoid them as well, if you're just interested in an empty value - use None. If you want a default value, you're likely doing something wrong.
&gt;Extra brace FTFY
I think it means "there's an NNTP client in the standard libraries for some fucking reason".
PhantomJS is a headless version that I know of, and use :) 
They're namespaces that you want to attach to a blob of data because the members are tightly related to that kind of data. So It might be better to say: if you could do it with a module and there wouldn't really be any functional difference, do it with a module.
I see what you are saying. Classes are to organize data, not code, is that fair?
Hah! I'm in the same boat, pal. I've also got an ETA about the same as yours. I have no tips, only empathy. We're so close!
I think [the Wikipedia article](https://en.wikipedia.org/wiki/Code_smell) adds a *very* important point to this: Code-Smell usually indicates a larger problem with the overall design!
**Code smell** Code smell, also known as bad smell, in computer programming code, refers to any symptom in the source code of a program that possibly indicates a deeper problem. According to Martin Fowler, "a code smell is a surface indication that usually corresponds to a deeper problem in the system". Another way to look at smells is with respect to principles and quality: "smells are certain structures in the code that indicate violation of fundamental design principles and negatively impact design quality". Code smells are usually not bugs—they are not technically incorrect and do not currently prevent the program from functioning. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
You are waaaay ahead of me
Not quite as strong as that. Knowing the most common code-smells helps you identify weaknesses in the design of a code-base. It does **not** tell you that "This code is shit", which your comment implies!
Then I would argue that the `with` block is safer because there’s no way you can forget to close a file. And again, it’s Python, so you might was well use features of the language.
That's my experience.
Keep in mind Node.js is a web stack only so by switching to that you put yourself into only one career path. Python is a full language used for many other things outside of websites like Machine Learning, data engineering(ETL and data pipelines) and software development. 
You probably want to include a link to your website.
Not if you're happy with anaconda. On the other hand, you might find you don't need anaconda in the first place.
Why didn't you use an existing library? My mouse finds the cheese :D
yes but i wanted it to use diceware's logic for randomness (throwing a die etc.)
&gt; I was not even aware that lxml might have problems with the HTML5 spec. If anyone knows of anything more standard The simplest is to use html5lib (the "reference" implementation) and tell it to generate an lxml tree (`html5lib.parse(f, treebuilder="lxml")`). html5lib being pure Python it is, however very slow. I've yet to use it in anger, but html5-parser is built on Gumbo (Google's fast/native HTML5 parser) and can build lxml trees (does so by default in fact), so it seems like an excellent alternative to html5lib.
Ok awesome! Well thank you very much for the help you have provided me and thank you for the resource links. I will be sure to had a read and see if I can figure it out my self. 
One day, one day Arch will not be alone with python pointing to python3.
Hey there, you can surely running it in an oracle virtualbox, I tested mostly with it, running debian Jessie. Ubuntu should be no problem. Editing the .xinitrc file you should put on the exec line the kobowm.sh file, with the full path, that depends on where you put it. At this point you can use startx, it should read your newly modified .xinitrc and launch my window manager. If you got here you can still have a black screen in which case I would check the dependencies, but this is unlikely, most of the time if there is a killing exception the wm will quit and the x server will close showing you what happened. If you are still lost feel free to pm me, I will help if I can. 
"Banker's rounding" is the default rounding mode of IEEE-754, the default rounding of Decimal (see decimal.DefaultContext) and the rounding applied by Decimals' `exp()`, `ln()` and `log10()` methods. It's not the rounding people generally learn in school (that's usually half-up or half-away-from-zero) but it has the useful property of limiting the bias of the output e.g. if you have a set of random numbers between 0 and 10, rounding half up will increase the average by a fair bit, rounding half to even should not.
Just run 2to3.py and push to production. Ez.
Also wrt dict utility methods, `setdefault` is an excellent halfway point when you don't really want a defaultdict but don't always want to deal with KeyError by hand.
Let's be better than numpy and annouce 2018 **year of dropping Python 2 support**. 
Gentoo use Python 3 by default too. 
I often write the test before the code because I *don't* know the code, not because I do. But when I write the test, it forces me to think "what exactly do I want to achieve here?". The test helps point me in the right direction with regards to the code I have to write.
OK! So this is what I have achieved so far. I managed to clean the script up a little. My only question is... Is there need for all those def ? The script just looks excessively massive considering what it actually does... Is there really need for all that code? Is there not a shorter way to achieve that? Also... I managed to get it so you can only type numbers when it asks for age, but I am having trouble with only typing LETTERS when it asks for name... Could you give me any advice? https://pastebin.com/jJ2zFPfw
You have an else without an if, the try except, the continue and breaks are fine. Just need to do your validation. 
it's Debian alike. They adore Debian.
if s3, half of a internet is down :(
No you didn't say that. You dumb cunt XD
Nice point!
 tot = sum( value(i,j,k) for i in range(1,n) for j in range(1,m) for k in lst if flag(i,j,k) ) As opposed to tot = 0 for i in range(1,n): for j in range(1,m): for k in lst: if flag(i,j,k): tot += value(i,j,k) I really think the required tabbing with loops makes loops look like shit.
Linters are for coders who aren't pedantically careful and precise :-)
It must be great to work for a company that trusts the mechanical output of a bot more than the intelligence and experience of its programmers. 
&gt; "if len(myCollection) &gt; 0" reads far clearer than "if myCollection" Depends on the context, but I would say that in general, if you find the second less clear, then the chances are good that you're still not yet a Pythonista comfortable thinking in terms of duck-typing. `len(myCollection)` tests an implementation detail of the collection (is your length zero?) and assumes that all collections have a finite length which is cheap to calculate. `if myCollection` simply duck-types the idea of truthiness, and asks the collection itself, are you empty? - an infinite collection can report "no" without having to count an infinite number of items; - an unsized collection can report "yes" or "no" (or perhaps Maybe?) without trying to call a non-existent `__len__` method; - a collection with an inefficient `__len__` doesn't need to painfully walk the entire collection counting items (that's O(N) behaviour); - if myCollection can be `None`, it just works; but on the other hand: - if myCollection can be something like a float or some other arbitrary object, you may get an exception in an unexpected place instead of where you expect it. Over all, I believe that `if myCollection` wins. 
&gt; This, but you don't have to be a stickler about the 80 char line limit from PEP8. We have wide screens these days. I find 120 chars to be a nice number. The 80 character limit has nothing to do with the width of the screen. It has to do with readability. Something like 70-90 characters is the upper limit for maximum readability, beyond that it is harder and slower for the eyes to track across the line without error. You can probably get away with it if only a small proportion of lines reach 120 characters, say less than 10% of the code and no more than four in a row, but if you're reading code that regularly hits the 120 character limit, your reading is probably suffering, and the code probably sucks. But then, if you're regularly hitting 80 columns, the code probably sucks too: - too many deeply nested blocks; - excessively long names (not every method should be called "doit", but neither should they be called "[DoTheSameChangeInShopThenDoTheSameChangeInInventoryForNotChangedDataInInventory](http://thedailywtf.com/articles/CodeThatDocumentsItselfSoWellItDoesNotNeedComments)"; - too many Law of Demeter violations (some might say even one is too many); etc. Wide code is a code smell. 
&gt; How many people develop with a single ≤1920x1200 monitor? Not everyone has the money and room for multiple large monitors. Or would want them even if they had them.
&gt; 80 is pretty extreme. 80 chars is not extreme. Its the long-held standard for email, for example, and is about 30% longer than the typical character width of books. (About 60 characters, including spaces, according to my very quick and totally unscientific survey of books I have at home.) 40 characters would be pretty extreme.
Milksteak?
That's awesome! We weren't allowed to use libraries besides math, turtle, and random.
&gt; If you're already using a try block... Be careful here: the intention of the `with` is to ensure the file is closed *if* it's been opened. When you say "if you're already using a try block..." that sounds to me like you're maybe missing the fact that you might, in fact, need *two* try blocks. This is not legit: try: f = open(myfile) # do something with f except: # some stuff finally: f.close() ... because if `open()` throws an `OSError`, `f` has not been initialised, so `f.close()` throws a `NameError`. Of course, you can fix it with: f = None try: ... finally: if f: f.close() but that's ugly and error prone (in my judgement). The point is that there's a difference between catching an error upon file open (which doesn't require a corresponding `close()` call, and catching an error after the file has been opened (which _does_). Before `with`, you had to do this: try: f = open(myfile) try: # do some stuff finally: f.close() except OSError: # deal with it Now, *if* you want to catch *all* errors (whether from `open` or in the `# do some stuff` block), you still need two `try` blocks; but if you just want to make sure the file is closed cleanly in case of an error *after* you've opened it, `with` will help you, and this is perfectly legit: try: with open(myfile) as f: # do something with f except OSError: # some stuff 
Tried it a few times, definitely did not work. Also, doesn't work on cython or 3rd party dependencies. I also can't just push to prod, production is an actual manufacturing environment producing products, and there are something like 50 systems out there to update. If they stop working or have problems we start losing money for every minute of down time, or worst case we ship products with defects and my team would get to take the blame. That would not be a fun day at work. 
So when I did this... https://pastebin.com/6yXGeAnB And I type only LETTERS... It makes the name "True"... and if it has numbers... it will make the name "False". So I am guessing I am on the right track. I am just tyring to make it throw an error instead of making the name true or false
He knows. Is joke comrade.
Also there's a difference between catching an error on opening the file (which OP asked about), and ensuring a properly opened file is closed. A `try...except` block for dealing with the first case can *not* just be turned into a `try...except...finally` block for dealing with both cases, so the notion that "if you're already doing a `try` there's no reason to use `with`" is misleading - see [this comment](https://www.reddit.com/r/Python/comments/7cs8dq/senior_python_programmers_what_tricks_do_you_want/dpup78a/).
&gt; IMO 80 characters encourages less descriptive variable names and/or artificial breakup of code purely to meet that character limit. You're right that this is sometimes a risk with 80 char limit. To some degree the fix is common sense: know when to break the limit, rather than mindlessly applying it. That's why Guido dislikes tools like pep8 and flake8, and I agree with him: they are [unable to apply the most important rule of all](https://www.python.org/dev/peps/pep-0008/#id15): "However, know when to be inconsistent -- sometimes style guide recommendations just aren't applicable. When in doubt, use your best judgment. Look at other examples and decide what looks best." My own rule of thumb is: - a soft limit of 79 characters, as per PEP 8, which acts as my target; - when I remember, and be bothered, a soft limit of 72 characters for docstrings and comments, also as per PEP 8; - a second soft limit of 85 characters: don't sweat the occasional extra few characters; - a hard limit of 99 characters (except as below). I don't sweat it if I need an extra four or six characters *occasionally*, but anything over 85 needs a good justification. And under no circumstances go over 99 chars unless it is a long URL or other token that cannot be broken. Now all I need is an editor which can actually enforce both a soft and hard limit :-)
Arch points to python 3? You've sold me on arch sir. 
No, it's not redundant, because OP was asking about catching an error raised by `open()`. This does *not* work: try: f = open(myfile) # do stuff except: # deal with it finally: f.close()
Having just "finished"[0] one such migration at $dayjob I'm not going to pass judgement any time soon. [0] quotes because we regularly find things which were missed during the conversion, or were mis-converted
Looks good. Have you tried the websockets API? 
[Context Manager](https://docs.python.org/3/library/stdtypes.html#typecontextmanager).
Ok so you are saying inputName, it should be input_name, again python style. Also your indentation is 2 spaces for some reason it seems, while python doesn't throw an error, 4 spaces is the python style. def inputName(message): while True: try: userInput = input(message) except ValueError: print("You cant have numbers in your name!") continue if userInput.isalpha(): continue else: # the else is for clarity, you don't really need it break return userInput
[Code Smell](https://en.wikipedia.org/wiki/Code_smell)
**Code smell** Code smell, also known as bad smell, in computer programming code, refers to any symptom in the source code of a program that possibly indicates a deeper problem. According to Martin Fowler, "a code smell is a surface indication that usually corresponds to a deeper problem in the system". Another way to look at smells is with respect to principles and quality: "smells are certain structures in the code that indicate violation of fundamental design principles and negatively impact design quality". Code smells are usually not bugs—they are not technically incorrect and do not currently prevent the program from functioning. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
Aaaaaagh!! Thank you so much. Yeaaah I cant seem to understand the indentations. I know that you need them because indentations tells the code which code block they belong to. But I just dont really understand where I should put them yet... But yes your code worked!! I just had to change if userInput.isalpha to if not userInput.isalpha ..... THank you so much!
Other than that you can do the same for the age input
Sure they are. I'm looking for _fewer_ requirements in my life--no, more than that, I want the *right* ones. Heck, I could stuff these services in Lambda, and probably work out some way to involve Ethereum. They quite well fit the model of a conventional Linux server (actually implemented as virtual machines, in most cases) endowed with standard packages, though, so configuration of virtual environments and containers and ... continues to feel to me like only a distraction. I summarize: yes, I certainly can virtualize and containerize and so on. For a production situation where my focus is on straightforward, undramatic Python source, supplemented by a few `pip`-able modules, do all those possibilities truly gain me anything? I don't see it.
Wide code is a code smell.
Because humans are human and can't read or see every line of code. It's the same reason people use spellcheckers and will miss typos if you just try to proofread by reading it.
You need to be more specific. What does "deterministic to True" mean? Are you looking for a flat list of all the items that map to true (and de-duped or with duplicates?), or are you looking for a list of groups? In other words, provide sample output for your sample input. But really, you're looking at inverting that data structure so that you have true and false as dict keys and the associated data as values. 
It will be great when Python 2 is not the default installed version on most Linux distros. 
Thanks, I have edited the post. But this is more of a theoretical question and I need some ideas.
That's such a contrived example, I have never had to do anything like this.
&gt; optional value which could be either set to an integer or None, foo &lt; 3 works in Python 2, it raises an exception in Python 3, if the value is usually set it may take some time for the error to happen. And this also holds for builtins relying on ordering, e.g. `max()`. Caught me by surprise :)
Yup, hence the note about sorting a list of dicts, sorting obviously relies on ordering.
Can you explain this algorithm in more detail? What is a "target"? Why does [Item2,Item3] have a probability of 70%? Why is [Item2] 50%?
This is a good example of sentiment classification, pretty easily done with Keras and/or TF. Of course, you'd need more data than what you have and it'd need to be more balanced than a 1:10 ratio for targets.
The thing is I'm not writing a book, which has to be printed on a page that's 1/2 the width of the smallest available laptop screen size. And books and emails don't often lose 15-20% of their character limit to structurally required indents. You also don't read code the way you read a book or a web page. So you don't have the same comprehension advantage to jumping lines more frequently. Lines and blocks are visual indicators of a change in the procedure in Python, so breaking up a single procedure into multiple lines can be disorienting and confusing. It's a standard written 16 years ago when 75% of display resolutions were lower than 1024x768 and a big desktop monitor was 20" The most important reason the 80 character guideline in PEP should be adjusted, though, is that it is so commonly broken and ignored within the community. That makes it an entirely worthless standard and is a huge indicator that it does not currently meed the needs of the community as it is today. I mean the PEP basically starts with a refrain on why consistency is so important in a community and that inconsistency should only be deliberate. So if the community isn't consistent, the style guide is not effective. Personally I'd prefer it were updated to dump the hard length limit due to the difficulty in there being an acceptable community wide standard, and simply lay out when things like bracketed data types should be split up, variable name lengths, etc. But in the absence of that it still should be updated to reflect the massive upgrade in display technology since it was written.
I've been working with some third party libraries this week that are written by an active development team with commercial backing. Unfortunately their python bindings are the weakest part of the project. Not only are they only Python2, they aren't exactly refined code; some classes are new-style, some are old-style and they redefine str and len to specific values in their 'hello world' demo program.
They also warn you about unused variables, redundant statements etc so there's that
why?
Thanks or your replying.
Thanks for your advice. 
Thanks0
I hope the python devs learn a lesson here and don't make upgrading so painful ever again.
Arch probably pointed to python 3 the day that 3.0.0 was released.
Well I have to disagree. *) Being more "pythonic" just for the sake of it is idiotic. That point alone just sounds so pretentious I almost stopped reading. Code needs to be readable, extendable, and maintainable. None of those requirements insist upon blindly following some language-specific dogma. *) The two conditions actually behave differently. Checking the length explicitly will raise an exception for a None object, whereas checking just the object will return false. More often than not, the former behavior is more desirable, since code should generally fail fast. *) Checking \_\_len\_\_ is not usually O(n). It depends on the implementation of the collection, and most if not all of the standard Python collection classes track the size in an attribute, so it's *usually* O(1). I'll grant you that this isn't the most obvious behavior, but still, an important distinction. * If the object isn't expected to always be a collection (like a float or something), you already have at best, unmaintainable code, and at worst, a bug, if the condition is relying on the assumption that the object is a collection. Again, checking length here catches that issue, checking the object directly doesn't. Read the PEP for this condition check. Even the author admits this lint check is probably not the best idea/needs to be rethought. It's just not a good warning, at all.
I thought 2020 was the PSF's End Of Life (EOL) for supporting 2.7 anyways. Maybe that's a goal that's been moved around, and the Numpy folks are drawing their own line in the sand here?
I and the rest of my team made this move last January, and no one regrets it. Tricky thing for me personally was situations where we had been playing fast and loose with character vs byte strings (which Py3 requires you to be much more specific about), but still wasn't a tremendous roadblock. 
I suggest taking a look at [sympy](http://www.sympy.org/en/index.html). Also /r/learnpython.
No, the 2020 EOL has not been changed - see [pythonclock.org](https://pythonclock.org), which is endorsed by Guido. Numpy is announcing that they won't release *new versions of Numpy on Python 2.7* after 2018; but they *will* continue to support the LTS version on Python 2.7 until 2020.
I think `joblib` is much easier to use than `multiprocessing` directly. The code is more readable as well. 
I feel a great disturbance in academia, as if millions of graduate students suddenly cried out in terror and were suddenly starting from scratch.
Fair point. But.... if your functions and methods are big enough that you can't tell that a variable is unused just by reading it, you are already in trouble.
## General * Don't write to `stdout` what you don't want as a print output of your program. Use `stderr` * Use `logging` to print messages for debugging. * Use the `unittest` library to test working code. It is much better than doing print statements for debugging, and also automates the process of testing. ## Data analysis specific * If you are doing any kind of numerical analysis I would suggest using the `anaconda` distribution. It is consistent across platforms. You can use its environment.yml file to define the exact environment. * `joblib` for parallel processing * If doing really large scale parallel processing on data use `pyspark`. Works even on your laptop. * Use pandas for reading data from CSV and other crazy formats. Try not to parse formats on your own, unless you created that format. CSV is not just comma separated, there are lot of rules for identifying a valid column entry. * Use `docstrings`. Allows for automatic documentation generation. 
What if the things you want to sum aren't numbers, but still support the `+` operation? For instance, you can do this: some_lists = [[1,2,3], [4,5,6], [7,8,9]] all_items = sum(some_lists, []) or: from collections import Counter some_counters = [Counter('abcd'), Counter('sdlkfj')] all_counts = sum(some_counters, Counter()) The default starting value for sum is 0, but it can be anything. Don't over-constrain generic methods just because they are *usually* used in one particular way. (Raymond Hettinger wouldn't like the list example, since he reports that summing lists is quadratic behavior, but I'm making a different point.)
Or they say "just use pandas to read that CSV". Sorry, I don't feel like installing pandas when there is a perfectly good module in the stdlib. *Learn the stdlib!!!*
Your picture is not enough to define the problem. In particular the equations, as pictured, don't include the definition of r_ij (though your code defines it as j-i, which I find dubious), and the picture doesn't define what N, i and j are. I can make a best guess that N is i*j, and that r_ij is a matrix of numbers, and that the two E_i are calculations over a given column of the matrix (excluding the entry on the diagonal), but that would only be a guess at what's not in the picture. (And if this guess is correct, then your sums are coded wrong -- but I have no idea if this guess is correct or not.) /r/Python is not the sub for this. You have some math problems you need to work out before even trying to think about programming.
If all I want to do is read a CSV, is it worth installing and learning pandas to do it?
By giving a default argument a mutable value when defining the phase, the mutable (lets say it's a list for demonstration) is defined at function definition time, not when you call the function. You're basically giving the function an attribute,but you're doing so implicitly (which goes against the zen of python). While there may be corner cases where this is desirable, 99% of the time this is not the intended behavior and the corner cases can be handled explicitly in other ways. There's a pretty good explanation of it here: http://docs.python-guide.org/en/latest/writing/gotchas/ 
I've definitely run into a lot of bytestring problems. Since we work with lab equipment they all communicate with ASCII bytestrings, and sometimes with just dumps of bytes for transmitting larger chunks of data. Getting these to work properly have been a royal pain in the ass. I do appreciate the advice, there are a few things in here that I did not know about (like `locale.getpreferredencoding`). As for testing, the only code that I have that is python 2 and 3 compatible is the code with extensive test suites. I don't deploy python 3 builds without it, because it _will_ be broken. There isn't a "maybe it'll work", it just won't work. As for `__future__` imports, we already require `division` and `print_statements` in every single module. I just set up a snippet in my editor that drops in a header with that included (along with encoding statement, legal header, and module docstring). If I could, I would enforce it on every commit but I don't have admin access to our svn server.
I don't really understand what you mean by synching since I also don't use envs. What does it mean?
Unless you are running tox and CI services. When I started playing with type annotations in a library that I wanted to support 3.3+, it blew all kinds of things up. :)
...also Linux desktop, nuclear fusion and Half-Life 3. Did I forget anything?
Thinkpad?
4k user checking in. I still gun for 80 but it's no big deal since vim ships smart wrapping via `set breakindent`
My understanding is that Dropbox has Guido van Rossum working for them full-time on making MyPy usable on their codebase and adding type annotations so that they can safely move to Python 3 without accidentally messing up strings/bytes somewhere or whatever. If you're doing a conversion of a large codebase without literally the creator of Python on your team, you're doing pretty well. (See e.g. [Guido's PyCon 2016 talk](https://us.pycon.org/2016/schedule/presentation/2266/) about what he's doing at Dropbox and why.)
All I can think of when I see this term is a Northeastern Pennsylvania regional paper company
Thank you.
oh nice, I had to test myself, thx!
Nah, desktop.
&gt; I've been working towards it for about 2 years now, off and on. I'm in the final push now. If anyone has any tips I'd by happy to receive them. It's too late for this, but you just used company resources to switch from one inefficient language to another. If you were going to port all your code base, you should have picked a target like Nim, D, Go, Rust, etc.
Pretty much. Especially due to Tensorflow not having Python 2.x support at all.
&gt; type hints can be great for medium to large projects (it's like testing, but free) It's also just a cosmetic change from Python2: http://mypy.readthedocs.io/en/stable/cheat_sheet.html
Yes, but is it representative?
&gt; Gentoo use Python 3 by default too. Stop spreading lies. $ python --version Python 2.7.14 
Last time I use gentoo, I got python 3
Lastime I use gentoo, I got Python 3
I've ported Perl to Python and Matlab to Python. Speed is rarely the most important factor.
This is just as absurd as [BioPerl](http://bioperl.org/) dropping Perl5 support in favour of Perl6. Only casuals would celebrate something like this.
&gt; Use the csv module for CSVs (you'd be surprised...) Would you say it's overkill to opt for using pandas to read CSVs from the outset?
That was a mistake. Python 3 was unusable before 3.3.
Thank you for your answer. Asking as someone that actually doesn't have a background in math, does it matter the definition of the variables? Aren't they just numbers? Shouldn't the equation be appropriate to receive any number as input?
DEAP is great once you get it to stop crashing because it doesn't respect variable upper and lower bounds after cross breeding. I'm serious. DEAP is good.
An example and a link to the module would be good. Nobody is going to know what you're talking about 
That's like asking "does it matter if they want x*y or x+y?". I'm not asking what the *value* of the variables, I'm asking how they relate to each other. It doesn't matter if x is 3 and y is 4 if you have no idea what to do with those values 3 and 4. That's the fundamental thing; code is meant to run individual numbers through those relationships, but if you don't understand those relationships in the first place, how can you write a program to calculate the output for a given input? You need to understand the problem before you can try and solve it. How do N, i, j, and r_ij relate to each other? You can't write code until you can answer that question.
Uh... sure. I thought it was obvious that this was the standard library? https://docs.python.org/3/library/heapq.html
We use the MAC address. It's great until you swap out the network card (so never) or switch computers or install the program on a virtual machine where you can set the MAC address to whatever you want. People will be pissed if their license doesn't work because they got an upgrade.
Well, casuals and everyone who’s been using Py3 and hates when they have to work on old Py2 codebases. 
Well, is not the relation of those numbers/variables given by how the equation is assembled?
You can emulate most of the Python 3.6 functionality with type comments, but it's not quite the same: - the syntax is uglier, dealing with imports is a pain, and linters mostly don't check them - they don't exist at runtime. This is a real disadvantage - tools from attrs to Hypothesis infer various features based on type annotations - useful types like enum.Flag only exist on Python 3, and backports tend to be conservative (ie work on 2.7 and 3.4+, instead of 2.7 and 3.6) - you're doing new work in a dialect that will soon be unsupported, when you could update instead and be much better off! 
Partially, but as my original reply states, not enough. The equations you show don't tell you what the summation is over, or how N relates to i and j, or how r_ij relate to N, etc.
I differentiated my example `sum` function from the built-in one because it's intended to work differently. Maybe it offloads the work to a GPU (although admittedly it probably wouldn't have quite that signature in that case) or otherwise does something to make it more use-case specific. The `new_group` function from my [other comment](https://www.reddit.com/r/Python/comments/7cs8dq/senior_python_programmers_what_tricks_do_you_want/dpszta0/) may be a better example.
Python is the perfect tool for our job. We do a lot of math, a lot of plotting, and a lot of desktop development. It's also all on Windows. While I love rust, it does not have the support we need on Windows, and until very recently cargo did not have the ability to point at an alternate package server. We use the Anaconda distribution and have an internal server, it's been a major boon for our development. If Rust had the libraries already that we need, then I would have considered trying to push for it, but it just doesn't cut it yet. Until there's a full port of pandas to one of those languages, I don't think we'd be able to even consider it. Also, Jupyter. We've done a lot of stuff in notebooks, and Jupyter consoles make up a significant portion of my development workflow. Not having a repl makes it difficult for me to get things done a lot of the time. At least a compiled, high performance language like Haskell has a repl, and even has a lot more of the libraries we would need to build our systems. Unfortunately, it just doesn't have enough. I don't know about Nim or D, those languages might be better suited but they're also harder to find people who want to work with it. And Go is not as suited for our style of development either. Ultimately, having an interpreted language is great for us, and when we need performance we just drop into Cython or use libraries like NumPy where the hard work has already been done for us.
And if N is 3.4 because you allowed floats? What if you run into division by 0 errors? Did you assume ij is swuare?
&gt;Before anyone passes judgement Anyone who does is a foolish idealist.
That's interesting. Can you enumerate exactly what I need in order to be fully able to understand the equation, if there's anything beside what you just mentioned?
Projects should be in virtualenvs anyway. And popular distros like ubuntu have shipped with python3 for a while. Virtualenvs make it harder to package code and for non-pythonistas to run it, but pipenv (the python packaging authority's official recommendation) is making that easier too.
Kill it dead.
I'm with /u/b1ackcat on this one. &gt; `if myCollection` simply duck-types the idea of truthiness, and asks the collection itself, are you empty? Well, not exactly. `if myCollection` duck-types `myCollection` and asks "are you truthy?" This works fine iff truthniness and non-emptiness are the same. If they're not, `if myCollection` will happily continue execution even though there's a serious bug in your code. That's not a good thing. Here's a fun example for you: &gt;&gt;&gt; a = (i for i in range(3)) &gt;&gt;&gt; a.next() 0 &gt;&gt;&gt; a.next() 1 &gt;&gt;&gt; a.next() 2 &gt;&gt;&gt; if a: ... print('non empty collection') &gt;&gt;&gt; a.next() Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; StopIteration Truthiness doesn't reliably map onto non-emptyness even for basic Python objects like generators. &gt; if myCollection can be something like a float or some other arbitrary object, you may get an exception in an unexpected place instead of where you expect it. Again, this is actually a good thing. If I have a variable that is a totally unexpected type, I want to get the error at the earliest possible point. If no exception has happened so far when this code runs, then I *want* this code to throw an exception. The performance downsides you mention are real, but they're not common, and the cost is a little bit of profiling and optimization once you realize you have a problem. Overall you're saving a lot more time by avoiding the duck-typing bugs than by avoiding the occasional optimization issue.
Those are good questions. I will try to address them in my code. Thank you. As for your last question, I assumed you guys would be able to help me because what I need here is to know if I've turned correctly the equation into Python code. Well, I actually assumed I didn't.
Hmm. I think psycopg2 is easy enough :P I can see how it would be useful in super corner cases or if you use tornado though.
py2 and py3 can run side-by-side. The default version of python has never been an issue. The only change is when you execute your script you type "python3". The first line of your script should also reference python3, however, if using python2, that should be referenced as well.
They learned that lesson before the release of 3. They said from the get go that this would be the only version with breaking changes do to poor assumptions made in the early days of the language.
Spam it so you can learn its use cases and limits more thoroughly.
Don't assume. Make some tests. Do it by hand first. Do simple tests and then harder ones.
I don't know what is the best as i tried a couple when i was somewhat of a bigger python noob and couldnt get anyone to work well. What worked for me was pulling historical data from an exchange and plotting it with matplotlib(even though this library doesn't know what intuitive means and i suspect pyqt would have been a better choice) and using talib directly.
I think that the main motivation is to provide a general purpose heap algorithm rather than a data structure. This way you can heapify any array-like object. &gt; This module provides an implementation of the heap queue algorithm, also known as the priority queue algorithm. Also relevant: &gt; These two make it possible to view the heap as a regular Python list without surprises: heap[0] is the smallest item, and heap.sort() maintains the heap invariant!
I would guess that this is some kind of energy calculation based on pairwise distances between particles, that `r_ij` should be the Euclidean distance between the positions of particles i and j (which is clearly *not* j - i), and that this is why the sum is calculated over all i and j where i != j. But seriously, OP, you need to show us the parts of the paper where all these values are defined.
I have no idea what we're missing. I don't even know where your picture came from. Did it come from a textbook? An academic paper? I cannot truly help you any further unless *you* provide *more* information to me and to yourself.
you do know which subreddit your in, right?
"heap queue" and "priority queue" are datastructures as much as algorithms. Failing to use an OOP interface doesn't change that. As for the other things, you could just make Heap a subclass of list (that or "pass through" all read operations and the write operations that preserve the invariant, either way would work fine).
That's also a very likely guess, indeed! Just highlighting the missing information of course :)
The default version of Python is most certainly an issue. A) it's the first python that many people will experience. When you type python in the Shell or tab complete, the system python will be the one the majority will go with. B) many companies will not deviate from the rhel/centos supported configuration. If that is python2, the company will stay with python2. So yes there's no technical reason you can't use python3 in a python2 distro. But there are several strong human reasons why it's necessary for distros to upgrade.
Back in 2002 somebody proposed the code to the mailing list and Guido merged it into python exactly how it was originally written. Back then there was less concern about the quality &amp; consistency of code in the stdlib, which is very apparent when you start poking around some of the legacy libraries in the python codebase. https://mail.python.org/pipermail/python-dev/2002-June/025893.html https://docs.python.org/release/2.3/whatsnew/node18.html
&gt; As for your last question, I assumed you guys would be able to help me because what I need here is to know if I've turned correctly the equation into Python code. You're missing the point. The equations in the picture *don't fully define the relationship between the variables*. You're basically asking us "here's x and y, how can I write an algorithm to combine them" and we're reply "what the *** does combine them mean? do you want addition? multiplication? subtraction? division?". Of course that's oversimplified, but programs execute algorithms, and an incompletely-defined equation does not specify an algorithm. Stop trying to write code and start trying to understand what the book is telling you.
I'm honestly hoping the un-versioned alias just dies instead.
&gt; books and emails don't often lose 15-20% of their character limit to structurally required indents. Indeed. &gt; You also don't read code the way you read a book or a web page. Also true enough. And that's why code can reasonably extend 30% longer than text in a book. But not 100% longer, not without it starting to hurt readability. &gt; you don't have the same comprehension advantage to jumping lines more frequently. I don't understand this. If I read it literally, you seem to be saying that Perl-ish one liners are fine to read. Of course you gain comprehension advantage by chunking your code. Obviously there's a happy medium between a single thousand character one-liner, and a hundred ten character lines, and that medium is somewhere around 70-90 characters per line. Its not a law of physics, and I completely agree that we can easily find exceptions. I often find myself testing for a condition three or five blocks in, and wanting to raise a exception, and finding that I can't fit the exception message in the 79 character limit: class X: def method(self): if this: for that in thing: if condition: raise ValueError('some longish message that takes the line past 79 characters') I'm certainly aware that sometimes good code wants to be a bit wider than 80 characters, and I'll even accept that some individuals may prefer 90 or 100 characters. I have no problem with people deciding they prefer a moderately wider standard for their own code. But I do have a problem with people insisting that the PEP 8 choice is a bad choice, or an obsolete choice. 80 characters is the *conservative* choice: it tries to take into account the ability of eyes to track across the screen and the rough number of chunks you can fit on a line before the complexity gets too much and comprehensibility falls, based on hundreds of years of collective experience with text and decades of experience with program code. It allows for the fact that code is still sometimes emailed or printed. And, most importantly, it also tries to make conservative assumptions about the minimum requirement to be a Python programmer. You don't have to be 25 years old with perfect 20-20 vision and a pair of 27" high-res monitors on your desk in perfect lighting conditions. Given that the std lib is meant to be read by a wide variety of people, with no minimum requirement for visual acuity or the size and cost of their monitor, it makes sense to be more conservative. Not everyone has, or wants, a 27" monitor. Apart from questions of cost and physical space, beyond a certain point, fitting more text on the screen at once doesn't help, it hinders. Even if I had a bigger screen, I still wouldn't want to be faced with code that regularly hit 180 characters, or even 120. And with more and more people using tablets and laptops for casual development, the assumption that everyone reading code has a giant developer monitor is getting less realistic by the day. &gt; It's a standard written 16 years ago when 75% of display resolutions were lower than 1024x768 and a big desktop monitor was 20" The line length has little or nothing to do with monitor resolution or width. If every developer in the world was given a Quad HD 2560x144 monitor the recommendation for maximum line length for the stdlib would *still* be a good one, because **its not about monitor size or resolution**. Its about **reading text**, and it doesn't matter how enormous your ~~penis~~ monitor is and how many hundreds of tiny characters you can fit on one line^1, our eyes and brain are still optimized for tracking lines of around 60 characters wide for regular text and a bit more for code. There's some wiggle-room for personal preference, of course, and it isn't like comprehension falls off exponentially with every character beyond 80. You might even be able to justify (say) 100 characters, although that's a bit much for my tastes. But going beyond 120 or 150? That's just programmer machismo, and actively hostile to a good proportion of potential readers. &gt; I mean the PEP basically starts with a refrain on why consistency is so important in a community That's pretty much the opposite of what PEP 8 says. It says consistency in a **project** is important. The **very first line** says: "This document gives coding conventions for the Python code comprising the standard library in the main Python distribution." It is a style guide for the **standard library**, not "the community". A couple of lines later it goes on to say: "Many projects have their own coding style guidelines. In the event of any conflicts, such project-specific guides take precedence for that project." It has an entire section about why a foolish consistency is the hobgoblin of little minds. There's no claim to speak to the entire community. Every project and programmer is allowed to invent their own personal coding standard. The Python core devs are not interested in policing the entire community for shitty standards. Of course it makes good sense for people to apply PEP 8 to their code, because it is a good, well-thought out standard. It is true that PEP 8 is a de facto standard of sorts, especially given how many people run pep8 and flake8 -- and that includes the 79 character limit. By the way, [Google also abides by an 80 char limit](https://google.github.io/styleguide/pyguide.html?showone=Line_length#Line_length) -- and [not just for Python either](https://google.github.io/styleguide/cppguide.html#Line_Length). (On the other hand, [Go doesn't have a line limit](https://golang.org/doc/effective_go.html#formatting).) The bottom line is that regardless of whether or not you personally have a giant hi-res monitor and amazing vision, the 80 char limit is still a good idea. But for your own projects, sure, go ahead and set whatever style guide rules you like. ^1 I once worked with a fellow who claimed to have better than 20-20 vision, and he used 8pt. That was on a Linux system, which made it [approximately equivalent to what Windows users would expect from 6pt](https://blogs.msdn.microsoft.com/fontblog/2005/11/08/where-does-96-dpi-come-from-in-windows/). It was utterly painful to read code on his screen. I have no idea whether or not he could read it either. Judging by the number of typos and errors in his code, possibly not, but he claimed to be a rock star ninja who needed to see as much text as possible on his giant screen (almost as big as his ego). 
Lol. Excellent information, thanks for those links. Does seem to suggest "because!" is the only answer.
You need to be able to point at each symbol and explain what it means and where the value comes from. Specifically, you need to understand what `r_ij` actually is, and what that summation symbol means (I don't think it works the way you think it works).
If you already know some programming: reading the official python tutorial and doing the examples. If you don't know, there's books aimed at the complete beginner. Then for whatever you are uncertain about there's bound to be a simple tutorial online somewhere. But you have to do the examples/code while you read, or else it's meaningless and also much harder to grasp.
Do these two pictures help? https://screenshots.firefoxusercontent.com/images/91daae16-c71e-43d2-9d55-644dc787d2b7.png https://screenshots.firefoxusercontent.com/images/f14119ce-374b-4a67-8216-a03bfb24c576.png First is a table that contains some sample values. Each column is a different way of measuring the objects in question and the last is actually a mix of the first two. Second is the graph of the equation.
&gt;A) it's the first python that many people will experience. When you type python in the Shell or tab complete, the system python will be the one the majority will go with. People do not just randomly start using python. They will be following a book or tutorial. I don't know of anything they will come across that will not mention the difference between py2 and py3 &gt;B) many companies will not deviate from the rhel/centos supported configuration. If that is python2, the company will stay with python2. Huh? This is like saying companies will not use any non-default software from a distro. This makes no sense at all. Why would they upgrade to say, a newer more support version of Apache, but refuse to upgrade to a newer version of Python? This argument makes no sense. Do you have any links to any examples of the either of these arguments being true in reality? I understand the argument of not fixing something that's not broken, and keeping an existing py2 app as is. But that has nothing to do with a refusal to install, and use py3.
Not really. Sample values of r_0 and p has nothing to do with the relationship between N, i, j, r_ij, and E_i. At least I can tell you're doing something chemistry related (which doesn't really help either). 
movies and stuff like that 
because I download from websites that I know. I can't know if I'm downloading viruses but I can't too when I download them manually. Anyway the things downloaded aren't for me.
A) tons of people start programming without thinking about the details. Many tutorials don't make mention of the difference of Python 2 and 3. Many people starting out also don't necessarily know that there is a significant difference between the two and just ignore it. After all why would they be so different if you don't know any better? Then, because they won't care, or they're lazy, they'll write code that targets their system python. So instead of updating their code to python 3 standards, they'll double down to use python 2. B) for companies, yes tons of companies will stick to the software stack that comes with a distro. You have to provide very compelling reasons to do an upgrade and in most cases there isn't a big one for a system level thing like Python. Every company I've worked for has been this way. I don't have links for either of these but it's also not like these are unlikely scenarios. You'll see it corroborated in pretty much every python 2 vs 3 thread
I'm using beautifulsoup for webscraping and its awesome. Pretty comfy
&gt;A) tons of people start programming without thinking about the details. Many tutorials don't make mention of the difference of Python 2 and 3. Many people starting out also don't necessarily know that there is a significant difference between the two and just ignore it. After all why would they be so different if you don't know any better? &gt;Then, because they won't care, or they're lazy, they'll write code that targets their system python. So instead of updating their code to python 3 standards, they'll double down to use python 2. I don't think it's really all that many people. However, the first time they encounter an error and head to google, they'll quickly find out. &gt;B) for companies, yes tons of companies will stick to the software stack that comes with a distro. You have to provide very compelling reasons to do an upgrade and in most cases there isn't a big one for a system level thing like Python. Every company I've worked for has been this way. This isn't an upgrade. YOU DO NOT REPLACE PY2 WITH PY3. That breaks everything. They install side-by-side. Your argument is saying that you shouldn't install MS Word, because WordPad is already there. It makes no sense.
Now I'm 99% sure that this is an energy calculation related to chemistry, and that `r_ij` is the distance between particles i and j. Is there a reason you aren't just telling us the title of this paper / textbook and explaining what this calculation is for? Is it a state secret? The main thing you're missing is data which stores the position of each particle. It's also unclear whether the constants are the same globally, or whether (as your first image suggests) they depend on whether the particles are both sodium atoms, both potassium atoms, or one of each. I think you also need to record the type of each particle.
I love how you cropped the exact comment that contained the statement I was referring to. "windows is by far the most popular platform outside of the developer community. (aka the most popular.) pip install only works with modules in the PyPl. I tried IdleX and anaconda." Fucking idiot, cant believe you wasted your time on that lol.
I am sure they would accept a patch.
You're 100% right about your guess, congrats for that by the way. Not at all a secret. I just didn't see it was that important, probably due to lack of understanding on the subject. So what I am missing is position of each particle? How about N, how do I get that value? And on what you previously said about i - j, can you elaborate a little bit more on that?
Working on a creating a python wrapper for the gemini api (a bitcoin exchange). Link to project: https://github.com/mtusman/gemini-python-wrapper I'm currently working on creating the wrapper for the websocket now which I've yet to do. Any contributions will be appreciated :)
I'm seriously considering it lol. just wanted to do a stupid check on reddit first. next stop: python-ideas
This has absolutely no place here. Reporting you. 
I believe the boltons library has such an interface
I'm not saying you replace python 2 with python 3. Again this is not a technical issue. But to get python 3 installed I need to go through my legal department. I need to justify its necessity. Then justify WHY it is an upgrade over python 2 that is already on our cleared distro. Installing other software goes through the same process. We don't just install word. We have to justify why word is an upgrade over notepad.
The only "hard" ones are grep and sed for which you can use regex (re). Reading a file and cutting the first 10 lines is literally, read the lines into a list and slice it.
&gt;But to get python 3 installed I need to go through my legal department. Why would you need to go through your legal dept to install software? &gt;Installing other software goes through the same process. We don't just install word. We have to justify why word is an upgrade over notepad. Which company is this? I've been in this industry for 20 years, I've never heard of these legal hurdles. I've seen some draconian IT policies, but nothing like what you're describing 
Thanks for your feedback... I will cross post it.
I think the other guy was just lamenting that he wishes it was that easy because of how hard he’s been working 
Not exactly, but quite quickly: the [news annoucement](https://www.archlinux.org/news/python-is-now-python-3/) was posted at the time when Python 3.1 was still the latest.
Cropped what? Thats our whole comment tree. Just moved out some whitespace. If you are referring to something you posted in a seperate comment thread **link it**
python 3 is not actually part of the `base` system (albeit the `base` system is quite literally basic) on Arch.
maybe [this](http://amoffat.github.io/sh/index.html) ?
Meh, just don't update numpy in the virutal environment that is being used with the former and current Python 2 projects, and use Python 3 with any new projects/analyses that are being started. I suppose it depends on how long term some of your projects may be. But a completed project, for example, doesn't need the latest version of numpy. 
&gt; Don't nest comprehensions, it makes your code hard to read (this one from the Google style guide, IIRC) &gt; You can use named generator comprehensions to make nested comprehensions more readable. silly example: ``` first_names = (f.upper() for f in ['james', 'jean-luc', 'benjamin', 'kathryn', 'jonathan', 'gabriel']) last_names = (l.upper() for l in ['kirk', 'picard', 'sisko', 'janeway', 'archer', 'lorca']) captains = {f: l for f, l in zip(first_names, last_names)} ```
They see me rolling, they hating.
nvm, i failed, need to use = not ==
don't shadow names of builtins and libraries list = ['python', 'anaconda', 'black mamba'] # now you can't use list() anymore 
+1 on the linters. Don't forget pydocstyle as well for checking properly-formatted comments. flake8 is great for initial development and upgrading legacy code. I always run pylint as the code matures (where 'matures' may simply be the difference between first thing in the morning and what I've written by end of the day).
embedded robotics ml and image recognition project. 
It does! So in speaking with a friend, it turns out im looking for a database project. I'm looking to compile every single instance of something on a given website. Is python still the thing to use? and how would I even go about finding someone capable of doing this?
"batteries included" means it is self contained and has no dependencies. It works out of the box, no need to go back to the store for something you didn't know it needed.
Yes, still python could serve your need. I have used python to search for certain words in any tweets and store the result dataset in my backend database- Microsoft SQL server. I used tweeter's API. I can help you if you want. 
That was mostly a joke about Arch always being at the bleeding edge, but I'm not surprised it happened that quickly.
golang got all the good practices reversed.
You can change which python version it points to using eselect, I believe. 
&gt; Not having a repl makes it difficult for me to get things done a lot of the time. Have you considered designing before implementing? Experimenting is fine, when you're doing rapid prototyping or just testing some hypothesis, but production code needs a proper design phase.
Late to the party, but I wanted to add some things I didn't read in this thread: - Read the full standard library documentation from start to finish at least once every major release. - If you want to improve the reliability of your code A LOT while making it more self-documenting, type it! Learn to use and love [mypy](http://mypy-lang.org/), run it in your tests and CI. - Every dot is a dictionary access. Sometimes creating aliases to qualified symbols outside critical loops pays a lot in performance: alias1 = somemodule.somesymbol alias2 = somedict["somekey"] for i in range: ...use alias1 and alias2 
&gt; the syntax is uglier It is, but not by much. &gt; dealing with imports is a pain It isn't: https://github.com/stefantalpalaru/generate_HLS/blob/5877099beb19a305657f030eaa59590fcfca1cde/generate_HLS.py#L12 &gt; linters mostly don't check them You're using the same linter for both Python2 and Python3: mypy. The only difference is having to give it the "--py2" or "-2" argument for Python2 code. &gt; you're doing new work in a dialect that will soon be unsupported, when you could update instead and be much better off! It's not a different dialect, it's a different language, and I'm sure the community of people working for a living will route around the core devs' sabotage. Something like this: https://github.com/naftaliharris/tauthon 
Sounds legal lol
&gt; Lastime I use gentoo, I got Python 3 And you don't know about "eselect python"?
&gt; you do know which subreddit you're in, right? Yes, of course. Who else but fanboys would celebrate being forced to switch to an inferior language and ecosystem?
So tell us what the paper is! This is my best guess: This is an equation for calculating some kind of potential energy for each particle in a system of particles. The particles are sodium and potassium atoms. There are two different kinds of energy calculations for each particle which are summed to produce the final energy for that particle. I assume that this is used as part of some kind of simulation; I don't know why else you would calculate this. But I'm not a chemist. You need a list of particles. For each particle you need to know its 3D position in space and what element it is. You don't read in *any* of the constants as input. You input the list of particles. N is the size of this list. The constants r_0 (which is some kind of base distance), A, xi (not psi), p and q depend on what the two elements are in each pair of elements. r_ij is the distance between the positions of the particles in each pair. i and j are used to iterate over the elements. Use for loops for this, not while loops; you're making your life unnecessarily difficult. The output (I assume) is a list of the final E_i values, one per particle. For each particle i, you calculate E_band_i and E_rep_i and add them together to get E_i: To calculate E_band_i you iterate over all the other particles j where j != i, and for each particle j you look up: 1. the positions of particles i and j, and calculate the distance between them to get r_ij for that pair (technically you only need to fetch the position of particle i once; I'm simplifying) 2. the elements of particles i and j, and use that information to look up the constants xi, q and r_0 for that pair and then you apply the formula, and accumulate the answer in your sum. At the end you raise this total sum to the power of 1/2 *and* make it negative. You seem to be doing this for each element *before* summing, which is wrong. Then you do the same thing with E_rep_i and the other formula and the other constants, except without the power and negation at the end.
I learned python with 3 to begin with. Could you explain why it is so difficult to switch? The syntax didn't change much.
I'm taking it from your replies you've never been at a large tech company or in a management role? That's not a judgement but an observation. Again I'm not arguing with you about the technical side of it. I agree that it's beneficial to switch to python 3 and it's easy to do a side by side install. I'm providing the non technical side to the argument for the need for distros to update their libs. Every software or library we use has to go through legal to buy off on licensing. It then needs to be vetted by the tech managers to verify it won't cause issues and is actually worth installing and maybe supporting. This is not just one company. This is the case at the majority of large tech companies. I know it's the case at most game studios, apple, google, most effects studios etc..because as part of my role, I have to have these discussions with people at other companies too. You can't just install software if you're shipping a product. Each piece of software opens you up to new issues and incurs technical and legal debt. All of that debt needs to be justified not only to programmers but to legal and management.
What would you say has been the largest hurdle in the migration? 3rd party dependencies?
yeah, and there is nothing in Py3 that would prevent any of that from preventing deployment. In fact, keeping Py2, would be more of a legal risk at this point due to zero day vulnerabilities that people are sitting on and counting down to 2020
&gt; Huh? This is like saying companies will not use any non-default software from a distro. This makes no sense at all. Why would they upgrade to say, a newer version of Apache, but refuse to upgrade to a newer version of Python? This argument makes no sense. Often, the whole point of using (and sometimes paying) RHEL/CentOS is for their long-term support of their base packages. The fact that they backport fixes/enhancements and promise to maintain a stable API/ABI may be the only reason to use them. If you're side-loading (and relying on) non-supported packages, then you might as well not even be on RHEL/CentOS.
&gt; Yeah, I've seen this argument many times. And not a single time in a decade of Py3's existence have I seen it corroborated with a single real life example. Which of these "tons of companies" are refusing to install an app on their machines? Do they not install VS Studio on their dev's windows boxes either? Because Windows doesn't come with it by default. How about the .NET runtime on the Windows servers? There are multiple versions of that too. Here's a real life example that I've faced. Writing installation/utility scripts for government servers running RHEL 6/7. It's so much easier to use python 2 and hand it over to the sysadmin (who you might not personally know or have good a communication channel with). Versus sending a py3 script and having to include instructions on installing the epel packages before they can run some 30 line python script. Sure if I was deploying a web server I would make sure that python3 and a virtualenv were properly setup. But there are plenty of marginal use cases for where it's just not worth the hassle for me.
Having a design phase doesn't necessarily help when it comes to implementation details. It's easier for me to write code interactively, then once I figure out a specific algorithm I can write a proper version into my source code. I do have a design phase most of the time, but when I need to figure out the best way to write a specific loop or condition I figure it out in the shell first. That let's me test it first, profile it if needed (%timeit is amazing), and generally explore the code. I can't really go through the same process with a test suite, that is for ensuring the correctness of larger details, not just small parts of methods. Also, whenever I'm doing data processing its more exploratory, there isn't a design phase because we don't always know what we need at first. 
I'd be very interested in talking with you about this, pm me if you think this is feasible
The problem is, if somebody writes code for free, everybody has to write code for free. Open source was intended as community development, but it's gradually turning into a small number of people writing code in their spare time for everyone else to use. I'm not saying let's go back to proprietary software, but if people are writing software used by lots of other people, there's nothing wrong with a funding model that lets them make a living at it. Meanwhile, expecting part-time, volunteer developers to treat the software they write for fun like it's their job, while requiring them to also hold down *another* job to survive, is a really discourteous thing to do.
Upgrading wasn't painful. It was the community's refusal to upgrade that was painful. They've given what, 12 years of support? 2to3? Backporting of features? No new features in Python 3.1 and 3.2? What more could they have done? The lesson here is that Guido needed to remember the "dictator" part of BDFL and kept a fire under people's feet. No mercy. It's the only way to get those who resist change to do anything. 
You really think Instagram's code base can be re-written, essentially from scratch, in 10 months, *in Rust*, and without massive user-visible issues? And then you think it's as cheap to maintain afterwards as it would be in Python? You're a Rust fanboy.
&gt; yeah, and there is nothing in Py3 that would prevent any of that from &gt;preventing deployment. The work. All the work. No one wants to fill out all the paperwork and wait six weeks for clearance. 
I doubt it's that big a deal but I only have experience with python 2
That's been one of the big ones. Another problem we had was where we were getting python from. Initially we used python XY, which is now abandonware and stuck on 2.7 32 bit. We've since switched to anaconda which has made things at least possible, but not easy. The syntax and standard library changes have made things difficult too. Another big issue has been that I've been having to support python 2 and 3 in the same source code, which limits me a lot in what I can do. I can't use async or type annotations yet, and have to be very careful about bytestrings and unicode. It's really just a lot of little things that have added up. 
I have. "Working bespoke" code that nobody is willing to touch because "it works" and it's been around for &gt; 5 years is the worst hell to work on ever. What I haven't ever done is work for a company that a) hired full-time programmers and b) never wanted functional changes on their software. At some point, you have to maintain that code or every functional change is going to be a nightmare.
Pfft; I once worked at a place that required the signing off of seven people to change the color of a menu item! It was so bad a director wanted me to essentially build a parallel piece of data processing software to what we were using and simply not tell IT we weren't running their software anymore. Needless to say I declined and also quit within six months. 
Hey, we've got Steam on Linux, Lockheed-Martin is promising compact nuclear fusion within ten years - [seriously!](https://www.lockheedmartin.com/us/products/compact-fusion.html), and Duke Nukem Forever shipped. Why not drop Python 2 support as well?
Internal does not mean I maintained. It’s far easier to maintain a mature codebase than it is to rewrite it.
dammit, the web page is dependent on my cookies... so I had to set which columns I wanted to see on that webpage, but I guess it's different. What's a work-around
like I'm using Ubuntu, so would it follow my default browser...
The syntax changed enough for it to matter, but a bigger one has been 3rd party libraries and differences in the standard library. Some of our deps didn't update into fairly recently, or we had to find different libraries that served the same purpose. A lot of it really comes down to inertia too, there's a lot of little fixes to make in a lot of places, it just takes a long time to update. Especially when you specifically have to deal with bytestrings and unicode strings in the same application. Those types have very significantly different behaviors between 2 and 3.
&gt; You really think Instagram's code base can be re-written, essentially from scratch, in 10 months, in Rust, and without massive user-visible issues? Yes. &gt; And then you think it's as cheap to maintain afterwards as it would be in Python? Any statically typed language is easier to maintain than a dynamically typed one. You'd know that if you were a programmer and not a perpetual newbie. &gt; You're a Rust fanboy. No, I prefer Nim.
They are addon packages for scipy developed separately but under a few small constraints (basically licence). https://www.scipy.org/scikits.html
That's a) great formatting and b) a great way to think about nested comprehensions. Thanks!
You’re right. 
Everyone is promising nuclear fusion within 10 years since 1988. At least. I think that's the first time I've read an article about it. Anyhow, personally, I migrated to Python 3 by migrating from a company that didn't want to prioritize it to a company that never even had to. Now I just need to fix _everything else_.
Absolutely. I've been using Node.js on side projects for a year now and I love it, it's great for internet-heavy servers but something with more need for local processing would be done better in C#/Java or even Go (which is lesser known but gaining traction). Angular.js is one of the more widely used frontend Javascript frameworks, although one of my web dev friends really likes React.js, which can be used for a website UI as well as Android &amp; iOS.
I posted this earlier, but a created a CLI to let me know when any of the 12 nearest Apple stores have the iPhoneX in stock. [Github](https://github.com/WTFox/iphone-checker)
Direct link to the repo for those interested. https://github.com/WTFox/iphone-checker 
I'm impressed by your answer. Can't thank you enough. However, I have a question, if you don't mind. You said I need a list of particles. Wouldn't be two lists of particles, one list containing j particles and the other containing i? As for what paper it is, the formula is called "Gupta potential".
What commands have you tried, and what is their output?
What error are you getting? Are you importing Django correctly? https://docs.python.org/2/tutorial/modules.html#importing-from-a-package
Very well written. What was your experience with Pushover? I migrated all my notifications to Telegram because it provides me with a 2 way communication method. Just asking because I need to monitor 100s of services and my telegram gets too cluttered at some point.
VS Code does this, and I'm sure atom does as well.
I am trying to work on learning web development using Django. At the shell I can import Django and get version 1.11.7 when I type print(django.get_version()) I am trying to follow the tutorial on the Django Site though and when I type django-admin startproject mysite I get a syntax error over and over again. https://docs.djangoproject.com/en/1.11/intro/tutorial01/ 
Without the actual content of any of the errors, nobody is going to be able to help you.
This is what I get. http://i588.photobucket.com/albums/ss322/gk2011/Capture.png
You're trying to run everything from inside the python interpreter. Run the django from the command line, instead. eg: E:\projects\django&gt;django-admin startproject foo 
What are you working on? I've found that, aside from a few syntax things, the difference between 2 and 3 isn't super nuts for biology unless you're doing some crazy modelling.
I've never used pushover at that scale. I used it quite a bit a few years ago, then went to PushBullet. I didn't really like the way that company was heading so for awhile I just decided I didn't need push notifications. When I wrote this yesterday I realized I wanted to be notified. Pushover is great, but only for simple pushes. You get something like 7500 pushes /month per app. (but you can create multiple apps, I just use a general one) It's free and pretty reliable, but if you want more than 7500 pushes a month, you can buy more. Pushover definitely doesn't support 2 way communication. So that might be a deal breaker for you. PushBullet might, I'm not sure. That library makes using any notifier pretty easy to use.
They say that debugging code is twice as hard as writing the code, so by that definition you are not smart enough to debug your own code if you try to write it as cleverly as possible.
Step 1: read the sidebar Step 2: go to the correct subreddit Step 3: see 1 (above), esp "How to ask a software question" and "Writing the perfect question" Step 4: post your code Step 5: post the version of python you are using etcetera
Tried in the cmd and went to the directory/folder on mys desktop that I wanted to put the site ran the django-admin startproject mysite returned 'django-admin' is not a recognized as an internal or external command, operable program or batch file. 
That's a path issue. Open a new command prompt to see if that fixes it. Otherwise, figure out where the django binaries are installed and add that to your path.
Hah, yes, for damn sure. 
Programmer productivity, as in time and hence money, is far more important in the 21st century than mere runtime speed.
GIS-related stuff. I mean I'm not looking forward to switching but I don't think it will be too crazy for the stuff I do. 
When your favoured languages get the take up that Python has then you'll be able to stand in the tree tops and shout about it. Until that happens I suggest that you keep a relatively low profile as pride comes before a fall.
No, Python 2 will keep going for years for those who have no need to update.
So what? Most of the changes were cosmetic and could/can be handled with 2to3 and similar tools. The one issue that has caused and will cause most work is the strings/bytes/unicode issues. This I see as being far more difficult than all other 2 to 3 issues combined.
I don't know how much safety you actually get. Yes you could put the storage array inside the object as a "private" variable and then implement public accessors `pop`/`peak`/`iter`, but since variables are only ever "private" and not actually private, you can't guarantee that somebody won't go in and muck around with the items in the heap. Additionally the heap functions just uses normal comparators on the objects in the array, and doesn't take copies or enforce any kind of immutability. So just because A was less than B when the list was first heapified doesn't mean that A is still less than B. So really you can never "guarantee" that your heap is a in fact a heap... In that sense implementing heaps as just a "property that an array might or might not obey" clearly places the onus on the programmer to make sure that their heaps are in fact heaps. Having a heap object implies that the object will in fact guarantee the underlying heap properties, and that is harder to do. 
Try /r/learnpython. Show them the code you have and describe where you are stuck. Be sure to [format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin. Also, include which version of python and what OS you are using. 
&gt; Programmer productivity, as in time and hence money, is far more important in the 21st century than mere runtime speed. That kind of thinking lead to software that is now slower on an eight core beast than old software on a 486.
Might be indentation. You didn't write what doesn't work. 
&gt; pride comes before a fall Sounds like https://en.wikipedia.org/wiki/Moral_universe#Immanent_justice You're supposed to grow out of it.
My mac has python pointed to 3. I think it happened when I installed Anaconda.
Get a python IDE and write your code there. Pycharm community edition is free and works well
This is the best thing I've seen so far and I'm tempted to use it even though it's essentially a wrapper for underlying shell commands. The only bad thing I see about it is how you have to nest functions to emulate piping in bash, that could quickly get out of hand. I feel like this could be implemented but the source code for that program is over 3k lines in one file so it would take a looong while to figure it out I think. 
Shucks im such a noob
The real issue I've found is strings/unicode while supporting both python2 and python3!
Not have forked and pushed the various changes one at a time with deprecation warnings? Allowed better python 2/3 interop for a period of time before killing off python2 code with deprecation to allow people to use python3 without completely updating all of their code (and all the dependent libraries in one go) in one go? 
Yo turn this in for Question 2 I dare you: from random import randrange for i in range(1, 5): exec("grade" + str(i) + " = " + str(randrange(1,5))) f = lambda x: eval("grade"+str(x)) print("The GPA od these four courses is XXX".replace("XXX", str(sum(f(i) for i in range(1, 5))/4)))
You can start the function by getting the current time, then once all steps are finished, get the time again and wait for the difference between the static value and the timedelta. Like: def func(fixed_sleep=10): start = time.time() ...do stuff... slp = fixed_sleep - (time.time() - start) time.sleep(slp)
The python-future package and their cheat sheet page helped us a lot. In fact, supporting current and legacy versions of NumPy and Pandas has felt more challenging than the py2-&gt;3 transition. 
You can try `python3` on windows but you won't get very far. For an indication of just how difficult this is try reading [[Python-ideas] Looking for input to help with the pip situation](https://mail.python.org/pipermail/python-ideas/2017-November/047708.html).
Not possible. Python does not communicate exceptions to the environment in any way, it just sets an exit code and prints the message to standard error.
How is that any different than running pip2?
Ok good to know, thank you.
You can use the VS Code or you can use the pprint module `from pprint import pprint` Instead of print() write pprint() 
&gt; edit: His comment was -3 now it's +20, oops My +1 made it 291, hence why I am strongly convinced that such voting systems are less than useless.
Use the future library, it makes it pretty easy and has a cheese sheet for supporting both
This is good for PyCoin. 
Im not wasting my time screenshotting bc you're incapable of reading the entire thread you're replying to. For fuck sake.
Your title says shell, but your description says it's not shell. Clearly you want a pipeline library, because you find the standard `subprocess` module inconvenient. Maybe change your title? Also, please avoid using the shell when the standard, less-risky, `execve` (the sys/libc call that `subprocess` wraps) suffices.
Can't wait for Python 2.7.27!
That doesn't allow folding. It really doesn't help when you have particularly deeply nested objects, like a Sentry API call response. What's the path to the breadcrumbs? What are its siblings?
yeah. Its just for learning, the webpages that upload that torrents sems more illegal. Dont you think so? I dont earn anything doing scripts for webscraping xD
Now I am realizing my first question was really dumb. There's only one list, j is the first and i is the second when iterating. Now I have another problem. How do I turn three values -- x, y and z -- into just one value that I can use as j and i? And my last question is still relevant, I think.
IIRC, core Python developers have said that they don't want to do anything like it again.
#Hiring Someone to teach me how to make a requirements.txt for my github repo which utilizes over 20 different libraries. Should be able to run a single command on cmd/terminal to install all the different dependencies. Willing to pay 5$ I know this is a strange request, but I'm pretty desperate. Thanks
Click on the "context" button on reddit. **That** is **this** comment thread, that's what it's for. You don't have to screenshot. Reddit has a handy **link** feature too! Learn to use the internet, or you can go on complaining about every nonsensical thing like you do.
import re filter = {} NFEfreq = {} AFRfreq = {} ASNfreq = {} for line in open('file'): line = line.rstrip() exac = re.split(r'\s+', line) altalleles = exac[4].split(',') for alt in altalleles: name = '_'.join(exac[0], exac[1], exac[3], alt filter[name] = exac[5] NFEfreq[name] = exac[9] AFRfreq[name] = exac[12] ASNfreq[name] = exac[15] Totes untested, but I'm making the transition from Perl to Python so maybe that helps?
Actually Zappa's author wrote about this: https://blog.zappa.io/posts/comparison-zappa-verus-chalice
On Windows, I use Notepad++ for that, with the JSTool plugin.
Hey, finally done. Polished it up a bit, ironed out some bugs and made it (hopefully) able to run on other computers other than mine. Here you go! https://github.com/andreaslordos/Olympia
Thank you I appreciate you giving me a starting point!
+1 for regex. I would use a context manager for opening the file though :) with open("filepath", "r") as file: for line in file: ...
Pycharm does this
Which lint programs did you use?
https://eev.ee/blog/2016/11/23/a-rebuttal-for-python-3/ Also, Zed now has a version of LPTHW for 3 that he sells for money. It's still bad.
I wouldn't say I'm a Python developer but list comprehension is a feature I wish I had in other languages. It's a concise, clear, and explicit way of reasoning functionally on lists that's sorely lacking in every language I known. Decorators on the other hand feel like obfuscation to me unless used with care and clear intention. (Also, named arguments, this should be a given in every language, I often resorted to arrays then to struct-like classes in PHP to get the same flexibility.)
Just finished (?) a project I have been working on since the Summer. If you're looking for a JARVIS to help you out, check it out and tell me what you think! www.github.com/andreaslordos/Olympia
Firefox Nightly does this. Just open the json file in your browser.
Just normal firefox does too :)
`flake8` et al will complain about that import, and doesn't lint type comments. I disagree with your other comments too but won't respond.
Switched to Scala - never looked back.
Do you just want to print the error? That's not really an exception. Test on exit code and print the output. How exactly, that would be on the powershell community.
Wouldn't while and sys.stdin be closer to the perl? Not on PC so too lazy to check if the IN thing is regular file.
I'm not OP, but `flake8` is great - good defaults out of the box for new projects, and easy to tune with a blacklist of checks to skip (or even a whitelist in extreme cases). I keep having this unpleasant surprise when I go back to code that doesn't use it - the benefit of reading code that's all in the same idiomatic style is hard to describe, but very real!
You can use the sys module: import sys sys.exit(1) In powershell $? should show false and %lastexitcode should show 1. I'm using PS 5.1 and Anaconda Python 3.6.3
Report? That sounds like it's news. 2020 has been the projected end for Python 2 for a long time.
Writing a python tutorial in a 3 column maganize format...i feel bad for you. But good try nonetheless :)
&gt; flake8 et al will complain about that import Yes. Solved by adding "# NOQA" after it. &gt; and doesn't lint type comments Of course it doesn't. The progressive (and partial) static typing is implemented and checked by mypy. Are you new to Python?
You are using the variable 'guess' twice, for what I think is supposed to be two different things. First, it stores the random number, but then in the for loop you assign it the value 0, when I think you are tracking he number of 'attempts' made.
You poor souls. 
You need to store the previous guesses somewhere. Have you already done dicts? past_guesses = {} ... if guess in past_guesses: # print and increment count else: # add guess to list past_guesses[guess] = 1 
Is there a reason why you don't go enjoy your perfect and ultrafast software ***elsewhere***?
Switched to Haskell, not really missing a thing. A library or two, maybe.
It's nice to see that Guido finally understood the benefits of static typing. Give him 20 more years and he'll start grasping functional programming ;-)
something like this? import random secret = random.randint(0,100) guess = int(input("make a guess: ")) while guess != secret: past_guesses = {} if guess in past_guesses: past_guesses[guess] += 1 else: past_guesses[guess] = 1 if guess &gt; secret: print("Too high!") elif guess &lt; secret: print("Too low!") guess = int(input("make a guess: ")) print(past_guesses) print("good guess!") 
&gt; so that they can safely move to Python 3 http://mypy-lang.blogspot.com/2017/11/dropbox-releases-pyannotate-auto.html : &gt; At Dropbox we’ve annotated over 1.2 million lines of code (about 20% of our total Python codebase) It would be madness to port all that to Python3.
Finished a basic budget tracker with Pythonista and Drafts on iOS, and I've been experimenting with micro.blog. I've also been trying to fix S3 redirection (aka make the www. go to the right area) by using Amazon Route 53. It's somewhat complicated, but I think I have it? The cache makes it hard to test. 
There never was any validity, so there was nothing to remain.
Why? If it ain't broke, don't fix it.
I think R is best for local interactive EDA and model building. For production products Python is better, and Go even more so. 
With official support ending in 2020 there is as much chance of getting to 2.7.27 as there is of getting to 2.8.0. [PEP 404](https://www.python.org/dev/peps/pep-0404/) refers.
&gt; import random &gt; &gt; secret = random.randint(0,100) &gt; guess = int(input("make a guess: ")) &gt; &gt; &gt; &gt; while guess != secret: &gt; past_guesses = {} &gt; if guess in past_guesses: &gt; past_guesses[guess] += 1 &gt; else: &gt; past_guesses[guess] = 1 &gt; if guess &gt; secret: &gt; print("Too high!") &gt; elif guess &lt; secret: &gt; print("Too low!") &gt; guess = int(input("make a guess: ")) &gt; print(past_guesses) &gt; &gt; &gt; print("good guess!") past_guesses = {} needs to be before/outside the while loop, otherwise you keep deleting your values with each iteration.
The daft thing is on windows you can run `pip`, `pip3` or `pip3.6`.
Plz tell me how
Well, you need to declare the past_guesses before the while, otherwise it will reset every time and you won't see anything. Make sure you understand why this happens: the line `x = {}` means "x is now an empty dict", so it should only be executed once.
mypy and typing module aren't really about static typing. It's called https://en.wikipedia.org/wiki/Gradual_typing and allows to have all flexibility of dynamic typing with enforced type correctness. Anybody could've realized after the emergence of Typescript that type enforcement over the dynamic language is a great thing. It's a shame though that Python community adopts mypy/typing so slowly. 
**Gradual typing** Gradual typing is a type system in which some variables and expressions may be given types and the correctness of the typing is checked at compile-time (which is static typing) and some expressions may be left untyped and eventual type errors are reported at run-time (which is dynamic typing). Gradual typing allows software developers to choose either type paradigm as appropriate, from within a single language. In many cases gradual typing is added to an existing dynamic language, creating a derived language allowing but not requiring static typing to be used. In some cases a language uses gradual typing from the start. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
How what?
Serious question, isn't virtualenv available on windows? I was under the impression it was. Yes, it's daft that their are three different versions, but hopefully the damage can be contained to just a single venv.
&gt; many companies will not deviate from the rhel/centos supported configuration RH ships Python 3.6 for RHEL and CentOS through their [Software Collections](https://www.softwarecollections.org/en/) product. If you have a support contract with RH, then it [automatically covers these packages too](https://developers.redhat.com/products/softwarecollections/overview/). Tell your friends and management :-). That said, the major distros are actively having conversations about how to manage the transition to make `python` refer to python3. It will just take a while, and have to pass through a period where there is no `python` command so people who were counting on `python` = python2 will notice and catch their mistake.
Having focused on the Node ecosystem in recent years, I wasn't tracking the exact EOL date—so it's news to me.
Any thoughts on how to run tests against code that requires connecting to a device and pulling information? My code connects to say, a network switch and pulls or works with data from that live system, so unless I can carry the switch with me (not happening) I can't reproduce 'tests' anywhere. I considered building a test to feed the scripts static data but it would require a bunch of refactoring and changes that would complicate code intended to be simple enough for new network engineers to grab. But right now, I just run it against a switch and make the determination myself if it's right or not....plus, simulating an SSH session seems like a mountain of work. 
Although Jupyter is a server and could be run anywhere the usual setup is to run the server on your own desktop machine so it is all local.
bro you gotta let python 2 die , it deserves an honourable death. 
RHEL/CentOS also ship years-old versions of NumPy. If you're only interested in using software that they include as part of the distro, then you'll be using that and never upgrading NumPy anyway, which means that this announcement is irrelevant to you :-). OTOH RH does actually provide support for [modern Python on RHEL/CentOS](https://developers.redhat.com/products/softwarecollections/overview/), and [here's a RH engineer urging volunteer projects to drop support for the ancient stuff included in the core distro](http://www.curiousefficiency.org/posts/2015/04/stop-supporting-python26.html).
&gt; bro you gotta let python 2 die , it deserves an honourable death. There's more Python2 code out there than Fortran or Cobol code.
Python without a doubt. 
&gt; mypy and typing module aren't really about static typing. It's called https://en.wikipedia.org/wiki/Gradual_typing Yes, type checking before running the program is really about static typing.
Thanks, I'll give it a try. 
Thanks, I'll give this a shot when I get a chance.
&gt;Upgrading wasn't painful. &gt;It was the community's refusal to upgrade that was painful. hmmmmm
You can also use chrome by installing one of the json viewing extensions. Just make sure to enable local paths in the extension tabs if you are working with files on your computer.
&gt;It will be great when Python 2 is not the default installed version on most Linux distros. That probably won't happen until much later (just kidding). Or the Mac.
&gt;isn't virtualenv available on windows And Anaconda. 
just start charging $ for v2 support :-)
Python is free. You don't need a key. Go to python.org to download it. 
I downloaded python for free, and It gave me a key to get to the program they made on python, I believe
OH I see. You mean like an RSA key? About 2,000 random characters? 
What else are they going to do, though&amp;mdash;keep running Python 2? (Honestly, the real answer is likely to be "Let the teams that are rewriting parts of the code do so in Go, and convert the rest to Python 3.")
&gt; What else are they going to do, though—keep running Python 2? Yes, of course. Or a compatible fork like https://github.com/naftaliharris/tauthon
Oh, you're the person on /r/python that I previously had an argument with about how this exact project is a completely infeasible idea for big companies (unless they want to commit to the support burden of keeping up with security updates etc. until the end of time for both the fork _and every single third-party Python library that is no longer supporting Python 2_, which is a much bigger project than converting 6M lines of Python to Python 3 once, and being done with it.). It's now been six months since your PR with no other activity to the fork, and ten months since any code changes to existing Python code. This isn't something you can trust a copy of the entire world's files to. Mind you, I'm not saying this project shouldn't exist. It should. I wish it had won over Python 3. But it doesn't seem to be happening (nor does any similar project) in a way that's suitable for use by big companies in production, and it is probably too late to build a community around Python 2-compatible versions of the ecosystem.
R is an interactive statistics package. Python is a programming language. (Maybe you denigrate it as a scripting language, but whatever.) Learning Python will help teach you programming. Learning Python will help teach you to script everything, for much cleaner and faster development, which leads to more and more useful code. Also, because RPy exists, you can see R as a subset of Python: The RPy wrapper gives you access to the full R functionality with the advantage of Python’s cleaner and more powerful syntax; it’s the best of both worlds. (Yes, i know about PyR.)
The goal isn't to prevent the programmer from deliberately messing with the data (which is always possible no matter how well wrapped as you point out) but to 1) make it conceptually more consistent with the rest of Python (OOP) and 2) as a side-effect, will make it harder to *accidentally* mess with the data. Deliberately messing with the data is no different, just more explicit through an OOP wrapper. (And I kinda disagree that an OOP wrapper implies stronger guarantees, though I think that's tangential to your main point)
Well not 2000, idk maybe
I started learning Scala to work with Spark more. The number of built-ins is staggering. The problem I run into is not knowing (as a novice) which data structure to use. For instance, I think there are at least 6 different array data structures. It's an uphill battle.
Ok, I'm guessing that's basically the password to log into whatever server the code is hosted on. That's has nothing to do with python. You will need to talk to them to learn how to log into their server and download their software. 
Ok ill try it thanks
To be fair, mypy is really far behind typescript. I'm not sure if its due to extreme dynamism being more common in python (attrs, django, sqlalchemy, etc), or mypy just not being as mature; but I've not found being reasonably early adoptor of mypy to be nearly as nice
Thanks I'll check it out!! I appreciate it 
On Ubuntu, they’ve finally upgraded the version that the OS uses to 2.7. So there is hope. 
Can you store the data you need in instance variables, eg. `self.theUser`, so they will be available to any number of other tests?
R has freaking powerful packages, but as a language is totally shit, the semantics don't follow any logic, someone must kill R for his userbase go to Python.
Ubuntu for me, but I like newer software, at the expense of stability sometimes.
I hit post before I finished a sentence.... hahaha. I want a job in python! 
You might be able to have it both ways, Jupyter has always supported R and python I think. http://blog.revolutionanalytics.com/2016/01/pipelining-r-python.html
Maybe people choose languages and patterns for reasons other than strictly adhering to some principal? No, couldn't be. Them must just not *grasp it* because it's *so complex*! /s
&gt; mypy just not being as mature Its this one. Once you hit critical mass, it's very, very good. Also smarter type inference than what mypy provides helps.
Why are you looking for Python books on those topics? They're all fairly language-agnostic.
Oooh that new path syntax
&gt; principal principle
Too slowly? They actually started adopting it before it was even finished. They broke their own policies by jumping on it rather than letting it percolate in the community over time. They broke their own policies by using Python 3's annotation, which they previously declared would be up to the community to use as it saw fit. Raymond Hettinger said not too long ago that the core devs are starting to move too fast; I think mypy is an excellent example of this. With a bit of time the community would probably have come up with something better.
I guess you can help some people on stackoverflow.com and creating a repository on github 
What concepts of functional programming would you like to see in Python? You can already program in a functional manner in Python pretty easily.
&gt;Not have forked and pushed the various changes one at a time with &gt;deprecation warnings? Why would you release each breaking change one at a time? And the deprecation warning was the existence of Python 3 combined with the long support window for Python 2. &gt;Allowed better python 2/3 interop for a period of time before killing off &gt;python2 code Killing off? It's been 9 years so far and it's still supported! &gt; with deprecation to allow people to use python3 without completely &gt;updating all of their code They also backported many Python 3 features to Python 2, so you could indeed use Python 3 features without completely updating all of your code in one go. So everything you're suggesting was already done. 
Guido actually has wanted type annotations long before mypy. See http://www.artima.com/weblogs/viewpost.jsp?thread=85551
All of my open source contributions came from fixing things I used. 
*touche*
Dropbox was what got me into Python. I used to deliver packages to them when they were in the Phelan building in downtown SF. After seeing the kitchen, the ping pong table etc. I decided I was in the wrong profession. One of the guys had the python in a nutshell book on his desk. 
Thanks for all the suggestions. I have decided to use [this](https://stackoverflow.com/questions/18873066/pretty-json-formatting-in-ipython-notebook/37124230#37124230) solution. I can remain in Jupyter-notebook, create a helper function and then fold json objects within the notebook.
&gt;Too slowly? They actually started adopting it before it was even finished Its a bit difficult to cover every edge case of Python, every possible combination of paradigm and type feature, without having a lot of people testing it. &gt;They broke their own policies by jumping on it rather than letting it percolate in the community over time. PEP 3107 was originally created because Collin Winter wanted syntax to type check programs. Guido didn't want semantics, and let things stew for almost a decade. From [this list](https://github.com/ethanhs/python-typecheckers) you can see that there are quite a few type checkers that were created. However none of them have become particularly noteworthy or well developed. &gt;which they previously declared would be up to the community to use as it saw fit Could you point to where they said this? I read through PEP 3107 and I found two snippets which stood out to me: &gt;By itself, Python does not attach any particular meaning or significance to annotations &gt;this PEP makes no attempt to introduce any kind of standard semantics, even for the built-in types. This work will be left to third-party libraries. Based on how I read these, they don't preclude a later PEP defining semantics.
Does that really manage all dependencies and everything? I don't recall if I've used pyinstaller in the past or if it was py2exe, but I remember having issues where it wasn't packaging any referenced packages so things would fail at runtime.
What type inference are you missing if I may ask?
Inference might be the wrong word, but more that (with pytype at google), a huge amount of what the library code has types, and I believe mypy doesn't do things like def f(): return 4 Although I may be wrong/outdated.
Mypy and pytype use the same type information for the standard library. Your example is an interesting one. Mypy generally wants functions annotated. The case you provided probably could be inferred with the `--check-untyped-defs` flag on, but more complex cases would make things much likelier to cause errors.
Yeah, I meant that the infra supporting typing is there for mypy or pytype, for example protobufs are type-annotated.
Go to the Github page for a project you want to contribute to. Click on the issues tab and then look for issues tagged "low hanging fruit", "good first bug" or something similar.
i think the typical things requested are pattern matching, function composition, nicer lambdas. but yeah, you can get pretty far. 
When I read "deliver packages", my first thought was of you printing out your code and taking it to them.
&gt; Being more "pythonic" just for the sake of it is idiotic. That's a ... strange attitude to take. By definition, "pythonic" code is good, idiomatic, well-written code. As an experienced developer, rather than a cowboy, you should know that idiomatic code is good code. Unidiomatic code is like language which uses its own clever slang that nobody else understands. "Clever" code is a code smell: if you write the cleverest code you can, you're not clever enough to debug it. Idiomatic code is its own reward: idiomatic code is readable code, easy to comprehend, and makes maintenance simpler. You should have a good reason for not writing idiomatic code. I don't know whether you intended it or not, but you effectively said that it is stupid to write code that others can understand. &gt; That point alone just sounds so pretentious I almost stopped reading. Code needs to be readable, extendable, and maintainable. Right -- and that's what idiomatic, pythonic code is. &gt; None of those requirements insist upon blindly following some language-specific dogma. "Blindly"? My *very first words* in this discussion were "Depends on the context". If you think I'm talking about blindly following any rule, then your reading comprehension is pretty poor. &gt; The two conditions actually behave differently. Checking the length explicitly will raise an exception for a None object, whereas checking just the object will return false. Indeed. And that was my point: it's often desirable to accept None or a collection. &gt; More often than not, the former behavior is more desirable, since code should generally fail fast. I don't know about "more often or not", but I agree that sometimes you do want None to fail. But not always. &gt; Checking __len__ is not usually O(n). It depends on the implementation of the collection, and most if not all of the standard Python collection classes track the size in an attribute, so it's usually O(1). I'll grant you that this isn't the most obvious behavior, but still, an important distinction. Indeed. I did specify "a collection with an inefficient `__len__`". But that's the thing: if you're duck-typing and can accept any sort of collection or sequence, you don't know in advance that you're going to only receive objects with an efficient len. So why rely on this implementation detail? You don't actually care what the length is. You only care whether the collection is empty or not, and the idiomatic way of writing that is `if myCollection`. &gt; If the object isn't expected to always be a collection (like a float or something), you already have at best, unmaintainable code, and at worst, a bug, if the condition is relying on the assumption that the object is a collection. Again, checking length here catches that issue, checking the object directly doesn't. Be reasonable: not all code that accepts arbitrary objects is buggy. And chances are that if you pass a float or an int, you'll get an exception just a few lines further in, when you try to call some other sequence or collection method. Besides, that's really an argument against duck-typing. If you want to be sure you have a collection, then call `isinstance`, or check for the availability of the methods you know you want. Assuming you've already checked that the object is (let's say) a collection, then there is no extra benefit in calling `len` when you don't actually care about the length. &gt; Read the PEP for this condition check. Even the author admits this lint check is probably not the best idea/needs to be rethought. It's just not a good warning, at all. I can't comment on the lint author's opinion, but PEP 8 mandates the `if myCollection` idiom for the standard library. In your own code, of course you can write anything you like, no matter how pointless: if ((sum(1 for x in myCollection) == 0) is True) is True: ... *wink* 
I am just curious. I know that there must be some available. 
Type hints are ugly as hell. They feel like a hack on top of the language, because it is. I don't think it'll ever be really popular.
Which (float) column are you exactly referring to?
It got a lot of improvements in the last patches. Might as well give it a shot and see how it performs with your project.
&gt; `if myCollection` duck-types myCollection and asks "are you truthy?" This works fine iff truthniness and non-emptiness are the same. If they're not, if myCollection will happily continue execution even though there's a serious bug in your code. Or a bug in the collection. *If* you know you have a collection then truthiness and non-emptiness damn well better be the same, or the collection is buggy. It doesn't matter whether you call `len` directly, or indirectly via truth-testing, the fundamental assumption baked into the language is that an empty collection is one with zero length which implies it has no items. If that's not the case, and something like this is violated: if not myCollection: assert len(myCollection) == 0 assert len(list(myCollection)) == 0 then what you have is fundamentally broken. &gt; Truthiness doesn't reliably map onto non-emptyness even for basic Python objects like generators. Generators aren't collections. And generators are a rare exception to the rule that truthiness equates to non-emptiness: that's [even baked into the definition of truth-testing](https://docs.python.org/3/reference/datamodel.html#object.__bool__). The only other counter example to the rule in the standard library that I can think of is time objects, which used to report that they were False at midnight. But that's been fixed. Off the top of my head, I cannot think of any other stdlib object that breaks the "something versus nothing" rule for truthiness. I agree that generators are an unfortunate case. But what you're describing is a problem more often in theory than in practice. In practice, we don't often accept a generator or a collection: generators don't include potential collection methods like `update` or key lookup. We do often write code that accepts either sequences or generators, but the right way to do that is to immediately call `iter` on the argument, converting it into an iterator, and then handle it as if it were not empty, catching StopIteration if it happens to be empty. You don't try to call `len` on a generator, because that won't work. 
&gt; By definition, "pythonic" code is good, idiomatic, well-written code. You're taking an untrue statement and treating it as a factually true one, then basing your entire argument on it. Based on the rest of your comment history, it's clear you have an extremely biased opinion on this matter and aren't going to be swayed or even open to others opinions on the matter. Best of luck with that.
Lol no, I was a FedEx courier. 
Pattern matching would be a nice addition although [a form of it is possible](http://blog.chadselph.com/adding-functional-style-pattern-matching-to-python.html). Decorators allow a form of function composition. Multi line lambdas are not happening in a significant whitespace language and while their absence breaks the flow a little (to declare the would-be lambda function) before its use it does encourage simple constructs. 
You need to find a project you have a personal interest in or start one where your personal interests can be exploited. Now you can contribute to any project even if there is a lack of personal interest, sometimes just submitting bug fixes can do wonders. However if you have a personal interest in the project your contributions will feel far less like work. Frankly I suspect most people do better work on projects of personal interest too.
Can you use those Debian packages then? 
&gt; Why would you release each breaking change one at a time? Because fixing one thing at a time is easier than switching your code over in one go, and people are more willing to do it. This allows you to avoid forking by forcing people to make small changes one at a time. &gt; And the deprecation warning was the existence of Python 3 combined with the long support window for Python 2. Certainly. Though deprecation warnings on the code you are running are a little more compelling and fixable than the existence of python 3. &gt; Killing off? It's been 9 years so far and it's still supported! "Killing off" was just descriptive here. The length of time that python 2 has been supported is admirable. The python 2/3 interop was deliberately bad however (though there were payoffs in terms of simplicity) &gt; so you could indeed use Python 3 features The thing you couldn't do is use *python 3 itself* with python 2 code. This might have increased adoption. Not without a costs in terms of complexity of the python core. But certainly the ability to write python 2/3 interoperable code existed and has been very useful for allowing python 3 adoption. I guess the difference is just in terms of *tooling*: if you are actually running python 3 then you never have to switch over. &gt; So everything you're suggesting was already done. Them's fighting words :P. I don't think that's at all true. Implementing each of the features into core with deprecations one at a time and forcing people to adopt them is very different from the current approach. Allowing python 2 code to be run by the python 3 compiler would have created a lot of extra complexity for python core, but may have encouraged people to write more python 3. I'm not saying that these approaches would have been better, there were alternative ways of getting from A to B however.
I am trying my hands on creating a [simple blockchain](https://github.com/jochasinga/miniblock). Figured Python would be the only language that wouldn't get in the way of trying to understand this.
If you are a student at an university, you can participate in Kharagpur Winter of Code: https://kwoc.kossiitkgp.in/ You will find plenty of Python projects you can contribute to while collaborating with many other like-minded people.
My mind jumped to TCP and then pypi before landing on bike messenger.
I'm not a Pandas user, but I'm sure it does a good job reading (and writing?) CSVs. I probably should have been more explicit with my comment: don't roll your own code for reading/writing CSVs
You're quite right; "A foolish consistency is the Hobgloblin of little minds". One of my favorite parts of the Zen of Python. 
Check out https://pymotw.com/3/
Do you mean you went from belng a delivery person to a Python software engineer?
Why is *how much functions* an interesting aspect? The builtin ``json`` module hasn't much functions but is very useful and nice to use. So how would you compare it to say ``numpy``? 😈
You don't use them as j and i! You calculate [the Euclidean distance](https://stackoverflow.com/questions/1401712/how-can-the-euclidean-distance-be-calculated-with-numpy) between the two sets of coordinates. That is r_ij.
&gt; As for what paper it is, the formula is called "Gupta potential". That's not the name of a paper. There are multiple papers about the calculation of Gupta potential for sodium and potassium. I assume it's one of [these](https://www.google.com/search?safe=off&amp;biw=1014&amp;bih=621&amp;tbs=li%3A1&amp;ei=3j4NWsXCGIaOgAb0xY6ICQ&amp;q=Gupta+potential+sodium+potassium&amp;oq=Gupta+potential+sodium+potassium&amp;gs_l=psy-ab.3..33i21k1.118215.121498.0.121947.18.12.0.0.0.0.692.1956.2-1j1j0j2.4.0....0...1.1.64.psy-ab..14.2.971...33i160k1.0.IK5VhGE2P0g). I genuinely don't understand why you are still being cryptic about this.
Well, obviously there's [the docs](https://docs.python.org/3/), but in a Python shell you can always just do this: import module help(module) Where *module* is whatever lib you're interest in (like **os** or **re** or **logging**).
If anything, the date was pushed *back*. If they had stuck to the original date, Python 2 would be unsupported as we speak.
You need to learn how to mock that data: * https://docs.python.org/3/library/unittest.mock.html * https://pypi.python.org/pypi/mock Basically, you use mock to replace the function that returns the values from the service you connect to with a 'function' that 'returns' the value(s) you want to test. pseudo code: @replace.function.thatConnects.to.device def first_test(): function.thatConnects.to.device.return_value = 'static_return_value' test_data = [1, 2, 3] test_result = operation_reliant_return_value(test_data) assert test_result = 3 You want to test as small a piece of code as possible, and for that code to be as static as possible. Unless you're writing a test for the connection explicitly, you're only interested in the value that connection provides. If you're interested in multiple values, you can then look up side effects, and basically iterate over a range of values in a test (useful for if you want to test how your iterators before, or if you want something to fail/recover after *n* attempts)
I surely used the first approach all the time but at one point I ask myself, why not the other? It saves one line of code and also declaring a class and then writing "pass" looked a little bit odd. So I decided to ask here. At this point, I didn't mind if someone else could read it. That was not on the scope of my thinking. I totally agree with cr4ds longer explanation now. In my eyes the most important argument he pointed out is readability. Everyone knows what the first approach does, even people which have never seen a piece of python code could at least guess it if they know what a class is. The type approach can't do that, there he is right.
thatsthejoke.jpg?
[thatsthejoke.jpg](http://i.imgur.com/tEjeMu8.jpg) --- ^(*Feedback welcome at /r/image_linker_bot* | )[^(Disable)](https://www.reddit.com/message/compose/?to=image_linker_bot&amp;subject=Ignore%20request&amp;message=ignore%20me)^( with "ignore me" via reply or PM) 
good bot
Good Human ---------- I am a Bot which automatically collects comments across reddit. Beep Boop
Hi /u/AkeemisKing, contributing to a open source project is a great thing and it helps other users in their project. I also would think about what my interest are. It is also a good idea to check the git sides of packages and libraries you are using on a daily basis. You can help the best way, when you already now what the project you want to contribute for is doing on the user side. Have a nice day! Best Martin
This is the guy that said Python 3 wasn't turing complete. He may have once have been amazing but he seems to have gone a bit crackpot.
Do they use type annotation now they're on python3? (I know this release has to supports 3.4, but there are backports of the typing module). I find type annotations to be a great help in large projects.
I have to opposed feelings on decorators and list comprehension. Part of that may be because I'm still new to those concepts. I agree on named arguments tho. Every language should have it, but I'm not sure it should be mandatory (like in Swift if I'm not mistaking).
Quote from his [website](https://learnpythonthehardway.org/book/nopython3.html): &gt;In the previous version I trolled people by pointing out that, if what the Python project says is true and it would have been "impossible" to support Python 2, then they broke it and Python 3 is not turing complete. Obviously Python 3 is turing complete, but Python project members frequently claim something this basic is "impossible" soooooooooooo alright. I even had a note after the gag saying it was a gag, but everyone is too stupid to read that note even when they do elaborate responses to my writing. Even more telling was when people said this was stupid, I'd feign ignorance further and ask, "Wait, so why doesn't Python 3 support Python 2 then?" This then sent them down a logic loop death spiral of simultaneously trying to defend the design decision and also state that Python 3 is fully capable. It was pretty funny to watch, but after a while I guess I have to straighten this out and simplify it so here you go. Seems like a guy who has no courage to say he was wrong. Also, my favourite: &gt; I mean, if I struggle to use Python's strings then you don't have a chance. No, Zed. People are just fine using strings in Python 3. 
I *hope* it will never be popular. It is an ugly unpythonic mess, imho put in place just because the BDFL feels the danger of being kicked out of Dropbox as happened in Google when they dropped Python.
Doing cpp now, pissed off at the lack of "if i in x" feature
Regular pylint, it has a bunch of Python 3 related lints built in and it's fairly easy (though not well documented) to write your own.
https://i.imgur.com/NwBAJbj.png works for me Keep in mind direct drive access requires admin privileges
I think if you ask on a Python board, people will generally recommend Python :) Biggest advantage Python has over R is that it's general purpose, so you can do so many more things in it. I'd also say that, for big data, you can write Spark scripts in Python (not as fast as Scala), so it has that going for it too!
This is how I became a contributor to a project, and I still don't know what I'm doing. The single best learning experience I've had since picking up Python.
Don’t forget a pipe operator! You may enjoy http://coconut-lang.org
So, for me my current job literally fell into my inbox. No joke - one day I woke up and there the job opportunity was. It happened because I uploaded my CV to job search sites and elected to make my CV visible to recruiters. A recruiter found my CV by searching for Python (on my CV, I wrote about my Python programming as part of my undergraduate degree dissertation) and they sent me an email to see if I would be interested. Two interviews later, I scored my first ever job, and I started work as a Python programmer. Moral of the story - highlight any Python experience you have on your CV and make sure as many people as possible see it. If you don't have Python experience, highlight that you'd be interested in the job plus anything you've done outside of work to show that. As long as you get the Python keyword on there somehow, this will help recruiters find you.
Yeah, after asking it I realized just that. Then I had success running the equation. Your help, despite my dumb questions, was very important for me to understand it, so thank you again.
&gt;Not everyone has the money and room for multiple large monitors. 2 22-24" displays, $200-$400 each. You already have one display. If it came down to money, you can snag a 17-19" 4:3 screen off Craigslist or the e-waste bin for less than $25. I suppose if you work in an open floor plan office where the company doesn't provide docking station with external monitors and you don't have a desk surface with your name on it. But that's compromising a lot of potential productivity.
It's not a paper actually, it's a master's thesis.
Could be a bit of work but seems the thing to do yea.
&gt; Rinse and repeat for syntactic changes/updates and builtins changes (open, map, filter, … should all be verboten). Am I not supposed to use open in Python 3? What makes map and filter problematic? I do not think they changed?
&gt; Am I not supposed to use open in Python 3? Once everything is ported there's no issue, while converting it's troublesome: * In Python 3, `open` is an alias for `io.open` and in text mode (the default) it will encode/decode the data, this os an issue because - Python 2's open basically always behaves in binary mode - io.open `locale.getpreferredencoding(False)` which probably isn't what you want so you will want to pass in an encoding explicitly, which will blow up on Python 2 so you can either keep using the builtin but *always* use it in binary mode (`mode='rb'` or `mode='wb'`) — which may be hard to lint — or ban `open` and require `io.open` during the transition — which is easy to lint * In Python 3, `map` and `filter` return iterators (not lists) - things will blow up when indexing them which is clear enough - but more annoyingly repeated iteration will silently break in Python 3 (the first iteration "consumes" the iterator, the second one gets an empty iterator)
Great piece, I'm currently building API for a financial data website and your code looks on point, I'll sure take a look over it when I have some time. 😃
Ah, ok. Thanks. I remember running into the map and filter iterators issue, now that you mention it. 
I read your question as: "How much *functionality* is there in Python's standard library?" There are two sources of packages (collections of modules) in Python. One is the *core* library, that is included with the basic installation of Python. To find out what it can do, see https://docs.python.org/3/library/index.html The other is PyPI, which is a repository of over 100,000 Python modules and packages. To find out what is available there, use the search box on https://pypi.python.org/pypi Hope this helps. Good luck with your Python programming.
&gt; Serious question, isn't virtualenv available on windows? Yes it's available but I've never used it. I program at home purely for fun so am in complete control of my own environment so have never had a need for it.
Oh hey, you're the troll that can't stop commenting on python threads. RES tells me I have you at more than -30. What a sad existence you must lead. 
&gt; AbstractUser.last_name max_length increased to 150 🤔
That would just be confusing for Python programmers though. Python has its own style.
It probably has to do with switching operating systems or something similar. Use pycharm and you should be good
Nice changes, they all make sense. Good on the Django Project and its developers.
My question was not about style, but about different functionality.
In my opinion, data belongs in files. Stdin is kind of silly unless it's some really trivial script that doesn't have to support Windows.
sauce?
for you only [the best](http://i.imgur.com/aoc2dYi.jpg). 
But Perl is in base. Scary.
Yeah, but then you have to ensure that they're created before being used. So either in `setUp()` or by making `.the_user` a property (and creating it on first access).
Agreed. Security patches are dumb.
Haskell is a language I want to learn some days. I'm not sure what kind of stuff you can build with it or what its sweet spot is. I've seem compilers or static analysis tools for others languages written in Haskell, so it seems to be good at that at least.
You might want to post this over in /r/learnpython, as this sub's scope is news about Python.
No, data doesn't always come from a file. E.g. may be called in a pipeline. Use fileinput to deal with this as below. This will read a file given on the command line, or stdin if no file provided. import fileinput for line in fileinput.input(): process(line)
I create an in memory sqlite database for use in some tests - that blurs the line between a unit test and an integration test - but as it adds no dependencies...
Shame this doesn't generate Python3 type hints
It's mandatory to people who've learnt it, for others, they almost don't see the point of it (and I was there at some point) I haven't looked into pytest yet, I have heard good things, but unittest is enough for me so far.
I did in another comment. Probably one of the most important things I've ever learnt in my commercial experience. Simple, but very important. https://www.reddit.com/r/Python/comments/7cs8dq/senior_python_programmers_what_tricks_do_you_want/dptxupv/?context=3
[Magnivore](https://github.com/wearewhys/magnivore). I have to move a large database from MySQL to Postgres, so I created a tool to move and tranform data among databases, rather than writing a single-use script. It performs at about 10k rows/minute on my machine. The instructions for moving data are written in json. It's not perfect, it could have better error handling and performance, but it works. If you end up trying it, please leave some feedback :)
Haha thanks, also it was for an audience of accountants who the majority has never done any programming, so didn’t want to intimidate them with actual code. 
The latest 2 stable version?
I like to use native GUIs, but nothing (including QT) can even touch the "batteries included" of JS/HTML/CSS. If you don't want to spend time implementing your own form validation, data tables, grid based layouts, prebuilt styling that looks great cross platform, and literally hundreds of thousands of other packages (npm), go for the web ecosystem. The major downside is that it will be harder to distribute (nearly impossible to do standalone binary unless you use something like Electron or CEF) and you have to use JS (or one of dozens of languages that transpile to it) 
&gt; Upgrading wasn't painful. It was the community's refusal to upgrade that was painful. They've given what, 12 years of support? 2to3? Backporting of features? No new features in Python 3.1 and 3.2? What more could they have done? They could have realized that most libraries will have to support both 2x and 3x for a long time (same 12 years), and they would want to do that from a single codebase, so support for doing that with minimal pain should be a priority. A library like six or future, and probably a tool like 3to2.py should have been provided from day one. Instead, initially the very possibility of having the same code running under both version was considered to be no more than a party trick, and instead of leading or at least supporting community initiatives the core team carelessly broke them, for example by removing unicode literal support from 3.1 or so. That the migration seems to be more or less complete, at least for new projects, more than a decade later, is a miracle and the Python core developers receive less than zero credit for that in my opinion.
Use it at home too. It's not just a corporate tool. It allows you to start new projects without the worries of breaking others. I completely removes you from worrying about dependancy versions. It's probably the most important python tool
Not yet. They need the plugin system to be finalized
Hello! I'm the author of this blog post. Please feel free to reach out either here or on our IRC channel #wallaroo on Freenode.
Not sure why you would need to unit test the relationships, when you should be unit testing the data that gets pushed into it...the relationship is either one to one or one to many, between those two specific tables. Regardless, your user table would have to be populated first before you associate an address with a user.
Google didn't drop Python and neither will Dropbox. The core of Dropbox is already written in Go. There is a lot of backend stuff and internal tools still written in Python.
I work in finance. All the young finance professionals here have been moving to python from R and matlab. 
From [here](https://about.sourcegraph.com/go/go-reliability-and-durability-at-dropbox-tammy-butow/): &gt; Today, most Dropbox infrastructure is written in Go. From this [engineer @ Dropbox](https://twitter.com/jamwt/status/629727836673175552): &gt; Our entire infrastructure service layer has been rewritten in golang, 10s of thousands of servers running millions of hits per second. *Feeling pressure uh?* 
 pip install sortedcontainers 
I am, and the main thing so far is that there isn't a compelling business case for me to port our product to the new platform. Everything is working well and all the libraries and extensions we use are working, so we'd need to believe there was a big enough "win" to justify the cost of making the switch. Also, some of our customers are still using Python 2, so that's another disincentive to change. That's probably a self-defeating situation though.
It'll work and they said they'd accept a pull request. A bigger shame is it doesn't handle exceptions.
Better to migrate sooner than wait till security holes in 2020 at the legacy python end of life. Plus you get speed gains. Also you might be surprised how much if not all of your app works after just running `2to3` on it. Still, I sympathize. Waiting till 2019 wouldn't be the worst thing
At work I am. We still support RHEL 5.5 systems. The estimate is that with a suitable set of imports from __future__ will make the effort of eventual switch less than building pythin3 for that ancient platform.
For speed it depends on the application, it might get slower, but probably it will be the same.
supervisord, beanstalkc, M2Crypto, amfast.
&gt; Also, some of our customers are still using Python 2, so that's another disincentive to change. That's probably a self-defeating situation though. wouldn't you want to be ahead of them on the change? What happens when your customers decide to switch, if you're not ready to go, they won't be happy. Sure maintaining a 2 and 3 compatible code base isn't great, but it is doable.
Documentation, spelling mistakes in error messages. If possible, translation. Follow the quickstart and see if it's still correct with the latest version. All this stuff needs doing.
I doubt that there will be that many security holes in Python 2.x in 2020. Even if there were companies would be able to get paid support from third parties, a far cheaper option than needlessly porting 1000s of lines of working code. `2to3` is certainly a useful tool but it has limitations, e.g. there are 53 open issues against it on the [bug tracker](https://bugs.python.org/). However relatively speaking that all pales into insignificance when you compare the string/bytes/unicode issues that have been a real PITA for e.g. people taking data down the wire. They have my deepest sympathies.
Yup, Film and VFX industry. But we'll be able to start upgrading once 2019 rolls around. This is due to the reference platform which was created in recent years to standardize the library versions used for studios, so all applications pretty much use P2 internally. http://vfxplatform.com
yeah, I'm just disappointed that 2 is the initial target of new tooling.
Lack of control over my life
A related question: Do you (library authors) plan to start charging for, or refusing, Python 2 work? I had a contribution refused because the code I provided wasn't backwards compatible :-/
If I'm having to actively develop python 2 along side them, why would I want to get ahead of them? And sure, I could do many things, but since I have limited resources I have to make choices about which 
What version of python are you using?
3.4.0
Speed gains aren't at all important to me (my main project operates at human speeds so is littered with `sleep` statements already to slow it down). That said, losing bug support and any libraries I use will be a pretty big incentive to change.
&gt; What concepts of functional programming would you like to see in Python? Proper lambdas and tail-call optimisations would have been a good start, back in the 90s.
&gt; RES tells me I have you at more than -30. What a sad existence you must lead. Yes, your downvotes keep me awake at night. Please stop, I can't take it any more! Oh wait, I have 76,192 silly points in total for comments right now. Whew, that was a close one...
Presumably you mean [queueutils](https://boltons.readthedocs.io/en/latest/queueutils.html#module-boltons.queueutils)?
Have you made those lint checks available?
Python 2 is used by a major GIS industry software provider, so shops that work with arcGIS will use 2 until ESRI decides to change.
I didn't mean to ignore you, Corm; it's just been a busy time. We're all still learning best practices for containers and virt-env-s; that conversation is part of what I hope to encourage here. MisterTheCookiePear wrote above that, "[... virtualenv doesn't deal at all with dependencies on shared libraries ...](https://www.reddit.com/r/Python/comments/7cs8dq/senior_python_programmers_what_tricks_do_you_want/dpti7tk/)" While that might give you, Corm, an idea of where our focus is, I don't think MisterTheCookiePear is entirely accurate, either. To me, this is just another translation of DLL Hell. ANY of our abstraction and re-use mechanisms are tools that fit better in some situations than others, not panaceas. I'll be more concrete. Several of our individually-maintained projects rely on Redis (not a package at the OS level, but nicely `pip`-able), and a convenience library above Redis. How do we manage those dependences? Part of our team likes to put *everything*, and certainly the two Redis libraries, in a virtual environment. Get the virt env right, and the application behaves consistently whether on their personal laptop or deployed in the datacenter. Cool, eh? On the other hand, what happens if I need to update the organization-specific wrapper library? I make the change, and ... now various people have to update all--ALL--the virt-env-s everywhere. Some people see that as a feature: someone close to each virt env gets to make the decision about whether to update it and when. For some, it's only a headache: they don't want to think about Redis, and they certainly don't want the distraction of figuring out whether it's time to judge my wrapper changes. I'm all the way on the other side (for this purpose). I'm trying to put one Redis library in `/usr/lib/python2.7/site-packages/redis` (let's fight about 2.7 another day), and one organization-specific module in one appropriate organization-specific directory. I update the latter when necessary, and all the clients immediately benefit. There are problems with my model, too, of course, which, for the moment, I leave to the reader as an exercise. There are other models, even. We can interpolate management of reusable components in all kinds of ways. We can talk over best practices for different technologies. We can customize policies for our own local use cases. What we can't do, as near as I can tell, is escape the reality that abstraction has both costs and benefits. I summarize: I asked others, "what am I missing?", and respondents usefully provided tips about wheels, library servers, and so on. I appreciate the help. No one said, "yes, virt-env-ing EVERYTHING is The One True Way because $EXPLANATION", probably because there is no such One True Way in this domain. I'll put it another way, Corm: with virt env-s, everyone has his own copy of everything he needs, and so there are no surprises where some far-distant work messes up what you are doing right here in front of you. Great! At the same time, that means if someone off in the distance *fixes* something, **you** don't benefit from it until you--or *someone*--synchronize(s) your virt env with that update.
Thank for your feedback, really appreciate. If you ever need help with your own project, I'm always happy to help.
Do you have a link to the change, I'm curious how much is involved with making it compatible. Generally six is a bad idea because it hacks imports and runs unexpectedly on startup. 
I am honestly surprised that there exists established professional software developers that don't know about unit tests. If you are new to the world of programming, then fine, you get a pass. If you have only ever developed alone as a professional developer, then it's also possible to have heard of unit testing but such people are still incompetent IMO and should make it their no 1 priority to learn it immediately. Everyone else who works in teams should know about unit testing. If you have worked in a software team for more than a few weeks and you don't know about unit testing, then that sets alarm bells ringing. It tells me that not only is the developer incompetent, but the team and maybe even the departmental culture is incorrect too. It suggests that the team itself is not in the habit of writing tests, or they do not call out developers who do not write tests, which is a worrying sign. On the subject of pytest, definitely look into it. The tests you write often look more Pythonic because you aren't forced into writing a unittest.TestCase subclass for every one of your tests. The minimum for a test is a top-level function. Also, you use the built-in `assert` keyword; none of this `self.assertEquals` stuff. Lastly, you don't have to rewrite existing tests. Pytest supports unittest nomenclature so you can keep your existing tests working while you write new tests in the pytest style.
Interesting, what kind of work do you do with Python and VFX? I always wanted to work in the film industry but I stumbled my way into being a backend web developer...
I do (or did) a lot of consulting on the BRTT Antelope seismic data processing system Some years ago they decided to switch from TCL to Python 2 as their embedded scripting language Unfortunately they refused to use NumPy because they HATE dependencies so trying to process seismic data in Python was slow as shit and then they decided to just use C++ for all their heavy lifting and Python became a second class citizen At this point I doubt they'll ever upgrade
I don't think we *created* any ourselves, just enabled &amp; configured those PyLint provides.
The wheel you downloaded is for Python 2.6 (that's what cp26 means), which is probably why it's not working. Try downloading the wheel for the 3.x series. Also make sure you download the appropriate "bit-ness" (i.e. 32 vs 64). Finally, make sure you download the wheel appropriate for you platform (i.e. Windows, Mac, Linux)
can you help out, i dont get how to install latest wheel version. Cant you do something like pip update wheel or something?
I knew about admin being required. You are the Man!!! This is exactly what I've been trying to find.
You don't think an object of type Heap should guarantee that it is in fact a heap? Should an object of type int occasionally be allowed to be a string?! I would absolutely expect a heap object to try and provide some better guarantees
i went to this site https://pypi.python.org/pypi/wheel#downloads and the latest version of wheel is also a whl download, how will that be installed?
so whats dropbox like nowadays? remember a big issue with privacy and security a while bk, have they gotten better?
&gt; You don't think an object of type Heap should guarantee that it is in fact a heap? As you yourself said, nothing in Python is ever guaranteed. Guaranteeing that it's a heap is *already* done via the functions in `heapq`, *if the user doesn't tamper with the data*. Similarly, the thin wrapper class would guarantee that only using its own methods will never violate the invariant -- but that's not the same thing as what I think you're asking. &gt; I would absolutely expect a heap object to try and provide some better guarantees than a heapified list. I would also expect any object, anywhere, to only provide guarantees if you use its approved methods. Which such a wrapper class *would* provide, and which is *already* provided by the module. Just in a somewhat-less-clean-than-could-be manner.
&gt; We do often write code that accepts either sequences or generators, but the right way to do that is to immediately call iter on the argument This doesn't help at all. An empty iterator is still truthy. In fact, this makes things worse: &gt;&gt;&gt; a = [] &gt;&gt;&gt; b = iter(a) &gt;&gt;&gt; if b: print('non empty') ... non empty It's hard to keep track of the intricacies of all these different approaches. But the behavior of the `if myCollection` check, when applied to things that aren't actually lists, tuples, or dictionaries, *requires* you to be thinking about these things and to know the behavior backwards and forwards. To me that makes the code much less readable. Duck typing is good as long as the thing you're duck typing on is logically the thing you care about. Once you start duck-typing on something that's just a proxy for the thing you care about you start moving into territory where your code may *look* nice, but it has a bunch of hidden gotcha's that you have to be aware of - all the cases where the thing you're duck-typing on isn't actually the thing you care about. The result is bug prone, and despite looking simple, much more complex and difficult to understand than a more explicit version.
Thanks for your advice, I was thinking about contributing to Selenium because I use it everyday in a script that I use to automate logging hours online at my job. I was thinking it'd be a good idea to contribute since I already use it on a daily basis. I just wasn't sure where to start. 
ok i downloaded the Pillow-3.4.0-cp34-cp34m-win32.whl my system is 64 so i also tried with Pillow-3.4.0-cp34-cp34m-win_amd64.whl got same error both of the times.
Pull down the code and run the tests.
That's the one
It might be also amount of resources you can put into it. My friend works directly in Redhat and he told me that they have been moving for a several years already, and it will take another several years to finish. Sometimes the codebase is just huge.
Can you use conda instead? Are you forced to manually download packages? Pip will download and do dependency management assuming it has an internet connection.
Yes, but I recently went through the entire code base and used six to make it fully compatible with 3 and 2 at the same time. Now I sometimes run in 3 and we have a continuous integration build that fires off all the unit tests in 3 to keep it clean until we fully switch. At the moment the problems in 3 are: (1) one unit test out of thousands always crashes with no output using pytest xdist, and (2) cythoned extensions run 8x slower for some crazy reason.
no idea what conda is, wanna stick to pip/pillow cause lots of related resources online in case i have problem in my program. Also seams pretty easy.
Are you bragging about reddit karma?
Haha, well IIRC it's used by some of the tools in the base system.
Is there a specific reason you're trying to install it from the wheel file and not just have pip download and install it?
[wxPython](https://wxpython.org/) support for python 3 isn't out of beta yet.
Dunno about u/omento, but what I did was a hell of a lot of automation of artist tools, rendering submission, and database interactions. VFX involves a lot of glue between programs like Maya and Houdini and Nuke, all of which have embedded Python interpreters. Unfortunately none of the vendors used to coordinate at all in their release schedules or what version of Python / Qt to support, which made for a nightmare in companies using multiple versions of multiple programs simultaneously on multiple projects. The VFX reference platform helped, though it's been (too) slow to finally make the leap to 3 until very recently.
Orefeo Toolbox (OTB). Only part of my entire workflow that doesn't have 3. Very very annoying to be stuck behind, at least partially, due to a single component's inability to manage new version transitions.
I am a student, I'm definitely going to use this website. I have no idea this existed, thanks!
lol yeah i just did pip install Pillow and it worked, i was downloading cause i googled and that was how it showed to install so i was just following blindly.
I use ROS for Robotics and for now it's pretty much Python2.7 everywhere.
So you are just here to troll. Nothing to see here folks, please move along.
[(ana)Conda](https://www.anaconda.com/download/#windows) is a python "distribution" that includes a bunch of the packages people might want and the low level dependencies (libjpeg, libtiff, etc) that the python packages need. I just makes all of the package installation type stuff easier. Wheels have solved much of these problems though so sticking with pip and your local python is fine. It kinda just depends whether you think its worth it to invest time in solving dependency problems (use pip) or if you just want to get to using pillow as fast as possible (use conda). Have you just tried doing pip install Pillow as recommended in the [Pillow docs](http://pillow.readthedocs.io/en/3.1.x/installation.html#windows-installation)?
That's what dropbox's code is on so makes sense. In some ways it makes more sense targeting py2 since it's much nicer to have static checking BEFORE you change to py3 than after.
How does this compare to http://transcrypt.org or http://brython.info ?
numpy's note doing anything in 2018, dropping Python2 support won't happen until Jan 1, 2019 at the latest.
Upstream wants to move the other way, with avoiding the versioned alias as much as possible. The idea is to not have everyone's scripts break when python 4 comes out.
And I would forgive the heap class if the cause of the heap violation were someone mucking around in the "private" data. I would be less forgiving of the class if the issue were that the data in the heap were mutating. The dict class won't accept mutable keys, and the proposed Heap class should similarly reject mutable keys.
The machines I need to run on are hard to install binaries on, easy to install scripts on and use old releases for security/stability reasons. (Meaning that they've thoroughly tested the software in that release, not that the software itself is necessarily better.) I'm probably still 5 years from even being able to run python3.
This is awesome, thanks for the detailed reply!
I use Python 2 for Ansible modules. Support for Python 3 for Ansible is still marked as 'experimental'; I'm waiting for it to stabilize.
It isn't like old numpy versions are going to vanish off the face of the Earth. They will still be available. You just won't be able to use the latest and greatest numpy with an ancient version of python.
Making a bot to play Keep Talking and Nobody Explodes. Or more precisely for this week: making one to identify all of the modules and gubbins on the bomb. Interacting with it likely isn't going to really get going until at least next week
I have to work against an upstream vendor python who's version stability policy is even worse then RHEL (so much so they bundle their own, older, python.) I mean, I'm still waiting longingly for the python 2.7 features to show up... We're on 2.6 now.
Too much legacy code and not enough resources to do the migration when other projects keep coming up in the meantime.
Or anyone who wants numpy devs to be able to focus on improving numpy without having to be held back by old, unmaintained software and old compilers.
Because it was more trouble than gain to switch to python 3. I'm using python to do stuff with it, not for the sake of using it. The python dev simply failed to provide improvements worthwhile of breaking the compatibility. Basically, when python 3 went out, we where trading compatibility and speed against better unicode handling and that's all. Many people were not motivated to put the work necessary to switch for something they didn't see much interest in. It's much better now, a lot of libraries are available and it's faster (although afaik not as fast as 2.7) but it's 10 years after. I see on this sub a lot of toxic comments blaming the python 2 -to 3 transition failure on he python community, but when your user base is not following you, maybe it's time to reflect that maybe they have good reasons and you are the one in the wrong (I actually think the Python dev already acknowledged that fact). 
We use CentOS 6 &amp; 7. I can always count of 2 being there. I'm not going to install 3 on +30k servers.
A lot of libraries are planning to drop support around when upstream drops support in 2020.
Until the percent of users on 2.7 becomes negligible, I don't see the point in jumping the gun. If your codebase already works with 2/3 it's pretty easy to maintain compatibility. Plus you still need to support older versions of 3, so you can't use cool things like f-strings or type annotations either way.
Yep, still on 10.2. No desire or need to go to Pro.
Keep in mind there may be holes that are already found. A wise and patient hacker might just keep it quiet till 2020.
I've used beanstalkc on python3 with no problem.
We use Twisted at work.
That's what worries me! Reminds me. I once filed a bug that `ed` wasn't in base, since it's the [standard editor](https://www.gnu.org/fun/jokes/ed.msg.html) They weren't interested in that.
Selenium is a great project, but it is also big and mature. Your learning curve might by quite hard. IMO, the best way to join a project is to submit a bug (either encountered or QA-ed) or adding small feature you want. (My first code contribution was adding `sorted` to function returned value) Note that many projects are following the open/close principle, which may require you to write extension rather than a patch.
 Duuuuuuudeeee that's excellent. I'm still a rookie programmer.. like three months in, but this is so awesome, I'm happy for you! I do have a question again, so rather than just saying you have Python experience, I'm sure you want to upload some projects somewhere. Is there a place other than Github you would do this? 
My team's Ansible automations stop working when I change the Python version to 3.6. The URL module breaks. If someone happens to know a way around this... then maybe we could switch easily : )
Look at Tactic, it's python web framework for the industry. 
Pretty much as u/yawpitch said. Personally I'm working on GUI tools, automation scripts, and project management implementations. The only time I use 3 so far is when I'm writing non-vfx related scripts or working with client side PyQt5 and bundling it with PyInstaller for distribution. Currently Blender is the only application that is using Python 3, and is a pretty sizeable reason as to why it's not integrated in pipelines. There are a lot of IT and tech positions available at studios, so you can always try your hand and apply. I'm only a student so I can't really speak as to who wants what right now.
The modules I need either haven't been ported to 3, or those ports haven't been packaged in the distribution.
It's interesting that when I tired this in Python 3.2 I get this error: https://www.data-medics.com/files/3.2error.jpg But, upon upgrading to 3.6 it's working fine now. Perhaps a change in syntax between versions has been my issue all along.
Great intends! From the top of my mind, I can recommend you listen to [good podcast](https://talkpython.fm/episodes/show/132/contributing-to-open-source) by Michael Kennedy. But anyway the best approach will just scan projects that you like, choose some with small amount contributors or with a good amount of issues that you can solve in a reasonable amount of time. After it, just write good code and reach out to other contributors. You also can write docfiles/comments, good documentation will attract new contributors and users. You can PEP8 code of other people, but be careful with it. And the end, if you confident in your skills, you can refactor some pieces of code, but also add a comment regarding why you change the code and why.
I don't understand this argument. Just because the default system version of python is old, doesn't mean you have to use it. Why can't you altinstall python 3 in /usr/local and then use that in a virtual environment for your project?
The platform I work with (Splunk) does not ship with Python 3. 2.7 has a much wider install base. 
This hits home
I use sage and it doesn't support python 3
You manage 30 thousand servers and don't have an automated build/install/upgrade system? Why on Earth would you be manually installing software?
My problem all over again.
Have you tried compiling python3 on RHEL 5.5? It's not as simple as `./configure --prefix=/usr/local &amp;&amp; make &amp;&amp; make install` It's been a while, but as far as I remeber, there is some crypto requirements, that are non-trivial. Also, we have some requirements wrt. to repeatability, that in effect mean that we would have to create a set of rpm packages to deploy. 
I don't have a reason to port old projects to 3. A better question would be why I'm still using Django 1.5
Pretty much yes, for the same reasons cited by Charles Harris and company: MSVC2008 for Python 2.7 is too much pain to have to program around, and there's not enough time in the day for open-source work (which is mostly unpaid). I do know that Continuum wants to release a Python toolchain compiled with LLVM on all three major platforms but I don't know what the status of that is. 
Did you try something like this? my_device = None for device in UART.find_devices(): if device.id == my_mac_address: my_device = device break if my_device is not None: my_device.connect()
&gt; That's what worries me! I mean, at this point I'd imagine most bugs arising from using perl in the base system *should* have been detected and fixed.
It's the standard!
Yeah, this Github search will show you open issues in Python projects that have been labeled "good first issue". https://github.com/search?l=&amp;q=language%3APython+state%3Aopen+label%3A%22good+first+issue%22&amp;ref=advsearch&amp;type=Issues&amp;utf8=✓ You can use advanced search to refine it. Hopefully there's something there that you can start on.
Thank you very much for your kind words :) Github, Bitbucket, etc. should be fine for any code projects. However, it's also a good idea to bring a copy of your code to any interviews you have. My current co-worker flunked his first technical interview, but he had his dissertation code on a CD which he then gave to his interviewer afterwards, as a way of saying "I'm not an idiot, here's proof I can actually code". This saved him and he was allowed to move onto the next stage of the application process.
my final version looks like this: https://repl.it/@jkibbe/Guess-the-Number-with-dict
There is rpy2 for calling R from Python, if you ever need it. You can even pass Python callables as arguments to R higher-order functions. As far as I know, there is nothing comparable for calling Python from R.
Guys, Thanks for all the comments. For what you all have said, I've decided to learn python and use RPy to handle to statistical analysis!
I use Python3 just because everyone says I should. There's tons of good libraries out there for 2.7 and I'm lazy enough that having the wrapping parens is an active dislike of py3. I have used but don't know enough about the new stuff in 3 so there doesn't seem to be enough great reasons to switch over. It's better incrementally, but I'm very happy with 2.7
I'm generally using Python for scripting level server utilities. I'm basically using it more and more where before I would've used Perl for that sort of stuff(20 years of habit is hard to replace). At the moment it's a guarantee I'll have a 2.6+ Python interpreter on up as a base install on systems(Ubuntu 12-16, CentOS 6-7) so it's an easy target to hit without having to write Chef recipes to make sure I have a proper 3.x environment across 80+ servers. Recently I did a new script for just a couple servers and went ahead and did that in both Go and Python3. Go would be a really easy deploy across all systems. I tested that years before and was able to write binaries on new Ubuntu installs and run them on 10 year old CentOS systems. I really want to like that language, but man, it just feels so obtuse to work with. Particularly JSON which I used for the script. So looks like I'll be rolling out Python3, but I probably won't be in a rush to do so. If distros dropped 2.7 or there was an awesome lib I wanted that was only in 3.x, then I'd feel the pull more. But right now I have this feeling like I can use 2.7 where it's easy to use 2.7 and use 3.6 for more stand alone uses.
The string/bytes/unicode issues I had when porting code that dealt with nasty file ingress and raw network things all turned out to be timebombs waiting in my code anyway. Python2 made it way too easy to get that wrong. Sure, it was a pain in the ass sorting them out, but damn if it didn't fix things.
Oh man. once QGis 3 hits, ArcGIS is a ghost of bloatware
in 30 years python 2 devs retire, amiright
A client who has a pretty large library they use and they won't let me port it, everything else I use python3
sounds strange, as numpy is just a C library, ain't it?
You can do multiline lambdas if you use a parentheses
Use [type hints](https://docs.python.org/3/library/typing.html)! Ideally use a static type checker like `mypy` too, but even if you don't the type hints alone make your code about 10x more readable. Also it forces you to reason about the types you're using, and if the types you're using are hard to reason about, that itself is a code smell.
If you had 100 servers that you need to deploy with reproducible configuration management (chef, ansible, etc) you'd understand.
I am no longer in GIS. But if this were to actually happen... I would shed a tear of happiness.
ArcMap
For future proofing yourself, https://wiki.python.org/moin/WindowsCompilers If you setup the necessary compiler on your computer, you can use `pip install` for almost everything else.
ya fixed it
Lol no I don't use RHEL because I don't hate myself. I just know it's possible because a place I worked at years ago did it that way.
Yeah, I've seen Tactic. The thing is you'll notice that none of the clients listed on the site are major VFX companies, or even mid-level ones. It's really hard for B2B vendors who aren't making very niche VFX-hyper-specific products (rendering engines, image analysis tools, fluid-dynamics solvers, procedural generation systems) to get purchase. There's a few big vendors (mainly Autodesk and The Foundry), and then there's guys writing more or less speculative tools that will probably never get picked up by the majors because they've already had an in-house solution for a decade. Key problem; most of these guys are trying in some way to leverage the cloud, and -- although there's been some slow movement -- that's *verboten* by most of the Tier 1 studio projects.
Why would you assume the installations are manual? If the various parts of automation break during the install, it could be painful even with full remediation via automation.
Python2 is one entity. Is is mature, stable, and works well. Very, very few libraries and other things do not work in 2. 3 would mean that I have to support 2 and 3, and what do I gain? Nothing at this time. I don't have the time to work with both, and with no real external push to do so at this time, I'm staying put. Also, I work for a for-profit company. My for-profit company will not make any more money with a Python3 codebase vs a Python2 codebase. It wouldn't surprise me if Python2 would be used for the next 10 or more years. If everything were to work in 3 without any effort, then of course everyone would go to 3. Is 3 better? Yeah, a bit. But 2.7 is quite good. And until there is a clear business case to do so, we are not going to move.
RedHat will be supporting RHEL 7 (and by extension CentOS 7), complete with Python 2.7, until at least 2024.
https://www.codetriage.com/
I wouldn't call myself a software engineer. Here's the professional breakdown the last 6 years: FedEx courier &gt; commercial crab fisherman &gt; unemployed (using time to learn php, sql, web dev) &gt; low level data entry job with wildlife agency (ms access) &gt; data management job (ms sql) &gt; fisheries biologist (python, pandas, r, flask... etc) I'm a biologist who has flask running on AWS to handle data coming off our mobile devices. I then use pandas, bokeh and other scientific libraries to do data analysis on the server. 
Same. Fuck ESRI.
Then download Anaconda.
Fantastic and highly insightful explanation, thank you very much claird!
Wow. See, this is exactly why i commented. This info is invaluable. That's so excellent. I'm also not the best under immediate pressure, so that will be a great idea! 
Pretty sure supervisor supports python 3 now. At any rate you can use py2 supervisor to launch a python 3 app. I'm doing this in production right now
Man, old memories of ArcGIS caused some stabbing pain. All my empathy to all of you out there forced to use that engineering nightmare.
I have one teeny question about the speed test you did - is there a particular reason you decide to clone a 1,000,000 length list of letters in the pure python example? I refer to this bit of code: def count_doubles(val): total = 0 for c1, c2 in zip(val, val[1:]): if c1 == c2: total += 1 return total `val[1:]` duplicates just shy of the entire `val` list in memory, which for a large val is a massive waste of both time and memory. I would expect it to very nearly double the runtime of the function, since the vast majority of the runtime is just iterating across the entire input list, and now you have to do that twice. Admittedly given the runtime saved by using Rust over pure Python is much more than a factor of two it doesn't invalidate the results, but it does seem a bit disingenuous to use what looks like intentionally slow code for the pure Python example. 
It can surface even in things like `pprint` (if you are trying to pretty-print a set).
No problem. It’s a really powerful part of testing. Once you get your head around it you’ll be writing much better tests and code I hope!
No, it sounds like an incompetent operations team.
Ditto.
CentOS
Because my coworker is an idiot who convinced everyone the new project should be done in Python2 because he could figure out how to use the ctypes package an claimed a library wasn't working in python2. Even worse he doesn't import anything from __future__. This was 6 months ago.
No competent operation team would ever think to install stuff in /usr ( bin, lib) except with the certified package management. Putting at risk library dependencies and all. Different discussion if we have standalone stuff in /opt, but python heavily relies on system libs, it's not the case.
I hope to be done before then!
The application i make text file processing for uses iso8859-1 so due to being lazy i use the easy way, using python 2.
Sometimes you don't have the chance to install a new version of python, where i work i constantly deploy python scripts into our customer's servers and I just have to work with what they have there... companies don't want you touching stuff on the fucking database server.
I can't remember where I was on reddit, but it was a holy war of talking about 80 characters is _professional_. Professional programmers use 80 and anyone who goes over that limit doesn't understand that you're being careless.
The usual reasons: A massive homegrown py2 codebase with no significant reasons to upgrade. 
why would you compile it? yum install python3
Laziness to convert my old projects. 
Did you miss the RHEL release?
And that's why you use C++ with ROS instead
Isn't this literally the point of using a tool like chef? My company uses saltstack instead but installing and using a new version of python on every one of our servers requires a short yaml file and a single command from the master server to push out to all of the minions. (I know Chef uses pull from minions rather than push to minions, but still) Sounds more like your company could use some devops improvements
It is pretty automated. The main obstacle would be that while they are all cent 6 &amp; 7, they have varying purposes, different generations and I would have to get multiple dev teams to buy in. I'm in operations so most of what I use python for is automation of administrative tasks. 
why are you using python3 to run ansible? Python2 and 3 can be run side-by-side. Unless you are actually working on the Ansible code base it shouldn't matter which version of Python your script is written in. This is like saying you can't write in Ruby, or use a bash script because of Ansible. It makes no sense
No doubt it's possible. We just estimate that it will take more time now, than porting to 3 will take when we get rid of the last dinosaurs.
What a troll comment lol
My typewriter only supports up to 2.7
Use click. It’s the best option I’ve found. http://click.pocoo.org/5/
I started with a youtube tutorial, and it seemed easier than other languages. Installed python and tried a simple script and it worked. Most of the learning after that was by searching on google for how to do specific things like opening a file, getting a specific tag with beautifulsoup, whatever else. After I had a few scripts made, I went back and saw a Pluralsight tutorial which is very reference / documentation-ish, which helped me understand more of the basics and what a feature can and cannot do. Right now I have a python website, image scrapers, movie database + imdb scraper + random things
Mechanize
I've yet to work for a company using python 3. I'd be more than happy to use it, but there hasn't been any push to upgrade.
Was tasked with writing something in Python. Looked at 2, looked at 3. Oooh... formal Type Hinting support in Python 3.5? And it works in PyCharm? Yes, please!
What a troll comment? If you're using Python with ROS instead of C++ then you've missed the point. Python has plenty of high quality, low effort IPC approaches you can take, while C++ has very few of quality, and none that are low effort. Python sucks for any robotics involving hardware compared to C++, and developing something in 2.7 when you don't have to is silly. Thus, the use case for ROS lies with the IPC benefits it provides to a C++ robotic system with hardware in the loop, especially considering there are no tangible benefits to ROS + Python that you can't get elsewhere for less effort and more payoff.
Why not? That's exactly the use case for `/usr/local`, and any package management will complain if you create a package installing things i `/opt`, because it's for unpackaged stuff.
No worries :) if you have any more questions don't hesitate to PM me :)
Too lazy to add parentheses to the many debug print statements I use
That's my point, the /usr filesystem on mission critical systems should be reserved for packaged programs. Red Hat as a business case for a reason ;) 
Thanks! It looks good, but I'm not sure how well it'll work for Python 3 considering all the caveats. However I don't anticipate needing any characters without an ASCII equivalent.
The Rust code too could be suboptimal because it decodes the UTF8 twice. This could be faster (not tested): fn count_doubles(_py: Python, txt: &amp;str) -&gt; PyResult&lt;u64&gt; { let mut chars = txt.chars(); let oc1 = chars.next(); let mut count = 0; if let Some(mut c1) = oc1 { while let Some(c2) = chars.next() { if c1 == c2 { count += 1; } c1 = c2; } } Ok(count) } 
Complacency and comfort in the known. Why change?
Well, that's the thing with Tactic, it's not cloud based. 
Red Hat.
Whoa, now that's an unexpected place..
Please don't even get me started. The idea of using python for scientific computing without numpy/scipy because "NO DEPENDENCIES" is ridiculous prima fascia. PYTHON IS ALREADY A FUCKING DEPENDENCY AND THE WHOLE SCIENTIFIC PYTHON COMPUTING WORLD USES NUMPY. "A foolish consistency is the hobgoblin of little minds, adored by little statesmen and philosophers and divines." --Ralph Waldo Emerson I might add "academics"
It's not either/or. Many ROS systems use components written in each language. The components that are in python are effectively limited to 2.7.
I don't understand your argparse comment. It does exactly what you want, easily.
Same boat, too many dependencies haven’t made the transition yet.
I feel your pain. I've got a 32-bit Open SUSE 11.3 machine running that is just a time bomb waiting to go off. It's running this software written by a third party, depends on a custom kernel (no source available) and no reasonable way to port it to a machine with newer hardware or OS.
Sure, but that doesn't make it a good idea
Happy Cake day! 
We wrote this little VSCode extension that lets you find code on GitHub that's similar to the code you're writing. That's very helpful when you're using an API you're not quite familiar with, of if you think there's a better way to do what you're doing. Please let us know what you think!
The benefits of python3 are obvious. The only discussion will be is it worth the time to port all the old python2 code you are still using to python3? For many companies that could be months of work. 
If it's something you are able to decide for yourself, absolutely use 3. But if consistency is required, then yes, have a conversation with them about it. 
update: have my 2nd mid-term next week and its been going great...have a 94% in the class and scored a 95 on the first mid-term :) . We're currently learning about classes and inheritance. I created a log parser at work(nothing too fancy) and it was implemented(with some extra modifications from a seasoned engineer haha) into our test automation so I was pretty stoked about that :P as soon as sign-ups open I'll be signing up for Advanced python for Spring 2018!
VectorCAST, dSpace, ETAS. Tens if not hundreds of thousands of dollars of hardware on specific versions of everything. 
The 'Repository' link 404s. It points to https://github.com/betai/Boris
With 3.6, and especially 3.7 from what I'm hearing, there are some VERY real performance wins in CPython.
What I mean is where should I store the arguments when they're in all in different files and I don't want to rewrite everything.
All new projects are 3, old projects on 2 are staying on 2 until EOL of those projects, probably. 
We used it in CS 1000 at my first college. I wasn't too hot on it, and wanted to use C or C++, but I did my assignments and passed. I transferred schools and my CS 1000 did not transfer, so I had to take it again. At my 2nd school they used Java. I found myself missing Python. I learned C and C++ in graduate school, but always found myself going back to python to do stuff. I used matlab extensively for machine vision, and computational intelligence type things. Once I got out of school and didn't have matlab i found that I could do 99% of that stuff in python for free anyways.
Usually we use `numpy.arange` for that. &gt;&gt;&gt; import numpy as np &gt;&gt;&gt; np.arange(0, .1, .003) # from 0 to 0.1 in steps of 0.003 array([ 0. , 0.003, 0.006, 0.009, 0.012, 0.015, 0.018, 0.021, 0.024, 0.027, 0.03 , 0.033, 0.036, 0.039, 0.042, 0.045, 0.048, 0.051, 0.054, 0.057, 0.06 , 0.063, 0.066, 0.069, 0.072, 0.075, 0.078, 0.081, 0.084, 0.087, 0.09 , 0.093, 0.096, 0.099]) --- If you have more questions like this it's better to post them on /r/learnpython. Be sure to [format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin. Also, include which version of python and what OS you are using. 
The happy news is that being an end-user of Ansible on Python3 has been fairly smooth for me. Once they mark it as stable, I expect it will actually be very solid.
Thank you for the quick response! I will be sure to post there in the future!
&gt; The benefits of python3 are obvious When someone starts the post with &gt; Python newbie here Then no, the benefits of Python3 are **not** obvious. OP literally talks about comments like yours &gt; I have recently seen a lot of posts about people considering it a no-brainer to move from using python 2.x to 3.x It's incredibly frustrating seeing people just say "well duh it's better!" with little to no explanation. Personally I'm not familiar enough with the benefits to offer an argument aside from "It's the new version where new stuff is and where old stuff will eventually be."
Have you used Greenstalk? It seems quite nice in limited testing (looking at adding beanstalkd to a project, and I'm on a Python 3.6 stack).
Django Piston FML :(
Robot Framework has not been ported to Python 3 and it is a major tool I use to break software at work. Edit: Looks like the RC was put out recently.
Yes, sorry, it's not Open Source yet. We're working on that.
http://docs.ansible.com/ansible/latest/python_3_support.html#what-to-do-if-an-incompatibility-is-found I don't have a ton of experience w/ Ansible, but I've found them to be responsive in #ansible on FreeNode. And Python3 support is definitely one of the areas that seems to improve with each release of Ansible.
A lot of these things don't hinge on "is it possible for us to use Python 3?", but rather, "what's the work that it will take to convert over to Python 3 and what is the risk associated with this?". Hard to convince management to let you do it if it's a lot of work. Also, the greater the chance for a bug to appear because of it means people are less motivated to push for it - because when something goes wrong, then everyone is going to be blaming you.
Is there a good alternative to six?
Would you prefer I just provide OP with [this link](http://lmgtfy.com/?q=python3+benefits)? 
I can see that being a hard decision to make. Every pull request probably doesn't need too much tweaking to make it 2/3 compatible. And so if you've been putting in time all these years to maintain compatibility with both, you're thinking "why would I end that now, just over this one pull request?". But then considering the effect of making it harder to contribute to your project - the cumulative impact of this over the course of years could be very significant. Hard to decide when the right time is to jump off the train. Hopefully when large projects like iPython and Numpy do it, it'll make it easier for the smaller projects to justify.
The "without having to redeploy" is the hard, if not impossible, bit. Otherwise it would be: 1. Create a python package for the shared code in a place where your deployment environments can see it (public github, private github, etc) 2. Add the package to the requrirements.txt of your apps. 3. Deploy If you don't pin to a specific version of your shared python package, a change would be: 1. push change to package repo 2. re-deploy each dependent app
No real reason to upgrade, really.
I just switched to 3 because i got a new PC. Before that i had everything i needed in 2 so there wasn't a reason for me to switch.
I wish I could bottle your rage and throw it at people, so I didn't have to repeat this conversation. I'm imagining something like a Howler from Harry Potter, but just with Python as the subject. 
I deploy Python 3.6 constantly with Ansible, so what?
Containerize it, then. But really, an operations team shouldn't be dictating software design.
I didn't realize that there are a lot of people making these projects. Is there a good place to see the standards for web robots (crawlers)?
So typically you would read all the arguments as basically the first step. You could just save the argparse option object globally, store them in a global object like a dict or custom object, or do something like prime other classes via class methods which save the options to class variables later used by those classes.
Existing projects 
on RedHat 5.5?
Ouch, sorry bro.
'print "something"' is just much much sexier than 'print("something")'
My company. I have heard of people here quitting because of lack of Proper 3 support though!
&gt; Containerize it, then. Docker on RedHat 5.5? Good luck finding a kernel running AUFS , and even in that case, good luck asking Docker Co. to produce an RPM for that version. &gt; But really, an operations team shouldn't be dictating software design. Lucky boy, you haven't ever lived in a Java J2EE Application Server deployment hell, do you?
You guys should probably upgrade.
I guess you missed my point. You could try and avoid the condescending and dismissive nature of that link and try /r/LearnPython? Or you could even google it yourself and provide the self described python newb with a more curated set of resources. It's easy to underestimate how difficult it is to discern crap results from valuable ones when you're new to a subject. 
At work I use Python 2.7. You try convincing my managers that our software that works perfectly fine needs to take on the risk of migrating to Python 3. :(
I'm not OP ... ;)
It depends on your needs, but from the standard library I'd recommend the following: * `string`: Not to be confused with the `str` type, the string module contains useful constants and functions for dealing with strings. * `math`: Perhaps one of the most useful libraries depending on what you are trying to do. No need to memorise the entire library, just remember that if you need a math function always check here first! * `collections`: Lots of useful container types, including `deque` (two-sided queue) which is one of my personal favourites. * `random`: Not useful for cryptography, but whenever you need some pseudo-random functionality this is the answer. As for third-party libraries, it really varies. Numpy and scipy are fantastic when you are dealing with lots of numbers and arithmetic, flask is fantastic for web development.
No, it can be self-hosted, and that's great, but they promote it being on AWS, which honestly automatically loses the companies doing the Tier 1 work that requires you to have a production network that's disconnected from the Internet. IIRC it started in VFX at CORE, and I know of some facilities that investigated it and even used it for a while, but it seems to have gained more traction outside the industry than in. And that's largely because asset management is *hard* and a lot of the companies for which it's hardest are way, way bigger than CORE ever was... they don't need a framework (they've got developer teams that are considerably larger than Southpaw), they need either rock solid turnkey solutions with amazing service level agreements that improve on what they've built -- which, from experience. tactic doesn't -- or they need low level libraries that do stuff faster and better with ludicrously large files. The mid-level companies could use a framework, but don't often have the manpower to pull it together into a meaningful solution, and wouldn't necessarily recognize a good turnkey if it came along, though every few years they think they'd like one. The small guys often haven't yet recognized the real need for asset management, and though they'd probably benefit the most from a turnkey, can't afford it, and never have enough people to make a framework go very far. It's a vicious place to try and eke out a living, especially when the very last thing a producer is thinking about right after a movie is done is whether or not better asset management web tools would have helped. I'm glad they open sourced it though, last I looked it was still closed.
Ouch.
As of now I just deploy off local code, I saw there was a way to do continuous deployments with Bitbucket but was unsure of doing something similar with github. Thanks for your help!
OK ignore the specifics of where you're putting it, I don't know anything about Redhat/CentOS. My point is, if your operations team can't add a Python 3 altinstall package to your servers then they are incompetent. Build custom RPMs or whatever you need to do. The default system python needs to stay on 2, but you are not limited to using the system python.
Ok but that is a different argument. The OP said they don't use Python 3 because they still support RHEL 5.5 systems. I pointed out that is not an excuse because you can get Python 3 on those older RHEL systems. 
&gt; A decade is too long to expect a bunch of volunteers work around the lack of features in Python 2, some of which were specifically created for numpy. Name one of those features.
No it's the same argument - you pointed out "it's possible for you to have Python 3 on RHEL" and my point is that "just being possible is not sufficient".
I would say the increase in popularity was due to big universities replacing C for Python as the first language students learn and in more recent years machine learning.
For RHEL 5.5? 
Would be nice to see the comparison with a better version, can you send a PR? https://github.com/rochacbruno/rust-python-example
Would be nice to see the comparison with a better version, can you send a PR? https://github.com/rochacbruno/rust-python-example
Is this genuine scikit library? Or no such thing? What about this library: https://pypi.python.org/pypi/scikit-video
Any task that's just glueing stuff together, make a quick hack, monitor some stuff... Tooling in general is (IMHO) easier and faster developed in Python. A lot of ROS is in Python including it's tools. I won't write a real time controller in Python, but a driver for a serial device? A demo showing off some technology? Yeah, why not! It depends on the use case.
Zope and plone, I manage mostly legacy code
I don't have much experiencing with testing so by pull down the code and run tests, you mean make a pull request and execute the test modules?
Just checked this website out thanks! It's a huge help.
Hey! Other Geo people!
Thanks! So basically just have an external file called something like "args.py" that's loaded into each file, which in turn grabs parameters from args?
I understand where you are coming from, but porting really seems more of a mountain than it actually is. Running 2to3 and testing it, see where it breaks and fix those things. I ported a pretty major project a few months ago in an afternoon. And the big win: depending on what you are doing, it's way faster.
Python is easy to program, but not all that fast or efficient. It prioritizes programmer time by sacrificing CPU time. I would guess that the increasing availability of cheap, powerful hardware meant that people felt that sacrifice less. 
Personally, I'd tie it most to Facebook, and then Instagram. Not because they use Python, but because suddenly you can make an app that puts stupid bloody filters on Kim Kardashian and sell it for a *BILLION DAMNED DOLLARS*!! I've had Uber drivers in LA with post-graduate law degrees giving me rides in their Tesla and asking me how they can learn to code. They see it as aspirational. It also happens to be extremely easy to grasp the basics of, has that "batteries included" library that lets it get used across a wide range of fields, has first class integration into GCP and AWS, and can pretty much do anything while also being accessible enough for people to feel like they might be able to become the guys in Silicon Valley. So it's got the right level of maturity to be useful, is accessible to people without a CS degree, and has a reputation for being friendly, all at the moment in history when being a programmer is seen as a ticket to riches, or at least anything but spending your 80s greeting people at Walmart.
Agree. It was originally, and still works well as, a language to learn with. It correlates with the rise of "coding" vs computer science as an employable skill
It's a fantastic idea for prototyping and glue. Direct hardware interfacing is a minority of what goes on in any reasonably complex system.
To the above I'd add: **os**: just a ridiculous amount of stuff related to paths and processes and other interactions with the machine you're on. **itertools**: incredibly useful stuff for efficiently working through long lists of things. **re**: one you really learn regular expressions, you'll never look at text the same way again. **shutil**: all your basic file copying **functools**: this one is harder to grasp, but it makes it easier to write and to an extent understand *decorators*, and those are actually really, really helpful **operator**: explicit functions that do the same thing as + and % and other operators, but are fiendishly helpful when using itertools **subprocess** calling out to other programs and getting the results can be extremely useful
Python 3 has better speed, not worse. I'm also surprised the dev didn't mention that python 3 is faster to write than python 2, and has better built-ins and is at this point about equally supported, with the trend moving more to python 3.
Hm, not what I was thinking. In your initial entry point, parse the arguments first into an option object/dict (or use the one returned from argparse) and then do stuff with that. Either save it globally or call configuration class methods on your classes with that data. I don't see why you would parse the options more than once or do it anywhere other than near the very beginning of the execution (you may have other stuff like logging you need to set up first).
The whole unicode/str/byte clusterfuck. I’m not convinced the new Py 3 approach is better, but I’m willing to learn it. However it’s not worth hacking all my existing code to work around it yet
Fair enough. But doesn't mean people have to put up with it. I would quit if my company forced us to use an OS from 2010.
AMQP
`click` is probably your best bet if you want to stick to command line params. I'd recommend supporting config files instead though - cmd params get really unwieldy as their number grows. 
VS Code does folding.
&gt; Python 3 has better speed, not worse. I checked and still not: https://mail.python.org/pipermail/python-dev/2016-November/146800.html http://igordavydenko.com/talks/by-pycon-2017/#slide-16 
I second learnpython. And include any errors that are thrown when you attempt to run the project.
Ohhhh, recognise the frustration. But not just for numpy but for python as a language. Trying to convince fanatic Java devs at work that python is a major thing in the scientific community.
Just use more-itertools' pairwise or a numpy array of objects.
At this point (it's almost 2018) you should have a talk with them because Python 2 support effectively [ends in 2020](https://pythonclock.org/), and numpy (one of the most important libraries out there) plans to [cease new release support for Python 2 after 31st December 2018](https://github.com/numpy/numpy/blob/master/doc/neps/dropping-python2.7-proposal.rst). That latter one really should be the nail in the coffin of Python 2, as numpy underlies *everything* related to statistical work, machine learning, fintech, and basically anything that relies on math. Where numpy goes, others will either follow or have already gone (numpy is actually very conservative). Any company out there that uses Python should have a plan in place already to transition, just on those items alone. Yes, there will be some community supporting Python 2 for some time, but the biggest corporate users are already transitioning, and a lot of key external libs are already talking about -- and looking forward to -- dropping Python 2 support, and more will follow. The critical mass has *long* since been gained, and continuing to straddle the two versions is costly and, more and more, just plain wasteful. I still mainly use 2.7, and more and more I regret it. 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [numpy/numpy/.../**dropping-python2.7-proposal.rst** (master → abbf415)](https://github.com/numpy/numpy/blob/abbf4155a0b068520138245b67c34a034a52c42a/doc/neps/dropping-python2.7-proposal.rst) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dpx9qb3.)^.
Haskell is gaining in popularity too
Works in 5.8, I would assume 5.5 would work as well.
How about std::find? http://en.cppreference.com/w/cpp/algorithm/find
PR sent, I think (to my eternal shame as a programmer I don't actually know git very well at all) I also have a sneaking suspicion that your original `zip(val, val[1:])` actually creates the entire zip as a list in memory too, so you were effectively creating three redundant copies of the val list, not just one. Should be quite the time saver. I didn't actually do any true benchmarking but some rudimentary messing with time.time() says it's about twice as fast now.
Thanks! I'll look into it.
Thanks! That's the goal. Do all the parsing at once as the first step.
Interesting. I'll give it a try. 
Do they intentionally shoot themselves in the foot by rejecting the standard scientific Java tools? Do they blame you when the GUI client you developed is slow over X11 SSH forwarding across the internet?
Someone will support 2.7 but it won’t be PSF. If you want to make some $$$$ that would be a good business plan .
I don't. Instead I get to hang out in places with security clearances.
Default version on CentOS is still 2.7.
I am sure the day will come when I will port it, and I hope it's as straightforward as you suggest (and that my tests are good enough to find the spots that need more attention). For what I'm doing, a speed up with be at best irrelevant. My project has to do stuff that operates at human time scales, so is littered with `sleep` statements to slow it down as it is.
Ahh, interesting, yeah I guess your only concerns would be security then. My goal most of the time is to literally do whatever I'm trying to do as fast as technologically feasible. 
Because I do a fair amount of ops work without any direct control over server infrastructure. I could commit code that I know will not run when called upon and suggest that they can resolve the issue themselves by upgrading Python, but that's unlikely to have a happy resolution. For the most part I am stuck using the system python on some of these boxes, and yes I have sent the infrastructure group guides on installing a separate python instance without breaking the system version or the software which depends on it. 
Yes, and internal software that you distribute around your servers is "packaged programs".
Hey, there were probably (almost definitely) a couple of bugs by the time you last replied. I fixed a lot of them and now it should run smoothly - try redownloading it if you had problems earlier.
I was expecting [this](https://i.imgur.com/BUZsXK1.jpg) but we ended up with a lot more of [this](https://i.imgur.com/TSXmVqA.gif).
I can understand people maintaining legacy code not switching to python 3. But new projects in python 2 in 2017? Oh boy. 
Businesses also like the idea of scalable products being able to be developed in matters of weeks rather than months. At least this is the feedback I heard the most in different companies I consult for.
Same here. No problem.
I don't know why you were down-voted (People, lol) but do you see any benefits of Haskell over Python? (If you use it.)
That's where we are as well.
Can't you write a script in python to do that? ;)
Good job!
oh,that is new , i did not know that two frame works could operate on the same database at the same time, thanks this is really helpfull
Regex and std unix tools can get you far in putting parens around Python print calls. Recommend all your new Python 2 code should use parens on print calls (use import __future__ printfunc). Costs you nothing now and will give you one less thing to fuss with when you do make the switch to Pythin 3. 
My university course uses Python 2 
Just a Vim regex would do it. 
Can someone ELI5 why I can easily (with few manual steps) convert Swift 2 to Swift 4 but Python2 to Python3 is harder?
pjproject
A lot of debian packages for 3rd party things will work, though it depends.
True story: my uncle works for ESRI and when I was little he threw me in a pool when he was drunk and my dad jumped in in all his clothes to save me and we never really spoke to him again until he magically showed up two weeks before my dad died from cancer. So if you thought using arcgis couldn't get any worse.....
Some people really think that living projects don't need upgrades. First, they say new tools are not better enough that used ones. Then it becomes too expensive. It's cheap and smooth to upgrade gradually as soon as upgrade arrives. It was strategical mistake to fight for backward compatibility to the last, maintain both branches for so long and increment major version to frighten people more :-)
Those posts are over a year old. Based on https://speed.python.org/comparison/ I'd say they are pretty much neck and neck on quite a few, with 3.7 being slower on startup, xml_etree, and pyaes, faster on mako, sympy, and a lot of other benchmarks as well.
My professor :(
You obviously know more about your job than I do, but Python 2 &amp; 3 can coexist together. Would it be possible for you to install Python 3 on a subset of machines and migrate your work to 3 while letting everyone else continue with 2? Later, as you become more comfortable with 3, you could include it on more systems. Having Python 3 available would give other groups the option to migrate when they're ready/interested. Either way, you migrating your stuff early will lessen your technical debt while giving you the time and experience in the future to help the other teams migrate. 
What the fuck. I laughed when I read this and then I read it again.... Now I'm confused. I'm also wondering why I laughed. 
RHEL5, Python development, government security clearance. I'm guessing weather and climate research?
Because its not necessary for the most part. Once it is sure I will do it more often but right now its not a huge deal. 
Modernize can do it smarter than regexes, and put the `__future__` imports in there for you. python-modernize --write -f libmodernize.fixes.fix_print your_code It can also do many of the other syntax changes for you. Here's [the list of fixers](https://python-modernize.readthedocs.io/en/latest/fixers.html) - plus it can use the [fixers from 2to3](https://docs.python.org/3/library/2to3.html#fixers).
I like it. I've found that the functional programming experience has made my Python code leaner and meaner. I have found that Haskell is much faster to write, even though there are many sources that say otherwise. Performance wise, I haven't found any significant signs either is slower or faster, but I'm still only a year or so into Haskell and only code for myself right now.
The [`@` matrix multiplication and `@@` matrix power](https://docs.python.org/3/whatsnew/3.5.html#whatsnew-pep-465) operators.
[Six](https://six.readthedocs.io/) doesn't do much magic. Might you be confusing it with the [future](https://pypi.python.org/pypi/future) package, which does do that kind of thing?
We use Docker containers to run our Ansible. Hence, we need to pick a Python version from the get-go. My thought was the same as yours - Ansible _should_ work, but unfortunately it didn't pan out that way. The problem is likely with the URL module as I suggested, which may actually be Python-version-dependent as Ansible modules operate independently from Ansible itself. As I said, if you happen to know a way of getting past this, I would be very grateful to hear about it. But you have not provided this yet.
Like [these projects](http://www.python3statement.org/#sections30-projects)!
Honestly? I’m just lazy. Everything works fine now, and I don’t want it to change.
Thank you so much! That helps us get one step closer to a solution.
&gt; The @ matrix multiplication and @@ matrix power operators. Why would you think that new operators are needed by a module? They are purely cosmetic function call replacements. In languages with proper macros, this can be trivially implemented by the user.
Reliance on packages built on Python 2. I hope the numpy change will fix this.
C library I have to interface with is written using OpenCV 2, which doesn't support Python 3. Upgrading to Python 3 would require migrating the C library from OpenCV 2 to OpenCV 3, as well as the Python ctypes wrapper from Python 2 to Python 3.
in Python3.6 `zip` returns a generator not a list
For any non-trivial project, the library ecosystem is the main thing that matters. No matter what the core language does, it can't make a big enough pull factor while all the major libraries are the same on the old and new versions. That's going to change as a number of the major libraries like Numpy and Django start to make new releases which require Python 3.
Why are you still using Django 1.5?
Its not super clear exactly what you're looking to do, but maybe Fabric? http://www.fabfile.org/
I'm using ROS with Python in a [project](https://github.com/Maritime-Robotics-Student-Society/sailing-robot) to make an autonomous sailing boat. It's frustrating at times, but it works, and I don't think we'd be happier writing C++. There is at least some effort in ROS to work with Python 3. I don't know how far it's got, but the rosbag code, for example, has clear evidence of compatibility work.
That could be fun :) However, the clearance is more of the "Not a terrorist" kind. My company makes logistic systems, where roughly 20% of the customers are large airports. We use RHEL5.5, because that's what was available, when SCO OpenServer stopped being a viable platform. We don't do goverment work as such, but with the uptime requirements we live with, we tend to be a bit conservative with existing systems.
Sounds like you need `pyenv`.
Depends how you want to split it. If you want to split by rows (first x rows in one file, remaining rows in another file) then normal python file manipulation will be enough. If you want to split by columns you could use standard python but something like the built-in `csv` module would be better. --- If you have more questions like this it's better to post them on /r/learnpython. Be sure to [format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin. Also, include which version of python and what OS you are using. 
Ok I'll do that anymore, just split it in half 50 50
My guess is it is because Swift has a static type system, Python's is dynamic.
I learn from books. There are better books for 2.7. So I learned it and am now eternally inconvenienced until good books are made which teach 3.6.
2 million lines of 2.x code
Then why can I transpile ES6 JavaScript to ES5 with *no* manual steps at all? Or better yet TypeScript or Kotlin to JS.
Not to argue with you, because trust me I've been in that position, but when it seems like you need to climb out, you might look at automating pyenv which among it's features is the building of most versions of python with a pretty clear set of requirements. It's possible it doesn't run on RHEL5.5, not sure, but something to tuck away. 
This is my reason, too
[removed]
At work we need Python 2. We have some old programs that need to keep working. We can't upgrade libraries either.
As I stated before, getting Python3.4+ to compile on RHEL5.5 turned out to be more work than we estimated the benefits to be. Both you and I could get it to work in a few hours. However, I have to provide the result in a way that's both repeatable and no-effort deployable. The effort needed to get there with RHEL5.5 is more than what we can defend, as opposed to delay until 5.5 is retired at the last customer system. 
I understand. I was being a bit flippant to be frank. Good luck!
I started a tornado project about a year ago and tried to use python 3.6. I gave up after about six libs I wanted to use failed to install.
Would pyenv help me to get the requirements to compile a recent python3 on an ancient platform? 
Good luck! I (mostly) run Ansible under Python 3 myself, and it's good to see other people doing the same.
close to all my projects are side projects for my Raspberry PI, and the ones at my work they don't care what version I use... Tbh I'd like to use py3
&gt; Why would you think that new operators are needed by a module? They are purely cosmetic function call replacements. Because it simplifies reading, writing, and maintenance of the code. Modules are written by people, not robots. Just because it is a module doesn't magically make cosmetic improvements irrelevant. That is why most big projects have style guides. But the `@` operator is just an example of features created specifically for numpy that can also be used to help numpy. There are lots of other features that are considerably more important, the biggest one being support for C99 on the C code side. There are also things like type annotations, which numpy wants but where python 2 is [limiting them](https://github.com/numpy/numpy/issues/7370#issuecomment-326678987). And things like the lack of keyword-only arguments prevents useful API layouts, especially since the C code can have them but python code can't. And then there are lots of small features that can be used to make the code simpler, cleaner, and easier to maintain, like extended unpacking.
Curious, do you use ArcGIS + Python because you have to? Because you're using ArcGIS for everything else already? Or because it can do things you can't do with open source tools like GDAL, PostGIS, and shapely / fiona? (For reference: [Python versions in ArcGIS](http://support.esri.com/en/technical-article/000013224).)
I still use Python 2; when I first learned Python, I was told that many scientific computing libraries were still unavailable in Python 3 (this was ~3-4 years ago). Now I continue to use Python 2 because I get sick of forgetting to include parentheses in my print statements and because Python 2 continues to work. I'm sure there are plenty of features that make using Python 3 nice, but I don't see any huge reason to change. That being said, I'm about to make a big career move, and I've vowed to officially change over to using Python 3 exclusively once I wrap up my current projects. 
I have a big project in 1.5 with Jinja2 hammered in. Since that Django gained support for that engine but it differs a lot and requires careful testing (we have tests for processes but no validation checks on pages content). To make it more funny, my friend also uses the same Django/Jinja solution in a project he manages. No one is willing to make the first step towards the light.
The most important is the API it provides. If you think you got that right, release. You can change everything else quite easily afterwards.
 I use the pandas library for this as it abstracts reading and writing to a csv. Basically, read the original file into a dataframe, split it into two and then save the two files. import pandas as pd data = pd.read_csv("filename.csv") csv_1 = data[:len(data)/2] csv_2 = data[len(data)/2:] csv_2.to_csv("output2.csv") csv_1.to_csv("output1.csv")
Super easy with pandas.
just psycogreen and lack of time/resources to replace it with something working for py 3.x But the time/resources to do that is on the roadmap.
I previously worked for a large cloud provided who is still on Python 2. I was told that they don't believe Python 2 will ever go away so they won't allow anyone to spend time to upgrade. Their reasoning is RHEL 7, which uses Python 2.7, will be supported until 2024. When that times comes things will be reevaluated but considering the average turn over at the company is 2 years it sounded more of a lets punt this till I'm not here any more.
I'm still learning Python 2
I published the updates here: https://github.com/rochacbruno/rust-python-example#updates And accepting PRs to enhance Rust and Python implementations.
Who handles the security and bug updates for things in /usr/local? The whole reason you use packages from your operating system vendor is so they handle it. Users/developers are notoriously bad at making sure packages they built are kept up to date.
We too. Our plan is to switch to Tornado and use the bridge for Twisted so that we do not have to re-implement everything. 
If you want to use command line arguments then click or fire are probably the most developer friendly modules for this. If you're more worried about the issue of having lots of command line arguments -- I find more than 4 or so get really unwieldy -- then one option is to store things in a yaml file, then have your application parse the yaml file. 
I bet you that the vast majority of those lines of code are also 3.x compatible.
&gt; There are also things like type annotations, which numpy wants but where python 2 is limiting them. That's bullshit and you know it. Having to import "typing" in order to get type annotations to work in Python2 is not a show stopper, but a flimsy excuse. &gt; And then there are lots of small features that can be used to make the code simpler, cleaner, and easier to maintain, like extended unpacking. Yet another cosmetic wank. Do you have any idea what modern languages allow you to do? Stuff that looks like science fiction to any Python newbie - stuff like integrating a Go runtime in Nim and creating new Go-inspired syntax to go with it: https://github.com/stefantalpalaru/golib-nim And you talk about a couple of operators and some shitty type annotation syntax that still needs an external tool for checking...
TBH there is no need to backwards compatible, the current stable release is 3.x so they need to think to update before 2020 (EOL of 2.x)
True. But some nasty breaking stuff too. Why in the hell would you make a computer language not backwards compatible? It's the biggest fuck up in IT in the last decade, the biggest. Guido, you fucked it up. 
we: * use travis to git pull/ run tests/ make the distro package * save these packages in s3 * deploy and run integration tests (deploy is either copy to lambda from s3, or to spin up an EC2 with a path to the zip in the init scripts) * pass/fail the build 
Got linkys?
Looks so flasky and pragmatic. :) I like how Django evolves at its own pace and takes its time for new shiny stuff to prove its value and filter the good from fashion. 
Aha, that does definitely explain why I saw so much improvement going from your version as written to the one I put up - I only have 2.7 to hand, so I was inadvertently comparing the old 2.7 zip against the 3+ (i)zip, which is obviously much better. Also I mostly just ripped the whole `.tee` part from itertools recipes, and tee is just a waste of time and effort since we don't actually have a single iterator that we're trying to preserve. It's better to just create one iterator and zip that plus the original val together. I can't get pytest to play nice with this laptop either, so I won't request another pull until I can actually get something I'm certain is an improvement on the current version (and tested in 3.6) Interestingly though, it seems like cloning the whole of `val` is really very quick, it barely affects the time to run the function.
Python 2 is nearing end of life, which is in 2020. NumPy, an essential scientific computing library, is phasing out Python 2 support starting December 2018. Basically, if you don’t make the transition, you will be left behind. You and your colleagues should be having a serious discussion about transitioning to Python 3.
It's ok you can laugh
I second /u/Skullbonez. Check the indentation. Other than that, your code should work.
requests for network. pandas for csv/data manipulation. Pillow for image manipulation 
Yep, ArcPy. We have scripts running on several enterprise servers, so upgrading to 3 once we upgrade to Pro will be Really Really Interesting.
Our whole enterprise system runs on ArcGIS (we run a mid-size city's GIS system as well as a county and a 911 district) so I think it can do things others can't, a lot of our non-GIS staff have ArcGIS experience, and training them on Q or PostGIS would be too much work.
I'm writing cross compatible stuff at work, but I've only been here a month. On the plus side, though, we're (I'm) going as fast as possible.
So here's a guy who used it to get 2.7.8 running. There was a problem with the version of wget which he had to overcome, but once done it seemed to work. http://xylil.com/2015/01/19/installing-a-working-pyenv-on-rhelcentos-5x/ I haven' t found anyone saying yay or nay about python 3.x under centos 5.x.
YAML 
I think I'm the only one who knows we have python code, and that's only because I saw the stack trace in an error message once. I know for a fact whoever wrote that isn't with the company anymore. We might upgrade if we ever upgrade our servers to a RHEL that doesn't support 2
Unless you have `print &gt;&gt;file, blah` or `print blah,` in which case you're going to need some extra smarts in there.
And then we're back at "what is the business case for this?"
Effort. It's in the backlog, though. 
Sweet pivot man!
Oh god this hurts. 10.4 running on 2.6 still, drives me nuts because certain large enterprise applications that rely on ArcGIS won't function on 3 either.... :(
Someone is going through the comments and downvoting suggestions for click... why?
Our scripting engine is IronPython. Not my decision, but I have to use it. Working fine, so why change?
Your comment addressed here: https://github.com/rochacbruno/rust-python-example#new-results 
In science, this has a slightly different slant - Python is very popular because it's one of the easiest languages for non-programmers to use, *and* using Numpy et al doesn't actually sacrifice machine time :-)
&gt; I now want to do feature selection so that I can drop some very low correlated variables. Calculating Pearson or Spearman correlation scores on your features can be helpful for discovering certain apparent dependencies in your dataset, but you have to be very cautious if you want to use these scores as some kind of threshold for the "value" of your features. You might unintentionally throw away information that way, especially when the relation between the two variables is non-linear (see [this figure](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Correlation_examples2.svg/500px-Correlation_examples2.svg.png) as an example). [Scikit-learn](http://scikit-learn.org/stable/modules/feature_selection.html) offers a couple of methods that are probably more robust for your use case.
Pandas wasn't released until around 2010. "Data scientist" wasn't really a thing until 2010 as well. IPython Notebook got really good in 2011-2. The book "Python For Data Analysis" was released in 2012. The huge uptake in Python recently can be linked to all of those things. *Money Quote:* __Python didn't become more popular with coders. Python CREATED more coders.__ And Wes McKinney is primarily responsible for that. IMHO
Hello, Thanks for the response. I simply want to find do the correlation to for feature selection. The main issue that I have is out of about 20 variables, 7 are categorical. They are already encoded ("pd.get_dummies") but I don't know if I would get the wrong correlations if I was to use these dummy variables columns for the correlation calculation.
Startup time is still slower, what if the application is a command line command?
Yeah I'm now using the supervisord implementation in go. https://github.com/ochinchina/supervisord
There is the beanstalkc3 PyPI package that works with Python3.
Step through your program in a debugger you will start in six. 
Sorry I mean get the however you do that (ex. git clone from GitHub) and run the tests however you do that, each project is different (ex. simply run tox). For what it's worth a pull request is a request for your changes to be in a project.
Difficulty grows with the complexity of the project. Say you use a few external libraries and one of them isn't Python 3 compatible, now you've got to either find another library that is or take it on yourself to refactor that library for the good of the people. And then you find out that library in turn uses 2 libraries that aren't Python 3 compatible, and it starts again.
&gt; That's bullshit and you know it. Having to import "typing" in order to get type annotations to work in Python2 is not a show stopper, but a flimsy excuse. Numpy has zero python dependencies outside the standard library. This is an important feature of the project, dependencies are kept to the absolute minimum possible to ease use and distribution. They are not going to throw that feature away. &gt; Yet another cosmetic wank. Do you have any idea what modern languages allow you to do? Irrelevant to the issue at hand. &gt; And you talk about a couple of operators and some shitty type annotation syntax that still needs an external tool for checking... Now you are just lying about what I said. You just flat-out ignored what I explicit said was the most important reason.
As I said a few weeks ago when I last mentioned it, I just got fed up with the whole thing, wrote the library off as "now non-existant" and saved nothing.
Plain and simple, redhat. I still write in 3 but trying to explain software collections then virtualenv to sysadmins gets painful. The minute I want someone else to use a tool I wrote I just keep it in 2. All my personal stuff is all switched to 3. Now I'm trying to learn Go since one project I am looking at is switching to go because of the GIL.
Work invested in a complicated, but somewhat poorly designed, infrastructure about a decade ago. I can't convince anyone that updating it to 3.5 standards is worthwhile. But really I only use 2.7 when I need to use that.
Wow this is so useful! The “learn from other’s mistakes” really is valuable. Is there a book or website or similar that focuses on these things? Dos and dont’ts for python programming? 
It was one of the first languages I learned when I stumbled into programming. I work in a large enterprise environment and we handle thousands of files between different contractors, Python is great for rapidly building scripts to read massive files to find problems or strip them of data especially when it’s time sensitive. 
&gt; This is an important feature of the project, dependencies are kept to the absolute minimum possible to ease use and distribution. Guess what? End users don't even have to have the "typing" module installed for the bloody devs to use mypy's Python2 type checking: https://github.com/stefantalpalaru/generate_HLS/blob/0d8e28ae8208ace3d64a3a53a6d3c1a296600790/generate_HLS.py#L12 &gt; You just flat-out ignored what I explicit said was the most important reason. The most important reason is the 24/7 amateur hour fanboy-fest.
The cost of legacy software. The cost of stagnation. The cost of upgrading legacy software if you wait too long. The cost of the toll on the staff(and its effect on hiring new blood). The cost of running disjointed versions of operating systems company-wide. The cost of not having access to new features and improvements(now the OS dictates your development instead of your architects). Security wise, they don't issue advisories for that anymore, though it looks like they might issue critical security fixes. So you might drain the stone for a few more years until extended support runs out, I guess. This shit ain't new. The cost of legacy software is well known.
And that cost is not always greater than the cost of making the switch.
&gt; Shame this doesn't generate Python3 type hints Guido doesn't need it, because he only works with Python2 ;-)
Doesn't work with floats in the csv I'll try again in the morning 
GLWT
This is an old thread but I hadn't seen this mentioned: I'm waiting for PyPy3 to be out of beta. PyPy gives 5-10x performance improvement on my production systems so I'm not really ready to give that up for the nice features Python 3 offers.
I down voted because the post is totally off topic
raw_input() was removed and im too lazy to lookup how input() works now. Im also self taught and terribad @ programming in general. :3
I just left a job that was 2.7 stuck. The big issues to me are around Unicode. 1. In 2.7, string literals (str) are encoded bytes and the Unicode is a special type. In 3+ lifeless (str) are decoded sequences of Unicode code points without an encoding and bytes is a special type. 2. 2.7 implicitly promotes its byte string type (str) to its Unicode type when you combine them by decoding them at utf-8 (or whatever your interpreter default global is set to). 3 raises an exception when you try to do this. The combination of these two facts alone makes writing 2.7/3 compatible code horrible. I consider myself to know Unicode in Python pretty well (I’ve given two talks on it) and compatible code is still hard as fuck. What’s worse is libraries that are 2/3 compatible behave differently in this regulars. Psycopg returns encoded in 2.7 and decodes in 3. Json is the same. You usually don’t even see those errors until you try and combine two strings in 3. Or write the encoded string to a file. Trying to use the __future__.unicode_literal import helps a bit, but god help you if you don’t do it to ever module at the same time or forget to do it in a new module. You write a literal in one module with the import, return it in another, that one tries to combine it with one of its byte literal strs, that gets implicitly decoded, you try and write that string to a file and you suddenly are getting an exception about the string being unencoded and you can’t figure out where the hell you did anything that had to do with encoding. It’s basically impossible to do a 2.7 to 3 transition in anything less than one giant fuck-it-ship-it PR. I just want it to be over man.
Ubuntu
Oh, interesting. I think I may try to integrate this through a thing proxy class. Thanks!
Here's a relevant [post](https://jeffknupp.com/blog/2017/09/15/python-is-the-fastest-growing-programming-language-due-to-a-feature-youve-never-heard-of/) from jeff knupp
Consider a series of categorical data [cat, dog, dog, cat, bird, cat, bird] which could be encoded to integers as follows: [1, 2, 2, 1, 3, 1, 2] If you used this vector as a base for calculating correlations, it would imply that a bird has thrice the value of a cat which is obviously nonsense (at least in this example). But beware, if you encode k categories to k dummy variables, the value of one of these columns will always be equal to 1 minus the sum of the other values, i.e. you introduce a collinearity. This will have an impact on some estimator algorithms. You can remedy this by dropping one dummy column and using it as a base. I don't know the data you're working with, but I would take a look at other methods outside pandas.corr() for determining independence between your features, like a one-way anova test or something. Or just let Scikit-learn do the work if you only really care about your predictions and less about the correctness of your parameters.
What about AMQP isn’t compatible with python3?
Others are focusing on advancements done recently in Python but the difference between Python and stuff like Java and Javascript is that Python started off as Guido's hobby project and continued to be that way for a very long time. Version 2.0 released in the year 2000 and included stuff like the first release of a garbage collector, unicode and a the introduction of a development process which started to include the community.[^[1]](https://docs.python.org/3/whatsnew/2.0.html#new-development-process) Other mainstream languages either started off with enterprise backing (Javascript) or quickly attained it (Java) with the aim of producing a usable product quickly and which they did. I don't think there's anything that special that happened in 2010. Python just had the time from 2000 onward to grow into a very usable language with batteries included and a slew of additional libraries that you can install easily. So it's not like Python suddenly started to be anything, it's just that instead of looking at 1990 you should be looking at 2000 and after for the time when Python was actually starting to be a serious consideration for widespread use. The growth came steadily after that and here we are today.
The idea is brilliant. Is this the next blockchain platform?
I just do it to annoy people 
This. And I’m not ready to move to Pro and the new ‘arcgis’ model yet. One day I will suck it up and to it, but it will like take as long as it took me to switch to using arcpy.da cursors.
The shop just switched to 3.5 from 2. Its been pretty painless honestly.
I'm not sure, your original question is a good one.
Depends on the Linux distro. Use Google.
A lot of studios use Shotgun or Ftrack to manage their pipeline. Both are commercial web based systems. The Shotgun Pipeline Toolkit (aka Tank) is a gigantic system whose code is well worth looking at - https://github.com/shotgunsoftware (not open source). I do hope Autodesk and others will ship with support for *both* Py2 and Py3 for several years - there are studios with literally millions of lines of code that will need to be ported. Just switching from Qt4 to Qt5 was a pretty big hassle - where I work, we skipped an entire Maya release because of it. 
Python 3.7 is not even out...
PyPy and some of the libraries used by it are still not fully supported on Python 3. Although this may change soon.
Can I entice you with the prospect that all previously made contracts, and all previously battle-tested code is going to note only puke all over the carpet, but cause corruption and chaos throughout the company if you upgrade? The quicker you upgrade to python 3, it's just moving up the date guido pulls this shit again and starts this dipshit merry go round all over again for python 4. Let him wait a little bit, let him sweat a bit, it's not going to kill him.
Captured my sentiments entirely.
An additional 8ms ([source](https://mail.python.org/pipermail/python-dev/2017-July/148678.html)) is probably not going to be a deal-breaker for most people's command-line tool.
Every new service and package I write is 3.x exclusively for the past year. I've had enough of dealing with 2.7 issues that are solved in 3. I still have to maintain some older 2.7 stuff, but it is slowly going away
I just used it with pygame for so long, plus for the longest time the most stable builds of pygame only worked with python 2. I did try to move to python 3, but yknow... it's a little difficult making the transition.
[docopt](https://github.com/docopt/docopt) gives you argument checking parsing based on a docstring, which is printed when you run your script with -h option.
I really like those libraries, more than the traditional approach in many cases: * https://github.com/docopt/docopt * http://click.pocoo.org/5/ If you have too many arguments, you might consider using configuration files instead .. you could just dump a dictionary filled with arguments in a temporary YAML file and then just do `python app.py --conf=/tmp/config-abc.yml`.
One thing I did in such situation is providing my classes with a `get_args` method. My script would loop through the installed modules and check for the existence of get_args method. So each modules would contribute their arguments and everything stayed clean.
That works, but it's rather messy. Also there's no for in x , which makes counting the occurrences of a substring slightly more tedious.
Seems I've seen this question posted a few times before. Maybe it's time to pin the best answers to it in a subreddit FAQ.
Honestly, I'd be very careful of wheel-reinvention here, not knowing what you're doing exactly but it does kinda sound like you're up to some very typical automated sysadmin or devops stuff. Rather than growing your own for that, seriously consider using an existing framework system like [ansible](http://docs.ansible.com/ansible/latest/index.html) (ansible in particular is implemented in and extensible via python and particularly straightforward, there are other tools in the space with different tradeoffs), then see ansible faq ["how do I configure a jump host"](http://docs.ansible.com/ansible/latest/faq.html#how-do-i-configure-a-jump-host-to-access-servers-that-i-have-no-direct-access-to)
&gt; Are you still on Python2? Yes. &gt; What is stopping you moving to Python3? It will cost the better part of a million dollars in development effort to convert our codebase, with likely problematic business impact as we work out the kinks. In the mean time, we won't be able to create things that make us more money or make our jobs easier.
Well, sure if you one of those people who knows what you're doing and don't like re-inventing the wheel. ;-p Thanks for the info! 
You can also do it like this: import soundfile as sf import soundcard as sc default_speaker = sc.default_speaker() samples, samplerate = sf.read('ping.wav') default_speaker.play(samples, samplerate=samplerate) Supports linux,win and macosx. https://github.com/bastibe/SoundFile https://github.com/bastibe/SoundCard Took me ages to figure out... If you can figure out how to load a wav or mp3 manually without soundfile and just numpy(i don't know how), you'll get a cookie.
Making brains out of reddit comments! From [GitHub](https://github.com/claytonblythe/redditstream-cli) 
Hey there fellow VFX programmer!
Hijacking to ask a question, how difficult is it to get into a GIS job without a degree? In my area there are a fair number of GIS jobs and it seems rather unapproachable.
i like jq for heavy json finagling. but jq is a whole other programming language for json... (and it was a bit of a bitch in the start, but now i can't live without), decimal for math that werks. arrow because you are as dumb as me(and lazy), psycopg2 with postgresql because less work and more just werks.
Trying to get a job in Big Data. Wish me Luck !
Python 3 has nothing that I need. Everyone works pretty well with Python 2. Or to put it more exactly, the new features are not worth the bother of investing time and energy into moving over. Now say if they improved speed by 3x then there would be a good incentive. Or say if 2 was broken badly, that would be another incentive, but it's not broken for me. 
GeoPandas makes life easy.
Because it's so much fun having one terminal window that can use python3, and another one that needs to stay on python2 for build scripts and system stuff. 
f-strings are frigging amazing. Once I caught wind of it I upgraded right away and never looked back.
Id have to put parenthesis in all my print commands. (Jk, I use python3)
You don't need to have every API/function memorized. Nobody does. If you know the basic syntax just find cool programs to work on and google for what you need to make it work. Eventually you'll be working on bigger/better programs and you'll need to google for some functionality when you vaguely recall using some library in one of your previous projects that would work perfectly. Use something like github to post/showcase your work and be sure to check out other peoples code! You'll find neat/different ways to do things and you might also find bugs that you could fix. 
Welcome to the hell that is writing code to run on client machines with policy-restricted OS's that only support 2! Someone save me ;_;
Yeah pretty much. Not c though, java. 
Yea once data manipulation became easy in python k switched from r. Never looking back now
If we're going to construct 5 sky scrapers, we need hundreds or thousands of construction workers but not hundreds of architects. 
I work on a closed system, based on our clients needs we cannot upgrade without exhaustive testing which would likely span around a year as we work on a huge system. It's not that we don't want to upgrade, it's that it's easier not to.
* **pandas** + **numpy** + **matplotlib** for everything dealing with data. (**Pandas** = easy to bring an excel/csv file into python, do stuff with it, and then write to excel, or plot, or whatever). (**Numpy** = powerful math operations, np.mean([values]) to average, np.linspace to give yourself evenly spaced values (for tickmarks on graphs etc). **Matplotlib** is great for plotting -- [see examples](https://matplotlib.org/gallery.html). All 3 of these libs worktogether nicely, for example, you can plot your data using **matplotlib**, from a **pandas** dataframe, with df.plot() etc.. * **requests** for getting data from a URL, like an API for example. So if you want to track the ISS around the world, you're going to need to request data from [this URL](http://api.open-notify.org/iss-now.json) a bunch of times, and store the latitude and longitude (in a **pandas** dataframe, for example!). That link is a JSON api, which pretty much gives you a python dictionary that is ready to use. However, if you want to scrape a regular website, you will use **requests** to get its HTML source and then **BeautifulSoup** parse the html and extract the data you want.
PHP didn't age well because it started life as a monstrosity and only very slowly crept its way toward sort-of-okayness. Python was pretty nice from early on. I've been using it since the early 2000's and it has just been steadily improving and gaining popularity since then. I don't know what exactly happened around 2010 but I definitely felt it too -- my employee then was mostly PHP in 2009 and we started using Python over the next year or two and it just kept gaining more acceptance from clients and love from developers. Now they are primarily using Python. Now that I think more about it, I think the web framework renaissance spurred by Rails, out of which Django emerged, really helped propel Python. The data science stuff has been big more recently too, as others mention.
From how you're wording yourself here. It seems like you don't know much about modules? For example if you want to make graphs with python I'd start by installing the module matplotlib and reading the docs for that.
What will you do when 2 reaches end of life? 
Because fuck you, that's why.
It's the default version of Python installed on OS X. Yes, I know you can use Anaconda/brew/virtualenv to change this, but if I'm sharing code with coworkers, I want to to be able to run without mandating they install some other software just to run my program.
yeah you should do Automate the boring stuff
I feel that the rise of Python is largely tied to the rise of open-source software. Python is particularly well situated in that almost its entire codebase is BSD/MIT licensed, or something equivalent. A lot of the people who moved into Python and built the huge libraries (like the NumPy/SciPy stack) had some prior experience with the horse collar that is GPL, and they rightly avoided it. When a computer language can put food on your table, it's going to enjoy success outside of academia. So Python combines two things to make it the superior choice in the new open-source commercial software regime: one, it is probably the best glue language for sticking together different open-source projects, and two, it's has largely commercial friendly licenses. 
@billy gates 
Go here: https://www.lfd.uci.edu/~gohlke/pythonlibs/#pillow Download the `Pillow‑4.3.0‑cp34‑cp34m‑win_amd64.whl` one and promise to buy Gohlke a beer some time.
Python26 is what's deployed on our production servers, and we have quite a bit of Python2.x code. The reason we haven't moved to 3.x? Cost vs. reward, simple as that. There's not enough wrong with 2 to warrant spending someone's valuable time migrating it over.
For many, probably most, there's just not a lot of good reason to move to 3. If it isn't broken, why spend time and money to fix it?
Where dem cute girls at?
Sshh.. you can't talk like that in this subreddit.
That is an extremely awkward time to say that.
My team's own code is version-agnostic, but we depend on a ton of internal libraries that haven't made the switch.
Post totally off topic? Yet shining increase in popularity of Haskell can also shine the reason why Python became so popular. Maybe a common factor? Some people just can't be bothered with creative thinking and that's fine. Down voting just because you can't make a connection is not fine. NOW THIS COMMENT IS TOTALLY OFF-TOPIC.
I use python3 and pip3...
I switched a 1400 line script from 2 to 3. I only had to change one line.
six is also very helpful here.
Not really... both are gaining popularity and both founded in 1990
*shrug* they bought the code. I told them about it. Their problem.
Default python on cent7 is 2.7. Work doesn’t want to change the default... We also still have some cent5 and cent6 kicking around. 
Ten times 0.00001% market share is still pretty small
its still etter then autocad
Django predates Rails.
I had the same frustrations when installing tensorflow-gpu. I suggest anaconda environments https://anaconda.org/anaconda/tensorflow-gpu as it becomes hassle-free. Not the best solution but a hassle-free one. 
Pro is looking promising though, at least what I've seen of it recently. Q is great too.
i switch to qgis, only thing it lacks is builtin annotations
Straight GIS? Pretty tough. If you have an application/domain and some GIS knowledge? Much easier. 
When I said Django emerged, I did not literally mean it was created after Rails. It became prominent after Rails did, unless my memory is really failing me.
Neural Networks using tensorflow.
Sounds like you should use a database. I don't have a lot of experience with them, especially not in Python, but for large, complex data like this that is nested and just has many entries that you can store and retrieve easily, it is miles better than using an array/matrix.
Hello there!
Don't beat yourself up. It sounds like you know python but don't know where to start. Don't fret! I've been using python fodr six years now. And I still find myself searching "How do I do X". I spend a lot of my time refactoring (changing the structure) but for me it's the journey not the destination. In my experience if you have an idea and don't know where to start. My first step is breaking down the tasks and finding a library to do something. I.e "How to import CSV into list "How to extract elements from list "how to make graphs in python" Reading the documentation also helps to find cool and interesting things. I.e copy vs deep copy. Then hack that code together. Does it do what you want? Great! If it doesn't, print statement everywhere! Or learn how to use a debugger. Bigger projects would use a debugger but print statements so work. When it does what you want. Then refractor and make it clean. Feel free to send me a message if you have any questions :)
&gt; Hopefully when large projects like iPython and Numpy do it FYI, [IPython dropped Python 2 support 6 months ago](https://ipython.readthedocs.io/en/stable/whatsnew/version6.html#ipython-6-0).
On the command line: NL=`cat myfile.csv | wc -l` HALF=`expr $NL / 2` head -n $HALF myfile.csv &gt; tophalf.csv tail -n `expr $NL - $HALF` &gt; bottomhalf.csv 
Not primarily a Python developer, but why should I switch over? Two does what I need it to do and everything I use is still compatible with two. You may as well ask why I don't just switch to a different language. It would be effort spent with absolutely no reward. 
Zed Shaw is a loudmouth whose opinions don't matter.
Tensorflow is not well supported on python3
Try docopt -- self documenting and posix compliant
Legacy.
ROS 2 when?
You can download and use the developers preview version already.
I write tons of python code though it is usually for my own uses and nothing too large. With that said, I made a strong push to convert everything to be compatible with **both**. That is, because at work, I an only reliably assume I will have access to python2. So that is always my default! I don't like it, but it works well enough. I run most things at home or for me in 3.6. For the most part it is fine. The things I would like the most about 3 are: * Easier unicode from the start. Even the `__future__` doesn't do it as well * fstrings * I forget what it's called but do things like `A,*B = ITERABLE`
The fact that python is used as a beginner language and is so approachable by many "non-cs" types; has lead to a huge adoption of the language by folks of a wide variety of backgrounds. Python has very good and well maintained libraries for data science, machine learning, web development, server automation / scripting, etc. I think the fact that it's primary focus is on programmer comprehension, it makes it easy to learn and run with; so it has now snowballed into one of the most popular languages out there. I love Python so much &lt;3
A lot of companies use Shotgun, but at least at the larger facilities they certainly don't use it for asset tracking, just tasking and review. And they always self-host. And I certainly wouldn't say they manage their pipelines with it, so much as they manage the reporting of those tasks in it. The Toolkit is nice because it's slowly evolved from what we're really the remnants of Tank (an experiment in asset management that was a separate product that got re-absorbed) into a pretty decent framework for assembling a consistent interface across tools... but it too doesn't see much use at the larger facilities, because a lot of what's in there doesn't really scale, and it necessarily involves vendor lock-in. The Toolkit itself is Open Source in a sense, but with a license that -- last I read it -- effectively says you must immediately stop using it if your Shotgun Service Subscription lapses or goes unpaid, which means that any pipeline you build with it is wasted effort should you ever decide the core product is no longer the best option. The good thing with 2 to 3 is that it's not really as bad a transition as people think. The bad thing is I've looked at a few million of those LOC personally, and it's often barely legible to begin with, with a lot of it meant only to run within the embedded interpreters in the various DCC apps. When each of the Autodesk and Foundry products ships with the 3 interpreter, **all** of the code that runs within those will have to be updated (you can't run 3 in 2 mode) unless the vendors all figure out and agree on the same consistent approach to a compatibility layer to their own API code (like accepting f"ormat_string" as well as b"ytes" and u"nicode"). I don't think they'll do that, they'll maybe ship a generation with you either run 2 or you run 3 via an env var or flag (which is a bad idea for the vendors), or they'll just ship with 3 and the facilities will catch up. It'll definitely have a winnowing effect which will be interesting. I know the large companies have a plan in place for the transition, but the smaller facilities that have lots of locations that only sort of talk to each other, and pipeline teams of like 4-5 self-taught TDs... that's gonna hurt.
Hah! To think I was feeling bad the project I manage is still on p2.7 Django 1.8 while the team downstairs wrote their new app on the latest using p3.
I’ve installed many CUDA versions hundreds of times. My coworkers like to fuck things up and just leave it that way until someone else fixes it. Did you read the [CUDA installation guide](http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html)? It actually has pretty explicit details, especially for pre-installation requirements. So at this point you have kind of a cluster-fuck of CUDA and cuDNN versions. Worse, it seems you have CUDA installed from both the repos or a .deb file, and from the runfile if I understood correctly. First thing I would do is delete cuDNN in any locations not inside of a CUDA directory. Next you probably will want to wipe clean any/all versions of CUDA installed on your computer. In the preinstallation actions section of the guide I linked it shows how you properly do this for both types of installations. I believe you apt-get purge nvidia* to remove CUDA and the Nvidia drivers installed from a a .deb/repo, and for a runfile installation there is an uninstall script inside of the CUDA directory. Read the install guide above for more info on this. Next, I prefer to install the Nvidia drivers from the graphics drivers repo. It’s significantly easier than having to drop to text-only mode to install them. A simple Google will help you find the repo and how to install it. Then I usually choose the latest long-lived driver version. Googling “nvidia unix drivers” will bring up a list from nvidia where they will list which is the latest long-lived version. sudo apt-get install nvidia-# where # is the latest driver version. Might be nvidia-384 at this point. After this give your computer a restart to make sure everything with the driver is in working order. Next, pick which version of CUDA you want. 8 is the default for tensorflow, but if you compile tensorflow from source you can really use any version you want. Compiling from source really isn’t that difficult with Google’s bazel tool. It’s not necessary however and I rarely see much benefit from it. Download the full runfile installation. While this downloads you should read through all of the preinstallation actions in the install guide above and complete them. Once you have the runfile downloaded and you’re ready to install, run it with sudo sh runfile-name in whatever directory it downloaded to. As you follow the prompts, it will ask if you want to install the graphics driver, choose no. We already did that ourselves. The only things you should choose to install are the CUDA toolkit, and the samples which you can use later to verify everything is working. It will also ask if you would like to create a link to the cuda-8 directory at a directory just called cuda which I usually do. I find a lot of problems if I try to install the driver this way or basically let it do anything else. Once that’s done I believe there may also be a patch for CUDA 8 which you should install too. It will be listed on the same page you downloaded the full CUDA 8 runfile from. Run it the same way. Then resstart again to make sure everything is still in working order. After this you should follow the post installation actions in the install guide. Set up your LDLibraryPath and any other environmental variables. Compile the samples and run them as specified, etc.. After that get the version of cuDNN you want downloaded and unpack it. Inside of that directory is a lib64 directory, and an include directory. Copy the files from lib64 to the lib64 directory inside of your CUDA installation directory and similarly for the include directory. Then run sudo chmod a+r path/to/cuda/lib64/libcudnn*. Since these files are now in your cuda directory, they are already in your ld library path by virtue of adding that to our environmental variables earlier. You should now be ready to install tensorflow. It really is a headache to get these installed at first, but once you’ve done it a lot you work out all the little idiosyncrasies involved and it becomes fairly routine. Good luck.
Is there a reason to use Pillow over OpenCV? I like OpenCV because I can easily port my programs to C++.
Try to get Oracle 9 and J2EE running on AIX 5.3. We haven't even explored the wonders of non-x86 processors and the IBM implementation of coreutils... not even a Bourne shell....
[Here you go](http://www.tornadoweb.org/en/stable/twisted.html)! I have some production code already running this way under Python 2 and it works great so far! 
Work on a small project. That's the best way to learn programming. I recommend digging into web technologies because that has the most job opportunities. Since you know a little python, you can try something like an online notepad. Basically a web page that can load and save a piece of text(into a local file). Use the simple web server built in to Python. You will need learn a little bit of HTML too. Once you understand how that works, add django to it, then a simple database to save text. Then use ajex for file loading/saving. Then support multiple notes, then add a simple login system. Hopefully that's enough for an entry level job.
It's not just pandas, though. There could be no pandas without numpy, Scipy, and Matplotlib. On other words, the scientific python stack.
I started with instructional websites like codeacademy, and then spent a few years just programming simple games with Pygame. I'm currently in school for a CS degree and none of the classes teach Python, just Java and C++. I've found that when I'm trying to design an algorithm for an assignment in Java, I'll write it out in Python first and make sure it works correctly, then I'll translate over to Java or C++. Writing code in Python first is just so much easier/quicker for me.
&gt; It wouldn't surprise me if Python2 would be used for the next 10 or more years. &gt; until there is a clear business case to do so, we are not going to move. You mean in 2021 when a fatal security flaw is exploited and your company has to use the last decades *for-profits* to keep the business afloat, and your personal CV is eternally blighted with years spent at a company that spectacularly torpedoed its viability by refusing to spend a few months migrating the code base to a language that was being actively maintained?
Have a look at [Plumbum](https://plumbum.readthedocs.io/en/latest/).
Yes. It's such a struggle. Like 4+ hours to get it all working.
python 2.7 will be continue to be patched until the end of time.
Apache's 
I'm working on 2 projects. One is python3, one python2. Literally no difference for me, just the print statements.
I infrequently use it because of Python Kivy. Kivy better supports python 2 for packaging apps.
This a an *optimization* problem! You should start reading about heuristics and the typical algorithm classes that exist. Iirc Google has an open source library for such problems. As they often offer bindings to many languages perhaps python is one of those supported langs. Opposed to other comments: a database or the data storage aren't your main problems here. Of course this might make sense later on to organize the data in a flexible way, but you should solve the main problem first. For that purpose you could rely on static inline data structures or json for external data. 
Humility? 
The data storage isn't the main problem here! That solves almost nothing 😉
No one is mentioning the package manage that is super easy. It complements and even empowers the open source community. I know if I were to make an open source package today, I would make sure it is python importable because it is going to reach so many more people.
I'd suggest you follow the guidelines anyway. They're written to help people make their code more readable, so it'll be easier for you to return to your own code after a while. It also helps people work together, even if it's a small team, because the code style everyone uses is the same. Also, learn git - it's an extremely useful tool.
I use Scons as a way to build reproducible scientific code and documents. Apparently it doesn't play nice with python 3, so for most of my work I stay on 2. For side projects I use 3 though. 
It took us 1 year to switch from Python 2.5/2.3 to Python 2.7. Which is compared to switching from Python 2.7 to Python 3.X "simple". So we need a very good business justification to switch to Python 3.X.
Probably not the answer you are looking for in the first place. I would suggest to use a config file. And reducing the number of arguments by deducting settings from other options/arguments.
Pro is python3. Even has a nice package manager built in. Other than that Pro is a piece of shit like most of ESRI's software.
It does not tackle the Byzantine problem at all, so no. https://bitcointalk.org/oldSiteFiles/byzantine.html However, git commits form a merkle-dag, so all the good properties (most notably, unfalsifiability of the history) that come with it are available here :)
Before I get to pep8, **please** use git (or at the very least *some* form of VCS) ... it's very easy and will save you so much pain in the long run. Hearing someone say they don't use it is like hearing someone using Photoshop or Word say "I don't use undo". Version control is not about helping others, it's about helping yourself. Now, on to pep8. The same basic point exists here; adhering to pep8 -- or whatever is the de facto "standard" style of a given programming language -- does actually make it easier for you to both type and read your code, but also read the code of others. No one actually codes in a vacuum. Even if you never share your code -- and usually if you're getting this advice it's because you *have* shared your code -- your code internalizes things you've read in the work of others, and though you might not recognize it up front, if that's all in pep8 it simply is easier to read and internalize than if it's in 90% pep8 and 10% ImABrogrammerAndI_DONT#caREAbout[you]reR¥les!!. Now, if you ever do decide to start collaborating with others, then it *really* begins to show its value, because using an agreed upon style up front just saves everyone debating an otherwise unimportant detail. Now, I'm not a Nazi, you can agree on any style you like with your team, but it should *always* be pep8 by default if your org doesn't have a logical argument for a choice that's both well documented and somehow improves on pep8 for your case. If you truly only intend to code in a bubble of your own, then of course it isn't worth learning (except to save RSI, which I swear avoiding dromedaryCase will do), but *very* few people do that for long.
Pillow is good for manipulation, like cropping, merging, filtering images etc. OpenCV is good for analysis, like detecting shapes and objects. I think they have different usages, although their features might overlap a little. 
When it comes time for you to interact programmatically with other people, you will be way behind. As you code more and more and learn good habits by osmosis, your old code will be a maintenance shitshow and will drive you nuts. Learn good habits - they exist for a reason - and you and everyone who has to work with your code will be better off for it.
Yeah I will try learning git. How much time shall it take?
I am willing to take that bet. Maybe we could set something up?
That's not a question anyone knows the answer to. It depends on how much you already know, how much time you spend on it, what resources you use, how those resources work for you, etc., etc.
Okay. I'll learn it first and then slowly try to implement pep8. But I think it would take a lot of time to amend my previous habit.
Splunk are terrible terrible people when it comes to this. They don't even support python3 in their official API and their response to paying customers is basically to just ignore them. 
Legacy app... Why change an app and libs that works since decades without any problem ? For the new apps i use Go which is more compliant with the zen of python than python 3. And more reasons that everybody know now...
It might do, especially if you've got a lot of existing code, though it will be worth it in the long run. Fixing all that existing code, though, will be *much* easier if -- hint hint -- it's in Git.
I haven't delved too much into detecting shapes and stuff with OpenCV yet, but I'm planning on using it for that eventually. I've been mostly using it for capturing images from video files, cropping, merging, and applying custom filters and colormaps. I'm also trying to learn Numpy at the same time, so it helps that opencv image objects are just Numpy arrays. I'll have to check out Pillow and see if there's anything I can't do with OpenCV, otherwise I'll probably just stick with it since it seems like it has a few more advantages over Pillow.
Until now I haven't felt the need of using git. But if it improves the overall efficiency,I'm ready to spend 10 min daily learning and using it. I don't exactly understand the term version control. 
I have got a lot of existing code, which are mostly self created python modules to perform some mathematical operations using NumPy.
Version control means keeping track of changes in your code. Let's say you have an existing program you want to modify. You tell your version control system "this is the initial version of my program", and it remembers that. Then you make some changes and tell the version control system: here's a new version, save it. The VCS now tracks two versions of your code: the one before the changes and the one after. If you find out your changes broke the code, you can easily see what you changed, or roll back to the previous version. If you make some changes that you don't want to save, you can easily roll back to the previous version. If you work with other people, you can take their changes (and only the changes, not the whole file) and combine them with your changes in a way that often _just works_ (though sometimes it doesn't, for example if you modified the same part of the program in different ways). If you want to try out some complicated change, you can move to a different "branch" in your history "tree" and easily go back to the main branch to implement fixes or simple changes while your big change exists on its own.
Good. Get them into a Git repository, write some tests, then start doing search and replace changes to update the style, running the tests afterward to make sure nothing broke. This usually isn't very hard. Most of pep8 is primarily about naming of variables and their case, so if you've got unique variable names it's just a rename, and the majority of the rest is about whitespace rules. If you're using something like PyCharm it can do a lot to help you. Also you can install **pylint** and run that on your code to see where the problems are. Using **pylint** is also nice because you get a score at the end of how close your code is to "ideal", but it doesn't just handle pep8 issues. You can also use install **pep** or **flake8** to get a more pep8-only view, but I've always found **pylint** to be more helpful if also more rigorous and opinionated.
The fact that Python 2 is on every box I administer. As yet, Python 3 is not. 
"the new platform" &gt;9 years old &gt;new wat 
Don't study the rules, just get a linter integrated with your text editor or IDE. Let it guide you. You'll learn over time. 