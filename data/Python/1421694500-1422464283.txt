From what I understand, unlike Python, Perl has the have-as-many-ways-as-possible paradigm. For that reason, I just can't get bother trying to learn more than very basic details of the language. I think the only thing that I've seen in Perl that I wouldn't mind seeing in other languages is the ability to use underscores in numbers, namely large numbers.
Logo is famously known for it's local versions. Because it's taught in primary schools it has to be accessible to young children. When we program in most programming languages it's bad practice to name objects/functions/variables in Polish.
I'm referencing Haskell's lazy evaluation, not Perl.
I'm gonna be *really* disappointed if [PEP 448 - Additional Unpacking Generalizations](https://www.python.org/dev/peps/pep-0448/) doesn't get accepted. It seems like something that should have been there from the start. **EDIT**: seems that [last week Guido mentioned](http://code.activestate.com/lists/python-ideas/30900/) having no problem with it, but that it needs a champion if it's gonna stand a chance :(
Basically what the article says is that they start honcho (or foreman), and this process then launches the two other processes. I haven't seen the code they have in detail, but I think you can achieve the same trick if you forget about honcho/foreman and instead run the celery worker via subprocess.call() from your web application, maybe in a `before_first_request` handler. Edit: subprocess.call is blocking, do not use that. Subprocess.popen is what I meant.
I use xlrd for reading and xlsxwriter for writing. I switched to xlsxwriter from xlwt and it is much more thorough and the methods make a lot more sense to me, especially when you get into things like cell formatting and charts. Although for pure data I have recently switched back to writing into CSV files rather than excel. Lately the only thing I user xlsxwriter for is when I need cell formatting. 
None of them seem as interesting as the three already accepted (@ operator, % formatting for binary strings, os.scandir()), but I quite like [PEP 455 - a key transforming dictionary](https://www.python.org/dev/peps/pep-0455/). It's a simple little class, but I can see it being a handy thing to have around.
But then you're stretching the length of the relationship. We can all agree a quote about programming in general can be well appreciated especially in a programming language that encourages brevity.
&gt; Copying 10 files at the same time will take the same amount of time as copying them consecutively. It won't though, it starts having to negotiate which goes through the pipe and in the case of a spinning disk harddrive move the head between parts of different files. Same deal when downloading multiple files on a modem, if you add up the download speed of the 5 different files you are downloading they don't add up to the same speed a single file would be downloading at. You are overloading the CPU with information it has to process, so you have to negotiate resources, but you overloaded the CPU so it bogs down negotiating resources making the overhead bog down the process even more. That's why you generally see programs max the threads to n-1 and you never see them go beyond that. You can devise a simple test to see this effect yourself, there are tons of multithreaded examples out there. Timeit with varying the number of consecutive threads for a length sample calculation and you will see the time (give the example scripts are pure CPU) decrease significantly up to the number of available cores and then increase as you increase the number of threads beyond that. Actually let me dig, I have some example here of a program I was writing that's slightly CPU intensive, so the decrease wasn't that great, on a quad core machine. You can see though how I lost any advantage when I went over 3 threads. Edit: apologies, the first python 2.7 example was on a quad core, the 3.3 example was on the hex core with hyperthreading but you can see when I went past the number of physical cores I didn't see much of a slow down or speed up and then going beyond the logical cores (12) it started increasing. Python 2.7 x32: i5 quad core Process=1, time=3.733974 Process=2, time=3.240570 Process=3, time=3.621810 Process=4, time=3.793044 Process=5, time=4.813963 Process=6, time=5.374350 Process=7, time=5.927902 Process=8, time=6.298794 Process=9, time=6.384847 Process=10, time=7.126289 Process=11, time=7.675376 Process=12, time=8.576280 Process=13, time=8.960128 Python 3.3 x64: xeon 6core /ht Process=1, time=1.9148696242695773 Process=2, time=1.1745971794762309 Process=3, time=0.9771652372991028 Process=4, time=0.7736542403111208 Process=5, time=0.7078036981806356 Process=6, time=0.6464961060545846 Process=7, time=0.6551731910644542 Process=8, time=0.6490236395825875 Process=9, time=0.6632605182511242 Process=10, time=0.689546579536011 Process=11, time=0.7106463932966989 Process=12, time=0.74272833202495 Process=13, time=0.7737027709256452
Maybe you will have better luck with [Portable PyPy distribution for Linux](https://github.com/squeaky-pl/portable-pypy).
“Progress isn’t made by early risers. It’s made by lazy men trying to find easier ways to do something.”― Robert A. Heinlein
OCR?
In a nutshell: If your problem can be tackled on a single machine, you are using a very, very expensive method to do distributed computing. For Python there are several nice libraries to scale on several cores, like [joblib](https://pythonhosted.org/joblib/). If you don't have data that needs HDFS and uses TBs and TBs of space and/or needs to scale out over several machines, throwing anything from Hadoop at it will probably just slow you down. Given your background, an excellent problem for MR is implementing an aligner, like BWA on Hadoop, implemented, *for example*, by [Seal](http://biodoop-seal.sourceforge.net/). Also a few papers in the Bioinformatics journal discuss use-cases, just look for "Hadoop".
pandas: pandas.io.excel.read_excel('myexcelfile.xls') or pandas.DataFrame.to_excel() I used xlrd at one point but was happy once I found that pandas could do everything I needed
My favorites are 3 of the 4 that have already been accepted: * Matrix multiplication with @ * os.scandir(): faster reading of directories in Windows * %-formatting for binary strings 
[PEP 441, improved Python zip application support](https://www.python.org/dev/peps/pep-0441/) would be awesome!
its the virtual machine creator for python3
I've used [Data Nitro](https://datanitro.com) years ago for a project, and had a great experience with it. At that time, I don't believe I paid for it, but it looks like it is now requires an annual fee. It looks like they have a free tier for students however, if you happen to have a .edu email. If you have a large project, it's definitely worth looking into.
It's nor incomprehensible. You're just too lazy to learn it. 
PEP 431. 1 less dependency for all my time based stuff.
What's the syntax error?
Why not just pass an `OrderedDict` as a parameter? 
That looks like exactly what we need! Very cool!
If you actually _learned_ perl, you'd find that it makes working with text and files extremely easy, and that the "have-as-many-ways-as-possible" paradigm is way, WAY overstated by people who have never bothered to learn Perl. Perl has _many_ more killer features than just underscores in numbers when one is working with the type of data Perl was literally build for. But you have to learn the language to get to know them. Reading why people think the language sucks won't help.
Look up the model number on Intel or AMD's websites and the technical specifications will tell you if it's hyperthreading capable or not. It's generally top end processors like i7s and top i5s that have it, from memory. Let us know what type of CPU you're using as well, so I can look it up myself to double check.
Print is a function: print (random.randint(1,6)) 
&gt; print (random.randint(1,6)) your awesome thank you, I hope you have a great rest of your day! :)
448 hype.
Swede here, been working with programming for 20 years. Everyone here, with very few exceptions, use english in the code, comments, variable names, and internal documentation. It's just simpler that way for a lot of reasons, and you really can't work in this industry without being good at english because all the documentation you need is in english. If you apply for an IT job here, your english skills are much more important than your swedish skills.
PyPerform is pretty much just a wrapper to make timeit easier to use :) It uses timeit underneath!
It's called appending. Found [this SO question](http://stackoverflow.com/questions/17731419/appending-a-matrix-to-an-existing-file-using-numpy) that does the main part of what you want. Basically: import numpy data = ... f = open("my_file.txt", "a") numpy.savetxt(f, data) Then you can probably do `f.write("\n")` and run `numpy.savetxt` again. Not tested, but seems simple enough if `savetxt` can take a file handle.
This worked like a charm! Thanks. If I understand correctly this approach opens the file in 'append' mode whereas what I was doing was simply running the numpy.savetxt() method which I'm guessing opens the file in 'write' mode, so it would overwrite every time.
Intel i7-4790 @3.6GHz
&gt; 3 of the 4 huh? &gt; Implemented / Final PEPs: &gt; &gt; * PEP 465 , a new matrix multiplication operator &gt; &gt; Accepted PEPs: &gt; &gt; * PEP 461 , %-formatting for binary strings &gt; * PEP 471 , os.scandir() there are only 3 listed as accepted. 
python 3 is different from python 2.7 # Python 2.x print "Hello, World" # Python 3.x print("Hello, World")
It sounds like you might have turned it off then, think it may be an option in the BIOS? Honestly it doesn't speed it up all that much, if you look at my hex core example for timings there wasn't much of an increase after I hit the physical core number and decreased when I hit the logical core limit. 
I think xlrd now supports xlsx
what? Yet another bandaid to help distribute python applications, which is currently so very very difficult to do? Its wont fix anything (the issue is *installing python* not running virtualenv), and no one will use it. I couldn't be less excited.
They're still working on it (PEP 484). Jukka Lehtosalo posted on his blog 2 days ago, saying the plan is to include it in Python 3.5. http://mypy-lang.blogspot.com/2015/01/mypy-and-pep-484-type-hinting-draft.html https://www.python.org/dev/peps/pep-0484/ 
What if you use the file handle as a temporary like so: for line in open("/path/to/file"): print(line) or: lines = open("/path/to/file").readlines() It's harder to test here since I don't think there's any way to do this and write to the file. I would expect CPython to function the same way here as in the write tests, but I wonder about the other implementations.
This is probably the biggest difference between PyPy and CPython: https://pypy.readthedocs.org/en/latest/cpython_differences.html Personally, I actually really like the RAII-style semantics of CPython's GC. If PyPy didn't exist, I would much rather let files close by going out of scope than using a "with" block. I used to write code like this all the time: lines = [line.strip() for line in open(location)] To me this is very clear --- the open file never even gets assigned to a variable; it's used and can be immediately cleaned up. So, I bristle at PyPy's position that this code is "wrong". It doesn't work with your implementation, okay --- and your implementation gives us a lot of good possibilities. Fine. I'll write the "with" blocks --- but all else being equal, that style is worse. I'd rather not be using them. It wasn't wrong to be relying on GC to have side-effects, and to assume that the GC would activate at predictable times.
For the video work and GIF creation [MoviePy](http://zulko.github.io/moviepy) is excellent, here is a nice [example]( http://zulko.github.io/blog/2014/01/23/making-animated-gifs-from-video-files-with-python/) Recognising the guns in your example and placing them in front of the white bars sounds pretty difficult. I've never done anything like that myself, but I agree with /u/tyggerjai that OpenCV sounds like your best bet if you want to do that automatically, but it certainly doesn't look easy.
I was unaware of this lo-fi 3D technique. Is there more out there like this?
Awesome, hope yourself or someone else can pick this up for the final push.
What do you mean by this: "It also loses support for calling function with keyword arguments before positional arguments, which is an unnecessary backwards-incompatible change"? Can you give an example?
I am also excited for the new Transformation dict. It was only recently I discovered that other people were also implementing their own such data structures, like the requests library using a CaseInsensitiveDict, and having direct language support sounds like an awesome idea!
Sorry I don't mean to be difficult, I just genuinely want to understand. What's the use case of preserving the order of **kwargs? 
I wonder if numpy is going to incorporate the @ operator.
http://www.reddit.com/r/SplitDepthGIFS/ The basic concept is to put white lines, and then remove them for the things you want to be 3d.
Can't imagine not, they were a big motivation.
Maybe this: https://code.djangoproject.com/ticket/19674
Indeed, and cycles aren't the only thing to worry about. Another gotcha that can lead to things sticking around much longer than expected is exceptions. Any exception you throw will hold a reference to the frame object, and thus to all variables, which can unexpectedly extend the scope of the file being opened to some function far up the stack that actually handles the exception. It won't get finalised till the exception handler resolves and the exception goes out of scope. This is probably not an issue in 99.9% of the cases, but could be for things like logging code (where the exception handler may end up calling the same code with the file still open), or in multithreaded code where that change in scope means a lock gets released with the file still open, and some other thread does something before the exception handler resolves.
Is there an option to not use CSD in Gnome Builder?
I think the standard solution uses `itertools.chain` but yours works too (especially if you need to reuse the logic often). list(itertools.chain(*zip(['a', 'b', 'c'], [1, 2, 3]))) 
If it worked on Numpy arrays it would be much better than .dot().
That's a really neat class, but it's very easy to implement. I'd love to have it, but some of those other PEPs like 448 (unpacking arbitrary **, *) excite me a lot more. I'd love to have both of course.
PSA: You can't use `len` on a generator since it's lazy. It doesn't know yet. Just an FYI that you can't just turn all your list comprehensions into generators and expect 100% the same behavior. They're an awesome tool though, and `yield` is pretty damn magical. Whenever you write a function that returns a list and builds it iteratively, consider trying out `yield` and see if that works as well. Especially if you're looping on a list you returned then `break`ing on a condition. If you don't need to calculate the rest of the list once you hit that condition, `yield` is the way to go. Also, you can dynamically create generators too: def antimod(mod): def antimod_gen(x): for i in xrange(x): if i % mod == 0: continue yield i return antimod_gen am2 = antimod(2) print [x for x in am2(10)] `[1, 3, 5, 7, 9]` Easily reproduced with a single generator that takes two variables `mod` and `x`, but still, it's cool stuff.
Ah HAH! Then that meant that OP must have spent time finding the text, and writing the code to automate the process! Which means that...that's ^very ^unlazy ^of ^OP ^^to ^^do... ^^that... ^^hold ^^on ^^^a ^^^minute...
&gt; The developers of the following projects have expressed an intention to implement @ on their array-like types using the above semantics: &gt;numpy pandas blaze theano
I literally just want a `step` argument to be added to `enumerate`. Don't know who to talk to about it, though. 
What happens if the generator looks like this: def lines(loc): with open(loc) as file_: for line in file_: yield line Does that have better GC guarantees than a version where the file is opened outside of a context manager?
Russian here. Feel free to ask any questions. Code, of course, is written on english, because you can't write python keywords in a russian language without interprepter patching, and it is really a weird idea. In fact, code for in-country usage often have a russian comments, but open-sourced code and code for international companies has an english comments. Also, we have here a 1C company which is creating software for business (document management, accounting and so on) and their platform allows to write java-like code in a russian language, it looks funny: ЗаписьXML=Новый ЗаписьXML(); ЗаписьXML.ОткрытьФайл("c:\doc.xml"); ЗаписьXML.ЗаписатьНачалоЭлемента("Root"); It rougly equals to this pseudocode XMLEntry = new XMLEntry(); XMLEntry.openFile("C:\doc.xml"); XMLEntry.writeElementStart("Root"); And I really want to say to all developers: use unicode and support for non-english languages, because sometimes programs fail if they're receiving any non-ascii character.
I know enough of it to stand beside my claim. One year in bioinformatics gives you plenty of time to learn it.
You might file a bug (maybe even with a patch) at http://bugs.python.org. It seems like the sort of a simple change that wouldn't require a PEP. I'm curious about your use-case BTW.
I think you have a logical error in your if statement.
Good question. I'm going by [this post on the tracker](http://bugs.python.org/msg65012): &gt; \*args is now considered just another positional argument, and can occur anywhere in the positional argument section. It can also occur more than once. **Keyword arguments now have to appear after \*args** Currently we can do f(x=1, y=2, z=3, *[4, 5, 6]) which is equivalent to f(*[4, 5, 6], x=1, y=2, z=3) If only for backwards-compatibility reasons, this behaviour should be kept.
I'm also happy that they're fixing the APIs of datetime to support timezones properly.
That's OK as long as you definitely exhaust the iterable. Since this is hard to guarantee in an exception-safe way, it's normally better to do def lines(file_): for line in file_: yield line # at point of use with open(loc) as file_: lines(file_) I've not seen a scenario in practice where this isn't possible.
Put the names of the special methods inside backticks like this: `__init__` then we'll see `__init__` instead of __init__.
Python is very popular in France, and the french language got a bunch of non ASCII characters : ùéèàûôêëïç... But while we do HAVE to write the output in french, we do NOT write the code in french. In fact, I've worked in various countries in Europe, Africa and Asia, and everywhere teams always write the code in english. Sometime the comments are not, but it's rare. So the only thing you have to worry is : - to have your code file in a declared encoding. Most of the time, you want UTF8. - to have all your string declared as unicode. - when you got text incomming (read a file, http request, db query, user input, anything not in your program...) you use decode('the encoding of the text') - when you got text outgoing (write a file, post a request, db query writting, terminal printing, etc), you use encode('the encoding expected by the destination') So you need : - to be sure you have your code in the encoding you thing you have. Setup your text editor. - be sure you didn't forgot a string in your program that is not in unicode. in python 3 it's automatic, in python 2 you can do from __future__ import unicode_literals - then identity your inputs and outputs. Everything that is not in your programme is an input or an ouput. - now the hard part, you MUST know what is the encoding of your input, and the encoding expected for you output. That's pretty much it : make it all unicode, use UTF8 as much as possible, decode your input, encode your output. Amen.
`__doc__` correspond to the class/module/method documentation `__builtin__` is the module that allow full name access to builtin method like open `__dict__` can be view as the hash table that allow access to module/class attributes `__iter__` if the class can be used as a container, this method should return an iterator on such class `__class__` in a method correspond to the object class of such method Generally speaking, the Python docs concerning [Special method names](https://docs.python.org/3/reference/datamodel.html#special-method-names) can be a good reference Edit:formatting
Please review the output from `which python`. If it shows `/usr/bin/python`, you must run `pyenv rehash` to update "shims". Please see also https://github.com/yyuu/pyenv#how-it-works
You literally don't need "a step argument to be added to enumerate". I'm not sure what exactly you mean by it but I'm sure you can do whatever it is you want without adding complexity to Python. To count by twos in the enumeration itself: for i, item in enumerate(iterable): i *= 2 ... To enumerate `iterable` skipping every second item ("step" of 2): from itertools import islice for i, v in enumerate(islice(iterable, 0, None, 2)): ...
Why not associate it with .whl extension that is already popular and well-supported? The sheer amount of different approaches to python code distribution has always puzzled me, and this adds another one, in the spirit of XKCD 927.
Wow didnt know we had pycon's in sweden, i will definitely try to make it there, as a visitor!
Okay, thanks.
Thank you. So what's the desired post 448 goal? Do we want to accept any order of keyword and positional arguments?
The website is a pain on a mobile browser. The word "python" always blocks part of the first line of the code snippet. The page also forces a portrait view in mobile and doesn't support landscape view (realigning). For a website about programming, the website is very poorly programmed.
Will it be open-sourced eventually? I don't see that anywhere. If not - no thanks, we don't need more closed-source tools made by a single developer that will eventually be unmaintained. Edit: It is already open-source. See comment by /u/goforkyourselfpal below.
the whole thing is in the open since day 1. https://git.gnome.org/browse/gnome-builder
In that case, woo!
I duuno about that. Remember, "Explicit is better than implicit." A with statement is many great things, but it (and context managers in general) makes things implicit, magical, and behind the scenes. This doesn't make them bad, but I think that it does make them "somewhat un-Pythonic," as I wrote in the post. And I can tell you from experience, having taught Python to thousands of people over the years, that "with" is far from obvious to newcomers to the language. 
`phone_sorter()` itself calls print and prints the newline. Also, for code to show formated like a code, add four space on start of each code line. Its much more readable and people are then more likely to read and answer your question.
It also requires an extra intent which makes for ugly code I feel. I don't use it. I just manually close files. Is that a big deal?
&gt; For that you can just use `islice(enumerate(my_list), 0, None, step)`. Oh, sure, and I could use a for loop instead of a list comprehension. Why even have list comprehensions in the first place? Additionally, `islice` requires another import, which feels a bit dumb for such a simple thing (And `0, None`? That's readable and nice...). Even if you wouldn't use the `step` argument, that doesn't mean no one else would. I severely doubt changing `en-&gt;en_index++;` in the [source file](http://svn.python.org/view/python/trunk/Objects/enumobject.c?view=markup) to `en-&gt;en_index += step;` (along with a few other small things) would have any recognizable performance impact (Though admittedly I don't know - it might have, in which case that's fair enough - it might also not be the correct line, in which case the very same). The complexity of Python would not increase in any meaningful way from this, either. It's literally a single argument, which will let code using enumerate with non-1 steps be simpler and more readable. Simple is better than complex, right?
&gt; I just manually close files. Is that a big deal? Unless you use try: # do stuff finally: f.close() which I find significantly worse than with f: # do stuff if an exception is raised while the file is open it may be closed "whenever" (and possibly never, the stack trace keeps a reference to the frame which keeps a reference to the file, so the file can't be released — and closed — until the stacktrace is released) Also note: in the first case, the `open` call *must* be outside the `try`, otherwise if the open fails the variable won't be bound (or it will be bound to not-the-object-you-expect) and you'll get an other error. So an old-style exception-and-GC-safe version is f = open(…) try: # do stuff finally: f.close() while a new-style safe version is: with open(…) as f: # do stuff (and the old style is even "funnier" with other "closeable" objects, like locks, as those are generally long-lived and not at all subject to the GC)
Brilliant.
Threaded writing, buffering where necessary, possible compression, and a faster disk.
Why would you want to write a "GNOME app" as opposed to an application that can work on a multitude of platforms? I like to use portable tools like Python so I can target a variety of platforms. And even if I *was* interested in targeting one specific platform, there's no way in hell it would be Gnome.
Under Win32 another possibility is to interact with Excel directly using the COM API. Not sure if this is what you are after, but I thought I'd throw it out there. [Here's a small example of how to do it](https://gist.github.com/mikepsn/27dd0d768ccede849051) 
FWIW enumerate is a relatively trivial composition of zip and itertools.count (which does support a `step` parameter in Python 3), so you can use that and it's almost as good: for i, e in zip(count(step=step), iterable): # stuff
Using the context manager is less explicit than calling close, but more explicit than depending on garbage collection behavior. Context managers may be unpythonic in the "explicit is better than implicit" sense, but I think they make up for it in "beautiful is better than ugly" and "simple is better than complex" senses. Using try...finally can get ugly, especially if you're dealing with multiple files (or other context managed things), and sometimes it can get confusing about what should be in the try block and what shouldn't. 
OP, you'll seriously get more answers and feedback there.
&gt; The complexity of Python would not increase in any meaningful way from this, either. Nor does the dirtiness of a city seem to increase from a single littered butt of a cigarette. If we were to add to Python's builtins extra arguments for everything people might want to do with them, the language would become worse and more complex very quickly, I assure you. Besides, the "step" of an `enumerate` is not a semantically unambiguous concept. Does it return `[(0, item_0), (2, item_2), ...]`? Or `[(0, item_0), (2, item_1), ...]` as you would have it? Or might it even be `[(0, item_0), (1, item_2), ...]`? That's one very good sign that a feature isn't a good idea. /u/masklinn's solution is simple, readable, and fast. I strongly believe that having small, composable pieces is much better than "everything does everything because it's shorter that way and I don't have to import anything".
The argument about `@@` is that it should be left for later to see if people really want it which is sane, standard practice in language design. I'm curious about why you dislike left associativity. The PEP's arguments seem pretty good.
That one exhausts generators, though, which might not always be what you want.
https://docs.python.org/2/reference/datamodel.html#special-method-names
Well, it's the same 'native vs generic' argument happening everywhere else right now (say, iOS vs Web apps) - you can go broad, and have something that works OK everywhere, or you can take advantage of the environment specific tools, API's and HIG have something that looks and feels like it belongs there. Me, I'm a GNOME user, python developer, and have some ideas for apps I want to make. I don't need gnome builder, but I'd love to give it a try. 
But now he just has to build an automated quote finder to push new content and there is now a fully integrated system that can automagically post quotes to imgur and reddit ;)
But your question was directed at "you".
To add to /u/goforkyourselfpal, your hardware limitations from the Pi aren't helping. Are you compressing now? Are you using the SD storage or an external drive? You could throw out every other GPS update and effectively capture at 2Hz, if possible. This way your write is complete before the next capture, provided you stay under 2 second per write. 
PyCharm works like a charm. And I got the licensed version, community edition for no cost. 
This is Python 3 code, not Python 2 (it won't run in Python 2, the `step` kwarg is not supported there)
Did you try `from . import package`?
&gt; Just a bit of trivia in case you're wondering where Pascal users are hiding. We're not all hidden! Pascal was the first language I seriously learned and that was only a few years ago. I moved to other things because I needed stuff I couldn't get in the Pascal world, but I still like it as a language. The fact pascal was left off this list is a huge injustice! /s
It will require your intervention. There's no way to know what should be in front of the bars and behind the bars, without your input.
Oh, does zip not exhaust generators and put the results in a list in Python 3?
Nope. Like map and filter, Python 3's zip is lazy.
You probably know this, and it's not optimal, but you can do this: d = OrderedDict([('a', 1), ('b', 2), ('c', 3)])
This may not work as well as I'm thinking, but it's worth a try: thread the GPS and video separately. When GPS updates, save it to a shared variable. The other thread will continuously write the GPS coord first, then capture the still. (I'm imagining either a binary file format containing both, or 2 timestamp-named files). At worst case, I think you'll have a 1s old GPS coord, but consistent still+GPS will be more helpful than interrupting the still capture when it runs a bit long; and at the scale you're at 1s doesn't result in a lot of movement.
1. Read the sidebar 2. Note what it says about /r/learnpython Good luck. 
Well, one example is in the `OrderedDict` constructor itself. `OrderedDict` is implemented with something like (paraphrasing) class OrderedDict: def __init__(**kwargs): ... And (as posted below) you currently can't create an OrderedDict like OrderedDict(a=1, b=2, c=3) With the intention of `a` coming first, `b` second, etc. Those arguments are converted to kwargs = {'a': 1, 'b': 2, 'c': 3} before being passed into `__init__`, which loses any order you supplied them in.
Nice! It still requires `itertools` and I'd still rather have a `step` parameter for `enumerate`, but that looks real good and is a nice way to put it. Thanks.
In python itself? [Use this](http://stackoverflow.com/questions/4172448/is-it-possible-to-break-a-long-line-to-multiple-lines-in-python). Out of curiosity, why not simply try? 
Yes, and I'm still curious why one would want to do that. I followed up by explaining why I personally wouldn't, but I'm interested in hearing counterpoints besides those just nitpicking my comment.
I recommend it, yes. Bitwise operators aren't one of those, "I use it every day things", but understanding bitwise operations is a good skill for any programmer. You ignore the real structure of your data at your own peril.
It's good they're adding that, but I'll still prefer my own implementation that allows transformations for keys and/or values at the time of storage and/or retrieval. The PEP claims that would never be useful, but I can attest I use it a lot. One example: dict1 is gigabytes of data dict2 maps alias keys to keys of dict1 - the get operation does the lookup behind the scenes dict3 is a union of the two, allowing lookup by original or alias keys without duplicating the data
....Yes? Absolutely. Ignore anyone who says "you don't need to know bitwise operators in Python" because they are absolutely, complete full of shit. Because understanding things like data types **matters** - including how you work with them. Also, most importantly, **it's easy**. What the hell? If you have a specific question, ask it, but you're literally just whining to this sub about it, presumably because find the idea hard? Not to mention, this is totally content for /r/learnpython, not this sub.
Seems like a lot of mucking with the fundamentals of function calling compared to just saying f(**reduce(dict.update, allMyDicts, {}))
Yes, I could have. But my points all still stand. It's regular subject matter, no different from learning any other topic. Why are you singling this topic out to complain about?
Hopefully relenting on % formatting for bytes is a prelude to also relenting on .format for bytes. I can't be the only one working with byte-oriented file formats. All this "BUT THE ENCODINGS!" obstructionism irks me. If encodings were relevant to what I was doing, I'd be using str.
If you want to just genereate excel files, I recommend simply create a csv file, then you can open csv files within excel, 
Almost certainly - the PEP was written by the scientific Python community for precisely that use case.
Actually it's even more complicated :( The way you wrote it, if you don't exhaust the generator you risk leaving the file open (until it's garbage collected). If you want to chain some generators and work with them explicitly, like with open(loc) as f: lines = iter(file) lines = (s.strip() for s in lines) lines = (s for s in stripped if lines) ... Then that just doesn't work because you catch "attempting to read from closed file" because it was closed before even the first line was read. So yeah, better not to mix generators and context managers -- construct your generators separately, then fully evaluate them before leaving the `with`-block.
&gt; I'm curious what for, and if you have the code anywhere Partly for fun, and partly because there doesn't seem to be any good LR(_*_) parsers, and I want to see if I could do anything better. Right now it's *not* better (it's 3 times slower than PLY) but I still have some promising ideas that I didn't have time to explore (more like: they're too mind-bending for me right now). It took me a while just to understand LR parsing at all, but it's simple now that I get it (LALR is still a bit wtf). Every explanation of LR I've seen is way more complicated than it has to be. I didn't publish the source yet, but if you pm me your email I don't mind sending you the copy I have. &gt; Do your thoughts on this matter stem (partially, at least) from my use of @singledispatch? singledispatch is very weird for me, since Python is duck-typed. If you don't take advantage of duck-typing, you're only left with its many disadvantages, and you might as well write in C# or D or Haskell. There are also other idioms that I remember were missing, like effective use of Exceptions. I also recall you used a lot of types and numbers when you could just use strings, which are much simpler and have the exact same cost. I once wrote a [blog post](http://blog.erezsh.com/how-to-write-a-calculator-in-70-python-lines-by-writing-a-recursive-descent-parser/) where I implement a recursive descent parser in 70 lines. It's full of hacks and cheats, but it's oddly idiomatic and it contains a few cool tricks (like the operator module). Maybe it will inspire you :)
I'm not sure what conda's launcher does, but one thing that is kind of neat is a project called pipsi (https://github.com/mitsuhiko/pipsi). Basically it lets you install something that provides a command (in ~/.local/bin/) but actually installs it into a virtual environment (in ~/.local/venvs/&lt;name&gt;). This gives you isolation per command without having to activate an environment.
I'd use getpass instead of raw_input for the password - it avoids echoing the password onto the inputting terminal. [Edit] s/askpass/getpass/ - that'll teach me for commenting from memory!
I am most interested in PEP 441 and PEP 448. Furthermore, I feel like PEP 441 should have a sister PEP for WSGI applications, so for example, Waitress, CherryPy, Gunicorn, mod_wsgi etc. could just be given a .pyz and know how to serve it. Essentially a Python equivalent to Java's .war
The naming of your package/subpackages/submodules is slightly confusing for this. I'd recommend getting IPython and trying to do your imports (use the tab completion to see what is available). Make sure whichever you're using (python, PyDev, Ipython) all have the up-to-date envs (exec $SHELL). 
Assuming you have a depthmap, then figuring out where to put the bars is relatively easy. /r/SplitDepthGIFS has some posts with guidelines, e.g. putting bars in front of something that moves to help ground the illusion. You can also assume that most of the scene should be behind the bars, based on the depth map. However, computing the depth map from a video is significantly harder. I don't think even OpenCV has tools for this...
Great post!!! Thanks!
Thanks! :)
I haven't tried a plot server like this before, but I was thinking about using this for an analytics dashboard. I like the idea of server-side downsampling of data that happens with the [Bokeh Server](http://bokeh.pydata.org/en/latest/docs/user_guide/server.html). I imagine this could be a future feature of Lightning as well?
More aesthetic. More functional: &gt;&gt;&gt; print "foo {}".format(2) foo 2 &gt;&gt;&gt; print "foo %d %d" % (2) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: not enough arguments for format string &gt;&gt;&gt; print "foo {0} {0}".format(2) foo 2 2 That piece of code shows how easy it is to use the same argument several times*. Also, format takes almost any kind of input and transforms it to its string counterpart, whereas using conventional formatting requires you to know what argument you are passing. And yes, it kinda looks more aesthetic. *I know that there's a way to do this using the conventional method, although I am not aware of it.
Sweet. I might try the IRC bot one soon. Thanks for all your hard work!
[yes it's fast, but just beware...](http://mod16.org/hurfdurf/?p=266)
PyMC is a great recommendation, but I think all the manual work needed to set up the prior relationships scares some people. Scikit-learn lets people throw all kinds of hammers at their nail relatively quickly, so it's going to be more popular. One of my favorite things in PyMC is just how easy change-point regression can be. I'm excited about fuzzywuzzy. There are many times when I'm matching up data sources, and I had been using difflib, but I'm always open for a new way of doing things. 
very cool list, looking forward to trying out fuzzywuzzy I found arrow much nicer time use than Delorean, although the latter wins purely based on name.
For progressbar, there's a updated version: https://pypi.python.org/pypi/progressbar-latest
PyMC is great. IMO, it's far easier to use than Bugs or Jags.
&gt; Assuming you have a depthmap Hah! Well, yeah. "Assuming the only hard part is already solved..."
This is cool.. Thanks Here, see if this is better . [LINK](https://gist.github.com/lfsando/87a48323dd481059c50b)
Short answer, everything ;) http://docs.opencv.org/doc/tutorials/tutorials.html It has built-in support for everything from motion detection to facial recognition, but the heart of it is access (via numpy in python) to the underlying pixels so you can analyse and manipulate every aspect of a picture, and thus a video stream. Since you can manipulate the underlying content, you can add what you like. It had inbuilt support for various polygons and contours, but again, the sky is the limit. The two things I do with it at the moment, for example, are take the feed from two cameras (a minoru stereo rig), pull the blue layer from one and the red from the other, and merge them to give a primitive "3D" effect. I also have a program to track a moving coloured LED that controls a robot arm - it not only does th the color and motion recognition, but for you the interesting part is drawing a circle around the LED it is tracking on the replayed image. It is, as far as I know, the current state of the art in open source image manipulation like you describe. 
Why don't you think it's pythonic? After all, [explicit is better than implicit](https://www.python.org/dev/peps/pep-0020/). 
I have separate threads going. How do I have a variable seen by both threads?
Ok so this isn't exactly perfect but it gets close... tr '\n' '\r' &lt; c.py | fold -w 78 | tr '\n\r' '\\\n' | fold -w 79 &gt; d.py That will break most python code but it adds the line wraps so that's something.. 
You may want to fix the translation on [line 40](https://gist.github.com/lfsando/87a48323dd481059c50b#file-gistfile1-py-L40), otherwise, it looks good.
:-) Well, splitting the problem into two... First, the technical issue of finding a depth map. I don't think it's solved yet but similar video processing techniques are able to extract geometry from video: http://research.microsoft.com/en-us/um/redmond/projects/hyperlapse/ I'm sure similar ideas could be used here too. Second, the design question of figuring out where to put the bars and what should be in front/behind, that part could be interactive but seems easier to handle with simple heuristics.
Matrix exponentiation isn't as extremely common (in the relevant applications) as matrix products, so I understand the lack of `__matpow__`
Yes, but it actually contained a list of lesser-known python libraries, so I don't mind. It also wasn't _11 python Libraries that you've never heard of... and will blow your mind! #4 really got me._ So I'm doubly ok. 
I had experimented with the idea of only selecting "touched" tests - performance was ok (&lt;2x the normal, non-coverage run), and it was pretty selective (most code only touched &lt;5% of tests). My problem was setup code - how to detect it, and what to do about it? Mark all tests as changed? I wonder how they solve that.
The developer probably had an iPhone in that case. I tried both Google Chrome and Mozilla Firefox on Samsung Galaxy Note 3. The "python" text is always on top of the first line of code and turning into landscape didn't readjust the text. Did your landscape also look beautiful?
In PyPy make sure you close your files and not depend on the garbage collector to close the files. The GC will eventually close the files but it occurs with a much longer delay than occurs on CPython which can lead to running out of file descriptors. Even under CPython it is wise to explicitly close your files or use a with statement.
Thanks! I love these lists; always finding new ones I could use. There's also [Clapp](https://github.com/kbknapp/clapp-py) which is a simple command line argument parser kinda like Docopt...but then I'm biasd because I wrote it...so yeah, shameless plug ;)
Really nice post, thanks! I was so amused by your comment "because it's listed on GoogleCode, which is basically the coding equivalent of Siberia" that I have mirrored prettytable on GitHub https://github.com/mapio/prettytable-mirror hoping this will help others discover the library!
Hm I understand the problem but still think it would be a mistake to introduce yet another way of working with paths that is different from (and presumably to some extent incompatible with) the existing "path tools". Was there a specific reason why some kind of `Path` subclass (e.g. called `CachedPath`) couldn't be used?
Conda really is a great alternative tool for particular audiences (e.g you're on Windows trying to get hard-to-build binary packages, and don't happen to have a system package manager to help you). For most python users, needing to install, activate and use many different versions of python just isn't a need. We also get to support more pythons than just an x86 abi compiled one, like on ARM and others from PyPy and Jython (or rather, we prefer not to leave them out in the cold). Anaconda also only support the Python they install, in their installers, in their way. All this essentially means we can't solve the binary problem nearly as easily as they can. The Python you get for instance in Debian isn't exactly the one that's distributed in python.org's source tarball. So all that said, in particular, no, something replicating (or being) conda isn't on the horizon at the moment. But we do recognise it has successfully filled a niche for a nice chunk of audience. If you'd like to know more about what we're trying to get done [you can read some goals in writing here](https://www.pypa.io/en/latest/future/) if you'd like as well.
What's wrong with google code?
Great list. I think I've implemented buggy/brittle versions of prettytable half a dozen times already. I'll be good to have a sane implementation.
Well, I fully accept that if I'm iterating over a file, and passing control back and forth from the function (via a generator) then the file stays open...And, if I exit a context manager, the file will close. That's what the construction means. But I may still want lazy evaluation. The resource that I'm iterating over might be very large. If I'm iterating over objects from a DB, for instance, obviously the connection is open while the loop is in progress. Sometimes you want to buffer the read and discard the resource; other times you don't. 
Is it sad I'm giddy to add this to a script I run at the office?
Thank you for writing about libraries I actually do not know about! I hate it when the title is the same as yours and I know every item listed.
thanks! that was way overdue
If that's sad, then I don't want happiness.
With PEP 448, that could just be (*pair for pair in zip(a, b))
Note that you should use `chain.from_iterable(x)` over `chain(*x)`. PEP 448 gives you an alternative, too, of `[*pair for pair in zip(a, b)]`.
&gt; For that you can just use `islice(enumerate(my_list), 0, None, step)`. That's `step` times as much work, though, since it iterates linearly.
very good point. the times I find it useful for IPython plugins is when you don't want to have pandas as a pip dependency.
Instead of Colorama, use the oh-so-amazing [Blessings](https://pypi.python.org/pypi/blessings/1.6). There's even [a fork with moar features](https://pypi.python.org/pypi/blessed/1.9.5) if you need. I'll also mention I just saw [progressive](https://pypi.python.org/pypi/progressive/0.3.2). Looks neat.
I like `clint` as a one stop to replace progressbar and colorama.
Yes, I agree. However the function `foldl` above isn't recursive on the reduction. It should really be called `foldll`... sorry for the confusion. It takes a nested list of lists and runs the usual `foldl` on each one until `_iter == 1`, then does one last reduce and returns the result. So it would take something like [[1,2,3,4],[1,2,3,4],[1,2,3,4]] with the `_iter` argument set to `2` and after one pass return [10,10,10] Then it hits the base case and returns 30 I can't remember the context for writing this thing. I see the `n_factorial` example can be misleading. A regular `foldl` would just be foldl = lambda f, x: reduce(lambda s, t: f(s, t), x) EDIT: I recall the context: somehow I ended up with a large nested list of booleans, all of which I expected to be `True`, but the default output for numpy in the ipython notebook is to preview large lists or matrices, so I just figured I'd do `foldl` on `foldl` on `foldl`... with the `and` operator in order to check if all values were `True`.
Does Blessings support ansi escape sequences? The thing I like about colorama is that it translates ansi escape sequences appropriately in a Windows console, which normally doesn't support it. This means that I can talk to a remote device via pyserial and autmatically get it to translate the ansi colors and operations when I dump the output to the stdout.
Hmm, didn't know that. I'll have to point that out, though we've already implemented something that works well enough for our use case. *edit*: Ah, turns out we needed even more optimizations than that is able to give us; in particular, the underlying system `readdir` call gives us the inode number, which we need to compare against a cache of hard links, in order to avoid having to stat the underlying files if we've already done so on another hard link. It looks like the `DirEntry` API used here only includes the path and name, not the inode number, without invoking another `stat` call, and we needed to optimize out that extra stat call.
I wonder why the same guy has uploaded a new package name... :S
What have you been using wget for inside of python scripts? I've never needed it and I'm just struggling to find a use case.
ooh, if that's really the case then I like that a lot. I've always thought that splatting into `itertools.chain` is a really ugly way to concatenate a bunch of iterables.
I haven't looked at it in detail recently. I was trying to make essentially a single-user webapp where UI actions in the plot could trigger callbacks to load more data or other arbitrary RPC-like things. That wasn't their goal so their messaging didn't do what I wanted. They also had heavyweight dependencies like redis. If I were doing it again, I might build on the ipython widget framework.
Quick and dirty web scraping, perhaps?
Oh my god, how did I not know about sh?
It outputs to stderr by default.
A little late, but here's one for fun. &gt;&gt;&gt; parse_accounting = (lambda o='$,':(lambda x:(lambda t=lambda c: '' if c in o else c: reduce(lambda i, f=['0']: (lambda s, u: (s/(-1*s))*(u+sum(map(lambda _: _[1]*(10**(-(_[0]+1))),enumerate(map(int, f))))))(*map(int,(i,i.replace('-','')))), ''.join(map(t, x.rstrip(')'))).replace('(','-').split('.')))())) &gt;&gt;&gt; parse_accounting('$,')('($1,00,00,000.000008)') -10000000.000008 The first argument is a string that takes anything you want to strip (so all kinds of currency symbols, whatever).
Gotcha. I think I read they might do that now, but not sure. 
In a tight loop, all kinds of normally trivial things can really add up to a lot of wasted time.
"#9 will SHOCK you"
It's not pypi
Especially when there is `requests`
Thanks! I'll be converting over, then.
You'll never believe which to libraries hooked up in Vegas!
It looks like the author just want a language which can do literally everything he wants without using any sort of external software. Well, ok, simply buy Wolfram and be happy then.
another sweet mcmc sampler which is ridiculously easy to set up is [emcee](https://github.com/dfm/emcee)
The link explains it all, and also because some people are nice.
To be fair, pyglet was last updated in July 2014: https://code.google.com/p/pyglet/source/list
So, we have actually added a pure in-memory backend so the redis dependency is optional. The ipython widget framework might do what you want, but from what I can tell right now, it's really meant to be a one-shot way to handle the needs of scientific programmers who want to build certain kinds of canned widgets, and not a generic way for you to do generic, cross-language "Web Components" type of things.
Something compelling enough, because Google itself seems to be releasing more and more into GitHub directly.
One of the projects I was on awhile back - I don't remember which one - decided they were going to test out migrating to Google Code from Sourceforge. They then announced that it went so smooth they were done, and they apologized for not giving more notice but they thought it was going to be more difficult. So somebody on the Google Team did a damn fine job of imports projects from other code repositories it would seem. TL;DR: Migrating code to Google Code is like pushing a banana peel across an ice rink.
Yes. The problem is that you want to print some phone number and number of calls from that number on the same line, right?
It's just syntaxic sugar really, i just defer to thread the requests. But it's a nice alternative to the treq lib : - less performant (requests-twisted uses threads while treq uses fast native twisted web agent). - it uses the requests API, while treq is a little bit different. - requests provide some additional features treq doesn't, so you get that as a bonus. In the end, it's just the easy solution for lazy people like me who don't want to learn another API and just want requests, but async. 
That's good to know, but in this case it's Apache Spark that's responsible for opening and closing files and it likes to open lots of files.
Seems it's not using Windows-compatible colors (search "Windows" on the PyPI link). I've never wanted to, so I hadn't noticed.
&gt; That's what the construction means. But I may still want lazy evaluation. Well, too bad. I mean, there is a way to achieve precisely that: you take all your lazy processing, the entirety of it, and put that into a context manager. So that the file is closed when the whole processing that depends on it is done. Which is actually pretty logical, if you think about it. But you have to be careful about it and you shouldn't try the trick with a context manager inside a generator to make closing a file not lexically scoped, because it doesn't work: http://ideone.com/NksXjN By the way, Haskell folk had the same problem with a vengeance (since _everything_ is lazy by default there), they spent years trying to figure it out, inventing iteratees (push-based iterators), then "pipes", then something called "conduit", then ["frames"](http://hackage.haskell.org/package/pipes-2.1.0/docs/Control-Frame-Tutorial.html), because each solution turned out to be incomplete or hard to use or unsafe. This shit is actually pretty hard, for reals.
Basically because it used to be amazing.
I'll be using the sh library for sure.
What would you use then? Qt? I don't use Gnome specifically, but I prefer Gtk over Qt and for the one desktop app I've written I used PyGObject, so the app would fit in with the rest of my desktop. 
i think github launched some years after google code
it's sad that i don't have a script that can benefit from the progressbar :(
It would have looked something like this to start with: def unfairness(group): return max(group) - min(group) this was inside a loop that called this function at least once every iteration, possibly twice this was exchanged for some subtraction of specific data elements in a list. e.g. j = 3 for i in range(len(some_list)): num = some_list[i+j] - some_list[i]
great answer- Thanks!
Um. Has he not heard of Flask?
Seems like api change is not backwards compatible. You can use the old api but have to call `pbar.start()` first. New way is to wrap iterable item like so: pbar = ProgressBar() for i in pbar(range(10)): time.sleep(1) If `len` call on iterable will fail, it'll use `maxval`. It's an mprovement IMO but changing package sucks.
Can you install this version using pip? What Python version does it support? etc....
The answer is clear, Visual Basic is the best possible teaching language: https://mrgict.wordpress.com/2015/01/13/choice-of-programming-language-justifying-my-choice/ Sorry for the sarcasm, but I think you guys will enjoy this one as well. 
&gt;Function calls are expensive because a new stack frame is created (this is the actually expensive part) and pushed onto the stack. What makes this more expensive than say, C, on an *algorithmic* level? I understand that compiled languages are inherently faster, but is Python doing something that C is not when "pushing a stack frame onto the stack"?
Google code came before github or bitbucket - and it was easier to use than SourceForge. Also, some folks still want to use mercurial or svn over git. 
It was the best when it came out.
You generally don't, though beginners might either because they are children and aren't good enough, yet, or because they aren't accustomed to using English this extensively. Tutorials, documentation, blog posts, screencasts, mailing lists, IRC channels, etc. are simply more numerous, of better quality and more populated in English. Exceptions aside you can't become a good programmer and not fluently communicate in English. Simply because no matter how intelligent or talented at all, you will be at an insurmountable disadvantage. Besides you don't have a decision anyway. Keywords, the standard library as well as any other libraries you might use are going to be in English. Even if you don't use English for your own code, you're going to end up with some mix of English and whatever other language you are happen to use. That's quite ugly and more difficult to understand than just going with English.
Counter's behavior around empty collections isn't collection like: &gt;&gt;&gt; c = collections.Counter() &gt;&gt;&gt; c['a'] += 1 &gt;&gt;&gt; c['a'] -= 1 &gt;&gt;&gt; 'a' in c True bag supports len in a more intuitive way also: &gt;&gt;&gt; c = Counter() &gt;&gt;&gt; c['a'] += 1 &gt;&gt;&gt; len(c) 1 &gt;&gt;&gt; c['a'] += 1 1 &gt;&gt;&gt; len(Counter(cats=4, dogs=8)) 2 API-wise, it has ``add``, ``remove``, ``pop``
I like to use [clint](https://pypi.python.org/pypi/clint). It also has more features that I tend to also use when I need (or want, really) colors.
Is game programming the primary reason for switching to JS for his introductory class? Seems a bit odd to me actually, if that's the case. Different strokes...
I tried to do something like this the other day but for reasons I cannot fathom this stupid Comcast router just will not let me telnet in, even after forwarding port -_-
fuzzywuzzy is such an excellent name. Before I even read the description I knew it was going to be a fuzzy string matching library.
A post from current fellow https://www.djangoproject.com/weblog/2015/jan/21/django-fellowship-retrospective/
 Will it be available to view after - 2pm PT is 10PM here in the UK! 
Oh. Looks like OP got himself kidnapped and deleted himself as poster
Oooh, I really like progressive. Super simple to use, and I think it looks better than progressbar. Thanks for sharing!
Its not setup in pypi but heres the windows port linked from psycopg2's web site: http://www.stickpeople.com/projects/python/win-psycopg/ If you want to install it in a virtualenv you can use easy_install as pip doesn't understand .exe packages. Also, looks like there's pip compatible packages here: https://github.com/nwcell/psycopg2-windows 
Yep. The hangout will automatically be uploaded to youtube. You'll be able to watch right from the event page, I think.
Still better than Sourceforge. 
Django + Celery seems to be the standard solution these days.
&gt; mercurial bitbucket 5ever
well, for the surprisingly commonly linux/bds/mac using developers the hops to provide sane windows binaries are quite a pain in terms of tool setup, while on linux/bsd, the source tarball will just work, even on the hipster toys without any effort
Yes, I did read the last two lines of your post. To put the proper context, in case you edit your post, they were: &gt; And stuck there. I finally succesfully installed it through unofficial channels offering precompiled binaries. &gt; What the fuck. It's 2015, is shipping binaries really that hard? So, you mentioned that you did find some precompiled binaries, but did not include any links for other people to use: all you did was write a rant. I obviously did not find the same links you did (although some other redditors did provide some more relevant links than mine) but I did my best to try to help others by finding what could be a helpful link. Des québécois avec une attitude comme la tienne, ostie, contribuent à nous faire mal paraitre. Au lieu de sacrer, de te plaindre et blamer les autres, essaie donc de contribuer positivement pour une fois dans ta vie.
Tes sérieux avec ton rant racial, Uncle Tom? Well, you are wrong. I took the binary from that website precisely. 
The readme are the only real docs. A lot of the search logic is actually controlled by Twitter. [Here](https://dev.twitter.com/rest/public/search) are the operators you can use. 
&gt; Obviously 0 is not connected and 1 is connected but to what, to ground? It appears that this board has internal pulldown resistors: &gt; There are 10K pull-down resistors on the board. So, removing the resistor will let the internal pulldowns connect the pin to GND, signaling a 0. Looking at the layout of the board, I see that the other end of the prepopulated resistors are connected to VCC (positive power), and are thus "pulled up" to signal a 1. TL;DR with resistor = 1, without = 0 EDIT: more info about the rest of your question: Take a look at the part's [datasheet](http://www.ti.com/lit/ds/symlink/tmp007.pdf) (page 23). It says that `0x1F` is the address of the device ID register inside the memory space of the chip. You can read this to find out the "Manufacturer ID" apparently, this is probably not going to be very useful for you. Some general info on how I2C works: The first thing you send on the bus is the device's I2C address (`0x40` thru `0x47`). The second thing you send is the address of the register you want to read/write from/to the device's internal memory space. The last thing to happen is either a write of a byte to the selected memory address inside the device, or a read of a byte from the memory address selected. Yes, that code is written assuming there is only one device at I2C address `0x40` and will not autodetect others. You could discover this info, however, by polling each possible address and seeing if any device sends back the ACK or NACK bit. Hope that helps.
Er, what is your question? The code looks fine, what isn't working?
The part when i promt fro 2 inputs and append that to a function that starts the server.
Use a VM. No seriously just give up on developing with Windows, I've gone down that path and it is a nightmare full of subtle and not so subtle headaches. Use a tool such as Vagrant and spare yourself. Shameless plug, I have a tool that can generate a development environment for you, check it out if you like. https://github.com/wldcordeiro/cookiecutter-vansible Note, you will need Virtualbox and Vagrant on your computer as well as pip but from then on you can just use the Ubuntu VM as the development OS with your project files in a folder on your host Windows 
OMG Yes!! Thanks!!! Here have some reddit [Gold!](http://i.imgur.com/FjUcQ69.jpg) But seriously your awesome!
can recommend source: still on windows semi-broken-alternative: cygwin
No judgement intended... laziness is often a virtue in programming. It can bite you in the ass though.
Has anyone proposed a StrEnum class? Python really needs it to help prevent the use of magical strings arguments. StrEnum could help people transition in a backwards compatible fashion similarly to NamedTuples.
Blurring is a non-reversible action: what you are describing does not make sense. Also, look at the sidebar: you are posting in the wrong subreddit.
Oh sorry i didn't know there were multiple subs for python, my bad!
You should be able to install both versions and then use virtualenv to create isolated environments to work in. Are you on Mac, Windows or Linux? 
This. All day, e'eryday.
I am on windows.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Richardson–Lucy deconvolution**](https://en.wikipedia.org/wiki/Richardson%E2%80%93Lucy%20deconvolution): [](#sfw) --- &gt; &gt;The __Richardson–Lucy algorithm__, also known as __Lucy–Richardson [deconvolution](https://en.wikipedia.org/wiki/Deconvolution)__, is an [iterative procedure](https://en.wikipedia.org/wiki/Iterative_procedure) for recovering a [latent image](https://en.wikipedia.org/wiki/Latent_image) that has been [blurred](https://en.wikipedia.org/wiki/Convolution) by a known [point spread function](https://en.wikipedia.org/wiki/Point_spread_function). It was named after William Richardson and Leon Lucy, who described it independently. &gt; --- ^Interesting: [^Deconvolution](https://en.wikipedia.org/wiki/Deconvolution) ^| [^Lucy–Hook ^coaddition ^method](https://en.wikipedia.org/wiki/Lucy%E2%80%93Hook_coaddition_method) ^| [^List ^of ^statistics ^articles](https://en.wikipedia.org/wiki/List_of_statistics_articles) ^| [^List ^of ^algorithms](https://en.wikipedia.org/wiki/List_of_algorithms) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cnww5tg) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cnww5tg)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
great software. I can easily convert any image into text for free. Thanks you for this excellent tool
but, my teammate, using xlrd, is quite unhappy about it. Anyways ...
That's like 4 operations per second. You can even do it with plain text files if you want to. 
Sure, but are you saying that these boxes don't just have wget installed? I suppose if they're Windows boxes with Python but not a Win32 compiled wget that could be an issue, but if they're Linux/BSD/similar systems they usually have wget you can use straight from the shell.
Listen to this person, `conda` is way easier than `virtualenv`, especially on Windows. And you can still use `pip` within a conda env so you only gain functionality, you lose nothing.
Opencv could help make a tool for this, but I bet those people are doing it by hand. You could spend over 100 hours making a tool to speed your labors afterwards 10 fold, but how many gifs are you going to make?
Listen to this person, `conda` has a lot of packages precompiled and working like magic on Windows where compiling things is... sad. So just say `conda install numpy` and BAM `numpy` works. Well it's already there because of anaconda, but that's details. Anaconda is like the Oprah of package managers.
Am I the only one who had now idea what a "stemmer" is?
it is really short.. I wouldnt hire you for remote work due to the lack of experiance 
It seems that I need add more descriptions about my experience.
Unfortunately unless you did something spectacular with your 3 years most people won't hire you for a remote job. With only 3 years of Django you are basically a mid level developer and most companies won't take the chance. Sorry man.
ops, yes I have to admit that I need more experience. However, I am not able to relocate for new job, meanwhile there is not any jobs like python developer in my city. Maybe I need some luck.
Yes, I do need a good recruiter. I have built a website which is currently reachable. Tuanzll http://www.tuanzll.com/zh-cn/ I take charge of background development, and some part of front end dev. 
I'd rather people used python packages and `pip install -e/uninstall .`
Give that website to the recruiters to use to sell you. Hopefully something comes up.
Pretty sure that's not a first year assignment. If it was, you'd get the equation handed to you.
Thank you!
WHAT IS THIS http://www.acronymfinder.com/EMC.html
I'm in the same boat. But because I also need multitouch on multiple plataforms, I think it's the best option for me. Woe is me, I was actually doing a UI using pygame before discovering Kivy.
TL; DR So much text without break. Too much text grouped together always deter a interested reader sub-consciously. Describe more but re-structure more than that. on a side note: don't just hang onto Django. Pick up some more technologies to widen your horizon. That will show recruiters you are quite dynamic in light of changing requirement. some other redditor can elaborate more on this point.
Kivy is not designed for game design. It's designed for standard everyday apps. The impression might get caused by kivy mostly showing games in the gallery, but that's just because a lot of users like to create games. Has nothing to do with the intention of kivy itself :) Another reason why a lot of people think that kivy is heavily designed for games is that it uses pygame as a background service. Most users don't know that kivy just uses pygame to draw on a window. It doesn't even give you the ability to use pygame features yourself. It's basically just a background provider for a drawable surface! The only problem I see with using kivy for everyday apps is the slow startup. That might be a reason to develop the app in a different language (especially when it's supposed to be an app that you open and close very often each day) So: * Apps that get opened/closed really often -&gt; Might consider switching to a different framework/language. Perhaps the native Java app thing. * Apps that you open less often (so you can live with the startup time) or if you don't care about the startup time: use kivy!
I've been looking at this kind of situation for about a year. I haven't used Kivy, but people I've spoken to seem to like it (or perhaps just the idea of it). The samples they provide look ok. I've also looked into the Apache Cordova project (write in javascript) and Xamarin (write in C#, support for win, android + iOS). Not sure what's best, but I'll likely try Kivy later this year. Android development is painful according to many. Apart the SDK in Java that they want you to use, there is also the lesser known NDK (native dev kit) which lets you write in C++. Worth a look into. Good luck, and let us know how you go.
One step closer. Python will finally have made it when it's used to make a GUI to track an IP address.
You might be beyond help after all.
As a novice in both Cordova and kivy, I prefer Cordova. It's a bunch easier to layout and theme your application. I found myself having a lot of difficulty using kivy to just layout a page... And wondering why some things overlapped when others didn't. Cordova gave me the ability to quickly prototype an android app to pitch to a local business that didn't look like it was built two decades ago.
Happy cake day
Have you tried googling _any_ of these questions?
I feel like if it has "Basic" in the title, it belongs in /r/learnpython 
Post your resume in /r/cscareerquestions on the weekly resume thread.
And here's the source: https://sourcegraph.com/hg.python.org/cpython@default/.PipPackage/Python/.def/trace/_fullmodname (Line 183)
Well, the idea is that I just want to see an advancement of this concept. so I'd design the filter open source with an open use license. That way it doesn't end up being a proprietary adobe filter. Plus, it would let more people make more of these cool gifs.
Then NDK is not for the feint of heart, it's really only meant for situations where the performance of the SDK isn't fast enough.
My guess is Java, but I dislike Java and don't know any good frameworks for something like this. 
Even I hate Java :/
You could use C# with [Xamarin]( http://xamarin.com/). Didn't use it, so I don't know how good it really is. And it's not free.
For which?
You still have to invoke the C++ code from Java. I don't know about iOS, I thought the options were Objective C or Swift, unless you used something like Xamarin
&gt; Lack of up to date documentation, an api that breaks with every update (have they even heard of retro compatibility?) Such as? There are APIs that you can only use on newer versions, but I've never seen them break existing ones. &gt; a complex build system What makes it complex? &gt; and the hurdle that is Java overall. Java is probably one of the easiest languages to write. What hurdle are you referring to?
Hmm, I'll have to look up how that is implemented. Good idea. Thanks
I worry about articles which focus on attractiveness, and not on comparing visualisation tools individual strengths. Not to mentioned mpl now supports style schemes, which adresses many of the common complaints.
Read [Open Sourcing a Python Project the Right Way](http://www.jeffknupp.com/blog/2013/08/16/open-sourcing-a-python-project-the-right-way/) by Jeff Knupp
I assume they wanted to go for more clean futuristic look as opposed to old-school 80s fluorescent green haxxorz one. Cause everyone assumes future will be cleaner and more sleek for some reason.
Yay pip \o/
I believe in order to use C++ you need to write a C or Objective-C wrapper around the library and you would have to do all of your GUI programming with Objective-C (or Swift with Objective-C objects) anyways. 
No detail at all.... 
I've submitted it for review at Apple, so hopefully it wont be long. Android is in beta, but I'm releasing it if the iPhone version gets approved. -edit- Oh, inclement! I didn't see it was you. This means a lot coming from you. We've talked before on irc. 
Do you have experience with Cordova? Everyone I know who has created an app with it hates it so much that they refuse to use it again. Can you be more specific about your annoyances with Kivy?
Kivy should install and run fine on Ubuntu 14.10. Stop by the [#kivy IRC channel](http://webchat.freenode.net/?nick=kvuser.&amp;channels=kivy&amp;uio=d4) on Freenode or the [kivy-users Google Group](https://groups.google.com/forum/#!forum/kivy-users) and we'll figure out your problem.
Where's the docs?
I'd be happy if we replaced the 6502 assembly in the next terminator movie.
What little set up this does, I could probably type faster than it would take to install and use this "tool".
&gt; Do you have experience with Cordova? Nope, it's even my first time getting my hands full with JS! But from reading the documentation and knowing its popularity, I'm keeping my hopes up. &gt;Can you be more specific about your annoyances with Kivy? Sure, first of all would be the lack of a proper, easy to use "table widget". I had to make my own implementation with whatever I learnt through months of fiddling with Kivy. Even then I'm not happy with it, and only on Kivy 1.9 did I get the functionality to make it work more or less well (there's still a bug with scrollviews inside scrollviews, the inner scrollview's content will block interaction with the side of the interface you're moving the info to, even if it's behind). There's buildozer not working well with Python 3, so I had to start my project with Python 2, not sure if anything has been done in this area. I've had troubles making .kv code and native python code interact (IIRC, the problem was binding actions in Python to widgets defined in .kv, but don't quote me on that). Then there's performance, but I believe they're working hard on that.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**IS (Infinite Stratos)**](https://en.wikipedia.org/wiki/IS%20%28Infinite%20Stratos%29): [](#sfw) --- &gt;___IS &lt;Infinite Stratos&gt;___ (Japanese: IS〈インフィニット・ストラトス〉, Hepburn: *IS &lt;Infinitto Sutoratosu&gt;* ?) is a Japanese [light novel](https://en.wikipedia.org/wiki/Light_novel) series by Izuru Yumizuru with illustrations provided by Okiura and CHOCO. As of October 2013, 8 volumes have been published by [Media Factory](https://en.wikipedia.org/wiki/Media_Factory) under their [MF Bunko J](https://en.wikipedia.org/wiki/MF_Bunko_J) label. From volume 8 onwards, the novels will be published by Overlap under their Overlap Bunko label. A [manga](https://en.wikipedia.org/wiki/Manga) adaptation by Kenji Akahoshi was serialized in the *[seinen](https://en.wikipedia.org/wiki/Seinen_manga)* [manga magazine](https://en.wikipedia.org/wiki/Manga_magazine) *[Monthly Comic Alive](https://en.wikipedia.org/wiki/Monthly_Comic_Alive)* from May 2010 to July 2012 with five volumes published under their Alive Comics imprint. A 12-episode [anime](https://en.wikipedia.org/wiki/Anime) adaptation aired in Japan between January and March, 2011, and an [OVA](https://en.wikipedia.org/wiki/Original_video_animation) was released on December 7, 2011. The anime is licensed by [Sentai Filmworks](https://en.wikipedia.org/wiki/Section23_Films#Sentai_Filmworks) in North America, and they released the series on April 10, 2012. A second series aired from October 3, 2013 to December 19, 2013. &gt;==== &gt;[**Image**](https://i.imgur.com/r1NvmFH.jpg) [^(i)](https://en.wikipedia.org/wiki/File:IS_\(Infinite_Stratos\)_Vol01_Cover.jpg) --- ^Interesting: [^8-Bit ^\(studio)](https://en.wikipedia.org/wiki/8-Bit_\(studio\)) ^| [^Megumi ^Toyoguchi](https://en.wikipedia.org/wiki/Megumi_Toyoguchi) ^| [^Asami ^Shimoda](https://en.wikipedia.org/wiki/Asami_Shimoda) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cnxdoe0) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cnxdoe0)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Speaking as someone who loves anime, this show is exceptionally bad. The French girl is cute though.
If we're talking about convoluted and cryptic-looking to a native Japanese speaker, pretty much anything in English will work.
You can actually target iOS with java using the package libGDX: https://github.com/libgdx/libgdx
I'll grant your first two issues as legitimate, but if you expect better performance from Cordova than Kivy you're gonna have a bad time.
I don't expect native performance, but if they're using the platform's native web engine implementation it should be as fast as that, and that's good enough for me.
I'm having an enormous amount of fun learning C from [K&amp;R C](https://en.wikipedia.org/wiki/The_C_Programming_Language), pdf [here](http://books.cat-v.org/computer-science/c-programming-language/) (but I'd buy the book). I find C beautiful, for all the different reasons that I find python beautiful. Python's polymorphism is wonderful, and it's so easy for a '1' to be a 1. With C, on the other hand, it is beautiful that 'a' is 97, and you can "shift" a letter Caesar-style just by adding a number, e.g. `'a' + 1` is 'b'. Both languages are wonderful (IMO), and I'd certainly learn C as well (or maybe Go). It's very good to see the "other end" of things. Actually, I find assembly language on the Pi a lot of fun too ... EDIT: As /u/Psimonster pointed out, 'c' is a char, but "c" is a string. Sorry.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**The C Programming Language**](https://en.wikipedia.org/wiki/The%20C%20Programming%20Language): [](#sfw) --- &gt;___The C Programming Language___ (sometimes referred to as ___K&amp;R___, after its authors' initials) is a well-known [computer programming](https://en.wikipedia.org/wiki/Computer_programming) [book](https://en.wikipedia.org/wiki/Book) written by [Brian Kernighan](https://en.wikipedia.org/wiki/Brian_Kernighan) and [Dennis Ritchie](https://en.wikipedia.org/wiki/Dennis_Ritchie), the latter of whom originally designed and implemented the language, as well as co-designed the [Unix](https://en.wikipedia.org/wiki/Unix) [operating system](https://en.wikipedia.org/wiki/Operating_system) with which development of the language was closely intertwined. The book was central to the development and popularization of the [C programming language](https://en.wikipedia.org/wiki/C_(programming_language\)) and is still widely read and used today. Because the book was co-authored by the original language designer, and because the first edition of the book served for many years as the *[de facto](https://en.wikipedia.org/wiki/De_facto)* standard for the language, the book was regarded by many to be the authoritative reference on C. &gt;==== &gt;[**Image from article**](https://i.imgur.com/WjUwRHP.png) [^(i)](https://commons.wikimedia.org/wiki/File:The_C_Programming_Language,_First_Edition_Cover_\(2\).svg) --- ^Interesting: [^The ^C++ ^Programming ^Language](https://en.wikipedia.org/wiki/The_C%2B%2B_Programming_Language) ^| [^CppCMS](https://en.wikipedia.org/wiki/CppCMS) ^| [^C++](https://en.wikipedia.org/wiki/C%2B%2B) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cnxfp61) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cnxfp61)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
that's funny, you weren't kidding
If you're a Pythonista then I'd try Rubymotion as Ruby is the closest language you're going to find. See my comment above regarding this :-)
It's horrendously expensive as well!
What about performance?
That really is too open ended of a question to have a real answer. What do you want to make with software? What platforms do you want your software to run on? What hardware do you want your software to run on? What libraries do you want to work with? What if your code was spiders? All of these are important questions to ask yourself before you pick up another language. Mainly just pick the best fitting tool (programming language/library/framework/operating system/spider) for the job as far as you can tell. 
I would advise you to at least: 1. post your code on something easy to read, like pastebin or something similar 2. explain what is not working, what you tried, etc. 3. Look at the sidebar and "please consider [r/learnpython](http://www.reddit.com/r/learnpython)"
I've seen part of your code and I'm sorry but I don't think you're intermediate yet, however I see big progress in small time. Can I ask your age? I'll give you a few tips: * Inconsistent names: Some bits seem [PEP 8 Compliant](https://www.python.org/dev/peps/pep-0008/) but other parts of the code seem completely random. Maybe you learnt in the meantime how to write consistent names I don't know. Read PEP 8. * Too many comments: It may sound like a good thing but it's not. I.e. visible = True # Makes the object visible See? Don't write a comment unless it's necessary. If a comment is necessary maybe there's a better way to write that code. * Too many imports, many times you import things that you clearly don't need, better safe than sorry, up to a point. * Too much exception handling: You shouldn't handle an exception that you can't handle unless your point is logging the issue. I.e: ` try: import pygame import os import Ships except ImportError as e: # Prints the error and keeps executing. print("Error -&gt; {}".format(e)) ` If your program cannot continue it's execution without these libraries you should only handle the exception to log it in a particular way. You don't log it nor handle it so why capturing it? * Massive lines: Make the shorter, one more time read PEP 8 * Code that works is not enough it should also bee good. I don't want you to get discouraged, at first all of us write code that isn't that good and if you see this code in 6 months you'll see a shitload of things wrong with it. Happens to everyone. I wish someone had given me these advices 8 years ago... When you're more experienced than now (not now seriously, stick to python for a few months): If you want to move to C/C++ for fun, if you think that knowledge is going to benefit other of your skills in a reasonable learning/time ratio or if you want to program for a small platform that only has a C compiler go for it. However, if you want to learn C because you think you're going to be able to make better stuff in C than in python it's a straight no. Even if you want to program 3D graphics and python is a bottleneck, C++ is a hard language to start and you have easier to approach.
If you want to get serious with games (as in, a career) then I would definitely recommend it, especially if you're talking PC or console games. You might be able to get away without it if you just focus on Android or iOS but then I think you're really limiting your potential as a game developer by sticking to one platform. Even if you're just going for a general career in programming it's good to be familiar with these languages. Understanding the principles and how the memory system works will make you a better programmer, and learning C/C++ will force you to do that.
Correction: 'a' + 1 = 'b' Double quotes for strings, single quotes for characters.
 tacidsky, thanks for your feedback. yes, I will add dependency checking maybe like from pip.req import parse_requirements requirements = parse_requirements("requirements.txt") setup( ... install_requires=[str(r.req) for r in requirements] thanks for your link to asciicinema look very useful ;), I'll try
Yeah, good character designs, shit show.
thank you :)
http://cdn.meme.am/instances/500x/45069827.jpg
No, thats not my concern... I appreciate you guys' input though... Just don't even know whats wrong. Teacher is a bit of a prick, and the semester is over tomorrow (hence my rush). I will continue to work on it. Problem is that inside the "if" loop, if the statement is true I need to change a variable name. I dont even know xD 
In fact, "a" +1 == ""
Try /r/learnpython
Looks like a scam.
&gt;Nope, it's even my first time getting my hands full with JS! But from reading the documentation and knowing its popularity, I'm keeping my hopes up. Then why are you going to use it? Are you just looking to have one codebase for all platforms?
This is awesome!! One day we may have Python optimizing and compiling itself be a more efficient solution than CPython
Double-enter for a newline and surround code with backticks (`)
Yeah, I definitely far prefer the backend (although I still get a bit of a childish thrill out of manipulating the DOM with jQuery =P) so you might be right on.
How about [Science](https://scipy-lectures.github.io/intro/index.html)?
I think maybe it's got to do with the fact that python is used a lot in making those japanese visual novel games, thanks to Ren 'Py and stuff.
Woops, I'm retarded. I was using RES so I thought it was just an image. Thanks.
Nice resource - in general. I looked at the OOP section ... horror, teaching to use set methods instead of directly accessing attributes. Someone learn programming using Java and realized too late that Python was useful...
tacidsky, I finally took the gif image with ttygif https://github.com/icholy/ttygif
i've thought about this, for sure. i feel like i'd be good at getting other people's science into a harness like this and helping people and groups with their research that way.
You can do this with [pandas](http://pandas.pydata.org/). Edit: Created an IPython Notebook [demoing this working](http://nbviewer.ipython.org/gist/jbarratt/d4a11fa3553064a100b9)
# Generally Python will have sqlite3 built in so ... import sqlite3 with open('/path/to/file.csv', 'w+') as write_file: # open a file to write to conn = sqlite3.connect('/path/to/database/database.db') # connect to your database cursor = conn.cursor() # create a cursor object (which lets you address the table results individually) for row in cursor.execute('SELECT * FROM your_table_name'): # use the cursor as an iterable write_file.write(row) # write to the csv, then you can open the csv in Excel. # Open up your csv in Excel. # You can also use the 'csv' module, which has an Excel dialect. # Completely untested, so look up the 'sqlite3' and 'csv' modules on: # https://docs.python.org/3/library/csv.html #https://docs.python.org/3.4/library/sqlite3.html
 &gt;&gt;&gt; import tkinter &gt;&gt;&gt; import ipaddress Okay, I did the hard part. Someone else can pick it up from there.
Both those questions are already answered in the blog post itself. There is even an example that shows the difference in size of a 100 element dict in the old way vs the new.
AttributeError: 'module' object has no attribute 'sql' :(
&gt;Java is probably one of the easiest languages to write. Yeah I dont really know how to respond to that. Specially being in /r/python.
Weird. Once I get my kids to bed I will send you an actually tested example...
There are many examples in kivy's repository at https://github.com/kivy/kivy/tree/master/examples , though possibly they aren't distributed with your installation (they're left out of some packages for space reasons). These are actually really useful and I don't think we point them out as much as we should. I also go through some basic examples in some tutorials I did, mainly video but I wrote up the first three, you can see them [here](http://inclem.net/pages/kivy-crash-course/).
What exactly is wrong with it? Here is a better link for anyone who wants to look at the [code] (http://pastebin.com/30GWmCJV).
I am a sociopath asshole that don't care about emotional arguing. Right. Good software are not made from mediocrity. Resign as a developer so that we can make softwares that works.
I added a little bit more extensive docs here: http://collections-extended.lenzm.net/bags.html#collections-counter
when you distribute a package with pip maybe the first time is a bit confusing, I recommend this post https://hynek.me/articles/sharing-your-labor-of-love-pypi-quick-and-dirty/
Why would they not be doing this on lighthouse?
I have tried all of these methods and get error messages... Is it the way I am saving the .db file maybe? http://pastebin.com/rnBcMMPK Line 124 is where the relevant information starts.
Yeah. ASM, perl or obfuscated C would be better for that magic hacker-ness.
Ok, fixed it. [See the IPython Notebook here](http://nbviewer.ipython.org/gist/jbarratt/d4a11fa3553064a100b9).
I'm not really sure what that adds compared to `python setup.py develop [--uninstall]`. In any case, I think writing a `setup.py` file is a huge barrier for many people. I rarely use this tool for my own code, but when *teaching* someone how to write modules and packages, the standard ways are really painful for people new to the language.
You can use os.walk to recursively traverse all subdirectories, like so: # create list of all files that exist in directory (recursive) global file_list file_list = [] for dirname, subdirlist, files in os.walk(dir): for filename in files: file = os.path.join(dirname, filename) file_list.append(file)
I ran your script to create the fake db (which worked perfectly) and then ran the following script: import pandas as pd from sqlalchemy import create_engine engine = create_engine('sqlite:///' + db_name) df = pd.read_sql_table('stocks', engine) df.head() but after this is ran I still get the error: df = pd.read_sql_table('stocks', engine) AttributeError: 'module' object has no attribute 'read_sql_table' I wonder if I am missing a module? I updated sqlite3, installed pandas, and installed sqlalchemy. Weird. 
How about trying finance? https://www.ziprecruiter.com/jobs/sandpointe-llc-686e6629/financial-software-engineer-9a256033
Weird. I tried it on version 0.14.0 and 0.15.2 of pandas. What happens if you print pd.__version__ ? If its &lt; 0.14.0 these features aren't there.
https://golang.org/
0.80 which is bs because I JUST installed it haha damn. Well I'll get on that and report back. apt-get install python-pandas has failed me :(
/u/inclemnet above is your guy. His youtube series is a really good introduction. But I made a [stop watch](https://gist.github.com/Laspimon/740185c161c386ddaf2a) for you. The [Pong tutorial](http://kivy.org/docs/tutorials/pong.html) is also very straightforward.
Well I might be out of luck. I'm on a version of debian and according to the pandas site apt-get install pandas is the newest stable version. Also this http://www.raspberrypi.org/forums/viewtopic.php?f=32&amp;t=81856
Well I'm installing the newest version of pandas with a ton of warnings (100s). According to stack exchange it should eventually compile after 30 min to an hour. I'll report back.
Can't explain why, as the creator has to show me what to expect.
That will install the latest version your distro's repository has, which will generally be very out of date. Best to use pip: `pip install pandas`
You should be able to do this straight from sqlite. sqlite3 -header -csv database.db "select * from my_table_name;" &gt; database.csv
That was really interesting, thanks for the link.
Oh nice, I hadn't heard that they were redoing Westworld. 
The dict array in the old implementation is at most 50% full, that means 50% memory wasted. To make insert O(1) the new dense array needs to be overallocated by a bit (we use roughly 12.5%) when resizing of the dense array occurs. That means on average only half of that, 6.25% is wasted.
I'm really tired of uncomplete and outdated blog posts. It's like everyone want its minute of glory and no one work in common.Turns out this doc has no publicity but is the most complete and up to date I've seen so far. Do you think something's missing ?
That's a good point! Thanks, I'll update it asap.
May I ask what lighthouse is?
ULP?
https://randomascii.wordpress.com/2012/02/25/comparing-floating-point-numbers-2012-edition/ explains comparing floating point numbers and ULP
That's about where I am at. I've been doing web development in Python for about 10 years and my 2nd strongest interest in Python is exactly what you describe: helping people do their research with Python (in my case, FMRI research as an alternative to MATLAB).
thank you for your help, I'm just getting stuck on how to implement this into my code. 
Make sure to check out https://caremad.io/2013/07/setup-vs-requirement/ for an awesome treatise on the similar but different purposes of requirements.txt and install_requires. It's important not to confuse users, IMHO.
i keep getting the error "TypeError: coercing to Unicode: need string or buffer, builtin_function_or_method found" not sure why.
https://randomascii.wordpress.com/2012/02/25/comparing-floating-point-numbers-2012-edition/[1] explains comparing floating point numbers and ULP
if i replace the dir at the end with "." it doesn't give me that error but it will not let me open the files. "for dirname, subdirlist, files in os.walk(dir):"
Windows may be the worlds most used desktop OS but it is far from the most used OS when it comes to developing or running python together with postgresql. Linux is almost the de-facto standard for python and postgresql, both for development and deployment. So in this case it's more about why would people care about supporting some exotic environment like Windows+python+postgresql when the most common one is some kind of linux.
ULP = units in the last place. Two numbers that differ by 1 ULP have the same exponent and their significand is the same except for the lowest bit.
I agree. lol
Considering that the stated implementation is abs(expected-actual) &lt;= max(tol*expected, abs_tol) which is actually pretty straightforward in meaning, I don't see how is_close_to(actual, expected, tol=1e-8, abs_tol=0.0) would be an improvement syntactically. I can see that perhaps hard-coding the function in CPython might offer a slight improvement in performance, but probably anything you're writing where using abs, max, and a comparison results in too much of a performance hit, you probably shouldn't be writing it in Python anyway.
Lighthouse is a crowdfunding system that runs on the bitcoin blockchain and uses smart contracts. It pays out far faster than the competition and is a bit more computer tech oriented. 
&gt; complex : for complex, abs(z) will be used for scaling and comparison. Wait, what? Doing that will make 1 and 1i equal, even though they're orthogonal. Heck, it makes -1+0i and 1+0i equal.
So that newbies can be directed to a one-liner way to properly check for floating point equality, without even needing to know the exact details, nor needing to install any library for this single common issue. Python implements a metric tonne of conveniences throughout the standard library and language to help people do the right thing the first time and without needing any custom code, so this is completely in line with existing design. A good helping of examples exist, for instance, in the `random` module. You don't need to get a statistical bias with `i = (rand() % (max - min + 1)) + min` because you've got `random.randint(min, max)` right there.
virtualenv and mkvirtualenv http://virtualenvwrapper.readthedocs.org/en/latest/command_ref.html
I've always just used elpy with ipython. I hadn't heard of emacs-for-python before though. Maybe I'll give it a try. 
I would recommend to use the [pathlib module](https://docs.python.org/3.4/library/pathlib.html). I provides a more modern api for the filesystem.
Tolerance has been abbreviated as tol in numerical applications for decades. It's not exactly the same thing, but no one will ever expect trig functions to be fully written out.
&gt; Tolerance has been abbreviated as tol in numerical applications for decades. History and tradition are no good arguments for continuing a practice. Often they are the only reasons why a bad practice hasn't been changed. I'd argue that upon introduction, this function's primary audience is for people "new" to doing this kind of operation in a program, so making it clear for them should be prioritised over having it take 0.8 seconds longer to type for an old hat.
Well when you decide to write the code by hand you can decide whether or not you need a tolerance or an absolute tolerance for each specific case and you can avoid unnecessary function calls which significantly improves performance. For instance, you may end up coding a specific case as if -1e-5 &lt; value - other &lt; 1e-5: which takes less time to execute than just the overhead of a single function call itself. For a feature like this that will often end up in an inner loop it is critical to remove all function calls. It's not necessary to do so in languages like C, C++, Java, etc but in CPython it becomes a bottle neck as the overhead of function calls are so high. Of course if a generic function is provided it needs to handle both types of tolerances and you will end up will an implementation that is less efficient than hand coded code that meets the needs of a specific case but it's still important to eliminate the function calls. You don't want the cost of calling the tolerance function and then the cost of it call a max and abs or calling a couple of abs functions.
Yep, s/prettytables/PrettyTable/
I'm arguing becuase you are using the wrong terminology. What you are calling monolithic are actually full stack frameworks. The smaller ones are known as micro frameworks. https://www.google.ca/webhp?sourceid=chrome-instant&amp;ion=1&amp;espv=2&amp;ie=UTF-8#q=micro%20web%20framework https://www.google.ca/webhp?sourceid=chrome-instant&amp;ion=1&amp;espv=2&amp;ie=UTF-8#q=monolithic%20web%20framework
It's not just the time it takes to type. It's that every other library and numerical language in existence uses tol, including Matlab and the very popular Python libraries scipy and numpy. I think it's better for newbies to spend 2 minutes consulting the docs and learning standard practice than for legions of experienced users to have to remember that Python is different.
Oh come on, it's already different, it will have a different function *name*, and more likely than not a different function signature. Legions of experienced users don't need the help. Are we even pretending that we should be able to copy+paste some other language into a .py file and have things immediately line up? Python syntax is quite different to most others, not to mention that's a horrible habit.
Interesting. I've never heard of them before. I'll look into it.
&gt;Freenode :/
What's wrong with Freenode?
I suppose is_close_to is more clear than is_close or isclose as well. If clarity was really the reason for that, rtol or rel_tol or relative_tolerance would be used instead of tol in the proposed API. Also, why is the default absolute tolerance 0.0? Why is relative tolerance the default? Either the defaults should both be 0 or they should both be reasonable like numpy. Also, the complex part of is_close_to(1i,1)=True is BS. The author clearly doesn't understand what close means for complex numbers. Magnitude and phase matter, so compare real/imaginary or magnitude/phase, not one of the terms. It's a good PEP. I just totally disagree with it in the current state.
&gt; will often end up in an inner loop it is critical to remove all function calls If it's critical, use numpy
I started codingforentrepreneurs.com. They have a free course. After I'll take their course on Udemy.
What namespace will this live under? `math`? Seems like a fairly useful function to have built-in, so I see no issue with having it. Only other idea I have it to make this state based, and have it automatically apply to all float, etc. comparisons (e.g. `set_tolerance(tol=1e-8, abs_tol=0.0)`). Could also be a context manager like: with tolerance(tol=1e-8, abs_tol=0.0): for i in range(N): if x[i] == y[i]: do_something(x) Probably a bit much for stdlib though. 
Just because it doesn't come up in your domain much doesn't mean it's not useful functionality to have. Python supports floating point math out of the box without a sane way to check for equality, and it's a really easy thing to screw up, especially for someone who isn't aware of the gotchas of floating point math. For a language that encourages doing the right thing and guiding developers into the pit of success, this is a pretty big failing. Of course, there's nothing wrong with using a third party library or writing your own logic (it's pretty simple), but it seems like in many cases it would be a premature optimization to most if there was SOMETHING included in the standard library to handle this.
your calculation for hours is wrong. if you are trying to convert hours to seconds, you don't take the number of hours and multiply it by 60...
Way too much policing/service-y. And not even the good kind, for example you registered nick expires in 60 days unless you identify with nickserv. Had irssi running in shell for two months without logging in? Too bad. Not to mention GMS and other useless clutter. KISS, which traditional IRC pretty much is, seems to be completely alien to the devs.
You're right that would convert it to minutes. But if you want to find the total seconds, wouldn't you take the total hours elapsed * 60 (which would convert to minutes) add that to the total minutes elapsed * 60 (which would convert the minutes to seconds) and then add that to the seconds? *edit* I think I see what's happening. It's not adding the hours converted into minutes to the minutes and then multiplying that. Its just adding it after the minutes have already been multiplied to seconds.
I manually downloaded and installed numexpr 2.1 and then tried df.to_excel('example.xlsx') and it did not work. Although, df.to_csv('example.csv') DID WORK!!! Thank you everyone for your help I really appreciate it!
It depends on what framework you're using. [Here's a stackoverflow answer with examples from a number of frameworks.](http://stackoverflow.com/a/464977)
I came here just for the token vim comment. Thank you.
I'd look into django more. I've worked in it a lot and it's great. You should also check out asynchronous frameworks like tornado, which I think the future is moving too.
Numpy legitimately has a learning curve. It's can be hard to vectorize your code and people think they should support arrays and matricies making their code overly complicated. Micro-optimizations done in Python aren't going to get you the performance you need. You either write the function in C (so now your Python script has a build requirement), or you write it in numpy. If you do it right, the speed will be the same. People just don't understand how important preallocation and loop unrolling really is. Python is slow because it's dynamic and not because of function calls, so get rid of the dynamic part (or cut it down to 1 millionth of what it was).
In Python you can call and/or assign a variable to almost anything. What you are seeing is the default string representation for a built-in function. Regards
What I really like about this PEP, and about PEPs in general, is the amount of comprehensive thought that goes into them v.s. the rather ad-hoc solutions we all write in a jiffy. 
~~That is because there is no sane way to check floating point numbers for equality without knowing the entire history of calculations that led to them. As an example, 1*10^-7 should be equal to 0 if it's the difference between two very large numbers, but not if it's the difference between two very small numbers, and there is no way to know this based solely on the number itself. That alone is enough to convince me that it is a very bad idea to make this standard functionality.~~ edit: I should probably have read the proposal before writing this. It appears to suggest that every comparison uses user-specified tolerances, which is completely different from what I was thinking. That actually makes sense. I still don't think it needs to be in the standard library, though.
I want my gui to run at 100fps.
From my interpretation `is_close_to(1j, 1)` isn't a problem but `is_close_to(1 - 1j, 1 + 1j)` is: # is_close_to(1j, 1) abs(1 - 1j) &lt;= 1e-8 # = False # is_close_to(1 - 1j, 1 + 1j) abs(1 + 1j - 1 - 1j) &lt;= abs(1 + 1j)*1e-8 # = True Your point is still entirely valid of course.
Well then I have some bad news for you...
If you use a package manager for vim, these are pretty good. Find them on github. call vundle#begin() Plugin 'gmarik/vundle' Plugin 'Valloric/YouCompleteMe' Plugin 'scrooloose/nerdtree' Plugin 'Lokaltog/vim-easymotion' Plugin 'flazz/vim-colorschemes' Plugin 'scrooloose/syntastic' Plugin 'Lokaltog/powerline', {'rtp': 'powerline/bindings/vim/'} Plugin 'SirVer/ultisnips' Plugin 'honza/vim-snippets' call vundle#end()
I'm not sure if this is all that useful. I find elpy to do everything that I did in Wingware, except for debugging. Which I believe can be done, and I'll blog it as soon as I figure it out. I also prefer elpy to emacs-for-python, because it can be installed through the package manager. Also, I see no mention of cython support, which emacs has as well.
You can do e.g. `from numpy import exp`, and then `exp(5)` will work. The computer you used may have had a command like that in a startup script. In fact, it was probably using *pylab*. This is a convenience mode that imports a whole load of functions so you can use them straight away. In an IPython session, you can get that by typing `%pylab`.
The ``%pylab`` command you used is specific to the IPython interpreter and does import many modules as a convenience for scientific calculations. However, you have to understand how to import basic modules if you are going to take full advantage of what Python has to offer.
I often use numpy, but numpy is not a good fit for all projects. If you have a lot of data where you have to do quite a bit of math plus you have a lot of logic in between the math you will find that these types of problems don't always work well with numpy. To get any speed up from numpy you need to broadcast over large arrays or taking advantage of some scipy or some other third party library that performs a lot of work during each call. In a project like this, if you want to get effective use of numpy you would end up having to convert a large amount of code to cython. The other option is to leave the code in pure python and just use PyPy as it handles these types of projects well. Another area where numpy does not perform well is when you have to deal with a lot of small arrays. For example lets say you have 1 million 3d vectors and you don't have the possibility of creating a 3x1,000,000 array as it may not make sense to do so for a particular problem but instead you have 1 million individual 3d arrays. Perform a np.allclose on those million vectors and time it and then do the same in pure Python. You will find CPython will blow away Numpy. Repeat in PyPy and you will get even faster results that approach the speed of C code. So numpy is definitely not always the answer when performance is critical.
R is a language specifically designed for statistics, so it has a lot of mathematical functions available by default. Python is a general purpose language that a lot of people use for scientific computing, so the base set of functions doesn't have nearly as many mathematical operations in. Give Python a chance - there's always a bit of friction when moving to a new language where things don't work quite the way you expect. Having to import modules isn't really a problem once you're used to it.
i've been building in django for quite a while now. i'm just not sure the web is where i want to be. that said, i'm thinking about building a corporate-level 'build your own cms framework' framework.
What a fantastic concept. Why not crowdsource a course that you charge people for monthly anyways? Its such a brilliant concept.
This looks very interesting. Thanks!
1. You are not returning anything; by default, Python functions return ``None``. What you likely want is to use ``return`` instead of ``print``. 2. This is the wrong subreddit for this type of post (look at the sidebar). In the future, please ask at /r/learnpython 3. When asking on /r/learnpython, look at the sidebar first to see what is expected for questions - in particular, what is mentioned about screenshots.
Thank you! Sorry :/
I'm just starting out on the site myself, and it seems really promising. Hope you find it useful too!
Don't apologize, learn from your mistakes :) Also you can iterate over a list in python by doing for i in scores: print(i) Instead of that for i in range(len(lst)) stuff you were doing before.
pip freeze https://pip.pypa.io/en/latest/reference/pip_freeze.html
Does this work with virtualenvs?
Sockets. Glad I could help.
Nice. 
The complete Anaconda distribution includes these packages. Minimally, this should do it: conda create -n envname python pip sqlalchemy ipython-notebook cython numexpr pandas xlrd xlswriter # matplotlib * http://docs.continuum.io/anaconda/pkg-docs.html * http://conda.pydata.org/docs/
Trying to learn, yet ignores the large friendly letters suggesting that you post these kinds of questions in /r/learnpython. Scumbag /u/itareu
&gt; This is definitely a case where CPython's call overhead will dominate the execution time. I think that's irrelevant as you're using a bad method . For the majority of cases, a pure Python functional solution is adequate. If your loop needs to be fast and it's called a million times, use numpy. If you compare math.sqrt and numpy.sqrt for an inner loop computation 1 million times, math.sqrt is faster. Numpy is much faster if you vectorize your code. As such, both functions are useful. &gt; We are starting to lose sight that this thread of comments started as a result of PEP 485. I think the PEP is a great idea, even if it's pure Python. I wouldn't approve it in it's current state for multiple reasons.
Looks very nice, thanks for the feedback, I'm probably going to implement something similar for accessing PyPI repository.
They're not necessarily the same down to the last bit, there's just one bit's worth of difference. In the example I gave, one value ends in ....100 and the other ends in ....011, so the last three bits differ, but the difference has a magnitude of 1 bit, because adding ....001 to the latter results in the former. 
I detect your sarcasm and agree with it. I hate to rag on his idea, but I am not understanding the appeal of this. &gt;The main reward is ... a significantly reduced monthly rate or a heavily discounted yearly membership. Now, one of the rewards allows you to "lock in" a monthly membership of $55/month. This implies that the membership will normally cost more than this. Given that everything he's teaching is already widely available to learn for free on the internet, I would never pay for a course like this. Let alone pay a monthly subscription. *Let alone* anywhere near $55/month. **Let alone** pay to develop this so I can have the privilege of paying more later. If the course was free, ad-supported, or otherwise opt-in payment wise (see *The Hard Way* series), I would consider this a reasonable kickstarter, but as it stands it seems somewhat ridiculous.
looks quite cool. They left the yeoman favicon up there...
We could call it isclose like numpy. Numpy already has an abs method, so this would be nothing new. I see no reason to call it is_close_to vs. is_close. isn't the to implied? Still, it should be in math.
I generally agree with you, but this PEP needs some serious TLC. It gets complex number comparison wrong. It's definition of tol as relative tolerance is also confusing (call it rel_tol or rtol or reltol). The issue of atol defaulting to 0 and is_close_to vs. is_close or isclose also seems weird, but I can live with that. Those other issues are deal breakers for me. I want the PEP to pass, but fix it.
Halfway done in 4 days. Looks pretty good and fun.
I found [autobahn](http://autobahn.ws/) easy to get started with.
Great to hear, good work :D
Yes I'm aware of how to use Numpy correctly so that it is fast. The problem is that it is not always practical to provide the data in an ideal way to Numpy. Let say you have 1 billion 3d vectors of which you need to perform calculations on 100s of subsets of 1 million of them and these subsets are not just simple slices of the 1 billion set but are a sparsely selected million of them. Setting up filters or masked arrays are not that practical and nor is creating a new 1 million by 3 array for each set of calculations. This is something I often have to do and much better handled using PyPy then Numpy. In another project you may have a code base that is highly object oriented which creates an impedance mismatch with Numpy. Let say greater than 99.5% of the code base does not need to do extensive calculations and benefits greatly from the object oriented code. The remainder of the code requires extensive calculations. You tend to have 2 choices. You could extract the data you need from your objects and stuff it into Numpy arrays and perform the calculations or you can recognize it will be expensive to do the data conversion and you may be able to just perform the calculations carefully in Python as long as you understand and can avoid code that would perform poorly under CPython. Which choice makes more sense will depend on the details of a given situation. At the end of the day if you are dealing with performance issues you need to understand when is CPython/Numpy/Cython/PyPy/etc fast or slow and what is the cost of conversion from one to another. There is never a one size fits all approach but people generally get familiar with one approach and then claim it always the fastest approach. Maybe one day PyPy will finally have great support for Numpy and Scipy and then we can have the best of both worlds and not have to worry about the slow areas of CPython which causes us to have to make compromises in our designs when we are faced with projects that don't neatly fit in one camp or the other.
They've integrated a voting system, which is the number surrounded by parentheses after the name of the package in the picture. It really helps when there are multiple libs that do the same thing, to filter out which packages work better. If you implemented something like that, hell I'd switch to yours from pip!
To the best of my knowledge, you cannot do this with cPython 2.7 or 3.4. If possible, you could pass the module path and function &amp; use importlib to import the library and get the function you need. A question for you is what sort of design are you working with that has resulted in requiring the serialization of a function pointer? It kind of feels like you've coded yourself into a corner.
Awesome, thanks! 
Thanks for sharing. For anyone wondering how this works and where it is documented: https://developers.google.com/gmail/imap_extensions
Yeah, been using 2.7 and picked up that bad habit early. I don't do it anymore but haven't updated things. 
Link? I'd love to see the talk. I think the "generator expressions don't need to be in parens if they're the sole argument to something" is an interesting design decision. It's one of only a few instances of syntactic "magic" (like `super` without arguments) in Python.
how does wx vs qt development compares these days in python? 
`Compatibility: &lt;loads of outdated pythons, nothing since 2.7&gt;`
As far as I know 3.4 refined some of the processes of formatting it to make it easily user editable. It's not much different but remember to parenthesize your calls to print.
You can rename columns using a function too. Try: df.rename(columns = lambda x : x.lower()) 
I don't think there is a way to build VSTs from Python as it has to be somehow compiled. But I'd be glad to hear otherwise. If you don't need the VST support and just wanna do audio processing in Python try [pyo](http://ajaxsoundstudio.com/software/pyo/). Also has midi support. Looked into pyVST, like every [other](https://github.com/guibarrette/PyoPlug) it seems to start up the Python interpreter, call it via the VST's C++ API and then run the script. Might be feasible for testing purposes, but I don't think it will work anywhere near real-time. If you need to build VST but don't wanna bring up C++. You could try [Faust](http://faust.grame.fr/index.php/documentation/what-faust). Never done it before but it seems like an easy enough way to build a VST in a afternoon. **edit:** typos **edit2:** additional info
Hey, I sent you some pull requests. Without being in person, it'd be hard to give you a good code review. I didn't fix everything I saw, just made some commits that really stood out as necessary. Very clever code, btw. I would encourage you to think about the suggestions that I made in my PRs, and if you have any questions, feel free to comment on them!
No Python 3 support? Really? Edit: oh wait, no activity for almost 2 years.. 
I'm open for suggestions on the filename. I 'm guessing the period in the name is the offensive bit and I agree.
You had me until the 1-based reindexing...
could you link the mentioned talk?
Thanks, really didn't know about that one!
I reccomend flask for this. Very easy to set up. Basically you have to send a post request to your flask view, which returns a response. The post data is encoded in a data payload, which can be JSON, XML, plain Post Data, or a number of other things. There is a great tutorial on the flask website about this: http://flask.pocoo.org/ Just follow that and try to keep it simple on the server side :). Also, for database stuff its reccomended to use SQLAlchemy http://www.sqlalchemy.org/. There is an extension for flask called flask-ext-sqlalchemy that simplifies it a bit. SQL alchemy is an Object Relational Mapper (ORM) which handles all your database connections and provides a clean API for setting up database tables. With ORMs (Django has its own) the idea for the user is that you set up classes which correspond to tables, and variables which correspond to your database rows. Hope that helps. 
~~In `[7]` I like this better:~~ row['name'], row['position'], row['team'] = process_player_col(row['player']) Edit: I was wrong, see links below.
The line "... and most Python programs (including Ansible) are not switching over yet." seems grossly incorrect. Python 3 support is getting fairly good and this sentence seems very misleading.
As an R -&gt; Python convert, give it some time and you will fall in love with python. The language syntax is much nicer, the libraries are amazing, and once you get used to and understand matplotlib, you can make amazing and beautiful plots.
Well, I have seen many more Python 2 programs than Python 3 ones. I would say the same thing..
That's because Python 2 has been around for 15 years, Python 3 for 7. Statements like Ansibles don't help the transition. It'd be better worded like "because of the complexity of Ansible we're not yet compatible with Python 3. If you're using Python 3 we'd love contributions to make Ansible compatible." (obviously I'm not great with words, but something similar). http://py3readiness.org/
Nice work! I like the web interface. 
I've been working on a PyQt app for a couple months now and have to agree, its a really delightful framework and QtDesigner is the bees knees for UI layout. The few times its let me down its just been a matter of subclassing one of the Qt objects to expands its capabilities while still allowing my QtDesigner workflow to stay intact. I haven't released this app yet so I'm still interested to see what problems or surprises await me in turning it into a standalone exe and testing on other platforms. When I first began messing around with PyQt it was to turn a CLI app I'd written at work into a simple UI. And this was my first foray into desktop app UI development. I believe at that time I had QtCreator (so maybe PySide) instead of QtDesigner (which I find a little more troublesome to use). Anyways, the point is I was slowly stumbling through the process of bringing up the UI and understanding slots and signals and the like. This experimentation only lasted a few days before I was pulled back into more job-critical day-to-day work so the code ended up collecting dust for a year. Fast forward to a few months ago, I had a hobby project at home that needed a UI so I jumped back into PyQt and have become much more fluent in it. I'd say that fluency happened in the first week of reacquainting with it. And now, as I finally hit that "oh crap my hobby project is starting to bore me" milestone, I decided to resurrect the simple UI I had begun at work. Jumping back into that project I could see just how much faster I could mock up a UI, get buttons working, make UI tweaks, build resources etc. Over the course of one day I nearly completed that whole app (and would have if I didn't begin adding new features ideas thanks to the how easy it all was.) I've never used WxWidgets and can't say anything against it, I just chose Qt as the first one to learn, but I so far have very few reasons to want to leave it. Overall it seems to help my development process along more than hinder it.
Who cares what version of Python is or isn't installed by default? It's easy to build. I don't know why anyone would let the OS decide what version their application would use. 
Thanks for posting. I'm just getting started on pandas, and I'm struggling to translate my sql abilities to it.
https://github.com/VikParuchuri/bostonpython2015/ I'm not sure if it was recorded, but these look like the slides.
Maybe you'll like [this]( http://www.gregreda.com/2013/01/23/translating-sql-to-pandas-part1/).
This is the first I have seen on glade. I have only attempted a few wx TestTheWaters apps but never got anything working quickly. Most of my programs are scripts or daemons so no UI.
&gt; df[~df['assists'].notnull()] Id use df[df.assists.isnull()]
&gt; Statements like Ansibles don't help the transition. Which is no reason to deny reality, however. Just send them an e-mail with a suggestion if you're too bothered by something like that.
Well it doesn't explain that precise decision but it's a great watch! https://www.youtube.com/watch?v=OSGv2VnC0go 
So just share the requirements file across the computers? 
Indeed. Plenty of geeking out this snowy day.
This might be even more concise albeit less readable since you are used to see "BLA".lower() and not str.lower("BLA") df.rename(columns = str.lower)
3
&gt; row['name'], row['position'], row['team'] = process_player_col(row['player']) Unfortunately this doesn't work. I guess it is because `row` is a local variable in the for-loop? 
There are many issues with this source code, notably : - Functions should never use variables that are defined outside. While this is valid to do so, it is not a good practice. If I individually read one of your functions (outside the context), I can't understand where "calls" or "customers" are. The data needed by your functions should be received as a parameter. - "calls" and "customers" files are used as global variables, and are never closed. - The "calls" file is read once in number_calls, and therefore cannot be read again. This is why your time() function doesn't work: you try to read a file that already has been read. You should open both files in your main() function, then read the lines (readlines()) and close the files. Then, add parameters to your functions and call them with the needed data. A trick: you can automatically open and close a file using a with statement : with open('customers.txt','r') as f: customers = f.readlines() 
Yes, like @jinqsi said it's just an example. Sometimes it can be useful, sometimes not. E.g., if you want to select the "top scorer" via `df.iloc` (in contrast to `df.ix`) there would be no difference. 
Thanks! And same is true for me. And I feel like there are still so many hidden pandas "tricks" that I don't know about which could make my life easier :)
And do what instead? More advanced things?
I've definitely done something like this before. What's happening, are you getting an error or just no changes seem to "stick" after? ~~It doesn't matter that `row` is a local variable, its not a copy of the row but a view into it, so by editing it you should be changing the actual dataframe. At least that's my memory of it, if it's not working I'm not sure why.~~ OK, apparently I was wrong, it only *sometimes* gives views: http://stackoverflow.com/questions/25478528/updating-value-in-iterrow-for-pandas#comment39768383_25478896 Also found this, which may give you some ideas for doing it without an explicit for loop: http://stackoverflow.com/questions/24870953/does-iterrows-have-performance-issues/24871316#24871316
It seems that writing about those things became the most popular way to learn Python nowadays. I mean, why not, if it helps to learn certain topics more in-depth while writing about those ... and there might be users who prefer one writing style over the other and might find those resources helpful. Generally, I also feel like I am getting annoyed by all the Python intro stuff that is shared nowadays -- not because it's not good stuff, but at some point it becomes really redundant and I see it as noise when I want to catch up on new Python topics or advanced Python stuff.
Could you provide me with a couple of the rows of your text files? I would help a lot to understand the format of the data. :-)
&gt; about those ... and there might be users who prefer one writing style over the other and might find those resources helpful In favour of what exactly? This subreddit isn't called 'Advanced Python' and I don't see why it should become that. I would suspect the majority of subscribers are only on an intermediate level and quite value tutorials like these. Its not like there is a dirth of advanced python topics here anyway. 
One last hint : properly naming variables will help a lot. You can for example create local variables whose name explain what data we are dealing with : duration_per_number = {} call_number, call_duration = row[1], int(row[3]) Then the code is more readable : duration_per_number[call_number] = call_duration Good luck!
I will second this conclusion. 
The solution to that is to start r/advancedpython or r/pythonista. Otherwise the demographics of any sub favors the beginner. 
The beginner road is so well trodden especially in this area. Sure, decorators can be confusing at first, but decorators in particular have been introduced, demystified, explained, primerred (?), all-abouted, covered from the ground up, anesthetized (made painless?), ELI5ed... if there is a nuance in this blog post, it is lost because it doesn't focus on that. If not, then this is just degrading the time I spent on SEO for my snake decoration service [http://pythondecorators.com](http://i01.i.aliimg.com/wsphoto/v0/809782507_1/Free-Shipping-New-Arrival-170cm-Snake-font-b-Python-b-font-Plush-Toys-Creative-Special-Children.jpg)
Thanks for the follow-up! Right now, I couldn't think of a better way, but maybe this SO article helps me to brainstorm a little bit ...
&gt; This subreddit isn't called 'Advanced Python' Agree, but there is also the learnpython subreddit. Like I said: It's not that those tutorials are no good, but it's just the same stuff over and over again. 
Thank you for these. They are great. 
Yes, and then use those requirements to maintain up to date your installations :-)
&gt; * Apps that get opened/closed really often -&gt; Might consider switching to a different framework/language. Perhaps the native Java app thing. Not Java! JVM is more efficient than any Python implementation, but the lot of slowness flak that Java used to get (and to some extent, still does) is almost 100% because of the slow startup of desktop apps written in it. JITed Java bytecode is a beast, but it requires long runway before it gains momentum.
I'm the maker. I agree on the basic part -- making more advanced stuff now. I'd love to hear more elaboration on the "poorly taught" part if you have some time.
Another downside of Python is its minuscule performance. Sure it doesn't matter much for simple batch processing, but once you try to do anything more than that, you've got to microoptimize your code really, really soon. 
I like this post and agree with the main point: Writing safe &amp; efficient code in dynamic languages is not so trivial. However, therefore you have other problems like memory leaks etc. in C / C++. Since basic coding in Python is super simple, learning how to write safe &amp; efficient code is just something that has to be additionally learned (as follow-up to Python intro tutorials). In contrast, this skill is likely be learned by a C / C++ programmer on the fly as consequence of the language design. But that doesn't mean Python is more difficult than C++ or the other way around: **One just has to invest about the same time to learn Python thoroughly that he or she would invest for learning C++.** Like I said, I like this short comment, but the "typo example" is not a good one... It will raise a syntax error upon execution, so what's the problem? Also, things like that wouldn't happen if one uses tab-complete... 
By the time my C++/Java program is done compiling, I've already executed my python program, found the error where the line was, fixed it, and run it again. Am I missing why people bring up static types up so often? I've never had a big issue with types or wasted more than a few seconds dealing with them.
Dynamic types can really bite you. What if your program runs for 10 minutes before it hits code with a type issue? That happened to me a few times on a crypto assignment in school. It is my fault, but programming languages are tools, and tools are supposed to help us.
C++ is faster than Python partially because the static typing allows the compiler to make aggressive optimizations. Another part is because C++ doesn't do checks that aren't specifically requested. For instance, in C++ you can read past the end of an array because it doesn't check every array access for validity. In Python you can't because you'll get an exception. All of Python's checks come at a price. No matter how great you are at optimizing Python code, it will never be as fast as is possible with C/C++.
i dont understand, can you explain please
yes i do but how do you apply it to this situation 
You dont want an arbitrary number of named variables. It could be done, but trust me. You want a list or dictionary. List: students[0] Dictionary: student_dict['student1'] Get them like this def get_students(n): students =[] for i in xrange(n): student = dosomething(i) students.append(student) Or stud_dict = {} for i in range(n): stud_dict['student%s'%i] = dosomething(i) Get the student 'names' from the dict with stud_dict.keys(), or name, value pairs with stud_dict.items()
Awesome. What is your bigger project about?
&gt;I once heard a C++ programmer say "oh no, Python, that’s so hard, I could never write that. I’m so used to having a compiler!" [*skepticism*]
&gt; And maybe this is part of why Haskell programmers get so attached to Haskell – because they’ve invested so much in learning the type system, and those skills don’t transfer well to other languages like Python. I find this interesting as someone who chooses Haskell at home but uses Python professionally. The skills I've picked up with Haskell influence how I write Python code, and I like to apply lessons learned in Python to how I write Haskell. Just because they're nearly at opposite ends of the spectrum doesn't mean that they don't have commonalities. Python has a lot of functional tools available, the core built-in data types are surprisingly similar to those in Haskell; tuples, lists, sets, lazy evaluation (iterators/generators in Python), and comprehensions.
This comes down to a "right tool for the job" mentality. Python excels at some things easily. It can be made to excel at most things with more effort. Which can be extrapolated to: &lt;insert-language&gt; excels at &lt;insert-list-of-things&gt; easily. It can be made to excel at &lt;insert-list-of-things&gt;. It is abysmal at &lt;insert-list-of-things&gt;
Where were your tests?
The post should've mentioned other, more secure ways of storing passwords. Bcrypt is shown in the available hashers, but isn't being talked about. Imo Django should also use a better encryption as default like it offers bcrypt.
Yep, where are his unit tests?
Sometimes you're just hacking something together! The code I was writing was just looping through a large encrypted file and collecting statistics on the bytes. Testing would have helped for sure, but a type system would have also been nice :)
&gt;Am I right in thinking a language with a more OOP design would be better for this task of automatically generating charts/visualizations? Wondering if I might not be better off in the long run for learning a more generalized language. If you don't need R's vast statistical packages, then you'll be ok with Python. Otherwise, you can execute R from within Python. Yhat's port of ggplot2 is still not ready for production. For really neat interactive visualizations, not sure if you looked at R's Shiny, but there is a Python version of it called [Spyre]( https://github.com/adamhajari/spyre/blob/master/README.md), currently works only with Python 2.x. Otherwise, there's IPython notebook and IPython notebook widgets which may work for you.
Quick and dirty JSON importer into postgres. Rip it to shreds, guys. Preferably on the link.
Static type systems find type-related errors without writing any testcases.
I've built a several megabytes project in Python in my last job (7 years at it). I HAD to microoptimize exactly ONCE (the rest of the times I was just being silly). Granted, most operations were I/O bound (as plenty of things are). Performance was never an issue. The one time I had to optimize was dealing with huge files, and I would have made the same optimizations in C/C++ if I where using that.
You might get to V8 speeds if you hire Lars Bak or something.
I think tests are a waste of time. But I only work on small projects so it just depends on what you're doing.
Dynamic typing can add a lot of flexibility to your program. In Java I often have to write a dedicated object to set up a flexible return value from a method when in Python I could easily return something of differing types and then set up a simple conditional and test case.
last one id rather use ` df.reset_index(drop=True, inplace=True) ` youcan also use `inplace` with fillna or sort (instead of reasigning to df)
You cannot mix tabs and spaces You cannot mix tabs and spaces You cannot mix tabs and spaces You cannot mix tabs and spaces You cannot mix tabs and spaces You cannot mix tabs and spaces You cannot mix tabs and spaces You cannot mix tabs and spaces You cannot mix tabs and spaces You cannot mix tabs and spaces You cannot mix tabs and spaces You cannot mix tabs and spaces You cannot mix tabs and spaces You cannot mix tabs and spaces You cannot mix tabs and spaces You cannot mix tabs and spaces You cannot mix tabs and spaces 
&gt; inplace with fillna or sort Yes, that's probably nicer! But about the other suggestion: &gt; df.reset_index(drop=True, inplace=True) Wouldn't that get rid of the column values that we assigned to the index (here: the player names)?
Nice cheat sheet btw. Thanks for sharing, too!
As someone who writes both python and c++ at work I'd say that unit/integration tests (and a fair share of tdd) would solve most problems. there's a myriad of ways in which you can make silly mistakes. heck, even with super IDEs you can end up refactoring wrongly and screwing up unwillingly a a framework header. 
hmm not sure if i read the whole article, or if you updated it recently. I was referring to the line that starts with the comment: ` df.index = range(1,len(df.index)+1) ` In that one you are not indexing by the name, but changing back the index to a numerical sort . But once again, maybe its a misunderstanding because i didnt see the section named "Updating Columns" (which btw, doesnt have the player name as an index neither) 
Overly simplistic. Yes, Python is slower then C++, but its more then fast enough for huge domains of applications that are more advanced then 'simple batch processing'. Not to mention, there are other implementations then CPython. PyPy is particularly promising.
The point is not that Python is ever faster than C/C++. The point is that you spend less than 1/10 the time writing the Python implementation as you would writing the C/C++ implementation, with far fewer lines of code, less future maintenance, greater portability, and fewer dangers (stack overflows, etc.). "Hey, I've noticed that Python is slower than Java. Hey, I've noticed that Java is slower than Go. Hey, I noticed that C++ is faster than Go. Hey, I noticed that C is faster than C++. Hey, I noticed that x86 assembly is faster than C... Assembly must be the ultimate programming language!" :-P
Well, I take it you haven't used it on a lower end machine, then. 
He's not talking about speed. If you're dealing with a task that's I/O bound instead of CPU bound then C++ performance is unimportant.
Would be a much more interesting article if you provided some discussion on _why_ you would do this. And other possible use cases. As it stands this is basically just an undocumented code dump and you should have just put it on gist.github.com.
Also IMO it's wicked bad form to assume people are going to try and figure out command line arguments to a program by digging through the completely undocumented source for references sys.argv[] ;) Learn to use the argparse module, it's always the first thing I write for any script/program. It self-documents the program inputs and writing the "description" field helps me clarify my idea of what exactly the functionality will be, before I even start coding. And will make your users' life much easier (that includes yourself, when you have to try to remember what the heck your script does 3 months later).
I mostly program in C++ (I'd have to say modern C++ i.e. C++11 is my favorite language, actually) and have done a little Python from time to time and I've never had an issue picking it up, they're just different tools for different types of requirements. The reason I don't use Python more isn't because it's more difficult for me to write safe code (anyone who can read, know how to debug, and test things properly can easily write safe code), it's for multiple reasons- it's slower, lacks explicit type information (and so *relies* on documentation to get things right when working with an external library) requires the runtime to be present and using the same version you wrote, and in general is slower to reason about when projects get large (multi-file, several hundred lines each type projects). It's great for writing "glue" code that manages a few separate processes, scripting for actual scripting purposes (e.g. AI for a game), in general shorter projects or parts of a project that need to be more flexible.
&gt; It will raise a syntax error upon execution, so what's the problem? This is the problem. You have to execute the code to be *sure* that it is correct on most basic level. If you don't execute it nor lint it, you have practically a Schrödinger's code - it may work or it may crash miserably. Catching of trivial errors ASAP (on compilation stage) is invaluable. Regarding the bit about "tab-completion": It is like an artificial leg. You can move when you have it but what happens if you lose it?
&gt; This is the problem. You have to execute the code to be sure that it is correct on most basic level. That's where doctests or unit tests come in handy -- a good habit anyway.
Meh, if python had a compiler it could be fast. 
Why would you want to Why would you want to Why would you want to Why would you want to Why would you want to Why would you want to Why would you want to Why would you want to 
Yes, but, given this was meant for a one-time, bulk-import, I didn't use [argparse](https://docs.python.org/2/library/argparse.html). Still, your criticism is a valid one.
Well, as someone who works primarily in both C++ and Python, I can see why working primarily with an interpreter rather than a compiler can be confusing. It's difficult to test certain aspects of code in Python that would otherwise already have been caught in a compiled language, which is the author's point.
pastbin, gist, whatever. my point was that without any context you might as well have just linked directly to the &lt;insert code-dump hosting site here&gt;. as I said, with context maybe it would be interesting. for now it just looks like blogspam for a script you had to write at work today.
And what's so wrong with using a lint-like tool? I have [flake8](https://pypi.python.org/pypi/flake8) installed in my Vim editor and it says: ``` elephant.py|2 col 1| F821 undefined name 'elephnt' ``` Checkers like this are easily integrated into editor save hooks and unit tests. They catch a lot of things that compilers also catch, especially the use of undefined variables, and variables that are set but never used.
Yes it would. Perl was inspired by LISP, Python by C. Even Larry Wall will tell you that he borrowed the object model for Perl 5 from Python and then changed his mind later. They are only similar in that they are modern programming languages. They are based on very different ideologies.
Thanks for the advice. I have only learned the very basics of Java/C/Python, though I am very familiar with SQL/SAS. I knew that when I started diving into advanced R stuff it seemed "different" than the other CS fundamentals I had learned with java back in school. You are right that R can be oo, but it feels much less natural to code that way than in python. 
What specifically can't you easily test in Python that would be caught by a c++ compiler? If you're doing TDD it shouldn't make any difference, should it?
I don't get it either. In all my years of using statically typed languages, I'm not sure I've ever tried to pass "spaghetti" into the square root function instead of a number. I've got epic tales of bugs (including one that saved a company) but absolutely nothing that revolves around types. It's logic bugs that will have you lying awake at night staring at the ceiling trying to figure out what's wrong.
If you could have any one food for the rest of your life, what would it be and why is it spaghetti?
Yum!
i didnt like this article at all. python is like using a shovel. c++ is like designing the shovel, using it, redefining it, and inventing a new one, thats even better. plus you own the creation
&gt;you've got to microoptimize your code really, really soon. Which you can do with time left over thanks to all the time you saved writing it. And that's not taking into account the contingent of developers who prematurely optimize everything anyway, even with compiled languages. 
Agree with the above. Also look into Seaborn (builds on matplotlib) for plotting as an alternative to bokeh
I am not saying that compilation is supposed to replace later stages of testing (execution being the first of them). It just catches *trivial* errors earlier and more effectively. Many people consider catching bugs ASAP, a very important thing. On the other hand, only in an ideal world you *always* have the full release cycle to apply and correctly verify a change. Sometimes (and this situation should be as rare and exceptional as possible) you have to jump into cowboy's boots and fix a critical crash on a living organism - because everything is better than system not working at all. It is very unpleasant experience when you fix/work around a sophisticated crash and instantly introduce another, trivial one, which you should catch during basic verification. Of course, lints and *excessive* regression tests may sometimes be enough to catch it.
&gt; python is like using a shovel. &gt; c++ is like designing the shovel, using it, redefining it, and inventing a new one, thats even better. &gt; plus u own ur own creation What are you trying to say here? That reinventing the wheel is a positive outcome?
&gt;So, not only is it not undeniable, it's quite easily deniable. This and other empirical evidence supports the superiority of dynamic typing. Why does every programming argument devolve into this Superman vs. Batman level of nuance?
&gt; By the time my C++/Java program is done compiling, I've already executed my python program, found the error where the line was, fixed it, and run it again. And found another error, two lines later :) And another one. And another one. The guy compiling his Java code catches them all at once and can concentrate on logical correctness of the program from the moment it executes (less of context switching for him).
[Politics](http://lesswrong.com/lw/gw/politics_is_the_mindkiller/). &gt; Arguments are soldiers. Once you know which side you're on, you must support all arguments of that side, and attack all arguments that appear to favor the enemy side; otherwise it's like stabbing your soldiers in the back—providing aid and comfort to the enemy. Unfortunately, the more trivial the question, the *worse* this behaviour seems to get. If there is any pointless distinction to be made, **people will make it**.
Hey, how about one of you joins the conversation instead of the lazy downvotes?
 \(input variable) -&gt; (return value) That is Haskell's lambda syntax. It can also be multiline. I'm guessing this is what GP was talking about. EDIT: Thanks autocomplete...
It was a rhetorical question, really. It's just obnoxious how this is such a marginal problem in every other area of STEM discussion, but a constant and derailing problem in programming talk. It's like programmers and only programmers get some specific mutation for low-empathy, high-ego, pseudo-technical yapping over the most trivial bullshit. Hell, couple of hours ago in /r/programming [this nonsense happened.](http://www.reddit.com/r/programming/comments/2tibrh/zstd_a_new_compression_algorithm/cnzok6r?context=3) Just a daily stream of sophistical garbage to try to filter out or let your eyes glaze over. Maybe it's an epigenetic effect... all the years of cave-dwelling or something. Either way, it's a running reminder that most programmers base their professional views primarily on unscientific/dogmatic buffoonery. And that I can't stand easily 95% of them despite getting along well with most other technical specialists.
Python has all the tools to remplace R with ipython, matplotlib and scypi. Check this out : http://nbviewer.ipython.org/github/ipython/ipython/blob/2.x/examples/Notebook/Plotting%20with%20Matplotlib.ipynb
Thanks so much!
I think a thing that my team has to deal with is fluorescent noise (blot removal?). How computationally complex is it to deal with things like that? And perhaps if you have some experience with that sort of thing, how is the development process for creating a reliable system that can eliminate the noise?
I completely understand the IDE thinking of Delphi devs. Even though I write a lot in a text editor, by necessity; I do miss using an IDE. Even after several years of working in a text editor, I find myself missing tools I had in the IDEs I used. Delphi will spoil you. I wish Mac had decent programming tools.
When it comes to C++, the type system isn't really that strict. There are still plenty of things you can fuck up. The comparison with haskell is interesting, but I don't really buy it. If you can write something with static types, you can write the same thing without them, you might just end up with a few extra bugs the type system would have caught. I would argue that using a programming language with a strong type system regularly actually means you are better at not making type errors, even when there is no type checker, because you have trained yourself to think about types all the time. 
I think there is no reason *not* to use Python. I'm no expert on R (have been using it for a few weeks a couple of years ago), but from what I hear Python can do everything R can. Also, `rpy2` is able to fill the gap if necessary. I found that OOP programming for data analyisis is a huge advantage. As a student I've been taught Matlab and have used it for about six years. After learning Python and switching to `numpy`, `scipy`, `matplotlib` and `pandas` my productivity went up by at least 200%. Right now I'm revising some Python code I wrote about a year ago and I'm amazed about how well structured my code is compared to something I would write two years ago in Matlab, even though my skills in Python have improved manifold of the last year. TL;DR; Python should be able to do everything you want and OOP is king.
Real life is large and diverse. I guess in simple web development typing is largely irrelevant. If it works, good. If it doesn't ... lemme fixit realquik, thxbai. In military software, you can't playing with rockets alone, please always invite Hindely and Milner too.
Wasn't my intention to complain about the topic of debate itself -- just the arbitrary pressure to end it, like so many programming debates, with black and white conclusions. Scientists say what you just did all the time. Sure, their debates get very heated at times, but they rarely end in this neener-neener level of splitting that constantly ruins programming debates and leaves anyone not already radicalized in one direction or the other unable or uninterested in participating.
From a thousand yards away, maybe. I'm not knocking on Ruby. I love Ruby. Not as much as I love Python. But let's not be stupid and compare them as equals just because they're both dynamic languages that can do things.
I think you misunderstood the structure of the argument. jsantos17 has not compared Ruby and Python. The argument was "Ruby after Haskell or Python after Haskell", with broader context being "statically typed language after a dynamically typed language". Edit: jsantos17, not bluecamel17 :)
TDD helps, to an extent. It helps to run and keep running all the code in your project that is testable, and will catch lots of errors that a C++ compiler would catch. But where it might fail you is the 'glue' code that isn't always test-driven. You need acceptance tests for that. The primary issue is that in Python you have to run ALL of your code to really trust its reliability. I love Python, don't get me wrong, but you really need all the help you can get in this area (TDD, acceptance testing, pylint, etc.). I've written tons of Python programs that run for weeks at a time, and it's insanely frustrating to get 50+ hours in and have to start over because of a typo in an exception handling routine. That just doesn't happen in C++; you get different classes of errors to ruin your day.
Static checkers integrated into your IDE are incredibly helpful. I can't go back to the days of editing code in raw emacs/notepad++; PyCharm's integrated static checker is great.
The good thing with WAMP is that there si no server, only one router that you don't need to code with. You only codes clients. But clients don't need to know about each others, nor where they are, not even which language they are coded in. So you can create basically any kind of architecture your want. One node to one node, one node to several nodes, several nodes to several nodes. If you want to keep it simple, you can just start with the classic mindset of clients with one servers (which will be a node). It will be just like having crossbar instead of nginx, and your client instead of django/whatever.
I agree with cuducos but I free is not a requirement then Introduction to Python by Jessica McKellar for O'Reilly is a video based course that will allow you to pick up most of the basics in a few days. It well done.
Python does have a compiler. As I mentioned above, it performs a lot of extra checks and bookkeeping. I am admittedly not an expert on Python's execution and memory structure but I can guarantee you that the language has inherent inefficiencies that simultaneously promote ease of use and computation overhead. This is why it is outperformed by C++ regardless of whether you interpret or compile.
Python was inspired by LISP as well (that's where functional elements such as `reduce` and `map` came from). Every modern language is inspired by a lot of prior art. Anyway, Python and Ruby (the languages proper) seem very similar in most ways. If you can think of a language that is different from one (e.g. Python is very different from C or Haskell) you'll see the other one is also different from it. Small distinctions in features are a matter of taste. Distinctions in philosophy even more so.
&gt; Regarding the bit about "tab-completion": It is like an artificial leg. You can move when you have it but what happens if you lose it? Why would that ever happen?
chapter 3 (from page 35) of my thesis has a lot of images: http://arxiv.org/pdf/1405.5968v1.pdf
not using executemany? not separating by table? 
http://imgur.com/uuS3YPM This is pyqt, not tkinter. If you're not already committed to the tkinter framework, I'd really recommend taking a look at qt. It is a very well-designed framework, and has truly excellent documentation.
It's interactive programming, like lisp/emacs with slime.
A simple quiz program for a local cinema club: http://imgur.com/xiTElwF
I use emacs which has [flycheck](http://flycheck.readthedocs.org/) that uses [flake8](https://flake8.readthedocs.org) for Python code. A [boatload](http://flycheck.readthedocs.org/en/0.22/guide/languages.html) of languages are supported.
So it's for sloppy programmers? How many errors do you write?
but... dynamic typing is superior. dontchu kno that? \#confused
I've tried to build it in a language-agnostic way, but I've only rolled out English, for now.
Inspiring a couple of features is very different, but I give up. Ruby == Python.
I am using flask but was giving a shot to try something new that will be better to use!! 
At [Real Python](https://realpython.com) we teach the Python syntax/fundamentals as well as web development by example. In other words, we focus on learning by doing. I highly recommend coupling Real Python with [Codeacademy](http://www.codecademy.com/en/tracks/python) and/or [LPTW](http://learnpythonthehardway.org/book/) since Real Python focuses more on the practical while the latter two focus more on the logic/syntax. You can download a sample of Real Python [here](https://app.simplegoods.co/i/MGJJDYYI). Hope that helps! Note: I am the co-founder/author of Real Python.
this thread explains a bit lot how to use the web frameworks..again thanks for sharing this thread
Yes. Whether that's 'fair' or not is a different question. I can say that at big companies, the HR departments have software that lets them input a bunch of data about someone and it outputs 'market value' salary range for that person, and that's how they decide what to offer. Having a PhD is a few tens of thousands of dollars per year above masters, and masters is a few tens of thousands of dollars above bachelors degree.
For the love of glob, read sidebars.
Go honnibal! Loved your blog posts on NLP. Good to see you're still around.
I feel like you're using a different Sublime Text than I am.
What happened to the QtDesigner? It seems to have dropped Python supprt.
Expected nonlinear programming...This isn't my field but very cool. 
do you have some exception?
I think that's only like a intro to Python. But, yeah, it's rather basic. 
 for subreddit in subreddit You really shouldn't use the same variable name for iterator and sequence. 
Alright thanks I'll change that. Im having trouble trying to figure out how to sort the comments. I want to make it so that it only donates to comments higher in the thread. any ideas?
I completely agree. I think C++ is a harder language, *overall*. But I also do agree with the author's point that Python has a "hard" aspect to it which is not experienced in C++. I guess the author would have done better to say "given people with experience in both languages, this is what a C++ programmer would find harder to achieve in Python"--which wouldn't be an interesting article, since basically it's been rehashed hundreds of times in various articles and arguments. So, I guess the article isn't actually that interesting.
Well, first, that Robert Martins post wasn't what you chalked it up to be. Second, rudimentary, solitary assignments that generally favour dynamic typing are hardly empirical evidence for one being better than the other.
I'll do that as soon as I can, thank you so much for the tips and the help
Thanks! TBH, the shell is taken straight from [this stackoverflow answer](http://stackoverflow.com/a/20610786)
&gt; This means all the work on twisted and tornado is lost, and it's a LOT of work. We need compatibility layers for those, stat. Tornado does have [integration with asyncio](http://www.tornadoweb.org/en/stable/asyncio.html#module-tornado.platform.asyncio), though I haven't tried it, so I can't say how well it works. Other than that, I think you have a good summary.
I use plain pyqt. Much of the interface is built dynamically, and I find QtDesigner and similar tools to be more of a burden then an aid in this case.
I can't share the full repo, since it is private, but I can share the [gui module itself](https://gist.github.com/PhilReinhold/05b475549e4c37e2f95a). It may not make a lot of sense without context, but it captures how I approach writing pyqt. 
Yeah, I was mostly using R because I have done a bit of statistical programming in it before. I am using only GLM and RF methods for some basic classification, i'm sure they are implemented just as well in python. 
Whats up with wrapping the main(), if it crashes wont it produce the exit code and the stack trace anyway? https://github.com/haradreborn/Crawler_links/blob/master/main.py#L53 Why call sys.exit(1) inline instead of raising an exception? This doesn't look like an error actually: https://github.com/haradreborn/Crawler_links/blob/master/main.py#L53 Why catch only KeyboardInterrupt? Commonly except KeyboardInterrupt is used to raise the error when you're doing a bare `except:` afterwards with other behavior. def __init__(self, arg): # pass domain name from args to other functions global root root = arg why alter global state like this? This is usually considered bad practice. # init array for page information result_arr = [] Comments like this are an indication that you don't trust the name result_arr. If you don't like it, name it something more descriptive. Remember to cite your sources: https://github.com/haradreborn/Crawler_links/blob/master/bin/manager_csv.py#L19 This isn't a full review, but I think your python style will grow with time. You'll be overwhelmed if you look at a full scraping library like scrapy, but looking at the interfaces it exposes might be a good start.
Here's PRAW's [doc](http://praw.readthedocs.org/en/latest/pages/comment_parsing.html) on parsing comments.
The Bitcoin tip for 1 some bits (405 bits/$0.10) has been collected by *ratulrafsan*. [ChangeTip info](https://www.changetip.com/tip-online/reddit) | [ChangeTip video](https://www.youtube.com/watch?v=_AnfKpypMNw) | /r/Bitcoin
Haha, thanks. :)
Why not just use a list?
Mobile user. Never use pc lol. 
I am a data scientist, and a long-time Python developer and proponent (more than 10 years, executed a few major projects in it, am very fluent in it). I also use R for data analysis (I would consider myself an intermediate user). Since this is a Python subreddit, I expect you'll get a lot of answers in favor of Python. And I would agree with most of them. However, I would suggest this: instead of thinking about which programming language to learn, maybe you should think about which language offers you the right set of Domain Specific Languages (DSL) that fit your problems. You see, in data analysis, it's less about the actual programming language, but more about the domain-specific features that you need. For instance, Pandas is a kind of domain-specific "language" (not really in the traditional sense, but in that it gives you a vocabulary to reason about data). R has a bunch of very compelling domain-specific features that either do not exist or have limited implementations in Python. You mentioned visualization. As of this moment, it is my opinion that the 2D visualization libraries in R are more mature. Seaborn is great, and so is the yhat ggplot port, but R's ggplot2 is more mature. For interactive plots, it's a bit of a toss-up. R has ggvis, and Python has bokeh. I recommend trying them all and see what works for you. But I want to say this: if your job involves analytics, and **you want to be good at it**, you MUST learn both R and Python. It is not an either-or choice. You may not need to be an expert at both, but you need to know both. Their feature sets do intersect, but it's the parts that don't intersect that are the most interesting. If you are only interested in visualization, I'd argue you may do better with a specialized tool like QlikView ($$$$) or Tableau ($$). I tried staying away from R for a long time because the language was idiosyncratic and archaic. However, I came across compelling libraries in R that had no equivalent (of similar polish) in Python -- so I bit the bullet and learned R. I am referring to libraries like ggplot2, dplyr, tidyr, lubridate and caret. The sheer quality of these libraries made my data analysis workflow so much more fluid than in Python. I would suggest that R is actually a better environment for exploratory analysis. There is a shorter path from data to insight due to the specialized vocabulary it gives you for expressing data operations (some of it maps to SQL concepts, so knowing SQL will help you here) -- and by R, I actually don't mean Base R, but dplyr, tidyr and so forth. The notation is more compact than in Python (the %&gt;% pipe operator is amazing), and once you get used to it, you can do stuff quickly with a minimum of scaffolding. Caret for instance lets you try out a myriad of of machine learning models with a minimum of effort (arguably scikit-learn does too; however in my opinion, while scikit-learn tries to provide a consistent API, the interface somehow lacks polish and fluidity. The documentation is a little wanting as well.). R is like a Swiss-Army knife, a shell scripting language for quick and dirty tinkering, and for getting stuff done. R is great for **data science**. On the other hand, I think Python is a better environment for productionizing your pipeline. It has way more robust tools for string processing, ETL, pre-processing, etc. and there is a lot more infrastructure and knowledge out there on scaling Python to production systems. Most industrial analytics vendors have APIs for Python but not R. While you can technically productionize R (it's sort of like productionizing shell scripts), I think that to build a proper data pipeline, you might get better results if you engineer it with a more general purpose language like Python. Python is great for **data engineering**. This is why I feel the two (R and Python) are symbiotic. You can quickly get some insight using R, and then if you need convert your code to production, you can translate it easily to Python (or call it via rpy2). Finally, the key to thriving in R is to understand its Scheme roots. It helps if you know something about functional programming. The Art of R programming (Matloff) does a good job introducing some main ideas, and Advanced R (Wickham) completes the picture by providing a more technical exposition. However, if you're not a technical programming type of person and just want to get the job done, you can get a lot done by just sticking to the few commands found in a cheat sheet, eg. https://github.com/sefakilic/ggplot-cheatsheet http://stackoverflow.com/questions/3446495/ggplot2-cheat-sheet This one in particular is great for data wrangling: http://www.rstudio.com/wp-content/uploads/2015/01/data-wrangling-cheatsheet.pdf I don't think you need to know much (anything?) about environments or non-standard evaluation to plot a graph. 
Also wondering if a dict is what you really want. But if so, one way of doing this could be: mydict['8675309'] = len(mydict)
I got really excited when I saw [Radim's post here](https://news.ycombinator.com/item?id=8943585). Having a good interface between this and Gensim would be awesome.
Not really.
I'm not sure if Qt Designer ever had Python support built in, but you can compile the `.ui` files it saves to Python with `pyuic4` or `pyuic5` (part of PyQt4/PyQt5 respectively). I do this for a couple of applications I maintain.
But flask is well start for the beginers level !!
I screenshotted one of the screenshots and put it on imgur so people can see it easily: http://i.imgur.com/kO7hWLy.png (/u/andjew - I assume you're OK with that. Let me know if not, and I'll take it down)
Springfield Poker - Tkinter based Simpsons themed game: http://i.imgur.com/tvtmWug.jpg
Nice going to,try this
i only quickly skimmed the code, the handler for the ProgrammingError is rather confusing i don't see its purpose - what condition makes that chunk of code necessary
Thank you for your comprehensive answer, it puts things in perspective very well. Almost all of the R tools you mentioned are what I have been learning with. I have been using dplyr, tidyr, ggplot2 and caret and I agree the %&gt;% operator makes manipulating a dataset for visualization quite straight forward. And the whole grammer of graphics setup with ggplot2 makes actually making the plots much easier than i expected. 
Flask/gunicorn/Python 3 are not related to asyncio.
I didn't realise dude. I've never really used reddit on my computer. Sorry if I offended for whatever reason. 
Damn that looks awesome! 
In my experience, the amount of time it takes to find an error in a "dynamic" language is like an O(nlogn) worst-case (n being the number of lines), while in a "static" language it's more like O(n). While it may be faster to find errors in "dynamic" languages when the projects are small, as it gets larger and larger, it becomes increasingly easier to find errors in the "static" language. Also, I doubt you can run a script, notice an error, dig through the section you believe it's in, fix it, *and* run the whole thing again in the time it takes to compile a project *of comparable size* in Java/C++, which would probably be compiling in &lt; 500 ms if I'm understanding the type of Python project you're talking about. You know, a small, sub-thousand line single file project that scripting languages are typically used for.
Document it. You have almost none.
Very cool project, I'd love to see this evolve and develop into a sustainable alternative to the NLP packages out there.
Thank you for your reply! Here my little comment: &gt; MySQL will be released soon: [aiomysql](https://github.com/jettify/aiomysql) &gt; PUB/SUB [aiozmq](https://github.com/aio-libs/aiozmq) already here, and you can do PUB/SUB with redis I think &gt; SQLAlchemy, Peewee, PYDAL as for ORMs, you are right, async and ORMs do not play nice, but this is common problem of all async frameworks. But there is sqlalchemy integration with *aiopg* and *aiomysql*, so you can write queries using sqlalchemy syntax &gt; embeded task queues Could you be more specific? there is [aiokafka](https://github.com/aio-libs/aiokafka) project (yet not released) and rabbitmq [aioamqp](https://github.com/polyconseil/aioamqp) support 
Sorry I'm not following your example. My guess is it sounds like you should check out R Shiny or Python Spyre if you havent already, since the basic underlying principle in each is to encapsulate the plotting in a function and mapping it to a HTML widget. You can do the same with IPython notebook widgets, but the code is still visible. Can't wait for the upcoming Jupyter notebook (formerly IPython Notebook 3.0) due to be released soon. It will provide Python and R kernels (and few other languages).
I live in a third world country, so... all the machines I used are low end :-) An AMD K7 @ 900 MHz with 256 MB of RAM, was my main machine until two years ago.
A list is basically a contiguous (gapless) list of values, where the first item has the key `0`, the next has the key `1`, etc. So: &gt;&gt;&gt; my_list = list() &gt;&gt;&gt; my_list.append("Hello") &gt;&gt;&gt; my_list.append("World") &gt;&gt;&gt; my_list ['Hello', 'World'] &gt;&gt;&gt; my_list[0] 'Hello' &gt;&gt;&gt; my_list[1] 'World' 
You have no idea what you're talking about. 1. `object2` has type `Class*` always and forever. 2. `delete` doesn't make a pointer `nullptr`. Assigning `nullptr` to a pointer makes it `nullptr`. `delete` just means the pointer is now pointing to deallocated memory that might be used by something else. 3. Why the hell would a `nullptr` be a type error? For one, a pointer to something is its own type, an integral type representing its location, alignment, and size (believe it or not). When you have a `nullptr` pointer, that just means it doesn't point to anything (or rather, points to a location that effectively means it points to nothing). 4. Null pointer dereferences are considered logic errors, not type errors, despite your own personal view. Sorry to be the one to tell you, but your beliefs contradict that of most programmers. 5. On the contrary, it's pretty hard to avoid keeping proper type safety. In order to go so far as to treat an `int` as a `float`, you have to explicitly call `reinterpret_cast&lt;float*&gt;(&amp;some_int);` Now I don't know about you, but I don't randomly include that line unless my goal is specifically to treat an `int` as a `float` for some reason. Now if we were talking about C I'd be more inclined to agree with you, but C++ was designed to have better type safety than C to the point that the designers gave up some compatibility in order to do so.
comments in code are good
Did you want the first column to be the key? If so, that is rows2[0], not rows2[1]. Arrays almost always start with item 0.
&gt; You do need tests in Haskell, but at the integration level, not at the unit level. If your goal is to catch typos, integration tests do that pretty much. I actually became much happier as a programmer when I realized that 99% of the hype about unit testing comes from the fact that having _any_ kind of automated tests is awesome, from the people who just discovered that or the TDD that forces them to write tests, _any_ tests. In my experience, trying to write unit tests for everything sucks hard because they make your code inflexible (oh the irony). It's much easier to refactor a bunch of code, changing argument types and return values, and to _make yourself to realize that you should do that_, when there isn't 5x the amount of code in tests that you should throw away and rewrite from scratch. In my opinion tests should test conformance at relatively stable API boundaries, precisely because they are relatively stable. Unit tests are for a function that implements some complicated generic algorithm. Since it's generic, the API would not change or would change in a trivially accommodated fashion. Doctests are smoke tests and are also at the API boundary (you're writing documentation for that function for someone, aren't you?). Any kind of larger scale tests is where it is, you verify that the code does the needful (he he). You can make them as detailed as you want, like, the code should do the right thing with this data and that data, if you can't exercise some part of your code that you're concerned about from that level then it's probably dead code, no? Like, a single actually sane reason for preferring unit tests in particular is that when they fail, they fail much nearer to the actual bug. Oh well, I'm sure that I'll be able to find the bug much faster using a debugger than it would take to write all those tests. Also, yeah, if you're concerned about testing failure modes, C++ leaves you as much in the dark as Python in this regard, I don't know about Haskell. 
&gt;Null pointer dereferences are considered logic errors, not type errors, despite your own personal view. Sorry to be the one to tell you, but your beliefs contradict that of most programmers. Type safety (the ability of the type system to prevent type errors) is defined as "progress + preservation". That is well typed expressions can be evaluated to something, and that something will also be well typed. I am not alone in this view at all. Google "safety is progress plus preservation". Dereferencing a null pointer is well typed, but unsupported by the language i.e. it is not type safe. "Weakly typed" has no hard and fast definition, but I would argue that a language that languages lacking type safety are weakly typed. &gt;object2 has type Class* always and forever. &gt;delete doesn't make a pointer nullptr. Assigning nullptr to a pointer makes it nullptr. delete just means the pointer is now pointing to deallocated memory that might be used by something else. I did not mean to imply that it becomes a null pointer. It is a dangling pointer. What I meant to convey is that "dangling pointers are type errors, and so are null pointers". As you said, object2 is now pointing to deallocated memory *that might be used by something else*. So now you can have a `Class *`, pointing to something else. So when you dereference it you break preservation. &gt;Why the hell would a nullptr be a type error? For one, a pointer to something is its own type, an integral type representing its location, alignment, and size (believe it or not). When you have a nullptr pointer, that just means it doesn't point to anything (or rather, points to a location that effectively means it points to nothing). This is related to my other points. A null pointer become a type error when you dereference it, because dereferencing takes something from type `X*` to type `X`. null pointers breaks this.
***Now if the key is repeated I want that value to just add to the last value and etc.*** what does that mean anyway. and you are confused about the rows and columns. i take that as you want list of entries to your keys. from collections import defaultdict total_spent_time = defaultdict(list) with open("calls.txt") as fp2: for line in fp2: row = lines.split(";") total_spent_time[row[1]].append(row[2]) print total_spent_time
Yep.. you are absolutely right. :) My head is in the cloud today. Updated the title to be more reflective of this fact. 
You seem to be adding strings together instead of converting them to ints first. This will make things clearer: key, value = row.split(';') ... total_spent_time[key] += int(value) and make it `defaultdict(int)`.
That's not what your example input looks like, but anyway. Youll need to convert all the numbers you want to do arithmetic on to integers (or floats if you have any decimal points.) Then you should be able to add them together. What you are doong now is concatenating the strings when you use the plus sign. 
Thanks for the nice examples. However, both Python and Haskell look conceptually pretty similar to me with respect to the lambda function. I can't see much difference
Sounds like you want the collections. defaultdict which is a dictionary that has a default value for nonexistent keys. Set the default to 0 to use the value as a count. from __future__ import print_function from collections import defaultdict phone_numbers = defaultdict(lambda: 0) phone_numbers["5551212"] += 1 phone_numbers["5553421"] += 1 print(phone_numbers) 
Store them as a list, then put them in a collections.Counter
Threading is perfectly fine for this type of workload. asyncio only gives you a benefit if you are dealing with *a lot* of concurrent connections. With *a lot* I mean a couple of hundred or even thousands of connections. Way more than any network clients usually need. asyncio is for servers (or p2p software perhaps). Have a look at https://docs.python.org/3/library/concurrent.futures.html 
&gt; On the topic of alternatives: you could probably use multiprocessing. This is ill advice. multiprocessing is for CPU-bound workloads. threading is for IO-bound workloads. Web scraping is clearly IO bound and suggesting multiprocessing without any explanation is misleading.
How can I pick chicks with it?
multiprocessing creates processes instead of threads. With 10 worker processes you have 10 copies of the python runtime in memory. While it does work, it is not what you want for IO bound jobs. Threads have lower overhead. Yes you can use a sledgehammer to put a nail in a wall, but that is not what you would normally do :)
&gt; will be released soon: aiomysql Good start. But SQlite is actually more important. &gt; aiozmq : already here, and you can do PUB/SUB with redis I think Both using compiled external dependancies. Not a good solution. &gt; as for ORMs, you are right, async and ORMs do not play nice, but this is common problem of all async frameworks. They have them in JS. &gt; Could you be more specific? With RPC and coroutines, it's easy to build task queues not requiring some compiled message broker. Most project don't need that, it's overkill. But you do need background tasks for generating contents, making database cleanup, etc. All in all, it's good than the community is getting involved in this. It's indeed getting better. 
Sure, but PyPy exists. A Python compiler could do what PyPy does at compile time for the whole program (instead of just the hot path). Sure, it would need a fallback, but generating machine code that does the same thing as the interpreter is also a potential for more performance.
I don't have a lot of familiarity with the exotic languages that do this, but then isn't that really just writing lots of tests in your code and calling it "types"? Does it really save lots of typing or is the amount of extra work involved equal to putting in lots of asserts and other code into a conventionally typed language program?
Maybe, this is what you're looking for? https://docs.djangoproject.com/en/1.7/topics/auth/customizing/#specifying-a-custom-user-model
No nuance here, just the "science" part of "computer science". We have peer-reviewed literature that has found that the "conventional wisdom" that static typing provides benefits isn't confirmed in reality. There are several more papers I could have posted. There's nothing wrong with pointing out facts. To this day it's accepted wisdom that object-oriented programming speeds software development, but as one computer scientist has said, every time that claim is made computer scientists have to stand up and say that it has yet to be proven. In fact, there's actually almost nothing in the literature about the subject. The very few papers that exist on OO benefits did not find productivity benefits at the small or medium level.
It is. It's an empirically proven fact. You're trying to insist that this is a qualitative issue for which there is no right or wrong answer. That's simply not true. We can measure effects on productivity and errors. Heck, the person who performed the experiment I linked to *created an entirely new language* for the test - two versions actually that differed only in typing. Competent programmers were given a tutorial in each - longer for the static variant. The programmers who undertook exercises in the dynamic version took less time to code the problems and had the same level of accuracy and no more bugs statistically than the static group. This researcher has followed up with other, related, experiments to test static vs. dynamic including its worth in APIs (which was indeterminate). These things are simply claims about reality, and claims about reality can be measured and tested.
This is the first I've heard of aiohttp. OP, do you know of any people using the server in production on a public facing app at scale? 
You probably should consider a site other than Google for this because from a terms of service perspective, it's not exactly something they'd commonly allow. I do have some other suggestions though which would work even if you picked a different site: * Use a cron instead of a script that sits in memory all the time. * Consider using some other method of trying to contact the outside world. HTTP is not exactly inexpensive and you just need to know if you can connect out. Something along the lines of "Do a dns lookup for &lt;server&gt;, then try to open a socket to &lt;server&gt;" would be enough to establish that you can resolve the server's address and talk to it. * The url you're opening is a redirect to the https page which means every request will be redirected * If you really want to use http, I'd do a HEAD request instead of GET since that will be lighter on resources Finally, you probably want it to fail a few times before you consider it a problem. That would rule out most intermittent issues. 
Excellent. Thank you! 
Yeah. OP writes as if it is small-business friendly...and maybe it is if you plan on selling NLP-enabled software at a high price, or already have good cash flow...
Martin: &gt; I thought an experiment was in order. So I tried writing some applications in &gt;Python, and then Ruby.... I was not entirely surprised when I found that type &gt;issues simply never arose. My unit tests kept my code on the straight and &gt;narrow. I simply didn't need the static type checking that I had depended upon for &gt;so many years. &gt;I also realized that the flexibility of dynamically typed languages makes writing &gt;code significantly easier. Modules are easier to write, and easier to change. There &gt;are no build time issues at all. Life in a dynamically typed world is fundamentally &gt;simpler. So he a) didn't need static typing and b) gained benefits from dynamic typing. How does that not equate to Martin denying the benefits of static typing, which is what I asserted? &gt;Second, rudimentary, solitary assignments that generally favour dynamic typing &gt;are hardly empirical evidence for one being better than the other. A peer-reviewed article by a computer scientist that gets published in a computer science journal isn't empirical evidence? There are (a few) more where that one came from, but it was the most ambitious to date and the one that answered the most objections leveled at previous experiments. 
Nothing =]. We used aiohttp for a an internal project, and it works great. It is so much cleaner. I am looking forward to pypy (STM)/pyston support one day.
C++ is a bit different, yes, but making claims of static typing about a language with stupid pointer tricks is a whole separate can of worms -- C++ certainly *can* be statically typed, if you accept "pointer to god-knows-what" as a valid type for everything in the program :)
Ah I see. I'm not sure if one needs to explicitly handle the non-standard evaluation part -- I've never had trouble wrapping dplyr/ggplot commands in a function (the only thing to note is that you have to print(p) if you change your plot p for it to update the plot -- that's the only non-standard eval I can think of). The rule of thumb for me is that if something simple seems unusually convoluted, there might be another way of doing it and someone on StackOverflow probably knows how... :). But point taken. 
Back in the day, trying to `ping` Yahoo was the canonical way to see if a machine was online. Perhaps that could make a comeback.
I just did something very similar. I wound up with a series of threads: 1. An http.server thread for a CGI part of the application 2. A serial server thread for a part of the application that pretends to be a serial device 3. A thread that updates the GUI based on the database 4. Temporary threads that update the database (a SQLite3 database) 5. A process that gets invoked when one of the CGI scripts is called so that I don't have to wait for a thread to return. All of that added up to a device emulator. It actually does a half-decent job of emulating the devices in question, too. I would also note that you can set a label to display a pixmap. You don't need to import the KDE libs for that. ETA: How to set a label to display a pixmap, as window.py: import form from PyQt4 import QtGui, QtCore class AppWindow(form.Ui_Dialog): def __init__(self, parent=None, name=None, fl=0, mainWindow = None): form.Ui_Dialog.__init__(self) self.kpixmapregionselectorwidget = QtGui.QLabel(Dialog) self.kpixmapregionselectorwidget.setGeometry(QtCore.QRect(30, 100, 341, 61)) self.kpixmapregionselectorwidget.setObjectName(form._fromUtf8(kpixmapregionselectorwidget)) with open("Desktop/IMG_0377.jpg") as p: self.imageLabel.setPixmap(QtGui.QPixmap(p)) Then call it as follows in your gui.py: import sys from PyQt4 import QtCore, QtGui from window import AppWindow class MyDialog(QtGui.QDialog): def __init__(self, parent=None): QtGui.QWidget.__init__(self, parent) self.ui = AppWindow() self.ui.setupUi(self) self.ui.pushButton.clicked.connect(self.OK) def OK(self): print 'OK pressed.' if __name__ == "__main__": app = QtGui.QApplication(sys.argv) myapp = MyDialog() myapp.show() sys.exit(app.exec_()) Now yes, I've kind of gone to the next town by way of China here. You *should* modify the .ui file to use a label instead of the KDE widget, then recompile it. 
The practical difference between using PBKDF2 and bcrypt tends to be rather small (as far as I'm aware), and PBKDF2 has an implementation in the Python standard library while bcrypt requires compiled third-party modules. So PBKDF2 is a good sane default, and anyone who wants bcrypt can install a module for it and use it.
I'm not the author.
You can always find a happy medium, I often call R and MatLab from Python.
I'm stuck with Python 2.4 with an outdated Curses for a crappy GUI-esque interface. Cannot upgrade it, and cannot install PyQT, and I'd love to use it!
What's the point of the UUID?
The integration with ipython should fix that right? Just install the extension + ipython and you can use the magic commands.
~~Currently no. At least not with vim-slime.~~ Nope, works! Edit: Okay no - it doesn't work (at least with vim-slime and manually). It starts with the %cpaste and then directly starts inserting code, without a newline between `%cpaste` and the first line of code. I guess that is a problem of ptipython, since this happens also when I'm manually trying to insert code.
Python version using lambdas and map (slightly different from above): map((lambda x: x * 5 - 3), [1,2,3]) Maybe more idiomatic Haskell version taking advantage of partially applied functions instead of explicit lambdas: map ((* 5) . (- 3)) [1..3] Actually the above doesn't work because of syntax weirdness with - and I ended up having to use: map ((*5) . (subtract 3)) [1..3] Meaning I'd just probably have used an explicit lambda like below :) map (\x -&gt; x * 5 - 3) [1..3] I try to use these patterns in Python where applicable. It might be interesting to check out: https://pypi.python.org/pypi/PyMonad/
 [KeepSafe](https://www.getkeepsafe.com/) using it in production, they have about 30m users. And as far as I can tell https://github.com/Eyepea using it too, with their own framework API-Hour
some suggestions for the module: * the way positions with defaults are declared goes via a dict, and is as such not sorted. thus (using the quick start example), you can not know if `person("Jim", "Raynor, "Eugene")` will really create a Jim E. Raynor or a Jim Raynor born on Eugene. keyword arguments are not sorted, and you can't make them sorted without being bad to python. * i suggest to use a proper class, that would allow better subclassing. also, you could then get rid of the uuid thing by implementing a __repr__ function that uses the id of the class (which is already what you expect from the uuid, that is, per-process unique) * check the namedtuple documentation for what it accepts as second args. afair it will take a list as well, and then you can merge_tuples with `[item for ...]` instead of `",".join(item for ...)` and avoid needless string operations where arguments would just be split again later. * i'd recommend against naming those things structs -- to python users (and c users in general), structs are not only strongly typed, but also related to how things are stored in memory (a python struct is primarily for packing and unpacking binary values). name it "quicknt" (for quick named tuples) or anything, but those things are not structs.
&gt; With RPC and coroutines, it's easy to build task queues not requiring some compiled message broker. Most project don't need that, it's overkill. But you do need background tasks for generating contents, making database cleanup, etc. I am not expert in django/flask but most of times, celery used for that... with redis or rabbitmq brocker... Anyway asyncio has ``run_in_executor(executor, callback, *args)``, so you can add potential blocking or long running operation there with threads or processes. &gt; aiozmq : already here, and you can do PUB/SUB with redis I think Both using compiled external dependancies. Not a good solution. From my experience something like reliable PUB/SUB always requires external dependency, could you point me to such library in tornado/twisted/django/flask world? 
Last time I checked QT 5.4 was the stable release. And 5.0 was released in 2012. Don't you want to upgrade the versions of the software you're using? =)
All valid arguments, but they work just as well or better for C / C++.
I didn't get pissy until you did dude. On the mobile app that I use, you can't see these rules anywhere! 
Selenium is a great framework for web testing. It really works well across platforms, browsers and pretty much all kinds of web implementations. What does Appium add into that? 
Let me know if you have any more questions.
Thanks for the suggestions and reading the code! First of all, you won't be able to call something like person("Jim", "Raynor", "Eugene") because positional arguments are strictly disallowed in istruct. Hence, it won't have the order problem like the one you mentioned. Please see the second to last example under Quick Start. I didn't know `namedtuple` takes a list as the second arg. This is very helpful. I agree that the name can be a bit confusing since Python already has `struct` (it's also mentioned in the README file). Think of it as struct in languages such as Elixir and Go for now (correct me if I'm wrong). Basically, the idea is to have an immutable dictionary-like data structure that supports 1. predefined keys, 2. optional fields with default values, and 3. instantiation via keywords only.
yeah sure!!
Why cant this be called by SSH ForceCommand? Everytime I see a "do x over ssh!" it always requires REPLACING my SSH with their program. :( [related](https://www.reddit.com/r/linux/comments/2r539r/why_arent_we_using_ssh_for_everything/cnh4i4h?context=3) Other than that.. its a pretty neat project. 
Sounds like you work with the military.
It's a challenge doing things the "hard" and "old" way. 
That's just how things roll.
Nice example - I suggest playing with the termination criteria a bit more. Side note: depressingly, I have seen drone related kickstarters funded with less proof of concecpt operation that this. Depressing really.
You have to run it from the console not your IDE. Getpass doesn't work otherwise. Also make sure you have imap enabled on your Gmail account. Hope that helps. Let me know if you still have trouble with it. 
So I am guessing the video was being transmitted and OpenCV was running in the ground station laptop? What hardware was involved to pull this off?
Other than qt itself you don't have to install anything. It works on windows and Linux, and does not require XML or a special compiler.
Alright.. Is it hard to make the transition? I guess its relative easy for me since im not very far in the learning process.
1. I did acctually consider using learnptyhon, but since it was a general python question i thought this subreddit was the best suited. 2. My question was not how to get pycharm to work, and that is why i did not feel the need to clearify it. 3. Thank you for the answer :)
I used Qt for years and have used PyQT in a few projects. My only problem is that at some visceral level I just don't find QT to be Pythonic. Yet when I look at my code it seems psuedo code enough. I am going to throw this out there. Python needs a trio of modern totally python graphics libraries. One for applications, one for 2D games, and one for 3D games. And ideally they are all aspects of the same library. And yes I know there are things that separately meet all my above criteria, but unlike things like NumPy they all feel wrong. 
No, it's not hard if your Python course gave you good habits from the begining. Mostly change some imports, print, and string handlings.
Nice ! If I understood correctly, you are simply segmenting the image that the drone films. But could you send a feedback to control the drone as a function of what it "sees" ? Examples of use could be (1) make the drone decide its own movements in order to follow an object (you, a balloon, etc.) or (2) ask the drone to always rotate itself in order to focus its camera on the same object, while you move it around with the remote control (I hope it was clear).
It's working out for me, but I don't like the resizing issue and drawing off screen issues. At least with 'less', you could draw off screen. With Curses, I have to truncate to the current window size and if resized, close the top panel. 
ClickBank?
"https:\//support.clickbank.com/entries/25511477-How-can-I-protect-my-product-" Somehow that doesn't sound quite right.
Neat... I'm new to python (and python-based GUIs) but have made an app using pygames that controls the lights in my house. When I get home from Vietnam I might try porting it to PyQT and see which GUI performs the best. Right now it's messy because I have rectangles that act as pseudo-buttons, a big loop that checks what's going on and functions that are called within the loop. There's some performance/behavioural issues that I've made 'hacks' for... most relate to the fact I'm using a cheap touch screen. Maybe QT will speed things up (because I can do away with the loop) and fix the behaviour because it won't constantly be looking for if statements relating to the mouse/rectangle bumping into each other at the same time as somebody 'clicks' (which is never a real 'click' because it's a touch screen tap). Fun!! Can't wait to try it out. Question though... how does QT perform? I'm using a Raspberry Pi (with raspbian) and am REALLY trying to squeeze as much performance out of it as I can. Fullscreen QT... is that possible and will it be one of my faster options? Essentially... I have logic that detects how many lights exist and a 'button' function that creates a button (aka clickable rectangle) for each light. It then loops around and sets booleans on/off, checks the status of the lights (so it knows for sure whether lights are on/off), has a function/'button' for pairing with your hub and has a preferences screen for setting up colours/brightness/contrast. Would it be faster in QT if I made buttons and attached them to these existing functions? I feel that getting rid of the big loop is a priority because it's a bit 1980s (I've resisted the temptation to add goto statements... all if/elif within a loop still though, which IMO is poor practice). Any references on how to plan your GUI a bit better so that I'm not cobbling it together as I go? 
You can `pip install python-qt5` And you're missing lots of nice features, introduced in qt5, you know =)
Thanks for the comments! I think asking what people would pay is part of LeanPub, not by my own choosing. While eventually I'd like to make some money off of it, that's not my primary goal especially for a first attempt. That being said, I'll see if LeanPub will let you put up a table of contents prior to the full book being published. After enough prerequisite material (probably after classes) it will take a project based approach. Once it is done, I will likely include one of those chapters in the preview, perhaps in lieu of the second chapter. The online tools and the project would be the two main 'selling' points.
/bin/bash is a single command.. its fairly interactive. My point being, forcing me to replace my ssh server for something that can run under a single user account is frustrating. OpenSSH is insanely powerful as a platform for multiplexing many different tools. Take [gitolite](https://github.com/sitaramc/gitolite/wiki). Its a fully functional git repository manager via ssh/git. It can do interactive commands for forking/mirroring/access managment. Without the need to replace the entire SSH stack. 
Hey I'm doing a senior project on this topic right now! Except we're trying to use depth mapping to make emergency stops/avoidance when obstacles appear in the flight path. /u/styguy get in here.
I use the anaconda distribution of python it comes with most of the packages I need already so it helps when I want to test my code on a different machine I know there's one distribution to download and it will contain all the modules I need. I have never had much luck trying to package up my code using py2App or py2exe to include all the necessary bits and pieces thus I use the anaconda distribution which contains the modules I need. It runs just like 'normal' python from the command line - ie. I type python mycode.py and it runs my code with the anaconda python distribution.
 list(open(filename).read()) But I doubt it's necessary, strings are iterable.
if i was trying to convert every value in the string to a number and add an offset, would a string still work? 
more control over spacing
Is he on windows ?
Two youtube courses that got me going with PySide, especially the first one, the Model View is very well done. * [PyQt4 Model View Programming Tutorials](https://www.youtube.com/view_play_list?p=8B63F2091D787896) * [Python GUI Development ](https://www.youtube.com/playlist?list=PLA955A8F9A95378CE)
do you mean something like: f = open('myfile.txt','w') f.write('message') f.close()
&gt; Crossbar.io interesting, if there is demand for such library, I can try to port it to asyncio. But from my experience it is better and easier to use zmq or redis pubsub (i can not imagine descent web project without redis anyway...). 
Yes exactly!
&gt; was **not** how to get pycharm to work, 
You're more than welcome to make single-process interactive programs in the way that you wish using its underlying blessed library, https://github.com/jquast/blessed x/84 is a meant to be highly portable and 0-configuration install -- it can run as user 'nobody', manage its own user accounts, and does not require any sysadmin work to make a secure public shell server -- it is more than trivial to set up a system like http://sdf.lonestar.org/ I have many more reasons for the design choices made, feel free to e-mail me if you are interested in hearing more about it.
You might get more answers if you edit your post to be more specific about the kind of help you want. Few people here are going to know what is taught in GCSE computing, for example. Good advice: http://www.catb.org/esr/faqs/smart-questions.html#asking Some general comments: * "procede" should be spelled "proceed" * You have unnecessary parentheses around some expressions in your assignments. This is only useful if it's not obvious at a glance what the order of operations is. * "plate" is not used anywhere * Is there any reason for your program to specifically require the letter "S" to be entered? If the only user input you need is some action to start/stop the timer, could you make this easier? * You can split up your code into smaller parts by writing a function that computes whether the car was over the limit for a particular time. This logic is unrelated to the surrounding code that interacts with the user.
I'll try to improve the parameters of the termination criteria, but first I'll take more samples of video to get a better error estimation. Thanks !
 message = list(open("Catext.txt").read()) no i am using the line of code above and because the opening is not assigned to a variable i am not used to working this way. the code reads and writes to a file so the file is already open when it needs to be written to.
I actually just started using pythonanywhere just to use to learn at work. I like it so far but I am just using a free version and not the paid one. I am new to Python all together but not new to web dev.
Django is actually probably not the best option, not that we are reinventing the wheel but it's not a traditional site in terms of URL routing and creating database models. Something simple like Flask seems like a good fit since we wouldn't be using Django models for anything other then managing User data. The rest of the site data will be interfacing with Elastic Search. How well does Flask work with creating and managing User data, sessions, security, etc...?
&gt;twisted is a great library, just it is easier to write bad code on it :) Can't argue with that! I'll add that the documentation is pretty horrific for beginners. Granted, writing asynchronous applications isn't really a beginner's task, but it's it's particularly daunting with Twisted. Interfaces, for instance, are particularly intimidating to the neophyte. Frankly I look forward to asyncio and I have little doubt that I'll someday prefer it. It's one of those things on which I'm keeping close tabs.
I currently use ConfigParser but I may have to give this a try. Thanks for sharing.
I see that now the idea was that the contents of the text file is encrypted and then the encrypted text replaces the original contents of the file.
&gt; python3 support ruined Flask why is that?
It's been pretty good thus far. I pay for the 10 dollar tier. I've been frustrated occasionally when using my own virtual environment, just getting that set up, but that may be mostly a reflection of my novice skills :) Yup, you should probably just give them your money :)
It would support your statement very much if you could list some reasons.
Very interesting, you say it is fast, do you have any benchmarks in comparison with a typical feature detection algorithm like SURF? Rescaling an image 20 times seems like it might be expensive time wise.
Hi, could you create a GitHub issue for this: https://github.com/jonathanslenders/ptpython/issues I take all feature requests serious. But I don't really understand the issue. For me, both %paste and %cpaste seem to work. Or do you want to be able to configure a key binding for %paste?
I would think benchmarking performance on frameworks would be possible, has no one ever done this?
~~The example presented in the wiki article isn't a shabby way to do it. The methods created are static. Since you can't have free-standing functions in Java, static methods are the way to go.~~ ~~The way you've presented seems... wrong. First, it doesn't do what the Java example does. You need to add a "if __name__ == '__main__'" block to your code to ensure that the tests can be executed.~~ ~~But the big one is... Python has free-standing functions, so why not use them? Even better, Python has a decent-enough unit testing framework built in. Why not use that? The point of self-testing code isn't self-testing classes. By all means, slap the test code into the module with the classes, and strap it up with a main block so you can easily execute the tests. There's no reason to add the test code to the class itself, though.~~ ~~Your tests should not be part of the surface area of your objects.~~ EDIT: It looks like your indentation b0rk3d the code, and you're doing exactly what I would do. Derp derp.
Great question. I really should have gotten some benchmarks together before I put the article online. I guess I dropped the ball on that part. But consider an algorithm like Difference of Gaussian keypoint detection which is a required step prior to extracting local invariant descriptors such as SIFT or SURF. To construct a DoG representation you're constructing an image pyramid (i.e. many scales). And for each keypoint detected you're extracting descriptors. And then for each of those descriptors are you using either a brute force matching, O(n^2) between descriptors or an approximate nearest neighbor, O(lg n) And once you have your raw matches you are running RANSAC or LMEDS (Big-O notation too long/tedious for me to type in here). Overall, there are a very large number of expensive steps that are going on under the hood when extracting keypoints, local invariant descriptors, and performing keypoint matching and spatial verification. Anyway, that's still no excuse for not having timings. I'll have to update the post.
I am envisaging that the test classes would be executed by py.test So perhaps in the test directory you would have a set of test code that just imports the self testing methods so py.test can execute them.
No. Anaconda is really only useful on windows. Mac and linux users use package managers.
The test class is intentionally ~~a subclass of~~ nested class within MyOperation. Is that what you were referring to?
I train all my windows trainee using notepad++ or sublime text. No problem.
I'm pretty new here, but I think it's because the syntax is simple, and prototyping things is quicker than some competing languages. Hope this helps!
Oh, well then yes. I don't agree with that. Just leave them both in the module. A module can contain many classes, test classes and otherwise. Just bring it up to the top level. No need to push testing concerns on the class itself.
Well, it implies your host allow you to install that. And you need compiled extensions. And you need to use an unstable version of redis if you dev under windows. And you need to write the event loop for your redis pub/sub. And you still don't get JS RPC and PUB/SUB in the browser crossbar.io offers. So yeah, it's a solution, but it's not perfect either.
So, the best way that I've seen to do it (without bringing any 3rd party libraries to bare) is to just use the unittest module, and create all your unit tests as classes. If you have a Foo class, create a TestFoo class that conforms to the unittest modules conventions. Then, while in the root directory of your project, just run "python -m unittest" No need to write code that actually runs your tests. Just let unittest Test Discovery Mode do the heavy lifting.
One strength is that Python doesn't have too steep a learning curve. People can pick up the basics fairly easily and then use it interactively. That's part of why it's popular in scientific applications, for example.
No it's not, not in the code you posted. It's a class attribute that is also a class. Very strange. I can't think of any reason you'd want to do that.
Yeah, I thought that was a formatting bug. Creating a class as an attribute of a class is... a strange thing to do.
Sorry, to be clear, the code I tried to post should be showing a test class within another class.
How is Pyramid on Python 3?
Code is communication. Doing things like this communicates... strange ideas... to the reader of your code. The most important test you can apply to what you do in code is "If I didn't know what's going on, would this make any sense? Could someone find this confusing?" If you want to do crazy unconventional stuff, there are better languages to confuse people with than Python.
Am I the only person who can't get past line #1? sudo pip install pyqt &gt;Could not find any downloads that satisfy the requirement pyqt &gt;Cleaning up... &gt;No distributions at all found for pyqt &gt;Storing debug log for failure in /home/linuxlite/.pip/pip.log I got this on LinuxLite 2.2 and Windows 8 both. No problems with pip before on things like pymovie or matplotlib or mayavi. 
As a language I would say readability. It really teaches you how to write good code not only for you but also for those who will have to read your code after you. For a technical feature, I would say list comprehension, it really is a powerful tool and it is really rare that I find myself writting a 100L+ program without any list comprehension.
Well... what is the reason *to* do it? The inner class can't even access the outer class at all. So what is the point?
Web apps for flood risk analysis? That sounds interesting, tell me more, please!
Which framework will scale best though as you throw more requests at it? This article show quite a few different benchmark tests agaist frameworks... http://nichol.as/benchmark-of-python-web-servers
You can keep the *entire* syntax in your head. You don't need to rush to the internet to remember how to do basic things. There is no "expert" Python programmers. Just people who haven't been exposed much to Python yet. Once they learn a few tricks, they've pretty much mastered it. Experienced programmers need only a few hours to learn it. It's fairly difficult to write code that is incomprehensible. It's much easier to make it clear and simple. You spend all your time focused on getting the right algorithm for the problem, rather than fighting your language. It's never "Do I put a semi-colon here or a comma?" It's, "Should I put in a linked list or an array?" You can use whatever paradigm fits the task. Scripts? Got it. Procedural programming? Piece of cake. OO? Built-in. Functional programming? Absolutely. Want to combine the best of all of the above? Done. Java came up with Aspect-oriented programming, but I discovered that Python already supported it. Now that games are talking about data-oriented techniques, it's like, "Oh, that's what you call this technique I've been using all along?" The only thing I miss in Python are dynamic variables, but there are good enough workarounds that it's not a huge deal. I can't tell you the number of times I've written 100+ lines of code, then just ran it and it just worked. Any other language, I'd expect to get at least 10 serious bugs in 100 lines of code, but Python is about 1:100 for me. It's pretty trivial to write a library and share it with people. PyPI has pretty much everything you need. If something's broke, it's fairly easy to dive in and fix it yourself. The fact that there are umpteen million web app frameworks for Python is testament that it's easier to write Python code than figure out what someone else did and adapt it to your needs. This says a lot. In other languages, web app libraries are dancing bear-ware: It's a miracle it works at all. In Python, you create your own set of requirements and quickly produce the software needed to satisfy it. Finally: My killer library is SQLAlchemy. I have tried my darnedest to use other language's ORM systems, but every time, I've discovered fundamental flaws that make it easier just to write raw SQL. In SQLAlchemy, I can do everything I need. If I need to write raw SQL, it still plugs in with the existing stuff.
Speed of development, or execution? I've never heard anyone claim python is a particularly fast to execute language.
Pyramid and its dependencies work on Python 3 and have been working on it for quite some years now.
Test code should generally be at least twice as long as app code (this is a trend I have noticed with my own code anyway), so this will really crowd your code and make it unwieldy. You're basically de-organizing.
Simplicity. Unfortunately this erodes with every new release. It is impossible to resist adding new stuff all the time.
Tons of times, as it's the easiest thing to measure and it gives the illusion you can compare web frameworks, though it is one of the most irrelevant things for most purposes as typically application code will totally dominate real world performance. 
I've only been coding in Python for a little over a month, so this is a newbie opinion. Here are the basic reputations for each language that I've gathered: C, C#, Objective C: For full-on developers. Don't try learning unless you're looking to get hired somewhere. Java: For Android developers. I'm sure it's possible to make desktop apps with this language, but you're going to end up making Flappy Bird clones. Ruby: Are you building a website? No? Move on. SQL: You are never, ever going to build a game with this language. Python: Everyone can use it, whether you're a hobbyist or seasoned developer. Whether you're building a web app with Django, or giving your Raspberry Pi instructions, you're good to go. Just type "import Finished_Product" and run it. So, in short, I picked Python for its reputation of accessibility and community support. For every project I've put together, there's been a seriously useful library to lean on. It's great. EDIT: Does it *sound* like I think I'm giving dictionary definitions of these languages? Enjoy the colorful re-telling of one newbie's impressions, or go live your life. Nobody's looking to me for accuracy.
[ndarray](https://www.npmjs.com/package/ndarray) N-dimensional arrays [ndarray-crout-decomposition](https://www.npmjs.com/package/ndarray-crout-decomposition) One of the many extensions made for the ndarray module [gl-matrix](https://www.npmjs.com/package/gl-matrix) Some linear algebra [Some PRNG's] (https://www.npmjs.com/search?q=random) or [node's own random bytes module](http://nodejs.org/api/crypto.html#crypto_crypto_randombytes_size_callback)
The modules exist ... but how fast are they compared with numpy? In other words, if someone wants to do serious numerical work, can they use these modules? [many of the state-of-the-art numerical routines are written in Fortran and available in Python; I have not heard that they have been made available to Javascript programmers]
Ok. That makes sense. I'll give it a shot. Thanks!
If by "not precisely worded" you mean "misleading", yes. Saying that you'll "never make a game" with SQL is like saying that you'll never build a wooden horse with Ruby. It's technically correct, but not a good summary of what the language does.
It's due to your use of `route_map.resource(...)`. This sets up a number of routes with REST-like semantics (ie, routing based on HTTP method). If you want simple routing, irrespective of HTTP method, use `route_map.connect(...)` Also, use Pyramid :P
wat? How is Anaconda really only useful on Windows? I use it on Mac everyday. What is this package manager you speak of?
Thanks, this worked.
Saturation. It's everywhere.
It's quite sad that while this article describes FP techniques very well, it fails at explaining what are the benefits of FP and in what case it can be useful.
Thanks for the answers (and I meant performance as in for the frozen applications, not the freezing). I'll compare the two later when I start using them.
While I enjoy node for many things, npm is not one of them (anymore). Unfortunately people publish so much stuff on there that it's incredibly hard to find the good libraries in all the rubbish. Even my gulp auto completion script is published/installed from there and it's a .zsh file that only benefits from the script option in the package.json. Regardless, the discussion is the OP asking what people love about Python - not inciting a debate. If they are interested in node love, my guess is they will also post there. 
For scripting (which is what often develops into modules), being able to start quickly: Decide what I need to do and write code to do it, even if it's quick + dirty.. and then have it pretty much just work. a) batteries included + b) enforced minimum code-formatting quality standards + c) simple and flexible core language, add up to this quality. Having **something** which does the task is the first and most important step in making something **quality** that does the task. Understand the problem -&gt; write something that addresses it -&gt; make it work well. This is IMO the most important metric of programmer-friendliness, and Python has it in spades. 
You're just wrong. Experience level aside, all your descriptions are wrong.
For future articles, consider screenshotting without window decorations (most screenshot tools have an option for this). The window dropshadow makes Figure 2 more confusing than necessary. I presume a variation of this technique can be applied to find possible multiple scales of the same pattern within the image to check? (for example a photomosaic where the base photo is also one of the components comprising the mosaic. Should match the entire picture and also the tiny component)
Alright... I like Python as much as the next guy but... COME ON! &gt; You can keep the entire syntax in your head. You don't need to rush to the internet to remember how to do basic things. Fair, but *most* good languages are this way. Java, for instance, may be the simplest language in common use that I know, for a perspactive of the syntax. &gt; It's fairly difficult to write code that is incomprehensible. It's much easier to make it clear and simple. Until you learn about lambdas and comprehensions, then everything starts looking nail-shaped and your code will never be uglier. I've rejected a lot of code reviews for these two alone. &gt; You spend all your time focused on getting the right algorithm for the problem, rather than fighting your language. It's never "Do I put a semi-colon here or a comma?" It's, "Should I put in a linked list or an array?" Um... I think that if you're worrying about semi-colons or commas, you need to go back to that "learning X" book you didn't read. Syntax is always the easiest part for any language worth using. Also... linked lists vs arrays? Really? In Python we have "lists", which are really Vectors with extra features. That's it. If you're using anything other than the builtin list object for sequences, you are very probably doing something wrong. &gt; Now that games are talking about data-oriented techniques, it's like, "Oh, that's what you call this technique I've been using all along?" No, you haven't. I don't know if you've been paying attention, but data-oriented techniques are all about cache-line optimization. Python chases so many pointers that you might as well figure that cache is a non-thing for Python programs. Unless you're busting out numpy for some extremely restrictive use cases, you're not doing data-oriented programming. Don't get me wrong, I love Python too, but it's not *that* amazing...
Speed? Really? Are we talking about the same programming language? Did you get drunk and stumble into this thread thinking that it was about C++ or something?
What is a private class?
Anaconda Documentation http://docs.continuum.io/anaconda/ Conda Documentation http://conda.pydata.org/docs/ Binstar Documentation http://docs.binstar.org/ Public support forum for Anaconda https://groups.google.com/a/continuum.io/forum/?fromgroups#!forum/anaconda Conda Mailing List https://groups.google.com/a/continuum.io/forum/#!forum/conda
I use it for rangevsrange.com. It's amazingly: * functional * easy to use * convenient * well supported * cheap But don't just shut up and give them your money. Minimal load applications are free!
&gt; Until you learn about lambdas and comprehensions, then everything &gt; starts looking nail-shaped and your code will never be uglier. I've &gt; rejected a lot of code reviews for these two alone. I am confused, it is like you are saying you are rejecting idiomatic code. I want to excuse myself if I understand the opposite of your code, and I will flatly excuse myself if I understood wrongly. But are you are rejecting idiomatic code? Why not reject code that have test such as: if empty_set or empty_record: # instead of if len(record) val = value_false or default val = a_test and value_that_must_be_true or value_if_test_false And while you are at it while not discouraged the use of sentinel because no one understand their use? SENTINEL = object() def func(bla, optional_value_that_could_be_none = SENTINEL): if optional_value_that_could_be_none is SENTINEL: now_I_know_this_not_an_intentional_None_Value() or better : def magic_wrapper(*a, **kw): log.debug("was called with %r %r" % (a, kw)) Idiomatisms are important to make a language more powerful. Lambda are coroutines that enable functionnal tricks and comprehension are a part of the language that often are pretty well optimized and avoid to modifiy an object while iterated (avoiding bugs) I would be strongly opposing the idea of promoting lazyness over correction if I understood you reject idiomatic code. But I am really unsure of what you said... 
I think that easing users into how functional code might look is what the author intended. Endofunctors are for another day.
*Not my video but helped me solidify "self" the first time I watched.
When I left PHP (I hated) Perl (I loved, but I needed to make money as a freelance), C# (because I was paid and it was easy but boring) I had 2 candidates: ruby &amp; python. I chose python: it had documentation. People seems to be boringly stupid to think a language is about its power or computer feature or adoption. No! There are heroes from the shadows that documents. Documentation can turn a pile of junk into gold: you know what will work and what will not because you have a clear mental image of how it works. Python has flaws : packaging (pypi compared to CPAN is so retarded it is a pain (I have a POC of a meta virus I can put on pypi), psychorigidity (?: shall not pass and the significant white spaces that makes code mixing tabs and spaces debugging looks like reading brainfuck, the absence of use strict that makes you loose time on typo a computer could easily detect for you), BUT it is WELL documented. And this is why I love python. Big thanks to the people writing the docs https://www.python.org/doc/ Oh! And now like perl used to be it is a system language (almost portable) that is 60% close from being it works everywhere as Tcl/TK. Ok Tcl/Tk is weired. But, it has native almost sane GUI. EDIT: and I can use fortran code that knows how to do numerical analysis fast and correctly because it binds easily to almost any libraries. Or use C code when speed is needed finger in the nose. ADDITIONNAL EDIT: And the GIL enables you to use safely non thread safe C code written with the feet, without too much of a performance loss and with freaking less bugs. 
Bingo. From idea to ... working thing, Python is super rad. To me, this is invaluable. Execution speed ... for what I do, time to execute is more important than execution time.
If it really bothers you, use .__len__ instead. Here's the reasoning: http://stackoverflow.com/a/2481433
This is the output I get [{'ip': '144.38.196.157', 'mac': '00:23:AE:90:FB:5B', 'name': 'tellurium', 'room': '119'}, {'ip': '144.38.196.157', 'mac': '00:23:AE:90:FB:5B', 'name': 'tellurium', 'room': '119'}, {'ip': '144.38.196.157', 'mac': '00:23:AE:90:FB:5B', 'name': 'tellurium', 'room': '119'}, {'ip': '144.38.196.157', 'mac': '00:23:AE:90:FB:5B', 'name': 'tellurium', 'room': '119'}, {'ip': '144.38.196.157', 'mac': '00:23:AE:90:FB:5B', 'name': 'tellurium', 'room': '119'}, {'ip': '144.38.196.157', 'mac': '00:23:AE:90:FB:5B', 'name': 'tellurium', 'room': '119'}, {'ip': '144.38.196.157', 'mac': '00:23:AE:90:FB:5B', 'name': 'tellurium', 'room': '119'}, {'ip': '144.38.196.157', 'mac': '00:23:AE:90:FB:5B', 'name': 'tellurium', 'room': '119'}]
BTW: The day you will want to make a serious module for python you will hate it. 
Shift d = {'ip':'','mac':'','name':'','room':''} Down a line, to within the for-loop. (Also you can shorten it to the following:) d = {} The problem is that you only create **d** once. Every iteration of the loop you're just replacing the elements and adding the same dictionary to the list. When you add a dictionary to a list, you're not adding the whole data structure of the dictionary - just a reference to it! So every iteration of your loop, you end up modify the same dictionary, of which now you have multiple copies in the list.
Good thing I'm not using matplotlib then, but could you give any specific reasons as to why matplotlib is a problem with them?
Oh... I feel dumb. That was so simple! Thank you!
Is there a simpler solution to this? Can it be done with zip? :e/ the question is turned in already, it just had to work. Im just curious now.
I think you can. Probably with something like: key_list = ["ip","mac","name","room"] for line in sys.stdin: data = line.translate(table).split() d = dict(zip(key_list,data)) endlist.append(d)
3 things: 1) *Easy to read and write.* This comes from a tighter formatting rules and less visual clutter (brackets or "beging/end" words). Remember when in an CS level Algorithms course, algorithms would be presented in some kind of idealized pseudocode that was supposed to be minimal and pure. Well Python is pretty much that. It just has a consiceness and purity about being able to express the main idea of the algithm. Unlike say Java where you have to put it in a clasa and have a static main and so on. And design an interface, and getters etc. 2) *Batteries included.* When it came out Python has one of the best standard libraries. Want to parse html -- sure. Send an email -- here you go. How about draw a GUI window or play some audio -- it had you covered. And it still does, some of that is showing its age. But by now there is a huge ecosystem of libraries coverying any domain possible. 3) *REPL.* Launch ipython prompt and just start trying things out. "What will this class member look like?" Well just type out or imported. Then explore members and operations with the TAB completion. That is just fantastic, I think. 
That does pull out the right pieces, but in the wrong order. The order doesnt matter for the assignment as long as I change them around in the dictionary, but is it possible to change the order of how they are pulled out using zip? Also, I didnt know you could .translate.split (stack more than one .whatever on top of eachother) great tip! Thank you again!
So, simple example is Error name spacing. module `errors.py` contains: `class EventErrors` contains Exception classes, `class TimeoutError(Exception)` then: `from errors import EventErrors`, use: `raise EventErrors.TimeoutError(e)` etc ...it's not the best example, I just use it for encapsulation. There are some other examples but I can't find them in my projects dump right now :P Trust me, it makes sometimes \^_\^ You can also think of `inner classes` as the lambda functions of classes.
I make new accounts regularly. I've been on reddit - and /r/python - for years, and it has taken a turn for the worse. I have - with a different account - asked for the moderators to take action. They believe voting should deal with people ignoring the sidebar, and I disagree. And the choice is theirs.
Python's syntax is very expressive and as a result it is highly productive. When I need to get a script or small web app working as fast as possible, I choose Python every time. It's one of the more versatile languages out there. It is well equipped for everything from tiny scripts to massive web applications to math intensive data mining. Libraries like numpy make it my go-to language for scientific applications. It's painless to get other libraries integrated in your code and actually working properly. With tools like virtualenv and pip, managing different projects and many different libraries is actually really easy. In languages like Java, C, Haskell etc. this can sometimes be a bit of a nightmare. 
Everything is just kind of organizational since Python object oriented programming is a little less rigid than other languages. It's not much different than the `__init__.py` files in the folders to distinguish a group of `.py` files as a collection. Your last sentence is key though :P so think about that when you're grokking inner classes: &gt; Which the nested approach doesn't allow ...that's the whole point summed up haha You don't want to allow someone to import one without the parent. It's niche, but there are use cases. I'll remember this thread at work this week and if i stumble on some code I'll hit you back :)
You dont have to use functions to write functional code
I much rather use list comprehension / generators over map(). Unless performance is very important, reduce() can better be replaced by an explicit loop. It's more readable and more programmers are able to understand it.
What's wrong with https://github.com/ajalt/fuckitpy? Also, self-moderation is a great idea, I disagree with your perspective. Why would I join a reddit that promises deletes by a anonymous person?!
 secret_names = map(lambda x: random.choice(['Mr. Pink', # ... This is a bad example of using map. The iterable being mapped over is irrelevant to the output, making the mapping function... not a mapping function. Why not: def assign_random(real_name): return real_name, random.choice(['Mr. Pink', ... ]) map(assign_random, names) # [('Mary', 'Mr. Pink'), ('Isla', 'Mr. Blonde'), ('Sam', 'Mr. Blonde')]
Completely and totally wrong. Since 2.4 and the new numpy based python interface it has been very solid.
Homebrew. Once you installed homebrew and gcc, what is the need for anaconda ?
One reason to demonstrate FP in Python is there are likely [35 times](http://langpop.com) as many Python programmers as Haskell programmers. Out there, writing code. Right now. So if part of the goal is to seed a functional paradigm into the minds of imperative coders *in their own language*, this is smart. No arguments, though, Haskell can look pretty.
While you can configure notepad++ to run your Python program (http://akafdmee.blogspot.fr/2013/10/writing-and-testing-pythonjython.html), i advice you don't do that. Just open a terminal in your project directory (Ctrl + Shift + right click -&gt; open a terminal here), and run your project doing "python your_script.py". This way you have always a terminal open. You can run ipython in it, virtualenv, pyped, grin... The terminal is your friend, use it. Although the terminal in Windows is a shitty friend, and you probably want to install Console Z to ease the pain.
So like a class with \_\_slots\_\_ defined ?
I'd like to plug Pyrsistent in relation to this topic. It has really nice persistent collection types with a nice API to modify them. 
&gt; It's more readable In Python it is, but whereas that line looks like this in Python: sum = reduce(lambda a, x: a + x, [0, 1, 2, 3, 4]) It could look like this in Haskell: sum = foldr (+) 0 [0..4] That may still look foreign, but if you work with folds for a bit, you get a sense of the pattern, and then it can be very quick to read. Haskellers abstract a lot with partial application, though, so they'd say what sum is: sum = foldr (+) 0 And then use it in its simpler form: sum [0..4] Both Python and Haskell include sum, of course.
path.py is a fantastic project. More featured that pathlib, works on Python 2 and 3, contains plenty goodies other libs don't have, and fits in only one file. It's clean, it's small. A fantastic opportunity to be involved more in the open source world.
homebrew and gcc? what does that have to do with anaconda? also my original point was I use anaconda to test the same code on different machines. ie. I download one 'thing' (the anaconda distribution) and then run my code... no need for homebrew and gcc or anything else
Functional programming is not using a bunch of maps, and folds. There is a lot more to it. 
I understand now that you use anaconda as a deployment solution : it comes with your most used dependancies. That's a big hammer for such small nail, but it does work. Usually people just pip install what they need, sometime using additional tools for compiled extensions. Anaconda is 337M, just as a download, and add very few benefits on mac and linux which already got all you need to install all project dependancies in 2 command lines. But I see your point, if you want a no brainer solution, it just works out of the box. I'm going to start considering it for my trainings.
LTR readability? How do you pronounce "x.length"? In English afaik that's pronounced "length of x" and "x(f)" is pronounced "x of f" in standard math, so "len(x)" is a LOT closer to fluent LTR readability if you're an English speaker.
&gt; Java, for instance, may be the simplest language in common use that I know, for a perspactive of the syntax. Excepting python then. Because there's nothing simple about the random sprinkling of "static" and "void" and whatever all over the place. Type information itself complicates a LOT. &gt; Um... I think that if you're worrying about semi-colons or commas, you need to go back to that "learning X" book you didn't read. Syntax is always the easiest part for any language worth using. C++ is worth using for a lot of things. The syntax is not at all the easiest part. &gt; Also... linked lists vs arrays? Really? In Python we have "lists", which are really Vectors with extra features. That's it. If you're using anything other than the builtin list object for sequences, you are very probably doing something wrong. That is _the point he was making_. In Java though you have to choose between LinkedList and ArrayList and none of those have a clear shorter syntax making it the "no thinking default".
My first serious foray into functional programming was in Python. I don't find the syntax that bad at all, in my eyes a bit of functional programming makes Python better. The principles are useful no matter what you do – creating clearer functions with fewer side effects, using generators, list comprehensions, and so on. They make you a better developer.
My point was that OP wrote his own command line skeleton for parsing basic arguments, but there is a fairly good argument parser in the standard library, argparse.
Very much this. Test code in Morepath for instance is vastly bigger than what is under test.
The map() function in multiprocessing is pretty useful though (same interface) . I prefer list comprehensions too unless I need to use 8 cores instead of 1. 
I think this is a decent idea. I too am frustrated by the amount of "low quality" posts on /r/python. If the situation does not improve, I might consider ditching my /r/python feed in favor of /r/pythoncoding and /r/learnpython (which not enough folks take the time to use even though it's in the sidebar.)
Very nice, I heard about the language but didn't check it out. This post got me interested in taking it for a spin.
example?
`map` is pretty useless in Python to begin with, because Python has generator expressions. [(name, random.choice(fake_names)) for name in names]
py2exe for python 2 was last released for 2008-11-16 but there is a version for python 3 that show the last release at 2014-10-21 [py2exe 0.9.2.2](https://pypi.python.org/pypi/py2exe/)
Treating this question as a *meta* post (as it is clearly not news about Python ...). I prefer to do my best and gently redirect people asking questions here to /r/learnpython. By gently, I mean: give them a quick answer if I can but point out that they should ask on /r/learnpython. If others have 1) already answered the question **and** 2) indicated that /r/learnpython is a better place, refrain from adding comments to the thread.
Felt the same way. I don't know anything about functional programming and this article just left me thinking "why bother?" A few times the author mentions "The code doesn't need comments, it documents itself!!" and I guess I don't see how that's different than just using expressive variable names.
Hear hear. I only know python, and am having a hard time choosing my second language. Getting introduced to the concepts of functional programming is what I need, in order to seriously consider learning a functional language.
yes, but there are those delicious moments when you already have the function defined and map(foo, lst) # is more delicious than [foo(l) for l in lst] 
Good to see you back your videos up with text notes on your site.
I hope it finds a maintainer. I find its abuse of \__div__ to be... distasteful, but I appreciate what it's trying to do.
Have you tried Nuitka? It's a Python compiler that'll give you an executable binary. http://nuitka.net/
could you elaborate on how it outperforms pathlib? from the README example, the only difference is `.files()` vs `.glob()`, it provides a little more direct access to stat attributes (atime, access) and integrates some other modules (shutil, hashlib), but all together it seems to me that the good parts (mkdirs_p) better be integrated into pathlib instead of using a library that mostly does what a stdlib component already does. (granted, when it was written, pathlib might not yet have existed, but we're not archeologists here)
I didn't see it mentioned in the article but fn.py (https://github.com/kachayev/fn.py) is a fantastic library for those interested in using functional programming within Python.
&gt; I am confused, it is like you are saying you are rejecting idiomatic code. Comprehensions used properly are great. Comprehensions used by somebody who just discovered them, and now thinks the should be used for everything, are not so great. When I first learned about list comprehensions, I shrunk a simple program from a few dozen readable lines into an eight line knot of nested comprehensions iterating over nested comprehensions. It was really nifty, but totally unreadable.
Where can I find a list of what HTTP methods map to what method calls within my class? *EDIT* http://stackoverflow.com/questions/6203231/which-http-methods-match-up-to-which-crud-methods
&gt; Until you learn about lambdas and comprehensions, then everything starts looking nail-shaped and your code will never be uglier. I've rejected a lot of code reviews for these two alone. &gt; &gt; I am confused, it is like you are saying you are rejecting idiomatic code. &gt; &gt; I have to strongly agree with @SFJulie1 What's wrong with comprehensions? They are well optimized, typically short and concise and easy to read, so why not using them? 
Thanks for the help, did some more work on it and have removed the need to input S etc, changed the spellings and also improved it by removing parentheses thanks.
Worked perfectly friend. Thanks again. 
Readability and the fact its a full stack language for most projects. You can stick with Python and do system administration, web development, mobile apps, desktop apps, etc. Life is nicer with a common code base, particularly in web dev where your system administration logic and web development shares common components. [e.g. Handling database failover]
Path.py is all about making your day to day life easier. It got a temp sublcass allowing for easy work on temporary files and dirs, reading and writting files in one raw with the given path, recursive creation and deletion, creation and deletion ignoring existing or non existing items, in place file modification...
It's just way easier to type, and natural to read. If you do a lot of path manipulation, it beats chaining 1000 of os.path.join().
 import logging logging.basicConfig(level=logging.INFO, filename='/temp/myapp.log', filemode='w') logger = logging.getLogger("program.stuffPart") try: do_stuff() except: logger.exception("Stuff didn't do")
This is perfect.
I don't know exactly why but I'd guess it's because he's reading images off of the disk, so it's probably being bound by the hard drive at that point. You might be able to squeeze some more performance out of it by buffering images into memory before. Also all 4 cores are sharing some resources on the CPU, so it could be an issue with that as well.
&gt; logger.exception("Stuff didn't do") Logger.exception(msg, *args, **kwargs) Logs a message with level ERROR on this logger. The arguments are interpreted as for debug(), except that any passed exc_info is not inspected. **Exception info is always added to the logging message.** This method should only be called from an exception handler. ---- Edit: It's basically the same as the code in the article, except using actual standard and battle-tested python library for it. This is how it looks: (newprod)user@dev:~/Projects$ cat test.py import logging logging.basicConfig(level=logging.INFO) logger = logging.getLogger("program.stuffPart") def do_stuff(): a = [] print a[2] try: do_stuff() except: logger.exception("Stuff didn't do") (newprod)user@dev:~/Projects$ python test.py ERROR:program.stuffPart:Stuff didn't do Traceback (most recent call last): File "test.py", line 12, in &lt;module&gt; do_stuff() File "test.py", line 9, in do_stuff print a[2] IndexError: list index out of range (newprod)user@dev:~/Projects$ 
&gt; self-moderation is a great idea Except for the part where it isn't working at all for this sub.
This is great advice but I don't think it only applies to Python. You can do this same antipattern in almost any language, and the logging practice should language agnostic. 
I don't have any experience with using it, but you might consider a Javascript library like [D3](http://d3js.org/) that does the rendering in the browser as an SVG. This [example from Stackoverflow](http://stackoverflow.com/questions/13204562/proper-format-for-drawing-polygon-data-in-d3) links to a working JSFiddle of a drawn polygon.
Due to some odd circumstances with PHP (it wasn't originally object-oriented, so it had errors instead of exceptions, and while there are now exceptions, the stdlib still uses errors. Unless you want to let an error bubble up, in which case you add a conversation to an ErrorException in your error handler), last year I and two other engineers went through our entire codebase and tightened up or removed every instance of "pokemon exception handling". Not only was this a great idea to save on issues for the future, but we found a bunch of bugs that no one had noticed over the years. And then we put a little test for it in CI, and it never became a problem again. Edit: s/insurance/instance/
&gt;Excepting python then. Because there's nothing simple about the random sprinkling of "static" and "void" and whatever all over the place. Type information itself complicates a LOT. I am a professional Java developer and I love Python; I tell everyone it is my favorite language. However, I don't think this is quite right. The type information in Java is basically the simplest part of writing a Java program. After you have some experience, it isn't really something you have to think about. The exception is when using generics; then it isn't always clear what types you should use where to make the type system happy given; this is the fault of type erasure. Also, the additional complexity that type information adds does confer some benefits. It isn't quite fair to criticize a language's structures without mentioning that they are useful for something. &gt;That is the point he was making. In Java though you have to choose between LinkedList and ArrayList and none of those have a clear shorter syntax making it the "no thinking default". I don't see this as such a strength. Of course, having a well optimized vector around is fantastic, but I don't see why it shouldn't be side-by-side with an implementation of a linked list. They are different things and each has their place. Pretending that there is only one list type that is useful to programmers is a bit naive. I agree that it would be awesome if Java's most frequently used collections were better supported by the syntax, but it really isn't so bad; it is just a matter of spending a bit of time learning the syntax. I think it is pretty obvious what this means: LinkedList&lt;Integer&gt; ll = new LinkedList(); The real pain is when you want to instantiate a list that contains some elements from the start. We shouldn't have to resort of external help for this, but Google Guava makes it a more pleasant experience. 
There's nothing wrong with the general concepts, it just makes it easier to write code that's hard to understand. Dumb example: print max((square for square in (num**2 for num in numbers if num &gt; 0) if square % 2 == 0), key=lambda s: str(s).count('0')) Should perhaps be rewritten to: def num_zeroes(num): return str(num).count("0") squares = (num ** 2 for num in numbers) even_squares = (num for num in squares if num % 2 == 0) print max(even_squares, key=num_zeroes) While I don't fully agree with the points made by that comment, I think it's absolutely true that list comps and lambdas make it easier to write confusing code, refuting the original point: &gt; It's fairly difficult to write code that is incomprehensible. It's much easier to make it clear and simple.
Yep. I was caught unawares by this same problem in 1988 in PL/1. Now where did I put my cane...
Yes, basically Python has an incredible weakness when it comes to exception management.
Not so much Python per se, but some (many?) Python programmers.
"Hello world"
&gt; You can do this same antipattern in almost any language ...and some languages don't even offer you a stack trace or have logging in their default libraries.
Mostly that it's a relatively easy language.
basically, I am trying to create an Xaxis that looks similar for my plot, displays "Jan 14". Tried passing a list of strings generated from strftime that were in that format but bokeh line class/function doesn't like that. I get a blank plot. If i try to pass a list of timedate elements for my X axis, I get an incomprehensible axis as seen in the top graph here: [link](http://bokeh.pydata.org/en/latest/tutorial/solutions/gallery/stocks.html)
Is this where you are posting your releases? https://geekhack.org/index.php?topic=51252.0 Didn't realize there was so much keyboard customization out there. Need to check some of this out later.
The kind of business where I'm not making money yet. It's all expenses at this point :-/ 
You should mention how to access and manipulate the variables in the QML using the rootObject(). IIRC you can't just do: rootObject().rectangle.color = 'grey' You must first declare a function in the QML and then use that function to change the variable. EDIT: [Another way to do it.](http://stackoverflow.com/questions/14939212/how-to-find-property-and-change-value-in-qtquick) I liked the function way better because it looked cleaner on the Python side, but was probably wrong for a hundred reasons.
thanks for sharing, you can use a dictonary instead of elif {'gmail": 'smtp.gmail.com', 'aol': 'smtp.aol.com'}
grate game and code, thanks for sharing
..ish. But trying to convince a boss to add that complexity to a big legacy product is hard :P
My favorite, I call this the "Fail to fail pattern"
I have no problem with people asking for help in /r/learnpython, but I too am rather annoyed that all those "How do I do X" posts end up here in spite of the sidebar. Hoping to see you as a contributor. :)
Hmm, while I see that as a sign you're a friendly and helpful person, I disagree that it's the right path to go. It is implicitly encouraging people to keep ignoring /r/learnpython and post here, and encourages beginners to beg for help in all the wrong places instead of using google and reading documentation. I would prefer to refer them to where they could find the information themselves, but I would definitively tend to lock and delete threads that clearly haven't read the sidebar.
This is exactly what I cam here to post. Yes, please, just use `logger.exception()` instead of hand-rolling your own poor version of it.
True. You could also just define add off to the side for later reuse: add = lambda a, b: a + b sum = reduce(add, xrange(5)) Of course, we'd want sum to work for all inputs: sum = lambda xs: reduce(add, xs) I do like Python's ability to skip the zero input for this. Haskell's folds don't allow that, though there might be a version somewhere that uses mempty somehow.
I'm curious about this, can you give an example?
Perhaps I'm naive, but what does coming from full-stack JavaScript have to do with selecting a Python web framework? This is a serious question. Also for whatever it's worth: now-days I like Django &amp; Pyramid for Python web development. 
This is awesome, but see [this comment](http://www.reddit.com/r/Python/comments/2tuhc1/the_most_diabolical_python_antipattern/co2gjmz) to improve it.
[Image](http://imgs.xkcd.com/comics/ten_thousand.png) **Title:** Ten Thousand **Title-text:** Saying 'what kind of an idiot doesn't know about the Yellowstone supervolcano' is so much more boring than telling someone about the Yellowstone supervolcano for the first time. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/1053#Explanation) **Stats:** This comic has been referenced 3032 times, representing 6.1214% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_co2uwbw)
What's the alternative behavior, though? I mean what is a situation in which you pass a string to something that expects an iterator, but you don't want to iterate over it?
Not to mention byte strings and unicode strings. They look the same, and respond to pretty much all the same methods, which means they can often hide subtle bugs that are only eventually caught further downstream.
&gt; I mean what is a situation in which you pass a string to something that expects an iterator, but you don't want to iterate over it? Many errors come from the fact that programmers are not perfect; ideally the language provides a safety net. It's unlikely you'd deliberately choose to pass a string to something that wants an iterator and not want it iterated over, but you might accidentally type the wrong name as an argument. def copy_list(self, list_of_stuff): for x in list_of_stuff: if meets_condition(x): self._existing_list.append(x) def main(self): list_name = "blah blah blah" list_names = ["x", "y", "z"] self.copy_list(list_name) # oops, auto-complete picked the wrong one and I didn't notice This is an example where the wrong thing is done, but no error is thrown and may never be detected. Even the right type of data ends up being stored. But a type-check on `copy_list` would have prevented it.
Yes, I get what language behavior you're requesting. Although people do iterate over strings so I don't know if that would work. But what I meant was, what are *you* trying to do that requires you to check for strings? I mean, what is a situation in which you both (1) are working with a function that expects iterators, and (2) don't want to iterate over a string? Do you have in mind something like: def do_stuff_with_things(thing_or_things): """"thing_or_things: iterable or single element"""" if not isinstance(thing_or_things, abc.Iterable) or isinstance(thing_or_things, str): thing_or_things = [thing_or_things] for thing in thing_or_things: do_one_thing(thing) If so I'd rather that be avoided. It's common in scientific code bases (looking at you matlab) to allow either one thing or many things, but it seems to me it adds unnecessary complexity. It's not that hard for the caller who is only passing one thing to wrap it in a list. Seems like an example of "special cases are not special enough to break the rules". Edit: nevermind, I get it. Thanks /u/kylotan
I sometimes like to stick some isinstance()-based assertions at the start of functions, to act as preconditions. Coupled with range checks and the like, it can make things a lot more robust.
Oh, I see. Thanks for the explanation.
I know that PyCharm (and probably many other IDEs) will mark up any code that tries to catch Exception, saying that it is too generic. Very helpful when going through existing code.
Do you have an alternative? As a heavy matplotlib, bumpy, ... user, I am genuinely curious.
This pattern has a name, at least among the developers I know. It's called the diaper pattern, because you catch any shit that falls out. 
It's difficult to explain the errors. I would always get them related to interpolate() somewhere in matplotlib. Unfortunately no, I don't have an alternative. I think for one project I got frustrated and just ended up porting it to a web app that was on the local network. For other projects they have been single lab station installs, so I just install python and create a .bat to run the python script.
&gt;When I was into java I saw people choosing LinkedList incorrectly ALL THE TIME. Most people don't know shit about anything, even what they are ostensibly trained to do. This is one reason why the world sucks. &gt;And in java, choosing LinkedList turns out to be the wrong choice pretty damn close to always. This assertion is very clearly incorrect. Java is just a very general language; how exactly can you claim generally which list implementation is most likely relevant without a bit of context? I use LinkedLists all the time. I also use ArrayLists all the time. Again, each has their place. 
wxPython. Native widgets (and some generic or pure Python), great community and leader, I already know it, and it's one of the few proper nouns that start with two lowercase letters before the capitalized letter kicks in.
I try to make mine in html. It's rare that I need a native gui. But, take a look at kivy.
I'm having an awful time trying to download PyQt on mac. Would you mind trying to guide me?
That's from another reddit thread but I like [this article](http://fsharpforfunandprofit.com/posts/is-your-language-unreasonable/) that addresses the point of using functional programming. Not python, but it is easy to make the parallel.
sounds like [Design by Contract](http://en.wikipedia.org/wiki/Design_by_contract) with some pre-condition contracts. Yeah, I'd say that helps. Once you're beyond beta though and your bugs are pretty much gone, I'd disable/remove them. I think it's said that asserts shouldn't affect any functionality of your code, and that they only catch bugs that should never occur. Basically, you should be able to remove them once your code is bug free and the behavior is exactly the same.
[Installing PyQT5 on OSX](https://gist.github.com/guillaumevincent/10983814)
Not with [the feature I need](https://docs.python.org/3.4/library/multiprocessing.html#multiprocessing.set_start_method)
Thanks! I didn't find that.
I commonly hear that checked exceptions (like what are in Java) are a "mistake". But they are nice in the sense that they explicitly tell API consumers what exceptions can occur--at compile time.
On that list there: How do I create a virtual environment? That's something I've never dealt with before. Thanks.
Slicker than greased owl shit!
Looked there but didn't find anything. 
whenever I use 'except Exception as e:' I like log to an errors file.
I appreciate your help. However: * The logging option for the bot is optional, it can be set to false so the bot won't log at all. How would I go using the logging module knowing this? Is there a way that doesn't involve having to use "if logging_enabled:"? * What kind of tests do you recommend for the functions? (A simple concept would be enough)
Not to mention that ignoring *everything* will hide exceptions that derive directly from ``BaseException`` and are essential to Python's operation, like ``KeyboardInterrupt``, ``SystemExit``, ``GeneratorExit``, and (in 2.7) ``StopIteration``.
Pretty neat. My little chromebook is about to keel over and die though :P
Is there some method for doing the HTML+JS way? I actually started on this path, but then got into simple web server, templating, etc, and thought I'm probably reinventing the wheel. Is there a nice light package that makes it easy to make GUI HTML stuff, without bundling a big web framework?
You'll need to download from here. http://wxpython.org/download.php Thats what pypi links to. https://pypi.python.org/pypi/wxPython/2.9.1.1
There's been plenty of times where I'm pulling apart a CSV file row by row, column by column, and then writing a new CSV at the end based on some manipulations. And then my output has rows with one letter per column. This is presumably not the desired behavior the vast majority of the time you want each cell of a CSV file. Especially when I was first getting into CSV manipulations with Python, it would have saved me a LOT of debugging time and sanity if it had thrown an error at the point where I was trying to iterate over a string and not over a list (the list being a row of a CSV file). You're right that people over strings, but I feel like the instances in which you try to iterate a string when you expected a list are more likely than the other way around. And the sorts of things you're going to do to a string will probably throw an error if tried on a list entry, but as Python stands, a lot of list operators work just fine on a string.
I don't have an answer but man try out the Darcula theme! That white is blinding.
Please see here for the one, true answer to this question :) http://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags/1732454#1732454
"[wxPython](http://www.wxpython.org/) is the best and most mature cross-platform GUI toolkit, given a number of constraints. The only reason wxPython isn't the standard Python GUI toolkit is that Tkinter was there first." -- Guido van Rossum 
I guess the ultimate form of this antipattern is [fuckitpy](https://github.com/ajalt/fuckitpy). It's basically an _error stramroller_, `ON ERROR RESUME NEXT` of Python. It wraps every statement in your code within a try: some code except: pass block. Edit: Please, please do not use it.
It tells you "Hello world"
This, to me, is something that static linters should pick up. They typically don't, but they really *should* fire off a warning.
Christ, some of our colleagues are autistic as fuck...
+1 for PyQt, I like the signals/slot mechanism + Qt Designer for doing the boilerplate work. 
I primarily develop on a mac and fedora and have always used pygtk until recently when I moved to using the new pygobject introspection. On mac, homebrew did all the work installing what I needed. On fedora, well its just yum install. Works like a charm for both environments. Glade for those quick gui design. 
I would love to see something like this as a video installation. You must calculate the time that each frame occurs (or it could be inferred), and instead of the result being a still picture, it is many many versions of the same movie on loop with different time offsets played in a grid like this. So that for most of the length of the movie the screen looks roughly like static, but for a brief moment the given image pops out. 
Just curious, any reason you'd go with lxml first instead of bs? I mean there's no downside besides another include to assume the markup will have errors (I use bs with lxml).
Nope. ~ $ echo '"Hello world"' &gt; hello.py ~ $ python hello.py ~ $ 
You can try pyinstaller.org but I don't remember about matplotlib
Plus, wx has a permissive license.
The reason people are so insistent about not parsing HTML with regex is because we've all tried it when we were too inexperienced to know better and we've all suffered and come to realise that it is just easier to learn to use the correct tools from the start. They are trying to stop you making the same mistake. I use https://pythonhosted.org/pyquery/ which is a wrapper around lxml that gives you jquery-like interface. I'd argue this makes using a parser far easier than even the most basic regex. 
so don't code like a php programmer, got it.
Or `('smtp.gmail.com', 'smtp.aol.com')`, cos you don't need the memory overhead of a dict when you already know that the first option will be gmail. 
Huh... I'm using Sublime-Linter (I believe with pyflakes...) and I never get warnings for this. Clearly a configuration issue...
PyGObject / PyGtk
As an alternative, this will also work with sets and tuples and dictionaries to return True # Python 2.7.3 A = [1, 2, 3] hasattr(A, '__iter__') # Returns True B = "123" hasattr(B, '__iter__') # Returns False
Many people who use my libraries have never touched python (or even a terminal) before. Even "pip install" is a difficulty, which is why I provide the setup.py alternative. I'm not going to complicate their lives with Virtualenv. People who really need a virtualenv will know what to do.
Suppose you had a tree made of lists, which has leaves that are strings. Now you want to traverse the tree until you reach the strings which you want to process... You end up using isinstance(string, ...) (Don't use isinstance on list! What if some are set? or you change your mind on what kind of collection?)
Please do it
An old favourite example why not to use rx on HTML &lt;a href="foo" title="5&gt;3"&gt; Oops &lt;/a&gt;
You can do useful stuff really quickly with Python. To me that indicates how good a certain tool is. It has a short learning curve. Also the clean syntax. I personally prefer indentation. Vast library. More often than not, you can find a good Python package to accomplish a certain task that has very good documentation. Also, love the Monty Python references. I had a blast doing the basic tutorial provided by www.python.org. So funny.
I thought the same thing but figured it didn't really add to the conversation lol 
What do you think about "marker" interfaces on exceptions? Example: class LibraryException(Exception): pass class LibraryIOError(IOError, LibraryException): pass class SomeDomainException(LibraryException): pass def one(): try: some_network_stuff() except IOError: raise LibraryIOError(e) def two(): raise SomeDomainException('oops') So any exception thrown by the library can be caught with `except LibraryException`. 
To be fair, that quote is very old, right? Like maybe 10+ years? Qt and PyQt is very, very good...
If your just doing something quick and simple that you then want to throw away, regex is fine. But if you want to create something long term, that can be extended as needs grow, you will out grow what regex can do for you. Also if you are scrapping whole websites, there is a great tool for that http://scrapy.org/
I once taught a few guys how to code, and one day after work, I decided to show them this magical thing called the try/except pattern. A few weeks later, after we had all gone our separate ways, someone chatted me - "Hey, this program isn't doing what I wanted it to do, I'm getting weird output." He sent the script over, which was making calls to an really terrible API we were required to use for our projects, and I got to work. Yes - every single call to this API had been wrapped in a try/except: pass block. Dozens of them. And now, whenever I teach someone about Python, I spend time on anti-patterns and why they shouldn't make those common pitfalls.
I believe that Pylint will also take issue with code like his as well, though /u/ModusPwnins caveat applies there also.
From a quick google search it seems the quote came out at least in 2005 if not earlier
This is how I do it. If there is a better way, I would really appreciate if someone could show how to do it. It doesn't feel quite right, but it works. The main issue I have with this will be explained later. So, in your .qml you have the very basics shown here: import Qt 4.7 Item { id: root property real a_variable : 0 width: 210; height: 210 function change_something(a_param){ root.a_variable = a_param } } Then in Python, you would do this: your_qml_view.rootObject().change_something(a_param) This will call the change_something() function and pass it a_param. Then, the qml will now assign a_param to root.a_variable. Somewhere else in your qml file, you will have: Behavior on root.a_variable{ //! Code is run when root.a_variable changes } My big problem is that I have no idea where the change_something() function actually is. If you call a dir(your_qml_view.rootObject()), change_something() doesn't show up as a method. It must be looking up the function somewhere, but I don't know exactly where. My understanding is incomplete and it irks me. 
Other options for "light and fast" [cherry.py](http://www.cherrypy.org/) and [bottle](http://bottlepy.org/docs/dev/index.html) are both microframeworks. Usability wise, Flask and Bottle write about the same for simple apps, Bottle is better if you need Javascript output, Flask is better if you want a support library with a lot of tools. Cherry I've used in *very* limited contexts and would put it lowest on this list.
for ... else is strange. Useful, but still rarely used. I would also add *generator expressions* next to the list comprehensions. They are especially useful for initializing set, list or dict.
This is great! Thanks for writing it up and sharing, i didn't know about nearly any of those.
I was thinking of doing a follow up post on more uses of `with` sometime soon. Also thinking of doing more with the collections lib, and also decorators (which I did not cover at all). If anyone has other suggestions of things that they would be interested in being covered in some follow up posts on, I am all ears.
I once had a bad experience with super and multiple inheritance. Accessing super-class methods is a feature most desired in initialization code, but initializers other have different argument list. It imposes requirements on base classes, and can make behavior hard to predict, when base classes are not collaborative.
Your information about the PyGObject/PyGI documentation and the Py2exe development are outdated.
&gt; Conditional Assignment I think this should be called "[Conditional Expressions](https://docs.python.org/3/reference/expressions.html#conditional-expressions)" since it's usable in more than just assignments. Might also be worth pointing out that it's similar to the `a ? b : c` ternary operator in other languages.
There aren't any advantages apart from less quotes and commas, I believe these people miss their `%w(x y z a b c)` from Ruby.
Now I see the right code, have you fixed it? There is my fault too, I've skimmed over the text, looking only at the code. Still, I think, that you could add samples with initializing dict from the generator expression. For example, this code can be used to "reverse" dictionary (swap keys and values) a_to_b = {1: "a", 2: "b"} b_to_a = dict( (v,k) for k, v in a_to_b.iteritems() ) but there are many more uses, of course.
i've never seen this. and in python it's much easier just to do: `list('xyzabc')` if you really want the list.
Might want to use a list comprehension instead: [c for c in some_str] But if you want to iterate on the characters of a string... You just do that on the string itself (in 2.7). I haven't seen a good reason to ever need to make a string into a list.
In some cases it might be easier to read too. Also, for single characters, doing ``list('xyzabc')`` is even easier.
Split allows you to do stuff like choose which character split the string by (the default is space). List makes every individual character an item in a list. So, if you split 'hello there' you get this: In [4]: 'hello there'.split() Out[4]: ['hello', 'there'] Whereas with a list you get this: In [5]: list('hello there') Out[5]: ['h', 'e', 'l', 'l', 'o', ' ', 't', 'h', 'e', 'r', 'e'] If you add an argument to split you can choose which character you want to split the string by: In [7]: 'hello-there'.split('-') Out[7]: ['hello', 'there']
Sorry one final suggestion. So the script was interrupted for some reason (I think the error was that the session timedout or i was somehow logged out of gmail). I re-ran the script, and it took basically just as long to go through the same attachments and mark them as duplicates as it took to download them in the first place. It would be helpful to be able to skip all of the attachments that were already downloaded or more quickly go through duplicates, that but I can't think of how that would be done. 
My understanding is that BS was sort of a hack using regexes that was later extended to wrap the lxml parser. I'd rather use xpath than their custom syntax. There's also pyquery if you prefer jquery syntax. http://lxml.de/elementsoup.html https://www.reddit.com/r/Python/comments/1x8oar/a_quick_note_on_my_pleasant_experience_with/cf9afvv 
that makes way more sense. edit: also, naming any future male child 'jimbob'
&gt; I want to learn coding back again within a week and need to get a web project online within 2-3 weeks. Kindly help how to go forward. I will pray for a miracle, yes. I mean seriously, what are you talking about? To me, this is essentially no different than saying you want to learn coding within *this hour*. Have you read [this](http://www.ashidakim.com/zenkoans/91thetasteofbanzossword.html)?
Seconding the opinion of metaperl... An impressive array of features. I went through the intro document. Extremely well written.
edit 2: originally OP wrote do something like `'snth'[:]`. the list comprehension will work, but `list('snth')` is simpler. this (`'snth'[:]`) actually returns a `str` type, not a list. it's just ~~a copy of the string~~ the exact same string. in fact, i can't think of a situation you'd ever need/want to do `[:]` on a string because strings are immutable. you generally only want a copy if you're worried about changes, but no changes can occur... edit: with some crappy cursory testing, `s[:] is s` evaluates to `True`
This is really rude.
Stopped me from reading too.
Yeah, I was aware of this already. The attachment has to be downloaded to check the hash. That is where the delay is coming from. I'm working on something. ;)