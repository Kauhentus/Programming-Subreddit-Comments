Why are you still using Tkinter?
 1. [Are you sure?](http://google-styleguide.googlecode.com/svn/trunk/pyguide.html#Indentation) Do you mean that they use 2-space internally, but 4-space for public projects? That would seem strange, but interesting. 1. He *said* that he wanted to make clear which code was open source, to avoid any legal issues. At any rate, if you are right, then I adduce Google rather than Guido. My argument stands.
What's the difference between a function that returns a new object and a function that returns an existing one? If you say 'memory', then what about `list`/`dict`? In a garbage-collected language, there is no reason to distinguish between classes and functions at the point of use. The capitalization convention is a legacy from C++, where the constructor implies a future call to the destructor in the same scope. In old C, structs were typically not capitalized.
The PEP is inconsistent: In the examples, the application returns (body, status, headers). In "Specification Details" the order is required to be (status, headers, body) which makes a lot more sense. I found some typos, too. The concept however seems reasonable. 
I can relate. I moved from web development to programming in a scientific environment, and it's just not as fun programming wise. I mean, we do much more interesting things than most web sites, but on the web the technology itself is constantly changing. Here it's scripts and very simple C.
xrange
Yes, generators that implement --len-- know their own length (I can't use the runderscores becaue reddit uses that as markup :-D).
"However, due to changes in the language, the WSGI 1.0 protocol is not compatible with Python 3." what changes exactly are that? anyone can recommend further reading...?
It's terrible if it's expensive. It's not terrible if it's cheap. In any case, if it's not a known length, QProgressDialog can show a "progress of undetermined length" bar (the ones that look like an old cylon eye)
You could try http://pyjs.org
What about threads? What about loggers you don't know anything about? For this little bit of more explicit code you make it incredibly painful to use. If you would show at all a good example of non trivial code using your proposed API and could show the advantages I might even agree with you but this shows absolutely nothing. Of course magic should be avoided but burning everyone at the stake for using magic is not the way to go. It seems that it's becoming more and more common practice to do that, probably because it's that much easier than actual criticism based on research.
Should be `(body, status, headers)` everywhere. Reasoning is that this is the most common way to create response objects currently so you can do something like `ResponseObject(*return_value)`.
string handling: binary vs unicode
&gt; I send you a mail today. Feel free to ask back if you need more. Great, I'll take a look at it. &gt; Or any method calling into basicConfig() such as logging.warning, logging.error etc. Yes, it's the same problem. This will be fixed in Python 3.2 and 2.7.1, but only occurs if you call into basicConfig() via logging.warning() etc. from multiple threads. This is not especially good practice (logging should be configured before threads are started) and logging.warning() and friends are clearly documented as convenience functions for casual/very simple usage. I'll certainly update the documentation for 2.7.1 and 3.2 to warn about this issue - but it's not really going to affect people who follow good or reasonable practice when using logging with threads. &gt; I wrote a couple of custom handlers for logging [...] So don't tell me I haven't tried. Sorry, I didn't know. I'll take that back. &gt; Logging would be a library I would not keep in a standard library. Actually, I disagree, because logging is an *infrastructure* service. While choice is generally a good thing, ultimately nobody is helped by having N different ways of logging, especially if third-party libraries all adopt a different one of the N ways, and you have to integrate several of them into a single application. Of course it might not be too bad if those N logging methods considered interoperability, but if they are not in the stdlib, interoperability is at the whim of the developer who developed that particular logging library. And in any case, it involves more (unnecessary) work for the developer using those libraries. &gt; The "Logging is not cool enough" [...] was supposed to be taken as a joke [...] Please don't hate me for failing at being funny. I don't hate you, or anybody else. Notice that I said that your boosterism was "off-putting", which pegs it at the level of a minor irritant. But your abf√§llig tone has the potential to upset people like myself and Massimo, whose hard work you criticise in an off-hand way, as if it were barely even deserving of your contempt. My "charm school" comment also alludes to this - that people have a plethora of views and approaches determined by their likes, dislikes and experiences, but are almost always deserving of respect no matter how much you might disagree with their views and design decisions. One's comments about other people's work should reflect that respect. Perhaps you don't mean to offend people, but that's the effect you sometimes have. Maybe you could take some tips from your Pocoo colleague Georg Brandl, who comes across as not at all abrasive, despite being probably just as clever as you and having made some strong software contributions, just as you have. BTW I have absolutely no affiliation with Massimo or web2py, having never used it, but the strong chorus of support from his users should show you that he is making their world a better place, and that's great for them and him. The world is big enough for several approaches and some are of course better than others, but there's no accounting for personal taste and it's each to their own. &gt; Performance of either logging or logbook is hard to measure because it depends a lot on the setup. Exactly, and I'm not really interested in a performance race. The main point is that a stdlib logging call takes of the order of a few **microseconds**, which is tiny in the overall scheme of things; of course there could be situations where a lot of logging calls amount to a perceptible overhead, but the answer would be to profile and investigate rather than tar everything with a broad brush. &gt; None of these things here are wrong. Some of them are opinion dressed up as fact, e.g. "why does nobody like logging?" where you assume that the views of you and your fans accurately represent everybody. Some of them are half-truths or stretching a point, e.g. "logging.warn and friends are not threadsafe" could be qualified by "in some versions of Python, and when you use convenience methods, intended for casual use, from multiple threads in a particular way". Without the qualification, it comes across as "Woohoo - stdlib logging has thread safety issues, keep away!" &gt; The default configuration of logging is to not do logging. I don't know why that's the case, but there is probably a reason for it. It's based on the same philosophy whereby Unix programs generally keep quiet unless they need to, or are asked to, say something. Perhaps you think this point is just a random artifact of how stdlib logging works - but no, it was a conscious design decision. To illustrate why: if I write an application which writes output to the console and uses a library which does logging under the covers, I don't want my application's output to be (by default) interspersed with logging output from the library. That would certainly violate the principle of least surprise; then, I would have to take explicit action to shut off logging, i.e. I would have to change the default behaviour. It's my assessment that people would more often prefer silence as the default behaviour, rather than verbosity. Of course in a web application there's no console to worry about so perhaps it doesn't affect you; but there's more to development than Web development, and stdlib logging has to cater for other types of developer, too. &gt; Still it means that the defaults are something you have to change which is why not enough people use logging. I find that "which is why" connection you make a little bizarre. You're effectively saying that the benefits that logging offers are so few that even adding one or two lines of code (to change the default configuration) is too much work, presumably for someone who is going to write dozens or hundreds of lines of code calling all kinds of APIs to do all kinds of things. &gt; The bad default configuration is something that I have no problem with You haven't said why it's bad - it's just a value judgement you're making. The default of silence is in line with the principle of least surprise. Consider: #lbprivate.py import logbook logger = logbook.Logger(__name__) def private_library_function(): logger.debug('Debug') logger.info('Info') logger.notice('Notice') logger.warning('Warning') logger.error('Error') logger.critical('Critical') #lbmod.py from lbprivate import private_library_function def library_function(): private_library_function() #lbtest.py import logbook import lbmod import sys logger = logbook.Logger(__name__) handler = logbook.FileHandler('test.log', 'w', level='WARNING', bubble=False) with handler.applicationbound(): print &gt;&gt; sys.stderr, 'Keep this line with the next, no gaps wanted' lbmod.library_function() print &gt;&gt; sys.stderr, 'Keep this line with the previous, no gaps wanted' If I run the latter script, noting that I want only WARNING and more severe messages in the log, then test.log is perhaps as expected: [2010-09-16 09:31] WARNING: lbprivate: Warning [2010-09-16 09:31] ERROR: lbprivate: Error [2010-09-16 09:31] CRITICAL: lbprivate: Critical but I get spurious output on the console: Keep this line with the next, no gaps wanted [2010-09-16 09:31] DEBUG: lbprivate: Debug [2010-09-16 09:31] INFO: lbprivate: Info [2010-09-16 09:31] NOTICE: lbprivate: Notice Keep this line with the previous, no gaps wanted So to my way of thinking, *your* default is bad. The first thing I think is, "what the heck is lbprivate"? &gt; For instance see how Flask uses logging currently. And I am perfectly fine with that, no issues at all besides the fact that this setup only works for my application and not a library my application might be using. That still goes to its dedicated logger setup. There are ways of configuring libraries for logging, see relevant threads on Django-developers to see the discussion about how logging in Django should be configured, as an example. &gt; The "nobody likes logging" came from discussions with many people to find out why so few people are using logging. Unfortunately I can't point you to my blog right now because it's still offline, but I had an article on there why I encouraged people to use logging more and I got all kinds of bad replies there that logging was slow, to hard to use and often misused. People giving you bad responses could be for a myriad of reasons; lots of people love to bitch, see Brett Cannon's post about this [1]. If people are complaining about how other people are misusing logging, they should properly take it up with those other people. I can't believe that you are constantly talking to people about logging and still constantly hearing bad feedback. The next time this happens, try asking this: "Did you ask for support on the mailing list? Did you log an issue on the bug tracker? Did you contact the maintainer directly? What happened?" and see what response you get. Most likely, they never bothered. Andrii Mishkovskyi created a Wiki page [2] in July 2009 with complaints about logging, each of which I addressed and invited responses. There have been very few responses at all - especially none from him - and no substantive criticism that I couldn't answer. [See sibling comment for your web app logging problem, there's a Reddit limit on post size] [1] http://bit.ly/os-complainers [2] http://wiki.python.org/moin/LoggingPackage
[continued from previous discussion, see sibling comment] &gt; I don't know a setup of logging that would work out for me. But maybe you do and could share. Say I am a library called by anyone and use three or five loggers without any handlers. Now in the same Python process are two different web applications, each independently but using the same library. How can each of these applications have their own log where all logging messages from that library are redirected to the correct one of these application's log files (the correct one is the one where all calls were issued by the same handling thread) including additional information such as current IP and HTTP request method. I tried, I failed. Okay, do these steps: 1. Paste from http://gist.github.com/582257 into webapplib.py 2. Paste from http://gist.github.com/582259 into webapptest.py in the same folder 3. Run python2.4 webapptest.py (or later Python 2.x) 4. Examine app1.log and app2.log. You'll see that app1.log contains only app1 messages, likewise app2.log only contains app2 messages. I specified using Python 2.4 to show that this is not new functionality. I will post a version of this soon explaining/annotating in more detail, on the Plumber Jack blog: http://plumberjack.blogspot.com Of course it's a simulated example, but you should be able get how the logic works and apply it to your actual scenario. &gt; I will file bug reports for these if you want me to. It just means more work for me which I so far postponed. If the problem is because of missing lock acquisition and release in basicConfig(), then there's no need to log a bug report as that problem's already been addressed. You can test that by just copying the basicConfig() from the py3k or release27-maint branch into your Python's copy of logging, then retrying. If it still shows up as a problem, then please file a report just referring to your LodgeIt snippet. If it doesn't, then please stop referring to thread safety issues in stdlib logging, unless you add the necessary qualifications. 
I would supposed that `(status, headers, body)` was more reasonable, but that is likely just the WSGI reflexes talking. Give me 5 minutes and I'll get over it.
Small GUIs for daylight-work. Win32. It comes with Python, and I don't want to introduce any multi-megabytes dependency if I can avoid it. Besides: PyQT is out of the question for being GPLed. wxPython, pyGTK... I don't like neither GTK nor wxWindows. PySide... might use that in the end... when the total size of the installers gets more or less the same as PyQT's (+170 MB vs 28 MBs, WTF?!?).
with regards to the website ... I think you might want to start with terms and language parlance: http://www.markus-gattol.name/ws/python.html#basics
Quote from web-sig: &gt; The motivation is that you can pass that to constructors of response objects already in place. &gt; &gt; response_tuple = response.get_response_tuple() &gt; response = Response(*response_tuple) &gt; &gt; The order "body", "status code", "headers" is what Werkzeug and WebOb are currently using. Django has (content, mimetype, status) as constructor but if they detect a list/dict on the third parameter they could assume that mimetype referes to the status thus they have a proper upgrade path. 
Plus, websites actually have something you can show curious family members. &gt; Yeah mom, we launched this awesome website today, I'm so proud of my team. See it? Sure, it's at www.example.com vs &gt; Yeah mom, we finished up the statistical analysis of water salinity levels in Siberia. See it? See what? Siberia?
What do you mean?
With bad defaults I am referring to things like that: &gt;&gt;&gt; from logging import getLogger &gt;&gt;&gt; mylog = getLogger('My app') &gt;&gt;&gt; mylog.warn('A warning') No handlers could be found for logger "My app" Or that if you use `basicConfig()` without anything else passed, it does not give the time which I consider a very useful information. The `SMTPHandler` uses the same default formatter which I think is not very suitable for mailing. I know that currently flask users that want error reports to their mail handlers copy/paste the logging setup I outlined here: http://flask.pocoo.org/docs/errorhandling/ I think that shouldn't be necessary. In fact I usually even subclass the `SMTPHandler` to override the subject, why can't the formatter do that? &gt; I find that "which is why" connection you make a little bizarre. You're effectively saying that the benefits that logging offers are so few that even adding one or two lines of code (to change the default configuration) is too much work, presumably for someone who is going to write dozens or hundreds of lines of code calling all kinds of APIs to do all kinds of things. I like logging, I see the benefits, I wish people would use it more. So far what I've heard when I proposed adding logging to a library the reply was that it's too hard to use and on asking it boiled down to the defaults being unexpected. Especially the warning message when no handlers are in place. &gt; I can't believe that you are constantly talking to people about logging and still constantly hearing bad feedback. Due to the activity of logbook on github recently I still get a lot of feedback. When I tweeted my failed attempt of configuring logging I got so much feedback that I thought it would be a good idea to rethink logging. If people wouldn't have responded to that I would not have continued with Logbook in the first place. &gt; Did you log an issue on the bug tracker? Did you contact the maintainer directly? So here is the thing with stuff in the standard library: If things change in Python 3.2, that does not help me a lot when the code I use have to stay compatible with Python versions down to 2.5 (until recently 2.4).
This is actually quite neat, I never considered abusing Filter for record processing. Will play certainly play around with that. &gt; If it still shows up as a problem, then please file a report just referring to your LodgeIt snippet. If it doesn't, then please stop referring to thread safety issues in stdlib logging, unless you add the necessary qualifications. I am pretty sure that every marketing material might not be 100% honest. threading.warn was not thread safe at the time I had that presentation, so it was certainly not wrong. Might not have been 100% honest, because it's only happening in rare circumstances and can be countered, true nonetheless :) Just to prove my point that I actually liked logging a lot in the past: http://lucumr.pocoo.org/2008/1/18/error-reporting-in-wsgi-applications //EDIT: and that is a yes in that I will not bring up that threading issue as an argument against logging :)
Maybe I'm nitpicking, but it should be `header` (singular), because there is only ONE header for a HTTP request or response. The header is made of SEVERAL fields (each with a name and a value.) But almost everyone make this mistake anyway..
[ask and you shall receive](http://lucumr.pocoo.org/2010/5/25/wsgi-on-python-3).
Actually, the key answer is here: no, you can't really run python in/on the browser. There is PyGame, which might be fun for you to try out, but if you want to use the browser as a deployment platform, you're going to need to learn javascript and html and css.
"Yeah Mom, we launched this awesome website today. It allows people of Siberia to check in real time the water salinity level in their water. It is based based on a statistical analysis package that I wrote. They can even zoom in using google map and discuss results with then neighbors online". It seems to people people who do research with public funds have to try make their results publicly accessible, building dynamic website today is trivial and costs nothing. Why would anybody build an app that is not web based, that requires installation, thus limiting its availability (except for intensive real time graphics such as games)?
No, the problem starts when you start overcooking a solution. When was the last time you actually had to do this? How many times have you actually had to do this?
 man find
"Also, can you bring me a sandwhich plz?"
The HTTP RFC itself names it headers because it consists of "general-header (section 4.5), request-header (section 5.3), response-header (section 6.2), and entity-header (section 7.1) fields". So I think we're fine :)
So is your problem related to Massimo defending and promoting(if you want to call it so)web2py.... He has put a lot of effort in it and the best part here is that inspite of you criticising it over and over again , web2py is getting stronger and bigger every day. Hey by the way I started using it after reading your comment. &gt;I don't have myself under control when it comes to web2py, I give you that. well we all know that.. lol.. does not bother any of us whether you are in control or not...
It's nice they finally figured out a Py3 way to do wsgi; and some of the improvements are nice (eg: eliminating start\_response). One thing I take issue with though is that they seem to have eliminated "wsgi.file\_wrapper" (or "web3.file\_wrapper" as it would be called if it existed). Does anyone know why it was removed? If anything, I was expecting an extension, eg a "web3.file\_range\_wrapper" which supported offset and length kwds, so http range requests could be efficiently served. Removing it entirely seems a step backwards for serving large files.
The full sentence is: "HTTP header fields, which include general-header (section 4.5), request-header (section 5.3), response-header (section 6.2), and entity-header (section 7.1) fields," (RFC2616) If you look closely it is almost always "header fields" or "header field". The expressions "general-header", "request-header",.. each refer to a set of fields and are part of the syntax description. So I don't see how it contradict what I said. I might be wrong though, but please post a more precise excerpt then. *Edit*: phrasing.
You can do this: \_\_len\_\_ (`\_\_len\_\_`) or simply `__len__` (\`_\_len\_\_\`).
This comes across as asking for a free lunch. Sometimes you just have to set aside time to find the best of breed and get to know the code you are using. &gt; Often, the only way I can really tell if a module is going to work well is to actually try using it. Generally this has to be in a real program (I find toy examples both frustrating to write and uninformative), which means that if I have picked poorly I may have wasted a bunch of time and effort. Exploration has a cost in software projects, and sometimes software projects fail (sub-project in this case). That's nothing new. You can't really expect, even with Python stdlib modules, to import some code and have it work great on the first shot. A good example in light of recent chatter is wsgiref in Python 3. It's a stdlib module, thus on the author's immediate radar, but without significant investigation of what it's doing, he would apparently run into some big issues to just drop it into his project. He does later state that the confidence in the stdlib is misplaced, but I think he's vastly understating it. I'm not saying the stdlib is bad, I just think blindly choosing *anything* without some understanding of what it does *will* come back to bite you.
Did that really require 11 screenshots? **tl;dr**: install DreamPie, run "Add Interpreter" as Administrator, select your ipy.exe path.
http://www.freefoto.com/images/09/09/09_09_5---Sandwich_web.jpg
There are ongoing updates :)
Yet the chapter is called "message headers".
Good to hear.
&gt; I never considered abusing Filter for record processing. You call it abuse, I call it minimalist design. The mutability of records by Filters has been a documented feature in logging since the earliest release, and it was never a hack. I *could* have created another class called Processor with a process() method, I suppose. But class proliferation is for Java, and perhaps for logbook too? ;-) In the logbook package folder (for 0.2), ack-grep --python class | grep -iv Test | wc -l =&gt; 144 In Python 2.6 logging package folder, ack-grep class | wc -l =&gt; 73 (No offence intended, and I didn't look very closely at all the classes, and no doubt they're all there for a good reason.) &gt; I am pretty sure that every marketing material might not be 100% honest. Sure, that may be true for marketing in general, but *you* are responsible for your marketing. While it's legitimate to market using others' weaknesses as well as your strengths, make sure your assertions stand up and are not based on minor technicalities. If you have to bash others using such dubious tactics, how confident are you of the quality of what you're marketing? &gt; Might not have been 100% honest, because it's only happening in rare circumstances and can be countered, true nonetheless Exactly, that's why I called it FUD. &gt; I will not bring up that threading issue as an argument against logging Even before the patch to basicConfig, it was not a real showstopper issue. Doesn't Werkzeug have bugs? For example, there's your Werkzeug issue #438, which prevents Werkzeug from supporting multiple cookies in the test client. That *is* a bit of a showstopper if you want to test with a session cookie + a CSRF cookie at the same time. You closed it 7 months ago with a fix that wasn't a fix, I reopened it 6 months ago, and it's still open. And yet, I don't go around saying things like "Werkzeug? Ha! Cookies can't be tested using real-world scenarios", which is also, technically, true ;-) It's a trivial fix, too, for #438 - just a typo to correct. So, perhaps you're so busy that you can't fix a little bug like that - busy duplicating stdlib logging functionality in a whole new project - wait ... what?? If you feel any sense of contrition about your underhand marketing tactics, then I hope, when your blog is back up, you'll publish a retraction :-)
The french, Portuguese and german fixes: http://codepad.org/vpLufw7q
There are a number of things you can do with a class but not a factory function. For example, inheritance and isinstance().
Why is it wrong for him to attack web2py? He's obviously coming from a position of expertise, he isn't just the author of Flask. That's the kind of discussion you expect to see here. If uninformed people are talking crap then that's different, but this seems to be a bad example.
CherryPy is a pretty awesome framework to get the hang of Python web programming. You can have a hello world site up in like 30 seconds, with just one hello.py file 
Fair enough. I used Tkinter for a while, but I never really liked its design.
I agree with you here, mostly, I apparently missed all these badly argued reviews. It does still seem like we draw a different line between what constitutes a fair review and what doesn't. Especially responding to a post like this one, it's perfectly reasonable to give feedback in the style of #1, especially when trying to give a framework users perspective. I just seems that these same arguments about reddit hivemind bias are made by php supporters or supporters of frameworks/technologies that are actually objectively inferior to others and I find most of them suspect, but I'm willing to believe that web2py gets a bad rap on reddit and I just haven't seen or noticed it.
Consuming and publishing web services (soap with wsdl for example) are much clearer in ASP.NET than in Python as far as I've seen.
&gt; "No handlers could be found for logger" message. This was discussed on python-dev when logging was being reviewed for inclusion in stdlib, and it was felt that it was reasonable to leave it in, even though I had some reservations about it. That's especially in view of users possibly misconfiguring a new library in its early days. But you can hardly gripe about that single one-off message, in light of the logbook example I gave earlier, when logbook *by default* produces unexpected output - including DEBUG output - which is not anything the end user is really interested in. &gt; Or that if you use basicConfig() without anything else passed, it does not give the time Yes, but you *don't* have to call it with no arguments. The documentation is pretty clear about what you need to do to get the time in, and it's not a lot given that you are making the basicConfig call anyway. &gt; The SMTPHandler uses the same default formatter Okay, but it's not hard to specify a formatter that does exactly what you want. It's not really that big a deal, given that the format of logging emails is likely to be application-specific much of the time. The library default is perhaps minimal, but if I'd given a default configuration as in [your example](http://flask.pocoo.org/docs/errorhandling/#email), then no doubt someone would have griped that something was missing, or that they would have preferred the lines in some other order, or ... that's bikeshedding I'd rather avoid. &gt; why can't the formatter do that? It could, but as that's not appropriate for a general formatter, that would have meant adding an EmailFormatter class with a getSubject() method. Chances are, a user would have to subclass that anyway if they wanted to customise the subject ... so what have you really gained from this approach? &gt; I like logging, I see the benefits, I wish people would use it more. If in the above statement when you say "logging" you mean "stdlib logging", I'm astonished. Astonished that despite holding this sentiment, you've started logbook development, and are telling everyone how awesome it is and how much better than stdlib logging it is. &gt; So far what I've heard when I proposed adding logging to a library the reply was that it's too hard to use and on asking it boiled down to the defaults being unexpected. Especially the warning message when no handlers are in place. That's a little overblown, if you ask me. There are plenty of projects that use logging, apparently without their teams having nervous breakdowns - e.g. SQLAlchemy, Pylons, Tornado, GAE etc. and even Flask. So, to such library authors, who moan about how logging is hard to use and how they don't know how to avoid getting that "no handlers found" message, direct them to the [relevant documentation](http://docs.python.org/library/logging.html#configuring-logging-for-a-library) which specifically tells them how to avoid that message, then tell them about all the friendly people on comp.lang.python who can help them out with issues whether trivial or complex, no problem is too small, and then tell them that if they have found bugs, they are free to open an issue on bugs.python.org where their issue will be triaged and assigned to me within a day or two of raising it, and under most circumstances, they can expect a follow up from me in a few days after that including a resolution (which is most often closed:fixed - check the tracker yourself if you like). And, feel free to name names - who exactly are these library authors? I'm quite willing to go onto their mailing list and offer to help them with their logging issues, provided that they look at things in good faith and with an unjaundiced eye. &gt; When I tweeted my failed attempt of configuring logging Are you trying to be funny again? You were able to describe your problem meaningfully in 140 chars? And the feedback you got was more meaningful than "I agree, logging is crap, let's write our own LOL"? Face it - the feedback you got to your tweet was from a self-selecting group of people who think like you and/or like your software and therefore follow you on Twitter - that's not necessarily representative of the wider community. When I saw recent comments from Ronny Pfannschmidt and Daniel Neuh√§user about logbook and logging, I can't help feeling that they're parroting their hero. Perhaps they've independently reached the same conclusions as you, but then why are all their comments long on generalities and short on substantive argument? They don't even declare their interest as Pocoo members, something which may not be known to Redditors in general. So, if this failed attempt of configuring logging that you tweeted about was the same one you presented to me, and to which I responded with a working solution after doing 5-10 minutes work on it, what does that tell you about the value of their responses? You've said numerous times that stdlib logging is not really suitable for Web applications, how it's hard to get request specific / thread-specific stuff into the logs etc. and yet I have relatively easily demonstrated to the contrary (I think). So, will you remove all the references in logbook documentation and in your slides about stdlib logging not being usable for Web applications? &gt; I got so much feedback that I thought it would be a good idea to rethink logging. If people wouldn't have responded to that I would not have continued with Logbook in the first place. So you committed so much time to a new logging project, based on a few responses via Twitter and Github? I'd be interested in seeing what those responses actually were, so can you please post a pointer or two? Is it true that you really haven't got better things to do, like working on PEP 444/Web3 and closing some long-standing Werkzeug issues? IIRC the last time I was directed to Twitter it was about some tweet by Zachary Voase on a (then) new project called "lumberjack" which was going to be the logging Silver Bullet and use Really Cool things like generators, coroutines, context managers and what have you. I couldn't find that BitBucket repository when I looked just now; has it moved, do you know? Or did he just give up and delete it, knowing that you were on the case? Personally I think the time you spent/will spend on Logbook is wasted time from a community perspective, though of course you may learn from doing it. Even if logging were not as good (and that's *very* far from being established, marketing or no marketing), backward compatibility means that stdlib logging will be present for a long time, and third-party library providers will continue to use it for a long while - perhaps because they don't want to add a logbook dependency, or perhaps because they don't see the need to change something which works for them. So, by persisting with Logbook you will succeed only in dividing the community regarding which logging to use, and this will lead to a lot of unnecessary integration work for people integrating multiple libraries into an application. If you drop logbook, not only have you gained a whole lot more time, but you don't lose any face, because people will still respect your work and feel goodwill towards you, and you will even gain the respect that is due to people who admit their mistakes. I consider the two slides on your logbook presentation entitled "Why not logging?" and "Why does nobody like logging?" to not contain enough justification for a completely new logging library. There are other approaches you could take: on the configuration issue, why not provide a utility function or functions which provide what *you* think is the best default configuration? People can download it from PyPI and use it if they agree with your assessment. Others have done it, such as [easylog](http://pypi.python.org/pypi?%3Aaction=search&amp;term=easylog&amp;submit=search). Your arguments about thread safety don't really stand up. Your arguments about logging not being suitable for Web applications don't stand up either. I am, of course, ready to address any other arguments you have. Ultimately, you have to accept that *even you* don't know *everything*, and that there's no shame in working with "upstream" people to get the best for you, them and the community. In that other (logbook) thread, I posted [a link](http://x264dev.multimedia.cx/?p=185) to a lesson about Open Source collaboration Done Right. You can take it from me that I want logging to be useful for as many people as possible, and if you hit a practical problem with stdlib logging when trying to achieve some result, and if you take the time to describe it understandably, I will do my best to help you achieve that result - as long as I think it makes sense, of course ;-) And the solution I posted to your problem shows that I'm putting my money (time) where my mouth is. By the way, that goes for not just you, but also those pesky library authors who need help to RTFM ;-) &gt; So here is the thing with stuff in the standard library: If things change in Python 3.2, that does not help me a lot when the code I use have to stay compatible with Python versions down to 2.5 (until recently 2.4). So here is the thing with the Real World: that's not unique to you, and other Python developers (like the Django team) have to deal with similar issues relating to multiple-version support, even though Django up to 1.2 doesn't use logging. Let's remember that in response to your complaint about stdlib logging, web applications and configurability issues, the solution I posted works perfectly well under **Python 2.4**. If you want a QueueHandler under Python 2.5, which provides support for in-process, multiprocess and ZeroMQ queues, you can either copy and paste a few lines from 3.2 and/or my blog posts on the subject into one of your utility modules, or spend *much* more time writing, documenting, testing, maintaining and marketing a completely new logging framework. It's your choice, but to me it's a no-brainer :-)
Great someone takes care of that topic! Here are a few improvement ideas: * I don't see the point of using a list of tuples for header, why not simply a dictionary? Order of HTTP headers shouldn't really matter, should it? * I don't understand why you would need a filewrapper at all -- just return open files. They are iterable, and servers can implement something like ``sendfile``, additionally, if needed. * As in the WSGI spec, ``wsgi.multithreading`` and ``wsgi.multiprocess`` are not clearly specified. Should the values evaluate to ``True`` if the server does multithreading/multiprocessing itself or if it is *possible* to use the application objects in named manner without complications (so that ``multithreading``, for example, would evaluate to ``False`` if the server does not respect the Global Interpreter Lock)? * I think the case-insensitivity problem with environ keys that are optional for the application to specify (``Content-Length``, for example) should be solved more elegantly. I don't see any acceptable implementation of the checking part on server side. In any case, the server would have to loop through all keys in the header, lowercase each and then do a string comparison. I can think of the following solutions to work around this problem: 1. use a custom, "case-insensitive" dictionary or 2. force applications to one notation. (Personally, I would prefer 2. with *This-Notation-Of-Headers*.) * Like the WSGI spec, the Web3 spec is far too much text. There's not really much to document and I think the text length could be halved. Feedback welcome!
So ? That's rather light. However.. from another excerpt: Both types of message consist of a start-line, zero or more header fields (also known as "headers"), an empty line (i.e., a line with nothing preceding the CRLF) indicating the end of the header fields, and possibly a message-body. So ok, `header fields` and `headers` are synonym in this context! That doesn't sound intuitive to me, but I'm not a native english speaker.
Please do not do this. It's fucking annoying to people trying to use the tracker for organizing bugs, and it contributes nothing. Python has 10s of thousands of users (maybe more), attempting to quantify the value of a dozen people commenting is stupid.
Is that really the responsibility of the layer in the stack that Web3 operates in? mod_python did "more" than connect the server and application and was a terrible terrible mess because of it. Why mix the two?
&gt; ack-grep --python class | grep -iv Test | wc -l =&gt; 144 logging does have less classes, but you got your numbers wrong because logbook only has 65 classes in total. That however also because it has a lot more handlers (something around 30). Let's compare the base interface. In logging we have a Logger, RootLogger, Filterer, Manager, PlaceHolder, Handler, Filter, LogRecord and Formatter. Logbook has on the base interface a LogRecord, a StackedObject and a RecordDispatcher. Everything else is not needed and just useful stuff on the top that provides a nicer interface. &gt; Werkzeug? Ha! Cookies can't be tested using real-world scenarios Would have been valid though. Fixed now.
I have nothing further to add to that discussion I suppose. You don't like logbook, I see that. I would say that's an impasse.
I program in a scientific environment and the technology itself is constantly changing. We Are working on all sorts of interesting issues related to scaling our toolchains, workflow management, GPU programming. Most of our work is using bleeding-edge Python and C++ libraries. 
&gt; Is that really the responsibility of the layer in the stack that Web3 operates in? Apparently not. it's still a missing battery in Python though.
Yeah, now that I think about it, my second sentence doesn't make much sense. It sounds like the problem is precisely that a flush is happening for every single line of output.
&gt; What about threads? What about them? Be specific. You demand it of others. &gt;If you would show at all a good example of non trivial code using your proposed API and could show the advantages I might even agree with you but this shows absolutely nothing. If would have read the entire comment, you would have seen that I said this: &gt; This obviously makes passing around a global configuration more challenging,... An then I demark the tradeoff here: &gt; but, at the same time, is much less magical. The advantage is simplicity and traceability. Figuring out what the magic is doing when it doesn't work is hard. The main problem I see is where you push a handler in some entry function, then call some other library function where you expect a log message to be called. However, between where you pushed the handler and expect the log message to be propagated, there is no reasonable expectation that some other function didn't push another handler, making this log message useless. The worry is not the individuals usage in a single codebase, but rather the heinous manner in which others will use it. Logbook's solution is an elegant one; nay, better than the standard implementation. However, we still need to shake the tree here, especially when a library like this is young, because python does need something better. &gt; Of course magic should be avoided but burning everyone at the stake for using magic is not the way to go. No stake burning here. This is called discourse. When something seems magical, it deserves an extra bit of examination. Would you not distrust a politician if he said he had some magic to fix all our problems? &gt; It seems that it's becoming more and more common practice to do that, probably because it's that much easier than actual criticism based on research. Not sure if your comment is very valid or very constructive. It's actually quite derisive. Did you even read the code? I did. Do you deal with production logging issues in python? I do. I have thought heavily into the tradeoffs that go into a logging library. If you want to attack strawmen, head over to /r/politics. Nine times out of ten, all that is needed something very simple. Go's [log package](http://golang.org/pkg/log/) is a great example of this. It is very complete yet gives you only what you need. 
&gt; You don't like logbook, I see that. I don't like or dislike logbook, and I don't need reminding that you are a free agent to do exactly as you please. I merely observe that: * Default configurations are often a personal preference and not enough of a deal-breaker to justify writing a whole new library. * You have not advanced any convincing arguments about stdlib logging, thread safety and unsuitability for Web applications. So I can't see the justification for logbook, other than as a vanity project or because logging's design offends your sensibilities too much to use it. But you're inconsistent, because sometimes you say that you *like* (stdlib) logging. Or perhaps I've misunderstood :-( * Writing an alternative for an established, working and maintained *infrastructure* stdlib module just because you don't like its style is not, in the end, helpful to the community, for reasons already elucidated. * If you are still having problems getting stdlib logging to do particular things in certain scenarios, I am willing to spend time to investigate and suggest solutions (I've proved this earlier today). * There is really no reason why a responsible member of the Python community should not engage in dialogue with a stdlib maintainer about issues they have with part of the stdlib, in a spirit of collaboration rather than competition. After all, isn't that community means to a fair extent? Collaboration? * There is no need to resort to marketing which does not follow high standards of integrity and fairness.
&gt; logging does have less classes, but you got your numbers wrong Notice that I put a ;-), showed my methodology, and acknowledged that I had just skimmed the surface. &gt; [logbook] has a lot more handlers (something around 30) Sure, logging has 18 handlers, which would account for a discrepancy of around 12, but then it's not trying to compete on the number of handlers. Other people (including you) have written handlers for stdlib logging, some of which are on PyPI, though I don't know how many of those there are. Note that RootLogger, Manager, Filterer and PlaceHolder are implementation classes, and do not need to be accessed as part of the public API. So, logging's class API for the most part consists of Logger, Handler, Filter, LogRecord and Formatter (plus the handlers, of course). &gt; Everything else is not needed and just useful stuff on the top that provides a nicer interface. If you say so. I would have thought that "a nicer interface" fell into the category "needed" rather than "not needed". By the way, what happened to Processor? I thought that was how you injected thread-specific things into the log when using logbook? Haven't you said, or at least implied, that this is one of logbook's *raisons d'√™tre*? &gt; Would have been valid though. Do you have difficulty distinguishing between "the letter" and "the spirit" of the law? (Or, here, marketing ethics/etiquette rather than law). No, don't answer that, it was a rhetorical question ;-) &gt; Fixed now. Great.
I've wondered your question before too. The answer is basically "No." Pyjamas is your best bet, and it isn't the same as writing normal Python GUI application code. You could check out http://www.aclevername.com/articles/python-webgui/ but this isn't as much about making browser applications in Python as using Python to run a web browser and interact with its contents. The problem is that the web browser in question has to have a Python interpreter and a Python interface to its innards. This could certainly be possible, but it isn't implemented in any major web browser, so functionally no one could use your client side Python powered web page. Server side Python is common and very well supported by many frameworks, however.
Thanks for the comment but most importantly thanks for maintaining the logging package. We just introduced app level logging in web2py. Some of the developers have privately discussed whether to use mitsuhiko's code or your logging module, reviewed the features, and decided to go with the your logging module (the standard python one).
Thanks for letting me know. The comments I made to Armin about how I support and maintain stdlib logging applies to all users of the package, including web2py. If any developers need input about usage, practices etc., please post on comp.lang.python with the word "Logging" in the subject of the post, so that I'll pick it up quickly.
&gt; Default configurations are often a personal preference and not enough of a deal-breaker to justify writing a whole new library. No, an extension library would have been more than enough for that. &gt; You have not advanced any convincing arguments about stdlib logging, thread safety and unsuitability for Web applications. I have not further investigated using filters for processing. And right now I don't have the time for it either. &gt; Writing an alternative for an established, working and maintained infrastructure stdlib module just because you don't like its style is not, in the end, helpful to the community, for reasons already elucidated. I have argued in the past already against rewriting stuff from the standard library, but that is currently happening. See argparse, distutils2 and to some extend unittest2. I can see that to some extend things I want from logging can be accomplished by applying hacks on top of logging with some extra effort, but that doesn't make the hole system itself any nicer. My biggest grief with logging is the central registry and that just does not work well for me. And apparently that and some other things are not unique to my usage. I saw the way how multiprocessing patched itself into logging, I see how SQLAlchemy is trying to get rid of loggers. I also consider the custom log levels a problem, especially if libraries have the idea to invent them and they clash. On my quest to playing with other logging concepts I skimmed through google codesearch and found tons of absues of logging. Situations where people would set a new logger class in a library blindly removing what's in there, not even warning. I saw libraries setting up global loggers and much more. All that leads to many problems if you try to move things together that all set up their own shared infrastructure on logging. I don't claim that I have this fully solved with Logbook, but I think it's a nicer way to handle logging from different sources. &gt; But you're inconsistent, because sometimes you say that you like (stdlib) logging. Or perhaps I've misunderstood :-( I used to like logging a lot, but the more I used it, the more I became convinced that it could need a redesign. Just because we used to do things in a certain way does not mean it's the right way. Consider logbook being logging's Python 3000. &gt; There is no need to resort to marketing which does not follow high standards of integrity and fairness. I think we're past that, aren't we?
&gt; I don't see the point of using a list of tuples for header, why not simply a dictionary? Order of HTTP headers shouldn't really matter, should it? Multiple headers with the same name are allowed (e.g., `Set-Cookie`).
This might be a dumb question, but: &gt; Web3 applications return a tuple in the form (status, headers, body). If the server supports asynchronous applications (web3.async), the response may be a callable object (which accepts no arguments). Why not just require `Web3` applications to return a callable that returns the 3-tuple of `(body, status, headers)`? Most of the examples given in the PEP have ugly conditionals for dealing with these two possible kinds of returns. There must be some reason for this (due, I'm assuming, to differences between the way synchronous and asynchronous servers run), but it's not immediately obvious to me.
&gt; Sorry, but could you please provide some justification for this draconian norm you are trying to impose? I will. About two years ago, right around the time Massimo first started posting about web2py in any thread even tangentially related to Python web development, a curious series of short-lived accounts began appearing. Their usernames all matched the regex `(mark|john)19\d{2}`, and those accounts posted exclusively in those threads, and their comments exclusively praised web2py and bashed all other Python frameworks. Some of the most egregious examples (one common theme was to declare Django "insecure", TurboGears "vaporware" and Pylons "too complicated" -- those exact phrases were repeated multiple times by different accounts) have had their comment histories blanked, but [here](http://www.reddit.com/user/john1973/) is one that apparently forgot to wipe all its comments later (I've got a screenshot of that overview should it get blanked out now). Notice that the account was only ever used in two threads. [Here](http://www.reddit.com/r/programming/comments/6zbos/django_10_release_candidate_now_available/c059xsj) is another which deleted most of its nastier comments, hence the somewhat strange-looking thread. While I don't know who was actually running those accounts, I do know Massimo was actively canvassing for web2py users to come to reddit and support him. Given such results, I think it's understandable that I'm a bit wary of such behavior now.
Well, I hope no one thinks it's OK for anyone to "attack" any project. And although Armin clearly has expertise, he has been surprisingly uninformed about web2py in many cases. For example, in this thread alone he has: * Incorrectly claimed that web2py's commitment to backward compatibility leaves "no room for performance optimizations at all." * Made an incorrect statement about setting a table default using "default=datetime.utcnow()" (see [here](http://www.reddit.com/r/Python/comments/ddkal/django_vs_web2py_what_do_you_use_and_why/c0zf8ya) for the correction). Armin is certainly entitled to his strong opinions regarding design philosophy, but they make him prone to overstatement and carelessness with regard to web2py. Unfortunately, mere "expertise" is no cure for this kind of bias (indeed, it can be a hindrance because it may lead to arrogance and intellectual complacency). So, it is wise to take Armin's comments with a grain of salt. Of course, mere factual errors would be much more tolerable if the presentation were more polite. For example, statements like "web2py leads the bad design decisions competition" are not particularly conducive to constructive dialog. I think this kind of language is why vph used the verb "attacking" rather than "criticizing" to characterize Armin's behavior. 
This is indeed troubling, but if you don't want someone to create a bunch of fake accounts, then say *that* (in which case, you would have my support). Instead, you claim it is inappropriate for any individual web2py user to see a post about reddit and then decide to register on reddit in order to contribute to the conversation. This proposed ban has nothing to do with the specific case you cite above. In fact, such a ban would be counter-productive -- it would turn away earnest web2py users who have legitimate contributions to make, but would have absolutely no effect on fraudulent users like `(mark|john)19\d{2}`. &gt; I do know Massimo was actively canvassing for web2py users to come to reddit and support him. Can you share some examples of this? Thank you.
There are also significant differences between what you can do with a module and with a function, or with an iterator, etc. The most useful distinction in Python is not inheritance, iteration, or attribute look-up, but rather "callability". If all callables are capitalized, the reader immediately sees the latent potential. I think the problem is that most coders think of themselves, rather than of readers. Capitalizing a class reminds the coder of how he coded something. The reader, however, cares more about what the code is doing. When he sees code like this: x = Foo() y = bar() if he knows the PEP-8 conventions, then he knows that `x` will have the methods of `Foo`. That's useful. However, he does not know the methods of `y`. So why bother to tell him the methods of `x`? He has to read the docs anyway. He'll know that `Foo` is a class as soon as he sees the word `class`, so you really did not need the naming convention. It only serves to make the code look strange. Hmmm. I think it's like the difference between English and German capitalization. In English, we capitalize only proper nouns; that is, we capitalize the *name* of a thing, but not the generic *type* of a thing. We like to recognize that distinction. In German, they capitalize *all* nouns. They are emphasizing that the word represents a thing, not an action or description, which makes German easier to speed-read. We're used to our way, which provides more information, but their way avoids making judgments . I've never heard anyone complain about German capitalization. They complain instead about the *lengths* of German nouns.
&gt; I don't understand why you would need a filewrapper at all -- just return open files. They are iterable, and servers can implement something like sendfile, additionally, if needed. In-band signalling breaks on iteration. That was also the flaw with filewrapper. &gt; As in the WSGI spec, wsgi.multithreading and wsgi.multiprocess are not clearly specified. Should the values evaluate to True if the server does multithreading/multiprocessing itself or if it is possible to use the application objects in named manner without complications (so that multithreading, for example, would evaluate to False if the server does not respect the Global Interpreter Lock)? These specify how the server operates. If you can create threads or not is undefined behaviour. &gt; Like the WSGI spec, the Web3 spec is far too much text. There's not really much to document and I think the text length could be halved. And it's not even close to being unambiguous. HTTP is complex, you can't simplify that spec any more I'm afraid.
(Maybe we are using the word "Attack" differently?) I do think it's ok. Why is everyone such a pussy about harsh feedback? Are we aiming for a meritocracy among FOSS developers or not? Look at how things work in the academic world, where feedback is much harsher because the goal is to arrive the closest to the truth, not save your feelings. Uninformed attacks or those that aren't backed up are useless and harmful, yes, but once someone tries to promote their software in the world then it's required to have a healthy debate. I should point out that I'm not talking about flamewars, but I am talking about people saying harsh things (with evidence) about the quality or design decisions that someone has made. Armin's an opinionated guy, sure, but you guys corrected the one error he made about the table default stuff and that's the way it should be. If he keeps using that argument after the correction that's something else obviously. The "no room for performance..." issue is bullshit, do you think he meant that it severely impedes the ability to make performance optimizations and makes some impossible and was using hyperbole or do you think he meant it literally?
&gt; I have not further investigated using filters for processing. And right now I don't have the time for it either. Okay, fine - but what is there to investigate, really? Nothing. You've got request specific stuff into ALL log messages, just as you wanted, with the stdlib logging from Python 2.4. And you can see how to direct messages from different web apps into different logs, even though libraries are shared. What other practical problems do you have, *now*, *today*? Describe them in the same way as you did this time, and I will do my best to nail them, as I did in this case. &gt; I have argued in the past already against rewriting stuff from the standard library, but that is currently happening. That's no reason to change your stance, because ... &gt; See argparse, distutils2 That's because of the intractability of optparse and distutils (which I believe were designed by the same person, who is no longer actively involved with maintaining them). I know Steven Bethard tried hard to extend optparse in a backwards-compatible way, before giving up and rewriting argparse from scratch. I think for distutils2 similar issues apply - I know that PJE was seen by at least some people as unresponsive to community needs, which led Tarek to reluctantly create a fork with distribute ... I know that's a fork of setuptools, but I think all of those modules are pretty interdependent and the idea is for the whole mess to be sorted out. I don't think you can point to too many other examples of this magnitude. &gt; and to some extend unittest2. From unittest2's PyPI page: &gt; unittest2 is a backport of the new features added to the unittest testing framework in Python 2.7. It is tested to run on Python 2.4 - 2.7. So unittest in the stdlib has been *improved*, and unittest2 is a way of bringing those improvements to earlier Python versions. That's not what you implied. Anyway, if you use this argument, every module in the stdlib should have its counterpart outside the stdlib, neh? &gt; I can see that to some extend things I want from logging can be accomplished by applying hacks on top of logging with some extra effort, but that doesn't make the hole system itself any nicer. Well you might call them hacks, but maybe there's some non-hacky solution you're not seeing, which is simple and straightforward. If you're too proud to ask, how can you be so sure that the hacks you are implementing are the best way to move forward? &gt; My biggest grief with logging is the central registry and that just does not work well for me. "Does not work well for me" == "Not to my taste", because you fail to explain what a central registry prevents you from doing, on a practical note. I'm sure you're capable of being aesthetically offended by the demon of "global state", except of course when it's in one of your projects, but that's more a comment about personal taste than a valid criticism of logging from a functional viewpoint. A central registry helps me, for example, to configure how a 3rd-party library's logging (like SQLAlchemy's) should work with my application. If I can't get hold of the exact same logger that SQLA is going to use, I can't configure it as I want. ISTM that would happen if a 3rd-party library used logbook: their loggers would be on a stack frame somewhere or buried in a context manager, so not accessible from outside. &gt; And apparently that and some other things are not unique to my usage. Back it up with some examples, please. &gt; I saw the way how multiprocessing patched itself into logging I don't know exactly what you mean; please elaborate. I thought I showed (in response to Mike Bayer's post on Reddit) a simple solution to his problem of using logging with multiprocessing. If you say what you mean I can perhaps take it up with Jesse Noller. AFAIK, my solution did not depend on any patching of logging by multiprocessing. &gt; I see how SQLAlchemy is trying to get rid of loggers. Can you point me to any discussion about this? My naive Google search of "SQLAlchemy get rid loggers" didn't show up anything. Is this more FUD, or can you substantiate this? &gt; I also consider the custom log levels a problem, especially if libraries have the idea to invent them and they clash. Agreed, and custom levels are not recommended for use except where absolutely necessary. But had they been left out, someone would undoubtedly have cried out that this was a glaring omission in logging's functionality. Certainly, I have no problem with emphasising in the documentation about potential consequences of custom level usage. Note that the same "custom level" functionality allows for different names to be assigned to the existing levels - which might be useful from an I18N/L10N point of view in a few scenarios. &gt; On my quest to playing with other logging concepts I skimmed through google codesearch and found tons of absues of logging. That's not a problem with logging, more a problem of people who don't necessarily know how to use logging. Google codesearch? So you looked at lots of code indiscriminately, irrespective of the known quality of the developers of that code? Do you know Sturgeon's Law? If there are some major, widely-used projects which abuse logging egregiously, then tell me who they are and I will take it up with them (i.e. explain what the problem with their usage of logging is, and how to rectify it). Whatever software there is in the world, you will always find *some* people who can foul things up royally. Perhaps you haven't looked at [The Daily WTF](http://www.thedailywtf.com/) recently ... &gt; Situations where people would set a new logger class in a library blindly removing what's in there, not even warning. I saw libraries setting up global loggers and much more. All that leads to many problems if you try to move things together that all set up their own shared infrastructure on logging. The answer is better education, not a wholesale rewrite just because perhaps some people don't know to write software (obviously I can't give any actual judgement, as you've not pointed me to actual cases). Are you saying that logbook's API is so foolproof that it can't be misused by *anybody*? Pull the other one. Anybody and their maiden aunt can probably write a library. Point me to well-regarded, widely-used, high-profile libraries which misuse logging, and let's see if we can't make that little corner of the world a tad better. &gt; I don't claim that I have this fully solved with Logbook, but I think it's a nicer way to handle logging from different sources. "Nicer" is about aesthetic judgements, and in my view you can't please all of the people all of the time so I certainly wouldn't expect to be able to please *you*. In my view, you haven't yet shown something that should be reasonably doable in logging, but which can't be done. &gt; I used to like logging a lot, but the more I used it, the more I became convinced that it could need a redesign. That could be because you found you thought you couldn't do some things with it, leading to disappointment ... but in at least one case, you actually asked, and then discovered that perhaps there was a way to do it after all ... can you infer anything from this? &gt; Just because we used to do things in a certain way does not mean it's the right way. Sure, but it doesn't mean that the Old Way is necessarily the Wrong Way, either. You should stop arm-waving about how logging is so hard to use that apparently everyone is misusing it, and yet never giving a concrete example of well-regarded, widely-used, high-profile libraries which misuse logging! How is that not FUD? &gt; I think we're past that, aren't we? I hope so, but you're telling me, right? :-) I would say: if you're acting in good faith, point me to the substance of your researches about widespread misuse of logging by libraries, and then tell me why, if *you* characterise it as misuse, your solution is not to help educate the misusers, but to invent a whole new thing which is perhaps just as susceptible to misuse. It's a bit like saying, "There are an awful lot of bad drivers out there. Let's change the rules of the road, as they're obviously too hard for so many people to follow." The first sentence there is typically a true statement in most highly-populated countries. But any government which advocated the second sentence as a consequence of the first sentence being true would rightly be accused of lunacy.
Changing the name from WSGI to Web3 is unnecessary and confusing.
&gt; Stage: needs patch As the bug says, it's apparently already been discussed. I mean, I've been told off by devs for pointing out that a bug which they're treating as minor actually has direct system-breaking consequences, because apparently consequences caused by the bug are entirely irrelevant to the bug. Go figure; bug-wrangling tyranny can go too far. But unless you have something of substance to contribute, there's no sense in commenting.
&gt;Why is everyone such a pussy about harsh feedback? I think it's possible to give appropriately critical feedback and still be polite and respectful about it. We're dealing with real people -- why not be decent to one another? But leaving common decency aside, just in terms of effectiveness, being rude doesn't pay off. If your goal is to actually convince other people, calling them a "pussy" just isn't going to advance your cause. &gt;Look at how things work in the academic world, where feedback is much harsher... Massimo is an academic, and he doesn't exhibit this kind of harshness. I used to be in academia as well, and I don't recall rudeness being considered conducive to the development of knowledge. &gt;once someone tries to promote their software in the world then it's required to have a healthy debate. Of course. &gt;but you guys corrected the one error he made about the table default stuff... But it wasn't a small error, because it reflected a fundamental misunderstanding of how the framework works. &gt;The "no room for performance..." issue is bullshit, do you think he meant that it severely impedes the ability to make performance optimizations and makes some impossible and was using hyperbole or do you think he meant it literally? There was absolutely no indication that Armin was using hyperbole. But even if he meant "severely impedes," I'd say that's probably wrong and uninformed too. Maintaining the original API leaves lots of room for optimization under the hood (not to mention the possibility of adding to the API). For example, a while back the team made some backward compatible changes that led to a 2.5x speedup of model execution. Note, if Armin had simply read the very first page of the [web2py book](http://web2py.com/book/default/chapter/00), he would have seen this (emphasis added): "web2py has always been built from the user perspective and is *constantly optimized internally to become faster and leaner*, whilst always maintaining backward compatibility." Cheers.
For example?
&gt; Please do not do this. Don't do what [the issue's creator asked for](http://mail.python.org/pipermail/python-dev/2010-September/103724.html)? &gt; I think there were other APIs mentioned back then beyond the urllib.parse ones, but I didn't find them when I went trawling through the list archives yesterday. **If anyone else thinks of any APIs that should allow bytes as well as strings (or vice-versa) feel free to add them to that issue**. (emphasis mine)
the only way i see it's possible to use python in the browser is through silverlight. a quick google says it might be supported in moonlight too. Edit: see the video here : http://us.pycon.org/2010/conference/schedule/event/14/
I didn't see any personal attacks, just comments about the code. To me that makes a big difference, I certainly agree rudeness doesn't help and isn't effective but forceful criticism of ideas or objects or code (not people) certainly does. &gt; There was absolutely no indication that Armin was using hyperbole. You can't be serious. The indication was that the thing he said was impossible. It's impossible to have a piece of code that large that is impossible to optimize at all. Everyone with an understanding of software knows this, it's obvious. The only reason to interpret it that way is to score points in an argument and it's dishonest.
I don't know what I'd use this on, but it's incredibly cool.
These are really handy for text analysis or information retrieval. I have implemented them countless times and wish I had this library laying around.
Oops! (in my defense, I'd never name a variable upper-case unless it were a constant, so it was just my brain on auto-pilot.)
I guess this is just a matter of preference. I personally don't find stuff put on one line to be any more readable. But the one-line vs. two thing wasn't the point, so I probably shouldn't have mentioned it. More to the point was the explicit checking of None rather than relying on boolean logic quirks. Using or/and operators in assignment is (IMO) problematic because they don't work the same way in every language, thus making it ambiguous or confusing to people who don't know Python quirks. It is not immediately clear that you get the value of A if it's set otherwise []. In other languages, your final result *might be* a boolean value (True if either the left or right side evaluate as True) rather than the actual value. If I remember my Perl correctly (I am not about to fire up a perl script to test this), there's "and/or" *and* "||/&amp;&amp;" -- only the latter short-circuits and returns the value of the last operation the same way Python does. 
&gt; Simply figuring out the quality of a module is a bunch of work, and the amount of work multiplies drastically if there's several third party modules that all do what I want. This is half of the fun.
Search engines, spell checkers‚Ä¶
xdg-open cross-desktop and desktop aware.
He can grant you an exclusive license to his code OUTSIDE the GPL. 
cool. don't have a project where I can use this right away, but no doubt I will some day, so I'm bookmarking, not installing. yet, cool.
Python code, apart from the enforced readability boost of significant whitespace, has always seemed more readable because of people's following PEP-8. The average Python code you find online is much more readable than the average C++/Perl/PHP piece of code. I just dislike people who go against PEP-8 without any apparent reason and ruin this conformity.
This is very cool, I've been messing around with IRC bots for various purposes, and I think this'll really come in handy.
&gt; One thing I take issue with though is that they seem to have eliminated "wsgi.file_wrapper" In-band signalling does not work with middlewares. A middleware has no way to detect that the return value was a file wrapper and when it iterates over it, it trashes the type information breaking the isinstance check on the server side making file_wrapper a noop.
Neither Chris nor me are some kind of official delegates from web-sig or where asked to write a new WSGI specification. We didn't want to have a pep for WSGI 2.0 on there that might be rejected, squatting the name. In case this is accepted on web-sig there is on reason not to change the name (and env keys) to wsgi. And bump the version to 2.0
I hear these people do... http://code.google.com/appengine/docs/python/
Yes, forgot that. Maybe any iterable that yields (key, value) tuples? So you could return ``yourdict.iteritems()`` for very simple applications.
&gt; In-band signalling breaks on iteration. That was also the flaw with filewrapper. Would you mind explaining that topic a bit further? Is it that about looing type information when using middlewares? How would that be solved with something like a file wrapper? &gt; These specify how the server operates. If you can create threads or not is undefined behaviour. The specs are ambiguous here. I think this should be clarified. &gt; And it's not even close to being unambiguous. HTTP is complex, you can't simplify that spec any more I'm afraid. I'm talking about "reducing the amount of words" and restructuring the specification. I think information is too scattered.
That was my first thought, but I can't imagine it would last more than a few days before getting a takedown notice (and I assume Google would comply with it).
I thought this sounded like fun, looked for a domain to register and found http://hdcpkeygen.com/ Looks like someone beat you to it.
Try http://utilitymill.com/ ... the simplest way to convert a python script into a web service 
What is the benefit of having a HDCP keygen? Since HDCP is the over-the-wire encryption, an in-line (read hardware) device is the most practical application of the "master key" leakage, and I'm just not sure what I would want your service for???
&gt;I didn't see any personal attacks, just comments about the code. I wasn't talking about personal attacks (though telling somebody you wish a significant piece of their life's work would "just silently stops to exist" seems a bit personal). And these comments aren't about the code: "Saying that I have no problem with you personally would be wrong, because of your aggressive marketing..." "Had to chuckle when I saw that mdp found a new way to promote web2py..." You may think these statements are justified, and therefore not "attacks", but it's clearly not just about the code. In fact, it's hard to escape the conclusion that Armin's assessment of web2py is being colored by his personal problems with its creator. &gt;&gt;There was absolutely no indication that Armin was using hyperbole. &gt;You can't be serious. The indication was that the thing he said was impossible. It's impossible to have a piece of code that large that is impossible to optimize at all. Everyone with an understanding of software knows this, it's obvious. The only reason to interpret it that way is to score points in an argument and it's dishonest. Nope. Just because someone states something that is incorrect does not mean they are using hyperbole -- they could just be incorrect. Armin probably made this mistake because he misunderstands what web2py means by "backward compatible." He misunderstands because he is uninformed. He would be informed if he (a) got past the first page of the web2py book, or (b) was involved in the web2py community, as Massimo has articulated what is meant by "backward compatible" on several occassions. The point is, just because Armin has some general expertise doesn't mean he knows what he's talking about when it comes to web2py. Note, on several occassions, Armin has admitted that he hasn't actually used web2py. The thing is, you really can't evaluate how a web framework will work in the real world until you see it operating in the real world. Most of Armin's concerns are theoretical and based on his intuitive assessment of the source code. But he has no evidence that his concerns will be born out in any significant way in real-world usage (or at least that his preferred alternatives wouldn't lead to bigger problems for web2py users). The fact is, lots of people have been using web2py quite successfully and happily for quite some time -- this real-world evidence trumps Armin's expert intuition. He simply is not well informed enough to be making such definitive proclamations about the quality of web2py. 
Challange accepted. Web app completed. http://web2py.com/hdcp Running live + source code. I had to make two changes to the source to 1) use the simplejson that comes with web2py, 2) output strings instead than print to console. EDIT: typo fixed
It's HDCP, not DHCP. 
So downvoted for posing an honest question? Nice. 
It takes longer to read the instructions than write a couple of lines of code to accomplish it.
Shits 'n' giggles. Or as a more typical geek answer: 'because we can'!
Huh?
Really? I heard from some of the framework police around here that Python is supposed to be anti-magic.
Was a typo in the link. It is fixed
Oh yes. That was pretty easy: http://hdcpgen.appspot.com/
Well... I did thanks to Google AppEngine: http://hdcpgen.appspot.com/
That makes sense :( I'd always figured there were very few pieces of middleware which inspected the return value (most I've seen mess with the request side of the call), making file\_wrapper worth having for middleware stacks which could pass file\_wrapper instances through unchanged. But I guess someone did a survey and such middleware was common enough to render file_wrapper generally useless? Though to solve it in-band, I can see how something like a "wsgi.is\_file\_wrapper" would just cause the code to get extremely messy. I hope someone can come up with an OOB solution, though I can't think of an easy way right now which wouldn't get fouled up by the same problem of unaware middleware altering the return value (thus leaving an invalid OOB signal still present).
 return environ['wsgi.file_wrapper'](the_file) when the middleware takes that it might do this: rv = app(environ, start_response) for chunk in rv: yield do_something_with(chunk) rv.close() # if that attribute exists only of course. The WSGI server now does that: rv = app(environ, start_response) if isinstance(rv, my_file_wrapper): # this is never true because the middleware removed the type # information and it's now a generator. 
Then why do people jump all over Massimo when he talks about Django? The degree of negativity that Armin talks about web2py is several magnitudes worse than Massimo talks about Django.
Yup; discussion finished below: http://www.reddit.com/r/Python/comments/ddg79/can_web2py_applications_be_provided_to_end_users/c0zea8c
Here is the plot of the possibilities http://www.wolframalpha.com/input/?i=%28k%2Bc%29^3 See the global minima ? Is you.
can't argue with that
http://www.codingbat.com/ is a nice learning tool. Making my way through http://code.google.com/edu/languages/google-python-class/index.html too. Nick Parlante is responsible for both, so they have a similar flavor. Good luck, keep us updated on any good resources you come across.
I like your coding style.
:) - thanks.
There's fanboyism on all sides of course, I'm definitely not defending those people. That's the difference between professionals (or informed hobbyists acting seriously) debating and fanboys flaming each other for being on the wrong "side".
So how would a wrapper around files help here?
Are you a functional programmer by any chance? Using reduce, map, filter, zip etc. looks a lot like my own Python code - and some people moan and groan over it. Fun anecdote: I was teaching programming to first year engineering students, most of who had never touched a programming language before. We were using Python and there was one task about sum, map, filter and reduce. One girl, who was very bright but a noob wrt to programming, called me and asked: *I understand sum, map and filter, but I can't figure out wtf reduce is supposed to do. Can you explain it to me?* I wrote one line of nested parentheses with some operation, something like ((((1 \* 2) \* ... \* 5) \* 6) \* 7). She looked at it for one second and said "Aaaah, awesome - so you can actually do all of the other functions with just this one!" I was proud :)
It does not. That's why it's breaking currently. A better solution would probably be an 'X-Something' header or something you can call from the wsgi environment which bypasses all middlewares, similar to how write() worked on WSGI 1.
Or you could assume Web3 middlewares behave intelligently (hence, leave file objects returned from the application alone).
You assume people read specifications and not do try/error.
and with awesome music to boot!
Any practical application involving the master key is going to require a steady stream of keys. If a developer generated a single key and embedded it in a device or application, it would be trivial for the key to be revoked for later content. Devices would certainly need to have a master key embedded in them to prevent their key from being revoked. Applications, however, could conceivably use an online HDCP keygen service in lieu of generating the keys themselves. That said, I'm not sure that HDCP could practically be implemented in software. HDMI pushes a lot of data very quickly, and as far as I know all usable HDCP implementations to date are done in hardware.
PM me and i'll give you a private beta invite to djangy.com - you can host it there
map and filter are made mostly redundant by [generator expressions](http://www.python.org/dev/peps/pep-0289/).
Paste Script? Not sure what exactly you mean, though.
This is good, but generally for those with programming experience already.
Yes, I know and agree. I still think map, filter, etc. make for clearer code when either the function you want to apply exists beforehand (i.e. you don't need a lambda) or when you chain/nest several of those to create a sort of a pipeline. Also, reduce is still quite relevant.
Developers are not stupid. If they are, maybe their code is not worth using. I don't think specifications have to keep in mind that noone will read them.
Basically I want to be able to create a collection of command modules or classes and be able to run them like, "./manage.py [command] [options] [args]" Paste Script is probably the closest example but again, it's tied to Paste. I don't need Paste for what I'm doing.
Aha. Cool. Don't care that it has to be named "WSGI" but don't quite like the name "Web3". Don't like numbers in names usually. Like "urllib2" and "popen732981".
It's only vaguely tied to Paste, in that it has some default commands. If you just want a two-level command-line helper, argparse does that.
I think I'll probably just use setuptools.cmd, that's probably good enough for me. Thank's Ian. I am actually looking for a solution for writing management commands for WebOb experiments as well as non-WSGI projects. I'm big fan of silverlining too and excited to see that mature. 
No. Downvoted for bitching. And I will be downvoted for bitching about the bitching. And that's the way it should be.
TIL about web2py. Tell us more. How do you like it? Does it measure up to something like Django or Pylons, or was it just an easy choice for a quick hack?
&gt; readability is subjective That's the exact point. Camelcase vs. underscores has no winner, so you cannot decide from a readability point which one of both to use. So you need another decision maker. That's where PEP 8 comes in: It's the one thing that just decides. It's not important whether PEP 8 uses Camelcase or underscores. But it's important that PEP 8 is the one standard that you can find and that all developers can rely on.
[Relevant.](http://imgur.com/LO4hR.png)
He's the author of web2py.. :-)
For what it's worth, I use argparse in silver lining. 
This guy is a jerk.
thanks, I'll look into it.
I don't understand her answer. Could you explain? :( 
Self promotion: http://github.com/ericmoritz/wsgirouter 
developers would always find reasons to reinvent the wheel.
The code on lines 114 and 115 of generate_key.py is a compilation of everything that can be done wrong in Python.
Any reason why you still use map() and reduce()?
Yup... Now I'm over it.
Bahaha, the music. So much nostalgia. Switched to linux a while back and haven't touched one of those awful keygen programs since.
If the libs are designed for strings why should they accept bytes? It just sounds like you are complaining about a library because it doesn't work the way you want it to work. Thus it must be a bug. 
[disclamer: I started the web2py project therefore...] I think it is the best web framework out there. I wrote this hdcp app because I was trying to show that with web2py I can write code very quickly.
Hey there, I'm working on this CI project called ShiningPanda, and I'd like to get early feedback from the Python community. The goal is to provide a dead simple web service so that you can build, test and deploy your various Python projects, without having to care about setting up servers, databases, build tools, reporting, etc. The workflow is very simple: you push your source to github/bitbucket (or a local repository), webhooks notify ShiningPanda, ShiningPanda pulls your source, runs your test suite, and if all tests pass deploys the code on your hosting provider. We are planning to enter into private beta soon, so if you would like to participate, please let us know. If you feel like telling us about what your dream integration service would be like, let us know too, we really want to hear about what our (future) users want! Thanks in advance! Alexis
So, suggest a correction then.
That rings true as a general statement. I take it you are referring to Armin's reinvention of the wheel here. There is merit in continuous improvement, and sometimes that's achieved by reinvention; but sometimes, having too many choices is not ideal (think: string formatting, regular expressions, binary pickling/marshaling, and of course ;-) logging), and, while reinvention just for reinvention's sake might be good for the reinventor (as a learning process) it might not be of much wider benefit.
sum, map and filter (and more) are all special cases of reduce. sum(xs) = reduce(lambda x,y: x+y, xs, 0) map(f, xs) = reduce(lambda l, x: l + [f(x)], xs, []) filter(f, xs) = reduce(lambda l, x: l + [x] if f(x) else l, xs, []) Realizing this usually takes both an appropriate exercise given by lecturer plus quite many more seconds.
Then why did you post his article?
If you tolerate his writing style, Zed Shaw has an interesting approach: [learnpythonthehardway.org](http://learnpythonthehardway.org)
A few places to poke around: Google Code University's [Python Tutorials.](http://code.google.com/edu/languages/google-python-class/index.html) There are also some general videos [starting here,](http://code.google.com/edu/languages/index.html#_python_understanding) intended for people with a little more programming experience. Demonoid and other Torrent Sites tend to have large collections of Python books for learning and reference. The official documentation at [www.python.org/doc/](http://www.python.org/doc/) can't be overstated as a reference. Oh, and MIT's fantastic (and free!) OpenCourseWare uses Python to teach programming as well. You can find the whole thing [here.](http://curiousreef.com/class/mit-opencourseware-600-introduction/)
Am I embarking on a daunting task?
Python was the first language I learnt (apart from bash etc) and I found it easy enough. I really suggest getting a book on it though, as I found online tutorials awful to read. I recommend [Learning Python](http://oreilly.com/catalog/9780596002817) by Mark Lutz.
I was too chicken to enable javascript on that page... =]
[Dive Into Python](http://diveintopython.org/) and [Dive Into Python 3](http://diveintopython3.org/) also this [Introduction to Computer Science and Programming](http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-00-introduction-to-computer-science-and-programming-fall-2008/) uses Python, however it's not really a Python course per se.
No. I have just started out with Zed Shaw's [tutorial](http://learnpythonthehardway.org/) couple weeks ago and have found it really suits my style of learning. I would recommend it. Alternatively you could go for [How to Think Like a Computer Scientist](http://openbookproject.net/thinkcs/python/english2e/) or [A Byte of python](http://www.ibiblio.org/swaroopch/byteofpython/read/).
I'll be honest....my only background is one computer science programming course at Uni. But a lot of good paying jobs in my field, require python. 
I'm using this now, before moving [Think Like A Computer Scientist](http://www.greenteapress.com/thinkpython/html/index.html). Zed's approach is to have you type in different examples of how to do things in Python, so that you'll get used to doing mundane things that a programmer would have to do, prior to moving to a book or tutorial that goes more in depth. I certainly recommend it.
Right there with you!
Or print out the tutorial and take it with you. This also helps because you can jot notes down in the margin.
I think the front matter of Dive Into Python specifically says that it's not a text for beginners to learn from.
Agreed. It has the 'empty your cup' approach and does not feel daunting at all. It makes you feel like the protagonist in Karate Kid who starts from mundane tasks to learn the art of Karate.
This PEP might as well leave out everything to do with asynchronous results. It assumes asynchronous means returning a callable. Callables do *not* express future results in any consistent manner. Clearly its up to each async framework then to deal with the callable in a unique way. If each async server is dealing with the application in a unique way, then there's no point in web3 at all. This spec is basically useless in terms of asynchronous web frameworks which means its basically useless for anything beyond basic webpage responses, forget trying to tack on a websocket web3 application that works in any sane manner on a set of asynchronous web servers using this.
Hi Alexis, ShiningPanda is for web apps only or is there any magic that makes possible to upload desktop applications (maybe with cli? )
not really. If you know any other programming language, python is easy to pick up, and generally much nicer to program in
As long as it's written in Python, or CPython to be precise, it will work by design.
ah, thanks. I didn't know about sum. reduce is certainly more convenient to reason about with the map and filter aliases
I've decided to go ahead and use paste.script. I was mistaken about what Paste was. It's not a framework but tools for building web frameworks.
When I had to do this I used a commercial app called Mira: http://twistedmelon.com/mira/ . You can assign IR actions to any keystroke per application. Not as nice as a "Python OSX IR" library, but if you really need to just make it happen it will do the job.
With an Apple remote and that's about it.
Yay! I've been waiting for this!
PEP8 or DIE!
Here's another fuzzy string matching library: [ssdeep](http://pypi.python.org/pypi/ssdeep)
Sounds great, but have you had any thought about testing somewhat complicated and annoying things like AppEngine apps? Ie, to test them with a real environment you need the app to be running inside the dev server, which means your only access is through a web client and thus your live code has to be tailored to provide urls for testing, etc. Another method is to fake the dev server, like some other libraries do, but none of these are perfect (though, i use them.. or am trying). Ontop of that, i have been working on setting up a nice system for BDD rather than TDD. Any thoughts on that, and specifically Freshen (which is a plugin for nose)? Note that, while thus far i haven't gotten the workflow i want, i am currently using Freshen and nosegae for my testing. Both are plugins for Nose.
Nick Parlante has a great video series on Youtube: http://www.youtube.com/watch?v=tKTZoB2Vjuk&amp;feature=fvw (There are about 10 or 12 videos in the series.) Watch them, do the exercises, and download the support code. Nick has a fun teaching style, and yet he still gets a lot of information across to get you up to speed on the basics.
There's something about him I find very endearing
Seems fairly simple to me: any string-searching algorithm is going to be faster when it's searching for a larger string, because it can skip larger chunks. r"^_" is effectively searching, at least in re.MULTILINE mode, for a newline character followed by an underscore. Shorter string, longer search. It's possible that they're missing an optimization that would abort early when in normal mode. Which would be nice, of course, but as pointed out by others, that's what re.match is for.
I went with Django when I started using python for web stuff. The admin app caught my heart.
Python.org has some amazing tutorial, as well, [here](http://docs.python.org/tutorial/).
I really like [Invent with Python](http://inventwithpython.com/chapters/). It's talking about game design and what not, but it's pretty basic, so I think it's a really great place to start out. [Dive Into Python 3](http://diveintopython3.org/) is good if you know about programming (i.e., know another computer language). Google's Python tutorials are really good, but they're outdated as far as I know (I think they use 2.4, so I have issues trying to learn 3 with it).
The Book Learning Python is rather good.
Running "$ system_profiler SPUSBDataType" in Terminal.app shows the IR receiver is a USB device: IR Receiver: Product ID: 0x8242 Vendor ID: 0x05ac (Apple Inc.) Version: 0.16 Speed: Up to 1.5 Mb/sec Manufacturer: Apple Computer, Inc. Location ID: 0x5d100000 Current Available (mA): 500 Current Required (mA): 100 You could install [libusb](http://www.libusb.org/wiki/Libusb1.0) and [PyUSB](http://sourceforge.net/apps/mediawiki/pyusb/index.php?title=Main_Page) and have a little play around. Libusb is available to download through [Homebrew](http://mxcl.github.com/homebrew/) which is nice :)
If you're into videos and Google Code University's videos aren't right for you, you might also check out [showmedo.com](http://showmedo.com/videotutorials/python)'s Python videos. They also have learning-track sorts of series, but I can't find them on the site just now.
Wow, you guys came out in full force, thanks. So how long did it take you guys to become familiar with the language?
&gt; making file_wrapper a noop Which is a safe failure mode in that case. If the response is modified, it's not a file any more.
Most of the time it isn't though, a middleware just wants to clean up after the fact, wrapping the iterator and providing a close().
It's been years since I did this, but you can do it with the "startupinfo" parameter. Specifically you want to turn off "wShowWindow". For more with that, read up on CreateProcess, and look at the source of subprocess.py to see how that stuff maps in. Good luck!
This seems like the right way to do it, I will play around with it and see how it goes. Thanks
I think this will work for what I am trying to do, but I found [iRedLite](http://www.filewell.com/iRedLite/), which is free and has most of the same functionality.
Thanks for pointing me in the right direction, Googled a solution and found [this](http://www.gossamer-threads.com/lists/python/python/783907). It works perfectly.
thanks. I was looking for this..
Hmm... how about separating the program into a launcher and the main app, such that when you want want to re-start, the program really just starts the launcher with an argument which is the pid of the currently running process. Then the launcher could monitor the processes to see when that process finally dies (or help it along even if it's prone to hanging), then launch the new one when the coast is clear. The whole idea of re-launching an app just to load new settings though is a little suspect. I would re-examine the motivation / necessity for that though instead of going through all that work. I know as a user, I much prefer Chrome in that respect instead of Firefox.
You're right. Dive Into Python says that a couple of times. The very first sentence on the Dive Into Python web page says "Dive Into Python is a Python book for experienced programmers." If you want to buy a book, try out [Beginning Python](http://www.amazon.com/Beginning-Python-Novice-Professional-Second/dp/1590599829/). I have a previous edition of this book, and it definitely eases you into the language.
Can you use the scheduler to restart the program 3-4 seconds after the original has closed? (at.exe)
Umm.. er.. heh. Nice job! :)
&gt;The whole idea of re-launching an app just to load new settings though is a little suspect What the heck, please enlighten me with a better way of restarting a large script after its variables that are listed in a separated .ini file have been changed. Say that the script is using gettext to translate strings from a .po file. Say that the variable defining the choosen language is in the said .ini ; how can I make the program refresh the value of all of its variables without restarting? Keep note that wxpython uses such variables for printing the names on the dialogs, etc.. 
What does |= do??
a |= b is probably the same as a = a or b.
So, somewhere your app is deriving a class from wxApp and then probably in the OnInit (or maybe before that), you're loading all your variables. I don't think it would be too difficult to have your frame signal that it is to be restarted to the app with a variable, then when the frame exits, the logic in OnInit would just check for that variable, then reload the text variables from the file, and bring the frame(s) back up. Sound doable? Apologies if I'm trivializing what may be a very vexing programming conundrum for you. I agree that trying to reload this into already loaded dialogues and getting wxPython to play along could be infeasible, but this isn't that idea.
Way too long &amp; flamey;dr You might like *my* new logger, [twiggy](http://pypi.python.org/pypi/Twiggy/)
Unfortunately, I am using a proprietary 3D engine within the wxpython frame (Worldviz, Vizard). It does not seem to allow a frame refresh from the same instance (some sort of drm they have in place) without breaking. That is why I need to restart the whole program.
Honestly, what's all the fascination by IDE makers with "create a project"? Do they get paid for wasted directories? Really, when I see this kind of overhead in the creation of any ol' utility, it makes me think that the IDE maker isn't particularly interested in helping me to get my work done. Anybody else feel that way? 
I can see your point - it is overhead and - depending on the IDE - very heavyweight to create a "project" to handle some simple scripting tasks. The way I see it is that IDEs are simply the wrong tool in these cases. Personally if it is a small script or one that I know will not grow into something more structured (no other team members, no version control, etc.) then I stick to the simpler tools that make it easy to edit/run scripts or a REPL shell. 
It depends on how much time you put in, how fast you can learn, and how you use it. It took me a couple of months because I took it slowly and sometimes lacked motivation or ideas about what to do with the language or what libraries to learn. 
First of all, the project creation in PyCharm is as streamlined as it could possibly be. In most cases, all that it takes is selecting "Open Directory" and pointing to your code - the rest is configured for you automatically. And it's true that PyCharm is designed mostly with larger projects in mind. If all you need is to create a single-file script, the benefits of an IDE will be much less significant, and you may well be better off using just a text editor.
To somebody not working on a project large enough to need encapsulating in this paradigm I totally understand why you think its wasted space and gets in the way. One day when you graduate to working on projects this size, you'll understand why the tools an IDE offers is important to getting your work done. Pretty much everyone who has made a career in software development has been there, done that. My first time, it took about 2 weeks to overcome what was basically my own prejudices &amp; I ended up with a sweet setup (Eclipse, PyDev, etc. with my customisations) that was the envy of the rest of the team because I could actually get information about their code significantly faster than they could (as well as manage my own). For example, how many times does a certain 12-line algorithm occur in the entire project (millions of lines of code in hundreds of modules)? You can't grep for it (not easily) but when the IDE has it indexed, it takes a few seconds to get the answer. Say the algorithm is flawed - what functions does that impact, what logic flows does it impact, what parts of a pipeline of information processing should we expect to see differences due to altering this algorithm? BTW the client is in the room, you can't just walk away and say we'll tell you in a few weeks... Comprehend the fact that some projects are so large that the number of people in the world that can comprehend the whole thing in its entirety and in minute detail are so few its doubtful any of them are affordable by your company (let alone are working on the project). You're not going to survive very long without the right toolset for the job. 
Take some comfort in the fact that a lot of good Python programmers are not from a CS background, they just find that Python is extremely useful for their job so they learned it. My advice is to have a goal in mind, something you need/want to do that you could use a Python program to solve, then set about doing it. You're not trying to write the worlds best program, you're just trying to get something that works. Without a specific goal you're going to spend a lot of time sitting around frustrated. Learn the basic concepts first. Even the online Python documentation sets this out very well (IMO) - it starts off with some of the basic CS concepts of branching (decisions) and looping, and progresses to more difficult concepts like object encapsulation and inheritance, generators, functional structures, and so on. There's so many ways you can achieve the end result just remember that the only one that counts is the one that works :- don't worry that some expert could have done it in less time and effort by using some concept you're just not familiar with yet. You gotta crawl before you can walk. If there's a particular distribution of Python appropriate for your field (e.g. Pythonxy if you're into science) get it and use it. Get into the community around it and learn from the people who are from a similar background as yourself. Read code. Read code that's interesting, and try to understand why it works. If you're stuck coming up with an idea to code from scratch, take someone else's code that does something and make it do something else. Practice the concepts you learn. If its looping, make that program loop around something even if the output of that seems retarded - like if its drawing a circle on the screen make it draw 10, a few pixels over from each other, even if that messes up what was a nice picture. Because you're learning what happens when you do whatever it was you did. That'll help when it comes time to debug ;) I learned a bit of Tix by writing an application from scratch that needed a UI because it was going to a manager who needed a simple interface. I started off with a window that would close &amp; exit. Then added a button that would do something else. Eventually it had drop-down menus, date/time select from a calendar with some shortcut radio buttons for common times the manager would use (e.g. working hours), was customisable from a config file, and would draw pie charts &amp; could save data to a CSV file. That data came from executing commands on several remote systems over ssh tunnels - all done by the application with most error cases covered. But it started out as a bland grey window with a "exit" button... (not even using Tix at that point - just plain Tk, I added Tix later and refactored all the graphics come time to use the canvas object for the pie charts, which wasn't an original design spec) Oh, and one final point - get Python 2.7 and 3.1 and become aggravated like the rest of us in all the little idiosyncrasies, like forgetting print is a function in Python 3, and mapping types don't have iterators in Python 2. You'll learn a lot trying to port a python 2 program to python 3. Its actually not hard, just very time-consuming =) 
The point is a very simple one: By having a "project" your IDE can remember all your breakpoints, last positions in files you opened, the files that have been open at last exit etc. Wing IDE does this perfectly well. And all it takes is ONE additional file, that can reside anywhere on your harddrive.
It sounds like you'll want to do some tricky with one of the various [fork functions](http://docs.python.org/library/os.html).
its equivalent to a = a | b which is a bitwise or of a and b e.g. a = 1 b = 6 a |= b print a will print 7 as the answer
Ah, should have figured that out :/ Thanks! 
I was away on vacation with my girlfriend's family for a month with no internet access, in a country home; I took my laptop with python, and a .pdf of Dive into Python. I'd say I messed around with it anywhere between 0 and 3 hours per day on any down time, first by reading the book, then reading the python documentation (you can easily access it from IDLE's help menu, it's a great read, I must've read it two or three times), along the way I also made alot of small and some not so small scripts for things I wanted to get done. For example, we used to play a card game, so I made a little script that allowed quick score calculation at the end of each round, and automatically stored those scores, organizing players from first to last and what not. Then I persisted that data, so eventually we would keep going back to the script to see our scores over the month. Her little brothers were also drawing these monsters by mixing different body parts, but were having trouble coming up with ideas, so I whipped up a 'monster generator' that read a few files with all the different body sections (eyes, hair, arms, misc..) that they could easily edit, and would spit out a new idea for a monster, something like: Your monster: Eyes: red, eye-patch; Hair: on fire; Legs: 6 legs; This was a great learning experience for me, and in turn I got to see them use it (and all the horrific monsters that it spawned), and this is extremely encouraging. Good luck!
Pass 0x08000000 ([CREATE\_NO\_WINDOW](http://msdn.microsoft.com/en-us/library/ms684863%28v=VS.85%29.aspx)) as the creationflags argument to Popen.
How about the device generates a new key for every time it need it ;)
This might be helpful: os.execv(os.path.abspath(sys.argv[0]), sys.argv)
I have not just read the code I have contributed to logbook. Nevertheless I think a function which allows you to get the current handler would be enough for debugging purposes. Your proposal requires everyone to expose their loggers somehow. Also there is the problem of the stack, we have several handlers which could not be implemented without it. One could work around it by creating joined handlers which are not actually used as loggers but this just adds another level of indirection just to get some sort of "better design" based on issues nobody knows we will even have and nobody but you complained about until now. In fact apart from you and the author of logging I haven't heard of anybody who seriously looked into it and didn't like it. Anyway Pida has been or is still being ported over to logbook from logging and Flask will see that change in the future, I believe that will give us a lot more interesting information and feedback after which we will surely see if the design is too magical.
This one is more generalized, neat!
But fortunately you can get the correct result by going 2//3 = 0. :)
That's one of the possible solutions I was trying to suggest with &gt; Devices would certainly need to have a master key embedded in them to prevent their key from being revoked. A device could generate a key every time it needs one, or every time it discover its previous key has been revoked. I don't know enough about the specifics of the protocol to know if one of these would be advantageous, so I was deliberately vague.
The TL;DR at the beginning of the post says it all. If you read the original article this blog referrs to, or if you really are curios what the fuss is about, this is an extremely detailed evaluation of another popular python bloggers crticiam of stdlib logging.
In the example project in the linked article, I only see an empty directory being created by the "Create New Project" tool. Where's this "overhead" you're talking about? Sure, there's a project file or directory somewhere, but without that, you can't really have an IDE. Looking at the example project again, I don't see why this IDE couldn't be used for simple scripts. I don't see any project cruft that would get in the way and highlighting, completion, etc is, IMO, well worth the "cost" of a project file.
I've liked `logging` for a long time. The two main things I've had a problem with are: A) Unit-testing with loggers. Who knows how to do this best? B) Finding attached log-handlers. I work with other people. Let's start with that, since so many coders seem to think the best solution is always completely logical. Sometimes, I need to delete the handler that was created elsewhere. If it wasn't stored -- which is normal when using config-files -- I cannot find it. I think there should be an iterator over all the handlers for a given logger.
&gt; A) Unit-testing with loggers. Who knows how to do this best? I hope to post some suggestions about this on the blog, in due course. Of course anyone who has helpful suggestions can chime in right now. &gt; B) Finding attached log-handlers. Depending on the specifics of your scenarios, it might be a bad idea to remove handlers added by other people. First of all, library developers should not add handlers other than NullHandler to any of their loggers. (There's never a need to remove a NullHandler instance, as it's basically a no-op handler.) If any of the people you work with are writing library modules for your use, get them to desist from adding handlers to any library loggers. The place to add handlers is in the application - which may or may not use libraries which use loggers. The application developer will know their end-user audience and what their needs are in terms of logging, so they are best placed to decide how to configure handlers for an application. When the application runs, the logging calls in the applications and the libraries will be sent to the configured handlers (dependent on the levels and/or filters configured, of course). Each logger has a handlers attribute which holds a list of handlers for that logger, but you should not be manipulating this. Often the handlers are not attached to a specific logger but to some ancestor logger, so a particular logger's handlers list will be empty, but logging calls made to it might still result in logging output. If you have a more specific scenario you want advice on, please post details on comp.lang.python.
&gt;&gt; B) Finding attached log-handlers. &gt; Depending on the specifics of your scenarios, it might be a bad idea to remove handlers added by other people. this feature is also needed if some code wants to decide *not* to add a handler, seeing that someone has already done so. This is the one last thing SQLAlchemy needs from the logging package so that our "echo=True" flag can establish a handler only if none are present already. 
I can provide this functionality by adding a Logger.hasHandlers() API which will check the logger and all ancestors (until propagation flag is false) for any handlers being configured, and return an appropriate boolean; will that be good enough? Of course, you'd need to be careful to call this late in the day, after application code had configured logging. BTW, Armin Ronacher has posted [here](http://www.reddit.com/r/Python/comments/ddkal/django_vs_web2py_what_do_you_use_and_why/c0zomwf) on Reddit that "I see how SQLAlchemy is trying to get rid of loggers". Do you know what he's on about? Google didn't show up anything.
Thanks for the awesome logging module. In my experience it does what it needs to do and does it well.
"One day when you graduate..." *chuckle* That's pretty funny! Gee Dad, it's sure good that YOU were here to give me the benefit of your wisdom... Oops, EXCEPT for the fact that I've worked on a number of projects in my last 30 years of software development that exceeded 1MSLOC, so maybe I've done a little bit that exceeds your threshold. It's probably better to make fewer assumptions about the ability and experience of the questioner.
But, don't you think that they should hide the "project" details from you, much as Outlook hides the file operations. (You've got to be doing something really out of the ordinary to use the File menu on Outlook. Sure, they missed the mark in other areas, but that was a nice piece of design.) Otherwise, it's one more thing for the developer to think about when they're in the middle of work.
That directory is exactly the kind of overhead I'm talking about, overhead for the coder. Think about the ubiquitous USB, and how there's only one way to correctly insert it. Now, with a little more design the silly thing could have been designed so that it could have been inserted either way, and thus many man-hours could have been saved each day. Now, think about all of the directories that are created by IDE's, and you've got much the same situation. It's easier for the IDE maker, but now every creating every little piece of example code adds another directory that will show up to the poor coder. Eventually it's just a mess!
Thank you for the very well-thought-out reply. The point that I was making, admittedly poorly, is that most IDE's are all about the "I" (Integrated), rather than supporting the "DE" (Development Environment). They try to integrate so much into the tool that it's all but useless. Consider, for instance, the Rational Apex environment. Consider it, but don't USE it! Bells and whistles galore, it sometimes even takes a coder a while to realize that they have to navigate a pull-down to do a compile! Yep, there are quick-n-easy ways to do nearly everything else, I'd bet that there's even a button to send flowers to your Mum-in-law, but if you want to actually COMPILE, nope. So, having lived through development Hell a few too many times, I'm knee-jerky about tools that try to do too much by forcing their own style and structure on top of the code. 
I was referring to this here: http://www.sqlalchemy.org/trac/browser/lib/sqlalchemy/log.py#L62
Oh, right ... the bit where it says, &gt; limit the number of loggers by chopping off the hex(id). some novice users unfortunately create an unlimited number of Engines in their applications which would otherwise cause the app to run out of memory. I find it hard to interpret that as "SQLAlchemy is trying to get rid of loggers", but it could easily be misunderstood as "SQLAlchemy can't use stdlib logging loggers, trying to move off them onto something else" - which is how I read your comment, even though you perhaps didn't mean it that way. Particularly as the context of your comment was the alleged trouble various libraries have with stdlib logging. It's somewhat easier to interpret the actual comment as, "sometimes you need to program defensively against mistakes made by novice users". It seems likely that creating an *unlimited* number of Engines would lead to out of memory errors even if there were no loggers per Engine. If there are N loggers per engine, then (roughly speaking, simplifying, thinking in rough orders of magnitude) perhaps the out-of-memory condition might occur N times more quickly, and by reducing N, you defer the time of reckoning somewhat. The stdlib logging documentation gives several ways of achieving certain results without the need to create unbounded numbers of loggers. 
The wording of the comment was changed at one point. Previously it said this: http://www.sqlalchemy.org/trac/browser/lib/sqlalchemy/log.py?rev=4012%3Aa54918fca925#L54
Sure, but the revision you've linked to was 2 years ago, and it seems reasonable to expect you to check your facts again before recently posting something that could be misinterpreted to your advantage. 
Separating your framework from your application is a bit like separating your foundation from your house. It really does sound to me that you're not trying to make a python web framework though, you're trying to make an executable, installable web scripting environment, which happens to use your form of python. It sounds like the application layer could be done in lua or javascript without really changing any of the core design decisions that you cite here.
So the change of the comment above the code invalidates the fact that you can't unregister a logger?
It's never been a secret that loggers remain in memory and aren't garbage collected. I don't try to pretend otherwise, and never have. I merely state that your comment "I see how SQLAlchemy is trying to get rid of loggers" in the context I mentioned might give the casual reader the idea that the SQLAlchemy project has some problems with the use of stdlib logging and are somehow trying to discontinue their use of it. That doesn't appear to be the case. With regard to the fact that loggers once created remain in memory, I say that the memory utilization of those loggers is not a significant problem except in pathological conditions such as buggy code. If any report of such a problem were made on comp.lang.python or bugs.python.org, I would be quick to point out how the problem could be avoided. The stdlib logging documentation already shows ways in which context-sensitive information (such as a database connection instance id) could be output to a log without the need to create an individual logger for that connection instance. Perhaps the way SQLA works in this area could be changed to take account of this, but it may not be a priority for the SQLA team as they currently have something that works satisfactorily. If the SQLA team wants to look at it again and wants some input from me, I'll gladly give it.
True. In fact we distinguish "programmable in Python" from "programmed in Python". In US house foundations are made of concrete while the houses themselves are often made of wood. We cannot control how solid are the houses (apps built by the users) but we want to make sure foundations (the framework) are solid and cannot be messed up too easily.
I have found Coding Bat to be quite good once you get past the first chapters of a Python book: http://codingbat.com/python
Yeah, I'm going to jump on here. I learned python because of Django. Django takes a very structured, practical approach to web development, There are lots of jobs available, and it powers loads of really great websites. I've cut most of my bids on complex projects by a significant margin, and gotten tons more work. That's the best compliment that I can give django, because it has so significantly affected my bottom line. 
"if there were several competing implementations of regular expressions in Python" oh, there are... eg. http://github.com/axiak/pyre2 and this is a very good thing, because the stdlib regexp is slow as hell most of the time. (i know, huge generalisation and i have no benchmarks at hand, but my experience is ~10x slower than comparable perl implementation. re IS slow)
It means, if you have three engines in your application, we give them each their own logger, with a name identified by "sqlalchemy.engine" plus a hex string. This is primarily so that you can set echo=True on one of them, that sets the INFO level for the logger matched to that engine, it will write to its logger, but the other two won't. What we really should do is just use "sqlalchemy.engine.Engine" as the log name for all of them - the hex strings are ugly. Then just make echo=False to disallow calls to log.info() before getting into the logging system...or perhaps the filters you illustrated the other day could accomplish it. We now support configurable logging names per-engine if you want to distinguish between multiple engines. 
There's also `regex` on PyPi, which implements the full regex language and may be the regex library in 3.2.
Even with a list of handlers, I think I'd need handler names, in order to distinguish them. I don't disagree with your points. My suggestion could be more about management or psychology than software. Do you know a good therapist?
Also there is ponyguruma: http://dev.pocoo.org/hg/sandbox/file/tip/ponyguruma
This. As I've said before here there is nothing long with web2py if you like web2py, but it isn't in the same category as something like Django or Flask.
Right, but as far as I know they're there because the stdlib package falls short in some way ... in this case performance, or in another case it might be because of some functional drawback such as unacceptable backtracking behaviour, or whatever. As I've said elsewhere, I have no intrinsic problem with alternative logging libraries. The problem I have is when incorrect, unsubstantiated statements are made about the stdlib logging code with strong suggestions that you stop using it. My solution to that problem is just to try and set the record straight. However, if the competing re implementations were all slightly different in their syntax and/or semantics and you had to integrate several libraries using these different implementations under the hood, are you saying this would always be trivial to do, in all possible scenarios?
If this is indeed about the vegetable, I will be a happy man.
This one is not, but I have processed data using a head of cabbage many a time before! 
I see - I thought it was about outputting engine-specific data into the log. As you say, you should be able to do this with a filter: class EngineFilter(logging.Filter): def __init__(self, engine): self.engine = engine def filter(self, record): return self.engine.echo class Engine(...): def __init__(self, ...) self.logger = logging.getLogger(...) self.logger.addFilter(EngineFilter(self)) It doesn't much matter how you name the logger except that if you use the instance id and if you are deleting and re-creating engines a lot, that would lead to a lot of loggers being created. However, you could handle that in a number of ways e.g. use a counter which recycles and assign a value to each engine as it's created so that each engine is guaranteed to have a unique ID 1-&gt;N. Then you can just append the value to get the logger name, sqlalchemy.engine.Engine.1, .2 etc.
I can't think of one off-hand, but I'll put my thinking cap on ;-)
 &gt;&gt;&gt; category = ['django','flask'] &gt;&gt;&gt; 'web2py' in category False
The problem with filters is that they are executed very late. At that point the log record is already created which in logging is not the best performing operation. I don't think this is a viable option for SQLAlchemy.
I quickly created a testcase for that: http://paste.pocoo.org/show/264692/ Results: Current solution: 10 loops, best of 3: 202 msec per loop Filter based: 10 loops, best of 3: 285 msec per loop
&gt; I don't think this is a viable option for SQLAlchemy. Let's see what Mike says. I'll investigate further. Edit: After thinking on it a little more I'm not sure Filters are the right approach, and not just because of performance. Thinking cap on :-)
&gt;Separating your framework from your application is a bit like separating your foundation from your house. Separating your foundation from your house sounds rather bad. So are you implying the web2py approach is misguided? If so, why do you say that -- you don't appear to offer any specific (or even general) arguments? &gt;It really does sound to me that you're not trying to make a python web framework though... How do you define "python web framework"? The web2py framework as well as all web2py applications are written in Python. How is that not a Python web framework? Or perhaps more to the point, assuming it doesn't meet *your* particular definition of "Python web framework", why does that matter? In other words, if you can use web2py to write robust MVC web applications using Python, does the semantics of "Python web framework" really matter? &gt;which happens to use your form of python. What do you mean by "your form of python"? How does web2py's "form" of Python differ from other frameworks, and if it does, is that good or bad (or neither)? &gt;It sounds like the application layer could be done in lua or javascript without really changing any of the core design decisions that you cite here. Assuming this is true, is the implication that there would be something wrong with that, or is this just an interesting observation (your first sentence would appear to imply the former)?
go ask on http://stackoverflow.com/ reddit is about social bookmark and what's new on the interwebs. Do you want to spam everyone's bookmark with n00b questions?
I suggest learning Python. I suggest applying what you've learned with a framework for the web. I suggest learning that frameworks convention and styles. Opinions about how you like things to work will come afterward. I use Django. There are many others that are just as great. Python is an awesome community. Here's how I'd do it in Django. 1. Use Django-registration (a django-app which if you learned the ideology behind Django you'd get). 2. Django helps you build forms that connect to the DB with ease 3. Define your urls in Django to get this info from the database (built-in) 4. Determine what you want users to filter by then have Django pull the right information to each page through it's ORM. However, this is contingent on not only learning Python, but also learning Django. You've already overcome one of the big problems a lot of people getting started have: having something to build. Now your next problem will be not being completely overwhelmed. Take it step-by-step and break down the problem into small chunks. User can create accounts turns into several tasks, such as "Read django-registration documentation" etc. Good luck, and follow-up if you have questions. There are other great web tools other than Django, and many much simpler. 
Well, you can probably define a category to which Django and Flask belong that web2py does not, but you could easily do the same for Django and web2py, excluding Flask (e.g., full stack vs. "micro"). In any case, is there a point to this statement? What are the implications of the supposed set memberships of various Python web frameworks?
No, reddit isn't about social bookmarking. Reddit is about community and sharing. Asking questions is more than welcome, we don't need asshats scaring people away from this subreddit.
Is the browser editor really an IDE? Last time I tried web2py I played with the browser editor but it was nothing close to a modern IDE (or even one from several years ago). Did I miss something? Does it include source control integration, code completion and code-outlining? 
Spend 1 day to build a blog using Django. Spend 1 day to build a blog using Bottle. Spend 1 day to build a blog using Web2py. Pick one that works best for you.
I regret that I have but one upvote to give to this comment...
Some things it always did: 1) if you have mercurial install there is a commit page (revert and marge would have to be done manually from shell) 2) there are two editors in web2py. The default is edit_area and works on most browser but not autocompletion. The other is Amy editor and it has auto-completion but does not work as well as we hoped so we do not make it default. Ask the mailing list if you want to know how to enable it. 3) admin helps you keep the file organized, prevent you from putting the wrong files in the wrong place, introspect the files provides links to run specific controller actions, run specific tests, translate text (internationalization) and provides a web based shell. 4) It does have a conflict resolution mode if two or more people edit the same files online. 5) Most importantly it provides an interface to uplaod/download apps and upload/download plugins within apps. This is not mean to compete with Eclipse (which you can use with it) but something different. It is not just an editor.
There is another community that likes sharing, it's called facebook. We already had proggit eternally septembered, I don't see how r/python could avoid it if keeping this way. Take a look at your right side area, it says this subreddit is for *news*. Besides, what's wrong with Stackoverflow? Is r/python really more helpful compared to a more dedicated site? If anything a starter needs is less crap advice and more dirt on hand.
This is why I love reddit. A redditor gets out of bed too early, turns on computer, goes straight for reddit and makes thoughtful comment.
Try Flask over web2py, there's some seriously good buzz about it at the moment
Something like this then? http://www.reddit.com/r/Python/comments/dd9j7/stable_badass_python_web_hosting_coming_soon/ A "heroku" for Python? http://heroku.com/
This is a weekend project for an intermediate django user.
You could do this using a relational DBMS like MySQL or PostgreSQL, but it'll be a bit awkward. At least take a look at document-oriented databases like MongoDB and CouchDB. Edit: Why the downvotes? A document oriented-database would be well-suited to his irregular schema, and investigating this will affect how long it takes him to get started, which is what he's asking about. If you disagree, don't downvote, adding nothing to the discussion -- *reply*.
You'd be surprised at the amount of processing power in the average vegetable field.
Logger.hasHandlers() now checked into py3k branch, r84917. I haven't added to other branches because they are closed for new feature additions.
I'd not focus too much on figuring out what works best. My advice would be to just start with Django (or whatever you're more familiar with) and start building. Building something tangible is the best way to learn. The expectations that you set for yourself are certainly achievable. Just set out and let us know where you get. Cheers!
a regexp lib and a logging lib are very different (logging has to work with the lib and application... it has an interface to the app; when an exotic regexp module is used inside a lib, it may be a painful additional dependency, but that does not force you to use the exotic lib also in your app)... so it maybe is not the best of comarisons. i just wanted to point that and positive effects of competition out... i see *your* point in trying to set the record straight and from what i have read in your blog it makes sense. tutorial/cookbook examples like your webapp example should help a lot of people using your lib the right way. also: maybe it was important that someone tried to implement something better, just to start off a discussion and improvements. the sqlalchemy &amp; logging thread here is the perfect example :)
&gt; so it maybe is not the best of comarisons You're probably right about that, so I stand corrected. &gt; maybe it was important that someone tried to implement something better, just to start off a discussion and improvements. the sqlalchemy &amp; logging thread here is the perfect example :) Sure, no problem with that. But improvements and better documentation would come about a whole lot sooner if people asked questions and/or made suggestions when they need the information or suggested improvement, rather than waiting for competing implementations to appear :-) - I like to think I'm reasonably responsive to requests made via comp.lang.python and bugs.python.org ...
Not really. I try to use whatever is the prevailing idiom in the language in question. I have the impression that inscrutable use of zip(), map(), filer(), et al is viewed as 'pythonic' and is what a python programmer would understand and use. It's also pretty cool to avoid having to write Yet Another Loop. Also in Python &gt;3 the parallel pixies might come and make it run faster.
Python 3 isn't retrocompatible with 2. It's great, but many important python libs haven't yet been ported from 2 to 3 and transitioning might take a lot of time. As a beginner, I'd advise going with the latest 2.x python to avoid any pitfalls. All the libs you might need will just work fine. Moving to 3 will be very easy and you may even import some Py3 goodness in Py2 when you feel ready using "from future import...". TL;DR: Go with 2.7 if you're starting.
I'm not sure I'd choose Flask for much. As a micro-framework it's pretty awesome, but the problem domain for micro-frameworks is pretty limited. You can do one thing in them, but expanding much beyond that one thing is usually an exercise in frustration. For anything that's got the potential to grow, I think you're best to use a larger-scale framework that lets you do so. Bottle falls into the same trap.
This is not an Heroku for Python. You can have a look on http://en.wikipedia.org/wiki/Continuous_integration for a quick overview on what Continuous Integration is.
*Potentially*. The OP is looking for a framework to let people create web forms (models) and for others to fill out these forms, which is pretty simple. Flask shouldn't be limiting here. What's more if you work your way through the examples and docs in Werkzeug/Flask you'll have a better understanding of what's going on under the hood than trying to repurpose Django which has a 'django' way of doing things. I'm not against Django, just that if you dive straight into Django's magic you might not appreciate what's going on under the hood. Flask also supports some useful stuff like Jinja2 templating (bit more powerful than Django's) and SQLAlchemy, and [while it's a micro framework it's not necessarily only useful for toy sites](http://flask.pocoo.org/docs/becomingbig/#becomingbig).
For something simple like this you don't *need* a framework (like Django) but you probably find it easier to do using it, once you've learnt Django. We did the exact same thing a couple of years ago, I gave it to the guy I was managing at the time, a Django n00b, took him about a day. His biggest hurdle was getting his head round object orientation having *never* used it before (he was a PHP nut).
Complete code in web2py (assumes scaffolding app): # some aliases for readability store_some,with_a,input_form_for,a_page_with,a_list_of=db.define_table,Field,crud.create,dict,(lambda t: db(t.id&gt;0).select(orderby=t.name)) dvd=store_some('dvd',with_a('name')) software=store_some('software',with_a('name')) response.title='Collections' response.menu=[['dvds',0,URL('my_dvds')],['software',0,URL('my_software')]] @auth.requires_login() def my_dvds(): return a_page_with( form=input_form_for(dvd), items=a_list_of(dvd) ) @auth.requires_login() def my_software(): return a_page_with( form=input_form_for(software), items=a_list_of(software) ) You can add the sorting part as an exercise. ;-) You can add the comments, etc. using [plugin_wiki](http://vimeo.com/13485916)
Am I the only one who wants to see this 20 minute implementation?
map, filter etc. seem to be rather controversial in Python circles. I don't really understand why, but a lot of people seem to have severe objections to using them, including Guido himself (he wanted some of them completely removed from py 3). 
you started with "take some comfort" and after reading this I'm now very afraid...
As someone who "started" a few years ago, and then promptly forgot about it, then picked up 3.x six months ago, I prefer 3. For me, it feels better. For me, it *makes sense*. And, being someone who has no real intention of doing anything useful with it, lack of libs doesn't bother me. But that's just me. If library support is a concern, 2 is definitely the way to go, sadly, but if that doesn't bother you, try both just to see how they *feel*. 
Flask has a growing number of [extensions](http://flask.pocoo.org/extensions/) for specific tasks - such as SQLAlchemy integration or email. Beyond that, of course, you can use any Python package as with any other Python web framework. So what exactly about Flask prevents you from building something larger ? What is that "one thing" that you can do with Flask ?
Could you use two processes? One is the loader. It loads settings, and has a while loop that keeps launching the main program. Then the main program. When the main program is done, it exits with a particular exit code that tells the loader to end its while loops. (Or the other way around - have a particular exit code mean "reload the settings and restart"). If you want tips on launching a new process without it popping up a new dos box, there's another thread on reddit/r/python at the moment addressing this issue. utorrent probably just reloads lots of its modules internally, which is what I'd have recommended to you before you detailed the nasty situation you're in. 
Almost. `a |= b` is equivalent to `a = a | b`, but `|` (_binary or_ for e.g. integers) is different from `or` (_logical or_ for e.g. booleans): &gt;&gt;&gt; 1 | 4 5 &gt;&gt;&gt; 1 or 4 1 
It's been 56 minutes. Let's see it!
Never said 3 didn't make sense. I agree it does. But a newbie wanting to have fun with python might want to use it for webdev... and most frameworks/tools rely on 2.x He may also want to use some major libs (from ui to image manip, who knows) and most of them still rely on 2.x and will for many, many more months (if not years). Finally he would certainly like to follow existing tutorials, dig into existing snippets/apps and most of these will be 2.x too. Considering how easy it is to move to 3 once you know 2.x and knowing that you can even import future features into 2.x, it seems like the right choice to me. Avoids loads of potential frustration. Your mileage may vary.
This would be pretty easy to do. Since you've already done some Perl and PHP, I'm assuming you're also pretty comfortable with HTML. I'd suggest going through the Django tutorial to get a feel for it. You should be able to get something done in a couple days or less. 
3.x is the new shiny thing. 2.x is what everyone is currently using (in production &amp; development). 3.x is a fantastic upgrade, but 9 out of 10 libraries have yet to roll out 3.x support, making the release essentially useless for another year or two. Everyone's still getting up to speed, even the package managers (pip, easy_install). Save yourself some serious trouble and use 2.6+ for the next few years. The transition will be simple in a year or two.
Start with 1 hour of spare time and: http://www.diveintopython.org Then browse through: http://docs.python.org/release/3.0.1/whatsnew/3.0.html and decide. I would stick to 2.x as it is still better supported and will most likely stay so for the next 1-2 years.
Python 3 *should* be nicer; that's the point of a new version. If you're doing much real work with it, you're better off with 2.x, but if you're just futzing around and learning some Python, then 3 is cool.
I'm not implying that the approach is misguided (I honestly don't know enough about web2py to say that). I'm saying that calling it a python web framework is maybe a misnomer. It seems much closer to a python web scripting environment. I think that calling something a framework does matter. When you toss out certain conventions of commonly accepted Python programming language like, imports, environments, etc, in favor of your own approach, then an experienced python web developer will have to not only learn your methods, locations, and what they do, but they will also have to learn all of the things that you do differently from python in a more generic sense. Web2py seems to be saying this: "we have created a program that you can make web applications with, and you will write your logic with python". I don't see that as bad, but it's a different set of goals than django or flask, who seem to be saying "here are a common set of components that you need to build web applications in python. Another example: When you program something with flash, you use actionscript. When you program something with web2py, you use python. That's what I mean, and that was my observation. I realize that it's a simplification, but if say, you replaced exec with a lua intreperter, you could use lua. 
I have used the registration of pycon 2009 and it was awful that after registration, I had to login again with google in order to pay with google checkout. Does this work the same?
The system you refer to (web2conf) was the grandfather of this one (conf2py) and they have a different workflow. conf2py let you login using your existing OpenID (Google for example) or OAuth account (Facebook for example), the prompts you with a registration, and for your credit card information. It uses Authorize.Net instead of Google checkout therefore there is no secondary login. We changed it for a few reasons: as in your case, users did not like to have to login twice; sometimes people did not get the registration emails and that was a problem. Moreover web2conf used google level 2 notification, that means the system was being notified by google when people cancelled their payments or were being refunded and therefore it was keeping its own simple accounting. That worked great (in the sense that data was always current) but administrators started to expect a full fledged accounting system and started to get confused on how to deal with partial refunds. Good or bad, the new system is much simplified from that point of view. There are many other changes, including the layout and the inclusion of a paper submission/review management system. conf2py follows a more traditional and academic submission/review workflow, as opposed to web2conf, which was based on custom specs from the Python Software Foundations. We hope the new system will appeal to a broader audience. 
I'd also suggest that you learn Python to some extent first. Diving right into frameworks might be a frustrating experience if you don't have any idea what happens in the background. Stop accumulating links to tutorials etc. instead pick one and do it through. The one that you probably won't regret is: http://www.diveintopython.org/ Once you've done that, you're ready to browse through the most popular Python web frameworks and select the one that feels most comfortable to you. It is not very easy to estimate the time it takes for you, as you're learning something from the ground up (I'd say you'll have your alpha version done within two weeks of everyday learning and experimenting). But when you've learnt how to use e.g. Django, you'll see that tasks like these take approximately 1-2 days to accomplish + the amount of time to design&amp;fix the UI.
I agree with this statement. I'm just learning python now and 3 feels like a more consistent language. I've been using 2 or 3 depending on what libraries the project needs -- if I can do it in 3, I do.
Use an easy to read and scan framework. Don't use Django( it's good ), don't use web2py( it's friendly ), don't use Pylons( it's the best and worst of the previous two ). Mind you all of the tools mentioned are good. Just not good for a newbie. From a scholastic point of view, I feel that you need something that's clear and without clutter. Try Flask, Bottle and Tornado. Here's why: There is a very straight path between idea , code and implementation that's possible in a short single file. Once, you learn the concept of modules and applications, you can easily port your clean code to a Django, Pylons or Web2py structure.
Now I understand better your original comment and I agree with most of what you say. Yet, I think the distinction is more semantic than factual. For example applications, although executed, can import any third party python module you may have installed on your system. It supports WSGI middleware and can call other WSGI applications like Pylons does. It connects to web servers using Python adapters (mod_wsgi, mod_python, cgi, or fcgi). The fact that it is programmable in Python is the defining characteristic of web2py and if we were to replace it with a lua interpreter it wouldn't be web2py anymore. The opposite instead is a possibility: rewrite web2py in C for speed and still be able to run your Python apps. That could not be done with Django or Flask. Minda that we have no plans to do so. We make the web2py binaries with py2exe/py2app.
Yep, a quick read to the actual linked page sorted that out. Completely missed the point here by parsing the title to what I expected it to be.
filters seemed entirely neat. the overhead is slightly concerning, mostly concerned about overhead when the logging is turned off, in which case we don't call the logging functions anyway. if you feel like patching, the goal is 1. remove the hex(id(self)) expression from def logging_name(), and 2. echo=True outputs logging only for the engine on which its called. http://www.sqlalchemy.org/trac/browser/lib/sqlalchemy/log.py
One of the major Python packages (NumPy) was just ported to Py3k, so you could go either way IMHO.
"3 if you can, 2 if you need to"
Every line of "real work"* for me is on 3.x. \* my day job
aw are you going to cry?
I dont know y this is getting downvoted, my man has a point here
&gt; 2.x is what everyone is currently using (in production &amp; development). As long as I am included in "everyone", this statement is false. I've been running on 3.x for around a year now. The code is 2.x/3.x compatible but I haven't had to run on 2.x in months, so I don't install 2 on any new machines I add to our lab. &gt; 3.x is a fantastic upgrade, but 9 out of 10 libraries have yet to roll out 3.x support This would require more work to refute than I'm willing to put in at the moment, but I really feel this is a pretty big over-exaggeration. Although many projects do not support 3.x in a production-ready release, a lot of them have a plan in place, and many have a branch available for people to check out (e.g., Django has had one for some time now, see MvL's bitbucket). [This graph](http://dev.pocoo.org/~gbrandl/py3pkgs.png) shows the number of Python 3 packages available on PyPI (updated daily), and although that includes some new packages and not just ports, the number is clearly rising. Let's say half of those are new and half are ports, or really any ratio you want -- the number is rising either way. A big roadblock for many was NumPy, and they just recently released Python 3 support. I would expect the coming months to show a rise in 3.x libraries just due to that. A few days ago [Genshi was ported](http://pythonsprints.com/2010/09/17/genshi-python-3-sprint/), and there are plenty more opportunities for PSF-sponsored porting sprints to be funded. *** Overall, I really think 3.x is more than a shiny new thing. There are areas where trouble will be had (web, for instance), but those problems are being worked out and we're getting closer to a time where 3.x is the answer for everything. That time is probably sooner than a lot of people realize.
I'd say 2, as there's still quite a lot of stuff that hasn't been ported over. Django is still using 2.6, Google App Engine currently uses 2.5 so if you intend to make web stuff in python 2 is still the way to go. If you're planning on writing pure python, then you might as well learn 3 as 2, but otherwise I'd stick with 2 for the time being
Nice, what kind of stuff do you do with it? For me, Pylons is probably my #1 hangup.
There are 11714 packages on PyPI. Your graph shows that nearly 250 of them are tagged as compatible with Python 3. I'd say "9 out of 10" was an understatement.
A lot of testing stuff for a commercial historical tick database (it's kind of like a DVR for financial markets). Most of what we're doing is performance and load testing, and there's a regression test framework around a C extension, along with a number of wrappers around maintenance tools that we write tests for. Since I don't really do anything with the web I was able to move to 3.x earlier than a lot of people. We deal almost entirely with numbers so my transition was pretty easy and focused mainly on syntax changes.
Same here. Personally I'd spend at least 20 mins looking at reddit half way through it.
Have an upvote for supporting that. Of the 11714 packages up there, a lot of them are relatively small that could be changed, and a lot of them are packages of a greater project that will probably all be ported at once (e.g., there are over 100 "zope.something" packages). I guess I'm just thinking of major packages, and should have stated that. My argument does fall apart though :/
That's exactly why I always feel that Python 3 is a great effort on a wrong direction. The main problem limit Python from more wide usage is that we have 5 major Python implementation, but none of them are fast enough.
There is clearly some room for clarification on the metric, but I do not think that 11714 has much at all to do with real world usage. Saying that 9 out of 10 packages you need in a likely given project are unavailable is an overstatement if half are available. That doesn't mean that it isn't a likely deal breaker if even one key package is not available, but saying only ~250/11714 are available has little to do with common experiences, since the most active packages are also those that receive the most attention.
A few months ago I would have said go with version 2 but now I think it really doesn't make a big difference. If you start with 2 then you will have no problems with the external libraries. They are all going to be available to you. For a beginner this may not be a big deal. The difference between 2 and 3 is significant but these differences are not immediately obvious for a beginner. In other words 99 percent of what you learn with 2 is going to be still valid with 3. If you keep using Python you will have to read others' code so you might as well learn 2 first then 3 so that you can read both. Reading code is a very import part of Python philosophy. Code is written to be read by others. This way you wouldn't feel uncomfortable reading some existing libraries and convert them to 3 by yourself. Summary: Either way is fine but starting with 2 may have some advantages.
&gt;I'm not implying that the approach is misguided (I honestly don't know enough about web2py to say that). Then maybe the separating-foundation-from-house analogy isn't quite appropriate. &gt;I'm saying that calling it a python web framework is maybe a misnomer. It seems much closer to a python web scripting environment. Whether or not it's a "web scripting environment," it's certainly *also* a web framework. The term "scripting environment" does not capture the full scope of what web2py offers, which is a framework for building web applications (particularly, using the MVC pattern). It provides all the things a web framework would be expected to, and it's used for the same purposes (and in the same manner). Just because a given framework does something distinctive doesn't mean it's no longer a "framework". Every framework has its distinctives -- presumably these distinctives are what motivated the creators to develop their frameworks rather than simply rely on/contribute to existing frameworks. &gt;I think that calling something a framework does matter. Yes, to some degree, which is why your claim that web2py is not a "web framework" is troubling. When someone is looking for a "web framework" to help them develop web applications in Python, by excluding web2py from "web frameworks", you're excluding it from consideration for this purpose. For example, do you think it's inappropriate for web2py to be listed [here](http://wiki.python.org/moin/WebFrameworks)? If someone is considering Django, Pylons, Flask, etc. for building a web application, should they not also consider web2py? &gt;When you toss out certain conventions of commonly accepted Python programming language like, imports, environments, etc, in favor of your own approach, then an experienced python web developer will have to not only learn your methods, locations, and what they do, but they will also have to learn all of the things that you do differently from python in a more generic sense. "toss out" makes it sound unthoughtful and gratuitous -- but web2py's design decisions were made with a great deal of thought in order to meet a particular set of needs and preferences (which may not be everyone's needs and preferences, but which are legitimate nonetheless). Also, you indicate that you "don't know enough about web2py" (presumably you haven't really used it), so it's puzzling how you would conclude that an experienced Python developer would somehow have a lot to learn in order to figure it out. As far as I can tell, web2py has lots of similarities with other Python frameworks, particularly Django -- if you're already familiar with another framework, you would likely have an easy time picking up web2py. As for "all of the things that you do differently from python in a more generic sense," what exactly are all of these things? Once you understand there are a few modules you don't have to bother importing (because they're executed), are there really lots of other things done "differently from python"? &gt;Web2py seems to be saying this: "we have created a program that you can make web applications with, and you will write your logic with python". "...Furthermore, the program we have created is written in Python -- and you can modify any aspect of it if you like, just as with any framework. If you really want to, you can also use a different template language (e.g., Genshi) or ORM (e.g., SQLAlchemy). You can even use the web2py template language and web2py DAL (database abstraction layer) outside of web2py with other frameworks/applications. (Of course, replacing core components of web2py or using them outside of the framework is not generally recommended, but possible if needed.)" Hmmm, this is starting to sound more and more like a "web framework" after all. ;-) &gt;I don't see that as bad, but it's a different set of goals than django or flask Sounds more like a somewhat different under-the-hood technical implementation meant to achieve largely the same goals. In fact, Django may actually have more in common with web2py than with Flask in terms of the goals it is meant to achieve (i.e., the full-stack vs. micro distinction). &gt;who seem to be saying "here are a common set of components that you need to build web applications in python." I think web2py is saying this as well. &gt;but if say, you replaced exec with a lua intreperter, you could use lua. But web2py doesn't use a lua interpreter -- it uses Python. So, it's a Python web framework. 
If you want to understand what's under the hood, use Bottle. It has only 1 (one) file.
To be honest, Flask is a competitor of Bottle, or other microframeworks. Flask does not compete with Web2py or other full-stack frameworks. 
this is a really bad advice.
Officially, Python 3 is recommended. NumPy recently got ported to Python 3 which is a huge step towards porting other libraries. There is problem which stalls the migration of web frameworks which is about to be solved (or we hope so) http://www.python.org/dev/peps/pep-0444/ I would suggest Python 3. Since you are a begginer, if you don't have to program immediately something with a dependance on a external library, go with Python 3.
http://wiki.python.org/moin/Python2orPython3
For those interested, http://github.com/eldarion/pycon is what Pycon is using now.
Okay, I'll give it a go. Before attempting a full patch, I'll work up a test proof-of-concept and post the gist to the SQLA mailing list, so you can give it the once-over and make sure I haven't goofed in any way. Edit: Proof-of-concept script is [here](http://gist.github.com/589337), and I've posted this link on sqlalchemy-devel too (sent to moderators). No performance data with it, but the impact is much less than with filters because (as Armin pointed out) filters run late, after LogRecord creation. Another edit: Existing gist updated with satime.py to show timing stats. Impact seems to be &lt; 10%.
How about both? Try to focus on learning 3, but try to build a working understanding of the differences present in 2. Many major libraries have at this point either been ported, or are in the process (alpha/beta releases). But be aware that most tutorials will still be using 2, and getting a grasp of the new features might not be as easy.
Congratulations to Brian Rosner. Is there a list of specs somewhere?
For anything to happen: 1.) You have to write a patch that fixes the problem or convince somebody else to write it. 2.) There has to be enough people with good reputation in python core that are willing to review the patch and support its inclusion (give a good opinion on the patch). Otherwise you can submit an issue (you already did) or put it up for discussion in the python general list, or if you have a detailed idea of what the problem is and how you would fix it you can put it for discussion on the python ideas list. Once you have a patch and positive opinion by some reviewers you can try to push for it on the python development list. That said, you will have a hard time convincing anybody but a Malayalam programmer to create a patch for this. Many programmers were against PEP 3131 because they didn't want people to write programs with funny characters that only people from that country can understand. And there are various restrictions already with characters and keywords you can't use in English for identifiers and everybody learned to live with those.
&gt; Should we contact python-dev list ? Yes, do this. Send a polite email to python-dev and all (or most) of the core developers will get it. If your ideas have support, they'll be addressed. Be prepared to code the changes yourself or have them coded -- you'll be hard pressed to find (a) a core dev who speaks Malayalam, and/or (b) a core dev who will code your fixes for you. 
One reason why you probably would want a Malayalam developer is because he would be able to understand and test the changes himself.
this
Interesting. If you were doing serious analysis of those numbers, I expect you would run into problems, though. Aha, NumPy was *very* recently (couple weeks ago) ported to Py3k. Still, if you make a list of big, popular Python packages, the majority still only work with Python 2.x. PyGame is a notable exception. Twisted, Django, Boost.Python (for creating C++ modules with Python bindings), wxPython, PIL, mysql-python, PyCrypto, py2exe...these are a few of the reasons that Python 3 is still just a toy for me.
I'm sure Eldarion has a doc somewhere, James and Brian might be a little non-responsive to email for a few days though due to wedding shenanigans.
I did not mean a list of implemented features, I mean a list of required specs from PyCon. I remember there was one last year (the one web2conf was based on) but I have not seen one this year.
Yeah, I'm sure one exists I just haven't seen it posted anywhere. I doubt Van/Doug/James would have a problem if you asked for it though, there just hasn't been anyone else that needed a copy.
Thanks, I will.
‡≤†_‡≤† 
Not the prettiest Python code I've seen. The Javascript code has interesting error conditions, looks like missing boundary checks; I can break the drawing code by dragging around.
Any reason? Beyond that they pollute the global namespace? (I think I'd prefer having them part of a hypothetical 'functional' package or similar :))
It's good advise considering it's objective. No newbie python programmer should look at web2py's code. It's almost scary. 
While I understand why you submitted the bug, I'd side on the "won't fix" side too. Sure, you can't represent all words in Malayalam, but the rules for identifiers don't allow words in a lot of other languages, such as "don't", "aujourd'hui", anything with an hyphen, and all kinds of other words. We've been living with these restrictions for years, and they're not that big a deal. That is, of course, unless you get enough support and write another PEP and everything else...
Extended but still short version: Go with 3, unless there is a third party library you specifically need that isn't up to date.
py2exe, last time I checked, was barely maintained. cx_Freeze works alright and works on py3k. As for PIL, the homepage says "A version of 1.1.7 for 3.X will be released later.", but it's been there for a while now :(
Stop it Massimo you're gonna take our jobs away.
Beautiful Soup is having some issues right now as well. Beautiful Soup 3.1 adds Python 3 support, but Beautiful Soup had to switch to a weaker underlying parser. Its previous parser, SGMLParser, was removed in Python 3 in favor of HTMLParser, which is more fragile. Beautiful Soup has to be rewritten for Python 3, but that requires supporting both HTMLParser (from the standard library) and a second more robust parser from a third party.
Definitely give Pylons a try. I found it to be much easier than Django or web2py :)
And that's about 80% of all packages.
This isn't /r/politics, we don't act like that around here.
&gt;It's good advise considering it's objective. How do you define "objective"? It's an opinion (i.e., *subjective*), right? If someone disagrees with your opinion, they wouldn't be objectively wrong, would they? Or perhaps you simply mean "unbiased". But is it? Hard to tell from here. &gt;No newbie python programmer should look at web2py's code. It's almost scary. Care to elaborate? You said "all of the tools mentioned are good" (web2py being one of the tools mentioned) -- so is it good *despite* its "almost scary" code? What's so scary? EDIT: OK, it's been a while, and no response. So, let's assume the "scary code" rant is just FUD.
...and who uses *all* packages? If you don't use all of the tens of thousands of packages, this 80% number doesn't mean anything. Most people are affected by a small number of dependencies, and in many cases a few of their necessary dependencies already support 3.x. Hell, a few months ago some PyGame user said he'd switch to 3.x when PyGame supports it...well, it already does.
That is not my goal. My goal is to allow you to do the job in less time so you can spend more time with your family.
what browser? I cannot reproduce the problem.
* ‚Äú[Dive Into Python Must Die](http://oppugn.us/posts/1272050135.html)‚Äù * [Dive Into Python 3](http://diveintopython3.org/) might be better * I like [The Python Tutorial](http://docs.python.org/tutorial/), also for [Python 3](http://docs.python.org/py3k/tutorial/)
Now, THAT is thoroughly awesome. I will have to give that a run later.
I don't mean it in the way that it's only good for "one thing"; that "one thing" can be anything. The point is that compared to larger frameworks like Django or Web2py, which have some concept of decoupling functionality (like Django's apps, flawed as they might be), it's difficult to build larger programs in micro-frameworks. I use Bottle at work for a few minor web service endpoints where all I need from an HTTP server is a few REST-ish calls that return JSON. If I needed to build something larger, however, I wouldn't consider Bottle (or Flask) as being a major contender for the framework I pick :).
I agree, but I don't think that Django prevents you from exploring. When I first started picking up Python (coming from a fairly varied background, but mainly Java and Ruby), I used Django as a stepping stone to get me in. The documentation is superb, and it's not really that hard to dig under the hood. It also doesn't require you to investigate a tonne of other Python technologies, which I disliked about other frameworks (do I pick SQLAlchemy or SQLObject? Why? Cheetah, Mako or Genshi? Why?); you can just get on with making something and then start looking at those later. I'm not saying it's the be-all and end-all; since then I've worked in Bottle, web.py, and am building a pretty major application in Tornado (which doesn't get enough love IMHO :)). Each is suited to a different job; I just wanted to mention that I didn't think Flask would be particularly suited to his "Collections DB", which sounds like the kind of thing that could quite rapidly and easily expand beyond the scope he's laid out above.
I'm a grad student, and I do over 95% of my development work in Python for a variety of different projects, most of them small and one big complicated one. I recently wrote an I/O heavy 100 line script for Python 2.6 to compute some stuff, and it runs flawlessly in Python 3.1 and ~3.4x faster, which is a Big improvement on the 4 to 30 minute run time in Python 2.6.
When did they announce that and what will they provide? I hate posts without dates :S I've invested some time with Pylons, but I'm always very underwhelmed with the amount of docs and support. What they say tells me absolutely nothing, having no idea about TG and probably being a bad idea to invest time in learning about it now that they are going to merge. I copy paste the part that tells me absolutely nothing: "The question has been asked, what does TurboGears 2 do to benefit Pylons development? The simple answer is that TurboGears 2 provides Pylons with a set of standard components, a new controller publishing API that is easier to get started with than Routes, a bunch of additional rapid web development tools, and perhaps most importantly a lot more developer attention. By working together on core components, we‚Äôll be able to move forward more quickly, and put even more effort into creating a robust, stable core."
I noticed from the website that Reddit is listed under "Who uses Pylons". Is that just for one part of the site? Anyone know?
Keep in mind that you will need to learn a web frame work, which adds a whole new layer of complexity to the project. That being said, it sounds like a good way to sink your teeth into the language.
I haven't tried it, nor am I literate in Python. But, I'll help you troubleshoot. Have you tried opening a file that was created in CS4 or below? Perhaps there was a change to the CS5 filetype that has made the script moot.
Python's choice of Unicode characters allowed in identifiers is given by the XID_Start and XID_Continue properties, as PEP 3131 states. http://unicode.org/reports/tr31/ is the annex that defines them. It does have provisions for implementations allowing ZWJ and ZWNJ, but personally I would vote -1 on an implementation of these complicated rules in Python. As hsoft pointed out, there are words in other languages that can only be represented incompletely as well.
This is a really terrible idea, for lots of reasons. But I am going to humor you anyways. You could encode the file into base64: import base64 with open("myfile.jpg","rb") as f: encoded_contents = base64.b64encode(f.read()) encoded_contents is now a base64 encoded binary file, which is just a regular string. You could (technically) put this value in a source file, and output with with open("myoutfile.jpg", "wb") as f: f.write(base64.b64decode(encoded_contents)) or however you planned on outputting the file.
Heh. Don't worry, I won't be unleashing it on any world at large. It's just a joke for a friend. I don't want him to expect it, and I figure I can disguise a string of nonsense as any number of credible things that should survive a quick look at the source... heck he probably won't even look, he'll just run it. But if there was a graphic accompanying the .py... well, that'd ruin the surprise. :) I didn't know there was a base64 library, I'll try this.
No need to bother with the base64 module anymore. The codecs have been united. Just do `'my string'.encode('base64')` (and correspondingly, `.decode('base64')`) 
What about the big packages like: - PIL - wxPython - Django - Scipy http://www.python.org/3kpoll
wx comes with an img2py tool that will compress images into source, for embedding icons and such. I don't know how wx dependent the result is, but it might give you some ideas.
AI is a complicated format, and this python file doesn't seem to be large enough to (by any means) parse the AI file format properly and output it to an SVG. I've been working with the EPS and SVG formats through pycairo, which is a very good library for output. However I'm not sure what to tell you about the AI format except it isn't going to be easy without using adobe products.
I did that just today. in an interactive shell I read in the image with file('image.gif') as f: print f.readline() I copied the output and pasted it in to my source. looks something like this: image = 'GIF89a\x01\x00\x01\x00\x80\x00\x00\x00\x00\x00\xff\xff\xff!\xf9\x04\x01\x00\x00\x00\x00,\x00\x00\x00\x00\x01\x00\x01\x00@\x02\x01D\x00;' I happen to be serving this over the web, so I just set content-type to 'image/gif' and that string as the response body. hope this helps.
We could probably compile a formal spec out of the various emails we had going around, but I've never seen an all-in-one written down spec (I work for Eldarion and have worked on this codebase).
Non-ASCII identifiers are relatively new to Python so there is little experience even with the more obvious cases. You have already received a response from Martin von L√∂wis who is the most likely python-dev member to contribute on this issue. Your reports and wiki pages should contain short, easily understandable examples like '‡¥Ü=1' works but '‡¥≤‡µç‚Äç=1' does not. Other languages that allow non-ASCII identifiers should be referenced with pointers to their policies on identifier characters. Using the term 'critical' for something that is not a crash or security vulnerability is likely to make people think you are overstating your case.
Because he claims they can be replaced by clearer constructs (this is a matter of opinion I'd say) for one thing. http://www.artima.com/weblogs/viewpost.jsp?thread=98196
Yeah I know how to spit it out to the browser, just couldn't get my head around how to store it as a string in code... I think I can do it now, thanks. What was *your* need for this? Is everyone making joke scripts now? :)
I am no authority, but I have gotten the impression that inkscape isn't that great at dealing with formats other than Inkscape SVG. I don't have a suggestion for you, especially for use with python, but you might look into other conversion methods.
I thought you would suggest `coding`
You could also try pickling it.
breaks every time when you click and drag around the border on chrome
I'm a beginner starting out with 3, so I want everyone else to switch as well. Might as well move forward; the more people using 3, the faster libraries will get ported.
its not difficult to manually convert to/from base 2 anyway
uh what exactly is "Code coverage" ?
I would think someone who speaks English and is coding would want to code in English for the same reasons I use underscores in Python but CamelCase in ActionScript. If you're integrating with an external library written in one coding style, going against the grain with a different style causes unnecessary friction in your workflow. Hell, even the operators in Python are written in English.
I recently read a comment in a thread about learning Python, that says something like "...web2py actually hides Python from you...", how you do responde to that ? &lt;hands over mic/&gt;
missed a word there i think
Thanks for the suggestions! I think we need to study the issue more. BTW, Malayalam is not the only language affected by this issue, there are few more languages: Kannada,Bengali,Languages that use Devanagari Script (Hindi, Marathi..),Telugu,Farsi,Sinhala,Arabi,Khmer (This list may not be complete). 
cherrypy + mongo!
Couple hours.
I constantly use microframeworks as prototypes for production pages and standalone webservices. That is a huge domain.
Agreed, dragging around occasionally causes the entire maze to be re-drawn so that the whole thing is simply a grid.
Works with FF and firebugs does not report error. Thanks for reporting. I will take a look. 
I don't have any help for the OP, but my experience has been quite different than what you say here. I find Inkscape to handle lots of imports pretty admirably. AI can be pretty f'd up, as it's just postscript, but in general I get good results from dropping various vector files onto Inkscape.
Out of curiosity, does the same thing happen when you convert it by running inkscape from the command line? 
[StringIO](http://docs.python.org/library/stringio.html) turns a string into a file-like object. You can pass this to PIL instead of writing your image to disk and opening a file.
LOL. Do you understand what that means? I do not. The example above is pure python code. Is it not?
Technically it is not JS, it is processing.js. It should not get out of boundary because the mouse actions are only captured inside the canvas objects. There may be a problem with Chrome but fireforx+firebug do not report any problem.
Yeah, I do too. The key point you're making there is your use for *prototypes*; but not large production sites. We're arguing the same point :).
I actually haven't installed inkscape, I was just playing with the python script linked on that page. It appears that it needs some adjustments with its regex matching among other things, as it's just not filling in all the path values in the svg file.
Yes. Python 1 is terrible.
That's interesting, since Python 3.0 was a performance regression. 
hooray! now I can program for CUDA without learning something new. if only I had a need for it.
How is this "critical"? Non-English speakers (like me) have been coding in Python for a long time without the benefit of mixing Unicode in their identifiers. Granted, if you use a non-western script, you get to write your identifiers in English or in the Western representation of your own language. English being the de facto lingua franca of CS, the former doesn't sound very onerous to me.
This is sweet. I actually have a use for this. :)
*brain explodes* Even the Fibonacci example seems complex. Has anyone here had a play with this app yet? http://code.google.com/p/copperhead/source/browse/samples/python_only/fibonacci.py 
BeautifulSoup changed its underlying parser just for that? Strange, SGMLParser is trivial to port to Python 3 (just run 2to3). Hell, I depended on it and I ported it (it's at http://pypi.python.org/pypi/sgmllib3k ). It works alright for me.
A quick google search yields: http://www.datamech.com/devan/trypython/trypython.py Just google for Python REPL Browser or something similar
The specific regression you're referring to was fixed in 3.1.
note that sandboxing them is really hard (ie you have to assume that if you run code for them, they can do anything the user python is running as can do).
&gt; it's difficult to build larger programs in micro-frameworks. Sorry, you haven't really explained why. First of all, it's a stretch to really call Flask a "micro-framework". Flask covers roughly the same ground as Pylons - HTTP handling, URL routing, template engine. Can you build a large project using Pylons ? Well yes, you're using it right now (Reddit). So how do you manage "decoupling functionality" ? Well, the same way as any other large Python project - using packages and modules. Python already provides a way to build larger programs. Django apps, for example, are just Python packages, with a bit of extra setup required (INSTALLED_APPS) so models can be registered. So how do you build a large application in Flask ? The same way you build any large Python application - start small, refactor into separate modules and packages as the application grows. That's it. Python has an excellent packaging system. Flask does not in any way prevent you from using that. Django has an advantage over Flask in providing more out-of-the-box functionality - such as user authentication. However that's a different debate and has nothing to do with whether you can build large applications or not. 
Are you looking for something like this: http://www.skulpt.org/ It is a javascript based in-browser python interpreter ...
Python 3 handles Unicode the Right Way, because it forces you to think what character set a string is/should be before you receive or send it. This alone will save you a lot of time fighting character encoding errors, so if you have no specific reason to use 2.x, go for Python 3.x. Should the need ever arise, you can then switch to 2.x, but you'll have to deal with a radically different (and more complicated because more implicit) way of dealing with text. Also, if I were using 3.x and would have to switch to 2.6 (I'm stuck on that because of WSGI), I would sorely miss some of the newer goodies such as dictionary comprehensions. TL;DR Python 3.x because UnicodeDecodeError
And, while it's not useful for image files, if you're embedding text files you can stick a .decode('bz2') on the end too.
you can try: * http://www.cafepress.com/+python+mugs * http://www.cafepress.com/+python-logo+mugs or u can create for free own shop on cafepress, upload logo on selected mug and buy ;)
Thanks! found it http://www.cafepress.com/+python_large_mug,437483791
Please, just stop spreading the FUD and come up with a concrete example of why you can't use Flask (or Bottle, for that matter) for a large production site.
Are there any? I work with large data sets and I need to keep a tabular representation of the data (because I convert it back and forth from R).
I wonder how good the performance is...
I'm not spreading FUD, and I resent the accusation. I've built several things in Bottle; I'm currently building an RSS reader for myself in Flask. I've used werkzeug (admittedly, only briefly), which Flask is built on. Like I said right at the beginning, in my very first sentence, *I'm* not sure *I'd* use Flask for much. I'm giving my honest opinion; nothing more, nothing less. When it comes to building larger applications, some of the tools in larger frameworks that I respect are: * django-south, for database migrations * a properly integrated ORM * decoupling URL routing, and using full regexes for URL routing * an abstraction in the form of Django's apps, which make it easier to bolt functionality on easily Now, yes, for the first two you can use SQLalchemy, and for the fourth you can break things up using Python's packaging system. For the third, I'm not too sure what you'd do, which is part of why I shy away from micro-frameworks; when the documentation describes single-file implementations, I don't understand how you easily glue them together into larger applications. As far as I can see, Django, web2py and the like make it easier to grow beyond an initial scope, but again, that's *only my opinion*. I'd list some of the projects I've built in Django and Tornado, but they're either reasonably mundane or currently under wraps pending launching a startup ;). I'm not saying that you *can't* use a micro-framework like Flask or Bottle for a larger site, I'm saying that I think it'd be *harder* to do that, than to use a larger framework (like a fully-fledged werkzeug, which Flask is built off) that's designed to deal with that scenario better. If you've got some experience building a large site in Flask, then please, I'd honestly love it if you shared :). Particularly, I'd be really interested to know how you bolted it all together, as that seems the biggest stumbling block to me.
great :)
&gt; I'm not spreading FUD, and I resent the accusation. Blanket generalizations without examples are FUD in my book. Sorry if that came off as harsh. Pylons and Catalyst (to give two examples off the top of my head) do not provide an out-of-the-box ORM. Pylons and Flask offer easier integration with SQLAlchemy if you want it. Strange how you like Django's "integrated ORM" but you seem to like "decoupling". So, an integrated ORM is a feature. There are pluses and minuses to this approach, but it's not the only approach, and doesn't prevent you from building a large application. &gt; decoupling URL routing, and using full regexes for URL routing This is a feature. Django has it; Rails and Pylons do not (at least, not in the way I think you mean). You like regexes ? Great. Other people hate them. Werkzeug's URL routing to me is a good compromise of flexibility and readability. Flask provides the Module system for breaking up your views. This is well documented: http://flask.pocoo.org/docs/api/#module-objects. You can access the `url_map` of an application separately if you want, or use `add_url_rule`. If you want an example of a larger Flask project see [here](https://bitbucket.org/danjac/newsmeme). It's just an example, and a rather simple one, but at least provides some design patterns to build on. 
no really. i think thats overfudding of the fib method. poor programming?
Gosh. I can't speak for other distros, but I use Ubuntu versions from Jaunty onwards. I've had absolutely no problems installing Python 2.4 and Python 2.5 alongside the system Python (2.6). I have a Hudson CI setup on the dev boxes I use and I've found automatic testing of my projects under multiple Python versions on the same box to be fairly painless. On the box that I do Python stdlib development on, I've got Python 2.7, Python 3.1 and Python 3.2 as well as 2.4, 2.5 and 2.6 (the dev versions not "installed", but invoking from the command line via ~/bin). I've not experienced any problems getting them to work - they don't seem to step on each other's toes. On an older Debian box, I have Python 2.5 (the system Python) + 2.4 which I installed for some tests. No problems there either. YMMV, obviously :-)
I concur. Using Debian testing and Python 3 since Python 3.0.0 I had no problem having multiple installation of Python. The only problem I have noticed are the old libraries/packages of some Python modules. Apart from that, Debian had pretty soon Python 3.1 at their experimental branch and now has migrated on testing. Yes, I agree Python 2.7 is hard to be found in a default installation right now, but it is not that hard to install it if you need it.
Come on, really? Should be rewritten "People don't upgrade their dippy servers and expect them to run the same version of the OS for 5+ years" Ubuntu has had 2.5 since Hardy and Debian has it in Lenny. Both are stable LTS releases. So if people haven't upgraded then it's their own loss. In fact the issue is usually the other way around. I know people running special PPA's to get python 2.5 in the latest Ubuntu releases since it's 2.6 ootb for a while now.
Why the need for special PPAs? On Lenny I installed Python 2.4 from the main repository. On Ubuntu and Lenny, all you have to say is sudo apt-get install python2.X At least, that's what I did. AFAIK they're available on the main repositories.
http://codingbat.com/ does this. I tried breaking out of their sandbox, but they blocked a lot of python features (there was a thread on this earlier--they even broke some list comprehensions so that's not good). at least, if security is one of your concerns (it should be, if you're gonna execute arbitrary code, though). you basically need to block a whole bunch of built-in functions (like `eval` and `open` and more, check the docs), access to any of the `__magic__` variables and properties (especially `__dict__`). you should also disallow `import`, instead providing a small selection of default imported libraries (`math`, `re`, `collections`, `itertools`, etc). I think if you start out like that, and then get a bunch of python-crazed friends to start hacking on it, see if they can find ways to break out of the box, then report it back to you so you can block those methods, at some point I believe you will hit a fixed point and it's sandboxed. If you do, please do a blog/reddit post on it, cause I'd be interested to see what you need to block! [plus I volunteer to try and hack it] One final problem might be that, afaik, there could be some ways to actually lowlevel hack the python interpreter, like a buffer overflow or something. I'm not sure, though, that's not my specialty, but I remember reading a warning about it somewhere.
I recently had to deal with CentOS while setting up a project. CentOS 5 depends on Python 2.4 for many of its utilities and there are no packages provided in the official repositories -- even their testing branch. Now it's pretty easy to install Python 2.7 side-by-side compiling from source, after you install a bunch of -devel packages. But not everyone is willing to do that. There are a lot of know nothing IT people who think that because it's not in their package tree it must not be vetted properly and has security problems (this is why some shared web-hosts who use CentOS or RHEL are stuck on PHP 5.1). When, in fact, the only reason for the later Python packages not being there is due to the fact that the system utility scripts are outdated.
&gt; the only reason for the later Python packages not being there is due to the fact that the system utility scripts are outdated I don't understand why that should be a problem. The system Python can be invokable as 'python' and the others as 'python2.X', say. Presumably the system scripts would say '#!/usr/bin/env python' or '#!/usr/bin/python' so they could keep on working exactly the same. 
Perhaps the Python Software Foundation should spend some money lobbing CentOS.org to distribute Python 2.6 and mod_wsgi with CentOS which on 100% of shared hosting platforms. It would really improve everybody's life.
Ha, no, but yeah that's the idea. Surprise.
thanks, fixed
is mod_wsgi what you use ? (just curious)
I have forever done away with shared hosting for anything other than static pages. linode is just too useful, and I can't imagine a person that needs dynamic pages but can't pay 20 bucks a month.
This would be great! I have a CentOS based VPS and ended up compiling python 2.6 and mod_wsgi from source. It seems to me that these tools should be standard. 
With apache, yes. web2py is based on wsgi.
May be too late. Should have been done 3-4 years ago.
It's worth pointing out that the aliases used in the above example are not part of web2py, and nothing like that is used or encouraged in web2py code (in typical web2py code, you would still see dict, lambda, etc.). I think mdipierro just cooked this up as a fun example. In any case, even without the aliases, it's still short, readable, and easy to understand.
* PIL [Their site](http://www.pythonware.com/products/pil/) states that a 3.x version of 1.1.7 will be released "later". Since 1.1.7 came out almost a year ago, it's unfortunate that it isn't available, but at least they are thinking about it, which is more than some projects can say. It could just be that none of the developers need a 3.x version so they are waiting for someone who does need it to do the work, which I think is fair. * wxPython I haven't seen or heard anything about wxPython on 3.x. It would be nice, but it's probably another one of those "if you need it, feel free to work on it" problems. * Django Martin von Loewis' port of Django-trunk to 3.x is located [here](http://bitbucket.org/loewis/django-3k), and was [started at PyCon 2008](http://wiki.python.org/moin/PortingDjangoTo3k). It is stated in that wiki page that it barely works, but I think it goes to show that if someone sits down and does the work, it's possible. As for 3.x supported by the Django core developers, I believe that hinges on a lot of the improvements that are going into 3.2 before they can more aggressively consider 3.x support. * Scipy I don't have any links off hand to to support this, but with NumPy just recently gaining 3.x support, many have speculated that it makes sense for SciPy to follow suit, and I agree. When that work will be done, I have no idea, but I would say it's logical to think it might be happening soon. *** So I just went 0-4 right there, but I think at least partial credit can go to some of those answers \*wink\*. Everyone knew the move to 3.x would take some time, but I know I'm not alone in thinking that the ability to transition is coming quicker than we originally thought.
Any response?
Strings and Unicode in Python (2) ... in 30 seconds: - Strings in Python 2 are sequences of bytes. - Unicode objects are sequences of Unicode glyphs or "characters". - Strings can represent character sequences by encoding each character as bytes using an encoding like (for example) ASCII, ISO-8859-15 or UTF-8. - Of these three UTF-8 is the only one that allows encoding _any_ (Unicode) character; ASCII (128 characters) is special in that it is included as a common subset by most other encodings. - You can decode strings (byte sequences) to get the character sequence the bytes represent. - If you don't know what a character set or an encoding is, step away from your computer and go back to school (or Wikipedia) right now. - Unless you live in a cave or the 1990s, there is no good reason not to use UTF-8 as your standard encoding (if your editor can't cope, get a decent one). Yours sincerely, a concerned citizen.
I never rely on the distro Python for a real project - you will just find yourself installing the releases anyway when you realize a distro python was compiled without zlib, which breaks a library you were depending on.
i also did something similar to this for storing the favicon in a python app that would serve content over http. i basically did the same thing as Dummies102, made a string with escaped bytes and then when needed i create a file object from the string and set the content type before sending over http. here's my example code if it helps http://github.com/elmiko/fenestra/blob/master/git.py checkout the default\_favicon object and the get\_favicon method.
This is possibly the safest way of doing it.
[http://ironpython.net/ironpython/try/](http://ironpython.net/ironpython/try/) IronPython REPL in the browser via Silverlight.
Funnily I've never had a problem running arch linux. Never.
In Ubuntu Lucid py2.5 is not in the main repos. I've heard there's work within the Ubuntu python maintainers team to actually get all of the versions maintained and in there, but it's not there yet. In order to get python 2.5 the current solution is to pull the dead snakes ppa: https://launchpad.net/~fkrull/+archive/deadsnakes
That's wonderful for you. Now, get involved with a major piece of Python software which has to work on the operating systems *other people* use, and tell me if it's still so easy.
I've said this in other threads and will say it here: Zed's not quite right here, because it's not "distros", it's Red Hat. Specifically RHEL, where even the latest releases tend to lag about six years behind the current actual state of Python.
&gt;As for "all of the things that you do differently from python in a more generic sense," what exactly are all of these things? Once you understand there are a few modules you don't have to bother importing (because they're executed), are there really lots of other things done "differently from python"? Any response to this? This is the second time I've asked, and still no answer.
it measures how much of your code is being executed; typically it is used during testing to see how completely you are exercising the code base.
everyone should use virtualenv with whatever latest stable 2.x version of python they need in /opt - this solves 99% of problems, we install tons of packages including matpolotlib, numpy, + various webapp stuff. NEVER EVER had an issue, and i dont buy argument of "someone is afraid to install alternative python" - if so i would be affraid to install libs i need to it etc. which would make my work impossible to do. To me this blog entry is pure FUD - tell the ppl to use alternative install of py - its simple - no, really it is (yes we use that centos with 2.4 and have no problems having 2.6 in opt :P ).
You're right - thanks. I hadn't checked Lucid.
fixed ? umm it's not, unless you have a broken keyboard....
I was not refering to the code above at all,,,,didn't even look at it.
It's not just old non-upgraded distros. Consider: [root@xenserver ~]# cat /etc/redhat-release CentOS release 5.5 (Final) [root@xenserver ~]# python -V Python 2.4.3 CentOS 5.5 was released on May 14, 2010
It is not that complex. Because there is no native matrix type in Python he just had to define matrix operation for this particular fibonacci calculation. 
Ubuntu deploying sitecustomize.py in order to hook apport into every single python program that runs on the system (whether it is ubuntu's or not) has crippled my software being deployed on Ubuntu before. My software worked on every platform, but would screw up on Ubuntu. It took me a long time to figure this out, not at the time being very familiar with Ubuntu. I found bug reports about this, but the response was basically Ubuntu don't care about breaking python standards because it won't affect very many people. So, yes, Ubuntu basically blatantly breaks python's expected behavior on a low level, and burdens all pythong code with apport hooks. Their sitecustomize.py overrides any other, because it comes first on the path. And yes, very few people will notice. But for those of us who do, it's *extremely* aggravating and utterly unnecessary. And one is tempted to say, along with Zed, stupid.
Obviously that's a generalization, and it is slightly slower when reading the text files, but the my list appends are faster. *edit: ...or something. I just benchmarked a series of list appends on my system and that's slightly slower in 3.1 as well. vOv
dude, it was a joke
&gt; installing a rival language What is that supposed to mean?
For a single sysadmin yes, you just need to make sure that your manual compile doesn't overwrite `/usr/bin/python` which system scripts use. How would you do it systematically for all CentOS? The standard and proper way would use the alternatives system, which would overwrite `/usr/bin/python` with a symlink to the alternatives choice which would symlink to the python version you want, which would break the system scripts as soon as someone changed it to something else.
Python introduced the "with" statement in version 2.5, so suppose an older script had a variable called "with". This would work fine with Python 2.4, but as soon as you install a later version, the script no longer runs. What those system scripts SHOULD be doing is saying '#!/usr/bin/env python2.4' so that they can keep working exactly the same even if the default "python" executable changes... but sadly, most distos don't do this. For example, the /usr/bin/yum Python script on the version of CentOS at my job simply uses "#!/usr/bin/python"
This just didn't make any sense to me. It is similar to complaining that distros have killed C++, because you want to use C++0x features in your project, but ancient versions of centos only have gcc-3.4 (or whatever, I made no effort to find actual gcc versions in any centos repositories). Old distros are for old software. It certainly is too bad that the cheapest shared webhosting companies don't upgrade to newer centos releases. But for $5/month, I don't exactly expect a pony.
http://github.com/haypo/pysandbox
Seconded. I don't know anybody that does not run VPS or "above" for their web projects. I have also never had problems with python versions. I suppose it is different for me though since I don't distribute software in any way but via webservers and into browsers. But getting stuff to, on a general level, work cross-platform is not a new problem. And it is definately not unique for python.
The problem being that the subset of Python they've implemented is still rather small. No exceptions, no decorators, no locals() or globals()... Exceptions are ubiquitous in Python code, so basically almost no common scripts will run unchanged there. It can still be very useful for teaching the basics.
While we're on this topic, how about different encoding methods for adding meta-data to source code? I generally "tag" parts of my code as such: # &lt;globals&gt; g_DEBUG = True g_USE_GUI = True # &lt;/globals&gt; # &lt;parameter_settings&gt; # miscellaneous code # &lt;/parameter_settings&gt; Outside of docstrings and (god forbid) Hungarian notation, are there any other "systems" of embedding meta-data into source code, such that these data can be parsed (either by the coder or by the IDE) to provide source code structure?
&gt;Operating systems that use Yum were screwed. Versions of Gentoo were screwed. It's trivial to upgrade Python on Gentoo. Don't know what he's talking about.
No but it does provide a counter argument to the point "...web2py actually hides Python from you...". no?
Sorry, I've never found it so bad. I develop on my desktop (arch linux) and then deploy onto the server (ubuntu jaunty (9.04)), and have never had any problems over python versions.
Debian Stable forces me to write 2.5 compatible code. Not that bad really but there are things I'd like to use from 2.6+ such as the new string formatting language and unicode_literals. Why there is no lenny-backports for 2.6 or 2.7 is beyond me.
Find a PDF to SVG converter. That's what you need. (AI files are PDFs, by the way.)
Waste of money lobbying CentOS, they'd be better off lobbying Red Hat. CentOS aims to be 100% feature complete with RHES, and you'd be very hard pressed to get them to change.
Would it not be a more fair argument to say that "Python has killed Python by not maintaining backwards compatibility"?
I agree
[Theano](http://deeplearning.net/software/theano/) compiles Python numpy formulas to native or CUDA code as well.
At least he provides specific examples we can check out for ourselves. Oh wait.
Someone might use a Ruby + mongrel2 stack
it means morons don't like software that uses a language on the wrong side of their stupid language war. I don't get it but i've certainly seen it.
&gt; What those system scripts SHOULD be doing is saying '#!/usr/bin/env python2.4' Yes, that makes sense if a new Python version installs itself as 'python'. I'm not sure how the various distros do it.
Or perhaps just never overwrite /usr/bin/python ?
Interesting. According to the [Ubuntu Wiki](https://wiki.ubuntu.com/Apport#How%20to%20enable%20apport), Apport is not enabled by default in stable releases. Is that information wrong, or are you getting bitten because sysadmins are enabling it on boxes with stable releases?
Eh? Python's backward compatibility record is pretty good.
The reason your advice is really bad because you seem to have know idea what you are talking about. If you use a microframework, you'll have to implement or use other people's implementations of many things such as database layer, authentication, permissions, form processing, etc. And to say that your application can be easily ported to Django, Pylons, Web2py, is really crazy. And to say that there's a very straight bad between idea and code also implies that you don't have a good vision of what apps are about. When people build reasonably complex web apps, often time they want to focus on the logic of their apps. They don't want to worry about other things database, forms, authentication, etc. This is why full-stack frameworks exist to supply these things so people will focus on developing their ideas. If you develop complex apps using microframeworks, your apps will be clustered with many things that are not directly related to the idea you want to implement.
I unknowingly ripped off the name of your blog for my django-logging project. Like minds I guess. Sorry.
Yeah, I've had 2.3, 2.4, 2.5, 2.6, 2.7, and 3.1 running on Gentoo before with no hassle to install and no hassle to run the system after. (This was to be sure that my app would work no matter what was in the wild).
Zed complained about upgrading too. Have you ever tried to take a 2.x version of python and installed libraries and upgrade it to 2.(x+1)? 
How does that help with sisyphus' question: &gt; How would you do it systematically for all CentOS? Your answer seems to be "don't".
So, every tool (like mongrel) that wants to use python for configuration or scripting support needs to install their own private version of python? 
have the same problem. i don't use debian, but production is on debian stable and because of that i am forced to write 2.5 code. and on top of that, i have to work with debian lovers, who would be happiest people on the planet if i would use python-redis package and not latest stuff from repository. if it does not have a package == evil! :) had the same problem before, when i had 2.1 on production while latest version was 2.4. 
If a package manager can allow you to break the system python (and assorted scripts) it is broken. Other than system upgrades any time you want to install a new python or ruby or whatever, the package manager should put it in /usr/local or /opt or /your/favorite. If it doesn't, it is a shitty package manager. If you are upgrading something in /usr/bin (and friends) outside of a full/partial system upgrade you have failed UNIX and need to try again next semester. I am not sure how shitty package managers for poor OS distributions are killing python exactly.
If Python's backward compatibility record is good, why would installing a newer version of Python on the distributions cause them to stop working properly? That's without even thinking about diving into the whole 3.0/2.6 thing.
Not to beat a dead horse but, since you brought this up, not me, and on this thread, .... I took a second look, read some emails, browsed the source code. The software you pointed me to does not compare with conf2py. Not close. I am sure things will change in the future but conf2py is better today because: 1) it provides full registration capabilities according to pycon specs (including users can register for multiple tutorials, can register and pay for other users, can have a time dependent fee structure). The other software does not provide registration, in fact PyCon WILL NOT use it for registration and has contracted a private company to handle registration this year. 2) conf2py supports single sign on with JanRain (open id, google, facebook, twitter, myspace, etc .etc.). The us.pycon.org supports only OpenID. 3) conf2py supports one stop payment with Authorize.Net. The other one does not do registration so no payment processing/invoicing. 4) It does provide paper submission with roles: author, editor, reviewer. The editor can assign reviewers and messages have a category (like private from editor to reviewer, private from editor to author, paper accepted, etc.). Each message has permission and can only be viewed by authorize personnel. Conversations are highlighted in color to show the different roles. This enforces typical academic paper review workflow (submit abstract, review, submit paper, review, resubmit paper, loop, paper accepted or rejected, if accepted paper is published online). The system you refer to does not provide anything close. This is not even required since PyCon has its own review process which departs from the one of traditional academic conferences. 5) conf2py is integrated with google maps. It automatically geolocates users (they are not required to know latitude and longitude) and shows them on a map. 6) Both can be used for wiki/blog but in conf2py every page is a wiki page and pages can embed widgets (forms, jqgrid lists, videos, tagging, comments, etc.). This is done with a wizard, without programming. 7) Installation instructions... conf2py is based on web2py so let's not even go there. ;-) Anyway, for the record, here I am not questioning any PyCon decision. I trust most of the people in pycon-tech, which include you. Yet since you brought up the other software, which is open source but developed commercially, and I assume you were not trolling nor advertising, a thought a semi-technical comparison was appropriate.
While the entry is FUDful, Zed is right about anti-Python people refusing to install a package that depends on Python. Of course, that has nothing to do with the distros neglecting Python.
I get it. I'm not bothered by any of the big FOSS languages, but I can't say it wouldn't bother me if a package I wanted to run depended on something like Mono. 
Not python's fault that CentOS sucks. EDIT: To clarify, I was saying that python is not a problem on anything except for CentOS afaik. Why should one distro pollute all distros (and in turn, the reputation of python)?
Nope, can't say that I have - fair point. Since I do development rather than sysadmin work, I tend to work with recent Ubuntu versions and have older Pythons installed for testing purposes. Edit: I know it's only in beta, but I did a fresh install of Ubuntu 10.10 (Maverick), which comes with 2.6.6 out of the box. I then installed 2.7 which was installed as python2.7 but did not overwrite /usr/bin/python; also /usr/bin/env python still invokes 2.6.6. So, at least some distros *can* get it right; I realise this is just an anecdote rather than a proper verification, but anyway, there it is.
Backwards compatibility at the language level has been pretty good. The C API, however, changes between major versions of the language, and so extension modules have to be rebuilt. Most of the time they don't need to make any code changes, but they do need to get recompiled with the new headers. From a language standpoint, this is pretty reasonable. However, if you have stupid or onerous distribution policies, then it can become a bit of a bear. The biggest fault/problem is not that Python is bad about backwards compatibility; rather, it would be more appropriate to complain about the state of packages and packaging in Python. (This is, in fact, a favorite pasttime of many people.)
You do get e.g. additional keywords added between major 2.X versions, which would cause scripts to fail if they contained those keywords as identifiers; but wouldn't that be a problem only if the 'system' Python suddenly changed when you installed a newer Python? IOW if you had 2.4 as the system Python and you installed 2.5, then presumably your 2.4 scripts would keep working unless '/usr/bin/python' or '/usr/bin/env python' suddenly pointed to python2.5? That seems avoidable, but then I'm used to installing older Python versions for testing on new boxes rather than newer Python versions on old boxes. Perhaps there is a real problem, but "The distros have killed Python" seems a tad overstated.
That's what Zed was talking about when he mentioned alternatives breaking stuff.
I've never worked with mongrel. It really depends on what the tool needs python for and what libraries it's dependent on. It's certainly pretty clumsy to require the user to install your own version of python with every distribution you put out, but the alternative is having them hunt down or recompile the right python. But this totally depends on what your tool does and what libraries it uses.
I've seen a custom `sitecustomize.py` created by web-host sysadmins, who suggested avoiding the problem with `virtualenv`. Would `virtualenv` solve your problem?
I know little of the features or the design behind them (except for the payment part, that is because we are using an external registration system that is integrated with the hotel), all I can say is that we are intending to run the conference on it so perhaps not everyone needs all those features (geolocation, for example, probably not the most important thing ever).
Right, but I thought that happened when someone went and manually switched - not when you just installed a newer Python. Maybe I'm wrong about that, though.
I think the problem is that most scripts select a python version via #!/bin/env python2.x rather than checking for backward-compatibility at runtime, *e.g.* import sys if sys.incompatible('2.4'): sys.restart('2.4') Usually, the scripts are fully backwards compatible, aside from the shebang itself.
as tripzilch and rweir have mentioned, it's tough to prevent users from abusing a python interpreter. security folks can find some links on this topic at [my wiki](http://unsyncopated.com/wiki/Switching_to_Python#Securing_the_interpreter). if i were you, i'd consider using google's free app engine hosting. they've probably spent a *lot* of money auditing and securing their implementation. this simple app (source included) might be a good starting point: http://shell.appspot.com/
Yet you brought it up in a thread titled "Complete Conference Management System".
As people have been pointing out all over the place, the latest and greatest CentOS is stuck on 2.4 (thanks RHEL).
Did someone say it was? The whole point of the article is that the *distros* are at fault.
Python adds new features with new releases. That doesn't make it backwards incompatible. It means you can't use awesome new feature like context managers, generators, list comprehensions, etc. when you write your code. Since those things tend to make your code easier to make correct and faster, people like them.
In the link I posted above (here it goes again: http://github.com/haypo/pysandbox ) you can read about the challenge that Guido van Rossum opened to break his sandbox. You can see really brilliant hacking minds at work there. I will copy-paste here: Python-dev mailing list ----------------------- * "Python jail: whitelist vs blacklist" Victor Stinner, Tue Feb 24 13:50:40 CET 2009 http://mail.python.org/pipermail/python-dev/2009-February/086444.html * "Challenge: Please break this!" tav, Mon Feb 23 23:41:30 CET 2009 http://mail.python.org/pipermail/python-dev/2009-February/086401.html http://mail.python.org/pipermail/python-dev/2009-February/086413.html http://mail.python.org/pipermail/python-dev/2009-February/086439.html * "Reviving restricted mode?" Guido van Rossum, Sun Feb 22 17:45:27 CET 2009 http://mail.python.org/pipermail/python-dev/2009-February/086352.html * "object capability; func_closure; __subclasses__" tav, Thu Jun 28 03:04:42 CEST 2007 http://mail.python.org/pipermail/python-dev/2007-June/073724.html * "Capabilities" Guido van Rossum, Fri, 07 Mar 2003 12:41:16 -0500 http://mail.python.org/pipermail/python-dev/2003-March/033820.html http://mail.python.org/pipermail/python-dev/2003-March/033854.html ... (read the whole archive of march and april 2003)
Same situation here, Debian Stable for the production server. Ubuntu Lucid myself. As for Python packages I just go with virtualenv; lets me install any Python package locally, without root and without disturbing dpkg.
EPEL has an appropriately packaged 2.6 http://download.fedora.redhat.com/pub/epel/5/i386/repoview/python26.html
Well, I've certainly never had this problem on Debian or Ubuntu. EDIT: Why the downvotes? Has anyone had problems with this on debian or ubuntu?
EPEL has an appropriately packaged 2.6 http://download.fedora.redhat.com/pub/epel/5/i386/repoview/python26.html It wasn't always available, so I would rebuild the Fedora SRPMS with the appropriate flags for "altinstall" which gives you a non-overwriting RPM like the EPEL one.
And my only comment was "PyCon is using this". As long as we agree PyCon is still a conference, then clearly it holds that the new code is also "complete" for some value of complete.
&gt;YMMV, obviously :-) That seemed to be the big problem ;-) 
No one is saying any of this is Python's fault.
You probably already bought it but this is the store that was set up by the Python Software Foundation and benefits the PSF: http://www.cafepress.com/pydotorg Also here is the link on the python webpage: http://www.python.org/community/merchandise/
&gt;Blanket generalizations without examples are FUD in my book. For other examples of FUD (by this definition), see points #1, #2, and #5 [here](http://www.reddit.com/r/Python/comments/ddkal/django_vs_web2py_what_do_you_use_and_why/c0zf1xk). Most of the remaining points could probably also qualify as FUD by a [more complete definition](http://en.wikipedia.org/wiki/Fear,_uncertainty_and_doubt) (e.g., misinformation, appeal to authority, reference to more "established" alternatives, etc.). The point is, one man's FUD is another man's reasoned opinion. :-) 
RHEL3 packages Python 2.2 and is supported for another month or so, RHEL4 packages Python 2.3 and is supported until 2012. It's somewhat painful to avoid the sexy new features, but *if* Python is not necessarily core to your users' job (as with Mongrel2), then it's not reasonable to expect them to go upgrade their Python environment just to build your software (which also doesn't use Python for anything central). It is however, not difficult to avoid the few gotchas (like the new `with` keyword) so that a Python 2.2 program will also work on 2.7, and I think that would have been a perfectly satisfactory solution for Zed.
So points #1, #2, and #5 are incorrect ;-) Fair enough; but at least I gave concrete examples.
CentOS is terribly outdated in general. (at least from my experience) The Ruby version they use is 1.6, which is like 4 years old.
Keep in mind that the title of the post was written in English (not Python), so the normal rules of social communication apply. Surely someone reading that title wouldn't assume it means "Complete Conference Management System (if the conference you happen to be managing is PyCon 2011)". In any case, the code you reference is not even complete for the PyCon conference -- it's just that the PyCon conference happens to be using an *additional* system for registration.
Oh, I vaguely remembered some issues with the unicode type changes, but apparently I was wrong (I haven't worked with the icky details of Unicode yet). One problem: it directly uses the internal \_markupbase module, which isn't part of Python's API and is therefore subject to changes. sgmllib/SGMLParser has been refactored before to share code between it and HTMLParser via \_markupbase, so it may very well be refactored again.
I have done this and wrote a very simple python module to do the job. It's called media.py. It creates another python module called '_media.py', filled with the stored files/paths in a dictionary, base64-encoded. Source: http://gist.github.com/477550 It's completely unpractical, of course, but my Python applications are fully compiled as stand-alone executables, so embedding media files in source code is a must. 
Whether or not those points are correct, they appear to be generalizations without any examples (for #5, I suppose the Zope reference could be construed as an example, but there are no specific examples of how it was bad with Zope -- so still a generalization without evidence). Regarding the "correctness" of the points, I think they were all fairly well handled in the remainder of that thread, and some have also been addressed [here](http://web2py.com/AlterEgo/default/show/271). My broader point was that succinctly stating an opinion without providing lots of detailed backup is not *necessarily* FUD. Of course, if details are not forthcoming when subsequently requested, that's often an indicator of FUD. EDIT: Oh, perhaps I misunderstood your claim, "but at least I gave concrete examples". Are you suggesting that points 1-6 in that comment count as examples? I disagree. Most of those points themselves are simply generalizations about web2py with nothing to back them up (e.g., Where does it deviate from PEP8? How does web2py's specific use of exec make your code "hard to understand", and what "bad practices" does it encourage? What makes web2py's specific implementation of web-based editing "a bad idea"?). You provide no evidence or examples to back up these generalizations -- hence, FUD by your definition.
Heh. Someone else in this thread suggested to use: #!/usr/bin/env python2.x Guess one which works? I don't know. In practice, the location of `env` is as volatile as that of the Perl or Python interpreter.
Yeah! The new release of PySide (PySide-0.4.1) for Windows now includes the needed libraries and the size is aprox 20 MB (It doesn't includes Assistant). Doing the switch to QT+Python... now!
indeed, if someone else has solved my problem, I regard it as churlish to complain about the way they went about solving it.
I don't understand why he would want his user-base to be full of anti-language zealots. 
You "are intending to run the conference on it so perhaps not everyone needs all those features" and you "know little of the features or the design". Fair enough. I trust you have good reasons for your choices. Why do you keep bringing PyCon up? I am only interested in software features, not politics, nor management decisions. I am interested in specs and feature comparison so I can make conf2py better.
$20/month is a lot for people in some countries outside the US. A VPS is also a waste of resources (and energy) if you do not need it.
Because if someone happens upon this post when looking for software to run a conference, I think it would be nice if they at least had a link to one other tool targeting a similar (not quite the same, conf2py looks to be aimed at more academic areas, pycon's software is more for tech). Also given con2py's heritage it is pretty directly relevant. (for those following along, conf2py grew out of the software built to power previous pycons)
And many Rubyist would happily install Python to use mongrel2. As long as I don't have to touch the code I don't care what programming language it's written it. I don't know why he has to cater for language zealots. Getting rid of them is an advantage.
Exactly like when somebody opens a thread about one particular web framework, it is perfectly appropriate to point out all the other options. conf2py is a complete rewrite of web2conf (the system used for registration at Pycon 2009, 2010).
either pacman or the arch package maintainers are subpar to the fedora and debian groups. More than once I have had to install an old version of a newly upgraded library because of broken dependencies. its a really nasty problem when the library in question is widely used like libssl and you are not at the local site. 
lxml is faster, more powerfull and it can parse broken html;)
The point of the VPS is others get access to those resources and energy as well. There are cheaper VPS' which are more than adequate for development 
&gt;Also given con2py's heritage it is pretty directly relevant. (for those following along, conf2py grew out of the software built to power previous pycons). Are you saying it's relevant for those interested in the history of PyCon conference software, or relevant for those interested in particular conference management functionality?
I've not really had an issue with it. I even do my app-engine stuff on 2.6/2.7 even though Google uses 2.5. Just don't use the new features which just goes without saying because you can't expect it to work on an older version. I would like to see more distros coming with Python 3 by default. I want to move on but there's not much reason to tbh.
you dont like python why use it in first place ? i would suggest those ppl to use the better tool ;-)
Now do one for dates
stop whining and come back after you made a python project with at least 5 c-module dependencies on solaris/sparc.
You're being downvoted because you made a useless statement.
&gt;Unless you live in a cave or the 1990s, there is no good reason not to use UTF-8 as your standard encoding (if your editor can't cope, get a decent one). UTF-8 is very Euro-centric and isn't necessarily the best choice non-latin alphabets. EUC-JP and Shift JIS are the dominant encodings for Japanese as UTF-8 would require 2-3 times as much memory to store the same amount of text. If you are just talking about Unicode then yes, UTF-8 makes the most sense. Unfortunately it's still not always the best choice - Windows for example uses UCS-2 (a subset of UTF-16) and CP-1252 (a form of extended ASCII) so it's probably better to use UCS-2 for Windows applications. Basically string encoding is a mess.
Because all bugs are probably relied on someone, so even bug fixes can break people's code easily.
No longer necessary. Use html5lib to parse the code and let it create lxml trees. That really works on *every* piece of HTML and parses with the same rules as a modern webbrowser.
use apt-pinning and install Python and all Python-related packages from testing. here's [a tutorial](http://jaqque.sbih.org/kplug/apt-pinning.html).
As a Debian user, all I can say is: "WTF, Redhat". Of course, this does help explain why the Django project goes to the effort of maintaining 2.4 compatibility.
as a somewhat beginner Linux user, I have to say that I found getting setup with Django + Python + Postgres on Debian to be extremely challenging. I work with Debian servers every day, so I'm comfortable using my system, but I still have a lot to learn. I personally learned a lot about working with Debian from doing it, but the difficulty doesn't seem to be beneficial to the Python community at all. I melted two servers in the process; one when I tried to install Python from source and messed up the OS version, and another when I used apt-pinning and installed some conflicting packages.
C++ in general has gigantic deployment issues on everything. Especially Windows. *Especially Windows with DLLs*.
I remember that 2.4 -&gt; 2.5 was an enormous pain in the pass, but otherwise, it's been pretty simple.
And nobody claimed that it was. "The **distros** have killed Python".
Will that get me a python2.{6,7} or replace Python 2.5? Also I recall reading pinning doesn't work well, can't remember source though.
Why would you *try* to do that? Moving from 2.x.y to 2.x.(y+1) is a simple matter; but moving to 2.(x+1) generally involves major things changing: future statements becoming defaults, new keywords being reserved for future, stdlib changes, all manner of things which you wouldn't want to transition in-place. In every case where I've had to upgrade, it made a LOT more sense to make a parallel install of the new python, install all the libs I needed, and transition the apps over to the new python one by one... leaving the old python around if there's something that can't be moved. Never had problems doing things this way. That's also how Debian / Ubuntu do it. Starting w/ Debian Sarge, they introduced a ton of improvements to the build scripts, so that parallel pythons were easy to install, meta packages for most of the libraries, and apps called whichever python *they* depended on. I've never had it give me a problem. And as far as distros "holding python back"? Debian's rolling right along with 2.5 in stable, 2.6 in testing; while Ubuntu (being less conservative) is currently using 2.6. If he's complaining about them not using 2.7, it just came out a few weeks ago. I assume most of the rant was about RHEL and derivatives, which certainly don't have a good system for handling python updates... but they don't have a good system for handling *any* kind of language updates (just try perl, php, etc). 
``#!/usr/bin/env python`` at least works with virtualenv.
The dynamic languages are not "rival languages." Python makes Ruby better. Ruby makes Python better. Perl made them both better.
Hmm, that's odd... I've been deploying Python programs on Ubuntu for years now with zero problems...
Could I pester you for a description of those sys functions (or better, a link)? My system has 2.6 and 3.1 installed, and I'm not seeing incompatible() or restart() as part of the sys module. It's been a long day, probably just missing the obvious...
You know what? I'd still use Unicode even if it was sinocentric and had European alphabets stuck somewhere in the higher planes. The important thing is to be consistent. Today we really shouldn't have to worry about text bytes.
Demo code out of the box would be nice.
which distro(s) build python without zlib support?
Rivals do that. Source: Kakashi &amp; Guy
Sorry. Here's a quick demo (assuming you've got one of the sound libraries above [winsound, pyaudiere, tksnack]): import musicalsort from random import shuffle s = range(100) shuffle(s) musicalsort.insertion_sort(s)
Maybe you should RTFM
There is no question that UTF-8 is the best encoding format devised so far and everyone *should* use it. Anytime I have a choice I choose UTF-8. The problem is that a lot of people have chosen not to use UTF-8, such as the Japanese and Microsoft. For the sake of interoperability you are going to have to use UCS-2/UTF-16 or Shift JIS at some point if you are working with Windows or a Japanese program/library. I would probably choose to use UTF-8 internally and convert when necessary. Hopefully at some point things will converge towards UTF-8 or its successor if there is one.
Clearly FUD. Don't tell me you can't bundle any choice of python with an app. Almost everyone does it on windows and it is easily done on linux too. FUD is FUD.
Arch is a rolling-release distro, breakages happen, you're expected to know what you're upgrading and why, and how to fix it if it breaks. If you're that type of person, it's an amazingly clean-feeling distro compared to the "major players"
if `env` is in `/usr/bin/`, yes.
Doesn't work on my laptop. Does it work using the motherboard speaker?
The worst offender of broken Python's is apple anyways. Snow Leopard ships 2.6.1. They never upgrade their installations for whatever reason.
The article cited (I mean, honestly mdipierro, you wrote it) mentions pycon multiple times. It wasn't random.
Which is always the case. If it isn't the case you can symlink like Gobo or rewrite the shebangs (many packaging tools does). The python command is more likely to be somewhere non-standard (as exemplified by virtualenv) than env.
update-alternatives should make sure python2.4 is left alone, while installing python2.7 as /usr/bin/python. This may be what was causing issues, though. edit: the user can also use update-alternatives to make python2.4 default.
 $sudo apt-get install python3 $python3 path/to/file.py &amp;&amp; echo bitches
Downvoted for useful links? I did enclose that headline in citation marks to reflect the subjectiveness of the claims in the first post.
&gt;Which is always the case No, it isn't, which is what `f2u` was talking about. &gt;If it isn't the case you can symlink like Gobo or rewrite the shebangs (many packaging tools does). No, you can't always do that either. As an application/script author, I have no idea what environment my app is being used in, and I can't rely on it being in repos, nor can I rely on users actually installing from those repos. `/usr/bin/env` works for the majority of cases right now, but for people who have to run scripts over a variety of different unixes, it can actually become a rather annoying issue. If you're an app author, you go with `/usr/bin/env` because it mostly works, or you provide binaries (or require compilation of them), or you provide different sha-banged files for whatever is out there. Most people, rightly, take the first route. If you're someone who runs utilities on, or admins a bunch of different types of systems (and is not necessarily able to go around symlinking willy-nilly), you get to check the sha-bang lines of every.single.utility. that isn't from the repos (assuming repos exist), and also get to check fun things like whether `python` in the script refers to the python you have, or whether the author of the utility's `/bin/sh` was actually `sh`, `bash`, or something else. It's really pretty nasty and it's almost an accident that /usr/bin/env works as often as it does. I'm glad it's a de facto standard right now, but it's still not totally reliable, and when it's a pain, it's a pretty huge pain.
It does, yes. Sorry to hear it's not working. Can you pastebin a traceback or any errors you're getting? Also, what OS you're on? I'd love to see what's going wrong.
&gt; I would probably choose to use UTF-8 internally and convert when necessary. This is pretty much how most Python web frameworks seem to handle the issue.
I think the "article" merely mentions that conf2py is a rewrite of software that was used for PyCon in the past (2009 and 2010), presumably to point out that it has had some real-world usage (and that some Python folks may have encountered it). In the same context, it also mentions two non-PyCon installations (so not focusing on PyCon). It doesn't go into any discussion of what PyCon will use in the future or why. In any case, from his comment, it doesn't appear that mdipierro generally objects to mentioning the PyCon pedigree of conf2py -- rather, he articulates more specific concerns.
What a strange, misguided article. Refactoring down to a lower level language like C(or C++, Go, or Java) should be the ultimate goal of any program that can benefit from performance or portability. Python is a great choice for prototyping, small projects, and fast development.
3 of my webservices are large production things. I'm also converting a bulky, fragmented PHP ecommerce site into one based on CherryPy, Jinja2, and a very lightweight custom ORM that is interfacing with MongoDB and PostgreSQL.
No error, just no sound. I believe most laptops don't have motherboard speakers anymore. Windows Vista.
Some of the older ones available on EC2.
I knew they rewrote the IO system, but I didn't know it worked out to being faster all around in the real world.
I read Japanese, but I'd rather have a page be twice as large rather than not be able to mix in Greek or certain Chinese characters. Unicode encodings are better in almost every situation except where the page size is the absolute only consideration. 
Python itself is usually just UTF-16 internally.
Pedantic note: it would work fine in Python 2.5 unless you wrote `from __future__ import with_statement`. It would break in 2.6. :-)
That does make sense. I had no idea their releases were so infrequent.
Sounds about right since CentOS 5 was released a little over 3 years ago. RHEL/CentOS 6 is currently around the corner. RHEL 6 is on beta 2.
Python 2.6 and mod_wsgi will be in CentOS/RHEL 6, which isn't far away.
Because Arch doesn't do backports. You're always bleeding edge.
Good to know. :-)
I see you have edited your reply to add "multiple times" and "It wasn't random." Are we looking at the same thing -- I see only one sentence in which PyCon was mentioned: "This software is a complete rewrite of the web2conf software developed for PyCon US 2009 and used for registration at PyCon 2009, PyCon 2010 and Flisol 2010." Of course that's not "random". What's your point?
afayk.
Well, squeeze should go stable relatively soon so you won't have to worry about that much longer. 
CentOS aims to be a free version of RHEL. In the business world, if you are running linux, you are probably running RHEL. Essentially they like feature stability for a long period of time so they don't have to worry about a change breaking their application. Luckily RHEL 6 is coming out soon!
Don't you need sudo to install virtualenv? It does not come with CentOS and you do not get root access to the many shared hosts that run CentOS (all of them).
RHEL targets companies that don't want a change in the underlying technology to break their application. Thus long release cycles with just security fixes. Most production servers run RHEL for this reason.
unless you're using backports, apt-pinning is risky. I'm very strongly in the "trust your debs" school of thought and try not to implement anything if there aren't debs available for it. I'm more in the sysadmin than coder school though. 
I talked to some of RHEL's developers. Really didn't like them.
Nah, Python works well for large projects as well. I just finished up an internship at a business with 100,000+ lines of Python (cloc count). There's some shell scripting in there, but most server-side code is Python based. If there's an extremely performance sensitive area, it can be converted to Cython. Granted the only portability issues are between the company's server(s) and the developers' test environment.
I thought that is what I said. Everything except the most demanding applications.
Basic shell on GAE (source available): http://shell.appspot.com/ Similar but with Sympy loaded: http://live.sympy.org/ This one is a Jython shell, but you can only get it from svn: http://code.google.com/p/jythonshell/ Here you can see some examples using it (apparently it's a bit old): http://www.gnucitizen.org/blog/system-hacking-from-the-browser-the-python-style/
Python is a scripting language, it's silly to have compilation or install processes dependent on it. There is a reason why there are package managers and CMake. 
no you dont neeed to: as a user you do this: go to unpacked virtualenv package /your/env/python virtualenv.py --distribute /home/user/new_python_dir and this is all you need to do, from this moment on you can use it like ~/new_python_dir/bin/python ... pip... paster, whatever you need - you dont have to have root - and you can have many virtualenvs with different sets of libs if you require that. 
I wasn't aware of that, actually. However, my point was that most Python web frameworks make sure the strings get encoded properly before being output and are decoded properly before being made available to your code.
Shift-JIS uses 2 bytes for most Japanese characters and UTF-8 uses mostly 3 bytes so the more normal expansion for UTF-8 over Shift-JIS for pure Japanese is 1.5 times larger. Much Japanese text is actually a mix of Japanese characters and ASCII, with punctuation, numbers, spaces, and foreign names and words in ASCII. Web pages in particular are strongly balanced towards ASCII. For example, only 4% of the characters (that is 12% of the bytes) of http://jp.fujitsu.com/ are multi-byte characters in UTF-8. XML files also generally show a lower but still very high proportion of ASCII.
I was expecting Artifical Intelligence visualisations on SVG. I admit I was a bit disappointed :)
I am likin tornado more and more... Especially when using couchdbkit. I do not trust mongo
Ya, the latest major release of RHEL was on 2007-03-14. It's a tough balancing act, people want the latest software on their servers but they also want stable servers that won't push out major software upgrades, all while keeping them updated with the latest security/bug fixes. RedHat needs to start releasing new major versions of RHEL more often, at least every couple years. But I can only assume that it's a pain having to [support these releases for up to 10 years](http://www.redhat.com/security/updates/errata/)...
Thanks. This is important.
I didn't bother to lookup the Unicode codepoints for Japanese but kind of assumed it would be either 3 or 4 bytes. As for the website you linked and the web in general, that makes sense since HTML is still going to be single-byte UTF-8.
My point about the size was really more of a tangent than anything else, the real issue is interoperability. If everything around you is Shift JIS well then it's probably easier to use Shift JIS. In a complete vacuum UTF-8 is always the best, in my opinion.
Weird, he has a documented history of sharing well researched and unbiased opinions.
Yes, those kinds of issues I can respect. I was referring more to the ruby fan dismissing software because part of it uses python or perl.
So... are you saying you are in fact one of those morons you were talking about?
ReportLab and LaTeX serve two completely different purposes. I use ReportLab quite a bit to do things that I would never even attempt in LaTeX: forms, invoices, registers, targets, cut-out patterns... LaTeX isn't designed for these, not without going through some extreme acrobatics.
Listen vph, I agree that web2py is great. I don't have a beef with it. Yet, I can find the objective angle that is correct on this issue, but you venture into web2py lala land. The guy is a new Python programmer. His intention is to learn Python, not decipher it or the framework or make as you put it, "reasonable complex apps". Maybe I did come off a bit harsh by saying not to use web2py. By all means, he should give it a shot, but it wouldn't be my first choice.
Well there's a couple of things you could do: * If you're looking to make the display have shiny 3D objects of any kind, I would recommend looking in to [PyOpenGL](http://pyopengl.sourceforge.net/). * If you're looking for some simple to use (2D only) graphics solutions, I would suggest looking in to [PyGame](http://www.pygame.org/news.html) (used often, as its name would imply, for writing video games) or [Pyglet](http://www.pyglet.org/). Both options have plenty of documentation and tutorials available on their respective websites.
No, I was clarifying that when I said morons I meant people driven by tribalism or fanboyism, like ruby vs python or perl vs ruby. I'm assuming your objection to Mono is based on an argument for free software, which I can respect. Maybe you lost the thread of conversation after a day? This was in response to pemboa asking about the usage of "installing a rival language" in the article, so I explained what the author meant by that and called them morons as well.
http://www.exolete.com/code/life they have a Python example with Tkinter. Tkinter comes with Python.
Language wars and license wars are all just different flavors of zealotry. We're all morons.
Have you tried [UniConvertor](http://sk1project.org/modules.php?name=Products&amp;product=uniconvertor)? 
Download Pygame at http://pygame.org Pygame is a wrapper for SDL, which is used in a lot of games. It doesn't give you radio buttons and scroll bars and other UI widgets like wxPython or GUI toolkits do, but it gives you a blank canvas to draw on and has lots of functions for drawing &amp; transforming sprites. There's a tutorial on it in the last few chapters of http://inventwithpython.com
For IDE, I would suggest PyDev plugin to Eclipse. For the graphic, try Tkinter.
Komodo for Python IDE, Eclipse is way overkill and daunting to even experienced devs, and can be slow as hell as well as buggy at times.
I would definitely recommend 3 because it's quite flexible......But if you are deploying applications using Django then you need to use 2. But if you are a NooB then i would say learn Python 3 because it also covers 2
you think LaTeX is easy ? wow. most inscrutable language I've ever seen, tools are impossible to install on OSX. Unless you like [downloading a 1.6 gig zipfile](http://tug.org/mactex/). My current mactex install is completely hosed and upgrading doesn't fix it. So I pretty much only use pdflatex on linux nodes now. Heres a [sphinx latex bug](http://groups.google.com/group/sphinx-dev/browse_thread/thread/e5c885371714006a/fc337dda0b3b8e87?lnk=gst&amp;q=bayer#fc337dda0b3b8e87) that nobody can fix. Can you fix it for us ?
&gt;you venture into web2py lala land Doesn't look like vph mentioned web2py -- he just expressed disagreement with your opinion. Even in his follow-up to your response, his only mention of web2py was quoting a list of full-stack frameworks from your own comment. Hardly web2py "lala land". &gt;I can find the objective angle that is correct on this issue... I really think you ought to look up the meaning of the words "objective" and "correct". Unless you can cite some carefully controlled experiments demonstrating that your suggested approach leads to better outcomes for new programmers, I don't see how you can claim to have the "objective" or "correct" answer (indeed, even such experiments would be subject to interpretation depending on the particular outcomes chosen to be measured). What you have is an "opinion," and for what it's worth, I think it's a valid one -- but so is vph's. What's most appropriate may depend on the goals, abilities, and preferences of the OP. If the OP really just wants the fastest route to building his specified application, then something like web2py is probably a good option. On the other hand, if the OP wants to become more of an expert regarding the nuts and bolts of how web applications (and frameworks) work, there are two possible approaches. One option is to start with a full-stack framework that takes care of some of the details for you and let's you focus on learning the higher level patterns of application development -- then, as you get more comfortable, start to dig into what's happening behind the scenes (this approach actually parallels the way many frameworks structure their own documentation, typically starting with a tutorial-style overview to introduce the general development pattern, and then proceeding with more detailed technical material needed to master the framework). An alternative is your approach -- start at a lower level and learn "from the ground up." It may be hard to say which approach is "objectively" better, but they're both probably workable. As I said, it comes down to the specific goals and preferences of the learner.
Take a look at [this link.](http://www.koders.com/python/fidDFBE3218DE0174D7A8E187A8723DB139EFDD6AAD.aspx?s=timer) It uses wxPython but you don't have to.
Or, if you didn't hate yourself, you could use the template language of your choice to make some html and use Pisa instead of using reportlab directly. http://www.xhtml2pdf.com/
Since no one has suggested it yet: [matplotlib](http://matplotlib.sourceforge.net/) is an excellent way to get low-key interactive graphics going. It does support animation and stuff, so you could put your Game of Life into a numpy array, visualize it using Matplotlib, and update the array and the display periodically.
If you are just looking to do the game of life. Just use [pbm](http://orion.math.iastate.edu/burkardt/data/pbm/pbm.html)
Komodo edit is free.
I run debian unstable/arch/fedora/gentoo. Debian unstable is my primary desktop system which is a rolling release. I am that type of person. With apt and yum if breakage would occur because dependencies cannot be satified then the upgrade fails without breaking the system. If you upgrade one package with pacman it can break others that have common dependencies by upgrading those common dependencies. Whats the point of a package manager if that situation can occur.
Debian unstable rolling release is a different sort of beast than arch's. Debian "unstable" is still pretty damn vetted and stable. Arch is cutting-edge, and it's possible to catch a repo in a "partially updated" state. &gt;If you upgrade one package with pacman it can break others that have common dependencies by upgrading those common dependencies. It gives you a list of what's about to happen, and asks for confirmation. What do you expect it to do if you upgrade one package, and it depends on you having a newer version of lib_foo? &gt;Whats the point of a package manager if that situation can occur. Package management. Remember rpm hell?
&gt; It gives you a list of what's about to happen, and asks for confirmation. What do you expect it to do if you upgrade one package, and it depends on you having a newer version of lib_foo? I expect the package manager to check which other packages share dependencies with the one I am upgrading and then try to resolve the situation. In apt and yum it solves it by upgrading everything that has common dependencies or failing to upgrade anything. EDIT: &gt; Package management. Remember rpm hell? Yes, I remember rpm hell. I avoided packages like the plague until apt and yum started being used. 
Oh nice, this is exactly what I needed it for :D
Nodebox is very newbie friendly, and I strongly recommend it. I managed to get something very pretty out the door a week after I learned Python. 
Tkinter is getting a bit old, I'd say use QT-python if you don't need the code to be commercial and wxpython in the case you do.
Or use [NodeBox for OpenGL](http://www.cityinabottle.org/nodebox/). It's cross platform. I haven't used it yet but it looks great from the documentation.
&gt;I expect the package manager to check which other packages share dependencies with the one I am upgrading and then try to resolve the situation. It does, as far as I can tell, unless you pass --nodeps. You can do it manually with `pacman -T` . If it's not recursing down the dependency tree as far as it should, you should file a bug, or submit a patch. It's possible that I'm totally misunderstanding your complaint though -- can you provide a concrete example?
Disagree. You've put it in a nice pithy way but the difference between the two is significant. "I refuse to support the existence of Ruby so I'll never install the command-T plugin for vim" is a crazy statement. The goal is some kind of programming language purity that even if achieved would be harmful, a large ecosystem of tools is almost always better than a small one. "I refuse to support the existence of microsoft IP in mono so I'll never install Gnome Do" is less crazy. The goal is software freedom and if achieved would actually have a societal effect. I don't subscribe to either, but one is pure tribalism with no discernible end goal and the other is a principled stand against a political issue (the ability to copyright ideas); it might be a useless principled stand that makes an insignificant difference to the actual political struggle but it's not fair to say the two are the same. tldr; Disagree, one is voting for the american idol and one is voting in a democratic political election
On my arch production server I only upgrade ssh. It is a stable managed server so I only want to upgrade based on critical security needs. Anytime cryptlib or libssl are upgraded, it breaks everything else that uses cryptlib and libssl. Pacman recurses down the dependency tree but it doesnt recurse back up to see what other packages share the common dependencies.
Zelle has some nice graphics for learning. Google him.
does it extract contents from pdf tables (which aren't really tables at all)?
TkInter is a good intro though, I feel. It just seems simpler than PyQt or wxpython.
Animation support in Matplotlib is buggy and fairly slow.
Why not Pyglet for 3D as well?
I have a related question: I'm interested in graphics too, but I'd like to be able to embed my program in a Qt GUI if necessary. What library should I use? I've also heard that the OpenGL API doesn't compare favorably to Direct3D. Is there a abstraction layer or alternative that's better?
Are you new to the concepts behind animation and such as well as python and programming? Just thought I'd mention that graphics tutorials that aren't related to python will still be useful in gaining an understanding of how those things work. For example if you're interested in programming games look into pygame but also read up on any game programming tutorials you can find. For 3D graphics and or 3d games the nehe tutorials are written in C but most if not all have python sourcecode to download and they give a good base of understanding in 3d graphics. http://nehe.gamedev.net/
I have way more fun with [pyglet](http://www.pyglet.org). By far. edit: Also [pymunk](http://code.google.com/p/pymunk/) for 2d physics is pretty fantastic.
The eternal question. For your purposes you have binned data so an interface to genreating PNG may be enough. I'm not so familiar with those so I give for your consideration: * matplotlib * pygame (suggested below) * vpython * PyROOT * PyOpenGL * TKinter canvas And probably a bunch I don't know about. 
Most GUI toolkits provide some sort of "canvas" element that you can draw to, and this is probably the simplest way to draw small black/white squares on the screen. Try PyQt4, PySide, PyGTK, or tkinter. PyQt4 has [a book](http://www.qtrac.eu/pyqtbook.html) available for it. Also, this is the correct subreddit. Also, Idle is fine. If you're looking for an alternative, there have been many discussions around here regarding that. Do a quick search. 
Are you pulling those updates from [testing]? I remember a whole slew of issues with libssl from 0-point to 1-point, but only on [testing] -- and they were announced loudly to arch-dev-public before the packages hit, and it's assumed you're reading arch-dev-public if you're pulling from [testing]. Otherwise, that _should not_ happen if you're not pulling from testing _and_ you're not upgrading during the time that your repo's server is updating, assuming you -Syy first. If it _is_ the case that that happens, I would think an rdeps addition to pacman would be in order. Doesn't seem like it should be too hard to add to pacman either, although I'm not familiar with it's source yet...
Fair enough.
I've never used pyglet but a lot of pygame. Can you explain what you like better about pyglet? I might just try it out then. :)
This did not solve the problem. In order to /home/user/newpythondir/easy_install the python modules I need, I still need gcc (which is missing) and therefore root access.
sheesh $18 for a mug
I find pyglet more "pythonic" (though I loathe that word). It does a lot of the tedious stuff for you but gets out of the way if you need to get close to the action. The opengl support is decent, and event handling is a breeze. It even has a good resource manager/finder, and can load from zip files. All around it's a great media programming library. Oh, and the fact that it's pure python makes it easy to setup. That's always a plus. 
It's not as straightforward as PyOpenGL. You need to use ctypes extensively, and some people don't like that. I don't specifically mind.
OpenGL is available on more platforms. Thus, that's the target of many python libraries, who tend to lean to the multi-platform audience. Direct3D isn't any "better" than OpenGL, though some may find it easier. I like the state machine concept, so OpenGL gets my vote.
I thought Pyglet was supposed to be more Pythonic.
I know what you mean, they can sometimes be a little unclear to someone without gui programming experience.
+1 for tkinter!
9.8.
What OpenGL versus Direct3D is mostly in that Direct3D comes with the rest of DirectX, and that OpenGL is less into enforcing a strict set of features upon developers/drivers/hardware per version number. For the rest of a game development library beyond graphics look at SDL or PyGame (further wraps SDL and other libs) For the driver features thing, just get used to the idea of graceful degradation (if feature X isn't available, do Y instead, or make it look okay without X), or roll your own equivalent of D3D versions, where you write a couple different renderers, one for the widest variety of users, and another one that looks nice on some but not all combinations of hardware/drivers. I really like OpenGL.
Mmm... reminds me of the [tonematrix](http://lab.andre-michelle.com/tonematrix) emulator I wrote back when that first popped up: http://pastebin.com/yw4Rzacp Requires [pyaudiere](http://pyaudiere.org/) Uncomment those lines at the bottom for a treat :-D
that's (what the article says) true but then there are some contra arguments as well http://www.markus-gattol.name/ws/python.html#contra
so ? you asked about virtualenv. to compile some modules you need to have python-dev package(headers) and environment. The problem you mention is completly unrelated to virtualenv. Ofc. to install lets say psycopg2 you will need libpq-dev etc. but it has nothing to do with virtualenv itself.
&gt; However, there are more and more voices saying that the standard library has become to big and should be cut down or set aside from Python core (the interpreter) release cycles altogether (releasing more often than core). The "too big" argument is different from the "separate release cycles" argument. For "too big" - What does that mean exactly? For "separate release cycles" - while it might in theory be better to have more frequent library releases, it's perhaps more manageable for users to have the two in lock-step (less configuration management headaches, because less combinations of Python version + stdlib version). &gt; The argument is that once code is included into the standard library, it stifles innovation on that particular area (because it is tied to release cycles of Python core and must maintain full backwards compatibility) and discourages other developers from innovating in that same area. There's no evidence that innovation-stifling is especially common - see. argparse vs. optparse, for example, or ElementTree versus the earlier alternatives for handling XML. If the itch is annoying enough, people *will* scratch it. There are many packages on PyPI, at least some of which overlap in functionality with the stdlib.
In the past I've used [NSIS](http://nsis.sourceforge.net/) to install [py2exe](http://www.py2exe.org/)-generated executables. That seemed to work without too much trouble. It didn't really interact well with updates or user-edited .py files, though. (Pyglet isn't too hard to package with Py2exe, thankfully)
extremly challenging you say ? you do this : 1. install virtualenv 2. use pip/easy_install from virtualenv to instal django and psycopg2 3. profit :-) i tested that in debian/ubuntu/fedora/centos - no idea whats challenging about that. 3 commands - it works
Thanks. You also brought up a very good point: patches and updates.
looks like folks beat me to it, [lxml](http://codespeak.net/lxml/) is great! Funny thing is, I just learned about this library yesterday. Coincidence? ...Or conspiracy*?!?* Check out this [hackish bit of code](http://pastebin.com/qXRSztMA) I used yesterday in about 1 hour to parse cars.com to build a list of car makers and their models! (please excuse the slop and use of set to cover it up, but it *works*! [when BeautySoup did *not*{*Italics!*}]) 
Yep, py2exe is the way to go. Here is an example of [setup.py](http://codepad.org/vn9jxrUE). The bundle_files option will include libraries in the exe, because py2exe generates a bunch of libs, it will be cleaner this way.
the real Andre Michelle from the real Andre Michelle's lab??
Django for large projects. WSGI for small/embedded web apps. There is nothing wrong with web2py but in my limited usage of it I found it feature rich but a bit confusing and easy to break.
Following pep8 is not tough and there are tools to help verify it. Pep8 also is not crazy strict. If someone sends me a patch or pull request of code which ignores pep8 fully I will not accept it. If there is an _attempt_ to be consistent on the pep8 style I will accept it and make minor style fixes myself. I like code I can read easily when I have to maintain it :-).
like... youtube? are you joking ? ;-)
[Gist with patch](http://gist.github.com/593569) produced for SQLAlchemy tip, had to change both log.py and the corresponding unit tests. Test results before &amp; after changes compared in gist: all seems well :-)
I wrote a book chapter about this: http://www.aharrisbooks.net/pythonGame/Appendix_C.pdf They ran out of space in the book, but they let me give away the chapter. It's a bit old, but it still works. I cover setup.py, py2exe, and nsis. I used pygame rather than pyglet, but it should work out the same. py2exe does a decent job of getting all the dependencies right. 
It is, for what it's designed for. Under the hood, though it's all ctypes. That's where you have to go to play with OpenGL in Pyglet, under the hood. :)
So the ctypes layer is transparent then? I thought you meant I'd have to be casting all my data to ctypes or something.
This is awesome, and I think it might help shed some light on packaging things besides sust games. 
I wonder how it compares to [PyCUDA](http://mathema.tician.de/software/pycuda).
what a shitty program ;)
**Followup**: solved, thanks everyone. Many of the ideas offered worked, but I ended up encoding the graphics from the command line, then using mackstann's way: theString = 'h4jk32h4jk32h4kj32h4k23' # encoded str, copypasted theThing = Image.open(StringIO.StringIO(theString.decode('base64'))) I chose this way because it was only these two lines needed (innocuous), and I already had StringIO loaded anyway for PIL's use.
I've just installed the pygame for python 3.1 (I'm using 3.1.2), but when i tell python to import pygame, it says that there is no such module.. any help? If it means anything, pygame also doesnt appear in my start menu or anything
Numpy for PyPy? Now we're talking!
django 2 is not very well rated: http://www.imdb.com/title/tt0093113/ ("maybe 20 years too late" said a reviewer).
People Order Our Patties.
I do not want to take away your fun of figuring it out yourself, but while checking out pygelt I just found this: [Conway‚Äôs Game of Life in GLSL/Pyglet](http://swiftcoder.wordpress.com/2008/12/20/conways-game-of-life-in-glslpyglet/)
total crap.
I'm going to reject the conclusion of this clearly buggy Python code and go tell my wife that I need more sex partners to protect myself against STDs. I'll let you all know how it goes.
yeah, as others have pointed, lxml is better. BeautifulSoup is also largely unmaintained and slower.
That seems to be a pretty logical conclusion without a simulation.
Interesting, but I think the premise of the article is that we hold the total encounter rate relatively constant, per the Kramer scenario. The total infection rate drops pretty rapidly if you hold the number of encounters relatively constant.
+1 for +1 for tkinter! And do you say it "tee kay inter", or the more Vulcan-sounding "Tuh'Kinter"?
I don't see a whole lot of vector math or complex calculations that could benefit from a transition to C in youtube. However, they might have the heavy lifting separated to the database level or the following... If I want to optimize a Python app, I write some python modules in C in call it a day. Thats a big step towards what I mean. I still say that it is written in Python.
Finally, oh wait you are based on xml.
I can say that I used the Python OpenGL stuff for a graphics class in my undergraduate, but I never quite got py2app and py2exe working the way I'd like. I was also using numpy at the time and ended up having to stipulate to the professor that the dependencies needed to be installed. I'd be interested in hearing other people's experiences with these things too, but in the end, I'm happier using C or C++ for OpenGL development.
Thank Allah somebody else had the same first idea as I did.
&gt; Since Landsburg claims that sex in itself is good The writer of this has quite obviously never got laid. Also, there is an intelligence bias in selection of partners - ones that are clearly high risk are quite obvious from personality, habits, etc. Also double bagging. &gt; It's hard to be sure exactly what Landsburg means because his essay is vague on specifics. Landsburg is more intent on speculating how to encourage sexual conservatives to loosen their morals for the greater good, even though it is not to their individual benefit. If you get laid more, there's obviously an elevated chance of getting an STI. BUT YOU GET LAID MORE. &gt; Half the high-activity players are already infected when the simulation starts. What
Oh, I meant those as place-holders. They would be easy functions to write, but might be system-dependent.
Yeah, but you're still stuck with a specific version, though not a specific path. You could try #!/usr/bin/env python2 or even #!/opt/bin/python2 but you risk some random script crashing that is not quite forward-compatible. My point is that *most* scripts are *completely* forward-compatible, at least &lt; python3k. Most scripts do not need to specify a version of python; they only need a *minimum* version. There should be a simple way to do that. It's a common enough occurrence. Such a system sure would have helped my old company with its versioning mess.
Oh my god it's been three hours! What has she done to him!?
Python is just not that suitable for desktop applications.
OK, you probably want to take this one package at a time. There are examples in the py2app source for PyOpenGL, PyQt, and wxPython, and I don't think NumPy should be much of a problem. I'm assuming py2exe has similar examples.
On Windows, since I just wanted to avoid installing Python on every machine, I've ended up using [cxfreeze](http://cx-freeze.sourceforge.net/) and copying some libraries from python/lib/site-packages. Here is one example: cxfreeze test.py --target-dir dist --include-modules=ctypes,xml.sax,xml.sax.saxutils,csv --exclude-modules=OpenGL_accelerate,OpenGL,matplotlib After running this command, I just copy the folders for matplotlib, OpenGL and OpenGL_accelerate from my installation to the *dist* folder where the frozen app is created. 
&gt; For high-activity players, the increased activity of the lows is a pure boon. The number of infections among high-activity players does drop with increased activity by the sexually more restrained. So Landsberg's motivation becomes apparent.
Most economists that get into sociology are full of bullshit like this.
Uh... what?
It uses PyCuda I thnk
She's informed him of how she's kept herself STD free for all these years.
Python has a horrible development/distribution tool-chain for anything other than web-development. That is true. However, if you ignore that, or can make an intern figure it out for you, then writing the actual code for a desktop application is a downright pleasure. Especially with PyQt.
It went better than expected! She assured me that if I started, I'd be able to have sex with any woman who also agrees with Landsburg's theory. I struck gold!
I just tried this now, and when I run the exe file it can't import GL (telling me "PyOpenGL must be installed to run this example." since I'm using this to test it: [hellogl.py](http://qt.gitorious.org/pyside/pyside-examples/blobs/master/examples/opengl/hellogl.py)). I've also tried including the modules OpenGL and PySide [edit: with the same result]. PS. not using OpenGL-accelerate yet, want to get a minimal system working first. Also, I was hoping to be able to develop for Mac on my windows box. Currently using Java for the application which works great and allows me to do this, but my program needs a significant rewrite and I thought I'd take the opportunity to switch to Python so that the JRE isn't required and because I like Python.
Yeah, I think I'll have to go C++ (wouldn't be able to do QT or wxWidgets in C). Only problem is I'll have to get my boss to buy me a Mac :)
hehe I think I say t-kinter with a really short t, so it's closer to the second one. Also, +1 for Vulcan-sounding =P.
Oh, you guys just down-vote me because I told the truth? I've been a fan of python for years, but no programing language is versatile!
I prefer WPF for desktop applications. If you need cross platform, then try mono. But if you are familiar with Glib, Gtk+, albeit a bit awkward, is functional. If you application doesn't need any native resources other than network, Adobe AIR is another alluring choice.
Qt is an excellent toolkit. You can even use WX. My company has delivered many native, rich-client applications of reasonable complexity and with 3D visualization, large data support, network APIs and multiprocessing capability. More importantly, they were extremely customizable and extensible (a la Eclipse), and had scripting support built-in.
Yeah, I forgot Qt. Better than Gtk+ or WxWindows.
You mean a logical hypothesis, yes.
I thought for sure that someone already had, but was happy to contribute the obvious.
Atlanta again?... :-(
Just yesterday I built a stand-alone binary for a desktop data analysis application which makes heavy use of wxPython, numpy, scipy, matplotlib and VTK. I was using bbFreeze, but I've also used py2exe successfully for this in the past (with the same set of dependencies). It's true distributing desktop python apps is not as easy as it should be. All the builder systems (py2exe, bbFreeze, cxFreeze, py2app etc) have their own pros and cons. With bbFreeze, the python code, eggs and compiled extensions are handled well, but you need to pack the package data (icons, images etc.) yourself, which can be tricky.
PyCon is always in the same place two years in a row. The previous two years were Chicago, the two before that Dallas, etc.; the contracts for venues and such work out better when you can make that commitment.
Seems like you need lots of access to a mac (or at least OS X) for testing in either case here?
With the current Java version, it took me about 1hr to port it across to mac and set everything up with opengl libraries etc, since then it has been over a year and during this time all I do is just send my boss an updated jar file and it's just worked ever since. With C++, I'll most probably need access to a mac to compile. A proper compiled version will be great for production release. [edit: not sure about p2app, but was hoping I could create mac binaries on windows]
&gt; rich-client Those are the best kinds of clients! heehee
&gt; no programing language is versatile! Shhh! What are you talkin' about?
I kind of like the idea but it would be a bitch to type
If you are using PyOpenGL just for its opengl bindings, then you could consider using Pyglet instead, which provides similar bindings in pyglet.gl, which work as a drop-in replacement in my experience. I have been able to successfully bundle pyglet using py2exe, for example in projects like this one: http://code.google.com/p/brokenspell/ In addition, I find pyglet bindings to be about *three times* faster than pyopengl (in total program execution speed), doubtless because they do less error checking and type conversion for each function call. 
Nicotine+
I'll be buying it :-)
What ubernostrum said - after 2011, it will be in San Jose for two years. That said, I don't know what everyone's problem with Atlanta is. It's not that bad a city, and has really good food.
I thought the plan was only to do SJ for one year as a test?
I would love pycon to be held in Atlanta forever, but then I am a bit biased because I am a 3 hour drive away and I save myself the annoying plane trips.
It seems you have to include some more modules. I was able to freeze the hellogl PyQt example with this: cxfreeze hellogl.pyw --include-modules=ctypes,logging,ctypes.util --exclude-modules=OpenGL,OpenGL_accelerate and then copied only the OpenGL folder to the dist folder. I believe you can do something like that with PySide.
I use py2exe and py2app every day w/ 2.7. No issues at all. I suggest using PyQT though, PySlide looks awesome but doesn't support alot of platforms yet (and there are fewer examples available).
Not a big fan of the whole thing, but I really like the for...in loop: `‚àÄ i ‚àà range(BOARD_SIZE)` It seems easier to read somehow.
I prefer a proposal for purely python math
We've been running Python 2.6/2.67 on CentOS in production for over a year, no problem. `./configure; make; make altinstall` and use buildout for deployment. Fire the app up on a port/socket, proxy to that from nginx, job done.
Short answer: No. In Python modules have their own scope, and the import statement adds the other module to the scope of the current module. The only way to do what you're suggesting is to create a file with the imports (call it: badform.py) and then do a execfile('badform.py'). This is NOT pythonic and NOT recommended. You should only import modules if you need them in that file, and having those listed explicitly is a Good Thing. Edit: fix weird underscore formatting.
I think you could do that by having a header.py where you do all your imports and then in your "implementation files" do "from header import *". This severely reduces readability of your code though, as you have to dig through another file to find out why something is not in scope.
What about it is specific to web applications? I've had no problem deploying a whole suite of in-house scientific tools using distutils. It takes only a few minutes to write and test a setup.py script and then they are ready to be installed.
Unless you're web2py :)
My one regret from last year was that I didn't make it to [The Varsity](http://www.thevarsity.com/), which always comes up on The Travel Channel or Food Network shows, along with plenty of other great looking places.
Here is a sample python GUI app that demonstrates one way to do what you're asking. It uses Tkinter, which may not be not the best toolkit for intense graphics, but it's simple, and comes with python by default, so it's easy to get started. This sample app works, and could be an easy GUI frame for your project. It's about 200 lines of text. Pasted online at: http://www.heypasteit.com/clip/NB8 cheers, michael.
You can also import all the interesting things in one module, then selectively import from that module (`from header import foo, bar`), which kind of does what you want but without sacrificing readability. Well, it sacrifices readability a little because of the indirection (someone has to read header.py to figure out what those objects actually are).
You shouldn't, and it's that way by design. Roughly, when you try to call a function, Python looks for that function's name to see what block of code to execute. If you've only got a few functions defined/imported inside that file, this is much quicker than, say, searching through every function name used everywhere in every file in your program! You can actually see some noticeable performance boosts by limiting what you import to what you need. And as a bonus, when someone else is trying to figure out your code, there's a direct link to whatever your including. (This is also why import * is considered kind of gross by a lot of people)
Remember, in Python imports help document what external interfaces and functions you're using and are a boon to development. Unlike C/C++ where the header files are a burden you must satisfy to keep the demons of linking at bay. 
Make sure you try the Chili Burger, the Frosted Orange, and the Onion Rings. If you like hotdogs (I don't), then you should probably add a Chili Dog to the list. That pretty much covers the iconic menu items. If you like greasy spoon fare and you're feeling adventurous (and don't mind boring cab rides through shady parts of town), try visiting the original Chick-Fil-A (located in Hapeville) and ordering a [Hot Brown](http://www.randomatlanta.com/37/the-hot-brown-at-the-dwarf-house).
That is a really bad practice in C because every simple change to any one of your headers will result in a recompile of every source file in your project. If that wasn't enough, every source file will need to reparse every header file. Some compilers can optimize some of that away; but not all. Further, it makes disentangling source files into distinct packages more difficult. And of course, the header order will begin to matter since the second include in your global.h will always include everything in your first include. Please learn to avoid this practice so when you start working with others you won't give them headaches.
No, but that is not the problem. You are still thinking in c++, and I think you will find python _much_ easier once you start thinking in python (otherwise known as being 'pythonic').
Note, web2py does not do what is described above (I know you're not saying that -- but just to be clear). Also, web2py *applications* do NOT use exec, and they do explicitly *import* any needed non-framework modules as usual. However, the web2py *framework* layer does execute the application code (in a prepared environment). This has some nice advantages. More details [here](http://web2py.com/AlterEgo/default/show/271). :-)
Upgoat for you! I came here to say exactly this. Anybody who inflicted this sort of include structure on any team that I work on would be called to task. There's only one place where you *might* do something like this and that would be with precompiled headers but, even then, you'd want to do it only with the very most frequently used header files.
Can we avoid links with affiliate IDs in them? This is a Stack Overflow affiliate link.
It's terribly bad form but you can use "from &lt;module&gt; import *" which will import everything into the namespace of the current module. so you could have all_modules.py: from module_1 import * from module_2 import * etc Then anywhere else you want to use all those modules: from all_modules import * And it will do what you want, but again, very bad form and not recommended.
I don't have anything against Atlanta other than its distance from me, which is rather great...
But I just signed up for SXSW Interactive during the same dates! *Sigh* Oh well. My employer is willing to pay for SXSW.
Oh god that sounds so good. I'm almost disappointed I went to Django's 2x (not that it was bad).
On top of what everyone else has said, it is a good question that most likely has benefited many. Thanks.
It's easy to see why, coming from a C background, one might want to do what the submitter is asking. After using Python for a while, I realized just how helpful it is to have all symbols explicitly declared in the file they are used (whether by being created in the same file or imported by name). It's incredibly frustrating now to come across an unfamiliar function in a C file which includes 27 header files, and have no idea which is the relevant one. The same goes for the 'from foo import *' mechanism in Python, but I hope most Python programmers know to avoid that.
A Model-ViewModel-View approach would facilitate swapping the View part. The Model part would be your domain stuff, like the connections, and the ViewModel notifies the UI (through an Observer pattern) of any data or state changes. This is close to MVC; the difference is that in MVC the Controller knows about the View, so it calls methods on the View _and_ the Model and thus suffers a bit from a God-class syndrome. In MVVM, the View knows about the ViewModel and the ViewModel knows about the Model, and all communication back to the View is handled through an Observer interface, so no knowledge of the View leaks into the ViewModel. Edit: I edited it. :-)
how is that any different from: import foo, bar ??
Reddit: I reddited them both and appreciate the info. We have a scheduled power outage here at work in 11 minutes, so I can't go any further for now, but you've given me a pattern to look into. Thanks!
Are they rotated arbitrarily? And are you only interested in integer points?
It looks a lot like the functional language [Agda](http://www.cs.nott.ac.uk/~nad/repos/lib/src/Algebra/Props/Group.agda).
Is this problem well-specified? There's something I don't understand. Do you mean to sample uniformly from the surfaces? Then you would choose *l* (which cube) using roulette-wheel selection, with probabilities proportional to the cubes' surface areas. Then choose one of its *2n* sides, and generate *n* numbers in *[0, l]*. But obviously you can't enumerate all the points on a surface (let alone *2mn* of them, or whatever the number is). And you can't create an exhaustive set. So I guess I've missed something. 
Take a look at Model-View-Presenter.
Thanks for that, Pyglet looks pretty good! They say that they regenerate the OpenGL interface from the latest specifications, sounds great because I need to use a specialised fragment shader. I'm just hoping that sending across an array of 10 million floating point numbers from Python to Pyglet's OpenGL interface won't be too slow :P
I'm not sure exactly what you're looking for but it sounds vaguely like [Latin hypercube sampling](http://en.wikipedia.org/wiki/Latin_hypercube_sampling)? Here's [something](http://code.google.com/p/bayesian-inference/source/browse/trunk/build/lib.linux-i686-2.6/BIP/Bayes/lhs.py?spec=svnb3cfeec1db2de79f5c00698199c0a9ebf86ce2df&amp;r=50a5c577b92ec2d08b744a6158725ea3b067b950) that's written in python that might implement that. That said, I've only got a vague sense of why something like this would be useful. FYI: If this isn't fruitful here, you might want to try stackoverflow.com, there are [some questions](http://stackoverflow.com/search?q=hypercube) some hypercube-related questions over there.
Wow, I haven't touched this stuff since Neural Networks. I'm not sure exactly how you can do this, but I would try to find a way to convert whatever is defining your hypercube to some type of [hypercube skeleton](http://en.wikipedia.org/wiki/Skeleton_\(topology\)). If you can generate a list of verticies as functions, you could plug in random variables to random functions in your list to create your random set. I donno if that helps at all.
That would work. The exhaustive set is possible as I'm talking about integral sided cubes (of relatively limited dimensions).
Both of those are true.
That's pretty much what I'm looking at at the moment - trying to set up a connection schema.
consider a hypercube in D dimensions of side 1. The coordinates of the vertices of the faces ate (-1/2,0,...),(+1/2,0,...),(0,-1/2,..),(0,+1/2,...) etc where there are 2D verctors, each of D components and components are all zero except one which is +/-1/2. Pick a face at random (random.randint(1,D)). That face is a hypercube of dimention d=D-1. You can generate a point at random in it by replacing the each of D-1 components of the vector =0 with a random.random()-0.5. So here is it def random_point(D): v=[random.randint(0,1) and 0.5 or -0.5] v+=[random.random()-0.5]*(D-1) v=random.shuffle(v) return v
&gt; not recommended Not least of all because module_1.foo and module_2.foo would clash.
That does what I want - though I should have made more clear that I need a defined number of unique points on the surface, so this may not manage that. This is why I suggested the enumeration of points - then dealing out the required number at random. Thanks.
To be honest, I feel that you would get more replies on stackoverflow.com
&gt; Connection schema Build it like you would build a _tree_ function. Each branch that connects down to m nodes will connect n branches (or however complex you want to make it - think [generalization](http://en.wikipedia.org/wiki/Generalization)). For a _normal_ hypercube, use 1 (or -1/2 to +1/2, however you want to translate it) as the length (or value) of the vertex. And there you go, you have functions that can return random samples across the verticies. As far as finding samples on the surface, you can build a function that integrates an equation between two vertices. And that's basically modeling. Good luck!
Yeah, I'm going general, but the connections are to surfaces rather than vertices. I've pretty much got is solved now - trying to replicate some work that was published in the 70s. Fun.
Will do, thanks. I need to find some good, simple examples of these patterns. Reading about how they do things doesn't seem to be enough for me.
This is the second time someone has recommended that place to me for some Python help. I'll check it out. Thank you!
I take it you're a Maya TD? Hello there, comrade! Assuming the utility code is not doing UI-related work, you'd ideally implement it without the slightest notion of a UI; this functionality can then be used by UI callbacks as necessary. It may very well be that you're already doing something like this. In your example, the real work of switching over to the new system is the bulk of the UI class (which you'll have to rewrite no matter what). In other words, you are not saving much work by putting the callbacks in a separate module and changing an import line, as opposed to including the trivially implemented (because they're just delegating to utility functions) callbacks in the UI class. As a final note, I would avoid using something like MVC unless you absolutely need to; that sort of design pattern seems geared more towards specific manageability issues in medium- to large-scale software, and if applied inappropriately may do more harm than good.
I second that Web2Py is a solid framework and will prove the test of time. Very solid structure build for simplicity. Lacks some flair but is leaning towards what .py is about, simplicity in structure even if loses some speed. So what with processor power to conquer that it brings natural structure which is easier to work with and proves itself to be something to develop into a developer friendly platform.
Indeed, and hello! I am leaning a bit toward extending the utility end from the UI end, and as you say, leaving the UI completely out of the working half. I've actually been implementing the utility side without need of a UI at the moment, even though the whole thing is intended to be a UI-only tool in the end. The data and manipulations thereof work all by themselves, though, and this tool could probably help out completely outside of Maya in the end, so I'm keeping one eye on the idea of making it more universal in the base class. I'm just now getting to where I'd like to start being able to click buttons and things to make it work, though, thus this research. I thoroughly agree about not saving much work and I realize I'd need to reimplement essentially everything on the UI end in any new framework regardless. I'm also forseeing eventualities wherein Python is not handling the UI, and then I'm not going to simply be importing things that play nicely together anyway, but finding some way to send data between sides. I've been feeling that design patterns are probably above the scope of this little utility, but it might be a nice place to learn more about them, while needs are fresh in my mind, and uses for such things may seem more relevant. Other than that, one of my minor concerns was that it would feel weird to create a new UtilUI, instead of just a new Util, but now that I'm thinking that over, it really is a UtilUI that I'd be creating - you know, with the UI as an intrinsic part of it. If I just wanted Util, I already have that in the base class, and it works fine free of the UI. It sure does help to talk this stuff out with people :)
Hello Pythonistas, Look at your Class, now back to me, back to your class, now *back to me*. Now sadly it isn't me but if you extend him properly he could have a method like me. Look down, back up, where are you? You're on a PDB session with the method your class could invoke. What's in your hand, back at me, I have it. It's an oyster with two tickets to Djangocon. Look again, the tickets are now ponies. Anything is possible when your class has a method that's not in a PEP. I'm on a horse. Sorry, couldn't help it :)
I think this is a good approach, but making a light-weight implementation (of the observer pattern) may be tricky. An excellent existing MVC / MVMV library is Traits+TraitsUI. In this case Traits "views" simply define the UI content and layout. They are totally decoupled from the model (objects subclassing the HasTraits class). The controller can often be left out (a default one is auto-created), which makes it easy to get started without the usual boilerplate overhead of MVC. Traits implements notifications on object attributes (i.e. an observer pattern) implemented in C for speed. The only thing stopping me from recommending this 100% for the OPs application is that TraitsUI is not freeze/zipfile friendly, making distribution as an embedded component in another app tricky.
lmao... you in india or something??
You're right; MVVM is an extension of MVP for Microsoft's Silverlight and WPF, which have plenty of support for Observer pattern and the like. I'm pretty sure there have to be approaches better suited to Python, but I've never built a big GUI app in Python.
The performance issue is because "import" actually executes the module's code, not because it is searching through more names. The hash tables used for namespace lookup scale up reasonably and do not because noticeably slower as they grow.
Good use of C/C++ also uses #include's as an indicator of what dependencies you have. Despite a completely different technical implementation, they are similar in concept to "import *".
Check your PYTHONPATH. Where is your site-packages folder? Did you install pygame using the python3.1 binary and not the system binary?
2D or 3D?
On then def random_points(d,n): "d = number of dimensions, n=points/hypersurface" points=[] for k in n: for z in (-0.5,0.5): for i in range(1,d): v=[z]+[random.random()-0.5]*(d-1) v[0],v[i]=v[i],v[0] points.append(v) return points 
pylons has RESTController that makes all the basics for you, i think werkzeug also has some support out of the box for it.
in web2py if you can decorate any function and turn it into a service. For example @service.run def f(a,b): return a+b could be called with (named arguments) http://127.0.0.1:8000/app/default/call/run/f?a=2&amp;b=3 or (unnamed arguments) http://127.0.0.1:8000/app/default/call/run/f/2/3 There are also decorators for xml, csv, rss, json, xmlrpc, jsonrpc, amfrpc, soap. This is described [here](http://web2py.com/book/default/chapter/09) in some detail. The web2py urls by default are not by-the-book restful because they are not resource/action but they are something like /app/controller/service/type/action/resource but you can easily remap them by editing routes.py. service urls (like the one above) are stateless as required by REST. Anyway, if you simply need JSON output or XML output, there is a simpler way. Just call the regular web2py action and append .json or .xml. Instead of rendering the action in in html will use a generic template to convert in the required format. The generic template can than be customized. For each controller function you can have different templates associated to different protocols.
Is it really that bad that someone else makes money? you get exactly the same price.
flask is easy and you can use sessions
Personally, I think hand-crafting the REST layout is much better. I am working on a project now that uses nothing but pure wsgi and has an awesome REST api.
But there are still infinitely many points on the surface of an integral-sided cube, ruling out an exhaustive set. But since you've solved your problem already, I'm obviously misunderstanding (still). Nevermind...
&gt; but I don't think it's fully conforming with RESTful architecture. There is nothing to "conform to" as there is no "RESTful certification" or anything like that. It also means *no tool can magically give you a restful architecture*. Now if you're interested in *understanding* REST. you might want to start with the wikipedia article on the subject to get a (probably mostly wrong) overview. Then go read [Roy Fielding's posts on the subject](http://roy.gbiv.com/untangled/tag/rest) (Roy Fielding is the one who [introduced and defined the expression "REpresentational State Transfert" in chapter 5 of his doctoral thesis](http://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm), you might also want to read the thesis itself but it's fairly dry and not necessarily useful). On his blog, Fielding discuses and clarifies REST and it constraints, as well as "case studies" of APIs claiming RESTfulness. Following this, you might want to skim the Atom Publishing Protocol spec as it is considered a fairly canonical RESTful protocol, and to read "RESTful Web Services" by Leonard Richardson and Sam Ruby as it gives a number of guidelines and concrete advices. The tools come last, if you have no idea what the fuck you're doing, they aren't going to help at all and you're going to head for cargo-cult land fast (or you're going to use "RESTful" as a meaningless buzzword while implementing an RPC-over-HTTP service)
Yes, the tables scale reasonably, but finding an item in a haystack is always going to be quicker if the list is smaller. Especially on large, repetitive codebases (I first learned this concept reading about someone who had halved their unittesting time by shuffling imports), it can make your code better.
&gt; The web2py urls by default are not by-the-book restful They'd have a hard time being considering *there is no such thing as a restful URL*. REST doesn't deal with (or care about) the look of your urls. On the other hand, from reading your "legible URLs", web2py doesn't seem to help dealing with REST at all either. From your URLs, you're doing RPC-over-HTTP, not REST. &gt; service urls (like the one above) are stateless as required by REST. I don't understand what you're saying here. URLs are paths to resources, what state could they ever have? And if the resources behind those paths have no states, what use are they? Even trivial resource upload (√† la imgur stripped of every feature but upload itself) has two resource states (existing and not existing).
&gt; I've been feeling that design patterns are probably above the scope of this little utility, but it might be a nice place to learn more about them, while needs are fresh in my mind, and uses for such things may seem more relevant. That's definitely an appreciable reason; I do find that design patterns work best when treated as food for thought, inasmuch as they're formalizations of generally good coding pratices (MVC for example is just a special case of loose-coupling). Just realize that these things are pretty vaguely defined, and you might go insane trying to implement something in a way that satisfies some purist's notion of what is or isn't Model-View-Controller/Presenter/Bartender. As far as I can tell (and I may be wrong as I'm not an academic), the basic idea of MVC is simply to separate your data and related methods (the "model") from their on-screen representation (the "view"), as facilitated by a mediator that modifies the model on behalf of the view and vice-versa (the "controller"). In practice, this can mean creating a pair of abstract base classes for the model and view, each containing only those methods needed by the controller to do its magic, and the controller is just whatever mess of code you need to write up to make everything work. This makes a lot of sense if: - The operations performed by the UI are conceptually related to a single piece of data. - The kinds of user interaction occuring in the view have a non-trivial mapping to operations performed on the underlying data (so the controller does more than just connect event handlers). - You require the model or view to be swappable with an alternate implementation. EDIT: spelling
Sorry, my fault. When i say integral-side I mean with integral positions - think of the problem as a choice of cells rather than positions.
"Doth" is third person.
Nope, LA. I had it wrong, though. They were shutting down the servers, and the power outage is today - Saturday. They're doing some big maintenance or something.
I agree minimal imports are great, but I don't think smaller hash tables having faster lookups is the reason.
Google tends to give results to the 0.9.7 docs. It would be nice to have a shiny "this is not the latest version; click here for 1.0 docs" near the top of each page. SQLAlchemy and especially Django have nicely-organized documentation pages with cross-version links near the top; that's the kind of thing I'd like to see on the Pylons site.
Vote for flask. I've been working on a hand-crafted REST project and it's beautiful to work with.
The resources can have state. But RESTful is by definition a stateless protocol meaning the resource has no knowledge about the state of the client. I am not talking about web.py. I am talking about web2py. They are not related.
Thanks - [this](http://roy.gbiv.com/untangled/tag/rest) was a very good primer. Also, roygbiv, isn't that some mnmonic for rainbows or something? :P
&gt; But RESTful is by definition a stateless protocol No, HTTP is. REST is not a protocol, and RESTful is a characterization of an API. And you didn't talk about protocols when mentioning statelessness, you talked about URLs. &gt; I am not talking about web.py. I am talking about web2py. They are not related. You're right, my mistake, this typo has been corrected.
I'm not sure I'm following what you're asking. Are you trying to get python to run code in the background while waiting for raw_input to complete? If so, you could probably use threading since I believe raw_input releases the GIL.
Two words: Multiple. Inheritance.
We used restish and it worked well. It is a very simple/minimalistic framework meant for RESTful interfaces. http://ish.io/projects/show/restish http://pypi.python.org/pypi/restish/
Why would you want to execute code while reading user input? Does the code not depend on an input from the user?
I think you'll need to poll for keys and handle the input line yourself. Doing so is OS dependent, I believe.
Use the select method.
look up the concept of a nonblocking read. or learn threading in python
If you're writing a standalone webservice, you can't get simpler than webob and your own choice of URL dispatcher.
+1
Flask is fine until you step off the reservation.
How so?
This doesn't work on windows.
Haha seriously?
Your comment makes me sad.
Yep - the colours of the visible spectrum in ascending order of frequency - red, orange, yellow, green, blue, indigo and violet. Also, "Richard Of York Gave Battle In Vain" or various other phrases.
You can use a library like [pygame](http://pygame.org/news.html) to poll for keys in a platform-independent way, or the msvcrt module if you're only targeting Windows. See [this stackoverflow post](http://stackoverflow.com/questions/2408560/python-nonblocking-console-input)
Regardless, threading would allow the user to perform actions pseudo-concurrently, just not truly concurrently since it's Python.
This problem is solved with threading. You probably have a lot of research to do if you ever want to do complicated threading. For simple applications in Python, you can start [here](http://docs.python.org/library/threading.html).
You could try the [ncurses module](http://docs.python.org/library/curses.html)..
http://blog.nodejitsu.com/create-nodejs-web-services-in-one-line
I think this is a honest question and this is not the place to act arrogant to people who do not have the same experience as you to answer a question. miles_g: of course at least a part of your code depends on the input (or else you wouldn¬¥t prompt the question in the first place), but other parts could work independently from the input. A very simple example would be: multiply the user-input with the third prime with 100 digits. You have to wait for the user to input the number, but you also need to wait a long time (say 30sec) to calculate the prime (supposing you don¬¥t have a list of primes). Say the user takes 10 sec to input his number, the total runtime would be 30 sec if you had processed the prime parallel to the input, otherwise it would take 30+10 = 40 sec. 
I thought the difference between pseudo-concurrency and real concurrency is that pseudo simulates parallel processing on a single processor using time division multiplexing and the real one does parallel processing on multiple processors. Can python not take advantage of multiple processors?
Right; it cannot take advantage of multiple processors with threads. It's one of CPython's biggest blemishes and is caused by the GIL, though I'm not exactly sure why such is the case. However, one way to achieve true concurrency is to use multiple processes with message passing, since each interpreter will get its own GIL. Python is not necessarily like this by design. Jython and IronPython use the true threading mechanisms of the JVM and .NET frameworks.
Maybe use [multiprocessing](http://docs.python.org/library/multiprocessing.html)?
A few road blocks kept cropping up but one issue I can remember is that URL patterns were really rigid. If you wanted to do something custom, you'd have to define a converter class and stick a regular expression in it. Generally these are going to be one-off converters, used only once in the project, or even my life. It seems silly have to right that much code for a one off scenario. That's honestly my biggest complaint with most URL dispatchers out there, they're usually just using regexp under the covers, so just let me define it myself. I'm a big boy, I can write regular expressions. 
It's a primitive chat client. I want messages to be printed, but also allow the user to write and send messages.
well, thats actually javascript and node.js but the idea of exposing python modules as RESTFul resources could be neat!
Oops, I missed the part where this was submitted to /r/python, but yes! Python would be an even better fit because named arguments as a better metaphor for what HTTP does than the argument lists JavaScript uses.
&gt; They'd have a hard time being considering there is no such thing as a restful URL. REST doesn't deal with (or care about) the look of your urls. I'm not a web2py user but you are being picky. "restful urls" is a term that has been coined to describe the generic pattern that has rised along with the success of REST to identify resources through URLs. I do agree however that the aforementioned URLs look more like those of a RPC-over-HTTP web service rather than a properly defined REST web service.
&gt; I'm not a web2py user but you are being picky. No, I am being right. There is no such thing as "RESTful URLs" and if you say "RESTful urls" when you're talking about legible URLs you're a moron. &gt; "restful urls" is a term that has been coined to describe the generic pattern that has rised along with the success of REST to identify resources through URLs. No it hasn't. Legible URLs have nothing to do with REST and are unrelated to it. And identifying resources by their URL is not a pattern, it's a core concept of representational state transfert. Finally, risen.
mpi, but it might be overkill for your purpose
&gt; No, I am being right. If you are then why your need to keep discussing past that statement? Please, define clearly what you mean by legible URLs because replacing one word with another is not helping. &gt; And identifying resources by their URL is not a pattern, it's a core concept of representational state transfert. What I meant was that a pattern about how building (what I assume you call) legible URLs has risen through common idioms and is generically refered to RESTful urls. You don't seem to like the term. However, REST doesn't actually care either about URL, only about identifiers. URLs are one possible implementation of said identifiers. They are, of course, the defacto mechanism when implementing REST over HTTP. In that sense, to me the usage of RESTful URLs, for all intents and purposes, is about defining legible URLs for a [RESTful web service](http://en.wikipedia.org/wiki/Representational_State_Transfer#RESTful_web_services). &gt; REST uses a resource identifier to identify the particular resource involved in an interaction between components. REST connectors provide a generic interface for accessing and manipulating the value set of a resource, regardless of how the membership function is defined or the type of software that is handling the request. The naming authority that assigned the resource identifier, making it possible to reference the resource, is responsible for maintaining the semantic validity of the mapping over time (i.e., ensuring that the membership function does not change). 
It's so amusing to see the hoops Windows developers have to go through to do something a Unix user would just expect to work out of the box.
Ah, so you're not using RHEL. 
&lt;nelson&gt;Hah hah.&lt;/nelson&gt; Here's a nickel, go buy yourself a real computer.
For something like that you definitely need to learn how to write threaded code. You need to be careful that two threads aren't writing to the same memory, so you use mutexes. Once you get that hang of it, it's not that hard. In python the global interpreter will only run one pure python thread at a time, but since most of the time your application will be waiting on IO you shouldn't have much problem.
I've just started converting some code from threaded to multiprocessing and that module is amazing.
MinGW is the wrong recommendation. It's a huge mess, takes forever, and is poorly documented. All the Windows Python builds that are available from python.org were compiled with MS Visual Studio 2008. Since you need a compiler to build extensions (as the post mentions) then you should just install Visual Studio Express 2008, the free version. You can find links to it here: http://www.microsoft.com/express/Windows/ Remember, you need the *2008* version, not *2010*. 
Python is installed by default, "yum install emacs" and I'm developing.
&gt; Please, define clearly what you mean by legible URLs URLs making sense to a human being, as in `/app/default/call/run/f/2/3 ` rather than `/base.asp?f=42&amp;skweee=3&amp;app`. &gt; You don't seem to like the term. No. Because it makes no sense. 
Okay. Incidently I think I prefer your term of legible URLs in the end :D
Wasn't there just a new PEP posted called "web3" (or similar) regarding this?
Fair enough. I was dealing with a diagram produced by Vizio, and saved as SVG. Whatever version of Vizio was in use had a XML namespace error in it, but was otherwise strangely clean SVG. I tried loading it into Inkscape, and it screwed up the styles pretty badly. I thought the SVG inkscape produced was uglier too (I was working with the diagram in a web app, so I actually cared). I can believe it is one of the better tools for the general problem of vector files though.
Some old version of Python is installed. If that's what you want, then you are in luck. Otherwise, it's a bit more work to set up a parallel installation. If the Windows guy had started with ActiveState Python, then it would pretty much be a tie. 
I think you mean PEP 444 - that's to do with a new version of the spec which learns from the practical experience of WSGI implementers as they implemented PEP 333, and IIUC may break compatibility in some areas but should be a neat solution for Python 3.X. The linked-to post is about tidying up PEP 333 so that existing WSGI implementations can provide better support for Python 3 within the existing spec, by clarifying some things which were ambiguous in PEP 333. However, there is (understandably) opposition to "rewriting history" by changing PEP 333 in place, and the counter-proposal is to have PEP 333 be in approved status as it was before the recently mooted changes, and to put those changes into a new PEP which will be approved without too much delay. My $0.02, anyway :-)
Yes, I was somewhat confused about this, until I found [the preceding thread](http://mail.python.org/pipermail/web-sig/2010-September/004655.html) in the Web-SIG mailing list. So, this is WSGI for Python 3 *now*, and Web3 is the next WSGI.
Step 1. Install Python. Step 2. Open IDLE.
It's not a matter of arrogance. It's just that this sort of response is not any sort of encouragement to the OP. While it is true that many questions seem to reflect the asker's desire to do the Wrong Thing, I think that automatically shutting down OP is not a very inspirational way to treat others. This is completely independent of any technical aspect, like that this is useful or doable. I just thought that miles_g was being a bit of an ass (which we all have been from time to time).
I've never tried this myself since I don't have the need (VS user), but I've seen it stated lately that you can compile extensions with MinGW via certain flags specifying the runtime.
The hoops in that article are artificial. You could do as little as run the installer and be done with it.
It's not amusing when you have to do it for your job.
Now, there you go making me feel bad for being a smug dickhead.
Oh, I was just wondering. Not sure why people got upset and downvoted me.
It's often difficult to move forward with new ideas and their implementations. It takes guts, insight, and a lot of work. And it also takes convincing people to do what they know is good for them (getting rid of the old broken system and replacing it with the fixed but slightly different one). There's usually 4 groups involved in such endeavors: * one is the folks working on the new changes * then there's the people interested in seeing the fixes happen, even if it means they have to change a line or 2 of their code * another is the group of folks who aren't terribly crazy about change, but who kinda' know deep-down that the fixes are necessary * finally there's a small (sometimes tiny) third group who want to actively fight any change or progress. These folks argue on mailing lists (especially just after positive steps or decisions have been made), and guys like PJ (the author of the linked-to email message) even sometimes submit patches to the old broken system in an effort to thwart any change or progress. The point is: progress has to happen. Broken things need to be fixed. Sometimes this will mean minor pain, and that's *ok*. *Don't support those who: wait until an issue reaches critical-mass, watch someone come forward with a fix to move forward, and then jump in with patches to put a new coat of paint on the old broken thing that's about to be replaced.* **It holds back progress and only causes turmoil in the community.**
In web2py can map urls into anything you like so instead of /app/default/call/run/f?a=2?b=3 You can do /myobject/set?a=2?b=3 or /myobject/2/post?b=3 or /bla/bla/bla?a=2&amp;b=3 or whatever, depending on what it means. web2py does not impose a convention. I was just using the default convention is you do not setup your routes. there is a very big difference between @service.run (for rest) and @service.xmlrpc @service.jsonrpc @service.amfrpc @service.soap the latter are services (input and output are encoded unsing XML, JSON, AMF or SOAP respectively) In service.call no.
Why try to patch up the previous pep when it's already been replaced by pep 444? Just support the new pep and move forward. 
Yes, you can, and I've done both options (MinGW and VS Express) and I'll tell you that since Python itself was compiled with VS, it's *way* easier to go that route. There's a nice installer, and it "just works" like you would expect it to. Just figuring out how to get gcc installed under MinGW is a trial. 
It is not clear in the blog site how does that work. What is the method used? What is the difference between Nuitka and Unladen swallow and PyPy?
&gt; Unladen swallow A project to optimize CPython and implement a JIT with the help of LLVM. &gt; PyPy A Python interpreter written in Python. &gt; Nuitka Good question, as it's not remotely clear from the site. It seems to translate Python code to C++...not really a "compiler".
A little more information after playing with it for a few minutes - it apparently takes Python code and translates it to the equivalent CPython API calls, effectively removing the step of interpreting bytecode: &gt; Currently it‚Äôs not more than 4% faster than CPython. No surprise there, if all you did, is removing the bytecode interpretation so far. Neat idea. It's certainly one way to do something like py2exe. Not sure if it will be of any use beyond that.
&gt; Is having 5 layers of indentation considered bad practice? Generally, yes. It's quite hard to follow that many levels of control flow. Split it up into separate functions. I don't like 79 characters as a strict limit, unless you have a good reason to use it. It's a legacy value for ancient terminals. But having some sane limit is a good idea. Wrap where it makes sense and to enhance readability, not to an arbitrary length.
So it's a less-mature Pyrex/Cython?
It depends. I have a style which I like for dealing with long lines, but some of the time the solution is to break up your code a bit more. e.g.: change something like a = func1(func2(b, c), func3(d, e)) into a1 = func2(b, c) a2 = func3(d, e) a = func1(a1, a2) Of course, this all depends on what you're actually doing. Perhaps an example of your code would help?
&gt; I don't like 79 characters as a strict limit,... But having some sane limit is a good idea. Might as well choose 79, then. :P I know there are legacy reasons, but it also happens to fit nicely when I have two terminals running side-by-side.
You mean the PEP which still has unresolved issues *documented* in it?
It also helps with GUIs. On my 19'' 4:3 monitor I can put two 80 character code at a reasonable font size. If I drop the character code, my 19'' 16:9 monitor can fit three, but its pushing it. For the OP, I go to 80 characters as much as possible, but there are some times I just can't. Mostly when I unpack the results of a function into descriptive filenames: result1, result2, result3, result4 = someFunction(parameter1, parameter2, parameter3) You get the idea. In those cases, I just ignore the limit, or sometimes I will put each parameter on its own line (in Idle, just press enter after the comma) although that can look worse at times! The PEP does say that its better to ignore the style guides when the code asks for it.
For anyone using vim, add the following to your .vimrc to highlight parts of lines longer than 79 columns in python files. " Highlight parts of lines longer than 79 columns au filetype python highlight OverLength ctermbg=darkgreen ctermfg=white guibg=black au filetype python match OverLength /\%80v.\+/ I find that the 79 char limit can be helpful, but is sometimes too onerous a condition to apply strictly.
ick.
Besides that 80 characters is close to the optimal line width for humans to read. Line feeds can't span too long distances without risking frequent loss of focus.
Actually, I've read it's more between 60 and 70 characters, at least for plain language text.
From the first paragraph: &gt; No special language required, no unallowed language constructs, and only very few differences to standard CPython so it can become a drop-in replacement. **EDIT:** [Cython](http://en.wikipedia.org/wiki/Cython) isn't Python. Nuitka tries to be. 
For functions I will often use the parenthesis to break up the code, taking your example: result1, result2, result3 = some_function( parameter1, parameter2, parameter3 ) Edit: Ah, you already said that.
You can break up code inside ( ) into multiple lines like so: a = func1( func2(b, c), func3(d, e) )
It annoyed me at first too, but after a while, it started to grown on me. I discovered that my code tended to be easier to read because I had a good metric for when to start re-organizing: when lines started getting too long.
Refactor. Depth of three is usually enough. I try not to cross the 70 columns border, since I find lines of this length to be helpful when speed-re-reading code. Nearing 80 is pushing it for me. ;-)
Linus Torvalds said that [80 characters limitation is outdated][1], but he said also: &gt; If you need more than 3 levels of indentation, you‚Äôre screwed anyway, and should fix your program. In the same reason, keep your code limited in maximum 80 characters and it‚Äôs better to fix your program when it‚Äôs hitting the maximum column length. [1]: http://lkml.org/lkml/2009/12/17/229
Close enough, particularly considering that Python code is typically indented for 4-12 columns in. The point stands: going much wider than that will actually make readability worse, not better.
I didn't intend to belittle your point, actually I fully agree with you.
Anything more than that doesn't print very well in my experience. I know, who prints code, right? It happens. Code in 79 chars is nice on the eyes too, and its a nice way to force you to keep within 2-3 levels of indentation.
Yeah, this is about the only bit of PEP8 I don't like.
I'd probably put all three params on the same line here though: result1, result2, result3 = some_function( parameter1, parameter2, parameter3) or (if the function name is not visible enough): result1, result2, result3 = \ some_function(parameter1, parameter2, parameter3) Though in this precise case, at toplevel you only have 78 chars on the line, still good.
It doesnt even mention virtualenv and virtualenvwrapper... how can that be a complete development environment...
True, and I do this. But if you overdo it, you can end up with LISP. :P
Not really. You're still executing Python code, more or less. CPython works like this, I think: 1. compile source to bytecode, 2. translate bytecode to API calls on the virtual machine, 3. execute those instructions. Nuitka snips out those first two steps, particularly the second which would normally be done at runtime. Everything is still done with the Python VM. All the string manipulation, math, etc. Everything. You gain virtually none of the speed advantages of a C module.
Yes it is difficult to stay within that limit, for example in methods which are already indented twice. Personally I set the limit to about 120 characters, it works for me. The 80 character limit is an anachronism.
The rest of PEP-8 makes sense, but fuck that rule. Get out of the 20th century and realize that using columns arbitrarily sized to that of terminals you should never actually use is plain silly.
class, def, inner function, if, for - what is there to split into a separate function?
Hence comments are limited at column 72.
well, i know people who indent by just 1 or 2 spaces ("better than nothing"). they can nest a lot deeper.
how many spaces do you indent, or how wide is your tab?
that's more lisp-like: a = func1(func2(b, c), func3(d, func4(e, f)))
In vim 7.3 you can also highlight just the 80th column with set colorcolumn=80 I use both of these methods.
4 space indent
* Yes this is normal. * Try to have less layers of indentation (has extra benefit of making your code even clearer). * Remember that "foolish consistency hobgoblin mind" thing. For me that means, if a line is *just* over 79 characters, and I believe that my code would be less clear by breaking the line (which is usually the case for a line barely over 79 characters), I won't break it. Remember that 80 character terminals *can* handle longer lines, it's just that they break them. The 79 character maximum line length is (among other things) for making reading *easier* on a 80 character terminal, a goal which you *also* accomplish by having *almost all* lines shorter than 80 characters. * remember that in Python you can break a line for "free" only if it's inside (round, curly or square) brackets. Otherwise you have to use the `\` line continuation thing. Fortunately, inside brackets is usually also the *best* place you'd want to break your line in the first place. * also remember that as long as you get your line break for free inside brackets, there's nothing wrong with breaking up a line if it wouldn't go over 79 characters, if it happens to make your code prettier or more consistent in structure with some other place where you *had* to break up the line because it would have been too long. * What I usually do in my editor, is to switch off line-wrapping entirely, but to have a vertical marker at the 79th or 80th column. This way I can benefit from the fact that my screen can fit somewhat longer lines if really necessary, but still know at which position I should prefer to break the line if in any way possible. Hope that helps.
Actually, it is possible it was inspired by the 72 columns recommended limit for plain text emails, which was set in order to allow a few levels of quoting (with "&gt; " markers) before the text would overflow the then typical 80-chars screen width.
&gt; they can nest a lot deeper Which is maybe not a good idea. Deeply nested code should be exceptional (though I'll be the first to admit I've written my share).
You really shouldn't place the closing parenthesis on its own line. Now it looks like C or Java code. Python doesn't have an end-of-block delimiter, just an unindent. result1, result2, result3 = some_function( parameter1, parameter2, parameter3) is much more Pythonic.
if you have an inner function in a `def` in a `class`, you probably want to think of splitting as you get to the `if` and probably think to yourself "WTF am I doing" once you decide to put a `for` in an `if` in an inner function in a function definition in a class definition. TLDR: you probably shouldn't have two layers of indentation in an *inner* function.
This is a good question which you should always ask yourself.
I also have a lot of trouble sticking to this, but it does seem like good practise. Someone else already suggested you show some code you find it hard to get to the correct length so people can give suggestions, so i'll second that.
Critics are often quick to point out that Linus mostly works with C, which doesn't have classes nor namespaces. Python doesn't have indented namespaces either, though it has classes. So you might want to adjust that rule to 4 levels if you want an exact definition. I generally find Python's Zen to be the right approach, though: try to keep your nesting shallow, but don't worry about the exact numbers. In practice this means you'll nest most of your code at one or two levels (functions and methods respectively) with some at three (e.g. conditionals and loops in methods) and the odd line at four (e.g. conditions in loops in methods) or even deeper, if it's the most reasonable thing to do.
Totally disagree. Splitters!
And the most readable of all the options here.
I have problems keeping to 79 chars with writings decorators like foo @foo(5) def bar(): return The problem being that it's a function, which returns a decorator, which probably has an inline function in it. That's already 3 levels of indentation, and there doesn't seem to be a way of splitting it that serves any purpose beyond the splitting itself. also list comprehensions: [a for b in c if d] If a or d are complex and I have chosen longish names can come close to breaking the 79 char limit, especially if this statement is indented.
Turn off word-wrap. Be aware of the char limit. Let unimportant bits of code go on if need be. Don't let important bits go beyond it. Try not to have functions that take a lot of parameters. In depth: Remember the ultimate point is to keep your code readable, which is why I turn off word-wrap, it makes things less readable. 80 characters is horribly out of date, but it is a standard, so you want to be aware of it. A lot of code bits (ends of strings, ends of comparisons, etc) really just aren't important for groking purposes, I let that shit go beyond. But things like comments, and docstrings are really important and should be readable everywhere. And finally, most of the time the problem is caused by functions that have a lot of positional parameters, I try not to do that for this and many other reasons.
But should they?
Since it's not 1987 there's no reason to write code as if we were using monitors from that era.
If instead you need a fully featured Python 3 webserver you may want to look into this (https://launchpad.net/rocket). This is the one web2py uses. There is a version packed in a single file too. It is very good that Python 3.0 includes such a thing in a library module with ssl support.
It seems he didn't got the [memo](http://s3.pixane.com/python_comrades.png).
The 79 char limit is one I ignore fairly often.
&gt; Linus Torvalds said that 80 characters limitation is outdated (...) He mentions grep failing which has bitten me before. It's fairly annoying than looking for "the quick brown fox" and finding that someone split it in the middle to accommodate the 80 char limit. IMO and all, but editors can wrap lines just fine...
What? Why not? Since Python doesn't support true lambdas, inner functions are the only way to get a lot of stuff done. Sure, you could change the for loop to yet another inner function and use map, but other than that, there is quite literally no correct way to do the same thing without adding garbage to outer scope boundaries...
That is not the actual problem, cleaning up ofter the test is the real issue. Eg: undoing the damage a library might have done to the logging state (removing handlers that might be added, removing loggers etc.)
The exact number is arbitrary, but the idea of having a limit is not. I don't want one fullscreened window of code at a time, and I never want to horizontally scroll things. So I want a fixed line width, to resize my windows to.
This means: Don't use hideously long variable and method names. Don't use heavy amounts of indentation. A really long line is hard to parse for people, break it into smaller chunks. Don't be afraid to bend these rules though. You might be more comfortable around column 100. Using a smaller column width means you can view multiple files easily, a well as more legacy reasons, and encourages you not to heavily nest control flow, or use gigantic variable names. It is a simple constraint to follow that is useful and encourages good code most of the time.
Libraries aren't supposed to add handlers (other than NullHandler) - that's the job of the application developer. Of course library developers can *mistakenly* add other handlers, but that's just one of the things that library developers can do which mess things up. Perhaps I need to stress this more in the documentation. There may be loggers that have been created by libraries you use, but in general it shouldn't matter if you don't remove them. It's wise to only check expectations against what you log in your code, otherwise your tests would become brittle. So if you have library loggers left over from previous tests, then in a subsequent test they will either be used by library code, or not. If not, then there's nothing to worry about. If yes, then even if you had cleaned them up, they would be re-created. Anyway, your assertions should not (under normal circumstances) assert what those libraries log, because of the brittleness that would result. I understand that it might seem messy to leave loggers and handlers lying around, but because libraries should not add handlers, the only handlers added in a unit test should be the ones *you* add. And if libraries that you use are adding handlers and hence causing problems, I'm happy to look at these situations in more detail and even to discuss with library developers where it's feasible to do this. As for the question of creating too many loggers (e.g. as in the SQLAlchemy comment you linked to in the other Reddit thread), there is usually no need to create per-instance loggers. I've submitted [a patch](http://www.sqlalchemy.org/trac/ticket/1926) for Mike Bayer to look at this issue (it's not using Filters, so the performance impact is much less than we discussed earlier) and so far it looks reasonably good to go, though Mike will want to play with it some more. I will probably blog about that approach in due course, just to make sure people are aware of the technique. Of course it is fine to supply a documented library API or a property somewhere which adds handlers to the configuration: however, it should not be so by default, and always within the control of the library's user. Edit: Perhaps I've misunderstood your point - please feel free to illustrate with some code examples (perhaps on comp.lang.python rather than here).
Agreed!
I'm not trying to argue, but am I the only one who really doesn't feel this way about text in general? I'd rather make big jumps from the end of the line to the beginning of the next line than make frequent jumps.
I disagree. the closing paren isn't a block delimiter, and it looks WAAAY better on its own line at the same indentation level as the line where it started. this is how I've always done it too. 
I like to keep things within 79 but really have no problem breaking that limit. I don't usually line break unless I'm going to be going over 100 lines. I do keep docstrings within 79, though, because I do usually view them in a terminal, which is that length by default.
I use your second example. The continuation line goes inside the parenthesis. The first example looks unreadable to me. If I was scanning over the code I'd do a double take thinking you had an `if` statement all on one line (bad form), followed by an assignment. I'll just pretend I didn't see the third example.
I would go for #2 of the 3 presented. #1 is confusing because of the indentation issues, and #3 wreaks of some weird C code. Generally, I try and avoid the situation if I can. Also, I would consider indenting the 2nd line in #2 a bit more (another 2 or 4 spaces) so that the end of the if statement is clear.
I do 120 as well. I have a wide screen monitor and so I can still fit a couple of editors side-by-side. Even at 120, I still sometimes exceed that limit, though usually only by a character or two. I like to have as much code on the screen as possible. If I could afford a 30" monitor, I would buy one in a heartbeat (have a 24" right now). 
I use the following string wrapping technique. Instead of: &gt;&gt;&gt; s = "Really long \ ... string" You can do &gt;&gt;&gt; s = ("Really long" "string") This has the added benefit of allowing you to line up the parts of the string. The first method is a direct continuation of the previous line whereas the second method will concat the strings. I find this especially helpful for writing help docs for optparse
That was totally obnoxious, unhelpful and uncalled for. Have an upvote.
I'm confused now, but somehow I have the urge to give you all my money.
With the extra indent don't you end up with slightly confusing looking code like this? if (something == something and something == something): pass if something == something: pass Or would you double indent the second body too?
I always wanted to learn APL for the silly symbols, but I'm pretty sure I don't want any of that in my Python thankyouverymuch.
The 2nd.
While somewhat interesting, I'm not really all that impressed because all of the complexity is just hidden by some standard lib modules. Ah well, like I said, still somewhat interesting. 
What about a combination of 1 and 2: if (something == something and something == something): pass
I'm always tempted by this but I think the lack of indenting is probably wrong. I'd use it if it was in a PEP.
 if (something.allows(the_argument) and something_else.allows(respective_argument) and etc_also_too): maintain_correct_indentation() 