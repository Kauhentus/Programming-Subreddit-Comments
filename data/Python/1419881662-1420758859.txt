I discovered Python more than a decade ago through the same query. Scraping is a gateway to the Python rabbit hole. There weren't that many resources back in the day, no Udemy or Youtube, slow connections and a tonne of other things we have today weren't around. It would have been a lot easier if like these things existed.
I had this on my front page and didn't see the sub/context. I was thoroughly confused as to what you were trying to do to those poor bears.
Glad to hear. If I've helped one person, then my work is done :)
I definitely would.
I find your use of the word "generator" in "decorator generator" to be irritating. It may actually be very confusing for Python newbies who might then wonder where the *yield* statement is. "Factory" may be a more accurate term.
I'd recommend taking a look at [virtualenvwrapper](https://virtualenvwrapper.readthedocs.org/en/latest/) This is the kind of attitude that separates the new/hobbyist programmer from those with more experience or higher ambitions. When you're just beginning or programming small stuff for yourself, you don't really consider maintainability, so all of this seems excessive. But what happens when you need to go back to your project months/years later? What if you have newer libraries installed, but your project still relies on old ones? What if you need other programmers to work on your project? Without an easy-to-replicate environment, all of these tasks become more difficult. Virtualenvs aren't hard to master. They will more than make up for the initial learning curve.
For sure, I'm going to push an updated version with decorator_factory instead, somebody mentioned it over on Hacker News too, good catch! Edit: Update pushed
Um, should I install the forums on this server myself, or...
[b'lieve so](http://youtu.be/-cDAqrywsHE)
[Wow, more blogspam. I mean, seriously?](http://www.reddit.com/r/Python/comments/2qod70/short_and_sweet_definition_of_a_variable_in_python/)
I'm talking about the *language*, not its ecosystem, which unfortunately makes it harder to fix. Specifically, things like [the weird-ass parsing ambiguities](http://shape-of-code.coding-guidelines.com/2012/02/29/parsing-r-code-freedom-of-expression-is-not-always-a-good-idea/), [the lack of a standard method to doing things, the non-obvious errors](http://www.talyarkoni.org/blog/2012/06/08/r-the-master-troll-of-statistical-languages/), [the inconsistencies in argument placing (eg between `sapply` and `mapply`)](https://github.com/tdsmith/aRrgh/issues/18), and all of the other things that made [aRrgh](http://tim-smith.us/arrgh/) necessary.
Page is gone already? &gt;http://hacking-forums.net/topic/21/all-about-classes-in-python
Yes.
https://www.youtube.com/watch?v=w26x-z-BdWQ&amp;index=5&amp;list=LL3J8IkAFzJBIoctf9WqeKPQ The inventor -- or designer or maker I dont know -- of pandas gives a pandas intro presentation. Not as thorough as his actual book because you know, thats a book but it starts with assumption you known nothing of pandas
taking a look but cant create an account at this time. on confirmirming my password i get an invalid input error. That aside, it looks like you have a lot of redundant code which could be refactored (ie account creation checks to see if desired Username is taken, so does your password loop function) The password loop function takes one argument which looks like it should be set as a constant. Upon further use, ive noticed that what is actually happening is that the CONNECT function is actually finishing. the for loop in line 43 though is basically only running one time because of the RETURN statements. To sum up the logic on one runthrough, I want to create an account 'BMO'. The for loop gets passed, but it checks your user list exactly one time, if Cchoicedesiredusername == 'System', you are returning false (ending the connect function), but if Cchoicedesiredusername != 'System', it is creating an account regardless of duplicate users. I created 2 bmo's accidentally doing this.
in windows 8 find 'powershell' then type in 'cmd' then 'python' to boot up the idle GUI. if that doesnt work you will need to [set the PATH environmental variable.](http://stackoverflow.com/questions/21372637/installing-python-2-7-on-windows-8)
Or even better, use py.test's loop on fail: http://pytest.org/latest/xdist.html?highlight=looponfail#running-tests-in-looponfailing-mode (py.test can run flake8 too, so you'll get tests and static checks) This way it will first re-run only the failing tests (which is pretty helpful if your test suite takes too long), and if they pass run the whole suite.
One could also have a module called lion.py and put the function eat(lion, food) in. But eating is a better example. It the main goal is to modify the lion, it's not a side effect. 
cool idea. might i suggest using the actual youtube api though? you could then use v keys instead of chopping up the URL. does it work with embedded links?
[You posted this same link just hours ago](http://www.reddit.com/r/Python/comments/2qnwxl/all_about_classes_in_python/). Your website is completely broken and the "#.VKHHfb4WW7E.reddit" at the end of the URL seems to clearly indicate that this is more blogspam. Please stop.
did someone say [PEP8](http://pep8online.com/)?
This looks like a ridiculous and pointless waste of time and money. There are already so many great closed and FOSS python IDEs and developing gnome apps is already well supported in most foss ides that this seems like a pointless splintering of effort. Instead, they should make a plugin for IDEA and eclipse.
Also check for talks from SciPy conferences (the Youtube username is "Enthought" I think) and also check Vimeo where there are some older PyData videos. Keep in mind you will find both talks and longer tutorials. I think the older conferences are more likely to have introductory tutorials since by now it is assumed that most people at those conferences are already using those tools. But a few years back that was not the case. Sorry I can't give a specific link but I know I have seen some good tutorials over the years on YouTube and Vimeo. edit: maybe PyCon also
This environment variable thing is confusing me...but I'll look into it and try my best to figure it out. I'm also thinking about just getting a virtual box linux window, because someone else suggested it and if it makes things easier down the line than I think it's worth the download. Thanks for the help. 
True story, I'm constantly watching YouTube 'how to' videos made anywhere from 7 years ago to yesterday. Lots of gems and if it doesn't pick up right away, it's very possible it could at some point in the future.
I think that's great advice. The most important thing is to actually be able to learn the program in it's most fundamental form. Unfortunately, the lecture I just watched was about pulling up text (he wrote it in editor then saved it as a .py file) in the terminal window and I was unable to do it. I'm hoping that switching to linux might change that...? I don't know. Either way, I appreciate the help. 
this was great
When I do that I get a "python is not recognizable as an internal or external command, operable program or batch file" notification. I guess I need to set the path environmental variable then? There is, however, an application called IDLE (python GUI) that came with the download. When I open it, though, it says "Python 2.7.9 Shell" at the top. Is the "shell" the same thing? If so, it still does not work the same way that the Dowell instructor's "terminal" is working. Regardless, thanks for helping. 
Should I remove the return lines? I want to make it so some function require you to be logged in, but I suppose I could make a variable called loggedin? And set it to true on a successful login.
Don't do that. Use same db for tests and app. 
Scapy is not the same as Sc**r**apy. Scapy is a packet manipulator.
Okay, but you have a very different idea about what is readable than I do. I don't see how `username` is a weird variable name but `Cchoicedesiredusername` isn't. Rather than explaining the context of the variable within each variable name, why not let the code block itself be the context? To be more clear than what you are currently doing: if userloginchoice in {'Q','q'}: quit() if userloginchoice in {'L','l'}: username = raw_input("Enter your username:") log_user_in(username) if userloginchoice in {'C','c'}: username = raw_input("Please enter your desired username:") create_user(username) Also, stuff like this is unnecessary and I don't think makes anything more readable. Just more lines to read. numberofuserscatalog = len(users) if numberofuserscatalog == 1: 
get rid of the loops as I suggested in another comment.
Do it. Seriously. Do it. https://www.youtube.com/watch?v=JoqDYcCDOTg
I'll show myself the door...
I use conda, which doesn't work with virtualenv at all... Sufferings?
I use conda, which doesn't work with virtualenv at all... Sufferings?
Here's yet another take on it: master, nmls = [], ["bird", "cat", "dog", "cat", "bird", "cat", "dog", "bird", "horse", "horse", "dog", "cat", "horse", "dog", "horse"] for nml in set(nmls): indices, start = [], 0 for occurrence in range(nmls.count(nml)): indices.append(nmls.index(nml, start)) start = indices[-1] + 1 master.append(indices) print(master)
Your blog/site is awesome. I really appreciate you taking the time to create these write-ups. You really have an amazing ability to explain things simply and clearly. Much thanks indeed!
I used to need to reinstall my OS regularly until I started following a strict rule: nothing touches the root system except the distribution's package manager. If I need an environment for a project I keep it entirely contained within the folder for that project. Virtualenvs are pretty key for this with python projects. Since then I've had far less headaches when dealing with installing libraries. Otherwise you wind up with conflicting versions, partially uninstalled packages, causing a world of pain.
Use anything 3.3+. It really doesn't matter which version you use (as long as it's a stable version) when you start out but Python 3+ is gaining traction so just jump into it now. 
If you're coming from R Studio, definitely give IPython Notebook a shot.
I used to think that way, until I had so many projects going at once. Then, when it comes time to package things, or call out package dependencies, you're really wishing you had started out smarter.
I've been doing it for 8+ years at work. I've had a lot of practice. I reinstall/upgrade Python and various Python packages every so often. You learn how to clean out sitepackages. I deal with 10 projects at any given time. They use standard versions. If you don't have the packages right, the buildbot won't build your code, so it's really not bad.
Thanks that was very informative. I got a book called "learning python the hard way" and it if for 2.7 so if there is no huge benifit to 3.(some numbers) then I will start in 2.7. Thanks again for the speedy reply. 
What are the benefits of 3+ to a complete beginer? Thanks for the fast reply as well 
I'd watch/read it if you throw in a few jokes or puns
What about for deploys? How do you keep track of which packages to install or update when you deploy something? Do you always use the same packages for every project? 
There really is no real benefit. There aren't that many differences you'll notice as a beginner if you use 3.3+. I saw that in your other comment you wanted to check out learn python the hard way. You could honestly get through it with 3.3+. The only really difference would probably be the print function
A little off topic but is there a difference between the mdfind / find / locate command in bash when it comes to cron jobs? In my original script I used mdfind? Also the dialog between you and Samus_ has been awesome and a lot of help! This is pure project but finding out that it will still be slow has bummed me out a little but I came out knowing much more. 
Just to clarify you're saying that what Teract and Samus_ are discussing is wrong? the find module that is apart of the OS is not indexing and keeping tabs? From what I have experienced python seems to be taking much longer and that seems like the likely explanation. I apologize in advance if this is not what you're referencing to. Thanks for the input! 
&gt; How do you keep track of which packages to install or update when you deploy something? We use pyInstaller and NSIS to build an executable and an installer. We keep track of it, by setting the versions in the setup.py file. Our customers do not install Python. &gt; Do you always use the same packages for every project? We do a mass Python upgrade every 6 months or so. We use the same packages for every project unless there's a good reason to not (which is incredibly rare and typically caused by a project that is due in two weeks and upgrading causes a headache). EDIT: We also have a egg server to have all versions of various packages precompiled, so in 10 years if we want to get version x of package y that we used on software z, we have it. It makes upgrading really easy as well. On my open source project, I don't care about versions either. That's what bug testers, I mean users, are for :) People complain loudly if it doesn't work, so any errors don't last long. It's not like I'm going to test on 5 versions of Python with all combinations of 3 major releases of each package, so I don't even bother trying. There's a recommended version and what's allowed.
I've been looking at those modules. The idea is to index the whole computer to find "mysterious" file. Move that file to a folder on the desktop and that is the end of the script. I have a command that works but it is brutally slow. Your information has been awesome though. I really appreciate it and have learned a lot from the challenges you are throwing my way 
Oh yes. I have all of the necessary imports at the beginning. The script works if I run it manually.
LPTHW is a great book. 2.7 is fine. You don't have to learn 3.3+ now.
I would use virtualenv, You can also look into eggs and importing the eggs from relative pathing for certain projects
They're discussing an entirely different approach, where you don't crawl the dirs to find the file, but use an index that's done all this already (and regularly rescans to keep up to date). This isn't actually part of the "find module of the OS", but basically a seperate program that does all this work in advance of when you need it. Think of it as if you changed your program to, instead of move the files, instead write out the path of every single file to a file. This will be just as slow to implement, but once you've done it once, you can find the file just by reading that file and finding the right line, which would be much quicker. Indeed, you can store it in a better data format to be even quicker again. This breaks down once people start adding new files, because your index gets out of date, so you need to regularly rescan and/or have a daemon that monitors all filesystem operations with something like inotify. Or, you could use something like locate which is doing all that already. That can indeed be faster (at least at the time you're locating the file), simply because it's already done the hard work. The problem is that you'll need to actually have it present - for instance, you won't be able to use locate on windows (though you might be able to try to take advantage of windows indexing, though that only covers certain directories by default). It also really makes your program irrelevant too - why bother writing it if it relies on locate, when you could replace it by typing "mv `locate testtesttest` /path/to/folder`. 
There's no reason not to.
What if you are using docker? That seems redundant to have another layer of virtualization.
Aren't decorators explained in the Python docs?
Could something the PATH be different? That's often a common culprit when seeing different behaviour in launching scripts via a boot script vs running in a fullly setup environment. Are you giving the full path for your executable in the system call? When you say it doesn't run, are you getting a failure code back from os.system, or is it returning success but silently doing nothing? It'd also likely be worth capturing and logging the output in case it is actually running, but failing for some reason that an error message might be telling you. Changing your code to use subprocess.Popen and redirecting stdout / stderr to some file that you can check after the fact might be useful.
With arch however, everything is so new and the packaging so easy that I find myself installing all Python packages globally via pacman.
How does it compare to [mockito_python](https://code.google.com/p/mockito-python/) ? 
I would be interested... Can you add it here once you do?
Logging + subprocess to collect output. For all you know, your Perl scripts can't be launched, etc,.
I found where the database is stored: I man paged the locate.updatedb which is the equivalent to updatedb in linux. "The locate.updatedb utility updates the database used by locate(1). It is typically run once a week by the /System/Library/LaunchDaemons/com.apple.locate.plist job. The contents of the newly built database can be controlled by the /etc/locate.rc file." So it appears that the var/db/locate.database has the goods. Anything I can do with this? 
hey, just to clarify, I meant scrapy (the scraping/crawling framework) not scapy (packet analysis)
You're a special case, for now. But you risk breaking your host (perhaps in a subtle and hard to diagnose way). And you also lose the ability to easily try out different versions of a dependent library, or run multiple versions of the same software on the same host. Others don't have that luxury, want to install newer versions of some dependency than their os was tested with, and/or simply want development flexibility. Seriously, use virtualenv. Once you've spent a little time with it you'll wish you started using it years ago. 
No, for several reasons: * You may want versions of dependencies that are incapable with the OS, or other applications running within the OS. * You may want to test &amp; try out multiple versions quickly and easily. Say, testing all permutations of every major version of several different dependent libraries via Tox. * You may want to try out different dependencies quickly and easily, perhaps comparing them in benchmarks, perhaps running software concurrently, with the intent to throw most of them away. In all these cases virtualenv helps you out even if you already are using Docker.
Yes, but [this is what I see](https://docs.python.org/2/glossary.html#term-decorator). That doesn't explain much, but it really shouldn't need to. Decorators are a general functional programming construct that exist in a lot of other places and aren't Python specific at all. It's nice to see a good article explaining it using one of the best written Python modules. Those without a CS degree aren't likely to learn them from messing around. Flask is a great module to learn from as well.
My game Electropocalypse is in the App Store. It was written in Python with Kivy. https://itunes.apple.com/us/app/electro-pocalypse-chapter-1/id795867884?mt=8
I wouldn't bother with virtualenv inside of docker but there's not real harm. virtualenv isn't virtualization so you're not adding any overhead. 
&gt; When I do that I get a "python is not recognizable as an internal or external command, operable program or batch file" notification. I guess I need to set the path environmental variable then? ya this means that python path variable is not set correctly. make sure you also close your CMD/Powershell terminal if you have it open when setting the variable as well. This has caused problems for me in the past.
Why point out that osx is Unix cert and Linux isn't? That's a pointless distinction. Linux actually properly implements posix calls. I don't understand how providing posix calls that always return failure allows osx to be certified. 
Really I would also like to say thanks, I've been using python for about 2 years now but only recently have I started to understand how things work in it and this article was amazing in helping me understand how Flask works. Now I'm trying to read through Flask code to understand how things work, even better.
http://pandas.pydata.org/pandas-docs/dev/generated/pandas.pivot_table.html#pandas.pivot_table http://pandas.pydata.org/pandas-docs/dev/search.html?q=pivot_table
I actually use miniconda, but I haven't had a single problem with Anaconda (just found updating packages to be easier with miniconda as there are less potential conflicts). I know conda has its own environment manager that I suppose is supposed to replace virtualenv ...but I suppose I haven't gotten to the point that I need to run it yet...
 With this command, the pip in ``bin/pip`` installs into a conda env, just like virtualenv: ``conda create --mkdir --prefix "$WORKON_HOME/envname" --yes python readline pip`` Instead of `python`, `python3` should also work.
I feel like I've been hearing the "Python 2 will be gone soon" argument for years now and it still hasn't happened. I personally would start with 2 and maybe switch later down the road. For learning it really isn't a big deal. If you really get into it then look into porting from Py2 to Py3. 
So, semi-serious question: What are people curious about? I've done a bunch of silly/interesting/linguistically intriguing things with python, from the C level upwards,and I can probably write something about many topics. What would people (/r/python, elsewhere, etc) be interested in?
do you have a github or somewhere I can browse some of your code. Surely I'll find something I'd like to know about from an expert.
This is pretty cool. Can be a pretty useful teaching tool too. However, I might never use it. Since I started using WingIDE, I almost always use its debugger, which is amazing. No really... it truly is amazing and you will not be able to go back to print based debugging.
PATH is a list of directories the console will search for programs to run. (including the current directory) So if python2 is installed at `/foo/bar/` **and** you have that directory your path, you can simply type `python` to run python2. Did you delete your PATH variable, or append to it?
Besides your problem, you should use the **getpass** module, for asking the users password.
Personally, I prefer conda environments to virtualenvs. Conda envs are like virtualenvs, but also include custom versions of python and not just it's libraries. Thus you can have one env running python 3.4, and another running 2.7. Additionally, identical versions of python or libs are simply symlinked to each env instead of copied. This can really save memory since you'll only have to install Numpy once even if you use it in several envs. 
The fact that the difference in most cases is so trivial makes this a great evidence / lesson of how little you can gain by doing micro optimization. Though it does show that modern high level languages do optimize their idiomatic code style, which is essentially free performance gain if you write idiomatic code. After all, writing code that describes what you want to achieve is the most important thing in coding. There are something you really should avoid doing: &gt;&gt;&gt; x = 99999999 &gt;&gt;&gt; y = 99999999 &gt;&gt;&gt; x is y False &gt;&gt;&gt; a = 1 &gt;&gt;&gt; b = 1 &gt;&gt;&gt; a is b True This just goes back to the last point I made. And there are some unfair comparisons, e.g. Test #15 I did some timeit myself: &gt;&gt;&gt; def a(): s = 0 for i in range(50000): s += 1 return s &gt;&gt;&gt; def b(): return sum(i for i in range(50000)) &gt;&gt;&gt; def c(): return sum(range(50000)) &gt;&gt;&gt; from timeit import timeit &gt;&gt;&gt; &gt;&gt;&gt; timeit(a, number=100) 0.3279228246736736 &gt;&gt;&gt; timeit(b, number=100) 0.3867327149317248 &gt;&gt;&gt; timeit(c, number=100) 0.13026088846984152 Test #15 compares a() and b() and makes sum() look bad, but really it's the implementation's fault. Test #16 is so misleading. You should never do [i for i in range(1000)] Instead, just range(1000) in python2, list(range(1000)) in python3 &gt;&gt;&gt; def a(): return [i for i in range(50000)] &gt;&gt;&gt; def b(): return list(range(50000)) &gt;&gt;&gt; timeit(a, number=100) 0.2375680143019565 &gt;&gt;&gt; timeit(b, number=100) 0.13630618950557505 **Write code that says what you mean. Write code that is idiomatic in the language you use.**
You can use learn python the hard way with python 3, you really just need to replace in 99% of instances (there may be a couple of tiny instances which are different). print 'whatever' with print('whatever') That said LPTHW may not teach you the best way of of using python 3, a few things have changed though are still backwards compatible. The issue with 3 vs 2 is that 3 very much represents the future of the language while python 2 represents the past. 2 Will not be supported past (2020??). 3 was written because python 2 had some fundamental flaws which were not easily fixed by patching and would break a lot of peoples code if they were patched. By learning 3 you (pretty much) guarantee what you learn will always be relevant and up to date. The disadvantage is a few (very few) libraries havent been ported to 3, if you haven't got any particular projects in mind though that most likely will never bother you. 
Thanks I think I will start in 3 as that seems the better option. I didn't expect all these reply's.
I had the same rule, however I had to make an exception for bpython.
luckily i only encountered this three times. in one case my patch was accepted and in two cases the devs quickly responded and fixed it. the latest case is [this one](https://github.com/scikit-image/scikit-image/issues/1316), thanks for reminding me. what i’m getting at: if this is the case, then it’s a bug and needs to be fixed.
Hey man if it works for then that's great. The only reason I am sticking to virtualenv is because I am relatively new and this is what everyone recommends. I definitely intend to contribute more to open source, but in order to do that I feel like I've still got a lot to learn. It's awesome that you send patches to the upstream (if that's the right phrase) but I'm still not there yet as a programmer. 
I believe you can set your python version via virtualenv as well.
Am I the only one who's surprised that Python doesn't optimize? Specifically in test #3, it builds a tuple, unpacks it, and rebuilds a new tuple, instead of just seeing that it should just be building the tuple (9,8,7,6,5,4,3,2,1,0) ?
Hi Veedrac, I agree that it's not entirely pointless to do micro optimization, and I've had similar experience optimizing some code written by someone else and achieved similar factors (10-30x). Most of the time the micro optimization we do is to make the code more idiomatic, or to some extent, more correct. My point being, once one has enough experience to use the right tools (libraries or patterns) to implement stuff correctly, idiomatically (not necessarily), there really isn't much more we can do to optimize without completely rewrite the code. Maybe I've been too harsh in terms of what good / correct code is like. Thanks for sharing the link! Love how you mark the changes step by step and how you like to push to the limit.
I don't get it. If you insist on print debugging, What's wrong with using the built-in logging library?
I can also vouch for the python standard pdb which is essentially gdb for python. All you have to do is import pdb, and use pdb.set_trace() to set a break point. From there you can "p" (print) variables, and run commands and either "s" (step) or "n" (next) etc.
yup, upstream means “everyone sitting nearer at the source than you”. if you’re a arch user who uses official arch packages of a project that is developed on github, upstream means either arch (if it’s a problem with packaging or a patch that arch adds) or the github project (elsewise). and about patching: it’s really easy in some cases (such as the one i linked). i don’t need to understand that project’s architecture to make that patch. i simply have a setup that https://github.com/blink1073 doesn’t have, so i tried his patch and modified it until it worked for me. then i thought about how to minimize the impact of my changes and came up with [this](https://github.com/flying-sheep/scikit-image/commit/2c2ff5acb1d7142c4e5eb34a5f8809bd050de38b). now it’s his turn to criticize my patch and tell me his opinion on how it can be improved, or to apply it if it works and is OK.
Python is notorious for not doing any static optimizations. Examples of others that aren't done: constant folding (e.g. 1+1 -&gt; 2), tail recursion, dead code (e.g. removing code inside if 0)
MySQL's issues are with correctness not performance. Assuming Aurora is MySQL compatible, it will mangle your data. Besides, Django has excellent PostgreSQL support, and the Amazon stuff you mention has swappable engines.
I like the comment above mine, but likewise, I appreciate the words in between his code samples. I'm no Python expert, so the original link doesn't provide much context to understand the optimizations - why does this make my code run faster? What are the downsides to these optimizations? Great effort in providing so many examples, but I think the title should be "Tricks to make your code faster, albeit you may not understand why and there may be unexpected consequences"
&gt; Write code that is idiomatic in the language you use. No thanks, I'd rather write code for my audience. Which means: * If they're experienced python developers that means idiomatic code. * If they're not experienced python developers, then I'll write code that looks as closer to pseudo-code or is otherwise language-neutral in appearance.
Try running these in numba. :)
Seconding this. Scrapy was the first thing I did in python that wasn't like 5 lines of code and I just worked through the official tutorial and came out the other end with everything working. All the roadblocks I ran in to were a lack of understanding of python/programming rather than issues in documentation of scrapy.
More importantly, how does it compare to Mock? It's the most fully-featured mocking framework I've used and it was mainlined in Python 3.3. http://www.voidspace.org.uk/python/mock/ https://docs.python.org/3/library/unittest.mock.html
Yes, I currently use Django with PostgreSQL (which I love). But the new stuff that Amazon is doing with Aurora sounds really cool. The fact that it was based on MySQL gave me concern. 
The worst part about this page is the fact that all of these cases are given with no explination. The reader is not given: - Context to what each case is trying to do. - A description of how the implementations differ. - A description of the disassembled bytecode. (Some times the slower implmentation has fewer lines. Unless you know what the instructions are, seeing more lines makes you think it would be slower.) Without all this information, people that don't know what they are doing will just look for the smallest number and start using that method. They won't understand that one implementation has a side effect and one doesn't. They won't understand that one implementation will only work for certian values.
I appended it. Is there any way to set a new path? Thank you for your help! 
&gt; If they're not experienced python developers, then I'll write code that looks as closer to pseudo-code or is otherwise language-neutral in appearance. The only situation I can think of where this is appropriate is when you're writing throw away code, maybe for a talk you're giving. In normal situations, you're just demonstrating, as the more experienced programmer in that language, that the anti-pattern you're doing is the correct way. Now your code and theirs is littered with bad code. Write good code, always.
I almost feel that he should just list cases where the speed up as at least twice as fast if not 3 to 5 times as fast, and order them by the degree of improvement so that any ones where it's 100 times faster are first in that list. Frustrating to scroll through many examples where the performance gain is a few %.
That's a good point, but I disagree: sometimes code clarity &amp; correctness trumps everything else. If your audience are not python developers, then give them a classic for loop rather than a list expression even when the list expression is simpler. Or be prepared to spend a lot more time on documentation and explanations.
you can set it, but you can't install it. Conda takes care of installing not just packages, but environment-specific Pythons as well.
Consider the third party requests lib over urllib2 for sanity sake.
Huh. Is there some rationale for this? I get it, if it harms correctness (hard to make any correct assumptions in a dynamic language where even a+b might cause any number of side effects), or if it makes things less predictable, but it seems like a no-brainer to handle some low-hanging fruit. I've been using numba lately to speed up performance-critical Python code, and I get tickled pink looking at the LLVM output. The LLVM optimizers work wonders.
I learn more via [Cunningham's Law](http://meta.wikimedia.org/wiki/Cunningham%27s_Law) than any other method... Seriously though, jesus, how do people find out about these axioms of python? it's killing me! every time I learn something new, I find out there's a better way of doing it and I'm a fool for having thought otherwise. I am left with the disturbing feeling that I am *never* doing anything right.
It is not recommended because it can change from version to version, hence not documented, but it can be looked up in the source if you're really into such kind of optimization. From what I can recall, currently in Cpython integers from -5 to 256, empty strings and tuples, and one character strings are interned. You can try this a = -3 assert a is -3 b = -6 assert b is -6 # Fails c = 256 assert c is 256 You can also do this manually using `intern` in python2 or `sys.intern` in python3
Okay, here's an overview of how (I think) the werkzeug package initialization works: The package is composed of many modules, and within the modules there are A LOT of different functions and classes that can (and will need to) be used. Naturally, you can import these functions and classes directly from the modules where they reside, but given the sheer size of this package having to figure out and remember which modules include which functions and classes would be a major pain-in-the-ass. "Okay," I thought, "so why not just import EVERYTHING at initialization?" This actually IS a solution -- the only downside is that then you're importing EVERYTHING, which will slow down initialization and add unnecessary bulkiness to your program. So you want to be able to access each module's functions and classes directly from werkzeug ("from werkzeug import *") -- but you don't want slow initialization times and to add more weight than needed. How can this be accomplished? The answer is [lazy loading](http://en.wikipedia.org/wiki/Lazy_loading). Lazy loading basically means you don't load a module or object until you need it. Essentially all of the "magic" involved in the \_\_init\_\_.py file revolves around supporting this lazy loading.* I can't go into the nitty-gritty details right now of how this is done (both for time/space considerations and because I'm learning how methods like \_\_getattr\_\_() and \_\_dir\_\_() work), but with this understanding of the "what" and the "why" it's relatively straightforward to then look at the code and roughly understand how it's implemented. The authors of werkzeug included a brief description of everything I just discussed as a comment in the file (gotta love those guys), my main problem was I didn't know lazy loading was a thing! Plus some of the wording wasn't totally clear to me, but that's much more my fault than theirs. Feel free to ask any questions! That said, looking at your comment below it seems like we're roughly at the same level; let's keep on keepin' on. *Edit: re-read and to expand, the "magic" supports both lazy loading, and the ability to import objects directly (and lazily) from werkzeug (ex: from werkzeug import whatever)
Much obliged! I actually did pop in there and the #python channels the other night and got some help, too cool!
Honestly, I don't believe *pypy* can be viewed as a "micro-optimization". Certainly JIT compiling uses catalogs of "micro-optimizations" (as it it optimizes small interactions), but it does so on the scale of every interaction/operation performed (i,e. millions) and thus is unfitting of the term in the sense meant here. Normally instead these types of optimizations are considered runtime or compile time optimizations (like JIT, which is considered runtime). *numpy* itself is a library which has many baked in non-micro-optimizations. So you are optimizing on that level instead. So in a sense "micro-optimizations" are being performed via libraries used. But you are not micro-optimizing yourself. So I don't think anyone really considers them micro-optimizations in the colloquial sense of the word. &gt; To be fair, that's because these micro-optimizations suck The point I was trying to make is: most, if not all, micro-optimizations suck when performed on the single level. It is only when you do them by the millions that they become "macro-optimizations" (like *pypy*).
Yea I could but grabbing the url could be done without reading youtube api docs. I am merging another script I wrote which finds and embeds lyrics automatically on your song. You can find it here : https://github.com/yask123/Auto-MP3-Lyrics-Tagger
&gt; it's not cool to expose blatantly inefficient functionality Sure, inserting values at arbitrary points in a list is marginally more expensive than appending them (O(n) for insert() as opposed to O(1) for append). I highly doubt that there will very often be the combination of large numbers of keys and frequent (re)insertions that will make O(n) become problematic. &gt; without warning That, I can fix. I had forgotten about this performance characteristic of list insertions and I will make a note of it in the documentation. &gt; in fact while making it seem that it's supposed to be efficient. Nothing anywhere claims "efficiency". This isn't a micro-optimized data structure. It's a structure for letting the developer create an ordered mapping of keys and values. As for the use case, I really can't recall! Some of them were using Django form objects, others simply wanted predictable output. You've asked technically valid questions but in the end they are all focused around performance and if you're sweating THAT much about shuffling some members of a list around a few times Python probably wasn't a good choice to begin with. Also, I'd gladly accept a pull request where the order-preserving structure is changed to a linked list or something else to reduce the cost of reordering keys.
Unfortunately, this kind of focus on idioms had made Python a less accessible language for those who need a tool, but are not full-time programmers. The learning curve has gotten steeper, in I believe an effort to attract language-geeks. This isn't to say that these features aren't great, but to insist that everyone uses them regardless of their audience fails to appreciate that everyone isn't a full-time python developer. EDIT: for example, I built a huge data warehouse that used Python for transforming all the data coming into it. This worked great. One of the things we attempted to do is to keep the implementation of the business rules simple so that anyone that needed to know how they worked could just simply look at the code. And they didn't have to be a python programmer to understand most business rules, and they didn't have to be a senior python developer to build most integration. Our more internal libraries were more sophisticated, and not as newbie-oriented. This approach worked very well for us - since our users weren't very fluent in python, and most of our developers at that time were wearing multiple hats, none of which was full-time python developer. Had we insisted on idiomatic python that would have delayed getting people up-to-speed - which would frankly have killed us. And our users wouldn't have been able to read the code, so we would have had to spend an enormous amount of time on documentation instead.
Cchoicedesired username isn't about how weird it is, it's about how specific it is. I'm not asking for organization help, I'm just asking why you think it's not working. The len part isn't necessary, but it always bothers me when other people's text says something like "You have 1 bananas."
I'm curious exactly how Python module loading (and referencing) works. Here's a question (well, actually two): Let's say I run the following in the shell: import sys sys.modules Up will pop a dictionary of modules. For each entry the dictionary key is the module name, and the value is either "None" or a module object. The questions are: * Does the Python interpreter use this dictionary to see where loaded modules are stored in memory? and * Why do some of these entries have a value of None? **EDIT: found [the answer to question 1](http://stackoverflow.com/questions/10501724/how-does-python-importing-exactly-work), still not sure about question 2** **ANOTHER EDIT: [annnnnnnd we're done here folks](http://stackoverflow.com/questions/1958417/why-are-there-dummy-modules-in-sys-modules). Sorry to bother you!**
&gt; Write code that says what you mean. Write code that is idiomatic in the language you use. Exactly. Don't say. if x when what you mean is if x is True vs. if x is not None 
&gt; You've asked technically valid questions but in the end they are all focused around performance and if you're sweating THAT much about shuffling some members of a list around a few times Python probably wasn't a good choice to begin with. There's a difference between taking a 10-100x performance hit for using Python and taking a 10000x performance hit for stuffing stuff into the beginning of a list of 10000 elements because you're using a wrong algorithm. This is not what "microoptimization" means, it's very much a macro-optimization. What's worse, the latter tends to creep up on you, everything works fine when you test the code or just deployed it, but then data accumulates and everything gradually slows to a crawl. And usually even a profiler wouldn't help you, people who write code with this lax attitude, "this is Python, I don't care about performance" (or it's twin sister, "this is C, I'll have enough performance anyway"), tend to write _all_ of it inefficiently, and it _all_ becomes a bottleneck, not just some single hot loop. This is like basic programming hygiene, along with "don't pass stuff via global variables", "give functions meaningful names" and so on. Always spend a moment to consider if you're not using an asymptotically abysmal algorithm. If you're always doing this stuff then it becomes a second nature and you become a good programmer, if you're not sweating it over shuffling a few elements then it doesn't and you remain a shitty coder. I mean, sometimes it's acceptable to write suboptimal code (and in fact for small datasets using simple lists (arrays) usually is more efficient than any fancy trees or whatever), but it should be an informed decision, not something you do because you don't bother to think about it. And definitely not something hidden besides an abstraction that encourages this sort of sloppy coding. And we, as a community, especially shouldn't encourage newbs to be sloppy like that. Do you like PHP? Because that's how you get PHP. &gt; Also, I'd gladly accept a pull request where the order-preserving structure is changed to a linked list or something else to reduce the cost of reordering keys. Unfortunately without anything resembling a single use case it's impossible to decide on a proper data structure for that. If you want to have a dictionary that you can iterate in a sorted order, there's a lot of already implemented solutions. If you want something else, well, you need to know what it is (and for instance how are you supposed to decide where to insert an element). By the way, at the very least you can derive from OrderedDict and add reordering methods that work with its own ordering info.
 x = 99999999 y = 99999999 x is y False a = 1 b = 1 a is b True ...would anyone care to explain (or link me to an explaination) of why this is the case? thanks for your time.
I've taken your comments into consideration. I'll think really hard about how I can handle the awful worst-case performance.
x is y is not the same as x == y.
IIRC, python caches small ints, so if you assign a = 1 and b =1 then a &amp; b will refer to the same instance of int. Large ints are not cached.
I would start by writing it similarly to how you would in perl. The languages are similar enough that you shouldn't have much trouble getting a working solution. Then go refactor it with a linter. Then post it on here or other forums asking for code reviews, which will help you write more idiomatic python.
Opencv would be the way to go. This article should help with detecting circles and computer vision in general. http://www.pyimagesearch.com/2014/07/21/detecting-circles-images-using-opencv-hough-circles/ 
Thanks, I'll check it out! Everyone has their own preferred way of debugging, and this tool isn't meant to be a separate work flow, but just act as a supplement for those who already use printing as their primary method of debugging (which, based on personal experience, is a majority of python programmers). 
thanks, I hadn't come across this article, will get looking into it right away!
Definitely some cool ideas in there that I hadn't thought of, thanks for sharing! 
This is interesting but let's not forget the proper way to optimization: optimize what needs optimizing 1. Get it right. 2. Test it's right. 3. Profile if slow. 4. Optimize. 5. Repeat from 2.
I wasn't including PyPy's numbers in that; the 20x speed improvement was from straight CPython.
Similar to #1 is to use a mixin. https://stackoverflow.com/questions/533631/what-is-a-mixin-and-why-are-they-useful This isn't necessarily a _good_ option, though. Multiple inheritance can make things unnecessarily complex.
`intern` only works on strings.
Why does it *have* to be a method? Does it use some state from the class(es)? The first abstraction option one should always go for is just a standalone function. Only if a standalone function wouldn't do for some reason, one should look for alternatives. I'd beware of inheritance unless there's a clear is-a relationship between the classes in question.
Exactly! &gt; Without all this information, people that don't know what they are doing will just look for the smallest number and start using that method And they won't know if/when/where the technique will *fail* to improve performance. Take this example #faster #slower d = {} d = dict() The left version creates a `dict`, assigns to a local `d`. The second one looks up the variable `dict`, finds it may (or may not!) refer to the constructor for `dict`, then invokes the constructor, finally assigning the result to 'd'. Using `{}`bypasses the variable lookup. An optimizing Python compiler or JIT might discover that `dict` is never assigned to, so could potentially compile the second example using the same technique of the first example, so it's worth reconsidering the technique if/when you change Python compilers -- e.g. PyPy. 
&gt; Huh. Is there some rationale for this? In the case of tail call optimization, Guido has stated in the past that he considers the stack "fore-traces" (sometimes mistakenly called "back-traces") a diagnostic aid. It's probably for the best, as he has freely admitted that he doesn't really understand recursion that well, preferring iteration where applicable.
&gt; But wouldn't these tenths and hundredths of second add up to some significant time if they were being called inside nested loops Yes, but if you care about that level of performance, you should probably switch to a faster implementation that will give you more of a performance boost that "weird coding tricks" will get you. That said, if you're stuck with CPython for whatever reason, use these tricks sparingly, only when absolutely necessary.
My apologies for leaving out the gory details. Yes, the helper needs to access state in the class instances. &gt; I'd beware of inheritance unless there's a clear is-a relationship between the classes in question. I agree that it's a contrived is-a relationship (MyClass-is-a-Helper) rather than something more natural (Circle-is-a-Shape), but the benefit is what the is-a relationship buys me: code reuse in the subclass without having to implement any code in the subclass.
This- unless the behavior of the method depends on private state in the classes, it should just be a function. If it needs information about the state of the instance, then the instance should just be a parameter. In the case where the method depends on the private state of the instances, if there isn't a true "is-a" relationship, I would probably use a decorator to inject a function. I'm sure that isn't sufficiently "pythonic", but I've found decorators to be a great way to inject certain design patterns without touching the core implementation of an object. For example, [the observer pattern](https://gist.github.com/RemyPorter/784cab94a29508bcec5c).
&gt; I'm no Python expert, so the original link doesn't provide much context to understand the optimizations - why does this make my code run faster? What are the downsides to these optimizations? I provided [one example here](http://www.reddit.com/r/Python/comments/2qszpn/python_tricks_for_your_code_run_faster/cn9pvmo), and [another user](http://www.reddit.com/r/Python/comments/2qszpn/python_tricks_for_your_code_run_faster/cn9hv4u) explained int interning. Let me try to summarize the first dozen: - `d={}` vs `d=dict()` -- the second spends extra work looking up the variable `dict`, which users can overwrite (e.g. `dict=list`) while the first does not. - `l.sort()` vs `l=sorted(l)` -- The second creates a copy of the list first. - `a, b, ... = 0, 1, ...` vs `a=0; b=1;...` -- the first uses 'unpack_sequence' to load a whole boatload of constants in one opcode, while the second has to dispatch multiple op codes, saving on instruction decode time. - `a &lt; b and b &lt; c...` vs `a &lt; b &lt; c...` -- same as above; fewer instructions means less decode time (4 per additional compare, vs. 5 per additional compare) - Test 5 `if a:` -- first has fewer instructions, making it faster. Second vs Third though is very close, but the `is` operator is a cheaper instruction than `==`, making it faster. See [is operator](http://stackoverflow.com/questions/13650293/understanding-pythons-is-operator). - Test 6 `!=` -- the second and third differ just due to measurement error; it's the same exact bytecode! As for first vs. second, I'm guessing that the fast path in `!=` must be slightly cheaper than the fast path in `is not`. Change `a=2` and the first will lose again due to the additional complexity in the `!=` operator. - Test 7 -- first and second, slight variations in branching. Third and fouth have more opcodes, so more dispatch costs (and using more expensive operators to boot!). - Test 8 -- minor variations in branching and/or number of opcodes. - Test 9 -- more opcodes/indirection - Test 10 -- not sure about this one; depends too much on how `str.join` is implemented. - `%s` vs `str` vs `%d` -- the second does an extra variable lookup (`str`) vs. native opcode `%` in first. Third probably pays for extra input validation. - `len` vs `__len__` -- I'm guessing this is just due to attribute lookup being more complicated than global variable lookup. 
I'm crossing my fingers until the "--target-windows" flag starts working. It's great for creating executable on Ubuntu, but I still haven't been able to create an executable that works on windows. In the 0.38 build it said: &gt; There is now a --windows-target option that attempts a cross-platform build on Linux to Windows executable. This is using "MingGW-cross-env" cross compilation tool chain. It's not yet working fully correctly due to the DLL hell problem with the C runtime. I hope to get this right in subsequent releases. But I still get this error: &gt; nuitka: error: no such option: --windows-target 
Are you the originator of the content in the link? Because it's just a page full of code examples and time comparisons...that's what I'm getting at. Not to be irksome - but was it your intent that users read the page, and then if they have a question about say, Test 14, they should scan the comments until they find your comment about that, if in fact someone has inquired about it? Why not just put the comments in the webpage in the first place?
Actually, I planned to start off the new year with completely dumping my bad habit of print-debugging... now, you come along with this nice library ;) `pdb` is probably the gold standard, but I still like your module a lot, it has a couple of really nice and convenient features!
As someone who was reading your code to see what was happening, I decided to comment on the style which made it difficult to read as well. Looking at a bunch of variables with long, similar names made it a little tougher. Also, using `if username in users` is more readable/pythonic than for user in users: if user == username: And using this convention would also solve your problem
No problem. Are you working on anything in particular or just trying to identify circles? If you are looking to find a moving ball, or know the circle object will be the same color you can use different methods. 
You may want to look at [moviepy](https://github.com/Zulko/moviepy) by [/u/laMarm0tte](http://www.reddit.com/user/laMarm0tte). It shall pretty much address the things you would like to do.
Looks like mdfind is mac OS X specific and uses the searchlight tool rather than find. I'm not 100% sure, but given the speeds at which searchlight returns results, I'd be willing to bet it's a mix of locate and find.
&gt; Are you the originator of the content in the link? Because it's just a page full of code examples and time comparisons...that's what I'm getting at I'm not the originator, and I agree with you. I was just trying to fill in the gaps left by the OP. 
AFAIR it is only faster than Pandas, which isn't built for speed and imitates R's data.table/frame. On any generic benchmark, Python beats R in nearly ever task, particularly if String processing is involved. Lastly, all that depends on which Python we're talking about. PyPy probably just blows R out of the water... Still, I think, if you are doing anything with statistics, R is far more appropriate for the task due to CRAN.
https://www.mysliderule.com/workshops/data-science There's a data science workshop coming up with a company I used to consult for-- they're really awesome. First, they match you with a mentor who is a data science professional, so you can have one-on-one conversations. Then, they have a professional data scientist curate a course sequence to teach you the "need-to-know" data science most effectively. They're also into project-based learning, so you'll probably have projects. I really like their product because they pull content from all over the web, so you're not confined by any one platform. Also, it's pay-by-month, so if you're a fast learner, it's an even better deal. Certainly cheaper and better quality than many options out there.
Thanks for the suggestions everyone. I found the problem. It wasn't that I needed to switch to popen or move away from os.system. Os.system was doing it's job, however, I wasn't giving it the full path to the file. I forgot that when the first python script runs it runs from where it's located and not where the perl script is located. My code looked like this: cmd10 = "/usr/bin/perl test.pl" os.system(cmd10) I needed to change it to look similar to this: cmd10 = "/usr/bin/perl /path/tofile/test.pl" os.system(cmd10) Once I made this change, it all worked. Thanks for the help. 
* http://paddy3118.blogspot.co.uk/2014/07/unique-numbers-in-multiplication-tables.html 
This worked for me but only on the basis that I had Xcode download beforehand. There was something in that which allow it to work, I am pretty new to this though I don't what it was exactly but yeah. 
I have not tried it. The code looks very well organized. Any negative criticism I would have to give at this point would be very minor. 1. you do not follow PEP 8 for imports, but do the reverse (recommended way: import modules from standard library first) ... however, I like your formatting for the imports (especially in render.py); 2. You defined a class Trigger which does not seem to be used for anything. Well done.
This is the correct answer honestly. 
I don't know what this says about me, but this might be the project I'm most proud of this year: https://github.com/eakmeister/python-invert In essence: mystring = 'Hello World!' add_inverts(mystring) print(ƃuᴉɹʇsʎɯ) # Prints '¡plɹoM ollǝH' Judge away.
If you need to optimize to this level you shouldn't be using python.
Well, sure - perhaps generally in their case. But slots are a general solution that have a use outside of caching, or where adding memcache to the environment would not be easy.
Python is the same speed as Robert but to be fair data takes would beat it BUT Python and Ruby are like a Toyota racing a Honda. If you need speed you have to change languages. Though the data.table is incredibly fast.
Could you suggest a good introduction for virtualenv specifically?
So, the code itself should be fairly easy to grasp - it gives you an idea both of how to *use* `dispatchmethod`, as well as how it *works*. What I'm going to give you is the motivation for my writing this. I'm currently hacking together a small network server for a simple message-based protocol. I've done this before, and I typically end up with something like the following in my code: class Server: # ... def handle_message(self, message): if isinstance(message, X): # Either do something, or call out to a special # handle_X method elif isinstance(message, Y): # Same as above elif isinstance(message, Z): # More boilerplate else: # Handle invalid messages Essentially, when the server buffers enough data from a client, it has to figure out what to do with a message - generally, I write something like the above, so that way other parts of the code can simply say: self.handle_message(message_i_just_received) The problem, of course, is that this is messy - Python being Python, we can do better. You might think to use `functools.singledispatch` (as I did), but the naive use doesn't work. This is because `singledispatch` reads the first argument (`self`) when we want it to read the second (`message`). It doesn't end up as beautifully as you might imagine: class Server: @singledispatch @staticmethod def handle_message(message, self): # Handle invalid message @handle_message.register(X) @staticmethod def _(message, self): # ... This is not only extremely ugly (yuck - I don't think I've ever had a reason to put `self` second!), but this abstraction also leaks into the caller, a big no-no: Server.handle_message(message, self) So, I wrote `dispatchmethod`, which is both cleaner than the first version and clearer than the second: class Server: @dispatchmethod def handle_message(self, message): # Handle invalid message @handle_message.register(X) def _(self, message): # ... Plus, the caller is now as clear as it was originally: self.handle_message(message) 
Ill have to check, but I think it works on immutables. On mobile right now.
I didn't know about splinter but I'll give it a try. The site I'm scrapping is ASPX and it seems there are some JS elements that Requests/RoboBrowser isn't catching, (in reality I'm most likely missing something). Whoa it pops up a browser window, freaky heh edit: added surprisedness
[Cut-Up Maker](https://github.com/rossgoodwin/cutup) I took a text modification method outlined by William S. Burroughs and implemented it as a Python script.
Since you raised the issue, let me just say this: [please don't buy from Amazon](http://www.antipope.org/charlie/blog-static/2014/05/amazon-malignant-monopoly-or-j.html). That is all I will say on the matter here, since it is off-topic. As far as your Python script goes, just write the script to fetch the information as you normally would, then use cron to run it daily. I expect you know this, but I mention it because I keep coming across people who want their Python code to schedule itself in some magic way. If Amazon has an official API for talking to their website, use it. Otherwise you need to screen-scrape. (Web-scrape?) The *wrong* way to screen scape is to use regular expressions, but I'll be honest, if their HTML is simple enough and doesn't change very often, that often works well enough. But I always feel a bit dirty when I scrape with regexes. Otherwise, look at BeautifulSoup4. It is a third-party library for parsing HTML, but unlike the standard library HTML parser it can cope with "real world" (i.e. broken, invalid and messy) HTML. If the web page requires Javascript, look at Mechanize, again a third-party library. 
Oh, one more thing... since you're a Perl coder, you probably have learned to reach for regexes for most everything. That instinct won't serve you well in Python. It's not just that the Python regex engine is less highly optimized than the Perl one, but it's mostly that the culture of Python isn't heavily focused on regexes. You'll probably find that will take you a bit of getting used to.
Number 1 is wrong unless you can reasonably give a "is-a" relationship between `Class1` and `Class2`. If they are both kinds of the same sort of thing, then give them an abstract base class with the shared methods. E.g. Class1 is-a Foo, Class2 is-a Foo, therefore it is reasonable to create a class Foo. Note that I said shared *methods*. If only one method is shared, that strongly suggests that they aren't the same sort of thing. The exception to this is if you are able to make the helper a Mixin class. That does seem like a reasonable approach, unless you have a policy of No Multiple Inheritance Ever (not even Mixins or Traits). Number 2 is the wrong approach too. If a class only has methods, and no state, as Helper() appears to do, then it has no good excuse to exist. Especially if it only has a single method. Number 3 is *almost* right, except there is (probably) no good reason to store the function in the class bodies. It's not exactly wrong, it just seems unnecessary. Just call it from your methods, like you would call len() or any other function. i.e. rather than doing this: def helper(self, arg): return self.something + arg class Class1: helpermethod = helper def method(self): result = self.helpermethod(x) do this instead: def helper(obj, arg): return obj.something + arg class Class1: def method(self): result = helper(self, x) # Pass self to the function as an argument. Number 4 doesn't seem terribly appealing either. It's creating coupling between Class1 and Class2. What happens if Class1 disappears, or if it's requirements change? Number 5 is probably reasonable under some circumstances, but I can't get excited about it. There's one more option: if the helper is short enough, just include it as an independent method in both classes. Why would I suggest that when everybody knows that copy-and-paste coding is Bad? If the method is short and simple (as good helpers should be), *and* there is no logical connection between the classes, there's not much cost to having two independent copies of that helper code. That is, although the two classes happen to have need for the same helper today, that isn't a logical requirement of the classes. This reduces coupling between the two and allows the two helpers to vary their implementations without affecting the other class. But only do that if the methods are very short, less than (say) a dozen lines, and you know that changing one does not require changing the other. 
&gt; the helper needs to access state in the class instances. The helper can still do this if you pass the instance to the function. It does mean that the function needs to know about the implementation of the two classes, but it needs to do that as a method as well. The only downside of this is that the function effectively becomes part of the class' implementation, even though it lives outside the class. But that's going to occur if you use a mixin, a base class, or pretty much any other solution to this problem.
Many of those "tenths and hundreds of a second" are just noise. When two versions of the function are that close together in performance, chances are very high that any difference is just random noise, not a real speed difference. If you run the timeit code twenty times, you'll find that version 1 is faster nine times and version 2 is faster eleven times, or maybe the other way around, depending on whatever other processes just happen to be running on your system at that exact moment. Besides, are you *actually* calling these functions thousands of times inside a nested loop? No? Then it's irrelevant.
Correct. Furthermore, the definition of "small ints" can vary from version to version. In CPython, it used to be (by memory) 0 through 100, now its (possibly) -1 through 255. You cannot rely on this: being an implementation detail, it is subject to change without notice, and some Python implementations may not do it at all. IronPython 2.6 Beta 2 DEBUG (2.6.0.20) on .NET 2.0.50727.1433 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; a = 1 &gt;&gt;&gt; b = 1 &gt;&gt;&gt; a is b False 
use os.path.sep instead of "/"
Strictly speaking you are correct. If you absolutely definitely positively intend to check *only* for the True singleton, then you should write `x is True`. But really, why would you do that? Normally you should duck-type bools just like you duck-type most types. `x` quacks like a bool, no matter what `x` is. If you really must ensure that x is a bool, then type-check first: if not isinstance(x, bool): raise TypeError("x must be True or False") and from that point on, just compare `x` or `not x` with none of that silliness of `x is True`. The problem is, I never know when to stop: x is True is True is True is True is ... 
Correct. Never use `is` when you mean "equals", always use `==` for equals. The only reason to use `a is b` is to check that the two operands a and b are the same object.
You shouldn't be surprised. CPython is the reference implementation of Python, and as a matter of policy they don't do many "clever" optimizations. PyPy is an amazingly clever optimizing JIT compiler, and Nuitka is intended to be an optimizing AOT compiler, although as far as I know it doesn't do many optimizations yet. CPython does do dead simple optimizations, such as constant folding and removal of some dead code.
you're probably using old pythons. throw `from __future__ import division` at the top, or use python3. sorry bout that. is just a little quick thing I threw together, didn't think much about making it work in py2 as well.
I don't know why you were downvoted, you're pretty much correct. GvR doesn't like tail-call optimization: - it is only applicable to a *tiny* subset of recursive problems - it destroys backtraces as a diagnostic - most cases where a problem is better written with recursion, you only recurse a few times and tail call optimization is not a great help (I'm stating GvR's opinion, as I understand it, not mine). Don't think of those cases where the traceback looks like this: Traceback (most recent call last): File "&lt;stdin&gt;", line 3, in factorial File "&lt;stdin&gt;", line 3, in factorial File "&lt;stdin&gt;", line 3, in factorial [repeated 1000 times] File "&lt;stdin&gt;", line 3, in factorial SomeException Instead, you should think of the hard-to-debug cases where there are multiple functions, and some of them are mutually recursive: Traceback (most recent call last): File "&lt;stdin&gt;", line 7, in spam File "&lt;stdin&gt;", line 12, in eggs File "&lt;stdin&gt;", line 35, in cheese File "&lt;stdin&gt;", line 11, in spam File "&lt;stdin&gt;", line 11, in truffles File "&lt;stdin&gt;", line 12, in eggs SomeException In this case, collapsing the stacktrace (as tail call optimization will do) throws away useful debugging information. TL;DR In Guido's opinion, as I understand it, the benefits of tail call optimization are far outweighed by the cost in loss of debugging information. 
I stand corrected. However it's very basic. &gt;&gt;&gt; def f(): ... if []: ... print "OK" ... &gt;&gt;&gt; dis.dis(f) 2 0 BUILD_LIST 0 3 POP_JUMP_IF_FALSE 14 3 6 LOAD_CONST 1 ('OK') 9 PRINT_ITEM 10 PRINT_NEWLINE 11 JUMP_FORWARD 0 (to 14) &gt;&gt; 14 LOAD_CONST 0 (None) 17 RETURN_VALUE 
Yeah, but FWIW Java (OpenJDK) doesn't either: import java.util.ArrayList; public class IsItRemoved { public static void main(String[] args) { if (new ArrayList().isEmpty()) { System.out.println("OK"); } } } Giving: Compiled from "IsItRemoved.java" public class IsItRemoved { public IsItRemoved(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object."&lt;init&gt;":()V 4: return public static void main(java.lang.String[]); Code: 0: new #2 // class java/util/ArrayList 3: dup 4: invokespecial #3 // Method java/util/ArrayList."&lt;init&gt;":()V 7: invokevirtual #4 // Method java/util/ArrayList.isEmpty:()Z 10: ifeq 21 13: getstatic #5 // Field java/lang/System.out:Ljava/io/PrintStream; 16: ldc #6 // String OK 18: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 21: return } PyPy and most Java implementations will most probably remove it at runtime though. 
Nice! I often forget that functions make a good alternative to thunks in Python, particularly if you can use lambda. They're not quite as lightweight as in Algol, but they'll do the job.
Best? Meh,,,It's an easy problem. Something like this would work import numpy dtypes = ['|S16', 'float32', 'float32', 'float32'] # name, speed, size, consistency fname = 'players.txt' A = numpy.genfromtxt(fname, dtypes) name = 'Bob' names = [a[0] for a in A] i = names.index(name) speed, size, consistency = A[i][0], A[i][1], A[i][2]
Check out the sidebar on the right or the info about this subreddit. Also post on /r/learnpython. I wouldn't just use one medium to learn programming. I personally try to learn from any format or sources like from books, online courses, videos, posting on stackoverflow, joining mailing lists, join your local Python users group, etc. I am still learning myself. Good luck!
&gt; Instead, just range(1000) in python2, list(range(1000)) in python3 Though in python3 you would just use the resulting range object anyway. You can index it, slice it and iterate over it repeatedly. It behaves a lot like a regular list.
Best is a matter of opinion, but [this](https://www.coursera.org/course/pythonlearn) coursera course may interest you.
What about "Premature optimization is the root of all evil."?
Try Google's python class https://developers.google.com/edu/python/
I'm compelled to wonder, though: How badly can you really mess things up by adding a `__slots__` declaration to the code? How likely are you to ever be forced to remove it? How much development time is it really going to add? Can it ever actually be counterproductive in terms of performance?
I thought it was generally agreed that using `{}` is better stylistically anyway?
Python allows you to develop quickly, plus it has lots of handy libraries. I recently wrote a Python program to count unique words and bigrams in 22GB(!) of text. It's just a one-off calculation; I don't want or need to install mounds of infrastructure or write it in C where I may save memory but have a far longer development time. Python (and NLTK) allowed me to develop the program in an afternoon and, while it took all night to run, that's okay because I was out doing other things.
I had a algorithms project recently to implement a simple SAT solver. Basically, there were a series of variables which were either equal or not equal to each other. I had to figure out whether all the rules were satisfiable. Decided to use Python because I hadn't had much opportunity in the past. Some of the large test cases that we were given had hundreds of thousands of variables, which meant hundreds of thousands of objects in my algorithm. At first I couldn't figure out why I was using all the memory on my computer (8GB). After a lot of research, I discovered that the problem was \__slots__. I disabled it, and RAM usage dropped to around 200 MB on the worst cases. Would have written a blog post, but I don't have a blog (need to rebuild my personal site.)
Also, if you *are* calling these (very trivial) functions thousands of times inside a nested loop you might wanna rethink your code.
Read file to stream, push stream through tcp stream, write received stream to file. Or read file to memory, write memory to tcp stream. don't be lazy
Adding \_\_dict\_\_ to \_\_slots\_\_ will put a dictionary back on every instance that will automatically fill gaps caused by using slots, if every variable in the instance has a slot then the dict will stay empty and won't take up much space. You can then develop the class without having to go back and change \_\_slots\_\_ for every attribute you add, and libraries that need to add special attributes to objects such as weakref won't break. As long as no one has decided to use \_\_slots\_\_ as a runtime spellchecker then it shouldn't cause any issues.
This is called interning. I've written a bit about which objects are presently interned in Cpython [here](http://www.reddit.com/r/Python/comments/2qszpn/python_tricks_for_your_code_run_faster/cn9hv4u)
can you give a short reason as to why slots caused the extra overhead?
If you don't mind an extra dependency, use [unipath](https://github.com/mikeorr/Unipath). I use it for almost every project since I discovered it.
Thanks for the thoughtful replies.
Thanks
I like Geany. Bonus: highly pluggable with a lua plugin for a scriptable extension/macro system. Really simple, but with highlighting, completion suggestions for Python and others, and in-tab terminal. Do build from source though, to get the full language set and bug fixes. Easy enough: apt-get build dep geany, then clone from github and `./configure; make; make install`.
Thank you, these are all very helpful suggestions.
PyCharm is heavy but worth it because it helps you make a lot less mistakes. As the size of the code base increases this advantage grows.
Exactly, which for integers seems weird. Why would I want to be sure that two 2s were the same 2 in memory and not merely equivalent?
Codecademy is where I started and is great because it is so interactive
PyCharm
If they are OK with using the system python and his package manager can supply it then I'd say go with the package manager. Edit: But I prefer Anaconda on my own system.
Definitely PyCharm.
It sounds like you know where your newly installed python is and that it isn't the system python. Try running the new python directly, `/usr/local/bin/python` for example and then `import numpy` from inside that. Does that work? I can't remember where the system python is in ubuntu, but if the python you want to use is different you could create a softlink in a "~/bin/" directory and add that to your PATH. mkdir ~/bin cd ~/bin ln -s /path/to/your/python python In .bash_profile or .bashrc: export PATH=$HOME/bin:$PATH
Check out Sublime -&gt;https://realpython.com/blog/python/setting-up-sublime-text-3-for-full-stack-python-development/
Check out [Real Python](https://realpython), where you'll learn Python and web develop through interesting examples. (Note: I am the co-founder/author). Cheers!
I use ST3 for python development every day and I love it, but for a lot of people PyCharm is an incredible language specific IDE. I point beginners at PyCharm but I recommend sublime for more advanced developers as the latter requires a steeper learning curve to become truly productive. 
I'm failing to see what's disasterous. Any clues?
No, this is because you cannot "splice" a file. You can append to the end of the file and you can, as you know, rewrite the file. But that's it. In order to "edit" a file you have to rewrite it. When explaining what a hard drive is or how a file system works I tend to compare them to a notebook. You write to it using a pencil and you're allowed to erase it. But if you want to write something to the beginning of the text or somewhere in the middle you'll have to rewrite everything from that point onwards. Otherwise you're just writing things on top of the previously written text. *I know disks are more complex than notebooks.*
This would be awesome. We cover a *ton* of web scraping via Scrapy in the [Real Python](https://realpython.com), and I just posted a blog post on it as well - [Web Scraping With Scrapy and MongoDB](https://realpython.com/blog/python/web-scraping-with-scrapy-and-mongodb/). Best of luck!
It's not really possible to edit a text file like that. That's party why databases exist, actually! You can think of a file as a long strip of paper. You can't really add or remove something in the middle without 'pushing down' everything else, which means rewriting it anyway. The only way to do it is to have a structured data file with fixed-length 'bins' you can update to point at new data. (Which is an oversimplified version of how databases work.) You can use the fileinput module to make it look like it's working that way, though, and have python handle all the plumbing of creating the new file and relink it. import fileinput from __future__ import print_function name = 'myfile.txt' for line in fileinput.input(files=[name], inplace=1): # to pass through existing lines print(line, end="") # to add new lines print("Here is some new content") # to remove a line # ... don't print it 
Perhaps you could use json to ease the parsing! My general advice to you is to think less in files but more in domain models. If you need persistance, all you wanna solve is to serialize and deserialize your domain models...
All these other guys are crazy. You do not have to rewrite an entire file to work with it and it's not "how files work" Read: https://docs.python.org/2/tutorial/inputoutput.html#reading-and-writing-files Specifically, when writing the file, you can open it with 'r+' mode to enable read/write. The functions you're looking for are the `seek()` and `tell()` methods of the file object. They will seek to a byte position and return the current position respectively. If you have a previously written 100 byte file, opened with `fd = open('file.txt', 'r+')`, then call `fd.seek(50)` to seek to the 50th byte. Then calling `fd.write(...)` will write in that position, then advance the current position by the length of what was written. It will overwrite whatever is at the 50-byte position. So in this example, writing 10 bytes at the 50-byte position of a 100-byte file, you will still have a 100 byte file, and then calling `fd.tell()` after that write will return `60` Now here's where it gets dicey: You probably don't want the hassle of doing manual file manipulation. It's cumbersome unless your file-format is VERY rigid. How will you know where the line boundaries are? A file object is just a stream of bytes. So you write an interpreter that can read it in. By this point, you might as well use an already-written and established file format. JSON is nice an easy, more-or-less human readable and has excellent Python support (Stdlib as of 2.7 I believe). Writing example: import json myvars = {'var1': 5, 'var2': 10', 'var3': 15} fd = open('file.txt', 'wb') fd.write(json.dumps(myvars) fd.close() Reading example: import json fd = open('file.txt', 'rb') data = fd.read() fd.close() myvars = json.loads(data) Note: with my example, you _ARE_ re-writing the whole file every time, but that's what happens with the convenience. Edit: I glossed over a lot of exception handling in the examples of course. There are many places they could fail. Could fail opening the file for reading or writing depending on permissions, will raise an exception if the file doesn't exist when reading. Will raise an exception if the file does not contain valid JSON. These are exercises for you to handle.
Hi Davey, I am not sure how to do your suggestion in the first paragraph, but I tried the second suggestion. I now have what looks like a shortcut to my installed Python in the home/bin folder, and I can see numpy in it, however when i try and run a script using "python MyFileName.py" I am still getting the same error where it cant import numpy. I tried again while the terminal was at the home directory in case that was the problem but I still get the same error. 
&gt; Now here's where it gets dicey: You probably don't want the hassle of doing manual file manipulation. It's cumbersome unless your file-format is VERY rigid. How will you know where the line boundaries are? A file object is just a stream of bytes. If the file is structured to have lines of fixed length (say 100 characters each), you could seek around to modulo 101 boundaries (101 to count the newline on each line), and read/write individual lines. You could even seek into the middle of a line (assuming you structure the internals of each line rigidly) and read/write there.
Functions are not sent to celery workers, the "arguments to functions" are being sent to the celery workers. Function are already loaded there in the worker (when you start it), celery doesn't marshall code for you. If you use the prefork or thread pools PyPy should make your tasks faster, given enough runs. Not sure about the eventlet/gevent variants (or if they are even supported). One thing to be aware of: if you have a very low maxtasksperchild or your workers die a lot PyPy probably won't get to JIT compile your functions. Also, you should do your own benchmarking, as all advice about highly complex system like PyPy is conjectural. Test and let other people know what you've found.
https://github.com/SamuelSital/Automatic-Torrent-Downloader Script to automate the download of new episodes from a given list of TV series https://github.com/SamuelSital/Soundcloud-Download Script to download music from Soundcloud
Okay, this makes sense! I am indeed using prefork workers, and I see no reason *a priori* to set a low `maxtasksperchild`. As far as I understand `maxtasksperchild`, there's no reason to change this from the default (infinite) value unless one of my celery tasks is known to leak memory. Is this accurate? Thanks!
&gt; You do not have to rewrite an entire file to work with it and it's not "how files work" In order to do any change that involves insertion and deletion, you have to rewrite everything from that point onward. That's effectively rewriting the whole file. It doesn't make any sense to try to optimize this by only rewriting the part following the change, because: - Rewriting the contents to a new file and then renaming the file into place is safer, because other programs will never see the file in an intermediate state — the update is atomic. And if something fails while writing, you're never left with a corrupted file. - Dealing with all the annoying little details and getting everything right so that you don't drop or duplicate bytes is really hard. - In many cases, you're going to be doing multiple edits, and in those cases you want to just read the whole file in memory, do whatever changes you want, and then write it all out. Again, trying to reuse the parts of the file that didn't change is a nightmare scenario — imagine something like a text editor where the user swaps lines 10 and 42 of a 1000 line file, and then inserts a line at line 50. That's an incredibly complicated situation to work out if you're trying to edit in place, because even simple changes like this produce numerous regions that need to be moved around. Moreover, you might have many changes queued up, and working out the order to perform them to get to the desired end state is non-trivial. You most certainly do not want to do them as the user performs the actions, because that would slow down editing immensely and lead to the possibility of a corrupt file if editing is interrupted. Most importantly, real world text editors do not work in the way you describe. They rewrite the file completely, for the reasons outlined above. It's crazy to call people crazy for suggesting the clear, simple, and correct way to do this. 
Definitely, and I've done the modulo-based files before, but they're just a bad time waiting to happen. If you accidentally edit the file incorrectly outside your program (shouldn't be doing that but it's a text file so WEEEEEE), then all of your data past that "record" is now corrupt, and your application will just blindly accept it. If each record is line-based, then just doing `fd.readlines()` or `for line in fd:` to retrieve records.
Any IDE that supports everything that you're looking for will be heavy. Save yourself the headaches of trying to get other IDEs up to snuff and just use PyCharm. If that's still too heavy, take a look at [Stani's Python Editor](http://pythonide.blogspot.com/) or [Eric Python IDE](http://eric-ide.python-projects.org/).
Yes, or if your tasks do other evil stuff (like leaking fds or go over time limits). Or you terminate them from the outside (revokes with termination).
I'll have to check out some of those. Thanks! This is my current list: * Docker Syntax Highlighting * GitHubinator * Markdown Preview * SideBarEnhancements * SublimeLinter-pylint I use PEP8 checks via the command line. Im also the guy that uses sublime text 3 in vintage (VIM) mode. Thanks again for your list. Edit: I forget to mention Gitgutter and Anaconda (with linting disabled) 
So just open up cmd, and write cd (directory\directory\Bot.py &amp;) I tried that and it didn't work, should it have worked?
Close! Open up cmd and write "cd directory/directory", hit enter, then write "python bot.py &amp;". The "cd directory/directory" takes you to the directory of the file and the "python bot.py &amp;" launches the application. 
Ah, it's unrelated. It just kills the process ([doc](http://docs.celeryproject.org/en/latest/reference/celery.app.control.html?highlight=revoke#celery.app.control.Control.revoke)) - so the JIT compiled functions would be lost then.
Yeah, that would be perfect!
reddit meta question: Why is this sub so much better than the PHP equivalent? 
TIL you can load and save .mat format files from SciPy. That's huge for me. Thank you!
You could do something like [this](https://gist.githubusercontent.com/ionelmc/8245494/raw/vbox-shutdown.py) - just remove the virtualbox specific stuff :) It would look like [this](http://blog.ionelmc.ro/2014/01/04/virtualbox-vm-auto-shutdown/).
&gt; In order to do any change that involves insertion and deletion, you have to rewrite everything from that point onward. That's effectively rewriting the whole file. It doesn't make any sense to try to optimize this by only rewriting the part following the change, because: Incorrect, along with "That's just how files work" is incorrect, a database server doesn't rewrite it's entire (eg) 1TB dataset every time a row is updated. For the rest of your points: I agree wholeheartedly. It will be easier for OP to just read/write the whole thing, VASTLY easier for someone just starting on file I/O. I agree with every point you've made, it's incredibly easy to either get the programming of it wrong, or damage the file from outside your program. That wasn't my point. My point of contention was that it _could_ be done, not that it necessarily _should_ be done.
Pycharm shills will tell you to use their product
&gt; All these other guys are crazy. Let's hear it. &gt; with fd = open('file.txt', 'r+'), then call fd.seek(50) to seek to the 50th byte. Then calling fd.write(...) will write in that position, then advance the current position by the length of what was written. Okay. &gt;It will overwrite whatever is at the 50-byte position. Exactly. So where's the bit where you show that all these guys are crazy?
&gt; Lambdas seem to retain access to their local scope, even if the caller does not. Admittedly, this seems to have fairly niche use cases, if any. I can't remember the last time I wrote a non-trivial bit of Python that _didn't_ depend strongly on closures.
If all the values are integers you can use... import numpy A = numpy.loadtxt('players.txt') &gt; So I still need to figure out how to define a specific integer on a specific line, have it search the right players, You need a mapping of the names to line number, which I wrote before name = 'Milan Hnilicka' i = names.index(name) Do you have an actual file with say 3 players and the columns properly titled? Your top block looks very different than the later one. You gotta be using 4 leading spaces to make your blurb look like code. So like this 71 73 73 71 71 73 71 71 62 63 63 71 71 39 76 42 10 0 1 4 1 1973 24 6 900000 0 1991 4 17 98 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 93540780 15430955 16560705 16670506 13530803 17650474 16760834 16670933 14450793 15330789 14440568 46551010 15540729 17660363 17670476 17750728 12440888 16560871 16680851 92430538 14540563 15571039 13550646 22550620 46770425 15340255 17760682 35760381 17560907 17561052 0 0 0 0 4 190 8 3 not 71 73 73 71 71 73 71 71 62 63 63 71 71 39 76 42 10 0 1 4 1 1973 24 6 900000 0 1991 4 17 98 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 93540780 15430955 16560705 16670506 13530803 17650474 16760834 16670933 14450793 15330789 14440568 46551010 15540729 17660363 17670476 17750728 12440888 16560871 16680851 92430538 14540563 15571039 13550646 22550620 46770425 15340255 17760682 35760381 17560907 17561052 0 0 0 0 4 190 8 3
I like the direction you're going with this, and while I think the complexity critiques are valid, I think there are a lot of convenience benefits to a data structure like this that will often outweigh performance (I only have 30 elements per BOD, but I don't have to implement and maintain the ordering myself). Quite often, what I'm really looking for is an ordered set, and since a hash map plus a list of keys approximates this, I end up exploiting the key lookup property in other sinister ways. So my idea... I would like to be able to specify a cmp function in the constructor that would be used to do a binary search on the inserts. This is quite different from the intent of the standard OrderedDict... But in this world, I can say coworkers = BOD(cmp=lambda a,b: cmp(a.last_name.lower(), b.last_name.lower()) or cmp(a.first_name.lower(), b.first_name.lower())) Which I would actually write as a function instead of a lambda if I wasn't posting from my tablet. And in my weaker moments: coworkers_by_parking_privilege = BOD(cmp=manhattan_distance_normalized_by_salary) Or whatever ;) Edit: and seeing how verbose that is, I'd like even more to say coworkers = BOD(sort_by_properties_case_insensitive=['last_name', 'first_name']) I also think you should avoid acronyms as class names, though I certainly understand the temptations of brevity. Edit 2: Don't add a kwarg for a specific cmp... Externalize that as from some_module import by_case_insensitive_attrs coworkers = BOD(cmp=by_case_insensitive_attrs('last_name', 'first_name')) Edit 3: Developers optimizing for computational efficiency will be using numpy or pandas or whatever. Make my routine tasks easy and simpler to understand, and you'll get props from me. 
It's just something you need to keep track of and understand if you're going to use it. A few other gotchas that come up are around subclassing and pickling. If you subclass a class with `__slots__` the subclass needs `__slots__` too or the `__dict__` is created and `__slots__` in the base class is useless (may or may not be the behavior you want). If you try to pickle an object that has `__slots__`, you need to implement `__getstate__` as well. Again, no reason not to use it, just be sure you know what you're getting into. 
I actually think that the `&amp;` option that ebo113 is telling you about doesn't work in the Windows command prompt. It's how you run something in the background on a Unix-based system, such as Linux or Mac OS. Anyway, what you want to do at this point has nothing to do with Python and everything to do with the Windows taskbar. I think you can google for "taskbar hiding" tools of various repute -- but beware of malware.
If you're on Linux you could open a Unix socket, or a FIFO file, and read from those? Reading from either may block depending on how you set it up, which could reduce the CPU load of looping and checking every second. You could also try a plain socket, which would work on WinMacs, but you'd have the complication that an open socket may be externally visible to other networked devices.
I believe Python for Windows installs `pythonw.exe` to address this issue. If you invoke your Python script with the command `pythonw script` no command prompt window will appear. Alternatively, you can change the file associatiation for `.py` files to launch with `pythonw.exe` so that double-clicking the file achieves the same result.
Well, there's a lot of great stuff that was made in PHP.
So I'm no programmer so I'm not sure how to invoke "pythonw script". Do I just put that in at the beginning of the code?
 from scipy.io import savemat, loadmat This line goes in almost all of my python code these days.
Yes it causes a read. `os.path.isfile` triggers a `stat` system call whose semantics depend on the OS. However; if you just need to communicate between processes (and don't need persistent storage), you can avoid the hard disk entirely. Pipes, sockets, or shared memory are all possible solutions.
For those wondering, .MAT is the matlab binary variable/data storage format.
How do I associate a file type with an .exe program?
It really depends on your real needs. I know you state some of them but it's not clear if you have a lot of state that needs to be shared or just a couple of items or if the system runs on one system or a number of distributed systems. If you were only on Linux you could use [Pyinotify](https://github.com/seb-m/pyinotify) library. You could then set it up to monitor a directory for file creates, deletes, access, reads, writes, etc. If you have many processes involved, you may want to use a messaging system such as [RabbitMQ](http://www.rabbitmq.com/) via [librabbitmq](https://github.com/celery/librabbitmq) library or via the [Celery](http://www.celeryproject.org/) framework. If you would like to have a server that saves all the state in memory you could use a [redis](http://redis.io/) server via the [redis-py](https://github.com/andymccurdy/redis-py) client. Redis is a key-value store (Think of a server for a dictionary). You could either poll the keys you are interested in or use [Redis Keyspace Notifications](http://redis.io/topics/notifications) for a more efficient async method. You can also use mapped memory files using the mmap standard library. Most OSs will cache these files in memory if they are small which is one way to reduce the reads to disk. You can also use sockets as mentioned in another response. So there are plenty of options that all have there own pros and cons depending on your needs.
Gods below! I'm just stunned by how incomprehensible this thread would have been 50 years ago.
I never understood why people are so interested in breaking dicts by overriding `__getattr__`. Is it really so tough to type ['key'] instead of .key? All it takes is a json file with an "items" or "keys" key to completely break this.
What does it do when it finds a keyword? Does it display it in the command shell? If so, if you hide it, how are you going to know if has found something? And, since someone else programmed it for you, why don't you ask that person, who is more familiar with what this program does than any of us every will be, to help with your problem? Many people have been trying to help you, but your main reply is "I am not a programmer"; this tells me that you should ask the programmer you already know rather than waste everybody's time on this list.
Has anyone figured out how to save v7.3 mat files from Python? I can load them using hdf5 and h5py. I can even save hdf5 files with h5py. But I can't save hdf5 files with the right metadata to call them mat files (so matlab can read them as mat files). Anyone else have this problem?
Refer Python docs: https://docs.python.org/2/library/email-examples.html
Because it's PHP. I mean, come on.
You' re welcome. A quick search will also lead you to several examples on Stack Overflow.
You don't have to put a \ in the tuple or duct continuations. Any form of braces implies continuation. `.has_key` isn't the proper style any longer. Use the `in` keyword (`key in dict`).
In this case, you wouldn't want to have to do some_json_file['key'], right? some_json_file.key is the more natural expression. The author could have probably wrapped a dict rather than inheriting from it, though.
It boils down at what level of expertise a python programmer is ?. a) Python Algorithms - Mastering Basic Algorithms in the Python Language - http://importpython.com/books/489/python-algorithms-mastering-basic-algorithms-in-the-python-language/ b) Test Driven Development With Python - http://importpython.com/books/445/test-driven-development-with-python/ This book is available for free reading.
Or "foo.bar" as a key breaks JSON this way too. It breaks javascript as well: var jsonObj = {"foo.bar": 12}; // Not valid because foo won't exist console.log(jsonObj.foo.bar); console.log(jsonObj["foo.bar"]); // Returns 12 as expected I've seen this be an issue in real applications, in both Python and Javascript front-end web applications and so its not just an "academic" issue. If you keys are URLs for example: "http://google.com" you will have problems. If your keys are the first and last name of someone "Peter Smith" you will have problems. Email addresses as keys such as "someone@somewhere.com" will have problems. These things are often uniquely identifying, so using them as a key in something like a JSON config object wouldn't be unreasonable. I could imagine a config JSON object that has the URLs of various domains and then inside the JSON object you would have properties indicating what to do with the URL. Using .key won't let you do that. 
I like how you're making a "naturalist" argument when the entire idea is completely unnatural. It's a neat trick and a fun proof of concept, but if I saw this in a code review, I'd call into question the hiring of the individual who wrote it.
I totally agree, if it is code intended for production. This is just something for fun and curiosity. Real usage of this code is not something which is to be desired.
If you are an Emacs user, org-mode should be a good candidate.
My life.
&gt; I like how sarcasm :-( &gt; call into question the hiring of the individual ad hominem :-( Getting back to the original subject though, what is appealing to me here is two data sources expressed in different languages being unified under the same object access style. This means if I know how to access Python module and their members, I don't have to learn the object model that my JSON parser decided to produce. Ideally you would express both sources in the same language, but sometimes this isn't viable (legacy, or interop with other systems). The OP actually has two components: adding attribute-style access to json.load's return, and mapping "import foo" to foo.json. The former makes a lot of sense to me. The latter may be a little questionable.
Both are questionable. JSON mapping to a dict is very pythonic. If you don't know how to use dicts, you don't know much about Python. Obfuscating that lack of knowledge by breaking how dicts work seems like a poor workaround for that lack of knowledge.
Ok, say you have a generic provisioning framework that knows how to generate JSON files natively. You want to provision Django installs using this framework. Django relies on Python modules for configuration (settings.py): https://docs.djangoproject.com/en/1.7/ref/settings/ How would you integrate these two systems?
I wish I could use scrapy with what I'm doing but it requires to do a few form POSTs. I'm trying to use [RoboBrowser](http://robobrowser.readthedocs.org/en/latest/readme.html) however I'm having a hard time with the form POSTs to specific pages, (/me shakes fist at ASPX). Great read none the less.
&gt;PHP attracts beginners, who then go on to learn there are other, and arguably better languages to use. There's no argument that there are better languages. The only argument is if there are any worse ones. 
I can't see why this is a problem. A json file with an *items* or *keys* key doesn't break it at all, If I want to get a keyed value and the key value is in a variable named *key* then I write as below, which works whether the key is like *name*, *mike@somehere*, 12345 or anything else: jsonObj[key] If I want a keyed value for a known key and that key is a valid python name which is not a method on a dictionary then I write: jsonObj.somevalidpythonname and if it is not a valid python name or is a dictionary method then: jsonObj['not.a.valid.python.name'] If you don't know whether a string of characters is a valid python name or dictionary method then the above is the least of your problems! Packages like ORMs do the same sort of thing all the time, even though you can have columns whose names are not valid python names, and we manage with it. A large system I work on has class support for this sort of thing, and it works just fine. 
[Wello!](http://www.reddit.com/r/lolphp)
Why not just write in LaTeX in the first place? 
How would you do this? Am i missing something? Just write the XML after you have collected the info.
And for the daily part you might want to use cron instead of sleep(). 'man crontab' for your terminal - if you're in windows you'll have to search yourself for a cron alternative for windows. 
The data is different, but the schema is the same, isn't it? At a guess, wouldn't you do something like this? &lt;host name="someserver" os="whatever"&gt; &lt;port num="22"&gt; &lt;state&gt;open&lt;/state&gt; &lt;proto&gt;tcp&lt;/proto&gt; … &lt;/port&gt; &lt;port num="80"&gt;…&lt;/port&gt; &lt;/host&gt; That's just a random stab at a schema that I came up with.
I dont understand the benefit of scrapy. If you need to write the parsing routine and database routine then why is scrapy really needed? Does it get more useful with bigger projects?
Really the best answer. PyCharm is the best ide I've ever used for any programming language, hands down. Having said that, why not download a few different ones and try them out to see what you like? 
Exactly. You can have as many subfields as you want. Yes, each XML will be different (in content) but the schema is the same. Im not seeing any problem.
The services running may vary from time to time. Which means in some cases the number of port subelemetns will be different. 
I'm using different resources, such as: CodeSchool,Learn Python The Hard Way, Making Use Of Python, and also the official Python website its self.
Yes. It's called sphinx. You write in a format called RestructuredText and it will output HTML, LaTeX, etc. It was designed for generating Python documentation. http://sphinx-doc.org/ It takes a while to figure out, but it works. And if you need to convert RestructuredText to another format, you can use pandoc.
More blogspam
Here's the article I'm referring to, [*Flipboard's Approach to Automatic Summarization*](http://engineering.flipboard.com/2014/10/summarization/). Enjoy!
Have you tried casting them to sets and taking a difference?
wrt. test 6; `!=` is slower than `is not`. The result is measurement error, mostly from having such as bad test. Here's a better version: $ python3 -m timeit "1 != 2" 10000000 loops, best of 3: 0.14 usec per loop $ python3 -m timeit "1 is not 2" 10000000 loops, best of 3: 0.0785 usec per loop wrt. test 10; this actually abuses an optimization the CPython does. It's [very fragile](http://stackoverflow.com/questions/24040198/cpython-string-addition-optimisation-failure-case) and it's not shared by other interpreters (eg. PyPy) so *don't use it*. Anyway, you'll probably find that `''.join` is faster in many cases if you actually write the function well: from timeit import Timer def a(): r = [] for i in range(10): r.append(str(i)) return ''.join(r) def b(): return ''.join(map(str, range(10))) def c(): r = '' for i in range(10): r += str(i) return r min(Timer(a).repeat(10, 10000)) #&gt;&gt;&gt; 0.10981534401071258 min(Timer(b).repeat(10, 10000)) #&gt;&gt;&gt; 0.07694110801094212 min(Timer(c).repeat(10, 10000)) #&gt;&gt;&gt; 0.09574692900059745 Note that I'm using `min(Timer(func).repeat(n, m))`[because it's the right way to do it](http://stackoverflow.com/questions/8220801/how-to-use-timeit-module/24105845#24105845). The first is slower because calling `append` a lot is expensive; using `map` to create the list (`''.join` converts its argument to a list) is faster. `%d` is slower than `%s` because it casts to an int first. Calling `__len__` requires creating a bound method, so my guess is the same as yours. 
I'd argue that mapping JSON as an object (or at least something that behaves like an object with attributes) is pythonic as well. I think it depends on what the JSON actually represents whether it makes sense to treat is as a dict or to map it as a "class" (I consider this an automated way to think of some JSON as an instance of a class with a bunch of attributes). 
Dude, questioning the hiring of an individual based on their work is literally the opposite of ad-hominem. 
Ugh, no that's O(n^(2)) due to list membership testing being O(n). The proper way to do this is with sets: &gt;&gt;&gt; first = ['something', 'something else', 'another thing', 'and so on'] &gt;&gt;&gt; second = ['something', 'something else', 'some other thing', 'or whatever'] &gt;&gt;&gt; set(first).symmetric_difference(second) {'and so on', 'some other thing', 'another thing', 'or whatever'} This is O(n) due to the O(1) nature of set membership testing. (Also, these are lists, not arrays. Python does have arrays but they are very rarely used.) 
That would remove all duplicates.
nice! Worked perfectly
That did the job! Thank you!
Did you get an exception? Silent failure? Did your computer crash? House catch on fire? Are you running a mail server? What did your mail logs say? You might want to ask this question on comp.lang.python on usenet, but be prepared to answer these questions. Don't just say "It didn't work" with no more details.
Markdown is okay, but ReST is better, and the tools for ReST are exceedingly powerful (and written in Python). See cdninbuffalo's comment [above](https://www.reddit.com/r/Python/comments/2qyi7v/any_good_software_for_writing_python_articles/cnaxf8q).
Or if you know the fields of the capitalist struct
yes, indeed, so how can slots cause extra overhead? They remove the need to have a dictionary object added to your instance. So I can't imagine how you saved memory by disabling slots. Hence my original question.
I think it is worth adding that you should cast to set *if* and only if you can guarantee that elements are unique in each list because `set([1, 2, 3, 3]) == set([1, 1, 2, 3])` but it is quite clear that the two original lists are not equal.
Great, so I can sell that algorithm to Yahoo! for 30 million dollars then?
I'd like to learn more about Natural Language Processing (NLP), Image Processing/Computer Vision and Machine Learning (ML) using Python this year. The goal has been elusive so far as there is so much to learn. However, I have made some progress by reading up a bit about these things and acquiring a few books. Additionally, I'd like to focus more on parsing (using libs such as pyparsing) and language design to develop simple DSL's. My main problem is that information in these domains is scattered and there is no clear roadmap for a learner to go from point A to B. On a more general note, I'd like to automate more of my day-to-day work using python i.e. more bots and scrapers. Here's to helping and encouraging each other to learn more!
...yes.
I'd like to understand how QR codes work, on an algorithmic/CV level. I read through most of the QR code specs, but I'd like to bridge the gap between image-processing and QR decoding.
When I last ran into this issue a few months ago, I just went with Selenium (webdriver) instead. More resource-intensive, and not pure Python, but it did the job.
Getting into python innards and start understanding bytecode. No idea why it's interesting to me.
I have always wanted to learn Python. And finally I have started learning it (Zed Shaw way at-least for getting started). Now going through the Polls app tutorial in Django. Really loving it. I got my hands dirty with Django 4 years back, but somehow choose Dupal/PHP back then. Then almost 1 year on nodejs (with the south Korean electronics giant). Shot term: Django Django Django Long term goals: penetration testing and data analysis with py - don't want to get more into oops and stuff.
The mathematical term is combination (if order doesn't matter) or permutation (if order matters). As in many cases, [itertools](https://docs.python.org/3/library/itertools.html) have you covered, look under “Combinatoric generators”
Review and reinforce knowledge of: * [collections](https://docs.python.org/2/library/collections.html) * [functools](https://docs.python.org/2/library/functools.html) * [itertools](https://docs.python.org/2/library/itertools.html) Learn about: * [pdb](https://docs.python.org/2/library/pdb.html) * [inspect](https://docs.python.org/2/library/inspect.html) * python 3 Write pure Python libs because: * [pypy](http://pypy.org/) * [processing python mode](http://py.processing.org/) Automate more things. Buy a boat.
If you're comfortable with using the money of grandmas paying for their email...
I remember reading your comment while researching for http://www.reddit.com/r/Python/comments/2qv2wl/what_small_projectsscripts_are_you_most_proud_of/ Can't remember if the code is public.
Python 3 support would be nice
Should have been mentioned that it wouldn't work in python 3.
I could look at it. Likely not much needs changing 
Given that descriptive extraction mechanisms have a long, well studied tail of research, I doubt there is any "secret sauce" you couldn't learn from reading the right papers. Now, if they had a generative mechanism somewhere up their sleeves that can write its own abstract, that would be the secret worth keeping... :) Jokes aside, it is always nice to see with how little effort programs based on complicated algorithms can be rapidly prototyped in Python!
What is import overkill? Are you suggesting that 4 imports is too many? I'm confused :|
I'll second that. The Jetbrains people seem to do a pretty good job. I've also just downloaded CLion from them. I intend to try that for my c editing (I was using pycharm for c editing along with the Rabbit IDE). 
[It's okay, you probably don't have to write classes.](https://www.youtube.com/watch?v=o9pEzgHorH0)
Check out [this](http://www.cafepy.com/article/python_types_and_objects/python_types_and_objects.html) illuminating free ebook on the subject. ~~It's for python 2.7 I think, but not much has changed in this area since 2.7, so it doesn't matter.~~ It is in fact written for both python 2.x and 3.x, precisely because not much has changed in the python object model since the introduction of new-style classes, which became the default in python 3.
Yes, I mean Flask. Apologies for the silly typo.
Yeah even I have been following that book.. Completed the first chapter. Love the author's attitude!
Most of those methods are explained in The [Python Language Reference](https://docs.python.org/3/reference/index.html) chapter [3.3. Special method names](https://docs.python.org/3/reference/datamodel.html#special-method-names) [__reduce__]( https://docs.python.org/3/library/pickle.html?highlight=__reduce__#object.__reduce__) and [__reduce_ex__](https://docs.python.org/3/library/pickle.html?highlight=__reduce__#object.__reduce_ex__) are explained in the [pickle](https://docs.python.org/3/library/pickle.html) docs.
I have plan to master two web frameworks, including their inner working methods. Though, i won't try to reach their Zen-level, not in 2015. * Django [related to my bread/butter] * Flask [i like it's simplicity] Along with that, i'd like to reach intermediate-level wizardry of core Python, so that i can understand what "they" are talking about on the latest PEPs. But, won't try to contribute in those. Not in 2015 ;)
Start here and don't look back. http://programarcadegames.com
You should check out [this!](http://learnpythonthehardway.org/). After you have a steady hold on the language, you can move on to the official documentation for the hardware interface you want to use. You may also want to look into arduino, it's slightly easier to start with.
The grandmas can afford it. They're saving so much money since they cancelled their AOL.
Scipy, numpy, pandas. That said, I would really love to develop a financial model, and learn how to really analyse data and mine it.
RoboBrowser is one of the more recent options, with commits within the last three or four months. The other thing I found along these lines is [Splinter](http://splinter.cobrateam.info/en/latest/).
You might also be interested in bottle.py or flask which are very capable but simpler web frameworks for python. They should be perfectly adequate for your needs
Take some code that kinda does something a little like what you want it to do and change it. Starting from scratch is can be daunting. If you start from a working base you can see how everything fits together, and then break it and try to fix it. Python is a very popular language, there is always someone who has done something similar to what you're trying to do. Being a good programmer isn't all about writing code, another huge part is knowing how to not write code and instead use someone else's. Here are some Python based raspi motor controller things I found on google: http://computers.tutsplus.com/tutorials/controlling-dc-motors-using-python-with-a-raspberry-pi--cms-20051 http://learn.adafruit.com/downloads/pdf/adafruit-raspberry-pi-lesson-9-controlling-a-dc-motor.pdf https://www.google.com/webhp?#q=python+raspberry+pi+motor+controller 
I use the free KomodoEdit from ActiveState daily. Not as heavy as Eclipse and PyCharm, but fully-featured. I use it for php, HTML, Ruby and Perl too. http://komodoide.com/komodo-edit/ 
/r/learnpython
Loads of unaddressed issues on Github
Yeah, forgot to mention Selenium; can't use it because of GAE.
http://www.tutorialspoint.com/python/python_classes_objects.htm
"Hey guys, I made a fully functioning AI in two lines of code" import AI as ai ai.start() It's not a bad thing but some of the implementation details are hidden. 
Because I am lazy
Ha, sure, I'm suggesting that for the 20 lines of imperative code, 4 lines of imports might just be overkill; I guess I also considered that those 3 libraries are all external libraries; the pattern module itself requires nltk - nltk requires training data. I'm sure there's a few more reasons why I considered it *overkill.*
I want to learn kivy and write up a game. but kivy's docs arent newcomer friendly. Help!
Thanks. I totally missed the "object." prefix on those special method names.
Looks great! I bet yours probably produces way better results. Why'd you end up sticking to cosine instead of the other measures? As an aside, that's the thing with summary generators, at least not the rule based - without having a definitive "this is what summaries should look like," and a few other reasons that would take a little longer to verbalize, *summarization techniques* as a tool requires a little more manual tweaking than I'd like. I much prefer the "specs" or ideas behind [text simplification](http://en.wikipedia.org/wiki/Text_simplification). Edit: rephrased what I meant.
I am happy so far. In one month I was able to write threaded scripts, do network socket scripts, web scraping, network scanning. As I type this, I am creating a web scrapper that will go to my favorite subreddits and capture the new submitted content. My goal is to keep scripting in python non stop. I want to get into actually using classes. I know how to write them but I have not yet used classes in any of my scripts. It hasn't clicked in my head yet.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Text simplification**](https://en.wikipedia.org/wiki/Text%20simplification): [](#sfw) --- &gt;__Text simplification__ is an operation used in [natural language processing](https://en.wikipedia.org/wiki/Natural_language_processing) to modify, enhance, classify or otherwise process an existing corpus of human-readable text in such a way that the grammar and structure of the prose is greatly simplified, while the underlying [meaning](https://en.wikipedia.org/wiki/Meaning_(linguistic\)) and [information](https://en.wikipedia.org/wiki/Information) remains the same. Text simplification is an important area of research, because natural human languages ordinarily contain complex compound constructions that are not easily processed through [automation](https://en.wikipedia.org/wiki/Automation). In terms of reducing language diversity, [semantic compression](https://en.wikipedia.org/wiki/Semantic_compression) can be employed to limit and simplify a set of words used in given texts. &gt; --- ^Interesting: [^Concordancer](https://en.wikipedia.org/wiki/Concordancer) ^| [^Concept ^mining](https://en.wikipedia.org/wiki/Concept_mining) ^| [^Trigram](https://en.wikipedia.org/wiki/Trigram) ^| [^Speech ^corpus](https://en.wikipedia.org/wiki/Speech_corpus) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cnbgn6n) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cnbgn6n)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
I want to write a dynamic GUI with PySide that interact with FreeSwitch.
I want to rewrite an application a colleague originally wrote in C++ in Python 3.x. The application reads trace plots and real time feeds of network traffic, and does statistical analysis of the traffic as well as displays it in GNU plot. The thing is, he wrote the app piecemeal over many years, always just kludging on some new feature. He did not architect it, do any formal testing, or write any documentation. So it's about 5,000 lines of spaghetti code. So my goal is to use this as my first somewhat professional Python application. I intend to architect it...do appropriate testing...fully document it...etc. If I do a good enough job, I anticipate being asked to rewrite a number of other old, hard-to-maintain C/C++ network applications they have floating around the lab.
Understanding python internals, I started reading this series of posts about cpython http://tech.blog.aknin.name/category/pythons-innards/ and looking at the code. Brush up on my C programming skills and maybe even try to contribute.
Pyparsing.
I have a finance degree and changed careers over the past two years (I'm 25). After 6mo I had an internship, after 9mo total I had my first full time job as a programmer. It's definitely doable. I started a degree in CS but canned it as I noticed quickly that experience is significantly more valuable. I may get a maters some day of the lack of a degree is an issue, but so far no one outside of one company I spoke with had any concerns.
It's public, but I haven't linked to it here.
&gt;ran a script that destroyed his desktop how?
Take a look at [Celery](http://celery.readthedocs.org/en/latest/). It might seem a tad complex, but the [first steps tutorial](http://celery.readthedocs.org/en/latest/getting-started/first-steps-with-celery.html#first-steps) will help. The basic setup here is that you set up a task queue; in your Flask app, the function for that particular endpoint should add the task to the queue and then return a response. The Celery workers then consume the queue.
yes i think so, there are some python books in there, a django one and one about machine vision
38 yo, 26 in the field, still don't have any degree and so far I never had any problems getting a job.
I simply made a challenge, and I'm googling as I go. My challenge is to make a home controller for my room. It'll turn on the lights when I'm home, and double as a home security for when the door opens and I'm not home. 
How hard was it to learn programming without any schooling behind it? I know this is a broad question but if I learn python per say can learning c++ become easier? Also what is the general staring salary for a programmer, I know that's a broad answer also just looking at the ballpark of things right now. I'm tired of slaving away in factories and want to learn something new.
verbatim response: "BAHAHAHAHAHAHAHA!!!!!"
I am familiar with regular expressions, I just always think of this quote: Some people, when confronted with a problem, think “I know, I'll use regular expressions.” Now they have two problems. Seriously though, you are right. It might be the best solution for this problem. 
Pillow is great. I just wished they added dicom support in the future. At the moment, pydicom and wand can be used to work with dicom, but it would be cool to have this in pillow as well.
To work through this [book](http://it-ebooks.info/book/2467/) and apply the principles to my job as a Data Analytics Engineer.
Yes, very possible.
My advice is to first pick up a book containing interview questions (there are literally dozens of such books on the market), and see how you would perform. If you are completely lost and can't get past the first question, at least, you'll know what you need to work on. If it's easy peasy, then you should be good to go. Additionally, I would recommend to begin building up a github portfolio either by starting your own open source projects or contributing to other projects you find interesting. Similar to above, if you find that it is difficult for you to contribute to existing projects, then you will gain an idea of what you need to work on. Whatever you do, you will need to fully focus on this to make it a reality. Good luck!
&gt; Pillow is great. I just wished they added dicom support in the future. There might be a greater chance of that happening if you opened a bug on the tracker, because there isn't any bug or PR related to dicom at the moment, open or closed. Of course there'd be an even greater chance for that to happen if you either contributed a greenfield implementation, discussed, used and merged an existing dicom implementation (beware the licensing issues) or built one based on GDCM or DCMTK. Either way, nobody's going to implement that if they don't need dicom and have no idea anybody even wants it. 
&gt; I just always think of this quote: Some people, when confronted with a problem, think “I know, I'll use regular expressions.” Now they have two problems. Those people must not know regular expressions very well. 
Is my age (28) something that would turn off possible hiring managers? I have a lot of willpower but sometimes my motivation is kicked down because I have taken so long In life to learn something valuable. I currently work as a quality inspector at a machine shop and I have this feeling of being locked in a box with no where to go.
I'm really interested in this. I only know python 2.7 and haven't done anything in 3. If there is anything I can do to help mail me.
Is there a link where you don't have to sign in?
The best bet is to actually build a portfolio or have something to actually show people, that's the easiest way to show an employer that you know something.
Seriously? To even just view the gist? I'll copy and paste the code here, but gotta warn you, it's pretty long... #!/usr/bin/env python # -*- coding: utf-8 -*- """ pip install networkx distance pattern In Flipboard's article[1], they kindly divulge their interpretation of the summarization technique called LexRank[2]. While reading Flipboard's article, you can, if followed point by point, reimplement their summarization algorithm. Here are the steps/excerpts that stood out to me: 1. We model sentences as bags of words 2. The strength of interaction... [can be measured by] standard metrics for this, such as Jaccard similarity... Note: We skip the normalization step 3. The normalized adjacency matrix[3] of the graph is... 4. We can compute the PageRank centrality measure for each sentence in the document. [1] http://engineering.flipboard.com/2014/10/summarization/ [2] http://dl.acm.org/citation.cfm?id=1622501 [3] http://en.wikipedia.org/wiki/Adjacency_matrix Note: The following pictures help visualize the mirrored for-loop(?): http://en.wikipedia.org/wiki/Adjacency_matrix#Examples I dont know what the technical name is for that double for-loop. If anyone knows, please send your answers here: https://twitter.com/rodricios """ import distance, operator import networkx as nx from pattern.en import tokenize from pattern.vector import Document,LEMMA def summarize(text_to_summarize): stokens = tokenize(text_to_summarize) # STEP 1 # pattern.vector's Document is a nifty bag-o-words structure, # with a TF weighting scheme docs = [Document(string= s, name=e,stemmer=LEMMA) for e,s in enumerate(stokens) if len(s.split(" ")) &gt; 7] linkgraph = [] # STEP 2 and 3 happen interwovenly for doc in docs: for doc_copy in docs: if doc.name != doc_copy.name: # STEP 2 happens here wordset_a = [x[1] for x in doc.keywords()] wordset_b = [y[1] for y in doc_copy.keywords()] jacc_dist = distance.jaccard(wordset_a, wordset_b) if jacc_dist &lt; 1: linkgraph.append((str(doc.name), #index to sentence str(doc_copy.name),1-jacc_dist)) #dist. score # By the time we reach here, we'd have completed STEP 3 # STEP 4 #I referenced this SO post for help with pagerank'ing #http://stackoverflow.com/questions/9136539/how-to-weighted-edges-affect-pagerank-in-networkx D=nx.DiGraph() D.add_weighted_edges_from(linkgraph) pagerank = nx.pagerank(D) sort_pagerank = sorted(pagerank.items(),key=operator.itemgetter(1)) sort_pagerank.reverse() top2 = sort_pagerank[:2] orderedtop2 = [int(x[0]) for x in top2] orderedtop2 = sorted(orderedtop2) return " ".join([ stokens[i] for i in orderedtop2 ]) if __name__ == "__main__": text = 'Someday I will have a place to put all my collections.\ It will most likely be my basement, or a little corner of my \ basement. But I didn\'t write Star Wars. If I had, I might be \ able to build a museum on the sparkling lakefront of Chicago, \ right next to Soldier Field. George Lucas did write Star Wars, \ and his art and memorabilia collections will be housed in his \ Museum of Narrative Art in the Windy City. Lucas just \ announced that Beijing-based MAD Architects will design the \ museum, while Chicago firm Studio Gang Architects will be \ responsible for the surrounding landscape and a pedestrian \ bridge that links nearby peninsula Northerly Island with the \ city. It should be a stunning addition to the collection of \ shoreline museums, but it has encountered opposition from \ open-space advocates and Bears fans, as the museum will \ occupy part of their tailgating field. In honor of the \ Museum of Narrative Art and its star-studded cast of \ architects, here\'s a roundup of articles from Architizer \ that feature Star Wars-related architecture: Jeff Bennett\'s \ Wars on Kinkade are hilarious paintings that ravage the \ peaceful landscapes of Thomas Kinkade with the brutal \ destruction of Star Wars. It is not unlike a contemporary \ rendering, which combines Sci-fi and Romantic notions, and \ we have examples with ratings. Ra di Martino, a visual artist \ and filmmaker, found the ruins of Star Wars sets, and \ photographed them in her two series, No More Stars (Star Wars) \ and EVERY WORLD\'S A STAGE. These haunting images show a world \ far, far away, now left as ghost towns. These haunting images \ show a world far, far away, now left as ghost towns. We \ explore the designs and the blueprints behind the architecture \ of the Rebel Alliance and the Empire. Artist \u00E9 Delsaux \ photoshops Star Wars characters and ships into everyday \ environments. Stormtroopers roam parking lots, the Millennium \ Falcon visits a Dubai construction site, and the Emperor lurks \ in the suburbs. Aedas appropriates the Sandcrawler for an office \ building, but replaces the weathered, rough brown material \ (COR-TEN?) with shiny glass and the treads with landscaping. \ The story of artist Ralph McQuarrie, the man who helped \ George Lucas realize his visions.' print summarize(text)
Why?
Agreed. PIL was always a weird thing in that it was a hugely important library (the standard image manipulation one that most things seemed to use), but had very poor performance and was basically a dead end project. I love that pillow's moving forward, hopefully PIL just becomes obsolete and people can just start using pillow from the get go now.
Who's "we"? Everyone has different needs, and there won't be a consensus on the topic for another 5 - 10 years until 2.x is finally in the grave. But most of the major libraries have been ported to Python 3 by now, so there are far fewer excuses these days for using 2.x, but there are still a few holdouts. If you absolutely, positively must use one of those modules, then you're stuck with 2.x. Another reason might be that you are forced by the company you work for to use something like a RHEL system and you can't install non-RHEL packages. Enterprise distributions take forever to transition. If you're an absolute beginner and you're using learning material that assumes 2.x, then you should also use 2.x. Try to find better learning material though. (I consider LPTHW to be very poor learning material.) Otherwise, there's really no excuse for not using 3.x. It fixes a lot of design blunders.
What is considered "knowing" something? Per say if I learn the basics of any language would this be enough to get me into an entry level position? Thanks
&gt; ...it is always nice to see with how little effort programs based on complicated algorithms can be rapidly prototyped in Python! That's one of the many beauties of Python! I mean, it's one of those languages that just, you know, makes people smile :)
&gt; which one has more job security If you want job security, the correct answer is "All of the above."
Believe it when I see it. Pillow is a nightmare of dependencies for Django developers. 
If that was the case i would also learn every single language.
Limit yourself to the ones you have an immediate use for or are curious about. It saves energy. 
fuck lol i dont immediate use for any of them, just wanting to learn
Isn't that a pretty specific use case best suited to a specific library? I consider pillow to be far more general low hanging fruit image processing.
nice, thanks!
Pure python? Wouldn't this be slow as balls compared to OpenCV? Python is a nice language to read and write in (so, good for a book in that sense), but when it comes to heavy lifting in python I really appreciate that there are so many C and C++ libraries with bindings all ready to go.
Thanks
As weird as it may sound, yes, since I was 12. I did a course in dBase III Plus and the guy was looking for another Clipper developer. Since dBase and Clipper have the same roots, I offered to take the position. It was a long time ago and laws around here (Brazil) were way lax about this. Today a 12 yo wouldn't even be able to get an apprenticeship.
[CheckIO](http://www.checkio.org/) features a lot of applied challenges to solve (with some hints and pointers to the official documentation). What I mostly appreciate is that: * it covers most core Python features (string processing, syntax, tricks), * there is a rich diversity of challenges (text processing, pathfinding, arithmetics...), with an increasing difficulty, * once a challenge is solved, you can see other peoples' solutions, and improve your knowledge of the language. If you're into maths, you can use Python to solve problems from [Project Euler](https://projecteuler.net/) ;-) This way, you will become familiar with: * the language, * where to find information in the documentation, * where to find applied examples (which in Python, tends to be either [GitHub](https://github.com/) or [StackOverflow](http://stackoverflow.com/)).
https://www.youtube.com/playlist?list=PLdNh1e1kmiPP4YApJm8ENK2yMlwF1_edq here's the kivy crash course series by Alexander Taylor, i dunno if this helps.
I don't feel MechanicalSoup is abandoned. Plus, being based on requests and BeautifulSoup (in fact is just one file with those two imports) it will be pretty easy to maintain it yourself. Anyway RoboBrowser looks like a good choice and having many issues not necessarily mean low maintenance but also popularity. Most issues at RoboBrowser are requests for coding support.
You can try [Babel](http://babel.pocoo.org) which does locale aware parsing of many things. 
I've seen this already. I forgot to mention, I'm looking to develop a game using Kivy. So I need a tutorial that focuses more on that aspect, than on the GUI elements. 
Use events. Rather than blocking the initial response while your application is performing long running tasks, you may trigger an event that initiates the computations and serves up results as they become available.
+1, Agreed especially with going the Python way if you may want later to develop not for the web. Ruby is definitely capable of being used as a general-purpose language, but Python is much more popular outside of the web.
What is your background? Are you totally new to databases and SQL? If so, there is a huge learning curve to learn about analyzing data that is "too big". Especially if hadoop, map reduce, distributed computing, etc sound strange to you. If new to databases, I would start off learning how to use sqlite3, learn SQL, then progress to full blown database servers. Then learn about distributed computing maybe with a few raspberry pis so that you have full control over whats going on instead of using a 3rd party company like Amazon.
Hard to tell, you'll have to look at what's going on in your area. Look at job offerings, or even make 2 fake LinkedIn accounts to see what the head hunters go for ;-) If you don't care about place, just play with both and see which one you like more (but be sure to not only look at the language, but also at tools, libraries and community - in the end those make up a big part of your experience with a programming language).
[Celery](http://www.celeryproject.org/) is the best, but if you don't want to to use it, take a look at message passing library such as [ZeroMQ](http://zeromq.org/) to built your own lightweight broker and workers.
Isn't the content a bit complex to go through by yourself?
Hi, I have been working with Django for the last 4 years. Personally I think to learn Django its something very enriching and you do learn a lot from not only knowing its API but also looking into Django's source code. I'm a contributor and worked two years on Tangent Labs, the company behind django-oscar. I also have a lot of good things to say about it and if you diving into python and want to build an e-commerce web-site its really the way to go. They are very good but when you build a really big system django its just not the way to go as it will make things very monolithic. So you always end up trying to break things down into smaller services. For that reason if you reach the point where you know enough Django perhaps you should than try to learn micro-frameworks and other libraries that helps you to move into a more distributed architecture. I'm leaving a list of python micro-frameworks/libraries I find interesting and worth to learn: * [Tornado](http://www.tornadoweb.org/en/stable/) * [Gevent](http://www.gevent.org/) (this is the one I'll dive into more detail :) ) * [Flask](http://flask.pocoo.org/) * [SQLAlchemy](http://www.sqlalchemy.org/) * [Django rest framework](http://www.django-rest-framework.org/) For the django lovers * [Celery](http://www.celeryproject.org/) For asynchronous tasks. * [requests](http://docs.python-requests.org/en/latest/) 
The book premises one not need any background in the subject matter to work through the book, where the recommended requisites are a basic understanding of the language and at least some college level algebra and preferably calculus as well. I don't think it's going to be easy (It's not, I'm on chapter 4 now reading-wise and have completed the problems from the first two chapters), but it's not outside the realm of possibility. However, if there's any interest in a reading group I'm all for it. Perhaps a github with all the sample code as well as the problems would be handy. I like figuring things out on my own but community feedback is priceless.
 screen = pygame.display.set_mode((x, y)) # Your width and height screen.fill(#your color) 
You have to have all the opencv dlls in the site-packages as well.
Are you asking if kivy supports the desktop, or if there are any particular examples? The answer to both is yes, most kivy apps (any not using mobile-specific features) work without modification on the desktop. I think the main downside on the desktop is that it doesn't really look native (doesn't match the local main toolkit in appearance). This isn't a big issue for games or some other apps, or depending on personal preference.
I'd love to set up a study group to study this book but I'm still a bit behind you in the Python learning process. Good luck though.
And now you have two problems. Edit: 30 upvotes on a glib, knee-jerk answer, and apparently not one of these people noticed that the requirements include parsing pairs of parentheses, which regexes cannot do. This is *exactly* the sort of mindless use of regexes that Jamie Zawinski warned against. Hint: this should be valid, and positive: `((((25))))` while this should be an error: `((((25)))))` 
I'm not sure about the windows installation details. The core problem is that we need to ship both kivy and some other modules including pygame and (I think) gstreamer, which can be relatively complex to compile on windows, so I guess the advantage of the current mechanism is that it's a single download that just works. I do agree that it's not a great solution beyond that, I'm not sure if there's some problem with providing binaries but I'll ask about it. &gt; Also, any thoughts on when an executable will be able to be created using Python3 + kivy? I think most of our devs and users mainly use pyinstaller, in which sense the main barrier is probably their own python3 support. Other tools should work, I think one of the devs has recently had some success with nuitka in particular, but I think there was still some problem making it inconvenient overall. If you ask on the kivy irc or mailing list you may catch someone who has looked at it more recently, I've never packaged a kivy app for desktop myself.
I can only speak knowledgably regarding ios? never (or at least, no time soon). No one is working on kivy-ios, because no one is using it in any serious capacity. The build uses a custom patch of 2.7, and the 3x line is waaay harder to work with. I believe the android story isnt quite so bad, but also no time soon. The 3x line isnt fun to work with in this regard, and theres no overwhelming motivation to use it. 
You're asking a lot more questions than you realize. Try smaller steps by learning SQL, statistics and then ways to combine the two first.
[Image](http://imgs.xkcd.com/comics/python.png) **Title:** Python **Title-text:** I wrote 20 short programs in Python yesterday. It was wonderful. Perl, I'm leaving you. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php?title=353#Explanation) **Stats:** This comic has been referenced 102 times, representing 0.2215% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_cnc8oln)
Kivy is great, and the friendly community on IRC (and here) is a major asset to the project. Kivy's kv-language and properties + events functionality allow you to quickly build (and iterate on) views and interactions with minimal code, while still allowing you as much flexibility as desired. The documentation isn't the best place (imho) to learn the API, but it is very useful once you know how kivy works in general. I think the recommended path is to do one of the tutorials first: http://kivy.org/docs/tutorials/pong.html
Or parsing parentheses like ((123)).
You can already create windows executables with python3 and kivy, there's a guide for that here: https://github.com/kivy/kivy/wiki/Packaging-Kivy-apps-written-in-Python-3,-targeting-Windows-using-Nuitka
I spent about a year reading around the docs and random blogs to get my job done, and when I found this book I was ready for it's rather in depth primer on python itself. The entire first chapter goes through most of the language syntax and its native data structure classes like lists, sets, dictionaries, etc. I wish I'd have found it sooner... but maybe I wouldn't have been ready. When you feel like taking the plunge have a look at the first chapter. Page 7 has a handy table of the native data classes.
Well i am trying to find out what kind of independent studies i am going to do next semester. I have to just jump right in i do not have a lot of time. Also ever since i was a kid i find it hard to move on once i have questions. 
Well, I only know Python, but don't find the GUI programming part of it all that hard. At times very frustrating do a little concerns over a widget not being exactly where it should be, but conceptually the GUI part is the easy part. The fact that you arty know Java and C# suggests that should not be an issue for you. Sounds it you just need to bulldog through it. What have you tried so far?
Check out blaze, aka potentially numpy 2.0 for big data and varied backends. http://blaze.pydata.org/docs/dev/index.html http://matthewrocklin.com/blog/work/2014/11/19/Blaze-Datasets/ http://matthewrocklin.com/blog/work/2014/12/30/Towards-OOC-Frontend/
http://www.lfd.uci.edu/~gohlke/pythonlibs/#nltk
This is not the right subreddit for this question. Although you got your answer, next time post in /r/learnpython, and you'll get better results. There is also an /r/pygame subreddit.
Alright, I'll do that
See original post by the article author [here](http://www.reddit.com/r/Python/comments/2qg6fw/handling_email_confirmation_during_registration/)
&gt; dicom support Isn't dicom *the* most annoying image non-standard there is?
/r/learnpython 
https://kivyspacegame.wordpress.com/ is where I started. In general, I've stayed away from using .kv files, doing everything in pure python. (I'm currently making a game in kivy. )
Have you tried [the Unofficial Site](http://www.lfd.uci.edu/~gohlke/pythonlibs/)? If you're on a stock Python install from python.org Gohlke's site nearly always has a build of what you're looking for.
 laziness is the mother of invention :)
Which is why I asked about the input data. No method exists for extracting numeric data from unconstrained text that will *always* give the correct output no matter the input. You have to know your inputs. Since I raised the issue of decimal separators, I'd like to see your magic code to parse these: 123,999 123.999 These could both equally be 123.999 or 123999 depending on the digit separator/decimal separator in use. Without prior knowledge you're up shit creek.
If you're dealing with financial data, don't use floats. You can't represent base ten with base two, and you'll get rounding or comparison errors. https://www.udemy.com/blog/python-round/ https://docs.python.org/2/library/decimal.html 
I like to considerWe are aware that time spent building a clean solution upfront has the potential to save many hours down the road. I generally only write scripts when I have reasonable confidence they will save time in the long run. Or if the task is horrifically boring and I cannot bring myself to do it manually.
Wow. Talk about being naive. When he gets out in the real world, he will be in for a rude awaking or a low paying cookie-cutter type programming job.
What about it is naive? I saw it more as a riff on an [old saw](http://threevirtues.com).
It depends on what libraries you plan on using. What sort of work are you hoping to do with Python?
Go with Python. Unless I'm horribly misinformed, Rails is the only thing really keeping people using Ruby nowadays, and Python is a lot more versatile insofar there are both more and more varied modules written for Python. 
3 has really closed the gap with 2 in terms of library support. Even a couple of years ago it was still pretty bad, now there's much less reason to use 2 unless you know you're going to need a specific 2-only package. It's also not a huge deal to switch to 2.7 for a project if you discover a package you need that doesn't support 3. It's not totally painless to use 2.7 after only using 3 but you're not talking about learning C++ on short notice either. 
Agree that programming is still a field where being able to walk the walk is the only thing that matters to most employers, but in today's environment you're at it severe handicap for getting the interview in the first place if you have no college degree whatsoever. 
I've used both, and I prefer Pyramid. Here is the train of thought that led me to this. * At first, I thought I wanted an "all in one framework". Looking around, I was led to Django. But after using it for several months, I realized that wasn't really what I wanted. * The reason is that the "web" is not really a single thing. How you handle persistence shouldn't really have much to do with how you handle URL routing. So, I realized that I really wanted a loose collection of tools. They needed to play nice together, but be able to swap out the different pieces if necessary. * The reality is that you really want several different tools (ORM, template language, URL routing, web objects (forms), and authentication/authorization) with some lightweight glue holding them together. * With this new way to looking, I was led to Pyramid and really liked it.
While I'd commend you on your undoubtedly great effort, I think this is misleading. First, print debugging only really works for "batch" programs, not in "reactive" ones. Second, print should be used to either write results or draw a UI, show updates/feedback for long-running batches, or, at least on POSIX systems, for errors/warnings - and nothing else; For logging and debugging, do use logging. Third, any serious programmers should know how to use a debugger better than their editor, so this "print debugging" stuff might be putting newcomers on the wrong track right there... 
&gt; You should always use a virtualenv. Always? One counter-example: My preferred Python env/packages for doing administrative stuff. Why would you put that in a venv? And then have to refrain from rc'ing it? Other cases (quick scripts, e.g. for the E and T steps in ETL, that require stdlib deps only) come to mind, too, obviously. 
That is exactly why venv by default "insulates" you from already installed site packages. So apart from throwing everything into your base installation, there is nothing wrong with having a few worthy goodies there!
im kinda in the same situation, i still need 3 courses to finish my computer science degree but im tired, and i program in my free time, mainly python/django, tried like..7 or 8 interviews, nobody wanted me because i had no degree...
Could GAE run PhantonJS as the browser and drive it with selenium? I've done that in the past but not on GAE
I'd like to give you a different take in reply to the overwhelming "use venvs only" hardliner opinions here. There is actually nothing wrong with having your top favorite packages installed locally (but do use --user, as already suggested here, if you're not the only one using that machine). I have my favorite heavy-weight libs pre-installed (scipy on ATLAS...) and let them leak into my venvs when I just am researching in experimental mode. Saves me a ton of time waiting for a disposable venv to actually become "usable". As I pointed out already, by default a venv even insulates you from local site packages and you have to pro-actively enable this leaky behavior.
Nope
Looks like there's a GUI designer for Kivy, no idea how stable it is: https://github.com/kivy/kivy-designer As far as desktop-only Python apps go, there are some other options: * Python comes with Tcl/Tk for cross-platform GUIs, but it's not really modern. Good if you can't install extra libs. There's GUI builders out there. Docs should come with Python. * wxPython provides bindings for wxWidgets. Gives native look &amp; feel. wxGlade gives you a GUI builder. * PyQt, PySide, or PythonQt bind to Qt. Native L&amp;F. I think you can use the Qt tools to build GUIs. * PyGTK binds to GTK. I think you can use Glade to build GUIs.
Nearly thirty years doing this stuff, and I have YET to have a single day where I went home after work and didn't keep right on thinking about the problems I'm trying to solve. I doubt if bakers/carpenters/whatever do the same. Also, wtf kind of school is he going to, where he isn't busting ass outside of class on the class assignments? Is it really that different now?
LoL, forget classes! I guess I can just write my way
It was the latter, thanks!
I appreciate your comments. You might be right about the "correct" use of printing and its role in debugging, I don't really know. I made this mostly for myself, implementing features I'd use and so it is more opinionated. As to your comment about newcomers, I have only been programming for 3 years, so I'm still learning myself =) 
I've taken programming classes every semester in college so far. Iv'e had to bust my ass every day to get something that I MIGHT be able to turn in. This last semester there were weeks where I spent probably 20+ hours on the homework for class. 
&gt;Programmers’ lives are devoted to eliminating repetivity. Aren't we supposed to make programs simpler so as to be more efficient and faster. The more repetitions there are, the more steps are needed to finish. 
The performance only suffers on that loading screen I've found. My apps are quite responsive once they have loaded. I have not done much investigation into CPU usage, however.
Try this example: http://programarcadegames.com/python_examples/show_file.php?file=instruction_screen.py
I know you didn't ask about it, but have you considered Flask? I've used it for several projects of various size, and it can really easily be whatever you want it to be. There is a healthy application ecosystem, and a core of developers that contribute to it that is very strong and diverse. If you use Flask-SQLAlchemy and Flask-RESTless, you'll have an extremely flexible CRUD REST API up in absolutely no time. Flask-Security bundles together some other great libraries to provide user authentication and management, along with a host of other features. Flask is an extremely customizable and powerful framework. It can be whatever you want it to be, but it also has those sensible defaults that make it great for just getting up and going. I've built three apps that provide the backend for AngularJS web applications, and it's just great!
I would take a look at flask.
PySide/PyQt is a great GUI library for desktop apps.
If you like to be more hands-on with the data you're gonna be working with and prefer Python's ecosystem, I would look into using IPython notebooks and the Pandas library. You can also work with R from ipython to take advantage of all the stats libraries available to R and work with a saner syntax of python.
That's what I have: pyramid RESTful + AngularJS. I would recommend Pyramid but only if you know what you are doing and are willing to invest time to mess around. However if it's a single page app, sounds like you are prototyping. Then Django also makes senses - quick and you can do multiple round of exp. Either way, just do it!
It's closer to webapp2. Django includes a lot of stuff "in the box" to build python websites quickly. Unless you're trying to build that kind of website, Django is too bloated and you'll be learning a specific set of tools that you won't use outside of Django development. Plain Flask, on the other hand, is solely centered around handling http requests. If you want templating, you'll have to include it explicitly. If you need to access a database, you can use whatever solution that you'd like - an ORM like SQLAlchemy, or just straight db calls. Flask is very popular and well-supported with a large community, and from everything I've read easier and 'more Pythonic' than webapp2. Final thoughts: - If you're experienced enough, you should be able to pick up any framework pretty easily. Don't pigeon-hole yourself by 'specializing' in any of them. - It's smart to know Django if you're looking for freelance work. Many small shops will use Django for simple interactive websites, so there's always work available. - On the other hand, if you need to set up a REST API, or do something more specialized, Flask is definitely worth looking into. If your project doesn't fit well in Django's model, you'll find yourself wasting time and energy fighting with how Django expects you to structure things.
Chef, puppet, sass, redmine, discourse...
Thanks a lot for the insight and the analysis. I'm probably going to pick up django to some degree anyway, if for no other reason than to follow that neat ["Test Driven Development with Python"](http://chimera.labs.oreilly.com/books/1234000000754) guide over there in the sidebar
Short answer: Flask Better answer: use Flask but make intelligent design decisions and don't just use a module or library for everything. I liked a lot of what Steve had to say on web frameworks. Especially the points on what's not important. Throughout my time with flask I have really only ever used an ORM (SQLAlchemy). The built in Flask sessions oddly choose to store everything client side... So I use Flask-Session to store sessions server side. Things like WTForms (form creation and validation) get in the way more than they help in my opinion. You get a lot more control and general web knowledge by just hand writing your forms and the code to validate them. Caching is available through Werkzeug although I haven't used it and can't really comment on it. Sometimes magic is good. But you don't learn anything with magic. Which is why i actually suggest PHP to people developing their first websites. You will absolutely trip over yourself with PHP but you'll be better for it in the long run. 
Welcome to Golang! Just kidding! Most setup scripts use distutils (or setuptools) in conjunction with their setup.py script. Here is probably the best example I can find : https://docs.python.org/3.3/distutils/introduction.html#a-simple-example Also if you are developing for windows take a look at: bdist_wininst Edit: I unfortunetly not quite sure of the order in which packages are installed I imagine it retains the order of how it is listed in the setup script??? 
&gt; Most setup scripts use distutils It may be useful to point out that although `setuptools` has long since replaced `distutils`, there is still plenty of software packaged with `distutils`. You'll know you've stumbled across one of these when `setup.py develop` doesn't work (since `setuptools` added it to the usual list of verbs).
You haven't "defined" your environment? What does that mean? First, you haven't told us how you're running the scripts. Are you executing scripts from Windows' CMD using `python script.py` ? Are you using Python's interactive mode? Second, what do you mean the print commands don't work? Are they just not showing up while everything else seems to work? Again, how are you invoking the scripts? Lastly, as per the sidebar, consider visiting /r/learnpython
Thats a great point, thanks.
Pyramid's auth and session systems are a massive headache for me. There is basically nothing completely usable 'in the box' and even the recommended add-on is deprecated/abandoned (beaker). I rolled my own with a lot of copy and paste but am unsure how secure or robust it is.
If you are making a CRUD site, Django rocks. If you're not, then Flask might be better. I would definitely learn both. And also learn how to make a agnostic Python class library with tests that could be used by either. 
I was thinking of the same question for a while. When I thought I'd settle on flask, I started having second pragmatic thoughts. When your project matures and you will be looking for other people to work on it, the talent pool will be more Django orientated. It will be easier to find more people with Django experience. Naturally good python devs will be able to work on any framework but it will be easier to hit the floor running using Django. So in my case (single page app, api layer, Javascript based ui) I'd go with Django and DRF. 
Sorry about spacing, copy and paste did that ☺ Thanks for pointing me to that subreddit ☺ What i wanna do is send (via serial interface) a string of mixed chars and 2 hex values in one shot. Using 2 separate 8 bit hex works ok, but now i need to use 16 bit values.... 
I've always found [Steve Lott](http://slott-softwarearchitect.blogspot.com/) to be pretty good. Check out [Mastering Object-oriented Python](http://www.amazon.com/Mastering-Object-oriented-Community-Experience-Distilled-ebook/dp/B00JVQ14UO/ref=sr_1_2?ie=UTF8&amp;qid=1420281743&amp;sr=8-2&amp;keywords=lott+python) 
Cool story bro
Do you have a github repository or something? I'm pretty experienced with setting up cython installations and I'd be happy to help. 
It really depends on the project you are taking. If you think you can do with a Django style framework, I'd propose taking a look at web2py. It is suprisingly complete and simple. Its DAL (Data Abstraction Layer) is not an ORM, but I find this a good thing. It's very pleasant to work with -- much more than Django's ORM in my opinion. The mailing list and community are extremely helpful. If you read about it, you'll find a lot of negative opinions - mostly from matushiko (Flask) and jacobian (Django). Their criticism is interesting but proves out to be purely theoretical, as the doom prophecies that should have applied to every web2py user failed to materialize. And if you want simple low level - I urge you to look at bottle. It does extremely little, but it covers everything that's needed to start hacking a web app.
Celery is very easy to setup and run. You can have a Celery + Flask/Django/Whatever in just a few minutes. They really did an amazing job with it. Iv've successfully used it even for quick just for fun projects that you see at hackathons. Celery also has a scheduler (celery beat) that can run/trigger other tasks similar to what cron does. 
Ahh gee mate. This is gold! Thank you!
The cookbook sections on authentication don't mention sessions. The sessions section says "Pyramid uses Beaker sessions". Beaker hasn't been updated in 2 years, and pyramid_beaker is essentially abandoned by its creator (https://groups.google.com/d/msg/pylons-discuss/KPOI21g2iW0/kdsybQHeFeYJ) so as far as support is concerned you're left high and dry. This reminds me a lot of how Turbogears used to be. It got released to the public as a full and usable stack but people stopped supporting bits of it and even the creator moved on. The community quickly partitioned into those who already understood it well enough to find it useful, and those who faced a daily struggle trying to find enough up-to-date documentation and supported packages to get anything done. Transitioning from the 2nd group into the 1st requires a lot of patience.
Py3: print("word") Py2: print "word" Stay with 3!
Also note that distutils by itself won't do shit about dependencies. Which is why everyone has setuptools installed and it takes over from distutils by force to make a tonne of things better. If anyone is asking "Why haven't we just improved distutils in python itself?", it's because python itself is a slow moving thing, and when you release a new major version, you have to get everything right with all the features you add in that major version. Python packaging has a hell of a lot of ground that it *has* covered, and *to* cover, and it's not likely that the volunteers doing it could get it right all in one go in a release (distutils2 was an actual thing that indeed tried and failed), which is why pip and setuptools improve themselves iteratively in separate releases.
You can use the `setup_requires` keyword for `setup()` to require packages that must be around *before* the setup() call supposedly even happens, which setuptools through some black magic will do for you. i.e, if you're planning your tool's majority use case to be installed from source, through pip, in which compiling with cython is needed, you can add `cython` to `setup_requires` and it'll just be there for the install proper.
It's pretty weird that distutils is as bad as it is, though. Consider that "requires" keyword. The docs don't say so explicitly, but they certainly *allude* to the idea that this will install dependencies. Instead, it's ignored entirely! This has been the case for *years*, and the docs are not updated?
I read some people were having issues with some of the functionality if they installed it via pip and recommended installing it from source. During my troubleshooting I did manually uninstall the module and install it via pip. The problem persisted but was solved when I changed the file name.
Matplotlib finds itself in a similar situation, check out this link. https://github.com/matplotlib/matplotlib/wiki/MEP11 
!!! I went to get you a build log of why that didn't work, but, even better --- it did! I think I had a variety of other problems, principally working with an old version of setuptools. At some point decided that an old bug report I read of people having problems using install_requires in conjunction with setup_requires applied to me, when it didn't. Thanks!
Ahhh, so you've discovered trying to get things right with compiled C stuff. This is where standard python packaging isn't the bestest, to put it nicely. Straight python things its ok at now, but making compiling C stuff work (remember 2/3 of the major platforms Python installs on and supports don't come with a C compiler by default!) is a *little* harder. Even trying to support linux is crazy, because ummm... *which* linux distribution are you on? Oh, and where exactly did it choose to put its headers and libraries? Oh, and did it choose to install python with headers like in the vanilla source distribution, or separate those into a separate package that the user probably hasn't got installed yet? Or is this BSD which looks mostly like linux except `$CC` could be `clang` instead of `gcc`? yada yada yada...
There's also the [generator comprehension](https://docs.python.org/3/reference/expressions.html#generator-expressions) ("iterable comprehension") that is seldomly talked about: (x * 2 for x in range(10)) This returns not a list but an iterable/generator, which can be very useful when working with lazy (on-demand) streams of data.
Get on #pyramid freenode IRC for help. No sense in flailing here.
Very nice and clear explanation.
Ah, so that's what it's called, a *generator expression*. Thanks!
Webapp2 is amazing
&gt; Pyramid ships with client-side sessions (via cookies) out of the box. Along with a big warning telling you not to store anything secret in it, or anything that *might* serialize to more than 4K, and basically not to use it except for the most trivial apps. &gt; The person you're quoting in that link is me, and I think the stuff in there self-explanatory. Quite.
If you are looking for a job, I've been getting hit up non-stop by recruiters for Django positions in NYC. I use Tornado at my current job, but Django's really hot in the NYC Python market. I don't see much for Flask. If you know enough Django to talk about it in an interview, you can probably get a Jr. dev role.
If you want to be a web developer, don't sink your time into any one framework. Web frameworks have different strengths and weaknesses and you don't want to end up being a $Framework-Dev wildly swinging around the hammer that is your framework because you have stopped seeing anything but nails a long time ago. Take a look at different frameworks, choose three and build something simple like a blog in each of them and an API as that is a common task. Make note of the differences between the frameworks and form your own opinions. In the long term keep up with security issues and major changes in the frameworks, learn about them. In case of major changes take a look at the problems they solved and consider whether other frameworks could benefit from similar changes.
I totally spoke too soon =/ I didn't update the travis.yml file, so I was still loading murmurhash first. This is what happens when I use setup_requires: https://travis-ci.org/syllog1sm/preshed/jobs/45779322
As a Jr., you're probably not going to get any help relocating. But I got my first programming job after a few months looking having been self-taught. This was years ago. It wouldn't have taken as long had I made the career switch any time recently. Do some side projects or contribute to some open source projects, make a resume with some buzzwords, know how to answer some interview questions, and start applying. Recruiters are scum, but they're getting paid when you get a job so they will put in some effort for you. Don't be upset if your first job is terrible, just use it for experience and start looking for something better after you get more comfortable working on a team. Never ever stop learning. Good luck in your search.
The problem is with messing up with SQL is that as a team, you will need to heavily rely on people who can write SQL vs let everyone writes the same python code. Thus I argue to use a good and powerful ORM in the first place, and only mess with SQL when there is absolutely nothing you can do it by using the ORM. 
Seconded. I've used it on Mac, Linux and Windows and there's no difference once it's setup.
Using what encryption method? There's any a hundred ways to do this depending on your application. 
I think that project is now abandonware :-)
Interesting to hear there's a new version about to be released. I've been following Kivy for a while but the direction of the project isn't entirely clear - it might be an idea to have a roadmap on Github or the main website.
This. 
basically yes its for learning purposes. iwant to read in as ascii then do something like a ceasar cipher or something a little more complex but its just the coding part which im not sure about 
@skiddleybop You can also check out doing it with web2py I give you both CLI and web2py examples. http://www.sifizm.com/python-and-rss-reader-from-reddit-then-web2py/ 
Nice. I look foward to read the rest of tutorials.
what has this got to do with python?
&lt;humor&gt;Yes, always make sure you use standard, NSA-hacked encryption systems&lt;/humor&gt;
You might want to look at [cryptography](https://cryptography.io/en/latest/)
Man I dunno. There's benefits to learning and reading the benefits and drawbacks to doing things a certain way. Sure it comes off as super negative, but it's not like we should be totally ignorant of things like this just to be a little happier. Python's definitely good enough right now, but why not try to make it a little bit better, or allow someone else who could a way to learn more.
Game Example (Not Mine, one of KivEnt's users): https://play.google.com/store/apps/details?id=org.chozabu.boardzfree Is built in Kivy and was alpha-released just a week or 2 ago, still its fairly polished and fun in its current state. It does a good job of showing off that even highly interactive and large scenes can be done in python.
This is promising. What else do you intend to add? I can see a Todo list of sorts for Abelian groups and monoids.
1. Stop scraping the web as a first resort, everyone! I swear 10% of this sub is about web scraping. 2. http://lxml.de next time
1. Everyone's gotta start somewhere. Scraping the web is a fun way to get started without needing to know too many modules. 2. lxml for web scraping? Really?
So, lxml for web scraping? Really?
I'm working in webscraping right now and tried to use lxml directly but turns out it explodes with mismatched html. Googled around, tried an attribute to ignore errors but it still exploded. BS4 has given me no issues. 
There's an [outline](https://gitlab.com/lysa/lysa/blob/master/outline.md). It's very out of date, but it nonetheless contains a rough layout of my ideas for the book.
I still see so many tutorials and github pages with `easy_install $packagename$` on their page. Could cause more confusion pulling that out underneath people. Maybe they could solve this by in-place replacing easy_install as an alias of sorts to just call pip for the job?
The website is built in python ? 
If you're using NoScript, that's probably it. 
I am not running NoScript, and i also tried to run it with firefox safe mode and i still have the same problem
Or if that's not possible due to fundamentally incompatible behaviour (I'm not enough of an expert in both tools to know for sure), the PyPA team could ship an `easy_install` that simply prints "This tool is deprecated, please install `pip`.", or even allow a 1 year grace period where it states that it will be deprecated by such-and-such a version.
What happens in chrome? Are there any errors in the developer tools? 
I have the same issue with chrome too, and as far as i can tell there are no errors in the developer tools
Edit- That is also not the problem
miniconda then used terminal to install ipython using conda "conda install ipython"
Most math books take on a formal tone because mathematics is a very formal field. I guess I would say be sure that you don't sacrifice any rigor at all in the name of making things "more accessible" because you're not doing anyone a service at that point.
Oh definitely. The goal is to make things easier to understand, and rigor helps with that. My issue is with books that are formal to the point where it hinders the reader's understanding. That's what I'm trying to avoid. In cases such as definitions, theorems, and proofs, it definitely helps to use very formal, precise language. Outside of those, it mostly just gets in the way.
I don't understand why this is getting downvoted. This has literally nothing to do with Python.
There's no python installer for Linux (unless you count package managers like portage or apt) ;) 
There are a few major reasons for this: * The simplest is simply backwards compatibility, anyone who currently types ``easy_install`` would be broken by this change. * There are [use cases](https://packaging.python.org/en/latest/pip_easy_install.html) covered by ``easy_install`` which do not work in pip. The major one is multi-version installs for which pip recommends using virtualenv instead. * Pieces of other tools use parts of the ``easy_install`` command (e.g. buildout). * Simply removing the ``easy_install`` command doesn't stop setuptools from essentially doing the same thing in *other* scenarios, like ``setup.py install`` triggers the same sort of installation as ``easy_install``, should these be removed too? They have their own problems which can be even harder to solve. None of these issues are ones that are particularly impossible to solve (in some cases the answer would be we aren't going to solve them) but figuring out the correct upgrade path and how to handle it is something that nobody has really stepped up to do the work needed to figure out what will break if we do it, the best way to mitigate that situation, advocate for their position on the answers for the questions, and finally to write the code once some path has been decided on.
Note: Be prepared to revise any OOP principals you may have learned using other languages as Python OOP may have different emphasis, (for example on privacy and Duck-typing). 
You might try creating showpieces that employers might like. Create an app. Create a shopping site. Control a robot... Do something were you can then say "look at this,. If you like it, we could talk contracts". 
Can you post a spec for the conversions you require?
Thanks everyone for all the advice. This has been really helpful.
What's wrong with using mechanize+beautifulsoup?
In a nuthsell: - installs to a different location to what you might have expected - binaries are now signed - Uses a web installer instead of single monolithic installer (*sigh*. so cool. like pro and stuff) - Installer now uses checkboxes! I guess it's nice to see the windows installer getting some love. /shrug Mostly seems like house keeping. The changed install location is going to generate some irritation I'm guessing, since 90% of the install advice on the net is currently 'add C:\PythonXX\ to your PATH', but overall these seem like good changes to me. ...kind of wish it was all part of a single consistent build infrastructure using something like cmake to generate installers though. :/ 
Most non-Windows users install Python via their OS packages or it comes pre-installed by the OS vendor. This makes any non-Windows installer largely academic.
Yes, but OS vendors won't use it because their have their own tools and layouts. That makes it not matter what Python uses for those platforms.
Have you sent that feedback to Steve Dower?
I'm not particularly interested in Django. I'm interested in being able to do useful things with sessions out of the box, like I could with PHP 15 years ago.
AuthTktAuthenticationPolicy could perhaps take an optional pair of `encrypt, decrypt` callbacks, then the developer could use the encryption library of their choice. But I think that is stepping around the fact that server-side sessions of some sort are usually preferable, where the cookie just holds the session ID (plus hash, etc). The main problem I faced was that I had to basically copy and paste AuthTktAuthenticationPolicy and twist it to my needs because the details of authenticating a user and storing session data for it are all rolled into one place. (Plus I had to modify it to not auto-create cookies on every login for legal reasons; though that issue has subsided now.) I'd have liked a system where Pyramid handles the session ID auth but has a pluggable serialization system where you just inject the read/write functions you need for your session. (eg. A simple `shelve`-backed session store would bring feature parity with PHP etc.) Perhaps that makes it harder to support sessions stored entirely in the cookie; but that seems a small price to pay.
Mailing lists? Now there is something I haven't interacted with in almost 20 years.
CMake exclusively would be great, but dealing with visual studio and forcing specific command line flags and other advanced options into the compiler for MSVC is apparently HUGE problem with CMake. 
&gt; since 90% of the install advice on the net is currently 'add C:\PythonXX\ to your PATH' That's because the installer didn't set up your PATH for Python until relatively recently, due to some strange stubbornness among the maintainers. That's been rectified in recent years so this shouldn't be a problem.
Honest question: What benefits do I gain by putting Python (or any programs) into "Program Files"?
Err... GPG?
For my money, PIL is already obsolete and Pillow is used from the get go.
Looks nice, but shouldn't you call it S(tub)Object? More on the ever-confusing terminology here: http://martinfowler.com/articles/mocksArentStubs.html
Can we PLEASE have adding python to PATH by default? Otherwise when telling students to chuck `python` in their console, we'll still have all the Windows users putting their hands up telling us it's an unrecognised command. pip, and scripts installed by pip, also tend to suffer the same problem. If you want to make a django project, you do so in the console, and so all that needs to be on the path to make it not hell to type in. I would also LOVE for this to be changed to checked-by-default in the Python 2 installer, it's absolutely no less of a pain point for new users. IIRC, in the Python 2 installer, only the Python folder gets added to path, but not the pip scripts one. I end up having to end up recommending all Windows users run the /Scripts/tools/win_add2path.py file all the time (which by the way, no-one seems to know about...).
maybe have a feature eg. ctrl-s -a which would run a loop. and ctrl-s would run once. Thanks for your opinion.
dist/ is for the executables. py2exe. the setup.py adds the folder to The PATH so the .exe can be ran on the command line like git. Any other names maybe ??? Path.py ??? src/ctrl-s.py has been removed, Thanks for letting me know.
While that would be the ideal practice, paths with spaces in it have a tendency to cause problems with certain programs (usually badly written shell scripts). My own workaround involves making a symbolic link `C:\PythonXX` to the `C:\Program Files\PythonXX` directory.
Well, after TWENTY years, isn't it high time shell scripts learned that paths may contain spaces? I mean, it's not like spaces in the path is something new! BTW, I've yet to encounter such a badly written script in my normal day to day usage.
I also think the a hybrid approach works best. All class methods that actually do computation should be moved into closures, and extensions to clean up syntax should be kept in classes. Then, stuffing the closures into classes, and treating the class much like a namespace. 
You would think … but even modern software like LLVM has broken configure files that can't handle spaces in Python's path. (This was about a year ago; I've submitted a patch w/out any reply, though it still may have been fixed since then.)
I'm totally unimpressed that this is the worst thing you can find. Don't get me wrong - there is a setting in which this might be a problem, and although it is quite unlikely, a warning or (explicit acknowledgement) is warranted. It's a replacement AES if you don't have a C library installed. It's used strictly for encrypting compressed cookies (which are also hmac signed). If you do have a Crypto library installed, it will be used. Yes, it would have been better to force you to explicitly acknowledge using a python AES implementation, that -- however carefully written -- is inherently vulnerable to cache-timing attacks if you can run other software on the same machine. I remember that this was discussed on the mailing list, I don't know why it didn't make it to the implementation.
A web-based forum or issue tracker. I don't understand how any serious multi-party communication can be done on what's effectively a party email line with no structure.
is there anyway to handle events occuring on one of the widgets without having to check for collision every time? I'm talking about custom widgets here. Like for example, if i am a player(hero) widget on screen and i would like to know if it has been touched. would that be possible?
1. Mailing lists typically have web-accessible archives which can be viewed by date or by thread; so they do have structure. 2. Mailing lists for projects are often supplemented by issue trackers; they accomplish different purpose. 3. Mailing lists have been used for many, many years by very large projects to enable very successful collaboration - your statement "I don't understand..." can not be taken as a refutation of the fact that mailing lists work. Finally ... I still don't see what you mean by the word "hostile" in describing collaboration through mailing lists.
There's no way to do it without at some point checking the collision yourself. How and where you choose to do it is up to you.
Hehe, yes. I think that you could use it to implement both stubs and mocks if you want to (doubles in general). But I agree, the expansion of the name may be a bit misleading. I may just remove it and be happy with the fact that MObject is a fairly nice name. :-)
Mailing lists are hostile? Is this a joke? Please tell me you're trolling.
You can look into pants. It builds "executables" that hold all the python dependencies inside itself. Docker builds virtual machine containers, not sure if that is what you are looking for
Exactly. Building on those points for this thread specifically: * [Web archives for python-dev mailing list](https://mail.python.org/pipermail/python-dev/) * [Issue tracker for Python itself](http://bugs.python.org/) * [First archived post on python-dev = March 1995](https://mail.python.org/pipermail/python-dev/1995-March/thread.html) -- though obviously discussion was already well-established prior to the Archive's furthest reaches, nonetheless the idea that mailing lists are transient, or that no "serious multi-party communication" happens on mailing lists is laughable. Quite honestly this looks like an issue of "kids these days" mislabeling something they're unfamiliar with as "hostile". What's the next target, IRC?
Not until people ditch bash or any of these other hold-overs from the 80s. As an aside, I think [fish](http://fishshell.com/) looks pretty great ("a command line shell for the 90s").
You have a funny definition of "attitude". I was honestly just flabbergasted that someone actually considers "sending an email" ... "hostile". From [python-dev's info page](https://mail.python.org/mailman/listinfo/python-dev): "To post a message to all the list members, send email to python-dev@python.org." How can you get any more accessible than that? Seriously. I am still just shocked that there's even a conflict here.
completely ignoring introspectability seems counterproductive an object is fairly easy to take a look at, in comparisation closures are a pain
Or Flask if these are really simple apps. Do you think learning Django is good for small webapps? I always use Flask and wonder if Django would be better.
Thanks! 
If the hosting is on the backend (AKA you're not using a javascript based frame work) there should be ample room on servers to conduct heavy computations.
Sessions and authentication are not the same thing in Pyramid, so putting those callbacks into AuthTktAuthenticationPolicy would not be right. You could use SessionAuthenticationPolicy, and conflate sessions and authn, but it's not required. Encryption callbacks could be part of ``SignedSessionCookieFactory`` but that'd be an example of a "knob on a knob" pattern that I'm a bit averse to (no one would be able to figure out when to replace the session factory or when to pass in the callbacks, so I'd prefer to let folks cutnpaste and replace the big thing). Anwyay, I know it's hard to mentally separate sessions and authn sometimes but they are pretty much independent. You probably didn't need to change AuthTktAuthenticationPolicy to do anything at all with sessions.
The thing about websites is they can hit a large audience with the same experience. If you have 1000 people who are going to use something, having them all install something is a little tedious, especially if a website would suffice. How big are your files? Anything under a Meg could probably be handled fairly easily. It depends on how significant the computation. Sometimes it might be fine making the person wait 5-10 seconds while the thing is chugging along. If it takes longer, it's probably better to make a pipeline where you take data from users in, process them in the background, then alert the users their results are ready. Also, depending on the specifics, you could translate your code to javascript and have the client do all the computation. Websites are generally fast food wait times, people don't like going to a fast food joint and waiting to be seated. Bundling up exes and dmgs is a pain. If you don't have too many dependencies, putting the source on github might get more attention.
Okay, this explains a lot. Thanks. I think the fact that you're using semantic versioning properly also confused me, thinking about these numbers.
You may also want to checkout [PyInstaller](https://github.com/pyinstaller/pyinstaller/wiki) which I found works well for deploying to Windows. It even works well when you have complex dependencies which often have issues when using py2exe.
In click(), you're specifically asking for the first letter only: converted = letters_and_numbers[entered_text[0]] You're going to need a loop or comprehension to do all the letters, something like: for letter in entered: conv = let_and_num[letter] # do something with conv Hope that gets you started.
That's a pretty complicated question really. There is a question of how heavy you want your frame. Personally, I like my framework to be a part of my app instead of my app being a part of the framework. Other people are the other way.
Personally, I find the typical web archives confusing as well. I never meant to say that mailing lists don't work. Clearly they do. You're right about "hostile". Mailing lists don't make sense to me, but obviously they work. And I don't think they're hostile.
Python shouldn't have to work around LLVM's bugs. And most python users don't use LLVM. I've never used it, so having a nonstandard install path just because of a bug in some unrelated software seems a bit crazy.
def click(): #defines a function called click entered_text = entry.get() output.delete(0.0, END) converted = "" for letter in entered_text: converted += str(letters_and_numbers[letter]) converted += " " output.insert(END,converted) this worked for me, thanks for the tip!
Flask can do db connections
This response may be delayed but I appreciate it. I think I need to check Python 3 out.
I perfer Flask if it's just an interface to an app. A few buttons, maybe a page to upload a file, and it just a little more than calling a few python functions.
This is a very vague question. We need to know use cases, why it needs to be encrypted, and why other solutions (like 7zip with password) don't work for you. 
Put simply, Flask can do just about anything django does.
&gt; I'm a biologist and have taught myself Python for data analysis and similar tasks.... To further the Python for Computational Science path specifically, check out the [Python Scientific Lecture Notes](http://scipy-lectures.github.io/index.html) (if you haven't already). I
Architectural design for a web application that processes lots of data in a computationally expensive way can be real work. It depends on target audience, size, complexity, and sensitivity of the data, required processing times, budget, willingness to maintain it all, comfort with the systems it all runs on, etc. So whether or not your application is a good candidate for conversion to a web application depends on quite a lot. If you'd like to discuss it with a bit more depth you're welcome to message me before diving in.
Valid: `0` `return: None` just evaluates to `None`. `3` `None; None` evaluates to `None` (the last expression inside the block). `4` Indentation rules are relaxed inside parens, so this is the same thing as (3). `5` Same reasoning as for (4). `6` Same reasoning as (4). Invalid: `1` `return:` expression not enclosed in parens etc. is single-line, so the second `None` raises an `IndentationError`. `2` Same reasoning as (1). `7` An assignment can't have two expressions on the RHS, so this is a `SyntaxError`. In general, my reasoning is that `return:` behaves syntactically exactly the same as `lambda:`, except it allows multiple statements and expressions within its block.
No; I would never mess with indentation and whitespace rules. Instead, I want to leverage the fact that the rules are _relaxed_ inside parens. This allows us to build multi-line expressions inside a single block. In fact, I show this in my example above (the fourth code snippet, where I define `f`as a lambda returning a tuple. That is valid syntax _today_). As to your second question, yes I realise that my examples have side effects. But you have to look at the reality of Python today: it is a (mostly) imperative, side effect-ful language. Python functions today _do_ extensively use side effects. And in many cases, they are _extremely_ helpful. Also, the point of the `return:` expression is not just to allow side effects, but specifically to allow _statements,_ like `if`, `for`, `while`, `assert`, etc. E.g. see my comment http://www.reddit.com/r/Python/comments/2ra8yc/return_expressions/cnee1ux above.
I think you'll have to override `__new__` rather than `__init__`. Since `ParseResult` is a `namedtuple`, its `__new__` expects 6 arguments (`scheme, netloc, url, params, query, fragment`) and just passing a `url` will fail. Something like this should do what you want: class Url(ParseResult): def __new__(cls, url): parse_result = urlparse(url) return super(Url, cls).__new__(cls, *parse_result) 
You could even host it on a server at work, if you're sharing with coworkers, especially if that server is intended for your heavy computation. Honestly I'd much more suggest using flask than Django. With magnitudes less lines of code you can get something very simple running to perform computations, and you can pass in data directly through a simple client that just uses Python requests. You make a request with the data as JSON (super easy to pack with python) or csv if that makes more sense, then let the server handle all the hard work and either save results which you later retrieve, or if it's quick enough (seconds or less), return them in the response. The sort of thing you might do is have python requests (on client computer) send a request with maybe &lt; 1MB of data, then the server receives the request, passes it on to either a message queue or just uses a greenlet to spawn a job, then returns a job id. Later, the client makes a request to check on the job id, which you would check the status and return results or something along the lines of "PENDING". You can either save the results to a static path with the job id "$webroot/jobs/$job_id.tar.gz" and then the client can download that to look at it, as you would share any file. Or they could just return it as a json response which the client formats and displays to the user. It's a lot easier than it sounds. Python flask and concurrent job starting might look like this: @app.route('/startjob/', methods=['POST']) def start_job(): data = request.get_json() job_id = md5_of_request_data_maybe(request.data) job = Greenlet.spawn(my_processing_func, data, job_id=job_id) return json.dumps({'job_id': job_id}) client side: start_url = "http://my_server_ip_or_domain:port/startjob/" genetic_data = {'data': [...], 'name': 'gmo_corn'} response = requests.post(start_url, data=genetic_data) job_id = json.loads(response.content)['job_id'] Seriously. It's 6 lines server side to turn your processing script into an API that can be accessed by a 4 line client. 10 lines, and your code is now easy to distribute and pass off to a server. Point being: You can know next to nothing of web dev to be able to implement a simple REST API that your work hosts internally. All you need to distribute now is a Python client that just uses the requests module. Extremely easy to do. And as a free bonus, anytime you update the server code and deploy it, they all get free updates. You might want to have them pass the client version so you can return data your old way if it becomes incompatible.
It depends on the access pattern and size of the resultset. IMO server side cursors make the most sense when the result set is large and you don't necessarily process everything in one batch. For example if you implement paging in a GUI app for resultsets.
C#==breeze
I would second the recommendation of PyInstaller. It was the only one with which I was able to package a medium-size pygtk application. It probably is possible with the others, given some particular configuration, but I wasn't able to figure it out.
I've used it in both Linux and windows, it is awesome. It works on Python 3, unlike most of the others. 
Are you referring to [pantsbuild](https://github.com/pantsbuild/pants)? This represents itself as very useful but I found the doc, while apparently well-written and certainly extensive, quite confusing. I couldn't find a way to answer the basic question, "Can this thing convert a Python script into a stand-alone self-contained executable? And if so, what platforms can it target?"
In addition to whatever Windows-specific thing you choose, your development lifecycle will benefit enormously from use of [Setuptools](https://pythonhosted.org/setuptools/) and [virtual environments](http://docs.python-guide.org/en/latest/dev/virtualenvs/) ("virtualenvs"). Regardless of how you ship, being able to run `python setup.py develop` and get up-and-running with a development environment with your codebase will feel fantastic and save you time.
I've only used it with linux and OS X, but yes it generates stand alone executables that include all python package dependencies.
That did exactly what I needed it to. Plus, I learned the difference between ```__new__``` and ```__init__``` today. Thanks!
Looks awesome, can't wait to try it! For further dispersion, you should xpost on r/datascience, r/pythonstats, datatau , hacker news and pydata google group
Did you read [the link on why people recommend pip](http://stackoverflow.com/questions/3220404/why-use-pip-over-easy-install) in the self-post text?
You can use a 3rd resource such as a database or key-value store to signal ownership.
What's so special about Christoph Gohlke that no one has re-packaged his code in wheels?
It's not his code. He's packaging other people's code. And have you looked at that page? It's roughly 2700 packages that he's providing — that's a lot of work to duplicate. (You can't convert binary eggs to wheels as far as I know, so you'd be essentially building all those packages yourself, including all the non-Python dependencies.) 
You can use a JavaScript-based server-side framework; NodeJS has tons of them.
Yes one of the answers says package mangers are broken in pythin
plt.show()
Would the [requests](http://docs.python-requests.org/en/latest/) library do what you need? 
looking over it, the requests module allows you to open urls within a Python program. What I'm looking for is a way for a python program to open urls in a web browsers like Google Chrome or Firefox. And I want to open them in the background. Thanks for the help though.
It's very clearly stated it the PEP https://www.python.org/dev/peps/pep-0324/ It's a security issue and there were many different ways to do the same thing, which is unclear
The easiest is to convert the binary to a `wheel` and do the install that way. It sucks, but it works pretty well 
When I was learning OOP I found that learning design patterns really helped me to understand OOP. At the time I was learning Java and read Head First Design Patterns. Design patterns are basically recipes for solving coding problems using OOP principles. 
I'm pretty sure you can do: tree = collections.defaultdict(collections.defaultdict) That's generally more pythonic IMO (no classes)
You should add a __str__ method. By default, when printing, you get: defaultdict(defaultdict(..., {...}), {'Reddit': defaultdict(defaultdict(..., {...}), {'r': defaultdict(defaultdict(..., {...}), {'python': 'I have to subscribe'})})}) Otherwise, nice trick. 
But this would only work for two levels.
You don't even need a class: from collections import defaultdict def deep_defaultdict(): return defaultdict(deep_defaultdict) d = deep_defaultdict() d['x']['y']['z'] = 'foo' 
I often use this in combination with the Inno Setup Compiler to make MSI-Packages. Works really great. On Linux, well, they have their own ways of deploying software ;)
&gt; auto magically initializing This is called [Autovivification](https://en.wikipedia.org/wiki/Autovivification). Just in case you're wondering :)
I would higly recomment using www.checkio.org. It has giant set of interesting tasks and quizzes in game form. It also has great community, which is really helpful during learning process But first, go with coursera's course. 
Honestly, you can do this in a pretty straightforward way in most languages. In C++ you actually kind of have to work at NOT doing this. ;-)
Usually I don't like implicit functionality, but since C++ became so cool I couldn't avoid this forever. I'm lucky that Python has not that much of this shit like C++. 
Python has its own set of oddities. ;-)
This looks like a job for [`itertools.tee`](https://docs.python.org/3/library/itertools.html#itertools.tee).
 def Tree(): return defaultdict(Tree) 
I haven't mentioned the purpose of this class, so posting this link a second time makes no sense. For the subreddit I just copied my code and my guess is, most people using this feature are going for a class because a tree has in most cases more purposes than storing values. 
Another benefit of nacl is that they formally verified it against timing attacks and memory bugs. 
Ah yes, my bad, I only skimmed the article.
I use [NSIS (Nullsoft Scriptable Install System)](http://nsis.sourceforge.net/Main_Page) for install on Windows. There are lots of good programs out there.
Is Flask overtaking Django?
You can use pyzmq to do a communication between processes. pyzmq is easy to handle and portable. 
I don't think benchmark games matter that much in the real world -- if it did, Flask, which hangs at the bottom of these benchmarks, wouldn't be so popular. But if you're going to do benchmarks with minimal web frameworks, you do need to throw wheezy.web into the mix. 
Oh, I agree that these benchmarks have little to do with the real world. I'm sure Falcon works fine in the real world, but Werkzeug does too. I find such benchmarks still useful for Morepath, but not to "win" them, but to make sure that the request/response pipeline is not doing unnecessary work, and to make sure it's not ridiculously slow. So to make sure Morepath is simple as opposed to making sure it's the fastest ever. 
Here's a much more confusing version of the same thing. &gt;&gt;&gt; make_tree = lambda: defaultdict(make_tree) &gt;&gt;&gt; tree = defaultdict(make_tree) &gt;&gt;&gt; tree['Reddit']['r']['python'] = 'I have to subscribe' It always felt weird to me that you can reference the identifier you're assigning to in the same expression! I've actually used this before: &gt;&gt;&gt; order_map = defaultdict(lambda: len(order_map)) But, I usually don't have the heart to leave it in, even in my own script. 
This is based on Alexa ratings which are unreliable. For example data only comes from browsers with the Alexa toolbar installed.
Reddit and Instagram, no? ;)
I am more of the opinion that lambdas are arguably far less pythonic and require more thought to digest exactly what's going on within the lambda. Instead, I think of lambda as a stop-gap for a lack of another mechanism for generic functions within Python.
I don't do the symlink...I just put it in C:\Python. I like separating my dev stuff from my app stuff that way.
Based on what you say I've read further and it appears that pantsbuild creates .pex files [documented here](http://pex.readthedocs.org/en/latest/index.html). Again I find these docs extensive but confusing. However, it is clear enough that a .pex file is a zip file with a "hashbang" header, quote: &gt;Adding #!/usr/bin/env python to the top of a .zip file containing a \_\_main\_\_.py and and marking it executable will turn it into an executable Python program. To me this says, (1) a .pex file is usable only in an environment that supports hashbangs, i.e. BSD, Linux and Mac OS, meaning specifically not Windows; (2) is only executable from a command line, and most importantly (3) there has to be a Python interpreter in the target platform, and specifically, a Python that answers to the path in the hashbang. This is not what I mean by "self-contained" or "stand-alone".
The easiest way to get up and running is with miniconda/anaconda. Then you just have to do: conda create -n some_project opencv conda activate some_project
First, I'd start by upgrading to the last version of `pip` (6.0.x), this adds retries on some network failures. It doesn't add retries for hash mismatches though. I also see these issues from running a fairly high traffic CI service, so I know your pain.
This is much better than OP's code. 
Sounds like that's your first problem :-) If you're not able to upgrade to newer versions of things, your choices are going to be pretty limited (i.e. even if `pip` adds a feature to retry on hash failure, you won't be able to take advantage of it).
&gt; It always felt weird to me that you can reference the identifier you're assigning to in the same expression! I'm not aware of any language where this is impossible, which allows assignment other than on declaration.
What is the benefit of using this over something like flask?
This is a stupid point irrelevant to the main point of the article (which I enjoyed), but it's a pet peeve of mine when people multiply by 100 when they normalize. Do that when you print the data if and only if you include a % sign. It might just be me, but I get confused when I see data that's normalized with values &gt; 1. As a practical matter it can hide mistakes that would otherwise be obvious. And it can be ambiguous in edge cases, like if you only show one value at at time and it's &lt;= 1, I'll incorrectly assume it's a proportion.
It's a web framework. You get them free with a box of cereal. Collect 5 of them and you get a new markup language, 10 gets you an IRC bot &amp; 20 can be exchanged for a half-assed Lisp implementation.
What's the point of your `__call__` method? tree = Tree() tree['Reddit']['r']['python'] = 'I have to subscribe' second_tree = tree() Here `second_tree` is just an empty tree. There is nothing gained by calling an existing tree rather than instantiating a new one.
Stop over thinking it. Just start reading and write something.
This is better, mostly because if someone sees this code, says "Hmm, what's this defaultdict thing?" and looks it up in the docs, it will look more similar to the examples there. OP's is more hack-ish IMO which should be avoided whenever possible.
This is the only reason I've seen so far why a class might be preferred, but the OP's version doesn't do this.
/u/ffiarpg is right. Just dive in. Don't plan it. Just do it. If you need guided help, the courses are okay, I guess. I really recommend the books by Mark Lutz, Learning Python and Programming Python. Zed Shaw's http://learnpythonthehardway.org/ is also a really nice "dive right in" approach to learning Python.
**grabs popcorn**
Should there be? As far as I know, django isn't exactly minimalist.
I don't think that this particular code can be faster by using Cython, since it is mostly using the standard library.
Good overview. Note that I stole umm borrowed pyramid_tm's transaction integration into more.transaction for Morepath. It was just that nice. :) https://github.com/morepath/morepath_sqlalchemy is an example of how to use it with Morepath.
Yeah I installed numpy and tried in my shell "import numpy" but it said fail no module exists
But will probably be faster than Flask in a benchmark like this, which is surprising to many.
As you said elsewhere, those benchmarks aren't quite that relevant anyway.
Agreed - it also happens to be closer to the old autovivificating tree code that was passed around here ~2 years ago. If it ain't broke. 
True but this the web framework benchmark bikeshedding session. :) That Django is faster at hello world than Flask is surprising to many people, which is actually a good way to show such benchmarks are pretty irrelevant to most. Otherwise people wouldn't be surprised at this as they would have noticed already, as I believe I said elsewhere too.
You might want to follow [this guide](https://packaging.python.org/en/latest/distributing.html) instead of hand-writing an "installer" to make your own package that is also installable with pip.
Not sure if you are the github poster, but nice compilation. FYI, US salaries are advertised pre-tax, healthcare etc., so take home is usually far less.
One downside to tying a transaction to the duration of a web request is that the transaction will be held open for longer than needed. Since most SQL databases use locking, this can seriously impact the number of simultaneous requests that your application can serve. I think this is important to mention :)
Right? I mean there is no harm in more choices but I think I'll stick to flask personally.
Thanks for your help. Finally could you just explain what the url['href'] bit does? Thanks in advance.
Thank you Edwin Starr
Like the OP, I don't have a strong programming background (I'm a mechanical engineer), however I developed a post-processing python script that took raw data collected from our test system, and did interpolation, followed by the generation of a whole bunch of plots. I decided to deploy the app to some of my coworkers, and after messing around with pyinstaller, I ended up using cx_Freeze, with great ease. It worked with the default settings, and I was able to trim down the overall package by adding more and more exclusions. I later converted my code to Python3, cx_Freeze didn't care, it still compiled (is that the right term here?) the code. Can't recommend cx_freeze enough.
Thanks. I'll look into it. Looks promising.
Good question, but unfortunately not that I know of. I'm working on stuff for a customer, but it's not open source. I do have years of experience with a particular configuration of Grok that uses a Morepath-style routing approach with SQLAlchemy (the earlier library I used for this is https://pypi.python.org/pypi/traject, I since rewrote it entirely in Morepath). This is where the routing idea originated and I built several large applications in the form of REST backends using that approach, but again those are not public. So either are not worth much in this discussion, unfortunately. Work has started on some example projects, such as https://github.com/webmaven/moreblog but is still work in progress. Typical "chicken and egg" situation. :( 
I'm trying by writing articles like the post above, and the whole Morepath documentation, but it's not something you do by a single act of communication. But we'll keep going. :)
Martijn, I understand your customer has a closed source product, but wouldn't it be possible to make a case study with some insight about the architecture for the product, some metrics (LOCs), etc, without disclosing confidential information?
Thanks for the link! Sure, everybody has different needs, but some things are almost universal, like file handling etc. What I get out of my package is unified syntax and logic. So it's easier to remember that saving a file is helper.write_to_file("newfile.json", data) because all output is in the same format, e.g. helper.write_to_db(curr_db, data) 
Being able to write `request.link(obj)` is nice. That's mostly what we're doing at Abilian (which is based on Flask), using an overriden `url_for` function that can take objects as a first parameters. It doesn't have the cleanliness of you beautiful model, but we get the benefit of being able to tap into the rich Flask extensions ecosystem when needed.
It might be interesting to do some level of shallow copy-on-write, duplicating file handles and other understood system objects. Such a technique would be inherently unreliable (can't duplicate sockets safely, for instance), though interesting as a thought experiment nonetheless.
Mind if I poke you with a few questions similar to /u/MeshachBlue's? 
While there is some merit to having One Giant Utility file to rule them all , it is not quite an ideal arrangement. Bulk/bloat is going to be a major concern eventually (if not already). Mixing so many disparate ideas/functionality/tasks is going to get cumbersome to maintain and extend. It also makes maintaining code and sharing it with others difficult. You also do have some wheel reinvention going on already. CLI parsing and JSON/CSV manipulation have quite a few well developed and accepted modules. Not that what you've written is potentially bad (or what is out there is great and/or covers your use cases), but it potentially didn't need 'solving' once again. There are probably other examples as well if we dug deep enough. TL;DR - While writing numerous helper tid bits is a great idea, your structuring (or complete lack thereof...) could benefit greatly from a small redesign. You should also check existing modules for some of the functionality you have in there (CSV, JSON, CLI parsers, etc...)
You are missing CM. With Ansible (it's in Python), Salt (it's in Python), Chef, Puppet, or any other tool like that you can get the app setup repeatably &amp; easily. Or Docker, where you setup supervisord once, pack it all in a tarball + some metadata, and have your application run in a small container. Or Nix (http://nixos.org/), where you can write an expression for your app and then build/push it wherever with all dependencies (down to libc). But those are just bare tools, I haven't seen a packaged "just works" solution yet.
I ran a `pep8` check: $ pep8 wallpaper.py wallpaper.py:2:3: E111 indentation is not a multiple of four wallpaper.py:2:18: E261 at least two spaces before inline comment wallpaper.py:3:3: E111 indentation is not a multiple of four wallpaper.py:3:19: E261 at least two spaces before inline comment wallpaper.py:4:3: E111 indentation is not a multiple of four wallpaper.py:6:3: E111 indentation is not a multiple of four wallpaper.py:6:15: E712 comparison to True should be 'if cond is True:' or 'if cond:' wallpaper.py:9:3: E111 indentation is not a multiple of four Since the `else` will never be reached since `passion` is always `True`, I maanged to optimize the function as follows: def success(deidcation, persistance): dedication += 1 # dedicate yourself persistance += 1 # be persistent magic = dedication + persistence return magic Which could be further shortened: def success(dedication, persistance): return dedication + persistance + 2 I recognize the style of this screenshot, but forget what site is used to generate it...
Alternately, use raw strings: xlrd.open_workbook(r'C:\PythonLearning\ExcelTest\162 FINDINGS SHEET.xls')
Do you have a link to the repo?
Just start, and things will come up when they do
/r/learnpython
Guess it would be this: https://github.com/jam-py/jam-py
I recently went through setting up my own little website (ended up using nginx with pyramids pserve in a reverse proxy setup). It took me many days of fiddling to find a solution that worked and seemed reasonably understandable to me. One issue I ran into was that there were a number of articles or tutorials that hinted at different bits and pieces, but few that included things like directory recommendations, agnostic configuration recommendations, etc.. A lot of the time I've found its hard to determine what is specific to their use case and what is general. I found the best info on linode and digital ocean, as they are aimed directly at people trying to do exactly what I was trying to do. I think it's a hard balance between just rehashing the docs of the different parts or being so general that it doesn't really give one all the info that one needs. All that said, I owe the each article for giving me a piece of the puzzle. I guess it would just have been nice to not have had to go through so many hoops. 
Ah, the indentation bothers me. It looks like it's only two spaces :/
Was falcon inspired by any other frameworks? Perhaps something written in another language? I'd like to investigate your design decisions by way of your inspiration, if that's possible or relevant. **edit:** This was a serious question. I like the framework for what it is—I can see it fitting perfectly with a future project I've got going—I just want to know if there are similar tools which inspired this.
&gt; cherrpy development to github? This has stopped me from contributing to several projects, for me atleast, git has won the next gen source control wars. I don't have time or interest to learn another SCM tool.
&gt; I recognize the style of this screenshot, but forget what site is used to generate it... Op, can you let us know what the site was please...
A couple suggestions: 1. Post a link to your repository (e.g. GitHub, Bitbucket, Assembla), not Dropbox. Don't have a repo? Learn about Git and get one! This should be one of your first tasks for any new project. 2. Research speech recognition and language parsing libraries. A few already exist and solve the problem you are trying to solve. Read the code to learn how you can improve your own.
i can't believe [uwsgi](http://uwsgi-docs.readthedocs.org/en/latest/) hasn't been mentioned here yet.
Here's something that is more idiomatic and actually makes sense: def is_successful(self): return all(attr in self.attributes for attr in ["persistent", "dedicated", "passionate"])
Is there anyone left who advocates the use of MongoDB at all?
&gt; but some things are almost universal ... and those are usually in the standard library. For example, to me file-writing is `with open('newfile.json', 'w') as f: json.dump(data, f)` is convenient enough. Although quite often I use `pandas` which handles that.
When do you ever need `write_to_db`? I.e. what do you do with that database afterwards?
Whenever I see that a boolean variable is compared to True, I hold my head. NO: if passion == True: YES: if passion:
Being honest...I do this sometimes in my code (probably due to caffeine or other substances). It makes sense at the time, but when I go back I'm like "You idiot..."
2 spaces is the devil's indentation
People who use words like "web scale" and think it means "more than 1000".
∎
I love Spyder2.
DasIch is right, "model-driven" already has a strong established meaning, that is (AFAIK) unrelated to what you have in mind. Cf. http://en.wikipedia.org/wiki/Model-driven_architecture and http://en.wikipedia.org/wiki/Model-driven_engineering You probably want to use a different expression to reduce cognitive overload.
Of course these are different ways to do the same things: they're web frameworks. I think you aren't giving the differences much consideration, so I'm giving up on this conversation. 
Daslch wasn't complaining, but you have a point. I'll add an issue to look into changing it. I need to think of a good succinct way to express the notion that models drive how your API (or UI) behaves, as opposed to the views being the primary driver. I'll note that "Model-driven" is used elsewhere in a context more similar to Morepath's: consider Polymer's usage in "model-driven views". 
Would IPython notebooks suffice? 
You are absolutely right
/r/learnpython
Some companies will require you to have a CS or similar degree... and some rely more on your experience and demonstrable skills. From experience, the ones requiring degrees are either dreadfully dull or inexperienced teams. Find a good team who's interested in you and your skills rather than bits of paper.
I have dabbled in cherrypy in the past. My projects all run on an intranet. Is the server secure and fast enough to support a user community of less than 100 people? Is it a viable option to serve up a Django project on Windows?
In short: http://www.sarahmei.com/blog/2013/11/11/why-you-should-never-use-mongodb/ Also: Postgres can do everything than MongoDB can do but doesn't sacrifice as much for it. (Relations and integrity stuff is easier with Postgres)
I just want to point out that most of the tutorials on CodeAcademy are based on python &gt;3. Meaning if you download and start to use 3.4 (the current version) like I did, just two weeks ago.. Then when you start to learn on CodeAcademy, some of it might not work. Some syntax did change in python 3&lt;. for example, some projects on CA refer to.. name = raw_input("What is your name? ") in python 3&lt; raw_input is no longer it is just.. name = input("What is your name? ") I am very new to python and programming but just thought I wish someone would of told me before going on CA to learn! However, CA did help with a lot of understanding what the code does, even if the syntax is a bit different.
Hi, it is very bad it is only in pdf and we can't browse the (hopefully mardown/rst) sources. It looks neat, but I wonder how we can integrate it in a wider web app.
Thanks for your work. I've started using Spyder recently as I plan to use it to teach students: with its various tools (integrated interpreters and variable explorer are great for teaching beginners, the integrated debugger is good for more advanced students, etc.) it has everything required imo. It is a bit quirky in its keys assignments (e.g. why doesn't ctrl-w close a tab? ... etc.) and a bit slow (especially compared with a text editor like SublimeText, my all-time personal favourite), but it's overall very nice. I like the fact that it doesn't force me to have everything defined as a project the way that PyCharm does. Now, if only it could have code folding.... ;-) Thanks again for your good work.
This is mostly untrue. Locking that actually blocks other transactions from doing things, even on the same row, are rare as modern databases use MVCC and isolation levels are usually read committed or repeatable read. Even a conflicting UPDATE on the same row under read committed won't block (and if you have lots of concurrent requests all trying to UPDATE the same row simultaneously, your app has bigger problems and should probably serialize these into a queue). Only on SQLite is locking potentially a much bigger issue since the whole db file is locked, but also the pysqlite driver doesn't actually begin write-exclusive transactions until the transaction emits DML, so even there the effect not as prevalent as one would expect; SQLite isn't appropriate for scalable web apps in any case.
I own an app development company and I don't give a rat's ass about your CS degree (or whatever degree you have or don't have). Only your skills (and English language skills) matter and it helps to be able to demonstrate that somehow. Github accounts with contributions like pull requests or repositories go a long way. Doesn't matter what language. Your enthusiasm and the fact that you love what you do matters to me more than some meaningless crap degree some idiotic university gave to you based on arbitrary attributes they think qualify you to be useful. There are many companies like mine. Keep searching. Edit: added things in parentheses.
&gt; Only version 3.4.x is in active development, in terms of gaining new features and functionality, while Python 2.7.x as well as 3.1.x to 3.3.x are actively maintained. Python 3.1 is not maintained; that plug was pulled in June 2012 (PEP-375.) And it's rather a stretch to say that 3.4 is in active development, because it's in bugfix-only mode now, and has been for more than a year. Python 3.5 is in active development.
CherryPy has always been good to me. Thank you CherryPy!
I'm on Windows and ctrl-W closes tabs using Chrome, Firefox and SublimeText (just tested all three again, to be absolutely sure). I have Spyder 2.3.2 which I thought was the latest version.
It's quite a common story actually so I would say yes. Unfortunately, usually these are internal projects like yours so it's hard to find proper public evidence for this. This [recipe](https://bitbucket.org/Lawouach/cherrypy-recipes/src/d140e6da973aa271e6b68a8bc187e53615674c5e/frameworks/django_/?at=default) is a bit dated but will give you the idea.
Of course the features would be part of the case study. LOC is useful to give an order of magnitude (1K, 10K, 100K ?) of the complexity of the project. Actually, I think you've already disclosed who your customer was (and, from its website, what kind of features the product has), but I don't remember it.
Flask is one of the top 5 Python web frameworks, but when it started it was just an april fool's joke, so yes there is room for innovative new projects.
Ok then, I'll change it to `Ctrl+W` :-) By the way, 2.3.3 is our next release, so it's still in the making.
I don't think so. This release will integrate the IPython notebook, which is a major programming effort :-)
The easy way would be to take on more development work and transition internally, unless your current company doesn't have a true dev team.
3.1 is maintained in terms of bug fixes. I agree with your point with 3.5 though. I'll make those changes. Cheers!
Pycharm has native support for ipython notebooks, so you can generate plots through that and have it work (though I've never tried it myself). 
For me nothing beats vim and the terminal. Vim can be setup with powerful IDE features with the help of a few plugins (YouCompleteMe for completion). IPython is a nice complement for quick prototyping.
Okay, that you need to heavily reword that. Keep in mind that MongoEngine is nolonger even a Django util/tool/app it's a generic Python library now.
Start a YouTube channel and show your skills. Since I started https://www.youtube.com/user/sentdex, I have received a large number of career offers that I didn't even ask for, and it has worked quite well in the past for raising funds/investments when necessary. A CS degree != anything past rudimentary programming knowledge. I pay no attention to CS or otherwise pieces of paper or checked boxes that tell me what you know as an employer. I want to see your previous work and code. That's all that matters. I've received a lot of emails from people in a Master's program for CS, working on their thesis. Upon talking to them, it's quite scary how little they know about programming often times. Again, it's easy to make the mistake, as many employers do, thinking a CS degree means someone is an expert programmer. It's just not what that degree means. They understand computer science, at best. I've also learned over the years that a degree in literally anything is nearly worthless. I graduated a few years ago and got to experience first hand what acquiring a degree in two majors was like. I trust no degrees. Show what you know. 
the only companies that i've known that actually cared were those companies who would get subsidies from the government for hiring college graduates. so if companies are adamant about you having a verifiable degree, don't be surprised if this is the reason.
Just don't pay for anything unless you value the resource, like some people just like to learn from a physical book or the provider is someone that you have a true connection with and like their style. Here's an intro to python series from my channel: https://www.youtube.com/watch?v=IX6mc9l6tY4&amp;list=PLQVvvaa0QuDe8XSftW-RAxdo6OmaeL85M&amp;index=2 Like many others have said, just start. Honestly, you don't even need to start with any "basics" series. Start on the project that you love. If you're interested in web development, do that, games, do that, robotics, do that. I learned Python by reading the Natural Language Toolkit textbook for Natural language Processing. A horrible "starting" tutorial/project for most people, but perfect for me because I found it very interesting. Just start on whatever you want, and then research the lines of code you don't understand. There are tons of tutorials for literally everything out there. I have a lot of tutorials on the channel linked to above as well, and am always there to answer any questions. Lots of other tutorials exist online as well, just dive in and take it one line at a time. If you try to do something you're not passionate about (ie: learning the boring basics), then you risk burnout IMO. Find a project you're passionate about and go!
That's the idea :-)
He's not scraping much so speed's not an issue. lxml's binary requirement is a bit much for something like that. There's the concept of premature optimization that some people seem to miss. If you aren't scraping more than a few pages, don't add a heavy prereq. If later you find that you are scraping so much that speed becomes an issue, then you can always add it. BeautifulSoup has lxml support, so instead of using lxml on its own, you can always just add the prereq later and update your method calls.
The integration is this: we assure that mpl works as expected in our interactive and non-interactive consoles. You can also set your preferred backend in our Preferences, along with changing the settings of the inline backend. Not much but more than most IDEs :-) For interactive plotting you should at Bokeh, it seems the best alternative.
I don't have the degree because I dropped out half way there, and it does impact some aspects of my career. Though, because I have part of a degree, I got some basic academic stuff that is asked a lot in interviews, and the rest I filled in because I really love what I do. I would suggest you understanding and implementing all data structures you can find, and keeping a github account with algorithms for various random things that interest you in a few languages.
&gt; use rest framework, or you'll have another item in next year's "mistake" list :) &gt; &gt; haha - i know, i know i really do like tastypie though 
I'm not a big python user, but isn't there a way to just use asserts?
Yes. You can return object types and handle them conditionally as well. If you write tests first you can also ensure that you're always going to get the type you want/expect. 
Agreed here too. One of the very useful things about python is that you can swap out a regular dict() for a custom class that implements the mapping methods. This seems to remove that functionality unless you subclass dict.
When I click on ctrl + = (i.e. without the shift) on Chrome, it magnifies. Yes, it is mentioned as ctrl + + ... but ctrl + shift + "=/+" yields ^ Same for Firefox, i.e. no shift key required.
Could anyone give an example of when this would help?
I'm a software engineer / data scientist with a degree in econ and poli sci from a crunchy liberal arts college. I was a complete newb when I got out of college 5 years ago with 0 programming skill, but landed a consulting job after school. I didnt even know how to use Excel. In my first year, i learned excel and pivot tables, then VBA and MS Access. Year 2-3, I learned SQL and how to work with developers and manage projects as a business analyst at a bank. Year 4 i landed a job at a tech company as a data analyst and learned python, php, restful API's and html/css. Year 5, i learned more python, big data /hadoop and pandas. I learned mostly on the job, teaching myself at work and leveraging expert resources at each job when I had the chance. I taught myself some stuff outside of work but since i get bored easily, i prefer learning while Im gettin paid. It was too hard for me to come home after work and teach myself these radically new concepts without feeling overwhelmed, incompetent and bored. Additionally, I had an overarching visipm that I wanted to be a programmer, but I didnt know the specifics of what that meant. As time went on, the picture became more clear and I wanted to focus on data engineering vs app dev. Also - if you dont feel like there are ways to learn more technical acumen in your current role, have a talk with your manager or consider other opportunities. Hope this helps! Tldr: start small, learn while you work, and have a longterm vision that you re evaluate periodically.
they are still merging in pull requests as of last month though: https://github.com/toastdriven/django-tastypie/commits/master
Alongside (or instead of, in my case) the debug toolbar, I use [django devserver](https://github.com/dcramer/django-devserver); it does a ton of stuff but most importantly to me it adds the time the server spent in the database, and how many queries through the ORM was made. I've modified my version to color code the requests with say 100+, 500+ and 1000+ queries to make for quick identification. I also use this one liner I can paste everywhere that counts the number of queries, the delta time since the last line was pasted and the total time. Makes optimizing a million time easier knowing exactly which line uses the most resources (in terms of time and ORM queries). I stopped using DDT because the line reporting for the sql queries took way too long to generate for the long requests and slowed down my shitty devpc anyway. Your needs would probably vary.
Alright, I just reviewed lambdas on codecademy, and it seems that option is better. Thanks!
Yeah, I guess you're right. My example wasn't that good, the real benefits come from string processing and doing a bit more complex, but commonplace operations with files.
I'm not actually a developer, I'm a journalist. So I do a *lot* of scraping and mostly I use a db as a cache for content I've already scraped and formatted correctly. That way I don't need to bug the servers every time I run a script. Like I said, I'm not really a dev, so I have no idea if what I'm doing is smart at all :)
Anything Scala-like is awesome in my book.
I have a github account that I've synchronized with one of my dropbox folders containing IPython notebooks. I have notebooks containing cheat sheets and an assortment of anything related to data analysis. Python is such a mature language with a huge, active community, there is probably a module or framework already made that you need. You can search pypi or ask #python IRC channel or search stack overflow. For handling URLs: people recommend requests library For web development: django or flask For data analysis/statistics/scientific computing: pandas, statsmodels, numpy, scipy, ipython For working with Excel: openpyxl, xlwings, xlrd For working with Windows ODBC data sources: pyodbc Working with dates: arrow Working with system processes: [psutil](https://code.google.com/p/psutil/) web scraping: lxml, beautifulsoup4, scrapy package and virtual environment management: [anaconda](http://conda.pydata.org/miniconda.html), virtualenv For plotting [charts/visualizations](http://nbviewer.ipython.org/gist/wrobstory/1eb8cb704a52d18b9ee8/Up%20and%20Down%20PyData%202014.ipynb): matplotlib, seaborn, bokeh, plotly, ggplot, mpld Working with ORMs: sqlalchemy Working with cryptography or passwords: pycrypto, passlib, getpass For Windows development: pywin32 ...and on...and on...and on... 
[django docs on files](https://docs.djangoproject.com/en/1.7/topics/files/) To actually send it you'll need a &lt;form&gt; with an action to the url and a &lt;input type='file'&gt;. If you need more help than that I suggest going to the beginner tutorials.
&gt; It has the element traversal methods rather than relying on regular expressions methodology like BeautifulSoup This is not correct - BeautifulSoup parses HTML to a tree and provides traversal methods, and it can use lxml as a backend. &gt; formatted_result = str(result.toAscii()) &gt; tree = html.fromstring(formatted_result) It looks like unicode is handled improperly here. formatted_result is encoded to latin1 (with undefined behaviour for chars outside latin1), and html.fromstring loads data using an encoding detected from &lt;meta&gt; tags. &gt; It is slow but 100% result prone The example is a good start, but it won't handle 100% cases, e.g. JS redirects won't be followed. Adding a small wait time is a bit tricky for JS redirects case because LoadFinished signal will be fired twice. Also, it doesn't handle iframes - iframes contents won't be returned. It also is not particulary efficient if several webpages needs to be downloaded (which is usually the case - otherwise automation may be unneeded) - user should either wrap this code in a script (and thus start/stop QApplication which is slow) or write some navigation code. A shameless plug: we're working on https://github.com/scrapinghub/splash which has a similar code inside (with lots of edge cases handled, and hundreds of unit tests) wrapped as an HTTP API. It allows to render multiple pages in parallel and use an in-memory cache - multiple pages from a same website are likely to be rendered faster as less resources will be downloaded. There are also PhantomJS-like scripting features (http://splash.readthedocs.org/en/latest/scripting-tutorial.html) which allow to write sane rendering scenarios without recursive callbacks hell. Of course, there are also tools like PhantomJS, CasperJS, Ghost.py, Selenium, etc. Manual PyQT scrapers/crawlers can get unwieldy for tasks which are more complex than getting rendered HTML of a single web page; IMHO using a specialized wrapper for crawling / scraping is usually a better idea.
True, but I don't know if Qt let's you define two shortcuts for the same action. We'll see :-)
I meant `Ctrl+F4` currently closes one tab at a time but for the Editor, not tabs for the Python or IPython consoles. That's what will be fixed in 2.3.3.
I feel like you're telling my life story! Glad to hear some other folks picking up data modeling and programming techniques from an economics background.
I did my best: caesar = lambda m, key, f=string.ascii_lowercase: string.translate(m, (lambda t=f[key:] + f[:key]: string.maketrans(f + f.upper(), t + t.upper()))()) Can probably be shorter.
You wouldn't be in South Australia would you? 
This is a little old, and it looks like the repo isn't be terribly actively developed.
This just cost me an hour, but it was well worth it! Especially the slides in the links. Thanks.
No :( In Toronto, Canada. We make a huge effort to hire talented software engineers locally.
Python types are heavily dynamic and this isn't going to change that. Bar some serious changes to the design of the language I don't think this will lead to any optimisation. 
Thank you for your suggestion!
Just thought I'd mention how much I've learned using your channel, thanks man!
Even though you aren't showing a web page (you are providing an app), the method for sending a file to the web server is quite similar. When you click Submit on that form in your browser, your browser (the app) sends a POST request to the URL of the form. That POST request contains the contents of the file, MIME encoded. If you want your own app to send files to your web server, you would want to send a similar request. The server-side Django will see this just like any other form submission, so the backend can be handled the same way.
My undergraduate degree is in physics, and then when to grad school working in research for a few years doing primarily big data in Python (and Bash and a little C++). I completed my PhD. After that I applied to about a dozen places, interviewed at a handful, and finally after 2 months of unemployment accepted a job as a Software Developer. Lots of money, and it's still big data stuff, but it is in an area not at all related to physics (which I don't mind).
I haven't tried Bokeh, unfortunately, although I've heard/read a lot about it. Biggest difference, off the top of my head, is that both ggplot and seaborn are based on matplotlib while Bokeh does its own thing. There are pros and cons to that arrangement, of course.
Still looking it over, but what I like about this... Is that it's laying out everything and giving simple examples. For me, this is easier to follow and reference ad-hoc as needed when working rather than using other "story book" training materials. 
They released an early version already last year? But it was missing features so I'm still using R's. And also because of plyr/dplyr.
To me, this seems like the ideal solution: make the check at runtime, and just have a way to compile them out for release builds.
Someone downvoted you, but I agree completely. Ipython provides excellent introspection along with %timeit, run (to load all your script variables into the interpreter) and other great prototyping features.
I will do you one better than that :) How about superimposing weighted multidimensional arrays in a virtual metamaterial data structure comprised of a sea of genetically controlled folding arrays that generate a single structure whose genetic components replicate when they are present in an area of a larger array which generates the longest values of pi. All this created by 8 Radeon 7990s computing in a rotational octagonal shape across 64GB of DDR5 ram and a custom 3d printed liquid nitrogen cooled motherboard which is able to physically move its components to focus pulsed magnetic fields across a centrally located frozen gallium sphere containing a magnetically suspended transparent ferromagnetic liquid full of 100 micrometer dodecahedrons of quartz, each surface of which contains an embedded coil of a unique length allowing for unique signatures for each polygon. Inside each polygon there is a Joule thief circuit which ionizes a fluorescent gas within the quartz polygon and together they are able to emit a 3d infinite resolution randomly adapting and self organizing fluid computational network...all of which looks amazing under a black light....
There are Python libraries/interfaces to OpenOffice/LibreOffice.
Edit: I am an idiot. I'm really interested on any reading material you have on the method you described. Doing stuff like this in pure python would be great! For the case where a c library exists though (ie, image manipulation) I still find it difficult to believe even the most fancy, optimized, pure python would come close to a python wrapper on that lib. For the case you describe, it's so specific it probably doesn't have a c lib that you could turn to. And with ddr5 I'm guessing you're pulling my leg.
Yeah, the initial release was very promising and they were adding features at a pretty good rate but it seems like they hit a point where their existing architecture wasn't going to cut it. The project is kind of stalled waiting for one person to do a *big* refactor.
Thank you.
I think it's a lot easier to develop and iterate python. Tons of great frameworks and open source libraries you can leverage to write and manage less code
I work in the exact same environment. All of my co-workers use VBA and a few use C#. In terms of vba vs python.... VBA is fine is you are doing things within access/excel. Outside of this environment python is absolutely the better choice. You might like this.... use python to insert and run vba. Requires you to set accessvbom registry key value to 1 (seach in regedit for it). import win32com.client directory = R"&lt;pathtoexcelfiles&gt;" outputfolder = "Output" for excelsourcefile in os.listdir(directory) : if excelsourcefile.endswith(".xlsb"): print "EXCEL FILE FOUND --- " + excelsourcefile + " --- CONVERTING TO .txt!" excelfile = directory + "\\" + excelsourcefile xl=win32com.client.Dispatch("Excel.Application") # application &gt; workbook &gt; vbproject &gt; print "PROCESSING ---" + excelsourcefile fileworkbook = xl.Workbooks.Open(Filename=excelfile,ReadOnly=0) xlmodule = fileworkbook.VBProject.VBComponents.Add(1) # vbext_ct_StdModule sCode = '''Public Sub SaveWorksheetsAsTsv() Dim WS As Excel.Worksheet dim wsname as string dim wspath as string wspath = thisworkbook.path wsname = thisworkbook.name For Each WS In ThisWorkbook.Worksheets WS.SaveAs wspath &amp; "\\" &amp; "%s" &amp; "\\" &amp; split(wsname,".xls")(0) &amp; "___" &amp; WS.Name &amp; ".txt", xlTextMSDOS Next End Sub ''' % outputfolder xlmodule.CodeModule.AddFromString(sCode) xl.Application.Run("SaveWorksheetsAsTsv") 
Definitely checkout the two MIT intro to CS courses using Python on edX. The second one especially (6.00.2x) serves as a great intro to data science. I took the verified course (which isn't necessary of course) and I highly recommend it.
Would you recommend me to set Udacity's CS101 aside and start the 6.00.1x course? Unfortunately I don't have time taking both at the same time.
Thanks. I tried bokeh, before a major update and I had good plots based on JavaScript code working, but after the said update everything changed.
Nice one, didn't know this.
Came here to suggest this! I know it has always had a very large scientific/academic following (though it's also pretty awesome for devs too)
I love matplotlib and it's great that there are some other options out there too. However I find that one area where Python plotting lacks is just _speed_. Are there any plotting libraries out there that concentrate on speed? In particular since I do enough DSP work, I often find myself needing something appropriate for real time plotting. matplotlib's draw() function is _okay_ but often I need something faster and more fluid, e.g. something that allows appending new data to the graph during a loop.
Pretty fantastic! I think you can replace the slightly elaborate [`_parse_dsn`](https://github.com/amjith/pgcli/blob/13b17b8141119d071e95a7918cc62bb1f2c0308b/pgcli/pgexecute.py#L7) with [`urlparse`](https://docs.python.org/3.0/library/urllib.parse.html#urllib.parse.urlparse).
If your focus is or will be data analysis, then absolutely. I've taken both, and Udacity's CS101 leans more heavily toward web development, while MIT's are more general computer science concepts (which will be more useful to you I think). 6.00.1x is still one my favorite online courses. I'd suggest going with that if it's starting soon. Keep in mind Udacity has those new "nanodegree" routes now, and "Data Analyst" is one of them. The only course I actually paid for on Udacity was Data Wrangling with MongoDB (which actually used Python mostly), and had tons of fun. I got word that they'll use my final project as the model to display as a sample on the final project instruction page, but it seems those changes haven't been implemented yet. Anyway, MIT 6.00.1x to 6.00.2x. Then checkout Udacity again if time allows you only one at a time.
You do know about: from __future__ import print_function Convert your Python 2 code to use a function and then the code base works on both. Doesn't make sense to try and go the other way and reintroduce print as a keyword.
The dropdowns are made with a library called prompt_toolkit (https://github.com/jonathanslenders/python-prompt-toolkit). There are some excellent examples in the repo and a tutorial. https://github.com/jonathanslenders/python-prompt-toolkit/tree/master/examples/tutorial
I'm planning to do a sweep of the popular destinations for the socket file before falling back to an empty string. https://github.com/amjith/pgcli/issues/37 I'll update the docs in the meantime.
The comments aren't exactly becoming part of the code, since AFAICT this doesn't affect the way the interpreter itself runs (yet). It seems more like a type-checking linter than an actual change to the language.
 * Open source * Better Web scrapping library (for gathering data) * better ETL library (IMO better than the SAP BW ETL) * better database (SQL based) handling with sqlalchemy or psycopg or cx_oracle * Pandas for analytical * Faster Yet with all the python script/projects I deployed to my company, they still call me the Excel Master :p. Oh and my job title is SAP BW Manager :(
If you think it's reusable – make a properly structured package in a repository on github. I'd be interested in taking a look at that.
It looks cool! The only bummer is the github looks relatively idle. It was made by the team that went on to create [Docker](http://docker.com) which was so popular it became their whole business, so I'm guessing they have other things (as well as mostly/all writing in [Go](http://golang.org)) these days.
Others usually mentioned pycharm, sublime text, vim or emacs. For me Python IDE is Spyder. 
Look at the bright side, a new pythonista every week :)
After tons of scraping I just use regex now, it doesn't require well formed html and it can easily extract from javascript code blocks and other non markup language text.
Technically, both print function and print statement offer same capabilities. The only difference is syntax.
No they don't: print(*items, sep=':', end='|', flush=True) There's no way to do things like that with the `print` statement alone. You'd have to write: import sys print ':'.join(items) + '|', sys.stdout.flush() Fugly. 
Why is it such a life altering hardship to have to type a few extra parentheses? You have to do that for *every other function* in the language. If typing extra characters is really what's holding you back, then you should *prefer* the `print()` function because it can be aliased: p = print ... p('foo bar') Hey look, less typing. 
I suppose html5lib is also an option. Always used lxml myself though.
Perfect. I am just wondering if this is safe enough... you know
Yes its true.Implementing it for bigger projects may not be feasible.Comfortability comes with a trade off.In that case selenium is prefered.But good understanding of web kit allows you to write your own way of dealing with rendering.Master Web kit,and you will be super star.Nice comment and suggestions kmike84.:) 
ZeroRPC is a nice library, not actively maintained but functionnal. Actually, only python and node.js bindings exist, so not really cross language. I'm using it in two project but forked it and maintain my version. 
Yeah, had a look at pandas. Seems like it does a whole lot of what I need. I had heard of it previously, but it not really bothered to read up on it. Thanks for this. 
Thanks for this, very useful way forward. Really appreciate it.
You do realize this is just (a slower) matplotlib in disguise right?
Plenty of famous guys have no degree. Dinnerbone (Minecraft lead) doesn't. He got hired by Mojang (the Minecraft devs) on the strength of his coding skills - he wrote a Minecraft plugin framework called Bukkit.
good to know it was of help..Any feedback?
I've had performance issues with matplotlib once, and used [PyQtGraph](http://www.pyqtgraph.org) instead. It has many nice features, and I could do some real time plotting with it. Requires Qt.
1. $12 800 with accomodation. 2. Will check it out, thanks for the tip! 3. Yes, it does. But I'm looking at how I can learn as quickly as possible - the most effective path to mastery...
Cool! Thanks!
Not to mention that the Python 2 version has an extra space at the end, so if you care about whitespace you need to use `sys.stdout.write` in that case anyway.
Do you want other people to use your programs? If not, it's not that big of a problem.
I've run into few problems with beautiful soup 4 backed by htmllib5
Thank you, this is very inspiring. I believe very strongly that engaging with politics must mean more than posting angry rants - for some of us, it must involve the grunt work of actually getting to grips with the data involved - accounts, spending patterns, changelogs on legislation, voting records and so on. I think those of us with even basic technical skills could make a huge contribution to the democratic process by searching, parsing, crunching and presenting this kind of data.
Very nice! Next step: Cassandra support. I may fork it and do it if I have time.
A got ~8% by fixing the benchmarked application and found some places within the bottle framework that could use a little tweaking, but falcon *is* fast, I have to admit that. A close second place is okay for me :) 
Beautiful Soup 4 is mostly designed as a frontend with support for several backends, including lxml. If you use html5lib as the backend, then you'll get better support for bad markup. The main reason to use Beautiful Soup now is for it's API, though it does add a small amount of overhead to any backend. If speed is your priority, use lxml directly. Personally, I don't find lxml that hard to use.
Sorry, that's what I meant by clear error. I.e. the error would be thrown at function call rather than somewhere deep down in the internals. 
If your target site is stable and hasn't any evil counter measures against scraping, you can get some information from it with regex. It's not the golden bullet, since it works only in small and limited cases, but for a quick and dirty scrape I use regex regularly.
Nice idea, never thought of it before, it could actually help alot of people!
Raymond Hettinger also gave an amazing talk (which has been discussed extensively in this subreddit, I know) called *[Transforming Code into Beautiful, Idiomatic Python](https://www.youtube.com/watch?v=OSGv2VnC0go)*. For a transcript of the talk, see [here](https://gist.github.com/JeffPaine/6213790).
...how often are you going to reuse this? Also, how is throwing everything into a function, and then turning the whole thing into a module, that much more *reusable*? Honestly...okay, I get that I'm an idiot when it comes to these things, but when I've done any screenscraping in the past, I don't tend to end up with anything that's useful beyond that project. That thing is 100 lines of mostly Beautiful Soup and Panda.
I've found the same when it comes to web scraping. The code is so specific to the page that it's not reusable. 
It's a bad habit, and makes it less readable. http://pastebin.com/NnDcQsxv is a really fast and simple refactor, you could expand on it if you wanted to. That allows you to re-use the fetch-url-cache code independently, and the display-data independently. It's not about the size, it's about not having multiple copies of the same logic. And those simple changes would allow you to re-use two of the three logic blocks if you wanted to parse something similar later. Moving it to object is a bit more work, and would probably want to make it more fine-grained and with more variables that could be overwritten easily by sub-classes.
This sounds like an OS problem, not a Python problem. Just Google something like "change default program by extension for &lt;insert operating system name here&gt;".
Do some side projects to show proof that you can talk the talk. My good friend was a biochem major and he just does app developing on the side and gets paid shit tons now. 
Fair enough, I never have to plot time series in real-time so I hadn't actually tried, but it seems you are correct!
It looks like all the examples are OpenCV.
This is also something CPython implements by stripping out the bytecode of blocks enclosed by at `if __debug__` conditional statement. (`__debug__` is a runtime constant (can't be changed) that is set to True by default, and False when running with `-O`) I use this a lot in my code, so that all the assertions, (rare) type-checks, and logger.debug(...) calls are run only in the non-optimized (default) mode.
Do it after work or do it at work. I don't even own a TV and rarely watch TV/movies online. If you have something your company needs that you develop, you can say "we should use package X. It's really good and I wrote most of it, so I know exactly what it can and cannot do." Nobody wants to reinvent the wheel. 
This is the difference between people that program for a job and people that enjoy programming. If you enjoy it, you are more than happy to spend your free time programming. 
You are correct. It's boiler plate that is normally needed but not for this specific case. Sorry for the confusion.
Ah, let's see: 168 hour in a week. Sleeping 8 per night leaves 112. Working+commuting 55 per week leaves 57 hours (5 per weekday night + 16 each weekend day) 2 hours cooking/cleaning/eating per day leaves 43 hours (3 per weekday night + 14 each weekend day). The average American spends 34 hours a week watching TV - now we're down to 9 hours for reading, "quality time" with the family or that side-project you want to work on. Really if you want to answer that question for yourself, log what you spend your time on for the next week, look back at it and decide if that's really how you really want to spend the hours you got left. 
I would also recommend looking at [`pyparsing`](https://svn.code.sf.net/p/pyparsing/code/trunk/src/HowToUsePyparsing.html), which I would suggest looking at for when things get a bit more complicated!
[Harvest](https://www.getharvest.com/) is great for this. I haven't done much in the way of side projects or writing, but what I have done answering/posting questions on SO or contributing to OSS has happened in small increments—usually during business hours. Doesn't have to take long, either. As far as contributing to OSS, my experience was: 1. Start using a library (in my case OCMock mocking/stubbing ObjC lib) 2. Find minor issue 3. Fork, point to fork, and fix for my project 4. Instead of continuously rebasing on top of upstream master, make a small investment to clean up the fixes and submit a PR (the sooner the better). 5. Once PR is merged, point original project back at the original repo Steps 4 &amp; 5 are beneficial to you and your employer, since you get new features and bug fixes "for free" w/o having to update your own fork, which can get exponentially more cumbersome the larger the discrepancy between your fork and upstream (long-lived branches FTL).
You shouldn't feel like you have to do all those things. Development is fun, but it's not such a magical thing that it should consume your life. If it's going to be your job for the next 40 years, pace yourself. No need to burn yourself out by doing it so much outside of work.
Much dry. Such optimize. Wow. What's up with the name, though? 
You need to indent the whole thing by four more spaces.
Does it support python 3 yet?
Yes, they should all work on Python 3.
Thanks!! I don't know what other FOSS devs think, but comments like this is what keeps me putting (sometimes too much) time on Spyder :-)
Thanks! Great things are coming in Spyder for 2015, stay tuned!
You make an open source license (I used LGPL) and you make sure they're OK with it. It's not IP under their control if it's online. One company I've worked with complained about a certain file format support (it was a horrific mix of Cython and C and very wrong). They gave me their Matlab version, I committed it with their license, and I used it learn the format so I could write a Python version. If you credit people, they'll generally be pretty happy. My company's policy is just allow any changes you make because then you don't have to maintain them. I've made hack versions for our releases to cut memory usage by 80% (and drastically speed up the code as a secondary benefit). The license on LGPL says you have to submit your changes for review, but when they're hacks I wrote, I don't want them in the official version.
How many hours are you working? I notice a lot of people work way too much. I work 40 hours a week maximum. Period. My current job has never done this, but if they asked me to work even one extra hour, I would say no. If you're working too much, have the guts to demand less hours or find a new job. When you are negotiating with a new employer, make sure you demand 40 hours or less per week maximum, and lots of PTO.
not bad for a long trip. 
34 hours TV per week = 34 hours wasted = 34 hours you can spend on side projects.
Thanks n Sorry bit new to this
Side-projects are easy: If you have something that you are really interested in, you will carve out time automatically (e.g, by deciding to not watch movies/TV shows or reading novels in the "free time" today or at the weekend). Right now, I am busy with a model (machine-learning) to predict the performance of soccer players for daily fantasy sports for example... I find this so exciting that I really want to find the time to work on it ... 
I realize that popularity doesn't mean superiority; if I did I wouldn't be working on Morepath, which is far less popular than Flask or Bottle or almost anything else at the moment. I didn't make the argument very well, but I'll try again. If performance considerations for Python web frameworks for "Hello world" were incredibly important to a lot of people, we would have people complain that Flask is too slow a lot more than they do. Instead, people are generally surprised to find that Flask is slower than even Django at the hello world benchmark. Performance shouldn't be the first thing most people should think about when they compare Python web frameworks. Performance is a very "bikeshed" topic -- you can create benchmarks pretty easily, and everybody thinks they understand enough about it to have opinions and draw conclusions. But I'll grant to you that for some use cases "Hello world" is indeed important -- good point. On the other hand, you already admit implicitly that for some of such use cases the language you love may not be the right tool for the job in the first place. Another point is PyPy -- it's possible PyPy makes a web framework like Flask so fast that its overhead also becomes less relevant again, even for very fast backends. All that said, there remains a place for high-performance Python web frameworks. 
In which ways do you find matplotlib lacking compared to ggplot2?
[Nobody cares…](http://i3.kym-cdn.com/photos/images/original/000/325/428/264.jpg)
The programming is actually invented for this kind of things, so good luck to you!
It's actually something that would make me want to give Python a more serious consideration
http://www.reddit.com/r/Python/comments/2rikx8/type_hinting_for_python/
Have you registered with edX and logged in? If I sign out I see no link either. **EDIT:** OK, sorry, it looks like only those who registered with a course *before* it finished can continue to access the archived course. So you're out of luck until it opens again, which might be in three-ish months (guess). I'm only thinking that because 6.00.1x just started today, and 2x is usually offered a couple weeks after it finishes.
You quit your job! I simply think that most people who work on projects like that actually do not fall in line with the life you describe. They either work part time, are in school, are professors, are paid to do those things or have absolutly nothing else going in their life except for their 9 to 5 job. That means: no familly, no friends, no house to maintain, no cooking, no exercising, no dating, no parties, no going out, etc. There's simply no way you can cook healthy meals, spend time with your familly, exercise daily, nurture your friendships, work a 9 to 5 job + communting time and occasional or frequent overtime, and make progress on a side project. UNLESS You are one of those very few person who require under 4 hours of sleep. And I'm not talking about those people who force themselves into less sleep, cause I still think these people wouldn't make it for very long, I'm talking of the few lucky ones who hold the gene for it as explained here: http://www.dailymail.co.uk/health/article-2713820/Thatcher-gene-lets-survive-4-hours-sleep-Scientists-gene-variant-allows-people-function-sleep.html It's also been demonstrated that the people who have this gene tend to be more successful in life. So ya, unless you have that gene, you just can't, you'll need to sacrifice either your job, or your life.
That's great. Not sure if you are apt at Excel, but all that could also be done right in the spreadsheet with formulas...but it doesn't have the same coolness factor. :D. I made an application in Python once to record class participation points....gave a 1-4 score (mostly 3) for awful, so-so, good, or great in-class comments on the material, and it worked by clicking on the student's row and the number I chose and wrote to a database.
I think there's a myth that developers are either insanely productive (10x devs) or insanely dedicated (not sleeping? then they're coding). I answer Stack Overflow questions at work. I work on my side project very slowly (I've spent about a month and I'm still working out the schema of one). Truth is, all those "I made this at a hackathon/over a weekend" is bullshit. They worked for months otherwise their site would be terrible. People lie. What you have to do is decide what you value. Do you like writing? Start a blog. Do you want to make friends with similar interests? Go to a MeetUp. Do you want to start your own business? Work on a side project. If none of those things really interest you then find something else to fill your time. Cook, play video games, read a book, or whatever your heart desires. You've only got one life. Don't waste it trying to impress people on the internet.
Python is a popular, modern, language with great support. It's also truly Object Oriented. However, at least where I work, we've been burned by typeless languages. A lot of, frankly, poor programmers just assumed the type that would be returned, didn't test well, and it resulted in tons of production errors. Python has been around a long time. I don't think it was intended to only be used in scripts. So, to answer your question, I lnow I want it because it means I could use Python at work.
Thanks for taking the time to show this refactoring. It's a fair point.
Yeah, I didn't say it was right, I just said that's probably why many people support it.
are you sure you are in the right subreddit? because /r/python is where people come to discuss python related matters such as the fact that python 3.5 will include type hinting.
I use [petl](http://petl.readthedocs.org) for anything complicated. There are many other etl framework. I never used them but [bubbles](http://bubbles.databrewery.org) seems nice. You can read the article [here](http://okfnlabs.org/blog/2014/09/01/bubbles-python-etl.html) and the [github](https://github.com/stiivi/bubbles) There are also [luigi](https://github.com/spotify/luigi) from spotify which can be considered an ETL framework. Although this one is way too complicated for my need. For simple one just use csv, json, [xlrd+xlwt](www.python-excel.org) for reading &amp; writing excel and for working with the database you can use sqlalchemy (this is an orm) or you can use the specific modules like psycopg2 for postgres, sqlite for sqlite, and cx_oracle for oracle.
&gt;Harvest is great for this. That ad is atrocious. I watched it to see a demo and still had no clue what their software does. They made some stupid whimsical BS Amelie videothat appeals to the sort of hipsters Portlandia mocks, and never once mentioned their product.
Idk about you but I'm mentally tired at the end of a day of programming. When I'm done with work, it's hard to sit down and program again. It was a lot easier when I had a non-dev job, I was far more refreshed at the end of the day because it required less concentration and thinking.
I don't know, I think it might be the best reason to implement something. The whole point of computers is to automate things that would otherwise have to be done manually, because people suck and are lazy and slow and stupid.
I don't watch TV or have kids. Simple as that really. I do tell the girlfriend I need a lot of time to myself so I can do my side projects, and whether she likes it or not, I made her understand that the time I spend doing this stuff is why I have the job I have, and how I got to where I am today. It's who I am and how I like to spend my time, so that's sort of a requirement for my SO. Weekends I'll spend with her for the most part, but when I get home from work I'll either relax or code. Even if you only code every other day, you'll get stuff done.
much better link thank you.
I'm guessing they care more than they do about Plone.
You can use Python at work now, given Google, Amazon, Lucasfilm, HP, even Reddit use it. &gt; A lot of, frankly, poor programmers just assumed the type that would &gt;be returned, didn't test well, and it resulted in tons of production &gt;errors. As someone who spent most of his career with very strongly typed languages, I assure you poor programmers and lack of testing result in tons of production errors too. Function Whatever(a, b : Integer) : Real; A compiler is going to catch trying to pass the string "possum" into this function, but it's not going to catch that b is supposed to be greater than a and that the return value should be positive. Guess which type of error is more common? 
saw this on Hacker News today http://talkera.org/opencv/
&gt;Benefit: you don't have to way for the long computation to run to &gt;detect the error. But if it's a serious bit of code you're going to want to run tests after every change anyway so that long computation is still going to run.
That's been the Python message for quite some time; it almost feels like Guido is saying the Python critics have been right. :-(
Because the format of the shebang is decided by linux, not Python.
Again, I'm not arguing the point. Just trying to explain a common belief. We were a smalltalk house, and I loved Smalltalk as a language. You can do things with block closures, that JAVA doesn't easily support. Being able to do away with a lot of tedious 'if ... then' logic felt like magic. Smalltalk really does well as a pure OOP language. However, it hasn't kept up in popularity. There aren't a lot of great libraries, and we had trouble transitioning non OOP programmers to the language. A common mistake was to return a string, containing a description of an error, instead of using the correct error handling procedure. Also, because that was a common mistake, people would often just treat whatever was returned as an error, as a string. My favorite joke was 'It's like you took a bridge, that was carefully designed to transport error information, and replaced it with a whiteboard, with a picture of bridge, that said 'Something bad happened'. Still, motherfuckers did this ALL THE TIME. Usually with errors that only happen in production, when the system is getting pounded. So, we get an error that says 'Method not found', in prod, and have to go track it down. I'm not defending them. I'm not saying they didn't make OTHER mistakes. I'm just saying dumb motherfuckers, who couldn't be bothered to check what types they were working with, did this ALL THE TIME. So, my management, who AREN'T programmers, are gun shy when one of the shitty programmers, who's moved to management, says 'I dunno, typeless languages caused us problems in the past'. So, python doesn't get a chance. Is it right? No. Is it true? ... YES!
Interesting, the django integration might be useful to some people, but I think most should stick with `enum` or the backport `enum34` (since it was introduced in the stdlib in python 3.4) You would just do something like: from enum import Enum class YearLabel(Enum): FRESHMAN = 1 SOPHOMORE = 2 JUNIOR = 3 SENIOR = 4 &gt;&gt;&gt; str(YearLabel(2)) SOPHOMORE 
Just scrolled through a few examples and its just the code ripped from official doc without the comments and explanation.
Note that this is an entirely optional and merely establishes a convention for static analysis functionality *that already exists* and will not have any effects at runtime.
They can still be used for whatever you want. This is only a *convention* for optional static analysis purposes and will have no effects at runtime.
IIRC, there will still be no checking at runtime.
I have The book "python for data analysis" and while I like it a lot, it became more useful when I got past the novice stage of data analysis with Python. I strongly recommend understanding the underlying objects that pandas relies on in addition to how you can use pandas to manipulate them. In addition, I also agree with the other people here recommending SQL. I came into data analysis already knowing python and sql and it makes doing things with pandas amazing.
Are you asking us to do your homework?
yes
because the information is Oops, try again. It looks like rental_car_cost returns None instead of the correct amount (100) for 3 days. 
I'm not going to do it for you, but consider the fact that only one of your if/elif/else statements will get executed for each call of the function. Walk through the function in your mind if days = 3
That's not actually correct. There are a couple of subtle differences. Firstly, you can't monkey-patch the print statement, while you can the print function. Whether that is a good idea or not depends on why you are doing it :-) Secondly, there is actually one thing you can write in Python 2 that has [no direct translation](http://legacy.python.org/dev/peps/pep-3105/#specification) into Python 3: print a, print will put a space after `a` and before the newline, which you cannot do in Python 3 without manually adding a space somewhere. However, this is a Good Thing, since the space is normally not wanted. When printing to the terminal it usually doesn't matter and people don't notice it, but when printing to a file it may be a problem. This can be demonstrated by running these two snippets: # Python 2 args = (23, 42, "hello world") from StringIO import StringIO s = StringIO() print &gt;&gt;s, (':'.join(str(a) for a in args) + '***'), # Note the easy-to-miss comma. print &gt;&gt;s, 'X' print s.getvalue() # Python 3 args = (23, 42, "hello world") from io import StringIO s = StringIO() print(*args, file=s, sep=':', end='***') print('X', file=s) print(s.getvalue()) Apart from the Python 3 version being much easier to read, write and understand (I won't embarrass myself by telling you how many buggy versions of the Python 2 one I wrote, with commas forgotten or put in the wrong place), the Python 2 version also puts an unwanted space before the X: # Python 2 output 23:42:hello world*** X # Python 3 output 23:42:hello world***X If I want that space in Python 3, it's easy enough to do: just adjust the `end` parameter to include a space at the end, or prepend it to the X, whichever I prefer. But getting rid of the unwanted space with the statement version is not obvious or easy. The `print` function allows you to set the separator and end delimiter to any string, while the `print` statement does not. That means that for many situations where the `print` function can assemble the output for you, you have to pre-assemble a string and pass it as a single argument to the `print` statement. E.g. in the above example, compare how in the statement-version I have to manually use join and string concatenation, while the function-version does everything for me. 
This sounds like a job that's easier to do by hand than with a script. You'll have to review all the changes anyway, to make sure they don't break the code. What is the actual problem you're trying to solve by removing print statements?
No need to be sorry, we all were new once.
I worked on a log parser that parses about 5 gigabytes every hour... and it was taking about the same time to parse it. The CPU was literally still busy parsing the last log even after it got rotated. Why? I ran `python -mcProfile $SCRIPT` and noticed that two things were taking almost all of that time: `strptime` and `json`. I swapped out `ujson` for `json` and noticed a huge improvement, but it was *still* taking an incredible amount of time. Then I wrote a custom strptime function that pulled out string slices. The format was constant length, so it was trivial to create a datetime object from string slices. *It was 5 times quicker*. Simply pulling out the year, month, day, hour, minute, and second manually improved performance considerably. So, I thought I'd create something a little more dynamic that would be easy to patch into anyone's code: `monkeytime` First: pip install monkeytime Then simply insert this line: from monkeytime import datetime from datetime import datetime And every time you use `datetime.strptime`, it will first build a much more efficient function, memoize it, then reuse it every subsequent call with that same datetime format string. This has a limited number of supported directives as mentioned on the link: ('%d', '%m', '%Y', '%H', '%M', '%S', '%f'). They must be zero-padded, like the output that strftime would produce. This fixed-length attribute is what makes static string slicing possible for increased performance. For most of us who parse logs, we work with fixed-length timestamps and this will dramatically speed things up. And most importantly, if it doesn't support the datetime format, it will just call the stdlib code for that datetime format. It will only use itself when it can. On average running tests with `timeit`, I noticed this ran 4 times quicker than the stdlib with datetime formats that it can support... and with pypy, it was a blazing **40** times quicker. Either interpreter you use, you'll notice an improvement. It's very very hacky. But it works. 
Speaking about **lxml**: upstream doesn't build Windows packages. The Zope Foundation has a Windows VM that builds a bunch of binary Windows eggs, including lxml's (which is a dependency of some other zope.\* packages). It's maintained by volunteers who are busy with other things and therefore little progress has been made for adding Python [3.3](https://github.com/zopefoundation/zope.wineggbuilder/issues/3)/[3.4](https://github.com/zopefoundation/zope.wineggbuilder/issues/7) or [wheel builds](https://github.com/zopefoundation/zope.wineggbuilder/issues/2).
a really good, and short, book on this topic is [How to Live on 24 Hours a Day](http://www.gutenberg.org/ebooks/2274) by Arnold Bennett. there are a million books and blogs about time management but this one is free (available as kindle/plaintext/html via Gutenberg), and the format is very nice. 
And yes, I am aware that I have just Godwinned myself.
Code academy! I recognize the problem. Also, youre getting a discount on 7 &amp; 3 days so ... 
Maybe submit it as a PEP similar in behaviour to `re.compile`?
Not the fact that Google, NASA, Dropbox uses it or the fact that is has more modules than any other language.
&gt; how often do you feel the need to reuse the ability to scrape the Minnesota 2014 Capital Budget? There are three logical steps in that script. 1. Fetch data 2. Transform data 3. Display data How often are you going to fetch data? Pretty damn often, I'd wager. That code is easily re-used. The process data is probably domain specific, but it's not unthinkable to guess you'll be scanning similar tables in the future, especially if you want to compare budgets, like last year's, next year's or even budgets from other states. Keep it as one blob now, and consider expanding it if you need similar logic in the future. Display data in that format. Also variable, but much less domain specific than the last section, and much more likely you will re-use. Worth generalizing a bit. But there are just a few lines, you might say. Why not write it again, or just copy it? It's not like it's rocket science. Well, first of all, why write it again when you have already written it? That's silly. And copying it is arguably even worse. You recognize that you already have the logic, but instead of referencing it, you make a copy of it. Secondly.. There was this old legacy PHP system I had to fix some problems in some time ago. One of the things it did was creating xml files *(by putting together strings)* that were then written to file, and then a big java B2B system read that file and deleted it. The code would then wait for a new xml file being written, read that, and parse the answer. And it was just a few lines, open file, write file, close file, loop while waiting for file 2, then read the data from that. So it was copied for each time they needed it. I found 5 copies of it. Two of them had a character bugfix *(non ascii chars had to be html encoded.. yep)*. One of them checked if the xml file written was deleted, and two *(not the same as the ones with character bugfix)* had a limit to the wait-for-new-file loop. One other had another xml write bugfix I don't remember at the moment. As a result, the system worked inconsistently, and had a lot of ... quirks. I replaced them all with a function that had all the fixes, and that part have worked pretty well after. *Lesson of the story*: Don't copy code. Reference it! Or you'll end up with a nightmare down the line, with some having a bugfix for that, some having a feature for that.. And the fix you remember having done once before for some odd problem you now have to do again because you have no idea where that copy of the code is that have that fix. And even if you ignore that completely, and are sure you'll never use any of it again, separating logical blocks into functions make better code. You only focus on one logical task at a time, making it easier to write that code - you have narrowed the area. You keep everything related to it in a logical area, which makes it easier to read *(and thus write and debug the code)*, and splitting it up again makes it easier to debug, as you can test each part of the code more easily. Compare that with the advantage of not putting it in functions which is ... a few lines of code saved, I guess? And all of that is why not putting things in functions is a really bad habit and shouldn't be encouraged.
Just curious, why can't you use the application? 
OK thanks for the help
actually no, there is some similarity but a lot of stuff is new, and there will be more.
Are you asking what the difference is between how python does multidimensional arrays versus other languages or in general how does a computer/programmer handle them?
Out of curiosity, what was the difference between CPython's and PyPy's datetime.strptime?
I would gladly see a syntes of static and dynamic. Dynamic is great, it makes my work a lot faster and often it requires a lot less code. However static is a lot faster. There are many times where adding types doesn't make coding more difficult. If I know a variable always will be an int I might as well just add int infront of it when I declare it and enjoy my speed boost. I say variables should be dynamic by default but static variables should be allowed. A good editor would use different colours for static and dynamic variables.
You didn't really - you weren't [comparing to Hitler or Nazis](http://en.wikipedia.org/wiki/Godwin's_law), you were pointing out the very real connection between the library's name and the Nazis.
Looks like a handy module. Something I think could be useful would be to not always use integer ids. I often want to use slugs, so a `SlugChoices` class would be handy: &gt;&gt;&gt; food_choices = SlugChoices('Spam', 'Eggs', 'Bacon') &gt;&gt;&gt; food_choices.choices (('spam', 'Spam'), ('eggs', 'Eggs'), ('bacon', 'Bacon'))
Part of what I'm trying to do with my blog is to encourage best practices. My normal production coding process is to include functions and try not to repeat code so I fundamentally agree with what you are saying. Although, I have cut and pasted code before and I should know better :) I tried a bit of a shortcut with this post and now realize that maybe it wasn't the best idea.
wouldn't this do the trick: sed s/"print"/"pass #print"/g inputfile.py &gt; outputfile.py 
I am in fact already using PyParsing in that project, although for something unrelated. I initially thought that this would be the way to go, but in the end I realized that it would get very complex. I need features like arithmetic operations, string manipulation, string interpolation, and list manipulation and I can imagine that I have to extend my DSL with every new instance because I'm running into missing features. It's also way more time-consuming to build a custom parser than just including an already existing full-blown language.
I have to agree with [rotek from the last post](http://www.reddit.com/r/Python/comments/2rikx8/type_hinting_for_python/cngb2cx): &gt; Syntax (mypy-like) proposed by Guido is terrible. &gt; &gt; Comments are suddenly becoming part of the code. Types names are inconsistent. For example, Dict[] and List[] type names are capitalized, but dict() and list() constructors are not. However, in case of int and str, both type names and constructors are uncapitalized. &gt; &gt; Cython-like syntax would be much better approach. &gt; if it goes live there will be no going back, let please not go python 3 launch all over again... I don't think anyone is in a rush to get this feature and python is definitely in no danger of losing popularity if it were to stall a bit. 
Maybe you don't need to mess with sockets directly. Check out the built-in [asyncore](https://docs.python.org/3.4/library/asyncore.html) module, perhaps especially the examples.
If you are processing logs like that you need to read a file in line by line or use mmap. I process 5 gb files in about 5 minutes. I'll also add that if you are writing your logs, log in unix timestamp format. You can sort them as strings or convert the timestamp to an int and it goes much faster than processing it as a time.
I am, and it is normally done all through excel formulas and stuff... but this is way easier and isn't limited to some oddities in Excel's macro creation stuff.
It is quite difficult to sandbox regular Python (it's a common security competition problem) but the enterprising madmen working on Pypy [have a working Python sandbox](http://pypy.readthedocs.org/en/latest/sandbox.html)
[There's already an internal cache](https://hg.python.org/cpython/file/8c25755a7c5c/Lib/_strptime.py#l308) storing the regex generated from the pattern string in _srtptime.py, though it only stores 5 patterns (and gets completely nuked when overfull). Problem might be that [there's quite a bit of processing afterwards to convert and fixup stuff](https://hg.python.org/cpython/file/8c25755a7c5c/Lib/_strptime.py#l342).
Haven't tested 3.x. I'll let you know, or please let me know if you test it first.
I can't get you exact figures right now but that's a dramatic improvement on its own if you're calling it enough and the program takes a while to finish. Pypy can be difficult to give useful benchmarks since the JIT is going to affect it differently depending on the nature of the code.
Sometimes the server will get hung up and if you kill it, it can be 5 minutes or more before you can re-use the same port number. When I am writing TCP programs, and debugging, I'll increment the port number on successive runs and then loop back to the original port number after I'm done debugging. That said, post some code (gist.github.com) and we'll help you where we can. Also, post here instead: /r/learnprogramming If you are using TCP and handling telnet input, you should know that TCP is a stream protocol, it is not message oriented. Meaning you can have packets and messages split up. If you are trying to send messages, then you will need to have some kind of message framing. The simplest message framing is a carriage return. Every time a CR is entered, you process that line. If you want to process messages instead of a stream, you should loop the receive until you get a complete message, then process that message. Otherwise, you can use UDP, but that is 'unreliable' meaning you don't know whether or not it was received. TCP is not quite as reliable as is claimed due to half-open connections, but it is quite reliable. That said, I've had no issues with UDP in my apps. Also note that there may be a 200-500ms buffering done on the sending side due to the nagle algorithm. You can disable this if you need realtime transmission of small packets.
-1 for me. Main reason: The semantics of any "good enough" type hinting system will continue to show limitations for all but the most straightforward uses. This encourages its users to want to expand the specification until it approaches a full generics specification. For example, can I implicitly cast `list[Subclass]` to `list[Superclass]`? How do I pass a `list` to a function that expects an iterable (`__iter__`-supporting) container? Will `list` now have to conform to an abstract `Iterable` interface? How do I specify that my function takes a parameter of `dict[Foo, Bar[T]]` and returns `T`? Don't be fooled: we are signing ourselves up for a *full generics-capable static typing specification* for this feature to be production-ready. Another reason: Type hinting systems without implicit type inference will invite boilerplate code. The specification must cover *what kinds of inference* the linter must make. Final reason: There is a conflation in the proposal between type hinting that helps an IDE complete code for people who *use* a package, and type hinting that helps programmers avoid errors while *implementing* a package. The former can be done by simply standardizing on docstrings notation; the latter requires legislating new syntax. I'm fine with the former. I'm not sold on the latter.
Why do you think that would change anything when everything which is cacheable is already cached, save for the final parsed output?
Because a specialised object would not have to depend on regex and could use slices where applicable. Think generated code a la namedtuple, not a mere instance of a generic class with compiled regexes.
Agreed. I was going line by line. I found "for line in f" to be the fastest outside of mmap (didn't get to testing that). I'm pretty sure that intelligently reads good-sized/sector-sized chunks of the file then yields you subsequent lines until the next read. `json.loads` and `strptime` were still by far the most time consuming. I don't believe unix timestamp format was an option either, unless we missed an argument in the logging program or decide to patch it and recompile.
I tried installing pip and it's a .whl file, I don't have pip on my computer, i'm so lost.
Well, it's compiling code that runs regexs. When running my code it will be compiling code to read string slices. Unless my testing was flawed somehow, when using pypy it seemed to run 40x faster with my code.
You can execute shell commands with the subprocess module import subprocess subprocess.call('ls', shell=True) The above executes the shell command ls - it should print out a list of files in the current directory So if you can find a terminal command for locking/unlocking the screen then it should be executable via python for example: subprocess.call('/System/Library/CoreServices/Menu\ Extras/User.menu/Contents/Resources/CGSession -suspend', shell=True) should lock the screen
Why such a quick change in name?
&gt; They are all padded directives ('%d', '%m', '%Y', '%H', '%M', '%S', '%f') Except for %Y none of these directives is padded (per-spec). Unless you mean that the library only supports the padded form. 
I was going off of http://toastdriven.com/blog/2014/may/23/state-tastypie/, not Tastypie's commit log. Silly me.
I'm not the author, but the original name referred to a story about a woman being forced to choose which of her children would be killed by Nazis. Which maybe is not the best thing to pick as a project name.
May I ask, where does your "ca_postalcodes.csv" come from? The reason you probably didn't find such a module, is that Canada Post apparently [holds copyright on "postal codes"](http://geocoder.ca/?sued=1) and are currently [in a legal battle trying to assert their rights against Geocoder](http://www.cbc.ca/news/technology/canada-post-sues-over-postal-code-data-copyright-1.1208723). IANAL but I'd advise caution with this. edit: [a third link (Michael Geist)](http://www.michaelgeist.ca/2012/04/canada-post-geocoder-suit/), [and a fourth](http://o.canada.com/business/canada-post-says-they-hold-trademark-on-the-words-postal-code)
Just a note: defining choices to be automatically named or numbered is very convenient. It is also precisely what prevents you from changing the label, order or list of choices at a later time without rewriting it all. All enums should always explicitly pair labels and values.
Shame it got written with Twisted. Now it's stuck on Python 2. I don't see why you'd want to be using all this new ideas but locking yourself into the old interpreter.
Than everything else? Ever? For what I want to do there is more available in Python than was ever written in C? C++? Fortran? Matlab? C#? And it's more efficient? And better documented?
Thank you **very much**.
Well. I'm not gonna answer that vague question. But if your concern was type hinting - then yes. You should probably reconsider python. 
While it is safe in this example, on't get in the habit of using `shell=True` with subprocess, it is a security risk if you use any external input to the command.
Well you were equally vague in saying "Python's community [and selection of modules] is bigger and better." There's a chance I may reconsider Python in the future in any event. 
They have more than one?
I'm sorry for my ignorance but what do you define as the *novice stage of data analysis with Python* ?
We're not here to do your work for you. Maybe this will help? http://www.researchgate.net/topic/dynamic_programming
It was 60% 3 years ago. It's not moving towards python 3 at all atm.
I see your point. But with Python 2 been discontinued, it will have to be ported eventually. Also, note that MacOS and most Linux distro still ship 2.7. It's not because they are lazy. The code base is huge, it takes a lot of time. We are the first language to my knowledge to leave such a transition so well. Pearl and PHP failed big time doing this. Most important stuff have been ported (http://python3wos.appspot.com/). The rest in on the way. It takes work.
I meant, zero padded, so they're constant length. %d is always 2 characters, %f 6, etc. It makes it trivial to slice the string up. https://docs.python.org/2/library/datetime.html All the ones that say "as a zero-padded decimal number"
To be clear, I'm about the furthest thing from a lawyer so I really have no idea what the legal implications are here. I for one think it's ridiculous that a crown corporation have legal ownership of the data, much less that they should impose heavy restrictions on its use—but I guess they're hurting for money and want to control access to the data so they can [monetize it](https://www.canadapost.ca/cpotools/apps/drc/home?execution=e1s1). I don't know if there is detailed information out there that describes exactly what is protected ... As someone else already said, proceed at your own risk. Maybe nothing will ever come of it.
I'm gonna echo pretty much what /u/sacred_agents said - I did read through all the legal docs a few months ago just because I found this stuff interesting, but couldn't find whether their copyright encompasses "any part of the postal code", or if 3 first digits are OK. Remember though, it's not because they're available on wikipedia that they're OK to use ;)
very hard to disagree with you...I have no idea how that stuff can hold water in court, I guess we'll see.
...It's not a software patent. They hold a copyright on the information they've spent a substantial amount of time and money recording and organizing. In what possible way is that unreasonable?
Well next time you produce something requiring decades to design, build and implement, then someone duplicates your results based off your work, remember that you don't think you have any reason to protect your product.
I think that "pypostalcode" is too generic for Canada only postal codes ;) And "py" prefix seems redundant. Also, Canada Post sue is really weird, did not knew that, wow.
&gt; I meant, zero padded, so they're constant length. %d is always 2 characters, %f 6, etc. It makes it trivial to slice the string up. That's how I understood it and I'm saying you are wrong. The 0-padding is for str*f*time, strptime parses values with or without leading 0s as specified by POSIX. You can try it out: &gt;&gt;&gt; datetime.strptime("2001-5-3T8:3:7.1", '%Y-%m-%dT%H:%M:%S') datetime.datetime(2001, 5, 3, 8, 3, 7) (for %f it's the trailing 0s which are padding, obviously)
I am not sure this is a viable option, but maybe you can sandbox the users code in docker somehow? I'm not an expert on this though, so I could be completely wrong...
The data for public consumtion is just the FSAs, similar to what this project is using. It's a real pain in the arse that Canada Post feels the need to go after GeoCoder about publishing the full postal code data without making it available to the public themselves - I had a project in mind a while back that involved all the LDUs in one FSA, but couldn't find that data to actually make the project a reality.
/r/learnpython
Then there appears to be no need to freak out the creator of this by saying it is likely he will be sued then? ;). As for the restriction of data: agreed. It serves to only stifle innovation, as you have clearly demonstrated.
I found a [Fusion Table](https://www.google.com/fusiontables/DataSource?docid=1H_cl-oyeG4FDwqJUTeI_aGKmmkJdPDzRNccp96M&amp;hl=en_US&amp;pli=1) of Canadian Postal Codes that I found useful for mapping some stuff for a project at work. 
Oh, gotcha. Interesting. I never noticed that. Well, either way the README says "This ONLY improves strptime when the format string uses padded directives." so I guess it's clear enough that it only supports that subset of input. And since I've made it clear it's using static string slicing, it should be obvious to those that use it that each directive needs to be constant length. Good point though.
If I understand your question correctly, use virtualenv. Heres a helpful tutorial: http://simononsoftware.com/virtualenv-tutorial/ You can install all necessary modules in the environment then zip it up when you want to send it out. 
well, mmap is pretty easy to implement... import mmap mm = mmap.mmap(f.fileno(), 0) (assuming 'f' is the name of your file) then use 'mm' as you would your file. 
They serve no purpose in this case. The author probably spends a lot of time writing in a language that does require them, such as C or C++, and accidentally carried the habit over to Python.
i tried to port a true twisted project to async io and notice severe speed and load issues. the stock twsited reactor just works better for many things. (async, deffered till result, twisted.web heavy load service to name a few) ive said it before in the subreddit ill say it again, asyncio is not a drop in replacement for twisted and shouldnt be even jokingly refereed to as equal. if you want to use python3 for the rest of your project, you make twisted an api/router base and break out required functionality , your client instances should be python 3
Either the author isn't familiar with idiomatic Python, or they were just writing a lot of code in some other language and forgot.
I feel for organisers. On side note, it would have been perfect if it was jazz band, no?
This cleared a lot up. Appreciate it
Well, you just have a *lot* to learn, and things are going to stay much like that for a long time, simply because there is such an enormous amount of things and so little time to learn them. Nobody in the world knows everything about programming, not even close to. Also, consider this - you are not only new to Python, but also to programming, to learning the inner workings of an OS, to software development workflows, to the Python culture, to general software development culture, etc. etc. You are basically learning 20 things at the same time, and there's not a lot you can do about it other than tackle them one by one, ask questions (lots of friendly people around to answer!), read documentation, decide what to learn right now, what to brush over just enough to "fake it" for now, and what to postpone until later. About the problem at hand: Python uses a *module* mechanism to group existing code on your system into handy isolated packages. There are, quite literally, thousands of Python classes and functions installed on a typical system, many of them sharing similar names. It would be quite inconvenient to have them all in the global namespace all the time (PHP, btw., does that, and it's a mess), so by default, only a handful of built-in classes and functions are available, and the rest needs to be *imported* as needed - there may be hundreds of modules available to you, but you don't typically need more than maybe a dozen at the same time. For now, think of a module as a box of "things" that you can pull in so that you can use them: when you say `import sys`, you tell Python to go find the `sys` module, and add it to your current scope. The `from sys import argv` does the same, but instead of pulling in the entire module, it only extracts the `argv` "thing", and puts *that* in your scope. So that's what modules do. This particular module, `sys`, is kind of a grab bag of all sorts of "system" stuff. `argv` is a data structure (specifically, a list) containing the arguments passed to your program on the command line (note that Python is somewhat biased towards Unix-like systems, where running programs from the command line is the norm, and graphical interfaces are a bit of an afterthought). For various reasons, the first element of that list is the file name by which your program was called, so if you put it in `test.py` and run it as `test.py --name foobar`, then the `argv` list will be `[ "test.py", "--name", "foobar" ]`. As far as resources go, python.org itself has plenty of concise information, as well as a bunch of good learning resources and links to more good learning resources. In terms of cool things you can do with python: [you're looking at one](http://www.reddit.com/code/), but there are many many more. Python is basically general-purpose, and there are very very few things that it is totally unsuitable for.
Use virtualenv instead of system libs. Pip install pygame. The DLL failure should be easy to fix. The DLL must be easily found by de exe. 
This is one of the reasons I have my editor run flake8 whenever I save a file. When switching between languages sometimes syntaxes get mixed together.