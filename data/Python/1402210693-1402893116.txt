I was just kidding :)
I have the exactly mutual problem to this — though I think pip’s dependency VSC links feature is not that related to this. Suppose you have the following tree as a whole dependency of the app (*Packages in italic type* indicate they are not uploaded on PyPI.): - *App* - *A* - A-A - A-B - *B* - *B-A* - B-B Also suppose these *in-house packages* are maintained by each others in the same team. If `dependency_links` work well as it worked well the simplest solution to package these in-house packages (including *App* itself) would be dealing these as a normal PyPI package except add `dependency_links` to download in-house packages. Unfortunately recent versions of pip disallow using them by default unless you explicitly specify several `--allow-all-external --allow-unverified A --allow-unverified B --allow-unverified B-A` options. If a maintainer of `A` adds a new dependency to an in-house package (say *A-C*) the installation command won’t work anymore until you add `--allow-unverified A-C`. The security concerns are understandable since things like `dependency_links` and `--find-links` can be [attacked using MITM][1] in many ways. Another solution would be hosting an private repository to host in-house packages. Although to maintain a private repository server is still way troublesome than `dependency_links`. [1]: http://en.wikipedia.org/wiki/Man-in-the-middle_attack
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Man-in-the-middle attack**](https://en.wikipedia.org/wiki/Man-in-the-middle%20attack): [](#sfw) --- &gt;The __man-in-the-middle attack__ (often abbreviated __MITM__, __MitM__, __MIM__, __MiM__, __MITMA__) in [cryptography](https://en.wikipedia.org/wiki/Cryptography) and [computer security](https://en.wikipedia.org/wiki/Computer_security) is a form of active [eavesdropping](https://en.wikipedia.org/wiki/Eavesdropping) in which the attacker makes independent connections with the victims and relays messages between them, making them believe that they are talking directly to each other over a private connection, when in fact the entire conversation is controlled by the attacker. The attacker must be able to intercept all messages going between the two victims and inject new ones, which is straightforward in many circumstances (for example, an attacker within reception range of an unencrypted [Wi-Fi](https://en.wikipedia.org/wiki/Wi-Fi) [wireless access point](https://en.wikipedia.org/wiki/Wireless_access_point), can insert himself as a man-in-the-middle). [*[citation needed](https://en.wikipedia.org/wiki/Wikipedia:Citation_needed)*] &gt;==== &gt;[**Image**](https://i.imgur.com/kjKPQ7d.png) [^(i)](https://commons.wikimedia.org/wiki/File:Man_in_the_middle_attack.svg) --- ^Interesting: [^Wireless ^security](https://en.wikipedia.org/wiki/Wireless_security) ^| [^Quantum ^key ^distribution](https://en.wikipedia.org/wiki/Quantum_key_distribution) ^| [^Software ^token](https://en.wikipedia.org/wiki/Software_token) ^| [^Multi-factor ^authentication](https://en.wikipedia.org/wiki/Multi-factor_authentication) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+ci221wb) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+ci221wb)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Looking at the performance timeline, pypy's performance gains seem to get smaller and smaller with each version. Do you think the project is nearing its maximum speed? Is the pypy team actively searching for, or working on ideas that will boost pypy's performance even more? (Besides STM ofc)
FYI the link to tarball with sources from the download page doesn't work, you've got an extra hyphen in there.
&gt; You'd be surprised how approachable some of the work can be, a lot of it is just implementing new stdlib functions, in Python naturally! Could you please comment on this a little more, where should one start and such? I'd definitely be interested.
Please make the link color more dark. The light blue is hard to read on a white background.
Yes, this
Via HN. Discussion: https://news.ycombinator.com/item?id=7861942 Current top comment, by HN user jnbiche: &gt;I'm really glad to see some of the Python committers taking a serious look at the GIL. Python is either posed for great victory (given its rapid rate of adoption in academia) or slow failure (given the rapid rate at which server apps are starting to migrate from Python to Go). &gt; &gt;However, between accomplishments like Micropython (huge potential for Python on mobile/resource constrained devices) , PyPy's slow but steady gains, and projects like this, it's at least an interesting time for Pythonistas. &gt; &gt;Now, if we could only get an optional static type checker... (heresy, I know). Dynamic typing is great for quick prototyping, and I would never want to lose that in Python, but I'm very uneasy now taking on any large projects or long-term projects without static typing. Mypy holds some promise here, but I think it will take sponsorship from a big company to push something like this to a mature state.
I think you need to say more. Are repetitions allowed? That is, is 67 = 55 + 10 + 1 + 1 an acceptable answer? Or should it be reported as not possible?
I didn't realize that llvm was that much more tuned to compiled/static typed languages. I am still learning about JITs in general as well so I find this all really interesting. Is there a list of stdlib modules needing ported/finished/worked on or some docs on how to get started? Would a site as simple as python3wos work? What are you looking forward to most in PyPys future?
It's really quite simple: * RPython is a VM-building toolkit. * RPython is also a proper subset of Python which can be statically analysed, so any valid RPython is also valid Python * Thus RPython VMs can be run as both themselves (a compiled VMs) and Python programs. You go from the latter to the former through the translation process which is *very* slow (and memory-intensive) so e.g. tests are usually run in interpreted mode (because the overhead of interpretation is still lower than that of translation) * Pypy and Hippy, as well as a few others, are RPython-based VMs, and thus also Python programs. You can run Pypy on top of CPython. Or on top of Pypy, for that matter.
Nice work! Btw I'd like to share with you my new favorite version of 2048 - 3072. And for those who don't have smartphones with AndroidOS ;) Enjoy http://3072.blooplace.eu/
I think this is something where it depends on who you talk to. If you talk to Python users like me who use it for exploratory data analysis or scientific computing, I think they are pretty content with Python for the most part since it provides a REPL environment where it allows them to see results immediately and interactively. What are the alternatives besides maybe Julia? I just can't see myself doing my job or tasks using a statically-typed language like C or Go or Rust or Java. For systems or server side programmers, I can see why they would like to see improvements in Python on the performance side. I think everyone can agree Python isn't the best language for everything (what is?). So although I am glad there are many smart people working on improving Python, as it stands now, Python is a suitable language for my tasks and needs. If it isn't for you nothing's stopping you to use something that is.
As much as the language sucks, the biggest competitor in the data analysis regime is certainly R. Also, while I prefer to do my job in Python, I would love to have real, working GIL-less implementation so I don't have to rely on a crutch like `joblib` to do multithreading. Python is great, but it could gain a lot by having decent threads. And no, processes are not a viable alternative if you need to share a lot of data between the threads.
I found the solution. It was '''event.widget.config(image = Image I Want)'''
It doesn't sound like you were entirely deploying from python packages in the first place? Especially if you don't have your own build server or package server. A friend recently had a similar problem, but for them the solution was vendoring in the errant package. Private pypi servers are awful too. 
Isn't the for loop at line 2 supposed to be indented? for row in range(3): for column in range(3): self.lst[row][column] = Label(self.canvas, image = self.pictures[2]) self.lst[row][column].image = self.pictures[2] self.lst[row][column].bind("&lt;Button-1&gt;", self.show) self.lst[row][column].grid(row = row, column = column)
Yeah, I'll fix it now
Have you tried cython with nogil? If i remember correctly you can also use openmp in cython if the bottleneck is in certain loops.
What do you mean most of the time? I thought down on the C layer, everything is a PyObject, unless explicitly typed otherwise. As long as you give it a type, it wont be the default generic object.
&gt; def write_hello(writable writablevar): &gt;Just bad. Unecessary layer. I dont care what type it is as long as it has a write method. So do we need static type checking really? This seems like a contradiction, caring about the characteristics of the type is essentially caring about the type. 
It *always* has type checking if you specify the type. But the time that this type checking is enforced depends on the setup. If you call a cython function from python, cython can only check the type at runtime. However if you write cdef functions and use them only in cython, type checking happens at compile time.
What about interfaces then? def write_hello(IHasWriteMethod writable): 
"Static type checking at runtime" is a contradiction in terms. 
There are a lot of popular idioms you'd have to avoid with this. Like def print_thing(thing, fout=None): if fout is None: fout = sys.stdout print shit
The nice thing for Python when stacked up against R is how many flaws R has. It's even slower than Python, has really painful syntax, complete lack of namespaces, etc. R is great, but only because it's so popular in academic statistics, so almost everything has been implemented in it. Besides that, Python is vastly superior.
This guy actually got rebuffed on python-dev quite a bit before writing PyParallel... One interesting argument he makes is that Windows async IO setup is actually way better than linux', it's just nobody takes the time to make use of it properly (presumably because very few people are writing low-level network servers in Windows in the first place). Unfortunately efficient use of it didn't get into the `asyncio` module, just "sort like how linux does" use of it, but this is always hard when writing something that needs to work on all platforms, the majority of which are Unix-y.
&gt; given the rapid rate at which server apps are starting to migrate from Python to Go When did this happen?
If I don't miss something, the amazon API has some limitations. For example, you just can't get list of product IDs in some category.
oh really? Did not know.
How come the static analyzer cant read the class declaration? Knowing whether or not a member exists for an object is something computers are very good at...
It's not though. Duck-typing says (In OOP speak) "You should care about interfaces, not types." In other words, you don't care if you've got an int, a Spam instance, a string, or anything else. So long as it has a quack method, you're fine. To see if it quacks like a duck, you have two options: A) You can check for some sort of language/framework level explicit interface (e.g. `if isinstance(thingy, Writable)` or B) you can just do this: `if hasattr(thingy, write)`. The hasattr approach is superior because it's more flexible. If you're doing explicit interface checks, now all external code has to either know that that interface exists (and explicitly record the fact that it supports it) or it will just be rejected by the code as an invalid type. If you're doing it via duck-typing, you just check if it's got the code that you need to call (`write`, in this case) and if not, fail. This achieves the exact same thing with less boilerplate code. 
[markdown-toclify](https://github.com/rasbt/markdown-toclify), a little script to create Table of Contents for Markdown files with internal section links.
Syntax wise yes, but the point is that /u/fuzz3289 only cared about having a write method, but not specifically what it writes to. My interpretation is that the "file" type in /u/fuzz3289 comment is a specific implementation, and there for callers will now have to care about what it feeds specifically, where as with interfaces they only care about what the interface promises is implemented. In short: def write_hello(file writable): Only works with a file object def write_hello(IHasWriteMethod writable): Works with any object that implements the IHasWriteMethod interface. Both of those can be checked at compile time. def write_hello(writable): writable can be anything and cannot be checked at compile time and provides no guarantee that writable has a write method.
It's been a thing recently and I, at least, can't really point to any specific event. But there's been quite a bit of posts about how people are moving their servers/web services over to go and posting their results. I don't know if I'd say it's specifically python that people are moving away from, but a lot of people are definitely moving to go. One example that pops to mind that is pretty big is [Disqus' change from python to go](http://blog.disqus.com/post/51155103801/trying-out-this-go-thing). And that was in May of last year with other people doing the same. It's isn't a drastic thing, but there's definitely a trend going on.
An comes before words that start with a vowel sound. A comes before words that start with a consonant sound. So "A python", "A user" as opposed to "An antelope", "An honor". So it doesn't matter whether the first letter is a consonant or not, but what the sound is.
Why not just do: def write_hello(file/StringIO witeable) It's a whole lot simpler than templates.
&gt; any object that implements IHasWriteMethod interface, which would be either file, StringIO or any third party library implementing the interface. I don't follow. File and StringIO don't have a common class (other than object), so you still need to define file as being related to IHasWriteMethod. If object is good enough (can't the compiler just define the write method in that case and put a NotImplementedError?), then you don't need types for user defined classes. I still see a use for strings/floats/ints having types, but not objects.
I found Guido's [reply on python-dev]( https://mail.python.org/pipermail//python-ideas/2013-November/024079.html) discouraging. "[...] you are looking further forward than most of us." I'd expect the BDFL of a language to be thinking about the GIL now, or at least encouraging others to. Concurrency is among the main reasons non-scientific Python users are switching to other languages (like Go).
Well I'm writing from the assumption that if interfaces where introduced they would be used through out the stdlib and by extension IHasWriteMethod would also be part of the stdlib interfaces, not one you write yourself. I think the desire for interfaces is just that they are really just contracts for classes which states certain things about the object will hold true. IHasWriteMethod would guarantee that you can call write on the object without raising a NotImplementedError.
And I'm working on the assumption that this is not going to be part of core CPython and that the developer/maintainers just plan on using the standard library as is. In that case, it's just a compiler and you'd have to do some things that maybe aren't the cleanest.
Serious question, not trying to be a dick: how is this useful or desirable behaviour? Doesn't it just increase the noise on the sub?
&gt;In that case, it's just a compiler Why, it wouldn't do much more than what is possible already in Python 3 with [function annotations](http://legacy.python.org/dev/peps/pep-3107/). The only change would be the ability to express an interface instead of just classes and just them for annotation. &gt; have to do some things that maybe aren't the cleanest Such as?
It didn't. Python excels at concurrency in the realm of server side apps .. with gevent, eventlet, etc. If you are switching to Go, you are switching for other reasons than simply concurrency. Where python doesn't excel with concurrency is more complex single user applications or data processing applications that would work best with threads.
But the benefit of static types or interfaces (other than the possibility of static analysis as mentioned above) is that an interface not only defines that a method exists but also it's prototype. In other words, an interface defines that a method is called in a particular way, whereas duck typing means you have to be careful that the method implementation matches the implementation of the passed object (all sorts of different objects may implement a 'write' method, but may expect to be used in different ways).
That's a good point. I don't think that (in my opinion) small benefit is worth the drawbacks for explicit interfaces though.
You should write your variable names, comments and printed messages in English so that more of us can read it. This being said, I really like the idea of your script, as knowing the least played numbers is the best (only ?) way to increase your expected gain in a lottery: if you play a rare combination, you have the same chances to win, but less risk that you will need to share with other winners. For this reason I think, the numbers are kept secret here in France.
Yes, this type of bot is more than welcome on /r/dogecoin.
http://i.imgur.com/glxWLGF.png
Ahh, ok, thanks!
Uhm, I actually like doing stats in R better than in Python, and not just because of the packages. Maybe it is because I started with R, but I always find pandas confusing and frustrating, and using formulas and vectors in R feels somehow more natural to me.
Here's a fragment for a brute force way to start you thinking about it: tri_nums = [0,1,3,6,10] mask = [0,1,0,1,0] subset = [a for a,b in zip(tri_nums, mask) if b] print subset, sum(subset) The zip function 'pairs up' the elements of the two lists, returning a list of tuples. The list comprehension extracts only the elements from the tri_nums list where the corresponding mask element is 1. Now, imagine going through each of the possible masks: [0,0,0,0,0], [0,0,0,0,1], [0,0,0,1,0],[0,0,0,1,1],... and so on. Then you could check each possible subset of the numbers and check them... How many such subsets would there be, for a list of tri_nums of length N? (The pattern of the 1's and 0's in the mask should remind you of something...). There's plenty you could do to optimize this approach, but it's a start for you... HTH! (You may want to check out /r/learnpython as well...) 
A static type checker could simply validate that each caller to write_hello is passing something which has a write(string) method. It is completely possible (and in many cases desirable) to have static types without requiring explicit type annotation. A number of languages have such a facility in one way or the other. Static types let you reject invalid programs. That's why you need them, in many sorts of project. Without them, you're left with a language which is limited in its utility, since it has an engineering burden of type-validating unit tests in the place of a type system. That said, I'm fine without static types in Python, but that's because I only use it for scripts.
This guy's a great speaker. I really enjoy his talks
Once again ... there is no migration to GO. **Especially not for concurrency issues with python.** Go doesn't have threads. It has co-routines. Python doesn't have threads. It has co-routines. To suggest that people are switching to Go because of concurrency issues with Python makes me think either you are mentally deficient or who-ever switched is. Python's GIL is a *complete* non-issue for server applications. Only the *completely* un-educated would think otherwise (redditors and bloggers from the sounds of it) ... since you *never* want to use threads in a highly concurrent scenario. Go is compiled ... faster in raw processing performance ... but that's mostly irrelevant when a coroutine is spending 90% of its time locked waiting for the DB and &lt;10% in compute. With a well written application you'll see at *best* 10% speed boost, and likely about the same in memory savings ... switching to Go.
With less boilerplate code? Assuming that I'm in a half-decent language then instead of doing the if hasattr(thingy, write) then I just modify my declaration a bit to be something like def write_hello(w: #writable) and it works. If it has an even better type system it's going to infer that w needs to have a write method and I don't even need to type anything differently.
GvR has been holding back pythons evolution in various ways for a while now, IMO. No JIT in the main implementation as well as missing out on many optimization opportunities in the interpreter, the GC etc, still the bad C API^* that makes python very unpleasant to embed, the GIL, etc. GvR (and other python maintainers, I assume) claim it makes cpython more maintainable, but I would not agree on many counts. Many of the techniques they deny are well-understood nowadays and almost every toy language has them. Will it pay off in the end and actually help python, or impede its progress? My bet is on the latter, but it remains to be seen. Some of these decisions have become very hard to undo now too, of course. ^* Unrelated to the GIL. pythons C API is (mis)-designed to be unsafe towards using more than one python instance in one process, because the cpython API relies on hidden global variables, unlike most other language implementations that make you pass in a VM object explicitly into every function. This prevents you from doing nifty stuff like having more than one python interpreter in a single process that you can switch between, or having two different python interpreters in two different threads -- even if the two interpreters are completely separate instances and share no data whatsoever. You can easily do this with many other interpreters, and it can be very useful for embedding (a browser or w/e) -- and unfortunately every other python implementation (stacklesspython, pypy) wants to be compatible with this mis-designed API because otherwise C extensions won't work.
I'm sure they always take patches for working code that improves it!
Err, no they don't, that was both alexjcs and my main point. Read the mailing list entry linked by alexjcs in the parent comment. Not that it's that easy, of course. As I said, since these wrong (IMO) decisions have been made manifest, they are very hard to reverse. a few "patches" would not be enough anymore now; it'd require a major "re-education" and shift in thinking for both cpython maintainers, writers of cpython extensions, a complete revamp of many parts of the cpython interpreter as well as breaking backwards compatibility in various other aspects that affect normal python users.
NameError: your 'shit' is not defined
I actually think go is likely a better fit for Disqus, it is simply better at what disqus does than python, because it was both written and designed to be better in this field. Go would be an *abject failure* of a language if it wasn't. Python is a general purpose scripting language so I don't think it harms us admitting there is a network-server programming language written by the biggest network server hosting company in the world that's better (mostly faster) than python in that regard. Go is not touching python's scientific programming, GUI or CLI lunches at all, for example. 
Go has threads which coroutines make use of; python's can only use one.
Python excels with 3rd party libraries.. Which means that other libraries you use need to integrate well with those as well. Go's concurrency is built right into the core of language, so there is only one model you need to work with and everything works with it.
Similar to https://pypi.python.org/pypi/pawk
You are mis-identifying the issue; it's not that doing these things is hard to do, or that nobody will step up and actually do it (consider how many other languages that have far less traction than python have many of the mentioned features -- sure, some are harder, but some of the things I mentioned are actually really not all that hard and can even be done without breaking compat!); no, the issue is (and this was both my and alexjcs' point) that GvR doesn't *want* to have them. Once you have made up your mind that you want to reject an idea, you can always find arbitrary reasons to do so, of course, but that doesn't really change the fact that it's actually totally feasible. One example is octave, a language that - has **far** less traction than python, - far fewer developers and - has as number one priority to not break compatibility (because the main reason people use it is because it's compatible with matlab) yet they are in the process of adding a JIT to the interpreter. As long as the python devs don't endorse these kind of projects and keep pushing the principle of "keep it simple at just about ANY COST!" users will follow that line of thinking and those projects won't make much progress. The problem is not a technical one, but the problem is that it requires a shift in how both python developers and community think. That's much more difficult, because many python users and developers interpret it as admitting they've been wrong, and that python (the thing they love the most!) has been "wrong" about something "all along". But that's not a good way of thinking; nothing is perfect, and in my opinion, these things need to be addressed to make python move forward.
I'm not sure there's a big advantage to putting your coroutine pool onto a thread-pool. Heavily trafficked application servers are designed such that multiple processes are a non-issue ... these sorts of systems are designed not just for multiple processes on a single machine, but for multiple processes spread across hundreds of machines. We aren't talking about mainframe applications here. When dealing with heavily trafficked high concurrency applications using a thread-pool has never been a solution that has crossed my mind. I've distributed load with message queues and distributed systems across multiple servers ... but I've never thought to myself "gee why don't we make our distributed system use a thread-pool". I took a look at the rationale from the horse's mouth ... according to the Go FAQ: &gt;When a coroutine blocks, such as by calling a blocking system call, the run-time automatically moves other coroutines on the same operating system thread to a different, runnable thread so they won't be blocked. Though this makes little sense, since a coroutine should release to another coroutine when it begins a blocking system or network operation. It places itself back on the stack, and when the event-loop comes back around it picks up where it left off (assuming the long running operation has completed). Using a thread-pool as they've described seems like it would have disastrous consequences. It seems like you'd eventually just end up with one coroutine per thread. Since each time a coroutine makes a system call, they spawn a new event-loop and thread ... each coroutine would eventually end up on its own thread. Sort of defeats the whole purpose of the eventloop. There's no instance where a coroutine would block as they've described that would require moving the stack to a new event-loop on another thread. The only case where a coroutine blocks is when you must do a long running CPU operation ... There might be a poor argument for using threads in this case, but if you're dealing with a highly concurrent distributed application server the idea of using threads is very quickly quashed in favor of using a message-queue based stack to handle these sorts of operations. In which case they are handled no differently than any other long running network operation. The coroutine sends a task to the message-queue, releases its lock to the next coroutine in the event-loop, then polls the message-queue when it gets its turn in the loop.
You mean like this: https://docs.python.org/3/library/asyncio.html Contrary to your statement python's concurrency functionality is built into the language's core framework. Your argument against the older functionality provided by eventlet or gevent is also fundamentally flawed. Other third party libraries work perfectly fine without any integration or what-ever. Eventlet and Gevent patch python's core networking and i/o libraries ... so any other third party library that depends upon python's network and i/o libraries is non-blocking by default when you're using eventlet/gevent. If you took the time to read the introduction documentation for either of these libraries these facts would have been abundantly clear to you.
&gt; you never want to use threads in a highly concurrent scenario Why not? What definition of 'highly' are you talking about? There are often times when I want a server to make use of all the cores, but the problem is not trivially parallelised like a web server (for example).
I guess the default markdown template doesn't have a TOC placed into. Try outputting to HTML or PDF. Edit: no, [it has](https://github.com/jgm/pandoc-templates/blob/master/default.markdown) the `$toc$` tag. I don't know why it doesn't work. Edit again: [here's why](https://code.google.com/p/pandoc/issues/detail?id=208). 
Did you try it too, or: did it work for you? I am curious now. I tried it on this example markdown file here: https://github.com/rasbt/markdown-toclify/blob/master/example_markdown/test_input.md PS: I don't want to output it to HTML or PDF, I want to keep it as Markdown. But as you said, it should work for both...
I later edited. What is missing is a sneaky `--standalone` or `-s` flag.
On GitHub: https://github.com/rpicard/explore-flask
Thank you. Really helpful stuff.
Highly concurrent = enough clients that you need to design a distributed system ... capable of not just making use of multiple CPU's but multiple servers. &gt;the problem is not trivially parallelised like a web server (for example). I've yet to encounter one of those ...
&gt; caring about the characteristics of the type is essentially caring about the type. Not at all. You only care about a particular method being available. If you care about the actual type, you're saying that only that exact type can be used (even if you only need the one method). Imagine a function that calls an "add" method. For a numerical argument, it would just add the new value. For a list argument, it could append the new value. For a map/dictionary it could insert the key or increment the value as appropriate. With duck typing, you care about interfaces, not data types.
&gt; especially if you tend to write unit and functional tests. Bingo!
Any update. The renewal is also backdated (e.g. you buy a license that lasts 12 months, then you renew after 16 months, your renewal will only last another 8 months), which in theory you can work around by simply buying a new full license (but in my experience it's often cheaper to just renew).
&gt; To suggest that people are switching to Go because of concurrency issues with Python makes me think either you are mentally deficient or who-ever switched is. Wrong person dude.
Just a side note: ever number can be written as the sum of three triangular numbers. 
That's not really the point. Yeah, you can turn the (possibly broken) Unicode Python 3 hands you back into bytes if you need to and pass that to `os.listdir()` etc. And yes, you can pass Unicode to `os.listdir()` etc. in Python 2 (on 2 and 3, you get back the type you put in). The problem is that Python 3 may silently hand your code broken Unicode because it's "decoding" bytes that it simply can't. At least with Python 2, it doesn't pretend it can do what it can't, and it's simple enough to use `isinstance()` to see if you've got bytes or Unicode. Trying to figure out whether you've got valid or invalid Unicode in Py3 is harder, and it's not at all obvious (they're the same class and Py3 doesn't mark in any way the invalid Unicode it passes you). Basically, Py3 has replaced the problem of mixing `str` and `unicode` (in Py2 parlance) randomly blowing up when the `str` contains non-ASCII data with the problem of Py3's `str` (i.e. Unicode) randomly blowing up in your face when it contains invalid Unicode (which was silently handed to you by Python itself). And whether stuff works is now also dependent on the environment, not just the input (thanks to Py3 reading its default encoding from the environment). To my mind, that's not an improvement in any sense. If they'd made mixing `str` and `unicode` (in Py2 terms) an error and left it at that, splendid. But the Py3 assumption that all text is Unicode is a broken one, and they've been adding hacky workarounds (such as surrogate escapes) since 3.0 to pretend that it isn't. At the very least, `str` objects in Py3 that contain potentially fucked-up Unicode need to be marked as such in some way. 
Ok, but by defining "highly concurrent" as "enough clients that you need to design a distributed system" it's basically tautological that you're excluding a class of servers that live in the middle ground. &gt; I've yet to encounter one of those ... These are exactly the kind of servers I work on, in game development. Every client is interacting with other clients and latency has to be kept low, so it's not practical to treat each client in a separate process. But nor is it practical to throw away the extra power afforded by spare CPU cores, as that limits the number of clients you can support. There are various ways people slice and dice the thread-based concurrency in such servers but they can never be effectively replaced by simply switching to a distributed model. (Researchers have tried, and failed.)
Nice code blocks. The main text font looks like ass.
looking forward to the release in July ;)
Haha my bad. I'm sitting here staring at the page like, "WTF is he talking about."
thank, is there a PDF version ?
Definitly NIH. See: https://pypi.python.org/pypi/Pyped/1.0 Which apparently features support for Python 2 and 3, allow you to import stuff, use multi lines and loads stuff like path.py / arrow / requests for you. Sony also created a similar tool : https://code.google.com/p/pyp/ I'd say, you'd better contribute to the existing solutions instead of creating a new one unless yours provide something the other won't.
No PDF version. You might be able to build one from source with Sphinx, but I take no responsibility for formatting failures there. :)
Got it to work now, but it doesn't add the internal links, so it is not that useful to me.
There are definitely some alternatives. I looked into them before building this tool, and came to the conclusion that the ultimate draw of a python tool like this is that someone who knows python well should immediately understand how to use it. Each of the alternatives that I have found and that have been posted here didn't pass that test for me, but perhaps I just have a high standard. Ultimately that's what I tried to build with pythonpy, and if there really are advantages to the other tools, I'd be more interested in hearing about their relative strengths than their mere existence.
Thank you. I like this.
&gt; Contrary to your statement python's concurrency functionality is built into the language's core framework. Built on top of, and not in the core at all. It's a python module with a C extension for Windows interop. If it was built into the core, it would be in Python 3.0, not as a library for 3.3 / 3.4, and synchronous operation wouldn't be the default in the entire rest of the language and most other libraries (hence the need for gevent). If you argue that asynchronous functionality is in Python Core then you're arguing that gevent was never needed. Lastly, it was "already in the core!" [see the conveniently named 'asyncore'](https://docs.python.org/3/library/asyncore.html?highlight=asyncore#module-asyncore)... well which one is it, then? Python is synchronous-by-default, with other libraries / modules invented later to help convert it. This is just how it is, and it's contrasted with Go and Node.js which have asynchronous operation built into the core (truly! Lookup libuv!) and by default. &gt; Other third party libraries work perfectly fine without any integration or what-ever That's just patently false. Otherwise you wouldn't have [a truckload of extra packages](https://pypi.python.org/pypi?%3Aaction=search&amp;term=gevent&amp;submit=search) to integrate them, would you?
Yeah I know, I just replied to you to put my thread in a spot where the discussion had already started.
Thanks a lot! I really appreciate the effort to write this book and then sharing it with the community! It will definetly help me finally tackle Flask!
Happy to help!
He had one of the last talks this year before the closing ceremony and wound up getting cut off, quite unfortunate.
Are you trying to say this doesn't happen? The evidence is pretty clear here, the whole industry keeps tabs on what Apple does at WWDC even if they are committed to other platforms. Actually it isn't just WWDC but product launches bring lots of interest. I remember the engineers at RIM expressing disbelief in the iPhones debut. RIM unfortunately wasn't able to develop a coherent response to iPhone and as such we all know what happened there. 
I use transmission quite a lot but have never thought to extend its functionality. Thanks for sharing!
np!
I don't think this subreddit's style is too bad, but the way that /u/aphoenix is responding to comments comes off as somewhat aggressive. I also don't agree with disabling upvotes/downvotes for non-subscribers. Also, it looks like parts of the tabmenu have been hidden completely: [New theme tabmenu](http://puu.sh/9losA/a7f1bec2be.png) [Default theme tabmenu](http://puu.sh/9louM/01e845599a.png)
In case anyone else runs into this, I ran into something similar on Ubuntu 12.0.4. Installed Python3.4, created a virtual environment, activated it, and found it was still using the system pip instead of the pip in the virtualenv (`env/local/bin/pip`). On my OS X box pyvenv creates an environment with pip in `env/bin` and is in the path when the virtual environment is activated. I'm not sure if I did something different here but as a workaround pointing directly to pip in the env works: env/local/bin/pip install -r requirements.txt
That's awesome. I've just started getting into flask and I see how quick and useful it can be, coming from Django. I'd rather plug my own choice of ORM in anyway. Looking at the blue prints structures, personally I think Divisional makes more sense, because each directory can exist without the others. You can't have *just templates*, but you can have *just the home app*.
To prevent people who aren't in the community from influencing the community. That feature had been changed though.
OK. Well, as I said; that's been removed.
thank you , good idea !
I had the style disabled prior to the current redesign and I plan to keep it disabled. I disable any custom subreddit style that deviates from the stock design by more than a little. I really don't want anybody deciding how a particular subreddit looks. Sometimes it sucks not to have things like line numbers, and I wish more subreddits were capable of only adding actual enhancements like line numbers without also making ten million other noxious changes, but I can live without the enhancements if it means not having to put up with god-awful colors and fonts and whatever. 
First of all, we need more information. What platform are you using? From where and how are you installing matplotlib? If you are using Windows, then download from [here](http://www.lfd.uci.edu/~gohlke/pythonlibs/#matplotlib). There are binaries for both x86 and x64 Windows and Python 3.4. When installing binary extension modules, you must match the version exactly. It's not optional, and a module compiled against 3.3 will absolutely not work with Python 3.4. The binary ABI is not stable across versions. It doesn't matter how much you think has changed in the language, because this is about the C ABI, not the language.
I know, right! Crazy coincidence.
Yeah, it's awesome to see the ecosystem developing.
I think the structure that you choose really just depends on the logical organization of the app. Ultimately it doesn't matter much, so just choose the one that makes sense to you. :)
gracias
I'm saying Apple aren't special in that regard. Sure, they're the Exxon Mobil of phones. But they rip off others as often as the reverse..moreso, if you as me. I'm not here to trash Apple, as much as I enjoy doing so. I was disputing only the assumption that a tech follower would *naturally* fawn at Apple's work. I've been unimpressed since the iPod Touch 1. Little has changed, most OS improvements since then are copies of Android features. I don't object to copying, either. Android is openish: allowing Apple to copy is part of the license. Pity Apple didn't reciprocate with their whizbang rounded corners but hey, can't win 'em all. I haven't watched a single Apple product release since buying my last iThing nearly a decade ago. Not a pride thing, just disinterest. And I remain a techie.
&gt; I had the style disabled Logged out, extensionless browser users are a part of *everyone* however contentious. &gt; I wish more subreddits were capable of only adding actual enhancements like line numbers without also making ten million other noxious changes Exactly my point. Well put.
Where's the printed copy?
Thanks a lot for this! Should be pretty trivial to build out a pdf of this from sphinx.
&gt; I started using Python 3 and so far I did not have this issue. Excellent! It is getting better. I think MySQL-python and Twisted are the biggest blockers right now, but I'm not sure. I'm only currently blocked by Zope/Plone. When I do other work I tend to use Python 3.
&gt; Also, I think you might be stupid. You should call your doctor and get that checked out. I downvoted your comment because of that sentence. Yes I know, you don't care, but it is sad; You have made some **great** points in this conversation, and you have actually given me things to think about (my python experience covers CPU bound as opposed to IO bound), That is until you decided to end with an Ad-hominem. For the record, I'm incredibly stupid too, so please don't bother pointing that out as well. 
This looks really solid. I've been looking for something like this for a long time. Thank you!
Very interesting question indeed. I'd love to know myself.
"I. Am Brandon Rhodes." I love it, it sounds like the intro to a an investigative reporting TV show. I might steal it.
Writing technical articles pays shit. So you can probably get paid in loads of places, but actually making enough money to make it worth the writing is near-impossible. I frequently get offered to write in various minor journals, and they usually pay in "self advertising" or so little that actually using your Linux skills are guaranteed to make you more money.
In `setup.py` you can easily say something like dependency_links=['git+ssh://.....'] Although I'm not sure if its just forwarded to pip itself. *update:* The problem with `--find-links` is that I have tons of internal links to put in there. It's not just to long type without but also no one will remember all those links to put when they want to install or update (and this happens often) anything. `devpi` could be a solution, but bringing another service into the game that needs maintenance and having to wait for some administrator to setup, will not get me into working very soon. Also we still would have the need to build packages and then put them onto devip (or has devpi a feature to track git repositories??)
&gt;Critics of Python as a first language often claim that being too simple, it makes students run into problems when having to use a more advanced language later on. But after both analyzing the programs and interviewing the students, Mannilla et al. concluded that students experienced no problems in the transition. (In particular, they had no problem adapting to static typing after having learned to code in Python.)
That sounds like that was a bug.
I personally dislike the new theme which I find cumbersome and noisy. But I don't really have much time to start endless discussion on the matter.
I don't want to deploy after every commit, but I want to be able (to update to the latest commit). In our case with very frequent updates installing directly from the git repository, being able to specify commit, branch, tag, is so much easier than having to build a package on every commit, dealing with the versioning automatically and putting it on a web or internal pypi server.
After hearing the whole thing will be dropped and hearing they motivation to it, maybe. But is it so extremly unlikely that one would heavily depend on something that's not on pypi?
I'm not sure what the problem is though. It's very easy to use devpi.
Edit: also you can just bundle all your dependencies into wheels. That's what I'm doing.
I don't like the new design at all. It was the last straw and I now disallow custom subreddit styles. The designer of this subreddit has also said that he apparently ran UI studies on this and so has validated his opinion, so I really doubt there is a point in discussing this any further with him.
Well I don't know if devpi can handle and update packages directly from a git repository. But otherwise I would have to build a package, versioning it and put it on to the devpi service, for every commit. Because the packages are actively developed and people need those bleeding edge features. On a normal day I would have done this twice by now. So thats not feasible to do. Having pip install from the latest commit on the repository (or specifying a branch or commit) is just the most practicable way. 
I don't like the new theme: it reminds me of the python.org site, just too blue-ish, big-ish and cluttered (not a fan of boxes everywhere, for example). Plus, when on a mobile device and not logged in, I get a gigantic "Subscribe Now" blue box floating on the screen. Which, of course, becomes more gigantic when I zoom in. 
I don't like it, but I don't think it's totally bad and useless. I prefer for subreddits with a theme that's more like default one (see /r/learnpython for example). Either way I think the majority of people like it, judging by the upvotes on the original thread, so I think that threads like this are pointless and won't change anything. And it **is** true that more and more moderators are taking this theme and just applying it to their subreddits, so that part of the discussion you quote is true.
&gt; Threads communicate with each-other via shared memory. You can achieve the same thing and thus the same latency with shared memory when doing IPC. Sure, but in practice this is not a very effective way to develop a application where more state is shared than not. &gt;&gt; There are various ways people slice and dice the thread-based concurrency in such servers but they can never be effectively replaced by simply switching to a distributed model. (Researchers have tried, and failed.) &gt; &gt; "Researchers" have most definitely succeeded. You've setup a vertically scaled application, which if you actually had some serious traffic would have serious issues scaling. In your model the only way to handle an influx of clients is to upgrade your single machine which has pretty severe limitations. Depends what you mean by 'serious'. These servers are not designed to run 10,000 clients each. But they are intended to run 1,000. Maybe not much more than that. Is that a "severe limitation"? It's certainly a limitation, but for this business model it is still the optimal way to go. &gt; One of the most popular methods of achieving low latency horizontally scalable applications is to use a message queue ... with algorithms like pub/sub. Sure, but unfortunately that approach doesn't lend itself to systems with a large degree of interaction and shared state. You want your authoritative data to be accessible immediately at all times if possible, ie. in the process memory. &gt; Threads have a great deal of overhead in comparison to coroutines/greenthreads. No argument there. But, you can't afford to throw away those extra 7 cores and you can't always write the same code in a multi-process fashion and have it fast enough and maintainable enough. Simple routines like having 2 characters trade items for money become very complex to do correctly and safely when you switch from a locking model to a message passing model. &gt; the designs achieved with message queues seem to me to be remarkably elegant. It provides for a very easy to understand application. They are very elegant, for problems where asynchronous message-passing is a suitable approach. Often, especially in games, it is not. Your 10ms message passing overhead becomes unacceptable when a routine needs to perform several such queries before responding to a client. And then you have certain algorithms that become too complex, as mentioned above. &gt; I really can't buy that you actually believe this. You work in the gaming industry and believe that all of the backend servers are single process multi-threaded applications ... and not using a distributed/horizontally scalable design. I've been working on MMOs and I can tell you without question that the majority of server processes are single process multi-threaded applications. That is not to say that there is no horizontal scaling - there is plenty - but it is horizontal scaling of single-process multi-threaded applications that work, as far as possible, in isolation. The main game server process itself is usually one single process - perhaps several of them are used, each one covering a different geographical area in-game, and some accommodating players in different real-world regions - and some other processes (which are indeed used via message passing) are added for certain functionality that is not latency-critical. But when you connect to one of these game servers, you are primarily connected to a single server and every other player you see in-game (with a few exceptions) is being managed by exactly the same process as you. &gt; You're telling me League of Legends (500,000 concurrent players/day) is using a single threaded application server to handle that much concurrency? No, I'm telling you that League Of Legends is not a single game with 500,000 concurrent players. It's 50,000 separate games each with 10 players connected. Of course that scales horizontally, for some loose definition of scaling. Each of these sessions are isolated and have no interaction with the others. Now look at games like World of Warcraft, Everquest, EVE Online, or Guild Wars, and what you'll see are geographically-partitioned systems of primarily self-contained multi-threaded server processes. (EVE does, incidentally, make heavy use of Python coroutines - but it's still essentially a single-server process, one for each solar system.)
&gt; you only need to profile the bottleneck, and that is worst case, complex scenario And, for god's sake, how do you know that the bottlenecks in 2 are the same as in 3? Your whole sentence above doesn't even make any literal sense (what complex scenario?) I intended not to reply to you anymore, but I can't believe you keep coming up with the trite FUD crap instead of trying to address the points I'm making. So I'll provide you yet another example that you can comment on, if you have something original to say. def myfunc(x): if x &lt; 5: # do something that is faster in Python 3 than in Python 2 elif x &lt; 100: # do something that is faster in Python 2 than in Python 3 else: # do something that is as fast in 2 as in 3 Given the function above, tell me how you profile it manually to decide if it runs faster under 2 or 3. Aren't you going to test it under at least 3 scenarios (x&lt;5, 5&lt;=x&lt;100, x&gt;=100)? If the question you are asked is what the most likely outcome will be, shouldn't you know what the most likely input value the users will pass (will your users mostly call this function with x&gt;100 or x&lt;5 or something in between?). Now imagine having hundreds of similar functions in your code. How do you decide how they'll interact with each other and what the outcome will be, based only on 2.7 profiler runs and visual inspection of the code? The point that you've been missing all the time is that running the profiler only on 2.7 may not show any bottlenecks in the function at all (for example, say that I'm perfectly happy with the overall performances of this function under 2.7, so no bottlenecks to find there). The bottlenecks (or speed-ups) I'm talking about are the ones that will only show up under Python 3. Let's call them the *relative* ones, the ones that you find when you compare one version with the other. And there are only two ways to find out: either run it under 3 (and hence port it first) or guess the relative behaviour by visually inspecting the code for all the scenarios above. So to sum up: - Performance changes with workload (you need to test multiple scenarios); - If you want to know how your system behaves in common usage, you need to come up with average use cases; - Bottlenecks found running a version of the interpreter are not necessarily the same as with another version, likewise efficient code paths in one version can become bottlenecks in the other; - All the above requires several test/profile runs and it's impossible to do if you can't run your application at all; - Pretending to do all the above by visually inspecting millions of LOC is preposterous; 
The problem with disabling custom styles is that some subreddits really require them. Spoiler tags don't work without them, the country flags on /r/europe no longer show up etc.
Awesome!
Pyanoputer, surely. This guy's all right. I wonder if he plays a button accordion.
&gt; And, for god's sake, how do you know that the bottlenecks in 2 are the same as in 3? Because for them to change, it has to be a case of doing something that is RADICALLY different in speed between the versions. The only thing that is radically different is that the Decimal module had been rewritten in C and is at least one order of magnitude FASTER. This will NOT slow down your application. Also, seeking in text files is much slower. But that can be avoided by not doing that, and opening the file in binary mode instead. The other things that slow down the app do not slow down so much that the bottleneck will change. Once again: Programming is not magic, which you seem to think. Nothing will magically change depending on the phase of the moon. This is not something that behaves in unpredictable ways. &gt; Given the function above, tell me how you profile it manually to decide if it runs faster under 2 or 3. I make a test to run that function with indata that I collect during a run in Python 2, under both Python 2 and Python 3, and see what the difference is. &gt; Now imagine having hundreds of similar functions in your code. I repeat: you only need to profile the bottleneck, and that is worst case, complex scenario That bottleneck can get better in Python 3. And then your application will NOT run slower. Or it will run slower. And then you have to think about if you want to move to Python 3 or not. &gt; How do you decide how they'll interact with each other and what the outcome will be, based only on 2.7 profiler runs and visual inspection of the code? I profile the application. That tells me. &gt; The point that you've been missing all the time is that running the profiler only on 2.7 may not show any bottlenecks in the function at all I'm starting to suspect that you do not know what a bottleneck is. &gt; The bottlenecks (or speed-ups) You are not exactly increasing my confidence here. &gt; Let's call them the relative ones, the ones that you find when you compare one version with the other. I'm getting more and more convinced you don't know what a bottleneck is. &gt; And there are only two ways to find out: either run it under 3 (and hence port it first) or guess the relative behaviour by visually inspecting the code for all the scenarios above. No, you profile the app under Python 2, identify the bottlenecks and profile those for comparison. &gt; Performance changes with workload (you need to test multiple scenarios); Yes? So? You know which scenarios you have. You know when it's slow. If you care about performance you have tried to improve it, which means you know WHY it's slow. &gt; If you want to know how your system behaves in common usage, you need to come up with average use cases; No. You need to come up with ACTUAL use cases. Those cases where you ACTUALLY have performance problems. Stop inventing stuff out of nothing. You clearly don't know ANYTHING about performance tuning of applications. You don't know what a bottleneck is, and I don't think you even HEARD of profiling before this discussion started. &gt; Bottlenecks found running a version of the interpreter are not necessarily the same as with another version, likewise efficient code paths in one version can become bottlenecks in the other; No. See above. &gt; Pretending to do all the above by visually inspecting millions of LOC is preposterous; So stop pretending then. I've told you from the start: You profile. It really is that easy, and I don't think you even know what profiling is. You are totally out of your depth here, you have no idea what you are talking about. &gt; I intended not to reply to you anymore, but I can't believe you keep coming up with the trite FUD crap instead of trying to address the points I'm making. I *am* addressing them. If you don't understand the answers, then ask for explanations.
I posted on this and it was downvoted into oblivion... maybe I should have typed more words, added a few quotes about perfection and minimalism, and conjured the great mitsuhiko. Anyways, here's my post. And yes I still hate the new sub. http://www.reddit.com/r/Python/comments/27k0ly/anybody_else_hate_the_new_rpython_style/
This is also the first subreddit that managed to screw up the compact design on i.reddit.com by uploading am empty image for the subreddit logo.
Holy shit that was amazing. Do you also play the piano or something?
And now I wonder what I can do with the ~200ms saved... 
I tried button accordion, but I never managed to play anything advanced. Here the keyboard layout is inspired by the accordion, but the accordion has rows of 3 or 4 keys, while mines have 5 keys (I think it's more convenient given the shape of the computer keyboard)
That's a great start. One gripe: When you hover over a post, a blue border appears to the left of it (which is nice), but this also causes the post to move over to the right. Could you add a similarly-sized transparent border to all other posts, so they don't shimmy on mouse-over? 
That has to be the best compliment so far. Act on that impulse and make some crazy useless web app!
economy is not so great where I live. An extra job wouldn't hurt me.
The main tutorial covers the basics of Flask, but you won't be able to write an actual production ready web application just from reading it. Miguel's tutorial gets you closer to the mark, and is probably comparable to his book and my book. I think the books are probably more comprehensive, but I'll let others decide where they'd rank it all. My goal with this book was to cover best practices for everything, rather than "how to" stuff. EDIT: Whoops, this was meant to be posted in another thread.
Thanks!
Uh ... can seem to find the glitch you're talking about. Can you make a screenshot?
No printed copy. It's just the HTML version. If you really want a printed copy, you can build a PDF with Sphinx and have that printed somewhere. The formatting might not be ideal for print though, so it won't look great.
http://i.imgur.com/rLc5dnj.gif EDIT: The same happens with the OP when viewing a post's comments.
Yes, I have played the piano for years. It's not the same feeling but it definitely helped.
But you don't have the new theme loaded. Enable the theme fist.
Right, sorry. Turns out I'd disabled *all* subreddit themes. 
I see you have RES installed, why don't you just click on that "Use subreddit style" checkbox?
Anyone knows how to build sphinx documentation so that it's readable on kindle? PDF is most of the time just too small and online HTML version is only good with wifi.
For some reason the "submit a new text post" link now is no longer white for me. (Latest firefox nightly). Also I did not yet figure out how to get the keyboard navigation focus ring back :(
So even though I paid for a printed copy...I'm not getting a printed copy.
 &gt;The problem with `--find-links` is that I have tons of internal links to put in there. It's not just to long type without but also no one will remember all those links to put when they want to install or update (and this happens often) anything. There's a `distutils.cfg` file and a `PIP_CONFIG_FILE` (`~/pip/pip.conf`) http://pip.readthedocs.org/en/latest/user_guide.html#config-file There may be answers in the "Python Packaging User Guide", which is relatively new. https://packaging.python.org/en/latest/
**Posting code to this subreddit:** Add 4 extra spaces before each line of code def fibonacci(): a, b = 0, 1 while True: yield a a, b = b, a + b If you are about to ask a question, please consider /r/learnpython
And those *best practices* where exactly what I was missing. Thanks a lot!
try these: https://www.digitalocean.com/community/get-paid-to-write http://tutsplus.com/write-for-us 
btw, you have an awesome name.
I love it, good job guys!
all the code line by line
&gt; Disqus' change from python to go for those who lack the ability to read and comprehend, Disqus replaced one system( the realtime piece). there's still python code. this hardly represents a trend. Disqus has different scaling requirements than the majority of users in this sub. Making shit go faster or consume less computing resources yields actual $$ savings. Given that, as we all know, when faced with bottlenecks in python conventional wisdom says, re-write those pieces in C and glue them together with python. No one would then give a shit if they wrote an article about that. So what is the big deal if they wrote a piece of a larger system in GO besides an opportunity for link bait to increase their market valuation?
Oh my, this is just majestic! Would you mind me translating the article into Russian and posting it on Russia's most popular tech blog habrahabr.ru? If I have time :-)
Thats nice. Using the configs seems like a quick (and not that dirty) fix for my problem, before I can dig into the new packaging formats. Thanks for bringing up that way of dealing with it.
Hmm...now I need to figure out how to attach a guitar strap to a regular keyboard and do some nerdy jamming!
The problem with this is that I don't know every nested dependency the libraries I need to install may depend on. Could be that during the course of a day, so modules are becoming their own package which now is a new dependency I don't know about. In the past the package owner would just insert a new dependency and dependency link pointing to the right git repository. But maybe I could instruct pip to do the `pip install -r requirements.txt` recursively? **edit:** typo
Well I don't know about Salt, but wouldn't that be a bit much overhead?
Guido is well known to be anti-threading. While he has not blocked anything which will enhance threads he has done multiple things over the years which can be regarded as passive aggressive anti-threading.
That is incredible on so many levels
&gt; I believe it would be great if a HTML5/JS/elm developer reading this implemented a browser-based version of the Pianoputer, it would make it accessible to more people. Sounds easy- I'll do it. The program takes in a sound using [HTML5](http://www.html5rocks.com/en/tutorials/getusermedia/intro/), does the same modifications, and maps it to a-z on keyboard (keycode 65 - 90). I'm at work now but this evening I'll revisit. Will I deliver? You'll have to wait to find out.
From a devops perspective, compared to testing and maintaining a script (shell, Makefile, fabric, ...) with sudo or root privileges, configuration management is a win. A high-level break-down of app installation: * install OS packages (git, httpd) * create a user account * install pip packages (VCS clone and/or pull) * set/fix/check filesystem permissions and labeling * open port(s) * copy/generate init.d/upstart/systemd files * (re)-start services
I wish somebody could put together a bunch of pre-built "builder VMs" for the most popular OSes, orchestrated so that I could just push my source to an endpoint and receive back all resulting packages -- a cross-platform Travis-like build system. In fact, it would probably work better as a SaaS offering! Hook it up to GitHub / Bitbucket, and Bob's your uncle. I bet a few companies would love to get rid of some of their build-related infrastructure.
You know I work with MMO's right? Like ones that get 500,000 concurrent players. It's not economical for us to run 1000 EC2 instances, when we can achieve the same thing with 2 ... and provide a much better end user experience with added functionality like playing against friends without the user having to pick a server .. or us to do a juggling act to get them all on one server. The whole vertical scaling thing is dead as of the past 5 years. I'm sure there are plenty of companies that have developers clinging desperately to concepts they are used to. Though it's simply not economical. It wasn't economical 5 years ago, but today it's especially not. Since there's a sea-change going on in how these games are financed ... moving away from traditional subscription models and towards in game purchases. The facebook games do especially poorly with massively sharded servers, since often one of the big selling points is "a single world" ... or what-have-you. Couple in the fact that these games rely upon in game purchases, and you realize fairly quickly the need to scale horizontally is important. Since only 1/1000 players are actually making you any money, you have to optimize for scalability and economics in a way that World of Warcraft never had to. The fact is there's no real justification for writing a single process server. If designed with some thought, the resulting application that's sharing state via message passing and shared caches tends to be in my experience a whole lot easier to develop for and maintain. The only reason you need to write an application as single process multi-threaded, is if you don't know how to do it any other way. There really isn't an argument in favor of such designs, given the alternatives ... other than competency issues with the development staff. Some of your statements lead me to believe that you simply have core competency issues when it comes to distributed systems. Though you argue that it's all but impossible to handle real time interactions and shared states without threads ... the reality is that not only is it possible it's easier, more performant, and orders of magnitude cheaper to develop, maintain and serve. 
Once, I actually wrote a regex for finding URLs. RE = re.compile URL_RE = RE( # Based on RFC 1738 predefined HTTP schema # http://www.ietf.org/rfc/rfc1738.txt # lowalpha = "a" | "b" ... | "y" | "z" # hialpha = "A" | "B" ... | "Y" | "Z" # digit = "0" | "1" | "2" | "3" | "4" | "5" | "6" | "7" | "8" | "9" # digits = 1*digit # alpha = lowalpha | hialpha # hex = digit | "A" | "B" | "C" | "D" | "E" | "F" | "a" | "b" | "c" | "d" | "e" | "f" # alphadigit = alpha | digit # safe = "$" | "-" | "_" | "." | "+" # extra = "!" | "*" | "'" | "(" | ")" | "," # uchar = unreserved | escape # unreserved = alpha | digit | safe | extra # escape = "%" hex hex # search = *[ uchar | ";" | ":" | "@" | "&amp;" | "=" ] # hsegment = *[ uchar | ";" | ":" | "@" | "&amp;" | "=" ] # hpath = hsegment *[ "/" hsegment ] # domainlabel = alphadigit | alphadigit *[ alphadigit | "-" ] alphadigit # toplabel = alpha | alpha *[ alphadigit | "-" ] alphadigit # hostname = *[ domainlabel "." ] toplabel # hostnumber = digits "." digits "." digits "." digits # host = hostname | hostnumber # port = digits # hostport = host [ ":" port ] # httpurl = "http://" hostport [ "/" hpath [ "?" search ]] # Should we support login for http? (login = [ user [ ":" password ] "@" ] hostport ]]) ur""" ( # first group: whole url https?:// # schema ( # one more group for re.findall not to flatten list (?: (?: (?:\w | (\w[\w-]*\w)) \. # Dot )+ # Domainlabel, * in RFC (?: # still no posix character classes :C http://bugs.python.org/issue2636 [a-zа-я]{2,} ) # Toplabel, same as domainlabel in RFC ) # hostname | # or (?: \d+\.\d+\.\d+\.\d+ ) # hostnumber ) (?: :[0-9]+ )? # Port (?: / # Slash (?: (?: [-\w$.+()!*',;:@&amp;=] | %[0-9a-f][0-9a-f] # escapes )* # First path component (?: / # Slash (?: [-\w$.+()!*',;:@&amp;=] | %[0-9a-f][0-9a-f] # escapes )* )* # extra path components ) # Path (?: \? # question mark (?: [-\w$.+()!*',;:@&amp;=] | [/] # Not in RFC | %[0-9a-f][0-9a-f] # escapes )* )? # Search (?: \# # hash (?: [-\w$.+()!*',;:@&amp;=] | [/] # allowing slash in fragments | %[0-9a-f][0-9a-f] # escapes )* )? # Fragment )? # [ "/" path [ "?" search [ "#" fragment ] ] ] (?&lt;! # Look-behind [.,!?( ] # Let's not end with this ) ) """, re.UNICODE | re.VERBOSE | re.IGNORECASE) Are you looking for some subset of all valid URLs? 
Nope, just all valid URLs. Even shortened ones.
Your regex matches anything that starts with `http://` and contains characters valid in URLs, t.co, www, bit.ly, whatever. I believe you're missing a `+` at the end though.
Replace `http[s]?://` with `(http[s]?://|www\.|t\.co|bit\.ly)` then. Note that your regex matches many strings that start with `http://`, but aren't valid URLs.
This is amazing and I love it unconditionally.
subprocess + rsync
For a second I thought you meant a different kind of bowl. Great write up and awesome job!
Do you have any constructive criticism?
Well, if your employment contract prevents you from consulting in your extra time, writing could be an option. But it really is very badly payed.
Yes, you "port" the **function** that is the bottleneck. This is usually a trivial task. **Not the whole application** which you insist. &gt; The rest of your arrogant rant is invalidated by this sentence of yours. You have, throughout this, insisted that you have to run the whole application to know how it will perform on Python 3. And I have insisted that you only need to run the bottlenecks and test it's performance. And now you suddenly claim that me saying that you need only to run the bottlenecks under Python 3, invalidated my claim that you only need to run the bottlenecks? Absolutely pathetic. 
This is from the guys who have brought us pypy/rpython all open source and this php vm itself is fully open source. Nothing is stoping you or I from implementing any required modules and releasing them as open source. If there are big companies that will pay for their commercial modules then more power to them. They deserve it. That money is going to help them continue doing what they do best, make more open source products for us!
I see you have read something up about profiling. That's nice. But you still clearly lack actual experience with it. Your synthetic example simply has nothing to do with real life. &gt; Case1. &gt; func1: call_count=1; tot_time_in_func=1s &gt; Case 2. &gt; func1: call_count=1; tot_time_in_func=10s So, func1 is a loop with Decimal calculations, and Case 1 is Python 3 and Case 2 is Python 2. That's the only way you can get those numbers. You are of course trying to imply that suddenly for no reason one function will take ten times as long to run in Python 3. I'm telling you for the umpteenth time that this is BS. 
Been looking around for an app that would trasnform my kb in a playable instrument for ages, this is awesome. Thank you.
Answer the question, darling. Where is the bottleneck in both cases? &gt; Your synthetic example simply has nothing to do with **real life**. &gt; So, func1 is a loop with **Decimal** calculations, and Case 1 is Python 3 and Case 2 is Python 2. Does the candidate see any inconsistency in the two sentences above?
The second one is an attempt to shoehorn it into some sort of reality. It admittedly does not fit very well. 
I've never seen criticism taken so badly. Just undo the damn theme.
Maybe. I've just loaded up a selection of subreddits I enjoy reading and ones I don't enjoy anymore (but did previously try). It would seem that I like subreddits that don't stray too far from the default style and I dislike ones where the style is profoundly different. For example, compare /r/askscience to /r/ScienceTeachers. The first has its own style but it is an enhancement on the default theme. Its variation is clean and keeps key elements the same colour pallet. The second is much further away from the default and key elements use a different colour pallet i.e. the my subreddits bar has inverted the default colour scheme (default: dark text, light background &amp; newstyle:light text, dark background). This makes flicking between subreddits quite jarring to me. I think that really is the crux of my dislike of the new theme, it's different enough from the default theme to be a disturbance rather than an enhancement. I hope that's of some use to you.
cool -- thank you both
Can you just undo the design? Nobody asked for it and there is lots of negative feedback about this now. You have 27 other subreddits to redesign if you want.
You have to type the name of the collection you want (in your case 'book') after hitting 'd' when the prompt reads 'Identifier'.
Having listened to it, I somehow *still* think he also implied that other type of bowl, too. (LOL)
Whatever makes you happy. Love.
Look at widget inside doThing. It's a top level widget (no parent), and a label is created afterwards with widget as a parent. label is stored for later manipulation as a member variable. Now, widget is local to doThing, and when doThing ends, it goes out of scope. It's the only reference to it, so its python reference count goes to zero, and it is freed by the python memory manager. However, due to Qt parent/child relationship, when a widget is freed, its children are freed as well, meaning that label gets freed by Qt. So now you have self._label which is a python object, you are still holding a reference to it so it's still alive, but it's pointing to a Qt object that has been freed as a consequence of its parent being freed. Boom. Segfault. There are other cases such as this. Briefly said: - Always hold references to parent widgets - Never use WA_DeleteOnClose - Never use deleteLater()
Still more positive than negative feedback. Lots of people asked for it. in fact, it was the reason i was brought on as a moderator.
https://pypi.python.org/pypi/rfc3987
I was already finding it hard to care too much about the redesign. Then you posted the "nothing left to take away" quote. Which is up there with trading liberty for security and "first they came for the X and I said nothing" in terms of pointless clichés that make me disregard an argument. (just so you know)
Thanks. You're actually the second person to say that (or did you say it before?). I'm really glad I've added something unique to the ecosystem there.
If you paid for a printed copy via Kickstarter you should have received an update before this announcement regarding a refund. Sorry that didn't make it to you in time. https://www.kickstarter.com/projects/1223051718/practical-flask-book-project/posts/861783
python 2 is no longer developed and simply speaking is completely superseded by python 3, so just use it. It fixes several issues with python, but breaks compatibility, so some people will stay with version 2 for a while, especially if they are tied to old codebase that is not worth porting, or few libraries they depend on were not yet ported or don't have required maturity. Version 3 (specifically latest stable version is 3.3, while incoming 3.4 is not yet stable - perhaps this confused you) is available for several years and is definitely production ready, so I'd suggest to just use it. There is no split in community - its agreed that v2 will be abandoned, and only bugfixes and security updates will be provided.
&gt; Is there some reason I should have known that the Official download site was not the one I should have used The reason is that it does not offer packages compatible with the version you're using, and that you can't assume something labeled 3.3 will work with 3.4. (Honestly, it was news to me that the official site even had Windows binaries available for download at all. Most projects don't bother. That they aren't quite up to date in offering binaries for the latest version of Python is not a huge surprise, because lots of developers treat Windows as a sort of second class citizen.) &gt; and that I should instead have gone to some professor's private website? Google for "matplotlib binaries windows" and it's the fourth result, right after the link to the official site. It's hardly an obscure site -- anyone that uses Python on Windows should be well-acquainted with it because it is first place to look for binaries, not just for matplotlib. (Well, maybe the second place, after checking if PyPI has a binary egg or binary wheel package uploaded. That's usually not the case, although it's becoming somewhat more common.) 
Ah right cool - yeah I'm definitely an outsider so my info is weak / completely wrong :) The course I'm doing uses 2.7 (I image a few do...) but I'm sure that'll be fine for the basics.... Bit of a bitch it's not backwards compatible, I guess there were reasons though. Onwards and forwards!
You can download the collection 'book' by typing "d" then enter, then "book" and hitting enter at the download prompt. If you want more; you can use other collecttions; or type in 'd', then "all" to download all the packages.
It is! Thanks very much.
I dislike calling subprocess when there's an alternative available. With a subprocess the best you get is a 1 exit and sift stderr captures. Doing things more natively give you a more specific exception on error.
From [JeffKnupp](http://jeffknupp.com/)'s recent [Kickstarter](https://www.kickstarter.com/projects/1219760486/a-writing-idiomatic-python-video-series-watch-and).
I think you and I have different ideas of what an 'MMO' is. The likes of LoL and DOTA are not MMOs in the traditional sense of the term and have quite different - and simpler - scaling requirements. To my knowledge there is no game with 500K concurrent players in a single shared world. The nearest I am aware of was World of Tanks with about 40% of that number, and even that's dubious as it's not clear how much shared state they have. Vertical scaling isn't dead - it serves a certain class of application well. For those classes of app, the GIL is a problem. I'm not going to continue debating with you the problems of trying to convert everything to a message-passing paradigm because it's well-known that certain algorithms are much harder to execute that way. What used to be a 10 line function becomes a convoluted 3-phase commit. If you want to call the reluctance to write everything the harder way "core competency issues" that's fine, but everybody operating in this space has weighed up the pros and cons and is doing exactly the same. I am 100% in favour of preferring processes over threads where it is practical; the only problem is, it's not always practical.
I find it sad that the author didn't expect viewers to have a smaller screen than his. This is really hard to watch on an eeepc :(
He prefers one with zips. *goes back to /r/dadjokes*
This uses a function in distutils: import os from distutils.dir_util import copy_tree SRC = os.getcwd() DEST = '/tmp/swoop' copy_tree(SRC, DEST) print('os.listdir(DEST)\n', os.listdir(DEST)) 
Custom CSS tends to be really annoying. /r/Cyberpunk caused me to turn off custom CSS for all subreddits.
Replying to save
I've seen some of the kids at the school where I work play it. :) There's a fellow who performs with an old PC in this kind of way. I saw a few videos of his concerts years ago and I can't for the life of me remember the name. Seems to me the front man is actually supposed to be the PC and he acts like he's just accompanying it. It's really out there electronic stuff with the PC talking through a Soundblaster card as the songs play. Maybe someone knows what I'm talking about.
&gt; I was already finding it hard to care too much about the redesign. Are you disabling it (preferences), adapting it (extension) or tolerating it. &gt; Then you posted the "nothing left to take away" quote. Last thing I wanted was to begin a discussion on design in general. Those are easily googleable quotes/design principles to let my peers quickly drill down to the essence of my pain. Everything I said was basic web usability and accessibility. It should **all** be quite cliche. It seems most of the dissent here is targeted at my rhetorical style more than anything.. &gt; (just so you know) Thanks for the honesty. I find your e-acute downright pretentious.
`ubernostrum` -- earmuffs &gt; Either way I think the majority of people like it, judging by the upvotes on the original thread, so I think that threads like this are pointless and won't change anything. tyranny of the majority &gt; And it is true that more and more moderators are taking this theme and just applying it to their subreddits, so that part of the discussion you quote is true. boy is this slope slippery..
It was that thread of yours that prompted this post. Do you know the history of `aphoenix` and `r/Python`? Anybody?
&gt; the way that /u/aphoenix is responding to comments comes off as somewhat aggressive +1 `aphoenix` not so benevolent &gt; it looks like parts of the tabmenu have been hidden completely +1 hidden features (add fluff, remove core features)
&gt; I personally dislike the new theme which I find cumbersome and noisy. +1 too much clutter/noise -- too little whitespace &gt; But I don't really have much time to start endless discussion on the matter. Be concise.
How much work was it to make your muscle memory from the straight piano keyboard to the space-filling laptop keyboard version you made up for this?
&gt;The poster you're replying to wasn't referring to your reply to me Read his post again, and my response. He accuses me of using an Ad Hominem (common logical fallacy) ... and I explain it's not Ad Hominem. I'm not using my language to back up my argument. Rather I'm simply stating a conclusion I made based upon your argument and statements. &gt;And I've done exactly the same and can tell you that it is how things are done. Perhaps 5-10 years ago, but the technology has advanced in great strides. Serving 1000 users/machine will not succeed with finances solely coming from in game purchase. Though if you manage to scale to over 100,000 user/machine it's a different story entirely. &gt;You clearly work on a different type of game to me which is why your requirements differ. Given the catalogue at the aforementioned organization this is highly unlikely. I think the big difference is that you aren't working with successful games. If you're satisfied with 1000 clients/server ... and it makes sense economically for your organization (high cost per license and continued subscription fees)... Though really you are digging your own grave doing something like this. Writing a program with the assumption that it's going to fail ... probably isn't a direction management wants you to go in. &gt;Quit calling everybody who disagrees with you stupid or saying they have "core competency issues" and accept that different people have seen different situations to you and have therefore come to different conclusions. Did I mention the guys at this org that were in favor of designs not so distant from yours, cost the company a pretty large sum of cash producing a backend that was beyond useless in production? Did I mention the entire team was let go? I'll call anyone I god damn well please incompetent or stupid ... especially when they are squirting massive amounts of bullshit from their mouth-hole and the "victim" of my "abuse" has said nothing to have me believe anything else. Someone working in the gaming industry as a developer writing real-time network backends for games that doesn't have a firm grasp of how to write horizontally scalable applications (and furthermore thinks it's almost impossible to do so), isn't someone I'd consider competent in their field. Maintaining state isn't any more difficult in a distributed system than it is in a single multi-threaded application. It's not difficult to do it with low latency, and it's not even difficult to do it with a scripting language like python and maintain an exceedingly high level of performance. Suggesting otherwise based only upon your appeal to authority, doesn't have me convinced. It's pretty clear you've never developed or maintained a horizontally scaled application capable of handling massive amounts of concurrent clients. So why even argue in favor of the only system you've ever worked with, when you don't have the core competency necessary to argue against horizontally scaled massively ( &gt; 20,000 concurrent users) concurrent real-time (&lt; 20ms latency) applications. You honestly think no one has ever written a scalable, concurrent, real-time application backend in python that's actually fast ... since the GIL prevents you from "scaling"?
btw.. 75% of voters are for the redesign *at the sticky* 75% of voters are against the redesign *here*
This book is great. And even better now that it's free. Thanks and congrats on the new job, Robert.
+1 links in lists in post body are hidden as dictated by hover action that reveals "edit share save hide delete nsfw"
Python 2 and 3 are very similar, so it isn't a big deal to learn either - you'll pretty much know python 3 if you learn python 2, and vice versa. It wouldn't be a bad idea to start with 3 and see if you can get away with it. The biggest thing holding back python 3 is still the lack of support from some modules that you may want to use (I don't know which ones you need, so I can't say). It's gotten a lot better, though: http://python3wos.appspot.com/ The colon indicates the start of an indented code block. There isn't so much a rule of thumb as it being required syntax to run after certain statements that include indented code blocks. You'll learn them as you learn python - there aren't very many.
Thanks! I really appreciate the support.
Flask can do just about anything!
So you finally realized that you can't continue this argument by just making shit up. Good.
Thanks a lot, completely missed it before. Added the missing type decls now, and calculate the sum without the numpy.sum() function, which gave it also a minimal boost.
This was fantastic, thank you.
It's whatever. I've never received anything I've backed on kickstarter...it's always become "Free" or "open source." I only backed $35 because I *wanted* a physical copy. But now I get an inferior version, just like everyone who didn't pay....yay.
Additional at what [frostidaho](https://www.reddit.com/user/frostidaho) suggested you may also try, if you're comfortable already with the shutil module, I'd say traverse the directory with os.walk() and use [shutil.copyfile](https://docs.python.org/2/library/shutil.html#shutil.copyfile) or shutil.copy depending on the logic. External: [How to traverse.](http://stackoverflow.com/questions/16953842/using-os-walk-to-recursively-traverse-directories-in-python) 
It just seemed like something that would have been solved many times over so I didn't really want to roll my own and worry about my own bug. distutils copy_tree seems to be what I wanted 
The last thing I want is to disappoint, which is why I'm offering the refund. Does that not seem fair to you?
Thank you.
Thanks. I prefer to learn on my own pace though. I'll see if I can find some tutorials/books online for whichever library I end up picking. 
Another thing I overlooked initially was that my initial Fortran code had 32 bit floats in contrast to Python/Cython, but it should be all fixed now 
I did not even know he was a moderator until he redesigned the sub.
Here you go http://habrahabr.ru/post/225745/
I second the vote for Qt via PyQt.
The Qt infrastructure is huge and now extends to android and ios. PyQt and PySide are two packages of Python bindings to Qt. Recently material was added to the python wiki about this, with links to sample code and numerous tutorials: https://wiki.python.org/moin/PyQt 
this is fantastic! i will be showing this as a feature of my local python users group!
This is why I Python. I'm not fond of the speaker's style (I may be alone in this; I do, however, like his willingness to point out things as ugly) but his message is a hymn to the choir. I feel entirely like a designer when I'm refactoring my code such that the appearance is pleasing. I particularly like his bit on naming things to be self-documenting. Python gives us decorators that make this a breeze while allowing us to disassociate potential complexities. Perhaps you want to restrict how often you query a third-party API across a network. Write your function to do the query, and write a decorator that restricts the call to confirm to the API's restrictions. It's beautiful. You've created clear code and separated concerns to reduce complexity. Wonderful talk. Edit: &gt; The biggest sins you can commit is to stop programming when it works Oh gods, it gets better! I don't entirely agree that we should go back and rename calling arguments to match the parameter names in all cases. There are times when the names are nearly synonymous, but provide context about their scope. I can think of no examples off the top of my head, unfortunately. I think that this can me most common in general functions that are indeed called with a number of different argument types. Not all of those types necessarily lend themselves to the parameter name in the calling scope. I think that it's a good guideline, but a bad rule. I will agree entirely where there is a function that will only be called by one other function. Edit: Edit: Damn. I thought that his talk on pluralization would be a discussion on whether a function should take a collection, or whether it should operate on an object and be mapped against a collection. And then he brought a new meaning to the pluralization problem, and had the audacity to provide no solution! Damnit! I suppose that I adhere loosely to the anti-pluralization party, but feel free to abstract upon the type to better describe a general interface that's allowed. Perhaps I don't care if it's a `dict` or a `list`, so long as I can operate on objects provided by the iterator. I'll call that a collection. But I prefer to call a `dict` a mapping. Mostly because I like the way it sounds. *Mapping*. Maybe that makes me more general (I take `dict`-like objects!), but maybe that just makes me an asshole: It's pretty obvious that if it accepts a `dict` as an argument, it'll manage just fine with a `dict`-like object, so long as you implement the interface sufficiently. Well shit. Now I have two problems. Also: Fuck using single letter vars always. I'm lookin' at you, scientists and mathematicians. Edit: edit: edit: And then I watch more and agree with him more. I'm done. Just going to agree with everything and call it good.
&gt;&gt; irregular vertical rhythm &gt; I need a better summary of what this means. your homework for the night. i shall go play in a sandbox and return in the morn.
Pointing out the save button right below each comment so next time you can help us keep the noise-to-signal ratio down.
oh my god, thank you.
With respect to vertical rhythm, are you satisfied with the work you have presented? I am having a difficult time understanding what CSS is owned by Reddit, Naut and /r/Python. This is why I have created a temporary subreddit for my own testing purposes. I can't tell what *you* have "done wrong" and what you have inherited.
With respect to vertical rhythm, please just post *any example* of a place that has an improper vertical rhythm. I retract my edit about it needing to be part of the CSS that I have changed.
useless statistics, all of them.
I've reduced the size of the fonts in the nav bar.
Anyone who could write a perfect translation core mod for 3.5 deserves recognition among the ancients
Where is there a place with proper vertical rhythm here? No matter how i set the lines, nothing aligns.
So forgive me, because like I said, i use the vim bindings and don't typically use tabs. When you go to the home page of reddit: http://www.reddit.com You are able to navigate by pressing tab and cycling through the links that appear, and you get an outline on the links that you focus?
The book wasn't free when I made all of that money. Free books don't make money.
So here is my issue right now. I am asking for *any one example* of the vertical rhythm problem. Just one. Please. Instead of saying "this is all garbage" please give me *one* example of the vertical rhythm issue that you are experiencing. I'm reaching out here. I've addressed some of the things you brought up the other day; I'm going to be addressing more. If you work with me and be constructive, it'll actually be a lot easier. So, again, to reiterate: please post an example of the vertical rhythm problem.
I have removed the Subscribe Now button.
This has been removed.
Hey there! I wasn't trying to be aggressive. I ~~may have been~~ was certainly terse. I apologize. I'm actually a pretty friendly guy. Well, yeah, that's there. Fixed it. ~~The issue that you bring up regarding the tabmenu is actually not an issue. The home page just has different tabs from subreddits. You can verify this really easily using RES by just turning off the stylesheets. Or, you can turn off styles in your preferences to check.~~ ~~We might need to poke /u/aagl so that he can update his score tracking.~~
[a 14px baseline][1] not aligned to anything in particular. [1]: http://i.imgur.com/nDXiwTR.png
&gt;&gt; Either way I think the majority of people like it, judging by the upvotes on the original thread &gt; 75% of voters are for the redesign at the sticky &gt; 75% of voters are against the redesign here Sorry. I was being facetious. The two 75% themselves are not comparable as `aphoenix` pointed out. Pointing it out in the `EDIT` is not inappropriate, however. Again, none of these are real stats ... salt .. grain ..
Yes. This is the only subreddit I frequent where focus navigation is broken.
Well I can't replicate this issue; all the tabs are the same for me with styles on or off. What browser / os are you using?
&gt; I appreciate that you answered this one question / comment. I patiently waited 20 hours before messaging the mods to ask for comment on an active top post. I was curt when I thought you didn't know what vertical rhythm was. I remain unconvinced. `EDIT` Can you guide this topic further? Where, to your knowledge, has vertical rhythm been considered. Are you relying on Reddit, Naut and/or your own customizations. I hate to beat what feels to be a dead horse but I've focused on rhythm to exemplify the leaks in the abstractions. Whose responsibility is it do acheive quality in subreddit design? Reddit or the subreddit. The subreddit can use a "framework" (haven't actually looked into Naut). Rhythm is certainly framework territory but a) the framework needs to implement it and b) the subreddit needs to run *with* it not against it. The same goes for everything. The cascading aspect of stylesheets is immensely powerful and with that power (earmuffs `ubernostrum`!) comes great responsibility. Get back to me when you can. Take your time.
Try posting the code on [pastebin](http://pastebin.com/) and posting a link to it here. It looks like reddit ate some of your code due to formatting. As for the problem you're having, without the missing code I can't tell for sure, but from what I can see here, it looks like currentguess will never be equal to "\^".
Ask it on /r/learnpython
No problem. Apparently just turning subreddit style on and off with RES isn't due diligince on this matter. My apologies!
http://pastebin.com/ACK0ra0F thanks, if it will never be equal to "^", then will i have to write out each co-ordinate one by one and see if currentguess has any of them in it?
What kind of debug system to measure the times you are using that are shown on the screenshots?
ok, will do if no one can help me here, i cant post the same thing within the same 30 mins anyway. :(
I disabled this new theme. The guy who designed this must also be working for Microsoft Metro team and must be thinking this is for the greater good. 
You posted to modmail and I was here inside of a half hour? I don't live on this (or any other) subreddit. I get push notifications for messages, though. If you want an opinion in a more timely fashion, feel free to PM me 30 seconds after you put something like this up. You're right, there are some issues here with respect to the vertical rhythm. I'll make some adjustments when I get time to do so. I'll even make a pull request back to /r/Naut when I'm done and this might get addressed on many subreddits.
Create a directory /static or /media and put your static content in. 
&gt; so I really doubt there is a point in discussing this any further with him. For posterity, and for anyone else who reads this: I'm not adverse to hearing your thoughts and opinions on the theme! Just don't make the mistake of thinking that I'll just implement any suggestion you come up with. I'll listen, and I'll voice an opinion back. I'm not always going to put these things in so you know my mood while I speak -&gt; :D But generally I'm friendly and I want to get to a good solution.
You should be using a two dimensional array for characters, that way you can just check of that part of the array is a chevron or not.
Use webfaction,com instead.
&gt; new maintainers of MatPlotLib are screwing it up badly who are the new maintainers vs the old maintainers???
i have havent I? i have the row then column.
&gt; You're right, there are some issues here with respect to the vertical rhythm. I'll make some adjustments when I get time to do so. Do you keep cherry picking monkey patches? Do you start clean? Vertical rhythm is not easy. It is something you do correctly from the start and are careful every step of the way not to break the rhythm. If Naut hasn't considered rhythm at 2327 lines neither you nor I are patching it in now. Love the allure of the scale of the effect of pushing dramatic changes widely but if that was the desire than shouldn't you be patching Reddit itself? Basically, ***why Naut!?***
You didn't include details about how you installed Matplotlib, and I don't understand what you mean by "imported pip". Also, you didn't include what syntax error you got. I tried to install python-dateutil using pip and Python 3.3, it installed without error. Are you sure you are using a Python 3 version of pip?
Take a look at the documentation Here http://wiki.gandi.net/en/simple/instance/python and here http://wiki.gandi.net/en/simple/git
so [this](http://pastebin.com/Si0EMfUx) wouldnt work because the variable is a string, not an integer?
I'm experiencing varying issues on the same topic of marching ants as well. Naut has the `:focus { outline: none }` right up near the top. However, my Reddit homepage is *not* giving me marching ants around the main links. I believe what `mitsuhiko` is referring to is the blanket marching ants problem introduce by Naut. Personally the **main** links (the core technology that takes users to their destinations) are the most important *not* to lose this feature and yet they seem to have been done in at the Reddit level. What I was referring to originally was my expectation of a designer is to *fix* that mistake not to run with it. \*exhales\* Again, let me just sandbox it.
This is my current attempt to translate a Javascript raycasting example that was recently posted in /r/programming. http://www.playfuljs.com/a-first-person-engine-in-265-lines/ The result so far is pretty cool considering it is just python/pygame (no OpenGL). Unfortunately the framerate is predictably low. Currently I am managing around 20 fps on my laptop. If you have any comments, or suggestions on how to speed it up, I would love to hear them. -Mek
Yup. "1"!=1 You can try those things to make sure before u put them into your code I use iPython for stuff like this :)
I understand that I can put basically everything into the requirements.txt but is there a way that pip also "executes" a requirements.txt of the dependency package? I think requirements.txt are flat and have no way to deal with recursive dependencies. In my case pyramid would be another *in-house* library with somebody making changes and updates to frequently and has its own requirements.txt that needs execution. Maybe I don't get it, but for me it seems like I several steps to install: 1. pip install my_application_from_git 2. pip install -r requirements.txt (from my_application_from_git) 3. look into every dependency if itself has some requirements.txt that needs to be installed And no I can not prepare a flat requirements.txt in advance. We are right in the middle of getting everything into packages and it can be that a script that ones was one now consists of several sub-packages. It is just not possible to keep all the requirements.txt up to date on a daily basis. I'd think even keeping track would be hard. 
Neat especially the outlier selection part.
flask-debugtoolbar and django-debugtoolbar
This is interessting, thank you, how much time do you have to do the course / complete the course once the coupon has been redeemed?
it really depends on what you are looking for. **Tkinter** - is great because it requires no setup because it's a part of standard python, which is great for small apps. **wxPython** - is still python2 exclusively so why bother? **Qt** (PySide, PyQt) - are my choice of GUI tools, well documented, huge community and runs on pretty much everything. My only gripe is that setting it up might be a pain at the start (still can't make it run in virtual environment on Python 3.4 properly). Also one of the biggest selling points is probably Qt designer(let's you design GUI in WYSIWYG manner), since hard-coding GUI is pretty much ridiculous at this day and age. **Kivi** - personally I haven't tried it but heard that's underdeveloped at some points, but has a great community. **GTK+** - haven't tried it either, but Deluge is written in it and it is pretty awesome, except for crashing on windows from time to time. Not sure if supports Python3 yet, since Deluge is written in 2. A lot of them with the exception of kivy work in very similar manner so if you learn one you can migrate to the other one without much effort, I personally recommend Qt because it's big, has a lot of support, great community and seems to be improving with every day, and runs on pretty much everything. Remember Symbian on old nokia phones? yeah that thing was built on Qt. Some Linux desktops are built on Qt or some fork of it.
&gt; Thanks for the honesty. I find your e-acute downright pretentious. I find your condescension and personal attacks on /u/aphoenix downright toxic. So I guess we're even on that one.
Awesome! I've been looking for something like this for quite a while. Will be heavily used in one of my projects :-)
I've used GTK, but QT is good too. If you want some GTK examples have a look at https://github.com/alexandrevicenzi/GladeBuilder
Thanks for the very informative post! I spent about 3 hours looking at Kivy last night. While I liked the tutorials, they were very basic and didn't delve into the UI elements I'm interested in. I'll spend some time with Qt today and see how I like it. 
thanks man
thanks man
Your welcome, regarding kivy, there's this new book which I have, but haven't read yet though I've heard is pretty good, however it's aimed more at the beginners so if you have decent knowledge of python you might find it a bit boring. It's called ["Creating Apps in Kivy"](http://shop.oreilly.com/product/0636920032595.do#PowerReview) 
So a REST API then? What's specific to Django here?
Yeah, I profiled it, and it was actually almost an even split between the `GameMap.cast_ray()` method and the `Camera.draw_column()` method. ncalls tottime percall cumtime percall filename:lineno(function) 1 0.005 0.005 35.255 35.255 raycast.py:1(&lt;module&gt;) 1 0.001 0.001 35.028 35.028 raycast.py:366(main) 1 0.007 0.007 33.384 33.384 raycast.py:338(main_loop) 530 0.003 0.000 32.937 0.062 raycast.py:206(render) 530 0.742 0.001 32.555 0.061 raycast.py:219(draw_columns) 159000 2.501 0.000 17.569 0.000 raycast.py:230(draw_column) 159000 3.186 0.000 14.244 0.000 raycast.py:115(cast_ray) 1541590 3.785 0.000 6.596 0.000 raycast.py:159(step) 929795 2.820 0.000 5.035 0.000 raycast.py:267(draw_rain) 823575 4.991 0.000 4.991 0.000 {method 'blit' of 'pygame.Surface' objects} So, the drawing definitely takes time, but it isn't the whole problem. Thanks for taking a look, -Mek
I just wanted to say thank you for listening to feedback and changing some stuff that most people, including myself, complained about (big fonts, low contrast, empty subreddit header image, etc). It's impossible to satisfy everyone, but you're trying your best and don't deserve being called incompetent or similar, that certain users are doing.
Obligatory I'm on mobile
We at http://flexget.com are still waiting for someone to take lead on developing the webui on top of flask ... ;)
Even in the highest available resolution, it's barely readable.
I, too faced the virtualenv nightmare. I was able to get PyQt5 in a virtual environment, with some work. I think it will work with PyQt4 as well. Don't know about PySide. I wrote up the procudure on Stack Overflow: http://stackoverflow.com/questions/18042919/how-to-install-pyqt5-on-a-new-virtualenv-and-work-on-an-idle One big caveat, though. It SOMETIMES works within an IDE. In PyCharm, it sometimes finds all the modules, but doesn't allow argument hints. Other times, it flat out refuses to see the main modules. The same thing happens with PyDev. I've found that doing all of this OUTSIDE of the IDE, and then telling your IDE that you want to use the new virtualenv folder as your project. It has to do with compiled extensions and code skeleton completeion. I don't know the reasons why you can't install PyQt with PIP or easy_install.
There is no time limit, it's lifetime :) 
Am at work so it was quite a brief look :)
How did you solve the autocomplete issue? I've just installed raw 3.4 Python and PySide binary on top of it and still PyCharm refuses to autocomplete some that as far as I am aware should be auto completed. It's really irritating since it leads me to believe that object x doesn't contain object y because autocomplete doesn't pop up, this is especially common in classes than inherit something from QThread or such.
I'd love to play around with PyQt, but can't get it working on OSX. :/
I am new to GUI myself but I really enjoyed Pyside and zetcode.com has a great beginner tutorial that got moving quickly.
You don't import pip, you use it as a separated program. So, in the same place you would write: $ python you write this instead: $ pip install python-dateutil (without the "$" part, it's there only to indicate the instruction *is not* Python code.)
Another user confirmed for me that reddit, by default, has disabled this feature. It also appears disabled to me (I don't get any :focus outline on the main page). What browser / OS are you using?
I'm not trying to be antagonistic, and I didn't say I don't believe you. What I said was I and another reddit user (the OP of this post, in fact) have confirmed that keyboard navigation using :focus *does not work* for vanilla reddit on the browsers that we are using. You are saying that it does. So clearly, we have some kind of mismatch somewhere. Something that you are doing is different from something that I and /u/aagl is doing. This is a bug; I need a bug report. To start off that bug report, I need to know what browser and OS you are using so that I can test in the same browser and OS. I don't need a video or screen capture; I need the basic information that I requested so that I can be in the same environment and see the same thing. If I can't replicate an issue, then I can't fix it.
&gt; I'm not trying to be antagonistic, and I didn't say I don't believe you. What I said was I and another reddit user (the OP of this post, in fact) have confirmed that keyboard navigation using :focus does not work for vanilla reddit on the browsers that we are using. You are saying that it does. Of course it works. And I have already said in some other comment how you broke it. Look. The reason you get negative feedback on this is that a modification to the theme was made without asking anyone here and ending up with an end result that clearly has problems. So at the very least please don't tell others that they are wrong and imagining things. I would have disabled custom styles already (and i did for an hour) but it broke too many of my other subreddits.
I think your assessment of approval by upvotes is generally not statistically valid. I know more than one person who upvoted this for the discussion, but fully supports the redesign. One of them is me! 
&gt; Of course it works. And I have already said in some other comment how you broke it. Can you please answer this question: &gt; What browser / OS are you using? Can you please read this comment: http://www.reddit.com/r/Python/comments/27o61z/original_reddit_vs_todays_python_subreddit/ci3q8zd Confirmation from someone who also thinks I'm an incompetent that they also don't have the marching ants on default vanilla reddit. &gt; Look. The reason you get negative feedback on this is that a modification to the theme was made without asking anyone here and ending up with an end result that clearly has problems. So at the very least please don't tell others that they are wrong and imagining things. Just so we're clear, I've gotten a lot more positive feedback than negative. I value the negative feedback more than the positive, but I can't completely ignore the positive feedback. Can you stop being antagonistic and just *answer the question that I'm asking you* so I can start figuring out what is happening? **What browser / OS are you using?**
The problem with this post is that it's not really an ISO8601 parser. It just parses ONE out of the 6 * 5 * 3=90(! maybe more, that was a top-of-my-head list of the ones I remember) date and datetime formats in ISO8601. I've got a library on github that parses all of that: https://github.com/boxed/iso8601/ And after parsing all those formats I still left out the entire class of formats that are used to describe intervals, durations and repeating durations. It's really annoying when people call these things "ISO8601", when in fact they are not. It makes it super hard to google for a lib that can actually parse this standard!
&gt; Can you please answer this question: [I already did. 8 hours ago](http://www.reddit.com/r/Python/comments/27o61z/original_reddit_vs_todays_python_subreddit/ci3olcb).
Mavericks or something outdated? Any comment on /u/aagl finding the same issue that I have?
Sometimes PyCharm doesn't build a complete binary skeleton for the virtualenv. I don't know why, but here is what I found. This works for PyQt, so replace Qt with PySide and see if it works. For some reason PyCharm seems to always find the base Python3X install, and if you have already installed PyQt it correctly builds the binary skeleton and you have 100% auto-completion. First, ENSURE auto-complete is working with your base Python install. If it doesn't I'm not sure what to do, but my understanding is that they hard code PyQt/PySide inside PyCharm. 1. Create a new Project and specify the *base* Python3X as your interpreter. 2. Under **External Libraries** in your **Project View**, you will see a library/folder called **Binary Skeletons**. Expand that folder. 3. You should see **PyQtX** and it should have an __init__.py, along with the other core module folders. They should all have __inits__ as well. (You will notice a difference between this binary skeleton folder in the base install, opposed to the one in your virtualenv) 4. Open the problem project in another window. Delete the **PyQtX** Binary Skeleton folder in the problem project's External Libraries. 5. Copy the **Base Python3X** PyQtX Binary Skeleton folder into the VirtualEnv's External Libraries/Binary Skeletons/ 6. Do a File... Invalidate Caches and Restart. This seems to work for me.
Nope.
On my Chrome and FF both up to date (not nightly, but still current) there are no marching ants in default vanilla reddit css.
They weren't there before. I put them in and now I'm trying to find an unobtrusive colouration for them.
First things I can think of: Don't use double underscores on the class name. There is no point and it just confuses people, just name them with a normal name (Entry). Second, your code may become harder to read and depending on what these classes do you won't be able to easily test them.
Are you using python 3?
John Hunter wrote the original library many years back and was the bdfl of that library. Sadly he died suddenly of cancer just a couple if years ago right after a SciPy conference. I don't know the current maintainers but their choices speak for themselves. 
What? Pulling out of dependencies is adding bloat?? All dependencies were already in matplotlib, the developers just pulled them out of the mpl source.
You can avoid most sys admin duties if you choose a host that handles that, and that may be a good way to start. Eventually you may want to delve into those details and have greater control over the environment and get your own server/vps etc. 
Sure thing, Usually these classes are just a collection of properties. I know a lot of people take advantage of tuple unpacking, but I have a hard time keeping track of longer tuples. Since I'm just creating the class for the sake of readable properties, I'm not too concerned with testing these mini classes. [Here](https://github.com/arecker/Marissa/) is my project, btw. It's a CLI podcast manager.
(1) I do this often (less often now than before), except that I declare the nested class at class scope, e.g. class Outer(object): class Nested(object): def __init__(self, ...): # Nested.__init__() . . def __init__(self, ...): # Outer.__init__() . . Most typical usage for me would be class-specific exceptions (e.g., exceptions that are thrown by a Parser class). (2) I typically would only define classes inside method bodies when the class definition might depend on the instance or other dynamic variables. I do this very rarely, as, to me, the code looks ugly and I usually can figure out a way to redesign the logic to make things both conceptually as well as practically more elegant. (3) In this day and age, I would not define a class that does not inherit from '`object`' either directly, or indirectly. (4) I would not try to munge the class name with double-underscores: single-underscore prefix to denote "private-by-convention", or nothing (namespace encapsulation is already given by the nested definition) (5) I think one justification for nested classes is to avoid cluttering the global namespace with class definitions that nothing apart from the outer class will use. Others may disagree. 
This is written to run under both. It performs slightly better in Python 3 however. -Mek 
You should definitely take things one step at a time, but don't despair. While it is useful and most of all 'fun' to become a linux/Unix ninja, you can practice your Python webapp programmin' chops using a Platform as a Service (PaaS) such as Google App Engine, Heroku, or similar. They support several languages and some frameworks like Django, Flask, or Jinga2. Definitely read up on them. Many are free for small apps and are easily scalable. 
Sadly, this means that you've not optimized for python 2, which should actually be more performant than python 3. range in python 2 will first create the list and then iterate over it. For python 2 you want to set range = xrange. This won't improve it drastically, but it will improve. If you have the ability to pre-calculate anything and use a dictionary as a lookup, that may also improve some of your timing. Anything thats in a list is significantly faster than other data types for lookup. So it may make sense to pre-calculate/pre-populate your ranges.
You will need to learn to manage a UNIX server of some kind. However, there are ways to side step it for a while - see my blog post: [How to learn Django without installing anything](http://lukeplant.me.uk/blog/posts/how-to-learn-django-without-installing-anything/) And PaaS are improving all the time, so you may be able to avoid things for even longer, depending on what kind of application you need to develop.
The range issue is handled at the very top of the code: if sys.version_info[0] == 2: range = xrange Dictionary look ups are used for checking map cells. There may be other things that would benefit from being hashed but I haven't found them yet. -Mek
Can't speak much about flask,but with django you can get a fully running development server with only one command. This will be more than enough for you to explore and learn. In my personal experience it was several months into learning django that I ever tried to do a real deploy. Knowing server stuff is invaluable as a web developer but you can cross that bridge when you come to it. Edit: to answer your original question, don't be intimidated, every great dev was where you are now! I'm not even that much further along than you and sometimes I impress myself with what I manage to make
Have you tried using Memoize?
I'm not sure click is much better than argparse which is in the stdlib. A little less verbose maybe.
I guess the CSRF token. I had the same problem, and while I only skimmed the article, all it really does is just add the csrf token to the post headers. xhr.setRequestHeader("X-CSRFToken", cookie.get('csrftoken')); Is my solution, pretty much the same thing.
&gt; but I have a hard time keeping track of longer tuples For this usage, you want to use '`collections.namedtuple`'. A "collection of properties" is almost the exact use-case for which this was designed, and this would the clearest and most obvious and most idiomatic way to go about doing it. 
Use collections.namedtuple instead: standard, self-documenting, easy to use, hard to misuse (a misspelling will give you an error).
I haven't for this, but I can't think of how it would be applicable. The player's position and angle are both floating points. This doesn't lend towards a finite set of cacheable items. I have considered doing initial area collision tests around the player so that each ray doesn't have to be projected all the way from the player's origin, but I haven't tried implementing it yet. -Mek
Aye, handling all the use cases for cli arg parsing gets complicated quickly and I feel like that starts creeping out regardless of how much you want a simple interface.
A PaaS like heroku will take a lot of pain out of the worry of "is my app working? Is stuff being served? Am I vulnerable on port 51 of my custom VPS? Oh god what ciphers to set on nginx?"
Sorry about that! I'm redoing the first video now for this exact reason. Expect an update in the next day or so.
Jesus, I've never disabled a subreddit's theme until now. Pardon the hyperbole, but this is a fucking abomination. It's like someone ate up a whole bunch of almost-trendy websites from 2008, and then crapped out this horribly-diseased stylesheet. Sorry, I know someone put a lot of hours into it, and I'm not saying I could design anything better (I freely admit that I suck at design), but this is pretty bad.
Posting links to personal accounts such as twitter will get you banned site-wide. http://www.reddit.com/wiki/faq#wiki_is_posting_personal_information_ok.3F
Your philosophy of taking one step at a time is perfect. I think it's the natural path to follow. Eventually (even using PHP) you had to get your hands in http servers and init scripts.
I don't think argparse does nested function. The alternative to click is [aaargh](https://pypi.python.org/pypi/aaargh/0.7.1), not as mature as click, but a bit more intuitive.
Yeah, that makes sense. It seems like there should be an effort to write a real comprehensive ISO8601 parser using C to make it fast. I wonder what the challenges there would be.
It's ok, I'm fine :P I'm just happy you finished something that, so far, looks well received. 
**Thank You** That did it. Then when I attempted to import matplotlib, It blew because it could find pyparsing. So I did the same thing (pip install pyparsing) and **that** worked too! Thank you! I hope I didn't screw up when I gave you gold. :-) If matplotlib doesn't do this as part of the installation process, why don't they mention it somewhere in the documentation?
Thanks, I really appreciate that. If you ever change your mind about the refund, just hit me up. I'm more than happy to send it to you or donate it to charity for you.
Sorry, I thought I responded already. It turns out I posted in another thread: http://www.reddit.com/r/Python/comments/27nnuf/explore_flask_is_now_freely_available/ci305g1 The main tutorial covers the basics of Flask, but you won't be able to write an actual production ready web application just from reading it. Miguel's tutorial gets you closer to the mark, and is probably comparable to his book and my book. I think the books are probably more comprehensive, but I'll let others decide where they'd rank it all. My goal with this book was to cover best practices for everything, rather than "how to" stuff.
I had a problem yesterday with Django Rest Framework and Angular, but the problem only appeared in Safari and was stated in the console as having to do with different access-control-headers, including variously 'accept-encoding', and 'cache-control'. Turns out it had to do with the trailing slash (django adds them, angular removes). While other browsers would follow the "permanently moved" on a GET, Safari would throw header errors. Anyway,fixed the trailing slashes and now it works in Safari. That was an interesting one to debug. 
Wow...some!
Pretty cool! I am currently working on a raycaster as well, just in Lua/LÖVE - ([code here for the interested](https://github.com/christiankolding/love2d-raycaster)). My current framerate is 7-8 fps. How did you manage to improve it to 20 fps? Maybe I can use some of the same optimizations.
Well I reject your hypothesis on the basis of https://github.com/matplotlib/matplotlib/graphs/contributors but even if it was true, the past is not roses and unicorns. Remember the original mpl maintainers gave us from matplotlib.pyplot import * #god hates import * and the whole horrible matlab compatible api...
Thank you! I bookmarked it and will be checking it out when I'm ready to sit down and mess with it.
Is JavaScript that much faster than Python? It didn't seem like the original version did any crazy optimizations.
There are some good reasons to want an internal class : - you want to avoid polluting the module namespace with a class that will clearly have an internal and limited scope/behavior. - you want to generate the class on the fly and a metaclass is overkill - you are lazy and this is just a draft / a prototype and fuck it it's 4 am. - your boss want that for tomorrow and fuck it it's 4am, and Monday. But your case does not fall into one of these. You actually should define the class outside of you current class, and allow it to be passed in some way (class attribute override or \_\_init\_\_ parameter). First, it's easier to read, to unit test and to get documentation for it. You can split the code in several files if needed later, you can use one without needing the other and possible side effects, and it forces you to think about the duty of each object, helping with separation of concerns. Secondly, it will allow subclassing the \_\_Entry\_\_ class (which, as been said, should be named with no underscore) to add additional features without the need of actually modify your code. This will help future you (or future colleagues). You don't know it yet, but you gotta trust me on this one, future you often think past you was an asshole, so don't give him too many chances to complain. One possible solution : class RssEntry(object): """ Some doc here """ def __init__(self, your_args): # your attrs class Parser: """ Some doc. Mention RSSEntry """ # The class used to represent an entry internally. # Override it at the class level to change all parsers # behavior or at the instance level to implement a # custom parser. entry_class = RssEntry def __init__(self, url): feed = feedparser.parse(url)['feed'] entries = feedparser.parse(url)['entries'] self.title = feed['title'] self.subtitle = feed['subtitle'] self.link = feed['link'] self.entries = [] for entry in entries: self.entries.append(self.entry_class(entry['title'])) This is what composition is all about, it allows dependency injection in a clean and easy way. It sounds complicated but really it just mean later you can always say "oh shit I need some additional feature on RssEntry but I can't modify the code or it will break the other stuff... Oh wait, i can just make another class, good, let's have an ice cream" And it will force you to not couple your two classes too much together, which is always a good habit. Eventually, if you are absolutely sure you don't need any logic in this class (no method what so ever), you may just want to turn it into a dictionary, or even a namedtuple. In that case, the entry_class won't be necessary, but I'm betting anything with a parser will need some flexibility as some point and I advice for the class.
The main thing I did that improved the frame rate also greatly limits the usability of the program. As soon as a ray detects a tile with a height greater than 0, that ray stops casting. This means that maps with multiple heights won't work as a block with a height of 2 wouldn't get drawn if a block with a height of 1 was in front of it. -Mek 
One other mention... I have three screens and I run on a laptop. On my standard laptop screen, I actually end up using the intel processor unless I specifically call out the nvidia chipset. When I do call out the nvidia chipset, my frame rate more than doubles using your code.
Fantastic answer! Thank you for your time.
It's not about sales. It's about getting donations and sharing knowledge. You owe it to the world to give back. That's what books should be for. The money is just a bonus and $10k is more than worth it. Have you considered doing something for your next book like tangowithdjango.com or djangobook.com, where the content is completely free? You can put a donation button on it if earnings are that important to you.
I use Webfaction, they play very well with Django and the setup is easy and cheap.
Hah, this guy right here ;) I donate to STM for PyPy every once in awhile, for horizontally scaling web applications (ironically?) -- throw a fiver in that pot whenever you get around to it.
A couple of people have recommended Julia and Scala. Does anyone here agree with Julia and Scala?
Lately I've just been using the browser as the interface to my applications...it's the perfect cross-platform candidate and HTML/CSS/JS UIX is much easier (for me) than trying to do the same thing in Qt Using Sockets you can even use the browser's development console as a python console.
All we have sitting on there is the raw data. All processing would be done after the user has move the data to their own machine. Which data is accessed and what regions of that data are to be used will change depending on the user, so everything would need to be dynamic. I have thought about using fabric to pass information to a script sitting on the server, then let that script do all the work, then using fabric again, download the newly created file. Webservice just seems like it is difficult to get into, especially for doing in on a server. That may just be me, since I have never done anything with a webservice. (Also, sorry, thought I replied to this a bit ago) 
Courtesy TIL.
Indeed. Bank of American had a booth at the career fair and was hiring Python programmers, for one. There were also other finance companies present.
If you're going outside of the stdlib, I like [docopt](http://docopt.org/) myself.
Yeah, from memory Merryll Lynch and Morgan Stanley and possibly another one or two.
Well...this is embarrassing. 
I think the documentation of almost every scientific python package mentions that it is much easier to use prepackaged distributions than to you own, most of time with a big fat warning for windows. Note that even years ago, you needed numpy. Following your point, they should had also bundled that. All the new maintainers (which are 90% the same) did, was to unbundle dependencies. If you use gohlkes site or pip in the right way, they all are easily installed. 
Java handles UTF-8 differently to avoid \NULL characters in the data stream. The python library does not reflect that. See http://docs.oracle.com/javase/7/docs/api/java/io/DataInput.html#modified-utf-8
I don't have any specific tips, but have a look through [requests](https://github.com/kennethreitz/requests). Documentation within that is pretty good from what I've gone through.
I've always liked the [Pyramid documentation](http://docs.pylonsproject.org/en/latest/docs/pyramid.html). Numpy also has good documentation, but I'm pretty sure they use a lot of custom classes, decorators, etc. to make their documentation to work the way they want. With a library I would say the more documentation you can put in the source code the better, but there is a point where there could be too much and coding becomes difficult. If you are using [sphinx](http://sphinx-doc.org/) you could use [apidoc](http://sphinx-doc.org/man/sphinx-apidoc.html) to help autogenerate some starting docs. I would not put class docs in per class files, unless that's the way the source code is organized. Obviously you want to group things as logically as possible.
THANK YOU!! This is the resource I've been waiting for :D I've been writing my own VM + Compiler in Python and seriously needed to spruce up the IL and Semantic portions. If I ever document/blog my process I'll be sure to reference you.
I should have explicitly disclaimed the triviality of all statistical claims involved.
docopt feels to magical. We're switching everything to click.
[relevant elcor](https://www.youtube.com/watch?v=5USn_CT_DpY)
I'm a nerd because I told you that posting personal information is not ok and no allowed on reddit?
Yes that's correct, I do not use the modified UTF-8 format. I should probably be more clear about that..
Okay, this is going to be my last reply to your comments. I feel like you completely miss the point of everything I say and when I respond to you, you just change the topic. I appreciate your interest in my book, but I don't think debating you on this is going to improve either of our lives in any meaningful way. Just to make my stance on this clear before I wrap this discussion up: Free books don't make money. If you don't care about the money at all, making it free is a great way to get it in front of thousands of people rather than hundreds, but you don't owe anything to anyone.
Happy to help! Let me know what you think.
I went ahead and threw a twenty-fiver in just for good measure. :) Feel free to send me your email address if you want a confirmation.
I see some copper-looking tubes over what would be the CPU's for those Raspberry Pi's. Are those heatsinks, or are those part of the mounting racks you used?
I'm actually planning on contacting the maintainer, because I implemented the ability to just copy directories/files instead of rendering them and I want it merged. There's more stuff that I want to do, like variable substitution in the cookiecutter.json file itself, but I want to know I'm not working in vain.
[What?](http://i.imgur.com/WuKZd.jpg) I don't even... Dude, you've got some issues...
Not really, cpython has no JIT.
This is pretty cool, I've installed it into my global Python ;)
Oh no, my points are all still valid and you are not answering my questions. Just being abusive all the time. It's not going unnoticed. As I said, whatever gives you satisfaction. 
Thanks. Apparently most of the boxes are gone as well. Cool.
The problem with the maintainer accepting pull requests is pretty well described here: http://audreyr.com/2014/02/28/cookiecutter-hits-704-stars-on-github/. Reading between the lines, this is my take: * Insistence on high code quality. * Maintaining code across multiple operating systems is hard. * Does what the maintainer needs, so unless someone sponsors them, nothing is more is going to happen. I just talked to the owners of my agency and they refuses to provide sponsorship. This is frustrating because it's another good project withering on the vine.
Here is the [source](https://gist.github.com/jasonsperske/31324a0cdffd8edf9683): #!/usr/bin/env python3 import struct import re import io from collections import namedtuple GrpFileDefinition = namedtuple('GrpFileDefinition', 'name size') Line = namedtuple('Line', 'a b is_one_sided') class Grp(object): """Encapsulates the data found inside a GRP file""" def __init__(self, grpFile): """Each GRP files contains the contents of several files""" self.levels = [] with open(grpFile, "rb") as f: header_size = 12 self.ken = f.read(12) self.num_files = struct.unpack("&lt;l", f.read(4))[0] self.points = [] file_defs = [] for _ in range(self.num_files): lump = f.read(16) file_name = lump[0:12].decode('UTF-8').rstrip('\0') file_size = struct.unpack("&lt;l", lump[12:16])[0] file_defs.append(GrpFileDefinition(file_name, file_size)) for file_def in file_defs: if(re.match('E\dL\d+\.MAP', file_def.name)): self.levels.append(Level(file_def.name[:-4], io.BytesIO(f.read(file_def.size)))) else: #Skip over file because it's not a map #print("Skipping %s (%d bytes)" % (file_def.name, file_def.size)) f.read(file_def.size) class Sector(object): def __init__(self, data): self.wallptr, self.wallnum = struct.unpack("&lt;hh", data[0:4]) def lines(self, level): for index in range(self.wallptr, self.wallptr+self.wallnum): a = level.points[index] b = level.points[a.point2] yield Line(a, b, a.nextsector == -1) return class Point(object): def __init__(self, data): self.x, self.y = struct.unpack("&lt;ll", data[0:8]) self.point2, self.nextwall, self.nextsector = struct.unpack("&lt;hhh", data[8:14]) class Level(object): def __init__(self, name, f): self.name = name self.version = struct.unpack("&lt;l", f.read(4))[0] self.x, self.y, self.z = struct.unpack("&lt;lll", f.read(12)) self.ang, self.cursectnum = struct.unpack("&lt;hh", f.read(4)) self.sectors = [] numsectors = struct.unpack("&lt;h", f.read(2))[0] for _ in range(numsectors): self.sectors.append(Sector(f.read(40))) self.points = [] numpoints = struct.unpack("&lt;h", f.read(2))[0] for _ in range(numpoints): self.points.append(Point(f.read(32))) numsprites = struct.unpack("&lt;h", f.read(2))[0] f.read(numsprites*44) #Skip over sprites (not needed for mapping) self.lower_left = (min((p.x for p in self.points)), min((p.y for p in self.points))) self.upper_right = (max((p.y for p in self.points)), max((p.y for p in self.points))) self.shift = (0-self.lower_left[0],0-self.lower_left[1]) # Scale the drawing to fit inside a 1024x1024 canvas (iPhones don't like really large SVGs even if they have the same detail) self.view_box_size = ((self.shift[0]+self.upper_right[0]+20),(self.shift[1]+self.upper_right[1]+20)) if self.view_box_size[0] &gt; self.view_box_size[1]: self.canvas_size = (1024, int(1024*(float(self.view_box_size[1])/self.view_box_size[0]))) else: self.canvas_size = (int(1024*(float(self.view_box_size[0])/self.view_box_size[1])), 1024) self.scale_x = (self.canvas_size[0]/self.view_box_size[0])*8 self.scale_y = (self.canvas_size[1]/self.view_box_size[1])*8 self.view_box_size = (self.view_box_size[0]*self.scale_x, self.view_box_size[1]*self.scale_y) def normalize(self, point, padding=10): return ((self.shift[0]+point[0]+padding)*self.scale_x,(self.shift[1]+point[1]+padding)*self.scale_y) def save_svg(self): import svgwrite dwg = svgwrite.Drawing(self.name+'.svg', profile='tiny', size=self.canvas_size, viewBox=('0 0 %d %d' % self.view_box_size)) for sector in self.sectors: for line in sector.lines(self): a = self.normalize((line.a.x, line.a.y)) b = self.normalize((line.b.x, line.b.y)) if line.is_one_sided: dwg.add(dwg.line(a, b, stroke='#333', stroke_width=10)) else: dwg.add(dwg.line(a, b, stroke='#999', stroke_width=3)) dwg.save() if __name__ == "__main__": import sys if len(sys.argv) &gt; 1: grp = Grp(sys.argv[1]) for level in grp.levels: print("Saving %s.svg (map ver. %d)" % (level.name, level.version)) level.save_svg() else: print('You need to pass a GRP file as the only argument') 
http://click.pocoo.org/options/#values-from-environment-variables Thanks!
If you are a Windows user and for some reason you don't want install the full library, you can download a standalone version (1 file) at [sourceforge](http://sourceforge.net/projects/isbntools/)
Thanks for the asterisked coda: I wouldn't have know what you meant by the deficiencies of the C API without it. From the perspectives of one and two decades ago, (C)Python has one of the best "foreign-function" interfaces, combining admirable power with nearly as much ease as Lua or Tcl. For 2014, though, you're right: globals that bind one interpreter instance to a process *seriously* cramp innovators' style.
Haha, they're heatsinks! I bought some of the little copper blocks on Amazon and used thermal tape to attatch them..then, I gorilla glued + arctic silver'd plumbing pipe to that. They're very effective -- my pi's run at 1.2 Ghz from their 700 Mhz stock.
Nice. What software did you use for the distributed computing? I've been thinking of trying out a very underpowered Hadoop cluster on a few Raspberry Pi's.
Thanks for the back and forth guys. Helped put me on the path understand threads vs queues much better.
This really bothers you? Rofl
I think the guy bitching non stop about how a subreddit looks may be the nerd..
I discovered [Unipath](https://github.com/mikeorr/unipath) in the Two Scoops of Django book. It took all the pain out of verbose path manipulations using os.path. Highly recommended.
Except now we recommend the Path library. And I believe it's making it's way into core Python at some point. :P
If by "nested function" you mean sub-command parsing, you're wrong: https://docs.python.org/3.4/library/argparse.html#sub-commands 
That is amazing. It's like an instant Ansel Adams. People like you are the reason I switched to linux. I love the community.
Thank you! The example source &amp; target images were Ansel Adams to begin with, so that helps :)
Instead of the long print, you can do `string * number` to duplicate the string number times.
I second this. Plus you invest in something where most things happen for better or worse...
Yes, that would be better. I'll edit the post.
also if you replaced the `print x` with `print(x)`, you would be compatible with python3, unless there are some other python2 features that you use in this. It would still work under python2.
Might want to link the github page to /r/coolgithubprojects. I'm sure they'd appreciate it there as well.
Enaml (http://nucleic.github.io/enaml/docs/) is awsome (built on PyQt).
Aren't source and target switched on the example or am I totally misunderstanding? Edit: never mind: it takes "target image's histogram".
can you explain this? what is it actually doing? it looks really cool and i'm interested in knowing what's going on.
http://en.wikipedia.org/wiki/Image_histogram
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Image histogram**](https://en.wikipedia.org/wiki/Image%20histogram): [](#sfw) --- &gt; &gt;An __image histogram__ is a type of [histogram](https://en.wikipedia.org/wiki/Histogram) that acts as a [graphical representation](https://en.wikipedia.org/wiki/Graphical_representation) of the [tonal](https://en.wikipedia.org/wiki/Lightness_(color\)) distribution in a [digital image](https://en.wikipedia.org/wiki/Digital_image). It plots the number of [pixels](https://en.wikipedia.org/wiki/Pixels) for each tonal value. By looking at the histogram for a specific image a viewer will be able to judge the entire tonal distribution at a glance. &gt;Image histograms are present on many modern [digital cameras](https://en.wikipedia.org/wiki/Digital_cameras). Photographers can use them as an aid to show the distribution of tones captured, and whether image detail has been lost to blown-out highlights or blacked-out shadows. &gt;The [horizontal axis](https://en.wikipedia.org/wiki/Horizontal_axis) of the [graph](https://en.wikipedia.org/wiki/Graphics) represents the tonal variations, while the [vertical axis](https://en.wikipedia.org/wiki/Vertical_axis) represents the number of pixels in that particular tone. The left side of the horizontal axis represents the black and dark areas, the middle represents medium grey and the right hand side represents light and pure white areas. The vertical axis represents the size of the area that is captured in each one of these zones. Thus, the histogram for a very dark image will have the majority of its data points on the left side and center of the graph. Conversely, the histogram for a very bright image with few dark areas and/or shadows will have most of its data points on the right side and center of the graph. &gt;==== &gt;[**Image from article**](https://i.imgur.com/X0DMkcs.jpg) [^(i)](https://commons.wikimedia.org/wiki/File:SunLou2.jpg) --- ^Interesting: [^Color ^histogram](https://en.wikipedia.org/wiki/Color_histogram) ^| [^Histogram ^equalization](https://en.wikipedia.org/wiki/Histogram_equalization) ^| [^Histogram ^matching](https://en.wikipedia.org/wiki/Histogram_matching) ^| [^Balanced ^histogram ^thresholding](https://en.wikipedia.org/wiki/Balanced_histogram_thresholding) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+ci4mo2q) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+ci4mo2q)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Yes, the labels "source" and "target" were somewhat arbitrary. Sorry for the confusion.
Thanks. Just [x-posted it.](http://www.reddit.com/r/coolgithubprojects/comments/27uyen/my_friend_and_i_wrote_a_script_that_maps_the/)
If you enjoy Flask idioms then click feels quite natural too.
 - [flask](http://flask.pocoo.org/docs/) - [click](http://click.pocoo.org/) particularly click, where the author explained the rationale behind the creation of yet another argparse module.
&gt; given the rapid rate at which server apps are starting to migrate from Python to Go In the real world python applications get transitioned to c++ or java. Sorry to burst your hackernews bubble :) 
No. Not everyone is using python3. Python2 is considered legacy. There is a big codebase, that is and probably will allways be in python2. I personally maintain a big python2 codebase, that won't be converted in the near (10 years) future. Python3 is the future. There will be no new features in python. 2.7 is the last version. If you know python3 you will have very little difficulty to use python2. We are still waiting on the killer feature, that makes python3 inevitable. So far we have reached the "syntactically nicer, technically not inferior" stage.
It's in the core as of 3.4: https://docs.python.org/3.4/library/pathlib.html
I would say: yes, it is easy I do not program in python3 in production. I help newbies on the net. I have never experienced any problem. There are tones of "converting from 2 to 3" tutorials out there. Python3 is nicer, more logical and is actively developed. So you'd better learn that.
Start with Python 3 right away. Python 3 is the future and makes no difference in Python's (very gentle) learning curve. I don't see any reasons, why beginners shouldn't start with the latest version. Most of the major 3rd party packages are already ported to Python 3 and I don't think that you need any super fancy, Python 2 only packages in the beginning. If you need to use Python 2 sometime in the future, e.g. cause you need to maintain a legacy codebase, you'll find yourself having very little problems adjusting to it.
ok but how does it do that, I imagine it could be achieved in many ways
Don't be sorry ;-) I should have read before posting. And thanks for sharing.
I'd agree with "learn Python 3 first". You can switch to Python 2.7 easily (read up on __future__ modules which make the process easy) and over the next few years most Py2.x programmers will catch up with you. Py3 won't hurt your employment prospects (it'll be neutral, perhaps a bit positive, and anyone using Py2 in production will know you could join the team easily). Look into an environment like Anaconda - you can setup a project with Py3 and have a simultaenous Py2 environment for code testing, so you could verify how well things run in both Py3 and Py2 (this would be great experience - more than most Py2 coders have!). Definitely look at unit testing to ensure robustness. Also - do your local community a favour, find a local Python/coding group and do a talk on how you got into Python 3 and the useful resources/gotchas you found. You'll help existing Py2 coders keep their eyes on the eventual 2020 sunset date for Python2 (when support gets turned off).
I guess the number of formats becomes different depending on how you count. But ciso8601 doesn't support weeks and ordinals, which my lib does. It also doesn't support years separately. And finally it doesn't support the formats my lib doesn't support. I agree with you that not having a big explanation of which formats aren't supported is a big nono.
One challenge is that no one seems to be willing to pay the hundred bucks or whatever to get a copy of the spec :P And then if someone does, you have to find another person also willing to pay for the spec and then code review at least the tests.
&gt; Is there some reason I should have known that the Official download site was not the one I should have used, and that I should instead have gone to some professor's private website? No, there is not any particular reason. It is simply that a professor who regularly builds heaps of binary python packages for Windows is doing a better job at releasing binary builds than the matplotlib maintainers themselves, since they are not yet releasing 3.4 builds for an unknown reason (you could ask them if you wished). Unforunately, outside of Microsoft languages and proprietary products, Windows support is not always first class, and often done by willing and generous individuals like that professor.
Very cool. It reminds of [this one](http://is-r.tumblr.com/post/36660147376/dominant-color-palettes-with-k-means), which uses K-means clustering in R to kind of reduce an image's colour palette down (I suppose you could also apply one image's colours to another, like was done here). It's a much more obvious effect, but I think it produces nice results.
Or if you're looking for [Python](http://www.pyimagesearch.com/2014/05/26/opencv-python-k-means-color-clustering/).
Very awesome indeed. However, instead of using a color histogram, it would be much more efficient and easier if you used the mean and standard deviation of the Lab color space. The algorithm goes something like this: 1. Compute mean and standard deviation of the source and target images in the Lab color space 2. Subtract the means from the target image 3. Scale each channel via the ratio of standard deviations 4. Add back in the source mean for each channel 5. Finally, merge the channels back together and convert from Lab to RGB [Required reading](http://www.thegooch.org/Publications/PDFs/ColorTransfer.pdf)
I could probably convert the raw material for lpthw into python 3 in about an hour, because it's not old - so that's perfectly fine, and someone who learns python through lpthw will have no trouble with python 3 either, this is never what I argued about. `import ConfigPaser` vs `import configparser`.. I think you are presuming far too much stupidity on learners' part. And if you're randomly copy+pasting snippets from the internet (single-handedly the best way to pick up bad habits in programming) I'd argue you're wasting your own time in the first place, there are far more efficient and effective ways to learn.
&gt;import ConfigPaser vs import configparser.. I think you are presuming far too much stupidity on learners' part. I'm not saying that beginners are stupid. But if you're unfamiliar with programming `"text"` and `text` are same to you (there is at least one thread per week with this issue on /r/learnpython), not to mention `ConfigParser` vs `configparser`. I'm not sure how much interaction you have with people who have never programmed before, but you're wrongly assuming that they'll figure out stuff like ConfigParser/configparser by themselves and that they won't have any issues porting (no matter how simple) python 2 code to python 3. 
Check out [histogram equalization](http://en.wikipedia.org/wiki/Histogram_equalization), which maps a histogram to a uniform distribution. I imagine they are doing the same exact thing but mapping to a different histogram instead of a uniform distribution.
Mostly good info, but for what it's worth here are three things I'd do differently: * I don't think a call to a main function wrapped in a call to sys.exit is idiomatic. * Function names with verbs that say what the function does seem more Pythonic, e.g., get_team_urls would be a better name that urls_for_teams. * I think performing a list comprehension, slicing it, and doing something with the result is too much for one line and suggest putting the list comprehension on a line by itself if better for readability and maintainability.
Also see how Bayesian metrics perform compared to Frequentist ones: http://nbviewer.ipython.org/github/bogdan-kulynych/trials/blob/master/examples/benchmark.ipynb
Of course it's not community news but I thought you all might enjoy [this utility](https://github.com/kobejohn/polymaze) I made. It converts black/white images or text into mazes. Or it can just make plain rectangle mazes. It started as an attempt to recover my long lost trigonometry basics. I'll hang around and make mazes for anyone who actually reads this. I have found kids enjoy the mazes at least once, especially if they draw the picture that turns into a maze or if the maze is made from their name. You can see some of what is possible in the gallery which has all of the examples I've included below. If you want an image done, modify it so the parts you want as a maze are dark (low intensity) and the parts you want as transparency are light (high intensity). There is an example source image in the gallery. If you'd like to try it yourself, it's available ([@github](https://github.com/kobejohn/polymaze)) or @pypi: pip install polymaze Easy rectangle: polymaze Easy text: polymaze --text /r/* --complexity 6 Medium difficulty unicode text (need to use a unicode capable console or run it from a script) made with a slightly complex Triangle/Rectangle tessellation. The complexity is raised so much because the font, while heavy, is still mostly empty space compared to the standard font I use for ascii text (impact.ttf): polymaze --text 迷路 --font meiryob.ttc --complexity 80 --shape Polycat Difficult reddit alien using [Q*Bert](http://www.arcade-museum.com/game_detail.php?game_id=9182) inspired tessellation: polymaze --image reddit_alien.png --complexity 130 --shape Qube Help available polymaze --help I'm a hobbyist (i.e. no professional experience) so If you have any feedback, I would love to get it here or as issues on github. Hope you enjoy it.
I must say it's surprisingly compact.
Another drawback. If you create two instances of Parser, the internal classes will be different classes. This may not be very important, but in some cases it can be. 
Looks pretty cool, will definitely give it a try!
Yes, but the reverse is equally true and Python 3 is future-proof and has fewer design "gotchas". I'd strongly recommend learning on Python 3.4, the most up to date release. It's got a lot of nice stuff baked in that may soon become necessary to use newer frameworks, such as the Asyncio module. There is no longer any compelling reason not to learn on a modern version, and learning an old version may soon become a problem.
This would work with python 3 if you simply updated your print statements: https://gist.github.com/timster/7402c847e20d706e50c4
I did the same thing probably 10 years ago using a point-wise nonlinearity. As an extension, i would suggest you also add the option to transform one image histogram into any arbitrary histogram (uniform, gaussian, gamma, etc). This is a pretty useful method for image preprocessing.
The Perl model came out of Windows hacking that threading model onto Perl in order to make it more friendly to use with IIS, so that they could get more of the (at the time) new web/cgi pie. No one uses Perl threads. They suck. As a Perl developer, I use Coro or a pool of forked processes (see my own lib, Argon, on CPAN). The reason the GIL has to be done the way it is, as it is in most popular languages, is that the data structures the interpreter uses in memory are monolithic in nature and access to them must be serialized to prevent multiple threads from modifying the same addresses in memory simultaneously. The only language I know that is really thread-friendly (not just thread-safe, but able to make effective use of threads) is Pike, which is not popular at all (although it's an awesome language). It does very fine-grained locking on its internal operations, and is apparently manages data internally in such a way that it can take advantage of this. It's not an easy problem to solve, and in most cases, the price in complexity (and single threaded speeds) would nullify many of the gains.
The example (which is perfectly fine for the sake of the argument) served to dismiss your claim that bottlenecks always show up at the same place, even when you move your application to another version of Python. Let's say that you have a function in your application that uses Decimal intensively and such function shows up as a bottleneck in Python 2, then it's likely not to be a bottleneck anymore in Python 3 because Decimal in 3 is "30 times faster" (you own estimate). So, by simply changing Python version, you've removed a bottleneck. And, of course, the other way around is perfectly possible (benchmarks show noticeable performance losses in certain areas when moving from 2 to 3). Not sure why you can't accept this fact: that the very same application can have different (even dramatically different) performance profiles when you change the underlying interpreter / standard libraries. You may have an interest in Python 3 becoming mainstream, but why this prevents you from having a civilised discussion with those who don't share such passion is beyond me. If you think my arguments are not valid, please ignore me. Others will be perfectly capable of deciding for themselves if I'm right or wrong, without your continuous incursions. Your fixation with FUD and trolls is beyond belief. As is your unnecessary discourtesy, which should stop now (see reddiquette link below if/when typing your reply). 
guys each of the code is ment to be in it's on line reddit put it that way sorry for that and the #writing isn't ment to be that big again Reddit's fault 
That's pretty high requirements for a single developer to create an entire platform for under 10k. Good luck with all that.
That's pretty lame. I thought the ISO specs were meant to be all open and what not.
&gt; The example (which is perfectly fine for the sake of the argument) served to dismiss your claim that bottlenecks always show up at the same place, even when you move your application to another version of Python. "Dismiss" yes. "disprove" no. Your numbers had no connection to reality you pulled them out of thin air, and in doing so also proved that you don't actually know anthing about profiling. Show me some *real* numbers, and I will give you answers. &gt; Let's say that you have a function in your application that uses Decimal intensively and such function shows up as a bottleneck in Python 2, then it's likely not to be a bottleneck anymore in Python 3 because Decimal in 3 is "30 times faster" (you own estimate). Or it may still be the bottleneck, Hard to say. But it will be faster, yes. &gt; So, by simply changing Python version, you've removed a bottleneck. &gt; And, of course, the other way around is perfectly possible Not it is not. Demical is an average of **30 times** faster under Python 3. There is nothing that is 30 times slower under Python 3. You will not get a new bottleneck under Python 3. This I have pointed out multiple times. What is it you don't understand? &gt; You may have an interest in Python 3 becoming mainstream I have absolutely no interest in it whatsoever. &gt; If you think my arguments are not valid, please ignore me. No. I will NOT allow you to spread FUD lies and bullshit uncontested. &gt; Your fixation with FUD and trolls is beyond belief. I'm not fixated with it. I just respond to your crap. 
&gt; Perl just spawns one new interpreter per thread[2] and all variables are thread local. You do realize you can do this in Python too, right? This is how i write all my multiproc code in Python. The GIL applies to multithreading.
So did you encounter problems using Python 3 or did you mainly switch to Python 2, because people you know and content you saw, were using 2? Like u/ivosaurus said: If a tutorial is written for Python 2 and can't be used with Python 3 easily (except print bla bla) then it's really a bad tutorial.
It's not the same. Python multiprocess spawns _processes_ for each new interpreter. Perl, as far as I understood, spawns threads and starts a new interpreter environment in each new thread. The address space is the same, but in practice threads are fully isolated in their manipulations. 
Nice one, Jeff :)
Did you incorporate any of Open.CV for this? Looks pretty well done and I'm sure it's significantly faster in py than in something like MATLAB. 
read the section to the right which gives you some info, copy and paste your code line by line with four spaces for indenting like this as well as four spaces before your first line of code def function(a): if a == 'yes': print('fantastic')
give your two functions different names like **function_a** and **function_b**
Sweet. Thanks for /r/learnpython ! 
i also suggest using a variable when you're calling your functions like Choice = input('Yes or no') function(Choice) 
Or, you know, it's a tutorial that uses a package that hasn't been ported to python 3 yet...
ok well that fixed the traceback i need to understand/learn what variables are and where to use them anyway theres only one more problem with the code What's your name? d Nice to meet you d! Your age? s So, you are are already s years old, d! where are you from? d ok yes or noyes fantastic why not? d it still comes up with "why not" even when i type in yes, in batch i could overcome this by quite simple hiding it or using the GOTO command any idea how i can do this in python?
try something like: def function_a(a): if a == 'yes': print('fantastic') elif a == 'no': Reason = input('too bad, may i ask why? ') if Reason == 'because': print ('tomas is a faggot')
wow this will come in handy but still "why not" shows up and I would only like it to show when I type "no" if its anything other than "no" I don't want "why not" to show on screen, anyway thank you very much for your help James and I know it seems like your teaching a kid but coming from a different program it is hard to learn a new language especially when your used to stuff that aren't in python. I'll play around with the code and see if I can improve it. thanks again:)
yes it is there https://docs.python.org/3.4/library/venv.html
I'm not going to write it for you but what you're looking for is the python library suds documentation : https://fedorahosted.org/suds/ 
&gt; [] * 256 This doesn't produce what you might expect. To understand what's happening here, we need two bits of simple math: 1. Multiplication is a shorthand for repeated addition, e.g.: 4 * 3 = 4 + 4 + 4. - The *identity element* of a binary operation leaves the elements unchanged, e.g. 4 + 0 = 4. Here 0 is the identity element of addition, and adding 0 to any number leaves that number unchanged. These two concepts also apply to lists in python: `[] * 3 == [] + [] + []` (concept 1.) (I'm using == because = is assignment in Python) Here, the + operation is list concatenation, e.g. `[1] + [2] = [1, 2]`. Now to the main point. List concatenation also has an identity element: the empty list. Appending the empty list to another list leaves that list unchanged. So we get: `[] + [] + [] == []` (concept 2.) Combining these two concepts, we now understand that `[] * 256 == []`
Here's the response they sent: &gt; If your subscription expires and your license is in version 3 then you can get the minor releases. You just cannot get version 4 (major release). It just depends what version you license is in at the time of expiration. Didn't take them this long to respond - I'm just slow.
If I remember correctly, he posted elsewhere looking for hints on getting it to work faster. In that case, list comprehensions would work better (speed wise). Besides, list comprehensions aren't cryptic, they're in a number of languages and all over mathematics :D
This is actually fun!
Uh, that's not an RSS feed? They just parse a feed and create a web page for it, I'd say at best that it's a feed reader.
AFAICT, you should be able to get around the problem with `line_profiler` being a decorator quite easily. from line_profiler import LineProfiler profiler = LineProfiler() ... profiler.add_function(...) profiler.enable() ... profiler.print_stats() I'm not certain of the API names, but it's basically that. This won't wrap any functions or squat. Further, you could wrap the API easily from easy_time_lines import profile @profile ... where def profile(function): global_profiler.add_function(function) return function # not wrapped and an exit hook deals with printing output. 
I think I remember a utility that did that. Because of Duke's ability to have sector over sector, and slanted floor and ceilings, I would assume you could only go from Doom to Duke. I think I could work out a way to get the structure (Duke maps use `long` values for x,y points while Doom uses `short` values, thus Doom maps appear much smaller in Duke (I actually have to scale down the Duke map to fit svgwrite's validation preventing any value larger than `int`, I can see some bugs in the output that I'm working on fixing that are related to this scaling).
I think I can do an even better job with some of the scaling and normalizing code, but a lot of the brevity is achieved because of the excellent `struct.unpack()` and the way the GRP and MAP files are organized (Doom WAD put the file allocation table at the end of the WAD so you have to read the entire file to find the file allocation table, then go back and break apart the file according to that information, this adds a little complication to that this project was able to avoid.
OK, then maybe it might be worth it. 
I did something related, but for color, which now was almost 15 years ago (where does the time ago?). I wanted to pretend that the pixels in one image were like mosaic tiles, and rearrange them to form the second image. It's easy on grayscale images - just sort the pixels by brightness, map one range onto the other, then unsort back to the original image. It took me awhile to figure out how to map across 3D, but of course the answer was to plot the pixels in a 3D RGB box, and find the closest pixels between images in 3-space. The trickiest part then was figuring out how to allow pixels to choose less well when there weren't enough nearby neighbors (this would have been as easy as the grayscale version if only I were a 4-dimensional entity). It worked out, but of course, the more crazy the pixels were in relation to each other, the worse it looked. I also only ever worked with images that had the same number of pixels (all from the same camera), so it didn't try to scale anything.
In the future, it will be a lot easier if you put things in pyfiddle or pastebin so people can easily modify them. http://pythonfiddle.com/ Or is it in an image so your teacher can't find it with a google search? 
An even better example &gt;&gt;&gt; a = [[]] * 5 &gt;&gt;&gt; a[0].append(42) &gt;&gt;&gt; a [[42], [42], [42], [42], [42]] &gt;&gt;&gt;
/r/learnpython would be better for this type of question.
And a beginners tutorial with heavy use of a not yet ported 3rd party module is... bad.
The important thing to realize is that once you set the variable, it isn't consumed by the function. You can use it many times. For example: def print_pos( number ): print i def print_neg( number ): print i * (-1) i = 5 print_pos(i) print_neg(i) Does that point you in the right direction?
There are comparisons to PyPy too, which has JIT.
I had this running for 20 minutes on a moderately sized image... and it's not even halfway done ._.
But then, on an OS that offers cheap processes (like pretty much every Unix-like OS), the difference hardly matters as long as threads are isolated anyway.
No worries! Far too many subreddits :)
Personally, I'm a big fan of Haskell's STM implementation. It's quite an elegant solution to the threading problem, and the tools that Haskell provide make it pretty painless - once you've gotten through the steep learning curve of Haskell itself, that is...
&gt; This is documented in The Python Standard Library - 2. Build in Functions He knows this, apparently, and still writes this post.
Well, this is pretty much not doing anything. The only functions that are in use are main and calc_byte. And calc_byte only sets a variable. It doesn't even return it. Here's the flow of the program, as it sits: 1. ask user for input, float that input. 2. multiply user input by 1000000000 and assign it to the variable 'bytes' And that's it. that's all it's doing. And then you have 4 functions that aren't being called. Also, please don't use an image. Use pastebin or pythonfiddle.
Not really, if your isolation is limited only to writing. If the threads only have to read, then it's much faster. One can use shared memory for that as well, so I don't know... As you said, it depends on how cheap is to create a new process vs a new thread.
I don't think it does what you want but IMO Slumber comes pretty close to that.
I stared your project but I am sorry I need to ask this question: What makes your package any different than the other 50 outlines in pypi. https://pypi.python.org/pypi?%3Aaction=search&amp;term=Cron+jobs&amp;submit=search 
This is great!
Great work!
Looks good besides the extra capacity function calls in calc_byte. Anything after a 'return' is moot, since 'return' ends the function right there. I don't know about the cacpacity functions. It's possible that it's not taking the fraction correctly into decimal, so do 1.0/5 instead of 1/5 and 3.0/25 instead of 3/25, etc. Python can be weird with numbers sometimes without the math or fractions modules.
I get this on Arch running "polymaze": Traceback (most recent call last): File "/usr/bin/polymaze", line 7, in &lt;module&gt; from polymaze.cli import commandline File "/usr/lib/python3.4/site-packages/polymaze/__init__.py", line 2, in &lt;module&gt; from .polygrid import PolyGrid File "/usr/lib/python3.4/site-packages/polymaze/polygrid.py", line 11, in &lt;module&gt; import shapes as _shapes ImportError: No module named 'shapes' Any ideas? 
Yeah, I'm using Hammock currently for much the same use case, and its decent, but I'd like to get even closer. Thanks for the response.
Just registered without downloading the cli. Can I edit scripts from the browser?
Cheers for pointing me the right way. I now have this code: http://pastebin.com/8R35CYdV How do I pass the authentication params to the API?
It's an issue when you are on the wrong side of the tradeoff.
As the programmer (and Mr. Stork can back me up here), we did a randomized avalanche transformation. To make life easy, let's assumer we have a B&amp;W image so R=G=B=value. We found the first value (0,1,2,etc.) in the source image that had more pixels than the target histogram. We then randomly chose pixels from that value equal to the excess and incremented or decremented their values by one to move them towards pixel values in which the target histogram had more than the source. We then grabbed and equal number from the next bin and moved them forward, so on and so forth, until we had moved the right number from the excess values to the deficit values. Lather, rinse, repeat. To do color, you just do the same thing individually for each color value: R, G, and B. Next step would be to add a distance metric so each pixel is edited the least possible (but with large images, the number of pixels in each bin is huge, so this essentially happens via probability). However, this metric would probably make a larger difference in RGB images than in B&amp;W images. I understand there are a lot of optimizations to be made, but sometimes you just need to drop code into an editor and make it work before you make it right.
Not at the moment, no. You can upload files through the web site, but our view is that there are already tons of great editors for the desktop, and we didn't want to rebuild all that functionality in the browser. (Why try to build a new editor when so many great ones already exist?) But if that would be important to you, let us know -- we aim to build whatever our users are asking for.
I was most of the coding behind this. I'm a c++ programmer by trade. I knew there was a pythonic way to do this, but I couldn't get it to work. Besides, that line was by no means our bottleneck. Sometimes you just need to hack it out to make it work, even if it's not the most beautiful code ever.
I haven't had too much time to look at this, but something about it shouts "bubble sort." Couldn't you line rank order the intensities for the "target", create a vector with a slot for every intensity and put the over/under percentage in each slot. n = number_of_intensity_values v = [pct1, pct2, pct3, pct4, pct5,..., pctn] where pcti = pct or number of pixels greater than the ith intensity slot. The vector can then act as a filter for a bubble sort style algorithm run on the source. Eg: some sort of Gaussian-like dispersal from the heavy values. 
I see. Silly mistake on my part. I typically use comprehensions instead of overloaded operators. 
That's my plan for the next version of the sorting algorithm. Thanks for making me feel less silly! :D
It is a non-issue up to a point. As odraencoded said, it's an issue when you are affected by it. I had direct experience of cases where the GIL influenced our development. They don't occur often, true, but the GIL does exist, and it does exert its presence in the real world.
I just had to do it... http://imgur.com/Bf6KRku I should really have created a program to do this. Nice project for when I get bored this summer. Either way, really cool program!
No problemo! :D
This maybe? https://stackoverflow.com/questions/17479296/read-in-raw-binary-image-in-python
You're not assigning the result of try clause to gbyte. So, you try to convert, nothing happens and you pass your input without any modifications.
I completely agree that an in-browser editor is unnecessary for anyone that is actually using domino to get stuff done. However as you were starting to onboard me as a potential customer there was a big leap between running pre-set scripts in the browser and me actively uploading and executing my own code. Had I been able to edit the preset scripts and tinker with very little effort on my part, it would have kept my interest, moved me forward with understanding the product, and brought me one step closer to uploading my own code. Just a thought from my experience. Otherwise it looks like a cool start.
Looks like I need to get the new version then! I'll check out the path library as well, though I am still infatuated with Unipath.
AFAIR Pike's internal locking model only works for "top-level" variables and won't work for e.g. values in mappings. I may be wrong, however, since it's been a while since I touched Pike.
i dont have the time to write an example currently but.. youll ether need to create an authtoken using the client factory or youll need to pass your credentials using client.service.doLogin this has the solution: http://stackoverflow.com/questions/2388046/can-you-help-me-solve-this-suds-soap-issue 
Travis doesn't cover windows. I'm not sure why windows is supported by cookiecutter, and I think that's half the problem.
 try: gbyte = float(gbyte) 
We did not, and to be honest, I'm not entirely sure what that is. I'll look into it. Thanks!
Many thanks.
See the explanation above from /u/Pssts (the other programmer). Essentially, you are correct though.
Cheers! I stumbled upon basic HTTP authentication, which after running the Docs through Google Translate seems to be what I'm looking for. However, I'll try creating an auth token if this does not work. Cheers!
Yes, but the 3 dimensions (R, G, &amp; B), each 256 values in length, are concatenated into one 768-value list.
Well, I sort of don't really see this getting blazing fast so long you use Python... maybe if you used NumPy?
I had to post it on [/r/coolgithubprojects](http://www.reddit.com/r/coolgithubprojects/)
Nice. It makes me smile to see one of these done.
pyodbc has executemany as one of its cursor methods. There are a couple examples online on how to do this with INSERT INTO
I'm happy to hear that. Did you try new ones or the ones in the gallery?
Thanks
Thanks!
TIL. Adding that to my subs for inspiration.
Just made some changes (made lists of pixels into sets) based on suggestions I got on Reddit, and it runs WAY faster now. Still not instantaneous, but it's about a 50x improvement.
Looks due to my inexperience with relative imports in py3. I'll try to figure it out. You have 3.4 as your default interpreter in Arch? Interesting!
Done.
I wonder if numpy code is faster in pypy vs a js implementation.
I think these are the changes that need to be made. I'm going to cross my fingers and upload a fix with those changes. Strangely it all seems to work for me with the code as it is with py3.3 or 2.7 but I am running cli.py directly with py3 rather than through the console entry point. `cli.py`: -from shapes import supershapes_dict -from maze import Maze -from polygrid import PolyGrid +from .shapes import supershapes_dict +from .maze import Maze +from .polygrid import PolyGrid `polygrid.py`: -import shapes as _shapes +from . import shapes as _shapes
See the /u/Pssts (the other programmer) comment below for a detailed explanation.
Not sure I am enamored with having to manually type the file name of the script to run. I can see myself second-guessing how I spelled the name of a script and having to go back to the Files view to check. Would be nice to have a directory tree type of interface to select one or more files to run/execute or when the user is in the Files view, make an option to maybe run/execute one or more files from there instead of having to go to the Runs view to execute or run the scripts. As far as what it provides, I would say it is pretty decent. But I am not sure I like the user interface. I would recommend looking at how wakari.io or cloud.sagemath.com have designed their user interface.
"fix" uploaded to pypi and github.
Oooh. That makes sense. It shows what high expectations I have gained for google that I expected it to mean a colloquial phrase instead of simply getting lost. Thanks for the note.
I think you may be conflating the interpreter's internal locking with what you as a developer are required to lock yourself in your own code. I believe you are correct with regard to what kinds of assignments are atomic in pike though.
Do you need the old versions for anything? If not, just note down which libraries you need, uninstall all of the Python versions and pip, and install Python 3.4.1 from the website.
I had the mess before. So I deleted all my python installations and downloaded anaconda and installed the minimal, 2.7.x. Then I created a virtualenv py3k: conda create -n py3k python=3 source activate py3k Now you have python3. The problem with this is that you have back to python2.7 to run conda to update your installation. I do this by using a shell script that sets PYTHONPATH, First run conda update and then run conda update -n py3k, to update version 3.
Great, thanks. Are there by chance any binaries available? I don't have a Linux Arduino environment right now.
I'm a programming noob. &gt;cd to the correct directory, and run the file from there. That way your output should still be visible. What?
Are you autistic?
whoever wants to solve a problem with threads, now problems you two have
It's only a hack on Windows. In posix threads are as heavy as processes.
Python does not have a GIL problem, CPython has a single-core problem. Actually, CPython does not have a single-core problem either, there are tons of python libs can support multi-core or even GPUs. It's just lazy developers want a magic bullet to scale their crappy, single-threaded, inter-locking, blocking spaghetti code to multiple cores for free. Anyway, if you are doing CPU-intensive task in pure python you are probably fucked sooner or later. GIL is just the final straw on camel's back, the most common excuse people usually find. btw I've seen millions of games written in C++ which can only max out a single core, yet no one blames the C++ runtime. **tl;dr** CPython without GIL won't solve your CPU intensive tasks running on multicore problems.
These files look mostly simple enough to use just str.split(), meaning they are just numbers separate by whitespace without any whitespace in the values themselves, and without missing values. For example: for line in open('somefile.raw', 'r').readline(): print(float(x) for x in line.split()) The csv module with the proper configuration is also a great suggestion.
I tried it with pysdl2-cffi, which has an advantage over PySDL2 on PyPy because it uses cffi instead of ctypes. It runs at 100fps. SDL2 is also a big advantage because all the scaled blitting is hardware accelerated. This program does enough algorithmic computation in Python to really benefit from PyPy. https://github.com/dholth/pygame-raycasting-experiment
Type "dir" to see what files are in the directory you are in. You may have the wrong filename or etc. Also, your email is showing, you should avoid that. 
Awesome utility! I just wanted to point out that your ReadMe says that the proper tag to create a text-based maze is --string when it's actually --text. Not a big deal, it just caught me by surprise when I tried to do a text maze.
[Picture of cmd after running "dir"](http://i.imgur.com/Kznm9mh.png). How do I change directory to Python27?
Type "cd.." to go up one directory. If you type it twice, you should be in your C drive. Then type "dir" to list all the items. Then to enter a folder, type "cd (folder name)", which in this case would be "cd Python27". 
OK, http://imgur.com/KHsPjNE Now i type "Dishmanbot.py"?
To be fair, Duke's "room-over-room" isn't true room-over-room.
Very nice. Here is a solver if you are interested: http://goo.gl/5AnAn5
That's quite clever. For some reason it isn't showing the map in the nbviewer.
The pypy people are working on implementing STM for Python: http://morepypy.blogspot.co.nz/2014/04/stm-results-and-second-call-for.html At the moment single threaded code is a lot slower with STM than normal pypy though, but it should scale nicely.
Learn to use virtualenv..
Interesting post, and I share your frustration with the Python community's lack of enthusiasm for testing, but you should check out [pytest](http://pytest.org/) for sure.
By the way, OCaml has a GIL too IIRC.
I don't know how nbviewer works. Using some js libraries sometimes it works and sometimes it doesn't. Anyway, if you download the nb you can play with it locally and break things if you want ;-)
I see, some of the edges get removed. That makes sense. Hmm. 
This is a-maze-ing! I'm out, PEACE
That's great! Is it being rendered real time? What structure did you use for the grid? Mine is a sparse grid (dict) since many tessellations do not fit in a square grid. The implementation is straightforward but pretty slow when it gets to large mazes..
Yeah, I thought about making that one of the demo mazes and then I punched myself.
Yes i made it in Processing. A java framework. The grid i used is the same as in the article, wich consists of back and forward slashes and I added a vertical line. So it kinda looks like yours but its not the same. If u know what i mean? :) edit: and like you i also use a reference image to determine the grid. Also just black and white images. In my case there were hundred images and i switched the images when the grid was resetting. Hence the timer :)
Great, that almost makes me want to switch.
Amazing!
(I'm assuming you're on a mac?) First, delete everything and start again -- Definitely the right approach. While you are at it, consider migrating across to a new user account. It's a good thing to do periodically to stave off bloat. As for the reinstall, let me recommend using macports to handle your installation. I have found this to be much easier and more stable than EPD, and much much more so than trying to do everything myself. Basically, i got just about my entire python work environment set up with a single command: port install py27-matplotlib (Because python, numpy, scipy, etc. are dependencies, they are installed as a matter of course.) It's also great for finding out what things are and are not up to date: port outdated and then updating whatever needs updating port upgrade outdated Long story short, in my experience, macports works as advertised. For those very rare cases when i haven't been able to install via the port command, it also seems to play very well with easy_install and with installing from source.
&gt; You have 3.4 as your default interpreter in Arch? Interesting! It's the newest stable python version. So why not?
Hi Veedrac. I cover your second solution (the pass-through decorator) in my book at the end of the profiling chapter. Cheers for the code snippets.
As noted by others - CPython uses the GIL so it won't efficiently use mult-core for CPU-bound tasks (many threads for I/O bound tasks is fine however). PyPy has a GIL (and also the upcoming Synchronous Concurrent Memory pattern). Jython (and I believe IronPython) don't have a GIL problem. You can use the multiprocessing module to fork for read-only access to shared structures. In addition you can easily share large numpy matrices amongst cores (e.g. 1*4GB matrix shared to 8 cores without copies). I gave a talk on some of this at PyDataLondon recently, there's a post here on reddit today about this and I link to my book on the same subject: http://www.reddit.com/r/Python/comments/27v3sc/the_high_performance_python_landscape/
I get it, most GUI toolkits requires some degree of threading, for a convenient mini IPC you need threading, but, GIL is not a problem in these cases. WIth GIL, you can only max out a core, so what? How many GUI programs out there can hog up all cores? (Which is horrible btw)
Thanks for trying it and letting me know. I knew that Arch intends to keep things simple but I didn't know it additionally stays up to date. Thanks for that too.
Yea... some are. But really most are not. I mean, they're "open" in that anyone can pay to get access to them :( This includes stuff like the C++ spec btw!
Easy now. The real problem is that we, as a Python community haven't really managed to solve the distribution problem. OK, the rest of this comment is not aimed at you, jj123321, you were just the trigger, I guess :) examples of problems: * the fact that pip still installs into the global python path by default * confusion between easy_install/pip/setuptools/distribute/the new setuptools(né distribute) * eggs, wheels, pypi, "you can find it in the cheeseshop"? * blogposts decrying virtualenv for deployment leading to newbies shying away from them when they would in fact be the ideal tool for their situation (development). We need a consensus and clear communication. * No, a newbie should not be expected to have to manage their Python path * No, a newbie should not have to read up on how eggs work * Yes, a newbie should be able to write pip install python-foo to install it in their private python path * Yes, we absolutely have to stop suggesting things like "oh, maybe you should use sudo pip install python-foo" [/rant] Sorry, I needed to vent some steam. :) Carry on.
What platform are you on? Did any of the other comments help already? On windows, try uninstalling everything and then search for any remaining python folders and deleting them if they belonged to the original distribution. And then start from the bottom up again. 1. Decide on a Python version. Scipy can work with Python 3.2 or newer, but I have very limited experience with SciPy, so I'd defer to a 2.7 version for Python 1. Clean the PATH environment variables: in the start menu, type "Environment variables" and then select "Edit System Environment Variables", and there click on "Environment Variables". In there, search for Path or PATH and edit it. (Pro-Tip: copy the string into a text editor for easier editing and then copy it back. Remember, you need a semicolon to separate PATH entries, not a colon like on Unix systems. Make sure you delete all the entries pertaining to Python. 1. Install the Python version you chose before. I suggest choosing a default path like C:\Python27 or C:\Python34, depending on your version. 1. install pip, for example with the get-pip.py script from here: http://pip.readthedocs.org/en/latest/installing.html 1. Install Packages through pip Alternatively, you can skip steps 4 and 5 by installing a python distribution with SciPy already baked in. I remember SciPy being a bit annoying to install through pip, because of certain native modules it wants to compile during installation. I don't have a good example right now, but have a look around, I'm sure you can find something. Good luck! Full disclosure: after I went through this kind of hell, I caved and installed Cygwin :D
Grammer makes this difficult to read.
I don't believe OCaml has a GIL, but it does have a stop-the-world garbage collector, and does not support threads.
&gt; How many GUI programs out there can hog up all cores? Every high-performance computer game in existence.
@Rihx, thanks for sharing this. This is fantastic IMHO.
Well, what's simpler than staying on the latest version? Upstream will handle all security issues, users won't bother you over missing features, you don't need to merge dozens of patch files before compiling...
Have you looked into Rust's threads? Because of the ownership semantics, all the values the thread captures are moved to it, so not accessible from other threads any longer. If you want shared ownership, you must use the Arc&lt;T&gt; data structure, which is read-only. If you want shared ownership and be able to read and write the variable, you must use Arc&lt;RWLock&lt;T&gt;&gt;, which automatically protects write access to the variable with a lock, and you can trust it will be unlocked thanks to RAII. 
First off, great work. Secondly, on the github page, you should show the result of your example polymaze --text "Happy\nBirthday!" --complexity 10 --shape Polycat That way, people have a direct comparison to something your shown them. Just my two cents. Again, bravo.
more like a personal project, I scraped a bunch of data off a site now I'm trying to catalogue it... It's proving to be harder than I originally thought, just hoping someone might have some general advice
I am sooo with you on my Mac. First time on anything apple since the II and I will readily admit I am the problem. Interested in knowing seeing how others have done things to solve this. Found some stuff on stack overflow and the like but nothing seems to get it "all good".
python is of course installed ...so what do you want to know, specifically?
I haven't had any breakage. The version's been revved to 2.7.6, still no python3. I did an upgrade from 10.9, not a clean reinstall. I'm finding the dev beta a little rough btw. Unless you need it, you might want to hold off for a refresh.
Oh ok, well it looks pretty easy if you consider that the make of the trucks contain only letters. The models contain letters and numbers. And the years are all digits. The string package contains everything you need to identify each of the data elements. (string.digits, string.letters, etc.)
Awesome, hopefull I'll get time to try this, does the code need any modification to work with pysdl2-cffi ? [EDIT] - Noticed it is modified, will have a go :)
What would be the changes I have to make to obtain valid URLs?
Just to have this said: I really like this style, especially how it gels with the design of python.org. It was in fact the reason I enabled subreddit styles again. (Yes, I am serious). There are a few things that should be addressed though: * visited links are not highlit anymore. * the text inside the Comment Box should not be greyed out on blur, because instead of just signifying that the box is not focussed, it also makes it seem as if the comment box is unavailable, which sends the wrong message. * The height of the header is a bit much, but I feel it's reasonable.
[good_point_thanks.jpg](http://imgur.com/A4lt3qC)
That doesn't bother me. I use brew and install my own stuff anyway. I never use the built-in stuff.
Is your concern variables local to the scope? Because if it is... that's a poor practice in many situations. For instance, with a c compiler, typically defining variables subordinate to internal scopes within a function creates a new stack frame which in turn requires cleanup when the scope ends. This is exacerbated if the stack frame is within a loop. In contrast, when the same variables are defined at the front of the function, there's only the original stack frame and the final cleanup -- which is faster and takes less code. If readability is a concern, comments can serve the same purpose as a declaration, but without impacting speed and code size. Just because you *can* do it, doesn't mean you *should* do it. :) 
I had no idea. That just sounds ridiculous. What's the reason behind it? Is it really to make $100 here and there?
Prior to 2.1 or so, you couldn't even do that -- names were looked up in the function's local scope, in the module namespace, and then in the builtin function list, and that was all. So for instance a recursive inner function like this: def f(): def g(x): ... g(x-1) would throw an exception due to not being able to look up 'g', as the local scope of f was never searched. There is still a wart in Python 2 when it comes to assigning to variables outside the local scope but not all the way up in the module; Python 3 adds the 'nonlocal' keyword which is similar to 'global' but for intermediate scopes. In other words, it's a historical artifact. In general I think the implication of this is that if you are using nested functions enough to keep running into scoping issues, the Pythonic thing to do would be to use some other construct, like a class or module, to organize that part of your code.
Read entries till you hit one that's entirely numbers(the year). The previous one is the make and the ones before that are the model.
I don't think you really need to change anything code-wise. Just changing your ReadMe example to use --text instead of --string would probably keep anyone else from experiencing any confusion.
Wow, I had no idea. What about the secret red room in E1L1? It doesn't seem to me to be true ROR (it seems to be the same elevation as the arcade, which lets you glitch from one to the other). Is there a reason they would choose to do false ROR over the true version?
That's how I would solve it too if I only had an image. But [dat_BFS.jpg](http://imgur.com/KGGHBig). I think there isn't a less efficient method to solving a maze. In this case since you can make the maze and have an actual data structure representing the maze, you can run the search algorithm directly on the maze structure. Or do other fun stuff with it. I'm going to work on that [soon.jpg](http://imgur.com/sgmhwO2).
Why was she even using from _____ import * to use one function?
Right. I updated the readme as you suggested. The change from --string to --text happened before. I had just missed updating it in the readme.
Yeah agree here. You are getting out of the realm of the portability point of json at this size. Great if you are exporting/importing but as storage a better format is probably a good choice here.
use elasticsearch
Well I know it'd still be installed, I was more worried about pip and such. I'm new to command line dev tools and was concerned that it may break some of the stuff installed by pip. As well as having Python3 not break. 
Rough in what areas? I could wait till the next developer build. It may be more polished. As I'm waiting for the next iOS 8 beta. The current one is very broken for my usability and tools. 
I don't know if it was intentional. Javascript has the same limitation. I suspect a lot of dynamically typed languages, where you can arbitrarily defined variables anywhere might have this limitation. Although, in Python 3 then made variables defined in generator/list/dictionary expressions limited in scope to the expression. So I guess they could have done something similar for 'for' loops but decided not to since it probably is more useful to not have nested scope there than to have nested scope.
So it's been a day or two, and I just wanted to revisit this interaction. I don't think that /u/wub_wub was twisting a rule. He was explaining that what you did potentially infringes on one of the very few site-wide reddit rules, in an effort to help you not get site-wide banned from reddit. It wasn't a threat - it was a "woah, not sure if you know this rule, but what you did can have bad results". Because what you did (looking up someone's information on another site and posting it here, which connects an outside real world name with a reddit username) is a **big deal** and **frequently ends with the people who did it banned from reddit**. Please, be careful about this rule. Don't post things from other sites where you connect reddit usernames to real world names. Nobody here is trying to villainize you; we're trying to stop you from getting banned.
You can always use virtualenv or anaconda to have a separate python install: http://continuum.io/downloads
Not sure I see the point, except as a programming exercise.
Or put it in pandas DataFrame
eh? Even with no optimisation in GCC there's no overhead (as in, literally 0 difference in the generated code in the testcase I tried). Furthermore, with multiple scoped blocks the total stack space taken up by the function will be smaller.
&gt; visited links are not highlit anymore Woops! They were, but then I made a patch that wasn't thoroughly tested. I brung back the purple now though. &gt; text inside Comment Box I think it was just too grey. I've made it much darker now. &gt; header size I've reduced the size of the header a bit. I may go a bit smaller, but I want to keep the tabs as far from the right hand menu as possible so it's more viewable on small screens (IPad especially) which is why we have a separate bar for the tabs instead of having them to the right of the logo.
You could get rid of the function call with something like: class X: def __enter__(self, *args, **kwargs): pass def __exit__(self, *args, **kwargs): pass scope = X() def main(): with scope: print('foo') main()
Blackjack is actually a lot of fun to implement.
the code shown is simplified to explain the situation more clearly.
I would look right to left, everything not a digit is first a manufacturer and, anything else, a model. Like this: from pprint import pprint d = ''' F-150, F-250, F-350, FORD, 1998, 1997, 1996, 1995, 1994, 1993, 1992, 1991, 1990, 1989, 1988, 1987, 1986, 1985, 1984, 1983 F-150, F-250, FORD, 1996, 1995, 1994, 1993, 1992, 1991, 1990, 1987, 1986, 1985, 1984, 1983, 1982, 1981, 1980 F-150, F-250, FORD, 1998, 1997, 1996, 1995, 1994, 1993, 1992, 1991, 1990, 1989, 1988, 1987, 1986, 1985, 1984, 1983, 1982 F-150, F-250, FORD, 2003, 2002, 2001, 2000, 1999, 1998, 1997 ''' d = d.strip() def parse_line(line): line = line.split(',') years = set() mani = '' model = [] while line: i = line.pop() i=i.strip() if i.isdigit(): years.add(int(i)) elif not mani: mani = i else: model.append(i) return mani, model, years done = {} for line in d.split('\n'): mani, models, years = parse_line(line) for model in models: if model not in done: done[model]={'mani':mani, 'years':years } else: done[model]['years']= done[model]['years'].union(years) pprint(done) 
couchdb might be a good intermediate for this. 61mb isn't that big though- you should be able to load it into memory as a dict via json.loads. What web framework are you using?
&gt; Edit: I forgot to add, whatever style you do end up choosing, don't forget to be dogmatic and oppressive about it. I know that sounds like I might be joking but when you maintain a library used by other people you are going to want to document the hell out of everything. Thank you! I took over this lib from a previous maintainer, I'm the third developer to maintain this lib during its life. I'm currently suffering from docs being in a separate confusing data format completely away from the code. Once I merge docs and projects I think the world will be a better place. I think I'll have to be extremely strict going forward (especially with myself) most of the community isn't used to that so I'll have to do it carefully.
I don't think that does what OP's talking about. Variables are scoped to the function, as seen here: &gt;&gt;&gt; def main(): ... with scope: ... mynum = 1 ... print "foo" ... print mynum ... &gt;&gt;&gt; main() foo 1 While here's the "scoped" version: &gt;&gt;&gt; def main2(): ... def scope2(): ... mynum = 1 ... print "foo" ... scope2() ... print mynum ... &gt;&gt;&gt; main2() foo Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 6, in main2 NameError: global name 'mynum' is not defined
I would imagine it's due in part to three things: 1. Python's "we're all adults here" attitude. Just like there's no form of access modifiers on classes or methods to prevent access to private data, there's no way to define your own scope since it effectively creates "private local variables" within that scope. 2. The only time *I've* needed to explicitly create my own scope in C# is in switch/case blocks where I tried to define the same variable name within two of the case blocks. Python doesn't have separate declaration from initialization, so you wouldn't run into issues just setting the variable twice. 3. In most cases, reusing the same variable name in such a way that requires custom scopes is probably a bad design.
I read something about how it was very complicated to keep straight because the editor only gave you a 2D view of the map. Maybe it had even more complicated restrictions that I was aware of though that made complex examples. As for the red room, you can see it in the map as a true room over room, and it looks like a mess. I wonder if the ingame Auto Map had some intelligence to make it easier to follow.
The rate of growth is going to be very small and on a kind of couple hundred - thousand lines every 6-8 months. This file would be 100% read only and replaced when we add new lines. I talked with a friend and we are thinking that breaking it up into 12 separator files would work for what we are doing.
I have been looking into exporting this file into a database or something different. What would you suggest for formatting it in? I was thinking of trying to export it into csv for now.
I was looking at this at first but I keep running into the problem that I would have very wide tables and there is not really a great way to split it up at this moment.
I'd put it in an SQLite database. Possibly an in-memory one. 
I will look into both of your suggestions. Thank you. 
I'd recommend using Conda - it's virtualenv with much better package control. Also, it's fairly new, so hopefully it'll keep getting better and better!
At the moment the server that I would be running this on does not have couchdb and I wouldn't be able to install it. Thank you for the suggestion of a dict. I'm still looking at getting a really small framework for this project. I need one input string field and the rest is just html and javascript. If you have a framework in mind I would love to take a look at it.
Full parsing in Python 2.7. Look what cars has become in middle of code. import re TEXT = """ F-150, F-250, F-350, FORD, 1998, 1997, 1996, 1995, 1994, 1993, 1992, 1991, 1990, 1989, 1988, 1987, 1986, 1985, 1984, 1983 F-150, F-250, FORD, 1996, 1995, 1994, 1993, 1992, 1991, 1990, 1987, 1986, 1985, 1984, 1983, 1982, 1981, 1980 F-150, F-250, FORD, 1998, 1997, 1996, 1995, 1994, 1993, 1992, 1991, 1990, 1989, 1988, 1987, 1986, 1985, 1984, 1983, 1982 F-150, F-250, FORD, 2003, 2002, 2001, 2000, 1999, 1998, 1997 """.strip() cars = {} for line in TEXT.split('\n'): values = set(re.findall('([^,\s]+)',line)) years = set(re.findall('\d{4}', line)) keys = list(values - years) model = keys[-1] marks = keys[:-1] cars.setdefault(model, {}) model = cars[model] for mark in marks: model.setdefault(mark, []) model[mark].extend(years) model[mark] = sorted(list(set(model[mark]))) # what a nice structure (nested dict) and accessible cars has become # now lets print it like you wanted to for model in sorted(cars.keys()): for mark in sorted(cars[model].keys()): line = '{model}, {mark}, {years}'.format( model=model, mark=mark, years=', '.join(cars[model][mark]), ) print line 
As far as I understand it, if you want to shoot yourself in the foot, Python won't stop you. Likewise if you are working with a library. No protected members etc
Ah, that makes sense. I was confused at first because the statement seemed to go against Python's enforcement of indentation patterns, for example. Thanks. 
This was fun. Here's my take at it. This will only break (given your format) if a car manufacturer name is all digits (i.e. most likely never). data = """F-150, F-250, F-350, FORD, 1998, 1997, 1996, 1995, 1994, 1993, 1992, 1991, 1990, 1989, 1988, 1987, 1986, 1985, 1984, 1983 F-150, F-250, FORD, 1996, 1995, 1994, 1993, 1992, 1991, 1990, 1987, 1986, 1985, 1984, 1983, 1982, 1981, 1980 F-150, F-250, FORD, 1998, 1997, 1996, 1995, 1994, 1993, 1992, 1991, 1990, 1989, 1988, 1987, 1986, 1985, 1984, 1983, 1982 F-150, F-250, FORD, 2003, 2002, 2001, 2000, 1999, 1998, 1997""" info = {} for line in data.splitlines(): pts = [s.strip() for s in line.split(',')] isyear = [s.isdigit() for s in pts] index = len(pts) - 1 while isyear[index]: index -= 1 make = pts[index] models = pts[:index] years = pts[index+1:] for model in models: for year in years: info.setdefault(make, {}).setdefault(model, set()).add(int(year)) Yields &gt;&gt;&gt; pprint(info) {'FORD': {'F-150': set([1980, ..., 2003]), 'F-250': set([1980, ..., 2003]), 'F-350': set([1983, ..., 1998])}}
He means that with regards to variable/function access. Kids try to touch whatever they can, adults should be wise enough to know what not to touch. Scoping prevents access to the local variable/function outside the scope (amongst other things such as calling destructors on objects once they leave the scope).
That's a great explanation. Thanks. 
Depends on the compiler, and the optimization, and of course, there have to be local variables inside the scope as well as locals at the head of the function: foox() { int a,b; // stack frame created here along with return address a = stuuf(); { int c,d; // 2nd stack frame created here c = stuff(); d = foo(); b = buibba(); flibber(a,b,c,d); // 2nd stack frame cleaned off stack here } // initial stack frame cleaned off here }
Optimization varies; it's important to understand what your optimization does, no question. But no, I wouldn't agree that nested scope variables are good practice. What prevents access to those variables is writing correct code. It is extremely bad to depend on the compiler to correct your code, which is what that sort of reasoning is all about. If you try to access a variable that you should not be accessing, your problems are deeper than scope; your algorithm is wrong, or your understanding of it is wrong, or your implementation of it doesn't match your understanding. It's a bad habit if you ever expect to deal with other compilers and other machines. Embedded systems compilers, for instance, may not have the optimizations you have become used to, and in that case, you may cause a serious performance hit. Same thing if the optimization options on a bigger compiler are changed, either by you, by management, or by someone down the line (sometimes that happens because optimizations turn out to have problems.) From my POV -- and this is just me, ok -- scope is a mechanism for constructs like if and case and while. I would never use it to isolate variables. 
In Python, man :-)
Yeah, it depends on the compiler, but in the two most common ones that I've tested, it's not a concern. Try it for yourself: #include &lt;stdio.h&gt; int main(int argc, char **argv) { int a = 0; { int b = argc; b += 1; a = b; } return a; } gives the following assembly with gcc (no optimisation): int main(int argc, char **argv) { 4004b6: 55 push %rbp 4004b7: 48 89 e5 mov %rsp,%rbp 4004ba: 89 7d ec mov %edi,-0x14(%rbp) 4004bd: 48 89 75 e0 mov %rsi,-0x20(%rbp) int a = 0; 4004c1: c7 45 fc 00 00 00 00 movl $0x0,-0x4(%rbp) { int b = argc; 4004c8: 8b 45 ec mov -0x14(%rbp),%eax 4004cb: 89 45 f8 mov %eax,-0x8(%rbp) b += 1; 4004ce: 83 45 f8 01 addl $0x1,-0x8(%rbp) a = b; 4004d2: 8b 45 f8 mov -0x8(%rbp),%eax 4004d5: 89 45 fc mov %eax,-0x4(%rbp) } return a; 4004d8: 8b 45 fc mov -0x4(%rbp),%eax } 4004db: 5d pop %rbp 4004dc: c3 retq No extra stack frames to be found. 
I don't think there's an easy way to do this, too many variables and lots of work including pretty much building your own html/css renderer. This is where I would say that Python probably is not the best tool for the job. 
You should always try to exploit the compiler to catch your mistakes - no one is perfect, and the compiler makes mistakes far less often than a human (it doesn't preclude thinking about your code, but the more checking you have, the better). If there is indeed a performance concern, then you may not be able to do this, but absent any evidence for it being an issue, using scopes is a good idea IMO. They have also been extremely important for me in an embedded context: In a system without malloc (only stack and static allocation), and extremely constrained memory, they allowed the use of multiple large objects on the stack in the same function without excessive memory use. Another area where they are important is using RAII locks in C++: being able to specify the lifetime of a lock to be less than that of a function can be critical.
Use the right tool for the job. If this feature is part of a Python application, and unless performance is absolutely critical, you can use something like PyV8 to evaluate the JavaScript.
"When Microsoft released Windows XP in 2001 with raw socket support implemented in the Winsock interface, the media criticized Microsoft[3] asserting that raw sockets are only of use to hackers to perform TCP reset attacks. Three years after the Windows XP release, Microsoft silently limited Winsock's raw socket support in a non-removable hotfix and offered no further support or workarounds for applications that used them." - Wikipedia I tested the script on Windows XP SP2 and Windows 7, and it works fine.
You can throw this into into SQLite, or just keep it as shared data in a module.
it's historical incompetence, not design.
Didn't know about that 2.1 issue, but then I haven't been around Python that long! `nonlocal` is one feature of Python 3 that I am certainly looking forward to. Whenever I do anything recursive I end up nesting the recursive function, especially if the algo needs some global state, setup or teardown. Brilliant. Except when that global state needs assigning to I end up using a list of a single element and doing something like this: def x(): some_count = [0] def y(): # .... some_count[0] += 1 #.... Horrible.
At one end of the spectrum, you can use httplib and check for response 30x and then look for a location header. Or use the twill library or the requests library and all that goes on automatically.
&gt; I suspect a lot of dynamically typed languages, where you can arbitrarily defined &gt;variables anywhere might have this limitation. Not just dynamically typed. Pascal/Delphi is statically typed, you can only define variables at the beginning of functions and there are no nested scopes either (but there are nested functions). It's the same scoping as Python. 
If you don't want to access variables later in the code... then don't access them later in the code. As someone said above, "we're all adults here". Python doesn't limit your freedom. 
Sure, I have no qualms with classes and agree with you entirely. I think the last time I did the above was when I was refreshing my algo knowledge. I prefer to implement the code as close to the given pseudo code first, then implement it in a pythonic manner afterwards. But that doesn't mean I should not be able to assign to my count variable and python 3 fixes that.
You can use this to get the result in python then create a function that posts the variable from js to a request. Then with django you can receive the request and do stuff with it and send it back. If you want an example of this process I can PM you the code.
http://www.reddit.com/r/metapy/wiki/index Install the fonts if you don't already have them. Contribute if you decide to take that pill.
As both a web and python dev: there is no way you can compute this without rendering the page. So python-webkit is one choice. You should probably look at headless browsers if you're on a server. Using Selenium is good too. You can get it going and drive it from python very easily, particularly with Firefox as it has a Selenium webdriver built-in. (we use it to take page screenshots, from a python script, works awesome).
&gt; You should always try to exploit the compiler to catch your mistakes Philosophical difference. I strive to write correct code instead. After 40 years and I don't even know how many projects on how many platforms, I do ok. We each have our ways, and our advice that is derived from them. 
I wish I could find the original source of the quote, but here's an explanation from 2003: https://mail.python.org/pipermail/tutor/2003-October/025932.html
&gt; I strive to write correct code instead. It's not 'instead'. It's 'in order to'. You can walk tightrope without a safety net just fine, doesn't mean that those that use the safety net are just 'doing it differently'.
Thanks. That's just the type of thing I was looking for. I also liked to reference to Perl: &gt;Perl culture is like python in this respect, but Perl expresses the sentiment a bit differently. As the Camel book puts it, &gt;`a Perl module would prefer that you stayed out of its living room because you weren't invited, not because it has a shotgun.` &gt;But the sentiment is identical.
You can add your own custom [redirect handler](http://www.diveintopython.net/http_web_services/redirects.html) in urllib2 and add the various redirects to the response object.
You can see the compiler is doing exactly what I advised: putting all the locals up front in the first (only) frame. Definitely an optimization, because that's *not* what you told it to do. Why would you need that kind of control? Suppose you're going to drop to asm, created elsewhere. Asm routine requires certain parameters. With a compiler that is obeying scopes, you can quickly create a scope with a known order and content at the top of the stack. This makes it trivial -- and deterministic. Anyway, yeah, compilers act differently, but this is a very good thing to know about this version of gcc. Thanks for your effort. 
Unless someone's uses __slots__ everywhere ... Had a lib like that a few days ago and it made no sense there
Okay, your comment is a bit all over the place but I'll try to address some of it. You are making a **lot** of incorrect assumptions. &gt; Thanks for contextualizing your follow-up around the the troll/hate thread. It really shows your desire to fix the subreddit's design. I don't really understand this comment. You know that moderators don't *only* do CSS right? There's the thing about making sure people follow the rules of reddit and getting rid of things that don't comply with the rules. You should read [the rules of reddit](/rules) as well. If you don't care about the rules, we don't really have a basis to communicate on. &gt; /u/ubernostrum [+1][1] has a chip on his shoulder -- troll from the start with karma and an industry reputation that calls for better. &gt; You give /u/mitsuhiko [+25][3] a greater amount of respect than you do others. When he speaks you listen. When he disagrees you defer. I respect his words because I respect his work and vice versa. Peer validation only tempers his resolve. &gt; Well, you fucking associate his reddit identity with the outside world. This is what I'm trying to tell you. **Associating reddit identities with the outside world will get you banned from reddit**. It doesn't matter why you do it; it's one of the primary rules of reddit. Also, one of the big problems is that you were actually responding to /u/wub_wub, not /u/ubernostrum. So you lashed out without rhyme or reason at someone who was merely trying to inform you that this was an issue. I think maybe you still haven't seen that you told /u/wub_wub that he's a nerd and you hate him. This is why I typically recommend stashing vitriol. It's pretty useless and makes you look like a jerk. Now let's move on to the other stuff. &gt; you just launched the new design without involving anyone else. This is important. It was a small coup -- out with the old, in with the new, "get used to it". I'm kneejerking not only about the new design (ugh) but to the politics as well. So, this is completely and totally untrue. It's not a coup. Just because you're not one of the people that were in on the testing process, that doesn't mean that nobody was involved. * I have a sandbox subreddit. * I had people in on the testing. * None of the people were you. Sorry. &gt; 20 hours into the thread you show up, quickly demand answers and post responses to your own responses within an hour of one another. I didn't demand responses. I responded, I think, quite kindly. You cherry picked *one* thing that I said and tried to turn it into me being a moron. I gave a long, thought out post and you responded to one *small issue* in it, while ignoring the rest of what I said. I called you out on that. In fact, the only time I "demanded answers" was when I asked questions and got responses that questioned my intelligence and didn't answer my question. **I am trying to help out**, and neither you nor /u/mitsuhiko have (even yet) treated me with an ounce of respect while I'm trying to make changes to accommodate the things that you're saying. Like, for instance, I had an interaction with /u/mitsuhiko where I repeatedly tried to get information from him about marching ants. Basically, he seemed to be questioning my sanity, and seemed to think I was calling him a liar. But all I wanted to do was *figure out what he was seeing differently from me*. It took me about 8 comments to get the information that I needed for testing (and for posterity, I'll note that i still can't replicate his marching ants on vanilla reddit using the browsers he suggested). I've been reading my responses to /u/mitsuhiko in fact, and I don't understand why I rubbed him the wrong way. I think he thought that any time I disagreed I was mad or something? I legitimately don't understand, but I'm going to PM them an apology. &gt; When you get a screenshot you dissappear. It was 4 in the morning. I had to get up at 7. I went to sleep, and then I got up and went to work. It should be noted that I own a business, I have a wife and 2 kids, and I do, occasionally, take breaks from reddit. Being a moderator isn't a paid position; I'm volunteering for this. &gt; I still do not know if you are able or willing to work on that aspect of the design. As you said, this is not a small undertaking. I'm going through and making decisions on how this is going to work vertically. I'm not "monkey patching". I'm also not going to start from scratch. There's about 10 people who seem to hate this theme an ungodly amount. I've gotten a lot of people sending me notes, comments and PMs about the improvement. You guys who hate it are in the minority, **but I'm still trying to accommodate the things that are driving you bananas** even though you are treating me pretty darn poorly. As for /r/metapy there are some problems: * **you can't require people to install fonts to use your design** * your sidebar is a work in progress * the yellow is an interesting choice. * there are several points where you have blue on blue. * your header is completely broken * your footer is a huge block * your text is incredibly small * your site doesn't really work with RES (this is a big problem) * (this is my favourite point) your vertical rhythm with your links is all kinds of messed up There are more problems, but that only took me a second to see. The biggest problem is requiring people to download a font to have things look right. You can't require people to download a font specifically for your website. Also, there are reddit limitations, so you can't just use a google webfont or something. I would love to use the Source fonts here. It's not a legitimate option. That's a wall of text, so **here's a tl;dr:** * it doesn't matter how you feel about associating reddit accounts with people in the real world, don't do it, or you'll get banned from all of reddit. * you definitely owe /u/wub_wub an apology. * you make a lot of assumptions about how this went down that aren't true. * the vertical flow issue isn't, as you said, a quick fix. I'm working on it, though. * I'm going to send an apology to /u/mitsuhiko because I think we just severely miscommunicated * your subreddit design... keep working, man. 
Remove the colon from "If statement" and function. Python is the worst programming language but it has large community:)
Immutability makes the stm cheap in Haskell. No mutation means no rollback.
WeasyPrint does this so it can print PDFs and PNGs of pages
And going the other way, Scheme (which is even mentioned in the title) *is* dynamically typed, but does *not* have this limitation. IOW, this doesn't have a lot to do with whether a language is statically or dynamically typed.
I suppose one could define a `with` context manager for a `UserDict` with `__setattr__` (**namespacing**) [EDIT] e.g. with MyNestedScopeDict() as s: s.one = 'red' s['two'] = 'green' s.one, s.two # NameError: name 's' is not defined * https://docs.python.org/2/library/contextlib.html * https://docs.python.org/2/library/userdict.html * https://docs.python.org/2/reference/datamodel.html#customizing-attribute-access * https://docs.python.org/2/reference/datamodel.html#descriptors From http://www.reddit.com/r/Python/comments/1kqewk/should_objects_return_data_or_bind_attributes/cbs2pbk : &gt; Values &gt; &gt; * https://en.wikipedia.org/wiki/Principle_of_least_privilege &gt; * https://en.wikipedia.org/wiki/Information_hiding#See_also &gt; * https://en.wikipedia.org/wiki/Encapsulation_(object-oriented_programming) &gt; &gt; Docs &gt; &gt; * http://docs.python.org/3/reference/executionmodel.html#naming-and-binding &gt; * http://docs.python.org/3/reference/datamodel.html#invoking-descriptors &gt; * http://docs.python.org/3/tutorial/classes.html#python-scopes-and-namespaces &gt; &gt; * [`@property`](http://docs.python.org/3/library/functions.html#property) &gt; * [`@cached_property`](http://wiki.python.org/moin/PythonDecoratorLibrary#Cached_Properties) From http://legacy.python.org/dev/peps/pep-0020/ : &gt; Namespaces are one honking great idea -- let's do more of those!
Yeah. It's literally a bug: http://bugs.python.org/issue9253 (hence being fixed in Python 3.3 but not backported to obsolete Pythons so as not to break compatibility) 
I don't think it's fair to compare the situation to access modifiers. You can signal private members with a leading underscore and as long as users abide by your intentions, it will work out fine. The counterpart for scoping variables would require giving a name to each scope and using them to prefix variables, which would become ungainly quickly. Plus, a big problem with the lack of scopes is namespace pollution. This is exacerbated in Python where you may have to create excess variables due to, eg., lack of proper lambdas. This isn't such an issue with private members, since they don't inhabit the global namespace. I have to say, Point (3) is completely wrong. Scoping names is *good* design (which is why extravagant use of global variables is generally frowned upon). If you only need to use a variable in a local area of the program, you should be able to give it a simple, readable name without chains of identifying prefixes... and that variable shouldn't clutter up the namespace throughout the entire program. As it is, the only way to avoid that is to delete the variable (or use some scoping hack like a dummy function).
I honestly think they left out scoped blocks *just to avoid braces*. Indentation was already being used for block statements that don't always have their own scope (eg. loops), so the only alternative would be "begin-end" blocks, which are awfully ugly and make it hard to apprehend scopes at a glance.
I didn't say scoping in general is bad. In fact, it's great, for exactly the reasons you mentioned. I'm specifically saying that if you have scoping issues *in Python*, you need to rethink your design. If one function is complex enough to need the same variable name defined in separate scopes, you should probably split it up into multiple functions, for example. I'll give that using lambdas is often a pain in Python due to syntax issues, but you should probably be thinking up good names for the lambdas anyway.
Your question makes me think that you are likely doing something fundamentally wrong. If you explain your ultimate goal and add more context about the kind of application, environment, etc... people would be better able to help you.
Doesn't **with** do just that?
I'm cutting off my big toe, and my pocket knife doesn't work. Can you recommend a chainsaw?
Python lacks a lot of features that other languages have that are used to keep you from making mistakes in your code (e.g. enforced variable typing, private methods, etc). Whenever someone asks why Python doesn't have such a feature that allows for the writing of safer code that helps keep you from making mistakes, someone else trots out the old "We're all adults here". It's the idea that they're all such perfect programmers who never make mistakes that there's no point in having such features in the language. I personally find it a rather childish attitude.
Mongodb sounds like a perfect fit. Mongoimpot takes CSV or json data.
Exactly... do whatever you want, unless it's not what the pythonistas want.
if they are in OS X, they need it for their system
Generally it's an explanation of why Python doesn't have the sorts of public/private/protected qualifiers found in, say, Java or C#. The philosophy is that if you're putting a piece of code out there, you can document -- and there are some ways to do this in the code, as with the `_` and `__` prefixes for names of "private" members -- what you consider to be public API. But you shouldn't try to actively prevent someone else from accessing the full API if they need to. Put more simply, it's about trusting that the person who uses your code will either know what they're doing (in which case get out of their way) or not (in which case it probably wouldn't have helped to try to restrict what they could do).
&gt; Okay, your comment is a bit all over the place but I'll try to address some of it. My response fits on a screen. Yours, two and a half. See a pattern here? I'll give fuller explanations. I'm not a **nice** person to everyone in the world all the time just because its the Right Thing ^TM^. &gt; There's the thing about making sure people follow the rules of reddit and getting rid of things that don't comply with the rules. You should read the rules of reddit as well. If you don't care about the rules, we don't really have a basis to communicate on. *le sigh*. I care much about the rules of design. &gt; This is what I'm trying to tell you. **Associating reddit identities with the outside world will get you banned from reddit.** It doesn't matter why you do it; it's one of the primary rules of reddit. 1984 as fuck. &gt; I think maybe you still haven't seen that you told /u/wub_wub that he's a nerd and you hate him. You definitely reworded that to suit your argument.. I can't tell if you're trolling me or just plain ignorant (to the difference in semantics in this case but elsewhere as well). In his case I refer to the TOS-dispensing, finger-in-the-air pointy-haireds running around hollaring "RuuuleBreaker!" putting a negative spin on the words "nerd", "programmer" and "hacker". I know exactly what was said and to whom. &gt; This is why I typically recommend stashing vitriol. It's pretty useless and makes you look like a jerk. Forgive me father for I have sinned. Want to know what else is pretty useless? Those [colored bars on the left][1].. [1]: http://i.imgur.com/6qi1ugN.png &gt;&gt; you just launched the new design without involving anyone else. This is important. It was a small coup -- out with the old, in with the new, "get used to it". I'm kneejerking not only about the new design (ugh) but to the politics as well. &gt; So, this is completely and totally untrue. It's not a coup. Just because you're not one of the people that were in on the testing process, that doesn't mean that nobody was involved. &gt; &gt; - I have a sandbox subreddit. &gt; - I had people in on the testing. &gt; - None of the people were you. Sorry. An excellent way to describe a coup -- just exchange the word testing with voting! After all, upon inquiry /u/mitsuhiko was told that the "test details are not available for your edification" [sic]. Is this horse dead yet? **This** was half the motivation for this post. Let me repeat. One day I woke up to a horror. I didn't get a vote. Lots of backtracking and whitewashing. Complete silence from all other moderators. Counter-protest propaganda. All the components are there -- just micro scale. Keep in mind Reddit and Python are both free and open source software projects. In nature life is often most vibrant at places where two ecosystems intersect. /r/python should pay homage to its relatives. Right now it stands as a deconstructed abomination of Naut. &gt; You cherry picked one thing that I said and tried to turn it into me being a moron. FUCK. Here we go. &gt;&gt;&gt;&gt;&gt;&gt; irregular vertical rhythm &gt;&gt;&gt;&gt;&gt; I need a better summary of what this means. &gt;&gt;&gt;&gt; your homework for the night. &gt;&gt;&gt;&gt; i shall go play in a sandbox and return in the morn. &gt;&gt;&gt; This was improperly said. What I mean is: &gt;&gt;&gt; I need examples of places that have an improper vertical rhythm. Edit: places where I make a change to the reddit norm. &gt;&gt; With respect to vertical rhythm, are you satisfied with the work you have presented? &gt; With respect to vertical rhythm, please just post any example of a place that has an improper vertical rhythm. I retract my edit about it needing to be part of the CSS that I have changed. At this point /u/mitsuhiko interjects to say that he cannot set lines to establish a baseline. I am still trying to set my own lines. /u/mitsuhiko and I have not PMed once. He knew entirely on his own what I meant by "irregular vertical rhythm" and set out to test it using the very same method as I. Mind you the exact same thing happened with the only other thing we discussed, marching ants. Its as if he and I were communicating telepathically. And yet Houdini was mortal -- its called design standards. **This** was the other half of the motivation for this post. &gt; It was 4 in the morning. I had to get up at 7. I went to sleep, and then I got up and went to work. I was patient and willing to be more patient as clearly evidenced by /r/metapy -- however incomplete. I messaged the mods 20 hours in to see if *anyone* was going to say *anything*. You could have said "I'll continue this tomorrow evening." I have no clue what time zone you're in or what schedule you have. At first it appeared there may have been a language barrier. &gt; It should be noted that I own a business, I have a wife and 2 kids No, no, no apparently it absolutely should not. But while we're on the topic I was actually starting to become afraid I was arguing with a bunch of children. &gt; I do, occasionally, take breaks from reddit. Being a moderator isn't a paid position; I'm volunteering for this. Not really an excuse given the way things have played themselves out, don't you think? If you're too busy to do the job right *don't* volunteer. Know your limitations. Every time that I have referred to you as incompetent please understand that I am doing so in an academic sense -- see [Four Stages of Incompetence][0], specifically stage 1: &gt; The length of time an individual spends in this stage depends on the strength of the stimulus to learn. However sadistic, you are more likely to come away a better person because of your interaction with me than otherwise. Call the hostility stimuli. [0]: https://en.wikipedia.org/wiki/Four_stages_of_competence#The_Four_Stages_of_Competence &gt; As you said, this is not a small undertaking. I'm going through and making decisions on how this is going to work vertically. I'm not "monkey patching". To be fair, without a proper reset stylesheet the whole lot of it is monkey patching. I suppose we should be speaking in terms of scale of patching as measured by unintended consequences of each successive change. Naut is 2000 lines. How many have you added? For perspective I have 200 lines so far. 200 and 2000 are an order of magnitude away from one another. My number will grow but so will yours. &gt; I'm also not going to start from scratch. That's the risk you run with jumping the gun -- time sunk. You know, point of no return. Now is better than never. Although never is often better than *right* now. Lets hear what /u/ubernostrum has to say about that design quote.. &gt; You guys who hate it are in the minority, but I'm still trying to accommodate the things that are driving you bananas even though you are treating me pretty darn poorly. Reads as the dissenters are monkeys. You see as long as /u/mitsuhiko and I are *confused* we can be ignored -- and yet we may very well have been the two best served to perform the redesign.. &gt; There's about 10 people who seem to hate this theme an ungodly amount. I've gotten a lot of people sending me notes, comments and PMs about the improvement. Tyranny of the majority. We don't vote on how our buildings and highways are built. If you can honestly say that a "good job" orangered cancels out a list of critical failures then this is a race to the bottom. ...
Python's indentation rules are not just about formatting. They are part of the language syntax. The indentation has meaning. PEP 8 in contrast is not enforced on the language level.
If the indentation thing was about control, PEP8 wouldn't be optional. But it is, and you're free to do all sorts of awful things with your indentation as long as the interpreter can make sense of it. Whitespace for controlling blocks is meant to save visual clutter.
&gt; The biggest problem is requiring people to download a font to have things look right. You can't require people to download a font specifically for your website. I would love to use the Source fonts here. It's not a legitimate option. [Do websites need to look exactly the same in every browser?][2] Let me remind you that the Source fonts are Python's official font and that many people have them installed already and those in our audience that don't could only stand to benefit from doing so. Furthermore, you optimize vertical rhythm in the primary font. The whole site design is in `em`s. If pixel perfection takes a hit when falling back to another font in the family it will be small and certainly within the limits of acceptability for this audience. The advantage being that it will pop for those in the loop with modern typography -- free and transparently. [2]: http://dowebsitesneedtolookexactlythesameineverybrowser.com/ &gt; Also, there are reddit limitations, so you can't just use a google webfont or something. The first night I spent ducking troll fire and learning the limitations of Reddit so that I could better facilitate the discussion. I familiarized myself with Naut and the Reddit and Python designs. So I've been chipping away for one day. &gt; your sidebar is a work in progress Clearly evident by the blatant lack of cohesion and it being explicitly defined under "Design Tasks" in the wiki I refered you to.. &gt; the yellow is an interesting choice. Ambiguity level 10. Since I have no idea where you're going with that let me leave nothing to the imagination. Those yellow links and buttons were taken from the Python design verbatim. Everything so far has. Deep blue and sun yellow are complementary colors already featured in the Python logo itself. I hope by "interesting" you mean good and beautiful and correct (not my horn I'm tooting) -- again despite any small, correctable problems in their current implementation. &gt; there are several points where you have blue on blue. Yeah clearly have not yet colored those links. Clearly. &gt; your header is completely broken `#sr-header` (the tiny top header) will be modeled after the top-most header of the Python site. The `.tabmenu` will be positioned 50/50 overlapping the `#header` and `.content` exactly as the Python site. Not sure what makes it *completely* broken. The Python logo is floated left as it should. The Reddit logo floated right as it should. My reasoning being that reading left to right and top to bottom you should see that this is the a) Python b) Reddit and that there are c) links to Python content and d) you can log in to do more with them. Python logo atop Python content. Reddit logo atop Reddit content. &gt; your footer is a huge block Modeled after the Python site -- clearly not yet aligned properly. Remember, one day in and the project presented unambiguously as a sandbox.. &gt; your text is incredibly small I deal with inferior technology as a principle -- build for the lowest common denominator and leave no one behind. I have NoSquint defaulted to 120% so I'm *constantly* readjusting websites. Resizing of the web has been trivial for users since before the cell phone -- as long as the designer has done his job correctly. Then its just a matter of picking an acceptable default. If the community at large is better served with a larger default font I have no problem setting NoSquint to render http://python.reddit.com at 90%. &gt; your site doesn't really work with RES (this is a big problem) RES and mobile. Not sure how much *more* work RES support entails -- will research it before I comment further. I can empathize entirely with RES users so if there is still light at the end of this tunnel there's no question it would be supported. I am not a designer nor do I have a smartphone. I am ill-equipped to comment on or design for mobile. However, this is exactly the kind of out-of-my-comfort-zone nugget that drives me to work on side projects like this after all. &gt; (this is my favourite point) your vertical rhythm with your links is all kinds of messed up Add a `dev` class to `body &gt; div.content` live for the baselines. Mind you I designed with the default fonts, late last night added the Python font, and just now rechecked the baselines. They almost align perfectly validating what I said earlier -- that `em`s everywhere makes font families Just Work. --- As for your tl;dr -- politics and sensitivities aside: Vertical rhythm is nasty, nasty business. I mean it. Like not afterthought territory.. This is why I am generally tolerant with bad rhythms. However, Reddit has had years to get this almost right. Python.org has just been redesigned by professionals and has good rhythm. The design that I woke up that fateful morning was so arhythmic I was becoming disoriented -- like a physiological response to bad design. I was in essence becoming slightly nauseated. Truth. Sorry. &gt; your subreddit design... keep working, man. I can't help but read that as sarcastic. But honestly, are you telling me to keep working because a finalized version will merit a community vote? ### Isn't beautiful supposed to be better than ugly? Last night I realized that the :visited links were no longer purple. Someone bitched about it here and you changed it. When I see a designer has overwritten the `:visited` to behave the same as `:link` I am left only to think that he a) doesn't know better or b) is dealing with such a complexity of code that one change is having adverse effects elsewhere. You aren't running UX campaigns after each iteration. If the reality is the latter than this will be an uphill battle that will likely not end in a rhythmic page let alone any of the other minor details that didn't even make it to my original list. If it is the former... I want you to go to /r/metapy and tab through the entire document. Marching ants *everywhere* -- still a *few* places to go but the most important parts are there. This is a subtlety that many take for granted. I have others -- too many to list. I can't hold your hand through the changes. I can't give you my marching ant code. It won't Just Work in your context. Worst of all, you don't seem to care. The designer of a 75,000 reader programming subreddit of a language that prides itself in its beauty ... simply cannot be brought to care. --- Racking my brain before submitting.. Are you familiar with the "reset stylesheet"? I haven't heard the term used much since the "CSS framework" seemed to supercede it. Understanding what the reset was doing was vitally important. It was taking a laundry list of good, well-designed defaults and reversing them or nullifying them on a per-element basis. It was a more sophisticated `* { margin: 0; padding: 0; font-size: 1em; }`. I initially misinterpreted this as simplifying the process. In reality it gave you complete control at the expense of much work. You got to control each and every pixel but now you *had* to control each and every pixel. Then came along the [CSS framework][4]: &gt; The general reasoning behind this was discussed in a May 2007 post, if you're interested. Reset styles quite often appear in CSS frameworks, and the original "meyerweb reset" found its way into Blueprint, among others. [4]: http://meyerweb.com/eric/tools/css/reset/ Reddit's defaults are the new browser defaults. You are starting with the /r/Naut "CSS framework" and what I'm realizing now is that what I've started with is a bit of "reset stylesheet" work: rescoping with `em`s, establishing a baseline, visibility reversals. Then I added font, color and placement on top. Should sound pretty normal. Except that is not [what Naut is doing][5]. Its hard to tell but there doesn't seem to be much if any reset behavior in Naut. This means it is not a framework for customization but something more rigid -- something to be used more as is. In fact it calls itself a "custom template". I believe you were the one who originally referred to it as a framework. It has, for all intents and purposes, zero use of `em`s. From what I know about design you cannot achieve a durable, portable, resizable design in anything but `em`s. I am now 100% confident that you cannot shoehorn a proper design into or atop the Naut template. /r/Naut has a "modern" appearance and vibrant community but the code just isn't there. It is definitely second-tier at best and thus a terrible foundation upon which to expand. Its Good Enough for /r/Lakers and /r/Pokemon considering http://lakers.com and http://pokemon.com but considering http://python.org I think the precedent speaks for itself. I mean we had a Django web framework committer on one side of the argument and the Flash web framework author on the other -- one more reason I believe /r/Python's web design should be held to a higher standard. That is my professional opinion and I'm confident now that I have all of the facts on the table. (I have also, in this postface, concluded that I can rip any RES and mobile hacks I might need out of /r/Naut without reinventing.) [5]: https://github.com/Axel--/Naut-for-reddit/blob/master/Naut%20CSS.css
Variables not having types assigned to them is an integral part of duck-typing, which is a philosophical choice that doesn't really have much to do with safety. Conventions (eg _private_methods()) prevent mistakes just as easily as enforcement.
Of course, if python was lexically-scoped, for loops would also be creating separate scopes. Control without braces.
My guess is that it started out as covering the manual handling back in the olden days when that was an issue and they just haven't changed it after the internet became a thing. Checked now and it's 153 USD for ISO8601... so silly
Sorry, you can only speak for yourself. Not for me. 
Absolutely not. In fact, even the document you worship so much has this to say: &gt; A style guide is about consistency. Consistency with this style guide is important. Consistency within a project is more important. Consistency within one module or function is most important. &gt; But most importantly: know when to be inconsistent -- sometimes the style guide just doesn't apply. When in doubt, use your best judgment. Look at other examples and decide what looks best. And don't hesitate to ask! &gt; **In particular: do not break backwards compatibility just to comply with this PEP!** Emphasis mine. PEP 8 includes a lot of stuff that's not worth losing your sleep over. I would hate to have a quick and dirty one-time-only script fail because I didn't include a fucking docstring.
 import requests r = requests.get('http://bit.ly/1hSZWP3') for h in r.history: print '[%s] %s' % (h.status_code, h.url,) print '[%s] %s' % (r.status_code, r.url,)
In my opinion its useful to have code conforming to it, but forcing people to put effort on ensuring that is just a waste of everybody's time. I like the way go does it, where you just have a tool that automatically formates code. So use those automated formatter if you like, but I'd leave python warning for things that can actually represent potential bugs or bad practices.
&gt; I like the way go does it, where you just have a tool that automatically formates code. I like it too. Just to emphasize again, python has it too! Current versions of python come with pip by default. So all one needs to do, is: pip install flake8. 
&gt; In particular: do not break backwards compatibility just to comply with this PEP! Python 3 broke compatibility with Python2, but it gave use 2to3.py to convert and adjust. And the world survived the migration. Similarly, giving people enough time (2 years maybe) to get the idea that pep8 is a good thing, would make things easier. 
So does every high-performance CPython code.
&gt; Not just to comply with PEP 8. It broke compatibility with itself. Python 2 code is not compatible with Python 3. That is what I meant. And I think Guido should stop being nice about it, and force people writing code that is easy to read for humans, not just machine. If there is someone who is to lazy to format his code, I don't mind. He can write in what ever style he want. His administrator, git master, someone should make an svn\git hook to format his code in a proper way. 
It does not: ~$ python Python 2.7.5 (default, Mar 9 2014, 22:15:05) [GCC 4.2.1 Compatible Apple LLVM 5.0 (clang-500.0.68)] on darwin Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; with open("foo", "w") as f: ... x = 42 ... &gt;&gt;&gt; x 42 &gt;&gt;&gt; f &lt;closed file 'foo', mode 'w' at 0x2024f0&gt; &gt;&gt;&gt; with open("foo", "w") as f: ... x = 24 ... &gt;&gt;&gt; x 24 &gt;&gt;&gt; 
They are [different languages](http://legacy.python.org/dev/peps/pep-3000/). They were not intended to be compatible. 2to3 was a courtesy.
No. There is never a good reason to make a style guideline mandatory to a whole userbase of a language. EDIT: Since you seem to think proponents of your idea don't voice their opinion here, maybe you can take it to python-ideas - we'd love to hear from you.
If you are using OpenERP or Odoo, I need your feedback to improve this series of articles about ERPpeek and OpenERP/Odoo. Thank you so much,
looks promising ... looking forward ...
&gt;Except a context manager doesn't create a separate scope. Except? Is this a request for a new PEP? What are the objectives? Encapsulation? Overloading that makes static analysis more difficult? "PEP 227: Statically Nested Scopes" http://legacy.python.org/dev/peps/pep-0227/ "PEP 343: the 'with' statement" http://legacy.python.org/dev/peps/pep-0343/ "PEP 1: PEP Purpose and Guidelines" http://legacy.python.org/dev/peps/pep-0001/
There're some companies who follow their own coding style rules. Especially those who need to certify their software for some particular purposes. Anyway, clean code is very important. Btw, check this fresh post http://blog.jetbrains.com/pycharm/2014/06/write-clean-professional-maintainable-quality-code-in-python/ 
No. PEP8 addresses a social problem, not a technical one. Social problems need to be solved socially, not technically. Communicate, build a culture of excellence, and by all means use tools to support your communication and workflow, but do not try to use tools to make people do things they rather wouldn't - it's more hassle than it's worth. Also, consider how Python is essentially an interpreted platform, and highly dynamic at that; this means that if you were to built a PEP8 constraint into the compiler, chances are it won't fail until you hit the relevant code at runtime. You really really don't want to have your production systems failing just because someone wrote their comments wrong, and I don't think writing extra tests to check for possible PEP8 issues is efficient use of developer time. Anyway, if you really do want to use tooling to force people into using PEP8, you can already do it. Tools to check for PEP8 compliance exist, they are completely scriptable, and hooking them into your source control system and/or build process to reject any code that isn't PEP8 compliant is pretty trivial. On a personal note: Python is bordering on "condescending" as it is, intentionally crippling its expressiveness with the best of intentions; we certainly don't need a compiler that refuses alternative (but valid) coding styles.
I remember trying to implement this myself, but failed miserably after finding out how dynamic the web really is. Glad to see that it wasn't just my own naive ideas and other people want this kind of thing as well!
If you make it mandatory you are saying programs must comply. Enforcing this will effectively break older code. If you have complete ownership of the code, this might be acceptable. If you do not you are going to lose source compatibility with patches and so forth. There are tools that can reformat code to PEP8 automatically. `autopep8` is one example. You can get any good editor to run these automatically when you load a file. pep8 isn't specific enough that two different compliant formatter tools will produce the same code (and therefore won't confuse the VCS or build system). Think about what it says on where and how to break long lines.
&gt;one feature of Python 3 that I am certainly looking forward to. You know it was added in 3.0, which was released in December of 2008, yeah?
The `__name` mangling is to prevent clashes between different "private" properties within the MRO, though. They are still easily accessible from the outside.
PEP8 isn't a full specification and leaves many things to be decided by the tool implementor. Hence, everyone who ever touches the code must use exactly the same tool with the same options, or it will confuse the build system and version control and risks losing compatibility with patches. 
cpython uses refcounting, copy on write is ineffective with refcounting, so it's not that efficient
While I've been mostly using vim/sublime plus various plugins for most of my work, I gave pycharm a try few days ago. I was reluctant at first to even try (eclipse and aptana studio had left a slow get-in-the-way impression for me), but I must say I'm really impressed. The fact that it handles python and js very well and it's not slow (well for a feature rich IDE), has been quite a pleasant surprise.
This wasn't about how to write good Python code, it was a commercial for how great Pycharm is for writing good Python code. I'm not saying that it's a bad ide, but it's more than possible to write high quality code without it. 
Would you mind putting [advertisement] in the title of your post next time?
Everything I've heard from Go users is that they fucking love `go fmt` and would probably marry the thing if they could.
flake8 doesn't format things for you.
`gofmt` is not mandatory. What the OP suggests is the equivalent setting `-tabwidth=N` for all users of `gofmt`; would they like it? No. Plus, I don't like `gofmt`. 
Is there a way to get these things while staying command line? On a laptop, using the mouse/ touchpad feels like a speedbump.
Yeah but being able to use all 3rd party libs is also awesome....
Isn't it one of the primary conventions of version numbering that the first number increments when backwards compatibility is severed? So, 3.0 would have been 2.7 if it was backward compatible with 2.6.
And leaking names from a block would be harder because Python doesn't distinguish between assignment to an existing variable and initialization of a new variable, syntactically. Though Javascript does have explicit variable declaration but does the weirdest damn thing: only functions introduce scopes and all declarations are "hoisted" from the scope and the code behaves as if all variables were declared in the beginning of the function. So this is legal code: (function f() { a = 1; a += 2; alert(a); var a = 20; alert(a); })()
Couch could (and should) run on a separate server. My framework of choice is Tornado Web - very fast. The static file handler is very easy to use, and if you need to make rest calls to get data from the web page (ie, via ajax/jquery) then setting up response handlers for that too. 
If you need to do socket to socket copies or mmap to socket copies you may want to look at splice() and tee() as they can be useful for building load balancers and such i have some bindings at https://pypi.python.org/pypi/butter/0.9 but these days cffi makes it very easy to write your own wrapper
There's also the aptly named splicetee module on pypi. It's not nearly as full-featured as butter is, but if all you're looking for is splice() and tee(), it's got you covered. 
I really respect Kenneth Reitz. He seems like a very nice person and a good programmer. However, this deification of anything he does is really strange. He's just another dude, right?
oh hey, neat to see something I wrote show up on reddit. Like so many interests and side projects of mine, my interest in PyPy was superseded by school and more important things at the time. PyPy is still one of my favorite projects just because of how mind-blowing it is, and I still want to learn enough about PyPy to be able to contribute to it some day. ...Well, you know, contribute more than a tutorial. =)
What is it? I read the README and I still don't have a clue. 
Thanks kumar99.
&gt; I'm not a nice person to everyone in the world all the time just because its the Right Thing I'd settle for being nice to people who are trying to help you out (/u/wub_wub in this case) &gt; 1984 as fuck. So you are mad, because /u/wub_wub took some time to let you know that you were breaking reddit rules (so that you wouldn't do it again and get banned) and you're expressing that by calling /u/wub_wub a nerd that you hate being associated with, because you dislike a reddit-wide rule set in place by the admins to protect people from having their personal lives hurt by things on reddit. And if we bring up that this rule exists, we're being nerds, and not just trying to educate you on the system, and reddit is now suddenly an Orwellian nightmare? I'm legitimately trying to understand here. &gt; commentary on other mods not responding, and timeliness of responses by me * the redesign is my project, not theirs * I'm not going to make myself available to you to be berated 24/7 &gt; Want to know what else is pretty useless? Those colored bars on the left When doing testing, I ran into the same issue with ~40% of users (in both the previous design, and a previous iteration of this design): they couldn't, at a glance, make a distinction between self posts and link posts. This wasn't something that I thought to add in while testing (I could see the difference quite easily) - it was something multiple test subjects asked me about. The bars provide a visual clue that these two links are different things that act differently. If we decide to implement link flair, then there will be more colours added here for the flair. &gt; marching ants This has been implemented back into the theme for a while. Still no marching ants on Vanilla subreddits, but I've ~~integrated~~ *monkey patched* them back into /r/python. I've now had more requests to turn them off than there ever was to turn them on. I'm trying to accommodate those people too. I know what we can say about that: &gt; **Tyranny of the majority!!** Because you say that a lot. &gt; purple :visited links issue I admit, I made a mistake, and didn't test rigourously enough. I'm sure you don't care, but what actually happened was that I had changed back to the default blue / purple for a day, because the lighter blue link colour I used at first was a bit too washed out. Reddit's defaults clashed with the rest of the design, so I made some changes, tested in my sandbox, and then pushed, but didn't realize that I had accidentally commented out the :visited before push. A simple mistake &gt; But honestly, are you telling me to keep working because a finalized version will merit a community vote? No, I'm telling you to keep working, because my first impression is distinctly unfavorable but I want to see where you get to. I wasn't being sarcastic at all. Keep working on it. &gt; 200 and 2000 are an order of magnitude away from one another. My number will grow but so will yours. My number will not grow, it's shrinking. I've implemented a few things "on the fly" as it were, because they were important to get back in the theme ASAP. &gt; From what I know about design you cannot achieve a durable, portable, resizable design in anything but ems. Your homework for the night: is *ems* even the best choice? Is there a better choice? How do modern browsers and devices handle things if pixels are presented instead of ems (or, if they exist, other better choices)?
&gt; Now, please note that I work mainly in projects with hi-level tech requirements (custom web service, intranet, job specific dedicated tool...) &gt; If you work in the day to day web dev (blogs, e-commerce solutions, simple sites you can build with a CMS, etc) Is it just me, or does this sound incredibly condescending? 
Just you.
Really wish it wasn't a video.
I'm aware that `requests` is a very fine library. And it has a fantastic API. I just resent calling things "for humans" because it is a backhanded way of deriding other libraries.
We found MongoDB is good only for read intensive but infrequent concurrent write scenarios. If you have multiple writers, MongoDB effectively serializes each write transaction. 
Fair enough, that doesn't bother me though. Some libraries deserve derision IMO.
So he does something with hyperlinks... And then mentions WIKI.... what is this 2002 buzzwords day?
genius. 
Presumably your username is ironic then? :P
&gt; Some libraries deserve derision I understand it's your opinion, but I don't see why. If you don't like something, use something else. Why disrespect other people's work, especially if they have shared it in good faith? Would you like *your* work derided? There are bound to be people who have different tastes to you / different abilities from yours. 
Kenneth is a smart guy and did a lot of nice projects. But i don't understand why people upvote almost empty repos with some weird readme files in it. After he has finish work and found a better way to tell the world what this project is all about, you'll have enought time to praise him.
Please let us know!
That title mislead me.
Enough to find a job, but still much less than non-remote jobs. Also python can be used for a lot of things so number of jobs in general will depend on what you're good at and what kind of experience you have.
I watched some video with a Brit yestereday and he was saying "NumPee." As irritating as it was, i let it go because he was a Brit. But now i watch this and this guy says "NumPee." Are we all writing Peethon code now? 
Using sendfile() over splice() / tee() makes sense just because the latters are Linux only.
For new projects, please write in Python 3. It came out in 2008. 
I've found [Seaborn](http://www.stanford.edu/~mwaskom/software/seaborn/) to be worth the effort too -- excellent statistical plotting (with good aesthetic control) that is pandas aware and built atop matplotlib for ultimate flexibility (if you need it).
How do you find these serious, remote gigs?
[This][0] was a wonderful time in Reddit's history. So similar and yet so different. Critical thought, craftsmanship and trolling were all -- different -- back then. The only explanation I can come up with is population scale. "Things used to be simpler" sort of thing. Don't get me wrong, things inevitably become more complex and this is can be a good thing but each and every addition should be well considered and tempered with time so that it provides a solid base moving forward. The whimsical nature in which /u/ubernostrum dismisses a desire to achieve "perfection" is rather ironic considering he's a long time committer to Django which on /r/python's very own sidebar is described as "a web framework for perfectionists..." To live under a perpetual ban hammer for hyperlinking as I did seems a bit oppressive, no? [0]: https://web.archive.org/web/20051210023737/http://reddit.com/help/faq &gt; When doing testing, I ran into the same issue with ~40% of users (in both the previous design, and a previous iteration of this design): they couldn't, at a glance, make a distinction between self posts and link posts. This wasn't something that I thought to add in while testing (I could see the difference quite easily) - it was something multiple test subjects asked me about. The bars provide a visual clue that these two links are different things that act differently. If we decide to implement link flair, then there will be more colours added here for the flair. Not opposed to color, mostly vertical lines. We're dealing with horizontal lines with type design. This is thousand year old common knowledge that might fall into the category of "not obvious without being pointed out." Vertical lines break, slice, intersect (remember I spoke of increased interaction in intersections) horizontal lines. Eyes want to relax not have increased interaction -- it is a designers constant battle to fight the urge to steal the users focus. You want to communicate self posts to a user looking for self posts and not be shouting "SELF POST, SELF POST, SELF POST" at every *other* user of the page. By the way, `:hover` overloading this color bar is currently not only the most disorienting aspect of your design but it breaks your above goal not insignificantly. --- If I may digress for a moment. A discussion between a competent individual and incompetent individual occupies one corner of a quadrant (in order of what I perceive to be increasing capacity for dissonance): - level 4, level 2 -- master, apprentice -- ideas, methods, technique flow effortlessly into a receptive mind - level 3, level 2 -- journeyman, apprentice -- both conscious -- few errors, little growth - level 4, level 1 -- master, novice -- both unconscious -- master's fluidity carries the respect to convince novice that he doesn't know but should learn - level 3, level 1 -- journeyman, novice -- journeyman exhausts carrying the burden of proof to an unreceptive mind I gauge myself at stage 3 "conscious competence" while I still gauge you at stage 1 "unconscious incompetence." The coupling of incompetence with political power only amplifies the situation. I hold a heavy burden of proof because not only do I have to search for evidence to back up my claims I have zero guarantee that you aren't essentially trolling me at this point. With power .. responsiblity .. even on Reddit.. #### Stage 2: Conscious Incompetence &gt; The individual becomes aware he/she does not understand or know how to do something. She or he also begins to recognize the deficit is significant and it would be valuable to learn new skills in order to address the deficit and gain competence. --- &gt; This has been implemented back into the theme for a while. Still no marching ants on Vanilla subreddits, but I've integrated monkey patched them back into /r/python. I've now had more requests to turn them off than there ever was to turn them on. I'm trying to accommodate those people too. I know what we can say about that: &gt;&gt; Tyranny of the majority!! &gt; Because you say that a lot. You just gave a pristine example, correct. To be fair, your implementation is terrible so that data is invalid (not a whole lot of strictly *valid* data being communicated here). Clearly your implementation is *different* than mine. Are you not interested in the difference? Because the devil surely lies in the details. I had to "reset" various `visibility: hidden;` among other things to bring working, functional marching ants back to Reddit. I am implying that Reddit's site-wide design was broken in this respect. I do not know *why* they were obfuscated to begin with. Can you speak on behalf of Reddit's marching ants in a mobile context? Were they hidden to clean up the page for mobile users who don't `TAB` around? My marching ants will be muted when I work on colorizing `.content`. It appears that all you've done to address my marching ants issue was to remove the one line from Naut that further worsened the situation bringing it back to Vanilla Reddit. The whole point of me bringing it up originally was that once upon a time we had a usable, accessible design in this respect and it has devolved over the years. Here we stand ten years later and /r/python mods are pushing the /r/naut template which has decided to "fix" the marching ant problem by removing it entirely and this axe-in-the-coffin design *fail* is being magnified across the system to the widespread delight of the "masses". Now all I can reasonably expect as an "appropriate fix" is your [monkey] patch. &gt;&gt; purple :visited links issue &gt; I admit, I made a mistake, and didn't test rigourously enough. I'm sure you don't care, but what actually happened was that I had changed back to the default blue / purple for a day, because the lighter blue link colour I used at first was a bit too washed out. Reddit's defaults clashed with the rest of the design, so I made some changes, tested in my sandbox, and then pushed, but didn't realize that I had accidentally commented out the :visited before push. A simple mistake I just realized that you've patched back purple visited links *for the main links only*. Every single *other* blue link on the site is static blue completely discarding of the visited state of the browsing experience. And yet python.org seems to have made the grave mistake as well. I think someone raised this point once upon a time.. Anyway, its a pretty important feature. Can you imagine Wikipedia w/o it? I can't. Terrifying.. &gt; No, I'm telling you to keep working, because my first impression is distinctly unfavorable but I want to see where you get to. I wasn't being sarcastic at all. Keep working on it. &gt; My number will not grow, it's shrinking. I've implemented a few things "on the fly" as it were, because they were important to get back in the theme ASAP. As far as I'm concerned there currently exists two broken designs -- one at /r/metapy (250 lines clean) and one at /r/python (2000 lines shipped [all the necessary hacks in place], spaghetti [unmaintainable, unpatchable, poorly designed]). &gt; Your homework for the night: is ems even the best choice? Is there a better choice? How do modern browsers and devices handle things if pixels are presented instead of ems (or, if they exist, other better choices)? http://stackoverflow.com/a/5985647 says that both `em` is superior and that designers often shy away from using them. This is the most succint representation of widespread commentary on the subject circa 2011 when people needed to be reminded that `em`s are a scalable unit designed for *varying screen sizes and resolutions* (basically any widely used site). My homework? ...
If you are not yet convinced has this all been for naught?
Why would I want to speed up a python program 114,000 times... Sounds like a lot of work. Why not just once? /s 
I adore docopt. Used it for the first time on a project recently, and thought to myself: "This is what opt parse, argparse, etc should have been'
More things to note not shown here: * You can save these as .svg file types and use Inkscape to add pictures, arrows, etc. for publication-ready vector-based images. * You can get LaTeX typesetting on figures through matplotlib, by doing: import matplotlib.pyplot as plt plt.rc('text', usetex=True) plt.rc('font', family='serif')
&gt; his (secret) company’s data-collecting program Uhhh
Considering numpy is a precompiled library written in C and FORTRAN, probably not.
Looking forward to this
I'd give you a B on the homework. You neglected to even think about percentages. Edit: I don't read any of the stuff you write about incompetence. You can stop writing it. In fact, I think I am done conversing with you. I'll continue working on the theme; you continue your thing. I've gotten some ideas from you on places to improve, and I thank you for them. Good luck with your stuff.
the common syntax for command line interfaces is programname [options] [arguments] can docopt handle more complex use cases, like options and arguments being mixed, for the purpose of having subcommands? for example: program command [options] [arguments] where everything after the program name part can be reduced to the above example think git you could write git --add filename, but instead it's git add filename
haha, I wonder how many will think NSA here
&gt; ggplot2 is a plotting system for R No thanx.
You can start a [matplotlibrc](http://matplotlib.org/users/customizing.html) and set default plotting values like text.usetex: True text.latex.preamble: \usepackage[semibold]{libertine}, \usepackage[libertine]{newtxmath} And then your plots will be publication quality.
You can install matplotlib using pip, and IIRC it would have automatically grabbed all the missing dependencies for you. 
import * is fine if you're just poking at a module in interactive mode to see how it works, but yeah, bad news in general. 
docopt is totally broken when it comes to using `-OO`. $ python --help usage: python [option] ... [-c cmd | -m mod | file | -] [arg] ... Options and arguments (and corresponding environment variables): ... -O : optimize generated bytecode slightly; also PYTHONOPTIMIZE=x -OO : remove doc-strings in addition to the -O optimizations ...
No offense, but has this guy been living under a rock? These examples are trite and dated, and show a tiny fraction of the power and flexibility of Matplotlib and Python. It's an article that could have been written eight years ago (and seriously, installing using apt?). For an example of the state of Python-based scientific visualization in 2014, one should be talking about [Seaborn](http://www.stanford.edu/~mwaskom/software/seaborn/) or [Vincent](https://github.com/wrobstory/vincent).
The API is built to match [The Grammar of Graphics](http://www.amazon.com/Grammar-Graphics-Statistics-Computing/dp/0387245448), hence the name ggplot. It has a fairly high learning curve, but once you get use to it it's a very powerful and clean way to do plotting. Ggplot2 is basically the only reason I pull out R nowadays, as I find it much easier to make pretty plots in it than any Python package. In particular, it has a really beautiful set of defaults, especially compared to the horrendous defaults that matplotlib has. 
&gt; beautiful *yawn*
Doesn't matplotlib have binary dependencies? Installing through apt has the advantage of getting all those, as well as packages you create with them can be packaged as a deb with the same matplotlib deb package as a dependency, so it can be easier to distribute to people with your OS.
Check out: http://www.codecademy.com/tracks/python
I did and it answered all my questions. Certainly going to give docopt a try this time, I hated argparse so much that I always used just getopt.
In addition to Code Academy, [Project Euler](https://projecteuler.net/problems) is quite good if you like math challenges. You can google python solutions to most of the problems.
If you want to make `-O` as an option which could be present 0, 1 or 2 times, you can do the following: &gt;&gt;&gt; docopt('usage: prog [-OO]', ['-OO']) {'-O': 2} However, you *can't* easily do something like GCC does with `-O`: -O -O0 -O1 -O2 -O3 -Os -Ofast -Og In this case `-O` either takes an argument, or not. In case of docopt each option either takes an argument, or not. Making options which *optionally* take an argument is more confusing than useful, I think. In today's age you should rather have a more descriptive options, such as `--optimization-level` with a shortcut `-O` and a defined set of all possible values. I love how in case of `python` the option is `-OO` (oh-oh), while in case of `gcc` it is `-O0` (oh-zero). There is a myriad of bad command-line interfaces like `tar`, where you can both `tar -xzf file` as well as drop `-` and just write `tar xzf file`. As well as GCC and Java-style `-long-options` (with single leading `-`), as well as options that start with `/` instead of `--`. It is not goal of docopt to support all conventions. We selected just a few most useful and most followed, that is POSIX plus `--gnu-style-long-options`.
Assign your doc strings to a variable and pass it in? 
I think he means `docopt` *won't work* if you call Python with the `-OO` option…
Ah, I see. Anyway, /u/Widdershiny is correct: just assign your usage string to a variable.
Code demonstrating exactly what you're trying to do would be helpful.
One gotcha is that the output maybe buffered--ie python is waiting until there is lots of text to be printed before it actually prints it. The Python 3.3+ print function can take `flush=True` as an argument. On older Pythons, import `sys` and run `sys.stdout.flush()` after each print. (You could also re-open stdout and set it to flush by default.) I doubt you'd be having this problem using library code though, so please post your code if this doesn't help you.
Absolutely not! Or, since pep8 says that it is a guideline. **Yes absolutely - adhere to what it says and use it as a *guideline*.** When working from specs or parsing, I reserve the right to insert lines of the spec or lines of example parsed input into docstrings or whatever. When they are longer than pep8 then there are strong reasons to break the guideline in those cases to aid maintenance. Some later maintainer might find it easier to debug problems when he has information on what was implemented in the source - often a simple comparison with the new input lines or the latest spec will quickly point to the problem. Hacking lines over X characters wide would interfere with visual comparison. On your update. It might also be that you asked the question and the reply from the community just isn't what you want to hear. Either way, have fun :-) 
You might try trawling comp.lang.python as it has been thoroughly discussed there for a decade or more...
I'm not in a position to evaluate this since i know nothing about AOP. I assume there are cases where a naive decorator doing stuff to function args/return values isn't enough. What I'm surprised to see is how complex the code gets (I counted 14 levels of indentation in class Aspect). Is the subject matter inherently complicated with all the edge cases and so on, or is there room for optimization? 
Python doesn't try to protect you from your errors, much. Apart from ctypes, which is a special case, nothing you do in pure-Python code should cause a core dump. But apart from that, if you tell Python to blow your foot off, it will do so. The strongest and most obvious example of this is, *no private attributes*. Private is a convention, nothing more. You know all those blog posts from Java and C++ developers giving non-portable ugly hacks to defeat the compiler and get access to private and protected attributes? Python doesn't even try to stop you, you're an adult, have some self control and don't mess with _private attributes, but if you do, on your own head be it.
Doing 100% remote python work, as I have anoter full time 'job' (grad student). Mainly small contracts trough odesk, but enough to pay the bills with a little extra left. 
Python is lexically scoped. The scopes are at the function level, not the for-loop level. "for loops define their own scope" is not part of the definition of lexical scoping.
Docopt is some ballin' shit. I tell everyone about it. So, so useful
Python is different from C++ in that sense, since lookup of variables happens at runtime, not compile time. If you have nested functions (say) five levels deep, that means that accessing a non-local variable could potentially do *seven* lookups: the five surrounding scopes, plus the module (global) scope, plus the builtins. That cannot be optimized away. (Python can tell at compile time whether something is local to the function or not, and accessing locals is fast. Everything else, not so fast.) Reducing coupling by using separate scopes is a good thing. Python encourages you to use separate functions and pass arguments to them, rather than rely on scoping rules. You can use nested functions, of course, but they're mostly used for closures, not merely to separate scopes. And for-loops, while-loops etc. don't create their own scope -- it is just seen as unnecessary. 
What's import wikipedia do? 
&gt;This code does rely on the WikiPedia API to run.
+1 for: &gt;ballin' shit. 
Real Python. (Note: I am the co-founder/author). Our motto is - Real Python teaches programming and web development through hands-on, interesting examples that are useful and fun!
How do you take screenshots using it?
[**@openwizard**](https://twitter.com/openwizard): &gt;[2014-05-18 14:28:47 UTC](https://twitter.com/openwizard/status/468035474238763008) &gt;[@bitprophet](https://twitter.com/bitprophet) Now that Paramiko supports Python 3, do you have a rough timeframe for Fabric 2 release? [**@bitprophet**](https://twitter.com/bitprophet): &gt;[2014-05-18 17:33:52 UTC](https://twitter.com/bitprophet/status/468082051842064384) &gt;[@openwizard](https://twitter.com/openwizard) "Soon", in that it's being actively worked on. Hoping to have an alpha quality API ready for feedback within a month or less. ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/284l8k%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
I asked Jeff Forcier, the maintainer, when we could expect Fabric 2. He said alpha within the month, hopefully. That was almost a month ago.
I liked Learn Python The Hard Way. The author has a unique approach that is hands on learning. 
print/log the json file somewhere when you get the error and look at what you actually got, and you'll know if it's the same or not.
Oh! I can't believe I forgot to mention, it works fine when I set the time.sleep to 30 seconds or less, and I think 1 minute works fine too, but get the key error when I sleep for 5 minutes.
"a really beautiful set of defaults" that is completely unsuitable for publications. Light blue dots on a gray background? Really? This is what it looks like in black and white: https://imgur.com/a/oGmXB
Don't think Android has anything nearly as polished (which sadly is true in general). iOS is also getting IPython soon: http://computableapp.com
That's python 2.x Code. You should write parantheses for your print, so your code is a little bit python3 ready. For best results Do it form the beginning. Edit: phrasing, correct "parantheses"
You probably looked at the wrapper handling the coroutines/generator functions. I want to truly wrap around them (consume them completely before giving control back). It's horrible on Python 2 (no yield from) - you can see the crazy code you need to write in [PEP380](http://legacy.python.org/dev/peps/pep-0380/#formal-semantics). Ofcourse it's much more simpler if you only need to handle values in one direction (plain generator functions) but I want to handle coroutines too (bidirectional generator functions).
I have also heard good things about click...
Acctually lern python 3, ecxept you plan to maintain old code, which can ne quick money, but is not so good for developing/prototyping 
Lol it's not any effect other than I am now tired of your constant comments about my abilities, and your overwhelming arrogance. Also your insinuation that I'm a fascist (stalker level: officially creepy) is amazing. I can't follow your logic at all.
Thanks, that explains a lot. Kudos for supporting Python 2 and 3! 
I agree. This is an absolutely atrocious article that will do nothing to help anyone learn scientific plotting using matplotlib. I would highly recommend this reference by J.R.Johansson as the ultimate cookbook and easy lookup to do most matplotlib plotting: http://nbviewer.ipython.org/github/jrjohansson/scientific-python-lectures/blob/master/Lecture-4-Matplotlib.ipynb Personally, I think matplotlib is still plenty capable for scientific plotting purposes. Sure, it may not generate "pretty" plots out of the box, but that can be solved using libraries like prettyplotlib in conjunction with it.
I mean, the defaults are clearly designed for web use or other on-screen usage. That isn't exactly an unreasonable decision. Changing to black-white for publication is quite easy, often as simple as adding "+ theme_bw()" to your plot.
This was too long, and I always see magical posts here on how to speed stuff up. Was this the real deal?
It's likely the case that the remote host is giving you different responses based on how often you request. It could be ratelimiting, e.g. The response from `requests.get()` has an HTTP response code, you could double-check that. Also, dump the text output.
I just started learning python 2 days ago. I am blown away at how powerful this app really is. I wish there was a second app for complete beginners though. I need something I can learn on that doesn't require an internet connection. Seriously though. This app is amazing!
I agree with LarryPete. After p = request.get() .... print p to see in the request returned anything. The solution may be as simple as looping to do multiple requests until you get a valid json response. Or using a try/except on the sidebar line below. The key error is likely coming from the line: sidebar = str(data["data"]["description"]) As it is the only place in the code the could cause a key error.
The app does note require an internet connection AFAIK. I assume you mean docs/samples?
I don't think his problem is that he doesn't have hands-on resources. I think his problem is that he can't find practical application for what he is learning. i.e. Why should he use tuples? What is a list for in general? What advantages are dictionaries and when to use them. That sort of thing. I also struggle with this as I am learning. I think Real Python might be a viable resource; I just can't spare 60 bucks right now. 
Of course, of lot of stuff come from my previous clients, either directly or with world of mouth. But when I don't have anything, which is now quite rare, and usually means I don't have anything I would enjoy doing, I do the following : - go to tech/geeky events, listen to a conference, have a beer with people, give a talk, sprint a feature, etc. You meet a lot of potential clients there. - script some crawlers to gather all missions related to python on dozen of sites, and batch process after a week. - call my friends, ask followers on social medias for work. EDIT: forgot to mention that _regularly_ contributing (even just a little, even typo fixing) to several open source projects help a lot. I also had some good job offers through my Stackoverflow account. Giving back to the community is good for you.
It's just you. I did blogs, e-commerce solutions and simple sites. I'm telling from experience.
In addition to reading just start coding and Googling when you get stuck. Take note of simple things you do daily or weekly and automate them. For instance I have a python script that runs once a week and deletes all files older than 3 months in my Downloads directory. I have several scripts that do my repititive tasks for work that my boss thinks I spend hours on but in reality python scripts are spitting out spreadsheets for me
Oh no, this app is great. It's just that most tutorials/learning videos or explanations require an internet connection. I followed along in the help section until I need to google some clarification. I wasn't complaining about the app, just surprised that there isn't a learn python app in the App Store. That's all. :)
Thanks
TLDW (one hour!); summary?
Have you been to /r/learnpython ?
Cool! I got busy and didn't have time to learn BS4, but now that I am using it it seems very powerful. However, I have one question. The website that I am trying to scrape in the API section states that it has a JSON component: https://familysearch.org/developers/docs/guides/know-this However, my json request fails for this webpage: https://familysearch.org/pal:/MM9.1.1/F1R5-1WL Sometimes, just changing one thing in the web address provides me with the same page, but one has json and one does not. For example: does not have json code --&gt; https://familysearch.org/search/collection/results?count=75&amp;query=%2Bbirth_year%3A1863-1863~&amp;collection_id=1417341 has json code--&gt; https://familysearch.org/search/records?count=75&amp;query=%2Bbirth_year%3A1863-1863~&amp;collection_id=1417341 Even though both addresses display the same information in html. 
&gt; the json file it grabs should be the same the next time &gt; so it shouldn't change &gt; I just can't see it. Step 1: stop assuming and look at the response you are getting.
There's a python port of ggplot, and seaborn is the library you want if you want ggplot aesthetics and statistical focussed plotting (pandas aware faceting etc.). Just importing seaborn instantly makes matplotlib have better defaults, and seaborn plot commands produce very beautiful plots very easily.
which seems to fit OPs model, it's not write-intensive.
There were some "programming language" apps that required a server (they actually compiled/ran stuff server side). There are ways to download tutorial videos and tutorials, and run them right from the iPad. You might want to look at AVideoHD and OfflinePages . I am sort of expecting Apple to come out with a Swift Playground app for iPad.
Their API docs seem to suggest that you must use "Content Negotiation" to specify your preference for xml or json, so try adding an "Accept" header to the request for "application/json" and see if that helps?
Okay. Fair enough. How do I check the response code? As I said, I'm fairly new to python, and have mostly been working off of tutorials so far.
Brits say 'pie-thon' like everyone else
I have said this to many budding programmers, make a game, PyGame is a fine place to start but almost any GUI system can give you crude enough access to make something fun. Aim for space invaders. Then pacman. If you could make a two place over the net version of pacman that bounces off a server then I will proclaim you a programmer. The advantages of games is that they are free form, cover lots and lots of programming areas, aren't exactly critical infrastructure, and might impress your friends. The other fun part of games is that there is generally no one right way to do anything. So you will have to google over and over things like, "Play an mp3 sound effect in Python" and then you will be exposed to the various arguments as to the best way to do this. But then you will realize that you want your sound effects to overlap, maybe the technique you used works or it doesn't so you have now learned something else that is new. And playing a backround musical score, that might involve a thread of its own, or maybe some library that takes care of it for you. Again you will bathe in new information. Also again it being a stupid game you can always cut a feature. Let's assume that ever single way you put in a background score it causes problems, then you just don't have a background score. But at the same time you can always add flourishes. Maybe you make a 2D game like packman on round 1 but then for your second try you abstract the bulk of the game but redo the interface in 3D but all on a 2D plane. Then you could keep the same game engine and go to a first person point of view with semi transparent walls. Making leaps like this will cause you to abstract as much as you can which is a generally valuable skill. Doing 3D math on a 2D plane is a much simpler way to learn 3D math and 3D interfaces. Also then you might find your bugs are surrounding you. So try out Unit testing which can really make your code rock solid. Also when you do unit testing it encourages your code to be less spaghetti like. Again a great skill. So again if you make a first person point of view 2 player networked, unit tested, Pacman then not only will I proclaim you a programmer but a programmer who has done something cooler than the majority of "professional" programmers that I have worked with over the years. At this point my only suggestion would be ProjectEuler to really polish up your skills. 
Okay I think I figured it out. I'm getting 2 different response codes, 200 and 429, seemingly at random. The string produced by the .json() command of that response is identical for both though.
I only used it briefly, but I remember thinking that the python port was only okay so far. Especially because I didn't have access to some of the R-specific utilities that I normally use with ggplot2 for plotting. I honestly find it easier to just dump the data and run an R script to do my plotting. Maybe once this port matures a bit I'll give it another try. Seaborn also seems okay. I'll admit that I haven't really tried it, but the examples seem to show a default aesthetic that is close to ggplots, but not quite as nice.
Look up what http429 means. The json is not identical, if it were identical you would not be having a problem. 
 if p.status_code == 200: do something elif p.status_code == 429: do something else else: do something else
I recommend taking part in [PyWeek](http://pyweek.org). It happens twice a year. Participants write a game in a week (alone or in teams), and then rate each other's games.
What Wikipedia API? How do we install it? Did you write it? Do we download it from Wikipedia? If not, where do we get it from? If you're going to use a non-standard library, you should explain where it comes from.
[Progress bars with Python.](http://thelivingpearl.com/2012/12/31/creating-progress-bars-with-python/)
Um, so, what's angellist?
http://www.codecademy.com/ I learned some from there. It's a great site! 
"numpy" looks like it might rhyme with "grumpy" or "lumpy". When all you've got is text, it's not always obvious how to pronounce non-words.
Even with `from __future__ import print_function`?
He's a vampire with a soul on a mission of redemption. Likes Barry Manilow. Or poosibly a websit for start-ups: https://angel.co/
https://angel.co/ It is a crowdsourcing platform for startups and private companies in general where the investors group together and try to invest startups in "syndicates".
Online dating for startups/investors http://www.technologyreview.com/news/511146/the-social-network-that-really-matters-to-startups/
One hint if that in the readme or post would probably be a good idea. 
Dude, look up the wikipedia API. The first result will explain
Thanks that seemed to have worked!
I cull a quote from page 1 of your user page and I'm a creepy stalker? You're a joke. I don't need you and I don't want you and yet to stay here I have to sit down, shut up and accept it. I didn't vote for you and I can't impeach you. If I want something different I have to go somewhere else and start from scratch. You're a fraud, an imposter, incompetent, ignorant and arrogant. All those nervous smiles earlier were an attempt to obfuscate this. You could have handed off the baton to someone more capable, more dedicated. Instead, fuck, just go play some fucking WOW you moron.
&gt; I don't need you and I don't want you and yet to stay here I have to sit down, shut up and accept it. * get RES * uncheck "Show subreddit styles" You are now officially done with any effect I have on your life.
Bro, do you even code?
Also, this guy's head.
You didn't indicate what you consider to be a bug. Eval() has access to the local variables of the function. So k is the current iteration and n is the last value. You don't have a variable t, so that raises an exception. If you want not to have a scope, you must pass to eval another scope: eval(input('enter number'), {}, {}) Note that eval will still have access to builtins. 
Use int(input(prompt)) instead? Catch ValueError .
I think you are right about the buffering. As I replied to an above comment, flush() doesn't seem to change anything. Because I was out of ideas, I tried calling print('.') sleep(1) within a gevent call within each iteration of my loop. Since that should (I think?) call these as separate threads, the sleep(1) shouldn't effectively do anything. Instead, it appeared that the entire loop ran, then it waited 17 seconds (loop ran 17 times) and then printed the dots. But perhaps I'm complicating the issue with my lack of experience with gevent.
what kind of useful information can you pull with this?
I would like to have a sense of which parts of a webpage are "important". What's important? My reasoning is that they have to be big for a human user to see them. What do you think? Ignore earthboundkid, he's just an asshole.
Thanks! This is what I was looking for.
Python is the only language on which I have a firm grasp. Thanks.
What, I didn't understand. What does Django have to do with this? I want to, given a website, do what I said. As far as I can tell Django has nothing to do with this. 
Using Python is really not good for this use case. You'll have to go through a lot of unnecessary problems. You can use something like Selenium or PhantomJS to automate a browser. You'd open the web page, run some Javascript code to find the things you are looking for, and save the results in a format that you can process later with Python. There's no other way that doesn't involve a rendering-engine one way or another. The size of elements on the page depend on a lot of things (including the Javascript code that may be executed) so by just looking at a bunch of HTML and CSS you can't calculate the size. You need a full-blown browser to completely process the document, fetch the external resources, execute any Javascript, etc... and only then you'll know what the document actually looks like. Is this for a product or a core part of a software? or just a quick and dirty script? depending on that the complexity of the solution may differ. (also you need to check if the large element is actually visible or not, etc..., lots of gotchas)
Most boxes I have to support are 2.6+ so I hadn't seen issues before. The point here was more about allowing the OP to learn python, and as a newb - it may be worth taking the time to at least be exposed to the future of the language as well. I much prefer the new print function over the statement but depends on the application.
&gt; It currently supports Python 2.7 and &gt; No external dependencies Python 3 has been out since [Python 3.0 - December 3, 2008](http://en.wikipedia.org/wiki/History_of_Python). I guess what I want to say is: **Why?** 
Mostly, anything from Angellist api: https://angel.co/api I created an ipython notebook for some of its capabilities, also updated readme with this link, please let me know if you have more questions. http://nbviewer.ipython.org/urls/gist.githubusercontent.com/bugra/5236ca2c69695d2afa37/raw/f8ad23c7678880729e745377cfc9e75201a6b05a/Examples%20from%20Module
Convince 'em to pay someone to write better docs. That's what's stopping me from trying it.
Because without using external library, urrlib is hard to use without import games and I simply do not have time/patience to support both Python 2 and Python 3 at the same time. For future, I want to create Python 3 branch, but it is only an idea now.
What about python-webkit that someone else mentioned? You think that'd be appropriate?
Not familiar with that one. You need to check to what extent it processes the document. It may only read the HTML and give you DOM functions but that is not sufficient in your case.
mind blown
I have narrowed down the problem. My theory is: PRAW only sends server requests at most every 2 seconds. For efficiency, it groups all requests in your python script together and then batch sends them every 2 seconds. I found that by looping through a much larger collection of posts, my progress bar indeed updated in blocks of like 50. This is nice to know. I'd still like to know *how* I can seemingly iterate through my loop 50 times without the loop code itself running until then. Seems like magic.
The whole subreddit is constantly complaining how they don't move to Python 3 because of dependencies, then upvotes new packages that run on Python 2 and constantly defend the decision. As a community people should encourage migration to Python 3, because this separation is a complete joke and hurts everyone. I didn't meant to come out as aggressive as it maybe looks, but at this point the whole thing is getting ridiculous.
That's the feedback I got from everywhere.
Interesting thing you have there. I noticed though, if I type in literal characters it has some trouble matching, but shorthand expressions work fine. Also I have a question. The way it runs the match in real-time, is this made possible via Python only, or do you need Javascript and other things to do this? I made a similar tool yesterday, but it is very basic: http://vm.pe/regex
So you had downloaded wikipedia api library, typed some print statements and library calls, and waiting an approval from everyone? Sorry, dude, I know that it is an big step in python learning for you, but it is really very simple code for most of the fellows here. Maybe you should upgrade this code and create some kind of a RSS feed or nice facebook app, so it will be really useful.
You mean this? http://www.mediawiki.org/wiki/API:Main_page That's the Wikipedia API. It says nothing about a Python module called "wikipedia". You know, instead of being a dick about this and making people *guess* what module he's using, all the OP has to do is provide a link to the website where it comes from. Is that so hard? Any time you use a non-standard module, especially one which is not well-known, it's a good idea to link to where it comes from, not just use misleading and generic terms like "Wikipedia API". It's not the Wikipedia API, it's a Python module. If I had known it was going to be so hard to get a simple bit of info out of the OP, I wouldn't have upvoted this.
The main philosophy behind python is "explicit is better than implicit". You can get the whole motto by doing "import this" in a terminal. The reason why it's a bad idea is that it forces the code reader to go back a line to get the full context of the current line. Backtracking, on any task, add to the cognitive charge. Small additions of cognitive charge is what's make the difference between "i understand" and "it's clear", and "I have to get a rest" vs "i'll fix this last stuff before leaving". Python has a very great syntax in that regard : it maximizes the context (for a dynamically typed languages, of course, since you lack the type information) you get from reading a very small part of the code. It avoids second guessing and information reconstruction. It delimits units of logic quite clearly. The opposite of that are lisp, perl, or more recently, coffeescript, which require a high level of concentration to be read : you need to keep a much bigger part of the context in your memory and match it to the place you currently are, based on ambiguous delimiters. Another important thing is that you have a big difference between mutable (list, dict, set, classes...) and unmutable (str, int, tuples...) objects in Python. The current syntax make it very easy to understand which kind you are manipulating, which is of the utmost importance in a language where everything is passed as a reference. With your suggestion, your brain has to, once again, take more time to rebuild the context to understand what's going on. 
Apologies, I'm new (As you may have guessed). I hope i have fixed it :P EDIT: Those seem like very valid philosophical reasons. Thanks for the input :).
Much better, I'll remove the passive-agressive part of the comment :)
Why not just use requests? Is not requiring dependencies really worth jumping through hoops and not being able to support Python 3?
The [Matplotlib Docs](http://matplotlib.org/users/installing.html) talk a lot about the apt approach, so you may be onto something. Still, getting it from pip will build all of the binary dependencies (or wire up the already-present ones) in a transparent manner. This works across all platforms and allows greater flexibility and the use of the most recent version of the library and all dependencies. In my experience, `pip install matplotlib` has functioned well on all platforms I have used it on, and is pleasingly the same as my installation routine for pretty much all other python modules. It's really a stellar tool.
Yeah, I think it really depends on your use case. I have seen pip packages that fail without a dev/lib package, but pretty rarely. I seem to remember matplotlib needing fortran libs outside of the pip package but I may be wrong. For those that plan to push their python package upstream to Ubuntu or Debian, it would be better to declare deb dependencies I think. Is there a way to have a pip package install binary dependencies into /use/local/lib, or install a Debian package? I haven't seen a way to declare them in setup.py.
I think it can deal with fortran dependencies as long as gfortran is present at the os level, then it just builds them and installs into something like a lib directory within the python install and adjacent to site-packages. If your python install is locally stored, you can even build C/Fortran dependencies without even being root.
That only works in in interactive mode, not when running a script. I've tried both ipython, python2 and python3.
Checkout ThinkPython: http://www.greenteapress.com/thinkpython/thinkpython.html It teaches you not only the syntax but the logic behind the concepts. I thought it was the best book learning programming so far for me. I gave it some friends who wanted to get started. Their feedback was really positive and one of them finished it within a week and was able to work with me on a project. While reading this book you could use little programming challenges like Project Euler, codeacademy, codingbat and so on and so forth. This will help you getting familiar with the data structures and syntax of python. :)
Did you install 32 bit version? [More here](http://stackoverflow.com/questions/19472141/can-not-import-pygame) Also, is it pycharm's problem, or you cannot import pygame even on terminal? 
You mean like importd
I suppose you forgot to add a link to this: https://github.com/sametmax/django-quicky Also it's worth noting that you can do without importd or django-quickly [just fine](https://github.com/ionelmc/django-redisboard/blob/master/run_redisboard.py)
Thanks, I added the link in the text blob. Also, you can do python web programming without django at all. All in one file if you wish :) Tools are here to save you time. Django-quicky saves you time for stuff like automatic JSON response conversion, and getting the view next to the URL it handles. It's not always something you want, but when you want it, it's handy to just be able to do an import and just hack some quick and dirty API or else.
UPDATE: Script now automatically removes trailing x's if every sub in the list ends in x without having to ask you
Some apps might not use south, for them you have to use syncdb. Other apps which are integrated with south, use migrate. `syncdb` can recognise apps which are using south, thus reminds you to run migration. 
I was looking for a good tool to try out and test regex since Kodos doesn't really run anymore (never got it to run on OSX anyway). PyRegex wasn't really it: aside from not being the fastest tool in the box (which is OK) my biggest beefs with it (and most online regex tools, to be fair) are: * you can't give it multiple test strings and see what the result is on all of them. That's very useful when you've got half a dozen test strings, some of which should match and some of which should *not* * the output is rather verbose (a big block) yet not quite helpful/readable. Importantly, it would really benefit from having the original text with matched blocks highlighted * the matching lags a bit for me, I get 300ms latency and 200ms download time even after the delay before it decides to send the query
&gt; * {m, n}? from m to n, as few as possible Well snap, every time I think I've got regex nailed, I learn something new.
&gt; The way it runs the match in real-time, is this made possible via Python only, or do you need Javascript and other things to do this? Javascript, when the input changes it sends a query to the backend to retrieve the match response: https://github.com/rscarvalho/pyregex/blob/master/assets/src/coffee/resources/regex_resource.coffee
I've installed anaconda in the past but continued to use pip on its own. This is a good overview of the purpose of conda and its capabilities. This covers how you can managed multiple python environments, create a python 3 environment inside a python 2.7 anaconda install, build packages, extract an environment and dependencies into a tarball, and use environments to manage non-python tools.
Silly question here but how do you guys pronounce regex?
Thank you for the comments! I'll create issues on github to address those concerns. I really appreciate your feedback!
btw the 500ms of wait is just because it takes time to process the regex, and I run the python server on a Heroku free web worker, which does not have too much priority on CPU cycles... Maybe someday I could receive some donations to help me maintaining a "real deal" server for PyRegex.
Another problem is that it becomes a nightmare. Say you do that. Then, one day you need to add a new variable in that block of code. Bang. Now you have to replace all the ! after that, because you are not reusing the last variable anymore.
"reg" as in "regular" and "ex" as in "ex-coworker"
**UPDATEUPDATEUPDATEUPDATEUPDATEUPDATEUPDATEUPDATEUPDATE** All files can be found in [this](https://www.dropbox.com/sh/7htrm98ppr4n2rl/AABxFUh6p0l6cDhloSmPOnh4a) dropbox folder. *Note that while writing this outline, I have been cleaning things up to make this more understandable. The outline is no longer in any way akin to how it originally went down.* First I went to [this wikipedia article](https://en.wikipedia.org/wiki/List_of_most_popular_websites) and Ctrl+C Ctrl+V'd the table to "Wiki Data.txt". I had to delete the 'googleusercontent.com' row because 'googleusercontent.com' (seemingly) no longer exists. I deleted the '360buy.com' row because '360buy.com' redirects you to 'js.com'. Outline of different scripts and their functions: "character counter.py": * goes to every site in the text file * finds the number of characters in the HTML * saves this data to a "Wiki Data plus Character Count.txt" * This is done seperately from the graph maker because I don't want to have to visit 100 webpages every time I make a formatting change to the graph. "line counter.py": * same as last one, but counts new lines instead of characters * saves data to "Wiki Data plus Line Count.txt" "mega graph maker.py": * uses matplotlib module in python to make some different plots * At time of posting this, I am not completely satisfied with any of the graphs. But it would be pretty easy to add one in another style. If you have an idea, LET ME KNOW! I *tried* to make the code very easy to read, so check it out if you know Python! **Also:** Wow, looking at the extremely ugly source for some of these sites, I feel mystified. Does anyone know a reason why some of these very simple home pages have upwards of 10,000 characters packed in a couple lines? **Edit:** tipsqueal (tip squeal or tips [queal](http://google.com/search?hl=en&amp;q=define+queal)?) answered the above question. Here is my understanding: * whitespace is removed to minimize file size and therefore loading time. So it is all packed on a couple lines. * A human would never write something that looks like that. Another program (I think in another language) generates this code. **Edit:** Less pretentious.
I use python 3.4 on Mavericks. It is a huge pain to get things to work.
I spell it with a soft "g". It sounds a bit like "red jacks"
I was really hoping to be able to see the name of the sites on one of your graphs. Then graph 3 has names but is an absolute monstrosity, no offense. Maybe do a really wide bar graph one or one for just 1 through 20 so its not too wide but can fit the names of the site. Really interesting work regardless. Wouldn't think there'd be a crazy outlier like Youku in there. Or that that even exists, Chinese youtube I guess?
while i agree in the sense that it fairly trivial to write NEW code that is compatible with both branches (2.7.5 and 3.0). I have to point out that python 3 is not considered stable by most of the enterprise world. Also 2.7 is what is in the official yum repo for rhel6/7 and pkgsrc. I dont think attacking the author is appropriate way to get what you want. Why dont you submit a request ticket so it can be addressed. ya know.. like every other open source project on github.
1.) A line graph makes no sense for a collection of discrete entities. By using a line graph instead of a bar chart, you're trying to get us to interpolate where a website that's between, say yahoo and youtube would fall. That's nonsense. 2.) If the bar graph had **horizontal bars**, not vertical, you could label them, inside the graph, with site names. 
&gt; Wow, looking at the extremely ugly source for some of these sites, I feel like I could write better. Does anyone know a reason why some of these very simple home pages have upwards of 10,000 characters packed in a couple lines? If you take all of that code and add whitespace then the file size explodes, and page load time increases significantly. It's called [minification](http://en.wikipedia.org/wiki/Minification_(programming). I assure you that the actual source code used to generate those sites probably doesn't look anywhere near as bad. What you're seeing is NOT source code, it is markup and some JavaScript. The source code used to generate these sites probably doesn't look much like what you're seeing. For example take a look at the [source code for reddit](https://github.com/reddit/reddit), it looks nothing like the markup you see on the home page. In short, basically the metrics you gathered are useless, you could have just downloaded each homepage of each site and counted the file size, that's all that matters.
 except: break You've just removed any possibility for the calling program to find out what the exception could have been or to handle it properly. If you don't have a really good reason to capture the exception, it's generally better to let them bubble up. So, you might consider just catching `Queue.Empty`.
&gt; A line graph makes no sense for a collection of discrete entities. I realize this, that's why I had the primary image be a bar chart. I included the line one because I wanted to show everything I used, but I see how it could be misleading. &gt; If the bar graph had horizontal bars, not vertical, you could label them, inside the graph, with site names. I tried, but couldn't figure out how to put labels on bars with matplotlib. If anyone would point me in the right direction for documentation on this, I would be grateful.
Sounds intriguing! Care to elaborate on details, such as industry, application field, amount of data, input and output formats?
&gt; I was really hoping to be able to see the name of the sites on one of your graphs. I'm currently making a horizontal bar chart. Since points are stacked vertically, and text is read left-to-right, no overlap. &gt; Then graph 3 has names but is an absolute monstrosity Yeah, I also posted this to [r/dataisugly](http://reddit.com/r/dataisugly). It got better reception there.
Oh IC, someone needs to do his homework. Good luck!
Will watch. Wanting to explore compiling complex libraries with tons of dependencies and distribute binary packages. Conda appears capable of doing that! 
Not for anyone else it seems. Try again.
I'm not surprised.
Like this: https://raw.githubusercontent.com/Mattias-/dotfilez/master/.vimrc The only plugin I use is: http://www.vim.org/scripts/script.php?script_id=790 
The code isn't that clean (particularly `Inductor.analyze()`) and there are a couple ugly hacks, but I figured someone might find it useful!
The only plugin I use is Syntastic + a globally installed copy of Flake8.
I ended up using requests. [Here](https://www.dropbox.com/sh/7htrm98ppr4n2rl/AABxFUh6p0l6cDhloSmPOnh4a#lh:null-Final%20Graph.PNG) is the final result.
These are non blocking queues for IO, but are still blocking for the CPU because of the GIL. Your probably want to give the chance to configure a different worker type such as multiprocessing. E.G : https://github.com/sametmax/Bat-belt/blob/master/batbelt/parallel.py
Load pymode.
As a long time vim user I have embraced pycharm as an evangelist. But this reference might be helpful: http://blog.sontek.net/blog/detail/turning-vim-into-a-modern-python-ide
Does concurrent futures not do this already? just without the decorator 
Vim is not an IDE, don't try and make it one.
Syntastic is one of the few "big" plugins that I would recommend everyone be using. 
pypy is amazing for speeding up python. Much better than Psyco. Unfortunately, it does not work on every library. If you are using standard libraries or even numpy it should be fine. If you are using numpy, you just import numpypy and most functions will work.
Are you thinking about Macintosh or Windows?
Plugins: - syntastic w/ flake8 for catching syntax errors early - ultisnips for snippets - camelcasemotion because `w` should jump to the next camel cased word - gitsessions for save / load with feature branches - easy-motion for navigation - ctrlp for opening files - fugitive for easy git blame to find patch comments for a line / function - rainbow_parenthesis because nested dictionaries / functions - vim-signature for easy marks - vim-gitgutter for gutter diff - vim-indent-guides to see tabs and spaces - nerd commenter for easy block commenting / comment inversion for debugging I also use ctags for jumping to function / method / class definitions.
If you are using numpy and scipy then pypy won't help much, and you might encounter stuff that just won't work. On the other hand, if you have a lot of pure Python code with loops in Python, then PyPy would be a great option. It's really easy to get started with so to really find out whether it's worth it just try it and see!
https://github.com/octopuscabbage/octopuscabbagevimconf I use a lot of other things besides python as well.
My vimrc probably needs a thorough scrub. Anywho, let's get down to the plug-ins: * [Pathogen](https://github.com/tpope/vim-pathogen) - Extracting a package to `~/.vim/bundle` will add it to `'runtimepath'`. Mega nifty. * [Syntastic](https://github.com/scrooloose/syntastic) - Really good error highlighting. I like to use [flake8](https://flake8.readthedocs.org/en/2.1.0/). * [Airline](https://github.com/bling/vim-airline) - Very nice status line. It looks kinda like the [oh-my-zsh](https://github.com/robbyrussell/oh-my-zsh/wiki/themes) theme, [Agnoster](https://gist.github.com/agnoster/3712874). You will need a patched font for this. If you're on Ubuntu, there's a great write up [here](http://askubuntu.com/questions/283908/how-can-i-install-and-use-powerline-plugin) under **Font Installation**. * [Bufferline](https://github.com/bling/vim-bufferline) - Because keeping track of 13 buffers with `:ls` can get tiresome. * [Tagbar](https://github.com/majutsushi/tagbar) - Lets you know which class and function you're in. Make sure to double check [Exuberant ctags](http://ctags.sourceforge.net/) is installed. * [Solarized](https://github.com/altercation/vim-colors-solarized) - For the pretty colors. 
Are you targetting end users or other IT people ? For the later, it's very easy : http://guide.python-distribute.org/creation.html It will then be installable using pip or python setup.py install. However, if you want to create a dmg or and exe, things are much more complicated.
I've used anaconda before, its best use seems to be in the Windows development envrionment. PIP still seems to be more useful to linux dev.
Set 'key' in options and you will get an attribute error in __init__
https://github.com/Ivoz/vimfiles I try to comment and explain almost every line
There are some other tools for optimizing scientific Python code, but most of them are not friends with Numpy/Scipy. If you have a GPU and code that is well suited to run on it, you could check [Theano](http://deeplearning.net/software/theano/), [Parakeet](http://www.parakeetpython.com), and [Numba](http://numba.pydata.org). Unfortunately, in some cases you'll have to end up using lower level tools, such as Cython.
Does flake8 complain about unknown modules if it's installed globally and everything else is in virtualenv?
No. flake8 is a static checker.
I can't recommend YouCompleteMe enough, wrote about it here: http://www.artandlogic.com/blog/2013/06/vim-for-python-development/