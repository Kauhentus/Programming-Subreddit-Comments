How is this better than just prepending the timestamp to a UUID?
I would think of a vector of particles, or vectors of the particles' properties, so that you could update several particles at the same time. But if it's a real modelling limitation, you could perhaps launch more than one case simultaneously, just watch out for the amount of memory that would require. I know that it can be frustrating sometimes. Feel free to PM me, I wouldn't mind helping out.
No, it doesn't, but you've just described yet another attempt at breeding a unicorn that has produced something with a fatal birth defect. If a language doesn't have a *large* community -- as in the 10s of 1000s of active and employed users, 1000s of engaged and productive library developers and maintainers, 100s of people contributing on the language implementation itself, and at least 10s of active, engaged, and *open* maintainers on the core language -- then it's *very likely* it will never acquire any of those things, which means it's a stillbirth even if it doesn't know it yet. Which is why I find it amazing how often I'll get into a debate where someone says something along the line of "**X** [heavily-used, well-funded, actively and widely used, and has a user base growing on an upward sloping curve] language sucks because it doesn't have **N** feature(s) [which are cool but you may only *need* very occasionally in practice], you should try **Y** [that has a tiny community which is growing linearly at an angle of between 0 and 1 degrees]. On that note, eliding D from the list of things to learn about.
it should be `if choice.lower() not in {"yes", "no", "y", "n"}` * use lowercase * `in` for set is o(1)
Is joke about programmers' desire to automate little things out of laziness and the futility thereof. That which starts out as "like two loc" becomes a five hundred lines of edge cases very quickly.
`for i in range(0, numDice):` This can be written more simply as: `for i in range(numDice):` 
Assuming you mean using the Spotify api and and tkinter simultaneously, I'd say yes, parse the data retrieved and out put it into a tkinter window. But I don't know if that's what you mean :/
You could use a Arduino, providing it's always wired to your device, python has a library to interface with Arduino serial stream, I've used it once or twice with a potentiometer to change the volume of my pc from the out a knob
Maybe next project - visualizing where code is dense?
Just one more ad.
I think Łukasz's point about people not testing betas etc is a really good one. I had started testing 3.6 rc 1 when it came out, now I test 3.7-dev. In general, even the beta releases are quite stable.
/u/Mperonen make sure you are not asking a xy problem http://xyproblem.info
Read the official web API information, you can practically do anything with it and they even seem to have a part on making your own streaming apps
I know, but first I need to get the bytecode. For bytecode decompiling, I was thinking Pyretic or Decompyle ++
I wonder if there's something wrong with the pip install version of nmap. Here's what happened when I tried to install nmap using pip on Windows 10: Microsoft Windows [Version 10.0.14393] (c) 2016 Microsoft Corporation. All rights reserved. C:\Users\Michael&gt;pip install nmap Collecting nmap Downloading nmap-0.0.1-py3-none-any.whl Installing collected packages: nmap Successfully installed nmap-0.0.1 C:\Users\Michael&gt;python Python 3.5.1 |Anaconda 2.4.1 (64-bit)| (default, Dec 7 2015, 15:00:12) [MSC v.1900 64 bit (AMD64)] on win32 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; import nmap &gt;&gt;&gt; print(nmap.__version__) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; AttributeError: module 'nmap' has no attribute '__version__' &gt;&gt;&gt; dir(nmap) ['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'nmap'] 
My intention is to have two programs. One actively writes data and one monitors/processes the data during runtime. I already have the programs. I just need a solution to actively monitor the data with another program that the other program is feeding.
I was able to use Curses tho. I downloaded from http://www.lfd.uci.edu/~gohlke/pythonlibs/ Should I avoid this and use Curses alternative for Windows instead? Edit: Trying to learn Asciimatics as of now
I think the proof is that if it is *tail* recursive, it can be done iteratively. 
I'm afraid you're going to have to be more specific - asking informed and direct questions is the key to learning and "I'm lost" doesn't help much. How far do you get? What code did you write? Could you start a python REPL (interactive console)? Could you run the python script you wrote, either by double clicking, or by using powershell?
Currently I am busy with MUD using cmd.
I think there is this technique called "Multiplexing" where you loop through every LED fast one after another. With that you dont need 198 seperate Pins. [Here](https://www.youtube.com/user/greatscottlab/videos) you can find some videos that can be helpful.
Seems a little too much for what I want to accomplish 
Yes, this. To expand, things like `py2exe` aren't really compiling anything, they're better understood as bundlers. You can create a .zip file containing Python files (either source or bytecode) and concatenate that with a Python interpreter executable and the result is executable. That is, the Python interpreter has built-in logic to look to see if it's got a zip file stuck on the end of it, and if so, import that as a package and execute its `__main__`. This can also be done by running `python some_file.zip`. You don't even need to rename anything, you can just do $ unzip foo.exe ...assuming you have the command line unzip utility. Or you could use 7z, or whatever. This works because the zip file format has its header at the end of the file, and the executable has its header at the beginning of the file. Things expecting to see an executable will look at the beginning, and things expecting a zip file will look at the end. The zip file format was specifically designed in this way to facilitate self-extracting zip files, which work in the exact same manner as these Python bundlers. You concatenate an executable — in this case a stub zip extractor — and a zip file, and the result looks like an executable to the operating system.
Read the sidebar: &gt; If you are about to ask a question, please consider r/learnpython or the learn python discord. 
name=("Harry") creates a tuple with 1 element, it works because python is smart enough to expand the tuple and get the string. If you try name=("USA", "Earth") it will fail.
Okay, I don't know the first thing about Ant+, but I did some digging (googling) and found this: [This is Ant: Search results](https://www.thisisant.com/forum/search_results/60b948450bdb1f06d810af7fbbd29984/) Also, the thread started talking about Java/python/nodeJs/etc mentions that the guy is making a mistake and opening his device as the transmitter not the receiver. So, while it's not your answer you may be able to learn from his mistake.
Inotify: Efficient, Real-Time Linux File System Event Monitoring 
I'm not going to pretend I looked at this a lot, but why not just loop over the cells and use replace on each value?
Is the work done saved inside the docker image or has something to be done in order to save the new notebooks? 
What?
Somebody answered like this: There is no difference between those two, both are considered as Strings. However parentheses are used to create "Tuples" so it's good not to use them like that, it would be easy to read the program, because generally, people are used to see parentheses as an indication of tuple, so the chances of misunderstanding are pretty high with that. But to create a tuple, you just add ' , ' to the "( ) "
Want to do look more like. It's that simple, dude.
From now on I'm using the word sintax to describe horribly written code hahaha
It is compiled into [bytecode](https://docs.python.org/3/glossary.html#term-bytecode). That's a CPython implementation detail, but it's also used when building distributable packages with stuff like py2exe to speed up loading times.
Virtual Env is your friend!
That was really embarrassing.
Bactrian and dromedary, perhaps?
which is?
I guess that was bullshit, sorry. I had assumed that Python is much closer to JIT than it is.
Bad syntax...so bad one might call it sinful...sintax!
If you do decide to put it on GitHub they will give you instructions for how to add the online repo as a remote and push from the command line. You may also be interested in their GUI, which I have no experience with, or Atlassian's SourceTree GUI, which is excellent.
Si eu as putea gasi ceva la tine pe care sa-l denumesc "awful"! Dar momentan ai dreptate! Oricum, iti multumesc pentru ajutor!
This would not work with numpy. Numpy ufuncs are all really small (add, sum, dot, cross, etc). The time to move the whole array onto to gpu and back would dwarf the execution time. You need to be able to compile a kernel (custom ufunc) that is going to do more than one simple thing to make the overhead worth it. Numba already does that.
There is [pdcurses](https://pdcurses.sourceforge.io/), which, while not preinstalled on GNU/Linux systems, is cross platform between all major OSes. As for the Python bindings, you have some options. You may wish to look at [python-pdcurses](https://github.com/jmcb/python-pdcurses) or [python-unicurses](https://pypi.python.org/pypi/UniCurses). I haven't used either of them, but from what I understand they are very similar to the standard `curses` library. 
I am pretty new to Python in general. I'm not sure if I used the most Pythonic way, though! Is there anything you'd do differently? Such a fun language to learn. I know a lot of PowerShell, and a bit of C#. Python is something I'm learning to get outside my comfort zone, and the Raspberry Pi 3 model B runs things like a dream.
This is more a question for /r/raspberrypi or /r/arduino and the answers will depend on what kind of LEDs are on the board.
As stated elsewhere, /r/learnpython is a good place to ask about this kind of stuff. As for using Powershell you **can** use it. Assuming you installed Python recently, run something like `py path\to\script` and your program will be run, and show you errors if it runs into any. I would highly suggest installing the [open-terminal-here](https://atom.io/packages/open-terminal-here) package to simplify the process. 
Commas make tuples, parenthesis just group things. The only time parenthesis make a tuple is the special `()` symbol which is an empty tuple literal. 
Ok this sounds like a lead but the link isn't working. I guess it all depends on whether the dongle can be set to master mode. I've emailed the developer of the python module to get his input 
That's a lot cooler than it sounds! It wasn't really clear to me that you project the words onto the image, in a nice "artistic" way!
Introduced, yes, but the whole idea of "yield from" and coroutines in general, plus generator comprehensions came later.
Hello, This can be done with the instagram api or may be through general scraping. I would be happy to do it. 
Python's clear namespaces are the one thing no other language seems to get, and it will always disappoint me. C, Haskell, Julia, etc. Why promote a style that requires spending 45 minutes configuring your editor before you can read it?
Re: Haskell. Check out this series https://youtube.com/watch?v=I8LbkfSSR58
Qt5 has that ability http://doc.qt.io/qt-5/topics-web-content.html Also, QTextEdit allows you to display HTML snippets. http://doc.qt.io/qt-5/qtextedit.html
Just downloaded a python file
Try make a very simple gui alarm clock, it will only require a single window so no fancy class editing. Heck skip the gui if you want it's not always the best Edit: I'm going to plug my fiverr cause I offer tutoring on many aspects of python including what I mentioned above. Fiverr -&gt; ashmoreinc
Automate the production and posting of cool graphs to twitter. 
I think its a little odd that your `format_data` function automatically formats the information of the first element in data. Maybe you only ever want the first result for your use case but I'd change it to something like: ``` format(convert_c_to_f(data['air_temp']), convert_c_to_f(data['water_temp']), etc... ``` and then just pull out the first object of the response when you call it data = get_data() print(format_data(data[0])) and now you can transform all the data by looping through it. Also I feel I should mention you can pass a dictionary directly into the format method and reference the values by name rather than position. I think you're fine in this case but it can make your code a lot prettier. &gt;&gt;&gt; data = {'name': 'starcast', 'language': 'python'} &gt;&gt;&gt; "Hi my name is {name} and i like coding in {language}".format(**data) 'Hi my name is starcast and i like coding in python' 
Thanks. It uses also the latest release of scipy for an algorithm that enumerates vertices of Polytopes (http://nashpy.readthedocs.io/en/stable/how-to/solve-with-vertex-enumeration.html). Basically the idea of the library is to implement what can be implemented "for free" with the scientific Python stack :)
Out of curiosity, do you think you could embed a soundcloud song into tkinter? 
Possibly all the additional video content?
Can't you just reduce it to linear programming? Enumerating vertices of a polytope is pretty much all that the simplex algorithm does
any from https://github.com/karan/Projects/
Not for non zero sum games. One of the better algorithms for general games is called the Lemke Howson algorithm which is a smarter search path through the two polytopes. I'm going to implement that too at some point. The state of the art in GT equilibrium computation is http://www.gambit-project.org/ (Nashpy is not meant as a replacement, just a lighter version with easier dependencies, gambit doesn't install nicely on windows for example).
Is keeping the trading algorithm confidential important?
Do you mean that you want to do automated trading, or just that you want software that will generate signals / notifications for trades?
Hey all, going through the process of teaching myself python. for this week(and the next few) I plan on creating a script to scan websites for items I plan on purchasing, in order to review prices/compare historic prices
Gosh, imagine writing a math theory back before computers were really mainstream and dreaming that someone would write a library of a software language and name it after you. This blows my mind. 
I often use Jupyter Notebook (over the Python console) simply because it is far easier to play with code, and when it doesn't work (and that is often) I can go back and edit it easily - and re-execute. And once my code snippet does what I expects - I can then copy/paste into my production code.
The data example given by the OP did not contain escaped strings. So given the example given by the OP - my solution worked. If it was my code - i would shoot the interface designer who thought that a tuple converted to a Unicode string was a good interface choice.
Ipython doesn't have anything to do with jupyter except that jupyter used to be "Ipython Notebook" Also, Ipython isn't a text editor like IDLE is.
Anytime you parse and type data, you never want to do that again. So, definitely store it in something other than CSV. I'd look into how partitioning works with Spark/Parquet and follow that pattern if at all possible. Then you have your data stored in small manageable compressed partitions, and you can read the entire dataset with Dask, Spark, Drill, Athena/Presto for querying in a consistent way.
From the page you sited &gt;As of IPython 4.0, the language-agnostic parts of the project: the notebook format, message protocol, qtconsole, notebook web application, etc. have moved to new projects under the name Jupyter. I've never installed jupyter but I use Ipython all the time. What you said is like "I only get scipy to use numpy". 
&gt; Ipython doesn't have anything to do with jupyter except that jupyter used to be "Ipython Notebook" That is not strictly true, they are still closely affiliated projects and the IPython kernel is still the reference kernel implementation for Jupyter. So although they are not the same thing anymore, they still have a lot to do with each other.
I was responding to the "I get jupyter for the Ipython repl". They are affiliated groups and I believe Jupyter uses Ipython for it's python evaluation (though it also has Julia, Haskell, R and maybe another). But if someone asks about a tool, responding about how you like one of its dependencies is confusing.
I just read A Beautiful Mind, I can't wait to check this out!
I think it's actually that professionals in companies use spaces, and tab users are independent or at small startups where one tab advocate gets to define the style. If you worked for a company with a team that paid well, they'd make you use spaces.
Why?
[removed]
I very clearly stated that I couldn't comment on the other features of Jupyter, and yet I'm still having to argue people who I guess love to argue. I figured OP would like to know about ipython, so fucking sorry to have bothered you. 
You sure? I've decompiled pyc files before. I heard it worked on a simple test script, didn't believe it, so I threw something super complicated at it. It was near perfect. Your python code is not as secure as you think...
Off topic: Hey /u/dbader, I like your blog and I thought I liked your idea of "PyTricks" every couple of days, so I subscribed to your mailing list. But what I end up receiving is mostly a daily sales pitch for your book, which doesn't interest me (I read the sample chapters and learned absolutely nothing new at all - not so say there isn't good info there, it's just that it's not for me). So, is there any way to unsubscribe from the book list and *just* get your PyTricks emails?
This is a longshot but is anyone in the Bay Area interested in road tripping up there? I'm interested but not looking to drop a lot of money on a plane/bus ticket up there.
I actually heard a lot of good feedback about win 10. Specifically about surface book. As long as it has Unix layer it's theoretically a perfect dev environment.
Hand crafted just for you r/beginnerprojects/
&gt; The data example given by the OP did not contain escaped strings. The example given by the OP doesn't contain a lot of things. The mods have removed his post, but if I remember correctly his sample data was something like: `u"('fred', 'smith', 'fred@example.com', 'password')"`. You'll notice that: - It doesn't contain capital letters. Would that mean it's okay to give a solution that breaks when given capital letters? - It doesn't contain digits. Would that mean it's okay to give a solution that breaks when given digits? - It doesn't contain the letter "y". Would that mean it's okay to give a solution that breaks for the name "tony"? The OP tells us what the data represents: - names - email addresses - passwords (oh gods why is he recording plain text passwords???) Therefore, any solution should be able to cope with: - **any** [human-representable name](http://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/) -- or at least any legal name in the country his application will be used in; - **any** legal [email address](https://www.cs.tut.fi/~jkorpela/rfc/822addr.html); - any reasonable password. I didn't come up with weird or exotic data that broke your solution. As an English speaker, you should be aware of English names that use: - hyphens, Mary-Jane - spaces, Billy Bob - umlauts, Zoë - apostrophes, O'Brian never mind "exotic" (to native English speakers) issues regarding names in other languages. &gt; i would shoot the interface designer who thought that a tuple converted to a Unicode string was a good interface choice. Ha ha, of course that's a really shitty choice, positively *awful*. Unfortunately in the real world sometimes you're stuck with interfacing with positively awful data sets and other programs, and while it would be nice to shoot the person responsible, sometimes you can't. And besides, for some reason the Powers That Be disapprove of us shooting idiots, and they make you fill out forms and paperwork if you do.
There are also philosophical and security concerns. But yes, running a Linux VM does provide certain benefits. Now that Windows translates Linux syscalls you don't even need a VM.
It's a great movie but FYI it does a poor job of explaining Nash's actual innovation. (The actual Nash equilibrium in that bar scene would be to convince your three friends to go for brunettes and then take the blonde for yourself, assuming your friends won't backstab.) https://mindyourdecisions.com/blog/2008/03/10/game-theory-tuesdays-the-problem-from-a-beautiful-mind-buying-new-or-used/
I use it almost exclusively as my starting point for any new project. It comes down to a couple of points: - progressive code execution: I can break my code up into smaller chunks and run (or re-run) them in isolation, inspecting the output/result as I go. - documentation: because Jupyter provides excellent formatting of output (tables and charts) and because the output remains inline as part of the notebook, it serves as reminders later and explanations for people I might want to share the notebook with. Once I'm happy with the result, I save the code out for use in production..
I thought the main reason you shouldn't do this is that it introduces static variables into your functions.
This is a better approach especially when you have many kwargs and manually typing all of them in the super class is just not readability.
This is even better as then Cat can add an argument without requiring any changes in the inherited Tabby
&gt; requests.get('http://some-page.com/').json() this is all I gotta do? Seems so easy. Love Python
Yes, that will return you the data already parsed. Also, post questions in /r/learnpython next time please.
Didn't know PyGal, seem interesting and easy way to build python-based charts!
Oh sorry. I was on /r/python and /r/learnpython and thought i posted on /r/learnpython.. Didn't doublecheck I guess
I like it! I think it's true that in most cases, too many entities per line is a problem. But if one wanted to set a limit, you'd find code using e.g. the Django ORM with several chained operations being counted as problematic, even though it tends to be very readable - the chained operations are more like lines. 
A problem with this approach is its lack of flexibility. E.g. you do not want to inherit ALL arguments, or you want to change order of arguments.
As the title suggests, the link is to my Whitespace interpreter project that has been written for my final OU project. As part of the project I would like to add some discussion about coding in the open, specifically how to deal with things like pull requests and giving credit to contributors. I would really appreciate any code reviews/suggestions/PRs... Please feel free to open issues. Thanks
[removed]
I did TM470 too. And also wrote my project (a flood warner) in Python. I'm going to have a look at your project later
Cool thanks, If you like I am more than happy to do the same for your code. PM me if you don't want to make it public.
But in this case you are forced to create new instance of Cat/Tabby per new food type
Not all arguments of all methods meant to be object fields (obviously). The (toy) example is too abstract to be judged for the incorrect logic IMO.
&gt; I thought the main reason you shouldn't do this is that it introduces static variables into your functions. Er, that's a bad thing? Please explain. 
&gt; you do not want to inherit ALL arguments That's a violation of the [Liskov Substitution Principle](https://en.wikipedia.org/wiki/Liskov_substitution_principle). You better have a good reason for doing so.
I'm sympathetic to the problem being described, but the solution sucks. Instead of a default value in the method, you now have to have a *global variable*. Imagine you have three classes with a dozen methods each that take two default values each -- now you have 72 globals. And anyone can write to those globals, breaking your classes. Better is to move the globals into the class as class attributes, but even that is not very nice. They're still writable, and what do you do if you have two methods with the same argument but different default values? I think there's no great solution to this problem in Python, but it is definitely a real problem with inheritance. Perhaps the solution is to try [composition instead of inheritance](https://en.wikipedia.org/wiki/Composition_over_inheritance)?
&gt; but the **solution** sucks. Instead of a default value in the method, you now have to have a global variable. Author: &gt; We can make this a bit better by using a constant to store our default value instead Author did not meant "having global variables" as the solution to the problem (that would be "always use None as a default argument"), but as "a bit better &lt;approach&gt;" then direct-default-values in terms of extensibility.
People do it, but they don't need to, and should generally avoid it. The normal way to get information back out of a function is by returning a value; anything else should a) be documented and b) always work that way (and not work other ways; i.e. it should return `None` like the builtins do in cases like this). In which case you wouldn't be using a default argument, since you always need to have a specific thing to modify! They only get modified outside function scope if you return them, which is also a major code smell.
I'm sorry, I don't understand what point you think you are making. Where is the mutable shared state here? def func(a, b=1): pass Default values are not mutable shared state unless they are mutable values, e.g. a list. (And while that is often a problem, it is occasionally useful.) Edit: perhaps I don't understand what is the "this" that you say we "shouldn't do this". Do what? Use default values *at all?* Replace them by `None` like the article suggests? 
You're going to have to be a lot more specific. What do you want to get from the website?
They are similar, but not identical. Being based on PDcurses, they have subtle differences, which you will find documented here: https://pdcurses.sourceforge.io/doc/PDCurses.txt The main omission is the lack of the terminfo/termcap database, so all functions that use that just return ERR.
In my opinion the problem you describe does not exist. You can always have default implementations of `eat` or `__init__` per class, and I do not know of an example you cannot conveniently solve with it. The main reason for `None` which was not mentioned, is that if the objects are mutable, unexpected behavior to the end user can happen. When you are solving a real problem, I'm pretty convinced you can come up with a nice inheritable way, without losing information :)
I want to get the results, if you put 3845 and * for example you'll get some info so i want to scrape the website for all possible numbers and get the results
&gt; That's because the author has pushed some of the class state outside of the class! That's incidental to the solution, though. The actually interesting part was using `None` and checking for it.
That's even worse, what arguments do I need to give it? Now I need to go meandering through the MRO to find out. It's a good strategy for Mixins with initializers especially if you're in Python 3 and can use keyword only arguments, but that's about it.
I have some experience with Parquet, some experience with how _not_ to use it. I have two massive problems with it. 1. I use it for a system where I only need a small slice of data at a time. Such as, amongst the last 10 years, only give me 2 days of data. This is a horrible usecase for parquet, this is what an index is for, the sort of thing you get with a database. 2. I use the parquet to mirror a database which is constantly mutated. Again, horrible situation. You can't edit a record in parquet, it is append only. If I were using it correctly I would have mechanisms to allow for adding new modified records that will take precedence over the original documents. Given my context I wish I was not using parquet. But, I would definitely use it again for a different project. It was just a bad choice for my current project. Silly decisions on my part of course. Make sure you don't need to mutate the data and only use it if you are going to consume the majority of rows at a time. (It being columar it makes sense if you are only consuming a single column)
There are number of things you can only do on Windows. Anyway both programming language and os are just tools, some better suited for certain things and some for others. Don't get too emotional about them.
I used to use Jupyter for that too, but recently switched to Spyder. Same cell-based execution, but the scripts can also be run without starting a kernel.
Awesome. I have been using gambit at work and it doesnt work on windows which is a pain. I will test this out and show it around! 
Remember when SO was fun ? https://stackoverflow.com/questions/234075/what-is-your-best-programmer-joke/788760 It is interesting that the questions with most answers are questions like this.
r/learnpython
No your exaple is bad here. Your cat can only eat one food where's OP's design allows cat to eat any food but when it's not specified it defaults to `catfood`. 
Awesome. Any comments/suggestions super welcome, the repo is here: https://github.com/drvinceknight/nashpy
Fwiwi: I wrote this vis a vis gambit this morning: http://nashpy.readthedocs.io/en/stable/discussion/gambit.html
Why not pandas? I feel like numpy requires much more mental overhead for tracking the meanings of rows / columns. Why NOT include them in the matrix definition? 
Good idea!
I'm using numpy for the underlying linear algebra. 
It's not hard to believe, the Python Software Foundation holds the copyright and/or trademark on the Python name as I said. Correct, anybody can fork Python as it's an open source project, but they can't use the Python name. My source is the PSF, they even have a mailing list that is dedicated to legal matters. A few months back a backport of stuff from Python 3 to a fork of Python 2 was put on github as Python 2.8. The author was very politely asked to change the name, and very politely did so. It was so pleasing to see it done so graciously by all parties.
Thanks for your offer! But I am not to keen on making it public. Partly because it became some playground for experiments for me, so sometimes it's in a sorry state (although it works). I liekd the detailed explanation on your project's github page. I think it's much better than most I have ssen there. I think it's alo good that you provided (or plan to provide) some example Whitespace files in your project. Maybe one for showing off your debugger would be nice. Giving credit to sources is important in an academic environment, but does not seem to be done and I think it's not important "in real life" when it comes to basic programming tasks or using patterns. Though it is important to provide references when copy-pasting (or just re-typing) someone else's code. Also very important to state any dependencies on 3rd party modules, but mostly for practical reasons. So to the review: I am far from being an expert on interpreters and definitely not on Whitespace, but I learned a bit from what you wrote on the github page. I am a fan of in-code documentation. Python offers pydoc to generate documentation (https://docs.python.org/3.4/library/pydoc.html, not a necessity to use it but could come handy) I like the way you handle parenthesis (see lines 19 to 52 in parser.py). Maybe you want to print out more details on the IndexError in ws_token.py (line 42). You were strict with the max characters per line convention of PEP 8. 
Nothing. It's [spam](https://www.reddit.com/user/sandeepscet_redit).
It works.
What trading platform / API will the trades be made through?
The url and gzip stuff is neat but running arbitrary commands because the filename starts with a pipe character seems very dangerous. Maybe make that a separate function?
Cheers I'll pop it over there
Tree ensembles are faster to train than ANN. Your parameter space is just very large on parameters that I wouldn't play with in a first attempt. If you want to run a fast scheme just try varying these (not anymore ranges, but choices): space = { 'max_depth': [2, 3, 5], 'learning_rate': [10**-4, 10**-3, 10**-2, 10**-1], 'n_estimators': [100], 'min_child_weight': [1, 5, 20] } After you find the best one there, just retrain once with 1000 `n_estimators`. I'm going to assume this will be better than the ANN :) 
I suggest that you read up on the history of iPython and Jupyter before you say anything else. It is a well known strategy to put the shovel down you make the hole any deeper.
Thanks, that's a good point. Thought I was clever with the bayesian optimisation, but that's probably the best approach.
What 'defs' are running unexpectedly?
I urge the mods to add this to the sidebar, It should be the first thing anyone reads.
Strange, the link works for me. Try [this link](http://www.blrice.net/blog/2015/08/10/leading-a-team-at-ruby-for-good/). This is the first year, depending on the interest we'll definitely look at expanding!
Cool that you followed up. What is the difference in timings? Also, note that it is impossible to determine significance with bootstrapping the same examples. I think a pattern might become visible when you do 100 random seeds (probably still low in power, but that'd be interesting). Are you also sure that you did not hand pick the dropout of 0.5 to work well for these 2 datasets :)? If you're looking for more datasets to try, have a look here: https://github.com/kootenpv/xtoy/blob/master/tests/all_test.py :)
It is not Python magic, but Qt magic. The paintEvent() method (overriden from the base class) is called everytime the GUI is painted, and paintEvent calls drawText().
**Torrench - A simple command-line torrent search tool** &gt; Torrench is a simple command-line tool that fetches torrents and displays results within terminal window. It does this by scrapping thepiratebay (proxy) sites. Once torrent results are fetched, torrench can further fetch torrent details as well. Details include torrent Description, comments, as well as download (magnetic) link. (Basically everything required to choose a torrent). Torrench began as a python learning project for me. The project is in python3. Please visit the project link for detailed info along with installation instructions. Hope you like this tool and find it useful. Suggestions/feedbacks are much appreciated. **https://github.com/kryptxy/torrench**
Take it for free :) You just need requests and beautifulsoup4 installed. https://gist.github.com/OrDuan/a37fddc4e82ea8f5050cce53493b6f92
Try Freelancer.com. it's a lot better than Upwork.
 &gt;Nuitka is a Python compiler. &gt;It's fully compatible with Python 2.6, 2.7, 3.2, 3.3, 3.4, and 3.5. &gt;You feed it your Python app, it does a lot of clever things, and spits out an executable or extension module. &gt;This release marks huge progress. The node tree is now absolutely clean, the variable closure taking is fully represented, and code generation is prepared to add another type, e.g. for bool for which work has already started. &gt;On a practical level, the scalability of the release will have increased very much, as this uses so much less memory, generates simpler C code, while at the same time getting faster for the exception cases. &gt;Coming releases will expand on the work of this release. &gt;Frame objects should be allowed to be nested inside a function for better re-formulations of classes and contractions of all kinds, as well as real inline of functions, even if they could raise. &gt;The memory savings could be even larger, if we stopped doing multiple inheritance for more node types. The __slots__ were and the child API change could potentially make things not only more compact, but faster to use too. &gt;And also once special C code generation for bool is done, it will set the stage for more types to follow (int, float, etc). Only this will finally start to give the C type speed we are looking for. &gt;Until then, this release marks a huge cleanup and progress to what we already had, as well as preparing the big jump in speed. 
I've never successfully compiled a Nuitka application longer than ~100 lines, or with multiple modules. There needs to be more documentation and examples that are known to finish, that aren't just contrived `def add_one(a): return a + 1`. I've tried every release for over a year and have had zero success. Help me use your project because I really want it to work.
I am working on creating a geological filled map of Wisconsin with sales and zipcode data. Suggestion for packages are welcome!
Thank you so much
I'm afraid I don't know anything about Atom packages. If you're new to git I would really recommend learning to use it on the command line. That error message means that you don't have the git binary on your path. You should download a Windows installer from the [Git website](https://git-scm.com/), and it should give you the option of adding it to your path (or running it through the included "Git Bash").
Two or more spaces at the end of a line for a linebreak. Four spaces at the start of each line for a block of code. If you're nesting a code block in a list or something, you need four spaces for each level of nesting, and then four more for code. Alternatively, you can use backtick (`` `like so` ``) for inline code.
Ahh I thought it was already part of the installation. Thanks. Will read about it more
I really never understood why Nuitka does not use Cython as a dependency. The author claimed that his pull requests to Cython were not merged, but he could just make it a dependency. Especially since he is moving away from C++ to C anyway.
It's 2.7. You can learn 3.6 for free on edx, much better than code academy. 
&gt; python my_code.py Could you elaborate on this? I'm really confused :( Also x posted this on that sub
That's the command you run, switching `my_code.py` with the name of the file that contains your code. https://duckduckgo.com/?q=how+to+use+windows+command+line
https://www.reddit.com/wiki/commenting
Are there any main advantages to using this over the more widely known and supported JIT compiled PyPy?
something like this? https://github.com/Mysterie/uncompyle2
efmccurdy probably has the best example for your exact scenario, however if the JSON wasn't available your easiest approach would probably be to use pandas.read_html() https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_html.html You could then save the relevant dataframe to csv (or various formats) that could be read by excel.
I had success building application of several thousand lines and bunch of modules. That was with rather old version of nuitka and used PySide as dependency. PySide required patches thought. Not sure what you do to make it fail. Mailing list is there for help though. It is not exactly a lively place because world for some hard to understand reason ignores nuitka, but if you shoot email you will definitely get an answer.
From its stated mission it looks promising. But I have never heard of it before in talks about Python performance. Maybe it is not polished enough?
I had an idea, make `open()` return a customised object like this: with open('1.log') | "wc -l" as f ... Just for fun. 
I tried to use this for a pysftp dependant project, it did not work. I have compiled projects with a bit simpler dependencies though.
This is really cool man 
:) this is a fantastic idea 
Yes! The conclusion drawn seems more opinion than based on fact, and the scenario in which the author thinks caused the issue means the title should read "\*.\* can be corrupted on any platform". As an aside I'm curious why the author had a file with just `pass`. They could leave it empty ...
Double clicking on the file to run it will close it when it's done. E.g when an error occurs. Instead you should open up a command prompt. for windows this can be achieved with *win + r* and typing `cmd`. When you click enter this should make a command prompt. Simply browse to your project with the `cd` command and run `python myfile.py`
Personally I love it. It helps me document the code in a standard manner. And it's optional: if I'm writting a small script, I ommit the type hints, but they help a lot in big projects.
It doesn't look like it's elsewhere. Hopefully, they get you activated today.
I kinda like this. I'll give it some thought. Thanks!
I was thinking about this yesterday, support for structural typing would be great. I haven't tried it, and I don't think it'll work since it does AST analysis, but registering a class to an ABC might work. Apparently there is also support for plugins, so a structural typing plugin might be possible as well. You'd need to define a custom type ala Generic, but it's doable. 
I'm just getting into it, but it seems like a good tool. It's prevented a couple of dumb errors on my part already. There's a few qualms I have, like enum having extremely severe type erasure, but nothing that'll stop me from using it. 
Há, I actually want to do the opposite: distribute executables without people reverse engineering the bytecode
I figured as much! At least in Cython, you generate a C module which is then compiled. While the Python-&gt;C transpilation could probably be reversed with sufficient info (it has to be deterministic, right?) you can at least buy yourself some cover by just distributing the compiled C module. If you're particularly careful when you write your Cython, you can avoid nearly all of the PyObject wrapping and boiler plate that comes from the Python-&gt;C bridge, which would help obfuscate disassembly. 
Yes?
Yeah unfortunately that's not a supported feature at the moment: &gt; Run-time addition/mutation of base classes (e.g. registering ABCs) https://github.com/python/mypy/wiki/Unsupported-Python-Features 
Thanks guys for your help. Now, I am trying to scrape stock data using 3.5.2 (32 Bit) Python.I tried to install 'pandas.io.data' using pip 'install pandas.io.data' command. But, it didn't work. Any suggestions..
Thank you. Newbie here.
So now it boils down to cython dealing with obscure libraries and whatnots :-) Thanks a lot for your answer, and rest assured of my gratitude (an upvote being a meager token thereof)
Any specifics to avoid?
You can't statically type a dynamic language. **In no way should Python become restricted to static typing only!** 
First, define 'sustainable'. Although your terminology has a common definition, within the confines of several industries, the meaning is different for those industries-- sustainable food agriculture is different than sustainable forestry. Both use pesticides, but the timelines, goals, and target markets are quite different. Then, define the problem you want to address: what is your sustainable application? Is sustainability the goal, or are you trying to show the advantages of specific aspects of sustainability? Or is an industry over-regulated and are the commonly-held benefits of sustainability not materializing? Finally, how are you going to prove correctness? What data will you gather, how will you analyze it? What assumptions will you make? Your premise is wooly. The programming language is less important that the problem defintion, use cases, requirements, etc. Sharpen your problem definition and you'll reduce the technical complexity, you'll lose the urge to guess, and you'll make fewer mistakes.
if i m not mistaken, u can pip install only whole package...so pip install pandas
It!uses ver 2.7. That said I completed the code academy class and had no issues switching over to python 3. That said if you have no requirement to learn python 2.7 I would recommend to go straight to python 3.6 and find a resource that teaches it. There are plenty. 
I'm really happy you've found PE because it's a great site with fantastic problems, but what you're doing is really against the nature of the site. There are many of us who use this site as a challenge, and providing solutions to the problems so that some people can just level up in the leaderboard seems wrong. I'm all for keeping your code so that you can reuse it in future problems, but if you decide to do so, it would be best to do it locally so that others can't access it.
I find this works very well for the projects I need to distribute across client platforms. I've been using it for roughly the last two years, the dev is very responsive to fixing issues, and it keeps up with modern Python very well, supporting Python 3.5 within a week or so of 3.5 being released.
You might want to take out the *ship_api_url* from the *get_data* function. It would be more flexible if the function takes the URL as an argument. Also you may make the functions invocations inside an *if __name__ == "__main__"* block. It would be much cleaner. Think about early returns in the short functions involving simple math.
Awesome ! 
I thought so. I did a few projects on Flask and hadn't had any issues aside from my own poor Python experience but still I decided to figure this out since you can never be as cool as random Reddit guy.
You can't really go wrong with either, as long as you understand the strengths and weaknesses of each. Django is a high-level framework, so it comes pre-installed with a number of [utilities](https://www.quora.com/Why-does-Django-tout-itself-as-a-batteries-included-web-framework-when-you-have-to-manually-write-regexes-to-do-URL-routing). Flask, on the other hand, is more of a low-level (or micro) framework. It provides only what is necessary. That said, there is a vast library of [Flask extensions](http://flask.pocoo.org/extensions/) that you can add on as needed. Both have excellent documentation and community support. I suggest trying both. Maybe spend a day doing both intro tutorials and see which one you prefer. If you are looking for something a bit more advanced, check out [Flaskr - Intro to Flask, Test Driven Development, and jQuery](https://github.com/mjhea0/flaskr-tdd) - a tutorial I wrote that extends on the basic Flask intro. That said, I almost always recommend Flask to beginners since you dive below the scenes a bit. Django does have a bit higher learning curve, but once you get going it can be easier. It does help, though, to understand what's happening under the hood, which is why I recommend starting with Flask. Hope that helps!
 bpo-12414: sys.getsizeof() on a code object now returns the sizes which includes the code struct and sizes of objects which it references. Patch by Dong-hee Na. this is pretty useful. 
Could you register over at myant too as it seems to take ages to get activated to download software, profiles etc. :(
Docker uses LXC and cgroups. Those are linux features. When you run docker on windows or osx, you are running a headless linux vm with docker installed on it. My "philosophical and security concerns" were about Linux and Windows in general. There's no "security benefit" to using docker on any platform.
What bad practices? Never heard of such a thing.
Structural typing is coming in 3.6.2
They do exist at runtime in a dunder attribute, so there can be effects if you want
With Python you'll get in the comfort zone as C# is uncomfortable as it gets. :D
As cool as this is, I would just notify my mother, and within fifteen minutes the entire family would know.
1. get twitter account 2. Use twitter
Do your grandparents use Twitter?
You can get MSYS2 at http://www.msys2.org if someone wants to give it a try.
What you are thinking of is Structural typing, which is being added via PEP 544. The PEP targets 3.7, but like PEP 484 I expect it to be supported for older releases as well.
Probably not seeing as they're all dead
Honestly Facebook makes way more sense IMO. More of my elderly family is on Facebook than have text messages, and I barely know anyone's phone numbers. 
Yeah, enums are sort of tricky. But my understanding is that people are actively working on improving support for enums in mypy, so hopefully things will be a bit better in the next release.
Well until now I didn't realize that there was too big of a difference, but when I used to program (years ago) I completed the foundations of it on code academy.
you find someone for this?
[See if this helps.](http://floating-point-gui.de/languages/python/)
So the Django web development would be a better choice if i need to work in a near future? 
I like the option of type hinting, but I dislike the particular MyPy syntax for it, preferring [Obiwan](https://github.com/williame/obiwan)'s.
Point taken :) I will remove the URL from the link and update accordingly.
Welcome to the wonderful world of [IEEE 754](https://en.wikipedia.org/wiki/IEEE_floating_point). If you need precision, you may need to use the [Decimal](https://docs.python.org/3.6/library/decimal.html) module.
I wish `float`s were implemented on top of `Fraction`s (and that CPUs and storage schemes were optimized for fractional data). It would feel more honest.
Truly an open minded individual as you don't dismiss it out of hand but it sounds pretty mutually exclusive to me.
I really like type hints -- they've significantly helped improve the reliability of the code I write. Here are some specific things I like: 1. I'm sort of lazy, and don't like writing unit tests for personal projects. Types are a pretty good substitute in many cases and let me focus on writing unit tests for actually interesting things. 2. I've always found writing code that deals with both bytes and unicode tricky. Mypy can help detect a lot of issues here. 3. The type system itself is pretty flexible -- it has all sorts of goodies like unions, type aliases, subtyping-without-subclassing, typed dictionaries, etc. that other languages (like Java) don't have. We're also going to be getting structural typing and plugins in the near future, which I'm pretty excited about! 4. I firmly subscribe to the "null was a billion dollar mistake" school of thought. I can almost completely eliminate this problem if I use mypy with strict optional mode enabled. 5. Having the type system be gradual can be surprisingly useful. For example, I often have my types for any functions that accept user input (such as JSON) files be relatively loose, use runtime validation, then switch to using precise types after validating. This is handy when user input is messy/doesn't really conform to a specific schema. 6. Mypy is also a relatively decent way of helping you migrate Python 2 code to Python 3 code -- run Mypy in both Python 2 mode and Python 3 mode and tweak your codebase until both runs are passing. Things I don't like: 1. Typeshed (the repository of type hints for the standard library and 3rd party libraries) has varying quality/is missing stubs for most 3rd party libraries. In particular, the entire scientific ecosystem is pretty much untyped, which is a pain. 2. Using types often requires you to add extra imports to your code (to pull in the types you're using), which can sometimes introduce import cycles that previously didn't exist. There are various of workarounds for this, but it's still a pain. 3. I also have tendency to architect-astronaut if I'm not careful, and I sometimes worry that types might encourage this. That is, Python's type system doesn't yet fully capture everything you can do with Python, so it's sometimes really tempting to start distorting perfectly fine code to work with types or vice versa instead of just using `Any` and moving on, or to try and do all sorts of metaprogramming hijinks (since annotations *are* technically available at runtime). Disclaimer: I worked on mypy as an intern for a summer (where I acquired a probably permanent trauma towards import cycles) and still contribute sporadically, so I may be biased.
bill * 1.15
No, not saying that. Right now *full stack web developer* is a **very** good career choice, but that takes a lot more than just intermediate Python, it takes Docker, possibly TypeScript, definitely at least EcmaScript and one or more of its reactive frameworks, and a fairly deep knowledge of a lot of technologies. Short term, I'd say try and learn enough **Flask** and say **TensorFlow** or **SciKit-Learn** to build a couple of portfolio apps that do something relatively simple, like identifying patterns in a text, or what have you, and then use those to get an interview with a company you're interested in working for.
Please be more specific. 
Hey, totally off topic but here's a new question I have. After I make a program, can I send it to others who haven't downloaded python and it still work? What if I convert the program to a .exe and then send it to others? I'm looking to build a really simple console game out of the python command line. Thanks for your previous help too!:)
Using a floating point number?
thanks
Sorry, will do.
They aren't gonna do that, and that is much more inconvenient than just reading it on Facebook. Plus this avoids them trying to respond to twilio and wondering why I'm not replying. 
The term you can search on is "freezing" your code. http://python-guide-pt-br.readthedocs.io/en/latest/shipping/freezing/ In addition to this, Nuitka and a few others exist. I've had most success with PyInstaller.
Hm my guess is that the Python compiler makes an empty file just a pass so it doesn't have to special case empty files. I guess I don't understand what is wrong with the created pyc file which caused the original poster to say it is corrupted.
I know it's been standardized, and I think that a proper consideration of alternative syntaxes was absent from the process. Can you give an example of concise 484 syntax?
Great work, mate. Will Django be an overkill for this project? 
I often use def over lambda, just because it is easier when someone else (or me later) is reading code and figuring out what it going on. Although short functions for sort and other things, lambda is cleaner if it is used once. If you write list comprehensions in multiple lines, it often helps with understanding what is going on. [value if A else alt_value for value in values_list if B] A - Condition to use 'value' B - Preconditions to include value in list at all
print("\nThe total amount to pay, plus a 15% tip is:", 15/100 * bill) bill = bill print("\nThe total amount to pay with a 20% tip is:", 20/100 * bill ) Gives me two different totals. Thanks all.
Lambda and comprehensions are amazing, and I recommend you look into them a bit more. If you know functional programming it's second nature. A lot of the collections library has a few features that aren't very well used, but they're useful in the intended cases. Python3 FYI
I don't think I use generators often - at least not directly. Generators and coroutines are stuff I wish I'd spend more time understanding - I don't even know if they're applicable in my day-to-day CRUDMaster9000 job.
This is priceless! 😂
I don't ~~use~~ write context managers as much as I would have expected. There are a few situations where they are a perfect fit, but I find those situations don't pop up very often.
I regret not using magic methods that much. They are wonderful places to put comparison and basic logic for custom objects. I do, on the other hand, use some features too much. like lambdas, Counters, map(), functools... they are wonderful, but sometimes they make my code "too clean". The thing is, at least in my experience, that a lot of Python features are not "non-Pythonista proof". Everybody use list/dict comprehensions, but I'm 100% sure that if I use a Counter to count, at least one of my non-pythonista colleague is gonna ask me "how are you counting those things?". Same for lambda and map(). (especially map.. everything that seems functional programming drives the Java-guys crazy.. hehehe)
The keyword you want to google is "python web scraping". Then you can save the scraped data using python's csv package. You also probably got downvoted because you should have posted in r/learnpython instead -- you'll have better luck over there. It will also help people help you if you have a better defined problem.
You're comparing 2.7.6 vs 2.7.6? (My mac says that system python is 2.7.10...) $ /usr/local/bin/python /tmp/test # brew python 2.7.13 Average Run: 63.5704948425 Min Run Time: 62.997123003 Max Run Time: 64.6661829948 (1, -61, 971): 71 $ /usr/bin/python /tmp/test # system python 2.7.10 Average Run: 28.4983819485 Min Run Time: 27.958758831 Max Run Time: 29.7931609154 (1, -61, 971): 71 I think you're up to something...
May I ask why?
(to first address your points) I use `lambda` all the time, mostly for tiny functions that need to do something specific. A contrived example is sorting a list of tuples, maybe by the second item some_list = [(1, 'c'), (2, 'd'), ...] some_list.sort(key=lambda tup: tup[1]) I also use list comprehensions waaay too much probably. I find them a lot more expressive for list generation. The nice thing about the csv module is that it streams things from disk instead of loading it all into memory like pandas does. It's also (in my experience) much much faster and better at parsing than pandas is. It's good for solutions that need to be fast and reliable. Also, if you're writing portable code, requiring pandas just for loading in a csv is a huge requirement. Relying on just the built-ins is better from a dependency management perspective. --- In terms of things that I barely ever use, probably #1 are async/await syntax things. I do a lot of parallel processing instead of threading though, so they're less applicable.
flask is perfectly fine for full websites though, especially if you're just writing an API and the frontend is a framework like react. We've been using that stack at work and it has been easy to manage, and really easy to scale as well. nginx + gunicorn + flask spread across however many frontend app nodes with celery workers, both scale laterally as far as we want with an AWS ELB in front of the app nodes. Yeah, you end up doing a lot more yourself of typical stuff that django has out of the box, but it's not a deal breaker whatsoever IMO. Django can be a bit complex to work with and sometimes it is just difficult to write CBVs and force everything to follow a proper django template. If you add flask_security you get a lot of what django has out of the box anyway. It's not more complex to install flask_security than it is to just have it with django beyond a pip install. You have to configure each properly anyway and that's where I think the complexity comes in. Django is awesome for the ORM in my opinion, and a great reason to use django on its own. If you want a solid SQL ORM, definitely consider django. If you want a great rest framework, DRF is great. I don't recommend NOT using django at all. But flask is great too. It's perfectly fine for large scalable sites. It's fast, and it's simple in some ways where I generally end up butting my head with django. If you do django the right way and structure everything cleanly, a django site is super easy to manage. If you don't or run into weird cases that are hard to represent in class based views, you might get stuck for a while. Django is something I consider awesome when you have a great python dev experienced with it and has built several sites already with it. However, I think flask is more intuitive and easier to build a clean site without knowing the framework in and out. I don't really like django unless you're willing to spend a ton of time becoming an expert or have someone architecting the site who is an expert with it. Otherwise it's all to easy to make a sloppy site where you lost almost all the benefits of django IMO. In the end both are awesome choices for medium to large sites I think, anything large and huge you'll have your own custom set of problems anyway which are going to involve expertise beyond django or flask. For any sites with just thousands of users, flask or django will be fine. I think flask gets a lot of flak [for a misconception] that it's meant for small rest apis and nothing more, but it's actually really easy to take it beyond that and use it for larger rest apis supporting major sites built with js frontend frameworks that handle the templating. Even with jinja2 on its own you can do a lot, but I think it starts really becoming great with something like react. I don't really consider django "great out of the box" too much more than flask because flask really just means pip installing one or two libraries to get what else you need, be it sqlalchemy or mongoengine or flask_restful or flask_security with strong password hashing. I think django does excel with the SQL ORM however, and its built-in migration and api kicks ass. I much prefer it to sqlalchemy + alembic, but honestly I don't think you're going to have a problem building a full site with sqlalchemy + alembic vs django ORM. Either will work but I do think that's where django excels. For anyone trying to get into python web dev, I definitely recommend learning both. You will find you like django for certain things and flask for others, and that may vary per person. I personally like django for smaller sites where I quickly want to throw together something with auth and a few data models. I like flask for larger projects where I want to build out a frontend in react and flask is extremely flexible for anything on the backend. That's my preference, and I certainly understand those who prefer django for anything major, and django rest framework is awesome. I ended up preferring flask, but DRF is incredibly powerful and can certainly be a great backend to a react frontend.
Thank you, I was considering learning Unity, as I do enjoy the code and creation of video games, but was unsure whether it was worth my time.
First elektron is not a solution for his problem. Also don't use elektron for anything please. You can search for packages here: https://djangopackages.org/grids/g/form-builder/ Sadly there is no solution like Qt designer :(
um...so tell them and spreadnthe knowledge?
https://github.com/Homebrew/homebrew-core/blob/master/Formula/python.rb#L102-L109 They don't compile with `--with-lto` or with `--enable-optimizations` which would explain maybe a 15%, but not the full 50%
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [Homebrew/homebrew-core/.../**python.rb#L102-L109** (master → 081869e)](https://github.com/Homebrew/homebrew-core/blob/081869eaf98133c15f3ccede777310f301a00fe2/Formula/python.rb#L102-L109) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dj4d1i1.)^.
&gt; flask is perfectly fine for full websites followed by... &gt; it's meant for small rest apis and nothing more There's nothing wrong with Flask. It has its uses. But it's not a do-everything-for-everyone fix-all. Neither is Django. Huge walls of text aside, Django is better for full websites and Flask is better for basically everything else.
Ffmpeg can send its output to stdout and your program can read it via a pipe.
I think this example would be clearer if you replace "B" with "value2" or something. Since A and C are boolean expression it's natural to expect B is as well.
As I said, running `pip install -v six` or any other command results in the same message. I'm running the command line from the same folder as my whl file get-pip.py. I tried `python -m pip install six` and this happened: Collecting six C:\Python27\lib\site-packages\pip\_vendor\requests\packages\urllib3\util\ssl_.py:318: SNIMissingWarning: An HTTPS request has been made, but the SNI (Subject Name Indication) extension to TLS is not available on this platform. This may cause the server to present an incorrect TLS certificate, which can cause validation failures. You can upgrade to a newer version of Python to solve this. For more information, see https://urllib3.readthedocs.io/en/latest/security.html#snimissingwarning. SNIMissingWarning C:\Python27\lib\site-packages\pip\_vendor\requests\packages\urllib3\util\ssl_.py:122: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. You can upgrade to a newer version of Python to solve this. For more information, see https://urllib3.readthedocs.io/en/latest/security.html#insecureplatformwarning. InsecurePlatformWarning Downloading six-1.10.0-py2.py3-none-any.whl Installing collected packages: six Successfully installed six-1.10.0 C:\Python27\lib\site-packages\pip\_vendor\requests\packages\urllib3\util\ssl_.py:122: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. You can upgrade to a newer version of Python to solve this. For more information, see https://urllib3.readthedocs.io/en/latest/security.html#insecureplatformwarning. InsecurePlatformWarning 
My point is that the original python file is not empty. It is a Python file in Python google appengine. But the created pyc is empty. Maybe I used inaccurate wording here. 
Async programming - I'm trying to find a use case but I don't write desktop GUIs and any time I need to parallelise code it is normally for CPU intensive stuff, so I can just use multiprocessing or an async worker library like Celery or PythonRQ. From what I have read, async's best use case is for situations where there is a need for very high demand concurrent workloads, e.g. a webserver. If I had that use case, e.g. the C10k problem, I'd consider using Tornado. Please let me know if you can think of any other good use cases. Coroutines - Again, I haven't really found a good use case for this. I've heard of people building mini data pipelines using them, but I think this would make my code unnecessarily complex. Generators - I use them, definitely more and more these days, but I should probably use these more instead of lists, especially when the sequence would only be consumed once! 
This is a great tutorial on image differencing, but I completely don't understand how this has any practical use for "tampering" or phishing/fraud detection. I would guess most fraudulent websites, counterfeit bills, etc. have differences too subtle for the algorithm in this tutorial to catch.
Django for sure. I started Python web development using Flask and it is a great framework. It is very light weight compared with Django. However, I'd go with Django, especially for your first project. It comes 'batteries' included - e.g. it includes an ORM, a built in Admin console etc. It also has a fantastic community and packages. I highly recommend the Django REST Framework (one of my favourite open source modules), Django Guardian (for object-level permissions) and Django-Reversion (for storing a paper trail of your models, allowing you to revert back to previous versions.)
By "image tampering" I was referring to the examples in the tutorial where elements of the image have been removed entirely (or even moved). Checking the URL of a given page is the best for phishing/fraud, but (unfortunately) not everyone does that. In that case, screenshots of a known webpage could be compared to the current page. If specific elements are missing, that would raise some red flags. For large scale phishing/fraud detection, be sure to check out the [PhishZoo](http://www1.icsi.berkeley.edu/~sadia/papers/phishzoo-icsc_final.pdf) paper mentioned in the tutorial. It goes into *much* more detail on how a CV-based solution could be applied at scale. The general idea would be to combine data mining approaches, with known phishing URLs, and known elements of pages.
No, but none of my friends under 30 are going to answer the phone for a number they don't recognize. 
Cool. Thank you
There were actually quite a few alternatives considered, see https://www.python.org/dev/peps/pep-0484/#rejected-alternatives Also, consider the main difference between the PEP 484 method and the Obiwan syntax is that attributes are stored in dicts as opposed to names pointing to classes. I assume that if one did a dozen operations on a class, it would be quite cumbersome to write, eg: def foo(item: duck(a: int, b: float, c: str,....z: function(int,str)) -&gt; int: ... # the function uses all the 26 attributes of item. In PEP 544/484 syntax you would do: class AlphabetProtocol(Protocol): a: int b: float c: str ... # etc z: Callable[[int, str]], None] def foo(item: AlphabetProtocol) -&gt; int: ... I _much_ prefer the PEP 544/484 syntax, as a protocol is a sort of extended ABC, and it is much better to define these outside of function signatures. Furthermore, defining the attributes in a class is much more Pythonic to me. Consider the Zen of Python says explicit is better than implicit (AlphabetProtocol is explicitly a Protocol), the class is flat, instead of nesting in a function in a comment. Furthermore it is sparse, and thus easier to read. But I suppose this is all a matter of opinion.
I never use `@property`. I just explicitly use a method call to set and get variables explicitly instead of hiding it behind some magic. I don't know if this is a "bad habit" or not. I avoid classes. And if I do have classes, I avoid inheritance. And if I do have inheritance, I avoid multiple inheritance, even "mixins". There's nothing more frustrating than debugging the mro. I haven't done anything serious with metaprogramming, but I'm not a framework writer. I'm finding myself not using tuples and using namedtuples instead. The only exception is working with databases (lists of tuples). For years, I've haven't done dict['key'] to get a value in a dictionary, preferring dict.get('key') instead. I haven't come across a reason to purposefully raise the `KeyError` in the work I do.
I don't have my computer in front of me but the system python is 2.7.10. Brew is whatever comes stock but isn't the same (although it's a recent 2.7) I'll try changing the version to see but I'd be surprised if that did it. I'll report back.
I find I only use lambda when making a key for sorting or something like that. But list comprehensions are so fundamental to my workflow in Python, I find it surprising people *don't* use them. In fact, I often see (though do **not** do it myself) people using comprehensions for the sake of saving a line of a for loop. I am like you though in that I tend to write for me with very few others using my code. While I certain use them sometimes, I find that I rarely write my own classes and even less often do I subclass something. At one point I decided I should do it more and wrote version 2 of one of my codes. It was pretty, but quickly proved to be untenable. That led to version three! (If you're interested, it was because they were designed to be nesting which left me unable to easily worth with deeper levels)
Thankyou very much
&gt; I never use @property. I just explicitly use a method call to set and get variables explicitly instead of hiding it behind some magic. I don't know if this is a "bad habit" or not. If all you're doing is returning the value, I'd say you don't need to do either. property replaces the need for getters and setters because you can upgrade a simple attribute to a computed property transparently. If you're doing something like fetching the data from a remote source, I'd say stick with the method call. 
Coroutines and generators are essentially the same thing, but I tend to have two distinct use cases for them. I use generators when I have a sequence of things that's easier to build iteratively than with a comprehension, or when I need some logic to occur between items. For example, I just wrote a recursive data structure and I wanted to get all the IDs for each node: def all_ids(node): yield node.id for child in node.children: yield from all_ids(child) Super useful and succinct. My other use case is for actual coroutines, and this is when I need some sort of back-and-forth in the code. The ability to `.send` data back through a yield is very useful, but it comes up less frequently. My notable cases are where I have a routine that is self contained, but needs to prompt the user to perform an action then click the OK button. This code lives near the bottom of the stack, while the UI is obviously at the top. Using a coroutine for this lets me write code like def do_a_thing(): # do some setup user_accepted = yield 'Setup thing 1' if not user_accepted: # do cleanup raise StopIteration() # do thing 1 user_accepted = yield 'Setup thing 2' if not user_accepted: # do cleanup raise StopIteration() # do thing 2 yield 'All done' # do cleanup I have a little less code repetition in mine, but I think this gets the point across. It means that my backend code can communicate with _any_ frontend, even automated tests. You could also have the calling code use `.throw(UserCanceledError())` or something and catch that specifically, but I like passing values better than passing errors. Another useful example I have is a data processing tasks. In this task I have a big chunk of input data, then many features extracted from this input data that are interdependent, i.e. I might be interested in feature X, but that depends on feature Y which I'm also interested in. I built a state machine type system that lets me write code like class Computation(BaseComputation): @computes('X') def compute_x(self): y = yield Request('Y') yield y + 1 @computes('Y') def compute_y(self): input_data = yield RequestInputData y = frobnicate(input_data) yield y This is oversimplified, but imagine having a dozen or more computations that you care about, some with multiple dependencies. This helps us keep the computations isolated, short, and composable. The state machine figures out which methods to call as it steps through the requests, and in the end just returns a mapping from names to data of everything it ended up computing. It also keeps a cache so everything is only computed once.
Based on post history, I can assume you are the person who posted the blog post. Could you describe what source you input? It was a non-empty Python source file (could you share it?) based on what you describe, but you don't explain what you did to compile it. I have no idea what you did, which would make it impossible for someone to redo what you did. Could you verify what happened? As I understand it: 1. You had a Python file 2. You called compileall on that file 3. You tried importing that file 4. The file was equivalent to an empty file Is it possible you were editing and the source hadn't been saved? For example, if I create a file and start editing, and run compileall, the file on disk will be empty until I Ctrl+S to save it.
What did/do you use for the front end?
For me it really just depends on the context. for example: def sort_key(x): return x.sort_me sorted(thing, key=sort_key) is much harder to read than: sorted(thing, key=lambda x: x.sort_me) And likewise with list comprehensions list_item = [] for i in thing: list_item.append(i * 5) is difficult to read and looks horrible. Whereas using a list comprehension can make it much nicer and easier to read. list_item = [i * 5 for i in thing] There's definitely also cases where the opposite is true and it is better to write a def or a loop.
Else on for and while loops https://docs.python.org/3.6/tutorial/controlflow.html#break-and-continue-statements-and-else-clauses-on-loops
Why would you use pandas to put things into a numpy array to store it in a table? That's just making it unnecessarily complicated...just use a pandas database and load that into whatever format you want (sql, excel, csv). Also as the other commenter said, SQLite and Pandas are different, one is a data manipulation tool and one is a database. 
Meta classes! So neat, rarely needed.
Thanks!
Exactly. The whole idea of attributes in Python is that they start with a simple self.my_property. When that stops working, then you can use @property or @.setter. Nobody has to change code. There is no way to have this simple -&gt; complex with get_ and set_. You immediately have to write code for NO GAIN.
I would recommend a simple key value store for time series. There are many specialized tools but your average nosql db will probably do the trick.
As with everything, it just needs to be used when appropriate. It annoys me when I come across a lambda that looks like a code golf entry. It also doesn't have the ability to hold any documentation. Sort is probably 80% of my lambda usage. However, I often find I need to sort with the same sort style multiple times, so it makes sense to have defined standard for use anyway.
Wow, thank you very much for that detailed and helpful response!
Sorry to say, but... by default, brew doesn't enable optimizations on Python build, because even on your shiny MacBook Pro, compilation would take an hour. You probably can modify the taps.
So is using both a common practice?
I agree with /u/flipstables personally, and for me it's about readability. When you work on a team (or even work as a sole developer maintaining a project past the point where it's small) you need to be able to quickly grok what is going on. "Code as if the person who will inherit it has an anger problem and knows where you sleep". My general rules of thumb are nested comprehensions are unacceptable in any form, and you should only ever have one boolean check per list comprehension, otherwise break it into a multi-line loop/function. Sometimes you *do* sacrifice performance, but I'll take legibility and quick understanding over almost anything else, and you can always optimize later if it's a problem. 
I tend to avoid lambdas unless it's a short and simple one, preferring defs for readability. List comprehensions I use extensively because it's nice, but I've seen some God awful double comprehension 5 liner ones with multiple if statements. I haven't really been fond of multiple inheritance due to the subtle nuances such as which one gets priority, but it is useful to have when needed. I use generators when I notice a bottleneck somewhere. Regular lists will suffice until you're dealing with large collections which need to be yielded. Would love to make more use of async code but alas, codebase isn't on python 3 yet... For me, readability is the main priority. Don't go about writing clever as shit code if nobody can read it easily. It usually comes back to using the right tool for the right job. Not enough people realise it and use the same thing everywhere even when it isn't necessary.
&gt; Sometimes you do sacrifice performance, but I'll take legibility &gt; and quick understanding over almost anything else Me too. 
Django is never overkill. But when is it, then there is Bottle.
please sub+like+share
Yeah, asynchronous programming still feels tacked on. Javascript and Go seem to handle it a lot better. 
My main use of lambda is for short sort functions.
I use Python on Windows 10, native without Unix layer. Why? My Engineering software for PCB design and other tasks is Windows only. I also code for Linux (specifically complex custom embedded charging and diagnostics carts using Raspberry Pi and a good bit of add-on hardware.) This is running a custom workflow and a Flask webservice server. Display on the cart is touchscreen HDMI web interface. I would prefer to not have some of the incompatibilities that come up with compiling things. I miss Unix style environments. However, it isn't worth the effort of running two systems. The main ERP App I built is a Tkinter GUI with PyMSSQL to SQL Server DB, with Network label printers and RFID readers. I compile to a single .exe with PyInstaller. Then I push to a network location. My launcher app sees copies any new version locally the runs. All clients are Windows for this. 
Inheritance, @property, super() etc.
It looks like this is a parser that works with lxml. From [the documentation][1]: &gt; A fast implementation of the [HTML 5 parsing spec][2] for Python. Parsing is done in C using a variant of the [gumbo parser][3]. The gumbo parse tree is then transformed into an [lxml][4] tree, also in C, yielding parse times that can be **a thirtieth** of the html5lib parse times. That is a speedup of **30x**. This differs, for instance, from the gumbo python bindings, where the initial parsing is done in C but the transformation into the final tree is done in python. The installation instructions for non-Windows systems include lxml as well: &gt; pip install --no-binary lxml html5-parser [1]: https://html5-parser.readthedocs.io/en/latest/ [2]: https://www.w3.org/TR/html5/syntax.html#parsing [3]: https://github.com/google/gumbo-parser [4]: http://lxml.de/
I like it how in most cases people on Reddit are wanting to help! I put it as a side note that I made an error on formatting and suddenly I start getting tips. Thanks for taking the time to help! You're awesome, guys!
Nope. I use just about every feature. Of course I've been using Python for about fifteen years. List comprehensions are the bee's knees and I use them all the time. Csv is just a module not a language feature. Generators are great especially if you have an object that you want to serialize. Used with a recursive function it's pretty damn amazing. I use lambdas to fake web calls and objects which is great for testing out the design of my programs before the other half is done.
If its all tabular data then you can create a pandas dataframe from the html and then export as excel using the pandas excel writer. It would look something like the following. import pandas as pd df = pd.read_html(html_file) writer = pd.ExcelWriter('pandas_simple.xlsx', engine='xlsxwriter') df.to_excel(writer, sheet_name='Sheet1') writer.save() 
&gt; That's like Python 101 stuff. It is, but it's still the foundation of what's being advocated and most of the point of the article. Yes, stuff arguing for "the basics" is posted to /r/Python all the time. And yes, I reserve the right to disagree with a fair bit of it - hence the self-selected flair.
&gt; I assume that if one did a dozen operations on a class, it would be quite cumbersome to write, eg: You wouldn't need to do that. Similar to your `AlphabetProtocol`, you could do: from obiwan import duck, function alphabet_protocol = duck( a=int, b=float, c=str, # etc z=function({(int,str),None}) # not sure what yours meant for z ) def foo(item: alphabet_protocol) -&gt; int: pass
&gt; Javascript It's not entirely unusual for me to use node.js and websockets if I want to do something asynch. I use them kind of like microservices. One example is serialport. I've never gotten serialport to work well and reliably in Python (maybe just me). But, it works like a charm in node. So I launch a serialport to websockets server in node and connect to it from Python. Works perfectly every time. Edit: node.js not node.io, I've had crossbar.io on my mind lately.
Generators are just classes with less keyboard typing. You can easily do what a generator does by making a class. Generators require less typing though so they're generally nicer if you can read them. class SillyKindaGenerator: def __init__(self): self.data = [1, 2, 3, 'easy'] def next(self): return self.data.pop() SillyKindaGenerator().next().next() That's kinda sorta mostly a generator. Much easier to just use `yield` though
If I wanted to learn more about FP techniques in Python, what should I read? 
I have no familiarity with plone but generally with valgrind on Python extension you struggle with valgrind understanding Python's garbage collection. I would google for a "valgrind Python suppression file" as a starting point to start making sense of the output.
Take a look at the `zmq` module, it will abstract sockets for you quite a lot. ZeroMQ is available for almost every programming language. Then you need an object serializer. Probably you can use `pickle`. If that's not performant enough you could look at `pyrapidjson` or `msgpack-python`, but those will require helper functions to encode and decode each object you pass.
I love context managers. I'm sure you could find uses for them. Do you ever do file IO? with open('some_file.txt') as f: data = f.read() You've read the file and it's closed automatically. Do you ever need to time something? from contextlib import contextmanager import time @contextmanager def timer(): start = time.time() yield print('{:.2f}'.format(time.time() - start)) with timer(): do_something() Now you'll know how long `do_something()` took. Do you ever need to wrap a series of database operations in a transaction, so that if anything goes wrong you can roll it back? from contextlib import contextmanager @contextmanager def transaction(session_factory): session = session_factory() try: yield session except Exception as e: session.rollback() print(e) else: session.commit() finally: session.close() with transaction(some_session_factory) as session: do_something_with_database(session) If any exception occurs, your database will go back to the way it was before the session was created. Otherwise, all changes will be committed. In both cases, the session will be closed properly. (Of course you should be more specific in your error handling, but that's up to you.) Maybe you won't find any of these helpful. I list them because I use them a ton. I think the context manager is one of the most elegant parts of the language. If you ever have a scenario that includes a setup and/or a teardown, you should try using a context manager.
There's basically no downside to using a generator. If someone needs it stored they can always list(generator), even if you don't expect performance issues. I like to just use generator syntax because it gives me warm fuzzies when I think about how nice they are versus every other language's equivalent tokenizing systems with their ugly static variables.
The pleasant thing of python is that the built in classes are so versatile that they're nearly good enough for everything. The only time I use them is when I'm making something modulary, and when I need to build in sorting or parsing behavior into how some data is handled.
You can forego the brackets and use a generator expression instead. all(x for x in xs)
&gt;If you ever have a scenario that includes a setup and/or a teardown, you should try using a context manager. That was really what I meant, that I don't run into the setup/teardown situations as often as I would expect. The file I/O is bread and butter and I certainly hope everyone uses that, but I don't _make_ context managers very often. For timing my code, I usually write a `@timeme` decorator/wrapper function and decorate the functions I want to time. Since the timing is usually just a one-and-done, this works fine for me. Your context manager would have the exact same effect, and the use-case is just a bit different. I rarely work with databases, so I don't use your third context manager (although it's one of my favorite examples of why they can be extremely useful). It's not that I think context managers aren't useful or are bad, I simply just don't find myself needing/writing them (outside of file I/O) very often. I probably write decorators 20x more often.
&gt; decorators are very often unintuitive to actually implement. It's just a function which returns a function, nothing magical, and totally standard in functional languages. TBH I think the `@syntax` makes people believe there's something magic behind the scenes.
I've been surprised at how much I use/like metaclasses. The two main use cases I tend to write them for are: 1. the metaclass' `__new__` will only get run once, when python creates the class when the file is loaded. this makes it useful for using the members of a class to create a new attribute on the class. for example, I might take all the method I decorated with `@some_decorator` and put the method names into a list. 2. overriding `__call__` to return a singleton or a cached object rather than creating a new one (I do a ton of lazy-loading-ish things) You may have known that already, but some others might not. I still try to only use metaclasses when I really really need them, however.
TIL. I didn't expect a linux vm. 
Everyone is mentioning metaclasses and async, but what about descriptors? Didn't see see them mentioned at all but I don't think I am the only one who almost never uses them. 
Not yet, but it wil probably work
if it's faster to parse it means you can parse more html pages per second, which means you can download more in parallel because you will be using less cpus 
do you even asyncio? 
This is great! Consider adding screenshots to your bitbucket README or Python package.
I've done some digging here at http://hackingantblog.wordpress.com
If you need to fetch and parse a lot of pages, then you should saturate your network and not your cpu. Otherwise it means you can fetch more. 
Keyword-only arguments are one of my favorite features in Python 3. They make inheritance with consistent __init__ signatures easy: class Sub(BaseClass): def __init__(self, *args, sub, specific, args, **kwargs): super().__init__(*args, **kwargs) ... It makes sense too, because typically only one or two positional arguments will [make sense without keywords](https://www.youtube.com/watch?v=OSGv2VnC0go&amp;t=30m53s) and typically the base class defines those obvious positional arguments.
I just used the stdlib curses library, no other dependencies. Should be good then right? I can't think of anything I did that messed with system paths or anything like that. Should be platform agnostic. Let me know if you try it and run into anything, but I think it should work!
https://wakatime.com/django-vs-flask-worksheet
PyCharm tip, if you set a breakpoint, in you next breakpoint step(even if that the same breakpoint) variables that changed from last step would be blue(in the debugger variables list).
Do a webscraping app for something you are interested in, and then do some NLP work on the results.
yep, that was made a mistake. I corrected it. Thanks for pointing it out :D 
I was thinking about properties. I corrected my answer :D
wow, my take away from all this: pypy is fast!!!
Actually this does not work, it will add 0.15 to bill bill *= 115/100 or bill *= 1.15
 bill *= 1.15
The simple answer is that these two frameworks are the best. The code, communities, and breadth of use make them the top contenders. If something is good, it becomes popular. When things become popular, they get better. There aren't any better alternatives when you consider code, communities, and use volume.
I just wanted to show an example of the difference being explained. 
Yes, and that's fine. It just happen to be a opinionated explanation, that caters to the widely held misconception. As such, it's not nearly as interesting, as it is to find out why.
&gt; The simple answer is that these two frameworks are the best. Also a wrong answer, in almost all respects. The distance between those two options are like the difference between a whittling knife and a fully automated sawmill. Neither of which are that good, when the question is: How can I cut a board to length. &gt; When things become popular, they get better. Ten million flies cannot be mistaken :)
I don't like it and lso django has a terrible name too. I think I will give up on web development until a framework with a better name appears 
Because these two have the critical mass of community popularity, proven to be effective and cover two ends of the spectrum. There are a ton of tutorials and articles about each, and a ton of apps and extensions and whatever on pypi. If you want to start with web dev in python these are a safe bet. Also this question gets asked so often that you can't expect a detailed balanced overview of all the options in every thread.
the shipped tkinter GUIs. they did come in handy ten years ago when i needed to quickly whip up a windows dialog box, but given they still support unicode in 2017 i leave my hands off it. (especially hurts when beginners take the sane step not to buy into an IDE right away but want to use what's shipped with IDLE, and soon realize that "python can't do emojis".)
This is the guy who wrote Calibre, the (imo) best way to manage ebooks. Absolutely brilliant 
You're assigning a random number to the variable 'random', but not actually doing anything wth it. Try: from random import randint print (randint(1,100)) or import random number = random.randint(1,100) print number
I'm not seeing the same kind of dramatic difference on my system. System Python is better, but only by ~10%: ocelot$ /usr/local/bin/python ./3ZFUFmFE.py Average Run: 31.4157967567 Min Run Time: 31.3465077877 Max Run Time: 31.5058290958 (1, -61, 971): 71 ocelot$ /usr/bin/python ./3ZFUFmFE.py Average Run: 28.0814129829 Min Run Time: 27.9272758961 Max Run Time: 28.1890830994 (1, -61, 971): 71 Brew 2.7.13, system Python 2.7.10. MacBookPro11,5 (2015 15" rMBP; 2.5GHz i7 
Tornado is awesome, and surprisingly under-represented on the web. I've been using it for around 4 years now without any problems. It's also kind of amusing to see everyone getting all hyped up about asynchronuous IO in Python when it's been right there in tornado all this time.
&gt; Also this question gets asked so often that you can't expect a detailed balanced overview of all the options in every thread. Well, why do John D. Newb feel that those two options are the only ones?
Yep, that's right.
If you take all the Python web frameworks, order them by popularity, and draw a line at the minimum community size needed to maintain a healthy and robust ecosystem, then these two will be above that line. Of course it's not a dichotomy in the strict sense, but it just so happens that when a beginner wants to get into Python web dev, there are exactly two obvious choices, and since our beginner wants to start with only one of them, the choice does boil down to a binary one.
Structural typing is itself not the same as dynamic typing. If structural typing is checked at compile time it cannot cope with runtime structure changes. Structural typing checks might be a better feature to add to a static typing checker, but it does not go the whole way.
Support for PlexPy is here https://github.com/JonnyWong16/plexpy/blob/master/README.md#issues
Well technically you certainly _use_ descriptors all the time, as that's how method calls work. And one could argue that you are writing your own descriptor every time you use `def`, since all functions are descriptors. But yeah, I think I've only ever written a custom descriptor once, and even then it wasn't that useful and I only did it because I could.
[removed]
&gt; I tried writing a GUI once, and decided not to do that again! I know a lot of people here will have disagreements with what I'm about to say, but I *hate* the way Python GUI workflow, look, feel, etc. is and I've tried just about everything out there. It just feels like a waste of time every time I try. One thing I've had great luck with, though, is using a 'web' front end with Flask and/or websocket server on the Python backend. I've been playing with [Electron](https://electron.atom.io/) for my front ends and its working out very well. The look and feel is *highly* customizable and the workflow is a breeze. On top of that, it makes it easier for me to offload the design onto one of the millions of HTML/CSS/Javascript devs out there.
I've been using Python for almost 8 years now, and I just read about this the other week. Shows how unneeded it really is.
Yesterday I saw a Raymond Hettinger pycon video praising else on for loops and saw in Effective Python that the author regarded it as confusing. Hettinger said else in loops should have been called no-break.
Would be awesome if you ported the source over to GitHub. Nice project.
Sure, I'm looking at way to execute code by other parties in a given group without them peaking at the innards. Cheat prevention if you will
Still, a function generating a function isn't exactly the most straight forward concept to grasp.
[HIRING DevOps Systems engineer, Optiver, Amsterdam] Like to be in full control of complex, high-performance (tradings) systems? Like automating your work so you have more time for performance tweaking? We can sponsor visa and facilitate relocation. https://www.optiver.com/eu/en/job-opportunities/eu-510834 
I was wondering why I didn't know about `display` and it appears it's a py3k feature. For those still on 2.7 `p` will allow you to see the variable's value as it changes.
&gt; How come that almost all entry level questions about which framework to chose is stated as the false dichotomy of Flask or Django? They have the most press. Simple as that. For people that come into the Python community not knowing much about it, they'll search for "python web framework" and these two will dominate the results. &gt; And what's worse, hardly anyone who answers, takes the time to explain the difference between those two, let alone mention some of the other alternatives. I try whenever this comes up, but it's tiresome to type out the same reasons every time. But my best advice here is to be the change you want to see. 
The article talks about measuring and profiling first (which I support) but then drops this line &gt; I recommend to store your cache in Redis. without any further explanation. This is not correct. If you actually want vegging you can easily start with Djangos build in in memory caching and later on move to Redis *if you need to*.
I'll give a few. These aren't bad practices in Flask, but just general observations I've had reviewing other code bases * avoid using request willy nilly. Nothing below the route handler needs to know about it. eg If you're calling another function inside of a route handler, don't pass the request, pass information off of it. * Embrace blueprints and application factories early on. You'll be in a much better spot when your app grows. I'm not saying immediately - it's silly if you only have two routes and that's all you'll ever have. But using the application itself to register routes becomes unwieldy quickly. * Do your best to understand the current\_app and request dance, how they're populated, when they're populated and their lifetimes. 
I used it for a while. It's fun for practicing list comprehension and basic functions. Problem is you can't really do anything with it. You can learn python on it but you couldn't deploy an application or commit to a git branch. It doesn't have pandas (or didn't then), which was kind of a non-starter.
I've been developing my project extensively in a windows environment. Somewhere along the way, something was changed. Now it won't work in a Linux environment. After I fix that, I gotta make sure the regex searches don't break if I introduce UTF-8 characters. 
Not only that. You also have a whole browser packaged with you app. :D :D
I've been working on a little service that checks your regular route to work or wherever and lets you know if there's a lot more traffic than usual. It started as a side project to teach myself python and then slowly morphed into teaching myself to make 'real' websites and now I'm looking into the viability of charging for it and hopefully making a little side income. Biggest issue I'm running into now is marketing and figuring out if this is even something people would pay for. https://notifytraffic.com/ If anyone has any input or suggestions I'm more than open to them! 
You need to win people's trust first. That s possible by letting them use your service for let s say 2 weeks(?) for free and then they can decide if continue with paying the Service or not. Or you can give 1 Month free to users that bring more users. Make a post on InternetIsBeautiful subreddit, I think that s the right place to Show the community your Idea. 
At my last job, my coworker told me about the time he removed memcache and got better performance. You gotta measure it!
Pythonista is well worth the cost. I use it to put components together while I'm on the go. If you combine it with stash you can even add pip functionality for adding pure python modules to the app. It is at the top of this link. https://github.com/Pythonista-Tools/Pythonista-Tools/blob/master/Utilities.md
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [Pythonista-Tools/Pythonista-Tools/.../**Utilities.md** (master → 9525844)](https://github.com/Pythonista-Tools/Pythonista-Tools/blob/9525844f68cad70912c71f7f96a804482a72263c/Utilities.md) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dj5kdk1.)^.
1. Collect a param from the URL GET query: https://stackoverflow.com/questions/150505/capturing-url-parameters-in-request-get 2. Populate a form with initial data: https://stackoverflow.com/questions/3833403/initial-populating-on-django-forms
I don't understand the downvotes, it is indeed a good hint, just a little harsh maybe.
Oh I didn't even look at the votes. I was suggesting like a possible answer (as OP didn't fully explain exactly what info they need), no intention of being condescending! In any case you can make the getter and setter report a good bit of what is going on so it's highly applicable in many many debugging scenarios. 
Now try to use your simple function decorator on a method, a classmethod, a staticmethod... There are definitely a lot of pitfalls, and so https://wrapt.readthedocs.io/en/latest/ or http://boltons.readthedocs.io/en/latest/funcutils.html exist
&gt; I don't like that lambda functions are limited to one line Lambda is not limited to one *line* but to one *expression*. The expression can be as big and complex as you need, and you can spread it over more than one line. lambda a, b, c=None, d=999: ( spam + eggs or cheese.method(a, b) - (c or default).attr)[d] 
Direct link to code: https://github.com/siddhantgoel/streaming-form-data Author here. A few weeks ago I needed a `multipart/form-data` parser that could parse arbitrary chunks of HTTP request data, but there wasn't anything that existed. So I spent some of my spare time writing one. It has recently begun to take some shape and it works quite well now (there are quite a lot of tests included). But there are still some features missing that could use some external help. Python 2.7 support, for instance. :) I wrote a summary here - https://sgoel.org/posts/streaming-multipartform-data-parser-for-python/ that goes a bit more into details. Anyway, I hope it's useful!
&gt; Hettinger said else in loops should have been called no-break. Well, that's one opinion, but it's a bad one. They should have been called `then` because that's how they work. for x in sequence: block else: stuff The `else` block **unconditionally** runs after the for loop. The only way to avoid that is to jump out of the for loop, using `break`, `return` or `raise`. 
Thanks, I will spend sometime with those.
&gt; I've been using Python for almost 8 years now, and I just read about this the other week. &gt; &gt; Shows how unneeded it really is. No, that just shows how limited and narrow your reading material and Python programming knowledge is. I don't grok or use asyncronous programming. That's *my* lack, it doesn't prove that async programming isn't needed. Same goes for you and for...else. It's an awesome feature, if you don't use it, that's your lack.
I have an Ant Adaptor Profile at MyAnt, but I registered a while ago.
Ah, right, properties are what I meant. That is a good point! I guess you *could* make a class and change its representation, string, add function and so on to handle it even if it is a variable, but that might be a bit over the top. 
I understand that, but what is the reason you don't want others to be able to see the source code?
&gt; You can't statically type a dynamic language. Except that's exactly what MyPy does: it typechecks your code statically, at compile-time. In fact, it's exactly what *you* do, when you read code. When you see something like: n += 1 you know that `n` is likely an int and certainly a number (otherwise that code will fail). 
I wouldn't recommend it. Retention with sololearn is really bad. You have to practice outside the app to really learn.
for-else statements. Can be useful, I just almost never use it. 
Actually, this isn't python 2 compatible (a `yield from` in the layout class definition for one, not sure what else) so all classes are new-style by default.
Sure, I'll take a look. If the API is the same, it's definitely worth a few extra lines of code to do a platform check and special import.
Writing an API wrapper, one of my bigger projects that I've decided to embark on! 
I wasn't aware that HTML parsing speed was an issue. This is interesting!
Cms with django
The main problem with Django's in-memory cache is that it's not shared. Each uwsgi/gunicorn worker has its own cache.
Hehe yep again. This is the poor mans boostrap since that would take forever. But as you pointed out that is what should have been done. Never thought about the probabilities in dropout as "p-hacking". Would that really help if you wanted certain results? If I wake up not a father of two kids I'll do some more tests :) but my main point was, that at least - ANNs is having unnecessary bad rep on small data. 
It can be fast if you have certain code paths that are executed often because it compiles those to actual machine code IIRC, whereas CPython always only compiles to its Python bytecode and interprets that, just like Java did some time ago. These days they also seek to improve the performance by translation into target code.
Not exactly python related but I've been learning Ansible and at the same time I've been writing a script that builds a VM based on the latest debian or archlinux from netinstall.
Trying to get a job. Which is the same thing I was working on last week... And the week before that... **And** the week before that...
My company sells a mobile version of our software to various customers. The apps we sell are identical aside from the branding and the servers they point to. I'm working on automating the entire process of branding an app for the customer and submitting it to the App Store (for iOS). I'm using python to initialize and create configuration files for a tool called Fastlane, which automates most of the iOS App Store deployment process, and then run the appropriate lanes from fastlane to do my bidding. I'm hoping to have the whole process down to just running "make_sacrifices_to_apple.py" 
Looks really cool. Do you plan to cover more security stuff. There isn't much of that stuff out there.
I don't know about VS Code, but I know you can debug curses in PyCharm if you check the "Emulate terminal in output console" box. I've also had success launching the curses application in a separate terminal window and attaching to the process ID through the debugger. In that case the stdout goes directly to the terminal instead of through the debugger's fake tty. Again, not sure if VS Code is capable of connecting to a remote process.
I find myself using for/else while/else try/else more and more as time goes on. A full try/except/else/finally looks beautiful.
Exactly
It would be interesting to have a library of wrapped primitives that you could attach callbacks to which would be executed on change. 
Hey, the last time I checked airflow required a unix/linux environment to run. You'll either need to use docker/vm or use an alternative ETL toolset. If you don't have strong reasons for choosing airflow, Luigi is much easier to setup and works well.
Learning how to use Python outside of self contained academic environments.
Because it's harder to debug since it's composed together. Since both tests `A` and `B` are coupled together, it'll be hard to resolve a bug in `A`, for instance. It's also harder to understand since you have two conditionals in your comprehension. I'd prefer to only have max 1 since it makes readability suffer.
Improvements to a scapy port scanner with multiple scan types like Nmap. Biggest problem for now is Threading the whole thing. I have problems understanding the correct way of threading with classes...
Maybe beautifulsoup as an option just makes the resulting objects implement the BS API so this can be a drop in replacement.
if the loop didn't execute at all, it will run the else. eg for i in '': print('for loop') else: print('else block') will only print `else block`
!! This is very good to know! Thank you
A hotel price checker for my upcoming vacation. Know the hotels I want to stay in. Im keeping a tab on the prices so I can hedge paying for it until Im ready.
Great read! I Just Wonder If using a faster language (such as C) or rewriting some of the library in C would make the It even faster. I havent seen the source code so maybe it has already been done.
I'm trying to program a graphing calculator from scratch for my senior project. I started this week.
Pillow-SIMD core is already written in high-optimized C-code with the use of AVX2 and SSE4 low-level instructions. 
If you aren't working in a project with other people, then do whatever you want. If you are, then follow that projects conventions. I personally think language specific conventions like how to write a variable name are stupid unless they specifically have an impact on performance. I do see their benefits, but I disagree with the practice. My solution to this was to make a lisp function in emacs that converts camel case to snake case since I dislike writing underscores.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [apache/incubator-airflow/.../**systemd** (master → d8891d9)](https://github.com/apache/incubator-airflow/tree/d8891d906c858ebb1413685a797913918207279a/scripts/systemd) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dj63s55.)^.
You are my hero! My coworkers will never know my dirty secret
Fantastic stuff! Just wanted to give you some feedback about the writeup itself: 1. In the paragraph starting with `What we’re doing with convolution is calculating output pixel values for`, I think you have a typo on line 3: `m*n` instead of `M*n` 1. In the paragraph starting with `While there are many window functions, only these three finite ones are `, line 3 has an instance of `0` (zero), but the font makes it look like a lower case letter "oh" And thanks again for this. I might just update my batch resizer utility to use your new library :)
Writing an MMO server. Hurray challenges?
Yes, with the caveat that basically every Pythonic job in the world is going to use PEP8, and that not using PEP8 in your personal projects is kind of like learning how to play guitar incorrectly. Unlearning bad habits is much, much harder than simply learning good habits in the first place. 
If your only doing python work stick with pycharm. It's lighter weight. They accomplish the same thing for python work. I personally use IntelliJ with the plugin because I don't pay for the all products pack. The important question is do you need the polyglot abilities of IntelliJ?
Trying to make a garbage collecting script, cleaning by comparing a gc file (time to live = 5d) to the directory age, then purging items in the directory. 
Do they have the same functionality though? I plan on doing both Java (for school) and Python (for myself).
Little bit late. The startup I was contracting for as a Django dev went splat last week. I've started learning React and the Node ecosystem and I'm enjoying it. Would love to get back into Django dev and have started applying for internships and junior dev positions, but we'll see how that goes. 
Note that you can also use a class-based decorator for this kind of thing, which is sometimes clearer: class ArgumentTypeChecker(object): def __init__(self, function, some_type): self.function = function self.type = some_type def __call__(self, *args): for arg in args: if type(args) != self.type: raise ValueError( 'Method \'{}\' only accepts arguments of type {}'.format( f.__name__, some_type, )) return self.function(*args, **kwargs) Then: @ArgumentTypeChecker(int) def fib(n): ...
You can definite use it to learn Python. I bought it and wrote minesweeper for it. It helped me to learn Python and it was fun to do. I would not call that productive, but it sure was educational and entertaining.
Are you using ctypes to call main? If so maybe try the subprocess module instead. It is a better fit for running entire programs. 
I use it on my iPhone and find it extremely useful. The no import thing is a pain, but there are many options to export, including pushing out to your gist account. Well worth the money. 
Just a quick reply to say thanks again - your advice helped me get it sorted.
I am not. Also, all of my experience in programming is hobbyist. None of it professional. Hence my flair. Thanks for offering though. That's more than I've gotten recently.
I use Pycharm and I have not found good reason to switch. 
Thanx for the share and awesome work.
It sounds like your organization is invested in airflow? If so, I would talk to a coworker about how they set it up. Setting up airflow will not be trivial on windows. It was made with a *nix environment in mind.
When I started it they didn't, maybe they do now but I haven't seen anything. As far as I know they don't let you have anywhere near as fine control as what I wanted, didn't send you push/text notifications, etc. And don't worry, I get that from every other person I tell about it lol.
Mechanism of exploit payload delivery using raw sockets in Python 2.7. The biggest instance I have ever created lol 
When I think of sandboxing I think of OS level features like chroot, VM, SELinux. Is python, a high-level language, suitable for that kind of kernel level coding?
Just to note: if someone claims that their python package is the fastest in the world, then they have probably already utilised C extensions. Nothing written in pure python will ever be the "fastest" anything. What this library provides is the fastest low-level implementation known (according to the author) with the convenience of a python API - best of both worlds. The downside is that it most likely won't work on non-Intel CPUs (or if it does, it won't be using the optimisations) so it's not portable. A pure python implementation would likely be very portable.
if you are struggling to do it, maybe add macro to fix it, or use formatter to format the variable on your file
Are you hiring also remote or only in-house? 
I am new to python so I am watching tutorials on python by the new Boston... Gonna watch a web crawler be built :D
I could wrap my head around flask better than django, and it's been my goto. I should try django again now that I understand python a bit better
It shows with code formatting, but "will show as" is also formatted the same. It goes from the first to the last tick, and ignores those in the middle. 
Oh, greedy as in regex quantifiers. That sounds like a bug report. Syntactic recognition should be happening at some level before you would need to look at "is it mobile".
This is excellent. Can't wait for the rest of the series!
great idea! I'll add that as a ticket. I like having the option of working with contexts with something like layouts where you might want to tear it down after.
So they come up with their own solution while still running other's and seeing the output
Yeah he likes my idea of using VMware to run Linux. So I'll probably figure that out. Is there a best Linux version for python or is Ubuntu good enough.
Alright, I added a simple check if `os.name == 'nt'` to list `'unicurses'` as a requirement in the setup.py and also where it imports curses to check os.name again and `import unicurses as curses`. If it's as simple as that, windows should work, but I have yet to test. I dual boot but I don't have a python environment set up in windows 10 so I'd have to take some time to set that up. I tested in linux and it still works as is so it can't hurt at least.
Oh, so it's for a teaching purpose?
Did you look into [Influxdb](https://www.influxdata.com/) yet? It has a [Python client](https://github.com/influxdata/influxdb-python)
or, they're wrong. 
Something along the lines of this: def foo(bar): print(bar) l = ["f", "o", "o"] for x in l: foo(x) Should work just fine and not require much work on your existing code. Probably not the most elegant solution tho.
Time-series databases are all the rage these days. However, people have been keeping time-series data in relational databases for about 25 years. It's what data warehouses &amp; dimensional modeling is all about. The relational database is the more general-purpose solution, so you usually need to write your own processes to maintain aggregate tables, roll off history, etc. But none of that is hard. So, if your volumes are small, and you have some skill, then sqlite would probably make for a very simple solution - that's very mature, great drivers, great documentation, etc. And from your description it sounds unlikely that you would exceed what sqlite could deliver.
&gt; I wish floats were implemented on top of Fractions Exactly.... revolt against the oppression of irrational numbers brother. Viva la Revolución! &lt;&lt;-- Your proposal is dumber than even my stupid reply, because... math
How? I'm guessing you mean the resume would be a bunch of linked pages, and not a single static page?
Pretty much! ^_^
What kind of structure would you have?
Working through 32 hour tutorial for Python
Me too, 99 allows less strange line breaks and still allows having two files opened side by side on most modern wide monitors.
I consider "educational" as "productive", so win win. :)
Yeah, data science competition for student
The standard library multiprocessing module has Pool.map that works just as seamlessly, use multiprocessing.dummy.Pool to use threads 
There is not point to have django API and react application together. Better approach is to split this to two separate applications. Django does not need to serve any of frontend code.
memcached is generally a better LRU cache than Redis Redis is a data structure server, its expire functions are too basic.
I worked on something like that recently : https://bitbucket.org/pythonian/tshistory/ ... even if you don't plan to update existing series, that might work for you. In practice it's also possible that pandas dataframe .to_sql might be enough for you.
While of course performance depends on the specific system that your software is running on, I think it is safe to say that Pillow SIMD is certainly not the fastest image resizer in the world. Have a look at [vips](https://github.com/jcupitt/libvips/wiki/Speed-and-memory-use). It beats Pillow-SIMD by 80%!
You're right, and edited to reflect that... though I still follow PEP-8, it's just that I've internalized the "maintain the pre-existing style" part for methods and functions, and my past employers having all used the same libraries.
Pillow itself quite portable across x86, ARM and PowerPC (see this table: http://pillow.readthedocs.io/en/4.1.x/installation.html#other-platforms). Pillow-SIMD works on modern x86 chips (both Intel and AMD).
I do -- apparently too much -- work in pre-existing codebases, and yeah I get maintaining camelCase for callables if that's the prevailing style, because it does communicate "I'm a callable" in a way that snake_case doesn't, but it's distinguishing variables from higher order objects that's the main point for me. As for methods vs properties or attributes, personally I feel like if you have to express it in two or more words, it's probably not a good name for a property or attribute, and if it's callable one of the words should be a verb.
Nope. It's just additional language support. Anecdotally, PyCharm seems to have more issues dealing with mixed language code-bases. 
&gt; CamelCase for callables if that's the prevailing style, because it does communicate "I'm a callable" That's just it. It doesn't. You've defined it to on your project. You could use all caps for that or put a verb in every method (e.g., get/set_area). You could also just know the code base or use some function that tells you the methods vs. attributes of any class (very useful function) or read the nonexistent/incorrect documentation. PEP-8 defines snake_case for callables for whatever reason. That's what new people expect. &gt; As for methods vs properties or attributes, personally I feel like if you have to express it in two or more words, it's probably not a good name for a property or attribute, and if it's callable one of the words should be a verb. It gets more complicated when you develop an FEA code and have multiple classes with similar APIs. In one case, I have 1D elements (so lines). One has an area attribute. Another has multiple areas (up to 10) at various intermediate stations. Another just has dimensions that represent an area at multiple stations. If I try and calculate the integrated mass (computed as `(density*area+nonstructural_mass_per_length)*L`), I have at least 3 classes. Both have area as a function, and one has area as a float, another as a list, and the other area needs to be calculated. I could write get, but I'm lazy. What about the mass, centroid, and center of mass methods? Should those also have gets to be consistent? It's been 5.5 years on that project and I still haven't solved the API. Old codebases are annoying. You never did it right. At some point, you organize it and realize your API is horribly inconsistent. It's 100k lines though.
I was thinking more in terms of ARM, MIPS, Tensilica, PowerPC, etc. Non-Intel-like.
Yes I am. But don't worry, the problem is solved. Thanks for the answer anyway! I'll post the solution ASAP.
I use both and there is a difference. I currently write python 3.6 code with static types and they are not supported in intellij idea plugin. New features from Pycharm are included in Idea with significant delay. I prefer pycharm for python code.
A counter example, you generate classes and evaluate expressions at run time. That is dynamic, and static typing will not help. If you restrict Python to what can be statically typed, you nolonger have a dynamic language. It ain't Python! 
hallo
Woa there. I think you are overloading the meaning of *dynamism* in your sentence above :-) If you enforce no run time changes, and so have variables and nolonger names, then you have a new language based on restrictions to Python that is *not* Python - You might think it good, but it is shorn of its dynamic typing. Stripped of its dynamism! 
There is /r/test
It is time to port it to Python 3
Which ones?
are you good at applied maths? if yes ML, its a much higher skill. if not your looking at a 10X to 20X greater learning slope.
I've been using bootstrap. Quite like it myself, just makes things pretty. You're still going to have to understand html &amp; css but it does save some effort.
That test includes more than just resizing. Maybe the other functions weren't simd optimised in pillow
You can, but you probably shouldn't do that. Hopefully people don't take this as advice.
Technically that's a Python2 iterator (python3 wants \_\_next\_\_), but not a generator, but fair example. Also worth noting that where possible generator comprehensions may be preferable to generator functions.
I think it's implemented in Java :-) But I agree: It would be nice if it could run 3.x code.
Creating some Celery workers to syncronize, the now 20GB MySQL database to Google Datastore while also making some calculations, in orther to move to the next step - refactoring the flask application and schrinking the MySQL database allowing it to be a buffer with data from the last 14 days.
I guess as long as you don't replace cmd with power shell (there is a setting for that) it will be executed with cmd, but this is a rough guess.
To add on to this, if you use the bash subshell (or whatever it is called), how does subprocess work? I really want to play more with the subshell. I hope my work will let me get it on my VM some time soon...
Jython was the gateway drug that led our company to abandon Java and go python whole hog. Good times!
www.github.com/sanchit3008/botmate
Why do we need to visit facebook?
This is one of the reasons. The seconds that in Pillow tests we try to measure bandwidth rather than minimal time. Vips claims it is multithreaded and the tested processor has 6 cores. If you run two vips programs simultaneously, you'll get no or little benefits. For Pillow-SIMD you'll most likely get 2x bandwidth. And so on up to 6 simultaneous processes.
By default it uses cmd. subprocess.call(["command"], shell=True) If you would like to run powershell script. subprocess.call(["powershell.exe","script.ps1"]) EDIT: From https://docs.python.org/2/library/subprocess.html#frequently-used-arguments Warning Using shell=True can be a security hazard. See the warning underFrequently Used Arguments for details. 
A plain text resume as the main page. (I wanted to still be able to print and use this as a true resume) A separate section for development projects with blurbs and photos. And a short about section with other interests and hobbies. 
Wrote more features instead of boiler plate. Then 10 years went by and our feature set got so large and team got larger that sometimes I miss the java formalisims and compile time guarantees that become benefits once the codebase / team get larger past some inflection point. So, alas, neither seem to be a 'perfect' solution for both the more start-up mode versus well established mature company modes.
yeah during 1st amd 2nd year i studied applied maths, but have to revise all stuff. 
This is really well made. Is it open source?
&gt; Object Construction: \_\_init\_\_ Nope. new handles construction (and the type metaclass manages it via its call magic method). init handles object initialization (hence, init). The exception is immutable objects which new plays double duty of construction and initialization.
at first glance there are definition time defaults at stuff like the creation time, thats a very basic mistake
If you are running python in bash then subprocess runs commands in bash.
Regex mainly. also i think the reason I'm having some issues is I didnt really understand some basic computer science concepts, now that I'm looking more into that things are starting to make sense. OOP is another concept im struggling with as well as databases. also, i have no idea what type of scripts to try out, I've made a basic calculator so far, I'm interested in the robotics side of things but cant really afford hardware at the moment either
I thought serious usage of "webscale" had been laughed out of the world.
Having installed and tested this on Windows the following error is thrown - *AttributeError: module 'unicurses' has no attribute 'initscr'* Which, looking at the [Unicurses](https://github.com/Chiel92/unicurses) GitHub page, must be to do with this - *First of all, the function used to initialize curses (initscr) must be called in a special way with an assignment to a variable named stdscr. Therefore, instead of just calling initscr() you must use the following expression verbatim:* **stdscr = initscr()**
There's also this GraphicsMagick wrapper: https://github.com/hhatto/pgmagick (a library parallelised with OpenMP)
Thanks for that! I'll make that change and also double check the unicurses docs.
Thanks, I'll check it out!! 
Thanks for posting @hoocoodanode! And thanks for playing around with the draft too :) I'm Chris (@chriddyp) from Plotly, author of Dash. Happy to answer any questions anyone might have!
Yes. I broke the datetime in part 2 and didn't realize it until part 3. It gets fixed in part 4 when I add e2e tests. Not ideal, but I think it's a bit more real-world. There's also a time drift issue that I think is related to Docker. It seems to fix itself when I re-build the containers, but then it slowly drifts until the next re-build. +1 for the datestuff lib!
Thanks to you for the work on this, looking forwards to putting it to use!
I'd like to build a nice Table component for Dash. There are lots of React table components out there (https://react.rocks/tag/DataTable) that could be easily ported to Dash (https://plot.ly/dash/plugins). I'd love to see a table component that is typed (dates, numbers, strings) and formats those types appropriately. Here is some inspiration: https://medium.com/mission-log/design-better-data-tables-430a30a00d8c
Thanks vph! You actually _don't_ need to have an account to create a Plot anymore. We open sourced our core graphing library a couple of years ago and since then all of our libraries work completely offline. https://plot.ly/python/offline/ You only need a Plotly account if you want to: - Publish your plots to your Plotly account (free for public plots, paid for private plots) - Edit or save charts with our online chart editor: https://plot.ly/create. (You can play around with the chart editor without signing up too).
Just as an FYI, reddit syntax is "u/", not "@". So it'd be u/chriddyp
ohhhhhhhhhhhhh. thanks u/ThePenultimateOne :)
The 3D stuff is really cool. Some more examples from the community at https://plot.ly/feed/?q=plottype:surface. Big thanks to Mikola at https://bits.coop for all the WebGL goodness (Regl: https://github.com/regl-project/regl, stackgl: https://github.com/stackgl).
Great. Thanks.
Thanks! Lets say that I have a very shitty flask app which currently accesses a posgre DB to pull data. Can I "inject" these graphs into my other current renders? more specifically,I have this silly site, and have a db, data gets loaded into a pandas DF, can I use this project w/o re-writting based on your hello world app.py? my (crappy) site hello.py is [here](https://github.com/terwilld/rmvtracker/blob/master/hello.py) very simple flask app. Im trying to inject a plot with a similar drop down here: http://www.rmvtracker.com
That isn't what I mean. For example, MyPy can support arbitrary attribute assignment and access. Given complex enough inference and logic, it would be possible to approximate most of Python's semantics, it certainly wouldn't be Python. 
In Stackless Python, the Python interpreter itself manages the scheduling and execution of "threads", rather than the operating system. These "threads" are not true OS threads, but rather a thread-like data structure created and maintained by the interpreter itself, so creating and switching between these "threads" does not incur the usual overhead of creating and switching between OS threads.
Complete pile of crap folks, don't waste your time, just move on.
&gt; There's also a time drift issue that I think is related to Docker. Unless you're running in a VM with time issues, it most certainly is. I run into this locally all the time because I hardly rebuild locally unless a new python dep has been added (lxml takes forever for some dumb reason I can't figure out). S3 starts yelling about signatures not matching because of timing differences. Rebuilding fixes that. Occasionally I have to restart the moby linux vm to fix it. I remember a coworker coming across a container that exposed a socket you could mount into other containers that would fix that. It related to Etherum containers to give you extra keywords to search for. 
Maybe you need the full path and .exe suffix? You can get feedback by using something like [ProcessMonitor](https://technet.microsoft.com/en-us/sysinternals/processmonitor.aspx), you can use it like an strace equivalent.
Shoutout to [Flask](http://flask.pocoo.org)
You have to know that each thread has its own stack. So if you were using the multithreading module then each thread has its own stack, which in pure python code is kinda pointless. The GIL will ensure that only one thread can advance at a time. So instead you have many lightweight "threadlets/green threads" not recognized by the OS, and therefore without C stacks. Instead the interpreter jumps around between the python code it is executing. The interpreter thread 0 says "I'm executing threadlet 16, and now I'm executing threadlet 17 and now 18..." instead of interpreter thread 1 waiting on interpreter thread 2 to release the GIL so that it can advance the associated python thread.
Built a simple Twitter bot which uploads a wallpaper every one hour. Will probably make it once a day upload. It's here if you want to check it out. https://mobile.twitter.com/WallpaperPyBot
It doesn't work (unless you want to put `__init__.py` files in every directory from your root), and it's a terrible, terrible idea. If you need common bits, put them in a common package and share it between all scripts.
I remember tinkering around with an earlier version of Dash, happy to see it finally go live. Python has historically lacked a R shiny-like feature and I'll be trying this one out! A few questions: Do I need a Plot.ly account to deploy/host a Dash app on my own servers? Does the plotting library handle candlecharts (with OHLC data)? Is it possible to export a snapshot of the dashboard? Maybe as .png or .pdf Thanks for your cool work and for taking time to answer questions! 
I tested this. No! The `subprocess` is using PowerShell. I have tried the raw command in CMD and it is working. But, both from my Python script (both running the script from CMD and PowerShell) and by executing the command itself inside PowerShell return the same error message. With this I conclude that Python3 refer to PowerShell when running `subprocess`. Here is my call on `subprocess`. import subprocess subprocess.run(["convert", "'{}'".format(nm_fi.ap_bak), "-resize", "{}x{}".format(_w, _h), "'{}'".format(nm_fi.ap_cn)]) This is based on this command. convert "download.png" -resize 600x "download_2.png" * Running `python3 -B convert.py` in CMD gives this error message, `Invalid Parameter - -resize`. * Running `python3 -B convert.py` in PowerShell gives this error message, `Invalid Parameter - -resize`. * Running `convert "download.png" -resize 600x "download_2.png"` in PowerShell gives this error message, `Invalid Parameter - -resize`. * Running `convert "download.png" -resize 600x "download_2.png"` in CMD is working. So what is wrong here?
[PyTables](http://www.pytables.org/) would be a good option? It is easy to use, you can compress your data, it is based on HDF5, you can add metadata to your tables/arrays/groups,... It could be seen as a lowcost NoSQL option to store arrays, dataframes.
Yes, but the ImageMagick is installed as Windows' .dll. I cannot access installed ImageMagick from Bash in Windows (using Git terminal).
Solution verified!
consider using the Pyramid framework - lots of features, including sessions - not sure if it does the "PY scripts in directory" thing - easier to get started vs Django (which I love), and not as fiddly as Flask. http://docs.pylonsproject.org/projects/pyramid/en/latest/
A simple example you can start from: #!/usr/bin/env python3 import os,sys,re,argparse import subprocess def main(): proc = subprocess.run(["./program"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) if proc.returncode: print("the program failed to exit successfully") print(proc.stderr) sys.exit(proc.returncode) lines = str(proc.stdout,"utf-8").split('\n') count=0 for num,line in enumerate(lines): if re.match(r"^Packet number.*", line): count+=1 print (num,line) print ("found %i packets"%count) if __name__ == "__main__": main() Read https://docs.python.org/3/library/subprocess.html if you want to do something more involved.
Thanks, was looking at Pyramid before my initial post. By default, it looks like Pyramid only allows you to create views manually, but haven't seen a feature allowing you to create a 'htdocs' directory. Everything else about it looks good though. 
I use web2py reguraly for a long time. I've developed a number of different application in it ranging from fintech application such as investment fund management platform to simple data analysis applications. For me it is the best python framework becuse it is designed really smart (kudos to Massimo and the team). Regarding Python 3: not long ago there was a thread in google group web2py-users about being able to run it on Python 3. I havenct tried it myself, but I suggest you ask in the group about it.
Thats not entirely true. Streaming / real-time plots are crippled / non-existent in the offline version.
Forgive my lack of art appreciation here... &gt; creating and manipulating digital forms of fine arts For me this is extremely vague and nebulous. Given the code base, I am assuming that this refers to some sort of graphical output, but I have very little idea _why_ or _how_ I would use this package without digging into the code. What is your use-case? Why did you create this package? What problem are you solving?
If you spend a lot of time looking through the [source](https://github.com/python/cpython/blob/3.6/Lib/subprocess.py) you'll find that when `shell=True` is passed, **subprocess.Popen** ultimately uses whatever the value is for the %COMSPEC% environment variable in the running process, falling back to **cmd.exe** if there's no value there. So, given your output, my guess is you've somehow set PowerShell as default, that Windows is -- as usual -- helpfully doing something opaque, and that the result is that %COMSPEC% in your running Python session is set to the full path to PowerShell.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [python/cpython/.../**subprocess.py** (3.6 → 4a66524)](https://github.com/python/cpython/blob/4a66524006852fc982aebafa277f2c043d9ad149/Lib/subprocess.py) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dj7z9ua.)^.
/u/chriddyp hey, I'm new to python. Is it possible for example to plot a graph that will take info from a file that's updated let's say in intervals of 5 seconds, then pause it and using UI change the info in that file. For example a file is: x=0 y=10 x=5 y=17 x=10 y=23 x=15 y=35 and so on... Then by clicking on the UI of the graph on the area that's `x=10 y=23` you can change it to `x=10 y=20` Just wondering if something like this is achievable
The Goldman Sachs demo source code is no longer up :(
Making an adf.ly bot :P
I currently do this kind of stuff with flask + socketio + plotly + vuejs/elementui. I think I'm too invested in that stack to migrate to dash. If I was starting that project today though I would probably seriously consider dash. 
This is going to suck regardless - especially if you're adding Py3 support to a Py2 codebase - but [Hypothesis](http://hypothesis.readthedocs.io/) can at least make your tests way more powerful. A single property-based test is a little harder to write, but can replace many example-based tests, so you'll probably come out ahead on effort and certainly get better coverage!
Hey, take a look on the 'about' section of this subreddit, if you could place 4 extra spaces before each line of code would help everyone who tries to help you to see your code indented.
Haha you have a point, thought you might be interested too though :)
Wow. Thanks a ton for the detailed answer! 
Good video! Some feedback because everyone loves feedback: -Have your ducks in a row before you start the video. -Cut dead air. -Your playlists are in reverse order. Good video though, keep it up! You've got a great voice for this biz, that's the important thing. That library is freaking cool.
Nice article. David Beazley has an awesome screencast on how to do this without mypy, https://youtu.be/js_0wjzuMfc
Yeah as a matplotlib user who has followed but never really tried bokeh or plotly, I'm now a bit conflicted on which to try. My end product is generally a static image in a presentation or report, but I also do a lot of data exploration and tool development (where I use PyQt and PyQtGraph). Possibly use this in notebooks only? I just hate having to recreate the plots in matplotlib for later reports. Can plotly auto-generate static images or am I going to be doing screen shots?
Where can I learn more about the "hovermode" attribute? I want to make a map with clickable points, but cannot seem to figure it out. Awesome library btw! I'm loving this. I was working writing web apps and tools in python for a small company, but moved, so now I'm working in customer service. I could totally use this to build some tools that would make my work life a lot simpler.
Hopefully this will make it a little easier to understand what I want to do. Not sure if there is an easier way for me to do this or not. This is my current code. One of my bigger problems with this is that I have to click the link to save it so it automatically saves in my downloads as "Financial_Report", "Financial_Report (1), "Financial_Report (2), etc. So ideally if I had a list of 100 companies I would like the program to take the first stock ticker from the list and enter it as the ticker variable and then run the program again with second one and so on. Once this is done I want to save the data to a database I can navigate easily and then build queries to find information (stock-screener). from selenium import webdriver import time ticker = input("enter ticker") driver = webdriver.Chrome("C:\\Users\patri\Downloads\chromedriver_win32\\chromedriver.exe") driver.set_page_load_timeout(30) driver.get("https://www.sec.gov/edgar/searchedgar/companysearch.html") driver.maximize_window() driver.implicitly_wait(20) driver.find_element_by_id("cik").send_keys(ticker) driver.find_element_by_id("cik_find").click() driver.find_element_by_name("type").send_keys("10-k") driver.find_element_by_css_selector("input[type='submit']").click() time.sleep(1) driver.find_element_by_xpath("//a[contains(@href,'/Archives/edgar/data')]") and driver.find_element_by_xpath("//a[contains(@href,'-17-')]") and driver.find_element_by_id("documentsbutton").click() driver.find_element_by_id("interactiveDataBtn").click() driver.find_element_by_xpath("//a[contains(@href,'Financial_Report')]").click() 
Hopefully this will make it a little easier to understand what I want to do. Not sure if there is an easier way for me to do this or not. This is my current code. One of my bigger problems with this is that I have to click the link to save it so it automatically saves in my downloads as "Financial_Report", "Financial_Report (1), "Financial_Report (2), etc. So ideally if I had a list of 100 companies I would like the program to take the first stock ticker from the list and enter it as the ticker variable and then run the program again with second one and so on. Once this is done I want to save the data to a database I can navigate easily and then build queries to find information (stock-screener). from selenium import webdriver import time ticker = input("enter ticker") driver = webdriver.Chrome("C:\\Users\patri\Downloads\chromedriver_win32\\chromedriver.exe") driver.set_page_load_timeout(30) driver.get("https://www.sec.gov/edgar/searchedgar/companysearch.html") driver.maximize_window() driver.implicitly_wait(20) driver.find_element_by_id("cik").send_keys(ticker) driver.find_element_by_id("cik_find").click() driver.find_element_by_name("type").send_keys("10-k") driver.find_element_by_css_selector("input[type='submit']").click() time.sleep(1) driver.find_element_by_xpath("//a[contains(@href,'/Archives/edgar/data')]") and driver.find_element_by_xpath("//a[contains(@href,'-17-')]") and driver.find_element_by_id("documentsbutton").click() driver.find_element_by_id("interactiveDataBtn").click() driver.find_element_by_xpath("//a[contains(@href,'Financial_Report')]").click() 
I will try it
It throws an exception with your age. You can't concatenate (join together) strings and integers (numbers) like your age. So if you respond "12" it just crashes. You can fix it in a number of ways. One of them is to use .format which you can look up how to use at the end of the string. You could also turn the last Ascii robot face into a multiline string but it doesn't really matter. Regardless good job on your beginings into Python. 
&gt; response.content Interesting, why would you want the data in bytes? Seems like response.text would be more useful here.
Just glancing at the code it looks like you can pass it your own flask object: https://github.com/plotly/dash/blob/master/dash/dash.py#L38 
i've updated to response.text thank you for your input. 
Yes that might be a cool approach. Thanks for the reference links too.
You can probably run parts of this code in a loop where you iterate over the elements of your list. There should be no need to restart your program for every element in a list.
that sounds great, but JIT classes are already in numba and they are slow and limited. No way one can write fast stack allocated structures with them. They are also non generic and theor member ttpes have to be hardcoded. I could go on. This isn't to dog on numba but im wondering about future plans. Also no way to write code against interfaces. Not robust because features arent being written in the runtime itself.
/r/learnpython
Don't you need a MANIFEST.ini to mark your non python files for inclusion in the package?
Subscribed to DataCamp to learn Data Science. Also, trying to get a job as a data scientist.
Generators are really nice for building processing pipelines for some kind of data. Also nice to be able to go for x in blah: yield do_something(x) rather than my_list = [] for x in blah: my_list.append(do_something(x))
Following on from this... is Dash compatible with Zappa in that it's able to deploy to AWS Lambda?
Indeed David Beazley's screencasts are always great, but as fun and interesting as they are to understand what can be done in Python and how, they are almost the opposite of the OP's "in 10 minutes"-style article… 
&gt; it certainly wouldn't be Python Amen. It might still be a good language however, but their are others (such as D), that it would more directly be judged against.
Your problem is that with shell=False you're actually running `/c/WINDOWS/system32/convert`, and yes, that's the exact error it's giving you. Specify the full path to imagemagick's convert.
There's an interesting web framework based on it: [Nagare](http://www.nagare.org/), which builds stuff like the impressive [kansha](https://github.com/Net-ng/kansha), a trello clone. Nagare also allows to write html and **front-end code** in python, including ajax calls.
&gt; Specify the full path to imagemagick's convert. Sounds like not a pleasant solution if my intention is to make this script to work in Windows and Linux.
 if os.name == 'nt': ...
The path to ImageMagick is like this, `C:\Program Files\ImageMagick-7.0.6-Q16`. I suppose, this means, for every release I need to adjust the codes? Then no. I will stick on what I have now.
why not make your list into a tuple and use that as a dict key?
A write-up/blog post would be nice. Would like to hear your approach :)
I think only if you use include_data_files = True. Since I listed the files to include in my setup.oh they are included automatically. And I believe when I go into the Miniconda\envs\EnvForMyApp\Lib folder I will find those files installed there. Will confirm later.
crickey - it's that simple? i feel embarrassed now
It's a set of tools for experimental design. It provides the basic foundations for working with digital media, such as reading and writing JPEG, PNG, PDF, SVG, OpenType, STL or working with different color spaces. It also supports more higher level operations on text and images, such as type setting with kerning and different typographic styles, resizing images, rasterizing Bezier curves or rendering images with path tracing. Above that are Boolean operations on straight-edge polygons, tree-based layout for dataviz or the (temporarily gone) ruggedness line breaking of text to paragraphs [1]. It's written in pure Python so there are no external dependencies; hence for best performance use with PyPy. There is also an application called Even [2], which bundles Flat and a simple Python editor and viewer for easier usage. [1] http://xxyxyz.org/line-breaking/ [2] http://xxyxyz.org/even/ Here I pasted a small demonstration from the documentation, it should be roughly clear what it does just from the looks of it: from flat import rgb, font, shape, strike, document red = rgb(255, 0, 0) lato = font.open('Lato-Reg.otf') figure = shape().stroke(red).width(2.5) headline = strike(lato).color(red).size(20, 24) d = document(100, 100, 'mm') p = d.addpage() p.place(figure.circle(50, 50, 20)) p.place(headline.text('Hello world!')).frame(10, 10, 80, 80) p.image(kind='rgb').png('hello.png') p.svg('hello.svg') d.pdf('hello.pdf') 
check the content of soup, print it
I came up with this, probably this is the one of most simple solutions: https://repl.it/Ix2A/0 However if you are working with very large csv's I recomend pandas. If you need any help with that feel free to ask.
Absolutely not, quite happy to dump into .txt The above looks good - assume it would be compatible with my for loop? My loop passes in the ID (from 'Tloos.json') which forms the latter part of the URL - returning the JSON i need for each individual ID
What's the contents of Tloos.json?
Some big data reports based on impala/hadoop queries, and an inner tool for our sales people that allows them to automaticly take sceenshots on our websites(we are an online news company). It uses celery for task queue and selenium for taking the actual screenshot.
The json response from the below URL - i pass in the ID in order to query each individual toilet - the response is then saved to the output file https://greatbritishpublictoiletmap.rca.ac.uk/loos {"type":"FeatureCollection","features":[{"_id":"54c2346a2ec4abe957b8353a"},{"_id":"54c2346a2ec4abe957b8353b"},{"_id":"54c2346a2ec4abe957b8353d"},{"_id":"54c2346a2ec4abe957b8353e"},{"_id":"55bbaa8f0e6e9710006a3653"},{"_id":"54c2346a2ec4abe957b8353c"},{"_id":"54c2346a2ec4abe957b83540"},{"_id":"54c2346a2ec4abe957b83541"},{"_id":"54c2346a2ec4abe957b83542"},{"_id":"54c2346a2ec4abe957b83543"}, etc etc
Or the immutable list...
https://github.com/plotly/dash-goldman-sachs-report-demo
I have written a special protocol for tunneling tcp over a non-standard http connection. (Can't really go into detail). Are you new to programming or to Python? No matter the answer: - Go to sites like codeschool, codeacademy and do some free courses on Python. Python is very readable and easy. Have no fear, just make your hands dirty ;) - Install the python language on your pc (go to https://www.python.org/) and get used to using a text editor and compiling it with python. You can always reuse examples from the sites mentioned before to test your setup and learn debugging. - Than draw up the different steps of you project and write them one by one in functions. You'll be fine
That's awesome, I hope it turns out great
From the [benchmarks](http://c9s.github.io/r3/bench.html), the prefix trie is two orders of magnitude faster than pattern matching or "match entry with string", three orders faster than simple string matching, which I'd speculate no framework does. What I am unclear on is how to use this in existing frameworks, can I drop this into Flask or Django easily? How do I overload the default routing mechanisms in those frameworks?
Those files are not making it into the conda package. More interesting is that if I take the tar.bz file and unzip it I am not getting the expected Lib/site-packages/mygui/ directory like a colleague of mine gets in one of his packages using the same method. I am curious why this is happening and if this is the cause of the error. But I created the MANIFEST.in file and it is still not including the source files or data files in the build.
If you do windows, know that you need py3.5. They currently don't have it running on 3.6. 
Thank you very much! You've been very helpful!
Nice write-up! I personally really like `flask` for the ability to really easily wrap other python programs with a web GUI and just go. :) That said having used `flask` for a website for someone looking back I wish I had used `django` is like you said there was a lot of re-inventing the wheel.
So I think this write-up is okay, but the experience represented by the write-up doesn't correlate to my own. For really big projects, when you hit scaling issues, django sinks like a rock. And the reason is because it is monolithic and the prototyping and evolution on a larger project means that it generally lacks the modularity needed to really keep moving. Additionally, my experience is that while the RDB model is proven, most of the time, a large project will add a ton of non-standard technologies over time. And all of the extra features from the RDB models are unavailable with the new technologies. When evolving, the first step taken is to try and add these new things into the django framework, but ultimately, that's just adding technical debt. Because in the end, you have to (painfully) break everything up into microservices: and everything tends to be a some sort of REST API wrapping a service. My basic viewpoint is that django is great in the middle of the evolution. That's it's sweet spot. That's when the monolithic nature is great. But at the start? You don't need the extra weight and at the end you can't hold up the extra weight. So from start to finish, I have found Flask projects to be far more agile overall.
I'm not the most familiar with zappa so I might be doing something wrong, but a quick test using code from one of the demos [here](https://plot.ly/dash/getting-started-part-2), did not work. Code is in `dash_zappa.py` and `app` is a `dash.Dash` instance. zappa_settings.json has `"app_function": "dash_zappa.app"`. The error in the log is: [1498144700216] 'Dash' object is not callable Also, if doing fun data stuff the lambda function is like 50MB due to pulling in pandas and numpy.
http://www.cnbc.com/id/44261909
If the platform has stackless python, does that make it easier for any other python packages to run, for example pyglet or it doesnt imply anything like that?
We actually want to remove it in the next couple weeks. It was part of something else that we added...basically a side effect we don't want. Out of curiosity, what are your OS, browser and browser version? Thanks! :)
Thanks, very interesting read.
Good. Better for us fundamentalists to exploit Mr. Market this way
Haha thanks. I'm still learning python so it's going to be awhile before it really works. I'm hoping that people will add to it once it's out.
&gt; - completer now understand “snake case auto complete”: if `foo_bar_kittens` is a valid completion, I can type `f_b&lt;tab&gt;` will complete to it. - tracebacks are better standardized and will compress `/path/to/home` to `~`. Ooh, I like these.
sometimes it's better than trying to beat the market and inevitably fail.
Instagram uses Django, they do a great talk about it here. https://youtu.be/66XoCk79kjM moral of the story, Django does not have to sink like a rock at scale.
Ahh cool, makes sense, thanks for the explanation.
While David's Screencast is awesome, it is _not_ static type checking, it is dynamic type check, as the checks happen at runtime. Part of the helpfulness of tools like MyPy is that you can catch errors _before_ code hits production. Still a cool screen cast!
Why not both?
[CONTRACT PYTHON PROJECT in Austin or LA] Have you integrated payment processors with a website using Python &amp; Flask? If so, we want to talk to you! We've got a short-term project with a major brand and need someone to take on a portion of the work... Austin or Los Angeles preferred, but not required. Please ping me with your experience, availability and desired rate. Independent 1099 contractors only, no agencies or offshore.
Making a tool that will create powerpoints for ESL classes in just a few minutes.
Fundamental will never be dead. 
Unless you algo trade w/ alternative data. An algo running on sequential order #s from a retailer will still be in direct competition with fundamental guys since the input is still fundamentally based.
That's a great answer thank you, about GPU computations is Linux not supported by Cuda?
interesting. what did he say (if anything) about future type system, function dispatch or python interop improvements? 
You completely lost me at the first answer: &gt; Python doesn’t really allow multi-threading. It is possible to use a multi-threading package, but not advised. In truth threading happens so fast with Python, it’s simultaneous to the human eye. Multi-threading packages slow this down. This is so far off the mark I don't even know how to respond.
&gt; If you restrict Python to what can be statically typed, you nolonger have a dynamic language. It ain't Python! I'd just like to point out that nobody is actually trying to do this -- Python's type system deliberately contains all sorts of escape hatches to make it easy to jump back and forth between a typed and untyped world. For example, if you evaluate expressions at runtime, and have no idea what type you got back, you can simply give that value a type of `Any`, which means basically "anything goes". This lets you do things like this: from typing import Any def mysterious_action(option1: str, option2: int) -&gt; Any: # Do some dynamic magic, and return a value of # an arbitrary type # So, value is of type 'Any', and my_list is deduced to # have a type of 'List[Any]' value = mysterious_action("foo", 3) my_list = [value] # Type checkers will complain here, since lists don't have # a 'floobargle' method my_list.floobargle() # ...but will NOT complain here, since my_list[0] could # be anything -- maybe it *does* have a floobargle method? my_list[0].floobargle() Notice that `mysterious_action` or `my_list` both don't quite have a fully static type or a fully dynamic one -- they're both hybrid types. Despite the dynamicism, static types are indeed able to partially help. Later, you can use asserts, isinstance checks, or casts to conditionally bring your dynamic values back into the typed world if desired: if isinstance(value, int): # A typechecker will deduce that in this branch, # value is of type 'int' elif isinstance(value, MyCustomClass): # ...or is of type 'MyCustomClass' else: raise Exception("Uh oh") # A type checker can deduce that value is actually of # type Union[int, MyCustomClass] now, which is a bit more # specific then 'Any'. We can do the same sort of thing with runtime class generation as well, but you might be interested to know that mypy in particular is actually in the process of adding a "plugin" system to its type system so that users can modify the type-checking process to make it understands things like Django models (which is basically runtime class generation). Of course, the plugin system won't be able to cover the absolute full range of Python's dynamicism, but it can definitely cover a decent number of common use cases. I suspect other checkers like PyCharm are doing similar things (special-casing runtime magic done by popular 3rd party libraries). So, I guess the other point I'm trying to make static typing isn't necessarily an "all-or-nothing" kind of thing. You can use static typing-ish features like 90% of the time and use various escape hatches the other 10% of the time and mix the two to get the benefits of both static and dynamic typing. 
Hi, I have been developing in shiny for over a year. Does plotly require a login to use Dash? Could this be used in industry without logging into Plotly? I love plotly graphing libraries, but sensitive information and in house developments has led me to stray away from Plotly. Can someone tell me if I am mistaken? Is this ideal for a python alternative to shiny without the agpl license? Edit: After reading the article... what utility can you use with Dash before going Enterprise? 
There isn't anything which is convenient enough for the starting-out and mid-size cases, and which instantly flips a switch and continues working with no code/component changes at OMG WE'RE AS BIG AS GOOGLE scale. Not Django, not Flask, not *anything*. Part of scaling is that you will get rid of things that worked for you earlier and replace them with things that work for you now. So basing an argument on the need to do that is pointless -- you have to do that no matter what. The advantage of Django is that it saves you having to re-build, re-implement or integrate a bunch of things at the lower scales, and is still flexible enough to swap stuff out at the OMG scale. Also, most people will simply never hit the point when they do need to do that, so arguing against Django (or anything else) for this reason is like making life decisions just in case your lottery ticket turns out to be a winner.
IDK the only stocks I ever picked did well. I got NVDA last Feb for $29 a share lol, and recently AMD for $10.30. I'll admit AMD was speculative, but NVDA I knew would at least double. No viable competition in the AI space.
Today's announcement is that they're switching off *uploads* on the old server. That doesn't necessarily mean that downloads or the HTML interface are being switched over.
add wheel package, support linux and osx
I'm working on a bot to add a comment to posts that are short, low scoring, and are made by users with new accounts, or accounts which haven't posted to r/python or r/learnpython before. Right now I'm trying to use NLTK to identify if there's a question in the post, and then search stackoverflow for similar questions. If any SO results score high enough, I want to add them to the comment. There are a few problems I'm running into, which attest to /u/PeridexisErrant's comment: By the time I wait long enough to get a good estimation of the score, (give or take 4 hours depending on time of day) r/python has already had someone comment that op should post on r/learnpython. r/python crowdsourcing is just really effective. 
This project is not used in frameworks (such as django and flask), p3py is used in a low level, which is something like https://docs.python.org/3/library/asyncio-protocol.html, and for parsing headers it is better to use [httpparser]( Https://github.com/dontcare/httpparser)
&gt; And if they do is it really that hard to migrate a single Django 'app' from the monolith to it's own django or flask project (probably not)? Given you've not really hit that point, I'm not sure I can adequately describe the pain points. But they fall both within the political and technical side. Yes, it's difficult. The video elucidates that difficulty explicitly with Django with its own slide.
&gt; The advantage of Django is that it saves you having to re-build, re-implement or integrate a bunch of things at the lower scales, I've used Django and Flask. They're very comparable. The idea that you might need a plugin for Flask whereas django may already have that built-in doesn't make a great argument. The difference is generally one line in your setup.py or requirements.txt file. &gt; and is still flexible enough to swap stuff out at the OMG scale. And that's where we disagree completely. I can hit a golf ball with a putter off a tee, but that doesn't mean a driver wouldn't work better. Based on my own experience, Django is the putter at the "OMG scale".
Good catch - thanks! I've fixed it. It took me a while to settle on which five-digit number to use; at some point I decided that Jean Valjean's prisoner number had more going for it than the Beverly Hills zip code did.
&gt; Even that is off by one due to your X list: In Python 3: &gt;&gt;&gt; import sys &gt;&gt;&gt; sys.getrefcount(2) 475 &gt;&gt;&gt; x = range(1000) &gt;&gt;&gt; sys.getrefcount(2) 474 &gt;&gt;&gt; Because `x` is a generator instead of a list.
Right, but OP is clearly using python2. 
All of my dash use was completely offline when I was playing around with the draft version. It had to be as the volume of data I was sending was enough that there would have been serious lag if it wasn't being served locally. I bought the first tier subscription only because people were asking me to share charts with them and it was ridiculously easy to stick them up in a private link on plotly. I'm not sure if this version has changed that or not but I do know you don't need to host your data on plotly. I know I'm not, at least not until I explicitly tell it to export the chart. Perhaps you need an API key to initialize plotly now, I'm not sure. My key was already in there to enable chart export. Dash is just a wrapper to permit callbacks for your chart; just use the plotly offline python library to draw the charts themselves. I.e. anywhere you see it written "plotly.plot" you can replace it with "plotly.iplot" and it works exactly the same. 
I've rotated web2py to flask and Django to Flask and didn't find it to be particularly difficult; generally just time consuming and "busy work". Controllers generally validate inputs, run a function with the inputs, and format the output. The biggest pain-points are switching application specific extensions (ORMs, redis handlers etc) but nothing insurmountable. If you're just extracting a single part of django app (for example) to its own django app so you can independently scale it then it's even easier.
Almost all advice you read is bullshit, regardless of whatever air of legitimacy the source pretends to hold. People just make things up! It's like sports news. Think you found a strategy that provides an edge and can use Python to help you exploit it? You probably don't.
Some folks are working through this on GitHub now: https://github.com/plotly/dash/issues/22 However, to /u/MonkeeSage's point: a common pattern in Dash apps is for callback funtions to read (immutable) data from the global scope, especially if initializing that data is slow. For example, a Dash app might initialize a dataframe (e.g. through a SQL query or a remote CSV) when the app starts, and then the callback functions will read and filter that globally accessible DataFrame. If you don't have access to this global state in a functional environment like AWS Lambda, then you'll need to initialize that data in the calbacks instead of at the start of the app, which could end up being expensive.
Check out the second section of the getting started guide on interactivity: https://plot.ly/dash/getting-started-part-2. There is an example that shows how to access the `hoverData`, `clickData`, and `selectedData` which update when you hover, click, or drag-select over data points respectively. The `hovermode` attribute in the `figure` object doesn't actually affect this - it just affects which "hover labels" are shown by default: `"closest"` displays just one hover label (the one closest to your mouse), `y` displays all of the hover labels along the y-axis at your current x-position (e.g. if you have a time series with multiple lines, then it'll show a label for each line as you hover across points in one particular line), `x` does the opposite, and `False` turns off hover. You can see these options in the "reference" page of the Python library, which contains _every single configurable property_ of a plotly graph: https://plot.ly/python/reference/#layout-hovermode. You can also play around with these options in the chart creator, and view the underlying JSON attributes of the graph: https://plot.ly/create.
Son of a bitch.. I never knew Reddit was *this* helpful.
MiTx course on edx - just started to learn this amazing language
If you're on a Mac just open up Terminal, change your directory to wherever the script is located. If you don't know how to use Terminal that means, once Terminal is open, type: "cd Name/of/Directory/Here", without the quotes, and hit enter). Next type "python nameofscript.py" and hit enter (also without the quotes). That's it. OS X has Python already installed on it so it should run the script. Windows installations work about the same, you're using Command instead of Terminal but you can still use 'cd' to change-directory to your script and then type 'python nameofscript.py' and it should run. 
Thanks, I have only really touched the surface of generators and generator expressions before. I'll check it out.
There are a few options to pull a particular graph (it's current view) out of a Dash app: - There is a camera button on every graph element which will download the current view of the graph as a PNG. Here's a GIF of this in action: http://imgur.com/a/CAlGN - There is a floppy disk icon in every graph element that will open up the chart in a chart editor on plot.ly. Inside the chart editor, you can edit every aspect of the chart: the colors, the text, the data, the chart type, even add annotations. You also have access to the underlying data behind the graph in this view. To save the graph, you'll need a plotly account (free for public data, subscription for private data) but you can also just take a screenshot or use the camera icon in this view if you don't want to sign up. Here's a GIF of this in action: http://imgur.com/a/kvddQ. Here's a link to the chart editor too: https://plot.ly/create.
Thanks so much - I added your version to the post (crediting you). I love how prominent the references to the powers of two are in Python. Here's a version of your plot with the powers of two highlighted in red: http://groverlab.org/assets/sys_getrefcount_integers_4.png
Pretty sure he wants numba to use datashape, but I'm not clear on what that is. Just a general way to declare Meta information about the structure of a buffer. That is one of the key strengths about numpy and he sees the ecosystem of which numba and datashape are a part as numpy 2. I asked if numba would support (statically typed) dictionaries and he said when jit classes are fully realized people will make some and a defacto one will probably evolve. I'm not clear on your questions about dispatch or python interop. I don't see much changing there. What did you have in mind?
No worries. We'll do it the easy way. Start by uninstalling python and deleting the downloads for it and scipy. You don't need them. Then download and install Anaconda. Make sure you get the Python2.7 version (blue link). All done. Now you can doubleclick on the file your buddy gave you and it should run. 
Great. That sounds good. I'll try it and let you know. Before I do that, I have the code in an email. Can I just put that in a simple text editor and save as filename.py?
Great - glad to help out. The amount of powers of 2 is not really surprising if you've ever worked with bitwise operations. It's very common to have something like a status byte, where every bit in the byte is mapped to some boolean. For example we could have a single byte to represent if there is a keyboard, mouse, monitor, soundcard, printer, camera, scanner, and / or USB widget attached to the computer. 10100000 # keyboard and monitor detected, nothing else 01000000 # only mouse detected We get this data out with bit masks, which we usually assign a useful variable name: &gt;&gt;&gt; KEYBOARD = 128 &gt;&gt;&gt; MOUSE = 64 &gt;&gt;&gt; MONITOR = 32 &gt;&gt;&gt; status = 0b10100000 &gt;&gt;&gt; #is keyboard connected? ... bool(status &amp; KEYBOARD) True &gt;&gt;&gt; #is mouse connected? ... bool(status &amp; MOUSE) False So for this reason we have huge amounts of these variables assigned to powers of 2. The `stat` library comes to mind: &gt;&gt;&gt; import stat &gt;&gt;&gt; stat.S_IXGRP 8 &gt;&gt;&gt; stat.S_IWGRP 16 &gt;&gt;&gt; stat.S_IRGRP 32 None of this is python specific, it's common in all low level programming. 
It looks like you forgot to copy in the first three single quotes. Hard to say for sure without seeing the code. 
Fixed syntax error. Now get the following: runfile('C:/Users/Owner/Desktop/Heartstone.py', wdir='C:/Users/Owner/Desktop') Traceback (most recent call last): File "&lt;ipython-input-3-51c319dad410&gt;", line 1, in &lt;module&gt; runfile('C:/Users/Owner/Desktop/Heartstone.py', wdir='C:/Users/Owner/Desktop') File "C:\Users\Owner\Anaconda2\lib\site-packages\spyder\utils\site\sitecustomize.py", line 880, in runfile execfile(filename, namespace) File "C:\Users\Owner\Anaconda2\lib\site-packages\spyder\utils\site\sitecustomize.py", line 87, in execfile exec(compile(scripttext, filename, 'exec'), glob, loc) File "C:/Users/Owner/Desktop/Heartstone.py", line 6, in &lt;module&gt; from scipy.optimize import linprog File "C:\Users\Owner\Anaconda2\lib\site-packages\scipy\__init__.py", line 61, in &lt;module&gt; from numpy import show_config as show_numpy_config File "C:\Users\Owner\Anaconda2\lib\site-packages\numpy\__init__.py", line 142, in &lt;module&gt; from . import add_newdocs File "C:\Users\Owner\Anaconda2\lib\site-packages\numpy\add_newdocs.py", line 13, in &lt;module&gt; from numpy.lib import add_newdoc File "C:\Users\Owner\Anaconda2\lib\site-packages\numpy\lib\__init__.py", line 8, in &lt;module&gt; from .type_check import * File "C:\Users\Owner\Anaconda2\lib\site-packages\numpy\lib\type_check.py", line 11, in &lt;module&gt; import numpy.core.numeric as _nx File "C:\Users\Owner\Anaconda2\lib\site-packages\numpy\core\__init__.py", line 24, in &lt;module&gt; raise ImportError(msg) ImportError: Importing the multiarray numpy extension module failed. Most likely you are trying to import a failed build of numpy. If you're working with a numpy git repo, try `git clean -xdf` (removes all files not under version control). Otherwise reinstall numpy. Here's code as it is now: ''' hs_gto.py Calculates a game theory optimal deck selection strategy for hearthstone laddering. Utilities in the payoff matrix are based on win-rates from the tempostorm website ''' from scipy.optimize import linprog decks = ["Mid-range Druid", "Token Druid", "Mid-range Hunter", "Freeze Mage", "Mech Mage", "Secret Paladin", "Dragon Priest", "Handlock", "Demon Handlock", "Zoolock", "Control Warrior", "Patron Warrior"] # winrates for each deck from the tempostorm website winrates = [[50,50,45,75,55,45,40,65,60,35,70,60], [50,50,40,60,55,40,35,55,60,40,75,40], [55,60,50,35,40,35,40,50,65,45,55,30], [25,40,65,50,30,70,70,70,70,80,10,20], [45,45,60,70,50,70,40,60,40,30,35,55], [55,60,65,30,30,50,50,45,35,55,60,30], [60,65,60,30,60,50,50,20,25,70,40,50], [35,45,50,30,40,55,80,50,45,65,60,55], [40,40,35,30,60,65,75,55,50,60,60,65], [65,60,55,20,70,45,30,35,40,50,60,40], [30,25,45,90,65,40,60,40,40,40,50,60], [40,60,70,80,45,70,50,45,35,60,40,50]] def solve(decks, winrates): '''find an optimal strategy based on the given deck winrates. the number of decks must match the number of rows/columns in winrates''' num_decks=len(decks) # maximize the new variable z c = [0 for i in range(num_decks)] c.append(1) # calculate the payoff matrix from win percentages payoffs = [[u for u in [(j/50.0)-1 for j in i]] for i in winrates] # append a column of -1s to subtract z from each upper bound constraint for r in payoffs: r.append(-1.0) # inequality constraint right hand sides b_ub = [0 for i in range(num_decks)] # setup equality constraint so x forms a probability distribution ones = [1 for i in range(num_decks)] # leave z out of this formula ones.append(0) A_eq = [ones] # the x add up to 1 b_eq = [1] # x and z must be non-negative bounds = [(0,None) for i in range(num_decks+1)] solution = linprog(c, A_ub=payoffs, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds) return zip(decks,solution['x']) if __name__ == '__main__': print solve(decks, winrates) 
You're in r/Python, not r/Wallstreetbets. Take it as an example of an application of python in the real world, not as investment advice. 
Awesome!!! Thank you so much! Once again, great library! I &lt;3 it already.
What's preventing the use of both? Seems silly to split into completely separate camps if both answer similar questions. 
You can't win in a rigged market.
How would you differentiate quant and TA? In my mind they are both strategies that attempt to divine future changes in price based on historical changes in price.
I agree with your points. One thing I never understand is this love affair with microservices. If your /api/tweets/ endpoint (written using Django and Django Rest Framework) is getting *hammered*, why can't you just spin up additional instances of the entire app that only serve that endpoint? Any load balancer should be able to route /api/tweets/ to your pool of instances... And you preserve the benefits of *one* codebase and all the benefits that brings. 
Personaly no but others have e.g. [Installing numpy for Windows 10: Importing the multiarray numpy extension module failed](https://stackoverflow.com/questions/41664756/installing-numpy-for-windows-10-importing-the-multiarray-numpy-extension-module), just search for your error message and you'll get plenty more hits.
that's a weird way to recruit people!
Hi Novel, reinstalled Numpy and Scipy to version 0.16. Now getting this error: File "C:\Users\Owner\Anaconda2\lib\site-packages\numpy\core\__init__.py", line 14, in &lt;module&gt; from . import multiarray ImportError: DLL load failed: The specified procedure could not be found. Any ideas how I can figure out what dll is failing and how to fix? Thanx
Using yahoo finance as an api may not have much longevity. It lost a chunk of functionality recently, and that probably isn't the end of it. 
HEY NOVEL! GOT IT WORKING!!! THANK YOU FOR YOUR HELP!
very helpful, thank you very much
The average programmer saw major corporations and many maintained projects stay on Python 2, long after Python 3's release, and went "Golly gee, Python looks great, but I can't build on these old frameworks because it's obsolete already." Also, Python's performance is fairly lackluster, even in comparison to PHP7. It breaks my heart - because Python is syntactically superior to almost any language out there. https://blog.famzah.net/2016/02/09/cpp-vs-python-vs-perl-vs-php-performance-benchmark-2016/
I thought I needed Tkinter to do any sort of graphical interface for my program, but from what you're saying it sounds like there are means of importing images and imposing a grid on top. Then there would be no need for Tkinter. Are there means of doing so within Python. Thanks for the encouragement.
I hate writing html so I wrote a library to be able to render pug templates with optional jinja2 syntax through Python. http://journalpanic.com/ninjadog/
Whoops, sorry, no, use Tkinter lol.
Sorry I feel like my advice is all over the place. DnD boards are usually physically on a table, no? What is wrong with using Photoshop? That's the crux of my struggle to understand what you need any sort of language for TBH. You want to be able to, what, drag and drop characters? Simulate die rolls? Hold entire character sheets? No matter what I did not mean to say you shouldn't use Tkinter. I believe you should. I am not sure I can give you a better alternative. 
Long live the cheeseshop
I learned how to develop code in a pypi package! I posted it in the main subreddit, but would love feedback if anyone sees it here! It's code that interfaces with an I2C-connected LCD screen for the raspberry pi. [Github link](https://github.com/pwlandoll/i2c_lcd)
Some program as a goal unto itself, others just want to accomplish a business goal and move on with more business 
&gt; It's quite neat, unless you want more fine-grained control over, say, validation (for instance if you need complex validation involving full form state instead of just a few dependent fields). Although the validators assigned to individual fields of the DAL models (i.e., `Field(..., requires=...)`) typically validate only the individual field, there is also a mechanism for handling more complex validations involving the full form state. The form processing method takes an `onvalidation` callback, which receives the form object and can check any form values as well as set any form errors. (Note, it is also possible for an individual field validator to access other field values via `request.vars`.) &gt; Python 3 compatibility, last time I checked (2 months ago) is none, and one thing that would make me hesitate to recommend it. There will be a new release within the next few days, and among other things, it will support Python 3. You can try it now by running the master branch from Github (note, `--recursive` is necessary to get PyDAL, which is a Git submodule of the web2py repo): git clone --recursive git@github.com:web2py/web2py.git 
I think the "simplicity" of Python gives it a leg up even if performance isn't up to par with that of PHP or other web development languages (if we're talking about web stuff). Look at Instagram, they've taken Python and basically have it running on all cylinders possible. I can appreciate the need for performance, but when the performance comes with all sorts of quirks and stupid B.S. I'll take Python any day.
Model 3 does, along with a handful of other shells. Definitely grab a Pi when you can! They're a lot of fun.
Python seems like a good language to use for this &amp; that's a GREAT idea! Please share when you've got a good skeleton of it! Will you include dice rolls &amp; other player-interactive things, or just use it as a visual DM tool?
Has anyone made a Python Mailing list viewer? Basically identical content but a modern look to it? edit: Ignore the f.lux colors, but a ubersimple boostrap include [change makes all the difference](http://i.imgur.com/j1UrTCO.png?1)
Pycoders weekly
I recommend one of the basic kits that comes with an sd card pre-loaded with noobs. It guides you through installing the raspbian os, which GUI-wise is similar to a stripped down ubuntu. I'm not terribly familiar with Redhat, so I don't have much input on that, but without a doubt there are videos showing the ins &amp; out of the os. I'm personally still figuring out my flavour of choice, because ubuntu is too bloated imo.
&gt; For really big projects That's arguably a corner case, no? &gt; But at the start? You don't need the extra weight What extra weight though?
&gt; One thing I never understand is this love affair with microservices. A couple companies have had success with it... and technically, it's a resurgence of an old concept -- SOAP was kinda aiming for this multiplicity of web services talking to each other too.
Thank you I will look for that when I Purchase my starter kit
Nice, unopinionated article. It's amazing that it was upvoted both in Django and Flask Reddits! 
Implying Laravel isn't cleanly designed? Besides, there's nothing wrong with liking both PHP and Python. I like both.
English is dumb. You should write this in Sanskrit.
I'm hoping to include statistics like character speed and health move and remove player characters and NPCs from the map as they die. So I think I will need to use Python, or some sort of language, for the task. I appreciate the advice. :)
You can't win in an honest market either. That's how markets work.
Yeah only if Indians cared to colonize more than half of the world!
Guido made the choice to prioritize usability and syntactical pleasure over performance, and redirect people to write extensions in C/C++ if must. Maybe correctly so, as no scripting language is winning C/C++ in performance any time soon. Just focus on what you do best.
90% of time is spent in 10% of code so Python performance is annoyance at most, certainly not a deal breaker.
What language would be suitable in your opinion for building something like Sandboxie? I generally am a 'do it yourself' kind of person when it comes to anything with a computer. I might give in and use Sandboxie, but I'd like to take a look at how I could build one myself so I can gain a better understanding of what sandboxing really is. I want to Sandbox games, I wrote a fishing assistant program in python for a game I play but it needs the game window to be the current active window in order to send commands, so I am forced to run it on my other machine and stream it using Steam streaming so that my fishing assistant doesn't interfere with my work on my main machine. The program I wrote runs on the host machine, along with the game and is streamed to the guest machine which is my main machine. I can't implement a solution using a Virtual Machine because VMs can not access my physical graphics card and therefore a VM can not run my games.
What I find funny is that the bottleneck is almost always db access or some sort of I/O no matter what language you pick. I really don't care if Java does it in 1ms and Python in 25ms if both are making a 1 second SQL query. I've easily made performance improvements by about 10 fold simply by cleaning up code and database queries, little oversights here and there where you missed a much better approach. Bad code will be slow no matter what language it's written in, and more often than not your bottleneck is going to be something crazy inefficient even in a high performance language. And it seems like 90% of the people I work with never profile their code... I showed a developer how to profile their code a few weeks ago and they have 20 years of experience. If someone complains about the language's performance, ask them: Did you profile the code? Does your program do any lengthy IO? Any places where you're using the wrong/slow algorithm? ... Did you profile the code, ever? Not once? There legitimately are times when you need high performance, but not equivalent to the number of people complaining Python Is Slow. Python can't do everything (but it can do close to everything if you consider writing libraries in C). I always think back to this one professor in college who taught queueing theory and high performance computing. He said something like: "Don't attack performance randomly... find the bottlenecks and focus on them." And I've rarely ran into the bottleneck being Python.
Instagram uses Python precisely because it reduces time-to-market.
Instagram is powered entirely by Python, and it is handling tons of traffic.
Do a dry run.
Well, if human migration theories are correct, they did... and their descendents also eventually invented English.
Those java fams get restless at times.
Laravel is a framework, not a language. This quote is towards programming languages.
I never understood the appeal of pug. Yes it's less verbose, but since it's also less clear, your mind has to work way more to parse the code. So you actually make it easier to write, and writter to read. But I read code much more often that I write it. 
The table definition is entirely up to you. You can define your models however you feel like. The session in `session.get('auth_email')` is different from the `SQLAlchemy` session. The one you're refering to is the HTTP session provided by flask (which looks like a wrapper over session cookies), while the `SQLAlchemy` session is related to your database connections. Basically, the only `SQLAlchemy`-related thing you need to handle when using `flask-sqlalchemy` is committing the database session. The rest is plain `SQLAlchemy`. Maybe [this](http://flask-sqlalchemy.pocoo.org/2.1/quickstart/#road-to-enlightenment) also helps.
Chinese characters are *inarguably* more complex than the Latin alphabet. This is even true for Chinese people! Being experienced doesn't make them less complex, it just means you've put more effort into learning them.
Whether I use Python (numpy), C++, Fortran, or some combination of these completely depends on what task I'm planning on doing. You can do anything with anything, but sometimes it's easier to write two lines of python than a hundred lines of c++, sometimes it's easier to write out the algorithms and data structures explicitly in c++ than to try to figure out the tricks to make python fast enough, and sometimes things are modular enough that you can wrap your c++ in some friendly python. It just comes down to the task and you preference. Edit: plus you can write horribly unreadable code in Python too, it's just different. It's usually when you try to be clever and put everything into one line using list comprehensions and vector operations, and you end up with a giant mess of a line that feels very smart but it's hard to decode
Stop forking stuff and adding dumb things!
I always thought they played different games too. fundamentals played long term and technical played short term.
Yeah, I guess my point was that when you get to that point of experience, they aren't as hard anymore. So, I guess what I'm really saying is people who complain about C++ or Perl being ugly or "poorly designed" and "hard to read" are mostly complaining cause they didn't put the effort into actually learning them. This isn't true for *all* cases, of course, but I'd say the majority. I know people who programmed C++ all their career and can't, for the life of them, understand Python's internals, for instance.
&gt; You can actually see the number 257 specified as the constant NSMALLPOSINTS in the C source code for Python. Looking at the plot above, 257 seems like an excellent choice for this cutoff; the integers above about 200 are mostly being used in less than 10 places in Python (except for the outliers 255 and 256) so sharing references to these integers will be less effective. Might be interesting to extend the plots to see NSMALLNEGINTS?
I don't own a house, my dude. Kept 5k cash and put my other $10,000 on it though.
From the SQLAlchemy documentation - &gt; A Session is typically constructed at the beginning of a logical operation where database access is potentially anticipated. This means, avoid having a global `dbsession` object across your entire app. Instead, initialize a new session for every new request and tear it down as soon as the request is finishde. SQLAlchemy sessions wrap their operations in transactions, unless you explicitly commit/rollback. So if you use the same session object from multiple locations, you might run into trouble. Looks like [before_request](http://flask.pocoo.org/docs/0.12/api/#flask.Flask.before_request) is where you could obtain a new session and [after_request](http://flask.pocoo.org/docs/0.12/api/#flask.Flask.after_request) is where you could tear it down. Also, make sure you're handling any exceptions thrown by your application code - meaning that you should commit the session at the end of the request, but if there is any exception then you should rollback your session so that any previous database changes are rolled back as well. `SQLAlchemy` has pretty good documentation regarding this - http://docs.sqlalchemy.org/en/latest/orm/session_basics.html#session-faq-whentocreate`. This gives a really nice overview of how to use and manage your database sessions. `flask-sqlalchemy` is helping you avoid all this work, so I would highly recommend switching to it. However, if you don't want to use it, then I would really suggest that you write your request handlers keeping [this](http://docs.sqlalchemy.org/en/latest/orm/session_basics.html#session-faq-whentocreate) in mind.
c++ isn't even ugly but perl can be annoying even if you wrote the code yourself 
If you want a great language design you would favor c over most others
Seems questionable. I'll take a statically-typed language over a dynamically-typed language for largescale production software any day. Or maybe they just don't debug. That said, I absolutely adore Python for small tools and scripts.
Decided it's about time I started to learn Python. Going to aim to write a Discord bot as a means to learn, along with playing with some API's. Java programmer by default but have dabbled with other bits and bobs via work. Been using the "Automate the boring stuff" tutorials as it seems like a fairly fast paced introduction to it all, showing me syntax differences etc which are the main things I need to grasp. Have noticed that there's no lesson specifically labelled regarding classes etc in Python though... Any recommendations on other tutorial sites/books/courses that maybe delves a bit deeper for more advanced knowledge later on? 
To be honest, I have no clue whatsoever how being a hyperactie weasel on LSD would affect design choices. If we decide C++ is not pretty, I wonder just how pretty a language with as much control as C++ could be. Just like in advanced math you start to run out of symbols for everything and need all kinds of letters from all kinds of alphabets.
&gt; trouble defining the proper way to do for-each loop What do you mean?
Awesome, I followed a similar approach while setting up things at my end using [tornado](http://tornadoweb.org), partly because nothing like tornado-sqlalchemy exists so I was forced to, but partly because I thought - well I'm using SQLAlchemy, might as well know how it *really* works. Good luck!
&gt; Isn't YouTube also written in Python? Not really anymore.
[While you're optimizing some feature for a bit better speed - others are writing new features](https://en.wikipedia.org/wiki/Amdahl%27s_law#/media/File:Optimizing-different-parts.svg) You might even find the code you're optimizing is going to be thrown out... 😭 **BUT**: I want to avoid anything that's bigger than O(logn) I want to avoid un-indexed queries. I want my code well tested. I want my code clean. Any code base that has these features can be more-easily ported or parts of it optimized. This wish list can be accomplished while you're being diligent writing it.
Linux and latest Chrome stable.
I've been hands-on learning Kong API manager by plugging in a demo web app built using Python + Flask and Swagger-UI, with Vagrant to manage my virtual machines.
If you need performance, there are many ways to get better performance out of Python these days. The quickest one is changing to PyPy.
Well, it obviously works for them. You still have to write unit tests for a statically-typed language, since compile-time checking does not catch most bugs. A static language does not protect you from buffer overflows, segmentation violations, or logical errors in your program.
thanks mate but I am newbie to programming and learning python as my first language. SO I have no idea what you wrote. Can you please explain me better and simple? 
&gt; I'll take a statically-typed language over a dynamically-typed language for largescale production software any day If you know for certain you'll have a large number of users then yes. But when starting a company based on an idea that's not certain to succeed (at least with out iteration/pivoting) and when you're still honing the idea of your business, having something that's more flexible and quicker/easier to write is a bonus. If Python can't scale in the way Instagram now want, they may start replacing it bit by bit á la Twitter. I use Ig quite heavily and it feels super-fast, so I don't think they're at that stage yet.
&gt; not equivalent to the number of people complaining Python Is Slow. Python can't do everything You're missing the other side of the coin. Your Python program may be fast enough for what it does, but Python's slowness also puts limits on what else you could do. If you used Go instead, which is 10–20 times faster, then suddenly you have a lot of possibilities that are simply off the table in Python. &gt; (but it can do close to everything if you consider writing libraries in C). That's not Python any more, is it? The bottom line is that improving the speed of Python requires a lot of jumping through hoops. Rewriting parts of your program in a different language, or dicking about with `multiprocessing` to work around the GIL. &gt; And I've rarely ran into the bottleneck being Python. You've never had issues with the GIL? 
The Firefox "Reader View" works quite [well](http://imgur.com/Sxjgqnm). I have to play with the text size and width to avoid ugly wrapping but that's pretty easy. 
I'm still in uni atm, but I've never heard of profiling your code before, definitely something I'm going to be looking up.
What is it in now?
Interestingly I have been looking into this topic recently and have concluded that it's impossible to choose the right tool based simply off weather its static vs dynamic. I would choose clojure over Java for a large project. 
What are the programmers that think they're shit but in reality are average? 
Hi /u/wowtheinternet Could you please provide a title related to the problem you are facing, and indent the code in you message ? It would be easier for the community to try to help you :)
&gt; chinese characters are indeed very difficult and complex - objectively speaking. Considering there's more than a billion people who can deal with Chinese characters without issues, you might want to back that statement up.
**Indo-European languages: Diversification** The diversification of the parent language into the attested branches of daughter languages is historically unattested. The timeline of the evolution of the various daughter languages, on the other hand, is mostly undisputed, quite regardless of the question of Indo-European origins. Using a mathematical analysis borrowed from evolutionary biology, Don Ringe and Tandy Warnow propose the following evolutionary tree of Indo-European branches: Pre-Anatolian (before 3500 BC) Pre-Tocharian Pre-Italic and Pre-Celtic (before 2500 BC) Pre-Armenian and Pre-Greek (after 2500 BC) Pre-Germanic and Pre-Balto-Slavic; proto-Germanic ca. 500 BC Proto-Indo-Iranian (2000 BC) David Anthony proposes the following sequence: Pre-Anatolian (4200 BC) Pre-Tocharian (3700 BC) Pre-Germanic (3300 BC) Pre-Italic and Pre-Celtic (3000 BC) Pre-Armenian (2800 BC) Pre-Balto-Slavic (2800 BC) Pre-Greek (2500 BC) Proto-Indo-Iranian (2200 BC); split between Iranian and Old Indic 1800 BC From 1500 BC the following sequence may be given: 1500 BC–1000 BC: The Nordic Bronze Age develops pre-Proto-Germanic, and the (pre)-Proto-Celtic Urnfield and Hallstatt cultures emerge in Central Europe, introducing the Iron Age. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot/) ^] ^Downvote ^to ^remove ^| ^v0.22
&gt; sometimes it's easier to write out the algorithms and data structures explicitly in c++ than to try to figure out the tricks to make python fast enough, and sometimes things are modular enough that you can wrap your c++ in some friendly python I totally agree. I'm fairly new to Python, and recently had to write some scientific code in it. I'd heard that Python could be nearly as fast as C, and seemed so much more user friendly, so I figured this would save me time. How wrong was I. Sure - if you program very carefully, and have a very deep understanding of the language and it's subtleties I'm sure it's possible to make it almost as fast.... but for me this meant endless googling and reverse-engineering of every "nice" python function to try to figure out how it worked under the hood and trying to second-guess what it was going to actually do, in order to make it fast enough. In the end I realised that I was wasting far too much time doing this (and my Python code was becoming a confusing unwieldy mess), and just wrote it in C++. I just finished it yesterday actually and ran a side-by side comparison - the C++ code is ~84 times faster, unoptimised. Lesson is to choose the right tool for the job of course.
&gt; A static language does not protect you from buffer overflows, segmentation violations Unless that language is Rust.
&gt;What is it in now? Moving from Python 2.7 to Go, [grumpy](https://github.com/google/grumpy) gives you an idea of how they're achieving that. 
I find that the Python code does usually end up more concise and therefore easier to maintain. But writing it in the first place takes more effort, because you really have to go digging through the documentation to find the exact right numpy function to do what you want. It gets especially tricky when you find three or four functions that all appear to do very similar things, and it's really not clear which one is best for your situation without going deep into how they all work. Like with plotting/visualisation there's hist2d and histogram2d, which seem to do basically the same thing, and pcolor, pcolormesh, and imshow, which all also do basically the same thing. Overall, it's not always faster to code in Python, because you just spend your time trying to figure out the API for the library to get it to *almost* do what you want, instead of writing it out explicitly to do *exactly* what you want. Of course, the trade-off is that the C++ code is probably six times longer. Wrapping in Python can be really powerful though. Wrap up your C++ or Fotran code into a Python library that does all the nitty gritty stuff, and call it from Python, using matplotlib to plot things up. That's how I do my galaxy &amp; AGN animations these days.
r/learnpython
Concise... probably agree... but 'easier to maintain'... I'm not so sure. Looking at my own C-code, sure, its long, but I can see clearly and explicitly what it is doing, with little ambiguity (there are no 'black box' functions... since I had to write most of them myself). If I looked at my Python code again six months from now and wanted to change something I'd probably have to go googling and digging into all the documentation all over again. Essentially, all the 'documentation' that I would need to search for to understand the python code is there directly in the source code in the C file, because I wrote it myself! Perhaps I'm a little biased though because I've been writing C longer than python. It's certainly very nice when speed is not a major concern. I did actually end up wrapping it in the end. That's definitely going to be my go-to approach in future.
This from a python programmer? Bplz.
As a webdev I can tell you that only requests is a library I can't live without since I've never used any of the other ones. I've played with them but nothing serious. ;)
So, you're paying extra for additional compute. Translate that to a number of development hours and assess if it's worth using an other, arguably slower to write, language and do (premature) optimizations.
Try cython or numpy before restructuring python code, especially if is scientific code with any tight loops or large arrays of numbers.
Microservices are aimed to solve a business problem: we need a couple of dozen programmers on different teams with poor cross-communication to work on a thing together. Splitting it into microservices makes it easier for those teams to do their thing and then throw it over the wall without coordinating. For basically every other scenario, a microservice is strictly inferior to a well designed monolith, and even in this case, they don't work especially well since you can't actually make something work by contract. 
That depends entirely on what kind of program you're writing. I mean, what would you *like* to be able to do but can't because it hurts performance too much? Perhaps you'd like to use [a fuzzy search algorithm](https://blog.forrestthewoods.com/reverse-engineering-sublime-text-s-fuzzy-match-4cffeed33fdb), but native Python makes it unusably slow with more than ~1500 items. So you have to use a simpler substring search instead. Go, or a C library for Python, runs 10–20x faster, which means you can easily handle ~20000 items before the fuzzy algorithm becomes too slow. That makes it viable in a lot of situations where it wouldn't be using pure Python.
SUMMER JOB FOR 2 PYTHON APPENGINE developers in Netherlands We're looking for 2 Python + app engine developers for a summer job in NL, to build part on an industrial production planning app. Work is remote. We'll have regular standups via skype during the week and some face to face contact also. Interested? Contact me at: kxtronic@gmail.com
JavaScript's basic data model is also very different from python's. It's fine for fairly simple browser stuff but Python is a lot cleaner. Indexing and attribute access being the same makes iteration confusing, their type coercion is really odd, and they seem to really like "undefined" instead of raising an attribute error right where the problem is.
Interesting, can you explain to me hoe you reverse engineered the python? Any functions in particular? Also, how were you comparing the speeds? I'm only a second year computer systems student, but I'm pretty interested to learn!
 &gt;I've easily made performance improvements by about 10 fold simply by cleaning up code and database queries, little oversights here and there where you missed a much better approach. Have you got any examples that you can recall of these types of mistakes? 
How to implement work through a proxy server? And the ability to change the proxy for each new conversion import asks import curio async def example(): proxies = { 'http': '162.244.134.196:8080', 'https': '162.244.134.196:8080', } r = await asks.get('https://example.org', proxies=proxies) print(r.content) curio.run(example())
Or Java, C#, Scala, Haskell, Swift, or Go, and there's a whole more
&gt; So, you're paying extra for additional compute. Or to look at it the other way, limiting the number of concurrent requests you can serve.
Bloody Go programmers. They won't be happy until the whole world has been rewritten in Go. And then they'll still be unhappy; they just won't be allowed to admit it.
Tell that to the insurance companies who had to pay out over Ariane 5.
Firstly, this is really great and it's nice to feel like we're drawing level with those dumb R guys. ;) Secondly, is there any way to access the data component of a figure directly from an `@app.callback` method? I've mocked up a little app which contains a mapbox map and a slider, but when I use `@app.callback` with the slider as input and the `Graph`'s `figure` as output, it reloads the map, which seems unnecessary and makes the UI a bit clunky. 
Why do people keep referring to Orwell's "The thing that is in Room 101 is the worst thing in the world.“? Is IT really that bad? :-)
Indeed, OP's quote would lead us to believe that the ideal programming language would allow only the number 1 and those 1's must be evenly and symmetrically spaced. Sure, it's limited in functionality, but it's elegant as all getout. Meanwhile people like myself (a professional Python programmer) choose to use a language like Perl for its robust suite of easily slung text processing tools, e.g.: $ perl -i.bak -pE 's/\b([\d+]+)/$1/eg' foo Aesthetically elegant? Of course not! Extremely handy to be able to sling around? Oh hell yes! Use the right tool for the job. 
How to wrap C++ and Fortran? I'm not an expert, but a few lines of makefile magic makes it work well enough that I don't really need to think about it much. Otherwise, your google-fu is as good as mine. For Fortran, my makefile is just: pyread: f2py --opt=-O2 --f90flags="-Wall -mcmodel=medium" --f77flags="-Wall -mcmodel=medium" -c sph_plotter.f90 -m sph_plotter For C++ it's: interplib: swig -python -c++ -o _tab_interp_module.cc tab_interp.i python setup.py build_ext --inplace where setup.py is just: from distutils.core import setup, Extension extension_mod = Extension("_tab_interp",["_tab_interp_module.cc", "dust_temp_interp.cpp"]) setup(name = "tab_interp", ext_modules=[extension_mod]) and you might have to `apt install swig` too. It's actually simpler to wrap Fortran than C++, which is fun.
&gt; If you used Go instead, which is 10–20 times faster, then suddenly you have a lot of possibilities that are simply off the table in Python. Well, maybe. That depends on what those possibilities are. But more likely: * I'd rather write a Python program in a day, and run it in an hour to get the result I need; * rather than spend three months learning Go, to spend a week writing the program, to run it in 6 minutes, to get the answer I needed ten weeks earlier. Your mileage may vary, depending on whether you already know Go, what the task is, etc. Generalizations are difficult. &gt; That's not Python any more, is it? Ah, how quickly we forget... Python was created as a glue language, and moving critical code into faster languages like C and Fortran is still one of the most powerful features of the language. It's not "Python code", but it is absolutely part of the Python workflow. Find the 1% of your code that is the critical bottleneck, and write it in C or Fortran, (Or Java, if you're using Jython.) Basically, you can think of Python as an awesome C library with DSL that lets you be *amazingly* productive when calling it. That DSL is great, but sometimes you need to drop back down to C. I just wish that there were more options beyond C, like D, Forth, Haskell, or Julia. Or even Go :-) &gt; or dicking about with `multiprocessing` to work around the GIL. As opposed to dicking about with threads, dealing with non-determinism, deadlocks, livelocks, and all the other horrors you have to deal with when you use threads. I've come to decide that [threads are the wrong answer](http://radar.oreilly.com/2007/01/threads-considered-harmful.html) to almost every question. You do know that `multiprocessing` and `threading` use the same API? You should be able to pretty much swap out one for the other and it should "Just Work". (At least in theory.) &gt; You've never had issues with the GIL? Nope, never, not in 15 years of using Python. I'm sure you're the exception, the one in a thousand case of somebody who actually does run into limitations due to the GIL. But in my experience, people who say "Python sucks because of the GIL" are usually blaming the GIL for their own poor code. As I say, there are exceptions, but I've seen people blame the GIL for their poorly-performing *single threaded* code. 
How about using a list instead of a hash table, or how about doing a SQL query then doing a query for each result? Or even better, query, then web page, then ajax query x 2 for each query result. And they wondered why it took 2 minutes to load.
Until you run into the off-by-one errors, failing to handle the error because it and the return value are one and the same thing...
That would be Python core developer Steven D'Aprano.
Christ, I haven't used Fortran in almost 30 years now...
&gt; Jokes on them, there are no average programmers because the average programmer thinks he's better than the average programmer so actually we are all rockstar senior ninja programmers. FTFY 
This would be cleaner if you wrote it in a incoherent map function. 
Why don't you use Twilio for the SMS part? Lately I've experimented with Pushbullet for sending myself actual push notifications on my own devices.
&gt; That's not Python any more, is it? C integration is very important reason why Python matters and maintaining stable C API to Python code is strongly limiting options to improve performance of pure Python code. 
The JIT wouldn't have to be enabled by default, which solves the startup time problems you mentioned. PyPy is not a solution because no relevant distro includes it by default, and because there is no compatibility with existing libraries. If cPython went and said 'after the next major release there'll be a JIT that works so and so' the standard library and all widely used libraries and frameworks would adapt to it. As long as it's just PyPy it's on the sidelines, and people actually concerned about the computational speed of their code won't choose Python. This is sad, because Python is a beauty. &gt; Adding a JIT to CPython might, maybe, make parts of your code faster Huh? Running my code on PyPy makes it almost always faster, sometimes 5%, and sometimes 20x. Performance matters. &gt; increase the complexity of CPython, reduce the number of people able to work on it The JVM and the CLR have JITs (and probably more runtimes that I don't know of). cPython shouldn't be simple for the sole reason that novice software developers can understand it, because it is the most widely distributed Python implementation. It should be fast. Let there be a simple implementation for educational purposes, fine. &gt; and generally lead to a worse overall experience How so? 
Modern Fortran is very different. It's got objects &amp; classes &amp; array-based operations, and no more 72 characters per line limit nor having the first 6 columns specially reserved.
That's called "[imposter syndrome](https://en.wikipedia.org/wiki/Impostor_syndrome)".
&gt; , I guess my point was that when you get to that point of experience, they aren't as hard anymore. And that's why we should all program in assembly language! Because after 30 years of experience, assembly is no harder than Python or Ruby!
&gt; Ah, how quickly we forget... Python was created as a glue language, and moving critical code into faster languages like C and Fortran is still one of the most powerful features of the language. You already rebutted that one yourself: &gt; rather than spend three months learning Go Except make that much more than 3 months to learn C. &gt; I've come to decide that threads are the wrong answer to almost every question. That may be true for the questions you ask. &gt; You do know that multiprocessing and threading use the same API? Yes. In fact, most of the time I use threads, I use `multiprocessing.dummy.Pool`, as it has a nice API where you don't have many problems with &gt; non-determinism, deadlocks, livelocks, and all the other horrors you have to deal with when you use threads &gt; it should "Just Work". (At least in theory.) It doesn't. There are extra hoops you need to jump through because it's starting separate processes that need to import your code and pass your objects between processes. &gt; I'm sure you're the exception, the one in a thousand case of somebody who actually does run into limitations due to the GIL. If all you, and everyone you talk to, use Python for is glue code, I dare say there's some truth to this. If you're trying to write an entire program in Python, as opposed to merely prettying up some data you've pulled from a database, then it's a very real obstacle. Python threads work fine for downloading a bunch of files in parallel. If you also want to parse them, then the GIL says you only get to use one of your cores for that. Unless you make your code (and any libraries you may be using) `multiprocessing`-compatible, write a C library, or just write the whole damn thing in a language that can use multiple cores to begin with. &gt; As I say, there are exceptions, but I've seen people blame the GIL for their poorly-performing single threaded code. If that kind of person is the rule rather than the exception, you spend too much time with terrible Python programmers. 
In varioius sublevels of my package, I import using star all of the submodule tests. I then include a `__main__` call to `unittest.main()` so it doesn't duplicate tests. I can then run `all_tests.py` and it's going to find all the tests I care about. I haven't figured out how to reproduce that behavior.
&gt; who can deal with Chinese characters without issues Do you think Chinese people can [enter ideograms on the computer](https://en.wikipedia.org/wiki/Chinese_input_methods_for_computers) as quickly and easily as Westerners can touch-type? I count 21 different input methods for Chinese, and a speed of perhaps as many as 200 characters per minute for experts. Touch-typists can easily reach 40 words per minute (approximately 200 letters plus 40 or so spaces) and experts can reach 100 wpm (600 characters or so). Just because Chinese people *can cope* with Chinese characters doesn't mean that doing so isn't objectively more difficult than some other systems.
**Chinese input methods for computers** Chinese input methods are methods that allow a computer user to input Chinese characters. Most, if not all, Chinese input methods fall into one of two categories: phonetic readings or root shapes. Methods under the phonetic category usually are easier to learn but are less efficient, thus resulting in slower typing speeds because they typically require users to choose from a list of phonetically similar characters for input; whereas methods under the root shape category allow very precise and speedy input but have a difficult learning curve because they often require a thorough understanding of a character's strokes and composition. Other methods allow users to write characters directly onto touchscreens, such as those found on mobile phones and tablet computers. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot/) ^] ^Downvote ^to ^remove ^| ^v0.22
And it's not as productive or portable or fun as programming in Python. Hence my statement "that's not Python any more, is it?"
I know but I'm saying that PHP *can be* cleanly designed and work quite well, look at Laravel as an example of that.
The pytest command automatically find recursivelly all the tests, and run them without duplicates. You can even filter the tests with pattern matching. So my guess is that it's hard to find a good tutorial on how to do just that with pytest ?
Because I don't have the day or so it'll take to work through my testing package and make sure everything works when I'm on a deadline to deliver new features to users? Would leave to convert my `unittest`s to `pytest`s. Ain't got the time, and if it's not broken, I'm not wont to fix it just for the sake of having the shiniest tool in the shed.
I don't want it to recursively explore directories. I want to tell it. I have another `test1.py` file that I want to only run when I call that file. I import that in one `all_tests.py` file and chain import that file.
If you were a construction worker you wouldn't want to put bricks where they don't belong either ;-p if you aren't capable of programming no language will help you.
Thank you for the reply! I will definitely be automating tasks at work. That reminds me, do you have any recommendation for tutorials or material for working with excel using Python? 
You can pass `pytest` (the terminal command) the top level directory or the specify file you want to run or even specific tests in the file. https://docs.pytest.org/en/latest/usage.html#specifying-tests-selecting-tests 
Not handy, sorry. The issue is with fixtures that help automate some setup/teardown and to my knowledge, I'd have to do quite a bit of small tweaks to the code for pytest to work correctly. Maybe not as much in recent versions but still - I have better things to do than adapt them. For new projects I'd be happy to start right away with pytest.
What do you mean? Automating things *inside* Excel or reproducing work-flows you'd otherwise use Excel for? If it's the former, then no - sorry. If it's the latter, then just [ingest your data into the scientific Python stack](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html) and proceed from there. Or you an take it a step further and cut Excel out of the mix entirely, and ingest directly from your raw data sources and do all of your munging/pre-processing in Python.
&gt; Python2 --&gt; Python3 was a failure in many ways The transition from Python 2 to 3 is only a failure in the minds of childish and ignorant "internet experts" who think that the transition from one major dialect of a programming language to another should be trivial. The transition hasn't been perfect by any means. In the early days, the core devs over-estimated the differences between 2 and 3 and advised people to keep two distinct code bases. That was a mistake: it is usually easier to keep one hybrid 2+3 code base. They also slightly underestimated the time it would take for the transition, and so have had to extend support for 2.7 for a few more years. But, broadly speaking, uptake of Python 3 is roughly where they expected it to be at this time: we're past the early adopter stage, the majority of important libraries support it, and now mainstream developers are starting to move towards it. At least those who don't intend to stay with 2.7 forever. &gt; and sugar coating it by too much just doesn't contribute. Since the divide other orgs have come up with a bunch of ways for speeding up the process for upgrades Such as what? Can you give some examples of other hugely popular languages which have managed the transition between two incompatible dialects How about Perl 5 and 6? There's a reason why, for the most part, languages like C, Javascript, PHP etc collect cruft. As they add features, they rarely remove them, because doing so will *break someone's code*. When Microsoft tried to force the VB community into a backwards-incompatible upgrade far more severe than Python 2 to 3, it almost destroyed the VB community, and it cost them a huge chunk of market share and users. It's easy for tiny language communities to shift, and very difficult for popular languages with huge communities. By most measures of popularity, Python is one of the top five or at least top ten most popular languages in the world. Its not just used by students and for toy projects. Its used by big projects, business projects where the has to be a business case made before any upgrade, and more. Anyone who thinks that the transition from Python 2 to 3 could have been any faster given the reality of the situation is deluding themselves. 
&gt; Java Java can have runtime exceptions for buffer overflows. For example, if your code is expecting a file within a certain size limit and works with files that fit that, but the user provides a file that does not fit inside that buffer. You *should* be checking to ensure it'll fit before you try to use it, but Java can't predict every edge case of user input at compile time.
Most people would just upvote for the friendly information.
conciseness is a nice way of saying unmaintainability. I have written dozens of Perl scripts and every time I go back to them after a few months I have no idea what's going on. There's just so much syntactic noise in these languages
Sanskrit is very easy for natural language processing due to its strict grammer.
well i wasn't sure if it was just friendly information... . . . or if it was like "hey idiot, he's the core dev. he knows what he's talkin about."
Have you ever tried to read the pytest codebase? Even as an experienced programmer, it's incredibly difficult to follow and has a ton of metaprogramming in it... That being said, it seems the python community has aligned behind pytest and I should probably get comfortable using it.
I don't know anything about it. Can you tell me what I'm missing by not using it over unittest?
Advanced programming techniques alone are not a good reason to avoid it. But they might make it more time-consuming to develop some custom helpers / etc. over the base framework.
I learned perl and C++ because I managed to buy books in my local store that had a CD. Choice was limited before the internet was widely available.
It's cool - tried it out a while back (last year). However, it seems to have got stuck.
If buffer overflows cause exceptions then you are being protected from them. 
Comments bruh
Thanks. If you look at StackOverflow there are certainly people who spend a majority of their time (free time?) answering questions there. Over 500,000 rep? Maybe same here.
Why the FUCK is the *aesthetic* of a language important? What a bullshit quote. Readability is mainly on the programmer. And a language designer isn't trying to make a "pretty" language. They're making a functional one.
Sometimes write-only code is really all you need.
The presentation in the comment from /u/epage does a good job of answering this question. https://www.reddit.com/r/Python/comments/6j1gcq/if_you_are_not_using_pytest_why_not/djb0j2m/
Adding a GUI with tkinter for an existing script I use to read .xlsx and write to .mrk
To call C++ functions from python on Windows, I compiled the C++ code to a .dll file and then used the python module 'ctypes' to interface with it. Look it up - there are tutorials out there better than any explanation I can give.
Well, he is a core dev so he does know what he's talking about. 
Really? Hasn't the rest of the world moved away from pointers everywhere? 
There are more lines in Chinese characters. They take longer to write. It's pure geometry, or perhaps topography. 
There's nothing wrong with liking PHP, but there is much objectively documented that is poorly designed in PHP. 
Yes, you might accidentally pass "weasel" into the square root function and no unit test will detect this until it's too late... oh wait, that never happens in reality. Actual research has shown no increase in bugginess for dynamically typed programs. In actual experiments (one even designed a new language in two variants, statically and dynamically typed, and taught it to test subjects!) dynamically typed languages are faster to develop in and don't have a statistically significant increase in numbers of bugs. 
If your post isn't a question, try not to phrase it as one.
*youtube-dl* is also a CLI tool, so writing your own wrapper isn't really that useful. pip install youtube-dl youtube-dl "https://www.youtube.com/watch?v=u_iAXzy3xBA" Use the *-F* flag to see all possible downloads if you don't like the default.
While I agree with you I don't see China doing that anytime soon. I'm sure they could overcome the logicstics but the culture, nationalism and so on would never let it happen.
For me the killer feature is lack of `self.assertEqual(x, 2)` nonsense. In pytest you just `assert x == 2` and still get nice diagnostic message on test failure.
Cython, Numba, PyPy - Python can go toe to toe with compiled languages if you need it to. https://www.ibm.com/developerworks/community/blogs/jfp/entry/A_Comparison_Of_C_Julia_Python_Numba_Cython_Scipy_and_BLAS_on_LU_Factorization?lang=en https://jakevdp.github.io/blog/2015/02/24/optimizing-python-with-numpy-and-numba/ http://economics.sas.upenn.edu/~jesusfv/comparison_languages.pdf "In the Python world, Numba ís decorated code runs between 1.57 and 1.62 times slower than the best C++ executable and Cython code runs between 1.41 and 2.49 times slower than C++. Both approaches demonstrate a great performance." 
I think you just proved the point - far too complex. 
If Python doesn't pass Go, it won't be able to collect $200. :-(
I like nose for running tests and sure for writing the assertions. Is there anything on pytest that would make the switch worth it?
Production is my test.
This seems needlessly antagonistic.
Depends on your definition of pretty, but i believe lisp/scheme family is really pretty (simple).
I have Graphene running in a Tornado application, and I have the Graphiql standalone application for browsing the API. What I don't have, and I don't know how to get, is the auto-complete functionality. I'm using Graphene-sqlalchemy to wrap my SQLAlchemy models, and I don't get autocomplete on the fields of those models. What am I missing?
Yeah those have a nice language design but they are also inherently flawed as cpu's simply work completely different xD
this is quite a cocky statement, and it also doesn't really matter to the highlighted programmers for a reason, because they don't give a fuck about aesthetics, rather functionality and speed. I'm a big fan of Python because of its ease/speed of development, but lets not focus on the aesthetics of the engine driving our programs like its the most important feature of a programming language. yes, its greatly important for sharing code easily, working in teams, readability, etc... but all of this can also be done in any given language.... that said, I've coded in all of these languages and I love Python much more. but people are choosing other languages than Python because Python isn't optimized for speed or a lot of other things compared to those languages, and of course if we look at legacy systems you shouldn't just start doing shit in Python for code aesthetics
Trying to read meme text with pytesseract. Extensions would be identifying the meme and making a bot.
An additional reason I don't see here is that it can also run doctests, if you use those at all. I particularly like these features as well: 1. Fixtures: Effectively dependency injection for your tests 2. Markers: A way to easily "tag" tests in some way, you can do something like `@pytest.mark.e2e` and then run just the end-to-end ones with a simple flag 3. Assert: You just use the builtin assert, and it shows the diffs on error automatically and points at what failed 4. Plugins: There are plugins to pretty format output, to run in a distributed mode (parallel runs) 5. It allows a slow migration if desired - since it can run unittest too. 6. Junit style outputs for consumption with something like jenkins or whatever CI reporting you have (not sure if unittest does this)
&gt; I view types as just another tool in a programmer's toolbox for helping achieve correctness, As do I. Python *has* types. It is dynamically typed, It has type annotations to aid those who want the help of static typing, but I resist attempts to make dynamic typing second class in the language, or to restrict the language to that which can be statically typed. Python has grown in its uses; static typing is to be welcomed as another arrow in its quiver, but Python grew to become a dominant teaching language, replacing Java for example, because it is easy to both use and easy to reason about. static typing should never become *the* poster child of Python, it should develop to become a useful feature of the language however.
 $ perl -pE 's/(\d+)/`python -c "print $1 + 10"`/eg' It's not that hard :-) 
uh, for the same reason as any other site...? Content distributors, producers and actors like feedback, in the same way as in any other industry. This is especially true on Pornhub, which is the de-facto center of modern porn.
https://www.udemy.com/python-the-complete-python-developer-course/
I love to work in Python, but anyone that thinks it's a pinnacle of language aesthetics has very different views about def __init__(self) and if __name__ == "__main__" than I do.
It supports many more sites, take a look [here](https://rg3.github.io/youtube-dl/supportedsites.html)
Please could you expand on how it avoids versioning issues? "...you can just keep adding attributes to the model as time goes by, and you can silently depreciate attributes that you want to depreciate." How does that work exactly without breaking clients?
That does not work. It still requires write access to directories which I am not willing to give until I know what it plans to do. 
I understand the idea of adding attributes. How does deprecation, or changing fields work? Or is it literally a case of removing or changing fields at a certain date, much like sunsetting a version of a REST API? Thanks
Thanks :-) Looks like I have a bit more reading to do!
I probably don't know enough to defend them but I believe you are talking about the idea of everything being a linked list? In that case, there _are_ other native data structures in many of the lisps. If you think about something like clojure, it really just provides a _lisp_ over everything JVM already has (including optimized data structures).
&gt; Sigh, no. No, no, no. Condescend much? &gt; You don't need threads to parse files in parallel. As the BDFL explained at PyCon in 2012, threads were never even designed to do that. Not in Python they weren't. &gt; People use threads for everything because most languages don't offer them anything else You're joking right? Most languages don't need anything else because they have real threads. &gt; Processes are for parallel computation, and you can quite easily use all of your cores to process files in parallel. As I already said, it *isn't* so straightforward. Surely you must know this? Or have you never used `multiprocessing` for anything non-trivial? 
Yeah, this sounds definitely like a good job for pandas... A very short process would look like this: *myDataframe = pd.read_csv(inputPath/My.csv", sep=';')* *myDataframe.sort_values(['Category A', 'Category B'], ascending=[True, False])* *myDataframe.to_excel(outputPath\My.xlsx')* You can imagine any Dataframe as an Excel-like spreadsheet... and you can do all sorts of operations on it (filling noData values, sorting, grouping etc.)
Wow! Yeah, I'm surprised I didn't see more references to panda out in the wilderness of stack exchange! Thanks a lot for the tip! I'll be sure to dive into those docs over the weekend... Meanwhile my 300 line script looks like it's close to done! (Yes, it seems panda will be super necessary)
Lol. That guys dongaroo grilled sausage got me.
This is amazing! I work in a macroeconomic analysis branch of the statistical agency in the UK and we are wrestling with the fact that we have legacy work in all 3 languages: R, Python and STATA. Do you have any comparisons of things that the other datasets can't do? E.g. in R I find it is harder to do panel data stuff than STATA and Python. Any insight on the trade-offs between the languages (unfortunately I think Julia won't get into the conversation at this point), or guidance on where I can find objective (if that is possible) comparison of the languages woudl be much appreciated!!!!
Lol, useful indeed 
To be honest - he mentioned 4 ways to iterate over array and Python have 3 of them, C# have 3, C++ have 3 and even Java have 3. Is a presence of for-in that complex? It's more about idioms, not language complexity. 
I am trying to write a program that will download what you entered from a specific torrent website
I'm quite confused by that. Pytest fixtures are explicit in the argument list whereas unittest tests have implicit state thanks to setUp. How is that ever easier? Also you can use pytest as the test runner while still using TestCase classes
First try just telling cython to use your existing VS compiler instead of mingw32/cygwin by replacing "--compiler=mingw32". I think it would be "--compiler=msvc" but I might be remembering wrong. This person changed their msvc9compiler.py file so it would always use the vs compiler. https://www.ibm.com/developerworks/community/blogs/jfp/entry/Installing_Cython_On_Anaconda_On_Windows?lang=en
Ugh, I hate the assertFoo nonsense. That feature alone makes me like pytest.
We use pytest extensively, but in a few cases we just use plain `unittest` because pytest can be too clever sometimes.
I would like to see the code for this looks interesting. Hoping it has good comments ^.^.
Converted Time Space Positional Information (TSPI) data into body frame coordinate systems with respect to particular assets. Was given a folder structure with datasets in various formats. Created a function to turn each format into a generic format, then produced the desired outputs as both csv files and mat files
py.test really isn't for that as much as Behave or Lettuce are. It's just very handy for unittesting.
I wonder who actually comments on videos. That should be a showerthought 
Now make it use voice recognition to do voice-to-text on the adult videos themselves and post those quotes.
Yeah, but because it's less performant, you end up having to scale horizontally with servers. That costs tons of money - though it is usually cheaper than developers.
There's nothing wrong with large institutions being conservative and wanting to stick with COBOL applications. I'm not a large institution, I'm a modern applications developer. However: if you were developing something nice, and most of the nice libraries were in the old version of the language, but you need some features of the new language, it can be very discouraging to use that language. 
You can label your tests with markers. https://docs.pytest.org/en/latest/example/markers.html
I don't what to suggest on the command line cythonizing. Do you have jupyter notebook installed? Have you tried its "%load_ext cython", and "%%cython" magic commands to see if you can compile and run cython code there?
Numba is a JIT designed for optimizing numerical operations. So in that case, it's not going to help if your code is doing nothing but manipulating strings. It also accelerates functions rather than whole programs, so the numerical code will need to be in its own function. Other than that though, Numba really doesn't require anything else - you just use a Python decorator above the function and that's it! You don't even have to provide information about variable types. It also has the ability to cache JIT-optimized code and even pre-compile the function blocks before first run. Cython is like a merger of Python and C++. All Python code is valid Cython, but Cython also lets you bring in C++ data structures, static types, etc. The Cython code will need to be kept in a separate module and then imported like a regular Python library. The least you're going to want to do is probably to specify types for the variables in the Cython code. You can even import C or C++ libraries directly into your Cython code, which makes it good as a simple way to wrap C++ libraries. I've only used Cython with small (numerical) benchmark tests I've written so far, but in each of the cases the Cython speed was almost identical to the C version of the benchmark. 
No I don't have Jupyter, and I really don't think that it would help as I've already tried Winpy with no luck 
Did you install cygwin mingw32 after visual studio? If it were me, I would first try the msvc9compiler.py fix, and check my path environment variables. Then I would uninstall VS and cygwin mingw32 and python, then reinstall VS and anaconda and see if it can find vcvarsall.bat and the msvc compiler then. Assuming you've already install other python packages, remember to freeze them to requirements.txt for before uninstalling python.
&gt;Condescend much? Yes. &gt;Not in Python they weren't. Not in OSes they weren't. As Guido said, "Python has totally real threads, and if you use them for what threads were originally meant for... OS-level threads are meant for doing parallel I/O, not for doing parallel computation." https://youtu.be/EBRMq2Ioxsc?t=33m55s Wikipedia backs him up on this, too. Basically, you (and most people) were taught something wrong, a hacked way to do parallelization, long ago and now y'all insist that Python has to do it wrong too. You used threads back then because, as Mark Summerfield noted, you weren't offered anything else. That doesn't make it right. &gt;You're joking right? Most languages don't need anything else because &gt;they have real threads. One: "Python has totally real threads..." - Guido Van Rossum. Two: threads and locking are an ugly, mid-level hack. Python is one of the few languages with safe, high-level concurrency. In fact, I know of a Delphi library that takes over 10,000 lines of code to try to give Delphi what Python has built-in in terms of high-level concurrency capabilities without explicit locking. Other languages wish they were Python in this regard. &gt;As I already said, it isn't so straightforward. BDFL begs to differ. Python begs to differ. 
I guess my point is who cares if it's more complex if you can understand it? Do you want to keep reading Dr. Seuss or do you wanna read Plato?
dont forget to share code please! 
Well, I wouldn't call Java or C# as scripting languages, and they have different (and broader) goals.
That makes "Except all the asscuddleing" make so much more sense. https://twitter.com/prnhubcomment/status/878401131327754244
There are escape sequences in some of the comments: &gt; Wow I would love to eat her pussy\xa0 &gt; love her!!!!!!\nreal horny girl!!!!!! Can these characters not be put in tweets?
Might be wrong but their code most likely took the raw string data when scraping the comments. When the string is displayed as raw escape sequences like \n are displayed as text rather than what they are meant to be. It think the best way to fix this is to have it corrected after the text is scraped.
I've started using pytest for verifying stuff that's not local importable code. Like assumptions about the way the developer environment aught to be setup, or that a remote system is alive. The test-runner makes a fine replacement for `__main__` in many cases, especially when I'm guaranteed to have the dependency already - adjacent to more-real tests. And the junit XML report is incredibly consumable elsewhere.
Looks like some kind of parsing error producing all those \\xa0
Windows? If so remove 2.7 from your path and add 3
Oh my god, this is great. I wonder what it would be like if all these were randomized into random sentences?
I would love to read some research on this if you have it handy. I can only go on my experiences. Python is my #1 choice for tools and small programs because it's so quick to get things going, and the third party modules ("batteries included") are outstanding. Where it came apart in my eyes was when program complexity started to increase. I found myself frequently wasting debugging time catching stupid bugs at runtime (the absolute worst place to catch them) that would have easily been caught at compile time in a static typed language. Unit tests help, but unless you cover every single part of your program there's always going to be problems, and extensive unit tests add overhead to your development time, making the language less efficient than it might seem. I love Python, but it's not The One True Language, and nor is any other. They all have their pros and cons. The best we can do is learn what they are, and choose a language accordingly for new projects.
This should be a feature.
Oh I'm sorry, did I upset you by pointing out that "PyPy isn't available in distros by default" is irrelevant to those who don't use a distro in the first place? 
Plenty of end-users just sitting around ready to do free testing
"The lecture was informative, just wish there would have been an actual demonstration." I wonder what video this was. OP, include a link to the comment perhaps.
I prefer super() as it's simpler for me to write and simpler for me to reason about. It also doesn't bind implementations to what they happened to be named. To give an example, I have a DRF permission that looks up if a user has a specific permission. But they're just strings, woo is me. After fucking up a few times I decided when it came time to run tests, I'd monkeypatch the existing permission to one that'd check if the permission actually exists (currently they're stored as a nested dict in code) and then super up to do the actual thing. What I didn't count on was by monkeypatching the class and using the old style super(cls, self) would cause the class to super into itself. Whoops. 
I write my tests of my classes or modules as if __name__="__main__":. Works good for me.
We have a saying in networking that perhaps applies: Everyone has a test environment. *Some* are lucky enough to have a dedicated production environment.
If you want to do cooperative multiple inheritance super() is the only way to do it. If you don't want to repeat yourself super() is the only way to do it. I'm not aware of any particular downsides of super() in python 3.
[folium](https://github.com/python-visualization/folium) looks promising (but I didn't have the time to try it so far)
Interesting the amount of NBSP being used throughout. E.g. https://twitter.com/prnhubcomment/status/878458559809376257
Tweeting this often my get your account banned on twitter. I had that issue with my twitter bot, but my was replying to people is tweet.
My answer: Beside `flask`, nothing good enough.
This is honestly the first I've heard of a desire to use an alternative to `super()`! I can see merit in Lutz's approach at times but it would seem that `super()` is more convenient on the whole.
I think your conclusion is correct. If you inherit from a class in Python 3, you can expect it to be a new-style class and you can expect it to use `super()` if it inherits from another class. I'd say the time `super()` becomes most useful is with multiple inheritance and the time `super()`is most confusing is also multiple inheritance. However, with single inheritance `super()` is still a great convenience (for avoiding repetition and playing nicely with classes which may inherit from yours).
I think the js precompilers [rapydscript](http://www.rapydscript.com/)/[rapydscript-ng](https://github.com/kovidgoyal/rapydscript-ng) deserve some love and attention in this field. The Brython code from Brython's [Hello world](http://www.brython.info/gallery/hello.html) example: from browser import document as doc from browser import alert def echo(*args): alert("Hello %s !" %doc["zone"].value) doc["test"].bind("click", echo) The equivalent in rapydscript-ng, using jquery: def echo(*args): alert(f"Hello {$('#zone').val()}!") $("#test").bind("click", echo)
Might not be exactly what you're after, but perhaps you're attacking this the wrong way. Try using QGIS, which is controllable in every way with python. Just use it as a map engine, even though it has a GUI.
Whoosh
this is a beginners post, and more importantly, with this script you can download at the location of your choice
In case you don't already know, this has been done before and was posted on this sub a few years ago. https://github.com/rndmh3ro/porn_comment_bot
Right It says it supports 3 but doesn't install with pip3. 
It's not arrogant. It's a simple statement that's logically true. Most programmers aren't language designers in the same sense that most construction workers aren't architects or house painters fine artists. 
http://i.imgur.com/EThqcXl.png Error in the code? Or did the comment actually say /n ?
&gt;I guess my point is who cares if it's more complex if you can understand it? Two points would be the extra time required to understand it and the fact that complex languages still make simple things harder than they have to be. If I can navigate with a sextant and compass that doesn't change the fact that it's much less effort to navigate with GPS. 
Please god, fix the parsing and posting to use the original formatting, and not use the escape sequences. PLEASE!
Machine learning with click data
Also, I rarely see a situation where celery doesn't fill in the gap for parallel computation. Not only does it make multiprocessing incredibly easy, but you can scale out across multiple computers just as easily as scaling across multiple local processes. There's definitely overhead to celery, but I can't remember a situation where doing my own multiprocessing and forking made so much more sense than just writing a celery task. And for those weird situations, dropping down to C or Rust is absolutely not a headache. The CPython API is perfectly usable. Really, every argument about python performance ends up being one side moving the goal posts and trying to find that little niche where Python doesn't work. And for some reason, it's just inconceivable to some that you might write C code in a python application and call it a Python application... When a C coder optimizes some parts in assembly, do they say it's not a C program? To me, C is a solid part of being a Python programmer. It just fills the gaps if you ever run into them, and it's not the end of the world. It's still an easy to maintain Python application.
[Learn to ask the right questions](http://xyproblem.info/). You asked a question about a problem you encountered in your perceived solution to a problem, _not_ the initial problem. Give the error log from your `pip3 install pushbullet`.
That is a nice post! I definitevely learned somenthing new today :D
Whoosh
&gt; And for some reason, it's just inconceivable to some that you might &gt;write C code in a python application and call it a Python application... &gt;When a C coder optimizes some parts in assembly, do they say it's not &gt;a C program? Languages like D and Delphi even let you inline assembly code; I thought it was perfectly normal to occasionally step down from something higher to something lower. It's been done since at least Turbo Pascal in the 1980s. &gt;It just fills the gaps if you ever run into them, and it's not the end of the &gt;world. The fact that there are ways to call code from almost any language within Python is to me one of the most important and powerful features of the language. 
I don't understand... this works: class Foo: def __init__(self): assert 0 # replace with print and you will see it completes correctly class A(Foo, list): def __init__(self): super().__init__() A()
For testing purposes, and because I thought twitter might deactivate my account if it constantly posts the word 'fuck', I replaced it at first. Changed that, though.
I'm still at work so I can only use my phone at the moment. Will upload to GitHub, of course.
Yes, they already made me verify my account and gave me an error message telling for posting too often. Seems to be fixed by setting the timer to four or ten minutes, though.
C types don't use super when chaining up (I assume for perf reasons?). list() is basically implemented as class list: def __init__(self, *args): object.__init__(self) no biggie, but I was confused as well when I first hit this. edit: found a Python bug about it: https://bugs.python.org/issue8733
Mouse is my keyboard.
You can start [here](https://learnxinyminutes.com/). Python works well for prototyping, backend development, data science, machine learning, and lots of other things that either don't require optimizing performance, or allow to delegate the slow operations to native code.
I use Google Groups to browse [python-ideas](https://groups.google.com/forum/#!forum/python-ideas) and [python-dev](https://groups.google.com/forum/#!forum/dev-python) for example. Here is the message from Steven d'Aprano: https://groups.google.com/forum/#!topic/comp.lang.python/OHMOOwGdAmE%5B26-50%5D
Video linked by /u/flipstables: Title|Channel|Published|Duration|Likes|Total Views :----------:|:----------:|:----------:|:----------:|:----------:|:----------: [Python 3 Metaprogramming](https://youtube.com/watch?v=sPiWg5jSoZI)|Next Day Video|2013-03-23|3:00:24|1,124+ (98%)|113,883 &gt; David Beazley Some of the most significant changes in... --- [^Info](https://np.reddit.com/r/youtubot/wiki/index) ^| [^/u/flipstables ^can ^delete](https://np.reddit.com/message/compose/?to=_youtubot_&amp;subject=delete\%20comment&amp;message=djc3kwf\%0A\%0AReason\%3A\%20\%2A\%2Aplease+help+us+improve\%2A\%2A) ^| ^v1.1.3b
This is great thank you for this. Maybe you should separate the migration from deletion and ask the user to verify his new account is correctly setup before wiping all user data. Errors happen :) For the code, I would say it would benefit in setting variables at the top instead of embedded in it Use underscore underscore main underscore underscore statement Finally use regex instead of string partitions Just my 2 cents :D 
Now THAT's distributed testing. 
In Python you just worry less about details until you really need to. 
The magic is exactly what you've described, and is -- to me -- extremely un-Pythonic. Suppose I write the following code: def square(n): return n * n If I happen to have `n = 4` somewhere else in the same file, Python won't automatically call `square(4)` whenever the file is executing. But pytest would, and that's what's un-Pythonic about it. If I want something called with a set of arguments, I'm capable of doing that, and with unittest I can see where everything is coming from in my test case: either set up in the test case, or in one of its parent classes. Having to be extremely careful about naming in case I accidentally collide with a pytest fixture and get my function "helpfully" called with it as an argument is not what I want.
I learned something today.
Simple Django blog 😏
Plotly has an offline mode that you can use for free: . https://plot.ly/python/offline/
Looks good! I'm not so sure about the usefulness/relevance of the section on binary numbers, though. Learning python before starting my degree was the best time investment ever. I used the (free) book 'Think Python: How to think like a computer scientist' from Allen Downey. Would recommend (in case the masterclass ends up being disappointing).
CPUs work different than high level programming languages? 
Well lets say functional languages will always be slow
&gt; I know but I'm saying that PHP can be cleanly designed A language is either well designed or it isn't. PHP isn't.
Why are you not using /r/learnpython? It's the subreddit designed for learning questions. Also, use `raw_input` instead of `input` on Python 2.
I think it would be funny if it replied to other people's media posts.
Very interesting thanks for this take.
Udacity Data Analyst program.
Why not just delete the comment rather than editing them?
Yes they can ;-p but sure they are nice too
As /u/K900_ said, refer to /r/learnpython, and make sure to post *all* relevant code. The error message you're getting explicitly says `line 1`, and something about a name `XYZ`, which your code snippet isn't showing us. Therefore, we can't help ya.
thanks for the answer! 
Faint art never won fair aidy. 
Why ignore the balance sheet? The way I was taught about algorthmic trading, you take all the data you can get. Using past stock performance to predict future stock performance seems much less likely to work than using that, plus other information.
You can find documentation for that in the [typing](https://docs.python.org/3/library/typing.html) module.
Your pattern matches `/images.*`, but your URL points to `/imghp`, so that's why it fails. Also, when defining a regex pattern, use a raw string so Python doesn't interpret the backslashes before it's sent to `re.search`. &gt;&gt;&gt; line = r'.*www\.google\.de/imghp.*' &gt;&gt;&gt; url = 'https://www.google.de/imghp?gws_rd=ssl' &gt;&gt;&gt; re.search(line, url) &lt;_sre.SRE_Match object; span=(0, 38), match='https://www.google.de/imghp?gws_rd=ssl'&gt;
First, thank you for your help. Second, I'm sorry. I meant to write /imghp twice. Next. How can I define the regex correctly when I read the regex contents from a file (which means I, as far as I know, can not type something like `re.search(r'variable, url)`
Oh wow... this is the first time I've heard about it - thank you for that. I'd seen the name before but never read anything about it. Looks like it would have been pretty much perfect for my needs. Will definitely be looking further into this in future. Wow - just reading more... Calling C and python functons directly Easy parallelism Built in package manager It sounds like a dream come true.
Is it okay from what standpoint? Morally or ethically, I'd say no just buy it. It's $40 (USD). I know that can be a lot of money depending on your situation. From a content perspective its probably filled with lots of silly errors (both in the code and explanations) that would be caught be editors. The book itself is fantastic, and it's definitely worth purchasing. However there's nothing you will learn in it that you can't find for free on the internet. Well, other than Luciano's explanations, I'm not sure if he maintains a blog or writes articles anywhere. 
I want this to be a common word so hard.
Nooo! It is so much better woth cuddling.
i would agree with this and also mention that naming the parent is (probably in most cases) ambiguous even when the class hierarchy is linear. it's immediately apparent what you're doing (edit: when calling super) and the convention is so wide-spread in my experience that if i started explicitly naming the parent rather than calling super it'd get brought up as soon as i submitted a code review. like basically, super is less ambiguous semantically, even if mechanically it may depend on the context.
So does this aim to be for python what diagramms is for haskell? The example with the elemebts is nice.
There is no option to run as administrator, it is a program to monitor and track the usage of the Plex server program
This is what I'm seeing in code I'm reading. Regardless of technical arguments, it seems the war is over. If you aren't using `super`, on average people will think your code smells for newer Python 3 code bases. The war could have gone the other way, but sometimes you just have to go with the flow and follow conventions. Plus, it really is easier to just name the parent once and not worry about it until there is a problem. I know this is sort of an ostrich approach, which is bad. This is *exactly* the thing the naysayers were worried about.
Thank you! How do I change the path?
Could you explain what an api wrapper is to me? I am just getting started
Why not go through a free book over on the sidebar? It's no worse.
Pip does weird things. It doesn't grab the dependencies from setup.py. I've never even used pip3. Literally, I just use pip on Python 3.
Y'all don't understand that eventually any not awful company will double in value. There aren't any other GPU companies that exist that compete with NVDA in the AI sector. Sure you could argue Google's TPU, but that cannot train AI (AMD also does not have much support). Right now GPUs are by far the most efficient means to train AI. I'm not gonna argue my financial philosophy anymore, my guy. Having 0 liquid assets is an awful plan. ✌✌
Is there a way to make a twitter bot without using the twitter api? Genuine question.
Right-click the icon and then select "run as administrator". Not sure if the wording is exact. I haven't used Windows in years. 
I tried that. I use A MacBook Day to day other than this server. But for this file that option (run as administrator" is not available 
I used tweepy for making the bot
I have a Plex Server running on a Linux Mint machine. I can try installing it, but I doubt that I'd run into that same issue myself. 
My PlexPy Worked fine idk what happened. I move in 6 days if I can't get it fixed by then I might try out Linux for my server. To me it always ran better than windows
I actually refined some things and want to fix others on the way. It now posts a picture with the quote instead of the quote. Thought this would be kinda cool. I'll iron some things out and link to Github. :)
If you guys have any suggestions or anything.. I would be happy to hear them! 
There are versions based on Ubuntu and others on Debian. I don't dig in enough to tell the difference but I prefer Mint because after an initial install all I have to do is install a few things to have a system that works with pretty much anything I want to do. I'm a python developer, mess around with 3D, edit videos, play Steam games, create and edit work documents with Libre Office, etc. I've tried many distros over the past 15 years and Mint is the one that I've been using for the last 8. Bottom line, it's easy to use but you can dig into the nuts and bolts if you like doing that too. 
If you want to be sure your comment is gone, doing the edit first then delete will make it completely disappear. I don't know if this is still the case, but a deleted comment still actually exists in Reddit's database. It just has some flag to show "deleted" instead, but certain tools can still see it. If you're as paranoid as you say, editing then deleting is the way to go. Who cares if it takes a little longer. 
Yes. You (plural) read, you learn, you take notice. You do not have to agree necessarily, but anybody who disagrees with a core developer has to have a very solid foundation. It's all pros and cons, swings and roundabouts, hence [my favourite expression](https://mail.python.org/pipermail/python-list/2002-November/141486.html).
Bayesian Optimization would be a good addition.
I don't know whether 10x programmers exist., but if you can't use sed/awk/perl and are working with text a lot you without a doubt are a 0.1x programmer.
I'm not sure how to accomplish this through pip, but at my company we always install the source through setup.py since we like controlling the exact versions of libraries installed. With that method, you can stop the auto-downloads with a distutils configure option. [easy_install] allow_hosts = None Just put that in your "$PREFIX/lib/python2.7/distutils/distutils.cfg" and it'll stop the auto-downloads from happening.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [100/Solid/.../**README.md** (master → b3590d4)](https://github.com/100/Solid/blob/b3590d444306c1799eb0c75def263128ce00392d/README.md) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply djcmafo.)^.
I can understand adopting the syntax from ggplot2, but why would you copy the look as well? Or am I the only one who things the default ggplot2 theme is horrendous?
&gt;am I the only one Probably not
Ah, yes, of course, that makes sense in this case. Although I still wonder if bypassing this using variable names like quora_user quora_password questions_file wouldn't be a better choice. It's a matter of preference, I guess, and the current names are shorter and it's obvious what they represent. Not a bad choice then, just slightly irritating when not having the globals in mind.
Wheres the code?
Does anyone know if there is a comprehensive python client for GraphQL? Can you query an endpoint and get Python objects back?
different people place different prioritization upon 'aesthetics'. there are also a multitude of other factors, such as the time and place a language was introduced; and of course things like performance considerations.
Not to mention the `&gt;&gt;=` ligature, which A) doesn't need to exist and B) is kind of uglier than the problem it's trying to solve. 
I have read it. Among the stipulations is that caller and callee must have matching signatures. In the examples that means a zero argument constructor. That isn't a safe assumption. An of the failure is simple: class B(Foo, list): def __init__(self, items): super().__init__(items) The `Foo` class is wrong and buggy.
Well put!!! There is certainly a move from inheritance to composition, but from someone with 40 years experience in engineering and computing I'm still waiting for the magical silver bullet that fixes everything for us mere programmers. I've tried Go for fun, thinking that it will alleviate some of the problems, but I've never had such problems with any language, so I will never be able to work out why it's so popular. Have I been spoilt by 17 years of Python? I suspect so.
The results are in: [+]that took 0.834820985794 seconds [+]that took 0.83774805069 seconds It's updating the seen set that's the overhead here I think.
You can do that in memory using the `zipfile` module.
Can't profile now, but using set operations is usually faster than looping. The following cuts the inner loop by doing a full set comparison (intersection) + adding in bulk if you get a miss. def uniqueElements(*arg): seen = set() for item in arg: if seen.intersection(item): return False seen.update(item) Note that this changes the behaviour a bit, in that in your current code if you get a "hit" on a value before another that is not seen, that later value in the tuple will not be added to the hits. But it's not clear from the description if that is intended behaviour :) Be interested to see the numbers for this.
I'm in the same boat. Move to minneapolis or die.
This feels like a job for sets. Sets find common / unique members of groups very efficiently. Have you tried making 'item' a set and doing intersection logic. That should cut out at least one of your nested loops. No? 