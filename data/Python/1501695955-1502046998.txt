Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
I think you and the English language disagree on the meaning of the word definitive. Notably this doesn't cover anything about configuration, gotchas, nuances. Nothing about why the logger name is significant to the library. Nothing about `disable_existing_loggers`. This offers nothing over the standard documentation at all
Humm, I'd say that the dependency management of mu would replace the centralized manifest (i.e.: you'd just ask to clone the repo you want and it'd get that repo and any other repo it depends on, without needing a centralized manifest). 
you're awarded no points for a bash forkbomb in a discussion revolving around perl. 
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Lol nice
Just wondering if you have a guide you would recommend for logging? I'm' building my first semi-large (for me) python application and could definitely benefit from more knowledge/best practices of the logging.module 
which gui framework?
I am using PyQt and an extension named pyqtgraph for some data visualization.
Hi @stickystuffremover, That was embarrassing for me, I've added a patch now. It should be working via pip already. Thanks for catching that!
Oh I see. Sorry I missed that. It's probably too late to change for us at Tanker, but I'll keep mu in mind for an other time :)
Damn, you're right. I thought it meant something different. I am exactly going for **this is how it is** and not definitive. The entire point of the post was that it wasn't so exhaustive as alternative resources. What title would you suggest? :)
Did I say wordpress.com? No, I said WordPress because it's an open source software you can host everywhere with 2 clicks. You can choose wordpress.com and migrate away from it if you don't like it anymore. Can you do the same with Medium?
There's an export button in the settings screen on medium at least. The formatting medium supports is so super limited it's quite trivial to convert anyway :P
Most active Python projects I'm following have Google Groups.
Maybe are you confusing decentralised and distributed? The Web is decentralised by definition mainly because it's based on hyperlinks.
and yet here we are talking on reddit instead of quoting each other in our self hosted microblogs. the current web is decentralised in the same way a four person family with mobile phones is decentralised
wow! That is impressive!
In fact I was talking of blogging platforms, not Reddit and every single service with a Web interface. Are you aware for example that WordPress has pingbacks to notify you when someone mention your article in his blog hosted somewhere else? Also the main point here is the following: you can use wordpress.com exactly like Medium but you can eventually migrate your WordPress blog from wordpress.com to a hosting solution. Can you do the same with Medium, keeping comments etc? What if at a certain point Medium change its terms of services and you don't like them or it decides to censor the contents you usually post?
Contents? If it was not possible I would had call Medium a fraud. With WordPress you migrate your **entire** blog. So after you export the contents from Medium, how do you recreate the experience of medium.com?
I know non-tech people that are capable to choose an hosting solution and select WordPress during the configuration. I expect Reddit users, Python programmers and /r/python subscribers to be capable to do the same.
I still don't understand why someone should suggest to a Python programmer solutions like Medium or Blogger when WordPress is available. If the hosting provider doesn't do a good job, change it. I used different providers and no one broke my experience with WordPress.
That was fast. What's to be embarrassed about? Unfortunately, I got another one: KeyError: 'Missing either c1, c2, or w in kwargs' I get it from line 5 of cell 3: gbest_pso = ps.single.GBestPSO(n_particles=10, dims=2, **options) 
Should make a Julia set fractal in Julia :P
I haven't found a single source, I've cobbled together what I know from multiple sources. The disable existing loggers one is by far the biggest gotcha though, because it means that changing the order of your imports, or imports vs logging configuration can actually change the runtime behavior of the code.
Does `pip install pygame` no longer work? If you're not on Windows, try `pip3 install pygame`.
I'd call it an introduction
I've no idea why someone would suggest WordPress to *any* programmer when Jekyll + Github Pages exists. Static sites ftw! 
Very cool! I'm learning new things.thanks for sharing!
You are perfectly correct in plugging your library here, provided that you give a thumbnail sketch of what it's about and what has changed. I'd also put it on [python-list](https://mail.python.org/mailman/listinfo/python-list) and [python-announce](https://mail.python.org/mailman/listinfo/python-announce-list). The guidlines for the latter are here [posting guidelines](https://www.python.org/community/clpya-guidelines.txt/)
pypi is where the new version goes, it's not the place to announce the new version.
I agree with the voting system, it's less than useless. I'm quite happy to have been banned from [/r/learnpython/](https://www.reddit.com/r/learnpython/) as it it was quite clear that many posters didn't have the faintest idea what they were talking about and didn't like being informed of that fact.
Yes, and it's a hell of a lot of work for the moderators if those groups are linked into mailing lists. 99% of stuff that goes onto the main Python google group is spam.
Don't be a dick, man. Unfortunately your measurements aren't well-controlled; all those programs do different things, which completely hides any reasonable measurements you can get from it. I'd show you how this argument applies to the comment I replied to, but unfortunately it's deleted now and I haven't saved it. With regards to `primes_raw`, note that it's doing a poor-man's sieve, which is an asymptotically faster algorithm than the others (two kinds of iterated division). It's not easily translated the same way to lists, but you can always use a traditional dense sieve instead, which will be faster. In contrast, if you take the original list-based code, eg. `genPrimes`, and move the early-out to insertion (because you want it to work with unordered containers) and make a version with that as a set, you see that the set code is again noticeably slower. You actually get fairly lucky that the hashing and insertion algorithm for sets of integers mostly hides their unordered nature, so the cost is less than it would be if the order was randomized, but it's still a cost there's no reason to pay. And there's no guarantee other implementations won't change the insertion algorithm. Times are up at https://gist.github.com/Veedrac/bea3a17296151ff860788120ee0aff1a
Linked to [Python-announce-list](https://mail.python.org/mailman/listinfo/python-announce-list).
Please ignore the idiot who needs to stand up as their voice is rather muffled, rather see my earliest post.
I used to post my Python blog tutorials here, but started getting told by the mods that I'm not allowed to, so I'm not sure if this is good advice.
My first thoughts: 1. Drastically and unnecessarily over-complicated structure... you've got an entire file, and a separate test file, simply for loading a file and yielding lines from it. This entire thing could easily be done in a single file. 2. Incomplete docstrings in `gcd.py`. 3. Docstrings and comments show signs of either having not been checked for grammar, or have been written by someone with a less than native grasp of English. This draws attention away from the code itself. 4. ... as do little things like not being consistent with capitalization of the first letter of the first word of a docstring. 5. Rarely a good idea to inject political content unless you've got direct knowledge of the politics of those who will be reading your code.
Try automate the boring stuff with python book. ive heard bad stuff about python the hard way also. By multiple posters.
I like the book. So, now you have heard some good stuff.
thanks
Didnt work. If you would like, maybe you could help the guys on my duplicate post on r/learnpython
&gt; "there's no need to time code before judging which is faster" There's no need if you can deduce the answer from first principles, which I could in that scenario from some fairly well-known truths. [Other times](https://stackoverflow.com/q/28885132/1763356) that argument doesn't apply at all. Normally it's a mix of both, with knowledge about execution guiding your search, timings checking your work and detailed analysis (of, say, the output assembly, since serious performance work in CPython is normally silly) feeding back into your knowledge about execution. &gt; on average, executing N bytecodes will take less time than executing N+M bytecodes Oh, absolutely, with a few exceptions, one of which shows up here. But code size isn't likely to have a meaningful effect on this for "small N", which I assume from context means ~10k, relative to `genPrime`'s asymptotic superiority. I assumed this meant you were saying it in another way, which I was mistaken about, but the point holds against the true argument nonetheless. Note that your asymptotic for `slowPrimes` isn't likely to be fair; the inner loop early-outs, so you'll have something more like `O(n√n / log(n))`. I agree `genPrimes` is likely to be more like `O(n√n / log²(n))`.
[Slinkie](https://github.com/segfaultsourcery/slinkie)! I'm trying to move some of the most useful parts of LINQ to Python 3.5+, along with some of the boilerplate extension methods I often find myself writing in C#, and whatever I think fits from other languages, such as Haskell. Here's an implementation of [sleepsort](https://rosettacode.org/wiki/Sorting_algorithms/Sleep_sort#Python) (from the unit tests). def test_parallelize(self): def _wait(number): sleep(number / 100.0) return number numbers = (7, 2, 1, 4, 2, 5, 1, 1, 2, 3) actual = Slinkie(numbers) \ .parallelize(_wait, len(numbers)) \ .list() expected = sorted(numbers) self.assertSequenceEqual(actual, expected) **Edit:** [I just tried writing Dijkstra's algo using slinkies.](https://gist.github.com/segfaultsourcery/e5eb960771f93a7559ddaf835fe0ee0c)
Is there any logging framework on top of the standard one that allows easy configurations of loggers per module/file? Like, if I'm debugging a problem in my own code, I want to have it spew lots of info at debug level, but not other code that calls my code or that I call.
Ok, with that first one it's totally a bug that I missed.... It should be instead something like ship.__dict__[key] = attr It ended up being a function that I just added as a backup and didn't use. The distance function there is super simple, it's just the [L2 norm](http://mathworld.wolfram.com/L2-Norm.html), or the [Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance) formula between 2 points. So each coord is a tuple of form `(x, y, z)`, so all we're doing is that formula while iterating over it. It's kinda messy, but i like generators a little too much.
The built in logging supports that and iirc will cascade settings down loggers with the same dotted prefix
For a second I thought this was a post in r/Julia
Three things you should never discuss in polite company (i.e. in this case Work): Religion, Sex, and Politics!
definitely. but, I didn't have such an intent. just used the politicians' name because they are known by everyone. I shouldn't have used them anyway. 
That is exactly what ansi-markup do: https://github.com/gvalkov/python-ansimarkup Also, this is built on top of Colorama so it is cross-platform.
There isn't any setup at all with those solutions, that's why I use blogger. Register and verify a domain, pick a template. Takes 3 minutes to have a functional enough blog to make a post. I don't care about any features other than getting words on a page. My blog is where I record solutions to problems I've found, or for jotting down thoughts. It doesn't effect my life at all. It could disappear tomorrow and I wouldn't notice for months.
Yes, but you invited the slightly liberal and physically proportionate centrists and disinvited the extreme right racist nutbag with tiny hands.
WHOA, it actually works, thank you! The key thing is to have import logging log = logging.getLogger(__name__) boilerplate everywhere, and then apparently `__name__` resolves nicely enough.
I'm on windows
I'm just trying to get started with python for analytics! 
this is interesting, i have stared your code😄
All the hosting providers I used have a "install WordPress" option at the end of the config. I'm surprised here everyone finds using WordPress more difficult than Blogger or Medium.
It's not that it's more difficult, it's that I have to do *anything*. That's the part you're not getting. I don't want to buy hosting, I don't want to set anything up. I want to do nothing.
If the version update would be interesting for many people, post it, and say in the reddit headline and release notes why it's interesting. In my own experience though, only version bumps for the most widely used libraries (django, flask, numpy, python itself...) are noteworthy solely for the version bump, and I personally wouldn't give much attention to a version bump for some small unknown library. If what you really want is interest/feedback for your library as a whole (and not just this particular version bump), I'd advise to rather write a blogpost, that explains what problem your library solves and how it does it, and post that. People trying to solve the same problem as your library are much more likely read that and will upvote if they like it.
also names like test_01_constructor don't indicate what is being tested
I've been using steam long enough to know that lol
REPL is good for trying things out, for simple debugging. The notebooks are useful for communication (even if it is with your future self) and for less ephemeral exploration of a problem (see whether you like something at http://nbviewer.jupyter.org/ ). It is a practical literate programming. A similar tool is org-babel that allows to execute code in the org-mode in emacs. Here's an example how it may look like http://www.howardism.org/Technical/Emacs/literate-devops.html It is a step in the direction of live coding https://stackoverflow.com/questions/9448215/tools-to-support-live-coding-as-in-bret-victors-inventing-on-principle-talk Example [skewer-mode in emacs](https://www.youtube.com/watch?v=4tyTgyzUJqM). An ordinary code (modules) is for reusable code, commands (scripts).
The problem is that the VS Code console doesn't handle input, as others have mentioned. I had to deal with the same thing a while back for Sublime Text, and my solution was to create 2 separate builds - one without input (SublimeText console) and one with input (Powershell). &amp;nbsp; Not familiar with VS Code's build syntax, but you'll have to set up a build that calls something like: powershell -noexit python -u "c:\path\to\file.py"
Kotlin is sort of held up to be a panacea, but it isn't, for a number of the reasons you suggest. I just like the language - it is elegant, powerful, and attempts to deal with problems I need to deal with. &gt;wouldn't this break compatibility to the Java packages and divide the ecosystem? Yep, for sure. Kotlin is intended to play nice with other people's libs and runtimes. Hence, it is trivial to use JVM code with the JVM-hosted version of Kotlin. Likewise, it is meant to be easy to use JS with it (this can be hit and miss, the functionality is new). With native, they are trying to make it work nicely with C interop. Doc here: https://github.com/JetBrains/kotlin-native/blob/master/INTEROP.md &gt;Is there a package manager with centralized package registry in Kotlin Jetbrains haven't really addressed this beyond saying they want you to use existing tools, so, with JVM, you would use the Central Repository and Maven, and the Gradle build tool. The barrier to entry is high for hobbyists - all of those platforms/tools I mentioned take a while to learn/employ! Why: 'enterprise' scale and design. Why make something simple when you can make it so complicated you got to pay a man to teach you about it? ;-) It is my hope Kotlin will end up with its own package management systems and repository. It -does- have a nice stdlib of its own, BTW. Regarding package management and hosted packages, keep in mind that even though Python had distutils way back in 2000, they didn't get pip until 2011, and the cheese shop went live back in the early 2000s. If you end up liking Kotlin, maybe you would like to make a package manager? ;-) 
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [JetBrains/kotlin-native/.../**INTEROP.md** (master → 5e55a75)](https://github.com/JetBrains/kotlin-native/blob/5e55a75d594bb4dd4d2deec558a15e825a915d30/INTEROP.md) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dl31nb8.)^.
I would strengthen that to _never_ inject political content in an interview. Seriously, never. Whether I as the interviewer happen to agree with your politics or not, just bringing up such a divisive area of conversation in an interview tells me that I might not be able to trust you around potential clients or other coworkers. Honestly, the interviewer may well have read `__init__.py` first and immediately said "not a good fit" because involving politics immediately flags you as a potential liability.
Finding a nice way to represent deterministic infinite state automatons for my cs thesis. I believe no one will actually need this even in theoretical cs but at least it's kinda fun to do. :D
Thanks! There will be more interesting stuff! 
On windows insure you install python to path this allows you to use the command prompt for pip. If you already installed then look on YouTube for adding pip to the environment table.
Obviously I know what a Julia set fractal is, but could you explain what this is for the other guys? (Google and Wikipedia only confused me further when I tried to get an explanation)
Great. I'd be very interested to know what conclusion you come to!
&gt; Everybody look at my website, I *might* do something interesting! Don't forget to like, comment and subscribe…
try typing python script.py
What's in your command file?
Your work, as always, is fantastic. Always glad to see your newest content!
that worked... thanks holmes
No problem!
Can you laminate the paper? Will the Qr still work? 
Just made a simple program to model ballistic flight and graph it. Other than that, working my way through the data visualization section in Python Crash Course.
Thanks! I'll keep on making this repo more and more interesting.
Sure. I will make a wiki page for this repo and explain more details of the images there --- after I have finished the hyperbolic models!
Thanks!
Hi, I think you have to pass the keyword arguments options as **options. Options should be a dictionary and must have keys c1, c2, and w. The Basic Usage in the Readme shows exactly how :D Hey I do appreciate that you're checking this out, thank you so much! I am still trying to improve the library and add more pso variants. If you have any bugs or feature requests, please write it in the Issues tab in the github repo link :D :D
3
Nice. Would you mind adding the link to the github repo on your docs and on the package on pypi? If you'd like a template for creating packages such that the docs are rendered for gh pages and pypi by sphinx automatically, I have a cookiecutter here https://github.com/knowsuchagency/cookiecutter-pypackage
Oh cool. I was actually just looking for a two-sentence summary for the not-math-inclined, but a wiki page works as well!
You should be redirecting logs to `stderr`, not `stdout`.
Looks like a Java programmer being forced to write Python. Almost the entire package is boilerplate. This isn't necessary in Python.
Here is a short explanation: consider a complex function f(z) which receives a complex number z and returns a complex number w=f(z). (in my program f(z)=(z^2 + c) / (z^2 -c ) where c=0.7). For a given z, will the sequence z, f(z), ... f(f(f(f(z)))), ... explode to infinitely large, or oscillate in a bounded region ? So I just computed the modulus of each item in this sequence, and remember the first index i for which the modulus of the i-th item exceed 2. i is called the escaping time of z. To draw an image, just think each pixel of the image is a complex number z in the complex plane, and color z according to its escaping time. Then one got the image above. This is the most common way for drawing almost all fractals.
Not python-announcements, python-dev and python-ideas.
But can they make a Python set fractal in Julia? Game, set, match, Julia programmers.
Building a bot using the Yahoo! Finance API and possibly Quantopian to trade/bet on earnings calls.
Cool! Thanks for the explanation.
Well, hopefully not that specific `__init__.py` ... I'd hate to have a technical recruiter reject a candidate because they looked at that particular file and thought "what sort of idiot gives a blank file at an interview?!".
Thank you to everyone who makes it so easy and accessible to learn Python
Sorry, you need to know a bit of digital marketing, (which I hope u dont) to understand what I'm trying to say.
Read "How to Write Short"
If u r running any course on this then I might enroll.
Your code looks like a mess! 😒 The problem is well described by the compiler: The text you parse isn't *encoded* in UTF-8. You use ``open`` without providing an encoding parameter, so the [default platform encoding](https://docs.python.org/3/library/functions.html#open) is assumed. In your case it is UTF-8 obviously as python tries to *decode* an UTF-8 byte sequence into a ``string``. The problem is simple: The text file simply isn't encoded in UTF-8 😉 You have to pass the encoding parameter to the ``open`` function with the correct encoding of the file! That's all. I could make many comments on your code but with a smartphone that sucks. So I simply tell you to follow PEP8! And you need not to explicitly call ``close`` on a file object if you use the ``with open ()`` idiom.
app.py: * Base coordinates should probably be a constant, though given the context this feels super nitpicky. * Coordinates should probably be handled as a tuple, named tuple, dict, or class, rather than a pair of scalar parameters. Not a big deal either. item_reader.py: * This is unnecessary. Just iterate over the file object directly. customer.py: * **(1)**Don't use class attributes to set object defaults like that. This is very bad because it makes me think you don't understand how Python classes work. * `__init__` should probably take id, lat, long, etc as keyword arguments. Taking a json encoded string works for what you're doing, but I don't think I would ever write a class like that outside of a toy example like this. * If you do that and give it an extra \*\*kwargs param, you can construct customers as: Customer(**json.loads(line)) * `__str__` will fail for the default object because `self.__dict__` will be empty. * If you want to get fancy, you could override `__new__` and ensure there's only ever one customer object with a given id. gcd.py: * **(2)** 'Feels' very wrong. Probably there shouldn't be a class here at all. * Instances of GCD are... earths? With different radii? * Getters/setters in python are poor style. Use properties instead. Or just set base_{lat, long} as part of `__init__`. * Rounding shouldn't be part of `calc_distance`; return a precise number and let whatever code is doing display deal with display. invite.py: * Most of this doesn't really do much. I would refactor and write create_invitations more like: def create_invitations(file_, base, distance): with open(file_, 'r') as fh: customers = {Customer(**json.loads(line)) for line in fh} nearby = [cust for cust in customers if is_nearby(base, cust.position)] # sort and whatever here **(1)** and **(2)** are the issues which strike me as serious. 
Don't forget to complain about all the other non-Perl examples, too! There's way more of those!
thanks a lot.
&gt; (1)Don't use class attributes to set object defaults like that. This is very bad because it makes me think you don't understand how Python classes work. While I agree with the rest of your comment, I strongly disagree on this one: setting attributes at class level actually makes a lot of sense in python: 1. If your objects will have many default values and memory consumption is an issue, then that saves a lot of memory + (less importantly) it saves initialization costs 2. It's often slighly easier to write/document/inherit
It's pretty. :-)
hey, your repository is p cool, ty
Meson is currently much more mature compared to this, offers more features and so on. However, this is probably mainly a question of time and contributors. Two advantages that Cook already has: - Rules are written in a real programming language, you are not restricted to running commands - Compiler warnings will be emitted and also stored for following builds, emitting them again without recompiling. There are also a lot of technical differences, like Meson using Ninja while Cook hosts the build process itself. I will soon expand on "why cook?" and compare it to other systems.
&gt; Nothing about disable_existing_loggers I have encountered just that, while I started learning how to configure my logging and using it, I suddenly saw "requests" logs in my logfile.
In English, only pretentious douchebags use the word "autodidact." The normal word is "self-taught."
Why? Just use scrapy.
Hm, interesting. I don't think I've seen it before, but it seems it's something that is sometimes done. I don't think it's a good idea to do under ordinary circumstances: * It's easy to imagine someone getting in the habit of this, and then setting a mutable value to be the default. * It's easy to imagine someone trying to change the default value for new instances of a class, without realizing that some existing instances will also change. * We can of course avoid those mistakes, but it adds cognitive overhead for anyone reading or writing code with this class. I don't see it being easier to write or document, TBH. I'll agree that it has uses, and that my objection was too strong. Consider it downgraded from "wrong" to "this rubs me the wrong way." Still, thanks for making me think about this.
First, ask this on [r/learnpython](http://reddit.com/r/learnpython). Unfortunately you might have to just start with [reading the manual](http://sikulix-2014.readthedocs.io/en/latest/scenarios.html#using-python), as it probably doesn't help that you've chosen a rather obscure project that appears to be rather poorly documented. 
If Haskell can interact with the CFFI, you can use that to use Haskell libraries in your Python code.
Depends what you mean by "experience". It's a social platform so you don't in that respect. 
...what.
(Fixed the formatting for you) x = 0 y = 1 for i in range(500): print("2^"+str(x)+" * (2^"+str(y)+"-1)") perfectNumber = 2**x * (2**y-1) print(perfectNumber) x = x+2 y = y+2 You could've just written x, y = 0, 0 for num in range(500): print("2^{x} * (2^{y}-1)".format(x,y)) perfectNum = 2**x * (2**y-1) print(perfectNum) x, y += 2, 2 In fact, I'm certain that there's much better ways to write this program. You might want to use /r/learnpython next time, however, because this subreddit is mainly for other topics.
The correct subreddit is /r/learnpython, except that a) you would need to read the sidebar and meet some minimum requirements for asking the question; b) people will probably not want to help you with something like this anyway (since it doesn't really have a non-malicious use).
https://github.com/ehmatthes/intro_programming
The best way to handle logging in larger applications is to configure it via a configuration file (https://docs.python.org/3/library/logging.config.html#logging-config-fileformat) and load it once on application initialization. After that, you should define beforehand what loggers will you use and whay their purpose will be (myapp.engine, myapp.worker) or you can just use the ``__name__`` variable as the name. Also, as a good practice in larger systems, send everything to stdout/stderr and let the environment manage the logs (redirect them to some file, or over the network). This method lets you change the destination of the code without changing the application code. Hope it helps!
well done
I suggest that you were originally correct as we are talking about default values, which should to me always be passed to the initialiser as keyword arguments.
I can hear Stranger Things intro music
As long as the reflection from the lamination isn't enough to keep the phone from scanning it, it should work.
This is exactly what I was trying to do this morning, first time putting Julia into practice. I couldn't get the plotting to work easily enough though. Python already has every conceivable question answered on stack - Julia isn't there yet. Or maybe working only with mainstream languages made me forget how to search more thoroughly.
I'm in more or less complete agreement, I'd add: * having your package called `src` is odd * pytest recommends against making your tests directory a module. Remove `src/tests/__init__.py`, fix imports and add a `conftest.py` at the root of the repository. That will also let you invoke your tests with just `pytest` * since you’re using pytest, unittest-based classes are completely unnecessary * don’t invoke magic methods by hand e.g. `c.__str__()` is not correct, this should be `str(c)` ### app.py * use a `__main__.py` rather than an app.py with a main test * logging then re-raising an exception (without there being anything else to catch it) makes no sense, do either one or the other, here you should just remove the try/except and leave only the function call * I support other people’s suggestions to not put politics in your code, especially not for interviews ### customer.py * with respect to `__str__` you could just pass in `self` and access the attributes via `{0.customer_id}`, … Alternatively, just use [attrs](http://www.attrs.org) which will handle the repetitive grunt work for you: str, type-checking and conversion, … * or it could just be a namedtuple: Customer = collections.namedtuple(‘Customer’, [‘customer_id’, ‘name’, ‘lat’, ‘lon’]) which you’d instantiate using `**kwargs` as /u/EsperCharmMyself suggested, that gives you proper str/repr, hash and eq without the need fot an extra dependency * why doesn’t your customer.json provide lat/lon as floats directly? json supports double-precision float, same as Python ### GCD * 6371000.0 could just be the default value for `r`, `None` is a useful value when you default to mutable objects, that’s not the case here * calc_distance would be simpler to use and understand as a free function * and with that out there's nothing you can do with a GCD without `base_lat` and `base_long` being set, they should be required.
Nice. :)
I've been writing a craps game, to see if I can test different strategies. It's going to be fun to see if the house always wins, and to prove to others that it really is a game of chance. 
Should have added comments, getting confused now. :)
Ahhhh... yap the getting indexes grabbed at a sum. I was wrong, sorry. :D Yeah generators are fun, but you pay for that fun when making them a list. They are ok when grabbing a data in the air, the once you need a part or complete list... it gets tricky. I often use them to test enormous data types for specific solution. But have you thought about functional programming? I am not trying to change your code, or to tell you what to do, but it you might be interesting check out pow2 = lambda x: math.pow(x,2) ## could be also written as x**2, or sqrt x**(1/2) vect_coord_distance = map( lambda (x,y): x-y , zip(coord1,coord2) ) # generating vector hypotenuse, zip generates tuple for every element, not indexing necesery ::&gt; generators :P vect_coord_distance = map( pow2, vect_coord_distance ) # squaring every element scalar_distance = math.sqrt( sum( list( vect_coord_distance ) ) ) # here i will wait till last moment to convert it to list, when all elements are calculated each. This takes a bit more space, but map and filter are quite fast. You could make it a one liner ... but to each its own preferences. 
First glance, I thought it was a cross section of a penis.
Of course not human :P
&gt; So, do you know any example of a python bindings for an Haskell library ? You can't quite do that directly, first you need to create a C API for the library, *then* you can use cffi (or ctypes) to call that C library from Python. See [Calling Haskell from C](https://wiki.haskell.org/Calling_Haskell_from_C), [Call Haskell from Anything](https://github.com/nh2/call-haskell-from-anything), [Using the FFI/Calling Haskell from C](https://wiki.haskell.org/GHC/Using_the_FFI#Calling_Haskell_from_C), I'm sure you can find others, though note that most of the FFI docs will be for the other way around (calling C from Haskell which is both more common and easier). Basically the way things work is that the only stable wide-spread ABI is the C ABI, so to make two languages A and B communicate you need to somehow produce a C interface which one can provide and the other can use. &gt; I know that Haskell from python exists, but it's just a toy example :/ It's a toy example but it shows the basics, you'll have to do essentially the same thing: create an FFI declaration for the Haskell library, and access that via the Python FFI.
some days i think i'll leave this sub and never come back.
Oh great! I will see how it behave compered to the theano performance for Jacobian matrix computation : I'm using sympy and Theano in order to approximate and compute finite different approximation for arbitrary pde solving, and I have to compute the Jacobian "by hand" in order to have a sparse result. May be that your library will "free" me a little compered to theano? I will try it :)
That explanation reminds me of the excellent song [MandelBrot Set](https://www.youtube.com/watch?v=ZDU40eUcTj0) by Jonathan Coulton. 
I know just enough to identify a plug without content.
Why not just use berryconda on Pi1 at home, backup microsd card with dd and compress it, then send it to the space station and ask them to just dd the image to their card...?
Let me get this right, you refuse to store the .kdbx file somewhere in the cloud without 2FA so it's always accessible, but you're fine with storing it on paper... Sorry, but to me it's just wrong on so many levels... and going back to using paper is not exactly environmentally friendly.
Use Anaconda to install Python and popular modules.
No problem. I should have pointed out that I was getting these errors from both of the jupyter notebook examples in the repo, not with code that I was trying to write myself.
Your post is very low effort and might be in the wrong place. That being said, here's a suggestion for you: If you really want to go forward with this, hire a freelancer to build it for you. You can find freelancers at https://www.upwork.com/
I *strongly* disagree. Class-level attributes are globals. If they're large, they're probably mutable so can't be safely global. If they're small, they're probably shared anyway, so memory costs are minor. If you're using another interpreter it's probably faster to only ever have the local version, too. I also strongly disagree that it's easier to write, document or inherit, and a tiny improvement in ease of writing is no substitute for correct semantics anyway.
&gt; z = RiemannSphere(Klein(Mobius(Klein(z)))) Pure beauty. Reminds me of good old Apophysis. Have you considered doing a MandelBox? Edit: Yes, i know the piece of code is from caleidoscope, not julia
You may want to read the math about (known) perfect numbers because your code doesn't work and prints out a lot of nonperfect numbers.
not true. it uses python for it's plugin system, but it's written mainly in c++.
In English, autodidact is a noun. take your shit elsewhere.
well we all start somewhere... thanks for the advice 
Yes, also an autodidact. Sikuli appears to use Jython -- the Java implementation of Python -- and relatively few people have much experience with that; I looked over their resources and there's not much there, though there are some examples in the FAQs. I'd start there, and maybe contact them on their forums.
Just saw this video and discovered the Pycon 206/2017 YouTube channels. I'm still a beginner so a lot of it is over my head, but it's enough to get you excited about Python.
That is awesome! I will be giving this a try to see what kind of monstrosity I can make. Thanks :)
I've a lot of doubts too: - Celery is good, but heavy and complex - Zato is even more complex and one-person project (think about this). I like their docs. - Nameko its great. I love it. But too much granularity is bad because serialization/persistence rabbitmq overhead. - Actor based approach sound great. I want to test thespian or pikka in a pet project. I've not read about this in your analysis. Using a queue system: - its at most one message delivered (so you can lost messages), al least one (so make your system indempotent) or exactly one (so you belive in science fiction). - its very fast but without persistence, it have persistence but you can lost some messages (between fsyncs or because you don't wait for replication) not very slow neither very safe, or... This things make your code dependant of tecnology. But there are more layers... Rpc systems: - Can I avoid overhead in local calls? - Can I interoperate with other languages? - Are functional and transport exceptions mixed? There are a lot of posibilities creating a lot of possible combinations. More I think about it, more doubts I have. Excuse my poor english.
Thanks for your clear answer ! I am not very confident, but let's get into it ! 💪
&gt; Python Crash Course A Hands-On, Project-Based Introduction to Programming thank you so much, is the ebook for the latest version of python? 
Usually when I want to be pretentious I describe myself as a genre-spanning multi-instrumentalist, now I have a new word. Thanks OP. 
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
/r/learnpython Python can be used for almost anything, but it's usually for scripts and services. Actually, Reddit runs on Python.
Is that why in many examples there is a line: fig, ax, = plt.subplots() Does this line create two separate objects (figure object, axis object) to allow the re-use of the axis object separately from the figure?
Just to add to this; Python can be used to make almost anything indeed! Including mobile apps (with Kivy), small games (PyGame, Ren'Py, PySDL2) and scripts to automate stuff.
E-book is about python3. It also covers few python2 examples so that you can be aware of differences between versions. 
Thank you very much, I really appreciate it 
Great and Congrats to you..would be really great if u look for urself before commenting and criticising other ppl stuff. 
Thanks for the reply, running scripts makes sense to me, rather than being a program back end builder unless I've misunderstood :)
Sounds interesting :) I'd be very interested in learning to do mobile apps down the line, and my job could benefit from some script automation I think if I were to learn it thoroughly. Thanks for the reply 
Well, it is not free, false advertising, cost 15$ and no reviews https://www.udemy.com/the-complete-python-developer-course/?siteID=TnL5HPStwNw-TG3TDrqSjFg4Mg6S5u_SNw&amp;LSNPUBID=TnL5HPStwNw
I know a quite a lot of astronomers and they love Fortran even more.
Awesome thank you for the lead!
Well, it was free when I posted it. Coupon sold out. 
In English, it is customary to capitalize the first word in a sentence.
Imagine creating a programming language and having it being used by astronomers. Crazy.
Have any of them presented a talk at FoCon? (Or whatever a worldwide conference for Fortran programmers is called) 
I'm an astronomer and I use python all the time! 
Yes. It makes two objects. You'll get one figure per window and one axes per subplot. Let's say you keep your x limits constant. There is no need to update the horizontal gridlines then. You don't clear a plot, you access the line and update the data on the line. Even if you want to update the axes limits, never clear an axes.
I've seen a lot of Pycon talks reposted by other youtube channels who make $$ on them through ads. I feel like we should redirect traffic to the original pycon video (in this case: https://www.youtube.com/watch?v=ZyjCqQEUa8o) since Pycon is an awesome event every year, and should be supported. For example, in this repost, they cut out the first ~5 minutes, where he explains what Pycon is and why it's great. The original video has like 6x fewer views than this one. Plus, the Pycon channel doesn't have ads (that I've seen).
You can get a bunch of ideas from https://automatetheboringstuff.com/. It teaches Python using projects. Another good book is "Python Playground" which has a lot of neat projects, but it's not free. 
That sounds harder than typing "pip wheel package"
Thanks for the link I'll check it out when I get home :) sounds like a great place to start 
As a [former] astronomer, the ENTIRE radio astronomy community uses python pretty much exclusively. The new generation knows pretty much nothing else as all the tools developed to deal with the array data use it. Your experience may vary depending on the age of the user and what sect of astronomy they are working in. 
Thanks for the reply. I already have a logging config file I define; one of the workflow my collaborator and I have is we periodically run an individual file in our application for debugging purposes (we through a simple main function in that tests the functionality of some of the classes/objects within the file). Because of that, I have to define the location of my logging-config file in every file individually which while a little annoying isn't the end of the world. Anyway I'll keep on a lookout for some other good practices, and I should probably take a closer look at some larger python libraries (a-la youtube-dl and so on) and see how they do it.
or IDL.
Fortran ruled physics for 50 years. I had a physics professor, near the turn of the century, that used 'f90not77' as his ftp server password for handing in class assignments. At the time, I was the only student handing in his assignments using python. Now it'd be 90% of the class, I'm sure. Both Matlab and python's numpy (and numeric before that) were built as a front end to hard to use but very fast/powerful fortran numerical routines: BLAS and LAPACK. So Fortran's legacy continues.
[@byJakt's latest tweet](http://i.imgur.com/MQ30uHP.jpg) [@byJakt on Twitter](https://twitter.com/byJakt) - ^i ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
In the near term, lamination will protect paper, but in the long term (a several decades or a couple hundred years), it actually causes damage to the paper.
That's interesting! Although, by then you probably won't need your keepass file... 
As a call-to-action, for packages you use that actually need *binaries* (not just source wheels, i.e. I'm not sure why Gohlke did NetworkX), you could file an issue or PR to [build it on Appveyor](https://packaging.python.org/guides/supporting-windows-using-appveyor/) or the like, so perhaps Windows binaries could be made available via `pip`.
I've been using the YouTube videos all day to learn.. They're amazing! Thanks man
Could you include some short description?
Offering ~~MD5~~ SHA256 signatures would help, but it appears that those aren't offered. ಠ_ಠ EDIT: My poor choice of saying MD5 probably shows my age. It was the right choice for a long time. But, as /u/dispelterror points out, if the hash is provided over plain text, then it too can be compromised.
Id second that automate the boring stuff with python. Book is cheap. The author has a few videos on youtube and he has his $10 to $15 course on Udemy where hell answer your questions. That's where I started and I enjoyed the book. Gave me a pretty decent foundation.
Sounds like something useful I could use rather than just being a hobby I guess :) and it's maybe something I'd want to move into career wise and I heard it's similar to C# etc I will definitely check out the book and course :)
MD5 is neither a signature nor secure in any way. Please don't use it.
"A good programmer can write Fortran code in *any* language." ;)
SHA256/SHA512 would be a lot better than MD5. Either way, in this situation it would be irrelevant. As long as the page where the download link for the binary is being mapped to the hash that the binary should match is being served over HTTP then it would be trivial to replace the hash strings with ones that match the compromised binaries. 
[See if this helps.](https://acko.net/blog/how-to-fold-a-julia-fractal/)
I personely liked the course of the SoloLearn app
Thank you. After a day of trying it finally worked
A lot of those packages aren't just for Python, and many of them were officially not just unsupported but never-going-to-be-supported on "Winblows"**&amp;**. **&amp;**: The package authors' nickname, I certainly didn't invent it.
Yes, false is indeed not not false.
I have to say, it is funny to me that you put "[Learning Python]" in the title of your post but didn’t think to instead, as the sidebar say, post to /r/learnpython As for your actual question, are you sure you're not getting stuck in your loops? Also, it is a **really** bad Idea modify a loop while iterating. Chances are this is your issue since it isn't doing what you think. Try instead (if you *must* do it): for item in re_f[:]: # Note the array slice notation to make a copy print(item) re_f.pop()
How is this different from [chromote](https://github.com/iiSeymour/chromote) or [PyChromeDevTools](https://github.com/marty90/PyChromeDevTools)?
I recently switched due to vim not liking having Py2 and Py3 support other than a rendering glitch with the cursor on my personal laptop (apparently it's something to do with tmux and neovim interaction), I've been loving it. `:vs term:///bin/bash` has been a game changer for me
https://www.jetbrains.com/help/pycharm/2017.1/managing-branches.html 
I worked one summer with a physics professor who swore by IDL, even though he had nothing to do with astronomy. Honestly, it did have its benefits in my opinion, but the lack of resources compared to say, python or even matlab, made learning it astronomically (hahaha) harder. And, he was always super restricted by the licenses. We would fight over the few available.
Really, I'm trying to learn the multi-threading. Yes, I do change the array, eh list sorry, while in the loop, but it does not explain the behavior... i think. The last line, after the Thread is "create, it should still be executed, no? import re import time import threading import sys class mainApp: myVar = str("Hello World") myThreads = [] def __init__(self): print("mainApp init.") print(self.myVar) re_c = re.compile(".") re_f = re.findall(re_c, self.myVar) for item in re_f[:]: print(item) print(re_f) myThreads = threading.Thread(target=self.aThread()) print("*************") sys.exit(0) def aThread(self): myc = int(0) while myc &lt; 3: print(self.myVar) time.sleep(2) myc += 1 if __name__ == '__main__': print("MainApp will init") threading._start_new_thread(mainApp()) print("*********1") Console shows: MainApp will init mainApp init. Hello World H e l l o W o r l d ['H', 'e', 'l', 'l', 'o', ' ', 'W', 'o', 'r', 'l', 'd'] Hello World Hello World Hello World ************* The output shold be: MainApp will init mainApp init. *********1 # NOTE The difference... Hello World H e l l o W o r l d ['H', 'e', 'l', 'l', 'o', ' ', 'W', 'o', 'r', 'l', 'd'] ************* #And here Also... Hello World Hello World Hello World 
I'm a Pythoner and I use astronomy all the time!
Does the CC license allow this? 
As an astronomer, I approve this message. And to all astronomers still using IDL, go to hell.
That is a good start! Firstly, I would look into structuring this into classes. You can eliminate those global calls by using classes. I would also look into what code you are re-writing over and over, and throw that into a function or method (your open statements are a prime candidate for this). Also, check out opening files using the 'with' statement. With statement SO thread: https://stackoverflow.com/questions/32379147/understanding-the-python-with-statement#32380154 Namespaces are a big deal, as well. https://stackoverflow.com/questions/3913217/what-are-python-namespaces-all-about I hope that helps. Cheers! 
Thank you making your book free for public use. A little bit ago I took an introductory level C++ and Matlab college class. This upcoming semester I will be taking an intermediate programming course in python and am looking for some supplementary material. Do you think that this would be of great use? The description for the class material is as follows: " Intermediate Programming (3) Object-oriented programming, recursion, fundamental data structures (including stacks, queues, linked lists, hash tables, trees, and graphs), the basics of algorithmic analysis, and an introduction to the principles of language translation." Any advice would be greatly appreciated. :)
I never said I refuse to store the kdbx on the cloud. I may even (:wink: :wink:) store it on my own website, on a non-indexed url. Re: environmentally friendly agreed. This is not meant to store large amounts of data.
&gt; the extreme right racist nutbag with tiny hands Why do people always forget that he also raped children? It is hard to top this guy's foulness, I bet even Hitler would have been disgusted.
You are not getting that there are hosting providers with free plans and one click WordPress installation and reasonable storage. Even the custom domains are cheaper than Medium.
hahahah I 100% meant `app.py`... my bad!
"Hold my beer." - Hitler, A.
Haven't tested that use case, but as long as the contrast between the foreground and background colors in the QR code is big enough it should not be a problem.
I find that description to be a bit weird. Linked lists aren't really a thing in Python. The primary data structures in Python are dict (technically a hash table), list, set and tuple. The collections module has a few special ones in it too. To me it looks like they took a generic programming class description and slapped it on a Python class page. I don't know what the term "language translation" means here. Learning OOP will definitely be of benefit though.
Yeah, it used to be taught in C++, but they switched it to python just last year and probably did not update the description. However, the course should still (in theory) cover much of the same material. Does your book cover any of this stuff and if so in what general parts? I am not proficient enough of a programmer to look at the chapter headings and know if it would be useful for me to read.
Well we are looking for experienced senior devs. So, expecting a lot. Not trying to be flippant or insulting but good devs that have worked on serious systems 4-7 years internalize the kinds of issues that come up and know to ask about them. It's somewhat hard to define. The spec of the problem is purposefully a little vague. We all know tic-tac-toe right? Experienced devs know not to assume product/customer has a clue or are even talking same language). Questions like capacity, scaling, testing, interface (do we need to run it interactively, programmatically maybe there are clusters of machines running millions of tic-tac-toe games pitting AI's against each other). Follow up questions we ask are how would your design handle different sized boards, non square boards, more than 1 player, coverted into an API rather than console. The better experienced devs bring up these issues before we ask them. Any problem given in an interview I'd and have asked at least - Ensure the spec is complete and that interviewee and interviewer agree what it means exactly. - What's the acceptance criteria? - What about testing? - Is there an SLA that needs to be met? - What is the deadline? Even if all the answers are "don't worry about that, this is just simple coding exercise" It signals that you know these are issues that come up, that you've dealt with them and understand that these answers inform and restrict the architecture and code. 
Already removed from Minimap, the fork will be deprecated.
I talk about the primary data structures in Python (dict, set, tuple and list). The ones you'll probably use the most are dict and list. I do talk a bit about classes and how they work, but it's not a deep dive into OOP itself. I actually know of a few good books on OOP in Python though if you want more of that. I didn't discuss recursion in the book, but that's probably a good idea to add. The main thing this book is really good for is learning Python, then learning some of the meatier topics in Python. It is free though, so at worst you can use it to supplement what you're learning in the class.
Thank you so much. I appreciate your willingness to help out us beginners :).
No problem. I'm glad to help!
BLAS and LAPACK are not the only reasons Fortran continues to be a language of choice for (astro)physics. I would say one of the reasons for its succes is because it is low-level enough to be relatively easily optimized for large simulations code (e.g. CFD codes able to simulate a large chunk of universe, or the inside of stars) and still quite fast to write because of the numerous array primitives. In some sense, one could even argue that it is better suited than C for this kind of job. Of course, another reason is *inertia*. Because rewriting large codebase in C++ or any other more modern language would require dedicated grants, for no clear short-term results… so no one wants to do it. Also, the Numpy community is kind enough to provide physicists with the excellent `f2py` tool, which basically allows us to call Fortran from Python. This combined with the `fortranfile` module (or its implementation in `scipy.io`) makes my life so easy when I want to interact with simulations :-)
Love, or loved but just always have other higher-priority pressures on their time so they perpetually put off rewriting it?
Thanks! Ill post in learnpython going forward. But you were too late i already got my answers!
Made my first Reddit bot with Python. The script uses BeautifulSoup to scrape "Top X" articles from [BuzzFeed's archive](https://www.buzzfeed.com/archive) and posts the article title as well as the main points of the article on /r/buzzfeedbot. I have the bot running on a Raspberry Pi which checks the website every 15 minutes for new articles to be posted 
few comments: * Use 4 spaces instead of tabs * function names should be snake_case instead of camelCase * split up in different files * don't use globals * don't script, use `if __name__ == '__main__': main()` and put main code in main() function. * use classes 
If you want to become an expert in Python, you should definitely watch this PyData talk from James Powell. EVENT: PyData, 2017 SPEAKER: James Powell ATTRIBUTION: The original content of this video was published under the Creative Commons Attribution license (reuse allowed). The link to the original video: https://www.youtube.com/watch?v=cKPlP...
&gt; Of course, another reason is inertia. Because rewriting large codebase in C++ or any other more modern language would require dedicated grants, for no clear short-term results… so no one wants to do it. This is the reason.
What are the advantages of spaces over tabs? What about splitting up into multiple files, especially for a fairly short program like this?
&gt; Use 4 spaces instead of tabs I'm new to scripting, and Python, but can someone explain why spaces are recommended over tabs? It seems to me that tabs are superior, because an error of +-1 space is hard to see, but crashes the script. The only convincing argument I've seen so far is that tabs can be different sizes in different editors, but afaik that doesn't negatively affect Python scripts.
Splitting to files allows easier extension and by default you most likely don't want to run script over 100 lines because it's hard to maintain and read. [Regarding spaces vs tabs see this so thread, it has a lot of good answers](https://stackoverflow.com/questions/119562/tabs-versus-spaces-in-python-programming)
Because it's recommended by PEP and there are a hundred other reasons. [see this SO thread, it has a lot of good answers](https://stackoverflow.com/questions/119562/tabs-versus-spaces-in-python-programming)
Here is a xpath tutorial that has more examples in it. http://www.zvon.org/comp/r/tut-XPath_1.html
&gt; Fortran ruled physics for 50 years I knew a recent phys/astronomy grad who discovered bugs in some widely used Fortran math libraries for her field. And she was a beginner programmer. It made me wonder how many more math errors were hiding in code that very few left can read...
oh god no.
Sounds like you mean write it for you.
Even if you *can* read it, it's not at all pleasant to read. Some of the code were written before structure control statements were a thing, so you have to decipher what each of the `GOTO 1337` means (it might translate to an `if`, or a `while`, or a `switch`). Moreover, a lot of the code don't explicitly initialize things, or reuse/mutate variables unnecessarily (possibly as an optimization that used to make sense back in ye olde days).
1. This isn't a Python question. 1. If it were, you should still be in /r/learnpython instead.
Will take a look. I use DO for my company 
Right on...
I would argue the opposite: that Fortran is actually very pleasant to read! &gt; Moreover, a lot of the code don't explicitly initialize things You are talking about Python, right? /s I think you (and probably lots of other people) have Fortran 77 in mind when they claim that it is all about `goto` and implicit declarations (indeed, in F77, `I`, `J` and `K` are assumed to be integer by default). But modern Fortran (starting from F90 and F95) includes most of what you would expect from a modern language. It even has a `switch` equivalent: `select case` ;D Most of the code I use (and most of the code I've seen) forces explicit declaration with `implicit none`, and it is common practice to initialise things, just as you would do in C/C++. And luckily, `gfortran` and `ifort` have flags to catch uninitialised values… just like in C or C++. I feel like I'm defending Fortran a lot whenever I see these topics, but I think there are lots of misconceptions about the language. Sure it's not the sexiest trendiest language ever, but it does the job quite well. Fixed form with 80 columns is no longer imposed, provides dynamic arrays, it can be interfaced with C, it supports OOP and recursive functions, … what else do you need? It's probably not the best for a web or mobile app, but for HPC, this is **the** tool people use and will continue to use. And because it is so widely used, people have developed Python tools to interact with Fortran code or binary format, allowing people like me to benefit from the best of both worlds :-) /rant
:( I miss getting mad at lun.
Thank you for doing this! I got your email about this today (because I had downloaded the book previously) and was just about to post the link here on Reddit. You beat me to it! ;)
The most common way to do that is to use the string method `lower()` to convert the user input to lowercase, and then check in a list that is also all lowercase. if user_input.lower() in case_list: --- If you have more questions like this it's better to post them on /r/learnpython. Be sure to [format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin. Also, include which version of python and what OS you are using. 
Thanks!
Thanks for reading the book. I hope you have enjoyed it!
The other way round is a hangover from C (and to a lesser extent C++).
Alex Martelli's main point: &gt; So, if A's structure is: if iswhatiwant(thefile): useappropriately(thefile) else: dealwithwrongness() &gt; then A is buggy. That is because, between the moment in which the test 'iswhatiwant' runs (and returns a true value), and the later moment in which procedure 'useappropriately' runs, *just about anything may have happened* -- in particular, some other program Z might have removed or modified 'thefile' so that it's NOT what A wants any more. I.e., A may lose control of the CPU between the moment it tests and the later time in which it uses the result of that test. &gt; This is known as a "race condition" and it's among the hardest problems you may run into. A may seem to be running just fine 99 times and then the 100th time BOOM -- because of accidents of timing between A and other stuff that may be running "at the same time"... a "race", so to speak, whence the name whereby this horrid condition is known. &gt; Fortunately, in a language with good support for exceptions such as Python, you are NOT doomed to enter the hell of race conditions -- just use [easier-to-beg-forgiveness]instead of [look-before-you-leap]: try: useappropriately(thefile) except ItWasWrong, howwasitwrong: dealwithwrongness() 
Why do you need numpy for this simple encoding? There is no reason for that? &gt; ROT-13 is one of the most common cryptographic ciphers I don't think so, it is mainly used as a toy example how encryption can work, because it is very easy to understand and to build. And you don't even build it on your own, you use the standard library. There is no educational point in that regard. And please don't let it look that this 'technique' would be safe in any way, just give your article a proper disclaimer that this is just a toy example and shouldn't used in real life! This brings me to my next point: &gt; The .npy format adds an extra layer of security during transit because it’s a binary Numpy file and not a plain text file. You know anybody with a numpy installation can load this file easily, also since numpy is open source the specs for the format are free to see, rebuilding would be not that hard for people who want to see your secrets. Please don't say something stupid, in the end newbies start to believe that crap. &gt; You’ve learned a basic cryptographic technique for obscuring simple messages Nobody learnt anything, you didn't show them how to do rot-13, so they just use the already given codec nothing more. Sorry but I don't see the point of this article, really, can you explain me your initial intentions? Also this is kinda funny: &gt; No scary math involved. The reason that numpy exists is for doing *scary math*... And don't get me wrong here, using toy example for introductions into a topic is great, but espcially with this topic, be clear that are toy example and nothing more. You know that sending your friend a post card with the raw message on the back would be safer, because nobody would care.
This was meant as a fun way to show Numpy in action...
It's not meant to be a crypto article
&gt; Numpy in action I can't see any *Numpy in action* in this article. 
Numpy is overkill, rot13 is hardly "cryptographic". Use https://cryptography.io/en/latest/fernet/ instead
Unless I am missing something, this does not look like a service but rather a module. In other words, if you have completed the express installation, you now have the `instapy` module installed, but you still need to write your code, and run it yourself. If this is correct, you would want to create a repository just for your code, and put the git url in you requirements file (requirements.txt). This being said, if you just want to try it out, or if you need help figuring out how to daemonize it, the docker instructions seem pretty reasonable. https://github.com/timgrossmann/InstaPy#running-with-docker-microservices-manual
There was a time, maybe it is still true, where astronomers used Forth for instrumentation control. Of course back then a 1MHz processor would have been state to the art. Python just rose to the top because there isn't anything else out there that really fits the broad array of users needs. One day Python will be replaced with something else but it is very entrenched so don't expect it to happen fast.
To sum up probably the most common error I've seen software generate over my career doing administration, operations, engineer, and architect work has been the situation where you check for conditions before attempting to operate. The "LYBL" in this case. The classic example (the mailing list touched upon it), is checking for a files existence, _then_ attempting to operate on it. Between those two distinct operations the file may be deleted, or permissions may change, or it may in some other way be inaccessible. Now you have a situation where your file check returns positive, but your file open fails unexpectedly. To properly handle this, you'd need to add a check around successfully opening the file, so why not just check once while attempting to open the file and skip the earlier test? This case becomes significantly more important as you start working with threaded or multi-process applications. You could have a pool of threads deleting files on disk, and if two threads successfully test for a files existence, one of those is going to delete the file before the other. Now imagine the dictionary example from the Microsoft post, but apply the multiple threads to it. You could end up overwriting keys and/or missing data in your final result because the two threads stepped on each other. This is an almost unbelievably common error to find in our industry. Race conditions can be caused by it, unhandled exceptions, panics, etc. "EAP" is almost always preferred in these situations in nearly any language you're likely to use (obviously there are exceptions to every rule).
One thing that I agree with in Alex's post is that Python is a practical language. In fact you an LBYL _and_ you can use ETBF in Python - and you can choose to use either whenever it makes the most sense. I'm an abuser of LBYL in Python primarily because it is often more succinct within the code _and that is practical_. And despite the race conditions that Alex appropriately identified - I'm rarely in a situation where race conditions matter. In those cases, I'll probably use try/except clauses with impunity.
chromote can not register Chrome Dev Protocol event and can not use Chrome Dev Protocol directly . PyChromeDevTools can not control multi tabs
&gt; Haven't tested that use case How did you deal with the paper crumpling and deteriorating?
&gt; I like the idea of storing to PDF or png, both likely to be readable 200 years from now. If you want to store things way longer than that time period and want to be sure it will be still readaable, the best way is to use black-white/colored slides or microfilm. You can build them out of materials that will survive a very long time and you only need a light source and a projection plane to *read* them. Technology can change tremendously over the times, or the nuclear holocaust can happen, but simple slides stored in a salt mine can easily survive this and are easy readable, even if the people can't understand the used language anymore, but pictures are fine :) This is actually used to store copies of very valuable cultural/historical documents. Copy them on microfilme and deposit them in an old salt mine. In the hope after something really bad happend it can be found by someone and it is still readable for them.
Here be mine from enum import Enum class Winner(Enum): """ Possible win conditions. NONE - Game is in play; winner as yet undetermined FALSE - Tie game """ NONE = None FALSE = False X = 'X' O = 'O' class Board: def __init__(self): """Create a 3x3 grid of empty spaces.""" self.data = [[' '] * 3 for _ in range(3)] def __repr__(self): """Represent the board in its current state and the corresponding moves a player can make.""" return '\n'.join(str(l) + ' ' + str([n + (3 * i) for n in range(3)]) for i, l in enumerate(self.data)) def __str__(self): return repr(self) def place(self, number: int, symbol: str): """ Place the given symbol at the given place on the board. If the space is occupied, raise a ValueError. """ row, col = number // 3, number % 3 placed = self.data[row][col] if placed != ' ': raise ValueError(f'{placed} already at position ({row}, {col})') self.data[row][col] = symbol return self.data @property def winner(self) -&gt; Winner: """Return the board's winner. It may be None, False, or a string.""" # get the symbols on the board symbols = set(s for l in self.data for s in l if s != ' ') rows = self.data columns = tuple(zip(*self.data)) diagonals = ( tuple(l[i] for i, l in enumerate(self.data)), tuple(l[2 - i] for i, l in enumerate(self.data)), ) # tie game if all(s != ' ' for row in rows for s in row): return Winner.FALSE for symbol in symbols: for matrix in (rows, columns, diagonals): for vector in matrix: if all(element == symbol for element in vector): # we have a winner return Winner[symbol] # no one has won yet return Winner.NONE def main(): player1 = input("Enter the first player's name ") player2 = input("Enter the second player's name ") board = Board() print(board) # flag used to determine which player's turn it is player1turn = True while board.winner.value is None: player = player1 if player1turn else player2 symbol = 'X' if player1turn else 'O' # switch players on subsequent iteration of loop player1turn = not player1turn def place(): """Receive user input and update board state.""" position: int = int(input(f'Enter the position you want to place {symbol} in, {player} ')) try: board.place(position, symbol) except ValueError as e: print('\n' + str(e), '- try again') place() place() print(board) msg = f'{player} wins! Play again? ' if board.winner.value is not False else 'Tie game. Play again? ' playagain = input(msg).lower()[0] == 'y' if playagain: main() if __name__ == "__main__": main() 
This is a huge problem be it astronomy, climate research or nuclear physics. It just isn't reasonable to put much certainty into software that hasn't seen lots of eyes. More importantly eyes that really understand what they are attempting to implement. Those eyes these days can be computer based. The point is how do you trust code written by scientists that maybe are under the same sort fo review processes most professional programmer have to endure.
Yahoo! Finance's API still works? Thought they deprecated it.
Uh, I don't need any further information to love Python, but, nice try anyway.
There is nothing like looking up at the stars and wondering what life is like out there. I'm one of those that pretty much believes life is wide spread and as such there has to be intelligent life out there someplace. Hell if you have a reasonably open mind there is more intelligent life on this planet than just humanity. Dogs, the various whales, elephants all exhibit a bit of what can be considered to be intelligence. All of us should be astronomers to a degree.
I didn't know about this practice! Very sleazy! This video actually appears in my 'Recommended' section of my youtube home page. I was not aware of any ad probably because I installed 'Privacy Badger'. Thanks for the info! 
Some of those don't build on average Windows setup or something, IIRC numpy+MKL was the problem in my case and mutually depends
I havent used Docker yet, it seems crazy to me I'd need to learn an entire new technology to run this. Theres got to be a place to add my execution code and run it, right? (Not trying to be disrespectful to your help, I do appreciate it)
/u/8rouillard explained the video stealing practice by youtube channel 'Coding Tech' &gt; I've seen a lot of Pycon talks reposted by other youtube channels who make $$ on them through ads. I feel like we should redirect traffic to the original pycon video (in this case: https://www.youtube.com/watch?v=ZyjCqQEUa8o) since Pycon is an awesome event every year, and should be supported. &gt; For example, in this repost, they cut out the first ~5 minutes, where he explains what Pycon is and why it's great. The original video has like 6x fewer views than this one. &gt; Plus, the Pycon channel doesn't have ads (that I've seen). Therefore I decide to delete my old post and put up the pycon video. I think repost is justified because my last post has incurred some 3.1k views. The talk is interesting and deserved to be seen by more. 
It depends on what you are trying to do. Because of Python's "Batteries included" philosophy, you will find number of libraries within standard library and will be able to do without external libraries, but will be hard not to use. Libraries like Requests, a great library for working with HTTP will never make to standard library. Some libraries off top of my head: Data science: Pandas, Matplotlib, NumPy, Bokeh, SciPy AI/ML: TF, SK-Learn, Keras HTTP: requests Image manipulation: Pillow NLP: NLTK Async: ~~twisted~~^[0] ORM: sqlalchemy, pewee CLI: click CV: OpenCV Datetime: arrow Web dev: flask, django GUI: pyqt, pygobject Html: beautiful soup, selenium for testing As I said depends on your needs, you can find more here: [Awesome-Python](https://github.com/vinta/awesome-python/blob/master/README.md) [0] - As u/nectromanteion pointed out, asycio is best for async if you are on 3.6. 
Don't, use CSS selectors instead. They're much more understandable, easier to learn, and widely used by web developers. For CSS, check out Mozilla developer network's site. 
Yes, you're right. But, for pre-3.6, twisted. As asyncio is included in stdlib from 3.4 , I suggested an alternative. Anyway, thanks for suggestions. I will make corrections.
Why not link to the original video in the first place? edit: Broken link.
Switching between C and Python constantly is always fun, I have tons of moments where I try to use braces in Python or forget to use semicolons in C
Personally, I think it makes more sense to keep things that are related together than to use length as a guideline. Keeping data separate from logic might be a good reason for breaking up a script. But breaking up related methods or classes just because they are more than a pageful to scroll through seems really arbitrary to me, and I also don’t see this pattern followed by most Python projects I’ve encountered.
r/learnpython
Thank you
Playing around with Flask to come up with a calculator for beer homebrewers. Total newbie here... User management is almost finished and now I'll start work on what really matters for the app. 
I'm aware of modern Fortran, but in this thread I'm referring to "widely used Fortran math libraries" like the decades-old relics from Netlib.
Yes I was. I just tried it now and it's a no-go. Oh well.
Is that open source by any chance? :) 
sure I'll link you to the github once I added comments on how it works. (might be a day or more)
Yes if someone could coach me and help me do it that would also be great
Also sounds like your up to a spambot.
&gt; If they're large, they're probably mutable The objects donot have to be large and they for sure should not be mutable. The memory savings happen for the case of many-objects-of-the-same-class-sharing-multiple-default-values. "Many" means tens/hundred of millions objects. &gt; they're probably shared anyway, so memory costs are minor. The interning of values helps, but you are still spending memory on object's __dict__ (or __slots__) &gt; no substitute for correct semantics anyway. semantics is correct, it might be slightly different and a bit unfamiliar, if you have not seen this idiom before. &gt; it's easier to write, document or in It provides an obvious documentation point and an easy way to specify all defaults in one place.. Whether that matters is probably context-dependent.
PyCharm hammered a lot of three guidelines into me
I'm a really big fan of the book 'Numerical Python' - it covers a ton of topics I hadn't seen since my engineering undergrad days. book: http://www.apress.com/us/book/9781484205549 code: https://github.com/jrjohansson/numerical-python-book-code
Tabs are wrong. Always. Forever.
Just finished my bot that catches fish for me in WoW! The script uses OpenCV template matching to find the bobber on the screen. Then, to detect hits, PIL ImageGrab is used to continuously capture images of the bobber which are then compared using Mean Squared Error to quantify movement. Finally, PyAutoGUI is used to to simulate key presses to cast/catch the fish. I'm a Python novice for sure, but laziness is the mother of all (of my) invention.
Didn't you decide to learn Python like two years ago? At least you posted in the right sub back then.
Im not sure if he will get this, but pinging /u/gohlke Could we get https? 
[link to the original by James Powell from PyData 2017](https://www.youtube.com/watch?v=cKPlPJyQrt4) Also, what on earth is going on?! Why is /u/Ricky-L-Wilson reposting a video from coding tech, WITH a link to the original but only in the comments. This is some shady stuff. The original comment is below. https://www.reddit.com/r/Python/comments/6rfb1k/what_does_it_take_to_be_an_expert_at_python/dl4l4ct/ &gt;If you want to become an expert in Python, you should definitely watch this PyData talk from James Powell. &gt; &gt; EVENT: PyData, 2017 &gt; &gt; SPEAKER: James Powell &gt; &gt; ATTRIBUTION: The original content of this video was published under the Creative Commons Attribution license (reuse allowed). The link to the original video: https://www.youtube.com/watch?v=cKPlP... The same thing happened to another Python talk by the same coding tech channel. Moderators of /r/Python! Can you do something about this? Ban links from Coding Tech? This is a practice we should not encourage!
Video linked by /u/temporaryred: Title|Channel|Published|Duration|Likes|Total Views :----------:|:----------:|:----------:|:----------:|:----------:|:----------: [James Powell - So you want to be a Python expert?](https://youtube.com/watch?v=cKPlPJyQrt4)|PyData|2017-07-24|1:54:11|147+ (95%)|5,413 &gt; www.pydata.org PyData is an educational program of... --- [^Info](https://np.reddit.com/r/youtubot/wiki/index) ^| [^/u/temporaryred ^can ^delete](https://np.reddit.com/message/compose/?to=_youtubot_&amp;subject=delete\%20comment&amp;message=dl57p6r\%0A\%0AReason\%3A\%20\%2A\%2Aplease+help+us+improve\%2A\%2A) ^| ^v1.1.3b
This is a stolen video
You can try using `conda` to install glpk or install cbc. I've personally preferred cbc to glpk, because I've had more luck with it, but both are excellent open source solvers. The optimization ecosystem needs more open source optimization solvers.
&gt; Sounds like a chicken and egg problem. ¯\_(ツ)_/¯ It really is isn't it. I can't change the python ecosystem single handedly.
No, but you can try it out. Nothing would be used if there wasn't a group of first adopters.
What? Do you mean lists? And lists aren't global, they're mutable. And if you're talking about using list as a default argument like: def function(numbers=[]): numbers += [1,2,3] return numbers That will almost always result in a bad idea.
SHA512 isn't enough. PGP signing should also be used, much in the way that it's used in Linux. Your SHA512 hashes are completely useless if I can't verify that they actually came from you regardless if they're being served over HTTPS or not.
I sent them an email with a detailed description of the problem and two solutions: either securely publish SHA256 hashes, or secure the whole path. Given they're on a university server that may not allow such a change readily, the former may be more expeditious. That said, it's a reasonable concern, if you or your data path is targeted in this way. A more extreme solution is to rebuild everything locally and hope you've got your environment correctly configured, etc. Personally I'm glad these binaries exist - Python is quite handy in Windows and where wheels don't exist yet this is a helpful bridge. (And if you distrust wheels or binaries, I hope you're scrubbing all that code you're building / installing to ensure it's free of unwanted surprises...)
Please provide a minimal running example!
Replace NLTK with SpacyIO, for 99% of people who want to do NLP it's the right choice.
What does it matter, so long as the CCA license is respected?
Pythong 
&gt;PSA: Don't use Windows. FIFY Edit: It's just a joke. Didn't mean to offend.
&gt; pewee +1 for peewee
File hashes don't help with security.
Wtf, python has a debugger with breakpoints? As someone whos well versed in python, your book shows there’s a ton to learn. I’ll have to read it all! Thanks. 
`any('payload' in msg for msg in data['result']['fulfillment']['messages'])`
So what is the reason people use those instead of Anaconda?
Wow that was quick. Thanks, it works.
Who the hell is trying to be clever? Maybe I should have put it in quotes. The point is it was (and in many cases still is) the opinion of many of those packages' authors; they never provided "official" binaries for Windows because they considered it a waste of time to support a closed-source OS whose entire ecosystem has been fundamentally unfriendly to (especially scientific) developers for its entire existence. They're *starting* to come around now that Windows 10 offers Linux-lite, but if you notice that Redmond has recently been putting a *lot* of effort into improving and marketing it's experience for developers, you might also notice that the sole reason they have had to do so is because they lagged so far behind. The entire reason these "unofficial" binaries exist is because most of them depend on each other AND depend on compilers being present that themselves aren't available in binary form on your chosen OS. *If* you want these packages on that OS, then the difficulty building them yourself **is** a deficiency of that OS... ie there wouldn't be a market for these things (and therefore this thread) if Windows didn't still *suck* for developers that require these tools.
These things could be hosted on Amazon over https at a pretty low ongoing expense. I should think the university would rather prefer that option as well.
I'm an astronomer and yeah, everybody in my department uses python all the time, (except for numerical simulations, where we use C, C++, and Fortran).
If you're unfamiliar, do yourself a favor and look into [pandas](http://pandas.pydata.org/)
The property you are referring to is called "mutable", not "global". "Global" refers to scope, that is, where in your code the name of an identifier refers to a particular thing (that is, in which "scope" a variable binding exists). Local variables only exist within the function where they are defined, globals exist everywhere. "Mutable" refers to whether operations on a data structure can modify the data without rebinding the variable; since you are changing the value itself rather than creating a new value and binding the variable to it, all other variables that are bound to the same value will also see the update. In Python, lists (arrays) are mutable, but tuples are not. Whether mutability is a desirable feature stands to reason; it can be very convenient, and sime algorithms can be implemented more efficiently with mutable variables, but shared mutable variables are also one of the worst sources of common bugs. IMO, Python's approach of attaching mutability to the runtime type of a variable is a horrible idea, because it means the semantics of code I write (pass by value or pass by reference) depends on arguments passed in from outside.
You probably don't mean *arrays*, but *lists*, and no they're not *global*, they're just *mutable*... but either way if you've figured out how to access them inside a function, **no** you almost certainly shouldn't be mutating them from outside the function, or for that matter mutating lists you pass into a function within that function.
Yep - pandas, seaborne, numpy, matplotlib, scipy, astropy etc. This department seems to have a very up to date python culture, which isn't the case everywhere
Indeed, or GitHub. The compromise of having digests published securely is good enough for me... What I don't want to see is the resource that this site is disappearing suddenly, so a compromise is a good and quick first step. Edit: a secure compromise, as noted.
money
Well, that said, crafting an MD5 collision that had a useful contents would be... difficult. I mean, could you generate a collision with a python package? Sure. Is the contents going to resemble a python package? Probably not... (but yea, an actual digital signature is the way to go, not just a hash)
* [**path.py**](https://github.com/jaraco/path.py) "Path" object conveniently wrapping assorted file/path-related functionality * [**pendulum**](https://github.com/sdispater/pendulum) Python datetimes made easy * [**tqdm**](https://github.com/tqdm/tqdm) A fast, extensible progress bar for Python and CLI And the classics: * [**numpy**](https://github.com/numpy/numpy) Scientific computing with Python * [**opencv**](https://github.com/opencv/opencv) Open Source Computer Vision Library * [**requests**](https://github.com/requests/requests) Python HTTP Requests for Humans * [**pytest**](https://github.com/pytest-dev/pytest) The pytest framework makes it easy to write small tests, yet scales to support complex functional testing 
&gt; nor secure in any way Oh, really? Got any backup for that? Or even better, shouldn't be hard for you to provide the 40 char string that generated the md5 hash "2dba65b3ce5d7e6791ce2ef92f105c16" then. While md5 should be avoided, and collision is very weak for it, please don't exaggerate things.
how trustworthy is pypi? And how easily can a mistake be done? http://incolumitas.com/2016/06/08/typosquatting-package-managers/
If you are a business, it is probably a useful thing to get your tech support to build opensource on site before they package it. Unfortunately it takes time and effort to create a viable build environment and that takes money and the important thing is that builds have to be maintained. I seem to remember one major bank that officially limited people to Python 3.4.x. One fix is that if a production project uses a version of Python, they get to pay for repackaging the latest version. As others have mentioned, signed pre-built binaries would definitely be an improvement.
&gt; shouldn't be hard for you to provide the 40 char string that generated the md5 hash "2dba65b3ce5d7e6791ce2ef92f105c16" then. let me borrow some time on an EC2 instance with some GPUs and I'll get back to you tomorrow. [if it can be done for fun with no profit](http://www.mscs.dal.ca/~selinger/md5collision/), imagine what can be done if someone was motivated by stealing and selling all your info for $$$. 
I doubt you'll be able to crack it, even with an EC2 instance. And your link is about collision, which is quite different from a preimage attack **Edit:** Quick calculation, providing you have a [8 nvidia 1080 gpu cluster](https://gist.github.com/epixoip/a83d38f412b4737e99bbef804a270c40) it should only take about 3.94**E**52 years for you to have a 50% chance of finding it. 
I've had better luck installing packages in PyPi on Windows than [Ubuntu] Linux. The packages I can't get to build on Windows are Scipy, numpy-mkl, and llvmlite.
Anaconda isn't everything in python. I don't see much about it being used in for example web applications or system administration. 
If you want to become an expert at python, you need to write buttloads of code and work with people who are better than you. Not watch a stupid talk on YouTube.
... whichever ones you need? I mean requests is awesome, but it's singularly useless if you don't do any kind of network/web work. Etc.
In a Docker setting, it is recommended to put your creds in environment variables. Then your app can read them in like import os username = os.environ.get("USERNAME") In your Dockerfile you can do ENV USERNAME "myname" This should be explained in the DO docs, and not python specific (except for the python syntax of course). 
Wut
If your lambda is longer than one line, it probably shouldn't be a lambda. Your coworkers will appreciate the increased readability.
Yes. I hate Heroku because their terminology is stupid ("dynos") and they do a lot of magic that leads you to believe it all just works... magically. Our job as technical people is to understand *how* things work, not willingly look away because of convenience. They also force you into their way of doing things, which is questionable. Heroku is very much tied to the Rails culture, which is cancer.
This is probably better on learn python. You might want to try a different http client, eg aiohttp or hyper-h2
Interesting. You should be marketing this hard as "ISOMORPHIC APPLICATIONS" to get the JavaScript drones excited.
Yes I saw that there are a lot of different libs available. How can I identify which one I should use before starting with a project?
First ask yourself if they support asyncio or are written in a sans-io style. If they are then they're good!
Just stop. MD5 should no longer be used except as a checksum to detect accidental corruption. Remember the flame malware? That used a certificate forged with a chosen-prefix attack on md5. It is not at all unreasonable to call md5 "not secure in any way", and their "backup" is most if not all of the cryptographers on the planet.
MD5 for collision, especially if both datas come from same source, is broken, yes. For preimage it's "merely" faster than the alternatives, and have less bits. It has some weaknesses that can reduce the effective bits a bit in some cases, but not enough to have it broken. Thus calling it "not secure in any way" is clearly false. While better hashing methods should always be chosen if possible, it's not broken and does provide some security. There are plenty of algos that *are* broken and can be trivially reversed, don't muddy the waters by incorrectly labelling things. Or someone can prove me wrong and reverse that md5 I just gave. If that was trivially doable, then yes it would be "not secure in any way"
Dan Bader's explanation on ETBF is how I learnt about some_dict.get(desired_key, error_handling) verses try: some_dict[desired_key] except: error_handling
Is it just me, or are the PyCon 2017 videos *less* watchable due to only using half the screen area for the video? The videos certainly need the small picture of the presenter, and the sponsors deserve that their generosity be noted, but I find the videos less watchable on even large-format mobile. This is no criticism of the quality of the talks. Wish I had been there. Edit: After viewing the video I noted that the sponsor logos were removed for the bulk of the video. So the static ~50% of the screen showed only that the video was from "Portland, Oregon, PyCon 2017" - twice. I kind of knew that and didn't need reminding. The only reason I can think for so much wasted screen real-estate is that it makes editing of the video much easier, as the producer doesn't have to move the presenter picture-in-picture around to ensure the slide isn't obsured in important ways.
&gt;Is it just me Probably not
You've stumbled on one of the nice and common gotchas in python. Have a look at this explanation from [The Hitchhiker’s Guide to Python! &gt;&gt; Common Gotchas](http://python-guide-pt-br.readthedocs.io/en/latest/writing/gotchas/#mutable-default-arguments)
I believe this can be edited in Settings Menu -&gt; Editor -&gt; Color Scheme -&gt; Language Defaults
Whatever you build now has to last at least a few years. Why even think of MD5 as a starting point when there is better available? It's not like it's harder to program by changing your hash function library.
That is a completely different thing. That there are better alternatives doesn't automatically mean MD5 is "not secure in any way"
I consider MD5 unusable for security, because you have to justify why you picked it at code review time, and that's going to be hard. Even you yourself admit there are better ways, how can you approve code based on MD5 when you could so easily sub in another hash? Also MD5 is certainly not good for checking file signatures, which is the use case here. edit: I probably should explain why. Because the uploader can create 2 files with same signature, and pwn you by swapping them out. It's not about a 3rd party matching a specific hash.
Yes, but you rarely need binary packages for those tasks. If you need binaries and there are no official wheels or eggs, Anaconda seems like the best option to me.
HTTP 429 is an error raised by the server because it knows you're trying to scrape it. Normally this is detected based on your user agent. Reddit does this too. So change your user agent to something resembling a browser and you should be all good. 
Stuff like database/cache connectors, image processors and all kinds of parsers and encoders often use binary packages. They work well enough with Linux wheels, but no idea if they all bother with Windows.
Converting my scraper from concurrent.futures + requests to asyncio/aiohttp.
Time and dedication
Ah so it was free. Then I'm taking my words back, it is not their fault if I'm slow :-) Hope you like it :-)
well I went with my own browser to https://httpbin.org/headers and used this information. But this isnt working
Again, that's a different thing. *"Why did you pick MD5 instead of scrypt"* or *"Why did you pick HTML4 instead of HTML5"* is different than *"MD5 is not secure in any way"* or *"HTML4 cannot be displayed any more"* &gt; Also MD5 is certainly not good for checking file signatures, which is the use case here. That I completely agree with, and have mentioned before (collision attack for md5 = broken). And a public/private key algo + hash should rather be used than a pure hash.
It is not faster than alternatives, cityhash is much better
&gt; comparing a non-cryptographic hash to a cryptographic hash, and implying faster is better. Welp then. Thank you for playing. PS: MD5 being faster is actually a *bad* thing in most cases.
"Not secure in any way" means for practical engineering purposes. The literal interpretation is useless as you can usually find a weird, bizarre edge case that breaks the rule if you try hard enough. Thus when an engineer says "never do this" they generally don't mean literally never.
You said MD5 is a fast preimage resistant hash function. Cityhash is faster. If you need only this property, cityhash is better, if you need other properties, MD5 will likely fail spectacularly. There is no reason to use MD5 in any case.
if it was not secure in any way, then for example all the md5 based SSL certs we have still wizzing around on the interwebs would all be for all intents and purposes completely broken. That's not a weird, bizarre edge case. And people who read that "md5 is not secure in any way" and believes that will also believe that those certs are completely broken, when they're in fact still secure. Should be replaced, true, but there's no practical attack on them at the moment.
What would you know? Judging by your post history you are not even competent at programming basics
If you need slow speed to stop brute forcing, CityHash fails miserably by design. CityHash is a non-cryptographic hash function and makes no promises or attempts to be preimage attack resistant. Any such property would be accidental. From quick googling I see no mention of it's preimage attack resistance.
I'd change beautiful soup to lxml or parsel since these built around standard xpath and css expressions.
&gt; no practical attack on them at the moment. That you know of. Would you stake your professional reputation on it? What if you build an md5 system today and they break it next year? You're still finished.
Considering the last breakthrough for MD5 preimage was almost 10 years ago, and no one has improved it and no results of attacks against md5 has been shown.. Yes, I think that's a fairly safe stake.
Either store inside a thick plastic folder (or maybe inside one of those vacuum plastic bags used on food) or fold it once and store inside a book. The QR codes have some redundancy built-in (according to the pyqrcode docs and at the current hard-coded settings, 30% of each individual QR code could be lost and it should still be recoverable). I made a few simple tests (there's one inside the sample dir on the code) simulating damage to the QR codes and as long as they are not totally out of alignment or totally unreadable it's still possible to recover (at least some of) the data. The header I add to each block registers the byte position of the start of that block on the original file, so even if you lose some of blocks you can recover the data for which the blocks are intact. This also means you can read the codes on any order and are still able to assemble the original file. Obviously, if the original data is encrypted using any cipher mode other than ECB, you lose the rest of the data after the first failed block. 
It's probably better to use linux even if it's a VM if you are gonna be using python. Linux(or even osx) is the natural habitat for python.
It's not just race conditions, nor is it about exceptions. But rather than explain, here's a quiz. Imagine you were reading some code and saw one of these: def int_or_default(x, default=0): if x.isdigit(): return int(x) else: return default def int_or_default(x, default=0): try: return int(x) except ValueError: return default For each one: * How confident are you that it's correct? * What do you need to know in order to understand whether it's correct? Post opinions below. 
Testing with `isdigit` does not guarantee being convertible to int: &gt;&gt;&gt; c = '\xb2' &gt;&gt;&gt; print(c) ² &gt;&gt;&gt; c.isdigit() True &gt;&gt;&gt; int(c) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; ValueError: invalid literal for int() with base 10: '²' Conversely, `isdigit` returning False does not mean not convertible to int: &gt;&gt;&gt; c = "-10" &gt;&gt;&gt; c.isdigit() False &gt;&gt;&gt; int(c) -10 
If 62.210.71.225:8080 is the proxy that you're using, they can tell that you are using a proxy from the X-Forwarded-For header "X-Forwarded-For": "unknown, 62.210.71.225", This may cause enough suspicion on their part to rate limit you.
Are you able to automate casting the fishing spell? You could catch that rare orgrimmar fish in no time! ;)
If I dont use a proxy I guess the variable should be empty then but I get the same HTTP Error 429. not to forget, that I can scrape the main domain with and without proxy
Are you able to see the HTTP request? Are the headers being added properly?
That was an amazing talk!
Fair enough. Looking at your code again, and this may not be relevant, but I see that you are only setting a http proxy, not https. Is that enough for you not to leak your own IP on whatever site you are scraping?
Why would Anaconda be better? In fact, I’m more inclined to trust Gohlke — a non-profit professor at a university — than a for-profit company. Plus, Anaconda is a waste of disk space, and I’ve seen a few issues caused by broken Anaconda packages that I could not reproduce with Gohlke or PyPI wheels.
I cannot see the http request and the checks inside the "## IP check" sections are returning the set values
I have now tested several free "elite proxies" with description " Level 1 - Elite Proxy / Highly Anonymous Proxy: The web server can't detect whether you are using a proxy." while changing it from http to https and I am still getting the same error
There is a TON of neat stuff in the standard library. The `pdb` module isn't as nice as some of the debuggers in a professional IDE, but it's quite handy when you don't have one of those available. I saw a neat talk on its `set_trace()` function at PyCon this year that you might want to check out: https://www.youtube.com/watch?v=2FftatTS3jc
~~Is there one in this style for arch? I tried looking in the arch folder but couldn't find one~~ I found it in `cards/`
OK seems like this is not the issue (although, rather than "changing it from http to https", add both to the proxy dict like proxy = {'http' : ..., 'https' : ...}) The only other thing I can suggest (btw I'm no pro; I believe there are many tricks sites can use for bot detection) is looking closely at the request headers in a browser and see if the site expects any special fields (eg maybe a Referer) 
I completely agree. I've never understood the burning anger among some folks about lambdas being restricted to one line: it's utterly trivial to define a named function in the exact same context right there. I just thought it was funny that even Java devs, whom the Python community caricatures as loving verbosity, came to the same conclusion regarding keeping your lambdas short.
Do it in an SVG Animation maybe? :D Representing infinite sets is always done the same way. Maybe an animation would give it a new insight for people?
Amen. Not in production settings at least.
I consider expecting people to remember the specific cases where md5 isn't completely broken yet far muddier than "md5 is broken, do not use it".
have you never heard of cross compiling?
Same, what are you working on now? I'm running through machine learning lessons at the moment.
I agree but that does not mitigate the attack. 
Now you're talking about security. You should check the digital signature on binaries used in production. Also anything used in production should have security monitoring software and be attached to a SIEM. 
Basically no, you need to learn each system. There are tools which allow you to build debs/rpms, but they typically are a quick hack, and lack the quality of distro-provided packages (both debs and rpms are fairly simple formats, their advantages come from the large amount of QA tools which are available). If you are planning on distributing an application, I'd suggest uploading it to PyPI, as most of the linux distros have tooling to build correct packages from sdists from PyPI. 
to get [higher salary](https://stackoverflow.blog/2017/06/15/developers-use-spaces-make-money-use-tabs/), of course
I've been working on Project Euler [problem 54](https://projecteuler.net/problem=54) ("poker hands"). My code is written and is reasonably well organized, but Euler says I'm still getting a wrong answer, so to make a long story short I'm on a bug hunt.
Have you ever heard of reading a blog post before commenting on it? Evidently not :) &gt; cross-compiling. I had my reservations about this, as it’s not all about speed: it’s about reliability and compatibility. I know these packages, built on a Pi 3 will work on a Pi 3. And of course, I want to eat my own dog food. If you can cross-compile and log 750k packages in less than two weeks at zero server cost, show it to be an effective and successful method, and keep a repository constantly running at zero cost, I'll be impressed.
Because not much attention is paid to a hash function that's already considered cryptographically useless.
&gt; md5 based SSL certs ... would be ... completely broken THEY ARE. https://eprint.iacr.org/2005/067 https://bugzilla.mozilla.org/show_bug.cgi?id=590364
Does Blizzard not ban people for scripting parts of the game?
I'm the one who delivered the talk. Pleasantly surprised to see it posted here. Happy to answer questions.
Thank you! I'm flattered.
have you ever heard of the PaaS thedigitalgarage.io ? Here is the documentation. Takes a little less "magic" http://docs.thedigitalgarage.io/
I'll go look at it. It is a learn to code app?
still having trouble with the difference between preimage attack and collision attack, I see. This is getting pretty tiresome
Yes, they do. I was willing to assume that risk because this was a fun learning opportunity for me. In my defense, I used this bot only for learning purposes; and since I am not modifying game files or memory, I believe I am unlikely to receive a ban. I will not distribute this nor will I use it to profit in-game. 
Yup, I just bound the Fish spell to a certain key and use PyAutoGui to "cast."
it's pretty easy to have "zero server cost" when you get donations from an absurd cloud provider of RPis...
&gt; I know these packages, built on a Pi 3 will work on a Pi 3. And of course, I want to eat my own dog food. This is bullshit. There are plenty of software misconfigurations that could crop up between Pis that are at least as likely as cross-compiling bugs.
&gt; I gave a lightning talk, and had a couple of people express interest in it. Both suggested cross-compiling. Maybe you should have taken that to heart...
&gt; http://httpbin.org/headers Ah ok, I think I get it now. Is this a public proxy? If so the IP has likely been blacklisted (as a few hundred other people are also using it the same way you are). Try removing the proxy directive and seeing if it works. 
Thank you! This is what I've been looking for! 
The answer is "standard practise". My tip is stop using bad tools. You press tab, your editor inserts 4 spaces. You delete one of those, your editor deletes all 4. How do you get misaligned by 1 space? If your editor can't do this, it's a bad editor.
The shattered PDFS aren't useful at all though. The point here is that generating a collision isn't enough. You need to get malicious code to collide with the set honest code. The shattered PDFS required modifying *both* PDFS to get the collision, which wouldn't work here.
The advantage of spaces is conforming to standard practise. You still press tab. The editor inserts spaces instead.
&gt; crafting an MD5 collision that had a useful contents would be... difficult. I guess if you consider that only in the context of http binary downloads.
I only added the proxy because I had this problem. never the less I have tested it again without success. I have also tested with probably 30-40 free proxies from https://free-proxy-list.net/. 
There's Miniconda on Appveyor, I think that should help
Pretty sure that's not preimage. Also, I thought it was this one, which is chosen-prefix and has a more dire impact: http://www.win.tue.nl/hashclash/rogue-ca/ Not that any of this matters, seeing as all major browsers and other SSL implementations stopped trusting md5 signatures years ago. There should no longer be any md5-signed certificates in production use ([data](https://www.netcraft.com/wp-content/uploads/2015/11/trend1.png)), which makes your use of md5 certificates as a defense of the algorithm nonsense. Either way, you should not be implementing new systems with MD5, and definitely should not be recommending others do that (or don't switch to SHA2/Argon/etc). The absence of demonstrated complete reversal doesn't in any way mean that's impossible or that md5 is secure. Again, not a whole lot of attention on something already deprecated as broken. Here are some smarter people than either of us talking about it: Hans Dobbertin, an actual cryptographer, wrote in *1996* that "MD5 should no longer be implemented... where a collision-resistant hash function is required." In 2005, Ron Rivest, another actual cryptographer and the designer of MD5, said it's "clearly broken (in terms of collision-resistance)" [.](https://mail.python.org/pipermail/python-dev/2005-December/058850.html)
The whole point of this submission here was that whether you trust Gohlke or not, you cannot trust downloads from his web site because it's open to MITM stacks. If you don't trust Continuum, Anaconda is no alternative despite their more secure web site, that's true.
I've been following Jasper for something like this, but Jasper has been a real pain to get working. I'll have to look into this, it seems very promising!
This has nothing to do with ``arrays`` or any other specific data type! This is based upon the scoping rules of Python: &gt; A scope defines the visibility of a name within a block. If a local variable is defined in a block, its scope includes that block. If the definition occurs in a function block, the scope extends to any blocks contained within the defining one, unless a contained block introduces a different binding for the name. You can read more about it [here](https://docs.python.org/3/reference/executionmodel.html#resolution-of-names). Here is an example from an iPython session: In [1]: name = "UChef" In [2]: def foo(): ...: print(name) ...: In [3]: foo() UChef You can see, that the name ``name`` gets bount to a string object with the content *UChef* in the global scope. I can easily refer to it from a *function* that is also defined in the global scope. But consider another function ``bar`` like this: In [4]: def bar(): ...: name = "Bolitho" ...: print(name) ...: In [5]: bar() Bolitho In [6]: foo() UChef Within the **scope of ``bar``** there is a **new** name introduced (``name``) that shadows the ``name`` of the *outer* scope (which is the global scope from the function's prespective). So within the function ``bar`` the name ``name`` refers to the value ``Bolitho``. But the ``name``-variable of the outer scope still is bount to the original value as you can see in [6] Btw: Mutating objects from an outer scope within functions (or methods when dealing with classes) without passing those objects via parameter is definitly a **code smell**! Prefer not to do that! Pass objects as parameters into a function and continue working with the given return value. If the goal of a function is just to mutate a given object, that is also ok, if the intent of mutating is clear. As long as you try to apply the [command query separation](https://en.wikipedia.org/wiki/Command%E2%80%93query_separation) your code is much better than that one you showed (even if I prefer to mutate as less as possible and try to stick to *immutable* data - my *functional programming* interests shine through here 😎 )
&gt; The property you are referring to is called "mutable", not "global". No! He definitly refers to the *scope*! The mutation is only a side note of his work.
Yeah, you're right that SSL have mostly phased out MD5, my bad. And I've never said to start using MD5 for any new projects, but in situations where MD5 is already used and only relevant for preimage, it's still reasonably secure. And that's what I'm trying to point out. And if you look through my comments on it, I've said several times that MD5 is indeed broken for collision attacks, and one should pick a stronger hashing algo for new projects. ***THAT DOES NOT MEAN MD5 IS "NOT SECURE IN ANY WAY", WHICH IS THE ONE THING I HAVE BEEN POINTING OUT*** again and again and people have argued about every other thing than that. "md5 is broken" - only on collision attacks. "md5 is broken see? Here is a link to collision attack" - yes, I said collision attack is broken, preimage is not. "but md5 is broken! look at more collision attack links" - that is still not preimage. "Why would you use md5 for a new project?" I never said I would, I said MD5 is still pretty safe against preimage attacks. Now if anyone can argue that instead of everything else, that would be nice. Edit: https://en.wikipedia.org/wiki/Hash_function_security_summary
Thank you for showing me how to deploy scripts, and not just websites, to heroku . 
there is work to support numpy + openblas
For command line applications, people tend to use PyPI and put up with its limitations, because it beats using a different technology for each distro. For GUI applications, there's no really good answer. Flatpak and Snap are aiming to make it easier, but they're probably not yet widespread enough to rely on users having them.
On the [Chapter 36 - Creating Modules and Packages](http://python101.pythonlibrary.org/chapter36_creating_modules_and_packages.html#chapter-36-creating-modules-and-packages) page: # outer __init__.py from . add import add from . divide import division from . multiply import multiply from . subtract import subtract from .adv.sqrt import squareroot Is that extra space after the . supposed to be there? Given the last one, I would think not.
I have found the Request Headers in my browser ^.^ chrome&gt;network&gt;header The referer seems to be the URL which I am trying retrieve. I have tried to add this to my hdr variable, but unsucessfull. do you see any other parameters i need to pass in my header? and can I just use my site variable when adding the referer in my header variable (hdr) ?? Accept:text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8 Accept-Encoding:gzip, deflate, br Accept-Language:de-DE,de;q=0.8,en-US;q=0.6,en;q=0.4 Cache-Control:max-age=0 Connection:keep-alive Cookie:nmatf=; JSESSIONID=; optimizelyEndUserId=; wt_fa=; wt_fa_s=; optimizelySegments=; optimizelyBuckets=; _dc_gtm_UA-75090708-1=; _uetsid=; wt3_eid=; wt3_sid=; _gat_UA-75090708-1=; _ga=; _gid=; optimizelyPendingLogEvents=; ab_tests=; ipcuid=; icda= DNT:1 Host:www.domain.de Referer:my site variable Upgrade-Insecure-Requests:1 User-Agent:Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36
I have posted the http request header to turn01 comments. did you mean this?
That's why they suck though :P
It's actually not always trivial to define it right there. For example in a class you can't just define it right there because a function inside a class becomes a method and that's super fugly. Sometimes it would be nice to be able to say "this function is private to that other function". There's no agreed naming convention for that afaik. 
I'm doing a lot of web crawling professionally and there really isn't anything better than xpath/css selectors. Personally I think beautiful soup is not very good and wouldn't recommend it to anyone.
How can something that is free be stolen 
Don't craps people "practice" rolling the dice lol.
&gt; This department seems to have a very up to date python culture, which &gt;isn't the case everywhere It is the case in herpetology departments. 
So a couple things..... If we're looking at *specifically* the distance function, it's already about as functional as you could make it. Your solution is not pythonic for a bunch of reasons. * [Map is not super pythonic, and is often times slower than a comprehension](https://stackoverflow.com/questions/1247486/python-list-comprehension-vs-map) * Your solution is tricky to figure out exactly what's going on, and has a few too many variable declarations with arcane variable names. * Your solution doesn't work. You can't have a lambda unpack a tuple in the variables, I fixed it in the code below. * [Mine is faster](https://gist.github.com/willzfarmer/856754cf80c54d846b09255f381029fa) Edit: Results from time trials: william@spitfire ~&gt; python3.6 ./tmp.py My function average time: 6.234169006347656e-06 Your function average time: 7.1666240692138674e-06
Hmmm... that's weird, can you please write an issue in the repo? So that I can see and replicate what's happening. Mine's working perfectly fine though...
You can actually do it both ways in most cases. At least it worked that way in Python 3.5
If you don't care about the response, it's easy because you can just spoof your IP. But if you want the response back then it gets much trickier. At that point you will want to look into VPNs
I don't care about the response. I tried using a proxy on my computer but got a connection error. Is it possible to have the script appear as if its coming from another IP without me having to put on a proxy myself?
Here's how you access them: for child in root: print(child.attrib['url']) and if you want a list of them all: urls = [child.attrib['url'] for child in root]
Whenever I have to work with xml, I use the [lxml library](http://lxml.de/index.html). Here is a [stackoverflow answer](https://stackoverflow.com/questions/12657043/parse-xml-with-lxml-extract-element-value) which should get you moving down the right path
Actually, now that I think of it more I don't think this will be easy. HTTP uses tcp, which requires a 3 way handshake to initiate the connection. Without a successful handshake the server will Ignore you, which means you won't be able to just spoof your IP for the request
Hmm... If you were to do it, what would maybe be a way of doing it or is it even possible? I'm not too proficient in HTTP/S requests and connections. Sorry for my ignorance lol
Hmm, ok I'll have to look at parsel then! I just can't stand xpath personally. But I realize in tricky situations you might need the power. 
Unless you are able to do this from some place that gets real IP addresses, it's all futile. If you are using a residential internet connection, you are behind a NAT firewall through your ISP (most likely). So the IP address that shows up, is the one your ISP has for you. It could be your router's IP address, but it can also be a DSLAM or other networking device that is upstream from you.
Over the open web I really don't think it's feasible without a VPN. If it's an internal network then you can do some fancy routing to make requests seem to be coming from different IP addresses
Numba is pure magic. No rewriting the code, not even adding type annotations, just one simple decorator, and -poof- your code runs at native speed. As far as my work is concerned, this entirely solves Python's speed problem.
Yes
https://www.eveonline.com/
Forgive my ignorance; couldn't you just make an MD5 collision by appending `"asdf..."` to the end of a python script? That'd still show up in the binary, right?
Not sure if you agree or disagree tbh
You can define it in the same module. Or a separate module. It's also possible you're overusing classes (a common stylistic trait in people who come to python from various languages eg Java; I certainly did it myself). Modules give you a lot of the same benefits. 
I'm right at the beginning. I'm just trying to sort through sources to figure out how to best approach this whole thing. I picked up the first version of Wes' book on Python for data analytics (I preordered the second version too but it doesn't come out until October) and think I'll be starting there. There's so much you can do but I think it's best to figure out what you'll actually use it for and focus on learning that stuff at first. I could so easily get lost in a rabbit hole otherwise! 
You can. Absolutely. But that might be far away which isn't very nice. Things that belong together should be close. It's not in the zen of Python but it should be :P I am fighting a mighty war against classes at work, believe me :P
Doing God's work.
I think so. Pity that Django is going the wrong way with their class based views ugliness. 
Ew Django. It's like Rails' deformed older brother. And since Rails is cancer, Django is deformed cancer. I'm sorry. :)
Thanks, I will look. That said I just prefer deploying to AWS. It doesn't take any longer and I know what's going on.
I totally disagree. Django is pretty ok. The ORM is limited but what it does it does very well. The implicit join thing is awesome. We have ended up writing our own forms library though heh. 
I read the doc and they are referring to containers as "pods." So I stopped reading.
The tool ecosystem is horrible. I had to set up js package bundling and a CDN of a Django / angular app and it took 2 days v. 30 minutes in Flask and webpack. Whitenoise and Django integration is gross. But if you enjoy it, that's great. I just stay away from fat frameworks.
No worries. No matter what, you will need to learn something new to accomplish what you want to do. The reason for this is that the module you are looking at is not just "plug and play". You need to use the module to write code, and then deploy the application. Packaging and deploying python applications is much harder to learn than docker IMO. I suppose another option is to use something like heroku, which handles much of the pain of deployment for you. No matter what route you choose, there are lots of articles online that can help you out, and the knowledge you gain will not be a waste of time. When you come to any new language, there is always a learning curve in regards to the tooling around that language, how to set up your environment, how to package and deploy applications. If you take the time to learn these things up front, you won't have to do it all over again next time. ;-) 
Here is the link to the SiriControl repository: [SiriControl Repository](https://github.com/theraspberryguy/SiriControl-System)
No. Although they share the fundamental concept of an event loop, they have very different goals and resulting designs and tradeoffs.
&gt; path.py "Path" object conveniently wrapping assorted file/path-related functionality For those on 3.4+ there is an [alternative built in](https://docs.python.org/3/library/pathlib.html)
Not in the original post. Maybe in comments posted after mine, but I haven't yet figured out time travel.
Python 2.7, ewww.
Still doing https://www.debategate.net/ It's doing considerably better than last time I posted here, but the rub is always getting users. I'm not a marketing person &gt;.&lt; It's a website where you can debate people in a structured format, in a series of rounds.
Automate the Boring Stuff with Python is always great. And of course, use the official docs/tutorial: https://docs.python.org/3/tutorial/index.html That's how I learned, at least. As for the rest of the question, you *could* probably make a mobile app in Python, but that is more Java's domain. Similarly, Python is capable of making games (https://www.pygame.org/), but usually C++, C#, Java, C, or Lua are used for games, simply because Python game libraries haven't really kept up with other languages, for a variety of reasons. Generally, I use Python for either websites, or small scripts/bots like what you were describing with your Twitch channel. In the end, Python can do anything you want it to; but these are some of its best usages.
You probably aren't going to get very many ~expert~ developers -- who are probably able to get actual pay doing something else -- based on no details whatsoever about the project beyond the fact that it is "potentially lucrative," and runs on a remarkably average tech stack. Re-reading that, it sounds a little harsh, but it's true. I know privacy is an issue for you, but perhaps you could consider open-sourcing the project. It would probably invite the free-ish labor you seek, and you get to keep your equity ;)
The js tooling at work has been a pain point sure. But flask is also super under powered and needs lots of decisions and packages to get anywhere close to Django. Talking about just the server side stuff now. Tried to look at how to do CSRF protection some year or two ago and that was a mess, as an example. In any case the comparison to rails is unfair as rails is just a big ball of mud with comefrom everywhere :P
Standard Python practice says split that main.py into different files. Standard Python practice also says use classes, but I'm not a huge fan of OOP, so to each their own. I notice you've already split the file up into sections with comments, so this should make sense to you. * Don't import *, unless you have to. It pollutes your namespace. * No globals, ever, if you can avoid it 
First I must point out that I think I don't deserve tone your post suggests. Maybe it was intentional or maybe it was not, but I think I should calmly say things like this so it would stop any possible further "flame war". I am glad that you've gone to this length to prove me wrong. I ended up learning some things. 
Just go to https://awesome-python.com
Found Ajit Pai's reddit account... You can run it on a cloud service, usually they run on several machines each with their own ip.
Would you mind explaining a usecase where I would use gevent over asyncio?
Nice hack, but storing passwords in plaintext is a complete nonstarter for me.
If you need to use Python 2.7 or both Python 2 and Python 3, or PyPy2, you probably want gevent for portability (the older version of asyncio that ran on Python 2 is deprecated; gevent is fully supported on Python 2.7-3.6 and PyPy2/3). If you can't use Python 3.5 or newer with its fancy async/await keywords and want to avoid a nest of callbacks, futures, etc, you might prefer gevent's automatic sequential programming style. If you want to use libraries that aren't specifically written with asynchronous programming in mind in an asynchronous system, you might like gevent's seamless ability to drop in stdlib compatible monkey-patches, thus making those libraries cooperative. If you need to call into C extensions and yet still be asynchronous when they call back into you, gevent's greenlets are a more flexible alternative than asyncio's coroutines. If you understand (and maybe even like) threaded programming, or are porting a threaded program to an async model, gevent's greenlets (and optional monkey-patches) are an easier transition than asyncio. That's a one-sided picture, I'm sure, but those are all reasons that I continue to use gevent.
Cool ! If you want 100% on-device Voice AI which respects your privacy you can look at what we build at https://snips.ai
I thought microsoft fixed that: &gt; Windows Subsystem for Linux (WSL) is a compatibility layer for running Linux binary executables (in ELF format) natively on Windows 10. https://en.wikipedia.org/wiki/Windows_Subsystem_for_Linux 
**Windows Subsystem for Linux** Windows Subsystem for Linux (WSL) is a compatibility layer for running Linux binary executables (in ELF format) natively on Windows 10. Microsoft and Canonical partnered together to enable an Ubuntu image to be downloaded and extracted to the user's local machine, and for the tools and utilities contained within that image to run natively on top of the WSL. WSL provides a Linux-compatible kernel interface developed by Microsoft (containing no Linux kernel code), with user-mode binaries from Ubuntu running on top of it – a Bash shell and command language, with native Linux command-line tools (sed, awk, etc.) and programming language interpreters (Ruby, Python, etc.). The Ubuntu version installed originally after the Anniversary Update was Ubuntu 14.04 "Trusty Tahr". It was updated to Ubuntu 16.04 "Xenial Xerus" in the Creators Update. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.24
You may be able to use PySocks, requests, and a tor service to anonymize your traffic. https://stackoverflow.com/questions/30286293/make-requests-using-python-over-tor See 2nd answer, Part 1.
This can be trivially fixed with some basic encryption in the script. I'll have a look.
Does Gmail support OAuth for IMAP clients? That would probably be the safest solution.
Because you are pretending it is yours and making money off it from Youtube ad revenue.
Interesting. Are you guys working with [Mycroft](https://mycroft.ai/) at all?
Oh, thats a good point. I'll look into that, Thanks
Cool project! In the past two hours I was able to have siri control my laptop's spotify player :) What made you realize you could get Siri commands through gmail notes?
CSRF isn't hard to do at all in Flask. :shrug:
https://developer.apple.com/sirikit/ is probably the more correct approach.
good work! Just trollin through the code, not sure you want to have a file named `tuple.py`, that might cause some confusion with the built-in 'tuple' method from python std-lib. Suggest renaming that module! Code looks clean and I was able to digest easily.
A dynamic settings manager to follow 12factor.net recommendations I use a lib I created -&gt; https://github.com/rochacbruno/dynaconf 
I suspect the problem with adding any really safe solution is the increase in complexity. This is a very simple script that does not depend on any third-party library and claims compatibility with "python 2+", so anything as complex as managing an OAuth flow or using PyCrypto would probably create a number of challenges that the maintainer might not want to face. I just submitted a pull request that adds b64 encoding for the password and stores credential in a separate dotfile. It's the bare minimum, not really secure but a few steps beyond "save password in cleartext in the file itself" while remaining self-contained and highly compatible. At the very least this should avoid SNAFUs like the guy who forked it and then proceeded to save his user and password in the script and pushed it to github (where it still lies, in plain view...) 
Still improving my built-from-scratch web crawler, [spidy](https://github.com/rivermont/spidy).
You don't need to write your own library, NumPy can do what you want with ease: import numpy as np data = np.random.rand(20, 3) # Some random dummy data idx = 0 # We are currently looking at the first element # Get closest neigbor in euclidean sense euclidean_distances = np.sqrt(np.sum((data - data[idx]) ** 2, axis=-1)) tmp = np.ma.array(euclidean_distances, mask=False) tmp.mask[idx] = True euclidean_closest = np.argmin(tmp) # Get closest neigbor along first axis x_distances = np.abs(data[:, 0] - data[0, 0]) tmp = np.ma.array(euclidean_distances, mask=False) tmp.mask[idx] = True x_closest = np.argmin(tmp) # Get closest neigbor in one direction along first axis forward_distances = data[:, 0] - data[0, 0] tmp = np.ma.array(forward_distances, mask=False) tmp.mask[idx] = True tmp.mask[forward_distances &lt; 0] = True forward_closest = np.argmin(tmp) 
I think you'll need to implement a ratio cutoff. You can take the string that's returned by your current process and compare it against the university you're trying to match. If the ratio (or partial ratio) is below a certain threshold--say 60--then you would count that as being not found.
yeah but another issue is that lets say i wanna look for harvard, i can either type "harvard" or "harvard university" and then the keyword university would yield a high score
Try with With open('namefile.txt','w') as file: file.write('tex to the file') file.close() If you dont know the directory where the file is saving. Import os os.getcwd() #return the current work directory. 
If you're only matching against school names, you might remove the "university" part (or "college", "institute", etc.) from both strings *before* doing the comparison.
I'll try that and see how it goes. thanks.
You don't need to close the file when using the with command. 
You'd like to persist some data? How about importing the json module and using `json.dump` to dump the variables you need to a file?
Alternatively, run the python interpreter in the terminal from a folder in your user area (eg desktop)
I would look into the documentation for JSON or pickle
You'll want to [`open()`](https://docs.python.org/3/library/functions.html#open) files to read and write data to actual, persistent files. Otherwise pretty much everything is kept in memory and thus cleaned up or otherwise lost when your python process ends.
Okay, you're not wrong, but I hope you see where your original comment could have been *much* more specific about the remaining not-completely-fucked use of md5.
I need this for Amazon echo and Okay Google
In my experience, distribute your package along with a requirements.txt and installation instructions that tell the user to run "pip install -r requirements.txt" preferably in a venv isolated environment. It just gets to be too big of a hassle to include all modules especially ones with C code and dealing with apt/dpkg vs yum/rpm can be a hassle too.
I believe it is true that every point is the center of the universe. So they are right.
I as well :D. Very curious to see how this was done 
Thanks I’ll look at this. I’m looking for something that can give me the distance across the surface. Edit: But I think using these methods will give me a good starting point to get me there. 
You are a wonderful person. I set up the code following your clear instructions and had everything working in less than 30 minutes. Thank you for making this available!
Here s a link to the google drive https://drive.google.com/drive/folders/0B3sMkpTLPS0gNG5YSHJhWVJhVkE?usp=sharing If you have questions about it just ask :) 
This depends on the shape of the Universe, which is still a much disputed point.
That should throw a SyntaxError. Edit: well, actually it *would* throw several NameErrors. First for **americans** being undefined, then **center_of_universe** being undefined, then **self** ... and ultimately it would throw a ValuError, because *nothing* can compare to an American but another American.
IPython's embedded shell: import IPython; IPython.embed() Opens a REPL in the middle of executing code. Particularly useful for interactive debugging during unit tests. You can do similar things with ipdb.
Point? The Universe seems bigger than a mere "point".
Well, if the Universe is convex, then the Big Crunch becomes the Big Bang, and basically the entire thing is just a point perpetually expanding and contracting into a periodically larger and smaller point that is always the same apparent size from *outside*.
&gt; basically the entire thing is just a point perpetually expanding and contracting into a periodically larger and smaller point I find it difficult to comprehend being limited to four dimensions and no mind enhancing mushrooms. Mushroom astrophysics; is that a thing?
Thanks for the review! I chose to call the module `tuple.py` as I thought it the most descriptive, and decided that the import is explicit enough that it's okay. Perhaps I should find a better name ;)
I believe that that function is mainly used to parse Python objects into C object. For example in this section of the docs https://docs.python.org/3/c-api/arg.html#parsing-arguments you have the str and numerical parsing described here: https://docs.python.org/3/c-api/arg.html#strings-and-buffers https://docs.python.org/3/c-api/arg.html#numbers All of those appear to file C objects with information. In the other objects section https://docs.python.org/3/c-api/arg.html#other-objects It has this to say about the `O` format character: Store a Python object (without any conversion) in a C object pointer. The C program thus receives the actual object that was passed. The object’s reference count is not increased. The pointer stored is not NULL. So basically it appears to me that usually you parse into C objects you've statically allocated (and hence have no refcounts), or you receive straight references to objects themselves (in the `O` case), but it doesn't increase the refcount itself (meaning if you do something like return that object, you should increase the refcount yourself). I don't believe there would be any situation in which you would need to increase the refcount and then decrease it again, unless you're somehow calling back into the interpreter in the middle. For example calling a python function or something that calls a python function which then makes it back into the interpreter and therefore could somehow possibly decrease the reference count of the original tuple (though I think anything that did this would probably be a bug itself since the tuple shouldn't be deallocated before your original function is done with it at least). Hopefully this rambling answer is helpful enough for you to sort this out... edit: _If_ my answer here is correct feel free to link it or rewrite it as an answer to your SO question. (Though if you're posting it yourself, I recommend possibly a quick editing job on your part and make my response here a bit easier to understand before posting it to SO. :) ) edit2: I read over your original question again and I think I must have been a bit tired when I responded this morning. &gt; I’m trying to be a little generic here so input1 could potentially be any type of PyObject. So the point it is always a PyObject and so you can ignore most of my response and only look at the part talking about general objects. So the point is that the refcount is not increased by the parsing function. So the answer comes down to "it depends on what you do with the object". If you were to return it directly, then you'd need to increase the refcount yourself, since otherwise you'd end up with two different objects pointing at it without the corresponding counts of references. If you were to use it in a "reference stealing fashion" (e.g. putting into a list using PyList_SetItem), you'd probably need to increase its refcount first before doing so. If you're using the object in a way where the new data structure doesn't steal a reference, you probably don't need to change the refcount yourself. Also as I said it depends on if you could possibly jump back into the interpreter in the middle. https://docs.python.org/3/c-api/intro.html#reference-count-details Honestly it's all a bit tricky (well to me anyway). You should probably write your code explicitly so that it's clear exactly what you're doing with it and then trace through it. Your question probably can't quite be answered entirely unless we see all your code...
I have a few observations about the codebase: - altough you claim that it is written with developers in mind, it does not even follow the most basic packaging requirements (having a setup.py, some documentation) and its configuration requires you to actually edit the sources of the library (which is bad). I suggest implementing a method to pass such variables from environment or from command line, or to specify a file from which to read those. - logging stuff with ``print`` isn't recommended. you should use logging - there are some code smells though the code (for example at line 125: except Exception as exc: print("Received an exception while running: {exc}".format( **locals())) why the usage of ``locals`` if you only format the exception anyway? - altough you claim "NOTE: This works on python 2.7 and above" , the old style class (not inheriting from ``object``) behaves differently in Python 2 and Python3 (when you subclass it), although this is an edge case, but it's worth mentioning. Other than that, you are on the good track and keep up the good work!
Alternatively, if you are just appending simple text strings: print("lol", file=open("trojtxt.txt", "a"))
This is what I used a = vec_compare b = vec1 cosine = (np.dot(a, b)) / ((np.sqrt((a * a).sum())) * np.sqrt((b * b).sum()))
Sadly the post was deleted. But iirc the OP talked about accessing some object (he said ``array``) defined within an outer scope from a function. So this is all about scoping - that he was able to mutate the object is only a side note to his observed behaviour.
I would venture to say that the Excel Spreadsheet is a huge clue about needing to write a program. The impedance mismatch between converting excel spreadsheets to working programs is holding us back as a species. Spreadsheets are great - easy to start and powerful - but if you start depending on them its a pointer to create a program.
I use Python all the time at work to automate things, mostly to process lots of CSV and XML files and to migrate data from legacy systems into new format used by current system.
Manager uses built-in reporting of some third-party application, but default reports don't give him what he needs, or he has to pull several reports and manually combine data. Making custom reports is difficult. I wrote a web service in Python/Flask that pulls data directly from MS SQL database of third-party application and presents it in exactly the form manager needs. Saves him hours every week.
I would've thought excel spreadsheets are more similar to relational databases and SQL programming than to Python programming. Can you provide an example of converting an excel spreadsheet to a working program?
Can you provide an example of a process you've automated? 
Nice. I've always thought of Flask to be for actual web sites, but if I'm understanding you correctly you're using Flask to host the Python script and having your manager access it through a localhost on his browser? Was this bc it was simpler than creating a GUI/desktop app?
I've just did. Migrate data from a legacy system (huge XML files with customer data, order data, catalogs, products and related data, etc.) into the new system. So like a middleware.
You sound like me lol
I'm afraid it's quite hard to convert JavaScript'ers to Python. My first language was MSBasic, some 35 years ago, and it took some time before I realized it wasn't the language to end all languages. But I hope the Pythonista's like this possibility. 
We have a support line for our service. We rotates agents through out the day to answer the phone. The schedule for rotation is stored in Google calendar. It was up to the agent to remember to log into the phone site and switch the number to the next agent after their shift was over. I always forget to switch the number. I wrote a script that checks the calendar, then switches the number for me.
Essentially the spreadsheet is the db - and **you're** the program. 
Renaming and organizing files in python is very easy and saves me so much time. 
Haha. Sounds like something you couldve done for the rest of the agents as well
I'd go with abomination.
i think lucidguppy is making a general comment that once data is in Excel it goes there to die, and spreadsheets generally imply a busness process is broken and requires manual 'clean up' or intervention
What sort of cases and why so often do you find yourself needing to rename and organize files by executing a static python script instead of doing it through the command prompt/line? 
Oh yeah I did it for everyone. That would have been mean.
I use python to automate just about all I can at work. Some of these things include smaller tasks like periodically querying databases, creating various reports, and emailing those to people. I appear very productive, but in reality I don't actually do much. A current little side project is something that generates markdown documentation from C# code. It has turned out to be really, really handy.
One example, currently I get hundreds of PDF files from and ETL load everyday. The names on the pdfs are not easy to sort, I keep all the files in a locked shred drive and rename the files to organize them. I run one code that organizes all the records at once so when I need to find something from six weeks ago I can easily go back and locate exactly what I need, Python is much more convent and faster to run everyday, but I use python most all day everyday. Once you write the short code to name it all you have to do is execute that one code everyday, I don't even think about it. I hope that's clear.
For programs that need to happen at intervals without your manual input, like your example with periodically querying databases, how do you let it happen? I guess more specifically I'm asking how you "fire off" or automatically execute the scripts from your computer without your go-ahead. Can you point to software or other packages for me to look into? 
I use flask like this a lot as well. Often enough, I get handed a bunch of data of some kind, and I'm asked to perform some kind of analysis on it. I discuss with the team or person doing the asking and figure out what they want, then I write code performing the analysis in such a way that it's easy to wrap a blueprint around it. That blueprint is then slapped into a library of tools I've created over the past couple of years, and I just give them the link. People are generally pretty happy with this approach.
Basically the entire HR workflow. It seems to consist of them copying and pasting ID numbers between Excel spreadsheets.
I would suggest you use your operating system's scheduler. On linux, you should check out crontab.
Is it the arrow notation? You could make it look more like ruby if you change this separator = '-&gt;' argnames, body = expression.split(separator, 1) into separator = '|' _, argnames, body = expression.split(separator, 2) I didn't test this, but if it does work, it should then be able to take strings in this format instead: "|x| x + 3" "|x, y| x + 3"
&gt;I appear very productive, but in reality I don't actually do much. I think a good analogy would be firemen. Most of the time they're just sitting around at the firehouse. We just pay them to be ready when something happens, like if one of your scripts stopped working :)
A wise man once said if you want to build a new company just go into a business and ask what they still use a spreadsheet for, then write software to do that.
Just about any task where a local Java programmer either can't do it, can only do it badly or will take 6-12 months I can do in Python in an hour or two with 3 orders of magnitude fewer LOC (which makes tweaking it a lot easier too).
PyCharm refactoring integrates with machinery in IntelliJ, which is in Java.
A lot of our legacy apps have text interfaces (for good reason, I might add--I'm all about the text interfaces). Some of the tasks they perform with these apps require human judgement but a lot of the lower level setup/checking is basically grunt work. `pexpect` is a great way to automate that part.
Clear as day. I thought you were initially talking about simply renaming directories and files within your local computer. 
Thanks. I'll look into them. 
Yeah, I agree. This reminds me of the thread I saw where a guy had qualms of whether it was morally defensible of him to automate his job and not let his boss know. I'd say they're probably getting what they agreed on out of him, and more. He's definitely in the clear.
This seems to be a good read: http://www.adminschoice.com/crontab-quick-reference
I see sorry I should have been more clear. Python can help you with a lot, the more packages you know the better too. It might not seem like you will ever use something when you are learning it but it will probably pay off in a completely different way than you expect! Keep it up and good luck! 
Gotcha. So you mean making programs that convert data from excel format into python-readable objects, manipulating the data however you need to, and then saving it back into excel format(in the case that we're still using excel). 
I would use JSON if it's just some variables, or jsonpickle if you need to serialize actual objects.
I can jump in here as well. A friend of mine was recently tasked with making a script for repackaging a bunch of data so it could be imported into ArcGIS. This included analyzing file names, then using that information to create a folder hierarchy, then renaming and moving the files into the correct ones. It's a very small task for Python, but previously, people had been laboring with this by hand, which took hours every week. Another example would be analyzing the file names in your "completed" folder, cross referencing it with IMDb, then renaming the files accordingly by "{title} ({year}).mkv", if you know what I mean, or "{band}/{album}/{band} - {title}.mp3".
I ran a single Jenkins job to deploy several staging websites several times a day, each with different parameters. I was tired to manually run this job through the Jenkins GUI, select the right parameters (there are 5 different parameters to set) and run it. I also had to manually notice people on a specific Slack channel that a deploy has started and has finished. One day I ran this job with the wrong parameters and one of the staging website was broken. It was time to automate all the things. So I wrote a Python script that use Jenkins parameters presets (stored in a plain old Python dict), starts the Jenkins job with the choosed preset (using the Jenkins API), send an incoming webhook to the Slack API which displays a notification in our channel that this specific deploy started. The script then automatically polls the Jenkins API to track the job's status until it reaches a final one (either finished or failed) to send a Slack notification about the result of the job. As simple as running "deploy beta6" in my terminal. I didn't used specific packages apart the excellent Requests.
Now all you have to do is to launch that code from your operating system's scheduler.
You can try fuzzy-wuzzy.partial_ratio that should yield the same score in both situations
If that's what he was saying, then I wholeheartedly agree. Excel is a symptom.
I wrote a small script to speak the time every hour and scheduled it. My co-workers think I've written an AI. I've also created some scheduled tasks to remind me to create reports on Monday! Some simple excel reports are auto generated and emailed :) 
1. I had a colleague do a weekly task which involved doing vlookup across two sheets having 100k rows. Using excel this would take about an hour to run. I did the same for him with Pandas , this would now complete the same task in about 10 seconds. After which upload the result to Amazon S3 using Boto3 , so saving another step there. 2. Running a SQL query on Postgres exporting the results as an Excel sheet. Then email the results to my managers. Used psycopg2, pandas and GMail APIs. Used a pretty HTML template for the email to make it look all professional. 3. Running a daily update query on the DB but to keep things flexible I had the script read the SQL commands from a file on S3. Now my team just needs to update the file in S3 to add new commands. So no dependency on me for anything. Used psycopg2 , pandas and Boto3.
I wrote a script to pull compressed database backups from a network share folder where they're stored to my local machine, decompress it, connect to a MySQL server on my development box and then run the SQL statements, to allow me to look at data that is backed up from production databases on a nightly basis. The script then cleans up the files it produced on my machine. I run this a number of times a day, depending on which client I need fresher data from at the time.
can we do this with android also? I'm not sure if that's possible.
Wasn't my responsibility but a lot of test control is automated with python. There are comms protocols to the equipment to control and pull data. Also controlling the devices under test. Better interface than HPVee or Labview.
I use python scripts to locate errors in the huge EMR logs files that gets produced when you run a cluster on AWS. Another use was to convert badly formed json into correct json using demjson library.
Think of Flask as an MVC framework. MVC loosely couples visualizations on top of database models. Views are customizable. Models are customizable. The Controller is customizable. Maybe there is a suite of visualizations he needed to create, visible in the browser. That becomes a more complex web app.
Web application + python + selenium = bulk data operations. This has saved us multiple person-months over the last years. Complete numbers are not available, but in one case we had to move codes from one field to another on 15000 records. Vendor didn't want to do it, our it department neither, estimate was three months of manual work. In the end, learning selenium, writing and testing the script and running it in production took us three days.
How does this look on the user end? Do they just get a .cmd file that they can double-click on and then the page opens in their default browser?
Since you are parsing lambdas from strings, why not make this into a complete lisp parser of sorts? *That* would be interesting.
No I send them a URL. Flask serves web pages, so everything runs on my server.
There is python-crontab if you want to use.
Well, the original idea was to see whether I could combine this with [Slinkie](https://github.com/segfaultsourcery/slinkie) in order to make the syntax a little cleaner, but I'm not too happy with the end result. Slinkie would then optionally look like this: print(Slinkie(12) .filter("x -&gt; x &amp; 1 == 1") .map('x -&gt; x + 99') .list()) Result: [100, 102, 104, 106, 108, 110]
Actually a pod contains containers. You can have multiple containers in a pod. The terminology naming comes from Kubernetes. And the garage is based on Red Hat OpenShift.
Two questions: selenium appears to be for testing through browsers--is this to say that your code that needed to be moved existed in the web? Selenium was used simply for testing the script which used the 'requests' package? Also, in real life everyday work scenario, is it commonplace to be hired as a developer and be told to learn new technologies as they're needed if it's within your realm of skills? Haven't worked as a dev yet, but always figured you get hired based on the skills you know and work on projects related to them. Guess I'm curious if for a job, its better to learn a bit of everything, or if thoroughly learning just the basics is enough, as it'll help me with how to learn new techs when the time comes. 
Yup, you are better off using the Python's lambda syntax; it's way cleaner.
You're too full of yourself.
I wrote a few different programs to automate filling in cells on the online "Google Doc (spreadsheet)" that our operations team uses. It saves so much time for a lot of people. I believe the main package I had to use was google's oauth2client to connect to the online google doc. I was pretty new when I wrote it, and was extremely excited when I get it working. It's amazing what reading the documentation will do.
I use windows Task Scheduler with no problems
Syntax-wise I actually like arrow notation way better than lambda-colon notation or whatever you want to call it. What I don't like is that I'm forced to wrap it in a string, and the rest of the hack required to get it to work.
Python is used heavily (in my case, solely) in the work of tech artists in the games industry. We build tools all day every day to automate just about everything about the character rigging process, and import/cleanup/export pipeline pathways. We also constantly create tools for artists and animators to use (in my case in Autodesk Maya), and tons of little one-off things. I thought for years I'd run out of tools to make, but never have. There's always some new need you would never have seen coming, or 100 you've had on your mind for years, but haven't had a chance to get to yet. I've probably built 500-1000 tools over the last 17 years, although Python was only introduced to Maya about halfway through that; it was all Maya's embedded language (MEL) up to that point.
I'm in the mapping business (hence username) and we operate within the realm of software that belongs to the Microsoft of the GIS world, ESRI. ESRI has a wonderful python package called [ArcPy](http://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy/what-is-arcpy-.htm), which allows access to their analysis and mapping tools from within python. Over the past four years, as various business plans come up for refresh, we have taken a process that normally took around 3 months for data loading, analysis, consolidation, and reporting and brought that time down to weeks. Now we load the data, confirm our numbers, then run the analysis and mapping in a matter of weeks, which has given us time to finally get our feet into creating digital maps and dashboards to give better insight to people in the field. Python and ArcPy have literally been a game changer to my department. And my wallet.
I don't work as a developer, I'm the business owner of this application. Most people in my team are somewhat tech-savvy, so it's quite common to learn new skills. FWIW, our IT guys also learn new skills as needed (especially new libraries and such). The application runs in the browser (it's developed by an external vendor), so since selenium allows us to automate clicks and fill out fields and such, we can use it to solve data quality issues and other repetitive operations. And yes, the application should offer such functionality out of the box, but it doesn't :-)
Great question!
TIL I can now apply my Python skills in Maya.
Try pyinstaller, very simple and easy to use, provided you don't have 3rd party libraries.
I had this issue at a company I worked at but they refused to allow me create any automation that would put the jobs of rudimentary analysts at risk.
I'm surprised someone hasn't used this fact to disrupt the HR industry and earn billions.
This is going back a way, but the best example I have of this is using a Python script to convert a whole stack of confidential documents from some outdated ancient electronic documentation system to Microsoft Word, somewhere in the early 00s. (Using COM to bridge from Python to the MS Word VBScript API -- much nicer than working in VBScript). The contract with the company that had maintained them had broken (or they went bust or something), and they were left with these documents in some obscure (and ironically undocumented -- or at least nobody knew what it was) format, which to them were just megabytes of indecipherable junk. I noticed that the company had included an export in a format that was pretty close to XML (some kind of not-quite-SGML), and it was meticulously-well marked up, so I said I could convert it. They gave me a printed version of the docs so I had a reference to compare to: a stack of dense manuals that covered my desk! They were going to do it by hand initially - would have taken months of work by a whole team of people, technical authors, proofreaders, etc. who would also have all had to have been background checked. (Hmm, in retrospect we should have charged a lot more...!) Took me about 10 days to write the converter, and an hour or two to run to completion across the whole set of manuals. It took them considerably more time to check it over than it took for me to do the work. They were pretty amazed, I don't think they believed it could be done. EDIT: Just remembered I did another (easier) job for them a bit earlier, converting another set of docs from another ancient pseudo-hypertext system, which had been custom-built from them, back in the 70s/early 80s, which they were still using in the late 90s. I remember writing a Python script to convert their ASCII-art tables into HTML tables, which I was quite proud of, and having to convert absolute pointers to URLs.
If your boss is against you automating tasks because it results in you doing less busy work for the sake of moving about randomly he's an ass. You have a job to do. How you reach your goal shouldn't matter as long as it follows the same laws/procedures that would be followed if done manually.
What if you do have third party libraries? Got a good YouTube video on that?
I created a build process that internationalizes your python application. I makes it simple to translate your application and keep it up to date with the latest translations. You basically run the script, it goes into your source code and extracts all the tagged strings. Then it tabulates that in CSV form so you can send it to a translator. When you get the translations back you run the same script and it will take that CSV and turn it into a .po and .mo file for use in your app. It also has features like checking if string templates have been tempered with, check for redundancies and will pull already translated phrases from other CSVs in the directory. Https://GitHub.com/lobocv/translation_factory
Kudos, but I'm just going to go ahead and forget I ever saw this post ;)
Let's get the obvious out of the way first: Is there any reason you can't just subclass the library class? class Supercharged(PythonLibraryClass): # define all of the attributes and methods you want to add Methods on the subclass can freely call methods that you inherit from the base class and `self` will be the same object throughout. Then, just create a `Supercharged` anywhere you would previously have created a `PythonLibraryClass`.
Thank you. This is all very useful. I’m in the middle of writing an answer on SO to help me keep track of my notes. I’ll let you know when it’s finished. It sounds like using the PyArg_ParseTuple is always going to be a Borrowed or Stolen scenario and like you said is dependent on what you do with the object. It’s also hard for me to wrap my head around the fact that when I create a PyObject in CPython it’s actually a pointer to the object. I have to think a little more abstract than what I’m used to :P
Management loves excel. Probably because they don't usually have any programming know-how, or if they did once they climb to their position they are swamped with xls of those who don't. Either way, you just need to look high enough in the organigram of a big company and you WILL find a level where the xls jungle begins. And it is pure digital cancer... I have made many scripts that pull the info out of spreadsheets, to make folder structures, to pass to a DB, to generate OneNote pages (sadly also very popular tool to abuse). And (sigh) also generated spreadsheets from other information sources.
I wrote a wrapper over PyDAQmx (which in place is a wrapped over nidaqmx). Labview, please, not, give me code, not pictures.
We use Nagios for monitoring, and write Nagios plugins in Python to automatically monitor custom application metrics ("number of logins", etc.)
I used it, just included 3rd party libs into my project. Iirc, there was thing literally called py2exe 
I work in cyber security for a pretty large company and work on a team where literally all I do is automate workflows with primarily python. I have automated things like the processing of millions of indicators of compromise, automated detection signature creation and testing, compromised system isolation and forensics, malware analysis, API orchestration, ticketing, reporting, etc. There's definitely much time and money to be saved by automating away the mundane cruft of a security analysts daily workload so that they can stay laser focused on researching and hunting the latest and most prominent threats.
As a heads up, something like this is more appropriate for /r/learnpython but I'll answer here because I think it's an interesting question with nuance. There are two main ways of handling this: inheritance and composition, subclassing vs creating a literal wrapper. There are pros and cons to each. With inheritance, you just subclass the class you want to augment. class MyClass(LibClass): # augments Doing this is best, in my opinion, if you're augmenting a lifecycle hook on the parent class. I've done this for Django Rest Framework viewsets to augment how requests are processed. This is also how Mistune recommends handling adding/augmenting its markdown renderer. However, you get tightly coupled to the underlying implementation of the class. The common argument against this is the `InstrumentedCollection` that adds a counter attribute for each element added. An implementation might look like this: class InstrumentedCollection(SomeCollection): def __init__(self, *a, **k): super().__init__(*a, **k) self._counter = 0 def append(self, item): super().append(item) self._counter += 1 def extend(self, items): super().extend(items) self._counter += len(items) That looks innocuous enough, but `extend` might delegate to `append` in the base class and now you're double counting items. Whoops. Or maybe it didn't before, but a refactor now causes it to. Inheritance is a powerful tool, but comes with limitation like that. The other approach is using a literal wrapper class (also called the `Decorator Pattern`, which is similar but distinct to Python's concept of decorators), where you write a class that accepts the base class as an argument, providing its own implementations where needed and delegating otherwise. In that case, the `InstrumentedCollection` looks like this: class InstrumentedCollection: def __init__(self, collection): self._collection = collection self._counter = 0 def append(self, item): self._collection.append(item) self._counter += 1 def extend(self, items): self._collection.extend(items) self._counter += len(items) def __getattr__(self, attr): return getattr(self._collection, attr) In this case, if `extends` changes to delegate to `append`, you're insulated to that change. Another advantage of this is you can choose *when* the class is instrumented and for how long, that's not something you can do with inheritance. The downside is that this style of wrapper is generally slower, and you'll also need to explicitly delegate magic methods since they don't flow through `__getattr__`. So it depends on *what* you're doing. If you're specializing hooks on the class, you'll probably want inheritance but be sure you know how `super` works and be aware of how you could shot your foot off. If you're strictly adding behavior that doesn't make sense in the base class, a literal wrapper might be more appropriate.
Take a look at [fn.py](https://github.com/kachayev/fn.py) that implements a special `_` object to create more expressive lambdas. It looks interesting, but I haven't used it myself (I keep looking for reasons, but I don't find them).
Hey all, I often see people asking how to get Python packages with C extensions into AWS Lambda. I wrote a blog post on how I handle it. Feedback welcome :) 
I have used cx_freeze, pynsist and pyinstaller. * cx_freeze did not work for me as soon as I used anything not pure-python. (Say, numpy, pyqt...) * pynsist works fine with pretty much anything I have tried, but you must feed it all the depencies yourself, and you get an installer, not a standalone exe/folder (like pyinstaller does). Fine for a stable solution, not so clean for early development were you generate a new version every other day. Resources are simple to use. * pyinstaller does a good job in guessing most of your dependencies. Resources require some tweaking of your code, nothing mayor. However, they lag behind badly in their release schedule. The latest release 3.2 is from more than one year ago and it does not work in python 3.6.x, which is kind of a big deal. The development branch in git does work, but I had to go trying several revisions until I found the one that both worked in py3.6 and did not break other stuff. Ah, also issues with modern pyzmq. At work I use pynsist for one project (stable) and pyinstaller for another (daily releases)
These numbers aren't made up. One example: A previous coworker left behind a couple years of work (for 2 people) consisting of 20k lines of Java that failed to solve an automation task and only covered a few cases. I covered *all* the cases with a few hundred lines. This isn't about how awesome *I* am. It's about how awesome scripting languages vs terrible languages are.
That's awesome! I can attest that ArcGIS requires near perfect file folder structures or you can break any work your doing in arc. Storing data is a nightmare on bigger projects. 
If that's what you want but I would bet the end result shouldn't be an excel spreadsheet again. I can only imagine two reasons you'd toss it back into excel. 1. The plan is to present / visualize the results in excel. We can do better than that. 2. Someone needs to take the results and use it as a basis for some manual tasks or process. We can automate that. Well third reason being your user asked you to... but you need to show them the way to the promyse land.
First make sure of which python version is actually running. python -c "import sys; print(sys.executable)" If it is the anaconda installation of python, you should be able to install and access packages using conda. Anaconda comes with scikit-learn already included. Try running IPython and importing it using ipython # wait for ipython to load import sklearn 
Automating a bunch of engineering tools and processes. Mainly Python wrappers on existing APIs. Engineering. WinPython Zero makes a good starting point for a small self contained package. 
I was doing a lot of updates and uploads to couchdb. Used to use couchdb or requets. I then switched to asyncio + aiohttp . It's been a lot more interesting and faster to fetch multiple queries and upload/update data to DB.
Thanks! That helped me debug the error!
Ok, that's handy, thanks. If I do decide to uninstall conda, how would I do that? Also, can you make any sense of the error I was getting with tensorflow? I'd really prefer to use that over sklearn.
Is that wise man you, Lord Tyrion?
Data pipelines for machine learning tasks
I'm the author of the document, I wrote it yesterday. Feel free to leave a comment, I can still update it to fix the text (English isn't my native language) or add explanations where needed.
Whenever a college graduate asks me what programming language to learn I always tell the Excel. It takes me a while to explain I'm not joking
The fun thing about doing these operations through the browser is that you don't need permissions or access to the database. Say your job is manually cleaning data, as long as you have a workstation with python installed (this doesn't even have to be your local workstation) and access to the application through a browser, you're good to go. 
No explanation of what the hell "method_missing" is, either here on the post or on the gist. Downvoted because you think we are mind-readers. 
we have this android project with a built-in log gathering process inside that involves hardware keys, popups and waiting. Fooling around I found [monkeyrunner](https://developer.android.com/studio/test/monkeyrunner/index.html) (automation tool in the android sdk using jython) and managed to make a script for that process, at least for me this saves almost a 1hr a day when doing regression/exploratory testing and we are more than 30 people on this project qa team
They didn't let me install Python on my workstation. :(
Never thought about it this way - blew my mind lol
Same, how do you deal with ArcPy/ArcGIS's general slowness though? I find myself having to use a lot of multiprocessing although that's not always easy or possible.
ITT: "If the [PHB](https://en.wikipedia.org/wiki/Pointy-haired_Boss) finds out I've automated this stuff, I'm out of a job" :D
Yes, but once we had the hierarchy specification, it didn't take much work at all. We had it working the same day.
That does look interesting. I'll look into it.
Wha?! Excel and Microsoft suite is the only way that non-tech companies communicate information. It's just how it is.
The promise land being..which format? 
Tracking temporary low-fly avoids and certain flights we can't go near, plotting them in mission planning software etc, setting up images of ground areas with overlays (that's mostly JS though), and made a specialised automated scheduler/training tracker I'm going to implement soon.
I'm an intern. I pull sql data from python using pyodbc. I use f strings (since the query requires several moving parts.) 3 conditions in my where clauses: Condition 1 and 2 have 3 permutations each and condition 3 has 10. Also there are 2 possible dates so this amounts to 180 total queries Pyodbc has to run for me, or 90 per year over two years. I do a bit of analysis on it with pandas, and write the data to 9 excel workbooks consisting of 10 worksheets per sheet. Luckily I am only writing two integers to each sheet, and a small row of threshold checks on if 2017 data is in the expected range or if there is an unusual underflow of data
The list of packages I couldn't get working in Ubuntu [without Conda] was larger; ie psycopg, scikit-learn etc wouldn't compile, in addition to scipy. And I couldn't get python 3.6 with Pip to work, and broke the system beyond repair (ie in a car-totalled way; not worth trying to fix it) trying. Even if it did work, having 3 versions of Python floating around is just awkward. Overall, easier in Windows, although Conda sorts out all these issues on both OSes. Once set up, the experiences are identical, except for Linux's better console. (Ie the way python/jupyter/vscode/pycharm etc work) There's no suitable alternative to Chris Gohlke binaries on Linux; CG binaries just work, while package manager equivalents are out-of-date or broken. [on Ubuntu]
[removed]
"Promyse" is just an intentional (bad) python pun. You see it a lot in packages. I'm not advocating a format. I'm just advocating python over excel. You have the flexibility to output the result in whatever format is best for the scenario.
Alas, I cannot take the credit. I wish I could remember the source, I think it was a post on hackernews.
I am actually in the process f building something for my dad. He does bank valuations and has a ton of exhibits in Excel he uses to support his claims of the bank value. Currently he downloads PDFs and enters numbers by hand into Excel. Currently my tool will take a list of banks, download all available quarterly reports (using a web service) in PDF and generate a single table for each bank with all of the info from the PDF reports. Now I just need to populate his reports which is gonna be a task and a half
So this is like a stupidly late reply bc I lowkey felt insulted by the cash flow comment but Ive been revisiting this and I really appreciate your naming several topics and programs to look up. I've been going through finals and a ton of Jon apps but I look forward to self studying some of this stuff during Fall semester. Thank you so much 
What kind of engineering / analysis are you referencing? Like Solidworks modeling or Stress Analysis?
* What on earth is django-hotsauce? * Why isn't this a link to a pypi page? * Why do I see "Welcome, Etienne Robillard. Sign out" ?
Py2exe works well
automatetheboringstuff.com I worked at a small tech shop that did support for a few companies around town, including the town hall, police department etc... * for a bait and tackle shop, I made a 'button' (yes, that is what he wanted; a button) to go into the router and block the mac addresses of a few computers he didn't want to have access to the wan at night, presumably because of porn. I think I used just selenium. * I created a 'good to know' script that pings google using the os library and returned if the internet was good or bad (lots of storms always took it out and we would get called). We eventually used this to ping anything that was unreliable over the net. It also scraped a particular imap server and presented how full it was at the beginning of every day using selenium. One day the server got full and lots of people couldn't get their emails. My boss payed for twilio so it could text him when something wasn't right on the script. I think this script just used os, selenium and the twilio module mentioned in the boring stuff. It's been a while though. * Last night I drunkenly made a small script that plays a snip of the Alabama fight song when I boot up my computer using the vlc module. 
Great! Glad I was of use. 
Got rid of about 10 part-time heads of data labeling with Python and scikit-learn. 
I for one appreciated the detailed explanation! Thanks for the post 
`method_missing` is a magic method that can optionally be defined in Ruby classes that's automatically invoked when trying to access a method that class does not have.
&gt; it needs to run every time an operator hits print on the computer. That does not sound right. I'll bet you can call it once at boot time and reuse the object. --- If you have more questions like this it's better to post them on /r/learnpython. Be sure to [format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin. Also, include which version of python and what OS you are using. 
use quantopian.com
Working around garbage software to enable data transfer and usage outside of it. Sadly, not in Python anymore because standards.
Made a Flask app to create proposals and spit out excel or PDF's to send to clients.
In Japan they use spreadsheets as word processors...
Isn't that all able to be done within Jenkins itself with slack integration and pipelines?
Do you need to open any ports on your server for this? Do you have a static IP? Or does your IP:Port format work on LAN (doesn't work for me :/ ). Sorry, new to all this.
If it doesn't work for you, pay attention to what host it's listening on. If it's listening on "127.0.0.1" or "localhost", it won't be accessible from the outside. Try setting it to "0.0.0.0", which means every address assigned to your computer. Try: app.debug(host="0.0.0.0") Also pay attention to any firewall you might have installed.
From a fresh install of Ubuntu 16.10: david@david-P65-P67SE:~$ pip3 install psycopg2 Collecting psycopg2 Exception: Traceback (most recent call last): File "/usr/share/python-wheels/urllib3-1.19.1-py2.py3-none-any.whl/urllib3/connection.py", line 138, in _new_conn (self.host, self.port), self.timeout, **extra_kw) File "/usr/share/python-wheels/urllib3-1.19.1-py2.py3-none-any.whl/urllib3/util/connection.py", line 75, in create_connection for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM): File "/usr/lib/python3.5/socket.py", line 733, in getaddrinfo for res in _socket.getaddrinfo(host, port, family, type, proto, flags): socket.gaierror: [Errno -2] Name or service not known During handling of the above exception, another exception occurred: Traceback (most recent call last): File "/usr/share/python-wheels/urllib3-1.19.1-py2.py3-none-any.whl/urllib3/connectionpool.py", line 594, in urlopen chunked=chunked) File "/usr/share/python-wheels/urllib3-1.19.1-py2.py3-none-any.whl/urllib3/connectionpool.py", line 350, in _make_request self._validate_conn(conn) File "/usr/share/python-wheels/urllib3-1.19.1-py2.py3-none-any.whl/urllib3/connectionpool.py", line 837, in _validate_conn conn.connect() File "/usr/share/python-wheels/urllib3-1.19.1-py2.py3-none-any.whl/urllib3/connection.py", line 281, in connect conn = self._new_conn() File "/usr/share/python-wheels/urllib3-1.19.1-py2.py3-none-any.whl/urllib3/connection.py", line 147, in _new_conn self, "Failed to establish a new connection: %s" % e) requests.packages.urllib3.exceptions.NewConnectionError: &lt;requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x7f05de14c198&gt;: Failed to establish a new connection: [Errno -2] Name or service not known During handling of the above exception, another exception occurred: Traceback (most recent call last): File "/usr/lib/python3/dist-packages/pip/basecommand.py", line 215, in main status = self.run(options, args) File "/usr/lib/python3/dist-packages/pip/commands/install.py", line 353, in run wb.build(autobuilding=True) File "/usr/lib/python3/dist-packages/pip/wheel.py", line 749, in build self.requirement_set.prepare_files(self.finder) File "/usr/lib/python3/dist-packages/pip/req/req_set.py", line 380, in prepare_files ignore_dependencies=self.ignore_dependencies)) File "/usr/lib/python3/dist-packages/pip/req/req_set.py", line 554, in _prepare_file require_hashes File "/usr/lib/python3/dist-packages/pip/req/req_install.py", line 278, in populate_link self.link = finder.find_requirement(self, upgrade) File "/usr/lib/python3/dist-packages/pip/index.py", line 465, in find_requirement all_candidates = self.find_all_candidates(req.name) File "/usr/lib/python3/dist-packages/pip/index.py", line 423, in find_all_candidates for page in self._get_pages(url_locations, project_name): File "/usr/lib/python3/dist-packages/pip/index.py", line 568, in _get_pages page = self._get_page(location) File "/usr/lib/python3/dist-packages/pip/index.py", line 683, in _get_page return HTMLPage.get_page(link, session=self.session) File "/usr/lib/python3/dist-packages/pip/index.py", line 792, in get_page "Cache-Control": "max-age=600", File "/usr/share/python-wheels/requests-2.12.4-py2.py3-none-any.whl/requests/sessions.py", line 501, in get return self.request('GET', url, **kwargs) File "/usr/lib/python3/dist-packages/pip/download.py", line 386, in request return super(PipSession, self).request(method, url, *args, **kwargs) File "/usr/share/python-wheels/requests-2.12.4-py2.py3-none-any.whl/requests/sessions.py", line 488, in request resp = self.send(prep, **send_kwargs) File "/usr/share/python-wheels/requests-2.12.4-py2.py3-none-any.whl/requests/sessions.py", line 609, in send r = adapter.send(request, **kwargs) File "/usr/share/python-wheels/CacheControl-0.11.7-py2.py3-none-any.whl/cachecontrol/adapter.py", line 47, in send resp = super(CacheControlAdapter, self).send(request, **kw) File "/usr/share/python-wheels/requests-2.12.4-py2.py3-none-any.whl/requests/adapters.py", line 423, in send timeout=timeout File "/usr/share/python-wheels/urllib3-1.19.1-py2.py3-none-any.whl/urllib3/connectionpool.py", line 643, in urlopen _stacktrace=sys.exc_info()[2]) File "/usr/share/python-wheels/urllib3-1.19.1-py2.py3-none-any.whl/urllib3/util/retry.py", line 315, in increment total -= 1 TypeError: unsupported operand type(s) for -=: 'Retry' and 'int' scipy and sklearn worked this time around though. This is on v3.5 I'm particularly impressed about scipy; that's notoriously difficult, and I've never gotten it to compile on Win.
Ah, that makes sense. I just assumed one has to host the app somewhere or something like that. I'll try 0.0.0.0. Thank you.
No, I'm fine with the arrow syntax, my problem is the unconstrained **eval**: print(lambda_from_string("(x,y)-&gt; __builtin__.open('somefile', 'w').write('payload') or x+y")(4,2)) But hey, if no one ever uses this on inputs someone else controls, go nuts.
`method_missing` is a fairly well known feature of Ruby, and the gist regardless shows an example of the Python mixin in use, again demonstrating what the hell `method_missing` is. The whole mixin is just 17 lines in the first place. It’s a joke, there’s not gonna be a README.
In Japan, they use faxes as email...
Data processing. I work in exploration geophysics. Much of the data that we get from our instruments comes in the form of time series data, usually as a csv or similar. There is usually a series of data processing tasks to be done on each dataset each night by the crew chiefs that are collecting this data. It usually costs them about 2-4 hours to do quality assurance on the data - check for bad values, gaps, plot it to ensure it's reasonably sane, compare against base values, etc. Using python, it becomes 'run a script, check the plots'. We typically develop against a collection of scientific packages called Winpython. https://winpython.github.io/ Basically, if the module is part of winpython, we are allowed to use it. If it isn't, don't. The more common modules we use are: numpy, scipy, pandas, matplotlib, pyqt/pyside, pyqtgraph, pyserial, and h5py. We use winpython due to the whole 'self contained installation' thing, requiring no admin rights. You can have a half dozen versions, each in their own folder, and switch between them freely. It allows us to use old scripts without having to worry about things that have changed in newer versions, which is important because ... When we archive our data, we also archive the script that was used to process that data. This is to ensure reproducibility. If you take the same data, and the same script, you should get the same results. A combination of the data, the script, and a winpython version meets those requirements. We've saved quite a bit of money this way, in terms of hours spent processing data manually. This means our geoscientists can spend more time interpreting the data, and less time massaging it into shape first. It also helps us bid against competitors who use cost-plus billing, who are used to billing hours for all of that data processing work.
Removed the need for a video editor with a Python script that adds "MTV-style" video titles to the start and end of music videos using moviepy. It took a few days time to totally perfect, but it can *shred* through music videos in a queue and now I'm creating an automated pipeline for uploading new videos into the system.
The script is only a few lines long, and is called by LabView in a CMD window. What the script does is generates a label using NiceLabel, sends it to the label maker, and closes. This is why the win32com line is called every time the operator hits print.
I keep meaning to do this for our internal support system. One day I'll do it.
For me, the answer is as simple as "I haven't learned enough Powershell yet".
Oh I see what you mean. Yes, it needs to live somewhere, but that somewhere can be your local machine.
There are these really old wen servers at work that have been around your 10+ years and are completely undocumented. The crash multiple times a day due to the programs the last kead dev wrote being poorly made, memory hogs, and just plain out of date. Instead of fixing it, the cio just wants me to build something to replace it and actually document my work. Regardless the machines crash everyday (usually a few times) due to zombie processes and running out of memory. So i wrote a script this checks memory and whether or not the main process are responding. If they are not it turns off my ha software (switching the ip to a different machine cause muh uptime), captures the last 30 minutes of relevant logs and sends them to a special logging machine, then finally reboots the machine. 
&gt; What on earth is django-hotsauce? Please see the wiki: http://www.isotopesoftware.ca/wiki/DjangoHotSauce &gt; Why isn't this a link to a pypi page? Because pypi dropped support for python2.7. &gt; Why do I see "Welcome, Etienne Robillard. Sign out" ? The OAuth middleware (django-hotsauce-oauthclient) is still under development and contains bugs like this one. 
This. During an internship, *I* showed them index-match, they thought I belong to people with pointy hats. I was like, "meh, what the fuck I am going to learn from this internship"
#
To address the wrapped-in-string issue, you could maybe do something like what sqlalchemy is doing with filter notation. Essentially, I think there's a way to get the params to a function as a string.
You can use the `inspect` module to peek at the interpreter stack. Actually doing this is almost certainly a bad idea. 
I think SAP tries to do this, only they just managed to make a product that is even more error prone than the spreadsheets and costs an absurd amount of money.
I use Python to redirect 10,000 texts per day from a very expensive vendor to inexpensive vendors (plural) and have saved a quarter million in the past couple of years. It's not just the money saved, it's also much improved service from the new vendors and also having choices in the future. My motivation was not to save money. That's just how I justified it. My motivation was a deep dislike for incompetence of the original vendor. 
Haha there are those people as well; I'm just looking at the math behind it. I don't think I'm great at rolling the dice to begin with! 
1. Wrote a script to generate dxf files for standard shapes (rectangle, sector etc) that's later fed to a nesting program (which is a 2d shape packing software) 2. Wrote a script that opens drawing files from excel by first matching text inside selected cell or by trying fuzzy search if that fails. Saves shit ton of time, I have to search, open and read like 300 cad drawings per day. 
Any chance it has interactive spreadsheets in the browser? I'm hoping to rebuild from Access to a custom web app, but in many situations editing a data sheet is quicker than filling out a web form. Like Handsontable with Flask, Pandas, and live SQL table editing would be, amazing.
Excel is just like cancer - it starts small and consumes all organs in the end
Workday, sort of. 
And if you're using IntelliJ, it'll give you a context based refactoring option to pull the lambda out into a method if you need it if I remember correctly.
Thanks for the answer! I'll try implementing it later! Why would this be a bad idea?
Here are some run-of-the-mill application my company saw gains in: 1. Building management. We wrote a set of scripts that interacted with a few buildings' management systems that had a web service. We were able to first aggregate how much time the system was running, what it was doing, and calculate the energy usage during those times. With this information, we were able to make changes to the operations and save up to 30-40% of energy usage during peak hours. Translated to big money. 2. Sales/Budget planning. We wrote a set of scripts that analyzed our various sales information. Sales per day. Customers who were buying and when. Customers who were calling and for how long. With it we were able to determine the end-of-budget-year times for a number of our clients and rather than having them all call at once and potentially end up disappointed we proactively reached out before the near-end of the year and got them setup. Saved us time and frustration and our sales were more consistent and increased. 3. Hobbies. I like to play D&amp;D and have a number of scripts that can generate: Town information, dungeon information, NPC vitals, treasure vitals, treasure tables, monster information, and all of the above for a thriving area ecosystem for the game. It saves a lot of time in planning and is helpful for friends who also want to run a game.
So many ways to get rich. But building a better mousetrap doesn't gauruntee you'll be able to sell the product.
Conda is packaged with Anaconda. You can uninstall Anaconda via the Windows Control Panel &gt; Programs and Features I have no idea about the TensorFlow error.
A large amount of capital to spend on advertising, sales, documentation, user experience and so on would definitely help - or a large group of mutually trusted, folk willing to work on it - although this all ends up being outside the remit of /r/Python.
If you truly only want it callable from within a certain function/method, then define it inside that method. That way it will not be accessible from any other code. class Whatever: def main(self): def do_whatever(): #do something do_whatever() 
The thing is, I want only one of its methods accessible from a specific function, but the rest of the class accessible from wherever else.
I'm also in the mapping business but I use QGIS everyday. It's an open source GIS software. It has a built in python console which is awesome. You can also write your own plugins in python. 
&gt; What sort of cases and why so often do you find yourself needing to rename and organize files by executing a static python script instead of doing it through the command prompt/line? Well at a very basic level it's just "which one is easier"? Most command shells (windows cmd, bash, etc; excluding Power-Shell) are all string based. Being able to walk your filesystem as objects instead of strings is a heck of a lot easier and less prone to oft overlooked issues with escape characters or variable expansions.
Exactly, I think the only way would be to implement `-&gt;` as an operator. That's the only way it could be clean. This string stuff ends up being uglier than "lambda colon" as you call it... 
because it creates counterintuitive code. Things should do what they do consistently. Why do you want to do this?
Thanks for the reply. Appreciate it.
This is just a silly anecdote. I'm a fan of python and I don't like Java, but it is insane to come up with an example and say "6-12 months in Java and I have done a better job in 1-2 hours of Python". Regardless how we don't like Java, this is unrealistic; it surely cannot be the whole story. That equation doesn't hold. 
I guess it depends on what you think a "static python script" even means. If you think it has lines like os.rename('test.txt', 'old_test.txt') then yes, of course that's dumb. If, OTOH, it can walk through a directory structure and do certain operations on files satisfying a certain criteria then it doesn't do the same thing every time you execute it. Depends on your definition of "static" here - the script itself didn't change but the result did, so does it count as "static" or not?
We have a large set of software components written in various languages, with different property file formats, that talk over JMS to form a processing system. If something like the IP of the JMS server, or some expected data paths, needs to change in our testing environment it's a pain in the ass to do by hand. So I wrote a convenience python script that basically does a find-and-replace across a defined set of property file extensions but with the ability to specify file names/extensions that shouldn't be touched.
It's probably more a question of what I don't automate than what I do. Both in AWS and here, Oracle Cloud, everything is exposed via API. Monitoring, load balancers, everything. I write tooling to automate stuff in part because I'm lazy. I hate to do anything by hand that can be automated, and generally anything I'll have to do manually will be something that comes up repeatedly anyway. Yesterday I had a one-off sort of task, to spit out some JSON. Some 70 odd of mostly the same thing, with a few minor variations. I quickly knocked up a python script that had a template, and just looped through the variations and spat out the JSON. Its took barely 5 minutes to write and saved me at least half an hour of immensely dull work. (I've bigger plans to better automate *everything* around that)
see https://stackoverflow.com/questions/42686763/how-can-i-build-a-gui-to-use-inside-a-jupyter-notebook
I'm currently replacing a paper based issue-tracking system with one that based on Django. Spans several departments. It should at least save some paper :)
How did you do this? Is it on windows or Linux? 
Creating a unicorn isn't just taking a horse and waving a magic wand over it to have it sprout a horn and a billion USD valuation. It takes willing investors, a market that fits the product, a solution that fits the market and company whose employees (at all levels) know what they're doing. Oh, and also a bit of luck. See: https://www.amazon.com/Lean-Startup-Entrepreneurs-Continuous-Innovation/dp/0307887898 What I mean is, it's quite possible that someone has tried before but lacked one of the above four prerequisites.
Ok... and can you explain your use case... what is it about that one method why it should be accessible only by a specific function... what is it about that specific function... what are you trying to achieve here...
Yeah, this sounds like something that could have been handled with Jenkins parametrized jobs. Polling the job also seems very strange, considering that Jenkins has plugins for sending Slack messages when it's done...
Great answer.
It's been a couple decades since I took physics at University. Back then it was taught through the simplified analogy of finding the middle point of the surface of a square. I always understood the analogy, but I always had trouble making the mental leap to the next step.
you on creativecrash (now highend3d)?
What kind of work do you do? It sounds really cool :O
I suggest that you put the question to [python-win32 -- Python on Windows (32-bit and 64-bit)](https://mail.python.org/mailman/listinfo/python-win32).
To be ultra specific, the other responder probably means doing things like checking against, say, two kinds of date formats (mm/dd/yy, month-dd-yyyy), and automating the format changes while moving it to the right place 
There are two ways I think you can go about this, the first method I'm going to mention is more straightforward and will definitely work, but some may regard it as a hack. The second is definitely more complicated, and I'm not sure if it is actually possible to do this. 1) Write a server that runs in the background always, listening to inputs from the client. Then you'll only need to dispatch once. I recommend using zmq for this purpose, it's straightforward to implement and supports a wide range of networking architectures and platforms. It is possibly overkill for what you need to do, but it's simplicity here would in my mind outweigh the need for an additional dependency. The alternative would be a socket interface, which is part of the standard library. 2) the COM object has a way to auto generate all functions in an interface, you could experiment with that to see if you could get that to work. I've done this once in the past, but don't remember if I needed to reinitialize the engine every time I needed to run the script. 
If someone asks me to report on file inventory, 100% of the time I'm going to just use Python. We turned a series of QA processes that took a couple weeks into a five minute exercise. This was really just automated log reporting, but it's a BFD for my team. Also, general ETL, which, huge deal in the business world.
I have one! I used to work at a Chevy dealership. Every month, we'd get a list of names, VINs, and address of customers that had open recalls on their vehicles. We sent postcards to these people letting them know of their recall and giving our contact information so they can schedule an appointment. Once we had the list, there were a few checks we did to eliminate a few local salvage yards and other people that requested to not have postcards sent. We also had to consolidate all the recalls together, since these spreadsheets had a row for each recall on a vehicle. We also had to check if an address had multiple VINs, since we didn't want to send multiple postcards to the same address. Since the checks were a bit too complex for a normal Mail Merge, they had been writing everything by hand on printed template postcards. I wrote a tiny python program that did these checks, consolidated the data and outputted it into a flat CSV file that could be mail-merged into a postcard template and printed. We then printed everything on the postcard directly in one go: address, VIN, and recalls. This took a task that would take days / weeks, into a few minutes. I'm happy to share the code if you'd think it'd be of any interest, it's a whopping 30-ish lines and nothing too spectacular, but it worked well.
Try MITX 6.02 on Edx.org. What you're probably doing is exploring probability using games, and that's what a good portion of that class is about. They use Python.
Good advice except you clearly didn't read the post and see that he's looking for something aimed at mathematical computations.
My very first application was built to handle auto parsing of crash dumps that our application was pushing into our servers. We had something like 170,000 .zip files sitting on a server that had various contents, one of which was an XML file with the crash info and address etc. Wrote a small app that crawled a folder on a cron schedule, extracted contents, pushed the results to a service called logly (sp?) then archived the zip file with a UDID that could be pulled by an engineer if they wanted to get the memory dump from the files. In two sprints we smashed two major bugs we had somewhat known about but couldn't find and removed a third party library that was barely in use but causing 60% crash rates in some environments.
import random
I'll chime in with: "if you want a method to only be called in **main()**, only call it in **main()**". Doing this will spend a lot of processor cycles on checking for what should be a very rare condition, one that that can be eliminated through better documentation.
I am so glad you stopped by 3 months later to correct me.
It makes your code hard to re-use. Maybe I re-write your code to do some work in a separate thread, but if I want to call your method from that thread. Maybe I realize I can factor out several operations (including calling this method) into a new function, or I want to use your function as part of a context manager. All these things are disallowed. Python doesn't have access modifiers by design. This sounds like some sort of attempt to jury-rig access control (I'm guessing you're more familiar with .NET or Java?) But it sounds very weird, and doesn't match what Python programmers are going to expect. I'll echo what others have said: why do you think this is something you need? Are you writing a library where a function needs to be run first to set things up? Are you afraid users of your library will misuse it? What do you *really* want? (It's probably not that your method is only invoked by functions named "main"). 
There is no sense in creating native apps .... For 95% businesses web interface is totally fine. Actually any website is an application, reddit, google, any site using DBMS and backend programming is a app with web interface. 
Processor cycles are not the issue here.
I'll grant they're not the only issue. Checking for an exceptional condition that can only occur because you haven't told someone how to use your code is a waste of time and computing resources, both of which are better spent on telling them.
I'm pretty sure I saw that at kottke
Thank you for the feedback! I am in high school and still learning so all suggestions are welcome. 
Oh how I remember the days when *a day and a half* wouldn't even have been considered a learning curve. Django is a *framework*, Flask is a *micro-framework* ... with Django it's all there, kitchen sink and all, with Flask you'll have to find or write plugins. Django seems to have always been a bit more accessible to the "everything-must-be-OOP" crowd, while Flask is arguably more Pythonic. If you're building (or more likely maintaining) a bloody big, massively interconnected e-commerce website + corporate intranet, Django has definitely got its strong points... if you're building a web app with a REST interface, Flask is amazing. It's all a matter of perspective. But seriously, a day and a half? Dude, try Dwarf Fortress.
Oh yeah, that would be terrible. It was intended to be a cleaner way of using lambdas in slinkies, though. See [this](https://www.reddit.com/r/Python/comments/6rr5ue/i_got_a_bit_drunk_last_night_then_i_sat_down_and/dl76z5w/) comment.
I am in highschool so I am still learning new things everyday! For security concerns, I mentioned in my blog post to create a new gmail account, only for SiriControl. This means that there would be no personal data in the account. Thanks for the feedback and advice, though!
What I meant by the learning curve is that after seeing how Django is built, I've realized that using it would be a waste of time, mainly because many things that are simple in other frameworks would take a long time to figure out in Django. Of course I didn't even touch most of the framework in these day and a half, but it was enough to realize that I'm not going to stick with learning it, especially because I'm busy with my work and I do have other stuff to do on weekends...
The learning curve was not that high for me. We use Django at edX. For the pay couple weeks I've been exploring using Node.js for a project with Express. Django gives you practically everything you need to get a database-backed site online fairly quickly. It even has support for functionality some folks may not use, such as i18n. Piecing that all together with Flask (or Express, as I've done this week) is resource-consuming. Put simply: do you want to focus on your business logic or the infrastructure. Frameworks let you focus on the business logic. 
Are these D&amp;D scripts something public? I'd love to take a look, both as a DM and a dev!
Try to automate everything you can and it will all pay off in the future. You have X process that is relatively easy and is documented so the new user can do it? Great. But why not automate it? That way, it's error free and you can test it works. It's gonna be as fast as humanly possible and you might learn a thing or two. It can be bumping up version numbers, setting up desired environments, testing backups, deploying things, analyzing and reporting things and I could really be all day. It's really practical to have that mindset.
[Interview Cake](https://www.interviewcake.com) is a brilliant website that I found recently. 
It's just called lambda notation ... it's a direct map of the **def** statement to a single line, only anonymous and with an implicit return: lambda *args, **kwargs: do_something Is the exact same thing as: def _(*args, **kwargs): return do_something And, visually, there's not much difference between: lambda x: x + 2 And: x -&gt; x + 2 Especially when, unless you wanted to do the monkey-patch madness -- hint, you don't -- you'd always end up having to do something like this anyway: arrow("x -&gt; x + 2") Note that unless you choose a name for your "arrow" function that is exactly one character long, you're doing more typing than the lambda way anyway.
Yeah, I get it, I just cringe whenever I see anyone using **eval**. It's very difficult to make that even remotely safe.
Military
Sure, no problem... only people have built entire careers off of having figured it out. You barely scratched the most minimal portion of the surface of what it can do; it can do *a lot*, and for a large number of users and a significant portion of the web it does it very well.
lol
I use Django-hotsauce to simplify pragmatic development of Django with a easy learning curve and stable API.
They are not, but I don't see why not. I'll look into getting them on GitHub! I'll let you know 
wrote a tool that replaces an expensive (&gt;$30k) 3rd party system that emulates wifi clients for capacity and performance testing.
Windows PowerShell script: Add-Type -AssemblyName System.speech (New-Object System.Speech.Synthesis.SpeechSynthesizer).Speak("It is currently " + (Get-Date).tostring("t") + " on " + (Get-Date).tostring("d")) Throw it in task scheduler for hourly.
Thanks... I'm aware of lambda. I called it lambda colon as to the OP and to accentuate that it is mostly about how the syntax looks like (a lambda and a colon would be swapped for an arrow). 
&gt; lol I developed Django-hotsauce because coding with Django was boring. :)
Yeah, sorry, my response was meant to be to OP, clicked on the wrong part of the thread.
Seems a bit backwards, shouldn't it be the next person switches it to themselves (manually)? The idea there being you know &lt;next person&gt; is actually at the phone and ready to answer or that someone is trying to at least find &lt;next person&gt; instead of just hoping calls get answered for the next rotation.
[removed]
I've done something similar but instead briefly searched for "php?id=", as you could find pages that could be tested for sql injection. Google was indeed not the easiest, so instead used the common crawl data to identify domains. I gave a presentation about it: https://kootenpv.github.io/injectable_presentation/#/5
I'm not seeking free labor. I'm sharing details with interested parties who have messaged me ;) And no, open sourcing is absolutely not an option. I'll do it myself if I need to, it will just take longer. A partner would be helpful, but not necessary. 
I can provide an example from experience: a small software editor I worked for as a sales rep used excel files for everything, including customer relations, licences sold, pay… Our CEO was good at Excel, and felt overwhelmed by tools designed for a specific job like a CRM.
Use portable python or winpython.
These companies exist already. Applicant tracking you have greenhouse icims taleo(was the powerhouse before getting bought by oracle). For actual human capital management ADP dabbles in it, workday, etc. it's a huge market and these companies make a killing since it's so vital to HR. 
I started with Flask first also thinking it was less to absorb. The more I got into my project, the more extensions I started to require and had to figure out how to piece things together (auth, security, admin,etc.). I had some ideas, but spent a lot of time wondering best practices. Later I tried Django and realized thousands of devs already thought about those best practices and Django is what came out of it. Django's getting started is not that much longer than Flask's. I spend more time focusing on business logic now and less on web frameworks.
I've used ConfigParser in some of my past projects, which is a library for manipulating .ini (config) files. import ConfigParser def setSettings(section, **kwargs): config = ConfigParser.ConfigParser() config.read('config.ini') try: config.add_section(section) except ConfigParser.DuplicateSectionError: pass for arg in kwargs: config.set(section, arg, kwargs[arg]) with open('config.ini', 'w') as f: config.write(f) def getSetting(section, setting): try: config = ConfigParser.ConfigParser() config.read('config.ini') return config.get(section, setting) except: return None
At my work, my team has a python app that literally saves a few hours a week of our time. It automates tasks we would otherwise have to perform manually in a big, enterprisy app that is a pain to deal with through a browser. We use requests, json, and xml modules. The app is run through a Django based web interface. 
Thanks a lot. I'm happy to help if you need, I wanna improve from my basic Python. 
You give them a link which can then run the library of tools?
Might be wrong, just going on my reading... looks like OP is using files, but they get 'reset' everytime OP's code runs... which indicates file is created for writing, not appending... So my guess / suggestion is for OP to look at the parameters used in the open() call
I find it intriguing.
Thanks! 
I stand corrected.
I definitely saw it on [Hacker News](https://news.ycombinator.com/item?id=14629533). He actually [references the post](https://twitter.com/kottke/status/885529510380261377).
I just had the same train of thought. Haha
&gt; I do not want others to copy my code The other replies here are good for going to exe, but they all will ultimately leave your code vulnerable. Python byte code can be easily decompiled to the original source minus comments, even in an exe if the file format is well known it can be done. Take a look at Cython. You should be able to build your python file into a pyx, then a c file, then truly compile it to binary. That's the best you can do if you really want to protect your code.
Other changes that nailed me while writing a library that's Python &gt;=2.6 and &gt;=3.3 compatible; - ``zip``, ``map`` and ``enumerate`` are generators now. This caused some of my code to work in Python 2 but not in Python 3. - ``sorted`` and other sorting related methods no longer accept a ``cmp`` argument. ``functools.cmp_to_key`` and compound functions will help you work around this in Python &gt;=2.7 (I had to write my own to ensure Python 2.6 compatibility) - Strings require an encoding now; you can have ``bytes`` objects that represent binary data in ASCII but are incompatible with Python 3 strings, which are equivalent to ``unicode`` objects in Python 2. (string encoding is my least favorite part of Python 3) - ``reduce`` is no longer a built-in, it's included with ``functools`` instead The other gotchas I encountered were in the C API, but you'll only need to know about them if you're writing C extensions. I must say I absolutely love Python &gt;=3.2's stable ABI, it's really helpful for making extensions that work on more than one machine. A few more things I encountered for when your lowest common denominator is Python 2.6; - Format with positional tokens only don't work in Python 2.6 (``"{} {}".format("Hello", "world")`` produces a runtime error) - There are no ``dict`` or ``set`` literals in Python 2.6 - ``argparse`` and ``OrderedDict`` are missing, though you may find most systems running Python 2.6 have these installed as extra party packages
Fabric and patching linux hosts was some of the most rewarding work I have done looking back( with python ). It's so silly but something that took so long to do everyday cutting it down into a couple hours made me fall in love with python as a sys admin. I have done some awesome things with python since but the scale at which python helped a daily task the at Enterprise level with minimal time investment speaks volumes.
A long time ago, in a company far far away. .. I wrote a python script that automated running two PDFs through ImageMagic. IM would highlight any difference in red. We used it for regression testing code that created the PDFs. 
The whole branding of our iOS apps. Python creates a new branch on git, converts images to the correct format, creates xcasset folders, modifies some source code based on customer needs, creates the app Id and provisioning profiles on developer.apple.com, creates the iTunes Connect store page, and builds and uploads the app. That whole process used to take around an hour and a half each. Now it take about 5 minutes. I did a full day's work in about 15 minutes total last week. 
Right now this: https://www.youtube.com/watch?v=PD1WEYVFYEY https://www.youtube.com/watch?v=urDXIdXaeTQ Other parts include putting a bunch of other boring tasks (Excel, reports, etc) in Python and running it with Jenkins.
Why not simply declaring it twice ?
It also handily avoid update headaches. Someone discover a problem, you fix it, all uses new version. VS running around the office trying to track down all using your script.
vOv Okay.
Or your modem might not allow hairpinning. (Problem with mine.)
Very very new to python, work in hospitality, looking to convert a daily excel spreadsheet we use to an easily viewable but still modifiable format, any recommendations?
I built a program that takes a daily updated list of patients, configures the data into a json format, then uploads it into Redcap via API where appointment reminder text messages are sent. The hardest part was working with all the data restrictions of a healthcare organization.
You could do what I did on my first user application and make it automatically update, silently, each time it's run This was just for a chat application, and I absolutely did use it to run arbitrary code on people's computers
You should patent the scheduler/tracker and sell it to drone delivery companies ;)
In your defense, most of these PaaSs are ridiculously complex! The real win is finding the PaaS that is designed well enough to be used simply OR complexly!
Saying what? edit: oh 'this'.
Instead of being strange, it's really just a way for the script to get even better. Not everyone knows everything.
yeah and that is perfectly fine if they want to pay humans to manage spreadsheets. But i think if they have multiple inputs/outputs or clean up tasks, then it makes sense to pay developers to fix it properly so that repetitive work is removed. The other issue with excel is there is often siloed information on how to update them. so people become attached to them. it's like pissing away money.
Opening card packs in a game to check if all cards can be dropped (cards with wrong errors in their definitions could break the game). It saves us many hours of opening and registering which cards have been opened. It uses Tesseract to get the card name and simple image recognition to go through app flow.
Finished my Python class, only four more classes until I finish my degree.
I wrote a scheduling, notification and alerting system for Microsoft orchestrator runbooks in python with Django, that's doing VMware snapshots and a few other things in the middle of the night that previously someone would have had to do. I like that my work can save people some sleep.
We used to call that ETL. Same thing?
This doesn't have anything to do with how "terrible" Java is, that's a terrible conclusion to reach. Sounds more like your coworker was either a complete idiot, trying to reimplement something from the ground up, didn't understand the requirements, or someone was constantly changing the requirements. There's no way someone competent thought 20,000 lines of Java were necessary to do something you supposedly pulled off in 200. 
My problem is that hosting is complex. It just is. And to address this, they layer on a ton of abstraction that doesn't help you understand anything (it still looks like magic) and isn't transferable knowledge. If your app becomes successful and you outgrow the PaaS, or want to switch for cost or whatever reasons, you have learned *nothing* about how the technology works. What in the everloving fuck is a "dyno"? I'm not advocating that everybody should learn how to kick-start a physical server and wire a rack. I don't expect people who drive cars to know how to build or even fix that car (I can't do that). But when things go wrong, and *they always do*, being completely helpless is not a good place to be. I can change my own tires, I vaguely know what an air filter is, where to find it, how to determine it needs changing (at a very gross level of understanding), and how to buy and replace it. With Heroku and similar PaaS service you're basically SOL and only have access to very specific parameters to tweak. And those are the ones Heroku/Engineyard/Digital Ocean have decided to expose. They may not be right for you. At some point there's *always* something else to tweak and suddenly you're this total tech noob who's never seen a MySQL prompt and you have to decide how to tune your buffers and it's just a nightmare. It's the same reasoning behind using GUI wizards for everything and never dropping to a terminal. I love GUI wizards for a lot of things and I'm glad it's not all CLI anymore. But I've worked with a lot of professional, highly-paid software engineers in charge of web apps who don't even understand how remoting into a server with ssh works (like, they don't know how a public/private key pair works, which one you need on your computer and which one you need on the remote machine and how your local user name maps to the remote one). This is a real problem in our industry, and I trace it back to the rise of Rails, its ecosystem (heroku being one) and its culture of always increasing the abstraction between your code and what really happens at run time (e.g. the switch from JS to Coffeescript as the *default* in Rails 3 or 4 (can't remember).
Thanks!
I really enjoyed the way this is presented. I had seen the pictures multiple times before but this is the first time I saw how simple they are to compute!
I made a system with Django that handles a lot of the processes and paperwork around bringing in freelancers - it allows people to request them from Finance, automatically sends out the paperwork via Echosign, and then prefills the freelancer's timesheets with the proper job numbers (since it knows what they're working on from the request) - that data can be exported to a spreadsheet which is uploaded into the system that handles payroll. That last part alone saved ~30 man hours a week, used to all be done via spreadsheets and email (shudder). I also had to send out this report for each office globally (same report, but different data - so some handful of separate sheets) - made a script that just reads the name of the file and emails it to the right person. No one actually cares about that, but it saved my sanity :P Also /u/spaghetti_taco has very wise (shared) words: "A wise man once said if you want to build a new company just go into a business and ask what they still use a spreadsheet for, then write software to do that." &lt;- Everything I've automated was in some way a spreadsheet before I killed it off.
It may have already been said but thank you to everyone who has commented! I'm not OP, but this post has given me so many ideas for the future I don't think I'll have to worry about coders block for awhile!! 
You should look into microservice architectures. He should be able to access the reports from anywhere. No need to run it on localhost.
The processing is done on the server and when the user access the URL an HTML page with the results of the preceding is returned for them to view.
A couple things... 1) my manager had to download about 2000 documents and create a folder for each. He used to do this one by one from a website, so I asked if there was a way to get them all at once. They sent credentials to an FTP site so I downloaded them all and wrote a simple script to create a folder for each unique document name and copy the doc into it. Used to take him 20-30 hours to download the docs and create 2000 folders, the script runs in about 60 seconds. 2) I write python code to customize the software we use (A terrible GIS extension to AutoCAD called spatialNET). There is no documentation for the API so it has taken me forever, but I've finally learned enough of it to write some time saving tools that save our production people a lot of time and headache.
If you're in Python 2, try: True, False = False, True
This. Same here.
&gt; ETL Yeah, sounds like it. *Extract, Transform, Load* is exactly like that - you get the data from the legacy format (extract), then you change it to work in the new system (transform), then you put it in the new system (load). 
This is a good rule of thumb. I just realized, I use an excel spreadsheet for something I should just automate.
It's possible Java isn't terrible. However, it isn't just this one coworker who produces terrible Java code. *Every* project where I work that's written in Java is bloated, slow, largely feature-free and useless.
Well structured!
Thanks! I really appreciate that!
pretty sure you're on someone's shitlist now.
Probably, but it's no longer a problem now.
&gt; It's possible Java isn't terrible. However, it isn't just this one coworker who produces terrible Java code. Every project where I work that's written in Java is bloated, slow, largely feature-free and useless. So I'm just going to put this out here - maybe the problem isn't java????
Very possible. All I can report on is the data I see.
_Very possible._ _All I can report on is_ _The data I see._ &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ^- ^/u/idesofmayo ------------------------------ ^^I'm ^^a ^^bot ^^made ^^by ^^/u/Eight1911. ^^I ^^detect ^^haikus.
You aren't reporting on data you're making unfounded correlations. The data would be "my coworkers write terrible code."
^ The mark of a good teacher
Congratulations, you're doing something weird. &gt; exception SystemError &gt;Raised when the interpreter finds an internal error, but the situation does not look so serious to cause it to abandon all hope. The associated value is a string indicating what went wrong (in low-level terms). &gt;You should report this to the author or maintainer of your Python interpreter. Be sure to report the version of the Python interpreter (sys.version; it is also printed at the start of an interactive Python session), the exact error message (the exception’s associated value) and if possible the source of the program that triggered the error. Working with some questionable C extensions by any chance? 
We're talking about dozens of people of various levels of experience and types of education. I mean, it's possible that they all *just happen* to produce bad code in the exact same language. But really, it's the overall system designs that are awful (XML + Java + ActiveMQ + unnormalized DBs will be the death of us all). Based on the fact that all these system designs are coming from different people working in the same technologies...I tend to blame the tech first. Something about it is rotting people's brains.
lol It does seem like a bit of a rabbit hole. Although digging into it, I'm starting to understand the subject a bit in the broader view. The udacity machine learning course is like a super simple approach to it all. Im almost skimming through the videos and getting the bigger concepts. I prefer videos to reading for some reason. How good is the book? I might pick it up myself. 
So uhhh, it seems the the keyword `iterable` is the cause here... Removing it makes everything run correctly. Is that supposed to happen? Why does that happen?
Any engineer worth their salt should be able to make something work in any language (assuming they've had time to learn it), period. The language shouldn't matter. Every language has it's drawbacks and weird/dumb design decisions - even python.
I had a highend3d account a very long time ago, but never got into the habit of visiting.
* maybe factor out the code that reads a string and exits into it's own function * try out something like `if xString.lower() not in ('quit', 'stop')`
&gt;An implementation may provide built-in functions whose positional parameters do not have names, even if they are ‘named’ for the purpose of documentation, and which therefore cannot be supplied by keyword. In CPython, this is the case for functions implemented in C that use PyArg_ParseTuple() to parse their arguments.
Ahh thank you!
Looks like this bug has been fixed. https://bugs.python.org/issue29327
Could I have the code? I'm interested in learning how to do these things, as I'm not the best at python.
Ahh righto, I was using python 3.6.0, guess its time to update
&gt; After a day and a half of attempting to use it I understood basically how it workes I'm embarrassed for you... complaining that it entire you 1.5 days to learn the basics of such a large (in terms of capabilities) web framework as Django.
It should be a hunt group. If they have a pbx.
In Japan, they train people to use calculators quickly.
I thought the same as you once but as I spent hours trying to integrate the different parts needed in Flask for a basic app I realised that Django had already solved these problems for me and all I had to concentrate on was my own code and not waste time figuring out which flask Blueprint to use and how to make them work together. 
I work often with spreadsheets and Python. I think some of their power comes from that they present data to the user. I often dump aggregated data from our dbs into them so they act like live dashboards. Also they can be read from for user input. Makes it quicker for everyone to have the ability to write into a dB. For Python and Google Sheets I recommend gspread.
I use it for many things in a hospital pharmacy setting. I use PANDAS for pretty much everything. 1. We use automated dispensing machines so I use the dispensing data to set PARs. 2. Use emailed CSV report files to combine them to yield relationships and put them into excel format. 3. For auditing, combine all narcotic transactions and randomly pull out x transactions per anesthesia staff to audit then archive the findings. 3a. Run YTD stats off of the DB archive then create Excel Charts by Provider, and by Station. 4. Use it to log into certain survey websites in the company to enter myself into raffles, they do not cap entries per employee since their goal is to collect data.(LOL) 5. Use it to log into web reporting tools to run specific reports and combine them with file IO and pandas to generate Excel formatted reports. Pretty much use it as much as possible. I wish the IT at my place would give me some leeway in order to let me have my own server time. 
My father works as a financial analyst and I can vouch for this entire thread. Everything he does relies on spreadsheets with occasional macros for small tasks but the amount of bloat on all the .xlsx files clogging up his workplace's systems is absurd. It's gotten so bad that it slows down his whole computer and lags Excel like crazy. I don't know how he puts up with it. Whenever he works from home I can hear him swearing about it constantly. EDIT: words 
Your so lucky, I wish I could get access to the SQL databases for the automated dispensing machines -_-. No one takes me seriously when I ask for it because I could automate PAR adjustments via Selenium!! FML I gotta find another field that uses my skills.
Have you tried anything yet? If it were my problem to solve, I would use selenium and automatic the browser. 
I use pythonanywhere for this type of project. Starts at $5 a month for your own domain. 
This was an outstanding thread, i really enjoyed reading these responses.
That's not a lot of information, but it doesn't sound incredibly promising for python-migration. &gt; Daily excel spreadsheet we use Use how exactly? If it's a spreadsheet that sits on a single terminal at the check-in desk then you might have some options. But if its something that gets passed around via email, etc. then you're looking at hosting a python app somehow, which may be more trouble than it's worth. You have to remember that excel is so lauded and abused because it *can* act as a database, one that has a single view for searching, selecting and editing semi-structured data. A program would separate these: a form to add rows, a form to select rows by conditions, a module to export these into reports. So, &gt;Viewable but still modifiable That sounds like excel. But, again, give us some more information and I can give you some search terms to google to get started. 
I've automated generating TPS reports, now I have more time for fishing. 
&gt; Library of tools You sound like the type of programmer that I'd like to emulate; I write useful things but they are so disorganized and non-functionalized/non-modular that I have hard re-purposing and integrating things (so I end up repeating myself every few months, to my own chagrin). In short, I wanted to ask if you have a github.
&gt;then compared using Mean Squared Error to quantify movement ^^^^^^^^^how^ELEGANT
I used my Python package in my pants to give your mom that good Python
Do you know of any introductions to Flask that are similar to this type of task? Also which modules help you do this?
You can do that with jquery-based plugins on the front end. I've used [DataTables](https://datatables.net/) in the past at work for internal data management tools. We're also fooling around with [Kendo UI](https://www.telerik.com/kendo-ui) which looks pretty promising. Neither is free, but they're both pretty reasonable, iirc.
I've been using Python pretty heavily recently for doing things like this. Between Pandas, csv, Sqlite3, and json, everything has been a breeze. 
Look into csvkit. 
Should we crosspost to /r/lovecraft to verify?
It's possible that the client needs a spreadsheet. Or that the information should be stored that way for future reference by a layperson.
AND no way to properly version control! 
We can only run exacutables that have been "certified". That's a hard "can", not "allowed to", on an OS service level. 
Care to elaborate? I don't quite get the business case. 
Cool, if I may, it would be even cooler if there is a test function for users because I spent most of the time on writing a test code. There are multiple scenarios to be considered (plus time limit, memory limit, etc) Like def test_sort(your_sort_fn: Callable[[List], List]) -&gt; bool: # run against extreme cases # print various information return So, I can test if my implementation is correct and that would be helpful.
Have you tried force closing explorer.exe in task manager and running executables from task manager? That got me around executable whitelists multiple times but maybe exe blocking software has gotten more sophisticated in the last 10 years. 
python -m comtypes.client._generate nicelabel.dll
I can't see how this should be useful. How should this be used by a student learning algorithms? If I need the running time of bubblesort there are a lot of online resources or books that provide this information in more detailed form, e.g. https://en.wikipedia.org/wiki/Bubble_sort . There I can also find a pseudocode program of this algorithm. If I want to study an algorithm it is better to write program by myself. Can you explain how think that this library will be used?
**Bubble sort** Bubble sort, sometimes referred to as sinking sort, is a simple sorting algorithm that repeatedly steps through the list to be sorted, compares each pair of adjacent items and swaps them if they are in the wrong order. The pass through the list is repeated until no swaps are needed, which indicates that the list is sorted. The algorithm, which is a comparison sort, is named for the way smaller or larger elements "bubble" to the top of the list. Although the algorithm is simple, it is too slow and impractical for most problems even when compared to insertion sort. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.24
&gt;three orders of magnitude Well let's see here, 20,000 is one order of magnitude greater than 2,000. It's two orders of magnitude greater than 200, and 3 orders of magnitude greater than 20. He wrote 20 lines of python to replace 20,000 LOC Java. Pack it up, boys. Java is trash!
It's on Windows using gTTS module.. The Google lady's voice is far better than Microsoft's default voice.
You are right, you said you have plenty of online resources or books that provide you with pseudocodes and running times. But, this is what I am trying to make, a module that will contain all of the pseudocodes and running times of all algorithms in a `single` module. So that you don't have to lookup in different resources! 
Sure, this is what my future plan includes. I am not much familiar with producing test cases with memory limits. If you can, contribute to the module and I would be happy to integrate it in the module. :)
I kind of run a lab at an HDD company. We test heads and media. I've written different python based scripts that speed stuff up. One I wrote is for a specific kind of test where we use different write conditions for the head and see where the writer is saturated. Before you'd have to manually change a bunch of values between each test iteration. It would take a ton of time. I made it so you could put all the settings you want to test in a csv and it would get imported to our test software. Each time you ran it it would cycle to the next settings. I've written a bunch of quick python scripts that save a ton of time. I can easily spend half a day writing a script that'll end up saving 100+ hours of man hours a year. That's what I love about Python. Another example: when we shut down our testing software it never shuts cleanly. There are always a bunch of processes left open that you have to manually find and close in the task manager before you can start the software again. I made a python script that automaiticallt shutdown all those processes. We also almost always run a test that finds the max areal density of a head/disk combination. Areal density is the number of bits per square inch. I wrote a script that automatically runs a test based on those optimal areal density settings and finds the quality of the data written and how easily it can be read back by the channel.
You could make XString into lower case before checking in the While loops. This makes the code shorter and possibly less typing needed if you were to add in more validation. 
We use Python to automate design of physical network infrastructure. About half a billion USD's worth so far, saving us millions in planning costs and years of design time. Now the humans spend time checking what computers can't and dealing with the real world.
Do you plan to do anything more interesting? Linked lists, Red/black trees, dijkstra's algorithm, A*, callbacks, message passing, etc... ?
Yes, in my next development release, I am including Data Structures. Eventually, I'll be adding more advanced algorithms like A*, Dynamic Programming, etc. :)
You're getting downvote because an image is a terrible, terrible way to share code. If it's less than one line, use \`backticks\`. If it's more than one line, add 4 spaces to the start of each line. If it's much longer than that, host it on gist.github.com or pastebin.com
One more change i notice in few 2.7 code i read is xrange() in 2.7 become range() in 3.xx
Hehe as i said, super new to it, i havent even heard of any of the apps mentioned in this thread but this is the first of many projects im looking to tackle. Its a manifest of people to board a ship. The data is: type of visitor, guest name, amount of adults/children, times, optional extras and booking reference number. We email it once a day as a pdf file to be printed so at that point it can be static, but it is used on a network of pcs by multiple people simultaneously which leads to people using the same rows accidentally occasionally, which excel deals with reasonably but not 100% foolproof. Optimally id like to create some sort of app where we can input new and/or modify existing info without opening/viewing the entire sheet. I would also like to be able to link to sources (scanned or saved paper trail) Hopefully thats a bit clearer, feel free to ask for more info. its also worth noting that im taking the MITX course on edx.org, are there any courses you know of which would be more relevant to my cause? Im having some trouble with all the (advanced) maths in this course.
&gt; def test_sort(your_sort_fn: Callable[[List], List]) -&gt; bool: # run against extreme cases # print(various information) return FTFY :)
 &gt;How can the number of stars possibly be a function of the index number? It's a function of both the index number and the height of the diamond.
One **for** loop over a **range**, and multiplying "*" by an appropriate calculation of the distance between the current index and the middle index. Also this should be in [r/learnpython](http://reddit.com/r/learnpython).
This should be in [r/learnpython](http://reddit.com/r/learnpython).
Oh sorry &amp; thank you for redirection.
This should be in [r/learnpython](http://reddit.com/r/learnpython).
Didn't know that existed, thanks
Sorry too late to response, there is a new test detail about the discussion at this [issue](https://github.com/universe-proton/universe-topology/issues/6). Thanks you, masklinn.
I would try to solve it like this: from datetime import datetime def intToDate(inDate): d = datetime.strptime(str(inDate)+"1", "%Y%W%w") return d print(intToDate(201601)) You have to add the +"1" to set a default day of the week (if I rememer correctly)
RemindMe! 2 Days "automate"
I will be messaging you on [**2017-08-08 08:17:04 UTC**](http://www.wolframalpha.com/input/?i=2017-08-08 08:17:04 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/Python/comments/6rr4b9/what_menial_tasks_within_your_company_have_been/dl8f9zs) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/Python/comments/6rr4b9/what_menial_tasks_within_your_company_have_been/dl8f9zs]%0A%0ARemindMe! 2 Days ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! dl8fa3n) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Try book : Automate boring stuff with python, it's aviable in HTML version for free.
When you say distance across surface, do you mean something like a line integral?
If you like Miniconda, you can create packages and custom installers that include whatever version of python you want along with it. 
Yeah it's definitively a parametrized Jenkins job, but as I wrote above it is used to deploy tens of different staging websites on-demand. Having one job for each website is obviously a mess in this use case. There is a moment the human have to choose the parameters. Also, I don't have admin rights to install Jenkins plugins, and I don't think the sysadmins will install a Slack plugin which will slow down the whole thing (they also have other more important stuff to do). In addition the Slack plugins I saw are notifying about ALL jobs in progress, and don't behave the way I want.
It will be way easier for me to run all the sorting in one program on the same list and compare. Further it is good to have everything under one roof, makes developers life easier
Nah I'm not looking for a graphical way of displaying the automaton. It's more about the inner data structure. And a kind of mini-"language" so you can type in new ones without rewriting entire parts of the program. (e.g. the dyck-language which contains all expression of balanced brackets. You can describe in a short finite way but the automaton is infinite. In the end I want to be able to analyze words in these languages.)
I agree with /u/miracle173 your intentions are good but this doesn't seem usable. If students are going to learn algorithms they should do it by writing it themselves. Moreover I don't see why anyone would go through the pain of using a module to look up running times and implementation instead of looking up at a standard textbook. A textbook has plenty of resources. 
I've updated the article to add a snippet to draw Julia Sets.
Wow! Thanks a lot for that!! Just checked it out and it's pretty cool!
Oh..I see sorry abt that
I am however unable to find the book for free. Do you happen to have the link?
UPDATE: Torrench is now available on PyPI. Can be easily installed using pip. Read docs for details. https://github.com/kryptxy/torrench 
When I've used pyqt, I've noticed that it doesn't throw exceptions like it should most of the time. Sometimes it will just crash or close a window when it encounters a problem. So don't think that it's necessarily some code explicitly making your window close. In your case, the problem might be that `word` isn't defined properly. I'd make it `self.word` in `__init__` then refer to it as such in your button callback method. Same with `number`. Also I think you have to use pyqts variable types to set QLabels correctly (something like `CoreQt.StringVariable`). You can't assign a label with a normal string, I don't think.
Wouldn't it be helpful to program your own test cases?
[removed]
Check out subreddit sidebar (there are more books) I am gonna pm you link. 
I always prefer illustration through examples, [so if anyone is curious, here is a link to the examples page in the doco](https://samreay.github.io/ChainConsumer/examples/index.html). Written for my astrophysics work, but hopefully applicable to an investigation using MCMC processes or grid posterior evaluations.
Most manual testing of API's (from a software testing / QA team). Edit: And it is software testing, using primarily PyTest and requests.
The whole "stay away from the root logger" and "don't use basicConfig" are not really good advice. *Understand* how they work and they're just fine, and the documentation is quite explicit about precisely how they work. No, the root logger is almost certainly not the right choice if you're using (or writing) libraries that include logging, and obviously the "basic" config probably isn't the right choice for anything even remotely complex (that's why **dictConfig** and **fileConfig** exist), but for a simple command line app or any number of smaller bits of code there's absolutely no reason not to use the module level functions, especially if all you want to do is log to stderr or stdout or a simple file, and they're a very big leap up in professionalism from **print**, which is what they're there to replace. Hierarchical logging isn't appropriate for a **large** number of scripts, but *level*-appropriate logging **is**, so I don't think it wise to scare people off from it, so much as give them an idea of when they should move away from it.
That's the whole intention behind creating it. Thanks for the kind words :)
Thanks
Yeah, you still have to write your own test cases to make sure the implementation is correct. Yet, you will still need the additional test cases because chances are that people don't know what to test especially when they are learning new stuff. Sure, any sorting algorithm will sort a list with 3 items or 2 items. But, can it sort a list with a billion of elements or a list with billions of digits or even under X micro seconds? It's likely to skip testing extreme cases because either 1. they get lazy 2. they don't know what to test Writing these sort of extreme test cases won't teach as much because its implementation is rather simple, but it still can teach the idea what to test.

Sure, but the fact is the moment you start using libraries that include their own logging you're already passed the definition of "basic". Root level logging is meant to be a step up from **print**, and it serves that purpose very well. When someone's searching SO for a solution to silencing a logger, it's because they've only done below the bare minimum of RTFM'ing. Likewise root level configuration is *doing exactly what it should do* when those libraries start piping up, which is pass on to you every message that's at least as important as you've bothered to tell your logger you're interested in. At least if the library author has used **logging** -- even very poorly -- you *can* shut them up. That's not true with **print**.
Very cool. Thank you for sharing. 
According to its PyPI page (https://pypi.python.org/pypi/pygam) it only publishes a wheel file. Wheel files, unlike sdists (.tar.gz), do *not* run code in a setup.py when you install them---they are data only. So unless you then started an interpreter and imported that module, you have nothing to worry about. Looking at the repository linked from the PyPI page, it looks like a legitimate project. I didn't look into the published wheel, though. 
Hi. It looks the the module you installed was in fact [this one](https://pypi.python.org/pypi/pygam). You can see the code for this packages on github, [here](https://github.com/dswah/pyGAM). You are right to be worried about installing the wrong packages, but in this case it looks benign, as long as you don't mind mathematics!
Okaaay, (waiting for the other shoe to drop...)
Is it your intention to create an analyzer for any code? That's a cool idea, but I'm trying to think of how to implement it. i.e. class ListAnalyzer: ... def __iter__(self): self.O.power += 1 But then how does it tell the difference between: for i in ListAnalyzer: for j in ListAnalyzer: ... and: for i in ListAnalyzer: ... for i in ListAnalyzer: ... So I don't think this works without getting into the base C code.
I use gohlke only if it's not available via anaconda and a pip install failed. I could be wrong but I think OpenCV fits that description? Seems like C++ wrappers are what I often end up going to Gohlke for. Shapely is another. There have also been a few rare instances where the binaries on Gohlke's site were betas that include bugfixes available via GitHub for a library that hasn't published an update to pip or conda in a long time.
I really enjoy the course thus far. It gives a thorough introduction if you're a beginner and provides plenty of substance for experienced programmers as well. I'd be curious to hear what you think of the course. 
No
I suspect the reason here is that Python type annotations does not actually enforce types on variables, whereas Graphene's type declarations (correct me if I'm wrong) enforce them. Try your example in a repl: even if you explicitly said name: str, you can still give "name" an integer or boolean.
Oh wow! And thanks again! And got the pm!!
There is plenty of stuff already out there covering that better than I can. Also, in the future, you should probably direct such questions to r/learnpython
I agree for first time learners. But, maybe this could be useful as a reference.
Ok thanks 
" my hacking skills ?" ??? Ofc its worth it! HTML and CSS is not a programming language and you didn't learn it if you don't know javascript(+ some server side language like php,python,java and so on). The next logical step would be javascript client side AND a server side language that could be python3.
I don't think that Python is a good language to teach algorithms and data structures... There's too much stuff being done under the hood and hidden from the developer.
Well that makes sense ! It can definitely be used as a reference material. 
On the topic of dnd scripts, here are a couple that I have written so far: https://github.com/david-wm-sanders/dnd/tree/master/scripts The new random.choices in 3.6 is extremely handy for simulating percentile dice rolls. I am looking forward to seeing u/ExcitedForNothing's scripts now. They are probably a lot more in depth than mine as I am still only a player at the moment. 
/u/omkarpathak27 an enhancement. Not sure if it is possible though. You can also provide visualisations with algorithms. Something like over here https://visualgo.net/en
I'm trying to improve my Python and C++ on the side and recently started running a dnd game for my colleagues so what better excuse to learn! 
I will be trying to avoid all the built-ins so that users can learn more. As far as simplicity goes with lists, this is the biggest advantage of Python :) 
Thanks for the feedback. I will try to do something surely! :)
True, but they could be parsed much more easily and the coder could code expecting the type hints to be correct. Normal Python. 
Cool, do you publicize your scripts anywhere, free/paid :) ? I'm always looking for new additions to my toolset to enhance my workflow.
I'm not a maintainer of that project and by no means speak their mind, but they seem to be wary of objects of the wrong type permeating through the system. Not saying that a programmer would not recognize the assumptions / type hints, but perhaps they are guarding against unintentional mishaps that can potentially cause data loss? I'm curious: do you think the problem is with the syntax? I've seen ways to overload the type hint syntax to actually check for types. But you seem to be more concerned with the fact that they are checking types in the first place.
How did you get over the unstructured-ness of PDF formats? I was looking into parsing packages a while back and didn't find much that was very flexible.
What do you mean by the common crawl?
Is there any progress with this? I have seen recently there is more r/Learnpython post instead of article/link/general python discussion thread 

Have you found a way to maintain nopython mode with classes? All the classes actually hold are np.zeros initializations, then the methods that change them, but they're a bit too required for the organization of the code to do it in a more function-driven way.
If you want hacking skills, you want lower level programming knowledge. In that case, I'd recommend learning C and assembly, as it would help you understand how computers work at a more fundamental level. Python is good for *avoiding* that kind of stuff (which is great when you just want to program things quickly). Personally I'm tired of dealing with bits and bytes and all those lower levels of abstraction. It's why I fell in love with Python, but having that knowledge is also very helpful to have. 
It's interpreted pairwise, left to right.
The webservice allows you to download in PDF or in XML. When I was doing the proof of concept for this, I initially tried parsing the PDF's and was semi successful but it wasn't feasible for the whole project. Luckily all of my fields had unique identifiers that I could search for in the PDF. It is pretty much just a bunch of string parsing.
In your article you advise that people entirely avoid the root logger and module level convenience functions, without equivocation or much exploration of why those functions exist or do what they do in the first place, beyond call basicConfig -- which they only do if there's no root logger. I brought up **print** because that's not great advice for a very large number of small cases. A person stepping into the logging module probably *should* use the module-level functions, right up until they discover a need for hierarchical logging, a need which does not exist in programs that would otherwise still benefit from nuanced, level-aware logging. When they go to write a library, they'll need to learn more (don't configure a logger at all, or add only a NullHandler). When they go to use others libraries, more again (hello to dictConfig). If they've vendored their dependencies they'll find a slightly different path (filters are your friend, not trickery), if they need to log to syslog or logstash or what have you another one (custom handlers and formatters, yay!). It's a very complex module that's actually extremely powerful and hides a lot in some not obvious places. Which is why I don't think blanket statements about just not using some of the -- for the right project, ideal -- tools it provides are very helpful.
I’ve been really enjoying serverless, and didn’t know about the python requirements plugin. Looks way less complicated and fiddly than what I was doing. 
If you implement \_\_add\_\_ for a class, sum() will do the right thing on an iterable (list, tuple, etc.) of instances of that class.
I agree with most of these comments, don't do this, but if there is some magic in that method (I assume some kind if global state?) Then you should define the class without the method, then in `main` subclass and add your method. Now the class itself is available everywhere, and in main the class has an additional method. Alternatively you can inject the method onto an object or the class itself at run time. 
What's `rgb.dtype`?
a few suggestions: try to write like you would write prose, sentences - (1) so the words have meaning. (2) Be consistent. (3) Be concise. E.g.: 1) `xstring` isn't meaningful enough - try something that says this is the input. Since `input` is already used, maybe `input_s` (for input string), or maybe `in_string`, or even `input_string`; 2) Python automatically types a variable for you - you can see what it is with `type(xstring)`. In your case, you initialize it to an integer (int), but everywhere else, use it as a string (e.g. the tests in your while loop). Other languages demand strict typing. Python's malleable typing is a convenience, but you will be clearer (and avoid type-coercion problems, especially when they're automatic) if you are consistent. Perhaps initialize `in_string` to the empty string, `""`; 3) There are many ways you can avoid being so verbose. You may or may not want to use any of them, but for instructive purposes, be aware of some of the options. Some have already been mentioned by others (I'll briefly repeat for completeness): - in_string.lower() is a good move; - another might be to let people input any non-digit that hints at 'quit' or 'stop', such as 'q' or 's'. A way to do this: `in_string.lower().startswith( ('q', 's') )`--- this says "starts with one of the strings from the tuple ('q', 's'). - it might be nice to have this both more readable, and configurable, so maybe: `quitters = ('q', 's')`; then you can read this as: `in_string.lower().startswith(quitters)` - you can go one step further for readability, and use "lambda" (unnamed functions, basically) for the test about quitting, e.g.: `quitting = lambda(s): s.lower().startswith(quitters)` Now you can write, e.g.: `if not quitting(in_string):`... (still (3)): I am not suggesting this (it doesn't always make the code clearer, but it can help make it concise) as much as offering it for information: - python allows / has conditional expressions on the right-side of an assignment, so you could write: even = lambda x: x%2 == 0 ... x = x//2 if even(x) else 3*x+1 (note: `a//b` is _floor division_, which - when both arguments are integers, is integer division) One final simplification to ponder: could you write the main loop as simply as `while x = integer_input(prompt):` (would you need the `if x &gt; 0` bit, then)? Actually, you _can't_ , but you can write it as `for x in integer_input():` - left as an exercise. Also, rewriting this w/ these suggestions raises the question of the purpose of `i` and the way you test and use it. I think it's more interesting to report the number of iterations to get to `1` for any input integer. But that's the point of rewriting for clarity. The point of this is not to unravel what you've done, as much as to suggest a way of writing code so that it says your intent more-nearly as prose. This is particularly useful when you don't know or haven't yet decided exactly _how_ to do something - just write out something which sounds like what you intend, and sort out defining the little pieces (e.g. `quitting`) later. Hope that's helpful.
Documentation may be the better alternative indeed. I was more curious in seeing ways to fail-proof its usage, but it's nothing that can't be done in other ways as well.
I suggest not using debug outside of dev environment. Use instead: app.run(host=....)
Depending on how sensitive the information is, they might not be able to do that.
&gt; sudo pip install'd I'm new to Python and linux, just asking out of curiosity, isn't *pip install PACKAGE --user* enough?
Well it would likely be accessible through the company intranet. Not to mention he can set up authentication.
Sure! #!/usr/bin/env python import argparse import csv parser = argparse.ArgumentParser() parser.add_argument("input") args = parser.parse_args() infile = open(args.input, 'rb') outfile = open('recall-out.csv', 'wb') print 'Parsing File...' reader = csv.reader(infile) writer = csv.writer(outfile) writer.writerow(['Recalls', 'Vin', 'Name', 'Address', 'City', 'State', 'Zip']) LastVin = '' out = [] for row in reader: if ' ' not in row[3]: continue if (LastVin == row[2]): out[0] += ' ' + row[1] continue writer.writerow(out) row[10] = row[10][:5] out = [row[1], row[2], row[3], row[4], row[7], row[8], row[10]] LastVin = row[2] writer.writerow(out) infile.close() outfile.close() 
I was messing around with using a decorator to reduce the amount of boilerplate for each method. from functools import partial from inspect import getsource _complexity = '''\ best case: {} worst case: {} average case: {}'''.format def info(*, best, worst, avg): def _info(f): f.best = best f.worst = worst f.avg = avg f.complexity = _complexity(best, worst, avg) f.get_code = partial(getsource, f) return f return _info This lets you write the different methods much easier. @info(best='O(nlog(n))', worst='O(n^2)', avg='O(nlog(n))') def quick_sort(seq): # real code goes here return sorted(seq) print(quick_sort.best) print(quick_sort.complexity) print(quick_sort.get_code()) print(quick_sort("fdecab")) The only thing I'm not sure about is how the files should be organized if this was used. Thoughts?
If you were to write it in text, how would you express adding multiple elements? If you answer is `a + b + c + d + e`, then consider that this is the same as `((((a + b) + c) + d) + e)`.
I have made this piece of code as an example: class bank_account: def __init__(self, amount): self.amount = amount def __add__(self, other): return self.amount + other.amount bc1 = bank_account(100) bc2 = bank_account(200) bc3 = bank_account(300) print(sum([bc1, bc2, bc3])) But the print statement throws an error and tells me that the operand is unsupported. Whereas if i just do this: print(bc1 + bc2) It works perfectly
The problem in your implementation is that adding two bank accounts returns an int, so `bc1 + bc2 + bc3` has to add an int to a bank account, which it can't do. The easiest fix in this case is this: def __add__(self, other): return bank_account(self.amount + other.amount) if you want to be able to add an account and an int it becomes a bit more complex.
I'm not sure how formatting double-underlines work so forgive the bold add and ints. There are two things happening here: When you add two of the bank account classes together, it returns an int. Using sum on a list adds the first two elements together and returns an int, which it then attempts to add to the third element. Since your __add__ method only works with bank account objects, it will throw an error. You should change the __add__ method to also work with ints or to return a bank account object. The other issue is that __add__ works from left to right, so when sum() tries to add the result of the first two elements (an int) with the third element, it attempts to use the __add__ method defined in __init__, which isn't designed to work with bank account objects. The solution to this is to define an __radd__ method (which gets called if the __add__ method for the left operand doesn't work) for your bank account class which returns the result of the __add__ method. The new class should look like this: class bank_account: def __init__(self, amount): self.amount = amount def __add__(self, other): if isinstance(other, bank_account): return self.amount + other.amount else: return self.amount + other def __radd__(self, other): return self.__add__(other) 
In your example, sum() works by adding bc1, bc2 together to get an int, then trying to add the int to bc3. Since ints don't have am "amount", you add implementation doesn't apply to them and it fails with a type error. If you implement radd as well as add, that will allow you to call sum() over a list of bank_accounts. def __radd__(self, other): return other + self.amount
Gotta love Python 2's pants on head sorting mechanism 
Yes, the problem is that your \_\_add\_\_ returns an int (or float if that's what you've used as amount), not a bank\_acount object. If you do sum([bc1, bc2, bc3]), or equivalently bc1+bc2+bc3, it's still evaluated pairwise. So it will first evaluate bc1+bc2 which returns a float, and then try to add bc3: (bc1+bc2)+bc3 which means it needs to add an int to a bank\_account and you haven't provided a way to do that. There's two ways to fix this: 1) Make your \_\_add\_\_ method return a (new) bank\_account with the summed amount: def __add__(self, other): return bank_account(self.amount + other.amount) 2) allow ints (or any numerical value) and bank\_accounts to be added. You can make \_\_add\_\_ more permissive: def __add__(self, other): try: return self.amount + other.amount except AttributeError: # other is probably a numerical value (int or float) return self.amount + other This will allow you to add back\_account and a int or float, e.g. bc1 + 100. However that doesn't really help here, as what you want to do is add an int (bc1+bc2) and a bank\_account (in that order!). Python will use the left term of the addition to look if there is an \_\_add\_\_ method. An int does have an \_\_add\_\_ method, so that's what will be tried, but it doesn't know how to add itself to a bank account. Luckily python doesn't give up immediately, it's also possible to define an add-method from the right term (called \_\_radd\_\_). So if you also define def __radd__(self, other): try: return self.amount + other.amount except AttributeError: # other is probably a numerical value (int or float) return self.amount + other you can now also add other + self. Note that the implementation of \_\_radd\_\_ is exactly the same as add, so instead you can also just add: __radd__ = __add__ to your class definition.
What proficiency level should you be at before beginning?
Intro level should be fine. There is a twenty minute introduction to Python. Admittedly I skipped this section but I'm sure it's quite thorough. Happy coding 
How odd. I used the same ascii cat for my console based game [too](https://github.com/StefanCardnell/FalloutWordGame/blob/master/bin/Release/WordFiles/asciiCat.txt). 