pip install requests pyquery https://pypi.python.org/pypi/pyquery/1.2.8
Ask the website admin about it, rather than asking us how to bypass protective measures they've implemented
Are you asking us how a machine can prove it's human?
It's been a while since using lxml but I think the advantages are being able to search more cleverly and more convenience of life type functions. Example not exact because I'm not on the computer at the moment. elements = soup.findall(class_ = "hello") print elements[0].span.a.text (prints out all the combined text inside the element regardless of the html inside) Stuff like that
Could you slow down your script to make it not trigger the captcha?
That post irks me. Its barely informative. Its regurgitated every time this conversation happens. And its simply wrong. &gt; You can't parse [X]HTML with regex. You absolutely can, and many people have succesfully done so. &gt; Because HTML can't be parsed by regex. Uh huh. I beg to differ. It just depends what you want to see at the other end of your process. The second comment is far more informative and useful.
I'm interested. I'm not coder, but I struggled to get scrapy to fly for me. I built my own scraper for the stuff I do collecting binaries instead. 
It is not difficult I don't know why everyone are saying this. Docs are really good many things are automated in django-like way so you only need to write scrapy start project to get basic scaffolding then you need to only specify where to extract links and how to parse fields/items. Xpaths may be slitghly tricky at first but they are really powerful especially xpath funtions like contains() or position(). Also you have logical operators in xpaths "and" "or" "not". One thing to note is that Scrapy shouldn't be really compared with bs and requests because scrapy is a whole framework with specific architecture and stuff. With scrapy you are not writing a function that scrapes a page but you are creating a whole suite of tools for parsing. So multiple components many possibly hundreds spiders many pipelines parsing items validating them etc etc. You can have inheritance here so you can have your base spiders and then individual spiders inheriting from them. Scrapy gives you a very clean and clear architecture to manage all this easily. 
&gt; Since N is large, after a certain limit, the server detects a bad behavior from my IP and asks me to prove myself as human via Captcha. How can I bypass this in Python Scrapy? You don't. Respect the limit, tone down your scraping so it stays under the limit.
Also, depending on what you want to scrape, there are some tools that do just that really well. For example, if you want to extract pictures from some gallery, there are tools that make this simple. Additionally, some sites have APIs that will help you accomplish these tasks. If you want to extract data from a site that has a lot of historical data, you might be able to just get all the data (manually, or hackishly) and process it later. Like if you wanted historical sports scores, for example. The best use-case for scraping is a site that has a lot of frequently updated data and no API to let you get at the data. My point is that scraping is a neat thing and a good reason to learn python, but sometimes if what you really want is x, learning to do y to get x is not as good an idea as just using the getx tool.
Sorry I'll take my "Best Practice Patterns" from someone who: * illustrates their point using real examples, not snippets that don't even work * considers new style classes a best practice * knows that enumerate() actually returns two arguments * uses uses more standard names for common objects (ex. `cls` instead of `class_`) * knows that type checks should be done with `isinstance` **EDIT**: As /u/hobojimmy points out, there's a [good discussion](http://www.reddit.com/r/Python/comments/1lpdi0/python_best_practice_patterns/) around this same post from five months ago. If you want a *real* discussion on this instead of some guy ranting, go there.
For people replying, [I know](http://www.reddit.com/r/Python/comments/1jvzk1/envelopes_mailing_for_human_beings/cbj9mez): &gt; In the past, people used more humble language like "simple". I hate this new trend; I feel like it's boastful, and it implies that other packages were made in a thoughtless manner. Even my humanize package doesn't use "for humans."
Note that this is a repost to this subreddit from 5 months ago. See the comments section over there for some [good discussion](http://www.reddit.com/r/Python/comments/1lpdi0/python_best_practice_patterns/). Also it appears that this post was mostly derived from a talk by [Vladimir Keleshev](http://youtu.be/GZNUfkVIHAY).
The conversion to integer part is so that you do not end up with floating point precision errors. For the calculation you might look at how to get your change using division (/) and modulo (%)....
And actually makes their point instead of assuming I'll guess it.
 from decimal import Decimal as D denominations = [D('20.00'), D('10.00'), D('5.00'),D('1.00'),D('0.25'),D('0.10'),D('0.05'),D('0.01')] names = ['twenties', 'tens', 'fives', 'ones', 'quarters', 'dimes', 'nickles', 'pennies'] price = D('21.37') tendered = D('50.00') change = tendered - price for d,n in zip(denominations,names): amount = change // d print '%d %s' % (amount, n) change -= amount * d 
Ok. I'll try that for the middle part where it's changed from a decimal to an integer. And just to clarify that's just for the middle part right? That doesn't have anything to do with the conversions to the denominations does it? I'm sorry if those are dumb/obvious questions but I literally have zero experience with Python
K. Thanks! I'll play around with what you've shown me. This particular instructor has a rep for teaching as if everyone is a mid level programmer and it can seem overwhelming for anyone who's not such a thing. 
So emacs and vim are obscure editors now? In the podcast they say "textmate and sublimetext are the biggest editors in the last decade. This and no mention of what I consider the big two shocked me. 
Good find, that's a much better discussion than the comment I made. Thanks!
I want to lock Steven Loria and Jack Diederich (of "Stop Writing Classes!" fame) in a steel cage and see who emerges victorious.... :-)
[Try the tutorial - it's good.](http://docs.python.org/3.3/tutorial/)
&gt; I posted my notes on my website hoping that others would find them useful too. Yeah I suppose it depends on perspective. When I post something, outside of reddit, I always provide the full context of whatever it is I'm explaining so there's not any question of either intent or the knowledge I'm trying to convey. If I'm scribbling down notes as I'm listening to something I'll fill in the blanks later and update the notes to be more correct than they were before. That's assuming I knew what 'correct' meant at the time of course. I really like to support the idea of sharing knowledge but only if the points I'm contributing outweighs possible detractors such as bad style, incomplete examples, etc. Of course who it's being show too makes a huge difference too and it's often connected the knowledge/experience of the individual developer.
Yes. Going more slowly will probably help.
I believe this was put in place specifically to stop people from doing exactly that.
can try to set your user agent to Googlebot, but i doubt it
i would like to second lxml. i have used bs4 and lxml. i don't remember either of them easy to get started with, but i think bs4 has better documentation. you might want to start there if it's your first time scraping. also i found lxml much faster in both execution time and programming time. here's an example to get all videos for a user's youtube channel (most recent 30 anways). from lxml.html import parse user = 'numberphile' link = 'http://gdata.youtube.com/feeds/api/users/%s/uploads' % user page = parse(link) videos = page.xpath('//entry') for video in videos: print video.xpath('./id/text()')[0]
You don't want to hand that version in! While correct and pythonic it is way above what your teacher will be expecting and it would be extremely obvious you didn't do it. 
The part that mentions integers being easier doesn't mean you should do int(change) it means to convert the dollar amounts to pennies like this change * 100 and then int(change * 100) will give you the total change required in pennies (as an integer.) From there you use // to get the number of a certain denomination and % to get the leftover change needed to go to the next denomination.
http://gsoc.copyleftgames.org/ It looks like they're part of the 2014 Google Summer of Code though.
So it's a placeholder thing, thanks.
I love lxml, but I'm wondering if I need to be a little smarter about falling back to BS4 when working with malformed HTML. Does lxml throw an exception with malformed html? Does BS4 support both xpath and CSS selectors? I use them both; sometimes elements seem easier to select with one versus the other. (Then again, I'm not great at using xpath selectors, so I lean towards CSSSelect.)
This thread has been linked to from elsewhere on reddit. - [/r/AmazingProjects] [I recreated the first level of Super Mario Bros using python and pygame.](http://np.reddit.com/r/AmazingProjects/comments/1z8fbg/i_recreated_the_first_level_of_super_mario_bros/) *^I ^am ^a ^bot. ^Comments? ^Complaints? [^Send ^them ^to ^my ^inbox!](http://www.reddit.com/message/compose/?to=totes_meta_bot)* 
 self
Is it just an interface for connecting to your system's local text-to-speech system?
Similar question: http://www.reddit.com/r/Python/comments/1qnbq3/webscraping_selenium_vs_conventional_tools/#cdeq2t7
&gt;uses uses more standard names for common objects (ex. cls instead of class_) This is mentioned in PEP-8, &gt;If a function argument's name clashes with a reserved keyword, it is generally better to append a single trailing underscore rather than use an abbreviation or spelling corruption. Thus class_ is better than clss. (Perhaps better is to avoid such clashes by using a synonym.)
This is my experience. I new to python and django and needed to scrape sites. All I needed was to grab a couple images, page title and some text and it didn't seem to make sense to try and learn another framework just to do that. 
I started with an electronic copy of Python in a Day which took me a few days of random reading to get through; very good book. I then moved on to python the hard way and when through about 30 chapters and moved to django and building a site. 
I have no affiliation with /u/mowrowow despite the fact I up-voted him/her multiple times in this thread.
I have to profoundly disagree. You're not "bam, you're writing code". That's like saying if I throw you into the deep end of a pool "bam, you're swimming". No, you're flailing for dear life. There's a reason that Python is a better first language than Java. In Java everything must be in a class. You can't teach "Hello, world" without invoking the concepts of classes, objects, methods and variables. Generally this means the instructor will say something along the lines of "Type this in and just ignore all of this other stuff for now." This leaves the student feeling like I did when I attempted to learn Calculus with a bunch of math geeks in college when my mind is not wired for math: you lose confidence. Even if your program compiles/you get the right math answer, you say: "I just wrote down a bunch of gibberish and I have no idea what it means or how it worked. I wonder if I ever will." I passed Calc I (with a D) yet at the end of the course I still didn't know what calculus *was* or why one moved their x's here or their y's there. I had no understanding, and you can imagine how that set me up for Calc II (two tries, two F's). Contrast this approach with Ken Ahmdahl's [Calculus For Cats](http://www.amazon.com/Calculus-Cats-Kenn-Amdahl/dp/096278155X/ref=sr_1_1?ie=UTF8&amp;qid=1393653920&amp;sr=8-1&amp;keywords=calculus+for+cats) which is mostly words and not a single exercise. The beginner to programming *needs* a 45-page intro trying to introduce them to the concepts of computer programming. Otherwise they're just memorizing keywords and actions they don't understand. I remember what I went through with Calculus so I can relate (even though I'm too old to really remember how easy/hard it was to learn programming). Maybe other people don't remember what it was like to learn their first computer language. No concept of variables, local/global scope, flow control, types, etc. I can't believe that throwing a complete newbie into the deep end ever produces good results. This poster doesn't need to learn *Python*; they need to learn **programming**, and that's something else entirely. Python can be a good tool to do that, but one does not approach doing that like one does one's fifth computer language.
Do you really believe reading along and blindly typing things into a screen teaches the core concepts of programming?
You seem to be on top of your game. Care to discuss scrapy versus lxml?
Shittiest top reply I ever saw. Like the top comment says, the question was about matching and the top reply is about parsing.
Unfortunately, it looks like it. [docs](http://pyttsx.readthedocs.org/en/latest/install.html)
&gt; This is mentioned in PEP-8, Oh I know what PEP-8 says but it also says, "Always use cls for the first argument to class methods.", right before what you're quoting. The original notes used `class_` instead: https://web.archive.org/web/20130618103028/http://www.stevenloria.com/python-best-practice-patterns-by-vladimir-keleshev-notes/
Could probably do it with a raspberry pi. http://www.raspberrypi.org/phpBB3/viewtopic.php?f=41&amp;t=40235 https://pypi.python.org/pypi/RPi.GPIO
Another option http://placehold.it/ 
Yes. I think that is the most sensible choice left with me right now.
Reading this makes me realize I have a lot to learn in terms of the pythonic way...
I will read this thoroughly.
It's not the most efficient method, but when, like OP you don't have access to teachers, and you have no experience in how to use big CS books, try-fail is probably the best option, yes.
So this is very elegant. But from a pure performance point of view: This can't really be faster than an (optimized) iteration over the nearest neighbors, right? This is surprisingly fast, but a numpy iteration was still faster in my test. Even FFTs have to look at every cell. Just to understand this in my mind.
Pretty sure this is against Reddits terms of service as you're not passing a custom user agent. Why not check out Praw (https://github.com/praw-dev/praw/blob/master/README.rst), which is designed to follow Reddits terms of use.
SQL injection? More like SQL infection!
I'm sorry for all the typos like `isinstance` vs. `instanceof` and the `enumerate` thing. But I don't think they affect any of the points that I tried to make. `cls` vs. `class_` is arguable, PEP 8 is contradicting in this case. And if you know me I'm a strong proponent of having *actual English words* in my programs, not things like `cls`. Anyway, this questions has nothing to do with points I tried to make. All classes in the slides are *new style*. In the end I mention that this is Python 3. So again, sorry for being sloppy with some of the code examples, and I hope this doesn't affect the value of the talk.
Could you build a speech synthesiser using your own voice? Im sure some of the more modern ones stitch together real recordings with pitch shifting. Would be fun to build one with your own recordings i guess.
I was going to ask if you intended to make this podcast available via [Bitlove](http://bitlove.org/), but then noticed that there's already an existing [import this podcast](http://www.import-this.de/) available there. Seems like you're not the first ones to think of this name.
You should learn ttk in python 3 and python 2.7 - next version of tkinter.http://tkdocs.org shows it. Whatever you move on to - you should always know tkinter well enough to be good at it. Tkinter is in the standard library, it's quick, and with ttk it's passably good looking. If you can't do what you want with tkinter/ttk - you're treading into unfamiliar territory with users and should beware. I wish there was a webview type gui in the standard library where python was the scripting lanugage of the dom - not javascript. Pyjs has it - but the project doesn't seem to be popular. I think something like it would be worthy of the standard library to complement tkinter. 
I will
Hey I enjoyed it and found it useful. Thanks for posting it! Mostly I just like "make your functions/methods short and make them do 1 thing". I'd extend that to everything though, keeping folders in libraries to only a few files (10 is my personal limit) etc.
Never even heard of pyquery. I'll look it up. 
If it's really simple and low traffic, use the built-in server and you can avoid needing anything but the standard library to run your app, which is handy if you don't want to spend time on installation / packaging. If you find yourself creating more than a couple views or spending time on routing logic, managing sessions or caching, etc. use Flask. It's great for building single-file apps and very lean.
By the way, would it be advisable to use wsgi instead of cgi?
I think this section of the documentation is what you are looking for: http://docs.python.org/2/extending/newtypes.html#providing-finer-control-over-data-attributes I also suggest you to have a look at Cython http://cython.org It makes writing CPython extensions a much nicer experience.
Not too hard to do, and a good project. What is your level of experience with firmware and code? You essentially have two high level hardware choices: A) A raspi - No analog I/O, but more powerful, and B) an Arduino style board (like a WildFire) - less powerful, but has built in WiFi and analog I/O. Personally, I'd go for option B, because all you really need to do is to report out the values and a few other things. Might as well keep it simple. 
Thanks! I'll take a look at Cython, but I'm not sure how useful it'll be as I'm maintaining an existing project.
yes
If the codebase is reasonably split into a C core and a Python binding layer, and you are refactoring heavily the binding layer, it may be worth to simply rewrite in in Cython. Otherwise I agree it would not make much sense.
Thanks for the compliment! Just trying to do what I can.
Not to mention the cascading method stuff. If a method mutates the instance in-place, I don't expect it to return anything. Conversely, a method that *does* return a value shouldn't mutate the instance. Breaking these rules makes code harder to read. Django uses cascading for its QuerySets, but those are immutable. When you write, for instance, this: foo.bar().baz().qux() The original `foo` instance is completely unchanged. The various methods each construct and return a brand-new instance with the requested change.
I generally use PyQuery for things like this. Here's a verbose example I whipped up: Python 2.7.3 (default, Mar 4 2013, 16:34:28) [GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.24)] on darwin Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; import pyquery &gt;&gt;&gt; pq = pyquery.PyQuery('http://coinmarketcap.com/') &gt;&gt;&gt; tr = pq('tr#btc') &gt;&gt;&gt; tr [&lt;tr#btc&gt;] &gt;&gt;&gt; btc = tr[0] &gt;&gt;&gt; btc &lt;Element tr at 106625460&gt; &gt;&gt;&gt; btc.getchildren() [&lt;Element td at 1066254c8&gt;, &lt;Element td at 106625530&gt;, &lt;Element td at 106625598&gt;, &lt;Element td at 106625600&gt;, &lt;Element td at 106625668&gt;, &lt;Element td at 1066256d0&gt;, &lt;Element td at 106625738&gt;, &lt;Element td at 1066257a0&gt;] &gt;&gt;&gt; a = btc.getchildren()[3].getchildren() &gt;&gt;&gt; a [&lt;Element a at 1066254c8&gt;] &gt;&gt;&gt; a[0].attrib {'data-btc': '1.00', 'data-usd': '569.26', 'href': '/volume.html#btc', 'class': 'price'} &gt;&gt;&gt; a[0].attrib['data-usd'] '569.26' &gt;&gt;&gt; 
&gt; I'm sorry for all the typos like isinstance vs. instanceof and the enumerate thing. I don't think you need to apologize honestly, everyone makes mistakes and the points I've been trying to make are for consistency and accuracy (which is important when passing something off to someone else regardless of skill). &gt; And if you know me I'm a strong proponent of having actual English words in my programs, not things like cls I completely agree with having real english in my code and I cannot stress how important naming things properly is in the long run. What I disagree with here `cls` is a widely used standard and PEP-8 even explicitly declares how it should be named for classmethods. I'm not saying it's entirely wrong, this is Python after all, just that it's highly discouraged especially when presenting to a beginner or when your code/talk/notes/etc are public. &gt; Anyway, this questions has nothing to do with points I tried to make. I do agree that overall it's not a big enough thing that it's worth making a massive deal out of it but not everyone can read code like you or I will and simply ignore the fact that it's written differently. &gt; All classes in the slides are new style. In the end I mention that this is Python 3. Yes, I was referring to the notes. &gt; So again, sorry for being sloppy with some of the code examples, and I hope this doesn't affect the value of the talk. Agreed, overall it does not really impact the talk. In general I liked the talk and may even give it to some Python beginners with some prior experience in other languages. The points I'm making here are not in any way targeted at either the presenter or the person who took the notes. All the comments I've made in this thread are specifically content itself. I'm a firm believer in "You Are Not Your Code" by Sam Stephenson so in this thread comments I'm making are not personal attacks (although my comment that started this all looked exactly like one....I really should stop writing comments after 20+ hours of working) I'm trying to just improve the content and understand why it was written the way it was. 
I actually didn't think about it ... why not? =) https://github.com/brettcannon/caniusepython3/commit/c95ed38c4209b7c937e1c8067f6a18e2aa7a7c76
Thanks! But is it compatable with python 3? EDIT: also a beatifulsoup example would be nice, I already installed the package :P
PyQuery is a port of jQuery to Python, so it provides an easy way to grab elements via, for example, CSS selectors. You can do this with other tools, but I'm lazy. :) &gt; I need the ability to enter a URL into an input field and then scrape the images, page title, and description from that URL and return it to the page. Could pyquery handle that? I have a project that does [pretty much that](https://github.com/xiongchiamiov/jellylorum/blob/master/jellylorum/anime/models.py#L71-112).
 import requests from bs4 import BeautifulSoup def get_html(): resp = requests.get("http://coinmarketcap.com/") if resp.status_code != 200: return None return BeautifulSoup(resp.text) def get_cryptocurrency_price(currencyname, soup): currency_row = soup.find(id=currencyname) price_element = currency_row.find(class_="price") usd = price_element["data-usd"] btc = price_element["data-btc"] return {"usd": usd, "btc": btc} &gt;&gt;&gt; soup = get_html() &gt;&gt;&gt; get_cryptocurrency_price("btc", soup) {'usd': '570.81', 'btc': '1.00'} &gt;&gt;&gt; get_cryptocurrency_price("ltc", soup) {'usd': '13.68', 'btc': '0.02396'}
thank you, this was exactly what I was looking for.
Also helpful because each call of the **get_cryptocurrency_price()** function does not have to load the html
ok, thanks
The socket module just relies on whatever the underlying OS is telling it which in turn relies on DNS being setup properly and doing the right thing. Try "nslookup \`hostname\`" a few times on the command line and you might see similar results (of course since you've resolved the fqdn for your local host, it might not change at all since the results may be cached.)
And Thank you too! - Selenium is working out to be exactly what I need.
You seem to be on top of your game. How does PyQuery compare to BS, lmxl and scrapy? (I know neither) 
Since you are just starting out, you should look into web2py. It is easy yet powerful. Has nearly everything you need to get started. Plus great documentation. http://web2py.com/
Hi Kevin!
Not trying to start a holy war, but there are people who think web2py is [bad for Python](http://www.reddit.com/r/Python/comments/ex54j/seeking_clarification_on_pylonsturbogearspyramid/c1bo1v5). Maybe it doesn't do magic namespace injection anymore, but if it does then I would say *please* don't encourage newbies to use it. It will only make using the rest of Python harder.
redis
This is the first I've heard of that, and I must say, it sounds like an unnecessary level of drama and hyperbole.
I'd go with ozzilee's suggestion and dump to a file, you can then use inotify or equivalent to monitor the file for updates from script B.
I'm doing something similar, using a sqlite db file object as the "go" between. I have three distinct scripts, one that contains all the db related things, (setup, queries, connection etc) that just one db class, the second is an ingester function that reads in some logs, the third is a processing script that does things based on various parameters in the logs. 2 and 3 both import 1 as my db object, so I can reuse all the things in the db class and the db file easily. 
Use the pickle module. 
You say this but you don't say why it's a bad idea. Personally I think the 'over abstraction' of django is rough for a beginner (still plenty of magic) and flask is going through the realization that secure authentication should be default rather than left to 3rd party libs of various quality. I like web2py for its ease of use and good docs. I spend less time worry about routing and regex maching and more time implementing buisnes logic. I toally get the critisms of being too 'magic' but its just less explicit. The source is well organized and commented so it helps some when you are trying to figure out the "why" something just works. But honestly is it bad that If I name my template the same as my controller method I don't have to do anything extra, the view just works? I don't think so, I call it pragmatic and productive. These are however mostly my opinions and I'm open to discussion. 
I don't disagree about Django. I cut my teeth on Python with Django, and figuring out where Python stops and Django begins was rough going. So I hear ya. But I generally subscribe to the notion that bringing beginners into the fold with things that violate community standards is not a great plan. It makes learning the standards hard later -- and it makes convincing folks that that's even a good idea harder, too. How many times have you heard, "Why should I use spaces? Tabs have been working for me just fine!" Advocating web2py use for beginners is just *begging* them to start asking why they have to import things at all. I get that web2py is productive for people. Great. I don't really care what framework you use -- only what you encourage learners to use.
A bit more info on how this might work with ZeroMQ, which is the simplest of these: script A would publish its counter periodically on a socket, and script B would connect to that socket and subscribe to messages. You could kill and restart B with no effect on A - ZMQ automatically discards messages on a PUB socket if there's nothing listening to them. It's also easy to have B on another computer, and to have multiple things listening to the same messages, if you ever need to.
I don't use scrapy much. But I'm warming to the idea of using it when I want to regularly crawl a site, e.g., to retrieve updates or comments or what not. It's a full fledged scraping framework, whereas lxml is just a library. If you use scrapy, you have a crawling engine, along with a lot of scaffolding to transform and save data. With lxml, you have to write your own crawling logic. The way I plan to use scrapy, moving forward, is that any scraping job I want to trigger via a cronjob will use scrapy. That's not to say you can't use lxml, but scrapy provides you with a lot of additional boilerplate. Plus, scrapy helps keep your code organized, which is always a plus for a hack like me ;).
Dump to file or UDP datagram. With UDP it is kind of nice because you only get the most recent message on the receiving side and it doesn't matter if anyone is listening on the sender side. Edit: If you are literally passing an integer of how many iterations have completed then anything that requires a third-party library is overkill. In the sending script you declare a socket for UDP datagrams and set it to reuse the address/port (depending on mac or linux). Then you just send a datagram to a local IP and port. On the monitoring side you bind to that address and port and read in the incoming data. I'm pretty sure this is less than 5 lines of code in each script. Edit 2: Sender (broadcast optional): s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) if hasattr(socket, "SO_REUSEPORT"): s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1) s.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1) s.sendto(str(my_num), (addr, port)) Receiver (broadcast optional): import socket s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) if hasattr(socket, "SO_REUSEPORT"): s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1) s.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1) s.bind(('', port)) my_num = int(s.recvfrom(1024)) 
well, not that different, it has routes and a templating engine. how is that different than flask? if anything, it's more complete than flask.
Yeah, that was the impression I got from their website's description, thanks!
Maybe they want to practice scraping and crypto's are what interest them :3
Cool. I'm on mobile and it's difficult to see your code but I'll check it out later on my laptop. Since I'm new to python and django, is there an advantage to using pyquery over BeautifulSoup?
&gt; I don't disagree about Django. I cut my teeth on Python with Django, and figuring out where Python stops and Django begins was rough going. So I hear ya. I actually had the same experience with Python and Django, and it does lend credibility to what you mentioned earlier with web2py. And for what it's worth, I think it even would've been easier for me to wrap my mind around Flask... now that I know better. 
I had a bit of status counters and other debug information I needed to pass around without too much disk access and decided to use memcache. I did however start out with UDP traffic, but I had 4 tasks that need to share a bit of data. It have the benefit of my monitoring app not being required to run all the time and still have data available immediately upon start, and it allows for some variables to timeout in memcache if the main scripts failed or got stuck. None of the data stored in memcache is vital, so restarts are no issue.
How often is this counter getting updated?
this is always true. no matter what. no matter if it is python or not. cgi is always the wrong answer :)
&gt;Thinking about using Python's 3 http server to run the scripts, but would like to know what would be the advantages of running frameworks like Flask, Web.py, Bottle. http://www.reddit.com/r/Python/comments/1uxv8j/difference_between_wsgi_utilities_and_web_servers/#cen5r7o &gt;I would like to keep it as simple as possible, and even try to run AirPlay as a background process in the Pi, if possible. https://github.com/ryatkins/videoAirPi https://github.com/PascalW/Airplayer : &gt; Airplayer is no longer under active development. XBMC users can use the built-in Airplay support which is available since XBMC 11 (Eden). 
great article! ...however: If you go with the Python path, this complexity is not even known. Why? Simply because there is no concept of binary file in Python. You can feed any *.py file into Python interpreter and it will try to run it : regardless of whether this *.py file is actually your main Python file or not. Pretty nice eh? This is actually the worst thing about GUI apps in python, not nice at all. It means to distribute your app you have to install python on the target system, and install qt, before you can run the app. You also have to deal with multiple pre-existing (eg. 2.6) python installs, and it basically makes your application *unusable to most people*. Python bundlers and installers for various platforms are usually the solution people use (eg. pyinstaller), but theyre somewhat tricky to get working correctly. Feels a little bit like the post hasnt really considered that aspect of it. 
&gt; but theyre somewhat tricky to get working correctly Maybe sometimes tricky for the developer, but it's fairly painless for the end user. I've used `PyInstaller` with some success (the [logview](https://pythonhosted.org/logview/) application) and it wasn't too tricky (and that was in 2011 - `PyInstaller` has gotten even better since then).
Tornado IS a framework like flask, web.py etc. I'm currently porting a web.py app to a non-blocking tornado framework. The performance improvement is incredible. It's sort of the python equivalent of mojo, has lots of great features including routing and templating, except it's so much faster than anything else I've used so far. I personally have managed to push 1000+ transactions/second through tornado in a single thread. I was averaging around 50/s with web.py. This is after the non-blocking rewrite mind you- but it's totally worth it. 
yeah, this. 
- Ubuntu's default is Python 2. - Even though Ubuntu lets you install Python 3 using its package manager, that copy cannot replace the system's Python 2. Therefore, now you have two copies of python, invoked with either 'python' or 'python3' or some other way to distinguish between the two. This causes some annoyances: - If you have a python 3 script that has a shebang "#!/usr/bin/python", the script most likely won't work without modification. - If you install a new python package, you need to keep in mind if it's going to install for Python 2 or Python 3. - By default a python package in Ubuntu's package manager would be for Python 2 and it's likely that your favorite python package might not be available for 3 in Ubuntu even though it might be available in pip. Then you need to figure out how to install that package with some other method, and make sure it installs for 3 and not 2. - With my method you can have multiple installations of Python (multiple 2.x versions as well as 3.x versions) which can seamlessly coexist "peacefully". If you want to uninstall a version, you simply delete its directory in $HOME/opt - With the virtual environments you can have multiple setups for even the same version. For example, you could have a web-development virtual environment, and a scientific stack virtual environment, and the two would coexist peacefully. If you want to uninstall a virtual environment, you simply delete its directory in $HOME/python3VEs. - Pip is python's standard package manager, and has more python packages than any distro repositories (I guess). Plus you get the latest version as soon as it's available, whether new install or upgrade. - This method works even if you're on a system where you don't have 'sudo' access (as long as the system admins of that system are willing to install or have installed prerequisite development packages needed to build python, which is a one time thing and better than asking them to install different versions of python). But to be honest, I think this is a transitional thing until Ubuntu as well as the whole python community moves to Python 3. Then you can simply rely on Ubuntu's built-in Python 3, and create virtual environments on top of that.
The combination of the 79-column limit and 4-space indents imposes a limit on the number of levels of nesting. In practice, helper functions are good.
Code isn't different, the return statement in each condition will guarantee the original nesting because there is no "else".
Yeah, I continued reading the same article I linked and saw this sane recommendation. 
Well, the negation of the logical union is a disjunction of negations so op's code is correct.
 &gt; Advocating web2py use for beginners is just *begging* them to start asking why they have to import things at all. This is not the case at all once you start building and actual site/app. While the framework compents themselves are all just auto imported, its common for a beginner to import lots of third party libs in order to handle business logic. There is no orm so you don't have to import models (the DAL is more of a functional abstraction ). So I could see the slight mental adjustment needed however even the docs stress you can import the DAL into any project and use it fine. Also when it comes to Auth they have already written a few plugins that need to be imported to be used. 
Okay, so after reading all the possible options Redis seems like the way to go. The main reason is that this would allow me to run the monitoring script on another machine altogether. I can simply have the key/value written to redis every 5 seconds or something. 
Make sure the production script doesn't die if the redis server is unavailable. 
What's the best way of going about this? Just some exception handling to pass if it's not available?
Try this: { "keys": ["f5"], "command": "repl_transfer_current", "args": {"scope": "file"}} 
It's not just web framework, it is a powerful server, very efficient.
You totally had me right up until the business of using OSX as the dev env. No, thanks!
Try import.io if you want to spare the technical details. Requests and lxml would be straightforward. Let me know and I will provide some code for this task.
If you can write anything in Python, [property()](http://docs.python.org/3/library/functions.html?highlight=property#property) would do this in two snaps.
I find the first much more pleasant to read. Multiple return statements, liberal use of continue and other tricks to keep things left justified are also not best practice. solution: use flake8 --max-complexity=N as your pep8 checker. A complexity number of 10 means that you will not see endless deep nesting on any particular function.
Well I think Kenneth Reitz does do a pretty fantastic job with his libraries, but I do agree, it sounds a bit obnoxious. I first heard it for the requests package and thought it was kinda cute, but the more it's reused the more I find it a bit grating.
I created a reporting end to a service I maintained at my last job using [pyzmq](https://github.com/zeromq/pyzmq). Its a lightweight messaging library that you can use in conjunction with the `pickle` library to send pretty much anything over the wire. In addition, if things are being published without a subscriber (like you mentioned that script B might be down), the messages will simply be dropped.
Scrapy. Period. Paragraph. Next question.
Why's that? Both OSx and Linux are great for developers.
Both cxfreeze and pyinstaller support PyQt apps pretty well, and you end up with a single file to distribute and no Python required by the user. However both of those have some glitches, and PyInstaller does not yet support Python 3. The maintainer of PyQt has announced that a "deployment" tool is on the way from them, which will be similar to the above two, but will rely on QMake as its engine. That will be the best solution to this issue when ready. 
yeah, of course, but it's also a web framework (I work with it).
Can you install QT in anaconda? 
I actually prefer early returns for readability. Do you also propose we collect all exceptions and only raise once at the very end? Or that we only have one yield in a generator/coroutine? There is nothing wrong with multiple return statements as long as the control flow is easy to follow.
Alcade, thank you!!!!!! Finally a link to something of my level. OP, if you're as new as I am (absolutely clueless about everything programming related) then this book is truly a great choice.
try following in your python interpreter: import this
I know, I'm asking how to do exactly that in CPython
As a Linux user and someone who likes to troll Mac users, I agree. For dev Linux and Mac are pretty much the same, with maybe more choice for tools on the Mac side, but I don't care I live in the terminal anyway. 
All slice operations return a new list containing the requested elements.
From the programmers point of view, agreed, but are you positive that there is no (possibly cpython specific) internal optimization that implements that as a copy-on-write or similar?
If you really need an iterator that doesn't copy, you can do something like this: class Slice(): def __init__(self,list_,i): self.list_ = list_ self.current = i self.size = len(list_) def __iter__(self): return self def next(self): if self.current &gt;= self.size: raise StopIteration val = self.list_[self.current] self.current += 1 return val # assume l is some list for elem in Slice(l,i): # do something
I personally prefer the use of guard statements rather than nesting ``if`` statements. I feel that deep nesting is a code smell, especially when error handling comes into play, sometimes with the same error handling in multiple ``else`` blocks dotted all over. It can also lead to a non obvious standard method flow, hiding the success case amongst exceptional ones. Books like Code Complete, Refactoring: Improving the Design of Existing Code, and Working with Legacy Code cover these sort of code quality questions really well (but can be quite dry reading). yeanothernerd mentions that the 79 line limit prevent the feasibility of this coding style, but as a Django developer I find that if you have a function in a class that does anything with the ORM with a model with a reasonably long name you soon run out of characters! Even before it is nested within any block. Also a hard and fast rule of 79 chars can cause some developers to start abbreviating the wrong things; using shorter badly named locals just to adhere to this rule of the 80's is almost always a bad idea. Amongst other things, this is why I prefer to adhere to the newer 99 column limit for internal projects, but if I was to open source something I would stick to the 79 line limit, I don't have the time for starting a religious war :) 
I love Linux, but I have no use for OSX. Don't like the GUI, the hardware costs twice as much, and my money's already sunk in PC hardware.
You can not just download PyQt build it without Qt framework installed first. To even attempt to build PyQt you must have qmake installed. 
PyGI/Gtk seems like it could do with more examples/docs, so be sure to put anything you find out on the net !
Yeah, the handful of people I know who have spent a good amount of time with web2py don't seem to have this particular issue. However it could have been some previous exp in another language.
 $ conda search pyside pyside 1.1.2 py26_0 defaults 1.1.2 py27_0 defaults 1.2.0 py27_0 defaults * 1.2.1 py27_0 defaults 
Thanks to everyone, both solutions are fine although I was hoping there would be something more "pythonic" that I was just missing, ill go with the slice iterator then probably as my loop code is already confusing enough and way too long as it is ;)
I wish people would just stop using OSX for dev already.
If you need zipped and unzipped data, I don't see any problem in maintaining both. If you data sets are not too large, loading the zipped and unzipped into memory for the duration of the program shouldn't be a problem. If you need something more robust you could create a class like "DataSet" with convenience functions for getting just the x or just the y component. Finally, you could use a library like NumPy/SciPy and store your data in a data frame which allows you to do just about any kind of manipulation you could imagine.
&gt;pandas
IIRC the zip function doesn't actually make a copy of all of the data, it just grabs data from the underlying iterables when you ask for it, so there's no memory issue.
Collecting exceptions is a horrible practice. I would never recommend that. Mostly because I do not use exceptions for control flow. Either I allow the exception to raise or I handle it as I hit it.
That sounds correct, so it would just be a matter of if it is faster to keep a zipped_data variable in memory or call the function on the fly. For small to medium sized lists, there is probably no noticeable performance increase to "pre zip" the data.
Now instead of having an article titled with "special consideration of using OSX as its dev env", i'd have an article with special consideration for my particular brand. Isn't it obvious? 
Can you tell a beginner like me what metaprogramming is?
2.7, sigh
I also find the 2nd style much more readable.. My own reasoning is that nesting makes tracking the flow much harder, in particular in python where blockend are implicit. It also makes for visually very "jagged" code which makes it harder to quick read the code... And then, it will eventually push code off the right edge, so the approach is obviously unscaleable. The only argument for the 1st style (which I have ever seen) is the fear of mutliple return statements (as well as "breaks" and "continues"). However, I find this fear hard to understand: after all 1st style just replaces immediate explicit returns with postponed implicit ones.. I don't see how, implicit postponed operation could be easier to read.. It'd be nice to see some real readability studies on this topic, but I've never seen one. Oh, and a few arguments by authority from the Zen of Python: 1. flat is better than nested 2. explicit is better than implicit 
&gt; Multiple return statements, liberal use of continue and other tricks to keep things left justified are also not best practice. So you prefer implicit jumps to the (nearly invisible in python) end of the block to explicit returns. As for best practice, go read some linux kernel code, or, gods, some *python* compiler code. You will see both multiple continues and multiple returns (and single returns are handled with **gotos**).. Yet, both python and linux kernel are much bigger, older and more successful than most of the projects on the planet.
Blogspam and [stolen, unattributed content](http://pypix.com/python/metaprogramming-python/). This is at least the third time this clown has tried this. Moderators, can you please ban this domain? 
At the very least, store your data in a numpy ndarray, then you can always get rid of the time-column when you don't need it. Or, more likely, you should have a look at pandas, it will give you very nice datastructures for handling time series.
Depends on the version of python. In 2.x, zip makes a copy. In 3.x, izip (from itertools) replaces zip.
Yup, that's what they've both got over Windows. Terminal is useful.
You're doing your accounts.py (user_login) using http - maybe try looking into logging via HTTPS (https://github.com/reddit/reddit/wiki/OAuth2, https://github.com/reddit/reddit/wiki/OAuth2-Python-Example)? I'm not 100% sure what the authentication platform is for Reddit, but I would believe there would be a more secure way to authenticate. Apart from that looks good!
Simplistically, code written to modify code. In contrast, normally you'd just write code to modify data or input. There are a lot of other definitions you can go by, but that should give you the idea.
Sounds like a nightmare to debug.
I don't see a reddit_py package or module anywhere in your code(it's mentioned in setup.py). Also, unless your code is in a single py file, you shouldn't have it in the top directory. Since you have multiple files all packaged together, their should be a subfolder with all the python stuff in it. 
what to use instead of ubuntu ?
Try: brew tap homebrew/homebrew-python brew install pillow
I don't recall it taking anywhere near that long. 
I'm trying it. It's running now ... I'll keep you posted how it went.
**sigh ** Doesn't seem to work, either.
* http://pandas.pydata.org/pandas-docs/stable/visualization.html * http://pandas.pydata.org/pandas-docs/stable/api.html#id12 
Any error message?
Also which Python you use? System python or homebrew python or else? And the python version?
Ok there's a last resort. You can use [Anaconda](https://store.continuum.io/cshop/anaconda/). It's a separate python interpreter with most common packages preinstalled including pillow. 
I guess you're using homebrew python. You can find the python location by: which python And if it's in /usr/local/bin. And if it's a soft link pointing to /usr/local/Cellar/python/... Then it's a homebrew python. 
I'm an Arch Linux person, although I understand that it caters only for a small subset of the Linux world. I'd experiment: Debian, Mint, CrunchBang, Manjaro... There are a whole freakin' lot of 'em. I've no idea how to decide for your individual case but my bet is that there are a lot of people stuck on Ubuntu because it's what they've tried. An OS is like clothing in its subjectivity; I just think that Ubuntu isn't nearly as good as it is popular and so conclude that people could do with more looking round. You don't have to try them all as much as reading for what type of people they cater for and going from that. Also, the whole Unity vs Gnome Shell thing seems to be split between three camps, and none of them like *both*.
Oh my fault. I look into wrong place. You can try install python by: brew install python
I don't even do that much statistics, and even I think pandas is awesome :D
This is a system python which it's out of date. 
You can also use werkzeug if you just want routes. I have a small server with many methods, then: m = Map([Rule('/my_uri', endpoint=myfunc)]) urls = url_map.bind_to_environ(environ) endpoint_func, args = urls.match() endpoint_func() See http://werkzeug.pocoo.org/docs/routing/ 
Updating did the trick! Thanks!
Take a look at [https://wiki.python.org/moin/PythonInMusic](https://wiki.python.org/moin/PythonInMusic) under "notation". You can also look at [http://www.lilypond.org/easier-editing.html](http://www.lilypond.org/easier-editing.html). Lilypond is pretty much the de-facto standard when it comes to music notation in the open source world
ok
&gt;are you confusing the words "best practice" with "never do this under any circumstances" No, I am not confusing anything. What I'm saying is that's not the best practice. At best, it'sa personal preference, at worst, it's outright bad for readability. Again, go read kernel source code: most functions are *flat*, they either use multiple returns or gotos to a single return... They are explicitly violating your best practice in pretty much every function. 
You want to enclose the titles in square brackets, so it would be [http://wiki.python.org/moin/PythonInMusic] followed by (http://wiki.python.org/moin/PythonInMusic) So: [https://wiki.python.org/moin/PythonInMusic](https://wiki.python.org/moin/PythonInMusic) [http://www.lilypond.org/easier-editing.html](http://www.lilypond.org/easier-editing.html) Cheers for the links by the way :)
I always mix them up, and I thought **this time** I'll remember. Apparently not and I forgot to check :p
I generally write them out and then reverse it because I get it wrong the first time.
Possibly, How far have you gotten on your own? Have you check out tutorials or /r/learnpython? What are your goals? Let's see the pseudocode
Can you give an example? It sounds like it's just a name for a short-lived variable ("temporary item").
Sounds like it's just a variable name. It's not a built-in as far as I can tell, and I couldn't find it in the Python source. Could you give an example?
okay, I actually just looked over it and it is a variable, thanks guys 
Iirc LaTeX has a notation package. One option is to use python to write the latex document then use the sub process module to render it to your desired image format or pdf. Question. How are you determining note length?
Hey thanks. I was aware of Anaconda and other packages but never tried any; good to know that they're easy to install. Just wondering if miniconda3 updates to latest Python as soon as it is released? Because otherwise that seems to be an advantage of my method, albeit a tiny one (although that means spending a couple hours doing a fresh installation everytime; I'm not aware of any method by which you could update the underlying Python version and keep the same virtual environments). **EDIT:** Looking at miniconda timestamps in your link, it appears the latest (3.0.5) is Feb 18, which I assume is based on Python 3.3.4, which was released on Feb 9. I think that's good enough.
The best way to improve your modules is to put them to some real use. Come up with something you actually care about and try to build it. See how the module works. Which parts you're comfortable with, which you find awkward to use. Compare your APIs to others in the same field. How does your solution differ? What are their strong points? What are yours?
I still highly recommend 'Learn Python the Hard Way'. The book wasn't made specifically for seasoned programmers and he mentions that in the beginning. The reason why he says do not copy/paste isn't because the author is lazy, but because the reader can then apply the reading into actual programming. You mention other tutorials were much quicker/better done... What would you recommend instead?
While I'd have to agree he is snarky, close-minded, and totally set in his ways, the code and tutorials we're horrible. I was actually quite pleased with the content. Being a fairly advanced Py3k developer I am disappointed that he choses 2&gt;3, though.
I still think the best way to learn is to give yourself a project you're excited about.
I'm not a seasoned programmer by any means. I still learn lots of stuff by reading tutorials meant for novices, yet his tutorials waste your time by giving you simple examples and expecting you to fail. Yes he mentions don't copy and paste, and then tells you to still copy the code exactly when you type it in. If you are copying code, especially something so simple, how could you make a mistake *every single time* as he expects you to. I think you misread my post. I called him lazy because of how he answers questions by mostly saying *it works, don't question it*. Diveintopython is a much, much better tutorial that can teach something to someone who has been programming for more than a few hours (which learnpythonthehardway probably cannot since he spends so much time ridiculing the reader). It also starts out immediately with code, but goes through everything and explains how/why it works in a way that anyone can understand. The code it uses is also more realistic code than that presented in learnpythonthehardway. You can immediately see real programs that do something other than print something. Diveintopython focuses on teaching you useful programming skills instead of ridiculing you over everything. 
down voting this rant, since I see no reason for this to be on the front page of this sub. 
yea this is pretty spot on. I try to preach 'Eat your own dogfood' at work, it's just that no one writes Python so it's tough to get better. I think the way ahead is start contributing to an existing module with the PR's and get some exposure to larger code bases. 
agreed
Interesting. I kinda want to go. It's rare for a good python conference to be hosted in my area. I'd have to justify the time off though, and the $185.62 registration fee. It does strike me as the kind of place where, instead of real good finance experts or Python experts, you get iffy financial python experts.
Appears to depend on pure bash scripting, hence works on Linux or Mac OS X. Not Windows of course.
There are already some good suggestions, but I'll add PySVG for pretty simple vector graphic programming. Cairo can be used to convert it to PDF.
Why install curl instead of using wget?
its a dependency from pyenv for their installer. You could checkout the code manually from github as well.
May work with Cygwin on Windows, but I haven't tried it. As alternative, I think I'd recommend Anaconda or Miniconda on Windows (which also works on Mac / Linux) .. Anaconda being the batteries included and Miniconda being minimalistic.. https://store.continuum.io/cshop/anaconda/
Never pipe something off the web through bash...that's insecure as hell.
When you read : building pylon instead of python, you know you've been playing too much Starcraft :-\ 
I just took a quick look - while it would be possible to write a restful interface to both forums that could be used to migrate, in reality what you really need is a sql guru- or at least someone who's comfortable with databases enough to migrate your data from one set of tables to the other. 
You must construct additional Pythons.
This is actually great, and I will switch to it from pythonz *on systems not currently supported by conda* (i.e. anything but Win, Mac, Linux). I never did like the way in which pythonz (and pythonbrew before it) injected things into your shell. On systems supported by [conda](http://conda.pydata.org/miniconda.html), though, there's just no question in my mind that it remains the way to go. It… * also only works by adding to your path * also doesn't require an existing Python installation * additionally replaces virtualenv{,wrapper} * even allows you to have multiple virtual environments with different versiosn of Python * gives you instant installs of even complex packages with multiple binary dependencies, like SciPy * neatly wraps pip/setuptools for those packages it doesn't natively support (Off-topic, but as a non-Ubuntu-user, I'm still startled every time I hear about this inflexibility of not being able to update an installed package independent of the OS. Seems so … weird, to me.)
Damn, one more awesome conference to miss.
I never would have expected `yield from` to do that in a generator expression. Did this come to you in experiment or hallucination, or did you realize this was possible through a more logical process?
hat-tip - James helped run our first PyData London last week http://ianozsvald.com/2014/02/24/pydatalondon-2014/ and he did a rather fine job on our industrial panel (representing the NY finance/py scene), teaching obscene generator foolishness and generally helping the conference run very smoothly. 
Yet another Python conference in the Eurozone - this ia really rather nice. After PyData London a week back and with PyDataBerlin and EuroSciPy (Cambridge) coming, science is well represented. EuroPython, PyConUK and no doubt others all help to grow their local userbases - this'll be a great year for Python in Europe :-)
http://placekitten.com
I think that's pretty normal, tbh. Some run Python with different options (pythonm, .pyw), others are to help you distinguish between Python versions (2 vs 3, 3.3 vs 3.2 etc.). 
I have a simple issue with property, is that it introduce a discrepancy in the api of a class where some states are acceded/stored using attribute access, and other using method calls. What is your policy with this? Are you writing property for every "getter" method which takes no argument, or are you using property only to preserve the api when a stored attribute is changed to a computed one? I really love the ruby pattern, where there is no difference between a method call with no argument and an attribute access (for the simple reason that public attribute does not exists and are instead exposed directly as method).
&gt; Feels a little bit like the post hasnt really considered that aspect of it. Actually, I only factor in the fact that as C++ developer that use QtCreator we must create separate project for it. In contrast with the flat project in Python that use PyCharm --which simplify things... But you were right. Those easiness, comes with its own cons. Packaging this PyQt/PySide application is another step that have its own complexity.
welp now i'm subbed to /r/codereview. This is excellent feedback, thanks for taking the time. 
This is perfectly normal
Keep in mind that, in Python, method calls are still attribute access. This is actually one of the things I like much more about python- in python, there is a clear distinction between attribute access and function calls. If I want to GET the function (for a callback, for example), I do `instance.func`, and if I want to CALL it, it's `instance.func()`. I was always bothered by Ruby's conflation of these 2 concepts.
I'd be curious to see an example where you have a `Temperature` class, with `celcius` and `fahrenheit` properties, each with a getter and setter that adjusts internal representation correctly.
&gt; In other words, **do you have linear performance** with 5 and 5000 requests using asyncio? i dont even think the article is making such a claim. But the answer would be "NO" for asyncio or the requests lib. 
Thanks. That was my question indeed. Not a claim the article was saying it. 
&gt; For this type of workload, an event loop will crush threading in performance (in almost any language too). Indeed. But the processing of the response can take its toll as well. An event loop is efficient only if it can run iterations at a reasonably fast pace. So what you've gained being able to make requests concurrently may be wasted once the response processing starts (unless you delegate the response processing to a thread...)
Author of the article here. Comparing performance in asynchronous code vs thread is a good idea my next blog post :) I would expect that, when done right (with thread reuse), the results will be equivalent. However, asynchronous code is much easier to reason about than multi-threaded code, and makes for much more peaceful development.
I would say scaling linearly is unlikely with any tech. if it was 5000 requests to one server, then the server would likely queue them up or start rejecting them. if it was 5000 requests to 5000 servers, your bandwidth would likely be saturated and throttled by your ISP. the fact is that the nature of getting responses involves a lot of waiting for them, which makes for some opportunities to do things concurrently. asyncio is one of several ways to do that.
I know nothing about music but svgwrite writes out svg. https://bitbucket.org/mozman/svgwrite/overview You also may want to consider creating vectors in open source Inkscape then your code copies and pastes the vectors together for the final image. Inkscape can convert svg to pdf.
Yeah, telling something to load a large chunk of data into memory will be faster than loading 1 float at a time. Since the HDF5 dataset only implements numpy-like indexing it (probably) doesn't have the data in memory.
Absolutely, these are great when you only one to do one computation and get the value back. If you need to share something, you're back into threading hell. And you know what? There is a concurrent.futures wrapper in asyncio, so you can call something in another thread or process, and yield from it : http://docs.python.org/3.4/library/asyncio-eventloop.html#executor
Indeed. It took me a while to get used to asyncio (due to a documentation rather not easy to digest and poor examples) but, once past that, it was rather fun to use.
&gt; What is your policy with this? Are you writing property for every "getter" method which takes no argument, or are you using property only to preserve the api when a stored attribute is changed to a computed one? I think it should be the latter one, considering the zen of python: * Explicit is better than implicit, so don't hide a (potentially expensive) function call behind a property * But practicality beats purity, so if properties allow you to maintain API compatibility you should use them.
There are many ways you can draw stuff with python. I suggest using pycairo (http://cairographics.org/pycairo/ ). This is a nice drawing API you can use with wxPython (using the wx.lib.wxcairo module) to draw stuff. The advantage of cairo is the high quality output on all backends (i.e. screen display, SVG and PDF). Other drawing APIs work well for screen use but often have problems with vector output (incorrect line widths , font sizes etc.). Cairo is very robust. PyQt is another option with a good drawing API (with a OpenGL accelerated option) but it you already know wxPython, I'd say go with what you know. Note, in both cases these are "immediate mode" drawing APIs. That means you need to redraw the window every time something changes or needs refreshing. Essentially, you make all your drawing calls from the on_paint method of your window. If you write classes for each of your objects in your music view (stave, notes etc.), give each one an "on_draw" method. You keep a list of everything which needs to be drawn then in the on_paint handler, just loop over allm drawable objects calling each on_draw method in turn. I'm slightly surprised there's no library already available for this but I couldn't find one.
 class Temperature: def __init__(self): self._f = self._c = None @property def celsius(self): return self._c @celsius.setter def celsius(self, c): self._c = c self._f = c * 9 / 5 + 32 @property def fahrenheit(self): return self._f @fahrenheit.setter def fahrenheit(self, f): self._f = f self._c = (f - 32) * 5 / 9 if __name__ == '__main__': t = Temperature() t.fahrenheit = 50 print(t.celsius) t.celsius = 0 print(t.fahrenheit)
alrighty, whew. thanks!
thanks for the reply!
Of course the internal value should be in Kelvin, not Fahrenheit or Celsius.
Once you start down the right path, `(None for g in g if (yield from g) and False)` turns out to be fairly obvious. `yield` and `yield from` are expressions, so they are allowed where-ever an expression is allowed (including within a generator expression.) `yield from` just delegates to a subgenerator and returns a value. (We discard this returned value by logical conjunction with False.) The grotesque one-liner does the same thing as: `(x for g in g for x in g)` (less perversely written as `(x for xs in g for x in xs)`) `itertools.chain.from_iterable(g)`
The obvious problem with Ruby's way is that you need to do some acrobatics to get to the actual method rather than the result of calling the method. This is not as big an issue because you could simply wrap the function call in a block and pass that instead, but that's a lot of indirection compared to Python's distinguishing between methods and method calls. This is actually one of several things I just couldn't get used to when I tried to learn Ruby after knowing Python already. Getters/setters are a nice language feature, but I prefer the distinction between an implicit method call via a getter and an explicit one using parenthesis. It just doesn't feel right to have a computation-heavy (say, simply O(logn) or worse) method for example "look" like a regular O(1) getter, though it makes sense to want an O(1) getter look exactly like a regular attribute (otherwise you end up with Java code where every attribute is wrapped in a getX method just in case you want to do something special in the future).
Python has autoproperties, too: they're called fields. Since there is no concept of public/private, there's no point in creating properties unless you absolutely need the extra computation.
when the language I used dictated that I had to use getters and setters, C#'s way was my favorite compared to java. But I prefer the direct consenting adults attribute access of python to both. And right now keeping data separate from the pure functional code that acts on it, is much more preferable to me. 
I was half-joking. You're right that there's no point for having an additional conversion in the code, but I find the temperature example extremely contrived anyway (although it's not as bad as the animal or car analogies for OOP -- and let's not forget the dreaded circle and ellipse debates). But the calculations are actually trivial enough that it doesn't make sense to store both values and then you open a can of worms by turning it into a "which scale is better" discussion which is where Kelvin comes in (by virtue of being the only absolute scale although likely unpractical in most real world applications where temperature is measured).
Just remember to **never** use properties unless you actually have some processing to do on get or set. This might sound funny when it comes to python, but properties are much slower than simple attribute gets, and also slower than method calls such as get_fahrenheit(). This is particularly noticeable if you are dealing frequently with them, for example in rendering code for something that changes every X milliseconds. If you are merely using it as a convenience in an API for normal scripted tasks, I don't think they will be much of an issue, though.
&gt; only absolute scale [Not quite](http://en.wikipedia.org/wiki/Rankine_scale).
Furthermore, it's an inconsequential change to swap out a field for a property if the need should ever arise in Python.
Am I doing something wrong? The screencasts don't load for me. I see a video tag in the source, but it's not loading.
Very weird, what browser?
In any python.
1) `self._f = c * 9.0/5 + 32` would be enough to prevent that. 2) That's what I thought as well.
Yep. Unlike in .Net, the "rules" for properties and fields are the same. In .Net, properties aren't allowed as `out` or `ref` parameters (not that Python has an equivalent) while fields are.
Scala conflates them too. They seem to think that it allows you to reimplement the same accessor as either an attribute or method call without the calling party knowing the difference. 
**5 ways to save 0.1 microseconds of execution time in Python**
Thanks Mahdi, for your efforts, and for making the result available for everyone.
The faster option will use more memory. Also use [:] when you want to copy a list
Flask doesn't really have an account or login system by default. [Flask-Login](http://flask-login.readthedocs.org/) provides that functionality.
Turns out it was a browser extension: HTTPS everywhere. I unblocked "Sublime (partial)" and it worked. Sorry for the noise!
1) I usually use Python 3, so that isn't an issue for me, but it's good to be aware of generally. 2) You're probably right. I just wanted to make a quick example. If I were doing this for real, I might use the Decimal class too.
Out of curiosity, what about for cases where you want to restrict access to setting an instance variable? Do you still think it's acceptable to make the attribute protected and then provide a getter property method but not a setter? 
Or you could do: from __future__ import division
That's because properties in .net are just syntactic sugar for getter/setter methods. ref/out params require a reference to an actual variable on the stack/heap.
"Field" is another name for "instance variables", which are also sometimes referred to in Python as "attributes" (in the context of classes).
`@property` and descriptors are very useful, but there is at least one strange corner case with their use. Let's say you have a base class that has a bunch of properties that run code that you may not have insight into and you want to customise some behaviour in a derived class. I ran into this with base classes for UI elements that were hiding .NET UI logic behind the descriptors. If implemented as a function, you can customise behaviour fairly easily (though it looks clunky.) class Base: def getFont(self): return self._font def setFont(self, font): self._font = font class Derived(Base): def setFont(self, font): super(Derived, self).setFont(font) If implemented as a property, you may have to know whether attributes are raw data members or descriptors when you hook into the setter logic. In the getter logic, you can remain ignorant. (I need to confirm, but I believe `super` doesn't hook up `tp_setattro`.) class Base: @property def font(self): return self._font @font.setter def font(self, font): self._font = font class Derived(Base): @property def font(self): return super(Derived, self).font @font.setter def font(self, font): Base.font.__set__(self, font)
 def c_to_f(v): return v * 9/5 + 32 def f_to_c(v): return (v - 32) * 5/9 if __name__ == "__main__": print(f_to_c(50)) print(c_to_f(0)) 
Source?
I'm very glad I don't have to switch to Django. Thanks!
10+ years of programming experience in a variety of languages. But the information is also available on [Wikipedia](http://en.wikipedia.org/wiki/Field_\(computer_science\)).
Oh, here's one more fun thing you can do with properties. Module level properties! At the module level, I've seen folks write getter and setter methods thinking that they may need to hook code in there at some later date. That's the whole point of descriptors: using raw data members first and then hooking code into them as the need arises without changing anything at call-site! This also illustrates something fun about Python, which is that binding is a core semantic! (That's why we have `from x import y` and `import x; x.y` -- they mean different things.) _bar = 10 @property def bar(module): return module._bar if __name__ != '__main__': from sys import modules orig = modules[__name__] # set properties on the type modules[__name__] = type(type(orig).__name__, (type(orig),), {attr:getattr(orig, attr) for attr in dir(orig) if isinstance(getattr(orig, attr),property)})(__name__) # set attributes on the instance for attr in (x for x in dir(orig) if not hasattr(modules[__name__],x)): setattr(modules[__name__], attr, getattr(orig,attr)) (Of course, as always, the *dutc* in my handle stands for *don't use this code*.)
Something else that may be of interest to you is [cookiecutter-flask](https://github.com/Widdershin/cookiecutter-flask). It gives you a basic flask app preconfigured with a lot of useful extensions. If you're partway through a project it might not be super helpful but I found it really nice for the last project I started.
Thanks W, it looks like you've dedicated a lot of time to it. I'll definitely look into it. 
It's been said that if you can't name three things you hate about a language you haven't been using it long enough to have an opinion on it.
Fun article to go through, I haven't messed around with dis or opcodes before, was very interesting!!
That's pretty vague. Can you be more specific? * General network socket programming? * Some specific network protocol? (e.g. HTTP) * Network routing/CIDR/etc? * DNS? * Network troubleshooting (e.g. ping/traceroute style tools?) * Network performance/stress testing? * Social networking?
This example does not use properties.
In my opinion, you shouldn't use properties for that. Python isn't such a language that works with ideas such as restricting access. If another python programmer wanted to modify an attribute of an instance from "outside" of it, he would be able to do that even if you didn't "expose" that attribute. A better strategy would be to document the attribute in order to inform other developers that they shouldn't fiddle with it.
yep, proves they aren't necessary(or objects for that matter), it's concise, readable and easy to comprehend, and fits in a tweet. The class/property implementation is verbose, more prone to error, does not fit in a tweet and is pretty ugly. python code is beautiful and readable. dont make python code ugly. 
deadlocks
A pure get/set takes 1 function call, getattr/setatrr. I'm not sure, but it's very likely that python has some sort of speed improvement for those calls when compiling code. Then, get/set methods take 2 functions. This second call is of the getter/setter itself, you have to pass arguments around in python so only the overhead of having them should be slower than pure gets/sets. Finally, fget/fset/fdel in properties are like a ping pong table. You pass arguments from python into the property, which is built in code and hopefully C, the property then checks if it has an fget, fset or fdel, if has one of those, it will call that method passing the arguments back into python code. Basically, it's like this: foo.bar_property.set(5) # in bar_property's def set(self, instance, value): if self.fset is not None: fset(instance, value) else: raise ReadOnlyPropertyErrorOrSomething Of course, the marginal overhead is usually nothing compared to the convenience of making properties with decorators and stuff, but when you accumulate too many property gets/sets at once it starts becoming noticeable even in profilers.
Here are some numbers testing three forms of attribute access that show this is true: &gt;&gt;&gt; timeit.timeit('f.bar', setup=''' ... class foo: ... @property ... def bar(self): ... return 5 .... ... f = foo()''') 0.2305891513824463 &gt;&gt;&gt; timeit.timeit('f.bar', setup=''' ... class foo: ... def __init__(self): ... self.bar = 5 .... ... f = foo() ... ''') 0.08671712875366211 &gt;&gt;&gt; timeit.timeit('f.bar', setup=''' ... class foo: ... bar = 5 .... ... f = foo() ... ''') 0.11962580680847168 
This. The miniscule time savings doesn't even come close to justifiying even thirty seconds of developer time to understand the bitwise cleverness on the next debug session.
In case everyone else has problems with this HTML5 player that's actually a flash player *(wait, what?...)*, [here's his youtube channel](http://www.youtube.com/user/tinimakoo/videos).
read https://glyph.twistedmatrix.com/2014/02/unyielding.html http://jjinux.blogspot.com/2014/02/python-response-to-glyphs-blog-post-on.html the tldr is remove global mutable state from your code. 
http://www.bbc.com/news/world-asia-26413101 [Imgur](http://i.imgur.com/pq6d34W.jpg)
http://www.bbc.com/news/world-asia-26413101 [Imgur](http://i.imgur.com/pq6d34W.jpg)
I think this will work: class Base: @property def font(self): return self._font @font.setter def font(self, font): self._font = font class Derived(Base): @property def font(self): return super(Derived, self).font @font.setter def font(self, font): super(Derived, self).font.fset(self, font)
You underestimate the stupidity of developers. I'd put it on the order of hours. I don't use bitwise operators.
Great post. I've been wondering about these for a while. 
I teach an annual introductory programming course (using Python) in a BYOD environment. Conda has enabled me to get even absolute beginners to the point where they can install *and manage* their own Python installations on their own laptops spanning multiple enviroments. &gt; About the not being able to install independent of OS on Linux. It's definitely not a Linux thing *per se*; there are distributions out there where the packages don't get frozen along with a distro version. (Arch and Gentoo spring to mind.) &gt; Python has a special place in this regard, as you generally don't want to mess around with the system installed Python I mean, various operating systems (and I include Linux distros under that) have their own philosophies, but I can appreciate the minimalist approach of moving as much as possible — and especially big, complex dependencies like Python — *out* of the "base" (e.g. Arch Linux, most of the *BSDs, &amp;c.) That said, you're right. On operating systems with a system Python (e.g. OS X) I prefer to leave it the hell alone. Thing is, that has only really been an option for the past year or three, since virtualenv has gained widespread adoption and some maturity. (And of course now other tools like we've been discussing.)
When you get right down to it… is it really any less secure than downloading a Python script and sending it sight unseen through your Python interpreter?
Their logo looks kinda like Mr. T...
In order to provide a good example I would advise to have the class be Temperature with properties/attributes for Celsius and Fahrenheit (and maybe Kelvin) rather than the other way around. Whether you use fahrenheit, celsius, kelvin or something else entirely then does not matter. That is because temperature is what you logically have and whether it is celsius or fahrenheit is a detail. More importantly in your example, the concepts for Celsius and Fahrenheit have a different status: Celsius is a class with attributes/properties for numerical values, whereas Fahrenheit is just a numerical value returned by one of those properties. Imagine some other piece of code comes up with a Fahrenheit class, now things would certainly start to get confusing!
Most likely the output of your subprocess exceeds the buffer that is allocated by default (which will cause it to stall until you clear the buffer by read() ing) Here is a stackoverflow question on a similar problem: http://stackoverflow.com/questions/1180606/using-subprocess-popen-for-process-with-large-output?rq=1
a lot of the people are singles...
~~The problem is not the black background, but the dark background with dark text.~~ ~~Gray on black is not exactly readable :)~~ EDIT: forget about that, RequestPolicy/NoScript blocked the code highlighter. This is what the page locked like for me: http://i.imgur.com/PM4VBms.png After opening it in a new browser I admit that it's readable without problems. Sorry!
I don't know if it had already been changed, but the hardest thing to read for me was only the Doctype declaration. Purple on top of black...
&gt; This is actually one of the things I like much more about python- in python, there is a clear distinction between attribute access and function calls. +1 on that point.
It's quite annoying that the article does not mention before the PS that this is windows only. I though that was an interesting project, but that's just a 5 years old wrapper for a windows API.
this seems like an odd work around to shoving the output into a websocket message.
Regarding arrays in Python, [] is a list, while array.array is an array. Lists can hold heterogenous data while arrays cannot.
I really wish Django used jinja, I just couldn't stand the limitations / style of django templates and the workarounds required when using 3rd party apps is a hassle.
Okay I spend a lot of time working with the subprocess module and attempting to read the output in a nonblocking fashion. I would be more than happy to attempt alternative approaches. Here are my experiences: If you cannot use Kqueue or something that supports signaling a read for a filesystem file descriptor (as opposed to socket fd), you need to use fcntl and os.read() with the NONBLOCKING flag set upon a subprocess.Popen.std(out|in|err) stream. If there is something in the pipe, it will return immediately. Else it will raise an Exception. This behavior is consistent unless you do a double fork() - at which that point, the process appears to have issues maintaining its file descriptors. I have no idea why – it appears to be common only on AWS Linux. The problem is as follows: If you closed all the file descriptors using os.close prior to a double fork, you would find that the os.read(subprocess.Popen.stdout, ...) would hang at times erratically. If your main thread was responsible for the read command, then the main thread will be blocked indefinitely until the offending subprocesses are terminated. After that, most subsequence subprocess Popen stdout reads will behave appropriately. If you did not, instead you would appear to get "confused" file descriptors. For example, I would get just emitted logging output from a logger on a recently opened Redis socket, which in turn raised a invalid response exception. It make no sense and only appears in the circumstances I outlined on AWS Linux. Never on my Mac. I was pressed for time, so I avoided the double fork and instead appended a '&amp;' to the command invocation, which got me what I wanted. If eventlet is like Gevent, then the monkey patches simply makes a blocking operation of a readline() be considered a cooperative yield. The underlying event loop library would simply wait for the file descriptor of the entity in question to become available before signaling to resume that stack. 
I don't understand why I really need monkey_patch in my scenario. My shelljob module spawns threads and takes care of the non-blocking aspect. Gunicorn does the same for the web server (obviously via monkey-patch internally). Somehow the combination breaks what I do in shelljob -- which is troublesome since it points to a defect somewhere in eventlet.
&gt;My shelljob module spawns threads and takes care of the non-blocking aspect Uh, I looked through the shelljob module and no, it doesn't. It blocks for 2 seconds when you call `g.readlines()` and the queue is empty. `monkey_patch` makes `Queue.get` asynchronous. Running `gunicorn` with the eventlet/gevent worker only affects how it reads/writes HTTP requests/responses, not how you work with other I/O. &gt;obviously via monkey-patch internally There's no such thing as "obviously". When in doubt, [read the code](https://github.com/benoitc/gunicorn/blob/master/gunicorn/workers/geventlet.py). The only thing it patches is gunicorn's own `sendfile` function.
Thank you all! After reading the posts decided to try Flask. Seems to have good community support and it was easy to adapt previous scripts. No Python 3 support though, but that does not seem to be a problem.
I'm using PyDrive to upload files to Google Drive but could not figure out how to define the destination folder. The following code saves a copy to the root on GDrive: gauth = GoogleAuth() drive = GoogleDrive(gauth) file1 = drive.CreateFile({'parent': '/home/pi'}) file1.SetContentFile('test.txt') file1.Upload() And how PyDrive returns the upload/download result? Thanks
UNIX/Linux terminal compatibility. Essentially, many, many UNIX tools assume that there's a blank last line, and will do slightly odd things if they're not.
can you explain the workarounds required for using 3rd party apps?
Ah okay! I should have guessed! Thanks!
Apparently, Django does not allow you to use Python expressions in templates at all. Anything other than simple attribute/dict look-ups must be done in a view or as an extension.
Even something as simple as ensuring your prompt doesn't get tacked onto the end of the last line of code after you cat a file.
The newline character is considered a line _terminator_, not a line _delimiter_.
Well isn't that more of a stylistic concern. I mean whenever I am displaying a page with a lot of content, I parse it into different dicts in my view before filling my template. I am trying to think of a situation where I need More logic in my template but I can't 
It doesn't. It says that .py files are to end with a line delimiter. This is the default convention on Unix and Unix-like systems (in other words, practically all relevant platforms except Windows), has been for more than 40 years. Virtually all the tools people use on source files will either expect a newline at the end of a file, or they don't care.
This is amazing. I am definitely interested in following the progress of this and trying to contribute, as this is a program I absolutely need.
what browser were you using, I used the latest chromium build on arch linux, to create the prezi, found one bug with right click, but nothing else, it worked perfectly on google-chrome-stable
What is the point of being the fastest web framework in Python? I don't get it...
It's convention, like many things in PEP8 it doesn't effect most things. But just as an example of a practical reason, if you combine two files (say with `cat`) having a newline will make sure the second file won't just be at the end of the first file. So instead of end of file1start of file2 You have end of file1\nstart of file2 Which will display properly in your text editor of choice.
&gt; many UNIX tools assume that there's a blank last line That's not correctly said (if you look at a properly terminated file in a Unix text editor, there will not be a blank last line). They assume that every line ends with a line terminator (\\n). A text file is a collection of lines, a line is a series of characters followed by a \\n. A file that does not end with a \\n is a file that has a last line that is incomplete. For example, if you concatenate two files, and the first file is not properly terminated, then the last line of the first file and the first line of the second file will end up forming a single line in the result.
Great read, and very succinct code!
I am interested in this as well. As part of DMing D&amp;D game I make tokens from illustrations in beastiaries and other source PDFs and transparent backgrounds look a lot better than the source backgrounds. They are often simple backgrounds but global thresholding does not work well if parts of the image are near the same color as the background. One deficiency of this method seems to be gaps where the background shows through the item of focus. But it is certainly a good first start, and automating the process is a huge step up from what I do now. 
Is there a particular project that needs help? I'm in search of an OSS project to join, and am wondering if this would be a good way to find one.
This is wonderfully succinct while still explaining it clearly. I'll have to quote you whenever someone asks me!
Well, depending on the 3rd party app you might have to completely re-write the templates and maintain your own jinja2 version which takes some of the convenience out of 3rd party apps.. If the app uses template tags you apparently can use [Coffin](https://github.com/coffin/coffin/) or [django-jinja](https://django-jinja.readthedocs.org/en/latest/) to use them in your own templates but you can't have a django template extend a jinja template.
[Image](http://imgs.xkcd.com/comics/effect_an_effect.png) **Title:** Effect an Effect **Title-text:** Time to paint another grammarian silhouette on the side of the desktop. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php?title=326#Explanation) **Stats:** This comic has been referenced 58 time(s), representing 0.4924% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcdcomic/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me)
Nah I just get that wrong all the time.
Use the `tp_getset` slot on the Type struct. PyObject* MyObject_getattr1(MyObject* self, void*) { Py_RETURN_NONE; } int MyObject_setattr1(MyObject* self, PyObject* val, void*) { return 0; } static PyGetSetDef MyObject_GetSets[] = { {"attr1", (getter)MyObject_getattr1, (setter)MyObject_setattr1, "attr1 attribute doc", 0}, {NULL, NULL, NULL, NULL, NULL} }; Read around in the CPython source for more information.
Python could be affected, if a foolish programmer was doing the equivalent of a perl 'chop' like 'line = line[:-1]' in order to remove a newline that is assumed to be there. This would be bad practice, though.
it means being faster than the slowest web framework in python... DUH
&gt; that blank line appears in text editors Depends on the editor. I checked with vim and gedit and neither showed a blank line. Emacs does though.
Awesome, thanks!
Dude, you already added PyPy into the mix. Was it really so hard to abstract out your function to C and use CFFI instead of trying Cython? It's the worst of both worlds -- generate a C file that is hard to optimize while restricting yourself really to CPython. A clean separation between C and Python allows you to optimize each and ensure code correctness. Finally, Cython doesn't run really fast with PyPy at all, whereas CFFI calls are inlined into the JIT.
OP mentioned books or tutorials, so I wasn't limiting it to only things that there are books about, but re: just books: * [Pro Python System Administration](http://www.apress.com/networking/python/9781430226055) covers some network admin topics * [Violent Python](http://www.amazon.com/Violent-Python-Cookbook-Penetration-Engineers/dp/1597499579/) covers a lot of network security aspects * [Twisted Network Programming Essentials](http://www.amazon.com/Twisted-Network-Programming-Essentials-McKellar-ebook/dp/B00BT0IEJE/) covers … network programming with Twisted * The latest [Python Cookbook](http://www.amazon.com/Python-Cookbook-David-Beazley-ebook/dp/B00DQV4GGY/) covers a lot of networking topics Also on PyVideo there are plenty of talks: * [Networking Libraries in Python](http://pyvideo.org/video/992/networking-libraries-in-python) * [Extreme network programming with Python and Linux](http://pyvideo.org/video/449/pycon-2011--extreme-network-programming-with-pyth) * [diesel: Simple and Scalable Network Applications](http://pyvideo.org/video/2278/diesel-simple-and-scalable-network-applications) * [and so on...](http://pyvideo.org/search?models=videos.video&amp;q=network) 
I am surprised to see higher number of `tcalls` and `funcs` for Flask. Function calls are a heavy thing in Python.
Really Interesting!
See multiple strong comments on YC Hacker News: https://news.ycombinator.com/item?id=7340818
You did see the "Without Trying That Much" part, right? 
You don't leave a blank line at the end of the file. You end the file with a newline character.
Eek, using `time` for timing such a small program? Let's go, timeit!
Optimizing Cython takes a hell of a lot more effort than a little C library and CFFI. Debugging it too is a bitch.
As someone debugging CFFI code right now, I'm not sure there's much hope. Then again, I'm trying to get code to work on 64bit python 3 on windows which is like barely supported.
I use [twitter](https://pypi.python.org/pypi/twitter) for [Twitter-IRC-Bridge](https://github.com/blha303/Twitter-IRC-Bridge) and [-lists](https://github.com/blha303/Twitter-IRC-lists), but [tweepy](https://pypi.python.org/pypi/tweepy/2.2) also [works well](https://github.com/blha303/H365IRC-python/blob/master/run.py#L271) (I don't like linking this program, it's so incredibly ugly :/). 
I've always used twython
Which one do you feel is more Pythonic? Also have you looked at [Twython](https://github.com/ryanmcgrath/twython)? I'm not sure which API looks/works better for me and I don't want to start writing code with one library only to find out that there is some subtle bug or limitation and I'll have to rewrite all my code.
Does Twython let your search for tweets by hash and location? I can't seem to find much mention if it in their documentation.
Does your C library work with a minimal C program? Are you holding the references correctly? CFFI deallocates objects super-super fast. 90% of my CFFI troubles in wrapping the one C library came from the above. The last 10% was a real bug in the library exposed via a test C program. 
I've been looking into Twython as well. The docs only have a tiny section on the streaming API. Have you used it? I want to use it for hackathon visualization.
Everyone has already answered the technical (and correct) reasons. But an analogy might help. It's like punctuation and grammar in a sentence, and when the newline is left out it seems
&gt; Does your C library work with a minimal C program? This is the angle I'm working on, but it's harder than it sounds (and it's a side-project, so I don't have a lot of motivation to get it working, I'm on a deadline at work). Something is wrong with my memory management or the libraries management or cffis (probably me), but I'm not sure what. I get different errors on 32 vs 64 bit python, and it only runs on 64bit python 3.
If you really need some help, send an email to the cffi list. Chances are you're handling it incorrectly, but there is always the possibility of a cffi bug.
So far the only vaguely useful thing I managed to do with this yield-within-comprehension idea has been to yield more than one value per loop in a generator expression. &gt;&gt;&gt; q = "12345" &gt;&gt;&gt; list("|" for x in q if not (yield x))[:-1] ['1', '|', '2', '|', '3', '|', '4', '|', '5'] I suppose one could emulate a couple things from `itertools` in terrible ways too. The fascinating thing about this to me wasn't so much that `yield from` is an expression (I recognize it as such from having used it as a rhs value in generators to which I `send` input), but that genexp/listcomp/dictcomp/setcomps meet the conditions required for them to act like generators when you insert a yield expression. Based on a bytecode disassembly of the listcomp `[x for x in "abc"]` it appears that a listcomp implicitly creates some function and passes it the input iterator! &gt;&gt;&gt; dis.dis('[x for x in "abc"]') 1 0 LOAD_CONST 0 (&lt;code object &lt;listcomp&gt; at 0x5551212, file "&lt;dis&gt;", line 1&gt;) 3 LOAD_CONST 1 ('&lt;listcomp&gt;') 6 MAKE_FUNCTION 0 9 LOAD_CONST 2 ('abc') 12 GET_ITER 13 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 16 RETURN_VALUE I had no idea this was happening but Python/compile.c confirms the behavior. This explains how they fixed listcomp scoping in 3.x, AND it explains why I can't do this: &gt;&gt;&gt; q = iter("abc") &gt;&gt;&gt; [x for x in (yield from q)] File "&lt;stdin&gt;", line 1 SyntaxError: 'yield' outside function ...yet these bits of madness work just fine... &gt;&gt;&gt; q = iter("abc") &gt;&gt;&gt; list(... for _ in [...] if (yield from q)) ['a', 'b', 'c'] &gt;&gt;&gt; q = iter("abc") &gt;&gt;&gt; list(_ for _ in [(yield from q) for z in [...]]) ['a', 'b', 'c'] &gt;&gt;&gt; q = iter("abc") &gt;&gt;&gt; def g(): ... yield "before" ... yield from (... for _ in [(yield from q)]) ... yield "after" ... &gt;&gt;&gt; list(g()) ['before', 'a', 'b', 'c', Ellipsis, 'after'] The next interesting bit is that I really can't figure out the conditions under which `("λ" for x in q if (yield from x))` would ever yield `"λ"`, even without that `and False` conjunction. I have a hunch it can be done, but I can't work out the semantics for sending a value into this perverse generator so that `(yield from x)` evaluates to anything but `None`. Any ideas or examples? Have you written about this anywhere else? 
Leaving a blank line at the end would be ending with *two* newlines characters. :-)
Error, expected ';'
I liked the part about profiling, but it's surprising that shedskin and nuitka are omitted. 
1. Statically link CPython and all C libraries (i.e. do not use `--enable-shared`); 2. Enjoy your 10% performance boost. EDIT: apparently, dynamically linked CPython became a bit faster at some point between 3.4a0 and 3.4rc1.
Oh, and btw, I'm not just looking for advice in the syntax of the code itself, I'm also open to tips on making the code cleaner and easier to read for debugging or for other people. Obviously being so new at this, I don't really know the standards for what makes a code "readable" vs not.
If I need more performance, I just add a new process/thread etc. and no framework can stop me from slowing an application because of programming mistakes. I mean, there are people using Ruby on Rails (and not because it is fast).
since you asked... def main(): print('a', a) # valid a =1 sys.exit(1) # crashing in a very unfriendly way... if __name__ == "__main__": import sys a = 1 main() # more stuff lets you import functions from that py file without running the script. The contents are defined in the global scope assuming you are running the script, so imports and variables that you write inside it will apply everywhere. Shockingly this can cause bugs, so people will put all that stuff in a separate function and call it run or something.
Thanks for responding. I appreciate the help, but uhh.. I don't understand that at all. :D While I'd appreciate a thorough explanation, I don't expect it - I know it'd probably be lengthy and time consuming on your part. Instead, does that have a name or something so I can search around for an explanation of it, or do you have a link to a decent explanation?
Python does have a style guide, called [pep8](http://legacy.python.org/dev/peps/pep-0008/). There is a checker called `pep8` in pip, install guide for pip [here](http://www.pip-installer.org/en/latest/installing.html). It's just a guide, and you don't have to follow it, but it does make code more consistent. Some of the stuff on pep8 is about line length, trying to keep your lines below 79 characters long. Why do you have \n for every print statement? If not having it would mean it overlaps with the board, you could put a `print`, with nothing after it to print a newline on python2. The ascii art is annoying, imo. My terminal has trouble rendering it properly, but you can use it if you want. On line `162` and `164`, you seem to be checking if the input, lowercase is either "yes" or "y". I don't know about other people, but the way I handle checking for multuple cases, is something like `if input in ["yes", "y"]`, which tests if the input is either one of the items in the list. It looks cleaner, and you don't have to repeat again.lower.
imo, `if __name__ == "__main__"` looks ugly. I never had a reason to do it, because I never come across a bug related to it.
Thanks for the style guide, it's bookmarked for when i'm not dead tired and working tomorrow. hehe The new line is just because it looks cleaner in the shell. I'm just using python IDLE, so I wanted the text to spread out to be easier to read and not look so cramped. I've never really liked ascii art either, but I wanted something really blatant and obvious when you won. Originally I just had it do for x in range(0, 11): print ' '*x+"You win!" sleep(0.05) for x in range(10,-1,-1): print ' '*x+"You win!" sleep(0.05) for this kind of cascade effect of simple text lines, repeating "you win" a bunch of times. -shrug- The actual game logic was my real goal - the text interface is just a placeholder for the lack of graphics. On lines 162 and 164, I actually knew about that, i'm not sure why I didn't do it there. I think it's just cause I was testing the replay function and I had to run it like a dozen different times, so I got annoyed two whole letters more. lol
I've always thought everything that uses the underscore key words looks a little weird.
No idea what it's called. Just run the script. a and sys is defined in that part of the code and used inside the function. They are global variables, which would not be defined if you imported the script.
Thanks! Definitely clears up a lot, I was having trouble finding a good explanation of the if name == main thing.
The code is fine. I'm referring to logic errors, so the script is imported and then main() is called, but "a" is not defined.
No, you can't compare a script not running at all because the interpreter won't accept it to a *bug* in a script.
Some good resources, thanks.
In my experience most problems with cffi are due to reference counting. If you make sure you explicitly hold references to everything what's passed to C function call, you should be fine. I just assign structs to Python variables and keep them alive in the scope the C function is called.
Thanks for your detailed answer, this will help me for sure ! :) 
Eh.... This is a great example of completely pointless usage of cython/profiling. Guess what, this program is absolutely dominated (on pypy at least) by dict lookups of created tuples. Why on earth would you store stuff in a dictionary that maps tuple of indexes -&gt; value!!!!! I replaced this usage with list of lists (you can use numpy arrays if you insist too) and run it 4 times in a loop to account for the jit warmup time. The time went from 0.4s to 0.05s (cold) and 0.025s (warm jit), so a speedup factor of 16x by choosing the right data structure! It can be likely optimized further. diff here - http://paste.pound-python.org/show/BISGUBzgVFdm0oEVieAY/
[citation needed]
 pushd cpython-23d9daed4b14 ./configure --with-system-expat --with-system-ffi --with-system-libmpdec --with-computed-gotos --enable-shared --prefix=$PWD/../dynld &amp;&amp; make -j 4 install ./configure --with-system-expat --with-system-ffi --with-system-libmpdec --with-computed-gotos --prefix=$PWD/../static &amp;&amp; make -j 4 install popd git clone https://github.com/sauliusl/python-optimisation-example.git pushd python-optimisation-example/alignment git checkout starting-code 2to3 -w . time LD_LIBRARY_PATH=../../dynld/lib ../../dynld/bin/python3.4 alignment.py time ../../static/bin/python3.4 alignment.py popd `dynld`: real 0m0.524s user 0m0.509s sys 0m0.013s `static`: real 0m0.467s user 0m0.449s sys 0m0.017s Good enough, or should I write a blog post about it? [A relevant question](http://bytes.com/topic/python/answers/19661-shared-vs-static-link-performance-hit-windows).
very nice, is there a github repo for this ?
just got an ebook on flask, thx for this post, can't wait to dive in. tried to do one for Prodigy, it seemed to be frozen or taking a long time to process.
For someone who didn't know any of this stuff before the article... I have to say it was a great read!
only if you use a dumb shell. zsh just displays a „%“ symbol with inverted colors to indicate the newline is missing from the last line of the previous command’s output.
that’s one thing i don’t understand: if a language knows it should be there, why can’t you leave it out? i like python, scala and JS, because you can leave it out there. (unfortunately, there are rare ambiguous cases in JS which prompted people to suggest using semicolons everywhere in JS – i don’t care)
One way to tidy things would be to gather everything board related into a class with a bunch of useful methods that are used throughout the game. e.g. elif ocean[gRow][gCol] in label: ocean[gRow][gCol] = hit[int(ocean[gRow][gCol])-1] board[gRow][gCol] = "O" print "\nYou hit my Battleship!" sleep(pause*1.5) Could become: elif ocean.ship_at(gRow, gCol): ocean.hit_ship(gRow, gCol) board.add_hit_marker(gRow, gCol) print "\nYou hit my Battleship!" sleep(pause*1.5) 
It's especially interesting comparing it with Morepath, which now has lower numbers in both, even though Morepath is built on Reg, which is a generic function implementation which naturally will result in more function calls than without it. When I cythonize Reg and profile then, the amount of function calls drops a lot more for Morepath, and I think it's not unfair to do this in this case as it would seem; Reg really is a mostly an implementation of a different way to do function calls. 
Morepath is not aiming to be the fastest web framework in Python. But it is nice to do a performance check and tune-up sometimes; doing lots of work in generating a response can also give an indication of the complexity of code involved. And being a bit faster doesn't hurt either. And then there's a bit of the competition aspect. I did want Morepath to be faster at this task than Flask at least. After some more tuneups yesterday Morepath is now faster at this task than Django and Tornado too. It doesn't say much really, but it's fun! 
Very interesting. Thanks for the post!
You've uncovered some very interesting angles that I'm going to have to spend some time looking into! You're right that in Python 2, the disassembly for the list comprehension would show you that the bytecodes corresponding to the list construction (`LIST_APPEND`) are inlined into the bytecode for the surrounding function. This is changed in Python 3 where we just invoke a code object created on compile. (As you note, in the former, loop variables leak scope.) For your other question, generators could originally only `return None`. This is a reasonable restriction, because we have no semantics for accessing any value that the generator returns. When `yield from` was introduced (http://legacy.python.org/dev/peps/pep-0380/), this restriction was lifted. In a co-routine that yields values with `yield`, we can send in values as follows: def c(x): while True: x = (yield x) In a generator or co-routine that delegates to a subgenerator, we can return values from the delegated subgenerator with return. def g(x): yield x return x*2 def f(g): x = (yield from g) Therefore, in our perverse chainer, def g(x): yield x yield x*2 return x*3 chain = lambda g: (None for g in g if (yield from g) and False) I may have written about this stuff on my disclaimer-in-the-title blog, http://seriously.dontusethiscode.com/. I've also given a bunch of talks on generators, most recently at http://pydata.org/ldn2014 and probably next week at the conference http://forpythonquants.com
which is exactly the same speed as pypy (but requires quite a bit more effort)
Great job, dude! Thanks for sharing!
I have heard that it's bad to do it this way but its all through my code everywhere. How bad and why?
Is the title a question.
Is there a reason you are using easy_install instead of pip? I feel like your article will retain value longer if things such as pip were included given the additions to Python3.4 - http://python.readthedocs.org/en/latest/whatsnew/3.4.html Working with Pyramid I've found pip to be fantastic, and especially helpful when I need to remove something I previously added.
not my article. I just posted the link. as far as pip being useful, buildout has it beat. 
Oh, okay. Thank you for the post anyway. Also thanks for turning me to buildout. I'll have to check it out.
I'm not sure how you managed to do that. 
&gt; Gather around kids while I tell you what you want to hear. &gt; What? How I managed to get shell access to groklearning.com using Python? &gt; Hohoho, that’s a good one; Listen closely: Titles can often be seen as the question that’s answered by the article.
Are you referring to compound statements or not closing files?
pip and buildout seek to address different concerns. About from that, buildout is also showing a lot of age.
Quite sad to see legacy packaging tools still being recommended in a late 2013 article. Stop using distribute or easy_install, neither are really recommended any more. Distribute hasn't been updated in ages (if you're lucky, it will infact install setuptools under the cover) but both use HTTP connections rather than HTTPS. [get-pip.py](https://github.com/pypa/pip/blob/master/contrib/get-pip.py) will install both newest pip and setuptools for you. If you already had distribute, run `pip uninstall -y distribute` and then `pip install -U setuptools`.
No this is a statement?
&gt; seak &gt; buildout is also showing a lot of age. explain, sounds to me like you are mis-informed. 
I hope no one ever uses a list to represent structured data.
Yes there is! https://github.com/codelucas/shorten.tv 
Yeah, not great, that said I give a huge amount of points to any team that goes as far as to call up the whitehat that reported the bug responsibly and talk it over. We can't all nail it every time.
He explains how in the linked article.
And if you don't know C?
Me too! It was a very simple example intended for beginners =) A dictionary would be a better structure, but the aim of the example was not to show good choices in that field. Thanks
Looks like you can: http://qt-project.org/wiki/PySide_for_Android_guide http://modrana.org/trac/wiki/PySideForAndroid Sorry for late reply
totally, but I think I found all those bugs, if anything I'm holding too many references and leaking memory. I'm trying to call out to COM-ish library (7-zip) which basically means interpreting C++ classes as structs of function pointers. If it all works out though there will be a zipfile like module that can open rars and open &amp; save 7z files. So making a minimal C program (not a C++ program) that can call into 7zip &amp; do stuff is the first step I think. Again, my code only works on windows 64bit, python 3. (it may never, the linux version of 7zip seems like it has a different ABI)
* [CWE-403: Exposure of File Descriptor to Unintended Control Sphere](http://cwe.mitre.org/data/definitions/403.html) * [CWE-769: File Descriptor Exhaustion](http://cwe.mitre.org/data/definitions/769.html) * [PEP 343: The "with" statement](http://legacy.python.org/dev/peps/pep-0343/)
The link is broken for me...?
Then Cython won't cut it, as moderately plain Python will get such a tiny performance boost that can better be obtained from PyPy. Cython generates a shitload of C from a few bits of Python. Good luck optimizing that without knowing some C. 
I'm Ron Burgundy?
In package/run.py, change convert() to convert.convert(), or change the import. You're importing a module and trying to call it, while what you want to do is call the function inside the module. Is the directory containing "package" on your PYTHONPATH? If not, add it. Show us the errors you're seeing.
indeed, its worth dismissing everything else about the article right? 
Personally, it gives me pause for thought to wonder if it's worth following the authors information over just reading pyramid's docs, if his knowledge is two years behind current.
Yes but it's to my understanding these tools don't come with Python 2.7.5, am I right? For example, when I try to use pip, it tells me that command doesn't exist.
Try this: `sudo apt-get install python-setuptools` `sudo easy_install pip` `sudo pip install virtualenv virtualenv-wrapper` From then on all packages you install should be inside of a virtualenv, so you won't have to use sudo. I think you can skip installing easy_install and just `sudo apt-get install python-pip`, but this seems to be the recommended way. 
Thank you, I read somewhere that Distributive is no longer used as it merged with setup tools .7 and I've been trying "install setuptools". I see that it's actually set to "python-setuptools" thanks.
Sure, I have no problem with that, but installing 3 years old 0.6 distribute and using easy_install which can't uninstall packages is still current bad practice to introduce to beginners, and I care very much about making their experience as awesome as possible.
Well, I hate to [ruin your day.....](http://en.wikipedia.org/wiki/LISP) :)
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Lisp (programming language)**](http://en.wikipedia.org/wiki/Lisp%20(programming%20language\)): [](#sfw) --- &gt;**Lisp** (historically, **LISP**) is a family of [computer](http://en.wikipedia.org/wiki/Computer) [programming languages](http://en.wikipedia.org/wiki/Programming_language) with a long history and a distinctive, fully parenthesized [Polish prefix](http://en.wikipedia.org/wiki/Polish_notation) notation. Originally specified in 1958, Lisp is the second-oldest [high-level programming language](http://en.wikipedia.org/wiki/High-level_programming_language) in widespread use today; only [Fortran](http://en.wikipedia.org/wiki/Fortran) is older (by one year). Like Fortran, Lisp has changed a great deal since its early days, and a number of [dialects](http://en.wikipedia.org/wiki/Programming_language_dialect) have existed over its history. Today, the most widely known general-purpose Lisp dialects are [Common Lisp](http://en.wikipedia.org/wiki/Common_Lisp) and [Scheme](http://en.wikipedia.org/wiki/Scheme_(programming_language\)). &gt;==== &gt;[**Image**](http://i.imgur.com/stQmegw.jpg) [^(i)](http://commons.wikimedia.org/wiki/File:John_McCarthy_Stanford.jpg) --- ^Interesting: [^Common ^Lisp](http://en.wikipedia.org/wiki/Common_Lisp) ^| [^Emacs ^Lisp](http://en.wikipedia.org/wiki/Emacs_Lisp) ^| [^John ^McCarthy ^\(computer ^scientist)](http://en.wikipedia.org/wiki/John_McCarthy_\(computer_scientist\)) ^| [^Scheme ^\(programming ^language)](http://en.wikipedia.org/wiki/Scheme_\(programming_language\)) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cfvcm6j) ^or[](#or) [^delete](http://www.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cfvcm6j)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
&gt; which can't uninstall packages [not exactly](http://peak.telecommunity.com/DevCenter/EasyInstall#uninstalling-packages) it can get them out of pythons path though.
You are close, but not all the way there. You have to think of it from the point of view of the interpreter. When you are inside the "package" directory and start python, it has no idea that it is in the "package" directory and since there is no "package" directory installed it can't find the package. When you are running from the root directory the first thing on "sys.path" is the current directory ("."). Now when the interpreter looks for your package "package" it checks "." first and sees a "package/__init__.py" file. That tells the interpreter that it found a python package and it can continue on with the import. When your sub-packages/modules import "from package.utilities" the interpreter is only finding those files because it is checking the current directory. Man I hope that makes sense. Whenever I have done work on my own packages I have always installed then in development mode using ``python setup.py develop``. Your other choice as others have said is to add the root directory (the one containing the first package directory) to your PYTHONPATH. I actually didn't know relative imports were frowned upon, I guess I'll have to look in to changing those. And please, someone correct me if I'm wrong.
forgot the huge one. * no instructions on how to install pycharm before doing anything else
The exception being on the first line of the script should give you a hint. There's nothing funny going on here. Python is simply unable to find the module you're importing. Try adding an "import package" as the first line -- it won't work either. Why? Because unless the directory containing "package" is on your PYTHONPATH, Python cannot find it. It's looking for a directory called "package" on its path, but there's no such thing. Going up a directory level works because Python typically adds the current working directory to sys.path. With virtualenv, do "import sys; print sys.path" to see what it does. Don't guess -- experiment and verify. 
And the "convenience import" is just asking for trouble. You're replacing a module with a function from within that module. It's confusing at best. Keep it simple, sir.
Django does this quite often to offer stuff like django.forms.forms as django.forms. I guess it can only do harm if I actually access the other module from another package (which I never do).
Thanks, but that's Pyramid, not WebOb. I don't know why Pyramid has its own version of these, though it's good the docs exist. [I asked Chris McDonough why the new implementation] 
Maybe not... this was a bit trivial. Oh look I can run arbitrary python code on their server...
Yeah, that's crazy they didn't sandbox either Python or the machine or both. I'm working on something similar with Google appengine but it's taking a lot more effort than that. I did get to read some interesting config files but the fs is read only. And these are not in the same dir as if you import os and listdir. They might have even fixed it because I was having trouble duplicating it last week. 
I'm Ron Burgandy?
Because running python on their server doesn't allow any room for exploitation?
http://docs.pylonsproject.org/projects/pyramid/en/latest/designdefense.html#pyramid-uses-its-own-http-exception-class-hierarchy-rather-than-webob-exc
The interesting part would have been: "So, how did they fix it?" But that is where this report ends.
I'm not experienced with VISA, but I have used python to communicate with Agilent multimeters and multiplexers via TCP sockets and with Fluke multimeters via GPIB. Maybe I can help, what exactly is tripping you up about the string command protocol?
The install notes work I'm sure, but I'd recommend something more like this: virtualenv flask . flask/bin/activate (flask/Scripts/activate on windows) pip install -r requirements.txt (you'll need to create a requirements.txt file with pip freeze &gt; requirements.txt) python create_keys.py python db_create.py python run.py IMO having scripts that you enable execution with and then run is weird in the python world (and possibly unpythonic). If you want to install python scripts as command-line utils you add them to your [setup.py](http://pythonhosted.org//setuptools/setuptools.html#automatic-script-creation) scripts for managing your web app (like create_keys.py and db_create.py) should just be run with python &lt;script_name&gt; probably. (again style thing, and just my opinion)
I'm very tempted to wire up Pyborg to OKC now! Taking bets on the probability that we can get a chatbot laid?
Some of these would be real layups to port, Flask-SQLAlchemy for example is mostly just Flask+SQLAlchemy which both support python 3 at this point. Others... like Twisted, not so much. I'd like to see all the Twisted libraries ported to tulpip/asyncio, but like that's ever going to happen.
Oh dear, here we go again. The reason you cannot do this: class Foo: """Some documentation""" pass foo = Foo() foo.__doc__ = """Different documentation""" help(foo) Is because the `foo.__doc__ =` is changing (or, rather, *creating*) `foo.__doc__`; previously there was no such thing, so Python would just translate `foo.__doc__` into `Foo.__doc__` via method resolution. `help()` always looks at `Foo.__doc__` and never at `foo.__doc__`. Of course, using `str` for this example is a particularly bad case, because (at least for me, on Python 3.3) `help(s)` just tries to look up the *value* of `s` (i.e. if `s = String("hello world")`, you get an error about not being able to find documentation for "hello world" rather than help on the `s` object itself).
But if you look at countries, Russia is an absolute winner. "Ru" in Cyrillic letters would be "Ру".
I'm going to give this a shot now. 
Taking creepy computer geek to a whole new level. Keep it classy, guys :)
There's quite a bit of potential for creepiness, I suspect. There's also quite a lot of cool data analytics and general awesomeness that can be done as well. So, um, I'll keep my fingers crossed that you guys know what to do.
Like, strings being Unicode? For example? 
This is disingenuous, some "libraries" are actually applications (e.g. uwsgi, supervisor, etc) clearly included to buff out the "non-compliant" stats. Others are libraries nobody has used in decades, like obscure plone stuff. Others are libraries of non-consequence, for example the stdlib comes with a perfectly fine XML parser, so why would I care for another one like meld3? The fact of the matter is, python 3 was "ready" 7 years ago, as indicated by the PSF declaring it stable. Its so old, [even RedHat are indicating people should move to it](http://developerblog.redhat.com/2014/02/18/migrate-to-python3-w-rhscl/). RedHat. The stable of shoddy old bug-ridden software they don't even include their own bugfixed packages in updates. You can't get any better indicator that its more than time to leave Python 2 behind. 
Fun tidbit I want to share as a speaker from a couple years ago and resident and fan of Ohio. Standard Oil of Ohio became SOHIO and if any Ohio people want to see the formerly ubiquitous signage (most are now BP) just find a marina where the old brand and logo are still used. Anyway, great conference and organized very well. Columbus also has OYO spirits another fun play on the state name. I'm sure there are more. Great conference. Come speak and attend!
Paramiko, why?
Of course it does. But this is such a painfully obvious vulnerability that I think most of them are beyond that. Most of the shit they talk about on /r/netsec I don't understand completely, or at all, and yet this exploit here I feel I could have done. It's trivial.
I guess it's a good thing I started learning Python after Python 3 came out. 
Some have replacements: for example I use [sarge](http://pythonhosted.org//sarge/) instead of envoy.
When you say 'ipython', are you referring to the IPython Notebook? Because that's what I was going to recommend. The [gallery of interesting IPython Notebooks](https://github.com/ipython/ipython/wiki/A-gallery-of-interesting-IPython-Notebooks) is full of examples that sound a lot like what you're trying to do. If you end up needing to put a lot of boilerplate in each Notebook to get things the way you want, check out the [profiles](http://blog.safaribooksonline.com/2014/02/27/using-ipython-profiles/), which are a pretty powerful feature for customizing your sessions.
How arrogant of you to assume our existence has a purpose. We simply ARE! Like ants or dogshit...
Actually I didnt try the ipython notebook yet, thanks. Seems ipython has a lot of features to offer I should take a deeper look into :)
Nah, if you are learning language, it hardly matters IMO. Even though it's backward incompatible, it is still same language.
As far as I know, spyder (https://code.google.com/p/spyderlib/) was designed to be close to the matlab IDE. You may want to have a look. 
Oh, great! It sounds like exactly what you're looking for. I found it not that long ago and just dove way in, to the point that I submitted a CFP to OSCON to talk about it there. (Fingers crossed.)
Is *Python* the name of some wierd new cult, now?
By flippin' bits 'n shit.
Agreed -- I think Spyder is what OP is after. I also want to give OP a heads up that the scientific stack (i.e.: numpy and scipy) are imported into the global namespace by default. It's just something to be aware of if you expect your scripts to be run from a non-Spyder environment.
I want to join PyAsthmatic
It's nice and clear, thanks. But I would have like to find a clear explanation on why and when use decorators (and other more advanced structures). It's something I often struggle with.
As explained [here](http://www.cmlenz.net/archives/2008/07/the-truth-about-unicode-in-python) Unicode handling in Python 3 is actually pretty shitty. Not worth a switch at all.
&gt; You can't get any better indicator that its more than time to leave Python 2 behind. Or you can't get any better indicator that Pyhton 3 is not actually an improvement but an aggravation. People are sticking to Python 2 because it is actually better.
I've seen examples with pure cython which were making the code run much faster than normal python with numpy, and without touching any C.
Thanks, I remember reading that but only remembered when I saw it again. :) 
Thanks that *does* sound exactly like what i was looking for!
How do I remove this thing from group talk?.. tried !quit, !leave, !bye, !exit --- edit: our admin has kicked this bot. Warning: this bot does not seem to have a command to quit a group chat
So big functions.
1. The [unicodedata](http://docs.python.org/3.4/library/unicodedata.html#unicodedata.normalize) module contains a function that converts unicode strings to their normal form. Though I guess the fact that most people aren't even aware of it (let alone *use* it) is a problem. 2. The case conversion this post describes is context-aware. It's really hard to implement stuff like that. 3. While I'm not sure about Unicode classes, standard regex escapes such as `\w` and `\s` are Unicode-aware (i.e. match any characters from the respective classes.) You can also use ranges of code points, of course. 4. The post states that bidirectional text should be implemented at the input/output, not in the core, yet still lists this as a problem in Python. What. 5. The internal representation of unicode strings was changed in 3.3: Python can now automatically choose the best encoding for a particular string.
Nice, good luck with that :) 
Python 3 is competely incompatible with 2: "waah there's too much stuff to change!" Python 3 features were backported to 2 so you could switch one feature at a time while the application would continue to work on 2.7: "hurr durr there's no reason to switch to 3 anymore". Sometimes I wish Python devs abruptly ceased supporting 2.7 at all. You know, to give the likes of you the message that "extended support" does not mean "you should continue being a lazy prick", it means "update while you can".
And those of us who live in or near Oklahoma City will now have to do a double take every time we see this stupid package name. WE WERE OKC FIRST GODDAMMIT!
It's being ported to python 3 right now.
Is this text generated by a python implementation of a markov-chain? Or did you confuse python with preaching?
I don't think it matters anyway. I started on Python when Python 3 was already a thing but I've always written code that pretty much works on both without changes (of course that's not *always* possible). I mainly wrote for 2.7 however, now I've switched to 3 recently. I guess it can be hard for some old-timers that have written Python 2 for ages and use "Python 2-isms", otherwise it's not a problem.
 -I removed the ASCII thing. That was a horrible oversight. Thanks. -I am cleaning up the code still. This is still in alpha mode. Fixed up the code a fair bit in the last few days, but a long ways to go. Let me know if you see anything else. Seriously, I am working on it everyday making it cleaner and better. 
[Here](http://pythonrants.wordpress.com/2013/12/06/why-i-hate-virtualenv-and-pip/) is an interesting article I found ranting about pip and virtualenv. While it doesn't talk about buildout specifically, it does bring up many concerns that buildout addresses. Also, I'm not sure why people are downvoting you for being helpful in this subreddit.
Try this: https://pypi.python.org/pypi/slave Works for me with a Tek scope over LAN. Can use VISA or Python VXI implementation.
I would like to to think these two sites have different target audiences. It was never meant to be that type of note taking. It is more a cloud based storage for organizing your notes.
&gt; not sure why people are downvoting probably because my comment is being interpreted as I don't like or think you should use pip. Which is completely false. Anyone who has used buildout knows that it uses pip behind the scenes and then a ton of other stuff. it's funny, people don't like buildout because it's old, it's used in the zope/plone ecosystem mostly(another downvote attracter). But when they manage to get a python application of significant complexity and they need a way to deploy, they'll start off with fabric and eventually reach for something like salt, or even worse chef(because now you have to learn ruby and 100 little dsls, or go hunting for recipes that might or might not work) or just deploy to heroku so they dont even need to understand how anything works(just git push). And even though all those tools have their place and are good at what they do, a well written buildout will get you a decent reproducible self contained app relatively easily. My rule of thumb for when to use pip or buildout is.... if it's a library, buildout is overkill. if it's an application with lots of moving parts (like a web app, with database, offline task processing, memcached, load balancing all with deployment differences for different environments like sqlite for dev, pgsql for qa stage and prod etc...) buildout makes it easier. my .02 based on experience 
Better yet, [COBE](https://github.com/pteichman/cobe)
Isaac Asimov's "Reason" (1941)....
No, that's not big enough. Yes, that's a big deal, but it's not going to be the "killer feature" that gets people chomping at the bit to pick it up.
I honestly think 2.7 should not have ever happened. 2.6 was a backport of the big-ticket 3.0 features. It should have stopped right there.
I have a very limited knowledge of Python, but I was wondering if there were many more differences other than: raw_input / input print 'string' / print('string') I'm sure there are many more differences, but I'm not sure just how game changing it is. I'm guessing it can be pretty annoying for people who are very familiar with Python 2.x syntax, but then again, I have very little experience in this. 
A big one is handling files. You don't read strings, you read bytes, then decode them into strings. There are other things. nonlocal variables also spring to mind.
&gt; Though I guess the fact that most people aren't even aware of it (let alone use it) is a problem. People are not aware of it because this function should not exists. It should work automatically out of the box. &gt; It's really hard to implement stuff like that. Well if you really want to convince me to switch my whole codebase to a new version you better make sure that you solve the hard problems. &gt; You can also use ranges of code points, of course. Why do I need python 3 for that. RE remains a complete clusterfuck concerning Unicode. &gt; The post states that bidirectional text should be implemented at the input/output, not in the core, yet still lists this as a problem in Python. What. Again solve the hard problems. I'm still convinced that the way Phython 3 handles Unicode is substandard for 2014. The advantages are negligible. Absolutely not worth a switch.
This is not open source? The Skype4Py API no longer works. I wonder how this was done. 
&gt;if you really want to convince me See, that's your problem. Nobody gives a fuck about *you*. "Convince" yourself on your own or remain an ignorant dumbass forever. I'm out.
"More permissive imports" Hehehehe
Doesn't look like it is, at least not that I can find.
ReST != REST
First, relative imports aren't deprecated, the old method of doing them (e.g. using `from loader import Loader` in `run.py`) is. Instead, one should use `from .loader import Loader` if the module is in the same package, `from ..loader import Loader` if it is in the package one level up, `from ...loader import Loader` for a package two levels up, etc. Second, if you're running `run.py` with `python run.py`, Python doesn't know it belongs to a package. You should rename it to `__main__.py` and run it with `python -m package` instead. Note that you'll still have to modify `PYTHONPATH` or install the package system-wide/into a virtualenv (both of these install the package into `site-packages`, which is added to `PYTHONPATH` by default); as already said, without that, Python would be unable to find the package.
Strange that there is almost no information provided about where in Ohio PyOhio is happening.
I don't think keeping the code secret improves your security.
Historically, at the OSU [Ohio Union](https://maps.google.com/maps?oe=utf-8&amp;q=1739+N.+High+Street,+columbus+OH).
How dare he work on a problem from a domain with such a VERY long history. (That his solutions to the issue seem to be correct just shows how amateurish people without color science training can be) We should go post condescending comments on his blog so he won't taint color science with his uninformed and untrained ramblings.
Just think of a small project and work on that. I usually have a hard time coming up with ideas but right now I'm working on a cryptocoin trading bot with a friend of mine. Also, you can use the advanced search on github to find small python projects. 
His approach is amateurish at best and likely wrong. That was my point.
I'm curious could you enlighten us with how this should best be tackled.
All i did was offer a warning to tread lightly if using these amateurish methods. They are also likely wrong, but i cant be bothered to figure out how/where because i would not be using this persons "services."
Does it have to be GitHub? I have a script-base strategy/combat game I'm continuously working on that could always use additional developers. Check out /r/pyshipcommand for more information!
&gt; All i did was offer a warning to tread lightly Since you did not read my post, I am reposting what i wrote just above.
But I did. My comment was a response to this: *"They are also likely wrong, but i cant be bothered to figure out how/where because i would not be using this persons 'services.'"* But really, my comment applies to both of your sentences fairly well.
The uploading based off extensions I honestly got from the flask website. I will look into a better way to do this. the htmlwork is just as you said, a weak sanitizer. I tried several sanitizers and it really hurt the copy and pasting from websites. I have not given up on the sanitizing yet. Do you have any suggestions?
&gt; But really, my comment applies to both of your sentences fairly well. Is English your second or third language?
Was that meant to be an insult? To answer the question, no, it is my mother tongue. 
&gt; I hear some developers even use Make for C anc C++ :( That tool was released in 1977 so it must of course be crap! /sarcasm Sorry man I replied to the wrong comment. This was supposed to go to the "buildout is showing it's age". In the context of this thread we agree. 
I hear some developers even use Make for C anc C++ :( That build tool was released in 1977 so it must of course be crap! /sarcasm
No, for a non-native speaker you seem to have a fair understanding of the language. For a native speaker, your grasp is tenuous at best.
You could also say that make showed its age a long time ago. Find anyone, *anyone*, who can claim to *enjoy* writing a makefile. Nowadays, you have tools which generate them for you!
He's using the color distance function as defined by the people who literally wrote the book on color science, a second, more amateurish, but probably still useful perceptual measure of color, and then putting a human in the loop to validate the clustering in case the algorithm goes terribly wrong. On the surface, nothing appears horribly wrong, as long as their target audience are native English speakers. You probably couldn't publish this without significant work, but that's hardly a measure of utility. I agree with the content of your post, but there's a helpful way to say, "This is a complicated field with a lot of extant work, and the authors should make sure they understand the possible complications." You chose to be sarcastic and demeaning about it instead. Also, the model with the black skirt is cute. And so is her outfit. Source: I am a physics PhD candidate. I study on the self-assembly of structural color. I have some color science training, but am by no means an expert.
I'll be open sourcing it at the end of the test phase
Out of interest does color science also deal with how the brain perceives color. Like I'm thinking that not everyone may perceive the color red in the same way (qualia), even if given the same wavelength of light.
Ok thanks. The htmlwork does use a white list using beautifulsoup. The extra stuff at the top of that function is for javascript and vbscripts. 
It's not whitelisting if you only apply it some of the time (the large `if` condition).
I just participated in a webinar on this add-in. It looks like a great solution with one exception. Every person who would open the spreadsheet would need the add-in (at $360-$399 a pop).
Yes, otherwise it's really not very interesting. That map shown in the article, for example, is an average perceptual color map for normal trichromatic humans. Color science deals almost entirely with human perception of color. I can't recall off the top of my head what the people who study your question are called (psychophysicists, perhaps), but broadly it falls within color science. There is also a [linguistic relativity to color names](http://en.wikipedia.org/wiki/Linguistic_relativity_and_the_color_naming_debate), adding additional complication.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Linguistic relativity and the color naming debate**](http://en.wikipedia.org/wiki/Linguistic%20relativity%20and%20the%20color%20naming%20debate): [](#sfw) --- &gt;The concept of [Linguistic relativity](http://en.wikipedia.org/wiki/Linguistic_relativity) concerns the relationship between language and thought, about whether and how language influences thought. This question has led to research in multiple disciplines—especially [anthropology](http://en.wikipedia.org/wiki/Anthropology), [cognitive science](http://en.wikipedia.org/wiki/Cognitive_science), [linguistics](http://en.wikipedia.org/wiki/Linguistics), and [philosophy](http://en.wikipedia.org/wiki/Philosophy). Among the most popular and controversial theories in this area of scholarly work is the theory of [linguistic relativity](http://en.wikipedia.org/wiki/Linguistic_relativity) (also known as the Sapir–Whorf hypothesis). An often-cited "strong version" of the claim, first given by Lenneberg in 1953 proposes that language structure in some way determines how we perceive the world. A "weaker version" of this claim posits that language structure influences the world view of speakers of a given language, but does not determine it. &gt; --- ^Interesting: [^Benjamin ^Lee ^Whorf](http://en.wikipedia.org/wiki/Benjamin_Lee_Whorf) ^| [^Linguistic ^relativity](http://en.wikipedia.org/wiki/Linguistic_relativity) ^| [^Color ^term](http://en.wikipedia.org/wiki/Color_term) ^| [^Basic ^Color ^Terms: ^Their ^Universality ^and ^Evolution](http://en.wikipedia.org/wiki/Basic_Color_Terms:_Their_Universality_and_Evolution) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cfw2uq3) ^or[](#or) [^delete](http://www.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cfw2uq3)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
I would like to make my own one of these. Is this open source?
Is there a way for me to use this without having an openID account?
Sorry, only google, yahoo, or flickr right now.
The main reason people want to contribute to GitHub projects is because some employers will actually ask for your GitHub account and look at what you've contributed. It looks better if you have contributions of GitHub.
In my opinion I found it easier to find a project I wanted to use. Use it, and then think of ways to make it better or fix bugs. GitHub itself takes some time to get used to. You almost need a course on it too. If that doesn't work then put up a simple project on github. Get used to how github works. this could even be a sample project (not real). 
Thanks for the comments. Please feel free to add suggestion on how to improve it. You are right about plone stuff, that they are not mainstream libs anymore, but they seem to be quite popular probably because they are widely used in old systems. edit: clarify my point
Looks like Flask-SQLAlchemy already supports 3. I added a PR to specify trove classifier.
But they don't actually care if it's on GitHub. What they care about is seeing examples of your work. They ask for GitHub because it is currently the most popular. If you show up with a Bitbucket or SourceForge account, they aren't going to close the door in your face.
I have really been enjoying this series of articles. Real world solutions for difficult problems. They aren't perfect but they are workable - a distinction that is easy to forget.
Hey you, I'm learning Python myself and did a little web app just to have a hands-on project to work on. It's [Whiskyton](http://whiskyton.herokuapp.com). As I just started learning Python and Flask, the code is very very simple, so maybe you'll feel more comfortable. Yet, we can try to develop something together, as we're both learning Python… In the [GitHub](http://github.com/cuducos/whiskyton) page you can find a couple of issues. Or feel free to add more issues, enhancements, suggestions, anything :) 
not creepy at all...
Actually, many employers will close the door in your face. The unpleasant truth is that most recruiters and managers care about GitHub. They ignore other other options. Whether or not that makes them worthy of your skills doesn't matter if you are trying to land that first job. For what it's worth, I'm not happy with this situation (and I'm partly responsible), but I'm also realistic enough to know that beginners with GitHub portfolios have an edge up on those that lack them.
Awww... 
The singularity will occur 
It will be soon
I've come across a few that use Bitbucket, or Google Code for that matter. Can't think of any right off, but they exist.
You are very welcome to make some improvements to PyPrind (https://github.com/rasbt/pyprind) or the twitter-follow-bot2 (https://github.com/rasbt/twitter-follow-bot2) if you like :)
Cool project! I've been thinking of doing something along these lines with beer to learn some Ruby on Rails. Definitely going to star and dig through it when I have some time.
Create your own project!
Did you use any HTML/CSS with it as well? Do you know HTML/CSS also?
I have a relatively popular (but still simple) python project on github, which generates secure xkcd-style passwords: https://github.com/redacted/XKCD-password-generator I don't have as much time to work on my side projects as I'd like. The next big thing I've being meaning to do is too make it a proper module so it could be imported into other projects more easily. Other things would be improving the readme with better examples. If you can think of something to add I'd be really happy to consider it and even advise you on implementing it!
Well of course. They already have access to skype and probably a few downloads already, plus thousands more if this is really developed. All it would need is a few tweaks and boom - instant robot army. 
I have no idea how I could get my self to program at work and then at home. Does that mean I will never be a good developer? 
Take a look at [Pygments](http://pygments.org/). It's on Bitbucket rather than GitHub, but if you're into getting familiar with lexers and regular expressions, take a crack at submitting some bug fixes or even writing a lexer yourself. (Shameless plug: I wrote the Lasso lexer.)
I have a few projects if you are interested in contributing. You'll need to know the basics of TKinter and/or praw. [my github](https://github.com/wykleph)
Same boat. I'd rather go eat out or chill with my sister or play the piano. But when I'm at work, I love to learn and code.
Didn't you say you were switching to meteor in a blog post? I guess node.js must not be as hip anymore...
I just don't have that much mental energy. Sometimes are really interesting problem with get me to work an 80 hour but going home to start a new one seems crazy. 
I believe that you've mistaken Reddit with [Issue tracker](https://github.com/pexpect/pexpect/issues).
[pypy](https://bitbucket.org/pypy) uses bitbucket. Another big difference between bitbucket &amp; github is that bitbucket allows you to use [mercurial](http://mercurial.selenic.com/).
Port some Flask extensions to py3.3. Everyone will love you for doing so! :) 
Node.js is *so* 2013. 
Why? Such a stupid statement sounds like what a smug hipster dev who loves ruby/js and github would say. There's lots of great projects at sites that are not github, including sourceforge 
Git, not Github.. 
Yup! Plus it is definitely going to be something that is interesting to you as well. 
I wouldn't call that scheme secure. See [here.]( https://www.schneier.com/blog/archives/2014/03/choosing_secure_1.html)
He says that because it's how hiring managers actually think. 
They're not the same person so one can't really assume that. 
Most of these were terrible examples. It's like regretting putting slashes on a URL. The world has moved on. I was hoping for things like MongoDB, MyISAM, Hardware bugs, NAT, etc.
Its not every day you get to disagree with Bruce Schneier, but Randall's entropy calculations are sound - check the comments for explanations. A person executing the scheme in their head would likely generate weak passwords - people are bad at randomness and vocabulary - so a computer does that for us.
Interesting timing, given the 'goto fail' security bug recently that went unnoticed in part because C relies on braces rather than whitespace. There's definitely some merit in forcing function to follow form. (Excuse the alliteration.)
Using a real-time framework for a URL shortener would be an overkill, don't you think?
Hell, I was expecting something like floating-point representation. It's one of those subtle things based on a design decision that could totally screw you. 
They should name it '7 historical decisions that continue to pain people that hate programming'. Nothing to do with *programmers* ... 
Except for Mongo, all of these are well older than Python...so...historical.
Ah yes. Divide two numbers and get near the answer...but not quite. That's a classic! This list was honestly crap, and it becomes more so as I the no about it longer. Two entries for JavaScript...and they use PHP to defend good behavior. How about the fact that PHP itself is rubbish? Especially early on! And a quote admitting someone won't use a language because of whitespace formatting? Throwing the baby out with the bath water much?
Rob pike worked on plan 9 and is a co-inventor of go, newsqueak, and many other things. But he makes his bias known about UNIXisms.
Mercurial is the only reason I use Bitbucket.
In my case the milestone was findind the database. Once I had it, I could start the project… do you know any db about beer tastes? 
I haven't heard about it before, but I'll check it :) Tks
Spot on. I think this article is over little things that good programmers don't mind. I program in Python and C. Both are great. I might add Rust in too. I don't get the whitespace hate. All my C has braces and indentation. Its easy for other Python programmers to read (LBYL &gt; EAFP in C) and the other C dev I work with commented on the cleanliness of it. Readability matters to me, in whatever language I use. I wonder if the anti-whitespace crowd neatly indents their code.
Also check out Pythonxy, it comes with spyder and lots of packages. There's also winpython which is a portable version of pythonxy.
For a new beginner, I'd get used to making your own github/bitbucket projects and understand the flow of pushes/pulls/commits/etc before you start doing pull request on other people's projects. 
Interesting how you negative speakers (kumar99 and pythongeek) don't appear to have any blog posts or meaningful work of your own. Instead of being mean and nasty to someone trying to share what they know, why don't you at least try to contribute back?
That's a bit of a strawman. Having your own blog is not a pre-requisite to discussing things other people have written. I also doubt that you can learn how much "meaningful work" a person has done by scanning their reddit history. Kind of insulting of you to imply that they have not done meaningful work. You simply don't know. That said, I do agree with you that the posts by kumar99 and pythongeek were not up to the level of constructive criticism that I would like to see. 
As well as [sphinx](https://bitbucket.org/birkenfeld/sphinx) and [pygments](https://bitbucket.org/birkenfeld/pygments-main) are pretty huge as well.
Maybe some form of a "10% time to help work on X FOSS project your work uses" would work for you. Or, the first half of the morning of Friday or something.
It's simply using the 360 most downloaded projects from PyPI. By the very nature of them being one of the most downloaded projects on PyPI obviously points to those projects not being obscure or of no consequence. Perhaps maybe the fact you've never heard of something does not in fact mean it is not widely used?
As a non-programmer, setting up and using git was pretty confusing at first, especially when you are using Windows and are not use to do a lot of command line interface. 
`nlargest` is much slower than sorting-and-slicing, though. In theory, the average and worst case complexity of `sorted(xs)[:m]` is O(n log n + m) while the average and worst case complexity of `nlargest` is O(n log m + m log m), which seems close enough (and is even better if m &lt;&lt; n)...until you notice that the whole heapq module is written in pure Python. Oops.
its hard.
&gt; I wonder if the anti-whitespace crowd neatly indents their code. Of course we do. The argument against significant whitespace code blocks isn't about readability. I have never come across whitespace indentation that was unreadable because no one in their right mind would write a function with 6 different levels of indentation. While that *would* be unreadable, having 20 brackets nested throughout a method isn't any clearer (although it gives editors a matching bracket to jump to). The main argument against whitespace in python stems from responsibilities placed on the display/editor. An editor's job is to display the contents of a file and provide editing functionality. Functions like copy/paste are the main targets of criticism. Each editor has its own stance on formatting what to paste. Inter-editor copies are generally well managed as far as indentation is concerned, but the bigger problem is text copied to the system clipboard from *other* displays/editors. If the other program displayed the text with a different standard of indentation, the target editor may not be able to interpret the indentation correctly. The sub-problem of this is even if the editors are consistent in displaying whitespace, if the source text is written with a different indentation style than the target, bad things can happen. Worst case scenario: you copy text inside a function you have and your editor decides to display the whitespace equivalently, but the amount is different. From the editor's perspective, it has done its job. But from python's perspective it is wrong. Unless the editor is python requirement aware, a burden is placed on the editor that it may not be able to fulfill. Python attempts to escape the responsibility of syntactic correctness, regardless of source, by encouraging style standards. The anti-whitespace crowd is against whitespace block delimitation because the editor shouldn't be obligated to format various indentations to fit the python interpreter. tl;dr: Pushing syntax responsibility to either the editor or the user is to a lot of people inherently a design flaw. I enjoy coding in python and am largely unaffected by indentation problems *because* I work in an environment that handles them itself, or I have modified my editor to handle them. I imagine the bulk of the python community is unaffected by whitespace issues, but that doesn't change what is happening.
 In [147]: numbers = [random.randint(1, 1000000000000000000000000000) for x in xrange(1000000)] In [148]: %%timeit heapq.nlargest(3, numbers) .....: 1 loops, best of 3: 155 ms per loop In [149]: %%timeit sorted(numbers)[:3] .....: 1 loops, best of 3: 877 ms per loop 
It's great to see they are starting to optimize NumPy on PyPy. In the past they have been focused on compatibility.
Wrap it into a shell script and try again
Yeah, that's what I meant by "m &lt;&lt; n"; 3 is much smaller than 1000000, after all. Guess pure Python is not as slow as I thought.
I had one one an interview question this week: double a = 2.0; double b = 1.1; System.out.println(a - b); What's the expected result? 0.9, of course. Actual Result? 0.8999999... The company did budgeting software so what followed was a discussion on how to get around this. 
A few additions to the answer you linked to: * `co_kwonlyargcount` is the number of keyword-only arguments the function accepts. What's a keyword-only argument? Well, consider this function header: def fn(a, b, *xs, c, d=1, e): Obviously, it's not possible to call it like `fn(1, 2, 3, 4)` and expect `c` to be 3 and `e` to be 4. Values for `c`, `d`, and `e` can only be passed as keyword arguments: `fn(1, 2, c=3, e=4)`. Therefore, `kwonlyargcount` of this function is 3. Note that `argcount` will be 2, as neither keyword-only arguments nor `*xs` count. * `64` in `co_flags` is `CO_NOFREE`, which means that this function uses neither `cellvars` nor `freevars` (i.e. both are empty.) This info is used to slightly optimize simple function calls. * `co_lnotab` is a byte string, but it always has a length that is divisible by 2. Each pair of bytes encodes the bytecode offset and the line offset relative to the last stop. For example, if `lnotab` is `\x05\x08\x03\x03` and `firstlineno` is 3, this is decoded as "opcode at offset 0 appeared on line 3; opcode at offset (0 + 5 = 5) appeared on line (3 + 8 = 11); opcode at offset (5 + 3 = 8) appeared on line (11 + 3 = 14)." It's not possible to go back, and all opcodes between two stops are assumed to be on the same line. Also note that these are literally bytecode offsets, not opcode indices (i.e. they also include the length of opcode arguments. If your code is `LOAD_FAST x; CALL_FUNCTION 0` and you want to encode "CALL_FUNCTION appears 1 line below LOAD_FAST" the correct sequence would be `\x03\x01`, not `\x01\x01`.) * The first item in `co_consts` is the docstring of the function. This does not apply to code objects that represent modules and classes, though; these should explicitly set `__doc__` with `STORE_NAME`.
I'm having issues in IE 5 as well.
Mosaic's working fine here. 
Standard issue Java phone from 2000 here: nope
Thanks for the information. And yes I'm aware that this isn't worth it. I'm looking into it for reasons of interest not productivity.
Thanks for this information.
I wish this dude had shirts or something, ya know so I could rep the neckbeard life.
just added some syntax highlighting, hope it makes it more appealing now :)
Why the sudden change? Not that I'm complaining, but it seems a little out of the blue. 
Well, you could always rep it with a neckbeard.
Love the name =P
Awesome, then the only thing left to do is shave the URL into your neckbeard. 
Ask and you shall receive. Started a campaign! http://teespring.com/neckbeardrepublic
If anyone is interested in some shirts started a campaign here. http://teespring.com/neckbeardrepublic
Free slurring and mumbling, sigh. 
good idea :D!
Woo!
Ah good old `return`. Occam's razor again. Well, your blog is very interesting and a lot of fun to read. I love to write code which shouldn't be used, and I appreciate being able to read some without stern warnings and lectures—you clearly have a healthy streak of curiosity.
I really wonder if PyPy is going to be hit by the "I'll upgrade when they support package xxx". I want numpy support, but I also want wx/qt, scipy, and matplotlib, and vtk as well. I could do a system call, but that's hardly robust.
During the brief moments where I've had to troubleshoot issues with XML, I've found it very convenient to be able to run the files through xmllint to prettify them in the same way, and then look at the visual diff through a normal tool like meld or diffmerge. The other question is whether you have an XSD to validate the config files (spoiler alert: you _should_ have one). That said, its a configuration file, why exactly would it be translated?? 
I got a stupid benchmark I was playing with, mostly division and multiplication and looping, down from 110 seconds to about 2.6 seconds with Cython. The only things I needed to do extra were add the optional static type and tell it not to worry about potential division by zero; I certainly didn't fiddle with the C source. In fact, Cython performed basically the same as the small pure C version of the benchmark I wrote myself. 
So awesome!
Very cool article. I think there are lots of people using Python that don't know their way around SQL and probably ignore the sqlite3 module, which is really too bad because it is a simple yet powerful way to keep persistent data. One thing I noticed was that the article makes extensive use of string formatting in the SQL statements. This is discouraged in the sqlite3 docs: &gt;Usually your SQL operations will need to use values from Python variables. You shouldn’t assemble your query using Python’s string operations because doing so is insecure; it makes your program vulnerable to an SQL injection attack (see http://xkcd.com/327/ for humorous example of what can go wrong). &gt;Instead, use the DB-API’s parameter substitution. Put ? as a placeholder wherever you want to use a value, and then provide a tuple of values as the second argument to the cursor’s execute() method.
[Image](http://imgs.xkcd.com/comics/exploits_of_a_mom.png) **Title:** Exploits of a Mom **Title-text:** Her daughter is named Help I'm trapped in a driver's license factory. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php?title=327#Explanation) **Stats:** This comic has been referenced 141 time(s), representing 1.1580% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcdcomic/)/[kerfuffle](http://www.reddit.com/r/self/comments/1xdwba/the_history_of_the_rxkcd_kerfuffle/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me)
Probably because nobody was buying the service. And really, why would they? With wonderful interactive training tools like CheckIO available, passively watching screen-casts doesn't make much sense.
Nice! Just wanted to know if another fellow Python programmer had experience with HTML/CSS as well.
I wrote this a while ago and just finished polishing it enough to release. It saves me a *lot* of time, so I thought others might find it useful. Feedback welcome!
.pyc files are bytecode written to file using the [marshal](http://docs.python.org/2/library/marshal.html) module. [Here's some more information, if you're curious.](http://nedbatchelder.com/blog/200804/the_structure_of_pyc_files.html) 
I am currently working on a Flask-based project that targets 2.7 due to some dependencies not being ported. Because of those backports, we were able to write code that is almost Python 3 compatible. There are maybe half a dozen lines that will need to be slightly altered. With all of the backports, the differences would have been much larger.
But from what I can see, the last commit was 10 months ago...
Right, but you still have no compelling reason to pick Python 3. Nobody does. I honestly feel that the efforts would have been better served if there was a nice treat waiting on the other side for Python 2 users, but there isn't. I'm still convinced that 2.7 was a mistake.
I think this is the biggest structural challenge with this effort. If NumPyPy doesn't speak the Python C-API, then it's missing half the point of Numpy, which is to be a common array object between Python, C, C++, and FORTRAN. If NumPyPy *does* speak the Python C-API, then it's really a very overlapping effort with [Numba](http://numba.pydata.org), which already supports CPython and LLVM. It might be more worthwhile to merely extend that to work with PyPy's compiler &amp; IR. I think that regardless, NumPyPy is going to be an interesting thing for some people. But for the existing userbase of Scipy users, until it gets solid scipy, matplotlib, wx/qt support, it's in roughly the same realm as Julia. For web programmers and others that don't need a "full scipy stack", it would be a great thing to get them doing more array-oriented programming, and to have yet another trick up their sleeve to make Python more performant. There is some confusion and potential marketing problems around the naming - calling it "NumPy for Pypy" when it doesn't support Scipy or Pandas is going to be confusing for people. So many people want to route around the multicore limitations of Python that they are going to jump on this - only to realize they can't really use it. If there was a nice way to message around this issue so it doesn't cause this confusion, that would be great. 
They're actually all hosted on YouTube, you can [watch them there instead](http://www.youtube.com/user/tinimakoo/videos).
I think the best way for any SQL tutorial to start is by providing a whole buch of data to play with. Maybe an unwieldy CSV file full of redundant information clocking in at a few mb, and then showing how it can be represented instead elegantly and compactly with a bunch of tables
The code uses string formatting to create SQL statements, allowing SQL injection attacks. The author couldn't have proclaimed his incompetence better if he tried.
&gt; CheckIO http://www.checkio.org for the lazy
A couple of years ago, the PyPy devs had the intention of providing full support for the Python C-API but while implementing it they discovered it was always going to be a slow interface as they would have to emulate reference counting, between PyPy's core and the C-API. PyPy has a much more advance GC than CPython that does not require reference counting. At this time only partial Python C-API support is provided. After running into this issue, they decided that they would optimize ctypes and anyone wanting to have fast calls to external libraries would have to use it instead of the Python C-API. The PyPy devs ran into some issue while trying to optimize ctypes and then decided to set out and create a new ffi library which would not have the same issues/limitations. The result is the cffi library which works on CPython as well as PyPy. The cffi library has about the same overhead as ctypes while running on CPython but most of it's overhead has been removed under PyPy. In the past couple of days they have also started a new branch to remove most of the overhead associated with release and acquiring the GIL which must be done with each external call to further reduce the total overhead when making these calls. The high level plan for NumPy support in PyPy is * Implement NumPy in PyPy in a way that can be optimized by the JIT * Add support to the JIT to optimize it * Provide an efficient way to call all the external libraries such as the ones you mention Most of the work to date has been with the first item making sure it is highly compatible with NumPy, and the cffi library provides support for the last item. The PyPy devs have no intention of wrapping all the external libraries themselves with cffi, that say scipy needs, but instead expects there will be others who will volunteer to do this work once it becomes clear that PyPy has clear advantages for applications using NumPy. Although they will likely wrap a couple of libraries to get the process going, such as the BLAS library. Anyone wanting some easy tasks to contribute to PyPy should consider consider wrapping some of these external libraries with cffi.
[Changes listed here.](http://ipython.org/ipython-doc/2/whatsnew/development.html)
Personally I just rely on the duck typing and the it's easier to ask for forgiveness than permissions aspects of the language when dealing with type. There are a few very specific use cases where I will just use a types comparison or isinstance if I need to handle the data differently as a list or a dict for example. These cases could be built as try/except clauses but if,elif are sometimes cleaner or faster. 
Struggling with the same thing lately. Python at work, then more python at home, on weekends is just ugh..
Agreed. Your function will usually fail in some way if your variable is the wrong type. With proper test coverage it's easy to find these before you ship code. If I ever have a situation where I need to make sure a variable is a certain type I just throw an assert with a description. 
I see very little point in doing something like this. Static languages can do type checking at compile time to identify that you're passing the wrong type to a function before you ever even run it. That can help catch errors before they reach a live system. This still won't be caught until runtime, and only a few lines before you would have had an error anyway. Then, thanks to duck typing, your "wrong" type might have worked just fine. In your example, I might have passed u"gravy" instead of "gravy" and everything would have worked fine without the type check. Instead, the type check blows up at the user during runtime on something that the function could have handled without issue. 
Throwing my hat in with the type checking is bad. The only time that I can really advocate for it is when you're coding magic functions like `__eq__`. At least you used `isinstance` which'll catch inherited types as well. 
Good news. IPython is one of those things I need to dedicate more time too. 
Agreed with the unit tests. I often feel that the tests that should fail or throw exceptions are more important than my expected to pass ones. 
I would see that as more practical. That would give you some clues if you were getting unexpected behavior, instead of immediately failing in a scenario that might have worked anyway. [Edit ] Actually, as I think about it, you could build a decorator that caught exceptions within a wrapped function, and only logged the unexpected types if an exception occurred. Perhaps you could log violations at debug level any time they occur, and at error level when an exception occurs along side a violation. 
Xmllint is awesome. 
Again, I agree with the other comments here in that you shouldn't do this. One of Pythons biggest strengths in my opinion is the fact that it uses duck typing. You don't care what it is, only what it can and does do. That said you asked if people do use it. The short answer is yes. Some people do this. It *can* be of help in large project or projects where the input is not guaranteed. I've used it in a project where I allow users to develop plugins and I was continually checking to see if the data they gave me was of the right type. I made things simpler by using a decorator. Should I have done this? Probably not. There are probably better solutions out there but it worked with what I had. If you don't need it, don't use it. However, it is great for trying out as an introduction to decorators in Python (it was the first decorator I wrote :D ).
[**+TurboGears**](https://plus.google.com/115723575598932631951) [_2014-03-08T15:10:45.109Z_](https://plus.google.com/115723575598932631951/posts/BbBhAMdzYj1) &gt; &gt;TurboGears 2.3.2 is now available on PyPi! &gt; &gt;All TG2.3 projects should upgrade without changes, please refer to the Upgrade Guide to check compatibility with your applications. &gt; &gt;Major Changes: &gt; &gt;* Quickstarted applications have been upgraded to Bootstrap3 CSS Framework, include the TurboGears admin &gt; &gt;* Python3 support now includes TurboGears Admin &gt; &gt;* Multiple Speedups in request dispatch and memory collection &gt; &gt;* JSONP renderer is now provided built-in ( [http://turbogears.readthedocs.org/en/latest/cookbook/jsonp.html](http://turbogears.readthedocs.org/en/latest/cookbook/jsonp.html) ) &gt; &gt;* Renderers support has been rewrote, renderers are now easily pluginable and configurable ( [http://turbogears.readthedocs.org/en/latest/reference/reference.html#tg.configuration.AppConfig.register_rendering_engine](http://turbogears.readthedocs.org/en/latest/reference/reference.html#tg.configuration.AppConfig.register_rendering_engine) ) &gt; &gt;* Error reporting improvements: Reporting to Sentry is now built-in, when reporting exceptions by email it is now possible to attach request dump and local frame. Error options are now grouped in trace_errors namespace. &gt; &gt;* Remove PasteDeploy dependency removed when in Minimal (microframework) mode. &gt; &gt;* Support simple custom templates for paginator ( [http://turbogears.readthedocs.org/en/latest/reference/reference.html#tg.support.paginate.Page.pager](http://turbogears.readthedocs.org/en/latest/reference/reference.html#tg.support.paginate.Page.pager) ) &gt; &gt;* Support for URL translations, it is now possible to serve as controllers urls that contain odd characters, in newly quickstarted applications those will be translated to _ character ( dispatch_path_translator option in AppConfig ) &gt; &gt;* Improve TW2 rendering engine detection, now only available engines will be enabled. &gt; &gt;* Quickstarted applications now enable the debugbar if installed &gt; &gt;* Improve error_handler support in validation, they can now keep decoration and wrappers ( [http://turbogears.readthedocs.org/en/latest/cookbook/upgrading.html#validation-error-handlers-now-call-their-hooks-and-wrappers](http://turbogears.readthedocs.org/en/latest/cookbook/upgrading.html#validation-error-handlers-now-call-their-hooks-and-wrappers) ) &gt; &gt;* AppConfig plain configuration methods got renamed to _configure_* convention &gt; &gt;* TGMing dependency has been removed when quickstarting with MongoDB/Ming &gt; &gt;* chameleon_genshi renderer support moved to an external extension &gt; &gt;* Improved the JSON Encoder, generators are now resolved as lists and tg.lurl() result can be encoded. &gt; &gt;* Fix validation error reporting for TW2 with nested layouts &gt; &gt;* Login should now forward also url GET parameters when redirecting &gt; &gt;* Improvements to i18n support major feature is the ability to make get_lang() return only the languages supported by the application instead of returning all languages requested by user. ( [http://turbogears.readthedocs.org/en/latest/reference/reference.html#tg.i18n.get_lang](http://turbogears.readthedocs.org/en/latest/reference/reference.html#tg.i18n.get_lang) ) &gt; &gt;* Trigger controller_wrappers resolution on environment_loaded milestone instead of config_ready so that they can be register on setup hook &gt; &gt;* To be coherent with add_ming_middleware rename the sqlalchemy related middleware setup method to add_sqlalchemy_middleware 
Here's an article from February 2014 about the roadmap for IPython: [IPython founder details road map for interactive computing platform](http://www.infoworld.com/t/data-visualization/ipython-founder-details-road-map-interactive-computing-platform-236429)
hi, there was a talk on last europython you will be intereted in: http://www.youtube.com/watch?v=BCTlX-omFS4 In python 3 you can do def(foo:str, bar:Bar) its not type check is more like a hint/doc (to help people use your code and tools to do the autocomplete). 
I HIGHLY recommend using PyCharm and docstrings instead. You get as-you-type type errors when you care about types, and you're adding documentation in the standard formats. I find this to be pretty much all of the advantages of static typing that I used to miss from time to time, but much faster and nicer to work with AND you can still write tests that rely on the duck typing!
Why?
Oh thank you so much. I completely forgot since I was only thinking about SQLite as a local tool and didn't worry about web apps here, feel really bad now :( Unfortunately, the `?` does only work for values, not for table names etc. However, I added a short section about security now to warn people: http://sebastianraschka.com/Articles/2014_sqlite_in_python_tutorial.html#security
It's all about qt or wxwidgets
http://andreacensi.github.io/contracts/ &gt; PyContracts is a Python package that allows to declare constraints on function parameters and return values. It supports a basic type system, variables binding, arithmetic constraints, and has several specialized contracts (notably for Numpy arrays). (@decorators, Python 3 annotations, docstrings)
What other editors support those?
After some googling, [pylint](https://pypi.python.org/pypi/pylint) seems to be a very strict one. There is also [pyflakes](https://pypi.python.org/pypi/pyflakes) for errors that have less to do with type (import errors, NameErrors, etc.)
Because i can
In /r/programming in response to this article there was an interesting discussion about the readability of list comprehension vs for-loops. Lately, I find myself using a lot of functional paradigms and the above discussion had me wondering something. In corporate environments, does anyone find that functional programming techniques are frowned upon in contrast to imperative/procedural techniques based on the idea that a) FP is less readable and that b) the codebase must be readable for the largest possible number of team members? In other words, do you have these discussions at work about whether FP is more 'readable' than other programming paradigms?
nice, any chances to have this moved to a library on pypi so others editors may be used?
If you need type checking you really should be using a statically typed language. Trying to shoehorn Python to do something it was never meant to do is just a recipe for a bad time. 
Thanks! I added a security and SQLite injection section. Didn't think about it since I am not using sqlite3 for webapps (yet). Unfortunately the ? Placeholder only works for values, not for col and table names :(
Thanks. Good points! I wanted to keep it simple, but `with conn` is definitely a good alternative to classic `try - except` statements. About the `executemany()`, I am not a big fan of it since it didn't have any performance gains (at least in my simple benchmarks), so I was not mentioning it, because I found the regular `execute()` more straightforward.
Does this version allow the notebook to traverse the local directory?
Yep
My boss doesn't like lambdas, but that's mostly it. (And I happily ignore him when it comes to his dislike of lambda)
Hell, I've had conversations with a boss who didn't like Perform Varying and wanted it done with goto's 
What's "perform varying"? Google didn't help clarify.
Definitely. It's modular, I just need to upload it. I'll reply when it's up.
another way to invert a dictionary (1.12 on the page): reversed_m = dict(itertools.imap(reversed, m.iteritems())) Advantage: Uses generators instead of lists only, so it saves space.
Or: foo = {v: k for k, v in bar.iteritems()} Also, the article could have just as easily used iterkeys() and itervalues().
Ah yes, your solution is definitely better than mine. Note: dict comprehensions only work from 2.7 and newer.
That is quite fortunate in a way, since it makes you realise you may be doing something dangerous. I've needed to do this once and I had the table/column names computed at startup and interpolated, but still used placeholders for values.
The mobile site that this link takes you to is very weird. You guys should consider bootstrapping this site. The positioning is all off.
&gt;In corporate environments, does anyone find that functional programming techniques &gt;are frowned upon In corporate environments a lot of languages are being used that aren't young enough to have functional programming techniques.
Download one of the wheels (or the tarball) from http://archive.ipython.org/testing/2.0.0/ and pip install it.
Yes, but you can always do this instead (works as far back as 2.4): foo = dict((v, k) for k, v in bar.iteritems()) 
That's why I asked in /r/python.
(cringing) Is this 2.7 or 3.x specific?
I built something similar, and even took some inspiration from yours, although I've not touched it in like 2 years :( https://github.com/aaronbassett/Pass-phrase
In my case (gov't not corporate) , lambdas are frowned on, but comprehensions are thought of as pretty cool. 
/r/learnpython /r/learnprogramming ***** ^This ^is ^an [^automated ^bot](http://github.com/WinneonSword/LFB)^. ^For ^reporting ^**problems**, ^contact ^/u/WinneonSword.
L is a list of numbers. Your teacher wants you to write a function that returns the average of the numbers in L. (Do you know what a mathematical average is?) In addition, if L is an empty list, the function should return 0. Your teacher wants this function to be at most 8 lines of code long. For 3.b, it sounds like the teacher wants you to run the function listExample3() and pass the return value to ave(). 
Cool as in "use them, unless it doesn't makes sense". For example, nested comprehensions look pretty awful. 
Pyramid is another option.
&gt; In corporate environments, does anyone find that functional programming techniques are frowned upon in contrast to imperative/procedural techniques based on the idea that a) FP is less readable and that b) the codebase must be readable for the largest possible number of team members? There are basically two main problems, I see: 1. You always need while/for loops, so the question is do you _also_ want list comprehensions as a slightly different way to do this thing you can also do just fine already. 2. List comprehensions tend to be slightly more readable (assuming you know both) when you aren't doing much ... but _much_ worse if things get out of hand (and that happens quickly). This is intensified when working in teams or long term maintenance where people don't want to rewrite the code from a LC to a while loop. ...to sum it up I've never seen a while loop that was confusing, but I've seen more than a few list comprehensions that made me go WTF.
Most of these are library features, and some are dubious at best (Eg. using zip to invert a dictionary is going to be a giant wtf for most people compared to the obvious while loop, and it's unlikely you need any speed gain).
TurboGears is yet another popular framework.
I found this somewhere (here?) and it might help you: [http://codecondo.com/14-minimal-web-frameworks-for-python/](http://codecondo.com/14-minimal-web-frameworks-for-python/)
Oh, and this might help too: [http://nichol.as/benchmark-of-python-web-servers](http://nichol.as/benchmark-of-python-web-servers)
Depends on what kind of web application you're looking to develop.
probably. sorry.
Correct me if I'm wrong, but you should know those "tricks", especially if you use python for more than a month and of course read the docs at least once.
The quickest way to check if everything works as it should is to run `iptest`. Report failures to [the bug tracker](https://github.com/ipython/ipython/issues)
Personally I try to write code that could be understood by a junior programmer. If you have to have advanced knowledge of the language or need to think very hard about what the line is doing, I think you are doing it wrong. The clearer method may be slower, not as cool, or concise but it will be understood by all. In the corporate world you are always picking up other peoples work or they are working on yours. Readability is more important than using the cool parts of the language. For example you can have an else on a for loop, I know this but most would be confused and would have to look it up or they would just rewrite it.
Pretty awesome work. Any interest on teaming up to integrate this into isort? This would make it instantly available on several other editors in addition to Sublime (vim, emacs, and kate). Look here and tell me what you think https://github.com/timothycrosley/isort - would love to work with you on this Thanks, ~Tim
 there is a video ? How to watch it in lynx?
&gt; 1.3 Extended unpacking (Python 3 only) WTF at that example? That's some of the nastiest shit I've seen, Python or other languages :| Naming slices looks kinda neat, could be useful for 'self-documenting' code instead of explaining the slice in a comment.
I assume that you're referring to the variable names used ('b' implying that it's of the same type as a or c). The Python manual uses the much clearer `first, *rest, last'. Usually it's used in the two-term way, not the three-or-more-term way, though (that is, to take the first item in a sequence and ignore/group the rest, or to take the last item in a sequence and..)
great, thanks! Now for the unveiling of a bigger problem that this one was nested in, I am trying to use regular expression to get the list data out of this string: I am treating Bitcoin as a variable also, name = "Bitcoin" $.plot($("#Bitcoin"), [{data:[[1393721761000.0, 7062241080.5], [1393732561000.0, 7039424713.499999], [1394221562000.0, 7787331316.0], [1394232362000.0, 7852616504.999999], [1394243162000.0, 7906420140.000001], [1394253975000.0, 7714592159.999999], [1394264764000.0, 7768083110.499999], [1394275562000.0, 7789530474.0], [1394286361000.0, 7729975896.5], [1394297162000.0, 7572296536.499999], [1394307961000.0, 7621638248.0], [1394318762000.0, 7718537995.5]]}], { xaxis: { mode: "time", ticks: false}, yaxis : {tickDecimals: 0, ticks: false}}); I figure I need to use regular expression, but I don't know how, I can't just select a portion of the list with [:] since it needs to be universal for different lengths and names. As you might have guessed I'm gathering data in html with beatiful soup, but it doesn't know how to handle this line.
uhm is that json data actually?
I like your definately bot. Check out mine :) Source code in bot comments
ImprovedGrammarBot has detected a misspelling or incorrect use of grammar. You wrote - **definately** which should have been **definitely** Comments with a negative score will be deleted. The author may reply with +/u/ImprovedGrammarBot -delete to remove this post and -ignore to be placed on the ignore list. [Message](http://www.reddit.com/message/compose/?to=no_downvotes_allowed) | [Code](http://1drv.ms/1fgEuex) | [Logs](http://1drv.ms/1fgEtY9) | [Hate Mail](http://1drv.ms/1fgEtr4) 
It could be, I'm entirely unfamiliar with html code and json, but i've heard of it. The code is located at: http://coinmarketcap.com/ 
Wow did that really just happen?
Haha if that wasn't on purpose that's hilarious
What is nasty about that? It was clear and immediately obvious to me.
Hehe. If the isort integration proceeds...
Sounds good to me. I'll let you know once I've pushed the package up to PyPi. You can see how the autoimporter works [here](https://github.com/alecthomas/SublimePythonImportMagic/blob/master/importmagic/importer.py#L263). Basically, for each unresolved symbol, we search the index for matches. Each match has an associated score and we pick the best one (though we could conceivably also prompt the user). From looking at isort, I think all you'd need to do is do the lookup and merge the result into your existing parsed imports. Shouldn't be too difficult.
Ok, I wanted to plot the data in python, so how should I gather the json data?
Wow just a quick overview of that code and I've learned a few things. I definitely have a long way to go before I'm making stuff like that. What's your background? Self-taught? CS major? 
the lines are very similar, you should be easyly able to take them appart
Could you list maybe the pros/cons or examples for each? I'm working on an assignment developing a web-app and am trying to decide on the correct platform. The app must allow students to submit questions in real time to a "teacher" (like a chatroom), and the teacher to poll the class. 
The problem with doing something like this in Python, is that it immediately breaks down when you try to express something like a list of integers or a list of two element tuples consisting of an int and a list of Foo classes where Foo again is polymorphic like a list. Another problem is that you can't really check against interfaces/traits/type classes... As soon as you want to do anything useful Python lacks the means to express the types. Even if you could express types to a useful degree, you can't check them. Does that file-like object return unicode or byte strings? Does this iterable yield integers? These are questions you can't answer without potentially changing the state of an object or even performing IO. If you want static types, use a language that provides ways of dealing with them like Haskell.
Assuming that what you want is a minimal framework. The question you should ask is how much you'll have to code in order to get a feature-complete site, versus what would already be integrated in a heavier framework. The tradeoff is that the minimal frameworks give more flexibility, but the heavier frameworks already have things that you will probably care about by the time you deploy (authentication layer, cross-site scripting protection, etc). 
The techniques will work with any modern python, subject to the usual minor syntax variations, except where explicitly stated. If in doubt about a particular one, you can fire up a python interpreter and try it out yourself.
import json D=json.loads("string here")
then my best guess it is a problem in routing at my end . i will try the ip address
Personally I would recommend using Django. It has a great community and on the jobs front it is the most in demand so it will be a nice addition to your resume for the future. Plus it is really enjoyable developing using Django. Have fun!
For future reference; [http://www.downforeveryoneorjustme.com/Docs.python.org]
thank you for the advice ill keep it in mind. you are right never got something really big with flask. i studied a bit on blueprints but never used them yet. 
I don't understand why c becomes 5, and b gets the middle three list elements.
Thank you, that makes more sense. So what happens with a four way term? Which items are considered the rest? i.e. if I saw: a, *b, c, d = [1, 2, 3, 4, 5] I would have no idea what b would contain (and I don't think most people reading the code would either?)
That was fast. 3.3.4 was just released... Any particular reason?
Don't know if this is up your street but I find the practical projects quite interesting. Stuff like using pandas to analyse a data set or solving a puzzle or something. This probably hasn't narrowed it down much!
Huh. Thanks for that!
For future posts, for stuff like this can we agree to link the release notes rather than the downloads? Better to stir up discussion.
Thanks for the reply. What I'm really after are **unmet needs** in the community.
I don't think there's enough of those things so I would say it is an "**unmet need**". There have already been umpteen decorator tutorials and the so I think it's extremely difficult to break completely new ground.
There was an important regression in zipimports in 3.3.4. I think that's why 3.3.5 was released so fast.
This [zipimport regression](http://bugs.python.org/issue20621) seems to have been one motivating bugfix.
If something like pandas has a big enough audience, I'll consider it. I've not personally used it. However I could see some potential integration of pandas with a data visualization library like D3.js.
b is a variable length expansion. It will be filled with whatever fits after the other variables are satisfied. In this example: [2, 3] Are you familiar with regex? It works similarly to the way * works there. The * indicates "match any number of elements between 0 and infinity". The difference is that it is non-greedy, and makes sure the other variables are filled first before it takes up the remainder. a is the first element, b is (if possible) any number of elements from 0 to whatever that haven't been placed into the other variables, c and d are the last two elements. In your example, the outcomes of various expansions would be: a, *b, c, d = [1, 2] Error, not enough elements to fill a, c, and d a, *b, c, d = [1, 2, 3] a, c, d are 1, 2, and 3. b is [] because 0 elements is still a valid match. a, *b, c, d = [1, 2, 3, 4] a, c, d are 1, 3, 4. b is [2] because * means a list even for 1 element a, *b, c, d = [1, 2, 3, 4, 5] a, c, d are 1, 4, 5 b is [2, 3] a, *b, c, d = [1, 2, 3, 4, 5, 6] a, c, d are 1, 5, 6 b is [2, 3, 4] And so on. Does that make it clearer? 
For small projects, MVP's and proof of concept work, I strongly recommend flask. It takes only a few minutes to get started with, has great documentation and a strong community. In my opinion, it's biggest weakness is the lack of good user-authentication package. For large projects and employability look into Django.
&gt;&gt;CheckIO &gt;Never heard of it before. Thanks I'll check it out http://instantostrich.com/ ^so ^many ^layers
I think the best blog posts are the ones that demonstrate how to accomplish real-world tasks. A great example of that is Miguel Griberg's flask mega tutorial. Given your site's focus on e-commerce, I think something on marketing/e-commerce analytics with Pandas/sci-kit/ggplot2/etc would be well received. Examples that pulled together web-analytics (GA), sentiment analysis (twitter) and some customer clustering would be well received. Here is a link to the mega tutorial as a reference: http://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world
Your best bet is Real Python (http://www.realpython.com/). There's also a list of other great resources on Hitchhiker's Guide to Python (http://docs.python-guide.org/en/latest/intro/learning/).
Few months back I was glad to find that Python comes with sqlite3 and was able to put to use as embedded DB and built exe with pyinstaller
Really? It's a basic tutorial about SQLite. I can't think of a single reason to use CouchDB to teach people how to use SQLite. If you mean to say that people should only ever use no-sql databases, that's just foolish. Sometimes a relational database is the right tool for the job, regardless of what hackernews might say. Is this one of those times? Of course it is. It's a tutorial on how to use SQLite.
Basically your choice is between Django, which is well-integrated, comes with a lot of stuff, and other frameworks which require you to assemble it all by hand. Pyramid is a bunch of stuff pre-assembled, which aims to give you the benefits of both (and its users generally seem to consider it successful in that respect). I don't really see the benefit of the minimal frameworks, so I use Django. Twisted/Tornado target real time/fast/async applications. That's not a space where Django works well. In fact, Django's biggest (and really only) weakness is its ability to directly support websockets. Even if you use Django, you'll want to use something else with it if you're working with websockets; that's not hard, django integrates very will with other things and plays nicely alongside them.
Id be interested in some best practices concerning classes. When to use class attributes, when to use @property, naming of methods, when to use a file with stateless methods instead of a class et cetera.
Or Web2Py
The unordered list in the example is actually an ordered list. Apart from that - great job, thanks!
[PyPI package](https://pypi.python.org/pypi/reckless) and [execute.py](https://gist.github.com/barneygale/9453761) for the curious. All credit to /u/edk141
Any comments, feedback or code review welcome.
Have always found http://rst.ninjs.org/ extremely handy as well.
I've never been a fan of the LCTHW books. As someone who has used Python for many years, I must say that I would have been very turned off by the drill approach to learning how to program. I'm sure there may be those that disagree with me, but I don't find these books to be particularly useful. If you are looking for a book, try reading "How to Think Like a Computer Scientist". You can get it free at http://www.greenteapress.com/thinkpython/. It takes a fairly straight-forward approach to teaching you how to actually think about coding in a non-language-specific way. Rather than simply regurgitating code you don't really understand over and over, it will help you build a firm understanding that you can draw on whenever you want. It also has exercises at the end of every chapter. However, with all that said, I would strongly suggest thinking of things you want to create and then go attempt to create them. Books can be a good supplement, but can't really replace actual programming experience. Start writing code, then write more code, and make sure to save all of it. 
don't do this... &gt;&gt;&gt; zip(m.values(), m.keys()) [(1, 'a'), (3, 'c'), (2, 'b'), (4, 'd')] it's wrong. use m.iteritems() or m.items()
That's exactly the sort of guidance I was after. Miguel's flask tutorial is indeed excellent, as will be his forthcoming book on Flask. Thanks for taking the time to look into my background as well. Maybe a contrived example of munging raw GA data with pandas and a D3.js could be very effective.
Ones that I have found helpful are: [http://inventwithpython.com/](http://inventwithpython.com/), which covers python and pygame (a lot of copying code, but a lot of explanations as well). [(http://www.diveintopython.net/](http://www.diveintopython.net/) (for python 2.x) and its [python 3.x counterpart](http://getpython3.com/diveintopython3/) I have also found these sites to be helpful: [http://www.pythonchallenge.com/](http://www.pythonchallenge.com/) [http://projecteuler.net/](http://projecteuler.net/) (400+ challenge problems) 
Flask is relatively simple to deploy with WSGI, the documentation is over [here](http://flask.pocoo.org/docs/deploying/) I use Apache but you can really use anything that supports WSGI 
Maybe it's time I finally learn Python. Would definitely make sense to learn Python3, right?
Yes. Although they're very similar anyways, you're best off starting with the latest. 
Well, it worked for me. The book introduces one concept at a time, keeps the difficulty slowly increasing and explains the key concepts. I had written a lot of code with the knowledge gained from it. At the point where I am, however, the book goes into concepts that I don't need at the moment. Right now I would like to learn classes, I will return to automated testing later. Thank you for the link, it looks very promising.
Thank you for the links. Especially the Hitchhiker's Guide. Super useful.
I don't think I need this stuff at the moment. Especially as the scope of my projects is usually a single file with 200 lines at most. I would like to learn about classes, then return to automated testing when I reach the point where I need it.
here are the release notes for the lazy http://docs.python.org/3.3/whatsnew/changelog.html
+1 Flask is very easy to deploy. I use uwsgi and it's a breeze to set up behind nginx.
Yeh, I've seen that ... but this is /r/Python.
Thank you for the links.
Also, Python can parse a subset of JavaScript literals with the [json](http://docs.python.org/2.7/library/json.html) module. It's handy.
To add to that, I looked into CherryPy, and when I was getting started up, it seemed that the community/documentation just could not compete versus Django or Flask. To me, CherryPy seems like a better Flask, but I ran into some pretty basic issues (surely my own ignorance). I would prefer the better product to win, but practically beats purity, so if you were going to the micro route, I'd definitely advocate Flask before Cherrpy.
The CheckIO people need to work on usability. Go to the site and it immediately asks me to create an account/login. No explanation of what they do, nor why I should even bother.
Any of the micro-frameworks I've used (Flask, bottle, web2py…) have been a breeze to deploy (usually behind nginx and uwsgi for me, but anything else goes).
&gt;Would definitely make sense to learn Python3, right? If you're new to programming it doesn't really matter. If you're already somewhat familiar with the language and general programming concepts go with python 3 - start with official tutorial. Also if you need more learning resources check out /r/learnpython wiki @ /r/learnpython/w/index
For a good Python IDE I highly recommend PyCharm. I've worked with or evaluated every Python IDE out there and in my opinion PyCharm is the best by far. It also works extraordinarily well on OSX, Linux and Windows. As for the rest, my experience has taught me that the most important thing is to be organized. It's very easy to try various things and bring your system into a jumbled state where it is difficult to know what is happening. Try to clean everything up and start fresh. Then try something, and if it doesn't work, go back to a clean slate and only then try something else. I use OSX 10.8 so I'm not sure if anything significant has changed in 10.9. Still, I have installed various different versions of Python via Homebrew and everything works as expected. Can you be more specific about the trouble you're having? What output do you get when you run "which python" and "which python3"? How about "dir /usr/local/bin/python*" (assuming you're having Homebrew install binaries to /usr/local/bin)?
I agree. I enjoy cherrypy for json/api backends, but the documentation is lacking and it requires your own boilerplate code.
~~I didn't upload it for some reason, but somewhere I have an improved version which bakes a proxy environment for the shell (and adds a retry option, which I think is missing from this one). I'll see if I can find and upload it.~~ edit: it is done.
Learning, sure. But if you're planning on making something, there's a good chance there's a library you'll want to use that isn't available on Python3.
Good point. I guess if I ever change the file I can just restart the service.
Ah, gotcha. I had the terms mixed up. Thanks!
Oh cool, I didn't know this existed. I was using [rest renderer](http://www.tele3.cz/jbar/rest/rest.html). 
Yeah I've noticed that too. Lots of those projects are being ported over though. Is the difference between them that much?
Or go nuts and give links to both the dls and changelog. A lot of us will end up on both of those pages anyway.
homebrew and then virtualenv -p /usr/local/bin/python&lt;whatever-version&gt; [leave maverics python alone!!!!](http://youtu.be/kHmvkRoEowc)
all of the wsgi ones. 
Just use 2.7 and Vim.
JM1234 is right. Using Python 3 on an important project would be risky. One day you find you need a package but it's still only in Python 2. If there's no decent alternative, you'll have to write all that code yourself (or hack the Python 2 version to work with 3). If you're still learning, that's a pain. If you're using Python at work, your boss still wants the code done yesterday. The ["Wall of Superpowers"](http://python3wos.appspot.com/) site lists packages that don't support Python 3 yet. The situation is much improved from the early days (when the site was called the Wall of Shame). Note that this is not an exhaustive list, just a list of packages on PyPI. That said, because Python 3 package support is so much improved, I've started doing some non-toy projects in Python 3. But I'd still be reluctant using it on the job.
Can't get easier than heroku and django
Really? Can anything be easier than [ONE CLICK DEPLOY](https://www.pythonanywhere.com/try-web2py)? It is based on WSGI as any other half decent python web framework. But in addition... For any other combination of web server/os we have deploy scrips: https://github.com/web2py/web2py/blob/master/scripts/setup-web2py-fedora-ami.sh https://github.com/web2py/web2py/blob/master/scripts/setup-web2py-fedora.sh https://github.com/web2py/web2py/blob/master/scripts/setup-web2py-heroku.sh https://github.com/web2py/web2py/blob/master/scripts/setup-web2py-nginx-uwsgi-centos64.sh https://github.com/web2py/web2py/blob/master/scripts/setup-web2py-nginx-uwsgi-on-centos.sh https://github.com/web2py/web2py/blob/master/scripts/setup-web2py-nginx-uwsgi-opensuse.sh https://github.com/web2py/web2py/blob/master/scripts/setup-web2py-nginx-uwsgi-ubuntu.sh https://github.com/web2py/web2py/blob/master/scripts/setup-web2py-ubuntu.sh For any python web server we have a startup script: http://web2py.com/books/default/chapter/29/13/deployment-recipes#anyserver-py 
I agree but notice that web2py comes with a [script](https://github.com/web2py/web2py/blob/master/scripts/make_min_web2py.py) that strips it down and makes it smaller than Flask+SQLAlchemy.
The biggest overall difference is that python 3 doesn't let you play fast and loose with unicode.
Doesn't bother me. I'm used to that already lol
Not in the case of web2py. Web2py apps have no configuration, no compilation, and database migrations are automatic.
I can recommend the free book [*A Byte of Python*](http://swaroopch.com/notes/python/).
As others have said try to clean up your environment as much as possible before continuing on (make sure to follow homebrew's or other's uninstall instructions in case they have configured something on the system level that can't just be deleted). I personally use macports on Mavericks, but homebrew should be fine. You need to keep track of what is in your .bash_profile/.bashrc and what your PYTHONPATH and PATH environment variables look like. Make sure that when you are running "python" or "easy_install" or "pip" or really any executable that you know which one you are running. A command that can help with that is "which &lt;exec&gt;", this will tell you which one you are running. From the python interpreter you can run `import sys` followed by `print sys.path` to find out where it's looking for modules. Also you can import a module and find out where it is installed by running `import &lt;mod&gt;` followed by `print mod.__file__`. As others have said, don't mess with the system python. I would stick with macports or homebrew (it's worked for many others so you know it's possible). Good luck.
I posted there as well. If you have any advice please 
+/u/dogetipbot 20 doge As a beginner in JavaScript, any good resources you suggest for specifically learning those three things?
I'm not worried about writing 2-3 compatible code. I'm worried about the 3rd-party packages that still aren't converted.
It's actually fairly clear by deduction. The part with * is the sequence part (the 'rest'), all other parts are scalar. There is never more than one 'rest' (eg. `a, *b, c, *d = [1, 2, 3, 4, 5]` will raise a SyntaxError) That means that for a, *b, c, d = [1, 2, 3, 4, 5] * a = 1 * c = 4 * d = 5 * therefore * b = [2, 3] another example would be a, b, c, *d = [1, 2, 3, 4, 5] * a = 1 * b = 2 * c = 3 * therefore * d = [4,5]
Is he using IPython? IPython is an interesting approach to Python and is very popular in the research communities. Of course regular Python is pretty big there too. As to your earlier question, learn Python 3. It is the way forward. 
yes, if you have to use a library that doesn't support python 3 yet, for instance twisted. you can check which libraries support it here: http://py3readiness.org/ Personally I think 3 makes a lot of improvements to the language, libraries just need to make the switch.
Check out [Anaconda](http://continuum.io/downloads) It installs python and a bunch of packages in a separate folder. It also comes with Spyder which is a simple IDE that I like to use. There's also Miniconda which doesn't come with any packages and you can manually install packages that you need.
If you're just farting around with Python, use Python 3. If, like me, you work for a very large organization who has centered their use of Python on Python 2 (2.6 to be specific), you don't have a choice. Use whatever's comfortable, honestly.
While I like Python 3, aren't most of the tutorials for beginners still using Python 2? That would be a pretty significant reason not to start there...
Thanks. Think you could make the dataset available somewhere as well? I can't wait to read the code, but I feel like re-scraping all of it is sort of silly if you already did it. 
I have had great luck using homebrew to install python and then using pip to install any modules I need. 
2.6 is old even for a large organization.
I'm still on java 5. That was released 4 years before 2.6. 
This is really cool. Thanks! I'd be interested in using this (and of course helping out in any way I can). I'd be happy to add documentation, as it will help me understand each piece anyway. Have you thought about other things you'd like this to include?
I want to go!!!!
And i still use 2.7 :( ^I ^hate ^syntax ^changes .
There are plenty of Python 3 tutorials out there. Besides, the syntax differences are minor enough that someone with programming experience shouldn't have any issue using a tutorial from a different version.
Well, that's a terrible name.
Sorry for the late reply. I replied yesterday on my bot account but it got automatically deleted from being down voted. Similar to yourself, I am also a first year CS Major (mostly familiar with Java and C++). I just recently migrated the project to github so feel free to have a [look](https://github.com/gabrielxh/ImprovedGrammarBot) Today I finished implementing multi threading to make it more efficient, and I'm testing it now to see how it goes. Anyways, let me know if you have any questions and I will help you if I can :)
Besides Twisted is there really any significant library that does not work in 3?
Thanks. Looking at it now.
Regular Python. OK, thanks.
When I run "which python" and "which python3," I get /usr/local/bin/python and /usr/local/bin/python3. When I actually go into /usr/local/bin, I see all [this](http://i.imgur.com/cYKLxoh.png). It just looks like way too many things are there and I don't know how to go about cleaning it up. I also have two folders in my Applications folder named Python 2.7 and Python 3.3, each with an IDLE and Python Launcher. What's the best way to start fresh?
&gt; Pretty much all significant libraries were ported to Python 3. There are plenty of good packages/tools that aren't supported: wx, OpenMDAO, paramiko, Twisted, vtk, PyPy Upgrading for the sake of upgrading, especially when it requires replacing existing, working code doesn't cut costs.
That looks about right. You have both 2.7 and 3.3 installed. I have the exact same listing on my MacBook running Mavericks. Also have to second the recommendation for PyCharm. 
I learned Python in 2011, back then it seemed the consensus was to stick with 2 unless you had a reason to use 3, I would say nowadays it's better to start with 3.
Could be RHEL or centOS that is behind that, they are both still on 2.6 :(
There's at least a PyPy Python3 beta. &gt;Upgrading for the sake of upgrading You're going to have to upgrade eventually and the longer you wait the higher the cost. 
It _has_ been 5 years since python 3 was released, after all... :)
I think this is what I need for work!
If you want your code to run on OS X out of the box. If you work with strings of indeterminate encoding.
Great Site for Coders
Yes, it's a bonus release candidate. There were a dozen checkins to fix regressions after rc2, so we added this to the schedule. Please test with it! 3.4.0 final *should* come out in a week, assuming nothing explodes between now and then.
&gt; There's at least a PyPy Python3 beta. That's not good enough. I'm not their beta tester. &gt; You're going to have to upgrade eventually and the longer you wait the higher the cost. How so? Staying current with package versions mitigates much of that issue. At my company, we keep my numpy, scipy, matplotlib, vtk, wx, OpenMDAO, etc. up to date. If the API is deprecated, we switch to something else. When Python 2.7 broke compatibility with float(2.0D+03) # same as 2.0E+03 without mentioning it in the release notes, we changed the way the reader worked. Libraries that support python 2 and 3, use the same API, so theoretically switching (assuming all the libraries work), is relatively painless. I run an open source library and at great frustration support Python 3 for the 20% of people that use it. There are some stupid, largely unmentioned changes to the API that have slowly been fixed in Python 3.1, 3.2, and 3.3 and made compatibility (as well as memory management) much more difficult. I know how to code in way that's reasonably compatible with Python 3, so it's not like I'm making stupid mistakes like float/integer division or double type dictionary sorting (string &amp; int keys). When you're highly dependent on a well-respected tool like VTK, yeah I guess I could use an inferior tool (OpenGL) as well as replace wx with PyQt or PySide, but what does that really buy me? I honestly couldn't care less about unicode. I don't do web programming and none of our customers want web-based tools, so again, what's the rush? Python 2.7 is going to be around for another 5 years. Guido is totally fine with it and I'm pretty sure, the day it's not supported anymore, we'll decide to switch.
Cool, but not as cool as https://github.com/ajalt/fuckitpy
If you're complete beginner choose whatever version the tutorial you're following is using. It doesn't matter if it's 2.7 or 3.3. If you're already familiar with programming I don't see a reason to start with 2.x - just go over official tutorial to familiarize yourself with the language.
i wouldn’t call it a good chance. twisted is the only big thing that comes to mind.
nobody argued for “upgrading for the sake of it”, and your list is both small and flawed: 1. wx has powerful and much more popular alternatives, PyQt, PyGTK, and (although that one’s not bigger) Kivy 2. never heard of OpenMDAO and vtk. granted, that’s only anecdotal evidence. 3. PyPy is no library, it’s another python implementation. and less compatible than python3 (numpy support isn’t ready, many other CPython extensions missing) so the only things that are libraries, missing, big, and without better alternatives are Twisted and Paramiko, both of which are in the process of being ported to python 3.
Be careful that the package you install with pip are not linked to a conda environment. EDIT: Forget that; I just found that I need to install pip in the new environment also. The trap is that if I don't do it, the pip command still work, but update the main environment.
Awesome. IMO, what would be even cooler is to have the ReST and the rendered content side by side.
I don't see any python (yet). Navigation menu has CMS, CSS, HTML, IT, JavaScript, MySQL, PHP, TV Channel, WordPress but no python. Searched "python", got no results.
Even Redhat are advocating people switch to python 3, so I think after 7 years its more than time. If a library like twisted still hasn't moved, they're 7 years too late - dump it for a library which is actually supported by a python from this decade or you're just going to find yourself in all kinds of trouble - if they're that lazy, the rest of the code can't be any good. 
What I mean is that if I install a package with pip, I will not have access to it in a conda environment, even if you install it from the environment. Maybe there a way, but I didn't find it by just googling 'conda pip'. EDIT: Forget that; I just found that I need to install pip in the new environment also. The trap is that if I don't do it, the pip command still work, but for the main environment.
Big project =&gt; Django Content heavy/CMS-like =&gt; Django Total beginner =&gt; Django Location-based Services =&gt; GeoDjango Small project =&gt; Flask API-only =&gt; Flask Need for heavy customization =&gt; Flask
The terms of use on MasseyRatings.com strictly prohibit recreating the datasets- what I'm doing is simply providing a link structure to download and use all of the datasets. Luckily since you only need to visit 2 sites for one year's data (the team index and the game list), scraping all 14 years of data available takes only a minute or two.
Hey pswami- Like I said in my post, I work on embedded software so the world of scraping and using this much data is still a bit foreign to me. Give it a try and see if anything feels like it is missing or could be more pythonic, and if you add anything submit a pull request and I'll merge it in for sure. Thanks for checking it out!
Well, Doug Crockford has written a lot of useful stuff on the topic. But he's also written a lot of stuff that can be counterproductive; he's been struggling for years to get JS programming right, and much of what he wrote documents this process. It's still good reading, but not everything he wrote should be followed to the letter. Other than that, I'm not sure - I certainly read a few really good things, but unfortunately, I can't remember what they were. And I read a saddening amount of highly confusing material, so I'm afraid I don't have a decent answer for you there.
Depends on the area you're working in. I've used Python 3 pretty much exclusively for ages now, and there are no libraries I've missed (or been unable to find perfectly acceptable alternatives for). For someone *learning* Python in relative isolation, they won't be locked into particular libraries that may not be ported to Python 3 yet. If you're working closely with others that already use Python, use the version they use (obviously!). If you're coming from many other languages, Python has so many more libraries available than you're used to that the odd one not yet ported will be irrelevant to you :-)
If you install pip inside of that conda environment, and then use that copy of pip (use the full path to the pip executable), then anything you install with that pip will be part of that environment, and will show up when you do a conda list of packages installed.
depends. A simple crud application, then use flask. if you are going to share data between apps, then django. 
I believe BAML, JPM and GS choose scripting languages over compiled languages for shuffling data around and convert it to different formats since it very flexible and fast to change. Never mind that GS is suing the chaps that left GS allegedly for bringing prop knowledge with them. The analytic for calculating PnL and risks of the products will still be written in C++ by quants.
Ah, I do remember hearing good things about *JavaScript: The Good Parts*. I'll have to check it out now. Thanks!
I would definitely think python or R would be great languages for this task. I wouldn't mind looking more into this task if you want though and point you in the right direction with how to go about it as well. 
Hi, my name's Taka and I'm the lead developer of [Awasu](http://awasu.com), an extensible RSS feed reader. It's very easy to write plugins for Awasu that extract data from a variety of different sources, including scraped web pages, and feeding them into Awasu. There is already a plugin that does this, although we have a better version privately available. We are also working on a GUI-based plugin that lets you use the mouse to select parts of a web page you're interested in and generate a feed from that. Once the feeds have been generated, you can either just monitor them within Awasu, which also has features for analyzing content as it comes in, then generating reports, sending out emails, updating web pages. Alternatively, we have previously built several systems that forward the content on to MySQL or SQL Server databases for larger-scale analysis, searching, etc. Some of these systems are monitoring tens of thousands of channels (including scraped web pages, email newsletters, web services), so 200+ will be no problem at all. And yes, we do most of the plugin work in Python :-) 
Arch Linux users, get it from the AUR: https://aur.archlinux.org/packages/python34/
Regarding the hiring just write this on the [scrapy mailing list](http://groups.google.com/group/scrapy-users) and you will find a lot of people interested in doing it for you. Although they may require some money. [Scrapy](http://scrapy.org/) is a high level scraping library for Python. I have myself used it to scrap data from 1000+ pages. It will be the most reliable solution for you as far as I know.
Great, thank you!
I'm having a similar experience with cherrypy. Documentation and community examples just aren't there. Otherwise I'm really enjoying the minimalistic approach, I've just had to problem solve by inventing my own solutions rather than using stack overflow. 
&gt; wx has powerful and much more popular alternatives I'll agree I like PyQt better, but they're so close, it's just overhead to switch. They can do the same things. &gt; never heard of OpenMDAO OpenMDAO is a tool for linking up engineering analyses. Basically you draw block diagrams to aide in distributed computing and optimization. It's developed by NASA and interfacing with it is a major requirement. http://openmdao.org/ &gt; VTK is a 3D visualization tool and is incredibly powerful. It's not getting replaced. &gt; PyPy is no library, I know, but it is a valid reason to stay on Python 2 if you need it. I didn't spend the 10 seconds trying to make it clearer. &gt; both of which are in the process of being ported to python 3. I know, but until then... I want to upgrade. I don't like coding for two versions of Python, but it's not yet feasible to upgrade for my company or most of my open source users. Maybe I'm just bad at coding (I'm an aerospace engineer), but writing compatible 2/3 code is not as robust as having a little script that converts it to Python 3. It's some issue with the different base of unicode vs bytes in Python 2 vs 3.
TIL miniconda What is the point with miniconda ?
[Very long YouTube video about web scraping](http://www.youtube.com/watch?v=52wxGESwQSA)
It creates a small environment to start with, you add what you need vs. the full Anaconda install which includes almost 200 packages. Allows you to use the conda tool to bootstrap and create new environments. Think of it as similar to virtualenv with more options.
Well that just made my life much easier
Take a look at puppet setup I have done for gunnery https://github.com/Eyjafjallajokull/gunnery, its manifests are more modular and easier to maintain :)
Very interesting project. Might be helpful for use in this: https://www.kaggle.com/c/march-machine-learning-mania/data I will also take a look and try to help with anything I can, still relatively new myself.
&gt;3.4.0 final should come out in a week, assuming nothing explodes between now and &gt;then. I consider Al Qaeda officially put on notice.
Try to have a look at http://lgiordani.github.io/blog/2014/03/05/oop-concepts-in-python-2-dot-x-part-1/, it's a blog post of mine where I try to dig inside the Python implementation of those concepts. I think the Python OOP system is rather rich and powerful, and thus very complex for newcomers. Feel free to comment the post if you find the stuff too obscure. =)
Thank you I will
Thank you, I will take a look at the wikibook
Hey, If you're still after somebody, drop me a message. Writing scrapers in Python is pretty much my day job. Infact I wrote an article about python scrapers on my blog yesterday. http://jakeaustwick.me/python-web-scraping-resource/ You can find my email within that article.
&gt; performance is incredibly slow when representing large ndarrays with 3D plots Define large. There's always a big enough problem that's going to break any optimizations you do. You can get a 10-100x speedup if you stop updating the axes object over and over again. You need to interface with some of the very poorly documented parts of the code. http://bastibe.de/2013-05-30-speeding-up-matplotlib.html &gt; smoothly zoom/rotate/etc. the figure? Zoom and rotate are very different problems. Zoom, you can definitely speed up easily. Rotate is harder for a large data set. I'd suggest looking into downsampling your data and changing the sampling rate when you zoom. Combine that with HDF5 and you can effectively handle GBs of data.
Hey Jake, I sent you an email. 
This article is significantly more advanced that the one linked, but is essential reading for anyone considering releasing a public package where decorators are used internally: http://blog.dscpl.com.au/2014/01/how-you-implemented-your-python.html
I don't know about the "best" language - that's highly subjective - but it's certainly capable of it and has a great toolset that is specifically intended for this sort of thing.
&gt; If you want your code to run on OS X out of the box. Why would you ever, under any circumstances, want your code to specifically run on Apple's compilation of Python? This is what virtual environments are for. &gt; If you work with strings of indeterminate encoding. There's no such thing as a "string of indeterminate encoding" - those are bytes ;) FWIW, I agree that grokking Python 3's string/bytes paradigm is much harder than I anticipated, and harder than perhaps it should be. There are even still some rough edges. That said, I think the end result is very much worth it.
The most commonly-used library of which I'm aware that isn't Python3-compatible is [boto](http://pypi.python.org/pypi/boto/) (An Amazon S3 wrapper). Unless something like this is holding you back, I say go with Python 3. It's trivial to step back down to Python 2.7 if you have to in the future - much easier than porting a Python 2.7 codebase to 3.x down the road.
It seems like a great idea but when I tried "django", it just processed forever and never got back to me.
I felt a bit unsure about sharing this, because I'm a relative beginner in Python (coming from Ruby), and I feel like I've invented a number of wheels here. On the other hand, I spent a lot of time searching for existing solutions, and in the end, what I came up with worked really well for me - so I thought I'd share both what I ended up doing, and my thought process in going through it - because this is exactly the kind of blog posts I like to read.
That's really cool. I literally had no idea what a Tree Structure was until you showed it to me. I was like, Double Dicts? Yeah I do that all the time! So useful.
Good idea and the search worked for me. I'd suggest adding "most searched" and "recent searches" widgets. 
not sure if you are aware of multiprocessing, just in case you didnt know http://docs.python.org/3/library/multiprocessing.html. Since you use popen to run python files it can be useful.
Local install is very appealing. This great blog post has me licking my lips. I definitely want to move over to this.
There is a link to grequests in the concurrency section, I'm going to write a whole section on it soon. grequests achieves async IO via gevent. I've never used defusedxml, I'm not sure it's required for HTML scraping?
You'll see that I experimented with the pool.map from multiprocessing and had issues (didn't get the speedup I wanted and hard to debug errors). How do you think it would have been better than popen for what I ended up doing?
plotly uploads your data to a server. just a heads-up because that’s not obvious and unacceptable for some.
Just reload the page, sometimes it just doesn't seem to work properly.
The program has the same problem I've encountered checking the compatibility. Some projects don't tag Python 3 or advertise it in some way. For example Flask-WTF is supposedly blocking my transition. But Flask-WTF is Python 3 compatible. Though the only way to know this is by going trough their changelog. I have a lot of those small plugin-like imports and I have no idea how many of those actually are compatible.
I have a lot of love for [Scrapy](http://scrapy.org/), which generally handles stuff like this pretty well: you need to specify a starting point and xpaths/css selectors to scrape/enqueue, and that's pretty much it -- there are a bunch lying around, but [here's one for crawling the AV Club](https://gist.github.com/jmduke/9474688) if you want an idea of how it's structured. Also, a simple trick that helped me reduce the amount of time I spend on scraping by an order of magnitude: `from lxml.cssselect import css_to_xpath`. (I come from a front-end background so crafting css selectors was way easier than xpath.) Another general thing about storing seen URLs: be very smart about how you do this, as sites tend to be reliably unreliable -- things like get params in URL can wreck a naive bloom filter.
How is the async package looking? I remember watching a Guido keynote on it a few months ago, and it still seemed a little young.
Yeah, I've looked into Scrapy previously. I replied to somebody who suggested it on HN here: https://news.ycombinator.com/item?id=7375740 I'll add a note about normalising URL's before inserting them into the set / bloom filter.
It got a huge flurry of work, right up until the bitter end. I'm not an expert in these matters but I gather Guido is quite pleased with it. For what it's worth, asyncio is considered "provisional", so they're allowed to make breaking changes to the API for 3.5. Just in case!
Thank you for that suggestion 
&gt; I literally had no idea what a Tree Structure was They're not sort of... self-explanatory?
Hey, thanks for the suggestion. Using download delay of 2 seconds made it work.
:) btw there used to be a 'conda pip' which just called pip, but they removed it as 6 superfluous characters adding to RSI for no reason. I can't tell you how many times I've been bitten by ignoring (or not showing) which venv is active. Luckily one of my build boxes is beefy so its not _too_ much hassle to recognise, resolve, and rebuild - but still makes one cranky at themselves for falling for it :) More or less everywhere now, my prompt will display an active venv and I'm also in the habit of typing "echo $PATH" before running build tools. Like other things in life, it pays to be aware of your surroundings. 
How? It means "lock (n)" in German.
haha. You mean a structure that looks like a tree? But what's the point ?
Nice write up! We've run into all the problems you mentioned at one time or another. Here, we're executing around 500 spiders continuously (via scrapy and some custom twisted services). 
 brew doctor would have asked you to run brew linkapps which is undone by brew unlinkapps however you should always run "brew linkapps" afterwards to ensure your existing links are setup fine. It just makes sure any .app directories (which is how OSX packages applications) are symlinked into /Applications so OSX can find them by default. Your default PATH will be defined in your shell startup files; I'm going to assume with your lack of familiarity you haven't changed this, so its 'bash'. man bash This will give you a whole ton of stuff on how bash works, including the names of the startup files and the order they are run in. Normally you just worry about your personal ones, so ~/.bash_profile and ~/.bashrc Environment variables should be set in ~/.bash_profile (which is executed once on login shells) - ~/.bashrc is run for every shell including non-login shells (don't ask, just believe for now) so the shorter that file is, the faster the shell will load. If you really want to blow your mind, man zshall and if you're keen, chsh -s /bin/zsh OSX comes with zsh by default (though since you have homebrew you can "brew install zsh" to get a newer one still). It makes bash users look like cavemen :) If you're going to spend time in the terminal on your Mac like this, I recommend you take some time to learn some basic UNIX stuff. The userspace in OSX is based on FreeBSD but (since POSIX is like this for this reason) any tutorial on FreeBSD or Linux for that matter will suffice. Many of the stdlib modules in Python are going to assume familiarity with POSIX compliant operating systems, so things like 'os' in particular will make more sense to you when you have the fundamentals. 
Yeah, a lot of the problems are pretty common. It's rare you get a straight forward scrape without something funky going on. Got anything else I can add in there? Sounds like you have a lot of experience. I'm planning on this article being a work-in-progress and adding to it regularly. Also out of interested, you mentioned "we". Can I ask who? Sounds like you're pretty involved in scraping.
Anything that's [hierarchical](http://docs.oracle.com/javase/7/docs/api/overview-tree.html) in [nature](http://docs.python.org/2/library/exceptions.html#exception-hierarchy) can be represented by a [tree](https://en.wikipedia.org/wiki/Tree_structure), for example pretty much [every bit of html in existence](https://en.wikipedia.org/wiki/Document_Object_Model). Then you can use them to [efficiently search for things in ordered lists](https://en.wikipedia.org/wiki/Binary_search_tree), [match strings](https://en.wikipedia.org/wiki/Prefix_tree), the popular [Btrfs](https://en.wikipedia.org/wiki/Btrfs) filesystem is literally constructed from a [B-Tree](https://en.wikipedia.org/wiki/B-tree), hence the name; and numerous other examples. So there's plenty of point to them! 
 def tree(): return defaultdict(tree) Cool, one line! Oh, wait, &gt; If you're following along at home, make sure to `from collections import defaultdict` HEY THAT'S TWO LINES
OP is a big fat phony. To be fair, it can still be done on one line: from collections import defaultdict; tree = lambda: defaultdict(tree)
In fairness, Exodus may not have done a data structures course yet. I know I hadn't when I first learned Python.
Semicolons are newlines in disguise.
This definitely looks production ready.
Because you're parsing HTML from random servers on the web someone could send you crafted XML that will kill your crawler
I also meant the new asyncio module specifically
i just do find/replace \n for ; Best python code!
You stole this content from "Twisted Network Programming Essentials" Take your stolen blogshit somewhere else.
To add to the nice list /user/ivosaurus provided, programming languages themselves are often (almost always?) parsed into ASTs, which are [abstract syntax trees](http://en.wikipedia.org/wiki/Abstract_syntax_tree) when being interpreted (run) or compiled (turned into runnable code). The [Lisp language](http://en.wikipedia.org/wiki/Lisp_%28programming_language%29) - created in 1958, and still going strong - is perhaps the closest language to an AST; you actually write your code in the shape of a tree, and it parses very easily because of this. In other words, instead of typing `foo = 4 * (3 + 5)` you would write something like `(defvar *x* (* 4 (+ 3 5))), which converts to the tree representation: defvar / \ *x* * |\ 4 + |\ 3 5 That looks just like the parentheses version, with the first thing in each set of parentheses - the function - being the node above its arguments in each case. The + function adds its 2 arguments, then the * uses the result as an argument along with 4, and then the defvar sets *x* (the asterisks just denote a global variable - it's just a convention) to that resolved value. In other words, this is how it solves: defvar / \ *x* * 1. |\ 4 + |\ 3 5 defvar / \ 2. *x* * |\ 4 8 defvar 3. / \ *x* 32 4. *x* == 32 When XML was invented, the Lisp crowd said it just looked like Lisp. They were right. You can convert a Lisp program into XML and back very easily. If you can convert another language to a tree, you can actually then translate it to Lisp (or another language expressible as a tree). Of course, the languages must match up in features, though you can write smart translators on top of the trees to make up for many of these differences.
I think you covered the basics very well. Not sure if it is useful for a general purpose introduction but you could mention in more detail how to handle feeds and APIs. We often combine feeds and APIs with scraping because the feeds are more reliable but the data from scraping is fresher. We also use ML models to infer certain fields. The reason being that the less we have to scrape the more reliable the spider and you can generalise models over different spiders to speed up development. You could also cover something like [scrapely](https://github.com/scrapy/scrapely) which uses 'item-based learning' to scrape via annotated templates instead of using explicit selectors. This is the technology behind many of the 'automatic' scraping services. The problems we deal with are mainly related the scraping at scale. For instance, network timing models; speed optimisations via asynchronicity; scheduling (how to optimise your scraper executions given your server resources to satisfy your scraping freshness requirements); how to detect when spiders are broken; how to fix them quickly etc. **EDIT** also not sure if you mentioned it but you could talk about how to use the browser to debug issues and how to generate css / xpath selectors
"Semicolooons" "Newlines in disguise"
&gt; Why would you ever, under any circumstances, want your code to specifically run on Apple's compilation of Python? This is what virtual environments are for. Because, exactly as I said, you're writing something that has to run out of the box. A plugin for an OS X app that uses the built-in Python. [Alfred 2](http://www.alfredapp.com/) for example. You'd have to be a proper fucking twat to write an Alfred workflow that required Python 3 or a virtual env without a *very* good reason. &gt; There's no such thing as a "string of indeterminate encoding" - those are bytes ;) Yeah, no they're not. Filenames? They're strings. Filenames in ZIP files? No encoding. But they're still strings. Sure, you can just extract them as-is to a Linux filesystem because its filepaths are bytes, even though they should be strings. Sure, Linux has a "filesystem encoding", but it's a recommendation and isn't enforced. You can extract a ZIP file with filepaths/-names that use a different encoding no problem on Linux. And Python 3 will silently ignore the files whose names it can't decode if you `os.listdir` with a Unicode path. At least Python 2 raises an error. HTTP also doesn't specify an encoding for URLs. They're strings, nevertheless. I admit, I've had a few difficulties adjusting mentally to the Python 3 model myself. But ultimately, I've run into the problems above that are 100% down to Python 3 being designed for a perfect world that actually doesn't exit, and makes working with such strings that much harder. What's worse, the "magic" Python 3 adds to hide the complexity of encoding is incomplete. It silently swallows errors trying to enumerate paths on the filesystem it can't decode, and doesn't even correctly normalise the paths it does: I can create a file from Python 3 with a Unicode filename (NFC-normalised—the Python default), but if I read that back from the filesystem (NFD-normalised on OS X), `filename_i_specified == filename_from_os` is not necessarily `True` because the value of the `filename` var gets munged during the round-trip via the filesystem. 
Something made of wood? Something with leaves?
There is a mechanism by which Numba could collaborate with the NumPyPy effort and that is in implementing NumPy-equivalent functionality on top of the memory-view data-structure. The purpose of the memory-view data-structure was to create a standard array object concept in Python itself. Add calculations to this data-structure and you have NumPy (both in CPython and PyPy). Numba and NumPyPy could work together on this *new version of NumPy* that could replace NumPy in Python 3 --- and still provide backward compatibility to the NumPy stack while also providing a way forward that the PyPy devs are excited about. 
I was informed on my blog post comments, that if the package you want is not available for conda, another option is to search binstar.org (make sure the package you find is built for the platform you are on), and then add that person's binstar channel with conda config --add channels binstar_username. (if you trust the user that is) - I think I'm going to stick to using pip. From experience... do a "conda install -n yourenvironment pip" before you do a "source activate yourenvironment" and then verify it's the correct pip using a "which pip" and it should point to the pip in your environment if all goes well.
I know you were asking about Code::Blocks, but I'm going to tell you to check out sublimetext.com anyway! Sorry for being *that* guy, but I think it is really really good, and you should try it! It has auto-completion and color-formatting for a lot of python names. Open .py files to see the colors and to use python auto-completion. (start typing and press tab). Press Ctrl+B to run your program.
I have a project that was specifically created with programmers like yourself in mind: http://jeffknupp.com/blog/2014/03/10/contribute-to-an-open-source-python-project-for-reviewing-open-source-python-projects/. The project is a simple site for reviewing open source Python projects. The git repo lives at www.github.com/jeffknupp/review. I know for a fact there are Issues that would take less than five minutes to "fix". Someone with basic Python knowledge could make quite an impact.
I think this is it: https://github.com/spillz/codeblocks-python It really wasn't easy to find!
No, I was just giving a quick and dirty example. For a production codebase, I would use something clearer and more concise like `tree = lambda: __import__('collections').defaultdict(tree)` I might also cache `defaultdict` for performance reasons: `tree = lambda dd=__import__('collections').defaultdict: dd(tree)`
contribute to an open source project using python that is math related and of interest to you.
I'll let someone else give a more thorough answer, but to at least solve your immediate problem: when you use an import statement, you don't type the file extension. So do `import hello` not `import hello.py`.
cd to where you've saved your file and then launch python. ~~import sys~~ ~~sys.path.append(*your current working directory)~~ import hello hello.hello("hello") Now, that's really NOT how I would do this. Not even close. In the real world I would never invoke a module directly that way. I'd make it a proper program I would do it like this: def hello(string): if string=="hello": print "world" hello("hello") Then, after saving the file as 'hello.py', I would run it like this: /path/to/your/python/install/bin/python hello.py I recommend you start with 'beginners guide to python', or one of the codeacadamy tutorials. they're great. EDIT: as pointed out by others, it's not necessary to alter the sys.path. 
Can you describe in words what you want this function to do?
...also, before you do anything else, you need to fix your python install. Post or IM me what the 'second command crash' is and we'll see if we can't fix you right up. Also post what flavour of Linux you're using. give me the output from the following: which python (it will return the path to your python binary) /path/to/that/python/binary/python -V EDIT: Removed the leading shell prompt from commands
Isn't a partial order sufficient as long as it's with respect to descendant/ancestor relations?
What would be the benefits, if any, of switching to Anaconda from Python (x, y) on Windows 7? That's what we use at work, and it seems to satisfy virtually all of our needs.
Ok sweet, I'll check it out :-)
Reckless is slightly insane, and potentially useful; fuckit.py is thoroughly insane and *should never ever be used for anything*.
I've said it before, I'll say it again: python = executable pseudocode. 
do you think it's really a good idea to tell newbies to change `sys.path`?
Oh man you should really pick one of the many python tutorial videos to see how it's done in action.
I recommend not using an IDE for Python. Just a good text editor with some useful configuration options (such as auto indentation, and using 4-space soft tabs) and syntax highlighting. Sublime Text is a great choice for this, though there are many good editors to choose from. 
Thanks for the detailed reply. I've actually used scrapely before, just not in a long time. I'll certainly add a note about it!
What version of python are you using? "x -= wallet" is not valid syntax for me (v2.7). I could be wrong there. If you're using python 3+, that may be different. Is your indenting correct? You have x being assigned within the "bet" function, but then modified outside that function. X does not exist outside of "bet()". I'm guessing you want the "x -= wallet" line indented so it's within the bet() function. You have "(either in or out of function)" text there. That's nonsense text. You should comment it (add # in front), or remove it. I'm guessing you copy/pasted this from somewhere else &amp; left it in. You're modifying "x" by subtracting wallet. Ex. the user wants to bet $10, so x = $10. Then you subtract wallet ($500) from their bet ($10) to get -$480. You probably want "wallet -= bet". You are modifying wallet within bet(). Wallet is a global. You probably want "global wallet" as the first line of bet(). Try those, see where you end up.
Yup. It's the dynamically typed Pascal of our era. 
I have no idea what he's talking about: &gt;&gt;&gt; x = 5 &gt;&gt;&gt; x -= 1 &gt;&gt;&gt; x 4 (Python 2.7.3) Also, you need int(x) because x is a string (sequence of symbols): &gt;&gt;&gt; x = raw_input() 5 &gt;&gt;&gt; x '5' &gt;&gt;&gt; type(x) &lt;type 'str'&gt; &gt;&gt;&gt; x = int(x) &gt;&gt;&gt; type(x) &lt;type 'int'&gt; &gt;&gt;&gt; x 5 But wallet is already an int (a number), so int(wallet) is pointless.
&gt;`sys.path.append(*your current working directory)` Python does that automatically.
If it's a partial order you may end up needing a forest. 
Just for future reference, the -= operator is just a shorter way of doing something to the variable on its left, and then assigning the new value back into that left hand variable. The "something" you're doing to it is whatever is to the right of the operator. For example, say you have two variables, a &amp; b, like so: a = 5 b = 3 The following two statements mean the same thing: a = a - b a -= b Either of those will yield the arithmetic: a = 5 - 3 a = 2 If you are still having some issues with it, just play around in the Python shell by assigning values to variables and trying things out. If you need to, double-check what's going on with a calculator.
variables have scope. That's where they live, what can see it/modify it, etc. A variable that's only within a function is a "local" variable. A variable that is accessible everywhere is a global one. a = 123 def func(): b = 123 print b print a #This fails, because "b" is only accessible within the function "func()" #print b So this: a = 123 def add(): a += 1 add() This fails, because a is defined outside add(), so can't be seen. If you want to see a within add(), do this: a = 123 def add(): global a a += 1 add() This works. Now you can see / modified "a" within add(), because you told add() that a is a global variable. 
For the same purpose, am trying to take a Matlab data matrix and make it ready for Python. I found the file below that uses classdef array, but it gives an error inside the method function at this line A = A@double(X); http://www.mathworks.com/matlabcentral/fileexchange/24087-display-python-formatted-arrays/content/array.m If anybody knows anything about this, it will be greatly appreciated. Thanks
On top of what /u/HilbertSeries says, you'd not often want to store, say, sets in a tree. This is because `a ≮ b` does not imply `a &gt; b`. Therefore, for example, an insertion into the tree can fail (silently) with typical algorithms. It's probably possible to work around with infinite branching and stricter checks, but then you lose most of the speed gains. Further, partial ordering can be really frail and a lot less nice than sets. (I have a feeling I've misunderstood you somewhere, though, so apologies if this misses the point.)
*&gt;Article about web scraping in python* *&gt;Doesn't mention any of the amazing frameworks specifically for it like Scrapy or Mechanize* Pretty shit article, son.
Thanks, I did not know the Guide
Use PIL https://pypi.python.org/pypi/PIL simply go from PIL import Image img = Image.open("foo.jpg") pixels = img.load() r,g,b = pixels[0,0] now you got the rgb value of pixel [0,0] (top-left) which you can compare to blue (0,0,255) But this would not bring anyting. Since you cant compare to a simple color value since the water is not always pure blue . It might be darker(0,0,100) or have reflections of the sun on it and look white or even the spray of the wave or some ship or whatnot. The thing is you could start to work with a gradient detection. For example find any fast changing colors. so you could determine where possible objects are. When you got these areas you could extract them into other images and try to detect objects by hand or let another program find forms in it. alternatively you could run a sobel-filter http://de.wikipedia.org/wiki/Sobel-Operator over it and see where some nonblack areas are. Just some fast ideas :) 
Since your home directory is apparently /Users/userid, are you sure you are actually running Linux?
TextWrangler is a Mac editor, so I'm guessing he's using the OS X Terminal application thinking it's "Linux".
I learned and started using that way, with just gedit and an interpreter. Would not recommend. An IDE will save you a LOT of time and effort. I do not personally know of a single professional developer that doesn't use an IDE or at least a highly customized, IDE like, VIM when it comes to python.
I initially wrote this because I was tired of littering other people’s code with prints and logging statements just to fix one bug or understand how something works (see aspectlib.debug.log). Of course, aspectlib has other applications (like mocking things in tests).
VIM is a text editor, not an IDE. Its functionally equivalent to Sublime Text, which is what I am recommending. 
&gt; Scrapy Scrapy more than anything if you want to crawl not just parse single page.
http://stackoverflow.com/questions/635483/what-is-the-best-way-to-implement-nested-dictionaries-in-python/7476491#7476491 Strewn throughout my code. 
Nice! I wrote a script last year to grab links for what i wanted from eztv and found that i had issues with shows with multiple options for quality (e.g. 720p and 1080p). Is there any differentiation for this in your API?
Hi ! No, there's not any differentiation yet but this is a good idea. Eg. While searching for the TV Show, you could add some options : options = {quality: '1080'} I will definitely think about it ;) 
Well, I meant as a general thing rather than practically. E.g. some set {a, b, c}, where a &gt; b and a &gt; c, but where b and c are incomparable, form a max heap a -b -c So inserting partially ordered data into a tree could fail like you stated, but if you had some immutable partially ordered data, it could still be represented in a tree.
yes it's the language for sketching apps that Paul Graham did not achieve with Arc.
That looks just fine, you shouldn't need to clean that up. Regarding starting afresh, others have posted detailed instructions here. I recommend following their advice!
For lines 3+4, you don't have to convert wallet to a string just to print it out. If you're using the +, it will attempt to concatenate, which requires two strings. print "Wallet:", wallet will print wallet as an int. 
for getting the data by parsing the log you can use this: https://github.com/jul/yahi
Yea, don't do that. If you can, make a heuristic: 1080p &gt; 720p &gt; 480p &gt; dvd, and while you're at it, you should probably add blacklists for stuff like screener, etc. I've implemented this myself in some code at home, it's much nicer :P
doh, you're right!
Not yet... it's a plugin for my media player: https://github.com/boxed/cmi so it's also a bit of code that's pretty useless if you're not running that.
I know that, that's just how i saw it I guess.
If your good at stats you can probably help me
No, it's correct to say the endpoint is omitted. It may be tempting to say "well no it's a zero-index issue", but the reality is regardless of the starting point, `range(x, y)` represents the integers on the half-open interval `[x, y)`. `range(1, 3)` returns `[1, 2]`, and the endpoint `3` is omitted. I find your usage of the word "faggot" to be immature and uncalled for.
Lambda can't be problematic for memory consumption. I was bitten once by this and it took along time to find.
If you're using python 3, the terminal command would be "python3" and the print will have to have parenthesis around the thing after it.
Looks like you might need to syncdb or migrate
I already synced. What does migrate do? This is the entire error message: https://snipt.net/Krytos/error-log/?key=81b9a562be629dcae0cb191e3df52cc1
&gt; The PyPy devs have no intention of wrapping all the external libraries themselves with cffi, that say scipy needs, but instead expects there will be others who will volunteer to do this work once it becomes clear that PyPy has clear advantages for applications using NumPy. What incentive is there to abandon the CPython ecosystem which already exists ( albeit in a imperfect state ) but which people can already use to solve their problems *today*. And invest hundreds if not thousands of man-hours of tedious work reimplementing the same functionality in top of PyPy for something that might pan in out in several years? I don't understand how the incentive structure for this can ever work. 
Hi, What books or material did you use to develop the algorithm? 
Strange not sure why using pool.map was slower for you. i'd say its easier to use something thats builtin less code and cleaner. how i'd debug it is use builtin map() for debugging and pool.map (probably starmap) when done. I guess the main advantage is to re-use the same 8 processes instead of re-creating
Hi, the research to build the algorithm is linked to from the "Whats this" section of the site. Let me know if anything is missing! (But it shouldn't its all there). As this is the one thing that is explained heavily on the site please read it there first. Happy to answer other questions regarding the rest of the site here though ofcourse!
As I wrote, part of it was that a bunch of the code couldn't be parallelized using a map (writing to file, transforming the Pandas Data.Frame etc), but I also think pool.map had a lot of overhead - there was a big difference in mapping over individual lines, vs. mapping over chunks of lines, for example.
Your operating system should have a way for you to schedule tasks. So, instead of writing a python script to run you python script, you can just use your operating system to schedule a task to run your python script every once in a while. Under linux, you will want to research "cron jobs". I think on windows it is called "task scheduler". 
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Cron**](http://en.wikipedia.org/wiki/Cron): [](#sfw) --- &gt;The software utility __cron__ is a time-based [job scheduler](http://en.wikipedia.org/wiki/Job_scheduler) in [Unix-like](http://en.wikipedia.org/wiki/Unix-like) computer [operating systems](http://en.wikipedia.org/wiki/Operating_system). People who set up and maintain software environments use cron to schedule jobs (commands or [shell scripts](http://en.wikipedia.org/wiki/Shell_script)) to run periodically at fixed times, dates, or intervals. It typically automates system maintenance or administration—though its general-purpose nature makes it useful for things like connecting to the [Internet](http://en.wikipedia.org/wiki/Internet) and downloading [email](http://en.wikipedia.org/wiki/Email) at regular intervals. The name *cron* comes from the Greek word for time, χρόνος [chronos](http://en.wikipedia.org/wiki/Chronos). &gt; --- ^Interesting: [^List ^of ^Teen ^Titans ^characters](http://en.wikipedia.org/wiki/List_of_Teen_Titans_characters) ^| [^Mêlée ^\(band)](http://en.wikipedia.org/wiki/M%C3%AAl%C3%A9e_\(band\)) ^| [^Chris ^Cron](http://en.wikipedia.org/wiki/Chris_Cron) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cg045mo) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cg045mo)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Added stackexchange and launchpad as two other options for login.
Dreamhost provides [a GUI for cron in their web panel](https://panel.dreamhost.com/index.cgi?tree=goodies.cron&amp;). 
I'll definitely check it out. Thank you.
The DreamHost server runs some distribution of linux. I know that on windows I can run a script, but my ultimate goal is to have it automated on the server. Is there any functionality like that for linux?
I'd suggest you start with the one that you've got to hand - 2.6 is likely to have all you'll be needing - especially as you will almost certainly grow to use it daily .. avoid the faddishness of "latest and greatest" (created by marketers for products they sell), and have a good technical reason for moving to a later version ...and by the time you've found such a reason, you'll be able to work easily with the comparatively small differences that come with newer versions.
I love you
You cannot import both into a conflicted, union namespace "foolib". You would need to add an __init__.py into foolib (both the top level one and the nested one). Within each project, you need to import foolib as "from . import foolib". Alternatively, in widget/__init__ you can add the widget/ directory itself into the beginning of sys.path, and then import foolib.
Well said and it makes sense.
2.7 is a great upgrade from 2.6.6. I'd recommend it.