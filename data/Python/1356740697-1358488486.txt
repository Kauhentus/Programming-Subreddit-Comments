The point about saying your function looked like C is that C is a much lower-level language than Python is. Python gives you tools and structure so that you don't have to work at the level that C generally has you working at. I was just observing that you weren't making use of any of that, and higher-level abstractions are baaasically the reason you should use Python in the first place. I mean, you certainly aren't going to use it because of the performance numbers. And I definitely agree that these functions and constructs can be used in such a way as they *are* unreadable. I also don't quite disagree with your comment about "join" being backwards. And for basic Python language or library reference, don't use google, just use Python's *excellent* [documentation](http://docs.python.org/2/tutorial/controlflow.html#lambda-forms).
Python exceptions are already a model of the Exception monad. Also, wtf does the NoneMonad do if an exception is thrown? Also, wtf is the .bind(log) bit doing? sendmessage returns an error message on failure and None on success? Really?
 &gt;&lt;}}}}*&gt; Frankly I think this looks more appetizing.
brevity is the soul of wit.
I know it's quick and easy to write straight to a file, but even for simple cases I'd suggest using a library. What if there's a comma in one of the fields or another ambiguous character like a quote?
I use [authbind](http://en.wikipedia.org/wiki/Authbind) and [twistd](http://twistedmatrix.com/documents/11.0.0/core/howto/basics.html) configured with [tac files](http://sprunge.us/GCEc) to provide direct access to my Python applications, it allows me to not run any application as root to access even low-level ports, it also means that I theoretically use less resources as I am just directly running the application. I also have [supervised](http://cr.yp.to/daemontools.html) starting the application so that it will automatically restart if it breaks.
I was not asking you. You are an asshole. Does belittling people make you feel like a big man? Yeah, fuck off, and eat a bag of dicks you fuckwit. And yet you ignored my reply to your post. Seriously, your level of dickheadedness is unfounded. 
There is a link to download the torrent file on TPB.
shit did i type reddit and get stackoverflow again
Read into [puppet](http://puppetlabs.com/puppet/puppet-open-source/), it may well do what you want. As an example, the following lines manage the ssh server on managed machines as per this definition, translate to your service as needed: package { 'openssh-server': ensure =&gt; installed, } file { '/etc/ssh/sshd_config': source =&gt; 'puppet:///modules/sshd/sshd_config', owner =&gt; 'root', group =&gt; 'root', mode =&gt; '640', notify =&gt; Service['sshd'], # sshd will restart whenever you edit this file. require =&gt; Package['openssh-server'], } service { 'sshd': ensure =&gt; running, enable =&gt; true, hasstatus =&gt; true, hasrestart =&gt; true, } 
Yes, you've actually hit on a very important point: *Abstractions always have cost.* That's not a criticism, per se--every line of code has cost. But when deciding whether or not to use an abstraction, one should figure out whether that abstraction provides enough value to overcome this cost. A concept's formality is irrelevant in the face of a particular implementation. 
&gt; 11 sloc 
Hi, Thanks for the note =). However, we actually already use Puppet, for configuration management, and setting up our boxes. What we want here is a bit different - querying and controlling our own custom processes - Puppet's not really suitable for this sort of thing. Typical use case, we'd run the command to check process status. Then we'd do some configuration changes, run the command again to send a signal, checking process status again etc. Getting Puppet to fit around our own custom apps - sending the right signals to the process, speaking to the app to query status, ports etc - is way more trouble than it's worth. Also, Puppet is really a "pull" system - that's not what we want - we really want a "push" style system - and we need it to be fast. Cheers, Victor
Magnet links can keep BitTorrent hosts out of jail; the TPB founders were convicted for hosting torrent files. Why not just use a client that supports them? EDIT: By the way your link goes to README.md. README.md is displayed directly on the project page here, and if you link there people don't have to click twice to find the script src: https://github.com/santiagobasulto/tpb-download EDIT2: Also, wouldn't it be better to parse the magnet link or the link to the torrent page on TPB instead? IDs suck.
I'm confused. Why does this script work, but going to the url "torrent_download_url" returns in a browser not work?
It does. For instance http://torrents.thepiratebay.se/7968597/7968597.torrent links to the torrent [here](http://thepiratebay.se/torrent/7968597/Burning_Man_2011_BRRIP_Xvid_AC3-BHRG).
I must have copy and pasted a quotation mark or something, thanks.
yep. the magnet link makes it so that they arnt hosting the torrent files, that way you download the torrent files from other people. 
There is another option: [Panda3D.](http://www.panda3d.org/) It's a 3D library, you write your game logic in Python but the rendering is done in C/C++, it's portable to Windows Mac and Linux (and there was a preliminary iOS port iirc). It's not super-popular, but professional shipped games have been written in it so I gather it has all the nuts and bolts you really really need. I've never used any of the above, but my dream is to someday write a game in Python. I plan to start with Panda3D and see how far I get.
Yeah; I love Python but this is the kind of stuff that belongs in a shell script, to be honest.
It does depend a LOT on what you are trying to do, so I can only offer generalities; but overall Pygame works, is stable, and is easy to find answers to. It hasn't had a major update for a while but that's more to do with the state of SDL rather than anything else.
* Pygame's API is crummy and probably not as good as Pyglet. * Pyglet was designed to use OpenGL and operate on modern GPUs from the ground up; Pygame (as a wrapper around SDL) is older, and is not OpenGL-oriented. In practice this means a lot of API cruft you probably don't want, and it means writing a lot of boilerplate OpenGL code that Pyglet comes with. * Pygame is older and has a larger community and thus far more third-party code and examples. * As Pyglet is written in pure python it can be used with Python interpreters other than CPython (such as PyPy); Pygame cannot. * Pygame is slightly more portable as SDL has a few additional backends (which probably no one will ever use, like directfb!) * Pyglet can draw multiple windows for the same process, unlike Pygame/SDL. I can't see the use for this in games, but it certainly could be useful for other multi-media applications. * Pyglet also has multimonitor support (apparently.) Again, this doesn't seem particularly applicable for games. I'm curious how well it actually works on Linux.
So, this may be a cop-out, but I use Boo in Unity which was heavily influenced by Python. It's not well supported. Unity is a very popular game engine and is more portable than python, as you can port to Android, iOS and consoles. It does so because Boo compiles through Mono. A disappointment for me though was that you can't port to non-x86 Linux builds.
Wit is often lost on people.
how is multimonitor support not relevant for games‽ other than that, thanks for the comparison, it’s really useful.
I tried to contact Phil Schwartz, the author of Kodos. I though maybe I could contribute code and he could work with me on the update. I never heard back from him. That's when I decided to fork it. I hope he's just not active on line any more. I like to think he got rich and lives on a tropical island unplugged. So I downloaded it and really hoped I could just update the UI files, make a few minor changes and it would be done. That didn't work out so instead I just sit with the old code and new code and slowly I'm trying to copy what he did. I'm not a professional programmer - I'm just a hobbyist. So - my goal is to have it do everything Kodos does and I'm getting there. Then I'm going to work on getting it all packaged and easy for people to install and use.
Yes - PyQT provides the gui. I use QT Designer to design the various ui parts, pyuic4 to generate the python and then it's all normal stuff from there. In a sense it's a demo of a lot of the things that the re module can do.
how’s the mailing list? it may be that you just missed the main communication channel – e.g. the ConTeXt (=TeX dialect like LaTeX is one) mailing list is extremely fast with help, and ConTeXt’s creator hans hagen answers there frequently himself. so while you get ConTeXt answers on tex.stackexchange.com, you get them faster on the mailing list.
Guido is wrong: For anyone who has taken the (small amount) of time required to internalize reduce, using it makes your code less error prone, more readable and shorter. Functional programming isn't awesome because it saves you a few keystrokes, it's awesome because it cuts away useless boilerplate like for-loops that just take up space and introduce bugs. 
Interestingly this is very much along the lines of what I was doing, sans the alterations to the frequency.
http://cocos2d.org/ It's a little hard to get into, but the documentation is pretty good (especially for being a one man project) The developer is also active on the google group it has (found on the contribute page) It's built on top of pyglet, so you can access it if you want to.
In what world are foreach loops buggier than `reduce` expressions? I honestly cannot imagine a scenario in which someone has difficulty with Python's `for item in items` but easily groks the equivalent `reduce`.
There's a whole list here: http://wiki.python.org/moin/PythonGames What happened to Soya3D? Last time I tried it I could import 3D graphics from Blender without a hitch (which is not always the case for obj, 3ds, collada etc. when going from Blender to a 3D engine).
Why does no one support python3 yet for any of these? As someone who learned python completely from python 3 this is really discouraging.
groovy is nice also
&gt; good documentation I found doing anything beyond the initial tutorial to involve digging through a *lot* of kivy source for lack of documentation. Have you found docs that I haven't? I'm not trying to be critical; I'd honestly love to know!
At least that guy should have used "repr" instead of "str"!
I don't think this is exact
If the data contains Unicode characters and/or you are looking for future compatibility with Python 3, this code may raise an encoding error. import codecs import csv def write_csv(_path, rows, header=None): with codecs.open(_path, 'w', encoding='utf-8') as _file: writer = csv.writer(_file, quoting=csv.QUOTE_ALL) if header is not None: writer.writerow(header) writer.writerows(rows) def main(): import itertools _path = './test.csv' columns = ('id', 'username', 'password', 'token', 'url') rows = itertools.izip(*(getattr(data, col) for col in columns)) write_csv(_path, rows, header=columns) if __name__ == "__main__": main('test.csv') **2to3** * **codecs.open** -&gt; **open** * **itertools.izip** -&gt; **zip**
I've read through all of that, honesty. It's lacking quite a bit, and a lot of the samples aren't terribly helpful (outdated, broken, poorly-documented.) I got stuck doing things as simple as trying to rotate an object, or have a hidden object that gets displayed later. I actually forked the project and started fixing grammar/logical mistakes in the docs, but I realized I didn't have enough knowledge of it to properly help out.
If so, where? Using pygame pretty often and have not heard of this
The problem is in the type of exception your are catching. When you run the code in the example the output is: &gt;Traceback (most recent call last): &gt; File &gt;"/base/data/home/apps/s~learnpythonjail/1.354953192642593048/main.py", line 99, in post &gt; exec(cmd, safe_globals) &gt; File "&lt;string&gt;", line 10, in &lt;module&gt; &gt; File "&lt;string&gt;", line 7, in get_last_name &gt;**KeyError**: 'last_name' So, you have to catch a **KeyError** exception. This code should works: def get_last_name(): try: return actor["last_name"] except KeyError: return "something" 
On the Pygame mailing list lately there's been a lot of talk about the website. The maintainer says he is in the middle of a rework, so it's not a lost cause, but there's some discussion over how long that's taking and whether we should just replace it with a new site, etc. 
What do you want to build? Your first game? Go with Pygame. Do you really want to do some crazy 3D stuff using OpenGL. Go with Pyglet. I've used both, they're both fine. Cocos is another option that I have not used but it seems like it has an actual community.
SPREAD THE INTERROBANG‽
Just do `NoneMonad.__rshift__ = NoneMonad.bind`.
It's a troll. Time to stop feeding. 
Hey thanks! I didn't know that the type of error was an important thing to keep in mind. Thanks a lot!
Bash: tpb-download() { # Downloads one or more torrent files from ThePirateBay.org TPB_URL='http://torrents.thepiratebay.se' [[ -z "$@" ]] &amp;&amp; { echo 'One or more Torrent IDs to download' ; return 1 ; } which wget 2&gt;&amp;1 &gt;/dev/null || { echo 'ImportError: No binary named `wget`' &gt;&amp;2 ; return 2 ; } echo 'Starting to download torrent files.' for torrent_id in $@ do [[ $torrent_id =~ ^[0-9]+$ ]] || { echo 'TypeError: Expected `int`, received `'"$torrent_id\`" &gt;&amp;2 ; return 4 ; } echo "Downloading $torrent_id.torrent" wget -O $torrent_id.torrent "$TPB_URL/$torrent_id/$torrent_id.torrent" done echo 'Done downloading torrents.' }
Multiple-section email (which is just about all of them), HTML emails, MIME attachments, etc..
I think you should.
There is [pygame for python3.2](http://pygame.org/ftp/pygame-1.9.2a0.win32-py3.2.msi) at http://www.pygame.org/download.shtml
100 per day.
Well, see comment below about pyzmail. It seems they support 3.x, so I'll just use that. (One of these or another should still be in the stdlib though.)
I should probably respond to that, then--thanks! I read that guide (I read *every* bit of Kivy documention I could find), and it was definitely lacking. Try to figure out how to rotate something--if you can find it in the docs, I'll eat a sandwich. 
Thanks for all the input everybody. I'm going to go with Pygame for now because of the user base, documentation, and number of examples that are available for a new programmer to lean on. You guys rock.
IMAP/imaplib can't send email, it can only read messages on an IMAP server.
The code needs a comma after 'email_subject' inside the call to 'join'.
Don't you need double CRLF at the end of headers? Maybe the following: content = headers + "\r\n\r\n" + body_of_email
I am a novice Python programmer and I found Pyglet to be much easier to get up an running than Pygame. I also use [Cocos2D](http://www.Cocos2D.org) which is built on top of Pyglet I believe and adds a bunch of gaming modules that are extremely useful. I learned to read the API's and with time and dedication I have a small little 2D platformer going. I also implemented [Pymunk](http://www.pymunk.org) for 2D physics and got everything working together. I am extremely pleased with the Pyglet/Cocos2D/Pymunk combination. You can check out my code [here](https://github.com/Art9681/the_batcave). Read the readme! And please disregard all my silly naming conventions as I am very new to programming in general but it works pretty good! 
 headers = "\r\n".join(["from: " + GMAIL_USERNAME, "subject: " + email_subject "to: " + recipient, "mime-version: 1.0", "content-type: text/html"]) I am not an python code, but is he missing the semicolon?
Where?
It's the only open source 3D accelerated game engine that allows game to be packed and executed via browser plugin. 
If you want to send an attachment too: #!/usr/bin/env python import smtplib from email.MIMEMultipart import MIMEMultipart from email.MIMEBase import MIMEBase from email.MIMEText import MIMEText from email import Encoders import os gmail_user = "username@gmail.com" gmail_name = "User Name &lt;username@gmail.com&gt;" gmail_pwd = "userpassword" def mail(to, subject, text, attach): msg = MIMEMultipart() msg['From'] = gmail_name msg['To'] = to msg['Subject'] = subject msg.attach(MIMEText(text)) part = MIMEBase('application', 'octet-stream') part.set_payload(open(attach, 'rb').read()) Encoders.encode_base64(part) part.add_header('Content-Disposition', 'attachment; filename="%s"' % os.path.basename(attach)) msg.attach(part) mailServer = smtplib.SMTP("smtp.gmail.com", 587) #mailServer = smtplib.SMTP_SSL("smtp.gmail.com", 465) # didn't work for me mailServer.ehlo() mailServer.starttls() mailServer.ehlo() mailServer.login(gmail_user, gmail_pwd) #mailServer.sendmail(gmail_user, to, msg.as_string()) # just e-mail address in the From: field mailServer.sendmail(gmail_name, to, msg.as_string()) # name + e-mail address in the From: field # Should be mailServer.quit(), but that crashes... mailServer.close() if __name__ == "__main__": mail("send-mail-to-this-person@address.com", "Hello from Python!", "This is an e-mail sent with Python.", "/tmp/some-image.jpg") From [here](http://pythonadventures.wordpress.com/2011/02/19/send-emails-via-gmail/).
&gt; I was running a cosmic ray simulator with python? if so, I would be interested in learning more about that. 
As someone who's still new to python can you give an example on header injection and elaborate on what sanitizing variables is? 
Some time ago, I extracted the mail backends from Django son they could be usable without it (or any other dependency). https://github.com/lucuma/MailShake The library includes several helpers for developing and testing. You can, for example, "send" the email to the console or to a file just using a different mailer class. Btw, the library is in pypi, so you can do `pip install Mailshake`.
Side note - armin's repo is a source of many cool hacks, but also requries serious software archeology skills :)
Thanks so much for taking the time to comment on my project. I'm trying not to glaze over and learn something from your feedback. Give me a couple of days and I'd like very much to PM you on my progress and double check a couple of things. Regarding the GUI, I used wxWidgets. thenewboston has some great tutorials which are simple enough to follow. I'd have loved to have used tkinter but it looks absolutely awful on Linux which is my primary OS. There's just no point in building a pretty front-end if it ends up looking like snot, so I went with the more verbose wxWidgets which has better support and looks more uniform across platforms. I still need to look into packaging the whole project up as an easy-to-install bit of freeware for all OS's. It's saved me countless hours of manual sorting.
Thank! I could use it. I am new to python and few tips be great. Is there a way make it memory efficient. I have few 10s 4GB csv files with individual coulums which I want to combine in to 1 big csv file. How can I write without loading everything in to memory and do it fast. I hear Pythin 2.x threads dont help? 
+1 for Panda3D, I don't have much experience with other options but I've played with it recently to build a small game that used Bullet physics and was pretty impressed. The main thing that I really didn't like is how it messes with `__builtin__` to magically put stuff into the global namespace.
Well, there wasn't any. But I decided to take the challenge, and now there is! From the (revised) readme: &gt;&gt;&gt; from x import X, SameX &gt;&gt;&gt; map(X**SameX, range(10)) [1, 1, 4, 27, 256, 3125, 46656, 823543, 16777216, 387420489] &gt;&gt;&gt; (X+SameX+SameX)('ha') 'hahaha'
Exactly.
nice idea to use stopwords, but I'm afraid it's not precise. what is the problem with sorting the trigrams by frequency? few lines more code in python. much more precise then stopwords. I'm on a phone, cannot include code at the moment
Is the PyPI page supposed to render your ReST? Seeing that "![PyHamcrest](http://hamcrest.org/images/logo.jpg)" gunk at the top of the page looks a little silly.
But play EVE (once at a time), and find yourself not wishing for multimonitor support. That's a challenge.
&gt;quote &gt;quote
I used to use the NLTK implementation for a project, but then I came across this library: http://code.google.com/p/chromium-compact-language-detector/ It's the language detection system ripped out of from Chrome, the results are not always correct (~95% with my datasets), but good enough for lots of use cases, but more importantly: it's a hell of lot faster! 
Thanks for posting. I was wondering if you know about [ldig](https://github.com/shuyo/ldig). For tweets, it claims to have [99.1%](http://shuyo.wordpress.com/2012/02/21/language-detection-for-twitter-with-99-1-accuracy/) accuracy. 
Header injection is basically abusing the concatenation of variables into strings. In this case; you can "inject" a header, by setting the to-variable to, for example: "recipient@domain.tld\n\rfrom: yomomma@somewhere.else". Normally it would be just the first address. And with that you have successfully injected a new from header into the e-mail message. And that's insecure because it could lead to abuse on the recipients side (think sender spoofing etc). Injections are usually preventable by sanitising the variables you're using. In this case you would only allow only one valid e-mail address, or a list of valid e-mail addresses, formatted in the way the specifications dictate. In other situations you would want to check if a value for "zipcode" is actually a zipcode; by comparing it against a database for example. Because validation is sometimes very hard to write - or at least in this case, because e-mail addresses are allowed to be hilariously complex - you can safely assume there's already a module out there somewhere that does it for you. And that module is very likely what you should want to use. :) Note that this applies to everything that gets data from a user, be it a website-visitor or a configuration setting. And always think twice about what you put into strings that go somewhere (to the browser, database or even to your disk). Ninja-edit: this isn't really Python specific, but good advice in general.
Cool. I've been working on a distributed test harness that will do exactly this. Unfortunately, I'm not quite done. However, you might want to take a look at RPyc. It's a really neat Python RPC library. It makes it very easy to execute remote Python code. I was going to use Twisted but RPyc is much simpler and does everything I need. EDIT: you might want to try Paramiko too. 
Dang, cool. I had not heard of it, thanks for the link!
♥♥♥♥
Wow. I was expecting it to be more money. The final paragraph really sums it up. &gt;It is amazing that just a few thousand dollars can move mountains in the open source community. This is the sort of money that Microsoft or Google say would regard as not even on the radar. We clearly need more informed philanthropists to push a little money in the direction of key projects - the shortage is most likely of "informed" philanthropists. Let us hope that the move to Python 3 accelerates as a result.
My quick take on this: https://gist.github.com/4418394 It uses Bayes theorem and trigram count (using the language id corpus, from nltk)
I'd love to be able to use Kivy directly from my iPad. Hope Pythonista or one of the other Python distributions add support for it sometime.
Yup, it's also worth remembering that because the open source community is a global one, many developers live in places with lower costs of living.
You must be using some device to interface a PC to I2C (e.g. over USB). This device probably has a driver or API library designed for use from a C program. In this case, you will need to use of the libraries for interfacing between Python and C (ctypes, cffi, swig, cython, etc).
IMDB is downright fascist about scraping their data.
This is a great point that I wish was discussed more. Different developer communities communicate in different ways. Some via forums, some via mailing lists, some IRC. I would love to see the "primary discussion method" as metadata for the project somewhere (PyPI?)
You can do this very easily with a pyMCU setup. It's about $25 and has essentially all the same functionality of a 16F1939. There are i2c read/write functions. Also SPI, IR decoding, one wire reads/writes... http://www.pymcu.com/ EDIT: Hook the board up with a USB cable. Install the pyMCU module. Import the module and use the functions to talk to the board.
Get some hardware that connects the I2C to the PC over USB as a serial port (in Windows, this is a virtual "COM" port). Then you can use the pySerial library which is not too difficult and well-documented. http://pyserial.sourceforge.net/
I certainly expected it to do so. I have no idea why it didn't. I will go and update it when I'm in a position to do so.
It's just like any other cloud environment, your Python experience will depend more on the OS you choose. I think I went with Ubuntu so it was breezy as usual. Azure's control panel (the alpha/beta/new version) is pretty nice, I found it a bit more intuitive than AWS. That said, I had trouble with my Azure account itself more than anything - I was trying some free plan, but without warning my account was deactivated and my servers were scrapped. I went back to AWS after that.
As I side, it's a little pricey but they support their product. None of this half assed Chinese make-r bullshit. You plug it in and go with no questions asked. If this is a company building a one-off fixture, it's worth the extra 200$. That's 4-6 hours of engineering frustration before you break even with the more expensive product. I've use devantech stuff in the past and it's usually about what I expect. Mid-grade (better than Chinese no name) but there's no real rapid support. If for whatever reason you need support, you're stuck with email. As an engineer that's extremely busy, the choice between phone supported and cheap but not having exactly what you need out of the box, I choose phone supported and exactly what I want. Also, he wants python not perl and total phase writes and maintains their python drivers which in my book is a HUGE bonus in terms of being certain it just works
Two hours of not having to dick with it to get it to work with python will immediately make up for for the difference in price.
check out the Bus Pirate: http://dangerousprototypes.com/docs/Bus_Pirate It has a scripting mode that supports Python as a scripting language, and I2C is one of the supported protocols.
What's the point of using an OS one does not like, when installing another is so easy?
Yes. I just got one a few weeks ago to hook up to a beagle xm. I am trying out each function from the module as I go. I will be testing the SPI next week, and maybe the i2c stuff later (we don't use any i2c stuff). The one wire read works on an RTD we had laying around. PWM works fine, the audio (tones) work. So far it is functioning as advertised. It's a really nice little unit for $25. Downsides: no python 3, analog ins are a little bouncy even with a filter. 
I've done this with just a regular Arduino.
Maybe for you "installing another OS is so easy". I have nothing but bad memories of attempts to do such a thing, no matter which OS it was.
Any asynchronous IO library is trivial to interoperate with greenlets or stackless. Look at corotwine.
Can you tell me how to get started in learning R, thanks
Yes. I've used this extensively. Worth every penny of the $35, i2c, spi, rs232. Good support forums, open hardware. An excellent device.
I've been programming in Python full time for five years. The way I initially learned Python (already proficient in several other languages) was I found a Pygame game that I thought was interesting, ripped it apart, and made it into something of my own. I'd written games in other languages so this wasn't too terribly hard. But for a first project I'd do something simple and 2D. If that goes well (meaning you're happy with it) go crazy on your next project.
wishIcanplaywithittoo.jpg
Not at all. With threads you have to use locks to achieve safety. The lock primitives in twisted are entirely optional and only used for convenience.
I don't have time now to study your post. I just want to say `_` is a special built-in object which has special behavior. Don't use it on the left side of an assignement statment. It's a dangerous habit, especially if your `_` is in module-level scope and someone decides to `import` that module in the interactive interpreter. From the official [Python Tutorial](http://docs.python.org/2/tutorial/introduction.html): &gt; In interactive mode, the last printed expression is assigned to the variable `_`. [...] This variable [`_`] should be treated as read-only by the user. Don’t explicitly assign a value to it — you would create an independent local variable with the same name masking the built-in variable with its magic behavior. 
Verilog or VHDL.
Unlike most of their competitors, Dropbox have an excellent Linux client.
The iphone version is indeed, unfortunately, a lot more popular than the python version. (I say unfortunately because that means there is really no way to google questions, and the tag for it on stackoverflow is mainly used for the Objective C version, despite that being wrong) Personally I have only looked a little on the examples and code for it, but I've seen people recommend doing that. I mostly used the tutorial, the api documentation and reading the source (which is pretty easy to follow and pretty well commented) Feel free to send me a message if you get stuck!
If you were importing them into a browser context you would already limit them drastically. You just deny read / writes into the local file system, you only allow a select few system calls, you don't let the script initiate forks, and you put the entire page in a sandbox.
can someone please explain the usage of __name__ and __main__??? i see these all over the place but for the life of me i have no clue what it means or where to find it in the python docs. 2 weeks into python. thanks!
hey thanks sorry for teh late reply. trying to do a lot of this by scratch just to understand it better but i may use this. i will look at it either way, it helps. thanks!
I don't think it's thant simple. Look at Java applets for an example odd a neglected VM with security issues.
This is what I ment. He apparently fixed it.
I am assuming you are running Windows. If you save your application as .pyw instead of .py it won't bring up the console window. However if you do this you will want to wrap your code with outputs to a file and possibly have a try/except everywhere so that when you update something you can still capture the errors. If you need an icon with a link and a folder inside of your program files then google something called Inno Setup. It's a free piece of software that let's you create a windows .msi program. 
Should have mention im on a mac, Would this still be the same?
google trends are *not* directly indicative of popularity..
Not sure either, would bet big blind on java cause android getting more and more popularity but why c#?
Does anyone else find it interesting that the languages are all googled '[Language] tutorial' except for C++, which was 'tutorial c++'?
Java isn't treated in an appropriate sandbox. That code still runs on the JVM and the language itself is low level enough you can do some nasty buffer overflows and bitwise tricks in it. I'm not saying it would be fluid, but I'd much rather have a generic script sandbox privilege model in browsers than *only* Javascript.
The words "fastest growing" are missing from the submission's subject. Based on those charts Java is by far the most popular, which surprised me. In my field I see a lot of C++ and Python these days.
&gt; .net has been more or less deprecated in windows development going forward That is in no way correct
Java is used in most introductory cs classes, so college freshman everywhere search for Java tutorials.
A different way to measure this would be what languages are gettibg the most action on github: https://github.com/languages
Well, C# is a better language than Java. Not that it's likely to be the reason, really.
Might Java be the most difficult langauge to write a useful tutorial in. So the average user needs to search for more tutorials on average.
I think that [TIOBE](http://www.tiobe.com/index.php/content/paperinfo/tpci/index.html) is better at this, actually.
This isn't exactly a good place to look for that, either. At most, it would give us an idea about *open source* projects, which does not always follow what companies are doing (programmers love to hate Java, but companies love it).
No
So google trends are better than TIOBE?
I have to say, visual studio 2012 makes writing windows apps super easy. I really don't want to look at wxpython or pyqt again. 
It's impossible to break memory safety in Java without JNI. Most bugs so far have been in the JVM itself, which any VM might have. I think I'd rather see a VM with some form of same byte code and DOM access to which both JavaScript and other languages compile, but that's unlikely to happen. The closest thing I've seen is Dart's VM.
They are both bad
I would gladly ask why.
They could *at least* use "~tutorial", which also searches for synonyms (reference, guide, manual etc)
Personally, I don't think these are really the best rankings. I like [RedMonk's rankings](http://redmonk.com/sogrady/2012/09/12/language-rankings-9-12/) (site's down now, but it is [cached here](http://webcache.googleusercontent.com/search?client=ubuntu&amp;channel=fs&amp;q=cache%3Ahttp%3A%2F%2Fredmonk.com%2Fsogrady%2F2012%2F09%2F12%2Flanguage-rankings-9-12%2F&amp;ie=utf-8&amp;oe=utf-8)) most, because the combination of the GitHub rankings with the StackOverflow rankings works pretty well for combining what's being used in workplaces and in open source. [Indeed's job trends](http://www.indeed.com/jobtrends?q=java%2C+javascript%2C+php%2C+python%2C+c%23%2C++perl%2C+C%2C+C%2B%2B%2C+ruby%2C+visual+basic&amp;l=) gives a somewhat better picture of workplace popularity, but is a bit hard to read.
Because these ratings are based on some data that's not correlated with actual *popularity*. First of all what *popularity* is? I don't know what it is, but I think popularity(for one year) should be calculated based on: * community growth * ammount of new large or significant projects * availability of developer's tools * other things good to platform itself 
TIOBE has its own methodology to define the popularity of the language. You can search for this methodology. If you don't agree with it, though, there's not much I can do. But TIOBE defines well what it measures and shows its data. It's not just "hey, lots of people are searching for this on Google, so it must be really popular!"
I do really wish there was some common easily sandboxed bytecode standard for the web that languages could compile to as well. Sending web pages as text has had benefits though, no website can really obscure its implementation since you can just read the minified JS.
For the record I didn't downvote you, but .net is behind pretty much every portion of Microsofts web stack, not just the waning webforms technology, there is Entity Framework, ASP.net MVC, SharePoint (for better or worse), not to mention most of the accounting subsidiaries like Dynamics and Great Plains are all written in .net.
I don't want to argue, because there are no unified methodologies and metrics to define popularity of programming languages. And I didn't said their methodology is bad. Quite the contrary they have good methodology and large dataset, but these results are not so related with popularity and they **absolutely** have nothing with naming one language being "Language of the year"
We reached a consensus.
Either C# is language of the year , or C'Sharpers arent that sharp, neither are Pythonistas.... If your a Windows developer using C#, well duh , that explains it. If your a Pythonista -- your a student or researcher working on some real projects
Frankly all the oft recommended python game frameworks seem undermaintained - pygame: last release 2009, pyglet: alpha status since many months, Cocos2d: little activity. Documentation is also generally quite poor and out of date. I just came across http://ignifuga.org/ which is promising but again it's very immature and has little documentation. I think documentation and community activity are key to getting started (as well as a well designed framework obviously). I tried plain pyglet but ran headlong into performance issues - nothing unsolvable but I knew already that I would be spending more time struggling with the basics than expressing an idea. I also tried Cocos but I found it a bit clunky and not very well supported (the docs tell you the basics but there's not much in the way of tutorials and examples and StackExchange answers) From what i've seen i would recommend Java with LibGDX, just because it has lots of docs, support, real world use, and it's free. I'm sure you could make a python framework work for you, but if you're starting out and you want to turn a game idea into reality rather than tinker with experimental things, it's better to go with something well established. 
Although minified JavaScript needs processing to understand anyway, which is about as good as a byte coffee disassembler. In a way byte code wouldn't be that much better than JavaScript already is other than perhaps opportunities for optimisation. Compiling to JavaScript isn't so bad.
It's not that Java is more popular, just that it raises more questions! ;)
Welcome to the world where we're shoveling our own grave.
I love C#. I write in it for a living but just happen to love .NET and everything it has to offer. Sure, there are some pitfalls that every language has (even python), but combined with Visual Studio, writing in C# can be very efficient, readable, and fun! Still, for all my home statistics side stuff, I use Python.
The py vs pyw is something that should come with your copy of python. I am sorry but creating a dmg file is something that won't work with Inno setup. I have not worked with macs enough yet to tell you what to do there. Best bet without an answer is to do a google search on how to create a dmg file for python. I would also look into stack overflow.
We're doing it to replace bout 30 Arduinos.
This looks interesting.
Limiting concurrency is probably what they are used most of the time however they are also used to protect data structures. You do have to think about whether something else could be writing to your data structures if you happen to update it in multiple stages spanned across multiple callbacks (or across yield statements in inlined deferred). I have had to do that and the larger the system the higher chance there would be a need for it. To clarify again your operation/ transaction is in multiple stages locally. These stages perform some IO (say read or write to some database) and because you use Twisted these stages will be spread across multiple callbacks (say cbk1, and cbk2). If you use inline deferreds they will be separated by a number of yields. The problem is if a second client connect and does the update to the shared data structures, the update could happen before the update for the first client finished. So you would have a sequence of Client1:cbk1, Client2:cbk1, Client2:cbk2, Client1:cbk2. And Client2 potentially saw a half-updated, inconsistent data structure since Client1 was in the middle of updating it. That is why these are not obvious or there are not many examples of using it in tutorial and other example code on the web. So the idea is don't drink the cool-aid, Twisted won't save you from ever needing a lock or semaphore. What Twisted does (which greenlet based libraries, eventlet and gevent don't) is that it makes IO context switching more explicit. Glyph (the author of Twisted and a brilliant guy) thinks that is a very valuable thing. I don't agree with him and prefer gevent. 
How are you going to quantify each of those bullet points?
If anything, the rise of javascript is undeniable in the tech industry in the last year.
I think if anything, github repository should be used as a industry indicator
Even then, that will skew towards communities where central repos aren't as common.
if you're using bash and py.test, it's a way to say py.test -k test_&lt;tab&gt; that displays all tests that you happen to have.
It means that we now start to have features in python 3 only that don't require any of the changes in the language but are there solely because python 2 was declared feature freezed.
Really? Why? I'm still on 2.7 and was thinking about switching to 3.x... bad idea?
Then maybe stackoverflow is a good place to look?
And maybe somebody already did both? http://redmonk.com/sogrady/2012/09/12/language-rankings-9-12/
public class QuestionFactory?
Java gets a fuckton of use in the corporate sector. It just isn't a sexy, buzz language anymore. But it's a heavy workhorse language being used by a lot of large companies.
Interesting... I'll just have to figure out how to actually use nosetests, now =/
There are certain over represented languages on github. Same for all the repo services (though different languages for each).
I don't have any problems with Python's package system. Maybe you have gotten caught trying things that hurt your case?
I wrote a [test harness](http://pastebin.com/maicMDD0) to evaluate the performance against the built-in dict. Here are the results: Size Test Built-in Proposed 5 creation -- 38.844x slower 5 get value -- 17.473x slower 5 iteration with items() -- 1.854x slower 5 iteration with iteritems() -- 2.262x slower 5 iteration with keys() -- 1.874x slower 5 iteration with iterkeys() -- 1.728x slower 5 iteration with values() -- 1.897x slower 5 iteration with itervalues() -- 1.864x slower 10 creation -- 49.125x slower 10 get value -- 17.499x slower 10 iteration with items() -- 1.572x slower 10 iteration with iteritems() -- 1.859x slower 10 iteration with keys() -- 1.578x slower 10 iteration with iterkeys() -- 1.372x slower 10 iteration with values() -- 1.695x slower 10 iteration with itervalues() -- 1.525x slower 50 creation -- 75.588x slower 50 get value -- 17.485x slower 50 iteration with items() -- 1.268x slower 50 iteration with iteritems() -- 1.313x slower 50 iteration with keys() -- 1.112x slower 50 iteration with iterkeys() 1.071x slower -- 50 iteration with values() -- 1.132x slower 50 iteration with itervalues() -- 1.048x slower 100 creation -- 79.788x slower 100 get value -- 17.905x slower 100 iteration with items() -- 1.113x slower 100 iteration with iteritems() -- 1.146x slower 100 iteration with keys() 1.084x slower -- 100 iteration with iterkeys() 1.346x slower -- 100 iteration with values() 1.197x slower -- 100 iteration with itervalues() 1.233x slower -- 500 creation -- 78.871x slower 500 get value -- 18.541x slower 500 iteration with items() -- 1.103x slower 500 iteration with iteritems() 1.020x slower -- 500 iteration with keys() 1.221x slower -- 500 iteration with iterkeys() 1.746x slower -- 500 iteration with values() 1.533x slower -- 500 iteration with itervalues() 1.560x slower -- 1000 creation -- 78.100x slower 1000 get value -- 17.912x slower 1000 iteration with items() -- 1.149x slower 1000 iteration with iteritems() 1.053x slower -- 1000 iteration with keys() 1.186x slower -- 1000 iteration with iterkeys() 1.857x slower -- 1000 iteration with values() 1.462x slower -- 1000 iteration with itervalues() 1.723x slower -- 5000 creation -- 72.733x slower 5000 get value -- 19.228x slower 5000 iteration with items() -- 1.087x slower 5000 iteration with iteritems() 1.031x slower -- 5000 iteration with keys() 1.414x slower -- 5000 iteration with iterkeys() 1.839x slower -- 5000 iteration with values() 1.444x slower -- 5000 iteration with itervalues() 1.723x slower -- 10000 creation -- 65.332x slower 10000 get value -- 17.732x slower 10000 iteration with items() -- 1.014x slower 10000 iteration with iteritems() 1.176x slower -- 10000 iteration with keys() 1.632x slower -- 10000 iteration with iterkeys() 2.101x slower -- 10000 iteration with values() 1.623x slower -- 10000 iteration with itervalues() 2.142x slower -- 100000 creation -- 41.010x slower 100000 get value -- 17.916x slower 100000 iteration with items() 1.349x slower -- 100000 iteration with iteritems() 1.599x slower -- 100000 iteration with keys() 1.833x slower -- 100000 iteration with iterkeys() 2.536x slower -- 100000 iteration with values() 1.740x slower -- 100000 iteration with itervalues() 2.086x slower -- Iteration is indeed faster, but not by a huge margin, and only for relatively large dicts. And you pay for it with *much* worse performance for creation and value access.
Of course, a python wrapper around dict would be slower than the original dict. However.. I believe some context is missing here... Raymond Hettinger (the author of the recipe) is one of core developers of python. About a month or so ago he suggested a faster/more compact replacement for python built-in dict. He also published this recipe which I think was only intended for algorithm demonstration. The actual replacement would be/is written in C... http://mail.python.org/pipermail/python-dev/2012-December/123028.html 
A better comparison would be adding the proposed dict replacement into PyPy (i.e. RPythonizing it), compiling it, and then running your test against the base PyPy dict.
[IMAP](http://en.wikipedia.org/wiki/Internet_Message_Access_Protocol) &lt;-&gt; [SMTP](http://en.wikipedia.org/wiki/Simple_Mail_Transfer_Protocol)
This should be a top level comment.
The reasoning for that is [here](http://www.python.org/dev/peps/pep-0404/#official-pronouncement).
no it's a reply to the previous comment l2reddit
I just flagged it.
When you do import something the contents of the file something.py is executed. Say you want to use that file as a stand-alone executable but also as a module, and you don't want the stand-alone code to be executed when imported as a module. Well... there's a special variable called \_\_name__ which holds the module name... if imported as a module, otherwise it's "\_\_main__". Type "\\\_\\\_this\_\_" in reddit comments to write "\_\_this\_\_" instead of "__this__".
I don't fully understand what you are saying, but to be clear it works fine, I just personally detest it. I don't like naming my files like my packages, which is why it makes me cringe.
ahhh I see! thank you very much. I just found the documentation on importing modules now that I know where to look, so I'll figure out to implement this. yeah, I noticed my error in posting but figured it wouldn't be worthing editing because the thread was getting old and had little attention.
SSL TLS SNI Server Name Indication Extension http://www.ietf.org/rfc/rfc4366 was added to Python 3 with http://bugs.python.org/issue5639 This is the code: http://hg.python.org/cpython/rev/846c0e1342d0/ Some might consider this a security fix for Python 2.
I know *you* know this, it was meant for other readers :-) BTW, now that Python 3.3 incorporating PEP 414 is out, what are the roadblocks to Python 3 support in Werkzeug?
Java and Python are comparable--it's possible to find exercises that tip one way or the other. A *far* more interesting performance question, as far as I'm concerned, is whether the domain in which one is working is well supported by one community or the other. In practical cases, I find that determines considerably more of interest than the alioth-style comparisons. Alioth was and is a constructive step. There's much more to the world than it measures, though.
As an example, [Django](https://www.djangoproject.com/weblog/2012/mar/13/py3k/) isn't even close to supporting Python 3. The majority of tutorials for beginners out there are still on Python 2.7. I don't think PIL supports Python 3 yet, and that's something I'd personally miss. Python 3 is the future, but we're just not there yet.
That article is from March and a little dated, it's January 2013. Django 1.5 is out now. https://docs.djangoproject.com/en/dev/topics/python3/ I don't have any personal experience with it on py3k so it might not be fully functional, but saying "isn't even close" is just silly. Here's an easy reference for general py3k compatibility, http://python3wos.appspot.com/ The most notable offender to me being the Twisted framework.
Cant find neither source or a version for mac :/
But what about the memory footprint difference? The article seems to be more about eliminating memory waste.
Beautiful.
Undefined behaviour is undefined?
So "x[0] += [1]" is equivalent to "x[0] = x[0] + [1]"? Isn't that what we'd expect? (i.e. "x[0] + [1]" is evaluated, and then the assignment to "x[0]" fails.)
I'm not a big fan of the "awesome way" for #3. It's shorter, sure, but it's more opaque. The boilerplate there could be improved by using += rather than repeating dct[key], too.
You missed part of the odd behavior: after executing `x[0]+=[1]` the list at `x[0]` *has* been modified.
I am also curious about the memory footprint. I'd also like to see the optimization of Dict with an actual C library. The expectation is that it will be optimized in C anyway, so the performance indicators as shown are not going to really be apples to apples. Either we move the builtin dict to a python version of dict or (preferably) we move the Dict to a c-version and then retest. I like pypy; I really believe in the effort of pypy. I really want to love pypy, but I guess I still see it as a tinker and research project -- not a production-ready implementation.
I don't really see how this would be a bug. `__iadd__` returns a value, which allows it to do either change the current object or create a new one. Since value is being reassigned to the original variable this behavior makes perfect sense, as (`x[0] = x[0]` fails as well in this case). 
 x += y is equivalent to: x = x.__iadd__(y) The list's \_\_iadd\_\_ function succeeds in updating the list, and returns itself, but the assignment fails. The number's \_\_iadd\_\_ function changes nothing, but returns the new value and the assignment fails. The issue here is that lists are mutable (can be modified), whereas numbers are immutable (cannot be modified). For the += operator to work on a mutable object like a list, it has to actually modify the object. You can't modify a number though, so for the += to work on a number, you need to store the result of the addition back to the same variable. Python doesn't know the types of variables at compile time, though. So when it compiles the += operation, it doesn't know if it will be running on a list or a number. As such, it does both: it calls \_\_iadd\_\_ and then it assigns the result back in to the same variable. The number does the calculation and a new number for the result, and the list updates itself and returns itself. In both cases the assignment back causes an error, but in the list's case the change has already happened.
Actually, "x[0] += [1]" is equivalent to "x[0] = x[0].\_\_iadd\_\_([1])". The effect of \_\_iadd\_\_ on a list is to change the list and return itself, but the effect of \_\_iadd\_\_ on an int is to return a new value.
It *succeeds*, but still raises an exception. It should do one or the other, but not both.
Well the assignment is what is failing, no the actual `__iadd__` method. 
Excuse my ignorance, but as someone who doesn't do much more with databases and data stores than inserting and retrieval, what is the purpose of doing complex mapping and/or reducing operations at the database layer? It kind of feels more verbose and less readable than querying the data and and performing the functions you desire on it directly, unless it's just simple `WHERE` or `GROUP BY` clauses. Is it faster to use PL/Python?
Actually, I believe this behavior is fully defined (see all the other comments) but it brings up a good question. Does Python have any undefined behavior at all?
Seconded. As an engineer, I'm constantly fascinated by these cases -- surprising, unintuitive behavior that's direct consequence of a chain of seemly intuitive decisions. `X += Y` in Python is shorthand for `X = X.__iadd__(Y)` (save that X is only evaluated once), and __iadd__ for lists modifies the existing list. The only strange bit here is that tuple member assignment fails. You can see this by executing: &gt;&gt;&gt; x = [0]; y = x; &gt;&gt;&gt; x += [1] &gt;&gt;&gt; print y [0, 1] Most of us are expecting the original list contents, but += on lists behaves more like `extend()` than like `+`. That's where most of the surprise comes from; while strange, it's less confusing than always failing operation to have a side effect.
&gt; I like pypy; I really believe in the effort of pypy. I really want to love pypy, but I guess I still see it as a tinker and research project -- not a production-ready implementation. can you tell me why? there is seriously very little we can do to convince you it's not true. we provide a rock solid python implementation that works. what do you want? a certificate from NSA?
This is unrelated to the topic. Both `x` and `y` refer to the same object, initially `[0]`, then appended to as `[0, 1]`. This is the distinction between mutable and immutable data types. &gt;&gt;&gt; x = [0] &gt;&gt;&gt; y = list(x) &gt;&gt;&gt; x += [1] &gt;&gt;&gt; y [0] The difference in this code is that *y is a new list*, rather than a reference to an existing list.
&gt; Most of us are expecting the original list contents Only if you think assignment like `y = x` means creating a new copy, as in C++. I don't think many people would expect += to be anything other than a mutation operation, which means x and y will continue to refer to the same object.
Didn’t know reddit markdown supports ``-syntax`. Cool! Is this new?
This is a bit of a cop-out answer, that will be buried under a buried comment, but it's an interesting question, so I'll try to say something anyway. There isn't a "Python standard", there's just a reference implementation and a reference manual. Almost all behaviour is "defined" by the reference implementation, even if it is as confusing as the example in the original post. Because of this, it might look like everything is defined, but there are actually a few different kinds of undefined behaviour. * **Documented undefined behaviour** – This is when the documentation says that something is undefined or unpredictable. Other implementations have no obligation to do it the same, this is just how CPython works. For example, if you search for "CPython" on [this page](http://docs.python.org/3/reference/executionmodel.html), you'll see a box explaining that if you modify \_\_builtins\_\_ it may not work on other Python implementations. So you'll probably get a "NameError" or a redefined builtin if you modify it, but it's possible that another valid python implementation launches a game of chess when you touch \_\_builtins\_\_. * **Classic undefined behaviour** – Just as writing past the end of a buffer in C is undefined, this is also true if you write past the end of a buffer in Python. Python deliberately makes this really hard, but you can still do it (and lots of other insane, evil things) if you use ctypes. It will behave unpredictably differently depending on which Python version was compiled with which compiler. * **Conflictingly defined behaviour** – According to Tim Peters on [this issue page from Python 2.3 in 2001](http://bugs.python.org/issue448679), and [the python docs](http://docs.python.org/2/reference/expressions.html#evaluation-order), everything is meant to go left-to-right. But I just tested on 3.3.0, and dictionary key/value evaluation order is not as documented (as mentioned in the issue). If the reference implementation and the documentation disagree, is it defined? Maybe it really is a twelve-year-old bug and any python code that relies on that behaviour is correct - it just doesn't run on CPython because of a bug. Try it yourself: &gt;&gt;&gt; def f(a): print(a) &gt;&gt;&gt; {f(1):f(2)} 2 1 {None: None}
This comes down to how pointers and array pointers work. One can't modify a const pointer's address value but modifying it's target memory space is possible.
Not as far as I'm aware! Reddit mostly supports standard [markdown](http://daringfireball.net/projects/markdown/), and has supported \``backticks`\` for a while.
&gt; Iteration is indeed faster, but not by a huge margin, and only for relatively large dicts. And you pay for it with much worse performance for creation and value access. From the comments in the code, it sounds like the lookup logic is the same as in the current implementation, and thus is probably the same speed when implemented in C: def _lookup(self, key, hashvalue): 'Same lookup logic as currently used in real dicts' [...] There's also this comment, to suggest that the changes primarily affect memory efficiency (at the top): &gt; Save space and improve iteration speed by moving the hash/key/value entries to a densely packed array keeping only a sparse array of indices. *This eliminates wasted space without requiring any algorithmic changes*. 
&gt; So, if `list.__iadd__` was changed to return a new list object rather than do an in-place update and return itself, this particular oddity would disappear. No, you can't do that. This isn't just an optimization. Your version would break other behavior. &gt;&gt;&gt; a = b = [] &gt;&gt;&gt; a += [1] &gt;&gt;&gt; b [1] Under your version, `b` would still be `[]`.
What do you propose should happen to get the desired results? 
This structure requires another level of indirection. This may introduce pipeline bubbles. I expect this to have a mixed effect on performance, making some thing faster and others slower.
What's the advantage of this? Why not just d = {} d['test'] = {} d['test']['b'] = 1 If it's just to show off a cool thing, then I'm fine with it. 
Check if the object is assignable before starting an operation that's going to assign to it. There may be a performance reason not to do so, but that's how it would fail in a statically typed language.
That's almost it. Rather, we're accustomed to x += z to be roughly equivalent to x = x + z, but for Python lists that's not the case at all. We don't expect x += z to affect y as x = x+z would not have affected y. 
 if [item for item in grocery_list if item not in purchased_items]: print "Haven't finished yet :(" Maybe it's just me, but I found myself having to think a little bit more to comprehend what it's doing even though I already know what it's supposed to be doing; especially compared to this: for item in grocery_list: if item not in purchased_items: print "Haven't finished yet :(" break else: print "Finished!" Granted all this is rendered moot by using sets as you pointed out; but I think just because you can make code more dense, doesn't mean you should (especially if you're not the only maintainer). But again, maybe it's just me finding the first example a little bit annoying (for lack of a better term) to read. Certainly doesn't detract from your overall point and was a good read.
You can't do this: x[0] += y, where x is a tuple. Because this is equivalent to x[0] = x[0] + y. The right hand side might be okay, but the assignment back to x[0] raises an exception because x is an immutable tuple. 
It isnt equivalent actually, using `__iadd__` allows the object to be changed in place rather than creating a new list. 
But your example is not specific to lists. It could be any mutable type, and the assumption that y would show the original content would be wrong, because x and y always refer to the same thing. x += z is only equivalent to x = x + z in mathematical terms, not in Python language terms. The += operation should be considered a mutation of the original object.
&gt; I think just because you can make code more dense, doesn't mean you should Agreed 100%. A point well taken.
Why not use the built-in any function? if any(item not in purchased_list for item in grocery_list): print "Haven't finished yet :(" That seems like the "obvious" way to do it to me. I'm pretty sure most english speakers could figure out what that line of code does even if they don't know python.
The fact remains -- it's not the reference implementation. It's not a drop-in replacement of python2.x. It's close. But it's not the same. It's not written in c -- and yes that's a detriment from my viewpoint with the systems I work with. In my mind, I cannot just choose pypy. While I realize many people in the python world are saying "go python3! yay!", but I don't have that option. I'm currently working on an embedded system with an ARM926EJ-S processor. On this processor with this system, using a python JIT would likely be detrimental. I've compiled python for the arm processor. It was a nightmare. Just a year ago, I was working on a VM that didn't have anything better than python2.5. Legacy code and legacy environments are a real problem for production systems. Just wanting to go to pypy is not enough to take down a critical path within your system. 
&gt; of the original object. Yup, and leaves x unchanged, which is quite different from most languages, even C++. 
Damn! I missed the sale. I was off having my first child and missed this. Will have to save up! 
Readability is a function of the reader and the code itself. Therefore, I'm not sure you can really argue that the `for-else` construct sacrifices readability for sparseness. It also seems strange to reject the above and then take advantage of the implicit nature of empty lists evaluating to false. I'm not sure what the consensus is on that, but it was certainly strange to read. Also, regarding the sets, you may want to mention that you can use `&lt;` and `&gt;` to check if one set is a subset of another. And being totally picky, probably makes more sense to check for equality than to check the difference is null.
I assume you mean the use of `get`? If so, I have to disagree that it's opaque, but I can at least understand where you're coming from. If you're objecting to `Counter`, then we have a fundamental disagreement. The clarity of intent is light-years better with `Counter`.
This might be cool someday. I'm working on an editor for Minecraft saved games. In those saved games, the world data is stored as chunked byte arrays. It would be really cool to have Blaze handle the chunked format instead of doing it myself.
I certainly wouldn't use it like that particular example, but I get the impression the author was building up to the ultimate solution, and wanted to show off handy features along the way.
then it seems your point is "changing any component of your software stack is just too hard". Well, we won't help you. No matter what we do, we don't own a time machine. We won't make PyPy come from 80s suddenly. Sorry, you're not the potential target market.
It's definitely a Pythonism that requires getting used to, but I've grown to love it.
I'm probably wasting my time here, but it sounds like you're a bit more defensive than you should be. I like pypy and I really appreciate that someone is working on it. I just can't use it. You asked why, and I gave you a reason why -- it's completely unprofessional as well as myopic to believe that the only people that should ever use pypy are on the cutting edge and have the latitude to choose something bright and shiny and new. If that is the case, then I'm not sure why the python foundation has been funding your work. For clarity: too hard is very different than "not an option." It's not an option for my project. I do not have control over the stack given to me by the manufacturer of my device, and while I can recompile a majority of the software, I do not have access to their compiler or their proprietary software. I'm not even sure they have that... 
True. Although {'a': 'b'} isn't exactly an assignment, that part of the specification is probably the reason for this behaviour. If it was unclear, the specific documentation I was referring to was: &gt; In the following lines, expressions will be evaluated in the arithmetic order of their suffixes: &gt; ... &gt; {expr1: expr2, expr3: expr4} Which is explicitly saying that the dictionary example I wrote should print 1 first then 2.
He's defensive because you first said that you see pypy as a research project and when asked for your reasons, you said why you can't use pypy and the reasons seem to be impossible for the pypy team to address. You said it yourself that running a JIT on that system would be detrimental and, on the other hand, I don't think they'll ever support old Python versions like 2.5. 
It only leaves x unchanged in the rather odd circumstances detailed in the main link, because it fails half way through the operation. In most circumstances it works exactly as expected, changing the original object, which is referenced by both the variables in your example. That's why I'm saying that your example isn't a good reflection of what the problem is here, because if you assign x to y in Python then they are the same object at that point, unless you reassign one of them.
That will break if the items can be falsy. For example, the items could be integer ids. any([0]) will be False.
It used to have a bug where it removed white space from Google Docs when pushing them back to the server. Hope it's fixed.
Cool tutorial! I've got a few suggestions on your last example. You can make the code look prettier by using choice from the random module and the string.lowercase instead of chr(random.randomint(...)). I am also a little confused why you are using the global keyword inside the functions when the variables are already defined in that scope. I hope you don't mind, but I [rewrote some parts](http://bpaste.net/show/cKdaeMPcLsJ4LIA7zFJe/) of your last example to highlight this and show some cool things you can do with python functions. (note: I haven't tested this as I haven't got termcolor installed). Keep the good work up. 
Well you are doing an assignment. You're assigning a value to a key in the dictionary. I'd expect the first key, value pair to be evaluated before the 2nd and so on. So that portion is left to right but the assignment is still right to left.
Go do some online programming exercises. 
Good point. Use of len() might be better suited there. Maybe this is why I don't consider using any() or all() much, eh? Or maybe I'm a dummy. 
What level position is it? How many years experience do they want? How many do you have? 
How does this one compare to Twisted?
one more?
This could be interesting, but unfortunately the introductory documentation is sparse, and there are aren't enough code snippets showing off its features for me to be able to quickly grok what is going on.
They must have decided that the existing frameworks were too twisted for their taste.
This one's an actor model based concurrency. Here's what the tally stands at now(correct me if I am wrong): | Concurrency Method | Libraries | |:--|:--| | Event loop based/callback based/futures/promises/whatever | Twisted, Tornado | | Green thread | Gevent, Eventlet | |Actor model | Pulsar, python+zmq | 
It is actor based but actor model is derivative (higer level abstraction) , so it basically needs to base on something to handle connections and concurrency. If Pulsar for 3.X bases on ``asyncore()`` then I am very curious how it works. OP are you the author?
haha cześć
I have to begrudgingly upvote you for your pun :(
Dunno when “last” was but it’s wrong *now*: Twisted has basic Python 3.3 support in the latest release. Courtesy of Canonical’s sponsoring.
But a lot of the existing are also making *very* slow progress on python 3 compat, though..
Very useful. Can't say I'm a big fan of annotations over vanilla composition. Two big wins for me: explanation of property for mutable vars kwargs / args overview Well written. Many thanks.
That’s why I wrote “basic”. The commenter above insinuated there are intrinsic problems of bringing Twisted to Python 3 though which isn’t true. It’s “just” a huge, crufty code base but they’re getting there.
Clearly it's my unqualified opinion, but I haven't heard anyone except you who liked rope better. If one module sets an attribute in another one that attribute is also not visible in Jedi. (would be cool though)
For the record, I didn't "insinuate" anything of that sort. My understanding had simply been that they were having a lot of trouble porting it to Python 3 and that we shouldn't expect it to be ready in the foreseeable future, and I am glad to hear that they have been making a lot of headway. Regardless, the fact remains that Pulsar *fully* supports Python 3 whereas Twisted still doesn't. That is perfectly fine and is not meant as a slight against Twisted, just that (since the question was raised) this is one advantage that Pulsar has over Twisted. (And honestly, due to the sparsity of the documentation it was hard to tell what other advantages it might have other than this.)
Looks really similar to Tornado, only slightly more focused on some specific concurrency patterns (actors).
Worth reading simply to find out that "lipo" is a fat-removing executable! Yay - made my lunchbreak!
Hi there, I'm the author and I agree, the docs are sparse unfortunately :-(. Pulsar has been written using python 3.2 and adapted to work with 2.6 and 2.7. I wrote it because both twisted and gunicorn (pulsar is a 2011 fork of gunicorn) are python 2 libraries and I needed an asynchronous multiprocess framework working both in windows and linux on python 3 and 2. Some working examples are in the examples directory.
The eventloop and the asynchronous I/O stream have been adapted from tornado. Each actor has its own eventloop.
Now, that's cool. Most useful algorithms with trees that I know need a parent reference.
Right, and I like that approach. But I'm an erlang lover... ;)
They're a workaround for a particular issue (import of test_foo.py fails -&gt; you maybe get a warning somewhere in the test runner output, but still get a misleading ALL TESTS PASSED message at the bottom). I would suggest checking first if your test runner suffers from that particular issue. Then again if you localize all the imports, that makes it easier for you to move tests around to a different module when you refactor things.
&gt; Import failures in the module-under-test (MUT) should cause individual test cases to fail: they should never prevent those tests from being run. whats the point ? &gt; Depending on the testrunner, import problems may be much harder to distinguish at a glance than normal test failures. Use another test-runner, or fix the one you are using :D
What's the case against annotations? I personally find them superior for practically every case, but there's a definite distaste for them among some parts of the Python community.
My comments: 1. There's no need for this `initFun` to exist. The first example can be implemented as: from collections import defaultdict class Tree(defaultdict): def __init__(self, parent=None): self.parent = parent defaultdict.__init__(self, lambda: Tree(self)) This should really use `super()` instead of naming the base class directly, although that's probably not going to make a difference here. 2. You can do pretty-printing with `json.dumps()` using the `indent` keyword argument. There's no need to write your own `toStr` function. 3. Don't check for types by doing `type(inp) in [dict, Tree, defaultdict]` because that will fail if somebody wants to subclass one of those types. The proper way to write such a test is `isinstance(inp, (dict, Tree, defaultdict))`. And you should not check if a type is `str`. There is a `basestring` class specifically for the purpose of checking if something is a string or unicode, so you should check against that instead. 3. When comparing against a singleton, use `is` and `is not`, not `==` and `!=`. `None` is a singleton, so you should never write `foo != None` but instead `foo is not None`. 4. `dict.update()` exists and should be used instead of this `addDict()` stuff. Taking the last four points into account, the second example can be implemented as: from collections import defaultdict from json import loads, dumps class Tree(defaultdict): def __init__(self, inp=None, parent=None): self.parent = parent defaultdict.__init__(self, lambda: Tree(None, self)) if inp is not None: if isinstance(inp, basestring): self.update(loads(inp)) else: self.update(inp) def __str__(self, *args, **kwargs): return dumps(self, sort_keys=True, indent=4)
If we are being picky, then a decorator is a callable that returns a callable :)
Nice writeup. I'd change identity decorator to: def identity(func): return func
Ah thanks man. I've only been programming in python for half a year now. Don't know all the stuff yet. Still learning the deeper things.
There are many other alternatives to Pygame and Pyglet witch may be useful in particular cases. They are probably not the 'best' or 'more popular' ones but they may be useful depending on the requirement of the game. For example: * FIFE -&gt; [fifengine.net](http://fifengine.net/) Specialized in 3D isometric games (used by Unknown Horizons) * Ren'Py -&gt; [renpy.org](http://www.renpy.org/) For dating simulation games ('Tokimeki Memorial' like games), adventures games (LucasArts like ones) and visual novels. * Multiverse -&gt; [multiversemmo.com](http://www.multiversemmo.com) For 3D MMO games. Python is used for the client side (but it's Java for the server side) * Platipy/Spiral -&gt; [Platipy Project](http://platipy.readthedocs.org/en/latest/) For games on 'One Laptop Per Child' XO computers * A bunch of Python backends to 3D engines : [pyirrlicht](http://code.google.com/p/pyirrlicht/), [Python-Ogre](http://www.python-ogre.org/), [PySoy](http://www.pysoy.org/), [Panda3D](http://www.panda3d.org/), etc... All this links to remember than before choosing the right engine, is important to know witch type of game you are planing to do. Is it a platform game ? Is it for an otaku audience ? Is it a MMO ? Did it even need 3D ? Depending on the specifications then narrow the choice of the engines.
I'm the author of the post. I worded it that way as it seemed to me to be a good 1 sentence definition to get started with. I thought that for someone that is brand new to decorators that would be an easy definition to consider first. I later expand upon the definition and explain that decorators in most cases actually return a new function. I think starting off with a more nuanced definition might introduce complexity to the post earlier than needed. I understand that perhaps for some people, like yourself, it might not be the best approach. I still think starting with that simplified definition has merit though.
hey! :) I know what you tried there and I think simple examples are very good to get the idea but it's imperative that those examples remain *correct* otherwise they'll hint you in the wrong direction. if I got the idea right, what you said is that -from the caller's perspective- when you decorate a function it behaves differently than before so the decorator must've chaged it somehow... but that's not what's happening, what actually happens is that the function gets replaced for another that has access to the original so what's wrong with that? that's a pretty simple explanation to me. the decorator introduces a middleman, a proxy if you like but the real problem with that statement is that function *can* be modified, that was my first impression "is it changing the attributes?" that doesn't make sense, it shouldn't change the behavior as we observed so it must be something else right? is he talking about macros? that can't be, Python isn't a Lisp so what then? you see what happens, when you start from a false assumption every guess is the wrong one and that because of the oversimplification, you ended with a koan-like phrase that lost all its meaning and connection to the situation you were trying to describe. but like I said before, regardless of that it's a good article.
MUCH better. Like other posters here, I forget about `any()` and `all()`. Tiny quibble - IMHO if you are using one-line generators, it's always better to have single letter variables, usually i - the longer names don't make it clearer, the scope of the variable is just that one line, and it's a little less to read and type. if any(i not in purchased_list for i in grocery_list): Still, in the context of the article, the set solution is clearly the best one.
&gt; I don't always like using the fact that empty lists or dictionaries evaluate to false, especially when they're stored as a variable. Making that if statement be if len([...]) == 0: might make it more readable for you. It takes very little time to get accustomed to it, and it simplifies your code a little bit, but in many places. It often makes for more robust code: `if foo:` handles the case where foo is None, whereas `if len(foo) == 0:` does not. As a rule of thumb, you should be reading at least ten times as much code as you write. You're going to be seeing that idiom everywhere - and there really aren't very many Python idioms. You might as well stop fighting the crowd and use it wherever you can. The advantage to having a single central source for style is simplicity. It's so much easier to just follow the standard Python conventions rather than puzzling out your own. When I read through the reasoning I so far agree with Guido's thoughts every time - and I probably trust him better than I trust myself on this matter anyway - but even if I thought he might be sub-optimal in some aspects, the advantages to _not having to think about this aspect of my coding_ are huge. So obey the Benevolent Dictator For Life. Don't write `if foo != 0:`, write `if foo:`. Don't write `if len(foo) == 0:`, write `if not foo:`. The people reading your code will thank you for it!
`issubset` could indeed have the fastest implementation of all those proposed in the original article, because it could be doing the operation directly in C code, and because it doesn't create any new objects (as the set difference operator would, for example...)
&gt; Therefore, I'm not sure you can really argue that the for-else construct sacrifices readability for sparseness. I do use it, but I'm also aware that I almost never see this in production code - because (IMHO) most Python programmers don't know about it but also because even if you know about it, you probably use it less than 10% of the time you use a loop. **Did you know** that you can also have [an `else` clause in a try/catch/finally block?](http://docs.python.org/2/tutorial/errors.html#handling-exceptions) It's also only useful in a subset of cases - generally when you need to do something at the end of the block's successful completion but you don't want to catch exceptions on it. &gt; It also seems strange to reject the above Not sure he's really rejecting it as much as "showing all the alternatives". &gt; Also, regarding the sets, you may want to mention that you can use &lt; and &gt; to check if one set is a subset of another. Great tip I didn't know! &gt; And being totally picky, probably makes more sense to check for equality than to check the difference is null. But that condition is not equivalent - say, if you bought everything on your original list, and items that weren't on your original list.
I'm still not convinced of that `if not foo:` over `if len(foo) == 0:` is a truism. There are cases where I don't expect a `None`, and by doing a `len(foo) == 0` I'm enforcing that assumption. `if len(foo) == 0` is much better than `if not foo and foo is not None`.
&gt; Did you know that you can also have an else clause in a try/catch/finally block? Yep! I actually find this to be one of my favorite parts of the language. It's make intention so much more obvious than try-except in other languages. &gt; But that condition is not equivalent - say, if you bought everything on your original list, and items that weren't on your original list. Oops-- didn't think of that case. Definitely makes sense to use &lt; or &gt; then.
A similar explanation is (now?) in the comments of the original article. But as I comment there, this certainly doesn't mean that this behavior isn't very surprising! Consider the following: tup = ([], ) def plus_equals(x, y): x += y plus_equals(tup[0], [1]) # Succeeds. tup[0] += [1] # Fails. One would be forgiven for expecting the last two lines to do the same thing! Do recall that in Python, unlike in C or C++, `+=` doesn't return a value, so on first or even second glance these two lines seem "practically identical". I "understand" why this is true, but that doesn't mean that it isn't still surprising behavior to me. There's also the other surprising behavior - where the operation _succeeds_ but still raises an exception. I can't think of any other place in Python where this happens - heck, I can't think of any other place in _any_ language where this happens...!
Unfortunately, that won't work. Consider this code sample: errors = (0, 0, 0, 0) error_code = complex_operation() errors[error_code] += 1 # vs errors[complex_operation()] The two blocks at the end "should" do the same thing and right now they do do the same thing, but with your suggested language change `complex_optimization()` would never be called in the second case only. EDIT: As Megatron_McLargeHuge points out, the side effect needs to be in the addend - on the right side. Here's the correct code: errors = ([], ) error_code = complex_operation() errors[0] += [error_code] # vs errors[0] += [complex_operation()] None of these statements are "illegal" though - not sure what you mean?
This is incorrect. The problem is specific to +='s definition, not to const vs. non-const. See dougall's correct explanation [here](http://www.reddit.com/r/Python/comments/15v46b/pythons_is_weird_part_ii/c7q5kaq), and see [my example](http://www.reddit.com/r/Python/comments/15v46b/pythons_is_weird_part_ii/c7r13wq) or [aceofears' example](http://www.reddit.com/r/Python/comments/15v46b/pythons_is_weird_part_ii/c7qd6n8) of very similar operations which don't in fact fail. 
I came in thinking this would be an adapter pattern of sorts, so the requests 0 API could be used with requests 1.0, but this is probably better. My deal breaker with Requests last time I used it was I couldn't requests multiple pages at a time from the same domain from different threads w/o the auto keep-alive putting everything for the same domain into one socket.
 &gt; There are cases where I don't expect a None, and by doing a len(foo) == 0 I'm enforcing that assumption. That's what assertions are for. If it is imperative to you, for some reason, that a variable never ever be None, then place an `assert foo is not None` the very first time you see foo - it makes it very clear to the next person what you mean. Hiding this key condition as something to be deduced as a side-effect from an operation is doing two unrelated things at once. compare these two functions: def function(foo): assert foo is not None # ... many lines ... if not foo: # ... def function2(foo): # ... if len(foo) == 0: # enforce that foo must be an array or tuple and non-empty. # ... And if you look at the second example, it isn't the same - it actually enforces _more_ than foo not being NULL, but that foo is some object for which len() is defined, definitely not the same thing. But there's a higher-level question - why do you want to ensure that foo isn't None, anyway? Because you think that code somewhere else will eventually fail? Well, let that code fail if it will fail, instead of failing here "in case" that code elsewhere else does. 
I usually see/use them for orthogonal stuff. For example, if I've got a web app (Django, Flask, what-have-you, the idea is the same), there's probably a function somewhere that gets invoked whenever the user hits a certain URL. If I want to require the user to be authenticated (and possibly authorized) to access that URL, I just drop a `@authenticated` (or whatever) on the function definition. That way, when I'm scanning my file, I see the fact that the user has to be authenticated right there next to the function definition. If I use the explicit composition approach, I have to scan past the end of the function def and look for it to be reassigned. In other domains, they might be used differently.
You might consider taking the folder (or a list of file names) as arguments to the script. This would allow you to use shell globbing when calling the script to provide file names, or allow you to drag a folder on the script in a file manager to minify that folder. A command line argument for compilation level would probably be useful too, if you went down that route. Check out the [optparse](http://docs.python.org/2/library/optparse.html) module.
This is good - I was thinking about how clunky the configuration options are right now - editing source code is obviously not the most effective way of going about it. How would I go about implementing dragging a folder onto the script? Would I just use code to translate the folder or file name into --options? But yes, fleshing out a full command line utility would be awesome, since I couldn't find good way to do what I specifically needed using Google Closure's options. 
When using optparse, you'll eventually have a line similar to: options, args = parser.parse_args() Your "args" variable there will contain all command-line arguments that aren't part of an option. I'm not a windows guy (haven't used it in years), but I'm pretty sure that when you drag a file or folder onto a program, it supplies the path to that file or folder as an argument. If you drag more than one at a time, it supplies them all as different arguments. This means that your "args" variable will contain a list of paths to files that were dragged onto your program, or provided at the command line. You can loop through them and minify them. If you wanted to be clever, you could check to see if there was only one arg, and that arg was a folder, and you could find all the files in it yourself.
I am in the same process and here are some of my choices: * Python 2.7 for the Python version for now. (Python 3.3 when all modules i need will be ready.) * A WSGI compatible web framework. I am using Pyramid, but Django, Flask, TuboGears, BlueBream, Bottle, web.py Web2py, an many more... are all good alternatives. The framework itself is just a mater of developer choice just try them an choice the one you like. * Apache+mod_wsgi during test phase and as long as in don't care about performance, scaling, etc * Chausette+Circus for serving and managing if one day i care about (witch will probably not happen) * PostgreSQL for the database back-end mainly because i will have, at some point to migrate a big bunch of data from an application using it. Also because i think it's good software. (ZODB would certainly have been a good Python choice) * SQLAlchemy for communication/ORM needs between Python and Postgres * **cracklib+libcrack** for password validation, to forbid my users to use 'Passw00rd', '123456' and other stupid passwords. * cryptacular.bcrypt to encrypt the passwords in the database * fanstatic for javascript and CSS serving. This is particularly useful to manage thing like *Twitter Bootstrap*, *Modernizr*, *jquerry* or *CKEditor* just as if they are regular python modules * unittest+WebTest for the tests Im am still hesitating for a few stuff: * PIL/Pillow or ImageMagick for image conversion and gallery stuff ? I will probably choice *Wand* a recent ImageMagick binding but i am still hesitating a bit. * Formencode, WTForm or one of the hundred available python forms libraries ? I am actually using Formencode but i am testing WTForms and may even decide for something else as an alternative. For me one of the key point will be the internationalization support (and particularly the lack of internationalization documentation).
Also, a friend suggested using [argparse](http://docs.python.org/2/library/argparse.html) instead, since optparse is deprecated - just as an FYI
It's currently implemented as evaluate index getitem evaluate increment amount increment setitem I'm suggesting evaluate index getitem confirm setitem won't fail evaluate increment amount increment setitem So it would work the same in both cases. I don't think the exact failure mode of an illegal statement is that significant either way. 
OK, very good - I'll have to look into and experiment with that. Thank you :)
yeah, I can imagine this would be useful, also probably more conducive to source code analysis. Interesting, thanks.
Odds are using the same keep-alive socket when requesting from the same domain will give you better speed than multiple concurrent sockets, especially if the remote web server has a limit on the number of concurrent sockets.
Specifying an exact package version is not a stopgap solution. It is in almost all the cases the only correct thing to do. (Unless your code is a package used by other packages)
If you know the length of the number, a useful function is the modulo function. You just do this (num - num % 1e6)/1e6 # returns 111.0 and you have your answer. If you don't want it as a float, you could convert `1e6` to `1000000`. 
And if you don't know the number of digits: int(log(x)) will give you that (make sure to do the log in base 10).
You probably shouldn't be keeping phone numbers as ints, because they don't behave like ints. You'll never add, subtract, multiply, or divide phone numbers. You will, however, access individual digits of them, so an array is a much more appropriate type. If you absolutely must store them as ints for efficiency reasons (unlikely), then at point of use you should probably just convert them, unless that is too expensive (even more unlikely). Remember readability is generally more important than minor performance gains, so digits(num)[:3] is much easier to understand than (num-num%le6)/le6 as skier_scott suggests doing.
And if you're not sure which base your log is in then (python's log supports an optional 2nd argument that specifies it's base btw) you can always write it as follows: the base n log of x is log(x,m)/log(n,m) for any base m.
Completely agree. I'm TAing a lab this semester that has some python. So I'm going off what the previous TA did. The homework says store the phone number as a number. Then find the first three digits. The hint they gave was *"use the math operation Divide"*. I really have no idea where the hell they got what they did. The assignment has them make a list with contact info. I'm sure they did phone as an int to show that you can store different types in a list. 
Integer division does exactly what you want. No modulo required. &gt;&gt;&gt; 1112223333 / 10000000 111 That obviously assumes you are dealing with a 10 digit phone number and want to chop off the first 7 digits. As masterpi said, probably not a good way to implement it in the real world, but for homework, well... you're the TA, so *shrug*. I don't know what version of Python you are using, so you might need the // operator instead.
python is in the process of settling on one that gets integrated into the stdlib. every new one in that state could end up giving new ideas to the people designing the one that everyone of us will be using soon. so yes, one more is a good thing.
you have to take the ceiling first so you have to do int(ceil(log(x,10))) otherwise 1/2 the time the rounding will give you a lower amount then you need.
No. Example: Log(10)=1 Log(90)=1.9 Taking the ceiling will result in giving different answers for 10 and 90, which is clearly not the result we want in this situation.
I also use 100; it's been convenient on the monitors I've had for the last several years.
I use 79 for the sake of being pep8 compliant. It works fine for 99% of my code, but 1% just wants to go long, and I let it. Of course, that 79 character limit comes with a price - principally less descriptive variable names.
That's not what I was seeing, the limit is typically like 6 sockets, though, and I could get 6x speedup by using 6 threads (well 6 workers). 1 keep alive connection was as fast as 1 regular connection, though that could very well be a by product of the exact servers I was communicating with.
That would just require swapping my 3rd and 4th steps, but there's a sequence point between statements in your first version so you can't expect them to behave equivalently. In any event, I don't think it's important to change anything. I was just pointing out that the most intuitive thing is to fail a little closer to the way static analysis would detect a failure. Both statements result in a TypeError being raised. How much more illegal can something be in python?
79 for Python, 100 or more for Cython. I usually split my editor (kate) vertically.
I have 2x wide screen monitors and like having a billion and a half editors open at any given time. If you can guarantee it'll fall under 79 characters, that means three side by side editors with my font size in one window. Handy and PEP8 friendly.
Flash back! Do you care about line length in this century? Punch cards are out, you know? As FORTRAN formatted lines. I use as many characters as I need, and let vim wrap the line when needed. 
*sigh* I hope converting to a string and using [:3] would be accepted too.
What you want is floor(log(n)) + 1
It definitely depends on the kind of requests. 6 keep-alive sockets will obviously be much faster than 1 keep-alive, but if you're constantly tearing down and constructing new sockets there can be a lot of overhead.
:set tw=100 But I try keeping it to 80 chars if easily possible. Ie mainly no string concatenation necessary. Readability wins! 
I use 75. Odd, I know, but the rationale is that 75 + 3 (" + "/" - " from diffs) + 1 ("\n") = 79, and have a nice buffer char so that I'm never at the edge of my terminal window. Also, vim is my text editor and the extra space lends itself nicely to line numbers.
You need to use Eventlet for that
Ah I misunderstood you, you want to create a request.Session() for each of your requests.
How is that different from num / 1000000
none, I use vim and the terminal but it's no longer the 70' deal with it.
You clearly don't understand. I suggest you have a look at the Python C API. The part about PyObject pointers or pointers in general might be revealing to you.
Fuck you, give me back print "stuff"
Uhh.....
While line oriented editors, diffing tools, and limited width displays are still commonplace, line length matters to some degree. As a child of the 90s I personally find anything &gt; 79 sorcery
Do pandas, numpy, scipy, and matplotlib all work?
But even for 2.7, installing numpy, scipy, and matplotlib on mac os x is not an easy ride.
As a c-style language migrant to Python, the print 'stuff' syntax scares me silly o.O love me some comforting function parentheses.
Oh Pascal. That takes me back to the early 90s. I probably will, but I think the point was to show that lists can handle different types, and show the difference between math operators on int and float. It does need changing though.
Its not a CS course. Its spatial modeling (GIS). Programming is secondary to what I do. Most the scripts I write are simple calling functions, and passing variables.
I used to think a 3to2 tool would be useful, but the more time I spend writing Python 3 code the less need I see for one (unless you need to support 2.5 or older). My current project works on both 2.7 and 3.3 and the only 'ugly' support code I need is: from __future__ import unicode_literals import sip sip.setapi('QVariant', 2) And 2/3 of that is just to make PyQt behave. I wish I could use `itertools.accumulate()` and a couple other Py3 things, but honestly it's not that hard to develop in 3 and keep your code 2 compatible. Outside of curmudgeonliness or library requirements (what's left? PIL? Biopython?), I would be curious to know why everyone hasn't started transitioning to 3 for new code.
Hmmm.. maybe time to see if my 2.7 stuff can port over.
I'm comfortable with `print 'stuff'` Not so much with `print 'stuff',` and `print &gt;&gt; sys.stderr, 'stuff'` That's the point where you realize it should just be a regular function rather than re-inventing keyword arguments. Also, in real programs it is a moot point since I would generally be using `logger.info('stuff')`
Sage, in my case.
Another fun python variable manipulation question is: given an int, write a one liner that returns the string representation of the int, but with a comma every three decimal places starting from the right. (i.e., 1 return "1", and 1000 returns "1,000") (Rules: the one line cannot use anything that has to be imported, and cannot use any string formatting)
I just started delving into Python seriously this past year (we're a small private research company primarily focused on telemetry for migrating fish). Python 3 has served me well for the data we manage but I've definitely noticed the issue that the author points out when trying to track down resources. I remember being disappointed that an otherwise great book I ordered about data management for biologists was focused exclusively on Python 2 for its programming section. From a practical standpoint I could certainly do things in my research in either Python 2 or 3 without causing any short term issues. Thing is I've dealt with other issues related to using legacy programs and standards (ancient Access databases that should have been dumped years ago come to mind). I can't help but have concerns I'd be possibly screwing myself or our clients down the line by not staying at least somewhat current with language versions and standards. While I don't see immediate problems with scientists sticking with Python 2 it's hard to say what's pragmatism and what is just unwillingness to stay current. Definitely good to see some movement on Python 3 related tools. My needs aren't as intensive as what I see my physicist friends though so maybe I'm insulated from some of the more serious aspects of this issue.
Why not? I do this regularly with no problem. Installers for 32 and 64 bit have been available for a long time.
My plan, at our weather modelling company, is to write easily portable code for the time being. Then hopefully ubuntu 13.04 will come with python 3 versions of e.g. matplotlib and basemap [which are annoying to install with pip] and we'll transition to that.
For: &gt;answer = str(myint)[:3] I see about 0.7 us For: &gt;length = int(log10(myint)) - 2 &gt;answer = myint / 10**length it takes more like 1.5 us I don't know which of those you are seeing as faster or slower and why. This is all using 10 digit numbers as with OP. I thought maybe yours is better as the numbers get longer, but in fact trying 50 digit numbers seems to favor string conversion even more (1.3us vs 5.3us).
I'd recommend gevent. I prefer its API.
It's not, it's just the way I thought of first. I would use num // 10000 to explicitly have the divide by int method. 
No , 2.7 is great and everyone in the research field will not move programs that have taken them YEARS to write. Maybe Python 3.0 programmers need to include a module that automatically converts!
I was holding out for matplotlib and sympy. I might now make the change. What are some of the big differences between 2 and 3?
&gt; The scientific community was still using fortran 77 in 2005 And there's a reason for it. Fortran is fast, well understood in the scientific world, and has a large body of prior art. No one is going to migrate their work just because there's a nifty new language out there. (Long time programmer, language dork, and serious Python user here, BTW...)
As a sysadmin who has to support these endeavors, the argument that 'I've been running the same FORTRAN 77 code since 1986' gets tiresome. I've had requests within the last year to get a compiler functioning again. At some point, we must all move on.
The assignment works better as a string anyway, because then you can have them loop through the characters to ignore the filler characters like "(" and " " until they get three digits. That's more realistic than telling them about division, which they should know anyway. OK, most realistic would be to use a regex, but baby steps. 
If anything the scientific community will move faster than the other communities.
I am currently developing a scientific application (for stochastic process calculi) in py3. From the very start I assumed to use py3 and stick with it. So I am individual scientist and use py3. 
It should port just all right. my project can be run in 2.7 and 3.X. I am using scipy, matplotlib and numpy too. 
Look at offical standard E164 for the format of a telephone number. Start here: http://en.wikipedia.org/wiki/E.164
This lecture includes: print "hello world", that is the level of programming most of the students have.
Personally, I will spend the effort when I get some advantage out of it. I.e. faster execution, new modules written only in 3.0 and so on.
I usually just eyeball it to what seems like a reasonable width. I have a lot of pretty techniques for wrapping lines, but I use non-standard indents locally, so I know things won't look the same for others anyway.
I hate to tell you this but the apps that run on the systems are the reasons those systems exist. No one builds servers in the spirit of absolute elegance or cleanliness. I currently am working with an organization that has some 800+ *nix servers in their data center, about half of which are outdated, old, hard to patch ... you know the drill. At the end of the day, though, they make money - lots of it - and the incentives to migrate to newer platform isn't there if all you can argue is "It's old and hard to maintain." In actual fact, there ARE arguments for migration but there are commercial/regulatory things that likely would not apply to scientific research.
just use `//` anyways and always if you want to do truncating division. it future-proofs your code and it, as well as the accompanying `from __future__ import division`, has been in python since 2.2, which is ancient. hell, in 2.2, `True` and `False` didn’t exist! it’s very safe to believe that your remaining code has incompatibilities with python ≤ 2.1, so just use `//` and `from __future__ import division` in any python 2 code you write.
it’s there since 2.2. so if you use `True` or `False` anywhere in your code, it’s already ≤2.2-incompatible and you should use `//`.
I'll look into it, thanks
`for char in telno: if '0' &lt; char &lt; '9'` isn't much more advanced. 
Google "2to3"
&gt; Breaking backward compatibility was controversial, to say the least. I think of the debate as one between the pragmatists – those who see Python as an extremely useful tool, which should not be unnecessarily tampered with – and the idealists – those who view the Python language as a living, breathing entity, which should be allowed to grow into the fullest and most Pythonic possible version of itself. I don't agree with this. There are pragmatic arguments in favour of a move to Python 3, and most of the stuff I've read from the devs have focused on the practical benefits of moving over. Most (if not all) of the changes introduced in Python 3 are justified by reference to practical concerns and use cases, not ideology. Python 3 is, arguably, a better language to write and maintain than Python 2 (given an equal level of similarity with each) and thus there is a strong pragmatic argument for moving to that language rather than waiting around while more and more code is written using the old, inferior, language. Of course, there are also pragmatic arguments *against* the change, and I'm sure many will argue that some changes in Python 3 don't actually improve the language, maybe even making it worse. I'm just saying that it's not simply a pragma-vs-idealism debate. There are pragmatists and idealists on both sides, and from what I've seen, it's the pragmatic arguments that receive the most attention from both sides.
I will as soon as OpenCV start supporting it.
I'll start it off... If you subclass dict type, you can use \_\_missing\_\_() method which will get called if d[key] is missing as "\_\_missing\_\_(key)" and it won't raise a KeyError exception.
After reading the initial document, I came up with this. It isn't a one liner, but I had fun with it. class tree(object): def __getattr__(self, n): if n not in self.__dict__: self.__dict__[n] = tree() return self.__dict__[n] if __name__ == '__main__': united_states = tree() united_states.new_hampshire.capital = 'Concord' united_states.new_hampshire.population = 1320718 print united_states.new_hampshire.capital print united_states.new_hampshire.population 
They did: http://docs.python.org/2/library/2to3.html
Yes, but it often costs even more to build a newer system from scratch. And the costs of maintenance are spread out over time, while the cost of upgrading is a single, huge chunk. I'm not saying that's necessarily a valid reason for or against updating; I'm just pointing out how management is going to look at it.
[Here is the Nature Article](http://www.nature.com/nature/journal/v493/n7430/full/nature11717.html#/comments). Unfortunately you have to be a subscriber or go through your School Library access to get the full pdf
No. When they get old enough, they just stop being maintained entirely ... which is zero cost until they fail for the last time.
http://code.google.com/p/pythonxy/wiki/Welcome - In case anybody else didn't know about it, like me.
My experience with macports for python stuff, and specifically numpy, scipy, etc has been terrible For the last two years it has been much much easier to install everything from the dmgs they all provide
Why are you so excited!
Made your point :)
It's the blog post title copied verbatim. The blog post author is probably excited because software development feels rewarding when you reach milestones. Hope that helps. :)
Not to mention there are small corner cases where equivalent syntax doesn't produce the same output: &gt;&gt;&gt; 3, (3,) &gt;&gt;&gt; print 3, 3 &gt;&gt;&gt; s = 3, &gt;&gt;&gt; s (3,) &gt;&gt;&gt; print s (3,)
In Java you have to name your files after the public class inside it. Because you have more classes than packages, that makes it worse for me.
I should have put a smiley on my post too. I was just being cheeky. :)
(probably should have stated this) I have been using 2.7.x, and upgrades have been pretty smooth. Can't say the same about their other ports though...
Age 6? I am not a parent but the way I look at it, you gotta start coding yourself and show your kid what is possible so he can get excited. I don't think there is some special GUI that will be appealing to a 6 year old, you have to make programming appealing, otherwise you are going to be one of those parents who push their kids to do something and the kid is going to be like "WTF? mate". Anyway, code yourself for a year, wait until your kid hits the 1st or 2nd grade (I don't know when kids go to school these days...) and show him how to solve math problems with programming, or show him how to create simple games so he can impress his friends. (and you should be able to do it after a year). Just my .02c. When all else fails, whats wrong with PyGame?
This might be the easiest way of getting a gui working http://www.cs.usfca.edu/~afedosov/qttut/
I believe i didn't phrase it correctly, i am not interest in teaching him how to program, this is more of project for me. To create a easy to use, program that teaches basic math functions easily and in a fun manner. One of the main issues i am running into is that the Python GUI is very bland and much more like reading a textbook rather then playing a game.
Sounds like programming to me! 
You can get an OpenGL context in Qt and draw to that. Or use the simpler painting tools: http://zetcode.com/tutorials/pyqt4/drawing/
I suggest you head over to [/learnpython](http://www.reddit.com/r/learnpython/) subreddit. There are several good learning resources listed on the sidebar, and usually people are quite willing to answer any questions you might have. And once you've learnt the basics you might want to check out [/dailyprogrammer](http://www.reddit.com/r/dailyprogrammer/), to practice and hone your newly adquired skills.
Thanks, that was a very helpful answer... and I can actually sympathise with what you're saying. It took me months to muster up the courage to try virtualenv, I was very intimidated by it and could only imagine I'd break my python install. Anyway, I'll check it out. Maybe it's a good option to introduce python to some friends/colleagues taking the *scary* out of it.
There is also portable scientific Python distribution for Python -- [WinPython](http://code.google.com/p/winpython/). Another option is [Anaconda](https://store.continuum.io/cshop/anaconda) from Continnum.io. &gt; How would this be different or better than just installing virtualenv, sqlalchemy, pyqt, and all the listed modules yourself (besides the obvious of it being done automatically)? It's not as easy as it look (at least on Windows). Take a look at [Blaze](http://blaze.pydata.org/docs/install.html#installing) for example: &gt; Many of the dependencies ( llvm, numba, ... ) are non-trivial to install. It is highly recommend that you build Blaze using the Anaconda Python distribution. My default Python version is 3.3.0, but for scientific stuff I use WinPython, because it's easy to install (unpack where you want) and uninstall (just delete directory).
Also I'm having tons of problems with virtualenv and a stable debian, I don't have root on. All libraries and also python are from the stone age, and pip just fails to install those packages successfully. Maybe this package would help me.
Yep. But note that there are other authors, research is a very competitive area and the journal probably the more 'important' one. Everybody accepting the boy as a contributor means something. 
It means that having his father *first* author played a big role…
A good introduction to programming with an excellent GUI is MIT's [Scratch](http://scratch.mit.edu/). Lots of good tutorials and can be used to create animations, games and tools. 
It's not a waste if you have multiple files in split view.
Look into the OLPC, a project of a Laptop developed for kids in developing countries, that runs Linux distro with Sugar, a GUI with tons of apps (called activities) developed in Python including tools for kids to learn and program in python. You dont need to buy the Laptop, you can download free the full Linux distro with Sugar and make a Live CD, Install and run it from a USB flash drive, install it on a partition or VM it. You'll get amazed by it. Just google Sugar Labs and OLPC.
This is more of a quiz/test than a teaching tool: https://bitbucket.org/jgrigonis/mathfacts/downloads It's something I wrote quite awhile ago using the tkinter ui.
I would use the Python track at Code Academy: http://www.codecademy.com/tracks/python There's a lot of other resources to go to after you've completed that. 
&gt; is there anyway to get a working GUI, that would be appealing to a kid around the age of 6? I would suggest you start him with [Scratch](http://scratch.mit.edu/). Once you feel that he is well acquainted with it and cannot learn any more from it, then move him to to [Alice](http://www.alice.org/index.php). I don't think a 6 year old child should start from Python, even if you add PyGame in her curriculum. If you still want to stick with Python then I will suggest looking into "Invent your own computer games with Python" and "Making games with Python and PyGame". Both these books are available for free at the [author's site](http://inventwithpython.com/). Best of luck!
I've been told that NC State University still teaches Fortran in its computer science department.
&gt; and much more like reading a textbook rather then playing a game. Welcome to a lot of real-world programming! :D
To name several differences between Python(x, y) and other distribution : * The inclusion of the documentation and examples for every package. * Most packages are custom made to have *optional* features enabled. For example, IPython comes with ipdb (allows using the IPython debugger anywhere pdb is used) and paramiko (enables SSH tunnels on Windows). 
Take a look at the [package list](http://code.google.com/p/pythonxy/wiki/StandardPlugins) - It's suited for general non-scientific computing as well (that's that I use it for). 
I did this for Boggle/Scramble. https://www.youtube.com/watch?v=OnWI_SCesvs I built my data structure based on Aho Corasic, still wrapping my head around this code...
Check out the raspberry pi. Main os comes with scratch and more python stuff than you can shake a stick at 
I don't mind talking about solved problems if one brings something novel to the discussion our aims it at neophytes who need a gentle introduction. This seems to offer neither benefit and just gets tedious.
That part isn't of much interest really: shove /usr/share/dict/words into a trie then walk the trie using letter combinations as prefixes. Unless you do it in the most inane way possible, it'll be much faster than a game of letterpress anyway[0]. The neat part would be image recog and a bit of AI (to handle territories) to automate the playing of letterpress. [0] checked my old code, a straightforward unprofiled trie-based script running on Python 3.3 takes 16s to load /usr/share/dict/words and discover all words matching TFA-provided board versus TFA's final code taking 12.5s. And 4.65s when fixed up for py2 compatibility and run on pypy)
I'd recommend keeping things simple. Think of the simplest games and program that to show your kid. Random-text-adventure games, pong is a simple game for example. If you want simple GUI framework, you can use Qt and PyQt.
Without caveats?
Actually, you shouldn't need the .sh wrapper. You can point your .desktop file directly at the Python script, something like this: [Desktop Entry] Name=My Program Version=1.0 Icon=myicon.png Type=Application Exec=python3 /home/foo/myprog/program_name.py If your program needs to have the working directory set, you can add: Path=/home/foo/myprog
This grew out of a meeting of my local Python user group. We spent a couple of hours building a [similar game](https://github.com/gistfoundation/adventuregame-pysheff), where the player had the rather artificial objective of retrieving golden keys. The new version is based on some lessons learned from that, along with some thinking about how to leave room for future ideas - a third dimension, combining items, or saving game state, for example.
I've taken classes in Fortran 77!! It was funny, though. Now I use in my research Fortran 90 + Python 3. Whenever I can, I try to bring someone from the "dark side" : )
You should totally make it an MMO, too. And maybe if the players reach a certain level, they can add their own content to the game!
So... kind of like a MUSH?
These exist. They're called muds, and they're the shit! Probably the first thing that got me going with the idea of programming. There actually aren't that very many good python codebases out there for this. I can only name a couple.
Incredibly false analogy, for two reasons. * Numerical scientific code, for a variety of reasons, is trickier than most to get right. Having a battle-tested, gold standard implementation is a huge win for everyone, and reimplementations (in addition to practically inviting bugs) would be slow to gain users when a long-trusted implementation is available. * In the vast majority of scenarios where these routines are employed, *speed matters*. Reimplementing in Python (yes, even PyPy) is simply not an option in many scenarios where these Fortran implementations exist. Reimplementing in C or C++ is pointless because even "C speed" is the wrong benchmark: Fortran has had vectorized computation intrinsics for decades, and that extra information about the high-level structure of the computation plus 40 years of compiler research has resulted in Fortran compilers can generate incredibly efficient code, blazing past that which a C compiler and manually written for loops are capable.
I'm aware they exist. This project just felt so much like one I had to joke about it.
You should really describe this library better. I'm a Django user since 0.96 and I have no idea what this is for.
Interesting you should mention this, because I actually did this a while back. I wrote an implementation in python first and then scala, and an OCR for letterpress in python. Indeed you are correct, the simple part is finding the words, and you don't really care just about words in the game, because there are multiple ways to play almost every word. For example, if the word is "cat" and there are two a's on the board, then you have two ways to play your word. Of course, when you're looking for the absolute best words (tend to be really long), the number of possible ways to play each tile permutations truly skyrockets. Once you have something working that enumerates all the tiles and permutations of tiles that are valid words to play, you need to find a system to score it. I chose something simple -- choose the play that maximizes the number of dark colored tiles you have, break ties by the overall number of tiles that are your color. If you want to get more fancy you can explore the game tree more than one step, by running your program against itself and choosing the play that minimizes the success of your opponent during his or her next move. I haven't done this yet, because my program was already well beyond the point at which all my letterpress playing friends no longer want to play against me, and none of them were willing to write their own solvers to make it interesting. Anyway, sorry for rambling. If you're interested in the code, I put the scala code on github scala code: https://github.com/mattomatic/letterpress python ocr: https://github.com/mattomatic/letterpress/tree/master/ocr Also, if people are interested, I have a python implementation of the real solver as well, but I didn't put it on github. PM or respond. :)
I *think* it allows you to query objects like dicts the same way you query Django recordsets.
&gt; Having a battle-tested, gold standard implementation is a huge win for everyone, and reimplementations (in addition to practically inviting bugs) would be slow to gain users when a long-trusted implementation is available. Yeah, if you ever wrote good code you'd know that you're expected to compare output to the last significant figure. I've yet to see a re implementation of numerical code that didn't reault in serious bugs being found in 'platinum code'.
Thanks for the update! No worries about the sparse documentation, but in the future if you want to really impress people about your project so that they'll think about using it themselves, then you might want to spend a little more time writing kick-ass introductory documentation to make it easier for your potential users to get as exited about your project as you are. :-)
Wow, that is really cool!
Installing SciPy and friends is easy. Only if you want build it yourself you are fucked.
I would still use fabric as phil_s_stein suggested. Ssh give you security, you do not want to end up with custom software which is hacked. 
Can't push my tile. Says the git repo is read-only. Shouldn't you open this up if you want people to contribute? 
Thanks. I'd prefer contribution to go through Github pull requests, though. Leaving it completely open would make it easy for someone to slip malicious code in. If you've used Github to contribute to other projects, you already know how to make a pull request. If you're new to it, [they've got helpful information here](https://help.github.com/articles/fork-a-repo).
I should have guessed it would already be a thing. ;-) It's not currently multiuser, though; each player explores their own instance of the world. A multiuser version is another possible extension. In the meantime, it could be interesting to have an internet-connected tile where users can leave messages for each other.
Not yet! This is the first time it's been publicly announced, so there hasn't been anyone to talk about it. I guess we could easily make an IRC channel for it, though.
Now that is neat. Thank you.
&gt; split panes for source/console. Indeed. My editing setup pretty much always has a vertical split, whether it's in Emacs or in IntelliJ/PyCharm (may also have horizontal splits within the vertical, but the screen is pretty much always split vertically). 75~79 characters mean things fit comfortably in my 1680 screen with a bit of leeway for those special cases where you can't break, for a bit of window chrome (e.g. sidebars) and for diff views (which add a few characters), very long lines are a pain because now I have to scroll. I need 1920 so I can have 3 columns (3-ways merge views) though.
This is a cute project. I really love these kinds of things. But I had a few questions and maybe a few suggestions (if you're open to 'em). 1. Shouldn't there be a Tile base class? It seems peculiar that you would have a new class with the same name in the same module for every single tile. 2. Reusing commands seems a bit hard in this model. Have you considered making an extensible Command class that allows the user to customize them without having to write new code? Or maybe having a dictionary of available commands? 3. Does this have a concept of entrances/exits? It looks like if you're somehow at a grid position, you've entered into it as if there was an entrance or exit. Am I correct? (This isn't bad or anything, I just wasn't too clear on that.) -- Suggestions (if you're open to them): 1. Make commands easier to reuse. A dictionary of lookups maybe? 2. Store the tiles in a different way that allows you to reduce the number of classes you have. Description and Leave could both be attributes rather than methods too. Since they're common to every single tile. I would suggest a yaml file. And just because prematurely optimizing is all the craze these days, you could even load these yamls into mongodb or redis when you first start up, so the entire file isn't sitting in memory. 3. You're going to need a dummy object class that can act as a container -- almost everything is a container on a fundamental level. People contain loot, chests contain loot, books contain spells, etc. I wrote up a gist to better explain what I mean -- https://gist.github.com/4473757 Keep in mind, I think this project is really cool. I don't think you need to change ANYTHING. It's your project, so you should do what you want and take pride in it. I just thought I'd pass along a few notes. :D Muds (as they exist now) typically have millions of rooms. You're gonna want an easy to maintain project structure that lends itself to that kind of thing. tl;dr: I like your project, keep up the good work! Check out my notes if you don't mind (hopefully) constructive criticism.
Might be nice. And/or a wiki. People might want to claim tiles or blocks of tiles. Or collaborate on sections. Just toss around ideas in general. 
You did, thanks!
Did you keep your python script running at all times throughout the day? If so (apart from leaving your computer switched on forever), how?
Yep, that is worth thinking about. I'm also thinking of a framework for combining objects. Maybe lighting a torch should be combining torch+matches.
I couldn't get my script to execute when I pointed to it directly because it needed the path set and I didn't know you could set the path in the .desktop file. Thanks for letting me know. Do you know where the documentation for .desktop files is located? 
I wish you have better fundamental knowledge about Django before pointing out a historical version number :) No matter, this is what you would like to read about: https://docs.djangoproject.com/en/dev/topics/db/queries/#complex-lookups-with-q-objects
Dude, I'm well aware what Q is, but some information other than just an example and talking about "two cents".
agreed, I kept trying to figure out where the two cents came in as well
I have a media server running all the time, ran it on that. 
Posted on reddit, must be true.
A proper link to github for EJTP would be nice. Also maybe you should change the title to specifically say the DNS project is CJDNS. I have never heard of these before myself but I usually am interested in any python dns server. I am currently writing one myself used internally.
Yeah. The problem with audio is that I can't scan it and see whether I'm actually interested in reading in-depth. As it was, I listened to a few minutes of him talking about 80/20 in politics, then gave up -- with written content, I could skip to the parts I'm interested in, which may be all (or none) of it.
I quit a top 10 world physics school because the "old platinum code" they were running was making rounding errors in FORTRAN 77. The code was so old it didn't use IEEE 754 conventions, while the newer C code on top did, thanks to stupid shortcuts that saved about 1 in 1,000 cycles during some multiplications on the complex numbers. Not only was it wrong it was also so unreadable because of all the "speed improvements". Judging by the comments left I was the first person to read that code since the early 80's. I found this out by implementing the functionality of a 3000 odd line library in under 400 lines of Haskell and comparing results. Nobodies test suite had caught the errors before because there was no way for C or standards compliant Fortran to produce the numbers which would cause the errors to prop up thanks to the different lengths of mantissa used inside the library and those that got fed to it. The only way to notice it was to compare a really long series of calculations done inside the library in which you had a chance for the end of a mantissa to be a series of uninterrupted ones to the results to a slower standards compliant version doing the same. Oh and no one was interested in using the correct code or even checking if the problem was as big as it looked because 30 years of work being slightly wrong isn't a good thing have to admit to. Thanks to NDA I can't ever say which school at which university and which work group did this. But it's all ok because no one ever asks for the source code in science so no one will figure out just how full of shit supposedly world class institutions are.
&gt; A proper link to github for EJTP would be nice. Huh, I thought I did have one... good catch. And to think I used to be an editor... but yeah, I've fixed that now. And have an extra one for convenience and good measure! https://github.com/campadrenalin/EJTP-lib-python &gt; Also maybe you should change the title to specifically say the DNS project is CJDNS. Actually, despite the name, CJDNS isn't related to DNS at all! It's more like a distributed VPN. The confusing name stands for "Caleb J. Delisle's Networking Suite," which just happens to initialize in a confusing way. DJDNS, the DNS technology I'm working on, makes it a lot more logical to do domain resolutions on machines that only have access to CJDNS internet, which is important for the Roaming Initiative project. So they do work together, but DJDNS is also useful on the regular internet, and hopefully will slowly take over the world of DNS servers! &gt; I have never heard of these before myself but I usually am interested in any python dns server. I am currently writing one myself used internally. I'm going to be trying out [pymds](https://github.com/thekad/pymds) for this project, I'll have to remember to let you know if it's any good :)
That shadowed font makes my eye ache.
A piece of its source for the lazy: trailer_url = 'http://youtube.com/v/rC8VJ9aeB_g?hd=1&amp;autoplay=1' argv = lambda x: x in sys.argv if (argv('install') or # pip install .. (argv('--dist-dir') and argv('bdist_egg'))): # easy_install .. webbrowser.open_new(trailer_url) 
**79** I have widescreen monitors at home and at work, so I split the IDE (PyCharm). I also use a decently large font so I get about 30 lines on the screen while maintaining visibility of about 82 columns on each side--that way I can detect long lines, etc. Other than that, we use PuTTY at work which defaults to 80-char width, so it's a nice fit for that, too.
Your Google-Skills are bad and you should feel bad. Here is a text-mode holdem in python http://delysid.org/pypoker.py
If you are looking for a single player against the computer, there are going to be a couple of main components. 1: A deck, including shuffling and dealing. 2: Hand evaluation 3: Algorithm for the computer to either bet, stay, or fold. 4. Betting system for the player. 5. Display for the player. Those are going to be the biggest obstacles. The remaining ones will be trivial, making a hand to store your cards, making hands to store the computers cards, actually putting them together in a turn structure.
its not working, missing modules.
I also +1 for Panda3D, it was quick to get up and working.
I have a single monitor and put my console to the right of my code window rather than below (in Eclipse).
Not sure if I'm a fan of the / syntax. It seems like using kwargs or passing in a dict would be easier.
Neither would work because dicts and (IIRC?) kwargs are both unordered, where in this case the order is important.
To be fair this is the first time i've seen this trailer...and it looks pretty damn good. I'll be watching this for sure, thanks OP.
Yeah, it seems something funky is happening with Python. I'm guessing it's a floating point rounding issue. Clearly len(x) is a better solution.
That's a very good point, I hadn't thought about that.
Avoid windows. Python is fucking horrible on windows. I have 4 different versions installed on my windows machine to satisfy different dependencies, and installing libraries with external dependencies like pyglet is horrible.
We've set our coding standards to 120 columns at work. It's actually surprising how well it works - on a 1920x1080 monitor, I can split the screen vertically and still have plenty of room in PyCharm for the project explorer on the side. Most of the time, the only lines that end up longer than 80-100 characters are formatted strings (log messages, exception messages, etc...). 
What about [`collections.OrderedDict`](http://docs.python.org/2/library/collections.html#collections.OrderedDict) for Python 2.7+ users then?
I wasn't terribly impressed until the Pascal string example at the end, but that's pretty cool. Given that it's one more dependency in my code (and the operator overloading is a bit weird) I'm not really sold on using it over `struct`, but I'll be keeping an eye on it in the future at least.
An ordered dict would definitely work! But the syntax would need to be: Struct(odict([ ("foo", byte), … ])) Which... Seems strictly worse than just passing a list of tuples.
If you don't like the operator overloading, it seems like you can just pass a bunch of tuples: ipaddr = Struct(('a', byte), ('b', byte), ('c', byte), ('d', byte))
I see that you did! Much better :) Looks cool too
I add a newline when it makes sense. I find code religiously truncated at a certain arbitrary column number misses the point of fitting code into a certain line length; the point should be to think about whether this is the right algorithm. But I've seen things like so: print("This " + that + "somthing else, blah blah blah blah blah blah" + \ "blah") which I find horrendous to read over just leaving it on one line. 
That's the first thing I thought too. 
It’s not too late to switch ;)
This sub needs more high-content, high-quality submissions like these!
So we have python-oauth2 for OAuth 1.0 and pyoauth2 for OAuth 2.0. I wouldn't mind if projects could pick an entirely unrelated name as to avoid that type of confusion.
In constuct 2, that's exactly what you do: each construct has a name (required), so you write Struct("spam", Byte("foo"), Int16("bar") ) but that doesn't make sense for any composite construct other than Struct, e.g., Sequence, Array, Repeater, etc., do not use the name. it also forces the introduction of the oh-so-silly Rename construct which simply wraps an inner-construct with a new name
that's where construct shines: protocols and file formats have all kinds of internal dependencies, often much more complex than length-value. trying to express these relations in imperative code is both ugly and requires separate code for parsing and building. for example, see the PE (windows EXE) file format: https://github.com/construct/construct/blob/master/construct/formats/executable/pe32.py it uses pointers and string tables and what not, but once you capture these dependencies in the data structures, you can do both parsing and building.
If users who have Requests 1.0 install our API client, would you suggest we forcibly downgrade them to 0.14, breaking their other code? Specifying exact versions is the point. The problem is that the current Python packaging ecosystem does not let you use two different versions of a package with the same name in the same environment, so in order to specify two different exact versions, you have to give them different names.
pyoauth2 is a client, not a provider, though. To make it more confusing, there is also [oauthlib](https://github.com/idan/oauthlib), a generic library that implements both!
Yesss... I've been waiting for exactly this. Went as far as a couple of experiments on my own, but caught up in some of the implementation details. http://www.stuartaxon.com/2012/01/09/cairo-with-python-ctypes/ Hope this is a drop-in replacement - would be great if I can switch to pypy..
Does this support some of the things not yet in pycairo, like cairo-gl ?
Yes, the API [is compatible](http://packages.python.org/cairocffi/overview.html#compatibility-with-pycairo). I’ve seen your project, but CFFI is so much nicer to use than ctypes :)
&gt; In light of this, the Python Software Foundation encourages all wiki users to change their password on other sites if the same one is in use elsewhere. What, were the passwords stored in plain text?
I'm just really glad someone's written this now :) [EDIT] Ahhh... I guess CFFI should be faster a well.
I'm still a bit hazy on opengl, though it's on my list-of-things-to-learn. I guess it'll involve getting a context from pyglet or pyopengl and passing that to the function that creates the cairo-gl Surface. The RecordingSurface is the big thing missing from PyCairo... support for this alone would be reason enough for me to try switching. Patch to add recording surface support to pycairo: https://bugs.freedesktop.org/show_bug.cgi?id=36854
Moin uses sha1, which may or may not be salted, depending on when you created the account.
The vulnerability now is brute computing power, combined with password dictionaries from past cracks. Hashes like sha1 are designed to be computationally cheap, and a modern GPU can do billions of them per second. If you've got a botnet, or money for EC2 compute time, or just half a dozen powerful graphics cards in a box, you can crack a substantial fraction of the passwords in a leaked database. bcrypt and pbkdf are designed to require much more computation. For the user, it's still a tiny fraction of a second. But it makes cracking them orders of magnitude slower. They can also be adjusted, adding extra cycles of encryption as more computing power becomes available.
Hmm.. I think the big difference lies in the main goals, Jedi is an autocompletion library, rope is a refactoring library. I tried a few things within spyder. With rope the following things don't complete (work in Jedi though): - generators/iterators - `__call__` and other magic methods - completion within classes/functions - dynamic arrays - *args, **kwargs - lambdas - simple sys.path manipulations - invalid code, rope cannot handle too many errors, in Jedi it will always work if some parts of the code are valid. - performance in big files Rope isn't "bad". It's just not as good as Jedi for autocompletion. It's a really good Refactoring library (although I haven't really used it for that) And PyCharm's autocompletion... is also worse than Jedi ;-) Edit: Sorry I forgot to answer the rest, Jedi detects virtualenvs. sys.path modifications are possible if they are small and if think that it should do something, which is not possible now, please report it to github.
Still, I don't think that address the fact that this thing uses a relatively large salt. Regardless of computing power, this is still relatively secure in a modern context.
Shouldn't "brute computing power" work in both directions though? I would have suspected that as raw power becomes increasingly available it would be adopted equally by black and white hats alike. Why aren't we using stronger algorithms more?
That's precisely the idea behind bcrypt and PBKDF and the like.
Well, that's what bcrypt and pbkdf are for. Unfortunately, there's plenty of passwords still stored hashed by weaker algorithms, like SHA1. I guess some admins don't know about the issue, and migrating your existing password DB while keeping everything running sounds like risk. And, of course, you assume it won't happen to your site.
Incorrect, we run them all on different VMs these days (though we don't think the attack managed to break out of the moin user anyway).
Newer users in Moin are a salted SHA1 hash (trivial to brute force, but at least not rainbow tables). The problem is as we have been using Moin for many years there are many user accounts with older unsalted SHA1 passwords. This is not good.
We think it was the same explot, but have no proof due to now-missing logs.
*tl;dr* salted-sha256 is many orders of magnitude better than plaintext, but also many orders of magnitude weaker than pbkdf2/bcrypt. --- *(didn't mean for this to be so long, but drinking coffee / avoiding starting work)* All of the following are desirable qualities in a password hash: 1) large salt, 2) large time cost per hash 2) variable time cost, 3) large memory cost per hash, and 4) variable memory footprint per hash. **Salts:** Rainbow tables are only really useful if the hash has &lt; 4 bytes or so of salt... more than that, and even *they* grow too large. The state of the art is still good old fashioned brute force. The catch is that modern crackers like [John the Ripper](http://openwall.info/wiki/john) offer refinements like fine-grained control of dictionary generation, multi-core / cluster support; and most importantly, GPU-based routines for performing massive numbers of parallel attacks used as many GPUs as you can fit on your motherboard. **Large Time Cost:** And that's where hashes like MD5 &amp; SHA1-3 fall down. They were *designed* to be efficient, to be pipelined, and to use as little memory as possible during operation. So brute forcing them is really easy - especially on GPUs where accesses to shared memory are expensive. **Variable Time Cost:** Password hashing only needs to take a fixed amount of real world time (= as long as the user is willing). As your system gets faster, it can do more work in that time - so why not take advantage of that? Usually this involves doing repeatedly composed `hash(hash(...))` operations... not just a fixed number of times, but a variable number, which is then encoded as part of the hash. That way, as CPUs get faster, you beef up the total number of cycles required on your system, and make brute force attacks that much slower. This is what SHA256-Crypt and PBKDF2-HMAC-SHA256 do. **Large Memory Cost:** This is why BCrypt is even harder to brute force than any of the above - it's internal construction requires a fix chunk of memory that's constantly read &amp; rewritten as the hash is calculated. Not only does this make things slower, but GPUs are only now approaching enough per-core cache to handle this, so for now the attacker is stuck with using more expensive CPU-based routines. **Variable Memory Cost:** Much like variable time-cost allows the hash to grow with CPU speed, Colin Percival's [scrypt](http://www.tarsnap.com/scrypt.html) was designed to configurably take up more and more memory - allowing you to *force* it outside of GPU cache, no matter how big those caches grow. While it's a great idea in general, SCrypt is relatively new, and only now are folks like the JtR developers trying their hand at gauging it for weakenesses. Also, there's some concern as to how much time / memory SCrypt will needed for security - and if the cost will be too much for large sites (e.g. reddit). Since salted sha256 has a fixed time cost and small memory footprint, it is millions of times faster to attack; which is why SHA256-Crypt, PBKDF2-HMAC-SHA256, and most importantly BCrypt, are the current "good" algs. 
We're still waiting on PIL also.
Assuming the attacker knowns the hash (and therefore the salt), a brute force attack will take roughly the same amount of regardless of the salt size - it's just another fixed input. E.g. say the algorithm is `sha256(salt+pwd)` - just configure the dictionary generator to prepend the `salt` to every input it tries. As long the result isn't hitting sha256's block size (~64 bytes I think), there's no additional calculation cost.
 spam, egg, bacon, sausage = ( (x,) for x in ('spam', 'egg', 'bacon', 'sausage') ) breakfasts = filter( lambda b: 'baked beans' not in b, # they're off :( ( # source: http://www.youtube.com/watch?v=anwy2MPT5RE egg + bacon, egg + sausage + bacon, egg + spam, egg + bacon + spam, egg + bacon + sausage + spam, spam + bacon + sausage + spam, spam + egg + spam * 2 + bacon + spam, spam * 3 + egg + spam, spam * 6 + ('baked beans',) + spam * 4, # oops, forgot `* 4` the first time around ('lobster thermidor aux crevettes', 'mornay sauce', 'truffle pate', 'brandy', 'fried egg on top') + spam ) )
Sure, I mean the Python Software Foundation itself, we operate out of a nice new private cloud thanks to some awesome donations!
Second to using better hash algorithms, I think that's the most serious problem with password hashing today - too few systems have "rehash password on user-login" routines, resulting in poor migration. Not that I'm ragging on wiki.python.org admins in particular, or even MoinMoin - it's an internet wide problem. And when there are banks using good ol' 8-char only DES-Crypt, it's not even the biggest problem :(
That is a pretty good idea. I'll see if we can come up with something! Any suggestions?
Nope sorry, I can appreciate that it will be hard to find something meaningful without having "oauth" in the name though. Perhaps an analogy to the functionnality the module provides?
There is no other way to rehash a password, unless you have the plaintext somewhere else (obviously a bad idea). How else do you have access to the plaintext for rehashing?
Not necessarily. The application was compromised, theoretically the login process could have been jacked.
When the old hash and current password hashed match, then take the new hash of the current password and store that in the database, and remove the old hash from the database. That part is easy. The difficult part is managing multiple hash types across many users and tables/databases.
But the old hash and the new hash will never match unless you hash the same plaintext again. Which you need the plaintext for...
Pretty sure warbiscuit is talking about rehashing during the login process. You're still limited to "when the user provides you with the plaintext" for rehashing, but for even remotely active users, you can easily set up transitional migration to any level of password security, without inconveniencing anyone.
Yes, I agree, that's how I have it done in my system. It's really the only way to do it. And to the two people who's comments are not showing up in the thread: You have a bit of a misunderstanding of hashing algorithms. You can't hash the existing hash again, and then wait until you get the plaintext, hashing that again twice to get the same hash in the end.
You would expect they run in separate virtual envs, not have one library to rule them al installed at the Python site-package level. Unless you are installing one single app on a server machine installing everything under global site-packages is a very bad idea, and even then there are great benefits to not installing in site-packages and using a virtual env. When you update to the latest version of your app you can create a fresh virtual env containing the latest tested and working versions of each dependant library, and then run the app out of that. This prevents ugly boring work like uninstalling or upgrading dependencies in/outo of the site-packages folder. EDIT: I think I misunderstood OP. Yes you can't run two packages with the same name... that will never work and you can't downgrade or upgrade. The lib writer could have changed the package name to reflect the change, ie urllib vs urllib2.
&gt; How else do you have access to the plaintext for rehashing? . &gt; rehash password on user-login
Yeah - I think that's been used a few places - e.g. when pre-1.0 Django migrated from md5 hashes -&gt; salted sha, it had to support two different hash types (`sha1(salt+pwd)` and `sha1(salt+md5(pwd))`), but was able to "add" security to all existing hashes in one go. Such a approach isn't even incompatible with "rehash-on-login", it merely provides a stop-gap in case you're hacked before everyone logs in again. In terms of practicality, there are a few cons - it adds an additional layer of code and hash storage complexity, and primarily is only useful to protect users who don't log in very often. Furthermore, the relative security of composed hashes depends a great deal on what the problem with the original one was. Adding a work-factor by doing `bcrypt()` of existing `sha1()` hashes is probably a good idea... any vulnerabilities exposed by the composition should point to a flaw in one/both of the underlying hashes. But if the original hash was something foolish like `crc32()`, updating to use `bcrypt(crc32())` won't change the fact that `crc32()`'s output space is way too small - no reasonable bcrypt work factor would help. edit: That said, IMHO if I was running something like a major email provider, or a bank, I'd certainly go through the extra effort.
&gt;And that, dear friends, is why you should run each and every web app as a different user ;) I had never thought of this. Thanks for pointing that out.
He's saying do it at login time. When the server is doing password validation it has access to the plaintext of the password that was entered on the login page. So you SHA-1 that plaintext, compare it to the SHA-1 in the database (if the user account uses the older unsalted hash method). If they match, generate the salt, hash the salt+password then stored the salted, hashed password and the salt in the database.
did you catch the part where warbiscuit said "rehash password on user-login"?
Salts do not *at all* reduce the time of an attack on a single hash. Salts simply make sure you cannot attack the hashes with a pre-computed table mapping hashes to plaintext, and it also means if 50 users have the password "password", the attacker would have to crack all 50 hashes, instead of just cracking one and knowing the rest of the hashes are also "password". So salts are useful, but if the algorithm starts with "md" or "sha", then it is very vulnerable to typical dictionary attacks and bruteforcing.
No, I missed it the first time but re-read later and caught it. My bad.
Also OS-level virtualization.
PIL is the 3rd most requested package in the [Python 3 poll](http://www.python.org/3kpoll). So if you're interested, do go and help test it.
am I the only one using 78?
I can't install on windows. I had pycairo working fine. 319 path = ctypes.util.find_library(name) 320 if path is None: --&gt; 321 raise OSError("library not found: %r" % (name,)) 322 # 323 backend = ffi._backend OSError: library not found: 'cairo' 
Would this be an acceptable solution? https://gist.github.com/4489948
&gt;the attacker knowns the hash (and therefore the salt) I don't understand how this is implied. My understanding is that a common approach is to use a short salt, randomized per user, but not store any information about what the salt is in the database. Now the local system has to "brute force" to see if any combination of `sha256(some random salt possibility + user supplied pwd)` matches the hash value in the database (2^16 possibilities for a 16-bit salt) while the cracker is stuck testing combinations of `sha256(any random salt + any candidate pwd)` i.e. they'd need to multiply their rainbow table size by the number of possible salts.
If the attacker gained shell access to the server to get the db, they also had the ability to snag the code - and thus should be able to use the same method as the server.
pretty much every OS does this with certain apps. On my mac, i have users like _netbiosd _spotlight _locationd, etc. 
Yup, that meets the rules. Here is mine: "".join([c if (len(str(value)) - i) % 3 != 1 else c + "," for i, c in enumerate(str(value))])[:-1] 
Oh cool, I like the blog post. I actually came across this problem at work because we needed to pretty print some numbers, but we're still on python 2.6 (they added a string formatter that does it in 2.7). Also, I saw you went to UCSD, me too! 
True, but the timeframe of the attack was about a week, only a very small number of users would have authenticated in that time frame compared to the thousands on disk.
Tracking here: https://github.com/SimonSapin/cairocffi/issues/1 How did you insall pycairo and cairo?
Excellent :) I'll certainly have a look at porting shoebot to this when I get some time. If you look in the cairo code there are a few other interesting kinds of Surface, I believe there's TeeSurface, a windows specific one as well as the GL ones.
Yes, I’ve seen these but I don’t need them at the moment. They’re easy to add if someone asks for them.
It's interesting, but just as a warning to Python novices: This is **not** how to write python code people! This code is *far* from simple. Terse does not mean simple. It is unstructured, used bad variable names, indenting is sloppy, hard coded strings all over the place, zero abstractioning, bugs all over the place, uses os.system to call a OS-specific command, doesn't follow the RFC for IRC properly, the networking code is not proper (recv is not properly buffered), uses str.find() in some places but "in" in other places and assumes array indexes on split strings will exist but doesn't check for them properly I'm sorry I'm being harsh, but when demonstrating Python code, I expect at least a reasonable attempt at readable code. 
To make it easier to test, I think I'll create a maintenance branch for Pillow 1.x and merge fluggo's branch in to master
Full featured Python IRC bot: http://pypi.python.org/pypi/pmxbot
Are you @randfb on GitHub? I have [a possible fix](https://github.com/SimonSapin/cairocffi/issues/1#issuecomment-12041568) if you want to try it. Please follow up there.
I should push my pil bugfixes before this happens. edit: first bug fixed
This is just plain not all that useful (a user script that runs in browser would make much more sense) even for people who have Reddit Gold (which is required to get the information described from one's user page).
&gt;Edit: for fucks sake, fix that indentation ;) What are you talking about?
I wrote a framework to create IRC bots in Python. I based it loosely off of Django and how it creates projects. You can check it out at https://github.com/silent1mezzo/jeeves-framework
supybot has been my choice for irc bot for a while
Anyone who wants to write an IRC bot in Python should look into Twisted. It gets you started right away and is well-tested.
Could you (or anyone really) elaborate on some of those terms (i.e. hard-coded strings, abstractioning) ? 
I'd be interested if there were examples, or perhaps documentation and not 'coming soon' haha. Are you still working on it, or is it a dead project?
Don't fear the method.
I hadn't updated in a long time but I'm planning on writing the docs and completing some features in the next month.
I use [Yet Another Useless IRC Bot](https://github.com/JulienPalard/yauib). It's simple, dumb and easy to extend.
I would check out [Twisted](http://twistedmatrix.com/documents/current/api/twisted.words.protocols.irc.IRCClient.html). I have a bot running using twisted and it's fantastic.
I used to use Pyramid quite a bit, but I've become a bit taken by Flask. It feels a lot simpler and cleaner than Pyramid and might be another option you can explore.
Here is another implementation (in Pyhton but real time compiled to C99): https://github.com/mdipierro/ocl/blob/master/example_black_scholes.py
Numpy version please?
 reduce(lambda x,y: x+max(0,strike-ST()),range(trials)) &gt; Sorry about the overuse of reduce and lambda functions – I’m kinda smitten by them today for some reason. No kidding. What's wrong with this? sum(max(0,strike-ST()) for _ in range(trials))
Oh wow, I cant reply separately to everyone but thank you all together for the help and criticism. whether it was constructive or destructive, I don't mind. mean criticism just makes me want to work harder to prove you all different. Thank you either way. I don't want to use libs at this time because honestly I am still learning the basics of python it just helps me to use them in something I'm interested in I learn it a little better.
Awesome. I really learned a lot from your post.
I realize that I have got a lot to learn, and I appreciate all feedback. A windows distributable can be found in the distributable folder. All comments are welcome :)
79, although I'm sometimes a little sloppy should a line be a few characters longer.
Awesome! For one of my first projects, I tried to write a simple advection-diffusion model in Python a couple years ago, got sidetracked rewriting the core in C and never finished it (although I did have a slowly diffusing blob rotating around a box at one point). I'll have to save this for the rainy day when I have time to futz around with that again.
when i see "what do you think", i will think of "元芳，你怎么看？"
Yes I've looked at some code samples and read some documentation but I'm not sure how or where i could implement it. 
Do you have any *specific* questions?
Python doesn't support *real* multithreading, due to its Global Interpreter Lock, so adding threading would not help greatly.
That's a little disappointing
Although it doesn't support true multithreading, you *can* [parallelize in Python with multiple processes.](http://docs.python.org/2/library/multiprocessing.html)
My comments: * README file that describes the project what is it? What it does? What are requirements? How to run it? * When doing method comments read about docstrings (PEP257) 
Seventy nine. * tradition * decent lowest common denominator for remoting or sharing * comfortable viewing/editing, even on a 10" screen * doesn't tolerate run-on lines or overly deep indentation/complexity 
Gotta say, that is quite cool :)
I'm on mobile so I can't fix it right now but by the time you've written this post, you could already halfway have fixed this :) The bottleneck I see right now is the constant recreation of bytes instances. I'd fix this by replacing the decoding with one traversal over the input file (as opposed to constant `data = data[1:]` and similar), and the encoding with a byte buffer.
Maybe this? http://pypi.python.org/pypi/BitTorrent-bencode/5.0.8.1 Based on the official BitTorrent source and should be Py3k compatible by the looks of it. Edit: official support for Python 2 only, but the code seems to be portable.
Am I reading it correctly that he's stepping through a day at a time to generate the final asset price, S_T? Giving it a time period t, of 61/365 would accomplish the exact same thing without having to call a function for each day in the option's life. This is quite a complex explanation of a simple-ish concept. For those interested have a look at http://www.codeandfinance.com/pricing-options-monte-carlo.html
[Practical threaded programming with Python](http://www.ibm.com/developerworks/aix/library/au-threadingpython/)
You can use Cython and do matrix manipulations on NumPy arrays without the GIL using the ``with nogil`` context manager and then spin the calculations and then execute the computations in multiple threads. This is a fairly advanced technique though, but it is possible.
I love all of these automation projects. Only complaint is that I wish there were better solutions for NOT going through the power in your house for communication, but instead something like a wireless solution. Whether that be plugged in for power or be battery operated does not matter. The wall communication solutions are just far too unreliable. 
I didn't realise this: I don't know anyone using Python 3 in the LHC collaborations. The list of software meant to be used for official stuff is [here](http://lcgsoft.cern.ch/) (currently python 2.6) - I'm not convinced we'll move to python 3 for official work for a while.
NICE. I've been looking for something like this to add to our build process.
Very clever. Nice job!
I think how they are doing this. Ever since 2009, I've submitted 1 or 2 (sometimes 3) talk proposals to Pycon/Djangocon, but I've never had one accepted. As much as I want to believe my talks were not accepted because my proposal wasn't good enough, I can't help but feel like the real reason is more political. It sucks to see a core developer give a vapid talk, while "unknowns" like me with interesting and unique ideas get rejected. I really hope this voting concept catches on. If it does, I might actually start submitting proposals to these conventions again.
well just ran it the code base at the day job. and it confirmed my suspicions, now I have definitive proof of where the hairiest code is. I assume you will get a pypi release eventually? if so, make sure you have baker as a dependency in your setup.py. I did a pip install on a tarball from master and I had to install baker afterwards in order for it to run. But that is understandable considering there's no official release yet. Other than that, it works as advertised and I find it to be very useful. :)
Can you post something on volatility and how to calculate it please?
What'd I say? :-) I thought it was relevant.
I have moved to using multiprocessing instead of threading module and it has been very painless for me. So much that now all my code uses multiprocessing instead of threading.Thread and sometimes I have to remind myself that I can do with threading when my "threads"are mostly IO bound. The library is very similar to threading. Although I still use threading module for GUI apps. So yeah as jmgrossen further down has linked to you, the multiprocessing module is your friend in your use case of parallelization. 
Since you probably already know python and just need to further your knowledge, I would suggest Doug Hellmann's website http://www.doughellmann.com/PyMOTW/threading/ He writes pyMOTW. Although I know most modules that I need to get work done off my head on any given day, [I am a devops/systems architect], I still every now and then find myself learning something new reading his PyMOTW when I am coding new stuff outside of my daily work. EDIT: And this should be interesting as well for your use case: http://www.doughellmann.com/PyMOTW/multiprocessing/ 
It is working with Python 3 now and I've uploaded 2 fixes and 3 features. Maybe someone can test the features before we pull them into the main repo.
For the mccabe complexity, you can also use flake8.
I installed it trough pypi and indeed did had to install baker manually later. Ran it for our project and the results were pretty interesting :)
why the name radon? radon definition: noun Symbol Rn A colorless, radioactive, inert gaseous element formed by the radioactive decay of radium. 
The volatility that is implied in the option? So the 'vol' variable in the script shown here? Or do you mean the volatility that the asset/stock actually realises?
This is done
OK, [done](https://github.com/flying-sheep/bcode). `pip install bcoding` Rewritten with speed in mind. uses file objects for everything, python’s buffering should do the rest. /edit: the link in the post now points to my code, so i guess he found his answer :)
Thanks! Looking forward to trying this out. 
Don't downvote this man, flake8 is a great tool! (pep8 checker + pyflakes + mccabe complexity calculation) http://pypi.python.org/pypi/flake8/
So you use the name of the file to theoretically figure out the episode information for a specific video? Pretty nifty. 
There's a lot more to security than just picking a cipher and shoving some data through it. The classic blog post on this is [If you're typing the letters A-E-S into your code you're doing it wrong](http://chargen.matasano.com/chargen/2009/7/22/if-youre-typing-the-letters-a-e-s-into-your-code-youre-doing.html). The author may have been on drugs at the time, it's hard to tell, but he makes some good points. For instance, you didn't have a mode arg to PyCrypto.Cipher.AES, so it used ECB mode. See Wikipedia's remarks on ECB mode, in particular the image encrypted using it: http://en.wikipedia.org/wiki/Block_cipher_modes_of_operation#Electronic_codebook_.28ECB.29 Better to use a library such as NaCL designed to have a secure-by-default API. See http://cr.yp.to/highspeed/coolnacl-20120725.pdf and http://nacl.cr.yp.to/
Yep! If that doesn't work, I try to look at relevant metadata for the file in question. Unfortunately, there are relatively few files with good metadata in circulation. I'm going to try using the name of the parent directory as well.
Sounds cool? :)
PySilesia invites you for our next meeting, we'll be talking about REST implementations in python web frameworks. If you happen to be in Silesia area (Poland) Thursday January 17th come and join us.
I am new to this and from what I understand the "vol" variable represents the volatility of an asset or stock or option for that matter. I was looking at getting a stocks historical data and figuring out how to get the values for "vol" variable for it. I hope this makes sense!
If you'd like an open source project to lend a hand on, [Gevent](https://github.com/SiteSupport/gevent) could use some help! 
I'd love to see this for the (also ipython-based) Flask-Script shell. 
Exactly :-) Once I usually chose meaningful names (starting with "py" for example), but then I started looking for more creative names.
Thanks. Yes if you look into setup.py you'll see that Baker is indeed a dependency, but it's included in extras, so that you would actually do: pip install radon[tool]. I did this because initially radon should have been used programmatically, but now that the CLI interface is a convenient way to use it, I'll certainly add Baker as a required dependency and update PyPI package.
As a member of this year’s PyCon US Program Committee (PC) I can assure you, that being a core dev doesn’t help you much if the PC doesn’t think your topic is worth a slot – we have rejected a lot of talks be lots of “famous” people. But please bear in mind how many proposals we’ve got. To get through you have to bring something catchy to the table *and* be credible about it. An extreme example is that we won’t let someone speak about cryptography or security without a proper track record. And of course you have to hope that someone else with even more credibility on that topic doesn’t submit something very similar. I can’t speak for last years since I wasn’t involved, but as an example: this year we had *a lot* of community talk submissions and had a very hard time to choose. And of course, people with more fame/credibility here had an advantage. But we had also to reject proposals by PyCon (non-US) organizers. And last but not least, bear in mind that something *you* find “vapid”, might be interesting for others. The PC tries hard to get a balanced conference together. Voted schedules tend to skew towards the hot shit du-jour – like EP 2012 had way too much PyPy to my taste and every Python conference has a strong Django-bias. If you want to know why your proposal didn’t make it, please reach out to Jacob as offered in the rejection mail; maybe you did the same mistake all these years? I don’t know and I don’t want to patronize you since I have no idea who you are and which were your proposals. But real feedback might be enlightening. Other than that, Tarek’s advice is very solid here – and he’s a core dev who got rejected too btw. Take the time to build community credibility around an interesting and unique topic and your chances to be allowed to talk about it will rise. But there are still no guarantees since we get so many so great proposals – which is a good thing. All that said, we know our work is *not* perfect. We’re human, we have biases. Since you seem to feel, that your interests weren’t properly represented, I would like to invite *you* to join us next year to do a better job. And with “you”, I mean everyone who fosters this feelings. We can use every perspective we can get.
Wrote a short example of how to add this to your buildout configuration here: http://awesomeco.de/blog/adding-code-complexity-analysis-to-your-buildout/ A nice feature to add would be analysis by package name as well as by path.
I prefer to write and run unit tests. Use an in memory sqlite db to save time. 
I'll certainly improve it! As for now you can also look at the documentation: https://radon.readthedocs.org/en/latest/ That too is WIP, and unfortunately on Chrome MathJax is not loaded if the user does not allow it... For this I opened an issue in ReadTheDocs issue tracker. 
Thanks, I'll take that into consideration! If you want you can open an issue on Github.
Never tried that. I use pylint + pep8 (great tool!) + radon + (occasionally) autopep8.
Take a look at what [The Renamer](http://www.therenamer.com/) did. It might give you some inspiration.
Awesome. Starred for later use. :)
Currently I use [tvnamer](https://github.com/dbr/tvnamer), but I'll have to give this a try sometime.
Send you a pull request that should improve performance even further (totally untested though :))
You could try IPython's [autoreload extension](http://ipython.org/ipython-doc/stable/config/extensions/autoreload.html)!
Yes, there is no command line interface to Halstead metrics yet. How are you using it? :)
Have you tried Beautiful Soup or other web scraping tools? Any reason why those wouldn't work? (Or was this just an exercise you wanted to try?) Looks very impressive regardless. How long did it take you to write the scripts? I'm a rookie and trying to figure out how long some more robust projects might take. 
It was an exercise i wanted to try. I like to give myself mini-assignments to code because i like performing implementations myself. Also, i never heard of Beautiful Soup (but after googling it, it looks very interesting - thanks!) They didn't take me too long, a bit more than 3 hours of coding in total probably.
dbr has some great code -- I'm currently using his `tvdb_api` module to interact with the tvdb and it's a huge step up from the crappy Requests code I wrote. This having been said, he doesn't seem to have a GUI app and I'm not a huge fan of some of the API decisions he's made. Basically, I thought I could do better, particularly with regards to the use of custom file name formats. `tvnamer` uses user-specified regexes, but I (as is the case with most people who don't know how to use regular expressions) happen to hate regexes. I thought a much more intuitive approach would be to use python formatted strings, e.g.: "{seriesname}{sep}S{seasonnumber}{sep}E{episodenumber}{sep}{episodename}" `sep` is the seperator (a '`.`' by default), and the other kwarg placeholders can be any key found in the `guessit` library's `Guess` class. This particular example yields something like: It's.Always.Sunny.in.Philadelphia.S01.E01.The.Gang.Gets.Racist.avi This is undocumented so far, but I plan on developing this to the fullest extent possible and baking in a large number of popular formats. The second thing I'd like to do differently is to really push the API end of things. I'm hoping that `Scrappy` can be a user-friendly library for developers who may want to include such scraping features in their code. That's why there are a bunch of kwargs in the `Scrape` class that don't get used in the CLI app -- they're meant for fine-tuned use in scripts. To this end, I have two specific projects in mind: 1. I want to write an [XBMC](http://xbmc.org/) plugin to automate renames with Scrappy upon adding media to the library. 1. I want to add a plugin to [flexget](http://flexget.com/) that can rename a file once it's done downloading, and before moving it to a target directory. Flexget has rudimentary support for formatted renaming, but with out the TVDB scraping, which I think will be a worthwhile addition. I mention all of this in the hopes that someone gets interested and feels like contributing =)
Thanks! If you ever try it, please feel free to give me some feedback (either on Reddit or on github's issue tracker)!
Good to hear! Feel free to leave some feedback either here or on GitHub!
This is, as it happens, my initial inspiration. It's a great little app, and I was saddened by the lack of a suitable alternative on linux. I have a few gripes with it, which I aim to fix.
God forbid that man create a script for the simple pleasure of it and then show off his work. It's not like the man advertised his script for commercial purposes or even flogged his website and said "hey, visit my website for awesome comics! Please click my ads!" This was an exercise, no more, no less and certainly no reason for any of us to get up in arms. If the script was flogged for sale or other such hornswaggle, then you would certainly have a reason to grab a pitchfork. 
Ahh, ok. I'll try to briefly explain a little about volatility in general then. If anyone disagrees with what I've said feel free to correct me :) ---- Volatility in general is an annualised standard deviation, and there are two volatilities to consider when we're talking about options. ---- **Realised/historical** volatility. This is the volatility that the asset has actually experienced (hence 'realised') over a particular period. This is generally measured by taking an annualised standard deviation of the daily returns. This is looking back over the **past**, it's just telling us what's already happened. **Implied** volatility. Option prices are dictated by a few inputs: * underlying price, S * the strike, K * risk-free interest rate, r * volatility, v * expiry date, T In the Black-Scholes way of pricing an option, the volatility parameter we set here is saying what the asset will realise in the **future**, over the life of the option. Of course, we have no way of determining what will really happen over the life of the option, no-one can predict the future. It's known as *implied* because you can *imply* what the volatility is if you know the price of the option. So there are in effect two measures of vol, realised is backward-looking and implied is forward-looking. How do we determine the volatility to use when pricing an option then? Using the realised vol might not be accurate, as the past isn't necessarily a predictor of the future. It's worth noting now that an option's price is essentially a function of its volatility. The higher the vol, the higher the option's price. Buying or selling options is taking on risk, and traders want a premium for this risk. It's quite common for the volatility used in an option to be above the realised volatility. ---- So as for **calculating** volatility... to calculate the historical volatility that a stock *realised* you can follow some simple steps. A brief Google search yielded: http://25yearsofprogramming.com/blog/20070412a-volatility.htm (Look at method 1.) Trading options can actually be thought of as trading volatility. Option prices fluctuate based on the underlying price AND also on the market's view on volatility at the moment. So for calculating you can't really *calculate* it. However, you CAN find out what the market thinks the volatility is at the moment, the *implied* volatility. This is fairly straightforward, but I'll leave the steps out here as it could be quite long. Let me know if you want me to explain it in another reply. ----- How's that? I apologise if my explanations aren't too clear! I'll happily answer any Qs.
Your point number 2 is most interesting to me. I currently have flexget start downloads in transmissionbt which then runs a script when the download finishes, and one of the things it does is call tvnamer. Having all that integrated in flexget would be pretty cool. However, regex's are the best :P My one line perl (I know, blasphemy 'round these parts, sorry) rpn calculator: $_=&lt;&gt;;print while s/(-?[\d.]+) \s+ (-?[\d.]+) \s* ([%*+\/-]) (?![\d.])/"$1 $3 $2"/eegx;
web scrapping is what got me interested in programming in the first place. Good job.
Sometimes it blows my mind how useful webscraping is on my list of things I solve with programming.
so true, I've used it for school, work and just for fun (grabing soundcloud links and downloading them). /r/forhire occasionally asks for web scrapers too
Just tested it out on a Django project. Got some interesting results from the cc but got curious about the Halstead stuff :)
I think you're right to be concerned about copyright, but in this case I think your worry is wrong. In a web context, these scripts are user agents as good as any (just like browsers), and while they do store the images locally, so does the browser. There would be copyright issues if the downloader were to republish the images elsewhere, but they could do that as easily with a browser. None of these sites display ads, either so they're not losing revenue from this. So, really, I don't think there's any problem here.
Numexpr doesn't work yet on Py 3! (this is important for the project I work on)
Thank you for taking the time to reply, I have now updated to use mode_cbc instead. I tried to look into using NaCl but I couldn't find a working library for my distro. And I'm not sure if there would be any issue with rewriting any blocks to try and modify the contents, since I maintain the last md5 (I know it is broken, but it provides a simple verification method, and I may upgrade to sha-512 soon enough) in each packet and check that as well as checking that the ciphertext is readable. If the hash is incorrect then the packet is dropped, and if the ciphertext fails to decrypt then the connection is dropped. Is there any other recommendations that you could make to help with my code? and again, Thank you
Also consider using Requests. http://pypi.python.org/pypi/requests
Yeah, it is pretty easy &gt;&gt;&gt; import urllib2, json &gt;&gt;&gt; json.loads(urllib2.urlopen("http://xkcd.com/1159/info.0.json").read()) {u'img': u'http://imgs.xkcd.com/comics/countdown.png', u'title': u'Countdown', u'month': u'1', u'num': 1159, u'link': u'', u'year': u'2013', u'news': u'', u'safe_title': u'Countdown', u'transcript': u'', u'alt': u'For all we know, the odds are in our favor.', u'day': u'11'} 
I'm not concerned about copyright. I'm concerned about lost sales from people not seeing what the creators advertise on their websites. Both the xkcd and Cyanide and Happiness websites offer physical items (books, t-shirts) that the creators make money from. Normally viewing the comic is meant to entice people into buying these.
I love your library! Thank you for writing it. It's the only thing that I know of that can "construct" and parse binary data... 
I wouldn't frown upon it, but why can't he create 'set' and 'get' functions with in the class to obtain the instance variables? 
Assuming there is a RSS you can pull it an parse with an XML Parser
I still use this for work sort of. I have certain email addresses (work related) filtered, so when I get an email from them, GMail forwards it to a email address used to send an SMS to my phone. So when the boss emails me, I can see its about my invoice as the first few lines of the email pass through.
That is strictly unpythonic (not that is necessarily a bad idea), and would garner far more frowns than \__dict_\_ would.
What's the best way to do this?
What's the advantage to this series over [Google's Python class](https://developers.google.com/edu/python/)?
This series will not only limit to class, functions and RegEx, but will also have developing application in python for security, and using python in different security applications.
Many of the Registered Members are not aware of basic, so i don't want to see spam threads and posts about asking basic structure of python. Your point is valid, I will take this point in my mind, and will cover rest basic in 1-2 thread probably and will come to the point. As soon as possible. Thanks for the Great Idea. :) 
@property?
Well, Our upcoming topics in series will be useful mostly to Penetration Testers.
Does anyone want to address the point that dir() returns a list of strings, and that `[i for i in dir(t) if callable(i)]` and `[i for i in dir(t) if not inspect.ismethod(i)]` have no effect and will always return an empty list. 
im sure he meant to use getattr there
Was never aware of this thanks! Im relatively new to the python world, so there are still a lot of libraries i dont know about. This little task was an attempt to learn a bit more, so thanks!
Nice to know, thanks! 
Yeah `vars` just feels more pythonic, though as far as I can tell CPython implements `vars(foo)` as `return foo.__dict__`, but if your access to `__dict__` is read-only, then `vars` is probably better. (`vars(foo)['bar']` looks a little strange)
Then you should enjoy this guide, there is a lot of recommendations and resources: http://docs.python-guide.org/en/latest/ :)
Try micro-threads instead, say gevent, stackless python, or pypy.
As others have mentioned, nothing specifically wrong with `__dict__` but `vars()` generally reads a little better. Note however that `dir()` *is* frowned upon as its behavior varies depending on the object passed, and [its interface](http://docs.python.org/2/library/functions.html#dir) doesn't actually specify what it returns -- other than 'useful names': &gt; Because dir() is supplied primarily as a convenience for use at an interactive prompt, it tries to supply an interesting set of names more than it tries to supply a rigorously or consistently defined set of names, and its detailed behavior may change across releases. As a final nit-picky personal style issue, I'd write `list(vars(t))` instead of `vars(t).keys()`.. although there's no real logic behind that.
Just a note that comprehensions can have multiple for and multiple if clauses. Does the statement always add a cc of just 1 in every case? 
there is no reason to put frown upon in quotes unless you want to imply that people would frown upon it in a way that indicated they were actually happy with it.
&gt; ... was one of the three co-owners of the popular social news site Reddit, ... It's in the article.
The only reason i wouldnt use requests is because its not part of the standard python library - so anyone who would want to use the scripts would first have to download it (and pip if they havent already). But other than that, it does seem like a vast improvement over what urllib2 has to offer! :)
Am i the only one that immediately assumes the Swartz suicide was not suicide at all? Edit: Maybe not direct murder, but the smoking gun was/is depression, that may or may not have been used to the advantage of his opponents.
But not in the title.
What do you mean by that?
In the age of activist vs the old world, the death of a hacker leaves plenty of room for conspiracy
For someone doing so much for society it *does* seem a little odd.
Porting Python 2 code to Python 3 is usually pretty straightforward and quick in my experience. String and bytes heavy code tends to be the most time consuming to port but the result is invariably cleaner, less ambiguous and also works on Python 2.
His suicide is a huge loss to the world. It's hard to imagine the things he would have done that and now they'll never be. 
It probably has more to do with [this](http://www.theverge.com/2013/1/9/3857628/jstor-opens-up-limited-free-access-to-its-digital-library).
How is it that news.ycombinator.com is full of news about Aaron and his co-founding of Reddit, and there seems to be nothing in reddit's FP??
In addition to telling you about the project, this is my first real python program and would welcome any feedback on it as well.
Cool then we should finish this year :-)
It's top submission on /r/all
Maybe doing so much for society could mean you're not doing enough for yourself.
Because he got in big shit for downloading JSTOR archives. Try to release scientific papers for free -&gt; get slammed in jail -&gt; lose will to live.
It's not for you to decide if there's an issue, but rather it is something the creators decide. I simply proposed that the OP be polite and write to them to ask.
And by moderators you of course mean those people who never check the spam filter..
Depression sometimes correlates with deep shame and this generates an armour and a protective shield that will prevent most people from seeing anything real about that person.
They removed existing (on page of the subreddit) posts. Noting to do with spam filter.
Thanks for the tip! Although I'm primarily looking for paid work i.e. someone or some company that wants someone to handle porting from start to finish (which I imagine involves considering implications, various approaches, etc.)
I've written some Python libraries but I doubt anyone will notice when I kill myself, what makes this guy so special?
I was working on something similar and I usually used [opensubtitle.org's api](http://trac.opensubtitles.org/projects/opensubtitles) to find data for files that had random filenames and no metadata... There may be something similar or better, but since I was also downloading subtitles I used this. Here's a quick example: http://pastebin.com/8iTvVANZ &gt;D:\projects\tests&gt; python osub_epinfo.py "D:\random_folder\random_filename.mkv" &gt;"Arrested Development" Pilot Edit: This example prints only 'MovieName' from first result which sometimes can be wrong, iirc I counted how many times tv show/ep name appeared and just took the most occurring one. And you don't need urllib2 in imports...
I've met plenty of folks after years in the open-source and open-data commuties that have done just as much or even more. The dude was great at what he did but there are sometimes a cult-feeling around some folks on the Internet, as if they had revolutionised the world. He didn't, however he helped making it better for sure. I'm not trying to be disrespectful to him, it's a sad news indeed but let's also keep things in perspective, there are great men and women out there that no one ever talks about. 
XKCD provide a json Api for doing the exact same thing and nasa is a goverment funded website and does not use adverts. Even if that weren't the case though, this is the very nature of the internet and I am doing is automating a task I would have been doing myself.
Thanks, I'm not subscribed to /r/news. Still, should be in other subreddits or maybe it is now? I'm subscribed to many subreddits including most of the default ones (except for pics, news and politics - which are IMO 99% a waste of time and extremely circlejerky).
For indicting someone for a crime?
I don't think he even had chance to upload them before he was arrested. He was [thrown in jail for downloading them](http://arstechnica.com/tech-policy/2011/07/reddit-founder-arrested-for-excessive-jstor-downloads/) apparently. ~~Because, y'know, signing up to a site and downloading documents from said site is apparently a crime now~~. EDIT: Read [this](http://www.reddit.com/r/Python/comments/16flol/webpy_founder_aaron_swartz_commits_suicide/c7vmwpb?context=1).
It can't.
My bad, comment edited.
Then I don't think /r/python is an appropriate place to conduct commercial advertising not of a general benefit to the python community.
and now in the comments, the only thing I read besides the title
That was deep.
I think we should avoid oversimplifying this. Yes, the last time he was in the news was the JSTOR case. But suicide rarely has one simple cause. Most of us don't know Swartz, or what had been happening in his life in recent months, so we shouldn't assume we know why he committed suicide. Cory Doctorow has a [more detailed personal account of Swartz](http://boingboing.net/2013/01/12/rip-aaron-swartz.html), including the fact that he had had problems with depression for years.
Rarely are depression, and other mental illnesses, visibly apparent. Unfortunately.
I can only hope that now in the great beyond he has found the peace he couldn't in life. 
`vars` also doesn't return descriptors, as they're attached to the class `__dict__`, not the instance `__dict__`. &gt;&gt;&gt; class Foo(object): ... @property ... def bar(self): ... return 5 ... &gt;&gt;&gt; print vars(Foo) {'__dict__': &lt;attribute '__dict__' of 'Foo' objects&gt;, '__weakref__': &lt;attribute '__weakref__' of 'Foo' objects&gt;, '__module__': '__main__', 'bar': &lt;property object at 0x7f1eef1fbe68&gt;, '__doc__': None} &gt;&gt;&gt; print vars(Foo()) {}
&gt; The real question now is, should you use a magic method to do this? Most Python programmer will probably frown on it. They’re magic, so they shouldn’t be used unless you’re doing metaprogramming. You _are_ doing metaprogramming there, lol. If anything I would say that you're not doing enough of it. At the point when you have 150+ attributes they are obviously not unique meaningful things any more and must be processed in bulk. That is, make a list of attribute names somewhere, initialize them all programmatically instead of writing 150+ lines in `__init__`, refer to that list to iterate over them, and maybe even assign that list to `__slots__` for extra safety. The idea being that at that point your class is more of a dictionary with attribute-like access (`d.attribute` instead of `d['attribute']`) enabled for convenience, not vice versa. On a related note, Python is pretty nice for implementing really simple DSLs for that kind of stuff in case you want to store your list of attributes in a convenient form: attribute_definitions_str = ''' font_family Name of the GUI font font_size Size of the GUI font reticulation_count How many times to reticulate the splines ''' attribute_descriptions = {} for attr_definition in filter(None, map(str.strip, attribute_definitions_str.split('\n'))): name, description = attr_definition.split(None, 1) attribute_descriptions[name] = description class Settings(object): __slots__ = attribute_names = list(attribute_descriptions.keys()) attribute_descriptions = attribute_descriptions def __init__(self): for name in self.attribute_names: setattr(self, name, None) 
/r/TrueReddit is top
I don't think he signed up. He 'snuck' a laptop into MIT (wasn't a student) and left it there to dl content. http://boingboing.net/2013/01/12/rip-aaron-swartz.html
A beautiful letter from Mr. Doctorow. Apparently, he understood and felt things intensely as many brilliant folks do. Sometimes deep understanding and passion burns both dark and light. The young dude was a full on hero. 
My biggest problem with tvnamer is when it gets confused because shows have similar names. I've had to add a bunch of rules (e.g. replace Scandal.US with Scandal.2012) so that the batch processing can figure out which replacement to make. Some heuristic for non interactive use based on what's currently airing (and/or popularity?) would be pretty cool.
Yes it should do just that. :-) EDIT: I could have misread the question. Just to clarify: it adds 1 for every "for" loop and 1 for every "if" branch.
From the [documentation](http://docs.python.org/3/library/functions.html#vars) on vars: &gt;With a module, class or class instance object as argument (or anything else that has a `__dict__` attribute), return that attribute. Could you explain what seem to be missing here? 
So he used MIT's membership? Thanks for the clarification.
i used numpy, and it works well. The time consuming processes are from arcpy
&gt; based on what's currently airing (and/or popularity?) Two things. First, this is a flippin' good idea. Second, this happens to coincide with one of the project goals I failed to mention earlier. I have a background in cognitive science, so I have a small amount of experience with natural language processing. I had planned on trying to refine TVDB lookups with simple and cheap NLP, because I agree that poor query results are a frustrating ordeal. So far, the fuzzy matching I implemented using a normalized Levenshtein distance seems to work pretty well. Also note that this was my reason for having the `tvdbid` argument for the CLI app and the identically-named `__init__` parameter for the `Scrape` object. In any case, using popularity seems like a very straightforward way of weighting identical results: All I would need to do is multiply the normalized Levenshtein distance by the popularity. Let the work begin! **EDIT:** And just a friendly reminder... Scrappy is currently in beta, so you should always use the `--test` argument to check the file names being generated before actually committing the changes to disk. I'd hate to mislead you into screwing up your library!
Hi, I'm English but I live in Poland. I'm having trouble locating where this actually is? Wroclaw myself. EDIT: Are you just outside Katowice?
Mainly I'd recommend using [Twisted](http://twistedmatrix.com) with [PyOpenSSL](http://pypi.python.org/pypi/pyOpenSSL) instead of building your own networking engine and cryptosystem.
Tornado and App Engine's webapp were directly influenced by web.py (well, Bret Taylor started both and he was influenced by web.py). Aaron became notorious for being such a whiz-kid and for his cyber-activism, but I most knew him because of his Python influences. So I would not underestimate his libs. :)
I've seen at least 4 posts related to him. Though this is the most surprising because I didnt know guy was well into so much
&gt;Because he got in big shit for downloading JSTOR archives. FWIW, I applaud him for that.
It's in Gliwice, so it's about 170 km along A4 highway from Wroclaw. It's about 20km before Katowice. Here's [map](http://maps.google.com/maps?q=Gliwice,+ul.+Pszczy%C5%84ska+85&amp;hl=pl&amp;ie=UTF8&amp;ll=50.285322,18.679301&amp;spn=0.003695,0.009881&amp;sll=37.0625,-95.677068&amp;sspn=37.462243,80.947266&amp;hq=ul.+Pszczy%C5%84ska+85&amp;hnear=Gliwice,+%C5%9Bl%C4%85skie,+Polska&amp;t=m&amp;fll=50.284746,18.679086&amp;fspn=0.003695,0.009881&amp;z=17) to exact place. The meeting will be held next to Lidl market. You should come and join us if you have time :)
Not everything can be in the title. 
Well, he helped in the RSS 1.0 specification at **AGE 14**. He accomplished a lot more than me at 14 than I have done at 24.
I'll see what I can manage ! :)
I guess the GIL does hamper you here. For many applications, the true bottleneck is not processing power, but input/output capability. The big applicable area for this has been in the last decade webserving. Threads turned out to be a really bad idea for this, as they were too heavy for handling concurrency in the 1000s or hundreds of 1000s of connections. Lighter concurrency methods have turned out to be faster and better for the job, even running still only in one interpreter instance, or a couple of worker threads in another language. However, if you just want to boost your application's speed by the number of CPU cores you have, there is one easy blunt method for python - just run a different interpreter on each core. Not super clean, we know, but it does work.
 &gt;&gt;&gt; print Foo.__dict__ {'__dict__': &lt;attribute '__dict__' of 'Foo' objects&gt;, '__weakref__': &lt;attribute '__weakref__' of 'Foo' objects&gt;, '__module__': '__main__', 'bar': &lt;property object at 0x13da050&gt;, '__doc__': None} &gt;&gt;&gt; print Foo().__dict__ {} It looks like the same to me.
That's what Julius Caesar said about Alexander the great. But he ended up doing a thing or two later.
35-50 years in prison and up to 4 million dollars in fines worse? You'll want to read this: http://lessig.tumblr.com/post/40347463044/prosecutor-as-bully and http://unhandled.com/2013/01/12/the-truth-about-aaron-swartzs-crime/ Then you'll want to read http://www.quinnnorton.com/said/?p=644 and see if you still think the punishment in any way was proportionate to the crime.
The \ and the + can both be ommited in this case. print( "This {0} something else, blah blah blah blah" "blah blah blah".format( that)) Is very readable to me. 
I frown on this, because since the use case involves linking a model to a file being parsed, you should be using a real schema system such as [colander](http://docs.pylonsproject.org/projects/colander/en/latest/) or another explicit system, rather than tying your parsing to a particular implementation (i.e. one where you need exactly all of the local data that happens to be in `__dict__`). What if you wanted to add some other instance variables to your class that aren't part of the file, or what if you wanted to re-purpose some of those instance variables as descriptors? what if some fields are optional and might not be present in `__dict__`? The hardcoded approach of linking to what happens to be in `__dict__` doesn't allow this flexibility.
Just out of curiosity. What kind of anti-depressant was he currently taking?
You mean sarcastically? I used quotes because it sounded a bit silly to me (I was quoting the source too and the author may have meant it sarcastically).
Cool, thanks for the bit about dir().
That's good to know, thanks.
Surely "penetration testers" would already be programmers (or at least aware) and are looking to specialize with regards to security. The concepts would be the same and the language merely syntax?
Sorry, I was referring to the use of `dir`. I should have clarified: `__dir__.keys()` and `vars(Foo()).keys()` have different output to `dir(Foo())`.
For sure. The Python source is quite pleasant to read.
So sad. He had a major part in RSS and reddit as well. Truly a visionary.
Thanks.
Hacker News is for startup news. 
you... you give me hope have a cookie
In Python 3, vars(t).keys() will return a view object, not a list, so if you want a list you need to call list explicitly. 
Good catch. Also, ``__dict__`` is not a magic method, it is not a method at all. Edit: fix formatting
Using ``__dict__`` directly is fine. Using it in this way is slightly dubious, because it doesn't do enough. The author ignores attributes inherited from superclasses (if any), fails to take into account that there are callables other than methods, and doesn't support either ``__slots__`` or class attributes. Nor does he take into account attributes dynamically generated with ``__getattr__`` and ``__getattribute__``. Depending on what you are after, all these limitations might be fine, or might not be. And frankly his dislike of importing the inspect module is rather irrational. I would lean towards using vars() instead of ``__dict__``, but that's not a particularly strong preference. 
Good grief, somebody reading the Fine Manual -- what will they think of next??? :-)
Less strange if you do this: d = vars(spam) d['ham'] = 'NOBODY expects the Spanish Inquisition!' d['eggs'] = 'Ethel the Aardvark Goes Quantity Surveying' 
You are correct, but your description is wrong. ``self.propfunc`` is not a property, it is a regular instance attribute containing an ordinary function object. Properties are a descriptor type created by the "property" built-in function. 
Oh, right. I had the ideas right, but I forgot about the overlap in terminology that I was quite merrily driving through. Properties are indeed the getter-setter-y things.
I'd love to know why projects like Django's port is taking so long then.
If you are well known and your libraries are widely used, then it wouldn't be that different.
You can think of like it a radon detector for your home, but for your code
You're using `h.from_int()` on the *same object* every time within your loop. You need to create a new `Note` object if you want to put a new note in - as it is, you're making multiple references to the same note and changing its value frequently. *EDIT:* feel free to ask further questions, or post your attempted solution here (try it first of course!) .. I'm guessing you're a new Python programmer; people should be able to suggest stylistic improvements and things to make it easier. I was tempted to suggest a few things here but it's worth letting you work things out before providing little nudges in the right direction.
You can always just stick the whole module inside of yours.
That's a good project! I haven't been able to find a non-script-kiddie looking renaming application over the last years... Not saying that they didn't work, but having a simple command line application and even an API in Python is very useful!
I'm curious, why else would you hire Guido than to work on Python? I'm sure there are plenty of Python professionals for implementing code, but only one Guido for designing Python.
Thank you! I believe I have found a solution thanks to your advice. --- from mingus.containers.NoteContainer import NoteContainer from mingus.containers.Bar import Bar from mingus.containers.Note import Note import mingus.core.intervals as intervals import mingus.core.diatonic as diatonic def Main(): intervalList = [1, -13, 5, -4, 3, 7, 10, -4] b = Bar() n = Note() m = NoteContainer() for i in range(len(intervalList)): n.from_int(int(n)+intervalList[i]) m.add_note(Note(n)) for i in range(len(m)): b.place_notes(m[i], 8) print b Main() --- the output: --- [[0.0, 8, ['C-3']], [0.125, 8, ['C#-3']], [0.25, 8, ['E-3']], [0.375, 8, ['F-3']], [0.5, 8, ['B-3']], [0.625, 8, ['C#-4']], [0.75, 8, ['F-4']], [0.875, 8, ['A-4']]]
Figured I'd update this with a brief overview of calculating implied vols. Option prices are a monotonically increasing function of the volatility of the underlying. Knowing this information, by pricing lots of options with different values for volatility, we can figure out what an option in the market has as its volatility. The gist is: guessed_vol = guess a random volatility if black_scholes(guessed_vol) &lt; market_price_for_option: increase our guess elif black_scholes(guessed_vol) &gt; market_price_for_option: decrease our guess else: market_vol = guessed_vol It's very rare we expect to find an *exact* value for the market_vol, so often it's sensible to work with tolerances. i.e. if the guessed_vol price results in a price that is within 5 decimal places of the market price, then that'll do. What we're doing here is called [root finding](http://en.wikipedia.org/wiki/Root-finding_algorithm). There are lots of ways to do this, but the popular methods for finding implied volatility are [Newton-Raphson](http://en.wikipedia.org/wiki/Newton's_method) and the [bisection method](http://en.wikipedia.org/wiki/Bisection_method) I'd recommend starting with the Bisection method, as it translates into code quite easily. Its approach is the same as binary searching, the difference is we're just searching a function rather than an array.
I can think of a few. The main one is that Dropbox is written in Python IIUC (most if not all of it). Hiring Guido will attract a lot of top-notch Python developers.
That's really good to hear! It's tough writing open-source apps because either your idea has been done before, or it's too advanced for your level =/ I started writing scrappy and then learned about all sorts of preexisting scripts that did the same thing, so I said "fuck it. I'll do it better". The point is, it's great to hear feedback like yours! If you have any ideas for features, or if you encounter any bugs (which will almost certainly be the case), I hope you'll let me know. You can PM me on reddit if you don't have a github account.
Groovy! Thanks a bunch! I'll go test this out straightaway.
Quick question: Is there a reason why you're using `if type(string) == unicode` as opposed to `isinstance(string, unicode)`?
What? Django's port was done months ago. They are taking a cautious approach, calling Python 3 support experimental because it needs more testing out in the field. That seems wise, given the number of different environments that Django runs on, and its importance in the Python ecosystem.
Yargh! Forgot about 3 :)
Here are the comments about SQLite's lack of support for `ALTER TABLE` - Don't break our necks over SQLite's inability to ALTER things. SQLite has almost no support for table or column alteration, and this is likely intentional. Alembic's design is kept simple by not contorting it's core API around these limitations, understanding that SQLite is simply not intended to support schema changes. While Alembic's architecture can support SQLite's workarounds, and we will support these features provided someone takes the initiative to implement and test, until the SQLite developers decide to provide a fully working version of ALTER, it's still vastly preferable to use Alembic, or any migrations tool, with databases that are designed to work under the assumption of in-place schema migrations taking place. 
I made a different version. It uses requests to get to HTML and BeautifulSoup to parse the response. Feel free to modify and criticize. It downloads the current png comic into a file named img.png from bs4 import BeautifulSoup import requests import urllib r = requests.get("http://xkcd.com") soup = BeautifulSoup(r.text) img_tag = soup.find("div",{"id" : "comic"}).find("img") urllib.urlretrieve(img_tag['src'],"img.png")
this seems safer than Alter anyway, especially if the data actually mattered.
It is not as light weight as SQLite, but take a look at Firebird. The embedded version can be bound to Python for a full SQL server without a separate process, minimal installation and single file database. http://www.firebirdsql.org/ http://www.firebirdnews.org/docs/fb2min.html We use it from Python for server-side apps with good results.
Seconded. That's how [SQLite Manager](https://addons.mozilla.org/en-us/firefox/addon/sqlite-manager/) (yeah, it's a GUI, but it gives you plenty of functionality you can't easily get otherwise) does it--and automatically, so you don't have to. There's also [sqlalchemy-migrate](http://code.google.com/p/sqlalchemy-migrate/) which can do those things in a more programmatic fashion. It's probably more relevant if you're already using SQLAlchemy (which is amazing, by the way, if you're not already using it) but I imagine you could use it standalone.
Too true.
SQLite does seem to be adding more ALTER constructs and we have been trying to support them. You can now [add and rename columns](http://www.sqlite.org/lang_altertable.html) and Alembic mostly supports this. The inability to add constraints at the table level is still getting in the way though, as that's how SQLAlchemy does it (you can have a CHECK constraint on your new column, but SQLA doesn't render the CHECK inline like that right now). Also in SQLite, the "type" you give to a column is almost not important at all, as they [type on value](http://www.sqlite.org/datatype3.html), so altering column types you can get away with not needing.
Nope, type() was just the first one to spring to mind (which is weird, I just checked that same codebase and I've used isinstance in it before... derp). Might be worth changing the input parameter from 'string' too... "isinstance(string, unicode)" tripped me up for a moment until I realised string was the parameter, not the string module/type!
I launched this a few months back as a Python/Django only job board - hope you find it useful.
Do you have a local Redis server installed and running and listening on port 6379?
Well, I thought I did. I've seen discussions through Google searches that have asked the same question you're asking and I've tried some of the solutions suggested, but to no avail. I'm new enough to this that I'm not sure exactly how to make it so that my "Redis server is installed and running and listening on port 6379." I am admittedly still having trouble understanding basic things, like how to make sure I'm installing packages in the right places, how to correct errors, etc... Any idea how I can check to see if I have the Redis server installed, running, and listening?
It's really hard to give you advice when all you tell us is "I did some stuff, I'm not sure." A list of the exact things that you've done would be a starting point. Did you install Redis? Did you configure it? Did you start the server? Did it start correctly without errors, i.e. is it running? 
On a related note, why does `__dict__` not always work, e.g. on `time.struct_time`: &gt;&gt;&gt; import time &gt;&gt;&gt; t = time.gmtime() &gt;&gt;&gt; t time.struct_time(tm_year=2013, tm_mon=1, tm_mday=14, tm_hour=2, tm_min=20, tm_sec=36, tm_wday=0, tm_yday=14, tm_isdst=0) &gt;&gt;&gt; t.__dict__ Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; AttributeError: 'time.struct_time' object has no attribute '__dict__' Python 2.6.5 FWIW.
Oh, oops. &gt; export PYTHONPATH=/usr/home/kchoudhu/anserinae/projects/python ..fixed the problem. 
nice
Nobody has said it so I'll say it now. Holy cow.
Insanely great.
&gt; I ~~don't~~ think "hire me for a paid sum" is ~~not~~ commercial. Totally agree. &gt; promoting Python 3 You didn't write one word saying why porting to python 3 is a good thing, nor how to do it, or why, or how Pillow has benefited, nada. You just said that it tends to be repetitive, and that you'd do it. The post had very little informative or instructional content at all. I have absolutely nothing against you personally, but if I don't call people out on this sort of thing, then people could star to see this more as a jobs advertisement board than a readership and discussion community.
It's on the sidebar so I guess it's a good bet. Also the documentation at http://docs.python.org/3/ and http://stackoverflow.com/questions/tagged/python will be handy. Also try to wrap your head around virtualenv before starting anything major, it's a great tool for keeping (pet)projects separated.
during development when I often refactor code or if I made mistake in import there will be a lot unused, deprecated modules. If i run script in different env, or without env by mistake , it will install packages which I don't need there. Or even i need jinja but with specific version. I think it's better use buildout or simple pip -r requirements.txt and have controll what's going on in my software.
I completely agree :)
I'm too lazy to type that much every time I import something. I'll just pip install it instead, pip will tell me if it's already there :)
You're right - "impip" is available. Though this isn't useful enough for me to take that pretty name.
I don't have this problem any more, because I now use pyflakes, both editor integration and as a unittest on the whole code base. Would highly recommend...
why?
Why not?
I don't know why, but lots of people claim the original "Dive into Python" is like a hundred times better than "Dive into Python 3". To be honest, I don't think one book is the best one for any group of people. It all comes down to individual tastes and we all have different ways of learning which makes different books suit different people. This is one of the reasons as to why there are so many books out there on the same topic. I say you should look up a few different books and see which one suits you best. Some books are available for free, which is good if you want to have a look at a digital version before buying a paper version, but honestly if you are not interested enough to spend 30-40 USD on books then you are probably not interested enough to spend the time it takes to learn Python either.
Why not `pimp`?
time.struct_time is created in C, and so doesn't actually expose a `__dict__`, but rather each property is mapped to the value in the C struct using the C API. This has a few consequences (eg. you can't add new fields onto the object) which make it act differently from objects defined in Python code. There is also a case where you can explicitly create a pure python object that doesn't create a `__dict__` and works similarly to such objects. The direct way is to define a member called `__slots__` which contains a list of all the members you will support. Eg. class C(object): __slots__=['foo','bar'] def __init__(self, foo, bar): self.foo = foo self.bar= bar &gt;&gt;&gt; a = C(1,2) &gt;&gt;&gt; a.foo 1 &gt;&gt;&gt; a.__dict__ AttributeError: 'C' object has no attribute '__dict__' &gt;&gt;&gt; a.baz = 42 AttributeError: 'C' object has no attribute 'baz' This has some advantages in terms of space usage (you only need to allocate space for the members, not the extra overhead of the dict), but comes at a flexibility cost. There's also `collections.namedtuple` which will use this behind the scenes to create convenience types that act similarly. Eg. the above could be implemented by: import collections c = collections.namedtuple("C", "foo bar") 
I'd start with the official Tutorial. Good if you have some basic prior programming language, it has just the right pace imo. 
I think the plan is to have an alpha, so people can play with it by PyCon. Don't really hold me responsible for that though :) (I'm also not doing any work on Py3k)
I recently learnt python from Dive into python 3 and would highly recommend it.
Re: "You didn't write one word saying why porting to python 3 is a good thing". I wrote several words about it, including: "The Python 3 Wall of Shame is now the Python 3 Wall of Superpowers. We are over the hump." I'm sorry if this wasn't informative or instructional enough for you (or inspirational enough), but you are not the moderator. Please use the down arrow and move on.
Thanks! You´re absolutely right, JSON APIs are always faster.
Wait, so you copied most of the code without any notification or even forking the original project? Wow.
I haven't actually read about anyone using Firebird before. Why do you use it over say PostgreSQL or MySQL? Anything special about it that made you choose it over other popular database systems?
[lol](https://github.com/Adys/patchtools/commit/daaea9647754e643e6fc43b5542695d26e3608c2), he used mine after i built it :)
I have not, but it seems like an interesting project. I'll have to try it out. Thanks!
Beginners to Python, or beginners to programming in general? If the latter, I just picked up a copy of [Python for Kids](http://shop.oreilly.com/product/9781593274078.do) (although I bought the hardcopy from Amazon and used O'Reilly's $4.99 eBook upgrade, which ended up cheaper). The code is all Python 3. My kids seem to like it so far, and it does a pretty good job IMO of mixing general programming concepts with how Python implements those concepts, all without alienating a young audience. I'm also considering giving a copy to my dad. He just retired and used to enjoy working with me on BASIC programs when I was a kid.
I recommend 100% [Ninja-IDE](http://ninja-ide.org/). Is open source and pretty cool. Also take a look at WingIDE a great propietary option (The give free licenses for education or open sources projects).
&gt;Eg. the above could be implemented by: &gt; &gt; import collections &gt; c = collections.namedtuple("C", "foo bar") That's something I wasn't aware of. Although it isn't quite the same because: &gt;&gt;&gt; c.__class__ &lt;type 'type'&gt; Instead of, (with your C class): &gt;&gt;&gt; c.__class__ &lt;class '__main__.C'&gt; I suspect that if I wanted something like that I'd use something like Norvig's [Struct](http://www.norvig.com/python-iaq.html) class and make a sublass of it fro my actual class. 
That's a hard thing to ask for because part of that single-file elegance is that there aren't multiple versions of the same database floating around. With a RDBMS server, when a drastic alter table comes up, the system juggles the old version of the table for transactions, makes changes, and then depending on the design of the database, either rollsback overlapping changes or reapplies them from the transaction log to the new table. Since SQLite doesn't have concurrent access, none of that is necessary. You can just rename your old table, copy everything over to the new, and drop the old one. That's fine because it isn't like there are other transactions coming in from other clients.
Nice! You might want to have a look at a library I wrote for guessing information from a filename: https://github.com/wackou/guessit This might prove useful to you. Cheers and good luck for your project!
[Ply](http://pypi.python.org/pypi/ply/3.4) supports Python 3.
&gt; so I said "fuck it. I'll do it better" That's the spirit! btw, I think that having and a good and simple API for a library is a great idea. Oh, and you might be interested in looking at this for doing fuzzy string matching, it looks quite nice: https://github.com/seatgeek/fuzzywuzzy Haven't had the chance to look at it myself, but it's on my todo list. 
So, as someone who couldn't claim to understand one bit of AI, what is this and does it work? 
Take a look at the imports in `scrappy.core`! My project wouldn't exist if it weren't for yours ... at the very least it would be severely crippled! I actually tried to read through your code and got lost. How does `guessit` work, exactly? And thanks for such a great library! 
Interesting link, thanks! I'll have to think about adding it to the Scrappy code base, because so far the normalized Levenshtein distance seems to work very well. I hesitate to add features where they aren't required. This having been said, this is probably a good library to use for more complex apps that exploit the `Scrappy` framework.
Thanks for the tip! How is pyparsing performance?
good point, don't take that nice of a name just for a joke package!
still no, but it paints the Australia map while traveling from Arad to Bucharest :)
Doesn't matter, vim was is and will always be the only editor to be used.
there are many known and studied AI algorithms and techniques for different kinds of problems. This lib implements some of them (part of the AIMA book), so you can just use them providing only the specifics of your problem, not having to program the entire algorithms. Example: You want to find the optimal placing for a group of machines on a factory. You could use the A* ("A star") algorithm to solve that. Using this lib, you would just specify the machines information and some logic on how they can be placed, and then pass that information to the already implemented A* algorithm (a python function), which will use that information to figure out the optimal placing for the machines. 
[TPG](http://cdsoft.fr/tpg/) is the only Python parser generator I have seen that has a reasonably declarative syntax for specifying the grammar. It now supports Python 3. Its biggest weakness is its lack of a documented formal class of languages that it can handle. In my experience it does not backtrack across different possibilities (so LL(k)?).
+1 for Dick reference.
That doesn't make any sense. Those languages would use 32bit integers by default so 7 digit numbers would be a problem.
131 because it's the next larger, arbitrary but historically significant line width. Actually, no I don't I just use 79 -- like everyone else. Except when I don't -- just like everyone else.
I would love to see an example (code / paper / etc..) of what you just described. :)
Because fuck you.
Ooh, I love the looks of this! I took an AI course that used that book a few years ago. I really want to play with this now :3
Part 2 is now available: [Implementing a Python OAuth 2.0 Provider - Part 2 - Authorization Provider](http://www.reddit.com/r/Python/comments/16ktqe/implementing_a_python_oauth_20_provider_part_2/).
Did you even click on the link? I love vim, but being a rabid fanboy is no fun.
We haven't captured that damn Wumpus yet?!
Given 1) a description of a state and 2) a list of actions describing how to travel from one state to another and 3) what the "best" state looks like, this library implements several different algorithms for traversing these states to find the best state. e.g. think chess computer, or your phone's step-by-step GPS navigator I haven't evaluated the library, so I don't know if it works, but the documentation looks good, and all of the algorithms presented would be fairly easy to implement in most programming languages. There's more to AI than just this, but the "search/planning problem" is one of the older and more well-understood topics of AI.
See http://plumbum.readthedocs.org/en/latest/ And for path manipulation: http://plumbum.readthedocs.org/en/latest/local_machine.html#local-paths
You're right, the earlier PE problems are really nice for trying out new languages.
this is pretty cool. way better than subprocess.call
If you're interested in applying Python in science and/or data analysis, I'd recommend http://scipy-lectures.github.com/ to get you started.
NoSQL: - bdb - redis - LevelDB - Tokyo Cabinet
That ":3" smiley really gives the rest of us canceraids, I'd advice you to stop, in order to not kill humanity.
You know what gives me canceraids? People who use "advice" as a verb. 
[:o](http://replygif.net/i/423)
&gt;Instead of, (with your C class): Actually, that's just because you called it on the class in the first case and the instance in the second. namedtuple returns a class object, not an instance (ie. it's equivalent to the class definition, not the "`a=C(1,2)`" line). You still need to call this class to create instances. ie: &gt;&gt;&gt; C = collections.namedtuple("C", "foo bar") &gt;&gt;&gt; c=C(1,2) &gt;&gt;&gt; c.__class__ __main__.C &gt;I suspect that if I wanted something like that I'd use something like Norvig's [1] Struct class It's aimed more at performance. Solutions like Struct create a dictionary for every object, whereas using `__slots__` / `namedtuple` only allocates an array sufficient to store the members (and thus lacks the ability to add new members). This is generally not important, but if you've got millions of objects, the overhead can be significant (namedtuple also has the advantage that it can be accessed by index too, so it's useful for all those "information in a tuple" types where APIs may still expect tuples but you want friendlier symbolic names too).
Have some more :3
Is there any verb for advice? I mean, Google Translate matches 'advice' to 'conselho' in Portuguese (which seems right), but 'conselho' also has a direct verb which is 'aconselhar'. So maybe the user it's just thinking which a translating mind - not that's an excuse, I personally love the ':3' smiley. Well... I did, until my boss mentioned that it looked something genital-like...
advise
What would be an example of something accomplishable with Rmagic that can't be done with numpy/scipy?
I like the idea of Plumbum, but I wish it didn't use indexers to provide an alternative syntax to simply passing arguments to a function. It's not idiomatic, and it's not even necessary. What does `local['ls']` do that `local('ls')` couldnt? Is the library author trying to say that `local` represents a dictionary of the entire system? This is a stretch, but I *suppose* I could be persuaded to see it that way. I do see, however, where it gets dicey (for the author of Plumbum) when you want to provide the ability to chain several commands together. Plumbum solves this by providing 2 different ways to invoke commands. Either with parens, or square brackets, depending on if you want immediate execution or deferred. I don't necessarily dislike this solution, but it is unusual.
pytest is one of the coolest python test frameworks I've run across. This is a quick introduction to the framework
I feel retarded. Thanks!
well, from an api point-of-view, the distinction is laziness. ``ls("-a")`` is strict, while ``ls["-a"]`` is lazy, so you can chain/pipe it. i agree that ``local["ls"]`` seems odd, but try to think of it as a "lookup operator". it relies on ``local.which`` to locate the command (see &lt;https://github.com/tomerfiliba/plumbum/blob/master/plumbum/local_machine.py#L537&gt;). on the other hand, ``local("ls")`` would look like a constructor to me.
Don't put the parens around the arguments of the *assert* statement. If you were to specify a message (second argument) then with paren~~t~~s this will turn into a tuple and be always true.
I don't know how much assertEqual does. but py.test handles nested structures nicely EDIT: i stand corrected unittest is indeed better with nested structs; just tried it. Unittest shows you the exact position the difference occurs. pytest only gives you the index of the top level list where the diff occurs.
&gt; You can just rename your old table, copy everything over to the new, and drop the old one. which makes it all the more frustrating - why cant SQLite just build that feature into their ALTER statement ? Making us all do it by hand has the great disadvantage that a simple SQL script to remove columns or modify constraints cannot be written without writing out the full schema of the table. The inability to remove columns or to add /drop constraints is very inconvenient and seemingly unnecessary. 
There are plenty of them if you search. For example [here](http://thenewboston.org/list.php?cat=36).
[well in that case](http://imgur.com/j7UEM)
Yeah I think that's how I've convinced myself to look at it, although local("ls") *is* a constructor, in the sense that it creates and returns a new instance of LocalCommand. I get the differences between ls("-a") and ls["-a"] and I think it's an interesting approach as opposed to ls("-a") for immediate and some kind of curry method for the deferred case. I think I like it conceptually, I guess I'm mostly bothered by the re-use of the (already overloaded) indexing operator. Any other choice would have to be more verbose though and I can certainly see why the author would want to avoid that.
Since version 0.4, parsimonious support Python 3 [https://github.com/erikrose/parsimonious](https://github.com/erikrose/parsimonious)
With PostgreSQL it is a close call. I don't think PostreSQL has an embedded version (I could be wrong) which is not a big issue for in-house server side apps, but for distributed win32 client apps, having everything run in process is a big deal for me. The win32 client app I am working on now can run from a USB memory key with the app, database and everything on the key with zero install, no local admin privileges needed. This app is an incident management system for first responders, so being able to run on any notebook without admin privileges is a big deal. I have worked with (and hated) Interbase for other shrink-wrapped apps. Firebird takes all the good parts of interbase and fixes all the warts. From a development perspective I would rather use SQL Server/TSQL, but I no longer develop anything that is not cross platform to mac/linux and SQL Server (even the workstation version) is a beast from an installation and support perspective. Nothing drives me crazy like some basic app that insists on installing a separate SQL Server instance on my notebook (and usually auto-starts the instance). While SQL Server is extremely reliable, it is also very difficult to fix once the wheels fall off which is not ideal from a customer support perspective. 
Thanks. Note it's slightly more tricky: splice moves data between 2 FDs, but one of these FDs must be a pipe. I might add more demos later (like how to send socket data to a file, or perform efficient network data sending using mmap, vmsplice and splice).
If you actually have a reason to care about performance, you will probably find pyparsing pretty bad - it's full of hooks for things that most people will never use, especially if they care about performance. Also it does some tricky things internally with exceptions to handle control flow, and tries to optimize this with some weird pooling/caching schemes that AFAICT don't really work. That was my assessment a few years ago, anyway. The situation may have dramatically improved for all I know. That said, I'm using Ply on my current major project, and I'm pretty happy with it. But that's more because I really need to do parsing in a way that agrees with textbook "parsing theory", and pyparsing is... built with the expectation of you not really understanding that stuff.
would be nice if your demo also includes passing fd using `sendmsg`
Wait, you can blog on GitHub? o_O
As does rply: github.com/alex/rply
For one example, up until recently, basic bootstrapping. I'm not sure if the bootstrapping module that they merged into scipy can bootstrap linear models and whatnot as well. As Auggie88 said, R's stats libraries are just a lot more developed at the moment. So until statsmodels etc. catches up, Rmagic can help fill that gap.
&gt;The win32 client app I am working on now can run from a USB memory key with the app, database and everything on the key with zero install, no local admin privileges needed. This is where SQLite shines. But after some googling I found this page. http://www.sqlite.org/cvstrac/wiki?p=SqliteVersusFirebird Firebird is actually better than SQLite in some use cases. I'll be putting Firebird in my toolbox now. 
As someone just starting out on python this guide is amazing. It should really be on the side bar for all us python newbs. Thanks for sharing 
The very last line really is the key point. You can painlessly write great applications, and use cython to optimize the small little portion that does the most intensive work, and you end up with something which is only marginally slower but far simpler and friendlier to develop, and not precompiled.
You write that you have problems running doctests in text files? Just pass `--doctest-glob=*.txt` to `py.test` command. Or you can put a `pytest.ini` file into your project directory with the following contents: [pytest] addopts = --doctest-glob=*.txt [Here is an example of `pytest.ini` file that I use in my project](https://github.com/halst/schema/blob/master/pytest.ini).
&gt; I know, I declared fib() to be of type "double" in the C code. [...] If I declared fib to be of type "double" in the cython code, it was slightly slower than the corresponding C code So, no, not faster than C code. Sorry, this is comparing apples and oranges.
And then saying 'do these apples taste a little bit like oranges'.
Geez, another person who can determine the speed of stuff using a recursive fibonacci function.
Fortunately, Python (at least, 2.7.3+, I don't have an older version to test) warns you that you're doing something silly. &gt;&gt;&gt; assert (True, 'blah') &lt;stdin&gt;:1: SyntaxWarning: assertion is always true, perhaps remove parentheses?
Thanks for the interesting reading. Anyway pytest is a no-go because of use of distribute/setuptools. Beside I don't understand what's the point of "functional" testing anyway: it just makes so much artificial what is more natural in an OO way (and without having to do a module level global initialisation). Moreover the assertEquals is more capable of the assert anyway (does the diff of large text, add a message to explain the errors and so on). 
( ͡° ͜ʖ ͡°)
I'd like to know why distribute/descriptions makes it a no go. I first tried pytest from behind a firewall and had to jump through a couple hoops: http://variedthoughts.com/programming/pytest-firewall/ There may be a miscommunication regarding "functional". I'm using the term to refer to the client API of the thing I'm testing. That API very well may be an object interface. So functional is as-opposed-to unit testing or regression testing. Not necessarily functional programming. I have not explored the difference between assert and assertEqual enough yet to comment on the last point. Thank you for pointing that out. Also, I'm glad you found the article interesting. 
First off, that's awesome. Second, that's precisely the type of stuff I want to do and why I'm trying to learn Python. Thanks for posting this OP. Inspirational stuff :)
Very nice. Puts my recent effort to shame. Is that using google chart to plot the graph? I'm currently working on a quick script to lot up/down vote ratios for various subreddits on a graph (using matplotlib) EDIT: that english
Nice data and graphs. My main complaint is the awful readability. I'm in a 19" CRT and I can barely read the text. also shameless plug for /r/visualization
Cheers, thanks! Keep at it.
Sorry to go a bit off topic, but where do you use these kinds of parsers for? lex and yacc doesn't mean pretty much to me.
What's wrong with distribute/setuptools? Simply tries to be many things to many different actors (developers, system integrator, final users). Personally I've always found the default beaviour to download things from internet a really bad design choice. Think of an audited company where you download things from internet with no tracking. The fact that hijacks the default PYTHONPATH mechanism is bad too. The discussion about distutils has been going on for years (and many rewriting attempts have failed). self.assertEquals uses assertMultiLineEqual and if two strings are different it will dump you the difference not two big text strings side by side: it seems a small advantage but it can make a difference on very big strings. The fact you can derive from a unitest.TestCase object allows you to specialise similar tests classes, something with simple function you can't do: there's more to this but is the usual oo vs functional paradigms. This IMHO is clear case where oo is best suited. Thanks 
Is it possible/legal to scrape the rest of the tweets? (I'd imagine it's possible, it's just a matter of how much work you'd want to put in). I'm curious to see the whole timeline. 
I like to use iPython sometimes to test something like 3rd party apps and integrating with my own code... it's nice, to me, reload without need to restart the shell.
I doubt it. Yesterday, before I started on the script proper, I was scrolling through the beijingair feed and all of a sudden, it just stopped, as if there were no more tweets to be seen. I was nowhere near the 3400 tweet limit they impose on the API either. 
I don't think the Guangzhou readings over 800 can be trusted. Every Guangzhou reading in the 800's I see is exactly 827. I think their instruments are flawed. It's a little suspicious to see crazy spikes where 1 hour it's 103ppm, the next it's 827, then the next it's 130 (See Monday, Oct. 29th). The Guangzhou crew needs to get their equipment calibrated.
I used this at first (the backported version for Python 2.x), but I had to move to joblib because the code kept on deadlocking with no apparent reason.
It was recommended to me as the *de facto* standard for graphics programming with Python. I do a bit of scripting at my current job &amp; as a programming hobbyist by night, there are many applications to which graphical Python can come in handy. :) 
This should be trivial to implement with reduce and functools.partial (or lambdas) for the arg handling.
I thought Pygame was old and not really supported anymore. Or am I thinking of something else?
Latest version released 2009 but exists for python 3.2.
Damn. I've been coding in Python for a few years but I've never heard of vars. So is this frowned upon: class Foo(object): def __init__(self, **args): vars(self).update(args) ??
That's freaking weird. I would have thought tkinter was the graphics programming standard since it comes with the standard lib. I do a lot of scripting at work but so far I've managed to stick with the command line.
For making games, or for graphical programming like the OP is doing? There's PIL for images, but pygame is perfectly fine for that task too. I wouldn't recommend pyglet for graphics unless maybe if you need hardware acceleration.
I have used it and I'd say go for it if you're going to use the "nice" apis it provides. however, if you want to do opengl 3 - at least, last I tried it - pyglet was not a good option. I had to jump through a lot of hoops to make it work for that use. 
this looks rather like a multi-use deferred...
it's because when I used it it was very very difficult to get it to give me an opengl 3 core profile. not sure what you mean about directx, pyglet doesn't use directx (thankfully; it'd be useless if it was dependent on directx).
I bet they get a little suspicious when you have a copy of *Work*~~Play~~boy on your desk.
 import how_to_stop_being_a_whiney_little_bitch
That squirrel-eating game is hilarious!
Is it difficult writing with your feet?
I had to explain that they printed the code sideways when my boss saw me examining the centerfold.
I've a Qt application that I'm working on (using PySide) and it works equally well on my Windows box as my Linux box. I've not tested it under Mac. I didn't need to do anything special to get that to work. I built it under Linux and tested it under Windows and it worked the first time. Of course, that's just my experience and I've not used all of the various widget and features. There may be some issues lurking that I've not found.
You can buy it or download it for free from here: [The OP's book site](http://inventwithpython.com/pygame/index.html)
Boss, some lines are longer than 80 characters so they have to print the it that way or those lines would get cut off...
Thank you kbrafford!!!
Tkinter is just in the standard library for GUI programming. Graphics programming is, well, working with graphics, not just necessarily GUIs! Pygame wraps SDL and lets you handle your own input and drawing.
Unless you want platform-specific GUIs, you usually don't have to do anything.
maybe using generator makes that interesting!
Me too, I gave up on it. I am not a thread noob either, I have been writing threaded code in C/C++ for a *long* time.
So is Pyramid kind of in between Django and Flask in terms of complexity/"batteries included"? There are so many (well-written and common) Python web frameworks that it's hard to know what to choose sometimes.
I think the author has it for free as an eBook on his page. I would link to it but I am on my phone.
okay, so say() and see() both take strings. So why in play_seeNsay() are you converting to int? It seems like you must want to pass the input value into the say() function, like say("14"). Does this do part of what you expect? Taking a simple value like "5", what should happen to it: see(say("5"))? or say(see("5"))? And what loop are you speaking of needing? Do you need to run say("5"), say("4") , say("3"), say("2"), say("1")? I am looking at changing the play_seeNsay() function to this: def play_seeNsay(): s = raw_input("Please enter index = ") print say(s) How does this compare to waht you expect to happen? If you can clarify that, I can help more.
What should I use for 3.x?
Actually I figured everything out. http://pastebin.com/7wbGpUGd What I need right now is when I input for example 3, I get this: 3 : 3110 : three one one zero what the lab wants is 3 : 3110 : three ones. one zero. so the the second name should be plural and have a fullstop. But I can't do that in the say function since it would mess up the string. Any idea how to fix it? Thanks
copying reply: Actually I figured everything out. http://pastebin.com/7wbGpUGd What I need right now is when I input for example 3, I get this: 3 : 3110 : three one one zero what the lab wants is 3 : 3110 : three ones. one zero. so the the second name should be plural and have a fullstop. But I can't do that in the say function since it would mess up the string. Any idea how to fix it? Thanks
I have no idea when it will be done, but I think wx programmers are stuck waiting for Robin Dunn to get his [Project Phoenix](http://wiki.wxpython.org/ProjectPhoenix) finished. He posted a video showing it working on Python 3, though, so it's not vapor ware apparently.
Maybe I shouldn't do this... def say(x): if x == 0: return "0" result = [] for c in say(x-1): if result and c == result[-1][0]: result[-1][1] += 1 else: result.append([c,1]) return "".join( [ str(n) + c for c,n in result ] ) for i in range(6): print i,say(i) 
:( Forgot to say we aren't allowed to use .append or len(). I know, its stupid.
That looks way too complicated to implement since I only have 40 mins to submit it. I might just have to go with what I have (sadly) =/
I'll have to creep on their production. Tkinter just isn't doing it for me haha. 
Ugly but works def say(x): if x == 0: return "0" result = "" prev_c = None count = 1 for c in say(x-1): if c == prev_c: count += 1 continue if prev_c: result += str(count) result += prev_c prev_c = c count = 1 result += str(count) result += prev_c return result for i in range(6): print i,say(i) 
In my case the parallel part was the use of scipy.stats.distrib.hypergeom.pgf and a couple of list comprehensions: about 50 lines of code in total. Yet what happened is that the processes ended their job, but didn't quit (in fact, killing them made execution resume without exceptions). Another bonus point in joblib vs concurrent.futures is exception support, which is much better in joblib.
Thanks for trying, I appreciate it a lot but I only have 10 min left and I would rather lose a few points than face plagiarism. I posted the thread for guidance not codes. Thank you very much though, I really appreciate your concern.
you should not call `say` and `see` to each other. Try keep internal data simple, only convert to complex strings when printing.
Some batteries: * Flexible URL to code matching with traversal. * Flexible view callable configuration eg: predicates, different renderers etc. * Console scripts * Easy logging and deployment with PasteDeploy. * My personal favorite, a highly customizable fine-grained authentication and authorization system that does not care about your choice of persistance system. * ...and more (extensibility etc) **All of them are optional. You can still have your one file app.** I like pyramid because it covers my need from one file app to a very large system. There are some products and frameworks on top of pyramid to help us even more.
Hi, I'm the guy who wrote this tutorial :) I've tried to keep the things really minimal and avoided many topics on purpose because if I would want to cover every component used in depth we would end up with 200 page book instead ;-) And this was supposed to be a newbie introduction that avoids complex concepts, so i skipped a lot of things. Feel free to send me questions, requests on what the tutorial should cover in future.
I'm currently evaluating web.py, web2py, flask and Django and was looking for something like that for Pyramid, thank you for this!
After extensive experience using wxPython for cross-platform GUI development, I would not recommend it. It has many bugs that require ugly workarounds. Of course I have reported them all but the development cycle is slow. It's not reasonable to expect to use the pre-built libraries if you come across some of the bugs, since you will have to fix them yourself (in the C++ code). Unfortunately there are few good alternatives. I don't have enough experience with Qt to make a judgement on it. The reason we chose wx over Qt was because PyQt was GPL'd (this was before PySide existed).
Early warning, turning pygame into an executable is a bitch and half. Especially for 3.0
Check out http://www.pyglet.org/
FYI, I just pushed a bunch of changes to the github repo, among which is a system for selecting shows based on popularity. Right now the metric is rudimentary -- it compares the show's rating with the number of votes -- but I plan to refine this further in subsequent versions. I'm open to any suggestions. I also included the possibility to manually select results from the command line. Lastly, I added the documentation for the custom formatting strings that I mentioned before. You can find the details [here](https://github.com/louist87/Scrappy/wiki/Formatters). I'd very much appreciate any feedback on the API or the documentation, if you have the time. Next stop, flexget integration!
Thanks! :D
Good thing no one in their right mind uses 3.0. Long live 2.x
Qt is part of Autodesk Maya these days (i.e. when you call the Python version of the old Maya/motif UI commands, these days it under-the-hood is creating Qt objects; also, Maya itself is now built with Qt), so it has a lot of love in film and games development, especially on the tools pipeline side of things. It's nice to finally be able to build tools somewhat natively that work inside and outside of Maya. Also, I love that not only can I use Qt Designer when I'm feeling lazy (or mildly incompetent laying out a complex UI strictly in code), but I FINALLY have the same UI at work on Windows 7, and when I'm working from home on my Ubuntu box, on which I also have Maya 2012 installed. [Video](https://www.youtube.com/watch?v=7zWlwdr7exo) from the announcement a couple of years ago.
this technique is pretty fun. but the hidden danger is writing code you won't comprehend months later. Still, it's pretty awesome when used sparingly and appropriately. 
how much do you make out of curiousity?
It's a training cost and a portion of costs can be deducted as such (many companies don't realize this). Many managers don't think of conferences as "training" at all, because many of the conferences they may attend are more sales pitches about products than actual learning. It's basically 3 days of advanced Python classes with some networking/fun around it. If you're looking to move to Python, what better place to network with top talent for future hires? 
Just started reading and i noticed i got some trouble following the text at the first paragraph of *Adding basic models* because the **Hint** (p.admonition-title) text is hidden. *(non-native English speaker here)*
They aren't (yet) a Python shop. This is as good a reason as any *not* to allow it. It could be construed as a job fair and talent grab.
From the perspective of a company, does it ever really make sense to send their developers across country to something like PyCon? Unless of course they're really specialized and need access to certain people. I can see the networking being advantageous to the developer, but to the company it just increases the chance losing an employee. As for the information/training part, you can usually find the videos of the talks online, as most other things you can learn from it. Especially if you're just starting to use Python. The target audience isn't beginners, but in that case you probably won't get any job offers from it either.
Do you have specific examples on what you could build with Python ? If you can say something like "Project A is presented at Pycon, and that's exactly what we could use in case B to be more efficient" that's imho something a manager can understand - in particular if you have concrete internal use cases that could be improved and that are targeted by some techniques/tools presented. 
Could you expand on why it is a reward? I am interested in that concept.
In my opinion it's a reward for two main reasons. 1/ Pycon is very enjoyable - you'll meet amazing folks and learn a *lot*. 2/ It means you are a trusted to represent your company and you can be part of your company innovation 
Convincing your shop to convert to python and then convincing them to send you to pycon are two completely different battles, and until yo usurmount the first obstacle you're not going to be able to approach the second.
Can you link me to specific part of the text?
[Here](http://pyramid-blogr.readthedocs.org/en/latest/basic_models.html#adding-model-definitions) is the link, the paragraph in question starts with &gt; This will make the app error... But it could be just me, a native reader wouldn't give it much thoughts probably :)
Thanks, need to correct this
Congrats on not being an average employee at an average company.
Management can see it as a positive thing: * Developers who love Python are going to have fun, so it is a reward, increases morale. * Developers need training so this is way to get some training * Conferences talk and present new technology, so send people to find out what the latest and greatest is. Sometimes it is the in-person, behind the scenes conversations that are the most helpful. Or they can see it as a negative thing: * Costs money * Chance of losing employees * Developers who love Python are going to have fun meeting other developers so not sending them is a good way to punish them [ the evil manager perspective ;-) ] Developers likewise see it as a positive (all the stuff that management might see as positive applies) or they could see it as a negative. They are force-able encouraged to attend but they don't really want to. Management might see it as a big reward (a bonus) to have a developer sent, the developer just sees it a wasted weekend away from family, when the could just watch the videos later at home. 
It does make sense in the same way that benefits packages make sense. A happy programmer is a long tenured programmer, and the company gets the added benefits of having a higher profile in the dev community (will help in future hiring, but definitely a long term investment in image). So no, not a direct and immediate benefit to the employer, just a long term investment in employee training and retention. Saying no because there is the potential to have your programmer poached is silly and will have the opposite effect: paid conference attendance is now something a poacher can offer as enticement. 
so you are using python and javascript?
This is the approach I've used in the past. We are a Java/.NET shop, so I used to highlight the IronPython/Jython talks. Look over the schedule of talks and find something that sounds like you could use it in your day-to-day job (or a specific project) and focus on that.
In the event they won't pay your team should still go. There are a lot of good talks this year.
Paying the costs of your employees doing anything (such as the work they usually do) is a business expense and comes off the bottom line before taxes, since money you have spent is not part of income. Conferences are no different in this regard and I assure you, every business realizes this.
If you are the manager of the development department, your prestige and power is measured by how many people report to you and how big a budget you control. Sending developers across the country to PyCon consumes training budget and thus assures that you will maintain at least the same training budget next year. If you don't spend all your budget, it is assumed you do not need it and it will likely be reduced going forward, thereby reducing your status among your peers at the company.
I'm not saying companies should be scared of losing employes because of the networking opportunities they provide for, I'm just questioning if it makes sense from a business standpoint to send them out to a conference, also because I don't think it's very effective for training purposes. I once attended something because it was in my city and it was very cheap for me as a student. Sure if was fun and a talk about PyPy was very interesting, but I didn't learn anything of practical use for a job that I couldn't have learned quicker by watching a YouTube video or an online tutorial. An airplane ticket across the country, hotels, not to mention the hours of the developers, don't seem worth the few things they can pick up online a lot quicker. Giving me a few extra days of so I can go on a real vacation keeps me a lot happier.
I did not have the same experience with online vs conferences. I have attended to many conferences and done some only via the streamings or the video they'd put online later. One thing that you can't get is the hall discussions, and the direct feedback from the authors of app X or lib Y -- and looking back that's where I picked most of the things that made me progress in Python and CS in general. Although I might not be a good example: if my company does not pay for Pycon - I am likely to take days off and rip off my savings to make it there. 
Nobody likes a jealous employer. If they're scared of me going to conventions because I might be looking for a new job, I *should be* looking for a new job.
Looks like a worth while purchase... ... but it requires my cc details, so no deal.
:D
 passes = [fn1, fn2, fn3] compose = lambda g,f: lambda *x,**kw: g(f(*x, **kw)) pipeline = reduce(compose, passes)
Nice, but you probably want to reduce on passes[::-1] to keep the left-to-right semantics.
Enthought came to my workplace for a short course. I did not take it, but a coworker (who has limited programming experience), said that it was a lot of good information, but a lot to digest in two days. He was also hoping for more visual feedback, like image processing. 
They are not personally handling your credit card details, they are using [gumdrop](https://gumroad.com/how-it-works), which uses [stripe](https://stripe.com/) for the transaction.
You can also just use a custom transport, subclassing [`xmlrpc.client.Transport`](http://hg.python.org/cpython/file/de6b91d97113/Lib/xmlrpc/client.py#l1098). Here's a (likely terrible) thing I wrote for Python 2.7 and an older version of requests: https://gist.github.com/2354951 Install the transport, use the xmlrpc client like normal: s = xmlrpc.client.ServerProxy('http://example.com/xmlrpc', MyCustomTransport()) s.system.listMethods() My Python skills are a bit rusty, so there's likely some errors in the above.
Insteon devices do both depending on the device.
You won't know the security practices of MOST companies. Remember the PSN debacle? How about LinkedIn which stored nonsalted password hashes?
I have an PyQt application that I develop on Linux and build for Mac and Windows and it works fine on all three. I didn't have to make any PyQt-specific changes for Windows or Mac either. The only wrinkle on the Mac was installing PyQt, but that's a lot easier if you use macports or homebrew.
As a new guy to this I just wanted to say thanks for being so verbose with your commenting, it's very helpful. 
Just curious, but why was csv selected as a more appropriate encoding for data marshalling when xml was already available?
At a former employer Enthought provided the quant/data science people with both python and numpy/scipy training. It was positive, and it did lead an explosion in-house in use of the tools.
(disclaimer: I work for Enthought and do some training myself) May I ask what you're looking for ? It is an intensive course (especially the short version of it), but we try to be as hands-on as possible. Sometimes, it depends a bit on the class as level vary obviously, and we need to take care of everybody in the room. You wil have a chance to interact with people who not only use those tools on a regular basis, but also develop them (I am myself a numpy/scipy contributor, for example, etc...). Would be happy to give you more details answer.
So ... aside from who to trust with your credit card details, has anyone tried the book, and is it worth reading?
I've little/no experience with using Mac to install things like that, how difficult is it to get started? Is XCode required? Just curious, I've an old bias against the OS that it doesn't deserve and I'm thinking about picking one up to test against.
2011 October - HN rolled out a bigger rss option for crawlers. The robots.txt asks crawlers not to traverse the site clicking 'more' repeatedly, which is essentially what your for loop is doing here. As an exercise, I appreciate what you are doing and I hope this advanced your project. http://news.ycombinator.com/bigrss You get about 10 pages worth of links with each request to the bigrss endpoint saving you quite a bit of time and resource. Dropping the request from 10 to 1 and eliminating the for loop should make considerable difference. Maybe you could benchmark the two and share? 
Unfortunately, the data comes out of an ERP system as 7 large XML files. The relationships are recreated in MySQL so that the data can be massaged, cleaned and approved. The end system only accepts CSV, and it only needs 4 of the 50 fields that come from the XML. It is a nightmare, but python is good about it.
Ah. Well, best of luck to you, comrade.
If you end up going, contact me and I'll help you out with some ideas on how to do this best.
Thanks. If I could articulate the pain it had caused me I would, but I can't.
It's usual to create and commit a README explaining wtf the project is all about. If it's a .txt or .md (markdown) file, github will display it below the table of files.
I don't envy you so that makes me feel a little better.