I like the end: *And even then, think twice before switching on useless optimizations.* 
I didn't go to WSGI in the first place. I will stick to CGIs, thank you very much. 
So the following Python code doesn't work ? What error do you get. import win32com, win32com.client op = win32com.client.Dispatch("PX32.OpenServer.1") 
I don't think I understood your point. You said that it's not a performance hack, but then you give link to FAQ entry, which says: &gt; Back in the days of Python 1.5, Greg Stein actually implemented a comprehensive patch set (the “free threading” patches) that removed the GIL and replaced it with fine-grained locking. Unfortunately, even on Windows (where locks are very efficient) this ran ordinary Python code about twice as slow as the interpreter using the GIL. On Linux the performance loss was even worse because pthread locks aren’t as efficient. &gt; Since then, the idea of getting rid of the GIL has occasionally come up but nobody has found a way to deal with the expected slowdown, and users who don’t use threads would not be happy if their code ran at half at the speed. Greg’s free threading patch set has not been kept up-to-date for later Python versions. Maybe I misunderstood something, but what it says is that GIL wouldn't be there if not performance issue. 
&gt; Can a lack of comments be overcome by giving variables descriptive (yet longer) names? IMO yes, as long as you make sure they are kept in sync when you re-factor methods / move around variables.
there is a simplejson branch that works better under pypy (still not as fast as the C extension). This does not come as a real surprise - an optimized C extension will run faster than unoptimized Python code (and this is the case here).
descriptive variable names are always good. In general comments should say something about the *why* rather than the *what* because the latter one is imperative with the code anyway... example: * http://www.markus-gattol.name/ws/python.html#inline_comments /edit: s/anyways/anyway/ ;)
Wow, that really changed how I think about comments. Thanks '#' == because
If they're useless, they hardly qualify as optimizations, do they?
I would have expected that kind of code to be *exactly* the sort of thing the pypy jit is good at optimizing. Using a naive timeit (which as fijal points out somewhere gives cpython an advantage) it looks like pypy is massively slower than cpython for string concatenation: $ pypy -V Python 2.7.1 (b590cf6de419, Apr 30 2011, 03:30:00) [PyPy 1.5.0-alpha0 with GCC 4.0.1] $ python -V Python 2.7.2 $ python -m timeit -s "a='foo'" "for i in range(10000):a += 'bar'" 1000 loops, best of 3: 1.74 msec per loop $ pypy -m timeit -s "a='foo'" "for i in range(10000):a += 'bar'" 10 loops, best of 3: 1.45 sec per loop Odd.
If you wouldn't understand a block of code when you came back to it later on, you should leave a comment explaining what that section of code does and why it does it. I don't think there's much more to it than that, and striving for a certain balance or ratio will just leave you writing unnecessary comments to reach an goal that doesn't provide value. Variable names don't tell you much of what their surroundings are about, which is the part that matters when commenting since you want to comment blocks or whole functions. Whether your name is `cnt`, `count`, or `count_of_hurfs_and_durfs` shouldn't change much, so pick whatever verbosity you are comfortable with.
Understandable. I've worked on webapps where json handling is the performance bottleneck (with CPython), so for those apps moving to pypy wouldn't offer any performance benefit.
Try this again without whitespace. In my very simple tests, using unindented JSON speeds up decoding quite a bit.
I try to avoid the abbreviation: 'cnt' I was also phrasing this from a collaboration standpoint. So its not just me reading my code. Thanks for the advice.
Of course, documentation guidelines differ. Until now I have found it a sufficient minimum to break up my code in a appropriate number of discrete functions (and classes) and to apply the following rule in combination with good variable names: **Before** a function is written, the behavior of the function to write is decided upon and illustrated with two things: A short description of the function in plain english. Optionally, the specification of every parameter inputed. One or more example calls to the function together with the outputs produced. Applying the following in a language like python produces the following: def add(a, b): '''This function will perform the numerical addition between `a` and `b`. &gt;&gt;&gt; add(2, 3) 5 &gt;&gt;&gt; add(5, 5) 10 ''' pass Only after this job is done, is *pass* replaced with the actual code that implements this function. If the function ever needs to be changed because your plan wasn't thought out well enough, then the documentation string is changed first before the source code. These examples calls and description strings end up in the official documentation automatically when you build it using a documentation generation tool. Same goes for classes.
Looks great, although I get a slightly unhelpful error: Traceback (most recent call last): File "/Library/Python/2.6/site-packages/nose/case.py", line 187, in runTest self.test(*self.arg) File "tests.py", line 50, in test x_buf, in_evt = buffer_from_pyarray(self.queue, x, blocking=False) File "pycl.py", line 2752, in buffer_from_pyarray evt = clEnqueueWriteBuffer(queue, buf, ptr, nbytes, **kw) File "pycl.py", line 1887, in clEnqueueWriteBuffer nevents, wait_array, byref(out_event)) File "pycl.py", line 837, in _result_errcheck raise cl_errnum._errors[result] InvalidEventWaitListError Any idea what might be causing that?
For myself, I never use variable names which are anything other than one or more words identifying the role or purpose of the contents. With one exception, I usually use single letter variables for the iterating variable in a generator, [c for c in counts]. In addition to that, if a block of code is in more than a handful of lines long, especially dense with function calls or list comprehensions, or does anything whose purpose could be argued over by people who hadn't read the code, put a comment there. If your code has many such comments, you should probably start breaking bits of it into functions whose entire purpose can clearly be articulated in a single good sentence in the doc string.
If the point of the exercise is comparing performance then changing the json would only be useful if it changed the *relative* speeds, not the absolute speed.
maybe you can use yajl-py to run yajl in pypy and maybe get interesting results http://pykler.github.com/yajl-py/
Not odd at all, the JIT can do many things, I can't fundamnetally change the time complexity of operations on data structures. String concatination is O(N), repeated string concatination is O(N**2). Don't build strings that way, the CPython hack is fragile, and 100% non portable.
IIRC pyOpenGL (or was it pyglet) runs many times faster with -O because it turns of a ton of assertions that could cause core dumps. So yeah, don't use -O if you don't know what it does, but also don't say that it doesn't do anything because removing assertions can be a big thing.
What is this "CPython hack" that you mention, anyway?
Yes I know. By removing whitespace I'm reducing N which would most likely reduce the times for all the solution at the same rate unless the time complexities are different, for instance if one solution is O(N) and the other is O(N^2). I was just passing along the tip that If you want the best possible speed out of any parser, use non-indented JSON blobs. I think if I remember correctly the parse times were 1/10 the time of the indented version. YMMV. UPDATE: At the size of this JSON blob, we're not going to see gains from removing indentation 
This is a fantastically concise explanation. I recently had to read some code where everything was commented with "how" statements. The code was good but the comments were so verbose that I had a slow time actually understanding it.
ya, correct. Well, working on it :)
if refcount is 1, then don't allocate a new string (remember strings are immutable). If you have another reference to the same string, things go to shit.
This article is basically from someone knowledgeable but not a "python framework developer". Most people who simply want to develop web apps in the easiest way will probably draw the same conclusion. Those who have transfixed with the status quo of frameworks in Python will probably disagree. One thing that might be noted is that the author of web.py (which powered early versions of reddit) is currently in legal trouble. So it's not clear if that particular framework is going anywhere.
Python can use COM. I recommend it, if there is literally no other way to do what you're doing. 
There is a saying that all programming is collaborative: you now is collaborating with you in a month. 
Generally I don't comment much except when I do something weird or rather clever in the code. Of course *documentation* is quite different, and try to give my functions docstrings as my first action.
But isn't it O(n^2) because of the intermediate allocations, and intermediate allocations is one of the things I thought the JIT recognized. Obviously I'm wrong, but that was my thought process. (None of the intermediate strings in the loop ever escape the loop, so could be replaced with a single larger allocation - which is what the CPython hack essentially does.)
Yeah, the point of this particular exercise is to choose _which_ parser - not to eke the best performance once you _have chosen_.
Doesn't -O also remove the SETLINENO bytecodes?
I'm sure I've seen such claim somewhere, but there is nothing about it in the section of Python docs linked. While writing the post, I've tried some things with -O and -OO and I've seen line numbers in stacktraces. I'm not sure if they're related to this bytecode
More importantly: don't write assertions with side-effects. A program that runs fine without -O should run just as fine with it. Assertions are a debugging tool for development, just like deprecation warnings or debug logs. It is completely sensible to disable all of that on a deployment. In particular, never use AssertionError as an API. You're not supposed to catch it (except in test automation).
Nice :-)
There is a problem in that there _is_ some global state for a Python interpreter. This causes problems for mod_wsgi (for example) that does try to create an interpreter per thread. There has been work in recent versions of Python to reduce this global state, but it isn't complete (and I don't think anyone is working on completing it).
They each escape the iteration of the loop. So for example: for i in xrange(1000): c = a + b + c Where ``a``, ``b``, and ``c`` are strings does one allocation. ``a + b`` never escapes the iteration, so it isn't allocated, but ``(a + b) + c`` does escape, so it is.
The reason the GIL is around *now* is because of performance impacts to removing it oh-so-long ago. Based on what I've read (insert nebulous hand-waving here, because I don't have any sources handy), the reason the GIL came into being was because it made hacking on the interpreter easy(ish). To me, at least, that means it isn't a performance hack because it isn't something that got added specifically to make performance better. I imagine that if the status quo were reversed (there was no GIL) and somebody suggested inserting one in order to speed up single-threaded code (which would make it a performance hack, in my mind), that suggestion would be shot down pretty much immediately.
The term you want to google for is "python idioms". Just read the various results on that page. They have lots of pro-tips. http://www.google.com/search?q=python+idioms Also learn the standard library. The best place to do that is the Python Module of the Week site: http://www.doughellmann.com/PyMOTW/
Comments like these also go a long way towards explaining what the application is actually doing, even if taken out of context. You can infer a lot from just a single line. win_size -= 20 # leave space for the scroll bar That immediately tells you that it's a GUI application that probably does some dynamic window resizing. Compare that to w -= 20 which can be pretty much anything.
Correct, and [Larry Hastings talked about optimizations at PyCon 2010](http://python.mirocommunity.org/video/1513/pycon-2010-optimizations-and-m). The SET_LINENO part starts at about 3:45 in.
How does your app get notified of the new data? You should be able to hook into that to tell the textctrl to update. Since it's an IRC bot I assume there is an event tied to incoming data on a socket via select(). IMO, polling with a timer is always a last resort in an event driven app. I really like wxPython, the learning curve isn't much harder than other GUI toolkits. I found the hard part is learning the paradigm of a mainloop driven app.
I seem to always use singular and plural nouns for loops. It makes me happy to see the singular version in use in the code: for joint in joints: for name in names: for prop in props.keys():
Currently (I stripped my bot of all it's functions except printing IRC messages to console) I have it in a while(1) loop with just irc.recv(4096). I have an IRC class that handles all of the IRC/Socket related things. I would I go about creating a method in my IRC class that could raise an event for wxPython? I swear I'm GUI-tarded.
What I was surprised by was that the pure python stdlib 'json' module was faster in CPython than in PyPy. It does definitely make sense that well coded C extensions should be faster than PyPy. I might add the simplejson pypy optimized branch to the benchmark later if I have time.
You might want to have a look at PySide (official python interface for Qt). I found it a easier to understand and to get it running. But yeah, I totally agree, CLI ftw :D
The *.dll or *.ocx is probably not registered if you don't see it in the COM browser. You can do it manually with Regsvr32. (http://support.microsoft.com/kb/146219/en-us)
What do you do if you have a list of deer?
Multiprocessing is indeed awesome. You might want to check out the [concurrent.futures](http://docs.python.org/dev/library/concurrent.futures.html) module as well. I used it yesterday to replace some MPI4py code that was always executed on a single machine. It greatly simplified the codebase. It's much less setup than using multiprocessing directly, and definitely a lot less than trying to use MPI4py 
I'm using descriptive names. If I feel the need for commenting then most of the time the code is to complicated. But sometimes I can't help ... I'm using plural nouns for sequences and "%s_to_%s" % (key, value) names for dicts. For methods verb and noun, like "eval_variantcondition()". The names can became quite long which bugs me from time time but to be able to read the code like a book later makes up for it.
fish pose a similar challenge.
So a GUI app has something similar to a while(1) called the main loop. Within the main loop it checks for events from the operating system and calls your appropriate event handlers (it really is like a glorified switch() statement which constantly asks the OS if any events are available). There are two common ways to add to the main loop: timers and idle event handlers. Timers just fire off an event for you to handle at regular intervals. Idle event handlers are called whenever your app is sitting around not doing anything. Neither of these options is a good fit if your irc.recv(4096) call blocks; meaning it doesn't return until a buffer is filled or something times out. The reason blocking IO calls aren't a good fit is because when you go to handle the event and it waits for several seconds for some condition your app can't respond to other events (like repainting the window or responding to mouse clicks or typing). If it is stuck in that event handler for more than a few seconds the OS will probably notify the user that the app isn't responding and give them an option to force it to close. If you can set a fairly low timeout on the irc.recv() call through an argument (something less than 100 ms) the user probably wouldn't notice the occasional delays. Even better would be if you can test if there is data waiting for you rather than using a timeout. Neither of these are ideal though. Some people use a separate thread to get around the blocking issue. I've used this technique successfully (in C++ though). This link may help you about [long running tasks](http://wiki.wxpython.org/index.cgi/LongRunningTasks) may be of assistance. The best option is to use IO that fires off events when you receive data that needs to be processed.
More comments, the better. Especially brief explanations before a section. I want to kill people that dont comment their code. 
Obviously: for dinner in deer: eat(dinner) 
The easiest way to implement this would be to structure your app around the gui, like this: while (1): do_irc_socket_things() process_gui_events() My memory of wxPython is a bit rusty, but I believe that translates to something like the following. Consult the docs or, better yet, wxPython examples, on how to add an idle event handler. class MyBot(wx.App): def __init__(self): wx.App.__init__(self) def on_idle(self): do_irc_socket_things() app = wx.App() app.MainLoop() This is the most straightforward approach, but it is prone to the blocking problem outlined by [echowastaken](http://www.reddit.com/r/Python/comments/jesk8/a_bit_of_trouble_with_understanding_wxpython/c2bigha). It will work, but will be laggy. Still, don't be afraid to try it out - it shouldn't take too much time to implement and might not be that bad, especially for a first iteration. Some advice on mastering GUIs. Don't get distracted by the fact that most books and tutorials spend a lot of time describing standard widgets. That's not the most important part. Event handling is what you should be looking at. This is what constitutes GUI programming. Standard widgets are there just for your convenience. Chances are, if you do anything fun with GUIs you'll probably be writing your own widgets almost immediately.
First of all, if you are hosting code from other people and turn optimization on, you're doing real harm in form of not only possible code breakage, but difficulties with debugging, et cetera. And in return you get *nothing*. Well, almost. So enabling optimization without *full* control over all the code you're running is just being a jerk. More importantly, while my asserts never have side effects, they check my sanity. And it's a pity, but I'm not really clever to write bug-free code: sometimes these asserts they go off. And I actually like that, because I prefer code with known bugs over code with unknown. Yes, I'm *proud* what I have asserts in critical parts of my applications. These apps will work with optimizations enabled, of course, but I'm gonna be more anxious. If I need to run my code in the environment where my sanity checks are prohibited, I' have to invent my own system to do them. Right now I just add asserts and wait for Sentry to report failures on them. Thank God these failures are really rare, and not because they are silenced.
I would use deer_list or something similar, or even deers (hey, I'm not writing a novel).
The code should be readable itself. Sometimes comments actually detract from this. Documenting a function for a documentation engine is obviously a good idea, though. Otherwise, in my opinion, the code should read cleanly to a person who knows the language in question. There should be comments to clarify in situations where something clever/confusing is happening.
What exactly are you doing that needs that many cores?
Err... this would have been fine with a big fat "these are my first impressions, correct me if I'm wrong please" label on it. With the authoritative voice the author tries to take, however, the inaccuracies are very glaring.
On the right, you see reference to [Spitzer](http://en.wikipedia.org/wiki/Spitzer_Space_Telescope) data files. Spitzer is an IR telescope, so I imagine he is an astronomer doing data analysis. Modern astronomy generates a lot of data, so I reckon he benefits greatly from the parallelism. 
This comments hints at the larger problem: knowing how to use COM/OLE/ActiveX. You need to know about using type libraries, registering COM components, etc. Much of the trivia around this is hinted at here: http://www.rhinocerus.net/forum/lang-basic-visual-misc/150999-class-object-creation-managing-automation-references.html And FWIW - A simple search on Google with 'PX32.OpenServer.1' as the term will lead you to more threads in various forums on this subject. 
interesting, can you elaborate on the advantage of using concurrent.futures over the std multiprocessing module? is it worth the dependency injection?
I like the approach Gtk + gobject allows for this kind of stuff. Your source class (the one that gets information from irc) can then be subclassed from gobject.GObject and raise signals when apropiate, which you can then connect to some method in your ui that updates the text control. Something like: class Source(gobject.GObject): __gsignals__ = { "irc-event" : (gobject.SIGNAL_RUN_LAST, None, (str,)) } def __init__(self): gobject.GObject.__init__(self) gobject.timeout_add(100, self.check_events) # will check every 100 miliseconds what our status is def check_events(self): # ... check the status of your source if condition_to_handle: self.emit("irc-event", str(data_to_pass)) return True # so it resets the timeout class GUI(gtk.Window): def __init__(self): gtk.Window.__init__(self) self.source = Source() # ... add your widgets self.text = gtk.Label() self.source.connect("irc-event", self.update_label) def update_label(self, source, data): self.text.set_text(data) GUI() gobject.Mainloop().run() EDIT: the timeout part is, strictly, unnecessary. That would depend on your design. EDIT2: and gtk is not really required either, so you can use this gobject-based approach using other toolkits too.
That's interesting, can you be a bit more specific?
*The short version:* Analyzing multiple scientific datasets that can contain tens of thousands of images. Analyses of the same data but different run parameters are often very different and need to be tested. Each analyses can take hours to upwards of a day to run (depending on the number of images) and each time you vary a run parameter, you have to start over. This calls for multiprocessing, where I can run 10 different cases at the same time. This saves days, really. *The long version:* I do research on extrasolar planets (exoplanets). We observe them with the Spitzer Space telescope. We basically observe when the planet passes behind it's star. When this happens, the total brightness of the system (star + planet) dims by a tiny amount. Since you can't actually resolve the planet separately from it's star, this dip in brightness is all we have to characterize the atmosphere, size, and temperature of the planet. Our observations are usually many hours long and the exposure times are short; sometimes an image is taken every 2 seconds and sometimes every 0.2-0.4 seconds. Some datasets can span over 100k images. We use python to basically draw a circle (aperture) of some radius, centered the star+planet system in the image, and then sum up the values of the pixels in this aperture. This sum (total flux) versus time will give a plot that [looks like this](http://science.gsfc.nasa.gov/667/images/exoplanets_stars/SecondaryEclipse.jpg). In the image I posted, I am running a data set of around 2000, 256x256 images (small dataset) through photometry (the process of summing the pixels in the aperture). I am utilizing the multiprocessing by running multiple versions of the same dataset through photometry using a different aperture radius. I went from 2 pixels to 4.5 pixel radii, in 0.25 px increments, giving 11 different runs. Each process uses 100% of the CPU, so I am using 11 cores. Simultaneously, I am doing the same thing (11 runs) with a different data set, using 22 cores. When the photometry is finished, we also model the data by fitting a bunch of different analytic models and also do some further data and noise reduction, which is also cpu intensive. Our group is composed of 7 people currently, so at any time one of us may be doing a run. You can see, the cores can fill up fast, as does the ram (we have 48 gb) and disk space (we probably have hundreds of TB saved in swappable drives). Oh, and all of our code is written in Python w/ NumPy, SciPy, and Matplotlib.
audio is horrible on many of these talks, what a shame
The main advantage is there's hardly any setup involved. If you look at the examples in the given documentation, there's very little that needs to be done to get concurrency going. You can essentially take code that's in the form of: map(my_func, my_data) and convert it: with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor: executor.map(my_func, my_data) and you are done. There's no need to create a process pool, queues, etc. All of that is done under the hood. If your code doesn't fit a simple map, you can can call `submit` for each function you want to submit to the executors. 
Wow, that sounds so awesome, I hope I could get job at a research station like you when I finish school. Thanks for lengthy description.
Dead on. I am actually an undergrad doing research, and my advisor is the professional astronomer. I have been doing this for many years however. [My publications are listed here](http://adsabs.harvard.edu/cgi-bin/nph-abs_connect?return_req=no_params&amp;author=Campo,%20Christopher%20J.&amp;db_key=AST), if you are interested.
No problem. I am actually an undergrad (5th year, meh) at UCF studying Physics (astronomy/data analysis track), Math (minor), and Computer Science (minor). I landed this research job my second year as a student when I changed majors from CS to Physics. It really isn't all that it's cracked up to be unfortunately. At first it was awesome, but times are tough as we are running out of money. Also, the workload is a lot. But I do have a lot of freedom, and I have learned a ton since I started the job, not to mention I got to travel to England and LA for a few conferences, for free.
I wasn't necessarily disagreeing with anything.
My personal thoughts, based on nothing much: 1. Docstrings can never be too long or too detailed. Conventions are good, though, numpy docs have a good one. 2. Inline comments should be used sparingly, instead write your code so it's readable. Part of the reason for #1 is that tools exist which automate creating documentation from your code, and they tend to like docstrings. Also, it makes it easy for people to read **either** the code or comments (but not both to save time).
I looked at it, but from a quick glance, I couldn't find an easy way to do basic serialization and deserialization.
I can see how it would be useful and more readable even in the case of two variables, if the bounds are specified as names rather than constants, e.g. if all(MIN_VALUE &lt; x &lt;= MAX_VALUE for x in (a, b)): 
Nice pattern! Thanks for sharing. It's worth noting that the any() function will short circuit, just like using a chain of "or" operators: &gt;&gt;&gt; def is_divisible_by_2(x): ... print 'checking', x ... return x % 2 == 0 ... &gt;&gt;&gt; if any(is_divisible_by_2(x) for x in (1, 2, 3, 4)): ... print 'found a value divisible by 2' ... checking 1 checking 2 found a value divisible by 2 
This is an excellent article. Not because of the result which of course has upset anybody who is not rated 9.0 and is not old enough to know that sometimes you lose. First of all this article is not targeted to hard core python programmers and it is no surprise it lacks the kind of technical details that some people here are looking for. This article is targeted to people who are new to Python web frameworks and want to know where to start. What makes this article excellent is that the author seems to have tried the frameworks himself before reaching his conclusions. There are lots of people here who re-tweet and re-post other people negative comments about other frameworks without trying them themselves. Finally an article by somebody reputable who actually tried them all. Is he biased? The outcome is but there is no evidence that he was biased when he started his research. Anyway, he appears less biased than people who down-vote this thread about Python frameworks on /reddit/r/Python simply because they work on/with a different framework. This article promotes Python web frameworks to an audience much larger than the Pyton community and all of them end up pretty good and solid. This good for everybody. All some of you can see is an article not advertising your toy. This is childish. Some of us are here to promote the larger Python community. Some of us seem to be here to promote only their petty little projects. Do you think any of these frameworks will be around in 5 years? This community needs to do a better job at working together not against each other. From the comments looks like some people did not even read the entire articles (you have to sign up to get the longer version). 
It seems that the WebOb approach is to generate a new Request instance at every http request; whereas another approach is to keep a global Request instance which is updated at every http request. Which is more expensive?
Other than the restriction to python, is there a reason that the lab you are working in does not use GPU processing for this kind of work?
No not really. In fact, we have actually discussed using GPU processing in conjunction with the CPU. Basically, it all comes down to time. To utilize the GPU, somebody would have to go in and write/modify all the code, and we really don't have the workforce to do it. It comes down to time vs savings, and really, our code isn't that restricted anymore now that we have 48 cores. Using the GPU would require more coding time than the time it would save in the short term. Obviously, it would be good for the long term speed wise, but still, it would be a pain. That being said, we have looked at PyCUDA briefly. Some undergrad will probably get stuck writing with it when I leave.
Regarding CUDA or similar, I just asked a Physics professor that question and her response was along the lines: The university requisitions department doesn't understand that GPU's can be for anything but computer gamings; The dept chair argues that while GPU's have far superior processing capabilities for a number of problems, they're hyper specialized and that its cheaper to buy the bare minimums ( mobo, CPU, memory) and then use netboots to a common shared NFS. The professor gave me a long list of reasons why the first problem was crap and had some relatively colorful things to say about the dept. chair. Note: I've worked on and off for the unmentioned university for the last few years and I usually have the Benny hill theme song stuck in my head each time someone explains how my invoices are routed through the financial gate keepers of the school. As I understand it, grant money goes to the professor(s) and is held in trust by the school and then the school provides book keeping to ensure the money is not misappropriated.
I would totally go with deers and fishes. It would make me smile every time I saw it again. I'm not even opposed to fishies. One time I made a utility for our 3D app that could hide selected objects (and remember groupings and other things). I named it "Hidey." A cute girl I worked with, upon launching the utility for the first time yelled from her cube "YOU NAMED IT HIDEY!?" and then she laughed. Girls like a guy who knows how to name things.
Python doesn't prevent you from using GPU processing. See pyCUDA or pyOpenCL.
Are you using several cores on a single instance of a dataset in memory? Or analysing several datasets at once, with one per core? And you are using the 'multiprocessing' module? (**edit:** first question slightly reworded)
That sounds good!
Part of Zen of Python: fear the Guido.
Did you consider writing the core inner loop in C/C++ and just call that from Python? I find that you can beat numpy by a big factor for all stuff that can not be easily vectorized (not sure if this is the case for you). Recently I used cython a lot, makes it easy to prototype in Python with numpy and later easily transition to C by adding some type annotations (and maybe explicit loops).
Whats the word on python 2 vs python 3 in your field?
Is there a reason you chose this over MATLAB?
Not exactly sure what operations you need, but [scikits.cuda](http://scikits.appspot.com/cuda) makes things pretty easy. Switch an import, and most of your functions turn into GPU functions. That said, as a data-crunching researcher myself, we tried to use GPU processing to do some of our work, but we quickly gave up on it. Unfortunately, most of our operations are data-limited, not computation limited. Switching to GPU would have required far more time shuttling data over the PCI bus...
I had a lengthy response written but firebox crashed. Either way, check [this](http://hginit.com/) out.
It makes me happy to see other people at UCF using python. By any chance did you see the new campus map? All python.
NumPy, SciPy, and Matplotlib: the holy trinity.
No. SET_LINENO was removed from Python in version 2.3. Before that, -O did remove it, and it was an optimization. From 2.3 and up, it just disables asserts and ``if __debug__`` blocks. Some versions of Python also have a peephole optimizer for bytecode that does a few minor rewrites of bytecode, but I *think* those are on by default in modern Pythons anyway, and aren't affected by -O.
Both are essentially free. That's a wrong place to look for optimizations.
Ah, thanks.
Very cool, thank you
I see three pages: a chart with numbers page, a summary page with mostly text describing each framework, and a third page with more charts. I see the same thing both logged in and not logged in. Is there more to the article than that?
Watch out for patterns like this (found recently in some code I'm maintaining) def doStuff { ... a bunch of code ... // start the server ... a bunch of code ... } The code following the comment should most likely be its own function. In most situations, the function name alone should give you a good idea of the what. As others have said, comments should be reserved for the whys, or the hows.
Still no luck with the latest hg version, unfortunately. Output is: Using /System/Library/Frameworks/OpenCL.framework/OpenCL Platform: Apple GPU: ATI Radeon HD 5870 CPU: Intel(R) Xeon(R) CPU E5462 @ 2.80GHz
Aha! "For the finer details, follow the links in the table below and plunge into the individual reviews." http://www.infoworld.com/d/application-development/pillars-python-cubicweb-web-framework-169105 http://www.infoworld.com/d/application-development/pillars-python-django-web-framework-168643 http://www.infoworld.com/d/application-development/pillars-python-pyramid-web-framework-168661 http://www.infoworld.com/d/application-development/pillars-python-webpy-web-framework-169072 http://www.infoworld.com/d/application-development/pillars-python-web2py-web-framework-168920 http://www.infoworld.com/d/application-development/pillars-python-zope-2-web-framework-168935
Yes. You are only looking at the summary article. [There are actually 7 articles](http://www.google.com/search?q=pillars-python+site%3Ainfoworld.com): a summary and one for each framework. These latter ones are a little longer when you are logged in. In total there are about 3x7=21 pages. It is confusing because the world "Django" does not link Django, it links the article about Django, etc. 
Quick tip: Instead of having a separate terminal window open, you can type M-x run-python (or python-shell) to have a Python interpreter inside of emacs. Just put that in a split-pane of it's own and you can avoid all the window-switching!
It's sort of an optimization if you have lots of debug assertions or other debug-type code guarded with ``if __debug__`` (such as debug logging), all of which would be stripped out of the bytecode and never run. Typically people don't have a whole lot of these and what they have isn't typically very expensive, though. Personally I'm doing design-by-contract via interfaces adding type checks to attributes and method arguments/returns plus preconditions and postconditions that wrap each method and class invariants that run after any attribute setting and method calling... I'd expect the overhead would add up in any larger system eventually, and ``-O`` disables all this. The primary intent is to catch bugs during *development* and improve tests by sort of embedding tests in the code.
[PEP 8](http://www.python.org/dev/peps/pep-0008/): ##Comments Comments that contradict the code are worse than no comments. Always make a priority of keeping the comments up-to-date when the code changes! Comments should be complete sentences. If a comment is a phrase or sentence, its first word should be capitalized, unless it is an identifier that begins with a lower case letter (never alter the case of identifiers!). If a comment is short, the period at the end can be omitted. Block comments generally consist of one or more paragraphs built out of complete sentences, and each sentence should end in a period. You should use two spaces after a sentence-ending period. When writing English, Strunk and White apply. Python coders from non-English speaking countries: please write your comments in English, unless you are 120% sure that the code will never be read by people who don't speak your language. ### Block Comments Block comments generally apply to some (or all) code that follows them, and are indented to the same level as that code. Each line of a block comment starts with a # and a single space (unless it is indented text inside the comment). Paragraphs inside a block comment are separated by a line containing a single #. ### Inline Comments Use inline comments sparingly. An inline comment is a comment on the same line as a statement. Inline comments should be separated by at least two spaces from the statement. They should start with a # and a single space. Inline comments are unnecessary and in fact distracting if they state the obvious. Don't do this: x = x + 1 # Increment x But sometimes, this is useful: x = x + 1 # Compensate for border 
... and I'd go one further and say that, whatever programming language you're using, descriptive variable names beat comments: window_size -= scrollbar.width (where scrollbar.width is property of your scrollbar class, even if it does just return a constant).
And the associated, very common, filter-while-you-map: [a.attribute for a in original_list if a.attribute is not None] 
I don't know about the OP, but I use Python for some significant simulation and analysis work. I've moved on to Python 3 since SciPy and NumPy are up and running. I, however, do not have a 48-core machine, only a measly dual-core system. And *multiprocessing* rules!
You gatta redo this with htop instead!
The only thing I'd love more than a 48 core machine is some type of work that would utilize it!
Don't let the language boss you around like that! Who is in control around here, you or some sniveling type system? r = [ struct.unpack("f",struct.pack("i",i))[0] for i in range( struct.unpack("i",struct.pack("f",2))[0], struct.unpack("i",struct.pack("f",8))[0] ) ] 
Yes, yes, and yes. &gt;The short version: Analyzing multiple scientific datasets that can contain tens of thousands of images. Analyses of the same data but different run parameters are often very different and need to be tested. Each analyses can take hours to upwards of a day to run (depending on the number of images) and each time you vary a run parameter, you have to start over. This calls for multiprocessing, where I can run 10 different cases at the same time. This saves days, really. The long version: I do research on extrasolar planets (exoplanets). We observe them with the Spitzer Space telescope. We basically observe when the planet passes behind it's star. When this happens, the total brightness of the system (star + planet) dims by a tiny amount. Since you can't actually resolve the planet separately from it's star, this dip in brightness is all we have to characterize the atmosphere, size, and temperature of the planet. Our observations are usually many hours long and the exposure times are short; sometimes an image is taken every 2 seconds and sometimes every 0.2-0.4 seconds. Some datasets can span over 100k images. We use python to basically draw a circle (aperture) of some radius, centered the star+planet system in the image, and then sum up the values of the pixels in this aperture. This sum (total flux) versus time will give a plot that looks like this . In the image I posted, I am running a data set of around 2000, 256x256 images (small dataset) through photometry (the process of summing the pixels in the aperture). I am utilizing the multiprocessing by running multiple versions of the same dataset through photometry using a different aperture radius. I went from 2 pixels to 4.5 pixel radii, in 0.25 px increments, giving 11 different runs. Each process uses 100% of the CPU, so I am using 11 cores. Simultaneously, I am doing the same thing (11 runs) with a different data set, using 22 cores. When the photometry is finished, we also model the data by fitting a bunch of different analytic models and also do some further data and noise reduction, which is also cpu intensive. Our group is composed of 7 people currently, so at any time one of us may be doing a run. You can see, the cores can fill up fast, as does the ram (we have 48 gb) and disk space (we probably have hundreds of TB saved in swappable drives). Oh, and all of our code is written in Python w/ NumPy, SciPy, and Matplotlib.
GPU's kind of suck for crunching through large amounts of data that is stored on disk.
Sorry, my question was not specific enough, I have updated it.
:-/ Until matplotlib understands python3, nothing will happen, at least for me (neuroscience). As far as I remember, not all of scipy handles python3 yet either? At least numpy is finally supported, but it's not packaged yet by all the major distros. I'll switch when the distros do :)
The answer is still yes, yes, and yes. For the first question, he said that he uses 11 cores on a single dataset, with each performing slightly different operations on it, and then he uses the remaining cores for other datasets. He is also using the multiprocessing module, as he stated.
I wasn't sure if he was working with 11 independent copies of a particular dataset or was manipulating a single dataset in memory with 11 processors. I'd guess it's the first one, but I wanted to confirm.
so you say that *not* asserting everytime you run something *isn't* an improvement and that it only affects module load speed? fwiw I've no idea how this works internally so do explain.
You could try running it as a shell script. Note I've gotten burnt really bad trying to use XCode 3 for python development. So I installed Eclipse just for Python. Yeah a big IDE on it's own but PyDev is very very good. As to XCode 4 so far it has been the biggest piece of crap Apple has ever released as far as I'm concerned. Very very frustrating so I don't even try to use it as a Python environment. That being said I have used XCodes scripting feature to run make files to build old bits of software. For the "C" languages XCode isn't bad if you can stomach all the bugs. However doing things this way certainly don't leverage the IDE well at all. 
While I totally understand the purchasing aspect... From a tech aspect GPU's aren't 'one size fits all' unfortunately. It requires that people understand how to develop for that specific platform. Some types of applications just aren't good a fit, and some ports are just in their infancy. Beyond that, with high core count CPU's, there's a trade-off between the performance gains from a GPU and a more general purpose CPU. Most GPU's take up around 200 Watts of power, which, assuming 95W Intel CPU's, you could, in theory, get 10 cores of regular CPU cycles that nobody has to specifically code anything for. In reality, you'd get 30 cores - since GPU's require there be a local CPU. Clearly, this isn't as likely with the E7 chips being expensive, but AMD 61xx series would do all of this as well.
First you should not catch 'Exception' but catch the correct exception name. In that case that could be 'TypeError'. Catching generic Exception without knowing the reason is bad habit. &gt;&gt;&gt; time.strftime(2) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: must be string, not int I would personnaly just let the exception happen and raise on its own ::) You modified the call for format_ks() to use __format as a variable name. You should read the PEP8 again, especially the parts about double underscore naming. It should be used only to avoid name clashes which is not the case here. If you really want to avoid redifining the format() builtin just change the name of your variable. The use of double underscore is not broadly appreciated in the python community. Looking at your repository again, I see you created folders for different versions of your project. Do you understand what git is for? ::) You don't need to do that and it's actually confusing. You should tag your releases in time with a convention you chose (git tag stable_1.0.0 for example) and upload tarballs of your stable versions in your github account.
Depending on what the code looks like GPU processing might not be the best answer. If the particular function has a lot of branching, or writes to many different locations (FFT) standard CPU's can do a better job. GPU's are great for operations that are easily vectorized, but aren't necessarily that amazing general purpose.
Another comment. Check out the new parallel library in IPython 0.11. It uses multiprocessing with pyzeromq, and in my experience is more stable, and easier to use. Moreover, you can easily hook up several machines to where they all just look like one cluster through ssh. It is allowing me to use two 48 core machines, plus my local 6 core xeon, plus a couple of other random machines around the lab, like they are a single cluster. 
I wonder if someone did this math already for my client school, relayed it to finance, and then finance promptly forget the reason but kept the decision. I've found a lot of truth in this [joke](http://www.difrances.com/monkey.htm)
Quad Opteron with a Tyan board?
I saw Spitzer and was quite surprised. I am working on Spitzer data for a large survey, so I can run the Mopex pipeline without much change, but you work is pretty awesome.
Google did a whole bunch of studies on this and found that the price of having specialized processors is too high versus plain old CPUs that they can easily swap out and use for a greater variety of computations. I'm guessing this also applies to a lot of things like physics clusters where they go through hardware frequently.
It's free and a lot more expansive. You can do tons of stuff in Python that you can't in MATLAB.
Yes actually. When we do our modeling routine, all of our models (including Chi-squared, the residual function) are written using the C API. This sped us up something like x10. We have yet to write our photometry routine in C, as it would probably not provide much of a speed-up. We use [numexpr](http://code.google.com/p/numexpr/) whenever we do operations on large arrays, which has also sped us up quite a bit. Originally our code was written in IDL, and what used to take hours to run in IDL takes a few minutes in Python.
Awesome. What do you do?
Oh yes. I live by these modules.
Thanks! 8 years and still going strong.
We've yet to move onto Python 3, mainly due to backwards compatibility issues as well as some of our packages are not suited for Py 3 yet. That being said, all of our code is written to be compatible with Python 3 when we are ready to make the move, and we have even included some features such as their new print function (from __future__ import ...).
It's actually both. Basically it works like this (in flow chart form): read data -- fix bad pixels -- find center of star -- photometry with aperture radius 4.00 px -- photometry with aperture radius 3.75 px -- photometry with aperture radius 3.50 px -- ...
Awesome. I will remember this.
What about the int/int=float thing?
'What exactly are you doing that needs that many cores?' All pulling at 100% too! I have an 8 core here that I don't think I ever saw pushed with all 8 cores at 100% like that ... nice.
We don't use integer division for anything. If we do, we use the floor function.
Thanks, it sounds interesting. I work with very large datasets in Numpy as well, but have only tried to parallelise the scripts using mpi4py (and never got very good scaling, either). If you ever make the scripts publicly available, I'd love to see how they work.
Multiprocessing also has a map command. pool = multiprocessing.Pool() results = pool.map(my_func, my_data)
I believe so. Definitely Quad Opteron.
Yes, but from terms of removing GIL then and removing it now -- what changed? The same explicit locking will go on, maybe codebase is now bigger, so it will be little harder. But the work will be the same and it's speed impact should be the same, I guess. And this work was long time ago, so I can think that cpython didn't have much of optimizations that it has nowdays, so it was even more slower (and still after all those locks had 2x slowdown). I'm sure hacking is easier with GIL, but I really think that if someone would be sure that explicit locks wont hurt performance -- someone would start doing that (besides, you can remove GIL step by step, not entirely dropping it, so migration can be more painless).
Well, it's a known problem for pypy developers and I guess it's not about jit or something like that (and I thought tracing jit is more about processing some existing data and doing some algorithms, not about allocating new memory).
That's what I do with our 24-core server at work when I don't want to be bothered. Start up some number crunching and then open a large terminal window with htop. "Hey chemo I have a question about whoa, that looks important, I'll bother you later."
matplotlib. Necessity.
First of all, I just told you what the smart people said in docs :-) And yes, I don't think that one boolean expression affects speed. I believe there isn't any jumps and complicated conditions, so it seem like `assert a == b` is really smaller (it's like 1 instruction only) than even `if a != b: raise AssertionError`. But I'm not sure. And actually not really interested in *how* small these assertions are - I believe they are small enough to go unnoticed
 n = int(input('Is this integer prime?')) for x in range(2, n): if n % x == 0: print 'No, ', n, 'is divisible by ', x, break else: print n, 'is a prime number'
While what you say is generally true, there still are some cases where an assertion will have a On^2 runtime (or more) for large datasets and thus it would be very useful to switch them off for deployments. Again, not practical for most processing, but in some scientific and computer graphics related fields these kinds of optimizations could be very useful.
Awesome. Muches Graciases
 import math n = int(input('Is this integer prime?').rstrip()) m = int(math.sqrt(n)) for x in range(2, m): if n % x == 0: print 'No, ', n, 'is divisible by ', x, break else: print n, 'is a prime number'
... and the default without the max_worker argument is "all the available cpus"
You're quite right! No idea why I thought that wouldn't work - I think I maybe tried it and mistyped it, hence my confusion.
Docstrings aren't comments. A docstrings is more a documentation for an API or an explication helping a colleague in a future refactoring.
well, definitely any optimization can be useful in certain circumstances
I've managed to get the COM set up: import win32com, win32com.client os = import win32com.client.Dispatch("PX32.Openserver.1") However, if I want to access a value within Openserver how would I go about this. In perl I would use run_name = os-&gt;GetValue('GAP.MOD[0].FILENAME') ; Where "'GAP.MOD[0].FILENAME'" is the variable I want to get.
 n = int(input('Is this integer prime?')) for x in range(2, n): if n % x == 0: print 'No, ', n, 'is divisible by ', x, break else: print n, 'is a prime number' one line output :)
RE: what changed -&gt; I have no idea. Hacking on CPython is a little out of my rating on C. If I had to guess, I'd say doing it now would be fairly comparable to the work done previously, but I do know that the GIL was changed in 3.2. That the perf impact is *so* big surprises me a little, but just from lurking around the UnladenSwallow announcements, it sounded like refcounting was one of the big culprits. Since I'm unaware of any serious effort to bring a true garbage collector to CPython (I *think* this is due to problems with C extensions, although it would also lead to unexpected resource leaks since so many Python programs are written with undocumented assumption w/r/t immediate cleanup), I would be surprised if somebody could remove the GIL without unacceptable perf impacts. I agree that the core team would likely approve a GIL-removal patch in the absence of any perf impacts, even if it did hurt the "hackability" factor of the interpreter. I was just pointing out that performance wasn't (to the best of my knowledge) the original reason for adding the GIL, and that the core team would be unlikely to add such a contentious thing just for the performance if the status quo were reversed.
And that is why you use the multiprocessing library in this situation.
top ⇨ press 'f' ⇨ press 'j' ⇨ press 'Enter' = Last used cpu column
From PyPy's perspective what's the 'right' way to do that sort of iterative string building? 
I find it a bit more readable without the redundant parens: if 2 &lt; a &lt;= 8 and 2 &lt; b &lt;= 8: return 2
Ah, I actually did get screwed on that one. I had a routine that expected int/int=int in order to index a vector. When I switched to Python 3, I remember this was actually a problem, but I don't recall how exactly it manifested itself.
Damn, that guide (or reference, or whatever you'd call it) is long but it is very informative. Good job. Bookmarked.
As I assume you worked out - just use int//int instead. This works in recent versions of Python 2 as well.
Spurred on by this thread (no pun intended!) I tried Multiprocessing on pypy. On a dual core machine got a factor of 10 increase using pypy "pool = Pool(processes=2) pool.map" vs python "map", that's fantastic!
Hmmm, I honestly don't remember what I did. If I remember correctly, the code was actually a bit ugly due to the direct use of a divide within the brackets. It was something like "vec[i/ntotal]" and it wasn't particularly explicit or pretty. I think I rewrote the code to be a bit more readable, so I probably resorted to the // operator.
Actually, it's telling you that you need a comedy troupe.
Ah Ok, to be honest I have no idea how to properly use git, I couldn't find any useful documentation on the github website that explains how to use it. All I can find is git bash commands. So, what you're saying is I should upload tarballs of each version and use 'git tag ...' before I commit and push? EDIT: Should I upload .tar.gz files named 'pyks-x.y.z' and then git tag them? I'm really confused now...
Nobody said anything about pet. You need a sneak from the jungle! 
This is true, but you have to do a lot of re-writing of code. You can't just call pyCUDA.run (function name illustrative) on your old code and have it run efficiently.
I have nothing to add, but that this sounds like some of the coolest job duties that I've read in a while. 
But how effectively you use those cores? If the performance 48 times better than 1 core or is only 20 times better or only 5 times better? Have you measured it? 
Have a look at http://wiki.python.org/moin/Python2orPython3 With regards to the first comment on this linked page: &gt; Short version: Python 2.x is the status quo, Python 3.x is the shiny new thing. I'd say that's not entirely true anymore as Python 3 isn't that new anymore and also has already become the status quo in lots of places/projects.
:( I really think with the new ctypes on pypy it would be very fast.
I went through this same dilemma in March of this year. I wanted to begin learning Python, but could not figure out where to start. After hours and hours I research, I decided that ["Learn Python The Hard Way"](http://learnpythonthehardway.org/book/) was going to be the best place to start. Chapter 0 in the book covers setup which includes installation. The author recommends python version 2.x and explains his reasoning. I went with this suggestion and it's only gotten easier to work with over time. Most of the code examples you find out in the wild are 2.x and if they aren't, they are usually clearly noted as 3.x code. I figure that once my understanding of the language is solid enough, I will begin the migration to 3.x. I do have a couple of suggestions to help you in using external libraries if you are working in a 64-bit Windows environment: * Install the 32-bit python -- a fair number of libraries have trouble installing/working in a 64-bit environment. * After you have installed python: Check your registry for **HKLM\SOFTWARE\Python\**, if the key does not exist, look for **HKLM\SOFTWARE\Wow6432Node\Python**, export the key, edit the export file by removing "\Wow6432Node", then re-import. Most libraries that ship with an install package (windows .exe installer) will be looking for **HKLM\SOFTWARE\Python\PythonCore\&lt;version number&gt;**. Good luck! 
I always say use 3 if you can, 2 if you need to. A lot of people come to Python for web programming, which would leave you mostly stuck in 2.x for the time being. There's plenty of other problems to solve though, many of which you can happily do on 3.x. What are your Windows specific problems? (speaking as one of the few Windows-using CPython contributors)
Seconded. Python 2.7 32-bit is the most compatible with current libraries and operating systems while still having almost all the newest features. If you want to use Pypy it's also currently at 2.7. Haven't looked at Jython or Ironpython lately but I'd think neither of those are at 3+ yet.
That's why you always package it with the program, but the post office doesn't take kindly to mailing live animals...
If you're using IDLE to save your files, you need to select "Save as .py..." *and* append the filename in the box with .py. It's *apparently* a feature but for me a big reason why I stopped using it.
I'm using PyQt4 and PyQt4 Designer as I am also GUI-tarded. I highly recommend.
My situation is worse: Youtube is asking me for an old-fashioned american superhero...
Oh my god thank you so much. It makes me want to die seeing that. *It doesn't even make sense!*
I seriously wish I could go to one of these PyConferences.
I enjoyed that video, you completely trashed them. TEAM PYTHON! What did you think of the lady? I saw a lot of tongue biting and sly humoring.
Actually no, you do want this one.
It seems like you just reinforced my point. =\
The problems that I run in to on Windows (but not when using Ubuntu, for example, which I just tried to see if it might be easier) were things like importing my own classes. I have some programming background and had built my own classes for a small python project that I was doing just as a learning experience. Importing them gave all kinds of errors and I eventually had to use **from classname import \*** which I still don't think is the right way to do it. Even then, I got errors depending on which directory things were in and I was having to check/modify sys.path() and... ugh. It just got messy and I gave up. Now I want to start again and maybe try to do things a bit more *right*.
Make a list and then join it together. I wasn't even aware that CPython has a hack to make += fast on strings. I always assumed that this would have bad performance.
IronPython is on [2.7](http://ironpython.codeplex.com/releases/view/54498#DownloadId=216704), and Jython is currently on [2.5](http://www.jython.org/downloads.html) but as of the PyCon 2011 Language Summit they may just skip 2.6 and go to 2.7 (or some hybrid on the way to 3).
That is also true for porting any other code to CUDA as well. Usually you need to rethink your algorithm, and then program a CUDA kernel that implements it in a parallel streaming fashion.
I wouldn't say that descriptive variable names beat comments, it's more like you have to write less comments when you use descriptive variable names. What your example doesn't convey is _why_ you're subtracting scrollbar width from window size, whereas the commented example does. In practice, I've seen more descriptive variable names than good comments. This is good in a sense that I'd rather work with non-commented code with descriptive variable names that with commented code with one letter variables. We can have the best of both though.
came across this yesterday, maybe you will appreciate it: http://conference.scipy.org/scipy2011/slides/lightning/goodman_research_tricks.pdf
Can I use a dead python to run script?
The problems that I run in to on Windows (but not when using Ubuntu, for example, which I just tried to see if it might be easier) were things like importing my own classes. I have some programming background and had built my own classes for a small python project that I was doing just as a learning experience. Importing them gave all kinds of errors and I eventually had to use **from classname import \*** which I still don't think is the right way to do it. Even then, I got errors depending on which directory things were in and I was having to check/modify sys.path() and... ugh. It just got messy and I gave up. Now I want to start again and maybe try to do things a bit more *right*.
Not sure about that Sergey... we could make the Request constructor a little more efficient I think. ;-)
Wow, so I figured it would be quicker but my god (most recent pypy nightly, pypy-c-jit-46430-82bf0efcfe7d-linux): skorgu@monopoly $ python -m timeit -s "a='foo'" "for i in range(10000):a += 'bar'" 1000 loops, best of 3: 1.05 msec per loop skorgu@monopoly $ bin/pypy -m timeit -s "a='foo'" "for i in range(10000):a += 'bar'" 10 loops, best of 3: 1.09 sec per loop skorgu@monopoly $ python -m timeit -s "a='foo'" "t=[a]" "for i in range(10000):t.append('bar')" "b = ''.join(t)" 1000 loops, best of 3: 1.47 msec per loop skorgu@monopoly $ bin/pypy -m timeit -s "a='foo'" "t=[a]" "for i in range(10000):t.append('bar')" "b = ''.join(t)" 1000 loops, best of 3: 633 usec per loop 
[https://github.com/matplotlib/matplotlib-py3](https://github.com/matplotlib/matplotlib-py3)
You think? Codepath for BaseRequest(env) seems quite short and simple. Anyway, let's continue this on IRC.
situacion*
Well let's put it this way. If I had only one core, it would take about 30 min per process, and I have 11 processes, so that is 330 minutes or 5.5 hours. When I use multiple cores, it takes only about 30 min.
It's not dead it's just sleeping.
Thanks..... u stopped using python or IDLE?..... I like using IDLE becuase it's the only interpreter I found that color codes, and a) I like pretty colors, b) its easier to keep track of. Thanks again tho, it worked.
Apologies, yes, I was thinking of Response
Well, it's a matter of....Ah....It's....Hmm I think it's related to compound conditionals, (ie. a &lt; b &lt; c which checks if `b` is between `a` and `c`). In your example, False is between 0 and True. &gt;&gt;&gt; False &lt; True True &gt;&gt;&gt; 0==False True Ergo, `0 == False &lt; True` is also `True` in much the same way as `0 == 0 &lt; 1` is `True` 
False and True are glorified versions of 0 and 1, respectively * Your first statement is essentially: 0 == 0 &lt; 1 (True) * Second: (0 == 0) &lt; 1 which evaluates to True &lt; 1 or 1 &lt; 1 (False) * Third: 0 == (False &lt; True) which evaluates to 0 == True or 0 == 1 (False)
In the face of ambiguity, refuse the temptation to guess. edit: correct the quote
&gt; Your first statement is essentially: 0 == 0 &lt; 1 (True) Why does that evaluate to True?
I don't think I *was* tempted to guess, nor did I fall victim to that temptation... that's why I asked /r/Python for an explanation.
~~It's a single expression, not a pair. Both relational operators evaluate simultaneously against the middle value.~~ It's syntactical sugar for a compound relation. [Section 5.9 Comparison](http://docs.python.org/reference/expressions.html#boolean-operations) "Comparisons can be chained arbitrarily, e.g., x &lt; y &lt;= z is equivalent to x &lt; y and y &lt;= z, except that y is evaluated only once (but in both cases z is not evaluated at all when x &lt; y is found to be false)." Thus... &gt;&gt;&gt; 0==False and False&lt;True True *Edit: I was teh mispoken.*
Since the comparisons are chained it's the same as writing: (0 == 0) and (0 &lt; 1) Since both statements are true the chained comparison is also true
I was going to recommend PyScripter as well, it's one of the best that I found so far (queue Vim lovers).
This is a quote from the pep 20 and you are in the rigth to ask reddit. The question is just about refusing the temptation to guess! afithian gives the good answer. It's just because 0 == 0 equals 1 and because python doesn't have boolean type originally False is 0 and True is 1 &gt;&gt;&gt; True + True 2 and this the same ~~behaviour~~ ambiguity with negative &gt;&gt;&gt; -1 == -1 &lt; 0 True &gt;&gt;&gt; -1 == (-1 &lt; 0) False &gt;&gt;&gt; (-1 == -1) &lt; 0 False &gt;&gt;&gt; -1 == -1 &lt; 1 True &gt;&gt;&gt; -1 == (-1 &lt; 1) False &gt;&gt;&gt; (-1 == -1) &lt; 1 False And more with None ( None is less than anything ) &gt;&gt;&gt; None == None &lt; 1 True &gt;&gt;&gt; None == (None &lt; 1) False &gt;&gt;&gt; (None == None) &lt; 1 False &gt;&gt;&gt; None == None &lt; 0 True &gt;&gt;&gt; (None == None) &lt; 0 False &gt;&gt;&gt; None == (None &lt; 0) False But in real life, comparing boolean and integer is weird. comparing boolean with &lt; and &gt; is weird. and adding boolean is weird too. and "Readability counts."
I believed that -O removed those entirely, not that they were replaced by something else.
What? I don't understand...
there was some related discussion here: http://www.reddit.com/r/Python/comments/ixaaw/ regarding versions and where to start (also lots of resources).
Learn Python 2, seriously. Not even half of the popular libs are ported to python 3, all the ressources you will find are for python 2, all the tutorials, blog post, fix, examples, etc... Python 2 is not going away soon and in the future you may need to touch a project using it. Then when you are a bit confortable with it, learn the difference to python 3, they are not that big and most of things stay conceptually the same.Python 3 was mostly an effort to remove old deprecated stuff no one use and ease the syntax a bit more than to be revolutionary (well that's my opinion anyway) 
The main thing to realize is that *they are not that different*. If you know one, you known 95% of the other. Don't let the "3" fool you, this isn't another language. 3.0 introduced some backwards incompatible changes at the type level (bytes vs unicode), and some other things. This is why it gets treated different, things are just a little off. The change was somewhat more disruptive than going from say 2.4 -&gt; 2.5, but not by much. The community isn't that fractured - everyone's in the same boat. The existing community has a lot of 2.x code, is slowly fixing it up to handle 3.x; most libraries are transitioning to support both. 2.7's going to be around a long time. For now, 2.x is probably the one to learn, since there will be many more examples out there. 
When you are faced with a dilemma of what to use and both options seem equally appealing/unappealing, the choice you make right now will have a 50% chance of being wrong later. Which is another way to say that it doesn't matter. If you are unsure whether to use a hammer or a rubber mallet, then it mostly likely doesn't make a difference for your purpose. As soon as you try to drive a nail with a rubber mallet, you will know what you should be using. Basically, I'm telling you to disregard technical arguments at this point because these arguments are what got you confused in the first place.
Jungle sneaks are the best!
Learn 2.6 (and don't rely on 2.7 features yet). When you want 3.1, you'll know.
Thanks very much! I was mostly poking around the PyQt site rather than Nokia. It seemed like a grey area for me since we are *essentially* using the software for commercial purposes. Thanks a lot for the quick response though.
Tried checking the output of `PyType_Ready(&amp;myType)`? Also, I would encourage you not to write extension modules in C. I've done it. It's a hassle. Use Cython.
thanks for the response. ya, everything is cool as far as the type being ready. thanks for the suggestion of cython, but it is not appropriate for my project.
I should also note, on the python side of things, everything looks fine. It is only from the C side of things that the checks don't pass...
the client would only be able to request the source if they were using the software directly. If they don't interact with the software directly then the (L)GPL doesn't apply to them. The AGPL might place restrictions on this situation, but that's irrelevant. Also importantly, while Qt is available under the LGPL, PyQt4 is GPL/commercial only
I recommend Python 2.7 if you're just starting out. Python 3 does not really have huge differences; you'll be able to learn and remember the differences easily. Lots of things are incompatible with it though, so it'll screw you up. I remember copying and pasting an example program when I was first learning Python, and it kept saying "syntax error at 'print'" (or something along those lines). I was like "how the fuck could I have THAT wrong?" And of course, I was running the Python 3 interpreter yet the code was using print statements.
"I put the snake on the keyboard, but now its just wrapping itself around my arm. Could I speak to your manager quickly? Its urgent."
My C API is a little rusty (and I haven't done any Python 3.x C work), but isn't comparing tp_name just... obj.__class__.__name__ to whatever? what happens when you compare the address of obj-&gt;ob_type to the address of myType? Is it possible somehow two classes have been created?
Ah, I'm using 10.6, and it is indeed OpenCL 1.0 according to for p in platforms: print("Platform: %s" % p.name) for d in clGetDeviceIDs(p): print d.version 
&gt; My C API is a little rusty (and I haven't done any Python 3.x C work), but isn't comparing tp_name just... So I can access the same pointer from both obj-&gt;ob_type-&gt;tp_name and (&amp;myType)-&gt;tp_name / myType.tp_name. They are absolutely the same strings in the same place in memory. Comparing these works, but just feels like the wrong way to do it (though its what is in my code at the moment). What is weird about the address of the type (&amp;myType) is that it seems to be the address that is changing. If i output its' address directly after initialization of the module, it is the same that sticks around in obj-&gt;ob_type. As the program progresses, and I output the address of myType, it does change: PyInit: &amp;myType = 0x2ad6f47955a0 new obj: obj-&gt;ob_type = 0x2ad6f47955a0, &amp;myType = 0x2ad6f4796980 new obj: obj-&gt;ob_type = 0x2ad6f47955a0, &amp;myType = 0x2ad6f4796980 at point i'd like to check the objs: obj-&gt;ob_type = 0x2ad6f47955a0, &amp;myType = 0x2ad6f4796be0
You spelled "my" as "mi", like in Spanish, so I "corrected" the next word to Spanish as well.
But in python 3 int/int=float *float*!
This, but replace 3.1 with 3.2. I usually encounter 2.6 or 2.5 in the wild and the difference is small enough to recommend 2.6. After you've been coding for a few months revisit the changes python 3.x brought about. By that time you'll probably have some idea of the libraries you've grown to attached to to let go and it will be a lot clearer if making the 3.x jump is right for you. Library support is actually getting pretty reasonable, but there are some major projects which haven't yet made the transition. Not knowing what you're planning it's hard to say anything beyond that.
Thank you! And yes, I am Spanish. Unfortunately mistakes like that are frequent when I try to write in English...
&gt; thanks for the suggestion of cython, but it is not appropriate for my project. I find this somewhat difficult to believe, unless you're just doing this to learn Python's C-API or trying to embed Python inside of some application. Even if you've got specialized C code that you need to use, it's best to let Cython generate the actual extension classes and python-side functions for you. Cython generates the C code for you to help avoid tricky situations like this.
No problemo; I actually just assumed it was a typo. Didn't think you'd turn out to be Spanish, ha.
Its hard to help without seeing the functions that you use to print your tests. Since the type is static, its pointer shouldn't change if you always point to the same global pointer. The only thing i could think of is that you create a copy of your type in your new_obj and where you'd like to check the objs. So my question would be this: Do you pass myType to your function, or does it access the global directly? My guess is that you pass the type yourself, and instead of passing a pointer or a reference to it, you copy it.
&gt; it's best to let Cython generate in most situations, you might be right. this is a computational chemical physics package, and the design of the project prevents cython from being an option. python, in this case, is more of a glue that allows one to design experiments and novel methods faster, and receive output in a more organized, direct manner than with existing computational packages that support similar algorithms. 
&gt; So my question would be this: Do you pass myType to your function, or does it access the global directly? I wish I could answer otherwise, but I am accessing the global directly.
Why not just use the python hotshot profiler and scrape the results (from a python string for instance) in your C++ app?
http://pastebin.com/6ak68NLb here are the portions of code that print the tests. whats going on behind the scenes is that a "model" object is created, with input of a PyList that is stored in the model object as "torsions." each torsion contains a parameter object. two torsions, and thus two parameter objects are created, stored, then passed. 
You may wish to consider PySide as an alternative to PyQt. PySide is LGPL licensed, so you would not need to purchase a commercial license. Here is a run-down of the [implications of the LGPL on commercial usage for pyside](http://lists.pyside.org/pipermail/pyside/2010-November/001345.html). Having not worked extensively with either library, I cannot comment on the maturity of either. From what I understand, PySide maintains API compatibility with PyQt, so if you are familiar with PyQt, you won't have any trouble switching to PySide.
Some really bad advice if you ask me. Learn for the future not the past. Not that there is a massive difference between the two series but the future belongs to the 3.x series. To look at it another way, let's say you where asking about C++. Let's also say you where paying to take a class to learn C++. Would you expect to be taught the language in a way that reflects the about to be approved standard or would rather your money went to learning the ten year old version? I specifically used the idea of paying for it above because no matter how you go about educating yourself you are investing in that education. If you look at it that way you will want to get the best deal possible for your investment. For me that means setting yourself up for the future. Plus there is the issue of learning good habits for the new language version and not getting settled into the limitations of the old language. As to Windows - sorry to hear you are stuck with that mess. I can't help you there. As to the community being fractured I don't think that is the case. Libraries are being ported to 3.2 at a pretty good clip. However there is a lot of production code out there that runs on 2.7 or less. I just see it as short sighted to focus on what is quickly becoming the "old" version of Python if you are coming into the community to learn Python. Learn 3.x properly and the old code bases will be easy to pick up. The comparison to C++ above wasn't a casual grab. Modern C++ looks very different from the C++ of a few years ago. If you where to ask about C++ I'd say the same thing, learn the new standard and develop the good habits around that standard. The only difference is that the delta between new and old Python code isn't that great in comparison to C++. 
Was thinking about this the other night, I'm not sure if a business study really matches up with a research project. Google must maximize their costs to profit ratio, while a research project would suggest the goal is more time critical. Just my thoughts, I'm a business systems code monkey so the scientific community is somewhat foreign to me.
 pkill python
Um, I don't think that's an error. I think you're printing the object type of x. Try doing a dir(x) and see if you get anything like read() or readlines(). 
You have to use open("hucket.txt", "r", encoding="utf-8").
No, PyQt is GPL/commercial. It is not LGPL.
I tried that. It just gave the same error, but with encoding='utf-8'
Hmmm...I think you're right. It's not an error, it's just printing the object-type. Jesus, I should have asked Reddit 6 hours ago.
If it's just sleeping, you might want to use SIGCONT instead of terminating the process.
Thanks for introducing me to marakana. Some great material on there.
I looked at Neo4j and other Java-based graph DB stacks and they were all too heavyweight for my needs. Instead I extending Redis to support a simple graph structure. The graphs are saved off to permanent storage as JSON. I use a separate Redis DB for each graph and use the default Redis DB as an index to manage the graphs that currently reside in Redis.
Not sure but, I'll give you a tip that I just learned recently while developing some Python extensions. You can save some lines of code and increase readability (imo) by switching your PyTypeObject definition to something like: static PyTypeObject parameter_cosineType = { PyVarObject_HEAD_INIT(NULL, 0) .tp_name = "chemm.c.parameter_cosine", .tp_basicsize = sizeof(parameter_cosine), .tp_dealloc = (destructor)parameter_cosine_dealloc, .tp_repr = (reprfunc)parameter_cosine_repr, .tp_flags = Py_TPFLAGS_DEFAULT, .tp_doc = "chemm parameter_cosine object", .tp_methods = parameter_cosine_methods, .tp_members = parameter_cosine_members, .tp_init = (initproc)parameter_cosine_init, .tp_new = parameter_cosine_new, }; 
See this: http://eli.thegreenplace.net/2009/05/08/using-gpl-ed-code-for-in-house-software/
Looks pretty similar to [Blatter](https://bitbucket.org/jek/blatter/).
Using C99 features such as designated initializers is unfriendly to Windows developers who use Visual Studio. Please don't lob any tomatoes at me; I use MinGW.
This is one area where threads are a good solution (because you don't want your GUI and the IRC code to mutually block each other). Run your IRC while(1) loop in a thread. You need to add a call to notify the GUI when a socket event occurs which requires a GUI update. You can use wx.CallAfter for this. It's a thread-safe means of calling another GUI function from another thread. E.g. have a function "update_gui" which sets your TextCtrl as appropriate and call this using wx.CallAfter when a IRC data arrives. The final thing you need to add is a means to shut the thread down when you are finished with it.
[Done!](http://get.adobe.com/flashplayer/)
Haha, that's definitely true with this client. Looking at the purchasing program it looks as if you require a licence for every developer (£350) is this true?
Great talk. I enjoy using Fabric. Used it for deploying Django apps to a ton of virtual servers. Also used it to add mon, awstats, and their respective config files to those servers. Abused it in other ways too. ;) Next item: How's you get your shell prompt to look so cool? ;)
I'm surprised you didn't find any good documentation on github, I find this website pretty well documented. For how to properly use git I would then suggest : * http://net.tutsplus.com/tutorials/other/the-perfect-workflow-with-git-github-and-ssh/ * http://www.kernel.org/pub/software/scm/git/docs/everyday.html * http://stackoverflow.com/questions/315911/git-for-beginners-the-definitive-practical-guide Interesting resource can be found on my delicious, login sberder (I won't put the link here as I'm not sure about self promotion rules). You should also read things about SCM, how they work and how to use them. On the tarball thing, I'll try to explain properly ([ELI5](http://www.reddit.com/r/explainlikeimfive/) unfortunately doesn't have an entry for git). There are two things here, your code in git and the tarballs. * Your code is handled by git, it's a very convenient way to keep a record of what happened along time, the modifications you made step by step and why you made them (that's why you HAVE to put a commit message). I will use git if I want to participate in the project and help in the development. * the tarball is just a snapshot you upload on github to provide a convenient way to download your code in a stable version. After your version 1.0.0, if you make modifications and slightly modify the behavior or break it, getting your source from git/github won't be useful. Most of the people will just download the tarball to use your code. A typical work flow would be, code -&gt; commit -&gt; code -&gt; commit -&gt; code -&gt; commit (at this point you're happy with the code and consider it stable) -&gt; tag (STABLE_1.0.0) -&gt; create a tarball of this code and upload it using the big download button on the right of your project page. Your tarball should NEVER be in your git repository, it is just some kind of snapshot of your code at one (stable) point in time. Versioned folders are redundant with what git already does with tags or the upload of tarballs.
If you're looking to get the contents of the file, x.read() gets you the whole string, or you can do "for line in x:" to read it line by line. Or x.read(15) to get a specific number of characters, but that's less common.
Speaking of what changed: here is an [*excellent* thread](http://mail.python.org/pipermail/python-dev/2011-August/112765.html) from python-dev about removing the GIL, including an update from David Beazley regarding his recent work to apply the old patch to modern Python. It also contains confirmation about the refcounting in CPython being a huge obstacle to a GIL-less CPython.
I have [this](https://pythonadventures.wordpress.com/2011/04/24/debugging-in-python/) in my bookmarks and it seems related.
The cross-platform debugger [Winpdb](http://winpdb.org) uses [rpdb2](http://code.google.com/p/winpdb/source/browse/rpdb2.py) (source).
PyQt is more mature.
Does blatter support Jinja2? 
&gt; going on where? with titles like "Stick to WSGI - you don't need a replacement" &gt; proposer of what? of WSGI, who suggested the "replacement" in [question](http://dirtsimple.org/2011/07/wsgi-is-dead-long-live-wsgi-lite.html) &gt;complained about what? where? no sure where you took that one from... &gt; author of what? of the WSGI proposal &gt; what people? let me quote myself: "people who think they know the intent of the proposal better than the person who wrote it" &gt; intent of what proposal? stated in this [article](http://dirtsimple.org/2011/08/is-wsgi-lite-library-or-protocol-and.html) in the "Why A New Protocol?" subsection. &gt; who found useful ways of what? Ian Bicking, author of WebOb who realized after, i quote "after reading the WSGI Lite docs that WebOb contained a latent bug I described there!" &gt; who says nothing is wrong with what? those who write title like "Stick to WSGI - you don't need a replacement" pheww, I hope i won't have to do this everyday.
Looking at the code everything is in one file https://bitbucket.org/jek/blatter/src/f8a01161a8af/blatter/__init__.py 
well it's not just about "knowing it". it's also about getting modules to run on a Windows 7 64bit for example. this is where different versions really hit you...
i feel the pain. i endure it everyday. here's a temporary fix: http://www.lfd.uci.edu/~gohlke/pythonlibs/ last time i tried to find PyCrypto 2.7 64bit, which this website does not have. i gave up after trying for a while...
I tend to agree with this but PySide is quickly catching up. My apps originally targeted Maemo 4.1/5 (originally PyQt but now also PySide) but now I'm adding MeeGo / Harmattan support (PySide only). I've made my apps function with either binding (there are some source breakers) and even after PySide went 1.0.0 there were several showstoppers for me. On the other hand they were quick to fix mine (filed in 1.0.4, fixed in 1.0.5) and since then I haven't spotted a difference in how my apps run between the two bindings. For a rundown of the differences, here is my compat code https://github.com/epage/ejpi/blob/master/ejpi/util/qt_compat.py And an example usage https://github.com/epage/ejpi/blob/master/ejpi/util/qui_utils.py
thanks for providing sources. will have a look. (really nice coding style)
Came in to say 'make sure you use api 2 in pyqt' Being able to switch between pyqt and pyside has been invaluable at shaking out bugs in my terrible code
Since Python co-exists nicely with itself, why do you consider this an either/or situation? Just install ActivePython 2.7 and 3.2 and use whichever is appropriate at the time. There are 2 things that will blow up in your face with 3.2, 'print' is a function not a statement now so what you want to print must be wrapped in parenthesis first, i.e. print "foo" print("foo") and strings now default to Unicode encoding instead of bytes, which will break compatibility with interfaces expecting bytes (e.g. most network calls) - this is probably why the popular web frameworks are still stuck in 2.x land There's a 2to3 program included with Python 3.2 that will convert most 2.x code to run fine in Python 3. Everything else new in Python 3 is either backported to current 2.7 (set &amp; dict comprehensions, etc) or is business-as-usual stdlib module improvements. If you want to be cool with your code, you can from __future__ import print_function to get the 3.x 'print' in Python 2.6 or above, its seriously the #1 thing that will drive you bonkers if you have both Python interpreters - just do 'print' the 3.x way (it is the future, after all) no matter which you use. 
And/or: for line in x: print line
nice, that is much more readable. thanks!
Congratulations on writing a book, from the reviews people seem to like it.
problema*
I don't have any direct experience with 'em but cx_oracle's used as the default Oracle API in [SQLAlchemy](http://www.sqlalchemy.org/docs/core/engines.html#supported-databases) so I'd imagine you're ok. You might want to just go ahead and use SQLAlchemy itself if you can.
Well shit, if it's in Django then that's a pretty high level of support. Thanks!
From that link it looks like SQLAlchemy doesn't support oracle, but I think I may be confused because it says it supports cx_Oracle. What exactly is SQLAlchemy, and why should I use it instead of cx_Oracle?
As the guys who came up with this nonsense already said (though nobody seems to listen): Design patterns are not universal, they are language specific. So don't go around trying to apply the same design patterns to languages which don't need them. Half the design patterns for Java are about circumventing the statically typed nature of the language. Python is dynamically typed. A lot of them are about visibility of attributes. Python attributes don't have that. A lot of them create classes to wrap functions. Python has first-order functions, so you often won't need those classes. It's far more useful to learn the idioms of Python and start from there. The common Design Patterns are mostly irrelevant because there's usually a better way to do it by following common idioms. Design Patterns are to Java and C# what idioms are to Python (and Ruby, and ...).
Used cx_Oracle two years ago. Don't remember any problems with it.
Alex Martelli does it right. http://www.lecturefox.com/blog/python-design-patterns-by-alex-martelli the above link is crap. :)
[chaburrod's answer](http://www.reddit.com/r/Python/comments/jgsrp/question_about_python_and_oracle/c2bz2eh) is spot on. Instead of writing an interface to a specific database like Oracle, you write to SQLAlchemy and it takes care of the low end stuff for you. That way if you ever want to switch databases or something you don't end up rewriting much of anything. It's also great for testing since you can write your code using e.g. a local SQLite file and when you're done swap it out for the Oracle database. You might also check out [Elixir](http://elixir.ematia.de/trac/wiki), which I find can greatly simplify working with SQLAlchemy. Elixir lets you think in terms of Python classes instead of data and databases.
It's only 400 lines. That doesn't seem unreasonable at all.
Yep.
SQLAlchemy contains an ORM. SQLAlchemy is not an ORM.
The installation was straight forward on windows. I then launched it and created a quick hello world app but could not get it to run :/ I also cannot collapse the code and there is something strange happening with the editor where my text disappear until I highlight it again.
Thanks for clarifying this as the ORM stuff had me concerned. The application I'm working with lives in the oracle database and the python utility I'm writing will really just be a way for a few non-techies in my office to load data without having to learn any SQL or sqlldr. I just need a straightforward way to write an insert statement using user-defined values, and then load data from a csv into a table.
Interesting, what is the relationship with web2py (i.e, does it offer some sort of integration with web2py)? I believe web2py has a built-in web-based IDE, is this a desktop alternative? 
So why should I get this over WingIDE, Komodo, Eclipse+PyDev, PyCharm?
It's surely more lightweight than Eclipse+PyDev, and Free/Open Source compared to PyCharm, Komodo or WingIDE. Yes, it's not as mature as those, but come on, project was created few months ago.
I'm just pointing that there are already many IDEs out there. Probably a few more free/open source ones that I don't know. Personally I don't use an IDE for Python, I do it in geany (+terminals) which I wouldn't call an IDE.
http://www.sqlalchemy.org/docs/core/tutorial.html#insert-expressions http://www.reddit.com/r/Python/comments/j8ydc/pythonmysqldb_question/c2a65ai http://www.reddit.com/r/Python/comments/iupwe/sqlalchemy_and_you/c26sqtr
I love and work on web2py everyday. The web "IDE" is a little bit of a stretch. It is handy sometimes I use it to change database URI's and I do use it to start projects and then use a shell and git to manage the code. For web2py dev I use Kate editor with VI bindings and ipdb for debugging. My favorite python IDE is eric but it did not feel right with web2py projects. I use eric for pyqt projects, it works great. I thought about modifying eric to work better with web2py like moving the project to the applications level of web2py and catching the tickets in the ide's console like wing. There is a test in web2py if wing ide don't use ticket. But I have been to busy and ipdb on the console works great.
Same, and occasionally komodo.... I think it's more efficient to use a lightweight IDE but everyone has their own def of lightweight lolz 
I thought about doing something similar but then I found the Reddit toolbar and the option to have all links target a new window.
Agreed but there are design patterns that are useful in Python, even if perhaps implemented differently than the corresponding Java version. The link is also useful in demonstrating how some patterns are nothing special in Python (e.g. modules are singletons); though it seems a little dated when i skimmed it (getter methods?).
I think the only relation is that the rad2py developer is one of the top web2py contributors so he wants to make sure this works well it. Otherwise this is a general purpose IDE for Python.
use robert kern's line_profiler. this way its easy to tell how long a certain call took. works wonders if you're profiling numpy/scipy code as well 
Looks like an interesting project -- but doesn't OpenCV do all this stuff already?
I hadn't come across eric before, looks good so will try it out.
... and the GIL makes C-extensions easier to write, because of CPython's design decision to use reference-counting (NB: reference-counting does not imply an inability to detect reference cycles - CPython detects reference cycles). CPython's reference-counting + cycle detection trades predictability (especially predictable latency and predictable resource release) for high throughput - increase the throughput using one of the excellent garbage collection systems available, you will lose this predictability. And the GIL lets all CPython versions make good use of commonly found OS C thread libraries. If you cannot work with the GIL, use Jython. Java's outstanding threading support and robust and efficient thread-safe memory model let Jython work famously if the GIL is a actual barrier to implementing your program (you lose single thread performance, but nothing is free). 
 (datetime.datetime.now() - datetime.timedelta(days=30)).strftime('%s') The datetime module is generally superior than doing arithmetic with seconds. Did you know there can be leap seconds? Your calculation could be off by one second. Also, what the hell is 2592000? I only know what it is because you explained it. If I read that code I'd have to figure it out on my own, which sucks. In instances like this it's much clearer to write `60*60*24*30`, or shove it off into a named variable like `seconds_in_30_days`. Then it's obvious what 2592000 means.
Extra second won't kill me since I'm working with data at a level in minutes. Basically I'm creating rrd files, and setting the start date 30 days in the past, filling it in with historic info going back 28 days, so I can create some historic stuff on the fly. But thanks for the info. When I go back over it, I'll probably convert the constants over into variables. But for my peace of mind, I work better with whole numbers. I'm very good at in-head math, so the numbers just make sense to me at the moment.
Yeah, I don't think either of the points I made are highly important for what you're doing, but they're good habits! Date arithmetic is complicated in many highly annoying ways. It's generally less error-prone to let libraries handle the arithmetic. The dateutil and pytz packages are also really excellent for when datetime falls short.
Any examples?
It's comparing apples and oranges..
No, he's trying to tell you that they do different things
[Online demo linked from the page](http://wyvern.cs.uni-duesseldorf.de:5000/)
If you had said "and" instead of "but", I think it would have communicated what you meant better.. with that "but" there, it sounds more like you will go with PyPy instead of Pyramid, hence my reply.. I use two dots to separate sentences.. they are not intended as ellipses or used in place of them..
So what, he could have said: "I was going to write this project in Springs, but I decided to go with PHP." I bet you'd not see a bunch of downvoting pricks jumping on him then. 
mackstann's method is most readable way to get a date in past. time.time() actually returns float not str.
Thanks, I must have missed that.
I've been thinking about using Firefox, but I decided to get a Mac instead.
I'd love to see an easy or officially supported way of getting psycopg to work on PyPy!
ide2py is not only a general purpose IDE. It embeds a web2py server so the scripts can be easily debugged. Also, it now has basic introspection (autocomplete, calltips) on web2py globals (i.e. db, auth objects, helpers, etc.) out-of-the box In the future it will have more web2py related features (more introspection on web2py models, syntax highlighting of web2py views, etc.)
Alex Gaynor has a psycopg2compatibility pypy branch that fully implemented a psycopg2 compatible module in RPython -- IIRC it even passed most if not all of the SQLAlchemy tests. However he's aiming to kill it in favor a ctypes version (like his MySQL-ctypes) as PyPy can likely speedup a pure Python+ctypes version to be fast enough.
Yes, there are already many IDEs, but I need one I could easily adapt ( ide2py is part of my degree thesis project). IMHO the other IDEs were too complex and/or don't have all the features (i.e., many lack an integrated debugger), and IDLE is not complete nor very appealing ide2py is a fully-featured IDE like VisualBasic and has a very concrete implementation, each feature (editor, debugger, etc.) is a short file so it is easily adaptable In that way I think it keep the essence of web2py: compact, feature-full, integrated, etc. 
So I guess Joel Spolsky was trolling when he said that you can't run such a platform on an opensource stack. Though I'm not sure how quora compares to stack overflow.
For the record, psycopg2compatibility was my branch, which included 95+% of improvements to CPyExt required to have psycopg run on PyPy. What Alex did was create a module in RPython, it lives in a fork of PyPy on bitbucket. I recently closed psycopg2compatibility to avoid this confusion (All useful changes were merged into trunk a while ago)
I'm sure it's possible he said that, but it sounds uncharacteristic of him - do you have a link by any chance? I'd like to see the context. 
Yeah, they have some good stuff there :)
his google talk, iirc http://www.youtube.com/watch?v=NWHfY_lvKIQ 
A bit of a tangent but does anyone here actually use Quora? I've fiddled around with it - it didn't do much for me.
Wow, your timing is amazing! I was just about to edit my comment to add this article, which seems to match up with what you've said as well: http://www.joelonsoftware.com/items/2006/09/01.html Thank you for the youtube link!
Sad to hear that, there are some reports about wxPython problems, look at the issues page at the project site, if you don't find any clue please fill an issue and I'll happy to help you. Although I've put a lot of effort in compatibility (unicode, line endings, python versions, etc.), the project is very young and there are many combinations of platforms and libraries out of there, I expect that in a couple of month the project will be stabilized
It's pining for the fjords. 
And when [doctest](http://docs.python.org/library/doctest.html) runs successfully, you know your functions, classes, and modules are good to go. 
BTW, web2py support is just a mixin (like mercurial support), ide2py can support any other add-on/extension for other frameworks and tools. But the fact is that web2py has some unique features (like exec and its concise global namespace) that makes things easier at this stage of development of the project.
So what is PyPy these days? I thought it was originally a Python implementation written in Python, but the site doesn't seem to hint at that at all anymore (aside from the logo).
In English, we say problemo. _Problema_ is Spanish.
I use cx_Oracle at work and have had no issues! They've been using it for a while before I showed up, too.
I agree with you but would add, "Don't be lazy." If you have any success whatsoever in your Python learning, you will become able to program in both 2 and 3. The only reason you would need to pick "which one" to learn is if you plan on quitting after a month or something. Any good Python programmer should be able to take code and port it from 2 to 3 or 3 to 2 with relative ease, because there are only a few big differences: a print function instead of print statement, different names for `unicode` and `bytes`, and the ability to specify the encoding when using a file object. Beyond that, none of the differences are very substantial.
Good to know, I didn't realize this!
The first sentence on the home page sums it up quite well: &gt; PyPy is a fast, compliant alternative implementation of the Python language (2.7.1). Much of it is implemented in a Python-like language called RPython, but unless you're a PyPy developer this is merely an interesting implementation detail.
Good read. Sounds like the original implementer had some good ideas, but ultimately the refcounting is the big issue in terms of speed.
This is a great article, and very accurate.
That's a good pdb cheatsheet.
Woohoo! Just the other day I defined and used a metaclass! I was coding up a Rock Paper Scissors exercise I ran across in which defining the game rules involved creating tuples of the Rock, Paper, and Scissors classes themselves. Okay, but the tuples of classes are so ugly in `pydoc` and the interpreter: &gt;&gt;&gt; class Rock(object): pass &gt;&gt;&gt; class Paper(object): pass &gt;&gt;&gt; class Scissors(object): pass &gt;&gt;&gt; {(Rock, Rock): DRAW, (Rock, Paper): LOSE, ... } {(&lt;class '__main__.Rock'&gt;, &lt;class '__main__.Rock'&gt;): Outcome('draw'), (&lt;class '__main__.Rock'&gt;, &lt;class '__main__.Paper'&gt;): Outcome('lose'), ... } And even `pprint` can't help in this case. I really would prefer to see &gt;&gt;&gt; {(Rock, Rock): DRAW, (Rock, Paper): LOSE, ... } {(Rock, Rock): Outcome('draw'), (Rock, Paper): Outcome('lose'), ... } Not only is this easier on the eye, but it can be `eval`-ed back to what it is, as is rather customary with `repr` (and `pprint`) results. I got to thinking classes must have their own `__repr__` methods which have nothing to do with conventional instance `__repr__`. Then it hit me: A normal class is an instance of `type`, so all I need to do is subclass `type` for the behavior I want and "instantiate" it. Metaclass to the rescue: &gt;&gt;&gt; class CleanTypeReprMeta(type): ... def __repr__(self): return self.__name__ &gt;&gt;&gt; class Rock: __metaclass__ = CleanTypeReprMeta &gt;&gt;&gt; class Paper: __metaclass__ = CleanTypeReprMeta &gt;&gt;&gt; class Scissors: __metaclass__ = CleanTypeReprMeta &gt;&gt;&gt; {(Rock, Rock): DRAW, (Rock, Paper): LOSE, ... } {(Rock, Rock): Outcome('draw'), (Rock, Paper): Outcome('lose'), ... } And happily as expected, the repr of a CleanTypeReprMeta instance has nothing to do with the repr of a Rock instance: &gt;&gt;&gt; Rock() &lt;__main__.Rock object at 0x8a9b84c&gt; The upshot is, metaclasses are not just for `__new__` black magic and defining classes on the fly. 
Quora may not yet be as advanced as the Stack Exchange platform, but at least you don't get half of your questions closed or deleted without notice for not respecting the numerous arbitrary "rules". Oh, and they also understand there's no reason to create a different "site" for every little niche topic, tags are fine for that purpose.
&lt;sing&gt;I'm a hacker and I'm okay. I hack all night and I sleep all day.&lt;/sing&gt; 
I just started using it, and I got good quality answers. I think it depends on the topic of your question.
schmichael's answer was correct but I just wanted to add the first line from [wikipedia's definition of pypy](http://en.wikipedia.org/wiki/PyPy): &gt;PyPy is a Python interpreter and JIT compiler So pypy can take python code and turn it into x86 instead of executing the bytecode in a VM, that's where the real speed kick comes from.
Which one do you use? Bookmarklet, button, Firefox add-on?
http://www.reddit.com/prefs/ - display links with a reddit toolbar &amp; open links in a new window Though I have been progressively phasing out the stock toolbar for the Chrome reddit extension
For those wanting to jump to his comment in the video go to 24:55 begins talking about his stack 26:00 compares MS products to open source
It should be very easy to install, even on a mac. If you have root try easy_install numpy If you don't easy_install numpy --user It is defiantly not a deal breaker to install on other platforms. 
In my research group we have recently started replacing old experiment control programs with Python scripts. We're using the [Enthought Python Distribution](http://www.enthought.com/products/epd.php) on a couple of Windows and Mac machines. Installing EPD is about as simple as it gets, and NumPy is included. Our NumPy scripts just worked from day one on both architectures, so we had no portability issues. About installing NumPy on a stock Python, I have no experience with that except on a couple of Debian machines where it's just a matter of pulling the right packages from the repositories.
Thanks -- I also tried EPD, which is as simple as it gets..., as you say, except that easy_install points to their proprietary repository (requires password) rather than the usual Python one, so installation of additional packages became difficult. This made me go back and install NumPy and SciPy on the stock (actually Mac 2.6) Python.
Hm, I think there were conflicts with other packages so the easy_install and also the MacPorts options definitely failed and I had to install from source, and even with this I had to change some configuration parameters...
I develop scientific gui-based apps using linux for deployment on Windows (XP and Win7) with no problems. I've no experience with Macs but both ActivePython and Enthought Python Distribution supports Macs. I was very impressed with the ActiveState Python Package Manager (it's a bit like easy_install but for pre-built binary packages). While EPD contains everything you might need but at a base cost of US$200 per seat (free for academic users though). ActivePython has a free "community edition"; it is a bit less heavy-weight than EPD but both scipy and numpy are available (in fact, the only scientific library I didn't find available from either repos was PyTables).
Yes it can be a pain, especially considering 64bit alternatives. I recently ran into issues with my standard NumPy / SciPy / Matplotlib setup after "upgrading" to Lion. Of course extensive googling around never really helped, after fixing one problem there was always some new interesting issue to hunt down the solution for. Interestingly enough, a lot of people are very keen on blogging about installing from source, but very few simply just share binaries. Until I found this [gem](http://stronginference.com/scipy-superpack/). It's a super easy sh script that automatically handles the installation of 64bit versions of NumPy / SciPy / Matplotlib / iPython for you. Some guy shares his binaries from what seems to be his dropbox account.
Huh. Can't say I noticed that... Mine points to pypi. But I'm using the Free license version, maybe it's set up differently?
I've used the commands library with no problems in a variety of programs, however if you are just using it for "ls -l" it is probably better to use the native python commands to get file information. By using getstatusoutput you are spawning another shell process needlessly just to get information about the file system which is going to be slow in comparison to the python libraries and doesn't need parsing of the ls command output.
http://docs.python.org/library/subprocess.html#subprocess.check_output
Yeah, I'm aware that "ls -l" isn't an example where you'd actually want to use this. I just wrote it as the example because that is what the Google example was.
I have used a module called pexpect for this. it returns the output and errors in a string. An example might be: info = pexpect.run('/usr/local/bin/ffmpeg -i /path/to/vid') http://www.noah.org/wiki/pexpect
I've used cx_Oracle for my previous job and it's works just fine. I've not heard of the other one.
Just at the beginning of the [subprocess module documenation](http://docs.python.org/library/subprocess.html) it tells you that it was designed to replace, among other things, `os.popen*` and `commands.*`. In the above mentioned documentation, you may want to look at the first example, the one about replacing the backquote operation.
I usually do something like this: import subprocess import shlex cmd = 'ls -al' args = shlex.split(cmd) p = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.STDOUT) result = p.communicate()[0] 
just do: easy_install --prefix=$HOME &lt;PACKAGE&gt; This is after making the directories: mkdir $HOME/lib mkdir $HOME/lib/python2.7 mkdir $HOME/lib/python2.7/site-packages and put: export PYTHONPATH=$HOME/lib/site-packages/python2.7 in your .bash_profile This whole business made it much easier for me with EPD and paths. It even replaces a lot of the messing around with virturalenv etc. which I used to do for personal projects since you have much more control over your path.
That's the joke :)
Okay, here's what I would try: Remove the static in the declaration of your static PyTypeObject parameter_cosineType. The static in the definition of a global variable will kinda make it so that all the different C files need to instanciate their own... I think. Meaning if you were to include that .h file in many .c, you end up with multiple version of that type and each file would have its own pointer when refering to the global. You will need to move your creation of the structure for your type to a .c file somewhere, and your include should instead just contain a "extern PyTypeObject parameter_cosineType" Note: I never made my own type in C-API...
Well, kind of. It still runs Python code in a VM, but when it spots a section that's run a lot with similar variables (e.g. some mathematical steps that always use integers), it can compile that and speed up the loop massively. There's no neat way to translate a dynamic language like Python to pure, fast compiled code.
I use cx_Oracle, and my perception is that it is the "default" Oracle lib (i.e. the most well-known). Never heard of DCOracle2. with cx_Oracle, the author Anthony Tuininga responds quickly and directly to questions and issues on mail list. You can't beat that support ! .#3: here is an option that does not require having to install cx_Oracle : http://code.google.com/p/pysqlplus/ its a wrapper that calls sqlplus. I use it on server (w/ Oracle client) where I'm just normal user and can't install anything.
Just INSERTs ? you don't need to query DB and read back and do logic things at **run-time** ? Then maybe your needs can be met by just dumping all the statements into a file and call SqlPlus (KISS) ? 
Interesting. So how do you distribute your programs? Do you tell your users to download EPD or AP, or do you guide them through downloading the required packages? The latter is currently what I am doing, and even the programs I have written are only used by a couple of people for now, it feels like unnecessary and sometimes complicated steps for using a program. How do you feel about compatibility between python distributions? I feel like Python could steal some ideas from LaTeX here (MikTex), which which has a built-in function which will notify the user of missing packages upon execution and offer to download/install them from the repository. It works really well and saves a lot of hassle, especially for users less experienced with python and setting up.
My experience is limited to GNU/Linux and Windows, but I've had great success running the code on both platforms. I developed a computational program on Windows with NumPy+SciPy, and I copied the code to my Linux laptop verbatim. It runs on both seamlessly. It even made relatively heavy use of the *multiprocessing* module.
 import commands commands.getoutput('echo pies') Will do what you want. 
So you dont have any C extention modules? Hatd to believe. Or you probably launch CPython as external process or on different url when you need it.
I hadn't tried shlex yet - thanks for the suggestion. BTW, I've just started moving over my os.popen code to subprocess.popen - and I'm completely dismayed by the additional complexity. The python philosophy of making things explicit is definitely tested here - in which simply capturing output of a shell command requires far, far too much research. 
actually I need the PK produced by one of the inserts, but in any event I don't really know how to call sqlplus from within python. I mention this in my post: &gt; 3. On the off-chance that there aren't any good libraries for this (which I doubt) are there any best practices I should know about for calling sqllplus and sqlldr into my script?
 &gt;&gt;&gt; x = pexpect.run('ls -') &gt;&gt;&gt; x '/bin/ls: cannot access -: No such file or directory\r\n' &gt;&gt;&gt; Cool.
I know this isn't a real response to your question (xeeton provides it) this is one place where perl shines over python. In perl its $variable = \`shell command\`; :D I love python, just like to find places where perl shines since it seems like perl gets a bad rep nowadays.
Very interesting. We are stuck with gil then. No problem. I use multiprocesing anyway.
&gt; don't really know how to call sqlplus huh ? Sqlplus is cmd line tool so calling it is just a shell command thing, [someone just asked about shell command](http://www.reddit.com/r/Python/comments/jhmcu/whats_the_best_way_to_extract_the_standard_output/)
I was able to install packages using "enpkg &lt;packagename&gt;" using both EPD Free and EPD Academic.
I've actually already built this utility in shell, but i'm trying to make it available to very non-technical members of my staff. I don't want them having to learn any command line jazz, and moreover they're all windows users so I don't want to have to deal with cygwin on their computers. If I can do this in a python script, I can just put the script on their desktop and all they'll need to do is drag-and-drop the files onto the script. The KISS needs to be from the perspective of their usage, not my coding.
For the sake of completeness, there's an assumption in your question that you don't address explicitly: are you sure you need to invoke the shell command from within the script? Does your usage scenario allow you to just use shell pipes on the command line, like this: ls -la | myprocessor.py I use this approach frequently for simple projects.
now I'm confused wtf exactly you're *really* trying to do.
RPython is a subset of Python.
An editor like [XMLSpy](http://www.altova.com/xml-editor/) allows rapid XML data entry based on XML schemas given. I don't see anything in your requirements that indicates anything beyond using the filesystem normally to store files.
That's an interesting solution, and it certainly fits the criteria I specified, but I neglected to state that I'm running in a Linux shop, and XMLSpy is Windows-based. 
Brilliant series. Nice introduction to python for me. 
Alright that's fair. I just know in the past they made a big deal out of it being a python interpreter written in python, and it was clear that they weren't really using that angle anymore. Personally, I just like the idea of self-hosted languages and how cool that is :)
Alright, thanks. I was aware of the JIT but didn't know if that was all it was these days.
Really? Where are you having issues? I skipped over os.popen and went straight to subprocess.popen and didn't have too much troubles.
I used it too, but strangely when i launch a script in textmate, the packages are missing... don't know why!
I have actually spent an obscene amount of time writing three programs that happen to require what you are looking for, in some form. First, there was the problem of needing to 1) Build a command that runs a Robot Framework script in a thread, and redirects the output to a wx.TextCtrl. This ended up looking something like this - import subprocess import threading import sys import wx class RedirectText(): ''' Takes a wx.TextCtrl and can be used to redirect output. ''' def __init__(self, outbox): self.out = outbox def write(self, text): # Use CallAfter, as the box is not threadsafe. wx.CallAfter(self.out.AppendText, text) #Optionally scroll to bottom class RFWrapper(): def __init__(self): self.MakeGui() # Not shown for concision self._redirector = RedirectText(self.consolebox) # This should actually be saved rather than relying on sys.__stdout__ etc, but we don't bother sys.stdout = self._redirector sys.stderr = self._redirector # Create the thread and set daemon self._RFThread = threading.Thread(target = self._RFThread) self._RFThread.daemon = True def StartScripts() self._RFThread.start() def RunRF(): # Here is where the good stuff is located # Generate args (Simplified...) args = ['pybot', self._variables, self._etc] # Start the process process = subprocess.popen(args, stdout = subprocess.PIPE, stdin = subprocess.PIPE) # TWO OPTIONS!!! # First, read by LINES (will block in RF coincidentally because it stops 2/3 of the line through to wait for Pass or Fail, so you can't know what test it is on) for line in iter(process.stdout.readline, ""): # The above basically says, for every line that we can read, until if it returns empty string (EOF) # Print uses sys.stdout's write message (flush too, so implement and pass that if it complains) print line, # SECOND OPTION! (Don't use both!) # This streams output while the process is active. # Optionially, I think you can use fnctrl to set the file to 'nonblocking' which means it won't wait for however many bytes of data before returning while not process.returncode: process.poll() # read() blocks, read(1) doesn't but it is slow, read(20ish) seems to work fine but make sure that it is not too big or you will still clip parts of the message if it ever stops) sys.stdout.write(process.stdout.read(20)) Second, there was a program called dbus-monitor which connected to a remote target with an IP environment variable. This used the same method, but the outputs were more consistent(always a line ending) so it didn't require the read() character based streaming. Lastly, there was a wrapper for 'adb' that controlled Android phones to make, receive (but not end...) calls. This used your first method (with communicate()[0]). There is ALSO a way to use 'select' to check for file input, but frankly, I find that the above method works fine. There is also also a module called pexpect, but I haven't used it. Sorry. 
[This](http://jessenoller.com/2009/02/02/an-interview-with-adam-olsen-author-of-safe-threading-completely-different/) is also a good read in this context.
I hear PyPy does ctypes well. There's [execnet](http://codespeak.net/execnet/) (from, I believe, some of the people behind PyPy) that makes it easy to do what you suggest in your last sentence. I don't find it that unbelievable though that they're not using (m)any CPyExts.
so this is written in Python and runs on wxPython ?
R is this way too (has an excellent package manager). I've been writing things mostly in R and installation + downloading packages has never been a problem for non-programmers.
Hm, I was using the Academic version (I and my users are academics) and yet it seemed not the case... this was with Version 2.4 though, maybe things have changed...
Interesting -- I was unaware of this. Looks clean...
Hm, the password required was not on my local machine (which would require sudo password otherwise) but for their repository... but this is also good to keep in mind. Thanx.
Ha. You've hit upon the one big weakness in the python ecosystem. Deploying applications is a pain. Asking users to install EPD or other distribution is not ideal. Breaking compatibility with existing python installs can be a real problem. You can easily get into Version Incompatibility Hell. Right now, my preferred solution is to make my own python distribution (on Windows, anyway). This turns out to be quite simple. I use a development system installed from binaries with BSD-like licenses. For a few packages I've built my own binaries. I do *not* use EPD or other binary python distributions because these invariably have license restrictions on the re-distribution of the binary components. Once I have all the libraries I need installed and tested, I create a binary installer using InnoSetup which takes nearly everything under C:\Python27 and pulls it into the installer. Along the way, I filter out documentation, pyc and pyo files and any libraries I know I don't need (e.g. Tkinter). The installer is configured to install these files under a new location under C:\Program Files (e.g. C:\Program Files\MyPythonRuntime) . A post-install script runs the python bytecode compiler over all the installed files to recreate the pyc files. Python scripts can be run using this custom python environment by setting a few environmental variables (typically set in a batch file used to launch my python apps). For *my* code (as opposed to the 3rd-party libraries I use), I deploy as a python egg. This is also placed under C:\Program Files (i.e. not installed in a site-wide site=packages location). These is also a launch script adjacent to the egg to form the entry point into the application. Finally, the batch file which the user runs simple calls the custom python environment python exe with the launch .py file as its argument. Thus, from my users/customers point of view, they need to install the runtime (~90MB installer, but which gets ungraded rarely) and the application code (which is a much smaller package ~&lt;3MB and may get undated frequently). They may never realise that the application is written in python. I've tried things like py2exe, PyInstaller, cxFreeze, bbFreeze. These are OK for simple apps but tend to be hard to use successfully if you use as many 3rd party libraries as I do (Enthough Tool Suite being a particular pain to packages using these tools). Things like virtual-env or zc-buildout are not a solution for desktop apps. Finally, if you're using linux, things are trivially simple; just install using the package manager.
Yes, both are very easy to install on the Mac now. I used to use the EPD, but now both SciPy and NumPy provide dmgs with installers that I have never had a problem with in the last 2 years.
Just beware that shlex doesn't support unicode.
[lxml](http://lxml.de/) seems to be the go-to library for complex XML wrangling (more complex than simple parsing and generation) so my personal approach would be to use that in conjunction with [bottle](http://bottlepy.org/docs/dev/) or [flask](http://flask.pocoo.org/) for the UI. Bottle is the one I'm more familiar with, but flask might have more in the way of form handling, I'm not sure. Again, just my personal approach, and not something I've already tried.
Thanks, great answer! I'll keep this in mind for the future :)
This is actually a temporary work around while we're developing the functionality into our existing front-end 
Very cool. How can I help? /newb
Yeah, I found it too complicated too, so I made my own convenience module: from subprocess import Popen, PIPE class ReturnedError(Exception): pass def run(command, input="", binaryout=False, encoding="UTF-8", stdin=PIPE, stdout=PIPE, stderr=PIPE): """Returns result of running 'command'. 'command' can be string (will be split) or a list.""" #Deal with unicode #If you want some other encoding, send us bytes. if isinstance(input, unicode): input = input.encode(encoding) #Subprocess wants a list of commands if hasattr(command, "split"): command = command.split() process = Popen(command, stdin=stdin, stdout=stdout, stderr=stderr) output, err = process.communicate(input) if not binaryout: output = output.decode(encoding) #Raise errors, but make the output salvagable if err: e = ReturnedError(err) e.output = output raise e return output Usage: &gt;&gt;&gt; print run("ls -l") total 80 drwxr-xr-x 3 ebk ebk 102 Aug 6 23:37 Applications 
That's good and bad though, because it makes the code less portable and whatnot if people just use the backticks all the time instead of using a proper Perl command. Anyhow, I have my system set up so you'd just do `variable = run("shell command")` anyway, so it's not as though the advantage Perl has is insurmountable. ;-)
In my convenience function, it returns output in a string but raises errors as a custom error class object with the error message attached to it. I can see the advantage of both approaches though.
Yes, the IDE is written in python and uses the wxPython toolkit (SPE, DrPython, Picalo and Boa uses it too), but this project is based on wxPython own demos of "modern" features like the AGW AUI (Advanced User Interface), with a snazzy &amp; customizable look and feel, perspectives, docking, etc.
I hate "Is there a better way to do this" type questions, since I have no idea what you are asking till I open the post :|.
cool ! I may look into the code and learn a thing or two about GUI programming
Anyone can help testing, mostly in different platforms Comments, reviews and suggestions are welcome too, and documentation is always necessary and it should be easy to write. Right now I have a tight deadline to add core features as I have to present and defend this research at my University, so I can not spend much time on third-party's features, but I will do my best to fix bugs and answer issues. Of course, if there are other contributors and developers interested, I'll be glad to give them the proper access to the project ;-)
Looks like a very nice intro! I noticed a couple places where more idiomatic python could be used. For example this: my_mesons = [ (x['name'],x['mass']) for \ x in particles if x['mass'] &lt;= 1000.0 and x['mass'] &gt;= 100.0] is better written as : my_mesons = [ (x['name'],x['mass']) for x in particles if 100 &lt;= x['mass'] &lt;= 1000.0]
I haven't had to do this in a while, I'm just remembering how crazy it was using all the different popen* variants. It did seem needlessly complex, especially for Python.
Awesome! Yeah, lots of libraries have convoluted APIs. Upvote on principle.
wish there were something like this near me when I first started and was looking for classes (and found none - round NYC !!!)
copied
looks good 
Nice; Looking forward to 3.x support.
[httplib2](http://code.google.com/p/httplib2/wiki/Examples)
Proxy support in httplib2 is a bit weird. 
`time.time()` doesn't return a string, so I'm just confused.
Hint: &gt;&gt;&gt; import time &gt;&gt;&gt; type(time.time())
A [talk](http://python.mirocommunity.org/video/4388/pyohio-2011-consuming-web-apis) on requests vs urllib2
&gt; Things shouldn’t be this way. Not in Python. Good one.
The Gnome window manager is used by software professionals across a wide spectrum of languages, including myself, without issue. Which version of Ubuntu are you running? You might find the Gnome 2 interface a better fit - I'm not sure about Ubuntu but in other distros, such as Fedora, you can 'fall back' to the Gnome 2 interface from Gnome 3.
Eclipse also has an XML editor which will can use an xsd for validation and data types (e.g. Will let you select from a list of valid options).
&gt;From: xah at xahlee.org (Xah Lee) &gt;Date: 9 Oct 2005 23:24:47 -0700 &gt; &gt;Fuck the Python liers and ignorant fuckheads. Motherfucking don't know &gt;shit and yet lying thru their teeth with fanfare. &gt; &gt;(for the technical context and justification of this message, please &gt;see the essays at the bottom of: &gt;http://xahlee.org/perl-python/python.html ) &gt; 
&gt;From: oliver.schad at oschad.de (Oliver Schad) &gt;Date: Mon, 20 Sep 2010 17:57:21 +0200 &gt;&gt; Why are you redirecting? If you are redirecting http to https, see item &gt;&gt; 2. in the FAQ at &lt;http://wiki.list.org/x/7oA9&gt;. &gt; &gt;Fuck, I got it. There is a new redirect that wasn't there with the old &gt;system. FUCK FUCK FUCK. &gt; &gt;Thank you very very much. &gt; &gt;Regards &gt;Oli 
&gt;From: jebva at yahoo.com (David) &gt;Date: Thu, 9 May 2002 11:15:40 -0700 (PDT) &gt; &gt;Jesus do you people believe in documentation at fucking all? The &gt;installtin package does nto even inlude the admin mail address for &gt;requests such as 'help' and 'lists'. How about fixing this piece of shit &gt; 
&gt;Bob Ippolito bob at redivi.com &gt;Tue Jan 24 02:13:23 CET 2006 &gt; &gt;They are, but only if the maintainer goes through the trouble to type &gt;"python setup.py bdist_egg upload" and press enter. For most &gt;projects, easy_install will automatically download the correct egg &gt;from the download page -- but only if the maintainer (or sourceforge) &gt;doesn't fuck up the HTML. It sounds like that happened when you &gt;tried it. 
&gt;John Bokma john at castleamber.com &gt; &gt;Tue Sep 21 19:53:01 CEST 2010 &gt;geremy condra &lt;debatem1 at gmail.com&gt; writes: &gt;&gt; It's a joke. Admittedly it's a bit pointed, but it's a joke &gt;&gt; [...] &gt; &gt;It makes you a patronizing fuck in my book. And no, that's not a joke. &gt; 
&gt;From: xah at xahlee.org (Xah Lee) &gt;Date: 1 Oct 2005 07:23:57 -0700 &gt; &gt;the programers in the industry, including bigwigs such as Guido or that &gt;Larry Wall fuckhead, really don't know shit about computer languages. &gt;Sometimes i get pissed by Stephen Wolfram's megalomaniac cries, but in &gt;many ways, i think his statements about the fucking moronicities of the &gt;academicians and otherwise dignitaries are justified. &gt; &gt;here i will try to illuminate some miscellaneous things regarding the &gt;lambda in Python issue. 
&gt;From: diazjimenez at ctv.es (Pedro) &gt;Date: Sat, 23 Sep 2000 18:56:58 +0200 &gt; &gt;Python 2.0b compiles more or less OK with cygwin (without ssl support), but, my old friend, to &gt; &gt;give ssl support to python I have to compile openssl wich, each time I try to compile it in &gt; &gt;cygwin, says something like: "hey you, motherfucker. Buy that Visual C++ or I won't compile ever" &gt; 
&gt;From: xah at xahlee.org (Xah Lee) &gt; &gt;Date: 5 May 2005 14:28:43 -0700 &gt; &gt;Extra point: If the Python command line interface is actually a robust &gt;application, like so-called IDE e.g. Mathematica front-end, then things &gt;are very different. In reality, the Python command line interface is a &gt;fucking toy whose max use is as a simplest calculator and double as a &gt;chanting novelty for standard coding morons. In practice it isn't even &gt;suitable as a trial'n'error pad for real-world programing. &gt; 
&gt;From: john at castleamber.com (John Bokma) &gt; &gt;Date: 13 May 2005 08:34:51 GMT &gt; &gt;If you had really any point, you didn't need to swear in every third &gt;sentence. Nor bother so many groups with your rants. &gt; 
Just upgraded to Lion and the module is working perfectly \o/
None of what I use for Python dev really depends on the distro (except gnome-terminal, which works fine for me): * a terminal multiplexer (like [byobu](https://launchpad.net/byobu) or [tmux](http://tmux.sourceforge.net/)) * [emacs](http://www.gnu.org/software/emacs/) * [virtualenv](http://pypi.python.org/pypi/virtualenv) * [virtualenvwrapper](http://www.doughellmann.com/projects/virtualenvwrapper/) * bash * [Git](http://git-scm.com/) * Google Chrome or Firefox I use Ubuntu (formerly Xubuntu), but I would expect this setup to be portable to any distro.
What is the point of this topic? Do you find it funny? I certainly don't. And I'm no language purist even.
Well, some of these did amuse me. Was that wrong? I guess I just find it interesting how people convey their frustration or just plainly misuse English in these heated programming debates. Seemed odd to me and worth a rough analysis (eg there are 298 google-hits for "fuck" since 1999 in mail.python.org). Reading the +2,-4 score, I guess I'm the only one interested in that analysis. 
Maybe slightly off topic, but it might be handy to have a subreddit for Python code reviews. Could be useful, especially for beginners. Thoughts?
Yah, I got that wrong, it returns a float, but still turned it to int for the sake of calculation.
I have used Ubuntu with Gnome and found it very effective in its simplicity. For editor I first used Kate but later changed to a customized Vim. Recently I tried the latest Kubuntu and really liked the updated KDE.
HTML5 video! This may be the first time I've seen it used outside of an HTML5 demo. 
Multi-part file uploads with httplib2 is a pain in the ass.
This is the only reasonable explanation that I can think of also, the multiple files, multiple definitions... I'll try this out tomorrow and let you know if you are correct. Thanks for this suggestion! It does seem that other C-API based modules (numpy specifically) does something like this...
Don't understand recursion? Google it. (seriously)
really well thought!
[David Beazley](http://www.dabeaz.com/) is a boss. I've really enjoyed watching some of his talks: * [Mindblowing Python GIL](http://python.mirocommunity.org/video/1101/mindblowing-python-gil) * [Mastering Python 3 I/O](http://python.mirocommunity.org/video/1573/pycon-2010-mastering-python-3-)
If you get the basics working then I will use it and send proper feedback. However right now the screenshots look really good but I could not get it to work. If you have to download a dozen dependencies then there are too many things to go wrong. If I were you I would get the installer working as a priority and then you will get more people to help you with testing it in anger. 
Vimeo has had the option to use an HTML5 player since [early 2010](http://vimeo.com/blog:268).
At the moment I use Arch + Awesome WM for a totally lightweight, fast, customizable development environment.
You're wondering about window managers, not distros. While programming, I feel like I'm not working at my fullest if I don't have tiling capabilities in my window manager. This isn't really tied into distro, as you can install any WM you so desire on whatever distro you so desire. I started with Openbox and a redditor's project, pytyle, gave it much needed tiling when you wanted it. I've recently moved to Xmonad, and prefer it. As with LHR777, a terminal multiplexer is also invaluable, I use tmux. Floating window managers like KDE and Gnome just feel like they're in the way, with Xmonad or Pytyle &amp; Openbox, I don't have to worry about resizing much. Further, I don't want to have to use a mouse. Xmonad doesn't require it, so that's nice, but Openbox required some configurations before I got it working with vim-like keys to select from the available windows and virtual screens. I still have my configuration, just in case. If you're (or anyone) is interested, I'd be happy to make it available and explain. The only issue would be if a pytyle package is available to your distro, or if you're willing to compile it. I've had a wonderful time with both Openbox and Xmonad, and both are conducive to programming. Mouse-less programming (and computing in general) is where it's at. Again, the distro doesn't matter much (so long as you've got the packages available or can compile), but I prefer Arch. There's a lot of people that would rather not mess with the configuration requirements of distros like Gentoo and Arch, and I don't blame them. I do like that I can install Python2 and Python3 side by side, but I don't doubt that other distros can do the same, probably easier. Use what's right for you and find or compile the software you want. Vim and iPython is available anywhere, so you should be golden.
I use Fedora, is just personal choice, i think in Ubuntu wont be different
I was also looking for such a tool some time ago, but I didn´t find anything. Closest I came was using Django Admin for CRUD and creating models and froms from xml schema with [generateDS](http://www.rexx.com/~dkuhlman/generateDS.html#django-generating-models-and-forms). But that is still far from a quick and dirty solution... 
Youtube supports html5 video (on some videos - probably something to do with ads) for over a year. It's still in opt-in phase. Visit [youtube.com/html5](http://youtube.com/html5). Blib.tv has/had html5 video suport as well.
Yeah, I tried that back when they first instituted it, but it never worked for me (that is, it still only ever served me Flash video). Same story with Dailymotion. 
you smell of Ruby amirite?
excellent - thanks
Funny thing though is that these things were easily fixable in httplib2 which has been around for years and yet a new package was created. So yes you're right, maybe you're in java land where things aren't fixed but re-created ad lib. 
I just switch out WM/DE's every now and again because I like to try new things (or something different - change is as good as a holiday so they say) I recently switched from Gnome/Unity to KDE 4.7 and its ... pleasantly indifferent ;) The great thing about Linux in general is that you have this choice &amp; most distributions package the majority of WM's &amp; DE's so its easy to do no matter what distro you use. For my Python programming its Vim + screen + zsh + git/mercurial + ipython + Google Chrome so this combo works with anything (by design ;) I have a long history with window managers &amp; have contributed to several of them. I have not found that any one has made a single iota of difference to my programming. What *has* made a difference is learning the toolsets I use everyday - becoming more familiar with vim, the SCM tools, and the languages I choose to code in. There are not many things a desktop environment does for a lone wolf - there's only so many ways you can switch windows &amp; virtual desktops and launch applications. If I was part of a team then I'd be interested in some of the collaborative tools in Gnome (e.g. the integrated chat &amp; file sharing) - but I'm not. 
I had this same kind of realization a while ago. Everything is key/value data (relational DB, document DB, XML, JSON, YAML, web forms, config files, etc.). So if you could get a 80% solution for editing and validating arbitrary (nested) key/value data, it would be useful in lots of places. One way to do this would be to use a JSON editor, for example: [1](http://jsoneditor.net/), [2](http://www.thomasfrank.se/downloadableJS/JSONeditor_example.html), [3](http://www.alkemis.com/jsonEditor.htm). JSON is a very common interchange format, so it would be easy to get data in and out. You could then put some kind of lightweight schema (like [Rx](http://rx.codesimply.com/), [Colander](https://docs.pylonsproject.org/projects/colander/dev/basics.html), etc.) on top of that for validating the data. [Futon](http://couchdb.apache.org/img/screenshot-a-large.png) (the CouchDB admin interface) has a pretty good interface for editing JSON documents. I really want to try this kind of system on a real project.
i probably would go nuts if i used tg on windows. :)
Nice! That's me! If you like/don't like it, please let me know (preparing talks on other topics currently). Also, if you have questions, I can try to answer.
So, what's the downside?
Does this have any cache support? That is the main reason I am using httplib2 now.
For those eager down voters, OP is actually referencing a famous Google [Easter Egg](http://www.google.com.au/search?q=recursion).
yep. really though if the python installer would just add python to the path, things would be a lot easier. it never will though. but if it did, this article would be a lot shorter. install setuptools install virtualenv create/activate virtualenv install turbogears in your new virtualenv 
You should also read this: http://www.reddit.com/r/Python/comments/jij1f/still_dont_understand_recursion_read_this/
None of my web browsers (thankfully) don't support H264
I think watching Inception should have much of the same explanitory power.
[I don't get it](http://www.google.com/search?q=it). Really though, I wish Google would do that with "practical joke" and "fooling someone", that would be classic.
Recursion: see recursion.
You are so helpful! I just saw you comment this at http://www.reddit.com/r/Python/comments/jij1f/still_dont_understand_recursion_read_this/
Awesome work!
I completely understand and really like the elegance of recursion. I just never get to use it in my day-to-day. :-(
Do people genuinely have a hard time understanding recursion, or just find it difficult to write recursive functions?
i understand recursion, but towers of hanoi had me puzzled for a day at least.
Pythonista for 6 years and lovin' it. Check out my record, http://code.google.com/u/ubershmekel/ it's spot clean of any ruby shenanigans.
I came accross this site today :) Does it really take only 3 hours to finish those slides?
Another way would be: lowerBound = 2 upperBound = 8 aInRange = lowerBound &lt; a &lt;= upperBound bInRange = lowerBound &lt; b &lt;= upperBound if aInRange and bInRange: ... It is longer than the original line, but (for my taste at least) by far the most readable approach. It has no magic numbers and the condition in the if-statement is self-explanatory. 
My usage of httplib2 has always been basic and for scripting rather than otherwise more extended well designed application. For that type of usage, I've found httplib2 straightforward enough. I'll admit that in more complex use case, it's quite possible that it has many shortcomings. I'll give Requests a try :)
Seems to be a pretty good summary. Although nothing beats the Python Tutorial for me, it's how I learned Python and quick to read.
Thanks! I will try it out. I've been using GEdit thanks to Zed, but I think i'll be happy to switch to something a bit more serious.
Well, I understood recursion, but now I understand how it is useful.
Well, it's hard to day without proper information. Are all of your rules in the form of inequality: function? Maybe you should just research rule engines with google, and if you can't see something that looks good, ask us when you know what you don't like about what you've found.
PyCharm is also a choice. And there is rad2py which seems quite nice.
I use Komodo IDE since around version 4. The upgrades are reasonably priced considering how great it is. Step-through debugging in the IDE is so useful!
The 1 thing that is bothering me: There are no language files for newer stuff. Everything remotely new gets language files for emacs, vim, TextMate, gedit. But nothing for Komodo Edit. But it supports HTML5 out of the box. This is a plus. 
Had not get it until encountered this pretty insightful [comment](http://www.reddit.com/r/Python/comments/jij1f/still_dont_understand_recursion_read_this/c2ckqy4).
I've been doing a lot of this lately for implementing a simple expert system, and to do it properly you really need to be able to parse and evaluate the rule syntax. However, in Python there may be an easier way to do what you want, which is to express your rules in Python syntax (as you do in your example), and use eval() For example, r1 = "if stock('pens') &gt; 3: alert('message1')" eval(r1) This will execute the rule, including calling the helper functions embedded in the rule. So for this to work, you need to have defined a function called "stock" that takes a string argument and returns a number, and another function called "alert" that takes a string argument. And there must be a variable in scope called "r1" which contains the rule text as a string. Where this approach falls down is if there are dependencies between rules; for example, if one rule only gets fired if another is fired. Still, it may get you started. I'm not aware of an rule engine in Python itself. You could also look at a non-Python rule engine, such as the CLIPS open-source expert system, for which there is a Python module that fully embeds CLIPS. 
First, read up on parsing so the Python script can make sense of the actual rules. Second, read up on dynamic concepts such as closures. Long story short, eval() should generally speaking be avoided on the back of security reasons.
I've been meaning to try it because Eclipse is driving me nuts. can anybody compare it to Eclipse ?
After a few years with Komodo, I can say Sublime Text 2 is better, and if you want something that loads fast, try Vim. Komodo was just too buggy for me and none of the bugs were ever fixed.
Komodo Edit is a great IDE, but one thing prevents me from using it for day to day stuff: no debugger. Lately I've been using Editra, which is like Notepad++ except it has a plugin that allows Python development including a debugger.
I use PyCharm for Python coding. Love it. I also use Komodo Edit for my Perl and Tcl coding. If Komodo IDE was a wee cheaper I might go for that.
I use it for PHP, Ruby, and Python. It kicks ass for all of them :)
I use Komodo edit for everything (except very quick changes to text files) because the macro / add commands feature is so simple. I can open the current HTML in firefox, I can run pdflatex on a .tex file, I can compile C or Haskell or Python and see the result at the click of a button. I know most IDE's do this, but it was just so obvious how to set it up in this case. Komodo edit is amazing.
Do you mean totally new languages? I don't think I would use KE or KIDE for a general editor. I would use it for its support of Perl/Python/Tcl/PHP and Ruby. I would use a lighter weight editor (I use MacVim) for my general day to day scripting.
I too needed something like this. However, Im thinking of modeling it after OS X's Automator—eg. have a set of configurable objects that perform functions or comparisons. Let me (us) know if you find anything.
If you're on Windows and use Visual Studio, have a look at [Python Tools For Visual Studio](http://pytools.codeplex.com/). It's done by one of the ex-IronPython developers and a team of others who have moved what used to be the IronPython-packaged tooling support out to its own product. It includes great editor support, project support, debugging, profiling, NumPy/SciPy for .NET, some HPC/MPI stuff, etc. I've been a Komodo user since 2006 and it really has been great, it's an IDE I love and recommend to anyone, but I've been giving PTVS a shot lately and I'm really liking it. It's not just for IronPython - it will find all of your CPython installs and work with them as well.
You cannot call eval with user-supplied data. It's simply too dangerous, and it lets them do anything, including side effects like, say, modifying your filesystem.
How will closures help him?
I don't know of "a rule language in Python", but you could look into creating your own external domain-specific language using one of the many Python parsing libraries. If the examples you gave are representative, it should be fairly simple.
Pycharm is my favorite by far. I'm a big fan of JetBrains and a bunch of their other products too.
Have you looked at 'Drools'...it's Java...but either you can communicate with it or replicate it..... 
Good point, but I was assuming the rules would be defined by someone trusted, not end users. For user-defined rules, you need to parse the rules, for syntax checking as well as security.
Is a rules engine one of those "and now you have two problems" solutions?
It's a wrapper for a lot of things. We are treating it more of a framework, where OpenCV is more of a library. You no longer have to deal with things like IplImage vs. cvMat, etc. You have an unified Image type that is abstracted and returns a feature set. It also wrappers things like libfreenect, so things are seemless. For instance: cam = Camera() img = cam.getImage() cam = Kinect() img = cam.getImage() Will do the same thing and return a "feature set" object. We also have 1-click installs for every platform. Please don't think we are trying to replace OpenCV, only augment it. Think of SimpleCV as jQuery or Processing for vision.
Try this: [http://pyparsing.wikispaces.com/](http://pyparsing.wikispaces.com/) I haven't tried it personally. I've tried lex/yacc, and looking at pyparsing's examples, it seems pretty easy to get into.
I used it and it was pretty cool
Not free. Hulk sad.
I recently started using Eclipse after trying WingIDE's and Komodo IDE's trials. Earlier I used simple `vim` setup, and decided to check out what do people see in IDEs. They're more or less comparable. All of them provide auto-complete to some degree, all of them have nice support for debugging or running unit tests... But I often write in different languages: C++, PHP, Python, JS, XSLT... and Eclipse handles them all. This is something I like very much. Eclipse is, however, much more complex, so it might be not the best choice when you're learning stuff.
I used Komodo once and started to learn VIM shortley thereafter - mainly because you can emulate VIM in a lot of other IDEs (Netbeans, Eclipse, Visual Studio, Qt Creator) - now I can have the same movement keys where ever I need them - and with [this guide](http://sontek.net/turning-vim-into-a-modern-python-ide) setting it up was pretty easy too. But I have to admit it is not for everyone - the first 2 weeks are just plain hell of unproductiveness.
Well since Python is a dynamic rather than static it means there are plenty of concepts that could be used to implement a rules expression evaluation thingy. No need to constrict yourself to nasty stuff like eval(). Closures is a nice simple one, hence I took it as an example to wet his appetite.
&gt; Do you mean totally new languages? Go, CoffeeScript, several template languages, … 
It is amazing and not only for learning, but for working too.
I use [WingIDE](http://wingware.com/) and love it.
There is only one editor worth learning: VIM.
But then you have to develop Python on Windows. One step forward, two steps back.
Woah nice dude, never seen this before. Will definitely give it a go. 
how about Eclipse vs Komodo for clunkiness ? You know what I mean: fighting the interface, slow reaction time. having all languages is a great win for Eclipse and might keep me there.
A quick search for "python expert system" brought up [Pyke](http://pyke.sourceforge.net/). There's also a [Pyton Semantic Module for Drools](http://legacy.drools.codehaus.org/Python+Semantic+Module) if you're willing to write Python rules for a Java system. I haven't tried any of these, but I am interested. If you give them a shot, please post a followup. Edit: Just found [Pychinko](http://www.mindswap.org/~katz/pychinko/) which is a Rete-algorithm implementation. That might do the trick.
Yeah, I never saw Komodo as "that kind" of editor. They have a few core ones they focus on.
This is going to be awesome. [Yahoo! News](http://news.yahoo.com/pycon-2012-announces-call-speakers-120015650.html) and a few others picked up the press release.
I hear nothing but excellent things about it and it looks badass. Doesn't have ZenCoding in 2 but does in 1, otherwise it'd be my editor of choice. Loads fast as hell too.
Same here. The personal license is really cheap, and the Wingware guys do a fantastic job of supporting the thing. Upvote!
I've got a pretty powerful machine (two 24" monitors, 16GB RAM), so both were working quite well... although Eclipse used a lot of disk operations sometimes, I've yet to check why. Komodo has simpler interface, and more intuitive, easier to grasp... but I felt I was using mouse too much sometimes, not knowing how to launch some actions from keyboard. Eclipse is much more configurable, and I've got a feeling I can better use my screen space too. What I miss now is `vim` emulation now. I did not have enough time to look into Eclipse plugins yet, and Komodo provided it by default.
With eclipse, your first "fresh" startup is going to be slow, but once the JVM is primed the launch is usually pretty fast, assuming you have okay hardware. Eclipse is pretty fast on windows, from my usage, but Linux 2d performance lags it a little bit sometimes. Eclipse's interface takes a bit of getting used to, usually you spend 20 minutes or so just moving things around to your liking.
Also grab [soda-theme](http://github.com/buymeasoda/soda-theme) because the default window theme is a huge mess of light and dark UI (on Mac, anyway). Once you're past that, however, it really is a great editor.
Vim is much, MUCH better.
Thank you for the suggestions, LargeDickington.
True. We are treating more as a framework than a library though. 1-click cross platform installs. The code is much simpler to write, you don't have to worry about IplImage or cvMat, etc. We aren't looking to replace openCV, only augment and make it easier to use and deploy. Think of simpleCV as the jquery for vision.
I agree, but only if you have gotten past the initial steep learning curve. 
Even though you need the right plugins to make it awesome for Python - but with Rope and omnicompletion set up + some nice exuberant ctags it will be hard to beat it.
Isvara's hardline on eval for python is simply untrue. You can tightly control the locals and globals available in the execution context, limiting access to "dangerous" functionality. The fear of eval seems to be rooted in JavaScript and php, where the code has full access to the execution context. However I do agree with isvara regarding the trust of input data; there is simply no such thing as a "trusted" user.
I fully agree that your way is significantly more legible. My thinking was that if the OP was so overly concerned with conciseness, though, that a multiline approach like this would be far less palatable than "keep it the way 95% of others do it". Your way is usually how I do it, when it's not super obvious up front :)
Here's [an image](http://i.imgur.com/pgd79.png) my [color scheme](http://dl.dropbox.com/u/440963/Vombatiform3.ksf), better than stock ones IMO.
[There's ZenCoding in 2.](http://www.sublimetext.com/forum/viewtopic.php?f=2&amp;t=580&amp;p=10654#p10654)
It's free to try. There's an annoying nag screen, but you won't actually be blocked from using it.
What bugs? I've been using Komodo Edit for a few years now and haven't had a single problem with it. Admittedly I only write code and generally don't bother with autocomplete.
I develop Python on Windows. And Linux. And Mac OS X. And FreeBSD. And Solaris. I take pride in my scripts being cross-platform, although since it's Python there's really not much to be done.
I use Vim. But the lack of error highlighting in Django templates in Vim is kinda irritating. Then again, Komodo Edit's error highlighting is frequently wrong.
&gt; there are plenty of concepts that could be used to implement a rules expression evaluation thingy ... Closures is a nice simple one Can you give an example of what you mean? I'm just not sure what it is about them that you're saying is particularly relevant to a rules engine.
Thanks for the link. I think I'll actually watch that one myself.
I can't vouch for Pychinko, but Rete is the way to go here; particularly if there are going to be many business rules. In my experience, the bigger problem with these kinds of systems is giving the user a way to edit the rules in way that makes sense to them. The last time I did this, we used ILog for .NET. That product also works for Java.
Komodo + Vim key-bindings. Boom.
Wow... testing out Sublime Text 2 a little bit ... any it is really nice. Simple but Nice. Unfortunately, they don't have built-in support for Python3, it seems.
Thanks for the awesome talk! Wish I could have been there :)
Nope.
It's not in the standard library (yet) :)
Does it work on a shell server? No? So bad.
Don't you use django.vim? I'm fairly sure that includes it.
I third this.
Use [modules](http://docs.python.org/tutorial/modules.html)! For example, suppose this is a file called `foo.py`: def hello(): print "Hello, modules!" In the same directory there's `bar.py`: import foo foo.hello() # prints "Hello, modules!"
Check this out: http://docs.python.org/tutorial/modules.html
That's great, is it possible to source .py files not in PYTHONPATH from within the Python script? I tried using os.chdir(myDir) but Python doesn't seem to look for modules in myDir.
It's really not that steep for most things. For me, it was just forgetting expectations and just sit there and take it in. i = insert = start typing code esc = takeout of insert mode to give it other commands :q! = quit without saving :q = quit if already saved or nothing changed :wq = save and quit :w = save and keep open That should be enough to start going. After getting comfortable i would learn how to do more. Now I can use it for mostly everything (related to text editing). Good tool to know, even if you never will use it for everyday coding. I can SSH into my server and edit things from in the terminal, which has been a life saver. 
(Pedantry: It's not really sourcing the file, that would imply Python is executing the contents in the same namespace, shell-script-style.) Modules should usually be in either the directory of the main module or in the global PYTHONPATH. Putting them anywhere else is bad style in most situations. But if you want to, you can modify the search path on the fly. import sys sys.path.append(myDir) `sys.path` is a normal Python list, so you can use any of the standard list-manipulation functions.
I dunno. I get syntax highlighting already so I kind of never really bothered to look into it more. Does django.vim detect errors too, or is it just syntax highlighting?
Pedantry is good, helps me to ask better questions in the future. Since I'm only a remedial Pythoner, I'm okay with bad form for now. Moreover, your example worked. Thanks!
According to the page at http://www.vim.org/scripts/script.php?script_id=1487 it does appear to detect errors. Can't speak from personal experience though.
oh ok, I thought you might be coming from there because they tend to pay a lot more attention to their divas and their attitudes instead of code. my apologies then.
[http://wiki.python.org/moin/GuiProgramming](http://wiki.python.org/moin/GuiProgramming) Qt is one of the best GUI tool. So, do not throw it away after first problem. import sys from PyQt4.Qt import (QApplication, QWidget, QLineEdit, SIGNAL, QVBoxLayout, QObject) class MyWidget(QWidget): def __init__(self): super(MyWidget, self).__init__() self.line = QLineEdit() layout = QVBoxLayout() layout.addWidget(self.line) self.setLayout(layout) QObject.connect(self.line, SIGNAL("textChanged (QString)"), self.onTextChanged) def onTextChanged(self, newText): print newText # Do something if __name__ == '__main__': qapp = QApplication(sys.argv) widget = MyWidget() widget.show() qapp.exec_() 
Nothing is compared to Vim. 
heard of Komodo Edit, never used it. I just use the IDE but i might give it a try i just did not understand it very much
Do you have an advice for a good tutorial for it (step by step)?
not a fan of PyQT thought i've heard many good things of it, there a couple of GUI creators out there easy ones? ever try looking in to Wxpython? http://zetcode.com/wxpython/ is pretty easy to use if you use the GUI of it. least until u get familiar with GUI's you can read more about wxpython here http://wiki.python.org/moin/WxPython
Check out the vim pyflakes plugin for error highlighting / linting.
I already saw these tutorials (zetcode with different GUI), i don't know, maybe i'm retarded, but in none of them i've found an indication of the only thing i'm interested in : enter values in a textbox and assign them to some variables when i click OK.
If you are using Eclipse, you need the PyDev plugin. It is awesome.
I have learn Qt by officials trolltech tutorials. They are really good, but it is C++. You can try Nokia sponsored Python + Qt implementation (PySide): [http://www.pyside.org/](http://www.pyside.org/), [http://developer.qt.nokia.com/wiki/PySideDocumentation/] (http://developer.qt.nokia.com/wiki/PySideDocumentation/). I think You can reuse most of tutorials by using PyQt.
have u tried using BoaConstructor or WxDesigner which allows you to make the Gui's more easy, i don't you are retarded, am not much fan of GUI building on python cuz you need the libraries on the pc you plan to use it so it tends to be a big file. try a gui builder maybe it will ease your problem. sorry if am no help. both the gui builders home page can be found http://wiki.python.org/moin/WxPython 
Don't you get a headache when you look at something else (which is most of the time brighter)? 
No point. Edit is IDE but stripped down. 
Upgrade to Komodo IDE. It has the step-through debugger. I'm pretty sure it can attach to remote instances also.
I've never used notepad++, so I am not sure if you are somehow trying to run the script from within the program, but have you tried running the script by just opening the command prompt and running the script that way, (ie C:\python27\python pathtoscripthere.py)? Also I didn't see it on the main page, but there should be a link to instructions for installing the libtcod module.
I'm going to try thank you!
For quickly building out GUI front ends (esp. with people who are not programmers), I've found [PythonCard](http://pythoncard.sourceforge.net/) quite good. 
I'm not a big fan of activestate as a company, pushing proprietary IDEs and stuff so it seems iffy. Does this really have any advantage over PyDev? I strongly doubt it. Though I admit, most of the time I just use a plain text editor (Geany on Linux or Notepad++ on Windows) to hack some python.
the syntax of the connect string is "oracle://user:pass@TNS", a colon not a slash. This code: e = create_engine('oracle://user:pass@tns') c = e.connect() is roughly equivalent to: import cx_Oracle c = cx_Oracle.connect(dsn='TNS', user='user', password='password') cursor = c.cursor() cursor.execute("select 'FOO' from dual") cursor.fetchall() Also reddit is not a great place for technical issue questions like these. Better places are the [sqlalchemy mailing list](http://www.sqlalchemy.org/support.html#mailinglist) as well as the [cx_oracle mailing list](https://lists.sourceforge.net/lists/listinfo/cx-oracle-users) for tns/connection issues. 
Thanks for the resources! I'll try it out tomorrow and see if that solves the problem (bet it will). I rewrote the script using cx_Oracle, but I want to get into SA (I'm only a few days deep).
I highly recommend GTK+ and Qt (maybe even WxWidgets), but expect to have to spend a while learning how they work. GUI programming is pretty complex and requires knowledge of some pretty advanced programming concepts.
I am not sure of the default locations that Python checks for modules, I don't know off hand where you would go to change that. Are you reading through all the steps for the tutorial? I know you also need a png file that contains the tileset which sounds like it may be missing, just a guess. If you are new to Python I would recommend checking out some getting started tutorials to get some of the basics down.
Like Peas and Carrots. http://npppythonscript.sourceforge.net/
Similarly, though, I could see lambdas being useful. def something_else(): print "hi!" self.add_rule(lambda x: len(x.pens) &gt; len(x.pencils), something_else)
&gt; must libraries and modules just be dumped into c:\python27 or can you tell it to look in a specified place (actually I'm assuming you can, it's just not very clear how to)? You need to modify the windows PATH variable. Not sure what version of windows you have, but they're basically all the same. Here's how you [find and modify PATH](http://www.computerhope.com/issues/ch000549.htm). If the folder you want to add is c:\python27\scripts, add the following line to your path variable: ;c:\python27\scripts 
Er what? That makes no sense as to why you are a fan or not. Are you against any company that creates a commercial product?
You need X11 to run in on OSX. Blech.
Sublime Text 2 is great, but the indenting and magit on emacs prevents me from it. I would gladly pay for sublime text if it had those.
This tutorial seems to be targeted at your situation: http://github.enthought.com/traitsui/tutorials/traits_ui_scientific_app.html It's based on the Traits library (parts of the Enthought Tool Suite). This is an excellent way to build GUIs. BC
what is this wizardry? 
I want something like this, but that also has a built-in Python interpreter. Kind of like IDLE (where you can just F5 to run) but less shitty. So, like a minimalist IDE, and not something as bulky as Visual Studio or Eclipse. Anyone have any recommendations? edit: For Windows.
A commercial programming product, yes. Especially in the field of programming I think it's beneficial for things to be GNU-style free.
Had never tried Sublime before a few minutes ago, but I've gotta say that now I'm HOOKED. Too kewl! Thanks for the suggestion, it works the way that I like to work.
http://zetcode.com/tutorials/pyqt4/ might be useful for you, along with using the documentation links petraszd linked to.
If you want easy simple try easygui. It's not powerful, but it is damn easy.
Emacs. Alternatively, I'm sure Vim/Cream has a python mode with inferior shell, although you might have to download the addon yourself. I haven't used Vim for Python, but I've heard it's pretty good. Emacs is excellent, I use it all the time.
The Enthought Python Distribution is very good in itself. Spent too much time trying to combine the packages I need, before stumbling on EPD.
I forgot to mention I'd prefer a GUI IDE...and also I usually run Windows. Not like a curses/ncurses type of thing.
If you want Vim with a shallow learning curve, try [Cream](http://cream.sourceforge.net/). Basically, it makes insert mode default (normal mode easily available), adds CUA shortcuts and menu items for common commands (with keyboard shortcuts listed after them), and a bunch of other usability improvements. Note that it's not in any way "dumbed down", just easy for newbies. All the power is still there, and even some experienced vimmers seem to prefer it.
Ugh, that is a deal breaker. :-(
irc and terminal are both pretty dark. Not an issue when going to something light browser either. Been doing it like that for years. *shrug*
Komodo edit is open source (MPL IIRC) in the form of the Open Komodo project. Edit is just prebuilt for you. 
You can setup Komodo Edit to do exactly this.
Agreed, deal breaker...
I'm also a fan of Sublime Text, but I'd prefer to wait till it has a little more maturity (and perhaps a nicer way to edit its preferences) before I fork out the purchase cost.
I would love to, but $400 is a bit out of my price range.
If you want to spend hours upon hours mastering a text editor instead of developing products.
I can't imagine anything better than the tag team of vim and ipython, but I'll give it a try.
Flow through `vimtutor` and you'll have everything you need in a relatively short time. I wouldn't call that so steep for the benefits.
Oh it is beneficial to have GNU-style software, but its also beneficial to have a paid software / support that allows the developer to put food on their table. That way they can make their product better without the hassle of living out of a cardboard box, or eating into their spare "non-work" time. I think [ActiveState](http://www.activestate.com/) do a fantastic job at supporting the technologies their IDE / Editor does while giving back to the communities as well. And no, I'm not an ActiveState employee.
I'm aware of that, it's a dislike for the company in general I hold.
I agree with you.
I use the full commercial IDE daily. I'd say it's OK but not great. In particular, no dual mon support -- I do like to park all my debug windows on another screen so I can see all my code. And slow as molasses to start up. It got embarrassing doing some code review with colleagues as I waited...and waited...and waited.
Enterprise solution ! 
Try this for fun: __path__ = globals().get('__path__', []) __path__.append(path_of_module_or_package) from __main__ import module_or_package Note: I'm not recommending anyone actually use this, but it shows an alternative to extending sys.path. Neither of these is a good practice. 
The current beta has CoffeeScript support (highlighting + error checking), so I imagine it will be in the next version of IDE/Edit coming out relatively soon. Also, it's possible to add your own support for language highlighting/error checking/compiling etc. That's what I love about Komodo Edit, I don't know many editors that are as easily extensible as KE.
I *strongly* encourage anyone considering trying Komodo to download the current IDE beta (it's free to try) rather than Komodo Edit/IDE 6. It's *much* faster than the older versions, and has a lot of great new features like CoffeeScript support. If you develop in dynamic languages like Python and JavaScript, it's hard to beat Komodo... What I love is how *easily* customizable it is....it uses the same extension system as Firefox and it's easily extensible via JS and Python as well as through the many settings.
You can assign a keyboard shortcut to just about anything in Komodo, and it's highly customizable.
That's definitely nice to have, but it's worth noting that Komodo comes with remote editing functionality.
[This](http://roguebasin.roguelikedevelopment.org/index.php/Complete_Roguelike_Tutorial,_using_Python%2Blibtcod,_extras#A_neat_Python_shortcut_for_Notepad.2B.2B) part of the tutorial shows you how to link up np++ with python. IIRC even that portion is not completely correct and I had to mess with it to get everything to work. I've moved on to using Eclipse since then but hopefully that section will get you moving in the right direction.
I am currently building a medium-sized desktop application using Python and PySide for a client. After a long search of packages and solutions (including using Ruby, Perl, C++, wxWidgets, tkinter, FX Toolkit, FLTK), this is the best combination that I've settled on. I think Python is better than C++ (especially when you need an ORM layer for database access) and easier to rapidly prototype something. And Qt is more mature than the other GUI toolkits. And it seems to have the best support for native looking elements. Note that this is mostly my opinion. The other combinations that I've tried had stability issues and sometimes a lack of good documentation. There is some learning curve (I'm still climbing this curve myself), but I've been able to build basic forms displaying data from a database (using SQLAlchemy) and its working really well for me. I've been able to reuse all of my ORM layer from previous work on a web site (same data and schema), so that part is almost free for this project. I design most of my GUI elements using [Qt Designer/Creator](http://qt.nokia.com/products/developer-tools/) a nice IDE tool from Nokia that is really designed for C++. But it saves the forms in *.ui files (XML files really), which can be converted to Python code automatically using the pyside-uic.py script supplied by the PySide package. It will help to take a short C++ tutorial on how to use this IDE (the tutorial is not long) and it will give you a basic understanding of signals and slots. tl;dr Python + PySide is highly recommended
I second the goodness of the tutorials even though it is in C++. I already knew C++ and Python well and so it was easy for me to transition from the C++ realm into Python (using PySide). YMMV.
Ah. Roger. Was just making sure. I personally find the distinction in those licenses moot. 
It's more about getting used to it. It rather just have a lengthy learning curve (as there is so many functions and plugins to utilize)
How about [NINJA](http://ninja-ide.org/) IDE?
Um, *what*? Monkeypatching the bytes builtin to be a function? Breaking every "isinstance(val, bytes)" call everywhere? Breaking who knows what other expectations stdlib or third party libraries have about the constructor's behavior? Let me provide a simple test to see if you're about to mess up your python app and all libraries involved... * are you modifying \_\_builtin\_\_? * Is it replacing an existing object? * Is that object a basic python type class? * Is your replacement not even a class? * if you haven't answered "no" somewhere above... Zeus help you. --- Seriously though... if you want python 2/3 compatibility within your app... write a compatibility module, isolating all the divergent behavior into one place. To take his example... if data is bytes, "ord(data[idx])" is just "data[idx]" under python 3... best way it to make a wrapper bord(data, idx) which performs the correct op under python 2 or 3. A "int_to_bytes" constructor which just aliases to "bytes" under python 3. And so on. *Not monkeypatching core types*. Or use [six](http://pypi.python.org/pypi/six) if you're ok with an external dependancy.
My thoughts on current Sublime Text 2: 1. Preferences are limited 2. Python 2.6 only, and instead using installed python directory and library, it comes with its own. 3. I tried code completion, type in: import re re. (I press tab) =this line turns into=&gt; reself., pressing tab further adds 'self' until it becomes something like: reselfselfselfselfself. Can't say I really like it :(
Haha http://youtu.be/gJiYOk_HctA -- nice face detection.
ctrl-c is much more accessible than esc to exit mode.
did you really have to call his name ?
Ok here goes: &gt; I want to give my users the ability to dynamically specify rules like this Because OP mentions the magic word 'dynamically', I assume the intended use is not just processing some text file or something. A good example is a stock trading rules system. Such a rules system should, if it's done correctly, be able to respond to changes in realtime, plus offer some form of observability of the rules and how they evaluate. In such a system the rules could be generated as classes (or functions) on the fly, and hence also changed as the user sees fit. Python being the foremost dynamic language IMHO would handle this perfectly. Now dynamic concepts in general are not too easy to grasp first hand. I myself took a long time getting used to them, but once you've popped you just cant stop. A nice gentle introduction is closures. Once that concept is well understood there are many more to explore. All in all, I think it's really silly to shoehorn Python into a static language (and use eval() *shudders*) when one can start using it for what it really is capable of... Just my 2c EDIT: ripraprup and its_in_the_computer are both the same person btw, but on two different computers. dunno why i havent streamlined that.
Have you looked at [PEAK-Rules](http://pypi.python.org/pypi/PEAK-Rules)? It's suitable for situations where you want to say, "here's a current situation or event, what should I do or value should I return?" The language it uses is Python, so if you need a separate rule language you'll need to do some translation.
jeez, no update since 2006....
Perhaps Bram Cohen is too smart for his own good. Your solution is much simpler and much more maintainable. He's an awesome programmer, and I hope he'll put out another "revolutionary software project" soon. Maybe this was just one of those things you do because you want to challenge your skills.
 &gt;&gt;&gt; class Something(object): ... def __repr__(self): ... return "%r is repr" ... def __str__(self): ... return "%s is str" ... &gt;&gt;&gt; s = Something() &gt;&gt;&gt; print s %s is str &gt;&gt;&gt; print "%r" % s %r is repr Is it clearer now? You can read more about repr and str http://docs.python.org/reference/datamodel.html#basic-customization 
Hmm, haven't seen that one, I'll take a look. Added to the post list though!, Thanks!
This is spot on - there are 4 main GUI toolkits for Python: Tkinter, Qt, wxWidgets and GTK. Tkinter comes with Python and is fine if you want simple stuff, it doesn't have any advanced widgets though. All the rest require add-on modules &amp; have other dependencies - but are far more feature-complete. No matter which you choose, its going to take time to learn how the toolkit works. Most of them follow the same principle however so once you learn one switching to another can be straightforward. The learning curve for a GUI toolkit if you have little or no experience is pretty steep - just stick with it - there's no other way through. I strongly recommend learning the base GUI toolkit before picking up a simplified wrapper for it, because most of those have been written with the hope that you already know the underlying technology and just want a simpler API in front of it. It'll make debugging a lot easier later on. 
Yeah, inactive is an understatement. Too bad, it's fairly good for what it is. Updates aside, it bogs down a bit when you try to do to much with it. You end up reaching around it to get at the wx innards which is more trouble than using wx in the first place.
I agree with the statement but not the sentiment. If you are a serious software developer, you had better spend hours upon hours becoming intimately familiar with the toolsets you're using for your programming. Ever watched a professional lumberjack chop wood? Try and accomplish his/her feat using the same tool without the hours upon hours of learning how to use it properly... 
repr is also more about creating a code based representation of the object: i.e. eval(repr(x)) == x str is about creating a human readable representation of the object.
I used to use Notepad++, and then PyCharm, and now emacs. If I was going to use an IDE for Python, it would definitely be PyCharm.
by code based do you mean how I'd type it in a .py file? Instead of how the user would see it when presented as str?
repr is something a dev could make use of so generally contains more info than str so not really something you would put in a .py file but something you would use doing print statement debugging
I used to use this, untill pdbpp came along
Alternatively, from foo import hello, goodbye hello() goodbye() *or* from foo import * hello() goodbye() *That being said*, AFAIR, movac's example is the "best practice" because there is no risk of confusing or conflating functions. Edit: [Article on importing in Python](http://effbot.org/zone/import-confusion.htm)
its insanely useful, makes debugging a lot more enjoyable...
If the object is simple enough, it should be 'code' to construct an equal object. If its too complex, I don't bother (those things are cached by other means anyway).
While I'm not disagreeing with you, just to clarify: EPD = Enthought Python Distribution, ETS = Enthought Tools Suite. The later is a set of BSD-licensed libraries developed by Enthought, the formal is a binary python distribution containing ETS and many other scientific/engineering/math libraries. It's easy to get these two acronyms confused. EPD may be the easiest way to install ETS on Windows/Mac.
Another exemple: class A(object): def __repr__(self): return "&lt;A more info here&gt;" def __unicode__(self): return u"A in unicode" def __str__(self): return "A in str" &gt;&gt;&gt; A() &lt;A more info here&gt; &gt;&gt;&gt; print A() A in str &gt;&gt;&gt; print "A: %r" % A() A: &lt;A more info here&gt; &gt;&gt;&gt; print "A: %s" % A() A: A in str &gt;&gt;&gt; print u"A: %s" % A() A: A in unicode edit:remove an error :-)
I thought I was the only Editra user ;)
Yep, sorry, I wasn't really elaborating on your comment, just mentioning something the OP might find useful and thought the context of your comment was the right place for it. I realize the two are different, it's just that EPD is a great way to get almost everything.
You have to spend the same amount of time with an IDE. It's better to know what you're working with rather than looking everything up or using only 1% of your editor's capabilities.
repr (%r) generally contains more info and is what you use to print the object for debugging str (%s) is what you use to print the object "normally" conversion table: * print \`obj\` == %r == obj.__repr__() * print obj == %s == obj.__str__() edit : corrected thanks to pje
Yes, but I think this is slightly different thing when some shortcuts are already assigned. I don't like customizing things too much, I assume that authors of an application thought of what shortcuts really make sense, or which one will be the most useful. Then I can experience the application the way its authors do. This is especially important in case of a big application like an IDE--these usually have some specific ways to do things. Ways which might be not obvious for a first time user. How can I then decide which shortcuts will be more useful, especially if I'm using the application for less than a week? In case of Komodo IDE the problem was that builtin shortcuts simply weren't discoverable, so I didn't learn them. I quickly got a habit of navigating menus by mouse, and habits are difficult to get rid of. Eclipse displays its shortcuts right in the menus, so its simple to learn them. To me, customization is important, but sensible defaults too.
We are talking about rule engines here, not about parsing rules. 
That's just bullshit. DO NOT touch \_\_bulitin\_\_.
Oh I see. I misinterpreted the question. Though I think the OP wanted the rules to be parsed in text form, not in python code. Searching a bit yielded: [http://pyke.sourceforge.net/](http://pyke.sourceforge.net/)
I heart [wxPython](http://www.wxpython.org/). It's so easy it will make you cry. Edit: The only drawback as far as I can tell is that it doesn't have advanced GUI features like multi-select grids with drop-down boxes and ribbon interfaces, etc etc. OTOH, that means it remains nice and simple.
If you would like to use a template, you could generate an HTML document. There are lots of HTML templating libraries for python.
Hi, the final format needs to be in something that MS Word can open or at least Adobe Acrobat. I don't know if I will be able to do that using HTML code? I've seen the ReportLab's Platypus, I'll play with it over my time off and hopefully it will pan out. Any other ideas?
If it isn't the code, the convention is to put \&lt;angle brackets\&gt; around it.
Tab completion being fubar was a big one a lot of people experienced, including myself. Not to mention Komodo throwing crash reports every 4th or 5th time you closed it. I like Komodo fine, but where it's a user-contrib kinda place, a lot of the plugins are broken shit. It also takes way too long to start. I tried using it as a .txt editor (Notepad sucks), and it'd take a minute or 2 every time to load up. :\
Get PyCharm
Yeah that sucks. I haven't used it enough to really know it's quirks, but that sounds like a no-deal for me. I just came off of Komodo because of that tab completion tard shit.
Komodo Edit is just as good as Komodo IDE anyway.
Some quotes: &gt; What most peo­ple see as a prob­lem with threads, I see as a prob­lem with the mem­ory model. They let threads mod­ify the same object simul­ta­ne­ously, result­ing in arbi­trary, ill-defined results. The com­plex­ity here explodes, quickly turn­ing the programmer’s brain into mush. Dabeaz's look at the GIL patch argues that the locking complexity is a performance killer as well. &gt; The solu­tion is to iso­late most objects. Keep all these muta­ble objects back in the sequen­tial, single-threaded world. Mul­ti­ple processes let you do this. Actors do it too. So do monitors. 
Oh I see this: www.sublimetext.com/forum/viewtopic.php?f=2&amp;t=2633 Nice :) Now to figure out it tab abbrs are fubar as someone suggested below.
You can do this with [markmin](http://web2py.com/examples/static/markmin.html) which provides a markmin2html converter and there are many html2rtf solutions. 
Most Template Engines are not limited to HTML. You can use jinja2 easily to create every text based format you deserve. As the OP needs something for MS Office, I doubt, whether he will be capable with this kind of approach. MS Office document format is still not free and open - so I don't think there are libs that can generate such a compatible file. I could think of using OO.org. One can use PyUno or a templating engine to create the xml based documents (they are zipped).
Yes! I totally forgot that OO.org had a Python engine built in. Will definitely look into this, as I am fairly certain later versions of MS Office will open the .odt files. Thanks for reminding me.
Lambdas are just a way to define functions in-place. He doesn't want to put the rules *in this program*, though. He wants them to be user-supplied. You can't safely execute arbitrary user-supplied Python code.
What you need is called a [template processor](http://en.wikipedia.org/wiki/Template_processor). There are many of these of varying complexity in Python. The standard library includes [template strings](http://docs.python.org/library/string.html#template-strings) in the string library. [Cheetah](http://www.cheetahtemplate.org/) is one of the older third-party template libraries. There is also [Mako](http://www.makotemplates.org/) and [Jinja2](http://jinja.pocoo.org/docs/). I would use one of those solutions, based on whatever criteria you is more important to you (ease of use, complexity, readability of the templating language) and create a template formatted for use with [MultiMarkdown](http://fletcherpenney.net/multimarkdown/features/). MultiMarkdown is a lightweight markup language that can be converted into a number of formats, including PDF and ODF. ODF can then be opened in Microsoft Word with the use of an [ODF plugin](http://odf-converter.sourceforge.net/) and converted to a DOC/DOCX formatted document, or RTF.
&gt; dynamic concepts in general are not too easy to grasp first hand Which dynamic concepts do you think are difficult to grasp? &gt; A nice gentle introduction is closures. There's nothing inherently dynamic about closures. Closure exist in statically typed languages too. From what you've said, I'm not even sure you know what they are, and to be honest it sounds like you might be a little over-enthusiastic about them because you just read about them recently. Externally-specified rules, not being part of the program definition, simply cannot be closures. &gt; All in all, I think it's really silly to shoehorn Python into a static language I don't think anybody even remotely suggested that. 
&gt; Isvara's hardline on eval for python is simply untrue. You can tightly control the locals and globals available in the execution context, limiting access to "dangerous" functionality. It is extremely difficult, and I would not trust anyone to do it correctly. For example, if the evaluation context is to be useful, you might give it a limited subset of functions you have defined yourself. But once you've passed in `fn`, say, as a local, the expression then has access to `fn.__module__`, which has all the globals defined in the module the function was defined in -- including any modules it has imported. There are just too many loopholes to make it a safe thing to do.
This is a great reponse. My overall idea is to have some engine where I pass a few strings (the template's values would be replaced) and a few boolean values (items in the template would be there or would not be there.) Using RTF parsing/manual creation the only thing that's causing problems is the boolean paragraph insertion. I just need something which can retain the template's format, whilst being easy enough to just 'insert' or 'remove' a large section. The main reason for RTF being annoying to use is that a machine generated RTF file is highly confusing and contains heavy markup. My core logic is simple: if $string in line: $string.replace(stringFomGUI) Whereupon for the paragraphs. I have taken the RTF markup in the template file and put it into a file of it's own and inserted a placeholder outside the markup where my code does: if line == $String if self.ui.checkBox.isChecked() == True: line = r'\par' # blank paragraph markup foo = open(text I removed earlier) for text in foo: output.write(text) output.write(line) else: line = r'\par' output.write(line) This overall isn't a problem. It worked out quite well. The proble came from when I went into an Office program and edited the template, all my placeholders got moved INTO the markup, which is understandable since it was saved as part of the document. It's causing me a rather large headache at the moment. 
Komodo also has Vim key-bindings.
Yeah... that surprised me. I really hope it was just a skill challenge, though I can't find any hints of that in the post. One you get even moderately good at a language, you're supposed to know where the live wires are, and not touch 'em. 
Idea: Stop relying on nonfree software. Try LibreOffice and (on Windows) SumatraPDF. Or, if you must remain chained, at least learn to test theories before you spout them--most office programs open HTML without issue. Abiword just did. Failing all else, you could print an HTML document (from your browser) to a PDF file.
%r is the result of that object's \_\_repr\_\_ method. %s is the result of that object's \_\_str\_\_ method. \_\_repr\_\_ is intended to output a string that could be used to reconstruct the object ("If at all possible, this should look like a valid Python expression that could be used to recreate an object with the same value"[1]). \_\_str\_\_ is simply intended for a "human readable" summary of the object - this might be more useful for, say, logging data. e.g., &gt;&gt;&gt; class Foobar(object): ... def __init__(self, mystuff): ... self.mystuff = mystuff ... def __repr__(self): ... return "Foobar(" + repr(self.mystuff) + ")" ... def __str__(self): ... return "Foobar: " + str(self.mystuff) &gt;&gt;&gt; myfoo = Foobar(True) &gt;&gt;&gt; print repr(myfoo) Foobar(True) &gt;&gt;&gt; print str(foo) Foobar: True foo2 = eval(repr(myfoo)) # foo2 is now essentially identical to myfoo &gt;&gt;&gt; print repr(foo2) Foobar(True) The difference is subtle, and far too often I see repr() being used as just an "alternate" str(), which is not really what it's intended to be. [1]http://docs.python.org/reference/datamodel.html#basic-customization
It's not I that relies on nonfree software. It's the companies that I work for. I never spouted anything without testing it, I actually said *I don't know if..* 99% of the software I use at home, in private is open source. All the non-commercial code I write that's of any use to anyone is open source. I don't know if your intention was to sound like an arsehole, but you definitely did. EDIT: Also, if I am creating software for a client, I can't exactly mention to them 'Oh just output the file to your browser and print to PDF...' it's not a solution, that's a workaround. I posted here solely for nicely marked up document languages, and/or experiences people had already within this area.
Kate is quite good editor as well. It's used in kdevelop IDE. Great IDE if you ask me.. but I didn't use it for python so I'm not sure how good is the support.
Why no work with Easy_install? Microsoft Windows XP [Version 5.1.2600] (C) Copyright 1985-2001 Microsoft Corp. C:\Documents and Settings\OneWeekWonder\Desktop&gt;easy_install Docvert Searching for Docvert Reading http://pypi.python.org/simple/Docvert/ Couldn't find index page for 'Docvert' (maybe misspelled?) Scanning index of all packages (this may take a while) Reading http://pypi.python.org/simple/ No local packages or download links found for Docvert Best match: None Traceback (most recent call last): File "C:\Python26\Scripts\easy_install-script.py", line 8, in &lt;module&gt; load_entry_point('setuptools==0.6c11', 'console_scripts', 'easy_install')() File "C:\Python26\Lib\site-packages\setuptools\command\easy_install.py", line 1712, in main with_ei_usage(lambda: File "C:\Python26\Lib\site-packages\setuptools\command\easy_install.py", line 1700, in with_ei_usage return f() File "C:\Python26\Lib\site-packages\setuptools\command\easy_install.py", line 1716, in &lt;lambda&gt; distclass=DistributionWithoutHelpCommands, **kw File "C:\Python26\lib\distutils\core.py", line 152, in setup dist.run_commands() File "C:\Python26\lib\distutils\dist.py", line 975, in run_commands self.run_command(cmd) File "C:\Python26\lib\distutils\dist.py", line 995, in run_command cmd_obj.run() File "C:\Python26\Lib\site-packages\setuptools\command\easy_install.py", line 211, in run self.easy_install(spec, not self.no_deps) File "C:\Python26\Lib\site-packages\setuptools\command\easy_install.py", line 434, in easy_install self.local_index File "C:\Python26\Lib\site-packages\setuptools\package_index.py", line 475, in fetch_distribution return dist.clone(location=self.download(dist.location, tmpdir))
It may be more complicated than what you need, but have a look at ReportLab: http://www.reportlab.com/software/opensource/
Or you could just copy six.py into your project; it's only one file.
[PyGUI](http://www.cosc.canterbury.ac.nz/greg.ewing/python_gui/) looks to be one of the easiest of the bunch. Simpler than PyQt/PyGTK/PyWx, but more modern than tkinter. 
I've actually seen that and it may possibly be what I use! Thanks anyway, someone else might see it.
The easy answer here is to use the 'mail merge' features of MS Office or maybe Open/Libre Office. First make a spreadsheet with all of the document values and options across columns. Now place your values in the rows below. (In Word) select the 'Mail Merge Wizard' and write your document, inserting values where appropriate (for the optional/conditional paragraphs you can use 'IF'/'ELSE'/etc). Next you can step through your list of recipients and preview everything before producing output (print job, email, save files, PDF, etc). Be sure to test before doing anything final - I have witnessed more than one company make themselves look dumb with Mail Merge.
I thought about this, and I even offered it as a solution but the company is asking for a standalone application to do it. If they want to burn money allowing me to do it, then so be it. Also, as the documents being created are financial of nature, they wish to have it where you have to log in etc...
If you have a good reason to be extending `__builtin__` (and simplifying compat work between Python 2 and Python 3 is one, especially if you need `bytes` in just about every file of the project), there's nothing wrong with adding missing stuff to `__builtin__`. `gettext.install` does exactly that.
&gt; if you haven't answered "no" somewhere above... Zeus help you. So should `gettext` be banned from the standard library? Or should Python 2.6 and 2.7 be banned as well, for that matter? They did add a `bytes` alias to builtins after all. And one completely and fundamentally incompatible with Python 3's `bytes`. 
Heck no. That'd be silly. My main call was for people to use a little common sense when working with powertools... just because I said that type of action was exceedingly dangerous doesn't mean I was calling for the banning of all libraries that do it - if there weren't *some* legit reasons to modify it, \_\_builtin\_\_ probably wouldn't exist. The reason messing with \_\_builtin\_\_ is dangerous is because you're globally affecting the behavior of all python code within the interpreter, so you better not break any assumptions imported code has about their environment. In your specific example, that's not what gettext does at all. For one thing, it's part of stdlib, and everyone's python code should expect and be able to handle any behaviors that are part of stdlib. Secondly, gettext only *adds* things to \_\_builtin\_\_. It adds a restricted of names, which aren't used by anything besides gettext. So it won't be conflicting with anything but itself. Finally, it's actions don't change the call signature of even it's own builtins in any meaningful way, so it's actions are unlikely to break code. So pretty much nothing I said applies to gettext's behavior... the answer was "no" starting with the 2nd list item. --- edit: Also, perhaps you missed the second sentence of my post, where I pointed out the proposed patch breaks ALL uses of "isinstance(val, bytes)" within the interpreter where the patch is applied. Python 2/3 compatibility is definitely not a good enough reason, if the side-effect is completely breaking tons of code under 2 AND 3 (if the change weren't global, it wouldn't be *nearly* as bad an idea). gettext's behavior doesn't come close to doing something so problematic. Of course, everyone's free to do as they wish with their own interpreter instances - but mine won't be importing any code with such poorly considered consequences.
Get into the business of writing software for money then write it off against your tax bill. Simples.
To respond to your edit which added the `bytes` example - Huh? Continuing to state that code should be "banned".. who's calling for that? And how would you even go about it? That makes so little sense it's not even wrong. In any case, you're missing the point: It's not touching \_\_builtins\_\_ that's innately bad. What's bad is a third party library or an app changing the entire interpreter environment in a way that violates reasonable expectations coders had when writing against a given python version and stdlib. That's why any examples drawn *from* stdlib or python don't apply. Though in the larger sense of things - *yes*, the changing in `bytes` behavior from 2.6 -&gt; 3.0 has caused expectations problems... which is why 2/3 compatibility is an issue. But that's at least controlled, and needed for the language as a whole to progress... and it *doesn't break existing code*.
Understood - in that case I would look at doing it all in HTML with a web app. If you must have a heavy 'document'... I have successfully implemented what you originally described by making templates in OpenOffice (ODTs are just zipped xml), adding/filling markers, then re-zipping to a temp folder and instructing OO (in 'headless' mode) to save a PDF via the UNO bridge. At the time this approach was easier than using ReportLab because I was dealing with several formatted/tabled documents that were changing often.
In addition to what others have said, here's a few examples that illustrate what built-in types do: &gt;&gt;&gt; print repr('Hello') # binary string type 'Hello' &gt;&gt;&gt; print 'Hello' Hello &gt;&gt;&gt; print repr(u'Hello') # unicode string type u'Hello' &gt;&gt;&gt; print u'Hello' Hello &gt;&gt;&gt; print repr(1L) # long type 1L &gt;&gt;&gt; print 1L 1 &gt;&gt;&gt; print repr(datetime.date(2011, 8, 17)) datetime.date(2011, 8, 17) &gt;&gt;&gt; print datetime.date(2011, 8, 17) 2011-08-17 So for built-ins, it usually gives you a string representation of the respective literal or the function call that would create the object in question. Of course this won't work for mutable types that can't be created with a single call (i.e. when the `__init__` call doesn't take all the arguments necessary to recreate the object). In any case, repr() is more of an internal representation whereas str() and unicode() are string representations that might be useful for an end user.
I'm in the business of writing software for money. Writing it off on taxes just means I won't pay taxes on the income used towards buying it. Which for my tax bracket still means I'm paying $300 for it.
One of the core philosophies of the python community is that "we're all consenting adults." If I can modify `__builtin__` and I have a good reason, why do you care? If it were a truly bad idea (like, say, open classes), it wouldn't be supported at all. 
Hmm.. sounds like you need to get a better accountant. That $300 should be $300 off your tax return.
Would I be able to take a peak at your source code? And/or a screen shot of the document you were changing? I want to know if it's a similar style. A web app is a bit out of my league at the moment as I've mostly programmed with PyQt4/Python/parsing kind of stuff so the web side of Python hasn't been touched at all. It may be a good time to get into it though. Although I've mostly written and debugged the GUI interface and it would be a pain to just throw it away. Thanks for your reply, I cannot wait for my holiday time so I can really devote some quality time to researching this (programming is not my main task at work.. I'm using this opportunity to show that it should be.)
Dear Lord in HEAVEN. DO NOT USE RTF DOCUMENTS. I'm currently maintaining a piece of shit system that uses RTF documents in this way and I repeatedly want to kill myself over it. It might have something to do with the fact that they chose to use Word RTF, which is an abomination to all that is holy, but RUN AWAY. Friends don't let friends use RTF. You can format INTO RTF. But don't store them that way natively.
This is the sole reason why I made this thread. After a nightmare of re-writing a portion of my parser/dumper because I'd changed the colour of like three lines of text I realised that it'd be a hellish future of maintaining this software and/or implementing document changes down the road. All in all, I want a file format that's semi-native to the business type XP environment that's human-readable and logically marked up. There's a great response here about using OO Uno, but I'd see how I'd have to package that before I totally commit to it, but it looks promising.
&gt; If it were a truly bad idea ... it wouldn't be supported at all. That's not true even as a philosophy, much less in practice. Since we're all consenting adults, python doesn't hold your hand. It makes only the most formulaic attempt to stop you from implementing all kinds of bad ideas, just so we can explore the space of possibilities. You can come up with wonderful elegant pieces of code, but the flipside is that you can reliably and efficiently shoot yourself in the foot. The linked idea is one of the latter ones. The community cares because we don't like seeing people give others bad advice, like this blog did. I'm particularly motivated because this precise idea, in the precise way it's coded, is *really* bad advice. --- Just cause I like people having *true* freedom, and letting them learn by picking up the bits lying all over afterward, here's a couple of dangerous and powerful bits of meta-python: * `__builtins__` - affect all code in all libraries, everywhere. sometimes that's needed. but usually, you want to isolate your changes to your own libraries. * metaclasses - lets you create implicit invisible behaviors that you won't expect when you look at your code 2 years from now. complex to work with, even when they *are* the only solution. but sometimes they are, so they exist. * `sys.modules` - you can really mess with python, putting dynamic objects in place of stdlib modules, doing all *kinds* of havoc (try replacing the 'sys' module for real fun). Hardly ever needs touching... but sometimes you need to use this for making a module appear to have dynamic contents, many other uses. * `ctypes` - with this, you can crash python. even better, you can load the python dll, get a reference to the C-level struct behind `bytes`, and monkeypatch your own methods into all `bytes` instances at the C level, without touching builtins. *Really* change global behavior. * intercept the parser, mess with the parse tree via `ast` - do things like implement custom language additions. One person did annotations - those made it into 3.x. One guy did 'goto', luckily only as a joke. * stack frames via `inspect` - you can write functions that reach up to their caller (or caller's caller) and modify the local scope. allows near incomprehensible code if abused. really bad idea. Also great for writing declarative languages using classes, writing debuggers, and other neat features. --- edit: totally slipped my mind - open classes. you say they're a bad idea? All pure-python classes are open. You can even dynamically modify what classes they *inherit* from. Sometimes, it's useful. Don't mean it's a bad idea the rest of the time. Only classes that can't be modified after the fact are builtins (and I mentioned how to do that above with ctypes).
Python certainly does not allow built in types to be modified: In [3]: str.mymethod = lambda x:'nope.avi' --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-3-c79f23c30186&gt; in &lt;module&gt;() ----&gt; 1 str.mymethod = lambda x:'nope.avi' TypeError: can't set attributes of built-in/extension type 'str' I suppose I should have qualified that, but given the context, it should have been clear -- most folks with a mote of experience with the language would know that you can modify an existing class. And your list of "dangerous" bits and why they're "dangerous" isn't very convincing. &gt; The community cares because we don't like seeing people give others bad advice, like this blog did. I'm so motivated because this precise idea, in the precise way it's coded, is really bad advice. You represent the community? I'd happily agree that the advice from Mr Cohen could be better (not going so far as to label it "really bad"). But to extrapolate from that and generalize that all of these other areas of the language and interpreter are somehow harmful and should be avoided is foolish. As in "a foolish consistency is the hobgoblin of small minds." If you care about freedom as you say, then you shouldn't be so concerned with telling people what's right and what's wrong. Let people learn from their own mistakes and all that. 
You've got the `print obj` and ``print `obj` `` reversed there -- ``print `obj` `` prints the `__repr__()`, not the `__str__()`.
&gt; What is a good method/library for parsing/creating RTF documents? I'd suggest LibreOffice. In terms of an interchange format for complex wordprocessing documents then you probably won't find better than OpenDocument. You could convert the RTF to ODT (a ZIP of XML), modify it, and convert back to RTF. To use LibreOffice you can run it as a daemon. Under Debian-based distros just apt-get install docvert-converter or docvert-openoffice.org to get a LibreOffice/OpenOffice daemon. Then use PyUNO (which uses temporary files) or Docvert (which uses streams) to connect to it and do your conversion.
http://forums.thedailywtf.com/forums/17.aspx - nuff said!
Is this for a law firm? If so, let me know.
*whhoooossshh*
Re: bad advice - Not everything said has to be completely for or against a particular topic. I *never* said those features I listed should be "avoided at all costs". I said *this feature* (`__builtins__`) used in *this way* (globally replacing the `bytes` type) was bad advice, since it had too many globally negative consequences, when simpler solutions exist that have far fewer. In another comment, I even listed a direct negative consequence of Cohen's idea: it causes a TypeError for every use of `isinstance(value, bytes)` in any code you write or import. That's not a subjective assessment that people can disagree over... this idea has the exact same effect as telling people to insert `raise TypeError` at random spots in their code. I find it really hard to consider that an acceptable tradeoff for 2/3 compatibility. --- Re: community - People are free to learn from their own mistakes, but when an otherwise extraordinary programmer gives some misleading advice... people are more likely to think that they followed the advice wrong, not that the advice was wrong. So others offered their own advice, warning that this wasn't as good advice as it seemed. It's self-evident that no one speaks for every last member of "the python community", and misleading to say I made that claim. I made a claim about the nature of the community: that most people were motivated to provide good advice to help other people. I didn't think that was controversal enough to require evidence, but since you disagree with it: I present stackoverflow, r/python, and tons of mailing lists, where you'll find lots of people sharing their experiences, and discussing programming problems with eachother. I'd argue they're motivated to give good advice, because there's no other reason for large numbers of people to bother listening. And we are *all* part of that community, so we all get to offer advice. --- Re: dangerous features - At no point in my comments did generalize and say my list of areas was harmful and should be avoided. That's a strawman of your own invention. I called them "dangerous and powerful". There's a big difference... First, I listed a number of bad ideas - making the builtin classes open by using ctypes to modify the type dictionary at the C-level, using access to frames to modify the caller's local scope without evidence, replacing the `sys` module itself, etc. If you don't think those are bad ideas that make code unstable and unmaintainable, that's one reason I listed them... so people could go and find out for themselves just how tangled those behaviors can make your code. But I didn't just list the bad ideas, I listed them grouped based on the features required to implement them (builtins, ctypes, etc)... and then showed why (despite supporting a lot of bad behaviors), those features were left in because they support some good behaviors as well. The reason I listed all that was to counter your argument that "if it were a truly bad idea... it wouldn't be supported all". Those were a list demonstrating why python's permissive philosophy allows bad behaviors in, because otherwise it would eliminate desirable behaviors. A feature being present it no proof it can't be used to achieve bad behavior, nor is support for a behavior proof that it's a good one. I'm not sure how you made the leap from that to claiming I thought the features should be removed, when the whole point of my comment was to argue that they *shouldn't* be remove, but should none-the-less be treated with care and used judiciously. In other words, "dangerous and powerful". 
Drawing pixels via [pygame](http://pygame.org/) seems like a reasonable way to achieve what you're doing. In pygame, draw the pixels via [direct array access](http://www.pygame.org/docs/ref/pixelarray.html) as the basic drawing commands will probably be too slow for your needs.
Out of curiosity, are you making something that spins or moves very fast?
You should probably phrase your problem in terms of vectorized math, then output the images via pygame. Straight up Python won't do pixel-by-pixel manipulations very quickly, but if you can think of it as a convolution, it can be very fast.
The answer really depends of what, exactly, you are trying to achieve, how many colors you are going to need, what kind of pixel manipulation, is it on the entire screen or only a few regions, is it bounded or unbounded, etc.
Your idea sounds interesting, but I would have no idea even where to start. Could you suggest an article or something on this concept?
Agreed - a pygame pixelarray should be pretty quick. If you're doing lots of data manipulation before writing the pixels that part might also be a bottleneck. I don't think you can use PyPy with pygame yet, or that would be an interesting path. I would start with python and pygame, and then profile it. Then you can see which parts are slow, and think about other optimizing strategies, like tweaking how you store + manipulate data or even perhaps pushing some of your lowest level code into a C extension. 
Once you follow the advice given by others, you may find that a lower level language is still more suitable to your optimization needs. Try direct OpenGL commands in C++ or D language.
Awesome work! Definitely thinking about replacing my old selenium code with splinter. One thing I find I definitely miss from Capybara though is [has_content?](http://rubydoc.info/github/jnicklas/capybara/master/Capybara/Node/Matchers#has_content%3F-instance_method). It's really useful for just checking words and phrases on a page. **edit**: Just noticed that the main example tutorial uses the function *is_text_present*, but I didn't see any mention of it in the [finding methods](http://splinter.cobrateam.info/docs/finding.html) docs. Any chance that could be updated / we could get a nice auto-generated docs page?
Wouldn't optimization in Cython also be just as good?
Well, it looks like Pygame has NumPy integrated now, so I would start there. I did some Pygame a few years ago, but I haven't used NumPy with it, so I can't personally vouch for that. http://www.pygame.org/wiki/FrequentlyAskedQuestions Like stoph points out, Python may not be up to the task of "tens of thousands of pixel color changes per second", but this is where I would start with trying to make that happen in Python. 
Well... first of all, the author probably doesn't want to do tens of thousands of color changes per second. Most monitors can only display up to about 80 frames per second. But if they need to do intense computation to figure out what needs to be displayed, there is still plenty of room to do that in C++ or whatever compiled language floats your boat. If you really love Python, you could write a DLL interface to C++ to offload the computationally intensive parts. I suppose the submitter could have meant "tens of thousands of pixel changes per second" in reference to the resolution of the rendering, as opposed to the frame rate. Still, there's nothing wrong with recognizing Python's limitations and using C++ where appropriate.
Wouldn't a DLL interface in C++ be a level harder than Cython though? (I'm not talking about CPython...I'm talking about Cython.) Cython allows static typing, massively speeding up any kind of computation you need to do, while maintaining a python-like syntax. http://prabhuramachandran.blogspot.com/2008/09/python-vs-cython-vs-d-pyd-vs-c-swig.html There's a good comparison -- C++ and Cython are in the same ballpark while allowing the use of Pythons native containers and (most of the) syntax.
I think we might be talking about the same thing. Calling fast, compiled code from Python sounds a lot like Cython. Cython might put a pretty wrapper on things but I consider both approaches to be the same.
Here's an awesome example of Cython code: http://wiki.cython.org/examples/mandelbrot
That's pretty sweet. I am not a huge Python expert but it sort of reminds me of how RPython is using a restricted language to boost speeds on core functions in PyPy.
Sorry, I wasn't clear. I meant the entire concept of "phrase your problem in terms of vectorized math". 
I think I've seen PyPy projects using pygame. pyopengl definitely doesn't work yet though.
Basically, you do operations on arrays of values all at once, instead of one single value at a time. Modern CPUs are optimized for this, so you can significantly increase the amount of work done in the same amount of time, but you are limited to certain mathematical operations. [Here](http://www.scipy.org/Numpy_Functions_by_Category#head-6c9145865f4bf85cdbeaa90ee8a70ae1edb9bf21) is a list of the vector operations NumPy supports, and [here](http://www.scipy.org/Numpy_Example_List_With_Doc#clip) is an example of how you'd use one of them.
I don't have the code but the output was three kinds of detailed job applications and my client wanted them all looking like the original. The setup took some experimentation: Make ODT file in OpenOffice / LibreOffice (this is your template). Put place marks in your file using either OO or a regular text editor (after unzipping). I used something like [[[!!! FIELD_NAME !!!]]]. Get OpenOffice running in headless mode (the '-invisible' option) - I used an RPM titled 'openoffice-headless' which was current and available at the time. Get a pre-made document converter program which can open the OO doc and save it in another format with OO (perhaps unoconv?). Every time you need a document copy the ODT to a temp folder, open the xml file and search/replace/close your special fields. Zip it up and pass it into the OO document converter. Get your file back, serve/save, delete the temps.
That sounds right to me. Also, a small, unrelated point is that raw_input() can take an argument which is the prompt; that is, you can pass the string of the question as an argument instead of printing it before. 
search for that one offered by MIT
Oh yeah that was one of the extra credit exercises in LPTHW, I made all the changes :). Thanks for the tip! 
If you used the string as a literal in your program, you'd enter either `'6\'2"'` or `"6'2\""`, escaping whichever quote character is used to contain the string. Otherwise it would raise a syntax error caused by either a string literal adjacent to a number or an unterminated quote.
Many thanks! I would have never made that leap. I still think of vectors in the physics sense.
How come when I do something like print "height %r" % "6\'1\"" output: $ height '6\'1"' why does it change the string back to using single quotes and not double quotes? and \" still isn't being escaped.
There's no need for the first escape since you're using double quotes to contain the string. On the other hand, Python represents (i.e. repr, %r) the string using single quotes, so it has to escape the single quote character that's part of the string. Otherwise if you tried to `eval('6'1"')`, it would cause a syntax error because the string literal '6' is adjacent to the number 1.
Depending on what you are doing you may want to use your GPU. Pyopengl has a decent APO for compiling and using GLSL shaders. The performance increase can be several orders of magnitude.
Pretty much anything that talks to C and hasn't been hand-converted isn't going to work.
A 800 * 600 image has 480k pixels and can be refreshed easily at 25Hz using opencv or probably even PIL. They both support Numpy. Treat your image as a numpy array and make sure all the operations you make on them are actually made on the array, entirely or sliced. NEVER USE LOOPS. You can make everything you want on entire arrays but it takes some mental effort to come up with the way to do it if you have not experience on it. For a safe bet, I'd go numpy &amp; scipy + cv. They both work very well with python 2.7 and they'll let you do more than what you want to achieve. They all have sections on stackoverflow too.
pyglet works on pypy by the virtue of only using ctypes opengl
Correct. And all the snake stuff is completely inappropriate.
The case you use %r is inapporpriate, keep in mind %r is for debugging not for end user. You shoud use %s to format this. The " is not backslashed because the string is wrapped with '. '"' is correct. 
Thanks for the tips :) I was just testing to see if %r behaves differently than %s, I'm pretty new to python and even with all the help or explanations on the difference, it's still hard to wrap my head around it right now.
... which is also why it's pronounced as such.
HR Outsourcing.
you are right corrected it, thanks a lot
I've been using http://appyframework.org/pod.html for invoice generation in my project. Works ok so far, but sometimes embedded images get removed after I open document in Open Office and try to modify or print it.
I also recommend [this book](http://www.amazon.com/Programming-Python-Prentice-Software-Development/dp/product-description/0132354187) In all honesty, PyQt4 is actually the most logical and powerful GUI framework I have ever used. Qt's vision is just brilliant, the slots/signals method is pure bliss when setting up the GUI actions. I'm not sure what you mean when you mention 'Enter to assign variable'?
I thought using super() on your __init__ was frowned upon nowadays? It was definitely mentioned in *Learning Python*, but I can see in the Qt4 book I am reading that it is used almost exclusively when initialising a subclass. Which is it and why? I.e. I think in *Learning Python* it mentioned to call the class explicitly. class MyWidget(QWidget): def __init__(self): QWidget.__init__(self) EDIT: Typo EDIT2: I much prefer to use the selectionChanged() signal EDIT3: Or whichever sends a signal when the focus changes... gah can't remember off the top of my head.
I use SciTE. Change the code a little, hit F5 to run it, see what changed (GUI) or the output of some print. I CTRL+Break to break the script if blocked. Then I change the code a little more. I can also auto-complete easily and select between available names in the global namespace or in the local (file) namespace. When my script throws and exception I can quickly open ANY file involved at the specific line involved in throwing that exception. All this is beautifully color coded for my convenience. As silly as it may sound, I have not found a simple OS X editor that lets me do these few things. Some of them do some of the things but I have yet to find one that does ALL of them. :( Most cross-platform editors I've tried on OS X seam to ignore OS X specifics and just choke on basic details: e.g. Komodo Edit choke on files with space in the path OR Editra bind Command+Space to "Word Completion". 
Yes, this is somewhat of a drawback of Python. Py2Exe packages all the libraries that you use and are required for the program to run. I made a 'Hello World!' app using PyQt4 and 'compiled' it with Py2Exe and the total folder was around 70mb. Ridiculous. Although, considering that it wouldn't get much bigger if it were simply *just* using the PyQt4 package it's ok really.
As another comment to this, all I gotta say is: dat code PyQt4 is beautifully simple.
I think mostly, when you learn the syntax differences of using the Python style of Qt, and the C++ way, you can mentally convert the code from the tutorial to the Python code. Just a matter of finding a single example in both C++ and Python and going from there.
Pronounced as...?
&gt; why does it change the string back to using single quotes and not double quotes? and \" still isn't being escaped. It doesn't "change anything back". The string represented by a string literal `"6\'1\""` contains 4 characters. While the literal itself contains 8 characters (including outer quotes). Think of escapes in the string literal as of instructions on how to build the string. You can't just put a literal quote there, so `\"` is your way of saying "put the quote in there". Then the interpreter executes your instructions and of course there's no trace of them left in the result. Also, there is a lot of ways you can make such instructions, for example `"\066\x27\x31\042"` produces the same string. Then, when you ask Python to print the representation of the string, it takes the raw string and replaces dangerous characters with instructions on how to build them. Moreover, it even chooses between single-quoted and double-quoted strings, depending on the content. Of course the reconstructed string literal needs not to bear any resemblance to the original one.
[Such](http://www.youtube.com/watch?v=-rutX0I6NxU&amp;feature=player_detailpage#t=10s). Though that's mostly a matter of taste (and silliness), I guess -- even the Pythons were inconsistent about that. Also, with the language's logo now being a cross of snakes, I guess the origins don't matter as much any more. Though I would wager that trademark issues played a role in that decision.
Thanks for the explanation, i'm understanding it a lot better :D.
To visualize Langton's loops we were using OpenCV for Python and friend of mine succeed with quite good speed.
Here's another example, which performs one step of the Game of Life in a fully vectorized fashion: def iterate(Z): # find number of neighbours that each square has N = np.zeros(Z.shape) N[1:, 1:] += Z[:-1, :-1] N[1:, :-1] += Z[:-1, 1:] N[:-1, 1:] += Z[1:, :-1] N[:-1, :-1] += Z[1:, 1:] N[:-1, :] += Z[1:, :] N[1:, :] += Z[:-1, :] N[:, :-1] += Z[:, 1:] N[:, 1:] += Z[:, :-1] # a live cell is killed if it has fewer than 2 or more than 3 neighbours. part1 = ((Z == 1) &amp; (N &lt; 4) &amp; (N &gt; 1)) # a new cell forms if a square has exactly three members part2 = ((Z == 0) &amp; (N == 3)) return (part1 | part2).astype(int) You might also want to try to combine it with [this](http://scipy.org/Cookbook/GameOfLifeStrides) to reduce the number of Python-to-numpy calls. Also, google "numpy cellular automata", "numpy convolutions" etc for more examples.
Have done quite similar thing: I ditched real-time and rendered an amount of .png files which I later stitched automatically using ffmpeg. 
It might help to see the character list: &gt;&gt;&gt; list('6\'1"') ['6', "'", '1', '"'] &gt;&gt;&gt; list(repr('6\'1"')) ["'", '6', '\\', "'", '1', '"', "'"] 
Probably not a practical solution, but out of interest, PyPy recently had a demo that it was fast enough to run some real-time image processing, written in pure Python. http://morepypy.blogspot.com/2011/07/realtime-image-processing-in-python.html
that does help, so what makes python put single quotes on the outside when I originally put double quotes?
`__builtin__` is a bit different. You're welcome to do whatever you like in your own code, but if your code modifies `__builtin__` when I import it, it can break bits of my code that have nothing to do with your code. I'd agree with warbiscuit - there are times when it could make sense to modify `__builtin__`, but not often and not without careful thought. Doing it for a quick convenience shim does not seem like good advice.
If you're comfortable with C, you can [see for yourself](http://hg.python.org/cpython/file/b4ccf8e1fdba/Objects/stringobject.c#l941) (stringobject.c, `PyString_Repr`). The string object doesn't know what quotes you used to form the string literal. It just has the underlying character array and prefers to represent it in single quotes. However, smartquotes is enabled by default, so it will switch to using double quotes if the string contains a single quote but not a double quote. For example, let's remove the double quote in 6'1": &gt;&gt;&gt; list(repr('6\'1')) ['"', '6', "'", '1', '"'] &gt;&gt;&gt; print "%r" % '6\'1' "6'1" 
[explainlikeimfive](http://web-ngram.research.microsoft.com/ngramwordbreaker/break.svc/?p=explainlikeimfive&amp;format=text)
As long as the files you're importing are in the same directory as the file you're running it should work. I would definitely try running it from the command line instead of notepad++. 
sys.argv is a list. You can get individual ones by indexing this list. I.e. to receive the second in the list use: print sys.argv[1] If you're creating a CLI, you're best off using something like: if '-t' in sys.argv: #code which uses the -t flag There is probably other ways to do this but this should get you started. As for the error: Since: script, firstname, lastname = argv Is really doing: script = sys.argv[0] firstname = sys.argv[1] lastname = sys.argv[2] Then when you supply only two variables, you get an index out of bounds error. This is again because sys.argv is a list.
oh thanks! unrelated question, what does it mean when a file is open in the script example: open(filename.txt) does it just mean that the file is now available for use?
Yes. There is a huge section on file I/O on the standard python documentation website. [Here](http://docs.python.org/tutorial/inputoutput.html) Have fun and if you have any other questions come back.
Thanks
I was skeptical to see yet another HTTP lib introduced, but I have to admit that this one is looking good. If nothing else, the author's willingness to actually write documentation and accept patches puts it far ahead of the other options. It still needs plenty of work, but it definitely shows promise.
That examples page you posted rocks. Makes me want to write something, anything at all, that uses all of the operations on that page.
if you want to deal with parameters, check standard library optparse
Or rather, [argparse](http://docs.python.org/library/argparse). It is an easy migration, and it handles positional arguments and subcommands better.
yup, that happen to me using a Hello World app with wxpython and py2exe, i tried using an app which i forgot the name that helps to compress it by using a different configuration, but i still ended up with 18 mb of files, but than again if the person already has the libraries you will just have the kb's of the .py file 
Yes, indeed. There has to be a better way of packaging Python applications. The current method is just insane.
hmmm, going to read on that one. works for mac? x_x 
is mostly because of the dlls's and when using gui well you got twice the files the python libs + the gui libs and the dll's for vm python i guess the only way to compress it a little more is by using a nice gz compression that is if you planning to sharing your app, cuz is just lame showing someone an app that originally was 20 kb and ended up been 20 mb x_x
Well, in all honesty it never *was* 20kb. It still requires all those libraries and DLLs to run even on your own system. So the file size is just spread out more. What I'm saying is that there needs to be a standard and non-insane way of going from .py/pyw -&gt; exe that's customer/non-technical user friendly. A good method I've scouted is: .py/pyw py2exe Inno Setup tools Seems reasonable, and somewhat professional looking. I've not used Inno Setup so I'm not sure how well it works.
i've used inno setup it creates the installer, it organizes the files beter in to one .exe file you can set a particular directory to be installed when the installer is executed but it did not compress more of like organize it better than rar it up a faster py2exe method is using Gui2exe it lets you create the settings ina more easy way this what i used you can compress the files instead of having all the tiles it hardcode the dlls in to the same exe sadly it only allows up to 3 Gui2EXe http://code.google.com/p/gui2exe/
http://pytools.codeplex.com . free &amp; open source from... Microsoft!
Great, I'll look into it. Thanks.
I believe this is one area where your exact python version makes a difference, for one thing
In "except NameError", you say I want to catch any exception of "type" NameError. In "except e", you say you want to catch any exception of "type" e which is an *instance* of NameError...
The one thing that mail doesn't address is the unexpectedly slow performance that can arise when mixing I/O- and cpu-bound threads, if on a multi-core system
this is correct. Likewise, the below works for reasons which are now obvious: &gt;&gt;&gt; try: ... raise e ... except type(e): ... print "an exception flew by" an exception flew by &gt;&gt;&gt; 
What is the error?
Good point. Python 2.7.2 (default, Jun 20 2011, 14:47:51) [GCC 4.4.5] on linux2 
The constructor doesn't take a port number as a parameter. That's done in the connect function. Try this instead: ftp = FTP(host=host, user=user, passwd=password) ftp.connect(port=port) ftp.login()
Ah. So the constructor just creates an instance of ftp but doesn't actually attempt to connect then samething with login()? Thanks for responding!
Thanks. I looked at the [docs for the try statement](http://docs.python.org/reference/compound_stmts.html#the-try-statement). It says the following which is in sync with your comments. &gt; the clause matches the exception if the resulting object is “compatible” with the exception. An object is compatible with an exception if it is the class or a base class of the exception object, ... Ok, so that's the final word. The doc says I have to provide a class if I want to match. But then why would python allow me to monitor for any exception of "type" e. Is it even possible to raise such a thing? I'm guessing python can't be too picky because it still has to support (deprecated) string exceptions.
No, it's not possible to raise something who's type is e, however Python doesn't try to evaluate the "except [type]" unless an exception is raised, which is why: &gt;&gt;&gt; try: ... raise TypeError ... except FIZZYWORPBANG: ... pass raises an error, but &gt;&gt;&gt; try: ... pass ... except FIZZYWORPBANG: ... pass is fine
fyi: you have some extra replies here.
God damnit, I thought the thing was "502, it went through, 504 send some more". Fucking transactions + HTTP, how does they work?
I've never posted my code up like this before, but I've got a need for some extra eyes on this code. First, I know it needs polish, this isn't a production ready build, and my commenting inside the code has been abysmal. So. onto the problems I'm currently trying to squash (and failing to squash). A few deadlocks / possible race conditions occur in a few cases that I'm having trouble coding around. Specifically if the threads terminate badly without cleaning up after themselves in the 'subdirQ' Queue it can lock the execution of the function and leave me hanging whether or not there is anything left to do. Also the ctrl+c capture sometimes sends the code into the wild blue yonder requiring a ctrl+z and kill -9 for it to go away. For the curious I'm using a test bed of fake data copying from a ./src to ./dest. This includes a few files in the root of ./src, three folders with files of various sizes included in them. These files were generated either with a 'finger' command or a 'dd' from /dev/zero into a file target to give me some variety while I tested. edit: I just realized this should be posted as a 'self' post, my bad. edit 2: I believe I've exorcised this issue with a few tweaks to the thread setup. There does seem to be an overtly long delay from the threads responding to a ctrl+c event while they wrap up their loop execution but they do quit correctly now. Now to start cleaning up and fixing the total lack of comments.
I know you're looking for specific help with the code in question, but it's a total mess, man. Read PEP8. Clean it up a bit, comment out entire sections to ensure the basics work like you think they do. Nobody is going to fix a bug hunk of code like that for you. Before making it threaded, make it work. Before calling out to rsync from python make sure xargs + rsync doesn't do the entire job better.
this was it right here. directly after initialization of the types (during module initialization), I populate some PyTypeObject pointers. I can then directly compare Py_TYPE(obj) with those pointers with success. THANK YOU
I've spent a bit of time looking into spooling out rsync to do this, and sadly the recommended solution is this. But I've yet to find anyone actually implementing it publicly. Which is why this even exists. I actually had this all functioning fine until I decided to re-implement it as actual threads objects so I could add ctrl+c handling. I'm pretty much back to where I started now, but with ctrl+c working in most instances and the system dead locking in some specific instances. As for xargs, I've never even seen it before. And it could be useful if my shell foo was up to snuff enough to do that. However I'm not sure it does the same thing as what I'm trying to do anyway, unless it's running those multiple commands in parallel instead of one after the other.
as mentioned elsewhere, [argparse](http://docs.python.org/dev/library/argparse.html) is probably a better way to go.
 &gt;&gt;&gt; import ast &gt;&gt;&gt; ast.dump(ast.parse('if stock(pens) + stock(pencils) &lt; 10 : alert')) "Module(body=[If(test=Compare(left=BinOp(left=Call(func=Name(id='stock', ctx=Load()), args=[Name(id='pens', ctx=Load())], keywords=[], starargs=None, kwargs=None), op=Add(), right=Call(func=Name(id='stock', ctx=Load()), args=[Name(id='pencils', ctx=Load())], keywords=[], starargs=None, kwargs=None)), ops=[Lt()], comparators=[Num(n=10)]), body=[Expr(value=Name(id='alert', ctx=Load()))], orelse=[])])"
Hows this handle forms? edit: I mean using mechanize I can do something like br.open(url) br.select_form(name) br['email'] = email rsults = br.submit() Which is really easy &amp; nice. 
Can't wait to have something like this in py3k
[poster image](https://github.com/glibersat/Zen-Of-Python-Poster/blob/master/zen-of-python.png)
Interesting article! I'm pretty confused as to why the accepted answer on SO has zero points though.
Except for ctypes
I don't understand the point of using continuations or defining your own stack. They both just seem to emulate the behavior of the callstack.
Well, his first major point is incorrect: [len is O(1)](http://wiki.python.org/moin/TimeComplexity), the list keeps track of its size. The improvement comes from the simple removal of unnecessary code, not because the unnecessary code was O(n). And then he goes and uses list.reverse() so that he can use list.pop() instead of list.pop(0), apparently unaware that list.reverse() is just as expensive as list.pop(0): it still needs to rewrite the whole list, and is therefore still O(n). And finally he goes and writes a cps version with trampoline to be faster still, again unaware that [the reason tail-calls exist is to _recover_ the efficiency of the iterative version](http://en.wikipedia.org/wiki/Tail_call#History) (reusing the stack by jumping to the next function's code directly rather than making a full function call), and that a trampoline is typically the inefficient hack used when you can't implement a true tail-call, but still want the bounded stack.
Yes, which they're eager to use of late.
- on `len` : crap, sorry. Thanks for the correction ! - `list.reverse` : I know the reverse is linear, and its use is intended. It allows me to switch from a quadratic merge (the `pop(0)` was in a loop) to a linear merge. - I'm afraid [there is no builtin tail call optimization in Python](http://neopythonic.blogspot.com/2009/04/tail-recursion-elimination.html). Which is of little matter, by the way, because what surprises me is that the (non-tail)recursive merge sort is faster than both tail-call-optimized versions. Naturally, I wouldn't dream of doing this in e.g., Ocaml (which has built-in TCO : I would have stopped at the cps version).
I would recommend reading the Zen of Python and trying again.
They would emulate the behavior of the call stack if Python had tail call optimization. [Which it does not](http://neopythonic.blogspot.com/2009/04/tail-recursion-elimination.html). Hence my naive question : how is the non-tail-recursive merge faster ?
Thanks. :)
Reddit comments are so much easier to work with than discus :p re: list.reverse, yeah, my mistake. Still unnecessary though, and the constant factor difference it makes will be significant in the total running time given the small number of items. re: "tail-call-optimized", that was sorta my point: it's not "optimized". You're doing manipulation on a reimplemented stack, then returning a function, doing a instance/member check (callable), and calling another function. This is much more work than a simple function call (which is itself more work than a loop would be, on cpython at least). Also, re: timsort, it's not _just_ a mergesort, it falls back to insertion sort in all the right cases :p If you're interested, I'll do up different iterative and tco versions, hopefully to make the impact a bit clearer (there's some confounding factors here still).
Great! Thanks for pointing it out. And once again I realise that every single module in the standard library is worth a look ....
Oh, just noticed; one of your "TCO" optimized versions is actually an iterative implementation, not a recursive one :p
Python3 support is in the pipeline!
Yeah, there are a ton of hidden gems in there, so it can be really hard to know where to look.
Actually, constructs like that are exactly why I'm not jealous of perl. What you're trying to achieve could just be rewritten as: for line in itertools.chain(*map(lambda x: open(x), sys.argv[1:])): print line[0] Which of course looks like crap, but why go through all this mess when what you really want to do is: for line in sys.stdin: print line[0] Then just cat the files to the processing script, I know this isn't exactly the same but it's a whole lot more unix-y. cat already handles reading a bunch of files specified on the commandline so why reinvent the wheel &lt;/unixbeard&gt; ;) disclaimer: fileinput is a great module
- Yeah, markdown FTW ! - Yes, the OP on SO gave a pointer-style function without the additional linear factor, for example. I don't think it will make a significant difference for 10k-sized lists, but feel free to prove me wrong. Nonetheless, this reverse occurs in the function that is (surprisingly) the fastest of the 3 I'm testing, hence not the one I want to throttle. - I would fully, entirely and serenely expect an iterative version to be faster than the trampoline. I would be surprised if the iterative version was slower, in fact (see below). The thing that surprises me *a little* is that a **recursive** (**not** tail recursive) version pushing *two calls* on the stack at every iteration is faster than a version with a (artificially, and admittedly overhead-inducing) managed stack. The thing that surprises me *a lot* is that it does the same for a function (the last one) that does this management with explicit arrays. Now, the stack blowup of the (original, non-tail) recursive version is in fact modest : as soon as you get out of the leftmost path in the array-slicing recursion pattern, the algorithm starts returning (&amp; removing frames). So for 10K-sized lists, you get a stack of size at most log2(10 000) = 14 - pretty modest. So I guess that explains beating the trampoline. But Python's native stack manipulations beating the last function, which does everything in flat flexible arrays ? *That's* impressive.
Yep! I remember reading that the last time I saw this here. Can't wait!
Yup :) And still slower. **That** is the shocker.
I'll tell you what's not Zen, reading text sideways.
why did you do 'lambda x: open(x)'? doesn't 'open' work just as well? Also, Perl's version keeps track of the files open and I think the line number within the individual files. I don't know if fileinput does the same but your version doesn't. Mind you, in situations like these I just use awk. 
Yeah the reason I put that extra lambda there is because I've been up for 24 hours, woke up in a different country ;) I never even use map, looks better to just write it as a list comprehension like itertools.chain(*[open(x) for x in sys.argv[1:]]). But yeah, fileinput obviously provides a lot more. Just seemed like an example where the good parts weren't explored much.
Which just means it's a slow iterative implementation :p Try this instead: def iterative(l): step = 1 while step &lt; len(l): output = [] for left in xrange(0, len(l), step * 2): left_end = left + step right = left_end right_end = right + step if right &gt;= len(l): output.extend(l[left:left_end]) continue while True: if l[left] &lt; l[right]: output.append(l[left]) left += 1 if left == left_end: output.extend(l[right:right_end]) break else: output.append(l[right]) right += 1 if right == right_end or right &gt;= len(l): output.extend(l[left:left_end]) break step *= 2 l = output return output
You're saying awk and sed aren't unix-y?
Give a try to PyGTK. You can make interfaces for it with Glade.
I think most people would agree they are quite unixy indeed ;). I just think it can get gory on the command line if you start mixing flags with multiple files.
Similar but recursive implementations: def recursive_logn_calls(l, step=1): output = [] for left in xrange(0, len(l), step * 2): left_end = left + step right = left_end right_end = right + step if right &gt;= len(l): output.extend(l[left:left_end]) continue while True: if l[left] &lt; l[right]: output.append(l[left]) left += 1 if left == left_end: output.extend(l[right:right_end]) break else: output.append(l[right]) right += 1 if right == right_end or right &gt;= len(l): output.extend(l[left:left_end]) break step *= 2 if step &lt; len(l): return recursive_logn_calls(output, step) else: return output def recursive_nlogn_calls(l): if len(l) == 1: return list(l) output = [] l = recursive_nlogn_calls(l[:len(l)/2]) + recursive_nlogn_calls(l[len(l)/2:]) left = 0 left_end = len(l) / 2 right = len(l) / 2 right_end = len(l) while True: if l[left] &lt; l[right]: output.append(l[left]) left += 1 if left == left_end: output.extend(l[right:right_end]) break else: output.append(l[right]) right += 1 if right == right_end or right &gt;= len(l): output.extend(l[left:left_end]) break return output 
All three of the above/below implementations beat all the rest of the originals (except timsort, of course). Of them, the iterative is the fastest by a couple percent. Timings: Python's native (Tim)sort time: 0.00865082788467 Bubblesort time: 14.6003530025 Original Mergesort time: 0.116734881163 no-len Mergesort time: 0.10508443284 no-len Mergesort + fastmerge time: 0.0676644611359 trampolined mergesort + fastmerge time: 0.0922549819946 Manual tail-call-optimized mergesort + fastmerge time: 0.0750918369293 Iterative mergesort: 0.0481363611221 Kinda Recursive (log n calls, internal iteration) mergesort: 0.0500257790089 Real Recursive (n log n calls) mergesort: 0.0637072808743
NLTK.
It's web site says it does. 
&gt;Eclipse is much more configurable, and I've got a feeling I can better use my screen space too. That's mainly what I was responding to. To people who may have read it, it could imply that Komodo is not customizable, or forced you to use menus, etc ...when really it's very customizable, comes with default keybindings for the major operations, lists the keyboard shortcuts in the menus, has options for default key-bindings like VI or Emacs emulation, has an easy to find list of *all* key-bindings. I can appreciate that you don't like the defaults, but imho since it only takes a few minutes to set them up how you like, and if you find you need to add or change one while you are working it only takes seconds, it's not really a major factor when choosing an editor. I'd be interested in hearing the ways you think Eclipse is more customizable, as one of the things I love about Komodo is how easy it is to customize. I've found most decent IDEs are fairly customizable, and in terms of "raw customization power" they are all equal. It's more a question about *how* they are customizable and if that fits with your tastes/workflow. anted to clarify for others and give my take.
I am not sure I get it or not, seems dict is the data structure you search. country = {"United States": ["United States of America", "USA", "U.S.A.", ...], "Other contry": [...]}
It's probably a bit ugly, but if you used something like: for line in (x for y in (open(arg) for arg in sys.argv[1:]) for x in y): print line the files will be opened lazily (i.e. when the previous file is exhausted) rather than all at once at the beginning. Of course, we could just use fileinput ;)
I have written a number of small Python scripts that do various text processing, spreadsheet combining and other sorts of things. They've proven to be so useful that other non-technical people want to use them. Unfortunately all the tools are command line based, and using a DOS prompt terrifies the potential users, so I found EasyGUI. What a great library! Just a few lines of code and I have a decent looking set of text input, confirmation, and other GUI boxes for the applications. Check into it if you have similar needs.
Looks better as for line in (line for file in sys.argv[1:] for line in open(file)): but it still doesn't have support for `sys.stdin` and it's way uglier than `for line in fileinput.input()`. :-)
http://www.clips.ua.ac.be/pages/MBSP might be worth a look
&gt; Actually, constructs like that are exactly why I'm not jealous of perl. Exactly. I never got &lt;&gt; to work outside the condition in a while loop. To me that's a broken "feature".
This looks really cool, actually. I cracked up at the tutorials being led by a child, also.
This line: one_more.write('\n' + rite) is not guaranteed to actually write the data to disk until the script finishes. This is why the last read() doesn't work. Try adding a one_more.close() after the write(). In general, this usually works fine in simple scripts: s = open('file.txt').read() but you have to be careful when interleaving reads and writes. Also, if you do it a billion times in a loop you'll have problems since you can run out of file descriptors. 
After opening a file you need to close it once you're finished with it, and to make sure any changed you've done are written to disk (especially if you want to read it after writing!), e.g. txt = open(filename) print txt.read() txt.close() or alternatively you can use the with keyword with open(filename) as txt: print txt.read() This ensures the file is closed once you're done with it. 
Unfortunately, adding the close didn't work. 
close the file after you're done writing or learn to use the with statement.
Haven't tested it yet but it looks like you're not using seek(0) to reset the file handler before you read(). The way it works is that a File object has an index that it uses for read()/write(). When you read()/write() it increments the index accordingly so that the next read()/write() will continue from that point. So if you did a write() and then wanted to overwrite everything except the first byte you'd just seek(1) and then write() again. To read what you wrote from the start of the file just do a seek(0) before the read().
OHHHHHHHHHHHHHHH MY GOD! Thank you for this haha I just realized my mistake was that I wasn't explicitly saying print txt.read() I was just saying txt.read() thank you thank you thank you. So now I must ask, why doesn't just saying txt.read() output the contents of the file? And I just wonder why I ever thought that it would...
Exactly. Write() actually write in a cache to make thing fasters. If you don't want to close the file to continue writing on it, there is also flush() which command python to write the modification to the disk.
That was your second mistake, the closes are still required. And the reason it doesn't output the contents of the file is simply because you haven't asked it to. Some python interpreters will show the return value of a function on the screen, for convenience. But when running as a script the return value will simply be ignored.
Thank you so much.
And pyscripter?
[Wikipedia list of countries](http://en.wikipedia.org/wiki/List_of_sovereign_states) might help. Implement a way to parse that data. As a bonus, you can navigate on each of the pages and extract data from the parenthesis. Alternatively, research the links from the bottom of that page. Maybe one of them will provide better data. (e.g. you might like better the [EU list](http://publications.europa.eu/code/en/en-5000500.htm) )
Make sure you're closing the file each time you're done writing to it. You seem to be opening and closing a lot. You may also want to use file.flush()
hey thanks for the tips, Im just following LPTHW and testing different file functions, probably not the most efficient way.
It is already 2 months since my trial expired, and Komodo does not allow to ability to run a 10-minute emergency session (like WingIDE), so I can't even launch it to recall what I saw there... so the only thing I can say is that this is what I remember. Sorry for not being more helpful.
Here are some [lists of country codes](http://gis.stackexchange.com/questions/1047/full-list-of-iso-alpha-2-and-iso-alpha-3-country-codes). I've used [this list](http://download.geonames.org/export/dump/countryInfo.txt) from [geonames](http://geonames.org/). Just clean up the dots and spaces so you can handle “U.S.A.” as well.
Facebook wrote a python project named "Tornado" that they use for real-time updates. [link here](http://developers.facebook.com/blog/post/301/) I don't know what the problems you were experiencing were but it's probably too simplistic to assume it's the language used to write the software that runs the site.
Have you heard of this youtube site? it runs on python. Furthermore, it would be silly for anyone here, including me to make any connection to the scalability requirements of a site like reddit or facebook or digg or amazon or whatever with our own scalability requirements. You are likely never going to see that level of traffic on your project. It's like considering all the issues with space travel before getting on your bike to ride to the store. It's fun, but completely misses the point.
oh hey, I had no problems submitting that comment. I guess pylons is the best at scaling to roflscale. :)
The EU list looks perfect. Wiki saves the day..again! Thanks!
That list will be very helpful! Thanks!
Yea that is the only sensible way I could think of. Now to research python searching algorithms for efficiency. Thanks!
I often find that reading from binary files it's easier to dump the file into memory and use it from there as you aren't limited by position. So: text = open(sys.argv[1]) data = [] for item in text: data.append(item) text.close() This places each line in a different index inside the data list. This is useful because you can step through the data arbitrarily instead of having to open and close the file each time you want to seek. You've got it in memory. Therefore, for printing, you can use a small loop to print out the files similarly laid out to how they are in the file with: for item in data: print item This will print each item in data. I'm totally confused as to what all your raw_inputs() are for, it's generally a pretty bad idea to count on user input being correct and/or spelt correctly. A simple error can throw your entire script off. Here is a way you could help that. def receiveInput(): try: file_again = open(raw_input('&gt; ')) except: print 'I/O error, please try again' receiveInput() This will take the input, and only if it's a valid file available for I/O will it be opened and read. 
good luck with your module! 
Thanks for the feedback. Just figured out that *is_text_present* is the only undocumented method on API. I'm filling an issue about this problem in our track :)
For IPython, you should be able to use an older version that's compatible with 2.5. Try "easy_install ipython==0.10.2". And if you have easy_install, installing extra libraries should just be a matter of "easy_install &lt;whatever&gt;", so long as it's on pypi.
can make a wallpaper .. 
Some more things which never seemed very zen to me: exclamation marks, namespaces, and the word "honking".
yeah that has been hardened in py3. You get a warning if you don't close a resource
Get a platform that will allow you to actually use other programming languages, like Android.
Or you could just use numpy.sort, which is ten times as fast.
Nice, I was looking for something like execnet the other day. Thanks!
I think you're failing to appreciate what an amazing job Reddit does keeping the site up and delivering a huge scale of data and interactions on a very low budget and staff. I haven't had a 503 in quite a long time. Twitter's cash and staff are massive in comparison (600 employees vs. around 5 for reddit) and up until not long ago they were fail whale on a regular basis. The main thing a site needs to be really, really big is a lot (dozens) of very smart people given the time they need and a stable environment (i.e. don't rearchitect site's core navigation every week and expect to serve 50M page views) to stabilize the architecture. You won't have time to do [analysis like this](https://www.facebook.com/note.php?note_id=39391378919) if you're too busy everyday adding new toolbars.
The only links I could find for domain model pattern didn't give me a clear sense of what you're trying to do. Can you clarify. 
MVC is notoriously abstract because nobody can agree what any of the terms mean. AFAICT, Domain Modelling is just about using classes designed like metaphorical objects that describe your problem domain (Customer, Cart, Product, Invoice...) If that's your definition, you can use Domain Modelling within an MVC framework. 
Doing some android dev and omg, I love returning python tuples so much...
One of the things I like about Python is how easy it is to read. This poster is not that easy. Even though I can rotate the words in my mind's eye, I know many people cannot. Additionally, I have trouble when there is insufficient contrast between foreground and background colours.
I have downloaded it months ago, have not had a chance to put it to use. Can you show pics of what you did (the GUI) ? edit: actually, rather...what limitations did you hit, if any ?
LOL oh the irony..... it seems to be the exact contrary to the ZoP "preaching" Think "Minimalist"
a noisy one
I'm attempting to compile a windows version of it right now.. though I've run into quite a few snags along the way. Not sure when the official windows version will be uploaded either..
I forget that exists ( I have done it with a .NET project ) ! I never seen this pattern in python, and this links could explain why. http://stackoverflow.com/questions/6425535/decoupling-domain-classes-from-django-model-classes &gt;But it's not Java, and it's not "enterprisey", and it doesn't conform &gt;particularly well to OO principles. In the Python world, that's seen as &gt;a feature, not a bug 
was reading the site, what is pypy for? did not give much info there what does it do? 
Congratulations fijal and whole pypy team !!! 
Hopefully they get the Windows version up soon, or if you getting working maybe you could send the binary back to them.
http://pypy.org/ 
Literally *five sentences* into the page: &gt; PyPy is a very compliant Python interpreter, almost a drop-in replacement for CPython 2.7.1. It's fast ([pypy 1.6 and cpython 2.6.2 performance comparison](http://speed.pypy.org/)) due to its integrated tracing JIT compiler.
It is an attempt at creating a significantly faster Python implementation. It should be fully compliant with the regular CPython implementation, version 2.7. It has a different C API for binary modules and garbage collection semantics are different. Specifically, in the example code below, the file f will be closed during the next GC cycle, not at the end of the function call, because PyPy does not implement reference counting, which allows Python to determine that the File can be closed as sooon as the reference is deleted: f = open('foo.txt') del(f) PyPy is written in Python, and also uses a subset of Python as an intermediary code format for the code it's compiling.
thanks and sorry got confused, didn't know if you can use that as an alternative, if i need to install python and than that or just pypy. was my confusion.
No worries, I'm just surprised anyone can hang out at /r/python and *not* know every intricate detail about pypy. 
&gt; Specifically, in the example code below, the file f will be closed during the next GC cycle, not at the end of the function call, because PyPy does not implement reference counting, which allows Python to determine that the File can be closed as sooon as the reference is deleted: This is why using context managers is a good habit to get into. e.g, with open('foo.txt') as f: # do something with f # f is closed here.
well, i came across reddit a couple months ago friend of mine gave me the link to the learningpython section, so i be reading here and the r/learnignpython see whats new and useful thing am no experienced on python i do like it's syntax i find it fun to code python cleaner than perl. so that's why i don't know much about hat is what. but thanks for the help.
Absolutely. It was just an example. :-)
Here is one of the fastest random function you can find: def randomint(): return 3 # Taken from a fair random generator.
randint() is pure python and uses randrange: http://hg.python.org/cpython/file/b2c6c65d59f6/Lib/random.py#l166 random() is in C Have you benched/tried os.urandom() ? it uses /dev/urandom or some win32 API. It's more secure also, if you are using the random stuff for some crypto work 
&gt; Preliminary support for NumPy: this release includes a preview of a very fast NumPy module integrated with the PyPy JIT **Awesome**! Anyone got more details on this?
Try downloading PythonMath from the Apple app store.
One of the drawbacks to pypy currently is its support of c libraries. The team (and gracious contributors) has been super busy replacing some of the most common libraries used in python and creating pure python versions. Their work is excellent, needed and very much encouraged by the Python Foundation. Many of the web-based python projects could probably use pypy. Many of the scientific communities are already using pypy. However, some projects require some libraries that are only found in a linux as a compiled binary. And in those cases, pypy is still just a dream. So you should definitely consider it if performance is a problem for you and you only need to consider python code in your performance analysis. However, if you need compiled c-level performance in conjunction with python, pypy is still probably not going to work for your needs.
heh. compliments of xkcd :)
When I read the title I thought this was from r/firstworldproblems.
i forgot about os.urandom(). Thanks for the tip! Good call, I figured randint() was pure python. Thanks!
quick question, i downloaded the pypy (am currently on a mac) do i trow the folder of pypy inside the python dir? or since i said it said site-packages put them according to the path? sorry total noob, perhaps i should just stay away of pypy until i further understand more of it. thanks very much for the information. 
&gt; So now I must ask, why doesn't just saying txt.read() output the contents of the file? As near as I can tell, the `.read()` method creates a string object containing the contents of the file you're reading. It doesn't automatically print for the same reason that putting an inline `int` or expression doesn't automatically print&amp;#8212;i.e., Python doesn't print things at run time unless you ask it to. EDIT: It is _most_ excellent that I got down voted with no explanation. If I was wrong, you should've explained _why_.
There were some blog entries about this in their status blog.
It doesn't seem to work with a lot of numpy functions (e.g. numpy.sqrt is not found). 
The development behind pypy is currently one of my favourite things about python. The fact that they continuously get these great speed increases is really impressive.
yes, because i will totally throw away my ipod and buy an android just for some project.
Thanks for the detailed response.
didn't know i could do that (haven't used easy_install much at all). also, not all of the libraries i use are in pypi it seems, including one of my own (that stores a lot of large dicts that i have). but shouldn't there be a Lib folder irregardless?
Ah, a little clarification :) Worried that reddit has a fundamental architectural problem stemming from the their language/framework choices. On the other hand, I will not be surprised if you saw that kind of traffic on your project. 
Oh I am sure reddit has some amazing supergeeks. I am also sure they are understaffed, and conde nast isn't a good parent. That doesn't change the fact that reddit is perhaps the largest, least reliable consumer facing website today. I like reddit and I will keep returning back, but I wonder when performance starts to catch up with consumer retention.
I actually disagree. Technology choices have some serious consequences. have you seen this talk at OSCON? On twitter's change from Rails to the JVM, mostly due to some fundamental limitations with the framework. http://www.youtube.com/watch?v=ohHdZXnsNi8 (Also, I actually don't think tornado is used at FB. It came with friendfeed...but yes, there are good examples for event oriented python use. Twilio depends a lot on Twisted, for example) 
No windows binary yet, that makes me sad :(.
Instant 15% speedup for me, nice. Congrats to the pypy team.
The point is a staff of five cannot keep up 1B page views a month period. That they keep it up just fine (I never get 503s, site is up 95% of the time for me at least) only proves how *strongly* Python/Pylons/(Mako/SQLAlchemy Core, of which I am the author) perform. I'm not sure if you were around to recall sites that were **actually** horrible performancewise, like Friendster. That was a site that was definitely the "largest, least reliable" site there was, and while they're still around, their lunch was quickly eaten by Myspace who was later eaten by Facebook (and they were built on a Java platform...but so are very major customer-facing portions of Google! language/framework choice not nearly as useful a metric of actual developer time spent optimizing performance). This phenomenon isn't happening to Reddit at all. Reddit's performance is terrific IMHO.
Tuples are just ad-hoc classes (or structs). If you want to return multiple values (e.g. `x` and `y`) in Java, just define a class (e.g. `Point`) that contains the values first and then use it. It is easier to understand.
The reason why it's slower is because it does more math to ensure that it's uniform, responds to subclasses that provide different implementations for random number generation by float or random bits.
I have got $.50, I can give. 
Why is this on /r/Python? It's Java: ugly, verbose and definitely not Python :)
They did say *preliminary* support.
The ones from a few months ago? Still, it'd be nice to know exactly what its current status is, how they'll keep it sync'd with NumPy trunk, etc.
How does `dir(numpy)` look?
I understand where you're coming from with the twitter talk at OSCON but then the problem is the framework, and they chose not to rewrite it and switch to something else instead. That doesn't make ruby a bad language it just means that to use JVM you sell your soul to Oracle. The problem I have is using some project, that has a limitation, doesn't automatically mean the language is bad. Imagine if you ran a C Program that crashed, would you swear off all other C programs too?
['__doc__', '__file__', '__name__', '__package__', 'abs', 'absolute', 'add', 'arccos', 'arcsin', 'arctan', 'array', 'average', 'copysign', 'cos', 'divide', 'empty', 'exp', 'fabs', 'floor', 'fromstring', 'maximum', 'mean', 'minimum', 'multiply', 'negative', 'ones', 'reciprocal', 'sign', 'sin', 'subtract', 'tan', 'zeros'] This is from about a 4 day old nightly, but I'm sure that not much has changed since then.
Preliminary indeed. Thanks!
I had no idea this module existed. Awesome.
Unfortunately, most of the PyPy team are linux users, so they aren't as well equipped for debugging windows issues. They are, however, in search of developers to help with windows-related issues, so spread the word to anyone you know of that might be of help.
Right. Use this. What the OP is asking for is NLP and NLTK is a great framework for that. As far as doing the word count (or subject count), there's plenty of examples in regular Python.
what's the difference between the 2 ? 
DDD like Naked Objects from Java hasn't really done much in the Python world. Python could certainly do DDD but I don't think it has scratched anyones itch enough for them to lay down the time and code to implement the DDD foundation you need. Doesn't mean you can't be the first though. :)
The point wasn't to implement merge-sort, but rather to compare a recursive algorithm with a closely matching iterative one. Including timsort and bubblesort may have obscured that if one hadn't read the original article.
What we have in there is limited, but next release should have some great stuff, likely both dtype support and multi-dimensional array.
type &amp;#38;#95;&amp;#38;#95; to print out two underscores in reddit.
Could've also just put it in a code block, but in the end, I just pasted it. :)
reddits scalling issues have almost always had to do with data storage (postgresql and now cassandra) and not relatively easy things like rendering html.
Looking forward to it. BTW will the extension support work with Matplotlib?
It shouldn't matter where you expand the pypy distro, it *should* be entirely separate from the 'normal' python that OSX ships. 
I rarely use Python these days but I always read news about PyPy. It's such an ambitious and awesome project and the team delivers again and again. It really is impressive, and they post these casual sounding blog posts about how they just sped this up 3x and that 10x.