This looks so cool! Professionally I'm a c#/vb .Net dev so its going to be awesome if I'll be able to use the same tool set at home as I do at work.
Python supports a lot more use cases than just yours. A pretty significant one is as a language people can use to learn programming. Changing the division operator goes a long way towards supporting them. There are plenty of other backwards incompatible changes in Python 3, many of which I consider big improvements. Seems pretty smart to me that they took advantage of the opportunity to try and get as much right as possible once they had the chance. I'm glad to be using a language who's caretakers aren't afraid to make improvements within my lifetime. Otherwise I'd be stuck using C. In many ways, Python 3 is a different language, which happens to have tools available to do most of the translation for you. I doubt anyone is forcing you to port whatever codebase you have to Python 3 any time soon. I wish they would where I work. Relax.
a nihilistic approach to data management
if he's learning stuff, then why not learn things that would be useful. My suggestion was an alternative to MySQL. Someone who is starting today and would look to learn some type of major db that would be similar to what MySQL provides for a web project, I'd advise them to learn to use mongo instead.
because osx uses a different library for readline (blame steve jobs), you could install readline and that would be fixed. sudo pip install readline 
but then you eventually get into things like sharding, replica sets, the gotchas of using a memory mapped approach, map/reduce, the 32 bits thing, then he'll have to get a server with a shitload of memory ... or he might try journaling and discover that other gotchas exists ... sqlite on the other hand, forces you to learn SQL
My questions are obviously based on what little I know of what you are working on, but do you actually need to upgrade to Python 3? Are there features of 3 that you want to be able to use that are held back by the amount of work needed to upgrade existing code? I'm only asking as this question is about the drawbacks of Python and the one you cite may only be specific to your own situation rather than be generally applicable.
what about concurrent accesses?
So you think it will actually be less work to port your codebase to C rather than to change your / to // in your python codebase?
Thanks for posting a solution. The ALLUSERS=1 option did the trick.
I think ipython is mostly used by scientists that want to explore the intermediate results/variables of a program. It has a lot of facilities to let you do this quite easily. Besides, it has tight integration with matplotlib, meaning that you can plot something without blocking the terminal. The new 0.11 series is even more powerful. It has been rewritten as two process model (kernel/front end) in as similar way as Mathematica. It also has a qt console front end with multi-line support and inline graphics. IMHO it's the best REPL in the python scientific world.
This is because mac shipped readline is BSD licensed while just readline must be GPL.
sqlite is probably best to start with and for what you're doing. If you're going to take the time to learn something learn PostgreSQL or MySQL. While the rest of the suggestions here are all perfectly valid, those two are going to be what you end up working with the majority of the time. 
I'm really confused by all the people saying they find the documentation lacking. What docs are they reading?
you have to be building something that's serving some pretty serious traffic before you have to worry about sharding or "the 32 bits thing", and it's got a query syntax that lets you avoid map/reduce. And the point is to not force someone to learn SQL.
The assumption is that a Python beginner writing a first app will not need to worry about concurrent access. [You ain't gonna need it](http://en.wikipedia.org/wiki/You_ain%27t_gonna_need_it)...
and presumably because it's intuitive and sexy. but it sure fucks things up for ipython :)
IPython is great, but I just started using BPython and think it is better (though I miss the ? and ?? extensions). It not only has tab completion, but a popup box of suggestions and inlined docs like an IDE. Just pip install bpython and give it a shot.
Other than my text editor (vim) I spend most of my time in a browser or an ipython shell doing web development. It's an amazing improvement over the standard python shell in pretty much every single way. It **is** heavily using in scientific computing, but it's not relegated there. 
&gt; Thus I stand by my simple happy snippet of code. Unfortunately, the [language reference](http://docs.python.org/reference/datamodel.html) does not: &gt; Do not depend on immediate finalization of objects when they become unreachable (ex: always close files). SCons is currently broken under PyPy due to this exact anti-pattern if the build is sufficiently complicated. So, not really just a hypothetical problem. 
I had the impression from reading some of the massive flame war over the division operator that the reason for the change was more for the use of Python in general education. What I thought of as the programmer education faction seemed to be against the change. Integer division is something that the budding programmer needs to learn fairly much right away so there is no real point in moving it somewhere out of the basic arithmetic operations.
All implementations close the file, few of them close it immediately, and none of them guarantee that behaviour.
&gt; And the point is to not force someone to learn SQL. Maybe it depends on what kind of development, skills and jobs that they want to learn. Because it turns out that SQL's actually a very useful skill, products like sqlite, postgresql, etc have a vast amount of usefulness to them, and depending on what you're doing - a relational database is a far better option than mongodb. Oh yeah, and the only attraction of MySQL is that it is ubiquitious. In almost every other way it has been eclipsed by Postgresql &amp; SQLite.
The community has had a long time to prepare for the changes to division. The // operator was introduced in [Python 2.2](http://docs.python.org/release/2.2.3/whatsnew/node7.html). The "-Q warn" option was added to help find cases of ambiguous usage. Also in 2.2 `from __future__ import division` was added, and it was made clear that Python 3 would use true division.
The amount of religion in that thread, as opposed to actual practical complaints, is saddening.
You're right. But [here](http://pytest.org/latest/nose.html#supported-nose-idioms) is the only place I found a reference to that in the docs. Is it elsewhere? The examples of parameterized tests [here](http://pytest.org/latest/example/parametrize.html) all rely on modifying the `metafunc` passed to `pytest_generate_tests`. I think the resistance to parameterized tests is well-stated [here](http://blog.devork.be/2008/09/generative-tests.html). He thinks that a single test can simply be to iterate over all tested inputs, turning several test-cases into a single one. From the point of view of TDD, he's right. But then, why not just have one giant "test-case"? And by the way, his example is unfair. Here is a better comparison: def test_iterative(): for x in (42, 17, 49): assert mypackage.mod7(x) == 0 def test_generative(): for x in (42,17,49): yield assert_equal, (mypackage.mod7, x), 0 Unfortunately, I can generate test-cases that way in neither **nose** nor **pytest**. But I think I can do this: def test_generative(): for x in (42,17,49): yield (lambda x: assert mypackage.mod7(x) == 0), x Again, I don't care about `assert` *vs.* `assert_equal`, as long as **pytest** handles this. There is a bias toward non-functional programmers. However, I do have to give **pytest** credit for giving me a way to parameterize test-cases within a test-fixture. Even GoogleTest does not allow that. (You cannot mix `TEST_P` with `TEST_F`.) EDIT: Lots. Sorry.
Awesome! Maybe I'll just drop that in the repo so it no longer is a requirement.
if only mongodb had a disk only database like sqlite! I really enjoy using mongo but i need a database where i don't have to worry about a database server, and mongo requires one =/
It does run on Windows.
if you run a 32 bit compiled mongo, it says that it can't go over 2 gb for the total database size. But if you use 64 bit, then that number goes up to some silly amount that you will never really hit
Sorry, I guess that came off a little more trollish than I intended.
IMO there isn't much to learn, except explaining why in Python `1 // 2, -1 // 2, 1 // -2, -1 // -2` equals `0, -1, -1, 0`, while in C all 4 cases equal 0. A related question is why in Python `1 % 2, -1 % 2, 1 % -2, -1 % -2` equals `1, 1, -1, -1`, while in C it equals `1, -1, 1, -1`. 
I use ipython extensively even when fine-tuning regexes for C#. Just about anything that requires some trial-and-error is better done in ipython.
I use all kinds of [%magic](http://ipython.scipy.org/doc/stable/html/interactive/reference.html#magic-command-system) functions: %whos - Lists all the local variables, %logstart - Logs all your activity on shell into a file %ed - Lets you edit a python snippet in vi or other editor and use Ipython as an alternative even to bash: %cd, %ls, %ll. And even for doc testing: %doctest_mode: Does auto complete and gives all the powerfeatures of ipython, yet does it in a way of the plain old python shell session that can be copy pasted for doc-tests. %hist -n - Gives you all the commands you executed in the shell in a list, so you can copy it somewhere. You can run some code module in the interpreter namespace: %run -i and searching code %psearch. You can also give any arbitrary bash(or your default shell) command by escaping it with !. Oh, ?, ?? and / are for the starters. Respectively they give the help on the corresponding object, the source code and do execution after right formatting. And oh, you can also have ipython fired in arbitrary parts of your code to inspect and debug. I do it all the time, to write my code. All you need to do is paste this: from IPython.Shell import IPShellEmbed ipython = IPShellEmbed() You can find out more about ipython, bpython and the like from an earlier blog post of mine, [on this topic](http://uswaretech.com/blog/2009/12/using-bpython-shell-with-django-and-some-ipython-features-you-should-know/).
Pygame comes to mind. They have a lot of games hosted on their site as well.
&gt; Downloads: 1.9.1 Packages (August 6th 2009) 2009...... And again, nearly all games hosted on their site are incomplete, buggy, unfinished messes. On top of that, PyGame is little more than SDL bindings for Python. There are no actual *engines* out there for 2D work...you either have to build up your own library from scratch, or constantly reimplement core game mechanics/features "PyGameReloaded" aka PyGame2 also looks pretty dead: http://code.google.com/p/pgreloaded/source/list Pyglet seems a little bit more developed, but even that seems to be blasé anymore.
same here. Best part for me: def myfunction(): xxx xxx oh no, I screwed it up. %edit myfunction Opens the entire declaration in an editor. Or you can do %edit 1-3
Yeah, I was always wondering "why do people use IPython when there is BPython?"...
Probably they've read them 10 years ago to have rant for the rest of their life. Or they're fixed on comments. 
Well, I'd have to easy_install it or something. Who has the time?
No, there's no reason. Now I'm doing this: self.li = [] To create a new list object local to the class, returned by some of the functions.
The IPython Qt console in the trunk version does all of that. Potentially a curses frontend could be written too. It's just that they didn't want to tie themselves to curses like BPython has.
&gt; I cannot afford to go through every one of those lines looking for where a division might give a different result I'm not very familiar with the / vs. // issue so forgive me if this is a stupid question. It sounds like you don't have to really analyze the code. Can't you just search for all instances of '/' and then change them to '//' in order to retain the original (Python2) behavior? Myself, I have mixed feelings about Python 3's incompatibility with Python2. Doing conversion definitely sucks but continuing to live with decades-old design mistakes is no fun either...
What I hate the most is going from one language back to python and for getting to hit tab in the command line...
&gt; 80% of the time, what you really want is a dictionary, 18% of the time you really want just a module and 2% of the time actually a class. YMMV, but I would modify that to something like "*40% of the time you want dictionary and 40% of the time you want a namedtuple*". Check out [namedtuples](http://docs.python.org/library/collections.html#collections.namedtuple) if you haven't already. They're pretty useful and a nice lightweight alternative to typical classes. 
You don't need a salt too :)
There are quite a few game engines with Python bindings or scripting, check this page for instance: http://en.wikipedia.org/wiki/List_of_game_engines Here are some 2D ones which are well-documented and with somewhat recent releases: - Ren'Py - Cocos2D And for 3D, here's a few well-documented ones with somewhat recent releases: - Panda3D - CrystalSpace And 3D engines can also be used for 2D games. Though I think most Python hobby 2D game programmers just use Pygame due to the low learning curve, cross platform support, and good documentation. And similarly, many of the games on the Pygame site are by beginner coders. But you should also check out the PyWeek submissions for some decent (smallish) games that use Pygame: http://www.pyweek.org/ And you can also see some other Python game-related libraries in use for those submissions. I think the Pygame project is still active (check the developer updates on the main page - and there's more-up-to-date versions in their SVN repo), but they're waiting for the next SDL release (which should hopefully be before too long from now, see also the pygame main page post) before making a major new Pygame release. If you don't mind coding Windows-only games, I guess you could also try using IronPython with Microsoft's XNA platform, eg: http://www.ironpython.info/index.php/XNA_Example_with_a_Bouncing_Sprite 
'//' is floor division, even for floats. In the case of floats it returns a float, e.g.: `10.0 // 3.0 == 3.0`. So you can't simply search and replace all instances of '/'. However, you can use the "-Q warn" option to check for integers being divided with '/': Warning: C:\Python27&gt;python -Qwarn -c "10 / 3" -c:1: DeprecationWarning: classic int division No Warning: C:\Python27&gt;python -Qwarn -c "10.0 / 3.0" 
Windows user can download matplotlib for py3.2 from http://www.lfd.uci.edu/~gohlke/pythonlibs/ maybe Linux user can build from source him/herself, no clue here.
I have nothing to offer, but I too am interested in any answers you receive. I'm also interested in your Twisted IRC bot. I personally want to setup a Twisted XMPP bot. My idea is to be able to send commands to it.
Check out this example from the Twisted documentation: http://twistedmatrix.com/documents/current/core/howto/clients.html#auto5 If you're interested in IRC, check out the irc.IRCClient documentation: http://twistedmatrix.com/documents/8.2.0/api/twisted.words.protocols.irc.IRCClient.html As for XMPP, Google around. There appears to be an enhancement for Twisted named Wokkel, specifically designed for XMPP clients and servers: http://wokkel.ik.nu/ I don't know anything about XMPP or Wokkel, so you're on your own there.
{x}py and py{x} package naming is also annoying, though slightly less so. "numpy"? Why not just "num"?
num is too generic, but it used to be numeric.
Use the fist word of the individual message, not the first word of the line?
how is "numpy" any less generic, when considering *Python* packages?
It's too generic as a name used in your module. But I don't much care. I always import it as `np`. I was just pretending to be a poet, in case you didn't know it.
I've tried multiple times to understand RPython but failed each time. I simply couldn't find enough information to quickly grasp what RPython is. As you said, a lot of Python's more dynamic features are left out BUT, maybe my code doesn't use those "more dynamic" features. Also, to be honest, I dream about implementing a crossplatform minimal GUI system and I dream about implementing it in something similar to python. RPython sounded about right and a JIT-ed interpreter for this would allow me to feed my addiction of "change a line, hit F5 in SciTE, see the results instantly". 
does bpython have history search yet? last time i checked it didn't and that degrades it to nice eye-candy toy unfortunately. :(
And why woulds they? It ams a heavyweight library that only peoples who favors certain desktop ams likes to install, not like Qt. 
so how DO you prevent it from making such an unreadable mess any time a simple exception is thrown ? and telling me something has gone horribly wrong and I should email the poor iPython developer edit: downvotes without answering the question is neither polite nor helpful. if the answer is so obvious, then why can't you just type out a quick answer ? update: I'm not talking about a normal stack trace. whenever any uncaught exception happens while I use iPython I get a thousand lines of mostly useless stack trace and a large message saying "Whoops, we tried to make it perfect but something has gone wrong with iPython, please submit a bug report to this dude in Italy" I then have to trawl though it all to locate the part that was actually my code. 
Sorry if I wasn't clear. That is what I do. Example: CatLuver420: did you see that ludicrous display last night? It splits that and makes a random.choice of one of those words to use as a starter word. This will potentially make the following statement somewhat relevant, as in: Bot: last night I banged your mom But it could also be: Bot: that dog barked at me And since I'm using a chain length of 2 (for more original sentences), it probably wouldn't change much if I used 2 words as input instead.
True. A lot of it is just people bemoaning the OOP structure of Python. I came from a PHP background and learning Python taught me OOP properly. Just because it's a little different doesn't mean it's wrong, and the things like the "broken" scoping make sense when you realise Python is **also** a functional language. Someone even moaned about braces. Come on -- Python code is extremely clean and easy to read, even more than Ruby IMHO. I'll happily sacrifice extra keystrokes so that my code looks the same as my colleague's code.
that way your testing message loses the values of x and y - reporting a test failure where you just say "nope, didn't work" is far less useful than one that says "didn't work, expected y, got x".
actually, that won't work (got bit by it): https://groups.google.com/forum/#!topic/python-virtualenv/BEQAurh9EZw/discussion TL;DR: as weird as it sounds, don't use pip, use easy_install for installing readline, otherwise it won't win out over the system one.
I don't understand how they can justify that. My understanding is that the OO features go quite deep and even standard types are objects - including None, True and False, all of which can be extended, monkey-patched and even have their meta-classes altered!
sorry for my joke. Yeah Flask is not based on Django.
Instead of using the current senetence are your corpus why don't you build it up from the messages it sees in the IRC channel over time? As the corpus grows larger the responses you generate should make more sense. Also you should be able to clearly see a difference between a 2nd order Markov chain and a 1st order chain with a larger corpus. 
Try Learning Python by Mark Lutz, its fairly heavy book with advanced stuff like metaclasses and descriptors too. Plus it covers both version of Python 2.x and 3.x
I am, though! I have a massive corpus with everything in the channel, as stated in the OP. The problem I mentioned is the fact that phrases and sentences are very fragmented by newlines, which is very different from using a sentence generator on a corpus like a book. Only a single word from the received line is used to "start off" the chain.
&gt;Can't you just search for all instances of '/' and then change them to '//' in order to retain the original (Python2) behavior? No, because it depends on each particular case. In C I can declare the dividend variable as 'int' to make sure the result is always truncated. In Python, since the variables are dynamic, I depend on which values are passed to the equation. Sometimes I need one behavior, sometimes I need the other one, there's no way to tell without examining the *intent* of the formula in detail. With dynamic variables I have no way to declare the intention of that variable in the code itself. 
So this means I have to go through 1200 pages of specifications with a fine-toothed comb before I start programming, just to make sure I'm not overlooking some detail like that? 
Sounds like you need a [web framework](http://wiki.python.org/moin/WebFrameworks). I'm using [web2py](http://www.web2py.com/) - it has a nice Database Abstraction Layer, which saves you from having to know SQL (mostly, anyhow - and the option's there if you want to). It is also trivially easy to connect, transfer, and just use, a large range of databases, with rarely (if any) change to your code (beyond your connection data).
Ah, sorry I missed that detail, suppose that's a sign I should get some sleep. Please keep us updated if you find a workable solution to your problem.
In one word, **autocompletion**.
!, ?, ??, _, _i. autocompletion. Works wonders with django's shell, especially to query on the model.
&gt;So you think it will actually be less work to port your codebase to C rather than to change your / to // in your python codebase? In the long run yes. I have code that started in the 1960s in FORTRAN. Millions of lines of code. Engineering and scientific code that has been tested, verified, and validated. That code stays exactly as it is, no one touches it. A big problem I'm struggling with right now is migrating code that used some features of machines that aren't available anymore, like VAXes and PDPs. The way I handle this is to carefully remove those special features, using only a language that's as standard as possible. *That's how real life programming works* In C there are also some features that you may not consider totally kosher. Like the '%' operator, it does not work correctly for negative numbers. People have adapted their code to those quirks. The people responsible for the C language standard won't change the way the '%' operator works because that would fuck up billions of lines of code all over the world. Luckily I don't have that many lines of Python code, I only started using it a few years ago. Now that I've realized that Python is meant to be a language of academic value only, not a language for true programming, I intend to phase out its uses, eventually I will migrate all my Python code to some other language on which I can rely. 
Maybe because "numpy" gives more relevant results on Google than "num" ?...
 &gt;&gt;&gt; str.newAttribute = True Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: can't set attributes of built-in/extension type 'str' 
&gt;Python supports a lot more use cases than just yours. A pretty significant one is as a language people can use to learn programming. Changing the division operator goes a long way towards supporting them. The promise of Python was a language that you could learn programming *without having to learn another language later*. It was supposed to be a *"batteries included"* language. Now with Python 3 they are clearly stating that there's one type of application that definitely is not supported by Python, programs that you may need to keep for future use. &gt;Seems pretty smart to me that they took advantage of the opportunity to try and get as much right as possible once they had the chance. Yet they forgot the big problem so many people complain about, the mixed use of spaces and tabs... Besides, if you go carefully through the changes, you will notice one peculiarity: every single one of those changes force you to write more code. Take the new text formatting functions, for instance. You have to write lots of additional stuff to get extra functionality that in 99.99% of the cases you don't need. Why not create a new formatting library that you can use in that particular, very specific, case when those small details are needed without deprecating the format operator? &gt;I doubt anyone is forcing you to port whatever codebase you have to Python 3 any time soon And what will I do when Python 2 is no longer available in the machines I use? The way they are planning their strategy ensures that Python will be a language fit only for throwaway programs. I don't need a new Perl. I have programs I wrote in C in the 1980s, other programs I use were written in the 1960s. I need programming languages that let me go on to new projects when I finish something, I have no wish to keep rewriting and maintaining forever the same old programs. &gt;In many ways, Python 3 is a different language True. They should have named it something else. When Niklaus Wirth felt the need to improve Pascal he called it Modula 2. &gt;which happens to have tools available to do most of the translation for you. But not the debugging, testing, and validation. 
I tend to agree with the YAGNI principle in a lot of situations, but using shelve without some sort of locking or serialization mechanism is at best naive. The module documentation itself warns against this type of situation &gt; The shelve module does not support concurrent read/write access to shelved objects. (Multiple simultaneous read accesses are safe.) When a program has a shelf open for writing, no other program should have it open for reading or writing. Unix file locking can be used to solve this, but this differs across Unix versions and requires knowledge about the database implementation used. 
I think you're painting with a very broad brush, and missing my point: for people who are just learning to code at all, it's useful to avoid SQL in favor of focusing on Python. Saying that MySQL has been "eclipsed" by SQLite is _weird_.
pip! Why do people still use easy_install when there is pip?
If you install it with macports it will work correctly.
What I hate the most is going from Python back to another language and crying because everything is shit compared to Python. True story.
i hate GIL
everyone does
DreamPie and BPython are just as good, if not better, IMHO.
weird, when I do a buildout with distribute installing readline via buildout (implicitly pip) works. So I assumed that the raw command would work as well. Thanks for the clarification.
It would be worth giving your bot an understanding of words and their parts of speech. No point in it finding relevant material via pronouns or something.
because sometimes you have to, as idangazit points out elsewhere in this thread. some of us have work to do with this shit and don't have time to discriminate one method vs another. 
What to do in the case of negative arguments(s) *is* an interesting question but a surprising number of beginning programers don't understand the less controversial case of integer division with positive values. That is the more commonly used lesson I was thinking of when I made my comment.
I am not a lawyer. You're infringing copyright if you download it and port it to Python/SciPy. In all likelihood, no one will try to prosecute you for that. Offering your changes to people under the GPL is still offering them an infringing work. You'd really need the original author's permission. Bottom line though: if you give the original author credit, and link to his site where people can get the original, I don't think anyone will mind.
But how can I infringe copyright if the work is not licensed? Is it because every piece of work, even if unlicensed is protected by copyright? But you're right, I should ask the original author.
Because. If there is no license, the default is that the copyright owner retains all rights. (Anything published is, by default, copyrighted.)
I quite enjoy your style of speech, and also your guitar god status, although it made it somewhat hard to detect what I think was sarcasm. IPython 0.11 (the version in the trunk) has a client-server capability using zeromq, which it can use both for various frontend/GUI clients as well as for parallel computing. The logic of the IPython "kernel" is separated from what the user interacts with. BPython, on the other hand (as far as I know) is very, very tightly coupled to curses, whereas IPython's frontend could be anything: a curses client, a Qt client, a GTK+ client, an (already existing) HTTP web-browser client, etc. That said, there are good reasons why Qt was the first non-vanilla-terminal frontend that was written. Qt is heavily cross-platform, much moreso than GTK+: it looks right and works well on OS X, *nix, and even Windows. It's also much less of a bitch to program than GTK+, has a very nice fully orthogonal API, and (at least until recently) strong support from Nokia. The LGPL status of Qt and PySide (and the GPL-exception granted by the author of the old PyQt) is also rather attractive to a project trying to remain BSD-licensed.
pygame?
IANAL either, but i believe it's not as cut and dry as you think... if he ports it using it only as a reference of how the algorithm to solve the problem behaves, it's not copyright infringement as algorithms aren't copyrightable in the united states (assuming the US here). so the reality is you'd have to talk to an IP/software lawyer to know, as there's a TON of grey area that is unclear in the law, in which courts have gone both ways. as to the OP, write the original author saying you'd like to port it to python/scipy and publish the results as GPLv3. I'd be shocked if he didn't give you permission if he's distributing it himself for free.
Maybe have a look at nodebox. Similar to Processing, but uses Python instead of (simplified) Java. http://beta.nodebox.net/ EDIT: was just pointed out this by a friend. Seems more simple that node box, and might be a good starting point. http://drawbot.com/index.html
pygame seems a little to complex for someone who doesn't know much about computers and is trying to learn to program. What I would like is something simple but useful, like html to JavaScript, if that makes sense.
&gt; Saying that MySQL has been "eclipsed" by SQLite is weird. * postgresql for large data needs * sqlite for very small data &amp; low concurrency needs Both are better than MySQL in terms of: * Licensing * Standards Compliance * Data Quality * Maturity Postgresql also has far more functionality and is often faster, and sqlite is far simpler to work with and embed in an app. That leaves MySQL with little more than it's everywhere. Which, admittedly, may be the most important consideration.
Will keep thinking about this, but one of the first things you should do is filter out filler words such as "that." You also need a tokenizer of sorts. Basing your chatbot purely on markov chains will yield as expected pseudo-random results, for true logic you also need a tokenizer and a lexer to make sense of what the people are saying.
You're quite right, I should have mentioned the limitations. If the app is to be deployed to the public web then there are issues around security and concurrency.
I tried getting IPython to work with PySide a month or so ago, and did not have any luck. They have only just started the refactoring required so that the IPython source code can work interchangeably with PyQt or PySide. Did you have a different experience? The GPL vs. LGPL difference forced me to choose PySide for my current task, but if it hadn't been for that, I would have returned to PyQt just because of the IPython limitation.
but then again, shelve is awesome 
An upvote for you sir. That is pretty cool.
I'm tutoring various artistic people (architects and others) in programming. So far I have found [VPython](http://www.vpython.org/), a good match between graphical ability and ease of use. I'm a physicist (and wannabe artist in many fields) myself, so that might have biased the choice a bit, but most of my students seem to like it a lot.
I use matplotlib for all my graphics, but I do a lot of graphing. [this](http://matplotlib.sourceforge.net/gallery.html) is their gallery page if that helps. You don't need to use a lot of classes (or any) to make this work, although you will want to start with the tutorial. On a more general note: One thing I really like about python is that, if you are suitably clever, the list and dictionary types are dynamic enough to do away with classes altogether. Obviously you can't scale up very easily without classes, but for small problems, what would be a class becomes a dictionary, with the key as the 'name' and a list as the value. Since dictionaries can take anything as a key and list can except anything as values, all you need to do is think creatively. 
I have a good friend called Gil, whom I like
%pdb will turn on automatic pdb calling - then you drop into pdb (ipdb, actually) whenever you encounter an error or expression. It's very helpful.
Hey guys. I've used iPython recently in an application of ours. It allowed us to have our own embedded terminal and extend the command and options. It has become and extremely useful tool for us. If you want to check it out, it's an open source machine vision python library: http://www.simplecv.org 
well, cause Python ins't the best for games I guess
Use NLTK to attempt to pull subjects from messages. The last time I worked on a markov bot based IRC bot, I ended up creating a fitness function to judge the "interestingness" of a generated sentence. The generator would pick a starting word, then walk the graph to create text before and after the starting word. Then I'd generate 100 or so and pick the one with the best fitness factor. Interestingness was generated by using statistics from the markov chain, such as the sum of the edge weights in the chain generated, length of generated text, repeated words, etc. If you haven't already, adding edge weights helps! Also, instead of picking a random word as the starting point for generation, I made a list of the longest words in the message the bot would be responding to, and picked one of those (if not in corpus, pick another, if you can't do anything pick a random word from the corpus). 
Someone with good knowledge of python should find this no problem, since there are already differences you already have to be mindful of which python you use, and rewrite code for python 3 anyway. The change, I assume, is to remove a stumbling block for new programmer, and forfill 'do as I expected'. Perl-style is more intuitive.
Well, nobody saw it. We cannot call `assert` inside `lambda` because it's a statement. That's why we need `assert_equal`. And that's why I disagree with the OP. Or is `lambda` "unpythonic"?
Very cool. These are the sort of things I wonder about now that I'm learning more about computer programming. It's interesting to see the "magic" exposed.
You could try something like turtle http://docs.python.org/library/turtle.html
Beginners also need to understand how dangerous floating point numbers can be.
"Standards Compliance"? "Data Quality" ?! "_Maturity_" ?!?! what the what? Saying SQLite *eclipses* MySQL because it's better at handling small data and low concurrency is like saying notepad *eclipses* Word at text editing when you don't need any features. It's *weird*. I can think of several reasons to argue for sqlite over mysql on a small project: ease of install, dynamic typing, portability, built in libs. But __Data Quality__?! I don't even know where to begin wondering what that's supposed to mean. Which is probably moot since the whole point of this thread was, "hey it's useful to avoid SQL when you're learning Python"
I don't think it should be controversial to say "Given the existence of the assert statement and the equality operator, the preferred way of checking the equality of two values and raising AssertionError otherwise is `assert x == y`". Yeah, assertions have special syntax. You might as well use it!
Unless you're contributing to PyPy or developing your own language with it, you shouldn't need to use RPython. There's no RPython JIT, not even an RPython interpreter, it's not meant for regular application development. Part of PyPy's goal is to do a Python implemented *in Python*. Of course, in interpreter written in an interpreted language is going to be extremely slow. If you took CPython and started writing even a simple language with it, some benchmarks will show just how poor the performance is. But, we still want to write our new super-fast interpreter in Python, because it's much easier to write in. So how do we get get our interpreter to have the same level of performance as if it were in C while still being as easy to write as Python? We can *translate* the Python code for the interpreter into C. Now we can write a whole interpreter in Python and get C-like speeds! *One* problem though...Python isn't that straightforward to convert to C. There are a lot of dynamic features that don't map well to C code. When we write our interpreter in Python, we'll have to limit ourselves to just the parts of the Python language that we *can* convert to C. This is why we don't want to use this limited version of Python for much else. We *want* to use all the cool dynamic features! It's not perfect, since a lot of things we otherwise like about Python we can't use, but it still gives us the ease and some of the flexibility of coding with Python. This subset of Python we write the interpreter in is basically a *reduced* version of Python, RPython! So as you see, if you're just using PyPy as your interpreter to make regular scripts, you will *never* need to bother with RPython, it's just an implementation thing. In fact, when you normally run the PyPy interpeter you should never even run into any RPython code since it's all been compiled to C already. When using PyPy you can write in regular Python and it will be able to interpret and JIT that for you. Now...here is where it gets muddy. You *can* use RPython for your own projects if you want some kind of Python-&gt;C utility. However, I don't think the PyPy folks have spent much time on making RPython a stand-alone thing for general use. As far as I know it's still tightly integrated into PyPy.
[Dive Into Python](http://diveintopython.org/) or [Dive Into Python 3](http://diveintopython3.org/) do a better job of giving realistic examples of useful code. Try those and see what you think.
Why not? My first guess is that it would be too slow compared to compiled language as C++. However, Eve online happens to be written mostly in stackless python, with the exception of the graphical backend. The game logic and server is written in python. If python can run a many thousand player MMO like that, it should be able to run basically anything.
You can write some wrapper classes and functions maybe? More interested students can dig deeper and learn about PyGame.
You might say it's... pygasmic?
I strongly recommend unity3d to build a professional looking games nowadays. It supports a Python-like language called Boo. See: http://unity3d.com/unity/features/scripting
The screenshot looks normal to me.
unfortunately it doesnt
Its not doing much processing though, just spewing a 404. Still pretty fast.
FWIW, I recently came across this new Python "my_chatbot" at SourceForge by MIT student Cyrus Lange: http://sourceforge.net/projects/chatbot/ 
` class OhShit(object): def __cmp__(self, other): ` if random.randint(1,2) == 1: ` return 1 ` else: ` return 0 ` `&gt;&gt;&gt; globals()["True"] = OhShit() ` `&gt;&gt;&gt; True == False `False ` `&gt;&gt;&gt; True == False `True Formatting is fucked up: http://chopapp.com/#k18fi6g4
Autoindentation is quite handy as well.
How about using Python to output SVG? SVG is an XML-based vector graphics format... it's really simple and you don't need any external libraries to explain. Just have your script create a human-readable XML file, and open that up in a browser or Inkscape. There are some libs that can help simplify starting from scratch if you want. I haven't tried them. I've done this by starting a project in Inkscape, then using taking that document into Python and tweaking it. My little test project was to make a weather map based off of live data from NOAA. Use loops, random variables, or incrementing variables to automates some repetitive patterns that would take ages to do by hand... like spirographs or mandalas or fractals.
I tend to prefer bpython because it can easily be installed with pip.
Alas it doesn't work in Windows :(
&gt; It's weird. Only if you take my comment out of context. I said that Postgresql &amp; SQLite eclipse MySQL. Which they do: Postgresql at the high end and SQLite at the low end. &gt; But Data Quality?! And the relevance of Data Quality isn't hard to understand if you're familiar with MySQL's propensity for silent errors - numeric truncation, acceptance of invalid dates, silently using MyISAM instead of InnoDB because InnoDB wasn't installed - and then quietly not supporting transactions, etc, etc, etc. 
So, IPython 0.11rc1 (which got installed with the latest [EPD](http://www.enthought.com/products/epd.php)) as far as I know works with PySide for the purpose of the qtconsole. matplotlib's Qt4Agg backend, as of the latest stable, still requires PyQt4 only I believe.
Remember, if you're storing passwords, use bcrypt. 
Really no matter what you should try to ask permission, which you will surely receive (perhaps with restrictions). It's really sort of juvenile to try to figure out what you can get away with in a case where the author is perfectly accessible and (probably) cooperative.
Sounds like a candidate for stdlib
Another comparison: http://www.voidspace.org.uk/python/mock/compare.html
Also i can't imagine why you want to give posterity an enormous headache by using gplv3, this can cause problems even for academic users. Please consider lgpl or Apache. 
What would be the benefits of lgpl or Apache over gplv3?
I also have shit to do, that's why I spent the half hour a few years ago to learn the modern best practices of my tools. Because I'm a professional with shit to do and pretending that avoiding learning something new is some kind of productivity boost is how I become one of those old guys I interview for jobs sometimes who say "I started on mainframes but I just learned PHP because it's the new hot thing right?" 
Can you add Google App Engine support? GAE has a pycrypto module
&gt;But you're right, I should ask the original author. Do this. I'm sure he won't mind if you're not selling your code.
A Flask "app" corresponds to a Django "project" and blueprints to Django "apps", and as in Django a Flask app can double as a "project" and "app". "App dispatch" is like hosting multiple, separate "projects" in one deployment. The primary difference to blueprints is that dispatched apps have separate configurations and such. Blueprints are components for assembling one unified application. Flask views can return WSGI application callables, you could take advantage of that for your last route example. For your second route you might be looking for the ``url_prefix`` parameter to blueprints.
I would rather choke to death on a cock than ever use anything based on .NET
 In [15]: type(True == False) Out[15]: &lt;type 'bool'&gt; In [16]: type(1 == 1) Out[16]: &lt;type 'bool'&gt; In [17]: class OhShit(object): def __cmp__(self, other): return 1 if random.randint(1,2) == 1 else 0 def dump(self): return 'In your imagination!' In [20]: globals()["True"] = OhShit() In [21]: type(True == False) Out[21]: &lt;type 'bool'&gt; In [22]: True.dump() Out[22]: 'In your imagination!' In [23]: (1==1).dump() --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) /home/mai/&lt;ipython console&gt; in &lt;module&gt;() AttributeError: 'bool' object has no attribute 'dump' 
Maybe it's because "numpy" google search returns 1,290,000 results and "num" returns 461,000,000 results... *That's* how numpy is less generic.
&gt;algorithms aren't copyrightable They *are* patentable, though.
well there's your answer
I would most certainly not!
Licensing has nothing to do with copyright. At least in the US, copyright is assumed, and no license means you have no right to transmit it at all. Whether writing in a new language violates copyright is another matter. I know nothing of that.
Blueprints are a really easy way to structure your app once it gets more complicated. For example, I might group all user account related stuff in a module and attach the blueprint to my base app. In your example above, you could create a stuff blueprint and assign it '/stuff' as a URL prefix. Blueprints also support having their own template dirs, so you could essentially make them completely self-contained and reusable. As far as application dispatching -- that is for if you have multiple separate flask apps running and want route to them. I'd more likely just use something like nginx to handle this, since I typically have it running in front of an app anyway. 
how about "num python module"? Why do our package names have to be universally unique? Are we such lazy googlers?
This looks awesome, thanks!
Because Python is the game in itself ;-)
Unfortunately(?), I'm not really interested in making any more work for myself. I enjoy teaching, but I enjoy being an artist more. Teaching doesn't get you tenure, and pygame isn't a tool that I use.
I used to do define my precision as an arbitrary constant, but I think this method is better.
Yes, definitely. And patent infringement is a whole different kettle of worms. Such as, even if he has no knowledge of the implementation in matlab, and he derives similar solution he could still be in violation of it.
This is great too, I have a lot of architecture students in my classes. Even though my Google-fu is strong, I'm not sure I would have ever found this one.
Oh yeah, and how about we not have Toyota, Chevy, and Hyundai either... We'll just call them Japan Car Auto, Detroit Car Auto, and Korea Car Auto... ***DERP.*** Quit trolling.
Thanks! I mostly want to use 2d graphics to explain different techniques. On a more general note: You can do a lot without objects. Most artists' projects do not inherently need them (though some awesomely do) nor scale to the point where you need them. The biggest problem is often taking an abstract idea or experience and breaking it down into a series of simpler programming problems.
Good grief! I didn't even think to look :(
Preface: IANAL. But, I believe you are wrong when you say "You're infringing copyright if you download it and port it to Python/SciPy." The act of translating the original code to python would make the result sufficiently different from the original as to invalidate the copyright. If the author had a utility patent (An entirely different and fairly unenforceable can of worms) then it might apply, however this does not seem to be the case in this instance.
VIDLE: It's easy and fun! http://vpython.org/vidle/index.html
IPython is fantastic in multiple dimensions. a bunch of stuff has already discussed in this thread. one that hasnt been emphasized is its parallel computing features. the ability to point it at a head node in a cluster &amp; run a computation over 64 8-core nodes is fantastic. our project (PTVS: http://pytools.codeplex.com) uses it as one of the optional REPL's. with it you can easily do interactive/exploratory and batch high performance computing. Here's a video of Brian Granger (one of the devs) demonstrating its || computing features on a Windows HPC (same w linux): http://youtu.be/qey9Yf7lYmA 
Sure, but why use it by default? If you don't have access to the good stuff, I feel for you. But it weirds me out how a lot of packages still only mention easy_install.
I thought the new hotness was scrypt? (disclosure: I use bcrypt)
Just FYI, the [new regex library](https://code.google.com/p/mrab-regex-hg/wiki/GeneralDetails) has fuzzy matching options.
I've never even used it, I just was inspired after hearing specs like "pimping out my interpreter". Sorry to clutter /r/python.
Use Python 2, be happy.
Makes users lives easier
Shame, because it's actually got a really good standard library, and as far as I know, Unity ships with the Mono libs anyway.
To play devil's advocate here (because I will always cite Eve when people say you can't make games in Python), they've had to write a hell of a lot of C++ code to get their game working at a reasonable speed, and on top of that, they have to host the servers on amazingly expensive hardware.
The Python reps didn't even show up, the Microsoft guys came in thousand dollar suits. I think the choice is obvious.
I just thought about something and decided to post it here... sorry if it's some kind of repost or something... (I didnt read the whole article, so also sorry if its in there) another way not to use lambdas instead of functions: lets say you want to print all the numbers from 1 to 50, but only if they're divisible by 3. printIfMod=lambda x: print((x+"\n")*int(x%3==0),end="") (lambda:[printIfMod(i) for i in range(1,50)])() say you want to do *more* actions instead of a function... well it's hard to set variables without using "global variableName"... but if you aren't setting it... import tkinter anInt=tkinter.intvar() settheint=lambda x:anInt.set(x) printIfMod=lambda: print((anInt.get()+"\n")*int(anInt.get()%3==0),end="") functionlist=[lambda:anInt.set(0), lambda:[[settheint(i),printIfMod()] for i in range(100)]] pretty much I'm saying: you can create a list of actions that as an actual function, but using only lambdas (again, this was definitely inspired by the memory of looking at the first bit of this link, but sorry if it's already said in there)
Could you please explain why?
We need a subreddit like /r/firstworldproblems, but for python. - I am a web developer and have to use Javascript, fml. - I pip installed my requirements but it was too fast, and now I can't go get coffee. etc.
It's a good point, but picking on numpy is a recipe for down-votes.
Tried BPython, loved it, but I love the `-pylab` IPython integration more.
I think a major part of the problem is that the Python community generally does not care about multimedia. I mean, it's only relatively recently that it started giving a damn about the web, when Ruby on Rails came out and the Python people noticed that they could have had that same success. So it's probably going to be a while before anybody significant in the Python ecosystem cares about pixels and audio. So the question then becomes: why do the Python people not care about multimedia? I don't know, but I think it's an inertia thing - the standard library has neglected sound and graphics for so long that most serious practitioners in this area gave up and adopted a different language long ago, meaning there are few such people left using Python to contribute to the libraries. Maybe they moved to C++ which has had DirectX from the start, or C# which can also access it, or Flash which has handled sound and graphics well forever. Even Java's had usable sound and graphics APIs for over a decade. Compare that with Python: you get [ossaudiodev](http://docs.python.org/library/ossaudiodev.html) if you want to use OSS on Linux for sound (and not its general successor ALSA, or the successor to that PulseAudio - yes, Python is about 2 generations behind) and [curses](http://docs.python.org/library/curses.html) for graphics, if you want to make a 1980s rogue-like. Awesome. Even Python's 3rd party wrapper for OpenGL was effectively abandoned for years. It was only once ctypes became viable that anything got done there. Basically, someone needs to lead the way here. Unfortunately what seems like an otherwise trivial task (eg. porting something like FlashPunk or Flixel, both of which are quite small) become tricky when you consider that the low level stuff just isn't supported by the Python standard library. I guess that's why people have just stuck with the ancient PyGame all this time - the tricky cross-platform stuff was done by people in C about 8 years ago and has been barely touched since then.
For the exact reason the GPL was created. If somebody wants to use the code and release it as part of a package, they don't have to worry about releasing the source or their license conflicting with the GPL. The original BSD license, for instance, is incompatible with GPL because it requires attribution to the author, even though it is otherwise very permissive. I don't know the specific problems jhonmcdonnell was talking about.
You're forgiven, carry on now.
Interesting idea. I looked at NLTK originally, but thought it was probably too complicated for what I was trying to do. Your idea sounds very good though. I am new to Markov chains (and somewhat of a novice programmer). What do you mean by edge weight exactly? Each word has its following words split into percentage by frequency of use, like dog { "ran": 0.333, "jumped": 0.666 }, and the selection is based on that percentage, if that's what you mean by weight. Do you know if there's an easy way to install NLTK on Python 2.7, on Windows? It only seems to support 2.6 and below.
make a class for each word it encounters, and include how the chatbot feels about that word, what part of speech it is, and other characteristics... work off of that, using knowledge of the english language, to make good sentences. Then what I'd do is to try to make it actually *understand* each line that someone types to it, and if it doesn't, then it should wait a few seconds to see if another line comes, and combine it with other lines that it doesn't understand, and after a while it might say something like "I don't understand" and then choose a random word from the sentences that it didn't understand and say "but I heard you say something about %s, and I %s %s" where the %s are the word, an verb with feeling, the word ... that probably doesn't help, but I just felt like thinking out loud about how I would *try* to do this (and miserably fail)
Midnight? But that's when the Narwhal Bacons!
maybe you could explain the concepts using visual types of concepts, e.g. an array is like a box, and you can put whatever you want in the box. a for loop is (sometimes) like taking every item in the box and doing something to it, before placing it in another box. a class anything you want it to be, it could be a person, or an object, and each one holds a bunch of other objects. strings/ints/floats are like pieces of paper that you can read. etc. etc. EDIT: visual aids isn't the right word for it but I cant think of it
It is, but I didn't notice it in this particular library. Plus, bcrypt is older so in this sense is a more conservative choice, often a good idea in cryptography (c.f., 3DES and CAST5). Having said all that, I'm not a cryptographer.
True point. Incredible package. Annoying name.
I mentioned it in this conversation because it was actually relevant...
&gt; the standard library has neglected sound and graphics for so long that most serious practitioners in this area gave up and adopted a different language long ago, meaning there are few such people left using Python to contribute to the libraries. This is my thought, seeing as most things are kind of only 1/2 done. I suspect anyone who started to get serious about game/multimedia development moved onto a language with better libraries and better selection of engines, active developers, etc... I mean, it's not like Python isn't capable of the kind of this kind of stuff. The question that remains then, is how can we solve this? Or even CAN we solve this? What would it take to jumpstart interest in this area?
learning to use a tool and then being it's fan boy does not fix the subtleties that arise when one method works and another doesn't. that was my point. where do your conclusions about someone is refusing to learn a tool as a productivity boost come from? I can't believe it took you a half an hour to learn how to type "pip install" though that seems a little excessive. :P
-1 no reasons stated. 
why does it matter at this point? they both (most of the time) work interchangeably. 
for the OP, or really anyone that's done this: looking to get spyder running on mac osx 10.5. where can I find installation instructions? It looks like there is a whole bunch of packages i need to install before getting spyder up and running...thanks!
I would ask on the pypy mailing list or #pypy irc channel. As far as I know (which isn't much) there are active implementations of Javascript and PHP interpreters "in progress" using the pypy toolchain.
nitpick: Midnight is a "false" value. The concept of "bottom" is slightly different than "false". See, for example, http://haskell.org/haskellwiki/Bottom
why everyone likes to complain on GIL, or did you actually overcome this [BDFL on GIL](http://www.artima.com/weblogs/viewpost.jsp?thread=214235) ?
of Bates'?
You might want to start here: http://morepypy.blogspot.com/2011/04/tutorial-writing-interpreter-with-pypy.html
&gt; Now featuring Python 3 support! Cool, I might actually use this.
You are correct, I knew that. Not sure what I was thinking. and Hey! it looks like I've upvoted one of your comments in the past. Have another..
Honestly, it scares me the package touts compatibility for several different schemes, but doesn't encourage proper password storage in the documentation, or provide any explanation.
Because you asked a subjective question, you get my subjective answer: it's not (great). I muchly prefer [bpython](http://bpython-interpreter.org/).
Well there's django and that's the "go to" web framework - especially if you're coming from php. You could try komodo ide (7 apha has some nice pylint integration) - i'm using that with no issues. Ofcourse there are other ides like wing, pycharm, pydev etc
Thanks for the info!!
Actually, it does in the [new application quickstart](http://packages.python.org/passlib/new_app_quickstart.html#choosing-a-hash) - though the layout of the manual is not what it could be, since it's also trying to accommodate other uses as well.
Ah excellent, there we go.
Actually, aside from BCrypt support, Passlib is pure-python and entirely self contained, so it should be usuable on GAE - though I don't think anyone has tested it there. Passlib doesn't make use of PyCrypto only because PyCrypto doesn't provide any primitives that are needed for any of Passlib's supported password hashes (PyCrypto does provide an HMAC implementation, but notes that it's just a modified copy of the stdlib hmac). 
Specifically, 00:00:0.0 UTC is False. For example, if the time zone is Hong Kong (HKT), then 08:00:0.0 is False: &gt;&gt;&gt; from datetime import time, tzinfo, timedelta &gt;&gt;&gt; class HKT(tzinfo): ... def utcoffset(self, dt): return timedelta(hours=8) ... &gt;&gt;&gt; bool(time(8, tzinfo=HKT())) False From `class time` in datetime.py: def __bool__(self): if self.second or self.microsecond: return True offset = self.utcoffset() or timedelta(0) return timedelta(hours=self.hour, minutes=self.minute) != offset 
I like BPython but I was never able to get into DreamPie. Can you explain what you like about it / how you use it to do things you can't do with I/BPython?
Same. Have you ever tried DreamPie? It offers some of the -pylab functionality in a bit of a bpython style UI. It never really stuck for me but is an interesting alternative. 
Yeah, scrypt's the new hotness. Or at least the idea of a memory hard KDF. The following are a couple of things that are probably hampering widespread adoption - 1. *It's new. Everyone's afraid of new :)* Most of the major crypto primitives have undergone a rigorous world-wide gauntlet of attackers; especially the ones involved in any of the NIST competitions (eg: AES, SHA1, SHA2, SHA3). Even the final round losers (eg Blowfish) tend to hang around, since everyone trusts them more than others. (Though this is why some don't trust / can't use BCrypt, since it's not NIST approved). Scrypt hasn't had near this level of trial-by-fire, and may harbor some unintentional and subtle flaws. 2. *Complexity of the basic design.* It's internals (esp. the ROMix function) are very obviously inspired by [PBKDF2](http://en.wikipedia.org/wiki/PBKDF2) (the other current hotness next to BCrypt). I don't want to ramble too far into things, but the summary is that ROMix makes some tradeoffs compared to PBKDF2, which give it memory hardness, but sacrifice some of PBKDF2's preimage resistance; relative to a given hash function (since both support a pluggable hash function). The only [paper](http://www.tarsnap.com/scrypt/scrypt.pdf) describing the algorithm gives a good mathematical proof, but is laser-focused on the final implementation; wider adoption would be helped by another paper, describing *why* those and other choices were made, what alternatives were considered, etc. Also, a description of how the N,R,P parameters affect the KDF would be useful - I *think* it's O(N\*R) space and O(N\*R\*P) time, but I'm not sure. 3. *The choice of internal hash function.* As I mentioned in point 2, both PBKDF2 and Scrypt can be implemented using an arbitrary hash function (PBKDF2 can actually do any PRF, though most people use PRF=HMAC+hashfunc). This makes PBKDF2 very nicely portable, any language with an SHA[12] implementation can have a PBKDF2 implementation in about 20 lines of code. The final implementation of SCrypt on the other hand chose the [Salsa20](http://cr.yp.to/salsa20.html) hash function. This means security proofs of the overall algorithm are dependant on salsa20, and would have been easier had it based itself on a standard hash... Though a salsa20 variant is in the sha3 competition, which mitigates things. 4. Finally, there's *portability*. There is only one Scrypt implementation right now, and will probably remain so for a while; mainly due to the complexity of the algorithm and need to reimplement the entire customized hash function. This implementation is written in C, and was designed as a file encryption utility / library; not as something which exposes the underlying KDF routine. In fact, a bunch of the useful bits that would be needed are "private" functions, which is easy to fix, but doesn't inspire confidence that the author felt they were ready for public use. All of this means even integrating the existing KDF implementation requires questionable changes, and reimplementing it would have to be done without the assistance of any good test vectors for each of the stages, to verify the new implementation is correct. --- All in all, I think that's why scrypt hasn't achieved adoption yet. PBKDF2 is the cleanest (and only NIST-approved) way to go for now, with BCrypt coming in next as the choice of the people. Also, I should mention I'm the author of Passlib, and that those are the reasons why I haven't included Scrypt yet - especially reasons 3 &amp; 4. That and I'm waiting for some dedicated and well known crypto researcher to chime w/ their review of scrypt. edit: added some links for references edit: just to add - I don't meant to be down on SCrypt. The basic premise and the core design are brilliant, it just has a few rough spots in a field which requires near-perfection and lots of review :) 
not a problem! would be great to hear how you go teaching the class with it if you end up using it. 
Only in substantial implementation. Mathematical algorithms (abstract ideas) are not.
U.S. rules, for those interested: http://www.copyright.gov/circs/circ03.pdf 
oh wow, this was on purpose (I guess it had to be) I don't agree with this decision at all. (you should check out ipython btw)
Have you tried pinging localhost? $ ping localhost PING localhost (127.0.0.1): 56 data bytes 64 bytes from 127.0.0.1: icmp_seq=0 ttl=64 time=0.046 ms 64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.045 ms 64 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.045 ms Is it so hard to believe that a Tornado 404 would be 15-25 times slower than ping?
The concept of "bottom" is **completely** different than "false". Not a nit.
If you are making a derivative work always ask the original author. Copyright law is for people who cannot work these deals out on their own. (or any law in general)
Don't get me wrong, I actually likes iPython a lot. bpython too! Just not too much a fans of Qt. I think the Gnome peoples ams doing some cool stuff with Vala/Genie, and glib object system, so I likes that for smaller stuff. And while thems ams some cool lightweight Qt things, ams actually harder to get a whole system working, I thinks, while avoid KDE than it is to avoid the Gnome platform... I dunno.
I'm in the process of building something, but I've found handling the database with python is a total bitch as I only know MySQL and PHP. There doesn't seem to be a lot of help out there either... As far as IDEs go, I always use vim but I know there is a decent plugin for eclipse.
I do not, and yes that is what I meant by weight. If you think of the words as nodes on a graph, the edges are links between the words in the corpus. Edges with stronger weight should be given preference when traversing the graph for sentence generation, as you are already doing.
I think game development is just a deficient area of development (compared to e.g. web development). Not enough people, projects, sustained interest, people earning a living, etc. The latter is probably the most important.
I'll post an update when I figure out what I'm going to do. Are you involved in nodebox? Or just a fan? It looks like a cool project.
Just a fan. I came across it a while ago when I was playing around in Processing and then started learning Python at uni. These guys are a good resource for all such things. http://www.creativeapplications.net/
Yes, there's smalltalk, javascript, prolog (probably the most complete of the non-python interpreters) at least two brainfucks and a gameboy emulator. In addition there's a PHP interpreter which I think is pretty exciting https://bitbucket.org/asuhan/happy if for no other reason than because it's a complex interpreter for a non-trivial language being written by a "third party".
I love Django. Good for big'n's. For smaller: Bottle, or Flask.
You missed Scheme, R, and Haskell :) Basically look at cfbolz on bitbucket ;)
Thank you very much for your kind and considerate reply! It cleared some things for me. 
Thank you for the detailed reasoning.
There is little you can show 'dull business guys' that would not be fraudulent or over their head beyond a list of hyper-successful companies that love Python(I'm assuming the only reason you would give a presentation on a programming language to such a group would be to evangelize its use). My presentation would be an homage to Fake Steve Jobs-- Slide 1: Frigging NASA? Industrial Light and Magic? Google? Have you heard of them? Slide 2: "if the mutant space-eating nanovirus should instantly stop the execution of all Python code, the powerful infrastructure that has been often described as "Google's secret weapon" would seize up." - Alex Martelli, Google Inc. Presentation over. Questions?
Well, yes. I was being polite.
What style API do you prefer with PHP for using MySql? Theres a pure python db driver out there that's similar in feel to PDO plus the c based mysql functions are available in a few of the other mysql python drivers
Ok, fair point, you can't fully monkeypatch builtin types in Python. Everything else user defined can be though, which is good enough (Why would you ever want to monkeypatch True?)
I most certainly agree. It matches the behaviour of falsiness for other datatypes perfectly. Zero hour is the default state, so it's falsy, just like zero, an empty container/sequence or such. You can still check for `is None`.
Just a nitpick: you want Python as a server-side _language_. Server-side _include_ is an unrelated technology (better known by its abbreviation, SSI) which provides a very simple mechanism similar to what can trivially be achieved with server-side languages.
I never liked midnight, and not just in programming. If we had to schedule anything for midnight, I would purposely move it to 23:59 or 00:01 just to be clear. 
&gt; Why would you ever want to monkeypatch True? Well, you brought it ;) But other types like string or list are good canidates for such patches.
IANAL This is my understanding (which may be very flawed) from talking to a copyright lawyer recently. If the original author has proprietary code that is licensed under a more restrictive license than GPL and that code uses the piece of code that you want to license under GPL it could become problematic for the author. GPL may conflict with his current license or even simply override it for the entire proprietary package. All of his proprietary work may then fall under GPL requiring free distribution. This would mean that a piece of software that he was making money on before would become essentially unsellable. I tend to believe that an author's wishes should be respected when it comes to licensing and selling of code. That said, it would be a very good idea to ask him whether he would mind if you put his work or a derivative of his work under GPL.
One improvement would be to identify the most important or interesting word in the sentence, instead of picking a random word. Words that are less frequent overall in language tend to be more 'interesting' or 'unusual' in a given sentence. If you know any information theory you can see why this is. So, get a list of the word frequencies in English: http://www.kilgarriff.co.uk/bnc-readme.html Then, for each word in your sentence, look up its frequency (store the freqs in a dict, lookup will be O(1), and choose the least frequent word as your 'cue' word for the response. For your example, the word chosen would probably be "ludicrous". You could experiment with choosing maybe the second-least frequent word.
Interesting. I do not know any information theory, but it certainly makes sense. I'll try to think of the best way to implement it. I'm also going to mess with the NLTK.
5.6ms is not really fast.
Some of those repositories exists under the PyPy user on bitbucket: https://bitbucket.org/pypy
thanks for the tip, but: &gt; ipdb&gt; %pdb &gt; *** SyntaxError: invalid syntax (&lt;stdin&gt;, line 1) ? 
It is worth noting that Mozilla these days is a Python shop. That was one of the driving factors for it being converted. Having a development/testing environment that was heavily focused on python made sync something of a odd child. One of the early sync php devs [wrote a little about these factors](http://tobyelliott.wordpress.com/2011/07/12/so-long-php-and-thanks-for-all-the-fish/).
Just about :) I've been doing some more stuff recently I need to commit too (or just make a branch in github while I get it cleaned up). Were always closeish to a release, I think once that happens we might get some more momentum.
...and now you're giving him more recognition and feeding him. Great.
OMG! Soon perl6 will run in pypy and perl comunity will have a dead parrot.
Obligatory shoebot plug, were quite good at outputting to svg :D
or British..
Not sure if serious...
Not sure if serious...
What will you do when you want to put a lambda function in a list? Example: def parse_table(csv): columns = [('id', int), ('value', float), ('comment', lambda elem:elem.decode('utf-8').strip())] for row in csv: yield dict((name, parser(value) for (name, parser),value in zip(columns, row)) This is great when parsing things like csv tables or whatever, so it is actually useful.
bad idea. This is not an "alternative" to lambda, but rather a syntactic sugar for this particular use. There are other use cases of lambda, not expressible by this "alternative" syntax. Further, the current lambda syntax is closer to those employed by other (purer) functional programming languages. Changing the current syntax is not a good idea.
I agree with vph: this takes a general concept (lambda) and makes it a strange special case. I'm not a fan of the proposed syntax either: f(key=lambda x:...) makes it clear that you are setting `key` to a function, f(key(x)=...) makes it look like you are setting a function of key to a value.
quite right, otherwise you end up with very confused people
Lambdas are already pretty concise, maybe you could make an argument for Haskell style syntax ( \x -&gt; x+1 ) but this proposal makes little sense.
But then I wouldn't be able to feel smart using fancy words like lambda, or be able to modify my text editor to use the lambda symbol in place of the text "lambda"
&gt; Further, the current lambda syntax is closer to those employed by other (purer) functional programming languages. Changing the current syntax is not a good idea. Since Python is not a pure-functional language, why even have a lambda keyword?
Well a half hour to learn virtualenv, virtualenvwrapper and when to use that and pip instead of easy_install. So now I know when to use it (almost always) and how to use the extra features it has that let me be much more productive. It's not fanboyism to recommend pip instead of easy_install, it's following modern best practices, ie being a professional.
Guido has proposed removing it several times.
Easily one of my favorite uses for lambda. 
No, just no. `lambda` is perfectly fine.
Agreed. It's kind of an interesting use case but it's not a lambda syntax.
Because it is very useful, and practicability beats purity in Python: both in case you presented in the article (`sort`'s `key` and `cmp` arguments) and in other places (see my comment about csv).
It may surprise someone in Hong Kong that 8 AM is False, but I agree that one should check for `is None` in general (edit: for a default value) instead of relying on the boolean value. It would be a pain to have to check the source code for a package at every step to figure out when a class is False. For example, the docstring here is insufficiently detailed (typical, IMO). Python 3.2.1: &gt;&gt;&gt; ?datetime.time.__bool__ x.__bool__() &lt;==&gt; x != 0 Obviously this comes from the fact that in Python 2 the check for a boolean value uses the `__nonzero__` method. Python 2.7.2: &gt;&gt;&gt; ?datetime.time.__nonzero__ x.__nonzero__() &lt;==&gt; x != 0 It's just not obvious, IMO, that the definition of time 0 should be globalized with respect to UTC. In the case of Python 2, you can't easily check the source since it's a built-in module. Instead you have to load up hg.python.org (unless you keep a local copy) and [check there](http://hg.python.org/cpython/file/488c6b481652/Modules/datetimemodule.c#l3464): static int time_nonzero(PyDateTime_Time *self) { int offset; int none; if (TIME_GET_SECOND(self) || TIME_GET_MICROSECOND(self)) { /* Since utcoffset is in whole minutes, nothing can * alter the conclusion that this is nonzero. */ return 1; } offset = 0; if (HASTZINFO(self) &amp;&amp; self-&gt;tzinfo != Py_None) { offset = call_utcoffset(self-&gt;tzinfo, Py_None, &amp;none); if (offset == -1 &amp;&amp; PyErr_Occurred()) return -1; } return (TIME_GET_MINUTE(self) - offset + TIME_GET_HOUR(self)*60) != 0; } It's pretty much the same as the Python code. It's just a tad more convenient in Python 3, since you can easily dump the source into the interpreter: &gt;&gt;&gt; print(inspect.getsource(datetime.time)) TL;DR: It's a pain in my lazy ass to check the source. Write better docstrings!
I don't agree that you should do check for is None in general. They are two different things if val: and if val is not None: Are two completely different things and should be used accordingly You should use 'if val' when you don't want 0, False, None or 'falsey' you should is "if not None" when you dont want...None
You bring up a good use case. It's not ideal, but you would have to write a def in this case.
Sorry, I only meant in the context of checking if an attribute value has been set, if you set the default to None. For example: current_checkin = get_current_checkin(user) if current_checkin.checkout_time: create_new_checkin() else: return "You have to check out before checking in again!" `checkout_time` should have a default of `None`, IMO. 
Yes, and Yes. I agree, and 'is None' is the answer here. Its just that a few people have responded with "You should always be using is None anyway!" Just saying.
Also it is confusingly similar to `{key(x):...}` which is completely different.
&gt;If you have a degree in Computer Science, you should be able to work in both. How relevant is that? Computer science and web development are only cursorily related
You might want to clarify this question a bit. Try googling Python Imaging Library (a.k.a. PIL)
This sounds like a major cockup on the part of the library designer. There are invalid times (13:00 in a 12hr system) but it seem unpossible that there would ever be a false time.
Read from stdin and write to stdout? Am I misunderstanding the question? 
I think it's terrible. I think the current syntax is fine; it's better than MATLAB's @(x,y) x+y syntax.
It's proposed as "alternative syntax", which it is; but in any case, I sort of agree with you that there are probably other use cases, but I think it salient to actually provide some examples of them. The author explicitly claimed that this covers all use cases, this claim is falsifiable, the burden is on you to provide a counter-example.
I've always wanted an operator 'lambda=', to be used as such: &gt; something lambda= somefunc instead of &gt; something = somefunc(something) before anyone says it, decorators are not good for doing this.
`find`
bc the calculator
Wouldn't that just be a calculator? Not that I'm complaining though, could be a fun project. Might even bust out the GIMP to make a really cool lookin' thing.
Aireplay-ng, airbase, etc
This is the stuff I'm more thinking about. I remember when I first started out with Aircrack and that whole suite and it was just annoying switching to the man pages looking up that switch *for the twentieth time*.
Reddit. Please. A console app that lets you surf reddit and *leave comments*. There's been another couple of programs that do this, but they don't even let you sign in.
Thanks for the advice. What do you think of something like that ? Is that enough ? import bcrypt from sqlalchemy... class User(Base): __tablename__ = "users" id = Column(Integer, autoincrement=True, primary_key=True) login = Column(Text,nullable=False, unique=True) _password = Column("password", Unicode(80)) def _set_password(self, password): self._password = unicode(bcrypt.hashpw(password, bcrypt.gensalt()), "iso-8859-1") def _get_password(self): return self._password password = synonym('_password', descriptor=property(_get_password, _set_password)) def validate_password(self,password): return self._password == bcrypt.hashpw(password, self._password) 
The best thing to do is just to make a game, and make it very clear that Python was used. I don't think it's going to be possible to get the core devs to start integrating gfx and audio into the standard library until someone can present them with a finished library ready for the purpose. If you want to contribute to an existing library, I think pyglet is the best option. It's semi-dormant at the moment but it has clean code and good performance for 2D work. It may well lend itself to a higher level library being written on top.
The API limits you to making calls every 30 seconds. I think it's a big no-no making a full blown Reddit app. I did, however, make a login script. Didn't do much else with it though, there's a nice Python API binding library out there.
What about ffmpeg?
There's already kfind for kde.
How well does links/elinks work with reddit?
radiance
Not a command line app, but I would really like a [Subsonic](http://www.subsonic.org/pages/index.jsp) linux desktop app or rhythmbox plugin.
A GNOME version of bc would pretty much work like "bc -lq", except it'd be easier to invoke in a GUI environment, and could have things like a persistent history, and show the values of all assigned variables. OTOH, the existing calculator that comes with GNOME is not too bad, but not as nice as running "bc -lq" in a terminal.
I sympathize with getting rid of the messy word "lambda", but that is not a good enough syntax you are suggesting.
Another idea would be a currency converter, or a GUI version of units.
along those lines, ImageMagick I suppose.
A **music** player that uses mplayer as backend.
There's no reason you can write binary output to a file with a jpg extension e.g., with open('/path/to/some.jpg', 'wb') as outfile: outfile.write(jpg_compatible_binary_data) as for actually dealing with jpgs I'd do what bryancole said (see the PIL)
see "grun" on pypi ... http://pypi.python.org/pypi/grun
 cron
Lambda's aren't perfect. They can't contain statements, for example. But - they barely made it into Python 3. Make waves and the whole debate could start all over again. I would *hate* to lose lambdas.
Or [imagemagick](http://www.imagemagick.org/script/index.php)? Disclaimer: I am not an expert.
Horribly.
I'm pretty ignorant about HTTP, and programming (actually, very ignorant) in general...but my browser can interact with the reddit server more than once every 30 seconds, so why can't a program you make? 
It's because Reddit has a limited and *known* capacity, if, for example they let 100 programmers make write a program that interacted with reddit every second, and then lets say each of their programs were used by 10 people it could be said that their traffic would increase in weird ways. If someone wants to correct me, then please do, but that's the only reasoning I can make out of it. Basically, they've designed the API for pretty minimal tasks not a whole replacement for Reddit. Still though, it'd be a nice project even if it'd get your API User ID banned.
But my browser can make requests to reddit more than once every 30 seconds. I don't really know what an api really is, or if a browser uses it, but it is possible to create a browser that interacts with reddit more than once every 30 seconds.
units
nohup ... I dare you
like it's Web 0.2
 pstree
&gt; Since Python is not a pure-functional language Neither are Lisp/Scheme, ML, Erlang, Scala, F#, . . . should we remove their lambdas as well? &gt; why even have a lambda keyword? Because it is useful.
Over the past 24 hours I have noticed the same thing... MySQLDB sucks... May have to just create my own... Edit: MySQLDB the python plugin not MySQL.
I don't understand. Can you clarify?
&gt; Since Python is not a pure-functional language Neither are Lisp/Scheme, ML (and most derivatives), Erlang, Scala, F#, . . . should we remove their lambdas as well? &gt; why even have a lambda keyword? Because it is useful.
Ya I saw the the two but wasn't sure which one i needed before I posted on here without any other knowledge. I found what I need but thank you for nitpicking anyway!
The easy way to get around this would be to not use the API. You would have to screen-scrape reddit's HTML using sockets to communicate with the http server.
+1 for getting the reference!
The fact statements (as opposed to expressions) exist is a huge defect in the language. If crippled lambdas barely made it into Python 3, things are not heading in a good direction.
Udev rules generation using events for a starting point.
I propose removing the division operator, since it's confusing to some people.
That's only for a particular case, and looks kinda ugly or confusing as it seems to suggest it's obtaining a key from the result of function application. I don't think it fits correctly. I do propose the following: 1. Get rid of statements (make them all expressions with the same syntax, returning the function or class or the last evaluated value) 2. In order to support the former, recognize INDENT and DEDENT tokens within parens 3. Make function name in def optional (it's useful to define it for backtraces); it ought to work similar to Javascript's function 4. Make parens in def optional (they're syntactically useless) 5. New lambda syntax: x = def x: x + 1 example(x, def y, z: #INDENT after this line for i in y, z: ... return whatever #DEDENT after this line ) example2(x, (def y, z: y + z), def k: ... , more, arguments)
Hmm, I don't know how I can clarify it, I always wanted python to have anoperator 'lambda=', that work a bit like '+=' or '*=', such that the expression: &gt; x lambda= f is the same as: &gt; x = f(x) Was it my comment on decorators you wanted me to clarify?
ffmpeg because I am a bastard and handbrake is actually *more* painful than using the man pages...
https://launchpad.net/python-email6 if you also didn't know what he talked about
Ah ok, I see. What's confusing is that what you want has no reason to be called "lambda". Lambdas are for constructing function values, but what you want to do is to call one. Something like x ()= f would make more sense terminology-wise since a pair of parentheses are the operator for calling functions (or callables in general). That said, I don't think it is a good idea. But I dislike += et al. as well.
Learn to love the Django ORM: https://docs.djangoproject.com/en/dev/topics/db/queries/
they decided and specifically enforced a limit for the API that they're not putting in there for the browser. the "why" is they don't want you to, for the reasons aeronotix outlined, and probably because they want to be able to serve you ads in a web browser which a completely different client almost certainly wouldn't display.
Your browser is not using the API, that is why. You are requesting the web page, which is not built for machines to understand - it returns HTML that when formatted humans can understand. Generally API's return data in a way that is easy for programs to parse and understand - for example when reading this thread the page displayed has all sorts of extra stuff like JavaScript to display this nice reply box, recently viewed links and the standard reddit header/footer. The API however would only return the data with no extra "fluff", it would only return a list of comments, the users who made them and some extra metadata. That means that any programs using the API can parse the data without worrying about the extra shit that is only meant for human eyes. A program you make can interact with REDDIT more than once every 30 seconds, but it would need to use a technique called "screen scraping". Screen scraping is when your program makes a request that looks like a browser (thus bypassing the limit) and the server returns nice HTML and JavaScript that is meant for a browser to render. Your program would then use some logic to exclude the extra fluff and just extract the data that it needs to use (the comments, users etc). API's are meant to remove the need for screen scraping because they only return the data that the application needs
It's possible to create reddit clients with the API – there are lots of them for cellphones, for example.
The one I always have to run to the manual for are rsync and wget. Of course, there are already GUIs for both of these, but you could maybe make a better one. Plus you're trying to learn. In general, the GNU coreutils have lots of options that are easy to forget.
GUI using telnet for querying http, dns, mail and maybe something else (modules). You could save profiles, have predefined headers, timers, batches, ... you could store results, .. don't know what else.
[aTunes](http://www.atunes.org/) uses mplayer as the default backend
Have you tried Qalculate?
you can also put .json at the end of URLs
The lisps, ML, Erlang etc. are far closer to lambda calculus than Python was, or will ever be. In Python, lambdas are just anonymous functions that may contain only one expression. The fact that they are called 'lambda' is an unfortunate accident. Given Python is primarily imperative and statement oriented, I would be happier with a different way of expressing single expression functions that are occasionally useful.
I think that's a bit drastic, jumping straight into a web framework for a python noobie is a great way to scare the living shit out of him lol. 
one quick note about the IDE thing. python has too many good command line things that you'd prolly be better off with just good old vim (or... emacs.) 
&gt; This is not an "alternative" to lambda, but rather a syntactic sugar for this particular use. There are other use cases of lambda, not expressible by this "alternative" syntax. My point is that in those other use cases are probably places you shouldn't be using lambda at all. For e.g. a bad use case for lambda might be: avg = lambda lst: sum(lst) / len(lst) This should be written as a `def` instead. But if you have good use cases of lambda, then I'd like to see them. 
I think the biggest hurdle you'll run into is hosting. The language itself is great for websites. With all the frameworks out there, you'll have a site up and running in no time. You can't just drop your code into a folder on your webserver, though, like you do with PHP. Of course, there are hosting solutions out there that are Python friendly. Check out [this](https://code.djangoproject.com/wiki/DjangoFriendlyWebHosts) for a list.
rsync and rdiff-backup
make a piping gui .. the real power of linux command line lies not in the tools themselves, but in the possibilities that arise from chaining them together in random ways .. so do that, make it possible to create these chains in a gui .. and then you can start adding small applets for all of coreutils I'm thinking of something along the lines of pipes.yahoo.com except with linux and possibly more user friendly.
Screenscrape and not use API.
Maybe the API checks out the user agent or header values.
see [corntab](http://www.corntab.com/pages/crontab-gui)
sweet!
I feel like grep is a good candidate. Especially if you can find an effective way of displaying the results.
I agree that Python's lambda is a bit of an eyesore, but this paragraph is complete nonsense: &gt; The lisps, ML, Erlang etc. are far closer to lambda calculus than Python was, or will ever be. In Python, lambdas are just anonymous functions that may contain only one expression. The fact that they are called 'lambda' is an unfortunate accident. Lambda abstractions (in lambda calculus) are *exactly* "just anonymous functions that may contain only one expression" and that's what they are in all functional languages. My original comment was referring to that you use the word "pure" more loosely than [what it actually means](http://en.wikipedia.org/wiki/Purely_functional) in terms of PLs.
KDE has lots of cool stuff that would be great to have on other platforms. I think rewriting some of that stuff in Python with a view to making it more cross-platform would be a worthy goal.
&gt; My original comment was referring to that you use the word "pure" more loosely than what it actually means in terms of PLs. Point taken - I shouldn't have use 'pure' but rather just claimed that Python is not philosophically a functional language. &gt; Lambda abstractions (in lambda calculus) are exactly "just anonymous functions that may contain only one expression" and that's what they are in all functional languages. My point however is that - in Python - lambdas are severely crippled versions of real Python functions (i.e. `def`). OTOH, in something like lisp, lambdas are full-power functions, except that they are anonymous. Anyway, I'm not going to debate the syntax of other languages. Lambdas don't fit in well with the syntax or philosophy of Python. That is why Guido almost axed them from v3.0. However, given that they are occasionally handy, I am trying to find a better syntax (perhaps with limited applicability than the current lambda) which would subsume all good use cases.
That's not true. From the [API Wiki](https://github.com/reddit/reddit/wiki/API): &gt; Most pages are cached for 30 seconds, so you won't get fresh data if you request the same page that often. So don't hit the same page more than once per 30 seconds There are plenty of reddit frontends for mobile devices, and they can sure as hell browse and post comments at a rate faster than 30s per call.
It shouldn't be that big of a deal. The API rules state not to request the same page more than once every 30 seconds because it only updates pages every 30 seconds. Just cache page requests. If the request is less than 30 seconds old, don't update it, pull from cache. Logging in, posting comments and links, and fetching different pages are completely different. As long as you limit those requests to a request every 2 seconds you should be fine. If this wasn't true, it would be impossible to have any Android or iOS Reddit apps along with the various other reddit applications.
Make a grep guy tool using qt
`lambda` itself is a strange special case of `def`. Specifically you can use a lambda if you have: def &lt;foo&gt;(&lt;args&gt;): return &lt;expr&gt; Unfortunately the special lambda syntax can be used in far more places than it *should* be used. I'm merely specializing the syntax further and restricting where it can be used. There are other examples of syntax that is only valid within the argument list (e.g. `**kw`)
Yeah we need more of [these](http://www.usernomics.com/images/developer-designed-ui.gif)
Suggestions: git, capistrano/capifony, curl
No. Nonononononono. What would be some good GUI tools that I could write up a CLI interface for? That's the question I want to read damnit!
Yep, it's cached for 30 seconds but they request you not make more than one call per two seconds.
 cd ; ls
Nope, you can make up to one request every two seconds. Take a look at https://github.com/mellort/reddit_api
I've got an idea: write a version of the recycle bin that includes shred as an option. In other words, it would act like gnome-(recycle bin or whatever) but it would also be capable of using shred. 
also: [gnome-schedule](http://gnome-schedule.sourceforge.net/)
This is not really a command line program but the System Log File Viewer which ships with Ubuntu could be improved. The current one doesn't handle large log files well, is a pain to use when log records are being updated, and is a bit cumbersome to hide / collapse multiple entries. Something a bit more akin to the way SystemInternals handles processes in Procmon would be nice (where you can filter certain kinds of entries via a couple of clicks). 
this exists! I remember seeing it a while back the guy made it so he looked busy at work. Search around for it I'm too lazy it was submitted at least 6 months ago maybe a year. **EDIT** So I found the one I was talking about and them some * [Rt](http://www.reddit.com/r/programming/comments/d30vt/my_updated_gift_to_rprogramming_rt_the_command) - C#/Mono (Cross-Platform) * [Rd](http://www.reddit.com/r/programming/comments/cvykd/my_gift_to_rprogramming_rd_the_command_line) - C#/Mono (deprecated version of Rt) * [Reddit-CLI](http://www.reddit.com/r/programming/comments/cxren/redditcli_the_python_commandline_reddit_browser) - Linux/MAC terminal based 
Even accepting that `lambda` should only be used as a keyword argument to a function I still don't like the proposed syntax. The current syntax is orthogonal: keyword arguments bind values to names and functions are first class (and so can be passed as values). Your proposed syntax creates a special case for "passing an inline function as the value of a keyword argument". It even looks different than passing an already `def`ed function (`f(key=my_func)`. It also unfortunately resembles a function call: `f(key(x)=x.foo)` looks like we're binding the name determined by calling function `key` with argument `x` to `x.foo`. But the big disagreement is that I like `lambda` and use it for things other than keyword arguments. The current syntax lets me do that too.
Start with the [multiprocessing](http://docs.python.org/library/multiprocessing.html) module. Create a `multiprocessing.Pool` with as many processes as you have cores, then call its `map()` method with your array and function. (I'm assuming NumPy arrays are iterable?) If speed is a major concern, you should run some benchmarks with different chunk sizes &amp; numbers of processes.
Yes It is mouse-happy, not keyboard-happy, the way bc is. A powerful tool, though.
KDE is already incredibly cross-platform.
Horrible. But i agree, the lambda-syntax is annoying. I think somethink like javascripts function would look way better. For example: x = def(a, b):a+b
wget - Oh wait.......
there is avidemux
convmv - the utility for changing the charset of file-names. Running it on lots of files with different encoding requires a lot of interaction and trial and error. I made a google project for this: http://code.google.com/p/convmvgui/ - but never wrote any code :)
&gt; lambda itself is a strange special case of def They should totally fix that, and support arbitrary statements in lambdas. Also, you got it backwards -- def is a special case of statement-supporting lambdas combined with assignment: &lt;foo&gt; = &lt;lambda expression&gt; 
This forces the programmer to repeat themselves unnecessarily, and invent multiple names for the same thing: def rule1(arg): body ... rules = { "rule1" : rule1, "rule2" : rule2, ... }
C++: [](int x, int y) { return x+y; } 
&gt; Make waves and the whole debate could start all over again. Which is why I'm moving away from Python. "Batteries included" is great, but the hostility and ignorance demonstrated by Guido last time left a sour taste in my mouth. Just tell keep telling yourself "at least it isn't PHP"
Python already allows `;` as a statement separator, it is conceivable that indentation could be nested in expressions. Eg: map( mylist, lambda x:( # note lambda appearing at start of a line, to set block indentation if x &gt; 2: return 2 else: return x)) To keep backwards compatible, lambda expressions always return their last expression, and statement-lambdas must enclose the lambda body in parenthesis (to avoid tuple expression ambiguity, among others).
Do exactly what sisyphus said, but also: **Make it relevant to them.** What's their business? Accounting? Maybe show them [resolver](http://www.resolversystems.com/products/). Does their business process lots of marketing/scientific data? Find a success story on numpy/scipy. Graphics? Maybe show them how Python can be used for [facial recognition](http://code.google.com/p/pyfaces/). So... * Slide 1: Who uses Python? Google, NASA, ILM, etc. * Slide 2: How can we harness the power of Python? yada yada yada. * Slide 3: How much money you should give me for bringing this to your attention? `sum(salaries_in_the_room) * 4`.
Screen scraping? An abstracted API that essentially used screen-scraped HTML as a backend would be pretty awesome. Yes, this would make one a bastard.
If I don't get to this first you can: General Config File GUI. This would be a program that you could run on the config files for any given application. The GUI would provide text fields for all the text variables, file prompt dialogs for paths, sliders for numbers etc. Based on either a spec in the same directory, or a preloaded one that came with the app/from a repo, or just guessing, it could set maximums and limits and get more information about what exactly various fields are. The goal is to bring the power and customizability of configuration files up to the beauty and polish of the GUI.
You'll need to develop a "wrapper" for each command available (Sort of plugins) ... That's a great idea.
Schematic editor for [ngspice](http://sourceforge.net/project/screenshots.php?group_id=38962&amp;ssid=12443)
 import scipy from concurrent import futures def getfmin(your_array): with futures.ProcessPoolExecutor(max_workers=4) as e: return e.map(scipy.optimize.fmin, your_array) Replace '4' with however many cores you have. 
An API is something that exposes the internals of a site to external users, programs or programmers. It allows interaction on a deeper level than simply through your browser. Reddit's normal browser use is accounted for, and generally known amount, use through an API is not however, and could effectively increase traffic tremedously.
This may be where I was mis-reading it. I stand corrected!
&gt;If max_workers is None or not given, it will default to the number of processors on the machine.
This is a great idea!
How about a shell browser that builds on a top of some other shell by adding a view, where hierarchical information presented from various command line tools is built into a folder tree, and other GUI components. There would be some way to describe the structure that various programs output, that the tool then knows how to present more compactly. Naturally the ordinary text form shell should be available if desired as well, as this kind of tool will lag behind changes to the command line tools and their output. I'm not sure if this is a worthwhile software excursion. It would be interesting to try out, though.
You could just build the command using the gui and run it. I'd imagine something like DFD where each node can have multiple inputs (pipe, file ..), parameters (arguments, enviroment, ..) and outputs (errors, normal output, file, pipe, ..). You add node, select program/commmand and "chain it in".
Use some general config schema which you'll translate all other types into (and from). That way it would be easy to write modules for various configuration files.
Firefox.
http://acko.net/blog/on-termkit (slightly related)
I do believe you may find [SpeedCrunch](http://speedcrunch.org/en_US/index.html) useful.
there is already winff
Htop. Like Process Explorer on Windows.
The operator module has some functions that can be used in most places of lambdas: lst.sort(key=attrgetter('name')) Or partial from functools: lst.sort(key=partial(somefunc, kwd=x)) Though that wouldn't work with ``getattr`` which only accepts positional arguments and we need to skip one. You could also easily make a class that produces functions based on actions on its instances, e.g.: class _Getter(object): def __getattr__(self, name): return lambda o: getattr(o, name) def __getitem__(self, key): return lambda o: o[key] get = _Getter() del _Getter lst.sort(key=get.name)
Ask them to teach you what they do. Ask them what's tedious. Suggest ways Python can improve that using the batteries included.
How about an fstab tool, for setting up hard drives. 
and that's perfectly fine. now what do you do when pip doesn't work for a package? do you a: easy_install it, or b: port it o c: not use it? for me, I go with a, because I'm getting shit done, and don't want to waste time bitching about it on reddit. 
I don't know sorry; I've not used either of those modules.
I never respond to his post. I posted this just out of frustration. I have setup filter to move entire conversation into trash... So annoying.
Can anyone come up with a snappy name so we can make a project? Cause honestly I feel like tearing into this right now :)
Make an interface that has two dropdown boxes, one for interface, and one for network, and then it does the rest for you automagically. That would be awesome.
`svn` Sure, there are plenty of GUIs for it already, but none as good as Tortoise. 
Your comment makes me think of [TermKit](http://acko.net/blog/on-termkit). It did the rounds on reddit and co. recently.
To go along with the specific example: def decode(elem): return elem.decode('utf-8').strip() def parse_table(csv): columns = [('id', int), ('value', float), ('comment', decode)] for row in csv: yield dict((name, parser(value) for (name, parser),value in zip(columns, row)) Not too ugly, is it?
OMG this would be so nice!
Your need a bit more work than this. Most of the tools in the multiprocessing module will try to pickle your data to pass it between processes (although if you're on linux, child processes can inherit the data from the parent directly - however this still doesn't address how you pass the data back to the parent). Pickling numpy array is quite inefficient. Start by making a block of shared memory (multiprocessing.Array and shared ctypes objects). Then make a numpy array out of this (using numpy.frombuffer). Copy your data into this array. Make another shared numpy array for the output of your optimisation routine. Pass the shared buffers undelying the input and output data arrays as arguments to each of your N worker processes (N=4 for a 4-core machine). Each worker should convert the shared buffer back to a numpy array and process its own segment of the data and place the result into the output array. See numpy.ctypeslib for functions for converting between numpy arrays and ctypes objects.
I was kinda referring to KDE more as a platform itself. As in, KDE's "house brand" apps don't run on other DEs without installing lots of large libraries.
so... lie and pretend to be a cell-phone?
What about the 'style' and 'diction' commands? To let someone select parts of their text to apply these to.
Some gotchas: * Modules imported to ``pavement.py`` are scanned for tasks (and I think recursively for modules *they* import); tasks don't have to imported to the top-level of the pavement file. * Tasks have a fully qualified name which is the module name (plus a dot) prefixing the function name, but where not ambiguous can be called by just the short name (function name). * Ambiguity can also be avoided by importing to the top-level namespace of the pavement file; short names are looked up there first. * The command line is parsed sequentially so options need to be set before the task that reads it when using the equal-sign syntax: ``paver some.option=value some_task``.
TIL that's cool!
Yeah, that's a great idea, let's hope it will work ;). But I see TermKit as a convenience for people who are already used to terminals, not as an bfu alternative.
Yes, being able to pipe various outputs to various programs easily would be great, that's kinda cumbersome in bash. (And not really that much better in rc, which is great with pipes.)
&gt; visual aids isn't the right word for it but I cant think of it Analogies?
I love the "Pro mode" button .. does it actually show additional buttons or something? :)
That'd be cool .. but having to maintain parsers for each and every kind of config file along with definitions for *every* config file (list of possible options, descriptions, ..) sounds like hell (and not the good kind).
If you're not using a framework with its on ORM (django probably) then take a look at SQLAlchemy.
that sounds exactly like TermKit ;)
Due to its DAL, and the fact that it comes with its own built-in webserver (if you wish to use it, that is). Coupled with the fact that there are bundles of tutorials on how to get up &amp; running within minutes, you can actually use it as a replacement for GUI desktop design for small projects, and other stuff which isn't graphics-intensive. In my opinion, it would be much faster for him to get his project up &amp; off the ground using that, than pretty much any other method that I can think of. [here is a video](http://vimeo.com/6782736) on how to build a wiki with versioning and authentication in 3 minutes and upload in the google cloud in less than 1 minute, using web2py. However, I think that everybody went off topic here. I suspect that what he's really after is a basic tutorial on how to connect to an sqlite3 database in python, and run queries... [Here is a basic tutorial](http://www.wdvl.com/Authoring/python/SQLite/Watts07162009.html)
&gt; I understand that due to the GIL, threads are not the answer No. http://wiki.python.org/moin/GlobalInterpreterLock &gt; Note that potentially blocking or long-running operations, such as I/O, image processing, and NumPy number crunching, happen outside the GIL. Therefore it is only in multithreaded programs that spend a lot of time inside the GIL, interpreting CPython bytecode, that the GIL becomes a bottleneck. 
Install ipython for mucking around and solve these: http://www.pyschools.com/quiz/view_summary 
Shouldn't be too hard actually... especially for WEP. There already is a tool (cli) which automatically tries to crack every network in range, I can't remember the name, but you could probably adapt that and write an interface for it.... EDIT: [wifite](http://code.google.com/p/wifite/)
That's just for convenient things like dropdowns for known options, sliders for ints with known bounds, etc. If it knows nothing about a config by default it would largely be a bunch of text boxes with labels.
I'll look into it when I get home tonight, but I'm pretty sure that if you just brough all the interfaces down and then brought the one up you want with the name of the network along with a password it should be good to go.
There's a qalc command line tool with it too, I use it in place of bc as it's much more powerful.
Just to be clear, the reason that threads are OK in this instance is because `numpy` is using C code to do the work, and the GIL is released while the C is doing it's thing. In the general case, "threads don't help" is the correct intuition.
All the other responses are technically correct, but I've never been willing to take the time to learn the details of multiprocessing because it hurts my brain. When I need to run the same operation on an array over and over that takes a long time, I usually just make 4 copies of the script, tell each of them to work of different parts of the data, and then run each of them separately. It's a horrible kludge, but it works.
The problem is that would be almost completely useless and you'd still need a definition file saying what character is used for comments, what's the key-value separator and whether there are any sections or stuff. (Compare smb.conf, Xorg.conf and mpd.conf ;).)
Thank you! This will not work, literally, since fmin takes a function, but I see where you're going. I'm using Python 3.2, I forgot to mention. I will try your idea ASAP, thank you!
As I recall when using filter, map, reduce and list comprehensions much of the iteration can be done in a way that doesn't hold the GIL (As long as the the bulk of the payload in those operations is also in C-Land). So running map operations in concurrent threads can be fairly effective. This is coming from somewhere deep in the back of my brain, so double check it for sure.
Yes. In fringe cases you'd need a config file or it'd break. The app would just work with the most common styles of config files. The target user is the least-fringe-seeking Ubuntu user you've ever seen. If they can run a program and browse to a file then interact with that configuration in a way similar to standard GUI apps I think that could be really helpful for a lot of people.
That's what bryancole was describing in essence - it's a good idea, just implemented in a different way.
I can't remember where I learned that, but it is true. I sped up some code once by replacing a loop with map.. testing that again now seems to confirm this as well. numbers = [] for x in range(1000): for y in range(1000): numbers.append(y) def one(): result = set() for n in numbers: result.add(n) return result def two(): result = set() add = result.add for n in numbers: add(n) return result def three(): result = set() map(result.add, numbers) return result In [1]: %timeit one() 10 loops, best of 3: 150 ms per loop In [2]: %timeit two() 10 loops, best of 3: 102 ms per loop In [3]: %timeit three() 10 loops, best of 3: 85 ms per loop The code in question wasn't using `set`, but I was calling a C based function 100,000 times.
It's not really that hard: http://docs.python.org/library/multiprocessing.html#using-a-pool-of-workers
Personally, I think the GIL problem is a bit overblown, and I think that in the general case it's actually not a huge deal. How often does anyone run code that is performance-critical enough to bother threading it, and yet absolutely none of it has been at least partially optimized into C? The GIL is still going to rob you of some performance no matter what you do, certainly. But it will surely be much better than singlethreading, especially on today's ubiquitous multi-core processors.
They threaten banhammer if you lie about user agent.
Yeah, I've been doing this same solution as well. Inspired by Javascript, which has "undef" and "null", I added a special "UndefType" and an "Undef" singleton to one of my swiss-army libraries. Over time, I've figured out a few rules when using this singleton - Logically, I had to make __eq__ operate s.t. Undef is not equal to anything, including itself (muchlike SQL's NULL, and for the same reasons - this doesn't represent "no value", it represents "it could be any value"). Tests should always use "is Undef". It's intended purpose was to set it as the default value for a kwd argument. Aside from that, it should NEVER be passed as *input* to a function. Going down that road led to dark things - what if the *other* function used "Undef" as a marker? Take for example "dict.pop(key, Undef)"... we'd expect Undef to be returned if the key was missing, but what if the object's pop() method used Undef as a marker? It would throw a key error instead. That presupposed knowledge about how other functions operated, and given how many of my own libraries were using it in various ways (and how no one else's was), passing it as an input to another function was a recipe for trouble. Same for using it as a return value. All in all, I like the idea. As I said, Javascript has "null" (Python's None) and "undef" (which Python lacks). I've seen some other solutions, I think some folks like to create a NOT_GIVEN singleton also, but I like Undef since it's got parallels in other places. I'm not entirely sure if something like this should or shouldn't be added into Python proper. If it was, we could all use it, but (given my lessons learned, above) using it properly is a delicate thing, that would probably serve only to complicate things for new users if added into stdlib. 
It's not hard at all to come up with cases where the GIL makes multithreading horribly slower than single-threading on multiple cores. David Beazley had an excellent [PyCon presentation](http://www.dabeaz.com/GIL/) about it. As for performance-critical code, it's usually not, but it seems ridiculous to expect people to write in C just to take advantage of the 2 (or increasingly, 4) cores their machine already has. Speed is a feature even if it's not a critical one. I also agree that for many cases, it's not that big a deal: in general, I prefer the multi-process model to the multi-threaded model, anyway. For the things I use Python for, especially, multi-processing is probably a *better* fit. That doesn't mean that there aren't domains where this matters more, or that I personally agree that a giant hack to make the implementation easier is worth the corresponding hassle for people who (quite reasonably) expect multiple threads to actually run at the same time. I'm also aware that there was a patch to remove the GIL a long time ago, but that it was rejected on the grounds of its gigantic impact on single-threaded performance. All in all, the GIL might not be the biggest problem facing Python (for most people), but it's been a lingering problem for long enough that I *really* wish it had been squashed by now.
Numpy arrays are iterable, and the problems they're used for will often fit into a mapreduce model and the OP's case is one of them. I did a quick search for mapreduce multiprocessing and got this: http://blog.doughellmann.com/2009/04/implementing-mapreduce-with.html Try it out.
Yeah, but I'm not a programmer, and the ROI of learning multiprocessing vs just running 4 scripts has never been enough for me.
why would you do that? def function(var, option=None): if not option: # stuff here
If you're going to rely on this, look to see if there are environment or other vars that may introduce concurrency limits based on the limits of the box the library was compiled on (e.g. ATLAS does this IIRC).
gha... tab doesnt work well in text areas :-X if not option: # stuff else: option = OptionClass()
FTA: &gt; (The problem with None as a sentinel value is that it's easy for a None value to creep into your program through various bugs, oversights, or just other functions that return None under various unusual circumstances. The result is a peculiarly hard to spot situation where how the code reads is not how the code actually works; you think that you're calling optarg() with two arguments because that's what's in the source code, but in actuality you're calling it with one. If the effects of this are indirect and only become visible much later this could be quite a head scratcher bug.) i.e. def f(a=None): if a: foo(a) else: bar() x = something() #should return a string, but returns None due to a bug f(x) #Why is this bar()ing instead of foo()ing? If we instead had: def f(a=no_arg): if a is no_arg: bar() else: foo(a) Then our bug would be easier to find and fix.
I'm not sure how much that helps. Your problem is with something() returning None, now instead of finding out why f(None) is acting funny, you have to find out why foo(None) is acting funny. I think both cases can result in funny behavior that's hard to track.
The minor problem: You have to do something different when a passed option can also be None for some reason. The major problem: Never use boolean coercion to test for None. Any other false value (e.g. False, 0, datetime.time(0), empty string, ...) will incorrectly be treated as "no option passed".
Yes, but those horribly slower cases are, from what I can see, trivial and ultimately silly cases. Threading a pure-python while loop that increments a variable? Yeah, the GIL is going to slaughter that. But nobody actually does that. I'm not saying you have to be a C programmer, I'm saying that most of the stuff you probably want to use threads for is *already* using C at some level. Some of the examples are loading or manipulating images, encryption, doing computations with numpy or scipy, networking, video encoding, audio/video stuff with pygame/pyglet/opengl/whatever. All the performance-intensive parts of any of that stuff is already done through C. The GIL is not going to bite you too badly on any of those things as a result. I agree, the GIL sucks and I would love to see it go away forever. But I'm pretty confident that in *practical usage* it's not nearly as much of a problem as it's made out to be. It's bad, but it's not *SO BAD* that you should avoid using threads altogether which is what the submitter seems to think. Threads are still useful in Python, even with the GIL.
I am an artist teaching myself programming and coming across these are definitely helpful.
not really, i mean, if they pass None explicitly, its the same as the default anyways, and you'd have to treat it the same way, same with false, but yes if 0 is a valid value, they you need to check for that. also the same for an empty string, but i'd suspect 99 times out of 100, forced boolean conversion is fine for checking if an option was not passed. no need to add complexity unless you actually need to. 
The minor problem is not very interesting. Using boolean coercion however is, as it is a common cause of bugs [citation needed]. It might not make sense for this option to be an empty string now, but in a future version it might. Using "option is None" adds no complexity, and actually it's slightly simpler for the interpreter to check.
I was at one point a strictly php developer, but have used a variety of technologies. It seems you do not have a technological reason for switching to Python, so I would say work with whatever you are most efficient in. With any switch, there's a learning curve to get you back up to the speed you would be with php right now. With that said, I am now a Python/Django developer, and I can highly recommend it. I use PyCharm for an IDE. Not sure what your background is, but if you are familiar with some sort of php framework like Zend, Cake, CodeIgnitor than switching to Django should be relatively straight forward, its just trying to understand the syntax and pythonic way of doing things. Try out the Django tutorial and see how it feels to you: https://docs.djangoproject.com/en/1.3/intro/tutorial01/
You use bcrypt but you don't know about the package bcrypt ? So which package do you use ?
It should be possible to write a frontend in any toolkit you like. There's an HTML notebook frontend in the works. Qt was just a good place to start. Messaging specs are here: http://ipython.org/ipython-doc/dev/development/messaging.html
The ipdb&gt; prompt means you're already in the debugger. If you're seeing a massive stack trace, there's a bug in IPython itself. Any exceptions caught while running your code produce a smaller, neater traceback. If you can reproduce it in the new version that's being released soon, please file a bug.
[Flexget](http://flexget.com/)
There are about a bajillion of those already.
thanks. though I'm not yet in the debugger, I'm in the interpreter. that's the ipdb. no ? the idea I thought was to go into the debugger when an uncaught exception occurs.
Maybe I just haven't run across a particular use case, but what do I care whether they provided the optional argument or we're using the default value? If you're just concerned for debugging purposes, it's better to add a decorator function to log the values being passed in rather than use some magical value for "they didn't set me".
Sample code: &gt;&gt;&gt; import logging &gt;&gt;&gt; def log_args(f): ... def wrapper(*args, **kwargs): ... logging.warning("Called %s with args %r and kwargs %r", f.__name__, args, kwargs) ... return f(*args, **kwargs) ... return wrapper ... &gt;&gt;&gt; @log_args ... def foo(optional=None): ... if optional: ... print "Bar" ... else: ... print "Baz" ... &gt;&gt;&gt; foo() WARNING:root:Called foo with args () and kwargs {} Baz &gt;&gt;&gt; foo(None) WARNING:root:Called foo with args (None,) and kwargs {} Baz &gt;&gt;&gt; foo(0) WARNING:root:Called foo with args (0,) and kwargs {} Baz &gt;&gt;&gt; foo(optional=False) WARNING:root:Called foo with args () and kwargs {'optional': False} Baz 
Why choose just one? Run multi-process, multi-threaded applications. This is not an either/or. 
I agree that it might not be a stop-the-presses sort of problem, but I also don't think that all those people who essentially say "The GIL isn't a problem" are being intellectually honest. I also don't want to just assume that threads won't bite me when I'm not looking because there's probably some C floating around that will bypass the GIL for me. I think that as PyPy continues to outperform the pants off of CPython for pure Python code, fewer and fewer things will be written in C, since writing it in C throws away all the performance wins you can get from PyPy. To be clear, I don't think you're saying the GIL isn't a problem, but it comes up often enough that I wanted to dispute the idea.
1. exit() or import sys sys.exit()
Sorry I should have been clearer. I have used it, but only on toy projects. I don't feel like I could properly comment on it because I don't have enough practical experience with it. I have more academic knowledge than practical.
2. You will need to look at os.walk() for this. See http://docs.python.org/library/os.html Off the top of my head, something like: import os import re regex = re.compile("file[0-9]+good\.fits") for root, dirs, files in os.walk('./'): for f in files: if re.search(regex, f): print "File %s matches" % f else: print "File %s does not match" % f 
Fair enough. I think we both more or less agree, we're just looking at different ends of the argument. :) And yes, PyPy is making remarkable strides and doing some very impressive stuff with JIT. I can't wait to see what else they have up their sleeve.
Your sexism is disappointing. What makes you think that among 22,511 readers, nobody reading this will be female? Women can, and do, program.
I didn't say no one would be, nor that women do not program. It is not sexist to appeal to statistics and to know one possibility is much more likely than the other (I said unlikely, not impossible). :) Anyway, if any women were reading this, I apologize if it came off as rude and I meant you no disrespect. I work with 2 girls in my office who program , so.... Relax!
2. It's possible to do the following easy bit of code if you are sure that the directory only contains files that will match a certain pattern like: Also, unless the files are padded with zeros, to operate sequentially on them you will need to sort the list in the way you'd expect. A google gives the following natural_sort function which does this. import glob import os.path import re import re def natural_sort(l): convert = lambda text: int(text) if text.isdigit() else text.lower() alphanum_key = lambda key: [ convert(c) for c in re.split('([0- 9]+)', key) ] return sorted(l, key = alphanum_key) file_list = glob.glob(os.path.join(somedirectory,'data*good.fits')) sorted_list = natural_sort(file_list) for file in sorted_list: do processing 
http://code.google.com/p/subsonic-client/
Awesome, I will give that a try. Looks like a fairly new project.
You don't need to use walk if all the files are in the same directory. It's also good practice to make all regular expressions raw strings. import os import re regex = re.compile(r'file([0-9]+)good\.fits') for f in os.listdir('./data_dir'): match = re.search(regex, f) if match: file_number = int(match.group(1)) print "File %s matches and has number %d" % (f,file_number) else: print "File %s does not match" % f 
odd...I can pip install ipython just fine. I like both tools btw. &gt;(sisenv)me@linux-2gsz:~&gt; pip install ipython -U Downloading/unpacking ipython &gt; Downloading ipython-0.10.2.zip (6.4Mb): 6.4Mb downloaded Running setup.py egg_info for package ipython &gt;Installing collected packages: ipython Found existing installation: ipython 0.10 Not uninstalling ipython at /usr/lib/python2.7/site-packages, outside environment /home/me/.virtualenvs/sisenv &gt; Running setup.py install for ipython &gt; Installing iptest script to /home/me/.virtualenvs/sisenv/bin Installing ipythonx script to /home/me/.virtualenvs/sisenv/bin Installing ipcluster script to /home/me/.virtualenvs/sisenv/bin Installing ipython script to /home/me/.virtualenvs/sisenv/bin Installing pycolor script to /home/me/.virtualenvs/sisenv/bin Installing ipcontroller script to /home/me/.virtualenvs/sisenv/bin Installing ipengine script to /home/me/.virtualenvs/sisenv/bin Successfully installed ipython Cleaning up... 
blktrace dear god yes
Yep iPython works - but as far as I know it is not possible to install DreamPie via PIP because it is based on a GUI that is distributed with it.
Both good points. Use this one!
Give it up already.
Honestly if None is 'creeping' into your code, you are doing it wrong. I use None all the time. To overcome the 'function returning None under various circumstances', you should either never have a "return" by itself in a function that is expected to return a value, or you should throw an Error. 
Same.
geany is an excellent multi platform IDE that has good python support. And try web.py it is dead simple and easy to get started with. 
PyGame.
[SQLAlchemy](http://www.sqlalchemy.org) is always looking for help. Though we have a lot of grunt work to be done (correcting links, grammatical, etc.).
And we'll parse reddit with a regex right? :/
I disagree - I use(d) emacs, but just discovered PyDev - it's so nice to have it tell you of missing / unused symbols - like having a compiler almost. (and multiple tabs without pain!) (edit: [Instead of!]) writing 1000 assertions and running it (which is what pylint (or is it pychecker? dunno, one of those)) boils down to. (edit:) Well I guess I'll still need /some/ assertions but, the static checking at the beginning is really nice. 
This kind of answers your question. The developers suitable to bring Python up to modem game dev standards already moved to better suited languages / frameworks. People doing this for a living use the best tool for the job. 
I never got into frameworks... It was a personal choice, I built my own libraries and i guess pretty much my own framework. I'm sure I would get laughed at if I tried to pawn it off as a framework for everyone to use but it works for me... I have been messing around with python for the past 2 days and I really like it. The whitespace/indent thing kinda throws me off but im sure I will get used to it... I will be using Django after I get the basics down of python, so thanks for the tutorial!!! 
Thanks, will look into this!!
Awesome, Thanks!
I will be hosting myself so this wont be a problem for now but if something were to grow to large for me I will keep this in mind, Thanks!
Will do, thanks man!
Twisted could use some help. Their docs are the hardest to read of any Python project I have seen. 
You could always browse the [open issues related to documentation](http://bugs.python.org/issue?%40search_text=&amp;ignore=file%3Acontent&amp;title=&amp;%40columns=title&amp;id=&amp;%40columns=id&amp;stage=&amp;creation=&amp;%40sort=creation&amp;creator=&amp;activity=&amp;%40columns=activity&amp;actor=&amp;nosy=&amp;type=&amp;components=4&amp;versions=&amp;dependencies=&amp;assignee=&amp;keywords=&amp;priority=&amp;%40group=priority&amp;status=1&amp;%40columns=status&amp;resolution=&amp;nosy_count=&amp;message_count=&amp;%40pagesize=50&amp;%40startwith=0&amp;%40sortdir=on&amp;%40queryname=&amp;%40old-queryname=&amp;%40action=search) for core Python. [This page](http://docs.python.org/devguide/docquality.html) has all of the info you'd need to contribute patches.
there's documentation? 
please, oh please oh please
See Django for an example of great documentation.
Im curious, how did you became a technical writer?
All.
Oh god please I used twisted and most of it was experimentation and reading source to figure out how the damn thing worked. 
Suricata could use some better help with their documentation.
Actually, right now I'm not a technical writer. I'm just a writer. I've done pieces for magazines and websites: interviews, reviews, marketing materials, etc. But this is how I'm getting started in tech writing. 
We could always use better documentation for [Deluge](http://deluge-torrent.org). 
http://www.egroupware.org/community_edition It's php, but an extremely useful framework of collaboration tools, the documentation for which could use a pro's touch. 
CMake, GUI for easily generating CMakeList.txt files.
[Mine (it's called Docvert)](https://github.com/holloway/docvert/). 
all of pyqt? they just copy pasted the c++ documentation for the majority of it. 
It depends on what kind of documentation you want to write. If you want to write server docs, several people have mentioned some options. API docs are also a good skill for a technical writer to have. There's also technical writing that involves stuff like release notes, technical notes . . . and of course, you can also write docs for GUI applications. If you'd like to try the latter, I'd recommend getting involved with the [Gnome Documentation Project](http://live.gnome.org/DocumentationProject). Best of luck!
You could also write guidelines for developers who are trying to write documentation for their projects. Every project could do with improving their docs but it is hard to know how to do so and especially how to do so productively. Or in other words programming in English is hard so help us improve. I also suggest contacting the folks at http://readthedocs.org/ as they can put pointers up on the site for folks who want to review and improve open source documentation.
I'm sure the [Plone](http://plone.org) community would welcome you with open arms to help with its [documentation](http://plone.org/documentation).
yesssss
PAM Openssl
You have a lot of choices already mentioned here, but if you want one more, we could always use people on [Review Board](http://www.reviewboard.org). Right now I'm basically solely responsible for the documentation, and am definitely looking for someone who could take more of a leadership role with our docs.
[RabbitVCS](http://www.rabbitvcs.org/) is a promising UI for (amongst others) git.
yes please!
[Relevant](http://www.youtube.com/watch?v=wjd7L6txGLk&amp;feature=related)
wtf is meta programming ?
I've been using it to parse XML, and it is a joy to use, especially if you're used to the cumbersome and verbose DOM API. If you have XML that looks like this: &lt;feature&gt; &lt;requires&gt; &lt;import plugin="foo"/&gt; &lt;import plugin="bar"/&gt; &lt;import plugin="baz"&gt; &lt;/requires&gt; &lt;/feature&gt; To parse it, just do: tree = lxml.objectify.parse(file) Then you just get the root and navigate from there: feature = tree.getroot() # print all required plugins for _import in feature.requires: print _import.get('plugin') For instance, "feature.requires.import" is both the first &lt;import&gt; tag, and an iterable that will return itself and all its siblings. TL;DR: Using python object attributes to navigate the Element Tree feels very natural. 
Since I'm not a programmer, the majority of the documentation I've read has been end-user material. Looking at the software that's available, I've noticed that the programs that rise above the others are often the ones that have the most accessible documentation for end-users (or customers). Dropbox is a good example of this. There are innumerable ways of doing the same thing as Dropbox does, for less money or for free, but Dropbox's elegant interface and clear documentation have made it king, at least for the present. I've made money in the past doing ghostwriting on subjects about which I knew very little. After interviewing experts and doing my own research, I've found that it's pretty easy to synthesize and organize materials in a way that is palatable and straightforward. Sometimes being an outsider is an advantage in this regard, since the writer can come to the material free of preconceptions. Also, unlike the techies themselves, a professional writer won't skip steps or that seem obvious to those more knowledgeable or make other leaps in reasoning that seem elementary to those more intimately involved with the creation of the project. I'm certainly not 100% positive that I can do the same thing as a technical writer as I have done in other fields, but it is a skill that has translated well for me in the past. Unfortunately, the other fields simply haven't proven particularly lucrative. Pretty long answer, I know. Especially for a non-answer. Are there any examples of technical documentation that you recommend?
And you have parts without any documentation at all. Ugh. What you get is a tutorial, but good luck going beyond that.
thanks for the advice. I gave the presentation yesterday - pitched it as a gentle introduction.....used markov chains to make a text generator, applied it to shakespeare and made them guess between real and fake text blocks. A few animations and how the programming can make their data nightmares less painful. It blew their balls off and they kept me there for a whole extra hour talking about possible applications. It was the best talk I ever gave....
Since you say you're still not very skilled with programming, I'd suggest something geared towards end users instead of a framework/library. [Flexget](http://flexget.com/) is an interesting project I started using lately that has lacking tutorials and recipes.
Seems cool, why is it better than Beautiful Soup?
Because its actually a proper parser, not a mumbojumbo of regex hell.
both are needlessly complicated import glob for f in glob.glob("data (*) good.fits"): ...
The API may not be better (that is probably a matter of taste). However, lxml is significantly faster due to using the super fast libxml2 under the hood (it's likely more memory efficient too).
calling exit from the middle of a program is a terrible practice. he should be returning from the function that is handing the data, or if anything, raising RuntimeErrror or similar.
Mozilla can always use a hand. There is a virtual docsprint scheduled for August 12-13, participants will be offered T-shirts/other swag.
Well, BeautifulSoup surely has its uses for parsing wonky HTML, but for XML I really want a proper parser. I remember using BeautifulSoup for XML, and it [changes all tags to lowercase](http://stackoverflow.com/questions/891690/can-i-change-beautifulsoups-behavior-regarding-converting-xml-tags-to-lowercase) when serializing back to text. That's a major bummer when you process XML for use with case-sensitive tools. Edit: [Here's the BeautifulSoup author recommending lxml](http://groups.google.com/group/beautifulsoup/msg/f5f28d7cae7e98d0) for when you need to preserve the case of your tags. 
telepathy-python, especially on how to use Tubes and deploying telepathy on windows. Oh one more thing, how to use telepathy-python with various python gui tools like pyside, pyqt, wxpython, etc. Also a complete example and tutorial for beginner on how to use telepathy-python with server like ejabberd, openfire, or anything. 
If you see, I was the one who asked him about it a couple months later...he responded to himself saying that he added login support. I'm using it now, and it's okay, but the logging in doesn't really do anything, and I'd love to be able to read comments.
http://sagemath.org is a great project, evolving quickly into the number one open source computer algebra system. It does have documentation, but it's by no means complete.
Or some sort of DOM parser. It's a silly idea really.
Well, I believe [Amara](http://wiki.xml3k.org/Amara/Tutorial#The_XML_bindery) has the best API but opinions are... well just opinions, aren't they? 
PyPy!
When demonstrating the concept I thought it was both useful to show that controlling the number of threads is possible (and simple), and also I believe as a practice its better to be explicit than rely on implicit behaviour that could change in any future Python release. 
lxml is the best. 
Good to hear!
Nice, because concurrent.futures is only in Python 3.2. I pulled this out off the top of my head (and I'm glad you picked up immediately it was a concept demonstration and not a homework answer ;) because I happen to think the futures module is great, and the opportunity to show off how some of these newer Python features (concurrent.futures, 'with' context managers, etc.) can make real-world problems pretty easy was too good to miss! So with map, what you might want to recall is that it takes any number of collections as arguments, and passes the function the sequential item from each. So with a bit of help from itertools you could: import itertools d = [1,2,3,4,5,6,7,8,9] f = "Fred" def dosomething(name, number): print("%s%d" % (name, number)) map(dosomething, itertools.repeat(f), d) 
`lxml.html` is about as good (if not better) than BS in reading potentially broken HTML.
Language implementation. By itself not very useful, but may make complicated applications much simpler through a specialized language. You could look this up on [Wikipedia](http://lmgtfy.com/?q=metaprogramming).
So what will you gain from the GUI? Why will it be better than just playing around with Terminal?
You could call `multiprocessing.cpu_count()` and fall back to a default if it raises `NotImplementedError`. 
Easier perhaps. Certainly more "clear". But I'm not really sure who the targeted user will be.
Meta programming should be practiced with a licence or a prescription. People tend to abuse it. Especially newcomer python devs that are familiar with it.
Not so fast with the full stops! I assume this breaks down horribly when working with large files where you really *must* use a streaming parser.
Care to explain your opinion?
Looks old and not maintained: http://pbnt.berlios.de/ http://code.google.com/p/pebl-project/ http://scikit-learn.sourceforge.net/ http://mdp-toolkit.sourceforge.net/ http://code.google.com/p/pymc/ I only have experience with MDP (but not for Bayesian algorithms) and found it excellent.
ffmpeg -- incredibly useful, but has a horrible command-line interface. Easy to use incorrectly, hard to use correctly. Example: Forget to use '-i' when specifying your input file and you can easily delete it... 
Did you see [my first comment](http://www.reddit.com/r/Python/comments/iq5el/lxmlobjectify_is_the_best_xml_api_for_python_full/c25rd7n)? My use case is that I need to extract bits of information from many different XML file formats. I've looked at DOM and ElementTree APIs, and they all felt unpythonic to me. For DOM, the API is based on a standard that aims to be implementable by any object-oriented language - it must stick to the lowest common denominator of language features. ElementTree requires that I learn a separate micro-language (XPath) in which to formulate queries. But I don't want to have to (re-)learn XPath, I'd rather use Python directly. The lxml.objectify API allows me to do that, by mapping Python object attributes to the document's tree structure. Unfortunately, it's still missing one thing: XML attribute access using Python's dictionary lookup syntax.
why use a metaclass when a class factory will do?
beautiful soup is designed for parsing the web, which is not proper valid xml
Not trying to be deliberately hip and meta here, but if you like documentation I would love to see more help for [sphinx](http://sphinx.pocoo.org/), which is used for generating documentation. Part of the reason I find the sphinx docs insufficient is that I am abusing it to make classroom documents, but it has so much potential to be useful for general-purpose documents for those of us who need more structure than Word and lack the intestinal fortitude to learn tex.
i think you will find once you start writing an actual application that the servers contribution to response time is insignificant in the grand scheme of things. is it worth worrying about optimizing the server that adds very little overhead when the template engine overhead is in the 10's of ms or the database overhead is in 100's of ms? What i'm saying is your will to optimize could probably be put to better use. Focus your energy where it will make an impact :)
What do you mean by graphical models?
Beautiful soup is not designed. Please don't use it. html5lib is a proper parser that was designed to work with the web.
Sometimes a simple class factory won't do, or is awkward. For instance, you want to perform a transformation on all the methods defined in the the class. Using a metaclass is a straight-forward way to accomplish this. Also, I find that metaclasses tend to produce a more readable (once you understand how the metaclass works) declarative style than class factories if the processing options are extensive or complex. Something like the DeclarativeBase behavior of SQLAlchemy would be fairly awkward to replicate with a class factory. Class factories do tend to be a better option if the processing is simple, e.g. something like namedtuple.
&gt; Well, BeautifulSoup surely has its uses Used to, no longer.
I think pymc is the way to go. It is a very complete package, and although it takes a while to get your head around it, it does everything you may want it. It also has an extension to deal with Gaussian Processes, all within the MCMC framework.
Agree, very easy to use. Been using it for a while for my own stuff and it works great.
I can verify this.
Seeing as they are very similar apis, I've never found it to be much of a problem.
Can anyone with experience w/ both say how this compares in features/usefulness to [elementtree](http://docs.python.org/library/xml.etree.elementtree.html)? (It does look like it lacks elementtree's streaming parser abilities, but the attribute-style path walking looks nice)
This this this, and this 100x.
Doesn't PyPy just mostly use the standard Python docs as reference?
It still blows my mind whenever someone tells me they have a server running in anything but UTC.
Is it telegraph based?
Although not python based, one of the best documentations I have found is the Atlassian Suite Documentation. Maybe you would like to give it a look for inspiration? Also I wish you good luck in your career. ;) http://confluence.atlassian.com/display/ALLDOC/Atlassian+Documentation
Running the server on UTC time doesn't really solve more than a handful of the problems that timezones cause.
pip doesn't support installing binaries, making it really painful for anyone under Windows who wants to install packages that have C extensions. Like it or not, some people use Windows, and easy_install has better support there.
Exactly, I've moved from BSoup to lxml and after getting used to the different API haven't had a problem it can't handle.
But neither is the reverse true. What would be the reason for not using UTC for the server time?
I'm not suggesting you should do that. Just that in the grand scheme of things, it's a relatively minor thing.
BeautifulSoup is really good for dealing with crap and lxml is for xml.
&gt; BeautifulSoup is really good for dealing with crap and lxml is for xml. Not nearly as good as html5lib + lxml. lxml is not for xml, lxml is for anything that resembles a document tree, html included. In fact, there is even lxml.html. BeautifulSoup is just a huge hack on top of a weird standard library parser and a pretty weird and dangerous API next to it. There are better tools by far nowadays. I used BS myself for a long time, but I would not do that now.
What's wrong with minidom?
I think he was giving you the Google search query to use if the package was named "num". I didn't really get the car analogy.
Well yes, but not for the whole translation toolchain or for how it is implemented.
Django. Seriously, the docs are good, but they could be better.
[Probabilistic Graphical Model](http://en.wikipedia.org/wiki/Graphical_model) My particular use case would be a [bayesian network](http://en.wikipedia.org/wiki/Bayesian_network)
http://seatgeek.com/blog/dev/fuzzywuzzy-fuzzy-string-matching-in-python This is the only thing I can think of. It was here a few days ago.
I'm taking a quick look at it, but do you know off the top of your head if it handles inference? That's really my main concern.
y = histogram2d(x) contour(y) ... i think, something like this OK: here's an example in full ipython -pylab x = normal(5,1,100) y = normal(5,1,100) pts = vstack((x,y)).T h = histogram2d(pts[:,0],pts[:,1]) Z = h[0] contour(Z) edit: also use the other output from histogram2d to pass coordinates of your data pts to contour(X,Y,Z) other things to make the plot better include messing with xticks(), yticks(), this can be messy though. 
Hi, I'm one of the Twisted developers. Get in touch with me if you'd like to talk about working on Twisted's docs - we're always interested in new contributors.
Make it a wiki. PROBLEM SOLVED
This advice is great, but you kind of have to throw the UTC-only part out the window when you're writing a calendaring app. =(
you may like this syntax: print &gt;&gt;out_File, 'abc' # note: if you add a trailing comma, the print doesn't automatically add \n
I'd suggest starting small - get something that's functional, then see where you could improve things. In this code for example you mention you've never learned how to do a main function, that plus some ability to use command-line arguments might be a place to start. As far as open source projects go, I'd just see if there was an itch I could scratch with a project I know and use. I did that a while back when a coworker couldn't find a wxPython control that really acted like an Excel spreadsheet, so I just cooked one up and sent it over. Not the best code I've ever written but he still uses it today and you can get a real satisfaction from that sort of thing, and that's when you start wondering how you could improve it and your coding at the same time. Good luck and keep at it!
Find me a wiki that supports reviews of changes before publishing and we'll talk.
Then you are kinda out of luck anyways because of DST. From a discussion on hacker news: store UTC and local time + timezone and see if they went out of sync which can happen, then ask user again.
Thanks for the tips! You're right. The main() \_\_name\_\_ thing is something that I understand, I've just never put it into practice because... well, I've never written a "library" module. Everything has been little things like this that I'd never import. So, basically, I don't know how. :) Command line arguments is how I plan to implement handling of multiple calendars. I have a personal calendar and a work calendar. Currently, my hack is to have gc2.py in my path and just cd to whatever directory I want to work in then ./gc2.py there to call a different instance of work.log - programming with duct tape! The roadblock here is exception handling. I've looked at code with it, but have never tried to write it and I know it is something I need to learn. Maybe I'll start there! Thank you for your suggestions. Honestly, I think I just need a place to talk about programming. I've always been a dynamic learner and looking at code, reading books and hacking away at things just doesn't work for me anymore. I need human interaction! :)
Does this write to the file? I've never seen anything like this before.
The equivalent of main() in python is: if __name__ == '__main__': #all of your code It obviously only runs if it's executed directly and not imported, like main() in other languages. Meaning, if you make another program and do "import gc2", it won't run the main function. This is useful, for example, when you make a class, and then have a main function that constructs the class with example arguments. Then people who import it can construct it with whatever they want. Some people also like to do def main(): #all of your code if __name__ == '__main__': main() That's purely for aesthetics though, and somewhat redundant in my opinion.
Wow, that's the best description I've ever read of this! So, I just need to add a single line above the code at the end (the stuff not in a function) and I'm all pythonic? Awesome! :) edit: Oh, and indents! :p
Hah! Most excellent. I just committed that. Consider that added to the do-every-single-time list. :)
If out_File is a file object, then yes. That syntax is a way to redirect output to a file-like object other than sys.stdout. You can even rename stdout: oldstdout = sys.stdout sys.stdout = out_File # this will write to out_File print 'abc' sys.stdout = oldstdout Python is pretty nifty sometimes. You can even do this to save some time with opening and closing files: with open('output.txt', 'w') as out_File: out_File.write('abc') Here once you get out of the with block the file object is automatically closed. Look up with because you can use it with other things as well like locks. They're referred to as context managers and you can even define your own. 
Holy shit that's amazing. I can strip all the newline escapes by using print instead of .write? Is that what I'm getting out of this? I don't want to completely rename stdout as I do write to the console, but just the knowledge that I can print to an object is awesome. I'm sure I read this along the way and the concept just never stuck until now. I may still use .write, just for clarity, but I like the option. Is one more "pythonic" than the other?
Thanks for that example, I don't think I even knew about the "with" statement! I notice you may need a 'w' instead of an 'r' in the open() call though.
What are the advantages of using PunkyBrowster over Spynner? The README just says that some useful features of Spynner have been removed, and a couple of new features added.. 
Are you sure it's meeting the "hasipad" and "hasiphone" conditions? Also I notice you're **enumerate**-ing without using using the values returned. And you're **write**-ing the lists you produced to the cells; not indexes of them. You probably want to do something like: sheet1.write(rownum, colnum, Both[rownum][colnum]) Look through the xlwt docs, there's probably a faster way to write than looping.
let me go back and look over your edits. if you will be around i will get back to you. thank you for giving me some things to look over.
I would second taking a look at fuzzywuzzy. Another workaround would be to create an additional column in your database, containing a 'normalized name', where you would change the (relatively) small set of: Co's, Co.'s, LLC's, A Prof. Corp.'s... to the full monty: Company, Limited Liability Company, Professional Corporation... those are just a few regexes away. Edit: Another thought, if these variations occur only at the end of the names, string.match is an option.
&gt; That's purely for aesthetics though The advantage of doing so is for debuging. If you don't isolate your code inside a function, then when you run: python -i myscript.py your code gets run rigt away without giving you a chance to setup anything.
my first problem is that I am not getting the hasipad/hasiphone loops to return the values back to the variables. i.e. Both=[] is actually just printing '[]' instead of a list of all the values that return yes yes
See what you're getting from: sheet.row(i) [11] Make sure it's what you're testing for.
Okay, what the heck does -i do? I just read the man page which was completely useless...
i will rework how I have it nested, thank you
REWORKED CODE: import xlrd import xlwt Both=[] OnlyiPad=[] OnlyiPhone=[] Neither=[] book = xlwt.Workbook(encoding="utf-8") sheet1 = book.add_sheet("Both") sheet2 = book.add_sheet("OnlyiPad") sheet3 = book.add_sheet("OnlyiPhone") sheet4 = book.add_sheet("Neither") WB=xlrd.open_workbook("/tmp/TV.xls") sheet=WB.sheet_by_index(0) for i in range(sheet.nrows): hasipad=sheet.row(i) [11] hasiphone=sheet.row(i) [12] if hasipad == "Yes" and hasiphone == "Yes": Both.append(sheet.row(i)) else: if hasipad == "Yes" and hasiphone != "Yes": OnlyiPad.append(sheet.row(i)) else: if hasipad != "Yes" and hasiphone == "Yes": OnlyiPhone.append(sheet.row(i)) else: if hasipad != "Yes" and hasiphone != "Yes": Neither.append(sheet.row(i)) sheet1.write(0,0, 'Both') sheet2.write(0,0, 'OnlyiPad') sheet3.write(0,0, 'OnlyiPhone') sheet4.write(0,0, 'Neither') book.save("Email_List.xls") 
I haven't tested it, but try this: import xlrd import xlwt WB=xlrd.open_workbook("/tmp/TV.xls") sheet=WB.sheet_by_index(0) Both=[] OnlyiPad=[] OnlyiPhone=[] Neither=[] for i in range(sheet.nrows): hasipad=sheet.row(i)[11].value hasiphone=sheet.row(i)[12].value if hasipad == "Yes": if hasiphone == "Yes": both.append(sheet.row(i)) elif hasiphone == "No": OnlyiPad.append(sheet.row(i)) elif hasipad == "No": if hasiphone == "Yes": OnlyiPhone.append(sheet.row(i)) elif hasiphone == "No": Neither.append(sheet.row(i)) book = xlwt.Workbook(encoding="utf-8") sheet1 = book.add_sheet("Both") sheet2 = book.add_sheet("OnlyiPad") sheet3 = book.add_sheet("OnlyiPhone") sheet4 = book.add_sheet("Neither") for (rowno,row) in enumerate(Both): for (colno,cell) in enumerate(row): sheet1.write(rowno,colno,cell.value) for (rowno,row) in enumerate(OnlyiPad): for (colno,cell) in enumerate(row): sheet2.write(rowno,colno,cell.value) for (rowno,row) in enumerate(OnlyiPhone): for (colno,cell) in enumerate(row): sheet3.write(rowno,colno,cell.value) for (rowno,row) in enumerate(Neither): for (colno,cell) in enumerate(row): sheet4.write(rowno,colno,cell.value) book.save("Email_List.xls") EDIT: Made changes
Or something like this: row = sheet.row(i) hasipad = row[11] == "Yes" hasiphone = row[12] == "Yes" if hasipad and hasiphone: Both.append(row) elif hasipad and not hasiphone: OnlyiPad.append(row) elif not hasipad and hasiphone: OnlyiPhone.append(row) else: Neither.append(row)
Did you know that if you change all those comments to multi-line strings, they'll be attached automatically to your functions, and people can see them in the python shell with help()? Like this: def gTitle(): """ Get calendar Title from user Format as raw to allow time and date entry. """ a_Title = '' It's a really useful feature for libraries, since you can practically work out how to use it in the shell. Check out [the Docstring PEP](http://www.python.org/dev/peps/pep-0257/) for more info. 
hmm, this is just creating a blank excel file for me with the proper sheet names but no data in each sheet 
I started that in the beginning with the simple intro string, then forgot why I did that. LOL I guess I should go back and clean the comments up proper!
I tried that and I just keep ending up with a blank excel sheet
ok thank you
What I'd recommend is pulling out of the database far more than you need. In your example, you might select rows matching any of the words: "eagle", "bank", "trust", etc. Then, order the results using the score provided by the fuzzy string matching above, and take the top one.
Try changing the haspiad and hasiphone to these two lines: hasipad=sheet.row(i)[11].value hasiphone=sheet.row(i)[12].value Also, I think 11 and 12 will give L and M columns so check if they are the ones with the data.
just gave me this error Traceback (most recent call last): File "TV_v5.py", line 36, in &lt;module&gt; sheet1.write(rowno,colno,value) File "build/bdist.macosx-10.6-universal/egg/xlwt/Worksheet.py", line 1003, in write File "build/bdist.macosx-10.6-universal/egg/xlwt/Row.py", line 248, in write Exception: Unexpected data type &lt;class 'xlrd.sheet.Cell'&gt; 
Change these two lines (and change the sheet number) for all the loops: for (colno,cell) in enumerate(row): sheet1.write(rowno,colno,cell.value) I updated my original post so you can look at it.
will it possible to share your slides?
**This code works**, I've added comments to help divide the areas and to explain what I've changed. import xlrd, xlwt # Open our temp file workbook = xlrd.open_workbook("C:/tmp.xls") # Read the data from the first sheet sheet = workbook.sheet_by_index(0) # Creating lists to temporarily store users (note: this doesn't feel right) Both, OnlyiPad, OnlyiPhone, Neither = [], [], [], [] # Get the data for row in range(sheet.nrows): # Note that cell/col/row do no return a value, they return an object. # You did not have ".value" and were trying to compare a "cell object" # to a string hasipad = sheet.cell(row, 11).value hasiphone = sheet.cell(row, 12).value if hasipad == "Yes": if hasiphone == "Yes": Both.append(sheet.row(row)) else: OnlyiPad.append(sheet.row(row)) else: if hasiphone == "Yes": OnlyiPhone.append(sheet.row(row)) else: Neither.append(sheet.row(row)) # Iterates a list of "xlrd row" objects and extracts the "xlrd" columns to write # one-by-one. Note again the ".value" def writeSheet(sheet, bucket): for row, person in enumerate(bucket): for col, attribute in enumerate(person): sheet.write(row, col, attribute.value) # Create a workbook to save into book = xlwt.Workbook(encoding="utf-8") # I would probably loop through creating these as well... sheet1 = book.add_sheet("Both") writeSheet(sheet1, Both) sheet2 = book.add_sheet("OnlyiPad") writeSheet(sheet2, OnlyiPad) sheet3 = book.add_sheet("OnlyiPhone") writeSheet(sheet3, OnlyiPhone) sheet4 = book.add_sheet("Neither") writeSheet(sheet4, Neither) book.save("Email_List.xls") 
Awesome that you pointed me to the PEPs... I've always heard of them, but never looked for them. This one brings up a new topic: The pep suggests that for stand alone programs the initial docstring should be the "usage" method that can be printed when invalid arguments or -h is passed. that's great and all, but how does one print a docstring without duplicating the text in the code? 
It starts the interpreter loading up and executing your file. Learn to use it early on, and you'll use it all the time for two things: * debug some complicated script, you can put break point in there, then change value and call functions etc... * try things out. At first you'll do that inline in the interpreter, but soon enough you'll be tired of retyping the same shit again and again. So you save it in a .py file, and run "python -i" against it. e.g.: #!/usr/bin/env python def addme(x, y): return x + y $ python -i a.py \&gt;\&gt;\&gt; addme(3, 7) 10 \&gt;\&gt;\&gt; 
ugh, Don't Repeat Yourself. you want something like this: sheet_mapping = { (True, True): Both, (True, False): OnlyiPad, (False, True): OnlyiPhone, (False, False): Neiher } for row in range(sheet.nrows): hasipad = sheet.cell(row, 11).value == "Yes" hasiphone = sheet.cell(row, 12).value == "Yes" sheet_mapping[hasipad, hasiphone].append(sheet.row(row)) 
Oooooh. Awesome! I do exactly what you suggest quite often; fire up the interpreter and build a function to check it before adding it to my code. This is useful! So, by simply embedding my code in main() (or whatever really) and calling it with if \_\_name\_\_ it doesn't get called when using -i? That seems like some odd functionality.
Ah, I was unaware of that. Thanks. I'm a novice programmer myself.
Ok, just got off work. Depending on how much this project is going to be re-used this is closer to how I might do it (outside of simply using Excel's built in features...) import xlrd, xlwt # Create new workbook genBook = xlwt.Workbook(encoding="utf-8") # Bitwise flags are fun IPHONE = 1 IPAD = 2 sheets = ['Both', 'Only iPhone', 'Only iPad', 'Neither'] filters = [IPHONE | IPAD, IPHONE, IPAD, 0] sheetsFromFlags = dict(zip(filters, sheets)) # Create our worksheets based on the inventory and desired stats namedsheets = {} for sheet in sheets: namedsheets[sheet] = genBook.add_sheet(sheet) def lookupSheet(InventoryFlags): return namedsheets[sheetsFromFlags.get(InventoryFlags)] def appendToSheet(sheet, rowdata): nextrow = len(sheet.rows) for col, attribute in enumerate(rowdata): sheet.write(nextrow, col, attribute.value) # Read our temp data workbook = xlrd.open_workbook("C:/tmp.xls") worksheet = workbook.sheet_by_index(0) for row in range(worksheet.nrows): # Scan the data, set the flags InventoryFlags = 0 if worksheet.cell(row, 11).value == "Yes" : InventoryFlags |= IPHONE if worksheet.cell(row, 12).value == "Yes" : InventoryFlags |= IPAD # Write to the appropriate sheet appendToSheet(lookupSheet(InventoryFlags), worksheet.row(row)) genBook.save("Email_List.xls") 
Whoops yeah you're right. Should've been 'w' instead of r. 
My god, use pastebin or at least proper code escaping.
You're right, it does, but you can easily comment out the if __name__ =, then use python -i. Once you're done debugging, you can remove the comments, and you're good to go. If you don't encapsulate your code inside a function, you cannot prevent it from executing when you run with -i.
via: http://blog.rtwilson.com/the-new-ipython-is-awesome/
That's some nice idiomatic code. I never remember to do this when I'm working, gotta keep this in mind.
lxml as a whole is far superior: even if you don't use objectify, you should use lxml. lxml.etree implements the ElementTree API and is [10x faster than cElementTree](http://lxml.de/performance.html), with a host of useful features on top. objectify is built on top of lxml.etree and is broadly compatible with it, so even though you might not want to use it in all circumstances, "ElementTree vs objectify" isn't an either/or choice -- you can easily use both together.
&gt; That's purely for aesthetics though, and somewhat redundant in my opinion. dorfsmay gave some good reasons, and here's why I like to do it: Not using main() means all your variables clutter up the global namespace unnecessarily, and can also lead to less maintainable code that uses those global variables rather than taking function arguments. Also, putting your code in main() gives you the option of importing your script from another script, as a module, and then calling your script's main() function from that other script. Usually untidy, but it can also be useful for unit testing. Additionally, you can add a docstring to the main() function, which helps with generated documentation, or running help(main) in ipython. It also makes general hacking easier - eg: you can comment out the call to main() quickly, or call a different function instead of main(). 
Just looking at it I see that Punky throws errors. This probably the most noteworthy change. Also, it seems that spynner uses embedded jquery to do most of the work. In contrast, Punky uses QWebpage's documentElement, though there is a "runjs" method. Punky's "saveSnapshot" method is useful; you can save a png of the entire page or specify an individual element.
Plus, lxml is able to use html5lib as backend.. or rather html5lib can output lxml-trees so you get all the goodness of a proper HTML5 parser and lxml.
A compromise: Use wiki ACLs to create some approved editors (or, just make them all into wiki admins), block anonymous edits or unapproved users, and then allow people to join the approved list by requesting on IRC/your mailling list/etc. Then in your newsfeed reader you keep an eye on the recent changes RSS feed for your wiki. You do block some pass-by contributions this way, but you also block 99% of spam, and there is more accountability for the edits. 
 print __doc__
Having it on github is great, but unless it's really popular it's unlikely to get much traffic. Simply having code available to share though is great, if you come across someone who might benefit from any of your code you can point them to it. 
Unix systems can fork a new process with copy-on-write access. The forked process has access to all of the global module data up to the fork; it's fast and efficient. Windows, however, calls CreateProcess, and the module gets imported in the new process, so you have to gate the mp setup behind `if __name__ == '__main__'`. Any global state up to the the Pool's creation has to be pickled and copied into the new processes, except for shared memory such as an Array. So you can only share objects that [can be pickled](http://docs.python.org/library/pickle.html#what-can-be-pickled-and-unpickled). I haven't used ProcessPoolExecutor, but here's a simple example that works for me in Python 2.7: from multiprocessing import Pool, Array SIZE = 100000 def sum_block(n): return sum(shared_data[n:n+SIZE]) shared_data = None def _init(data_array): global shared_data shared_data = data_array if __name__ == '__main__': #create an Array of integer type to be shared #for read-only processing you can disable synchronization #by setting lock=False data_array = Array('i', SIZE*10, lock=False) #fork or create new processes. calls _init to set the global #variable shared_data to the Array. pool = Pool(processes=3, initializer=_init, initargs=(data_array,)) #store some data. note the '[:]' data_array[:] = [n for n in range(SIZE*10)] #map sum_block to worker processes result = pool.map(sum_block, [SIZE*n for n in range(10)]) print '\n'.join(str(x) for x in result) 
No slides really - I used a few xkcd cartoons, but otherwise was just, um, "riffing" on my computer. I had prepared a few routines using the awesome numpy library. I'm so envious of students who have the time and opportunity to study with python. 
Cumbersome API (w3c DOM more or less), slower, memory inefficient, lack of lots of features. But it'll be okay for smallish files. 
lxml does offer a streaming parser too (iterparse). But you'll have to stick with the element-tree style API then as far as I know. For the readers: "large" here means *huge*; a couple of megabytes of XML is fine, it's just when you start approaching a gigabyte when lxml's in-memory parsing stops working and you have to switch to streaming. 
i suspected as much
Looks cool
Cool cool cool.
All good reasons. Honestly, this was my first real attempt at being "proper" and not writing this all under one big module like the QB days. :) I can understand why hogging global namespace would be bad in larger projects and I guess it should be something I think about on all projects, no matter how small... I just tend to get lazy with things if I think the project will never be much more than it is. Thank you for all the examples!
Oh python, you so silly. You go and make things so easy! 
You want a kernel density estimate, rather than histogram2d or hexbin. You can use scipy.stats.kde.gaussian_kde, but it isn't designed for large numbers of points. If you'd prefer, here's a version optimized for large numbers of points. It bins things and then uses a convolution, which is an approximation, but is much faster for large numbers of points (but much slower for small numbers of points!). [Here's the code](http://pastebin.com/Du3ZvvKz) [Here's an example result](http://i.imgur.com/e42rL.png)
Yeah, that's what I figured. Honestly, I just need to talk about code. I have a hard time getting excited about other peoples code, so I thought I'd start sharing mine in hopes that I can develop a few people along the way to talk with about it and programming in general. Currently there is zero people in my life that I can talk to about it and it makes it difficult to maintain focus. If /r/python and /r/django don't mind, I'll keep posting questions and topics to discuss because this is as close as it gets for me right now. I've absolutely LOVED reading all these replies and answering them.
Friendly advice for your future debuggings: it's simpler to divide the issue to actually find out what's wrong instead of trying random modifications. For example I would suggest to print the list before adding them to the excel sheet. If they are empty it's a problem in the code filling them, add some printing in your conditions with the values of hasiphone and hasipad to see if they are correct, also check if it loop correctly. If your lists are not empty, check the code after that, maybe write a 4 lines examples using your excel library to see if it works correctly Also for posting code on reddit add 4 space in front of all your code, that will make it display correctly. edit: re-reading your code, you enumerate over the list with rownum and row but you don't use them, and you just write 0,0,list isn't that your error? re-edit: didn't see oohay_email2004 already told you that
That traceback tells you exactly what is wrong: classes cannot be pickled. When using the ProcessPoolExecutor, the data passed between processes need to be pickled. The ThreadPoolExecutor does not need to pickle your data to share it between threads, which is why your code works with the TPE. You can find plenty of good explainations of this on the python mailing list and on Stack Overflow.
Can someone explain the last part about the curry? For instance, how does the argument end up in the right place?
license? 
Ok, I've been addicted to iPython for a while now, just for the command line completion &amp; help... but the multibackend features, the mathematica-like matplotlib stuff? I had *no* idea that was in there. Wow.
I wonder what are the main differences and pros/cons over distutils2.
MIT; http://www.opensource.org/licenses/mit-license.php
The way I end up doing it is that (within a single file) I try to divide up my functions into sections, with little #============ # utils #============ -style section headings to keep them grouped together. That keeps things nice and organized, but eventually the file just gets too big (matter of personal preference, for me ~800 lines), and I look for one of those sections which is large enough, and not dependant on anything else in the module - and I split that one off; then repeat as needed. Keeping things grouped, and figured out interdependancies does become somewhat of an art though. The one hard and fast rule I know of though - if you've got a utility library, and you find different applications are needing different things from it, you may want to split it into submodules so only related functional groups are loaded together - so application A loads only foo.bar and foo.common, and application B loads on foo.baz and foo.common. Outside of those reasons (aethetics, organization, and minimizing load time/memory), there's no real reason why your script can't be 10k lines long :)
Cool.
What exactly don't you understand? How currying/closures work? Or how it works with this Infix class?
Hard to say. For one, I don't really understand what goes on in the curry function, especially the syntax in the nested function def curry(f,x): def curried_function(*args, **kw): return f(*((x,)+args),**kw) return curried_function And also what actually happens here.. Does curry take operator.add as an argument? And it seems like magic that the number 6 gets passed to the correct method and that everything works.. :p add5= operator.add |curry| 5 print add5(6) 
&gt; Brubeck's simple demo: (demo_minimal.py) &gt; $ siege -c500 -t10s localhost:6767/brubeck &gt; Lifting the server siege... done. &gt; Transactions: 9007 hits &gt; Availability: 99.98 % &gt; Elapsed time: 9.88 secs ... &gt; Tornado running simple helloworld &gt; $ siege -c500 -t10s localhost:8888 &gt; Lifting the server siege... done. &gt; Transactions: 8789 hits &gt; Availability: 100.00 % &gt; Elapsed time: 9.71 secs I expected a bigger difference. Why not just contribute to Tornado? I use Tornado now even for non-web apps. Just for the way they wrapped command line args handling and the non-pythonic Python logging module.
Awesome! You cater to my laziness! :) I really just want to avoid the feared "god module" or "god function." If this little utility becomes what I want, it will have quite a bit of code, even for its simplicity. I just wanted to make sure I was doing the "normal" thing. :)
What does your post-processing loop does while waiting for the next content? I hope you are doing something like locking and not just doing an infinite loop that checks non-stop for more stuff. Becaue that would kill all performances. Are you only using 1 thread for post processing and 1 thread for the retrieval? To maximize the potential of threads in your situation, you should have multiple threads doing the retrieval.
[Multiprocessing module](http://docs.python.org/library/multiprocessing.html) It uses multiple processing instead of threading, with some form of message-passing. I've only used it very basically myself, but it worked very well.
The logo looks like the Me Gusta face. Cannot be unseen.
&gt; I expected a bigger difference. Why not just contribute to Tornado? does tornado use zeromq/mongrel2?
yep, and if you need to communicate with processes look into pyzmq, IMO it's way more robust than the mechanisms provided by multiprocessing. 
Nope. I coded with real threads for long running request handlers. I haven't found a need for zeromq yet. Tornado provides option to spawn multiple copies of the server if you have more than one CPU. I know I'm getting off track. Just thought I'd mention it.
The line using the infix operator is equivalent to: add5 = curry(operator.add, 5) The curry function now has `f = operator.add` and `x = 5`. Ignoring for the moment the syntax involved in the inner `curried_function`, understand that when this function is defined, it remembers the variables `f` and `x`. For the case where the function you're interested in currying has exactly two arguments, this is probably easier to understand: def curry(f, x): def curried_function(y): return f(x, y) return curried_function What's going on in the more complicated version uses Python's syntax for functions with variable-sized argument lists ( the `curried_function(*args, **kw)` bit) and for applying a function to a sequence of arguments (the other bit). In this case it modifies the input argument sequence to have the remembered `x` in front. This allows the curried function to work for any number of arguments. 
but brubeck is a mongrel2 handler, so that answers your question as to why the author wrote what they did rather than contributing to tornado. :)
yep, this writes to the filehandle after &gt;&gt;, at least in python 2.x
Ah. Yes! It's so much clearer. Simplified and explained perfectly to my level of understanding. I imagine you must be a good educator. Thanks!
Oh, thanks. What's the advantage of having [Mongrel2](http://mongrel2.org/) under the covers?
This has been by far the most useful comment exchange I've read all week. Thanks to both of you.
Use Twisted to make the requests (Uses no threads and can achieve a very high request throughput) then dispatch the data to a thread/process pool for processing. 
Use libcurl perhaps?
I'm probably not the best qualified to answer that, and maybe the brubeck author could weigh in. From what I understand, mongrel2 is a web application server built with zeromq and supports multiple languages for handling http requests(any language that zeromq supports). the multi-language thing would probably be considered one advantage. mongrel2 being built on zeromq probably offers the same advantages as what tornado and node.js etc would give you as far as being able to handle a lot of connections asynchronously. so async + multi-lang. mongrel2 is actually on my list of things to play with as I get time. Having recently gotten more familiar with zeromq i think that it would likely be a good tool to have at your disposal. 
Or, easier, you can use [eventlet](http://eventlet.net/doc/examples.html) for the downloading -- this is trivial, and works great -- and then, as you say, use something like [multiprocessing](http://docs.python.org/library/multiprocessing.html) to parallelize the CPU-intensive parts.
It's also fairly low-level. Something like [celery](http://celeryproject.org/) might be easier to get up and running right.
Faster, too.
Why not WSGI?
in my experience, zeromq was easier to get setup. ymmv
If someone wants to just try it out on osx (esp. the inline plotting features), I had to grab the following via macport: py26-scipy py26-matplotlib py26-pyqt4 py26-pygments py26-zmq
This is absolutely the fix. Python doesn't do multithreading the way you would expect it to if you were coming from other languages. Here's a good explanation: http://jessenoller.com/2009/02/01/python-threads-and-the-global-interpreter-lock/
how does it compare to django or flask?
Very nice trick indeed, can't believe it's 5 year old and I never seen it used, is there practical reasons for that?
See [here](http://www.dabeaz.com/GIL/) for excellent material and detailed explanations on why exactly the GIL makes this sort of workload slower with python threads. 
This. If you can't use processes, you may need a different language.
If you want the docs, you can find them here as well http://readthedocs.org/projects/python/ (2.7 and 3.x)
&gt; but I am wondering if there would be any other way to go around this and make the processing faster even on single processor machines. Use your OS's affinity masking feature to limit the scheduler's choices. This might workaround the "defect" (IMO) in CPython that Beazley highlights (see kremlan's post in this thread).
Law of Python thread scalability for CPU-bound computation 1 + 1 &lt; 1
If you are running pure python code, it should not be threaded, because of the GIL. If you want to split your processing code, your processing code needs to do a substantial chunk of its work by calling a C/C++ library, or it needs to be in a different process (ie, multiprocessing instead of multithreading). Your fetch is faster because it is both calling C (I think?) and doing socket IO, both of which release the GIL. Pure python code will NOT release the GIL, so you are doing the exact same thing as you were before the threading, except now you're bouncing back and forth between a bunch of threads even though only one of them can run at a time (because of the GIL). In short: Don't ever thread pure python code unless you're doing IO.
Some of the special things I had to do in my homegrown REST system: 1. the REST client is capable, roughly, of having [webtest](http://pythonpaste.org/webtest/) mocked into it so that a functional test can run both sides (client/server) of the application in one process. 2. a hook can be given to allow special handling of errors, including that they can be converted into a particular kind of message format, etc. 3. the system accepts XML/JSON and returns both as responses based on the value of the "content-type" header. 4. setting up a client looks like: client = Client( "http://foo.com/api/", error_handler=my_error_handler, some_api_call = Get("/some_api_call/%(id)s", schema=SomeSchema, headers={'Authorization':standard_auth} ), some_other_call = Post("/some_other_call/%(token)s", headers={'Authorization':standard_auth} ) ) usage looks like: # get - returns a SomeSchema schema, parsed # from the returned JSON/XML response = client.some_api_call(id=5) # post - given a SomeSchema, rendered # into JSON response = client.some_other_call( token=12, SomeSchema(name='foo', id='bar') ) Values in the "headers" dictionary, like "standard_auth" above, can be a string, or callable that produces the string at calltime. "error_handler" receives ClientError instances that were thrown and can re-throw or do other handy things. SomeSchema is a presentation-neutral schema like that provided by [Colander](http://docs.pylonsproject.org/projects/colander/dev/). If you can get something that's similarly simple+featured, then I can use your product !
Not that this has much to do with your problem, especially since the site is back up, but I also just decided to really learn python. I have a little background in java, c++, and php, and let me tell you - Dive Into Python (free ebook) is the way to go if you have previous programming experience. I'm almost halfway through and it's a really easy but thorough read.
I CAN NOW STEAL ALL THE DATA!!! tyvm for this link :)
I'm afraid I don't know enough Python to be of any real use yet.
This is a great idea. Thanks!
There's supposed to be an article on it on http://hacks.mozilla.org/ "this week", but it doesn't seem to be there yet. If you want more info, join #devmo on irc.mozilla.org (I'm cers there, jms is in charge of the docsprint)
One of the main difference is bento support for pluggable build engines, which is helpful for packages which need fine-grained control of compilation options, compiler. Doing so in "distutils1" is difficult, and reusing existing build engines like waf make a lot of sense. But it also works fairly well for simple packages. For the cons compared to distutils2: still mostly a one man show, is not concerned with what happens after installation yet (integration with pypi, etc... is non existent, but you can use pip to install a bento package), and you need to rewrite your package metadata (but there is a command to convert simple distutils packages to bento format). For the pros: I think bento is more extensible. You can add new categories of files to install, package description is clearly separated from operations on it, adding new commands is easier. But don't listen to me: just try it on your own package (using bentomaker convert as a starting point), and make up your mind.
Perhaps I am missing something. What's wrong with [imp.load_module](http://docs.python.org/library/imp.html#examples)?
I know there are things that do this, but maybe include it for the sake of completeness: the ability to parse a WSDL file and produce python objects from it.
True, the setup for celery is kind of irritating, but once you've got it running, it pretty much does what you want it to, unlike 0MQ, where there are some great design patterns in which it will be amazing, but nothing is quite as trivial as you'd like it to be. (I should qualify my praise for celery: its rate limiting support is not up to the task of not getting cut off by Facebook, so I'm going to be moving away from it on Monday, in favor of something involving Redis, which is the most lovely database I've ever met. Redis is beautiful.)
Maybe I am also missing something, but even if there's something wrong with imp.load_module, what's wrong with: import sys sys.path.append('/home/me/mypath') import mymodule sys.path.pop() 
import "mymodule" didn't work. for example: &gt;&gt;&gt; time = "os" &gt;&gt;&gt; import time &gt;&gt;&gt; time &lt;module 'time' from '/opt/python2.7/lib/python2.7/lib-dynload/time.so'&gt;
&gt; The first tipoff that this book was a bit strange was that the author uses Windows and some combination of Firefox and IE. It seems like most web developers use OS X (or occasionally Linux) Most web developers use Macs? I've never noticed that.
I'm not sure what you're trying to demonstrate there... time = "os"? what is that for? Also you didn't seem to change sys.path at all? The sys.path is the module lookup paths... if you add your path to the list, it will look in your path, and will load modules from there. Also if you're loading a module that is also named "time" (it conflicts with the standard library "time") then you need to assign your path to the beginning of sys.path, not using "append" like I did. Otherwise it will find the standard "time" module first and load it. That's generally a bad idea though, you should not name your modules the same thing as the standard library -- extremely confusing. Anyway, I was trying to agree with you in the first post, I was just offering another way to do this that is like your way: a lot simpler and more clear than the way the blog post suggested.
sorry for my broken English, I just want to demonstrate that 'import "string of my moudle"' didn't work. for example, even assign "os" to a variable time. 'import time' just import original time module. not os module. so, if we get a filepath(a string, such as "/tmp/foo/mymodule"), we can't just load it with 'sys.path.append("/tmp/foo");import "mymodule"' 
That's true, you're right. Good observation! I wasn't thinking about using strings, in which case your method works better.
I came here to say this. You can do what the example did in far fewer lines.
Neat. I've got a question, though: why do people keep writing new web frameworks? It almost seems as though the web framework is python's version of the text editor. Everyone's written one.
Anyone else read this as "Netflix operator hack for Python?" 
Python is the only language you can learn in a week. I love writing up simple games and apps in a matter of minutes to impress friends with. 
Take a look at [ProtoRPC](http://code.google.com/p/google-protorpc/) features. One good idea is that it sets a "message" protocol to be used by both clients or services (so, e.g., a JS client talks the same 'language' as the service). It parses messages in JSON, Protobuff or urlencoded formats (no XML afaik). Docs are [here](http://code.google.com/appengine/docs/python/tools/protorpc/overview.html).
Quoting from [a post on /r/programming](http://www.reddit.com/r/programming/comments/irbli/simplicity_oriented_programming/). "Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it." -- Brian W. Kernighan
What you might like to do is get a third-party Python distribution from [Enthought](http://www.enthought.com) or [ActiveState](http://www.activestate.com) as both include the upstream Python documentation. At the moment I really like Enthought, in their new EPDFree release they include common modules people like such as numpy, and also bundle the new 0.11 ipython too. ipython will help you debug why your script doesn't work a lot easier than the standard python shell, even if you never learn any of its moderate-advanced features. I mentioned something random about Enthought and EPD on twitter and got a quick reply from their staff and followup in email, so they obviously care a lot about their product and reputation. Can I also recommend getting a book - even if its an online freebie like diveintopython (included in ActivePython) just so you have some relevant labs to work through as you learn concepts - then also think of something yourself (you've got something in mind, otherwise you wouldn't be learning Python in the first place) and use that concept there. For example, when I first started using the 'with' statement I went back through my old scripts and converted all of them to use it when appropriate - and it cut out a LOT of fluff code. I had some backend servers I wanted to execute some jobs on, and they can be parallelised so it was a perfect scenario for learning the multiprocessing capabilities. I had some data manipulation to do and it helped a lot to use list and dict comprehensions and generators to both make the code more readable and also make it run faster and use less memory. This wasn't all in one sitting though :) One thing I like is that you can do pretty much anything in the core Python language and the original distribution, e.g. in one place I wasn't able to install numpy, matplotlib, PyGTK etc. so I had to compensate by rolling my own GUI and graphing with TkInter (to do the small subset of functionality my program required). Not as pretty, but the fact you can actually do and achieve that in Python and its just straightforward for an afternoon's work is pretty phenomenal IMO, esp. as I can count on the fingers of one hand the number of times I've typed "from tkinter import *" before that, and still have left-over fingers. Best of luck in your endeavours learning this great language! 
I guess not.
Ok. I will try it next time i need it. Thanks for advising me.
i don't know how much more trivial 0mq could be. you import pyzmq, you create a context, you create a socket, you write to it or read from it. and I was merely recommending it as a better way for threads/processes to send each other data than the Queue etc that comes with multiprocessing. 
Imho : Because it's fun, you learn a lot and you always have specifics/details you want to address differently than in other frameworks -- that's my own reasons, as I write one too.
If we were talking about this in an air conditioned room, 5.6ms is the time it would take for the words "yeah, it's pretty fast" to travel from my mouth to your ears.
Thanks. Some subreddits have a really high signal/noise ratio, I've started to hunt for those and un-subscribe from the others, and it makes for a very pleasant experience. * edit: i never know where is the signal and where is the noise. I just looked the [wikipedia page for signal/noise ratio](http://en.wikipedia.org/wiki/Signal-to-noise_ratio) and it turns out signal is the numerator, so I meant high, not low!
It was just released Friday, and it supports any Blueprints-enabled graph database, including Neo4j, OrientDB, Dex, OpenRDF -- a InfiniteGraph implementation will be released next month.
&gt;HTTP gateway timed out Edit: ok, it's up now.
neat. so it requires pygame and presumably pyopengl? though they aren't listed in setup.py requires and i see Cython mentioned as well. adding to the "stuff to play with when I get time" queue. 
looks awesome, but can't access the page 
I haven't taken a close look yet, though I'll give it a shot given how much I like what's out there already :), but just a tiny criticism: &gt; kivy is the most awesome framework (for any language) for creating stunning user interfaces This isn't really the best way to get me to try out your framework.
some like wsgi some dont some like webob some dont some like kitchen sinks some dont some like sqlalchemy some dont some like learning and figuring shit out themselves and have time to do so some dont 
I was looking at this the other day. I was under the impression that it's meant for developing of touch based apps. Is that about right? 'Next gen UIs' seems to imply something a bit more comprehensive. 
thats why i put the disclaimer i guess. I really do feel that way though; we started kivy because we think the way other frameworks are designed from the ground up is flawed because they mostly are grounded in paradigms that no longer apply (like input is always mouse/keyboard based, so all widgets are written to that assumption, you just want to use standard components, rather than easily make custom controls etc.) i think I understand what your saying, I don't like it when people make overly general or bold claims either I guess. What would have been a better way to get your curiosity sparked? 
seems to be down due to too much traffic. reddit + hn = :( server
pygame is one of the libraries you can use as a window provider (and image loading etc.). The kivy core is designed in a modular way so you can use various providers for input/window/image/camera/video laoding etc. we've written a layer on top of OpenGL ES that provides drawing instructions that can be used by the end user (and you can still write your own OpenGL ES 2.0 code). The instructions are sweet though becasue we essentially have written a JIT compiler for the graphics instructions, that will optimize drawing by compiling our instructiions to a merge vertices and avoid state changes, while never leaving the cython generated c-code thus avoiding context switches from c to python. 
&gt; (like input is always mouse/keyboard based, so all widgets are written to that assumption, you just want to use standard components, rather than easily make custom controls etc.) By saying more things like that :). I think you want to lead with your strong points– which you've partially done in that paragraph and again just now, so those were good. The overly general stuff generally puts me on my toes, so I'd typically leave out the "most awesome" and "stunning" there and let my feature set speak for itself :). Anyways, don't read too much into it, all I meant is that exaggeration is fishy and the wording wasn't great, if you've really got something good though, neither of those will matter much in the long run. Thanks for sharing!
multi-touch is and has been one of our primary focuses, and reasons for starting the framework. However it works just fine with a mouse and keyboard. The nice thing is that we have a unified event model, that allows the same application to work with mouse/touch/multi-touch based input, and lets developers easily check what device generated the event or what features it supports without having to know anything about interfacing with the underlying OS or actual hardware.
thanks, i'm not to worried, but I very sincerly appreciate your feedback!
its loading, albeit bery very slowly here. reddit + HN brought too many people at once :/
Is kivy able to read the accelerometer on android? The answer is not obvious from the documentation and I didn't find much with google.
kivy is the same as PyMT, no? Name change? Why did you guys change names?
Does it have a module for sprite loading/saving/transformation?
kivy is pymt 's successor. At UDS last year we decided to do a big rewrite of most of the library. while we used some of the code from the core providers, we decided on the rewrite so we could take the best ideas and experiences from PyMT and fix some of the mistakes we made. the result is kivy, which especially in terms of performance is way more advanced than PyMT while using some of pymts ideas about how to make it easy to code these kind of applications, borrows good ideas from qt and other frameworks aand introduces new ones. 
&gt; we essentially have written a JIT compiler for the graphics instructions, that will optimize drawing by compiling our instructiions to a merge vertices and avoid state changes, while never leaving the cython generated c-code thus avoiding context switches from c to python. That is fucking awesome.
An issue have been opened while ago for that, didn't go time to push the code yet, it have been done at last europython :) https://github.com/tito/kivy/issues/169
If you're one of the kivy developers, mind telling me wtf this sentence means: &gt; Check the Generic launcher if you want to execute application without creating APK: check Installation for Android It's got 2 links on it from the Android hover-over, but the sentence doesn't make any sense whatsoever. Do I check the generic launcher if I want to execute an application without an APK, or do I check Installation for Android? And what do I do in order to *create* an APK?
i thought something like this was bound to happen, kudos!
Requires Windows 7? :(
also runs on linux, osx, or android
the generic launcher allows you to put just the pyhon/kivy apps on your SD card, the launcher then shows you a list for all apps on your SD card which you can start from there. If you create your own apk, it will make a stand alone app that just launches your app. see the documentation here: http://kivy.org/docs/guide/packaging-android.html
I'm just saying...tell them to fix that sentence. It doesn't follow any kind of logical formatting. I know exactly how Kivy works (PyGame subset for Android works the same way).
I already have some return about people using it on vista, only native multitouch is not available.
And the "correct" behavior would be?
http://www.reddit.com/r/Python/comments/ba3rk/bottle_python_web_framework/
Perhaps this isn't what I need. I'm just looking for something to use to create forms for data entry/calculations. I need it to be compatible with Windows XP. I don't need multi-touch. This will be an excel-type "plug and chug" type application. Not for handhelds. Just computers. Should I be looking elsewhere?
Thanks for that. Where would you suggest I look?
 In [1]: a = [] In [2]: for s in [1,2,3]: ...: a.append(s) ...: In [3]: a Out[3]: [1, 2, 3] In [4]: s Out[4]: 3 
s should not be affected outside of the list comprehension I would suspect. It should be treated as a local variable to the list comprehension -- at least that's what I would expect it to do. If for some reason I was using the variable s, set to...say...1,000 (which would be stupid, I know), and then used a list comprehension afterwards with [s for s in [1,2,3]]...it would be resetting the variable I was using outside of the list comprehension to 3.
I think he meant "broken" Can anyone come up with a real world example where this actually causes a problem? 
Fixed in python 3. Though, IMO, not "broken".
Yep! I love this subreddit. I've lurked it for a year. I'm glad I didn't get the "take this to /r/learnpython"
How does the android deployment process work? How large is the apk relative to the application code size? I'm wondering if I have to include 100+ MB for python...
I have always thought of list comprehensions as more of a shortcut than something that would define its own scope. Take a C/C++ example which kind of mimics the behaviour: int i = 56; for (i = 0; i &lt; 42; i++) { // solve life } This results in i = 42, not 56. Don't really see this as a problem.
I tend to agree. Besides, anybody reusing a previously populated variable in their list comprehension deserves whatever trouble they encounter.
We embed Python and some modules, not all. Feel free to add to your project what you really need. As for the size, check PreseMT (https://market.android.com/details?id=org.kivy.presemt) and fit in 4.9MB.
Apparently all Ruby devs do. Therefore all web devs do. Because everybody knows web development is mostly about Ruby. Also, MacOS X is popular with web _designers_ for historical reasons. Given the quality of the rest of the review, I wouldn't give his musings about web devs too much thought. For example, the template functions in jQuery are not intended to be used yet and will be moved out of the core library soon-ish. Also Firefox is still very popular because Firebug &gt; Chrome dev tools (and I say that as a Chrome user).
I think the reason this isn't particularly popular is that it makes the resulting code harder to read for anyone not familiar with the trick and the exact intentions of your code. Also, the fake operators result in non-PEP8 code layout.
the multitouch picture viewer app from the examples ends up being 4.2 MB as apk (it's on the market for free). that is including three images of decent resolution. 
then how could we do this dynamicly?
I know I'm complaining about something free, but I really wish this were available in PDF.
[Removed in Python 3.0 :(](http://www.python.org/dev/peps/pep-3113/)
&gt; make the processing faster even on single processor machines How do you see this working?
Make it render through a HTML backend like QT/lighthouse or GTK and I will love you forever.
comments? sure :-) your function and variable naming seems completely random. I have no idea where you are getting these names from.. * gInfo() -&gt; load_credentials() * gTitle() -&gt; get_title() * gDate() -&gt; get_date() * gTime() -&gt; get_time() * gAdd() -&gt; add_event() * a_Email -&gt; email. etc * s_Time -&gt; start_time * xTitle, xDate, rTime. WTF? It seems as if you think variable names have to be unique across the entire program. they don't. various issues: a_Creds = gInfo() calendar_service = gdata.calendar.service.CalendarService() calendar_service.email = base64.b64decode(a_Creds[0]) calendar_service.password = base64.b64decode(a_Creds[1]) You need to think about how you are writing functions and using them. Why does the function that reads the username and password return the encoded string? Decode it in the function, then do username, password = load_credentials() calendar_service = gdata.calendar.service.CalendarService() calendar_service.email = username calendar_service.password = password I have no idea what you are doing here, you are constantly wrapping things that are already strings with str(). xTitle = str(gTitle()) xDate = str(gDate()) rTime = str(gTime()) if rTime &gt; "": xTime = rTime.split() sTime = "%sT%s" % (xDate, str(xTime[0])) eTime = "%sT%s" % (xDate, str(xTime[1])) else: sTime = xDate eTime = xDate `if rTime &gt; "":` should be `if rTime:` further, why do you concatenate the two times into a single string, only to split them up again? If you want two strings, return two strings. `while (a_Day == ""):` should be just `if not a_Day:` a_Day = "%s-%s-%s" % (str(time.strftime('%Y')), str(time.strftime('%m')), str(time.strftime('%d'))) again you are calling str on things that are already strings, but it's all irrelevant because you can just write a_Day = time.strftime('%Y-%m-%d') general problems: You are using the log file as a configuration file. When have you ever seen another program do this? Your API is cumbersome. `gAdd(calendar_service, title, start_time, end_time):` Should be `def gAdd(username, password, title, start_time, end_time):` or `def gAdd(configuration_file, title, start_time, end_time):` Or at least you should have methods like that in addition to the one where you pass the calendar service directly(that one is good for testing, but not very user friendly) 
Curious that no one has suggested [gevent](http://www.gevent.org/) yet. For single processor machines, gevent should be able to beat multiprocessing and threading for the IO bound piece. For the CPU-bound piece I'm not sure how much any of these approaches will help on a single processor machine. AFAIK multiple threads/processes really only become useful when you have multiple cores concurrently running your processes.
What does it even mean to parallelize on a single processor? Also, I recommend [gevent over eventlet](http://blog.gevent.org/2010/02/27/why-gevent/) since it uses a more consistent API to threading and multiprocessing, among other reasons.
Replying to myself for the sake of future readers -- the current development version of IPython works just fine with PySide. That is to say, the qtconsole itself works fine. However, the Qt event loop integration *within* the console still does not work, either with the new Qt console or the stock terminal console. If you have to have Qt event loop integration (interactively creating Qt GUIs from the command line), for now you'll have to stick with PyQt.
On a single-core processor without SMT, there will indeed be no advantage to parallelizing a program -- but that's seldom the situation these days. Also, I recommend eventlet over gevent because the documentation is so much nicer, and eventlet supports thread pools for running blocking code, such as all the various blocking C extensions out there. MySQLdb and an Apache Zookeeper client are the ones that I use right now.
I agree that it's rarely the case, but it was specifically asked in the OP's question.
Where does it say that? Maybe I'm just blind but I couldn't find anything in the installation or FAQ.
I don't normally recommend Python newbies a web framework, especially a heavy one. Not because I dislike web frameworks (I use Pyramid myself) but because I think it does the user an injustice because they never fully understand how the framework works. They just know if I type blahblah.render() it just works...where as they need to understand how the stack actually operates. I usually send people to a micro framework first too, large frameworks such as Pyramid, Django, or web2py can be daunting. 
I dunno, I think you need to start with some overly general but strong points to catch attention sometimes, so that people will even bother to read the rest of the points. People have *very* short attention spans nowadays. (Also more people will come if they think we have punch and pie!)
Having worked with both, I much prefer pyside (QT).
[Broken in Python 2.x](http://ideone.com/WpE4j) Apparently [fixed in Python 3.x](http://ideone.com/JC6K7) Yes, Python scoping has had a hairy history, but I think it's become rather decent lately.
Ah, so I was indeed correct in my assumption. It just seems the most logical to me (as someone who doesn't do C/Java/C++/C#)
At least, python has a scope.
Um, click "Downloads" on the site home page. Then read the page that comes up. It says "Required: Windows Seven (32/64 bits)".
ಠ_ಠ This kicks ass... Thank you 
nice ... ZODB www.zodb.org should also support blueprints.
It's actually under consideration from a long time ago. I already did an analysis for previous version (pymt) using pyjamas, and it was 2 month work for making it happening. For Kivy, we could do Cython-&gt;Python (Cython gsoc undergoing) + Pypy-&gt;Javascript (Was possible before, and pypy guys would be able to put it back if community ask for, what i already did). Then, it's just a matter of writing core providers for Image, Video, Window... in Javascript. And then... nothing will stop us :)
Google app engine does not even support 2.6 I think
Can you say what you don't like about wxPython?
Awesome! How do I run the programs, though? I have a WebGL enabled browser, but I only see a black rectangle where I would expect to see the WebGL canvas. Also, I don't see print output in the console. Should I? **Edit: Project-&gt;Save All and Run (F8)**
Linked to 1: Webhosts don't have it.
I've been using bottle for prototyping (and in some cases growing) lightweight projects. I'm not a web dev (can r/w HTML, can't do the same for CSS!) but I picked up bottle in an hour for writing simple pages, uploading files and providing a RESTful interface. It gets a +1 from me.
GAE could be one main reason why some web frameworks still support Python 2.5
4\. OSX 10.6 still ships with 2.6 by default
10.7 ships with 2.7
10.7 has not shipped yet. Until it does, the only Apple-provided version of Python on OSX is 2.6.1
The Celery rate limit is not distributed, it only rate limits within a single celeryd instance, also it uses a token bucket algorithm, which imposes a limit on the average rate, and allows for bursts of activity. What you want may be a leaky bucket, which gives a constant hard limit. Adding leaky bucket support to Celery shouldn't be that hard, but then if you want to rate limit across celeryd instances then I usually recommend using Redis in combination with celery to do that. (celery + rabbitmq + redis is a great team).
I support 2.5 due to GAE (and Jython to a lesser degree). I support 2.6 because it's easy enough to do; using 2.7-only features would be nice but nothing compelling enough to make me ditch 2.6 compatibility.
Thank god.
&gt; Are we referring to the context of deploying a commercial app? We're talking about reasons for not using Python 2.7 yet.
iPage servers only do 2.5
&gt; So you're just to lazy to update python for your own local scripts? Does this even make sense in your head? Because it makes none as serialized in your comment. &gt; Or maybe you are dependent on Apples enhancements to the included python? I'm not dependent on anything, but I do not subscribe to the idea that "it works on my machine" is acceptable. People using what I provide may or may not have the desire (or technical chops) to install Xcode and a new version of Python via homebrew or macports or whatever. Python 2.6 is the baseline on 10.6 (which has been out for 2 years now), so as far as I'm concerned it's a very good reason to not require 2.7 if there's any chance of OSX users wanting to run the software. 
he was talking about bundling the required python version with your program. you could code in 2.7 or 3.0 for all it mattered if you bundled the necessary files with your installation.
&gt; They'll have to install Xcode anyway No. &gt; if you use any uncommon modules and you don't bundle them pre-compiled with your deployment. If and only if these are C modules with no pure version which are not available in the base system. &gt; And your deployment strategy is to not bundle the modules neither the interpreter with your deployment? You seem very hung up on deploying stuff. That's not healthy.
&gt; he was talking about bundling the required python version with your program. I'm not "deploying" anything when I'm providing python scripts or single-file python applications. &gt; you could code in 2.7 or 3.0 for all it mattered if you bundled the necessary files with your installation. There is no installation.
The latest version of Slackware (13.37) ships with Python 2.6.6.
Because 3.2 is out.
then clearly his solution does not work for you.
woah! i had no idea about sys.stdout redirection! set_stdout(fd): sys.stdout=fd restore_stdout(): sys.stdout=sys.__stdout__ set_stdout(out_File) print "lol" restore_stdout()
&gt; How many modules on pypi do you think are coded in C? Many. ## WOW! MANY? THAT'S SUPER DUPER NOT NICE, WHAT AM I GOING TO DO NOW, AND MORE TO THE POINT why the fuck should I care? That they exist does not mean I 1. want or 2. need them
I cant extract the file i downloaded for Linux. Anybody have the same problem? Getting this error while extracting gzip: stdin: unexpected end of file tar: Unexpected EOF in archive tar: Error is not recoverable: exiting now
Pypy have reimplemented parts of the stdlib in python - I wonder if it's worth using those for missing bits. Also I believe there's a unit testing framework for compatibility, it would be good to get this working so that it would he easy to see what needs attacking. [edit] not to mention that parts implemented in rpython might be easy to translate to python.
I downloaded Kivy from Git hub and when run make (linux) I got the following error I am using Python 2.5.2 in Debian lenny python setup.py build_ext --inplace setup.py:76: Warning: 'with' will become a reserved keyword in Python 2.6 File "setup.py", line 76 with open(config_h, 'w') as fd: ^ SyntaxError: invalid syntax make: *** [build] Error 1 
No psyco for 2.7.
You are sad about Windows from &gt;10 years ago, but don't mention any other type of OS from even &gt;5 years ago. haha...
You'll need python 2.6 or higher; or alter that file to from __future__ import with_statement (from memory; might be slightly wrong)
Download it again or check the md5
Blame the victim?
Google App Engine has 2.7 on the roadmap and is likely to ship with Python 2.7 support soon.
Yes, this.
Thanks it worked. But cant install cython on Debian lenny. 
It might be simple but it isn't fast. The documentation says that similarity search takes over 5 minutes, which shouldn't be the case even with all of PubChem loaded. I think it's because they don't use MySQL integer fields for fingerprint bits, but instead they do the search in user-space. There's a lot of SQL sanitization code which is there because they don't use the db-api correctly (it uses sql_string % fields!). My guess is there's a decent chance of SQL injection attacks. I must say it's the first time I've seen a while statement with a lambda: "while ( lambda limit, results: limit &lt; 0 and True or len(results) &lt; limit )(limit, results):". BTW, the package uses the Javascript structure input widget plus backend from the Indigo toolkit. I think that's recent addition because the main documentation doesn't mention it.
Considering I don't have a problem in the first place, I would not expect it to. Not like he provided any solution to the non-existent problem.
you have pypy compatible with 2.7
That's what I'm talking about! I have a bunch to talk about regarding your post, but I'm going to go over it and my code, then get back to you. I hope you don't mind having your inbox flooded. :)
I know. This is an awesome trick. I'm sure I'll be using it in the future!
Pypy doesn't work with Numpy. Psyco does. 
To me the choice is either: 1. you want your script/apps to be available to most people, in which case check what is the least common versions on all popular platform, including RHEL adn SUSE (which are "entreprise" versions and tend to be a bit behind). 1. you have full control over the version of python - in which case, there's no reason not to use the latest 3.x stable.
I did that, but then I get an JavaScript errror: runoutput is not defined, ide.js (line 120)
Because you need to use a specific version that is tied to some other application. I manage enterprise software that is tied to version 2.1 :(
This should also be on [/r/SEMANTICWEB](http://www.reddit.com/r/semanticweb)
Yes, but the number of libraries supporting Py3K haven't reached critical mass yet. We are close, but not quite there yet.
Reportlab and SciPy
I use Python 2.7, but I write code that still works on older versions because many of my potential and actual users don't have 2.7 installed.
Layout managers are annoying and I never found a good way to do absolute positioning of widgets. QT's widgets are also richer, more configurable, and there are more of them. Also it's my opinion that QT looks nicer and more contemporary. These are all pretty subjective, but it's my opinion. Before some white knight inevitably rides in to defend wx and tell me how wrong and biased I am, keep in mind I was asked to say what *I* don't like. I'm not saying wx is bad or QT is better, I'm just saying that personally **for me** QT is the better choice.
Go ahead and post it... (/r/semanticweb has a decent number of readers, but submitters are a bit sparse...).
What about them? Reportlab has 2.7 binaries as of October 2010, and SciPy as of February 2011.
psyco is 32bit only, and with very little support. There are people working on getting numpy on pypy.
I will definitely be trying this out with Flask sometime in August. Which graph database should I try first? My requirements for complexity, scalability and speed are minimal (10,000 nodes or thereabouts in a DAG.) Therefore ease of setup coupled with stability of the DB implementation are probably my main drivers.
because of GAE
You should look at Neo4j. The community edition is now free and the embedded version comes bundled with Rexster. It's easy to configure -- here are docs on how to do it (http://bulbflow.com/docs/quickstart/#rexster). P.S. I'm the author of Bulbflow and will be releasing more of the Web toolkit in the upcoming weeks, including Flask libraries that do authentication and authorization in a graph-DB way. Check out the Gremlin Users group for graph-related discussions (https://groups.google.com/forum/#!forum/gremlin-users). 
It can even saveSnapshot() when it's running invisibly. We have a fair amount of regression, etc. tests that are using this now.
Alright, I've updated a lot of the stuff you've discussed... so please please please look it over and give me more feedback. This is the stuff I like! - As for naming convention, I'm horrible at it. It's an artifact of years of BASICA and QBasic. I'm not used to reading functions as their own little programs and so I name things to differentiate it. I need to stop this. I'm obviously not using the global namespace... that's the "right" way... right? - As for the function that gets credentials and such... yeah, I'm rewriting that. I think I'm going to build a credentials file (yml?) to hold login data and allow the user to pass it as an argument at runtime. The reason I used a single file for the login and log was part laziness, and part a simple solution to handle multiple calendar accounts. I'm working on it! :) - String formatting... um, yeah. This was a product of "I'm not sure, so I'll wrap it." I wrote ZERO error handling, so I did this for robustness. It's been removed because I need to do some proper error handling anyway. - I really appreciate the *if* and *if not* help. I always assumed that '' was not equal to not/none - lesson learned! - I wasn't even aware I could do the time.strftime the way you did it. That's MUCH nicer! I'm working on rewriting functions now to improve the API. Once I get everything a little more solid I'll begin implementing the new features I have planned. Thanks again! 
Well the Python ecosystem is huge. For example, I couldn't care less about Django. I'm personally waiting for IPython.
I tend to use a combination of both: git submodules to track which particular version of the other project I'm using, and virtualenv to "install" them with. I keep all the submodules in a src subdirectory and then can `pip install -e src/django` (or similar) to have them accessible from the virtualenv.
I have used both and they can both work. Checking the version of Django you are using into your source tree works astonishingly well. It Just Works. I have a hard time understanding and remembering how to use pip/distribute/setuptools/virtualenv and it am often frustrated when a download fails when trying to deploy or PyPi is down for maintenance or an old package version is no longer available or has moved. On bigger projects where the number of dependencies can grow past 50, tools like pip and setuptools save time. It really comes down to what you want. Do you want to have slow checkouts, or do you want to try and keep things in sync some other way?
Ahh, good point. My experience of trying to setup that configuration on Snow Leopard is somewhat out of date, I guess. Although there still isn't a nice package installer for SciPy / Py2.7 on OS X (such as [Superpack](http://stronginference.com/scipy-superpack/)).
The main problem that I foresee with using git sub-module for dependency-tracking is that git won't automatically compile binary extensions for your distributions like pip will. I could be wrong, but I'm under the impression that that could break certain packages that rely on binary extensions. As such, I'd be more in favor of doing using mikeboers's approach. 
Because 2.5 and 2.6 are good and productive, and for an existing system the effort to move up to 2.7 may not bring enough benefit to be a priority task. 
Let me know what there are differences between [Gunicorn][] between this. [Gunicorn]: http://gunicorn.org/
i think numpy works already - or is very close to work.
Superinteresting! Are there some videos or screenshots of example apps to get an impression of how it looks? I like the website, by the way. The whole project looks extremly well and passionate done. Congrats!
Open the file in 'r+' mode, like this: file = open(filename, 'r+') r+ means append, while "w" means write/overwrite. EDIT: my apologies -- my brain was somewhere else when I wrote this. 'r+' is read/write, 'a' is append. Bluh.
Looks like an awsome job you have done there... And the frontend design looks great... Going to check this out in more detail...
Based on what I was able to find after rummaging through PyPI some days ago, there is none. There is a handful of WIP ones. Some are abandoned. Nothing comes close to what you'll find in the PHP realm. I guess Python projects are generally more about using frameworks to build things from scratch rather than installing third-party software on a server and just filling it with data.
I've seen such handling of dependencies quite a lot. It takes time for people to realise and admit. Having dependencies with your code is **bad**. If not anything else, for security reasons (you should patch the software, not ever package that bundles it) De facto standard is distutils+distribute. It's how every linux distribution installs python code. What is very little know to django comunity is buildout. It has lots of recipes, also for running django. But this one might come handy in your case. It checkouts from versioned repository and runs python setup.py develop on packages http://pypi.python.org/pypi/mr.developer/1.17 [sources] my.package = svn http://example.com/svn/my.package/trunk update=true some.other.package = git git://example.com/git/some.other.package.git branch=customfeature It comes really handy when you have patches for software. You fork on github and use oneliner to use your git repository instead of egg release. Also, I highly recommend pinning down versions as buildout offers to.
Plone has gotten much easier to install recently. If you can install Python, you can install Plone. See http://dist.aclark.net/build/plone/4.1.x/README.rst
Do i then just say file=open(filename, 'r+') file.write(array I need written to end) ? 
'a' is append. 'r+' is read+write.
I hate to be "that Plone guy", but there is [Plone](http://plone.org). :-) And depending on how you rate your CMS, Plone is much better than most PHP alternatives (e.g. security-wise, for one.)
To import a module from a string, you can use the [`__import__` builtin](http://docs.python.org/library/functions.html#__import__) &gt;&gt;&gt; themodname = "os" &gt;&gt;&gt; themod = __import__(themodname) &gt;&gt;&gt; themod &lt;module 'os' from '.../os.pyc'&gt;
As mackstann said, use 'a' for append. f = open('file.txt', 'a') f.write('some text') f.close() You'll need to convert your "array" to a string before writing it. How you do this depends on what you are trying to do .. a = ['foo', 'bar'] f = open('file.txt', 'a') f.write(str(a)) # will output '['foo', 'bar']' f.write(" ".join(a)) # will output list elements separated by a space f.close() 
Thanks a lot, feel free to let us know of any feedback you may have!
If you are already using numpy (read: C library) for your number crunching, the gains from Psyco should be minimal (if you are doing it right).
If you're using &gt;=python 2.7, you can use a with statement: with open('test.txt', 'a') as f: f.write('foo') 
Like [mackstann mentioned](http://www.reddit.com/r/Python/comments/it5mv/append_text_file_in_python/c26fpr2), you'd want to open the file with the mode 'a' for appending. fh = open(filename, 'a') fh.write(stuff) [More info](http://docs.python.org/library/functions.html#open)
Probably doing something stupid but I can't figure out how to serve to anyone outside the computer the script is running on. I opened port 8080 but I still could not access the hello directory. It does work with localhost:8080 from the machine running the script. If there a setting I need to change to allow these pages to be viewed? Warning: I may be missing something obvious/doing something very stupid.
What about [skeletonz](http://orangoo.com/skeletonz/About/)? Haven't actually tried it - just asking.
Having a computer science degree should really allow you to, with a little bit of practice, perform at least adequately in any software engineering field. If you went to a university that placed a heavy emphasis on swe, you should be able to perform well in any such environment. 
Try Kotti, based on Pyramid framework.
Great design! I'd love to give this a spin.
we use it alot for our work at fresk: http://fresklabs.com (most videos are usin old versions/pymt, need to upload videos of our newer work also). we also just started http://thenobooth.com which is done using kivy.
if it's always in the same spot you can just take a slice, like the_string = 'wordwordword23wordword' the_number_in_the_string = the_string[12:14]
Thanks, you can [signup](http://mediacore.com/signup) for our free beta and get started. 
 import re c = re.search('\d+', 'wordwordword23wordword').group() If it's in the same exact indices of the string, then you should have just asked: "How do I extract a substring from a string?"
you may also want to cast it to an int s = "wordwordword23wordword" n = int(s[12:14]) print "The number is %d." % n
I've worked on the credentials function quite a bit now. It is now possible to implement multiple sets of credentials in a single file which will be iterated through until the correct set is found. I'd like to know how sloppy this code is before I continue. I also moved the b64decode there as you suggested.
Numpy, scipy, and pygame to name some reasons. 
yes, although if you do you have to be extra serious about trusting the integrity of your input. slice on a string that's not long enough won't make a runtime error but casting bad stuff to int will.
But ... Zope!?!
If you have anything to do with Kotti -- the demo[*](http://kottidemo.danielnouri.org/) linked from docs does not work. edit: works now
It crashes - a lot! If I had to rely on it for semi-serious applications, but couldn't, how would you convince me. It's not my intention to come across as facetious, but it's a bit funny how often the example apps crash. Is there a reason why my 64-bit OSX 10.6 would cause problems?
Just to clarify, I'm looking for people that want to participate with me in the design, creation and enjoyment of the game. I'm looking for programmers, writers, anybody who wants to collaborate. 
Interesting. I've been hosting podcasts for my friends. I will definitely look more into this.
How about: import string st = "wordwordword23wordword" newst = int("".join([c for c in st if c in string.digits])) which works regardless of where the numbers appear. Like the regular expression suggested, but without regular expressions. 
Your page is... completely empty. It doesn't even mention that the goal will be a 'command line game'. I think you need to have something more before you start soliciting help.
Working on it. I guess I should have had more complete before posting...
SWEEEEEET
I can do that for you by reading 2 links. but maybe you might like to do it yourself? :P
import re str = "wordwordword23wordword" c = re.findall(r'\d+', str)
 ''.join(x for x in s if x.isdigit())
I've been looking for a good library that does Python objects -&gt; XML. Any suggestions ? I understand lxml is great for the other way round. 
I'm a Python(/programming) noob, but I'd love to help if I could.
I'd like to contribute
I don't know why it's crashing for you, we use it in production kiosks at http://fresk.co and http://thenobooth.com (we run it mainly on ubuntu though), and I know several others are using it in production environments like museum exhibits etc. It would be super awesome, if you could file a bug report on github with the output of the example app when it crashes: https://github.com/tito/kivy/issues thanks!
Seriously. I'll take Drupal over Plone anytime.
The interface and feature set looks incredible. I've been looking for something similar, but I don't think Mediocore is geared towards this. Suppose I already had a collection of video files and wanted to have a web-based app index them, pull IMBD descriptions/artwork (or perhaps Amazon Video), and allow searching. Could Mediacore be setup to handle anything along those lines? A similar example would be the Calibre web server (Calibre is also written in Python), but for videos.
Not really a CMS, but maybe worth checking out: http://pyjs.org/ 
i like this the best
Maybe I should have checked Reddit earlier today; I didn't read your comment until after I'd already written the code. :-) What I ended up doing was writing a task queue with Redis that did token bucket rate limiting on a per-OAuth-token basis. It works great. The disadvantage is that it doesn't support multiple instances; adding that would take another hour or so.
Hey. Sorry... I didn't know Brubeck was posted here until just now. Mongrel2 connects to request handlers across a ZeroMQ socket. This is more efficient than the usual approach of upstreaming HTTP connections, which sometimes timeout and always require the overhead of HTTP. From there, receiving a message from Mongrel2 is a lot like receiving a web request, but it's a JSON string and I have to send a response across a separate ZeroMQ socket. Many people like the routing system of Flask / Bottle with a function wrapped by a routing decorator, so I added supported for that. Many other people like the web.py / Tornado approach and because I was most familiar with Tornado I figured I'd support that too. Turns out it wasn't too tricky. From there I was having fun and writing demos to show each milestone I was reaching. I added template rendering. Then cookies. Then authentication. And after that I just wanted to build a full project so I built listsurf. https://github.com/j2labs/listsurf I have a whole social networking layer coming out soon. JSON API + basic following graphs and based on streaming lists. Listsurf being an example of a list of links. I regret not thinking to come here sooner but I'm pleased to see people accurately describing the differences between Tornado and Mongrel2 handlers. If you check my repo, you'll see I actually did try putting ZeroMQ in Tornado and around that time found Mongrel2. I read up on eventlet and that was that. https://github.com/j2labs/dillinger It's named after my other favorite band with odd time signatures: The Dillinger Escape Plan.
Because it pulls messages straight off a ZeroMQ socket instead. There are reasonable reasons to consider WSGI support at other layers but I haven't finished that investigation yet. What is your opinion of working with WSGI?
It is similar with the exception of how it interacts with a web server. It speaks directly across zeromq sockets to Mongrel2 and that provides some very interesting arrangement opportunities. For example, you can have one Mongrel2 box sending messages across TCP sockets to 20 handlers running on 5 big boxes; 4 per box. None of these boxes need to run a webserver and they don't even waste resources with a zillion file descriptors. It's just one ZMQ socket per Brubeck instance. Because Mongrel2 just sends messages and waits for responses it is asynchronous. Brubeck gains asynchronous / nonblocking behavior by using Eventlet (or Gevent). It will take blocking Python drivers and convert them to nonblocking automatically. Tornado does not offer anything like that so people are often left to solve painful blocking issues themselves. The interfaces to handlers is similar to Flask. It can also be similar to Tornado. I attempt to support what I perceive to be the two most popular patterns for web request handlers. Where it really shines is in the ability to handle a large amount of concurrent tasks. It feels like Flask but performs like Tornado.
I believe the combination of Eventlet, ZeroMQ and Mongrel2 is a new combination. I had spent 9 months building with Tornado and Bottle and my experience with Tornado left a sour taste in my mouth. I felt strongly that Python needed simpler options that can scale as easily. Especially with Node.js adding yet another implementation of Twisted's model to the table. I started building around a modeling library called DictShield because it allows me to build features that require data models without having to insist on any particular database. Relational, document oriented, key-value... whatever. I'll give you a python dictionary and you can sort it out however you see fit. I also really like coding.
"Some people, when confronted with a problem, think “I know, I'll use regular expressions.” Now they have two problems." -- Jamie Zawinski: August 12, 1997
I think mine is the shortest one: &gt;&gt;&gt; filter(str.isdigit, "wordwordword23wordword") 23
How these packages becoming a reason ? Those things doesn't support 2.7 ?
I tried a couple weeks back with the installation and on windows it looks for 2.6 
We use [buildout](http://www.buildout.org/) for multideveloper projects that require synchronizing multiple dependencies.
It is nowhere close. Also their (pypy) approach is to rewrite numpy in RPython which will never happen.
It is not minimal at all. Usually I get 5 times speed up with psyco and numpy.
this looks interesting. I'm going to bookmark this for later viewing
Have you played nethack or other rougelike games? How is this different from that? 
Hi there, I am running an older version of SILVA CMS (http://www.infrae.com/). It is Zope based, however it is not that bloated like Plone and therefor running fast even on a VM. Have a look at it, it is worth checking out.
I dislike this quote and have come to believe it is part of the problem. It makes regexps look like dark magic you should avoid instead of a technique which should be learnt like any other. In my experience, people unable to write correct and reliable regexps to solve their problems are no more able to write correct and reliable "manual" parsing code either.
Setting the timezone was unnecessarily confusing. I'm in the UK. Normally, when selecting a timezone, I have to pick Europe, then London. Not there. I noticed it was grouped by country, so I looked for United Kingdom, which is normally listed near Uzbekistan, United States, United Arab Emirates, etc. Not there. So I figured you didn't understand my country, and looked for England. Not there. So I thought maybe you were going by geographical region and looked for Great Britain. Not there. I finally found it under "Britain (UK)". Please, if you're you're going to do things differently to every other UI on the planet, at least get it right. "Britain" is not a synonym for the United Kingdom and nobody looks for it in lists like this. When setting timezones, London is usually grouped under Europe, and when picking a country, you should use United Kingdom.
We're working on it for release soon: https://github.com/ipython/ipython-py3k
btw, you can replace your whole imgName reversing/splitting/reversing code with: imgName=os.path.splitext(image)[0] you should also know about str.rfind, which'd let you rewrite it as: imgName = image[image.rfind('.')+1:] but that's a bad idea. (it's basically the same thing, minus the reversing) os.path.splitext is a much better solution. 
just check it with n.isdigit() before casting
Or PyPy: http://morepypy.blogspot.com/2011/07/realtime-image-processing-in-python.html
My 'High Performance Python' write-up from my 4 hour EuroPython tutorial is probably useful: http://ianozsvald.com/2011/06/29/high-performance-python-tutorial-v0-1-from-my-4-hour-tutorial-at-europython-2011/ It covers splitting CPU-bound tasks to use multiprocessing (for many-core) and ParallelPython (for many-computer) pure-Python approaches, along with PyPy, numpy, Cython and ShedSkin and pyCUDA (though all treated as single-cpu in the doc). v0.1 was released a few weeks back, I hope to get v0.2 out in the next couple of evenings.
You should check out the a new cross platform vision system library I have been building with people. It wraps opencv amongst other vision libs to make it super simple: img = Image("/tmp/pic_with_faces.jpg") faces = img.findHaarFeatures() img.show() http://www.simplecv.org Please check it out, I'm working with one of the founders of slashdot on it and trying to get some momentum behind it. I believe it can be the processing/jquery of machine vision.
&gt; I also really like coding. I suspect that this is the *real* motivating factor. Which is great! I think I came off pejorative in my original post. Really, I'm just sort of amused. It seems to me that a web framework is just the kind of problem that is implementable, non-trivial, and interesting. It used to be that the text editor fit this role.
you should look at ConfigParser http://docs.python.org/library/configparser.html config = ConfigParser.ConfigParser() config.read('example.cfg') username = config.get(account, 'username') password = config.get(account, 'password')
I'm also confused by the fact he's using pyglet yet it's a "command line game".
Using the with statement is always a good idea. Reduces clutter, and makes sure your files get closed.
While your statement is completely true, I think that Regex suffers from the same issue as XML. It's a fantastic, portable, robust tool that is far too heavy for the task at hand in many cases. String manipulations in python with Regex are often slower than using the builtin string functions. Like any tool, it's important to know when not to use it.
PM sent
[Me Gusta](http://media.tumblr.com/tumblr_lf431jew2v1qbu91v.jpg)
PM sent
I have played a few games. It definitely won't be as in-depth to begin with since games like nethack have years of development. My initial thought was a Zombie game meets Rogue meets Fallout where you can upgrade different abilities, group up with a team of AI, potentially create new weapons from the weapons and items you have. I wanted to find a writer to actually have a good story (since writing definitely isn't my strong suit). Basically I just wanted to code something that I'd play.
Ya, forgot to remove that code :P The initial code dump was very quick just to get a repo up. 
[NumPy 1.6.0](http://sourceforge.net/projects/numpy/files/NumPy/1.6.0/) has installers for 2.5, 2.6, **2.7**, 3.1, and 3.2. [SciPy 0.9.0](http://sourceforge.net/projects/scipy/files/scipy/0.9.0/) has installers for 2.5, 2.6, **2.7**, and 3.1. [pygame 1.9.1](http://pygame.org/download.shtml) has installers for 2.4, 2.5, 2.6, **2.7**, 3.1 and 3.2.
You should turn this into a blog post somewhere
Indeed. Once I figure out how to capture the output from the application, I'll add some more insightful comments. Just drag-and-dropping the .py files onto the Kiva app doesn't allow me to see a stack trace.
Ah OK. So this is something mostly with `print` statements and command-line input, right?
That's what I was thinking ya. I'd also be open to ideas from anyone else. We could make it web-based, or tile-based or really whatever we want.
LoL. That would have been useful last night. I spent quite a bit of time figuring out my parser.
I'm not very clued up on Python, but the frameworks I hear about a lot are Django (like you said) and Pylons (which is what Reddit runs on).
it's simplecv.org
Yeah I jumped on the django bandwagon since there are a lot of people hyping it up, but when it comes down to it, I don't think people really do use it, due to the lack of current information. Another thing is 1.3 has come out recently and the developers are very trigger happy with changing the code, thus making everything else pretty redundant unless you enjoy looking through the changelogs.
You must be a troll. Django has the best documentation of all open source projects on this planet. And you can google for ANYTHING and you will find answers on stackoverflow, snippets on djangosnippets and millions of blog posts. Forget books. THEY will be outdated. Learn to use the internet. Google loves you.
Going to go download 2.7 right now. Thanks!
My gripe is that most of the code changes within Django version to version, so when you do find something you are after, you have to spend just as much time figuring it all out. Are you saying I should stick with Django then?
I really wanted to practice my coding skills, and get a professional blog started (killing two birds with one stone) I know I should just use an already made solution like wordpress, but I really want to create it myself as a proper "project" as such.