Several developers just use "what's in the box" so unless the majority of linux distros use python 3.x by default, most of the projects just will use the installed python 2.x
A couple of weeks ago, people were complaining about how difficult it is to distribute Python applications on Windows. This is a new project to make it easier. Unlike tools such as cx_Freeze and Pyinstaller, it doesn't try to make an exe of your program - instead it makes an installer that will install Python on the user's system, then install your code, and make a start menu shortcut to launch your application. That makes bigger installers, but it's less brittle than freezing code, and with a bit of care you can build the installers on Linux (probably Mac too, but I haven't tested that).
* Already added more docs on *path* variable. * Already rebranded as you suggested. * The pattern you suggested for get function looks like a really good idea. will consider it. &gt; Thanks a ton for the constructive criticism. 
Actually is a greek loan. It's not a single word though, it's a phrase of two words "και + έτερα" -&gt; "κ' έτερα" (=literally "and others"). That's why etcaetera is completely wrong spelling , the vowels of 'και' would not be pronounced before a word starting with epsilon(ε). 
Internet, I love you &lt;3 http://t2.gstatic.com/images?q=tbn:ANd9GcTiNDB9LZSOVj-EgtSm_QYpeOIgW6FM0yRxhg_b7sGK6_vUC3lCVc_XkzS7-Q
This is absolutely fantastic. I'll definitely be changing over my homegrown monstrosity in one of my current projects to this.
The 64kb of previously de-allocated data is sent as an answer to each heartbeat request, which can occur many times during one TLS/SSL session.
I love this approach. I have already ask [previously](http://www.reddit.com/r/Python/comments/21pnhi/how_to_improve_user_experience_in_usinginstalling/), that Python should be treated in the same way Microsoft treated .NET Framework installation. This tool should be halfway of my previous thinking
It sounds like what you want is CRUD. A quick google search comes back with many projects that might fit your needs. The problem you will have any framework or ORM is on complicate table structure. translating what you want to change visually back to sql statements (or ORM logic) can be tricky. You'll find you'll have a lot of 'if than else' logic that may be unique for one and only one use case.
Yes, I was inspired by the way .NET apps are distributed, with an installer that installs the framework if necessary first. You could extend this approach to a network installer that only downloads Python if it's needed, but for the first release I decided to keep things simple and include the Python installer.
Thanks for your advice, I've added a notes so the readers would also consider another options 
Interesting, could you tell me how those things work in CherryPy? Because I don't quite see it myself.
There just aren't any real benefits to me, and there's always the chance I'll end up needing a library that isn't supported. Aside from a few little syntax improvements, I've never seen a compelling case made that Python 3 is a significant improvement.
Depends on what you're doing. I do some devops using Ansible, so I'm likely to use whatever Python is bundled with the OS we deploy to so I don't have to add any extra software and things "just work".
I need this
My project isn't ready for prime time by any stretch of the imagination. I suppose I could put up another experimental build, but it's moving so fast that I just don't see the point. (it used to be exclusively Python 2 and now it's exclusively Python 3 because 2 is evil)
I use both for different things. Any scientific computing pretty much has to be done in 2.7
So good article. I'm still mindfuck for the last result, and I don't even know exactly why that happen...
On occasion, I have to work with WLST, which uses jython 2.1. That's kind of painful, but the pain is mitigated by the ability to use Java libraries to cover for the holes in 2.1. I also write some python scripts that have to run in RHEL 5, which uses python 2.4. Hopefully we'll be upgrading to RHEL 6 soon, so I can start targetting python 2.6. The real limitation is that I have to use the version of python available on the server. For personal projects, I stay at or close to the latest release of python 3.
The 2.5 million XO laptops out in the wild all use 2.x, so as long as I want to call myself an XO developer, I'm sticking to 2.7.
How? virtualenv and pip make it really easy to switch between python environments and python 3.4 comes with such capabilities built in.
Centos, and all of the non-3 distros any potential users are on.
I use a number of different programming languages. It simply is not important to me to use a specific version of a language at this time. Most of the time the language that is available is more than sufficient for the task.
Big but reliable. I like this. I gave up trying to package django using cx_freeze, py3exe, pyinstaller ..
thx dude i just switched this one is more fancy
This is fucking sick.
Thanks!
But if you want an if condition based on an argument, you **have** to do it with a regular string. Again, it doesn't hurt, so who cares? I write docstrings like this: def func(): """ stuffA stuffB """ return 10 which isn't how some people write them, but there's nothing wrong with it. I think it's clearer than def func(): """stuffA stuffB""" return 10 
The python ecosystem was a deciding factor for me. Language wise, both Ruby and Python are great. Although Ruby has traction beyond Rails, it's no where close to python. There does seem to be more learning materials out there for RoR versus Django, but I think in the past year and a half that's also starting to change. Either way, both are great web frameworks.
Feel free to call it obj then. It is a convention and also signals to the developer that the generic function also works for subclasses of the model.
Why is that the case? 
Does it set up virtual environment or are the packages installed globally?
I wasnt being 100% honest. What I should have said was, "If you're doing any niche scientific computing, and dont feel like pulling your hair out in frustration, you pretty much have to do it in 2.7" If you're just modeling a dynamical system or some heavy matrix algebra (I think numpy is ported to 3) then 3 is fine. Given enough time, there will be a point where you think, "Hey, I need a package that does 'X'." And you will look that package up and see its only compatible with 2.x. You'll do this once... maybe twice if youre a die hard "3er". Then you'll install 2.7. I specifically use Continuum's Anaconda just for the simplicity. Its great.
YES! A THOUSAND TIMES YES! This is awesome! If we can build on this to package pre-built binary extensions, we've got magic stuff.
Python and its standard library are installed globally. The packages included with the application are installed into the application's directory in program files. It doesn't actually use virtualenv, but those packages will only be visible to that application.
Thanks! Note that while you may not need Morepath's app extension as much as you'd need blueprints in Flask, it is there when you need it, and support s overrides too.
Thanks ;-). I'm not quite sure what you mean about binary extensions. If you want to distribute extension modules to end users as part of an application (e.g. PyQt4 in a Qt application), it can already do that. If you want to distribute the libraries themselves for developers, there are already tools to make installers - Christoph Gohlke [makes a lot of them](http://www.lfd.uci.edu/~gohlke/pythonlibs/). Plus wheels look promising.
EAs are the future.
lol what?
Sorry if this is retarded but how do I install this on windows?
a bunch of encoding shit
WxPython, VTK, and PyInstaller, and OpenMDAO (NASA modeling framework) don't uspport Python 3.x. Because we have a lot of software that already works in Python 2.7 and some software that still has to work in Python 2.4 because that's what our customers use. Python 3.x doesn't have any required features for us.
Thanks for the quick reply. Here's the __init__.py file (as created by pyramid): from pyramid.config import Configurator from sqlalchemy import engine_from_config from .models import ( DBSession, Base, ) def main(global_config, **settings): """ This function returns a Pyramid WSGI application. """ engine = engine_from_config(settings, 'sqlalchemy.') DBSession.configure(bind=engine) Base.metadata.bind = engine config = Configurator(settings=settings) config.add_static_view('static', 'static', cache_max_age=3600) config.add_route('home', '/') config.scan() return config.make_wsgi_app() How do I call the current main to return that?
This is pretty awesome, and I'm eager to use this. I have a couple questions. 1. I know right now this requires Python 3.3. Are there immediate plans to support older versions of Python? (We're looking to build an installer using Python 2.7 for now, as our codebase isn't ready for 3.x, and we're still supporting 2.5+ for enterprisey reasons). 2. The software we're looking to package is a set of command line scripts, and there's no need for a start menu entry. Right now, people get these through the entrypoints we have defined, which easy_install will turn into actual scripts. Can we get the same behavior here? It looks like the "entry_point" config item does what I want, but it only supports a single entry point. 3. We make heavy use of entrypoints for registering a bunch of plugins. This works fine with easy_install. I'm guessing this might be problematic with pynsist? Thanks for creating a nice alternative to projects like cx_Freeze, and also for providing a good pros/cons for why you'd use one or the other. Very useful.
thanks! the last code piece is a bit tricky. I'll give you a hint: function parameters are bound to their default values at definition time —that is, at the same time the function name gets bound to the function body. When we call a function with arguments, these parameters get rebound to the provided objects. But what happens when we call the function without arguments? Does any binding operation happen then?
This looks great! Going to give it a go tomorrow. Nice work mate. 
based on that code, you would want 1 additional line but it's probably not what you want. main = main(the_config, **anything_else) uwsgi expects a function with the wsgi app signature which is 2 params a dictionary, and a function to callback with http headers(make_wsgi_app returns such a function), you are giving it instead a function that takes 1 parameter. the signature to your main function is what something like paster would call and hand a bunch of values from a config file. you could try uwsgi --ini-paste-logged your.ini for more info: http://uwsgi-docs.readthedocs.org/en/latest/Python.html#paste-support 
and another way.... from pyramid.paster import get_app main = get_app(os.path.join(__this__, 'production.ini'), 'app') assuming that is where the production.ini is and the section is called 'app'
Fantastic work! I really like this solution.
Thank you very much. This has been very helpful sir/madam.
Some one should do this Open Source with python and LibreOffice
What happens if the system already has Python installed?
I use Python 3 at home, have done ever since I started learning 3 years ago. At work I use Python 3 for a couple of reasons: * I'm programming psychology experiments using Pygame, and Python 3 support isn't really guaranteed yet. * I use Anaconda to get numpy, pandas and other libraries set up quickly and easily on Windows, and while you can create Python 3 environments in Anaconda, I can't be bothered activating and deactivating environments every time I need the other version. 
totally agree - Google Sheets would be another interesting option...!
Ahhhhh! I get it now! When you call a function withouth parameters Python evaluate the default parameter and save it in some memory position, when you use it inside the function, you change the value in that position. When you call it again, Python sais: "Dude, I know where are the default parameter of that function, is in that position", but if the value had been modified, you get the modified. Is it right? :-) I guess that it can be corrected with something like that: def foo(x=None): if x==None: x=[] None, or any non-mutable type should works.
 LookupError: No section 'app' (prefixed by 'app' or 'application' or 'composite' or 'composit' or 'pipeline' or 'filter-app') found in config /var/www/wsgi/venustate/production.ini I tried playing around with the production.ini but no dice :(
`",".join(["thank you"]*100)`
examples?
Alright. . . i see what it is... the docs are broken WAY out, and each area/section is sealed away from the others. I was looking in 276 tutorial. Then when I looked in l language reference, chapter 5 is "expressions" . . . your link goes to Library Reference. TIL that I may have to look in more than a couple different doc repos for the answer to my question.
I've been unable to find any reasonable solution for python3 + MySQL + Django. MySQL-python appears to be a dead project. There are several forks that claim python3 support but none that the Django developers feel comfortable recommending. The official mysql-python-connector seems to work (as in, all the unit tests for my project pass), but my tests take nearly twice as long to run. I haven't measured exactly where the slowdown is, but it seems reasonable to infer that this package has performance problems. After a bit of coaxing, I got PyMySQL to work, but it still lists itself as a beta package, leading me to worry what edge cases I'm going to hit. It also adds somewhere between 10-20% to the time required to run tests. I haven't evaluated CyMySQL yet. Given its description I would expect it to be like PyMySQL with better performance, but it is also a beta package.
* If it has the same exact version, nothing. * If it has an older bugfix release (e.g. system has 3.3.1, app has 3.3.5), it is upgraded. * If it has another version of Python, the new one will be installed alongside it. This isn't anything special pynsist, does, though - it's just the default behaviour from running the Python MSIs
You can `pip install pynsist` on any platform. You'll also need [NSIS](http://nsis.sourceforge.net/). I appreciate the irony that pynsist doesn't have a double click installer itself, but it's a developer tool, not an end user application.
Sorry about the release announcement not talking more about what it is. Luckily you did find the docs! Concerning the rich API, thanks for bringing this up. If I understand your question right, then it is how does Morepath deal with more complicated scenarios where you want to touch multiple database models and involve other logic. If you have such an abstraction in your application that you want to be able to address using a URL, you can create another model that does this for you. Models don't have to be database models; you can route to any Python class. I'd argue that is better than just creating an ad-hoc route, for several reasons: * it's still a good idea to separate your user interface operations (spit out a result to the user) from the underlying operations. Your code will become more testable, more comprehensible, and potentially more reusable. * if you have more than one path with the complex operation on it, you benefit from the linking logic. * perhaps you want multiple operations (GET, POST, say) on the same route. You don't have to repeat the route information if you have a model and two views. Even the CRUD example has a non-database model, namely a collection that is not directly backed by a database, but represents a query into the database. Consider the scenario where your collection is batched; you have multiple instances of the same collection you want to address using next/previous: collection/1?offset=0&amp;limit=20 collection/1?offset=20&amp;limit=20 You can create a Collection model that has the offset and limit information in it and has a method that can do the appropriate database query for you. The view code then uses this method to get the results. You also have a next() and previous() method on the collection to get the previous and next Collection instance, if available. Since you can link to model instances, creating the batch links becomes easy. For an example of such batching code example you can look at morepath_sqlalchemy: https://github.com/morepath/morepath_sqlalchemy Or for a more RESTful example morepath_react (which is very similar, but has a pure JSON backend and a frontend based in React; you can ignore the JS for this example): https://github.com/morepath/morepath_react You want to study the collection.py odule and the bit of view.py that uses the collection. tl;dr: It's a good idea to model things. Morepath encourages you to model things by letting you neat things with models, and this will make your code better, not worse, than plain routing. 
that's it. When the function is defined, the x parameter is bound to its default value, an empty list. As the function is later called without arguments, x is not bound again and references the original list every time. using ` foo(x=None) ` is the correct approach, but make sure to check using `x is None`rather than the equality operator! [1] [1] http://legacy.python.org/dev/peps/pep-0008/#programming-recommendations
The site says you can install it using pip. pip is a package manager for python. Here is a stack overflow question that detail various ways to install pip on windows. http://stackoverflow.com/q/4750806/1281548 Fun fact, this install is what prompted me to learn Linux. I was trying to start with Django at the time and I found getting pip on windows a pain and much longed for the joys of; $ apt-get install pip $ pip install newHottness I found (in the end) it was worth learning Linux because you'd be two commands away from getting this project and trying it out.
I work at my work with openstack and libcloud at the moment... so it's quite difficult to move to 3.x but for my personal projects I use 3.x :) 
I imagine it will still make big directories, but it's hopefully easier to understand than cx_Freeze. And you're right, the join solution is better there.
not yet ....
This looks great, but I was curious why you went with INI file syntax, rather than something a bit more robust such as JSON, especially when some of the configuration constructs require decidedly non-standard INI syntax, e.g. [Include] # Importable packages that your application requires, one per line packages = requests bs4 html5lib versus { ... other stuff ... 'packages': [ 'requests', 'bs4', 'html5lib' ], ... more stuff ... } with the latter being trivially processed by json.load(config_file). Not trying to pick on you, just genuinely curious about that particular design decision. I'm definitely going to be checking out the project in more detail, it seems really handy. For what it's worth, I agree with the others that want to see Python installations on windows handled rather like .NET, installed if necessary or use the existing install.
Fascinating, but I'm still not exactly sure what he did. Wish this had more details on the GP aspect.
Why not parse a setup.py or a setuptools generated sdist/wheel to find what python files should be included / packages required, etc, instead of a custom format?
INI isn't really fashionable nowadays, so I was expecting someone to ask that question. I picked it over: * JSON - no support for comments * YAML - the parser is not in the standard library * Python - automated modification of scripts is much harder than for config files. In fact, though, it is possible to call pynsist from a Python script and supply all these values, if you prefer. It's just not documented yet, because I'm still working out the API. Also, multiline values are part of the [supported INI file structure](https://docs.python.org/3/library/configparser.html#supported-ini-file-structure), so all the extra parsing I have to do for a list is to call `.splitlines()`.
I write docstrings like that, too. textwrap.dedent(__doc__).strip() 
This made sense a year ago. But now, if the next package you'll want to use is 2.x only, is it *really* the next package you'll want to use? What went wrong with its development?
There's no sane way to parse setup.py reliably, you have to run it (that's the downside of storing information in scripts). You could write this as distutils commands; I also work on cx_Freeze, which uses distutils as the main interface, but in my experience, it's harder to use and harder to develop than if it defined its own interface. So I opted to steer clear of the whole Python packaging mess. It also means you can easily express that the application needs e.g. PyQt4, which isn't installable from PyPI. It just looks for importable packages.
Wow this seems like a really cool idea. I may have to bounce a design idea off you I have been working on at work if that's cool with you. Not sure if I should just grab a routing lib/framework to build my pluggable routing or build one myself. Honestly it seems like your design is closer to what I want to build as is. 
haven't messed with it in a while. just uninstalled the crap and went back to 2.7
This sounds backwards. The "encoding shit" is built into the standard libraries now, while you had to do it explicitly in Python 2. It's possible that you're messing something up. To work with strings on Python 2, you either had to use bytestrings ("str") all the time and probably crash if you ever encountered something outside of basic ASCII, or wrap everything inside a "Unicode sandwich" and put u's before all your string literals and stuff. In Python 3, the built-in `open`, `read`, `write`, and so on will do the "Unicode sandwich" *for* you (unless you tell them not to, by opening in binary mode). You don't have to `.encode` and `.decode` manually anymore when you're working with strings and files. It's way more readable. So I think one of the two of these is the case: * You're writing buggy code, and duct-taping over the bugs with encodings and type-conversions without figuring out how your data got that way. * You're actually doing crazy shit with low-level network protocols or something, not basic strings.
He means run your test script using sudo as the specific user that your code would run under as with mod_wsgi.
&gt; In the next episode, we'll try to uncover other novel and unpredictable approximations to other common expressions. Stay tuned! Can't wait to see this.
tl;dr use `psutil` do all the heavy-lifting. I am still looking for a `netlink` version. Kernel netlink are quickly updated and the docs are aweful
Jython on PyJVM would be a blast.
Thanks for the candor! I think it was worse before. I just got done building a classifier with scipy and scikit on Python 3. Just excellent. The only scientific computing holdout I can think of is nltk, which has Python 3 support only on the dev branch.
Instead of trying to use reddit as a continuing Pyramid tech support venue, you'd probably be better off using the right channels. There's a maillist (http://groups.google.com/group/pylons-discuss) and an IRC channel (#pyramid on Freenode).
It's conceivable that nothing went wrong with its development; it's more conceivable that something went wrong with Python's development that it requires library authors to 1) spend a nontrivial amount of time porting code and 2) port into a subset language that is worse than either 2 or 3 to be compatible with both and maintain that port in that crappy subset language for an indeterminate amount of time.
They aren't different repos. [Here is the top-level start of all the documentation](https://docs.python.org/3/). You should bookmark that. The main distinction is between the language and the standard library. And the slice syntax [is covered in the language reference](https://docs.python.org/3/reference/expressions.html#slicings).
I tried not to drown beginners in gory EA details while keeping an appeal to people that already know the field. At least the code is there... Too bad I didn't had the time to tidy it up. Roughly speaking, I started from DEAP's symbolic regression example ( https://code.google.com/p/deap/source/browse/examples/gp/symbreg.py ). From this, I added the integer reinterpretation hack. Then, I realized that finding a good constant (or constants) is quite critical for the performance of the equation, but sadly, GP will difficultly explore different constant values, at least enough of them quickly enough (We have to cover from 0x00000000 to 0xFFFFFFFF, considering floats). Then I came up with the idea to add the Scipy optimization as part of the individual evaluation to get good constants. So, the GP part is not different from the symbolic regression example. Since it is a pretty classic example from the literature, I skipped its details. They can all be found in the DEAP's walk-through of this example ( http://deap.gel.ulaval.ca/doc/dev/examples/gp_symbreg.html ). Feel free to ask details if you want!
pyvenv is great, but the question is specifically how to get python 3.4, which is not distributed with ubuntu yet, installed into ubuntu. pyvenv won't download and install into the virtualenv any version of python that is not already on your system. I wish it would, that would be really cool!
This is great, thanks for sharing. I need to read more on EA's 
I created a daemon class for just this task. It is discussed on my blog at pytopia.wordpress.com. Feel free to take a look
Really? I was in the "tutorial" https://docs.python.org/2/tutorial/index.html (276) and using 'quick search' for step and a couple other related things returned seemingly unrelated hits. Looking at the index &gt; L &gt; list and list() didn't show it either. searching "list()" gave zero hits. clearly I'm missing something. tbh I'm used to php.net where the search is . . . smart. I mean it assumes that when you search for "list" that you mean the function. However I need to use this, i'm fine with, but if having to "do it right" saps the utility out of it for the python newbie.
Thanks for sharing! I'm excited to give it a try. Makes using the win32com.client much smoother. One possible idea might be to allow the RunPython() function to receive output from python, so that it could behave as a UDF. For example, in VBA one could write: Range("A1:B2").Value = RunPython("import numpy; numpy.random.randn(2,2)") I'm guessing it probably isn't easy to get the 'interactive' results back from python though. But it would be nice, because then you could wrap that into a VBA function, and call python right from a cell formula. Maybe the RunPython could also pass an arbitrary number of arguments (VBA ParamArray) into python as sys.argv. That would be worth compiling and deploying. If you think this is possible, and you need help, I'd be happy to try. But I wouldn't know where to start. I only dabble in python, I've written lots of VBA in excel.
Finally, someone who doesn't just complain, but actually did something about this problem. You're awesome.
The quick search searches all of the documentation, which includes a lot of things. If I enter "list" (with no parens) on the quick search, I get hundreds of hits because it's a very common word. But the `list` function is included in the results. It's a line that reads: &gt; list (Python function, in 2. Built-in Functions) Likewise, if I click on "index" from the page you linked and then "L", the `list` function is also listed, as &gt; list() (built-in function) 
I very strongly disagree. EAs are inherently pretty 'dumb', in terms of how they work: you can't feed them any information about the problem at hand, except for whatever you manage to encode in your mutation- and crossover steps (e.g. you can't feed them any gradients, even if you have them), which is usually very little. So they essentially do (more or less) educated guesses of what good parameters are, based on the current generation of parameters. They definitely do have their place, e.g. in combinatorics (such as OPs example of evolving code), where no better algorithms are currently known, though.
Interesting. FYI, for the 2nd part of your problem, you could've just tried out all 2^(32) possible floats -- Evaluating a small expression this many times doesn't take too long if done properly (a few seconds in C, probably), although you might have to use Cython, PyPy or at least vectorize the expression using Numpy, otherwise CPython might slow you down too much.
Okay, that's a much better idea. Thank you :)
Thank you, I'll give it a go.
This is similar to what this guy did here: http://cyrille.rossant.net/create-a-standalone-windows-installer-for-your-python-application/ Except he used a standalone, portable, pre-built, python environment. I don't know what is done to make it portable. At this point I can't really complain that this isn't standalone/portable, but it would be *nice* if everything was in program files (or whatever installation directory is chosen). But I agree, this directory/installer approach is better than an exe. If this directory/installer approach becomes robust it will probably make the exe side of things better eventually.
Interesting, but not as interesting as the original mathematical solution (which appears to be documented many times with a quick google search).
More languages in use means more accidentally mixing up the features between them. For me, at least.
Ah. The simplicity of Python. As a frequent user of C/C++/C#/Java I still come back to Python often just for the lovely straightforwardness.
Well yeah, but what sort of stuff are you going to have in your client's address space that you care about? 
&gt; If it has an older bugfix release (e.g. system has 3.3.1, app has 3.3.5), it is upgraded. Argh. I would expect pyninst to ask me first.
All very right! A helpful intuition might be that that function definition is equivalent to: _supersecret = [] def foo(x=_supersecret): x.append(1) print(x) (Also, I didn't notice the footnotes were on the right, so I thought they were missing!)
&gt; Another option could be converting all metric values to the same unit and then running 1 function to convert to imperial That's the way I'm writing my converter. If you're just doing distance, store how much you need to multiply by to get to 1 metre for all the imperial units. Metric is very simple, just store the prefixes.
Haha, thanks for the morning laugh. You _were_ joking, right?
thanks for the comment. I'll try to work something out for the footnotes!
Thanks for sharing!
OpenCV and Web2PY haven't been ported. Most problems occur with scientific or hardware related packages. 
Twisted for a while prevented me from switching to Python 3, but I've since replaced it with Tornado and haven't looked back. It is far from the perfect replacement, but for my purposes works just fine.
Agreed, Python is all about being "pythonic", which usually takes the most conservative, clear-cut approach when deciding on language features and syntax. This is the reason why I think Python is one of the most beautiful computer languages in the world.
http://continuum.io/anaconda http://developerblog.redhat.com/tag/software-collections/ 
I haven't read the code fully but here's my understanding. Hopefully the author can correct me. They break up the search into two layers because the optimization target, essentially a formula, is a combination of both operators drawn from a finite, discrete set (e.g. bit shifts, add, multiply, etc.) *and* constants which are drawn from real values. Just think about what you would have to do if I asked you to manually find the best formula and constants for that formula to maximize or minimize something. This heterogeneity presents some issues for standard evolutionary algorithms because those methods tend to work better for discrete optimization whereas other methods such as convex optimization are better for real valued optimization. However, the problem is intuitively decomposable into separate optimization problems because the intuition is that the combination of operations has a much more significant effect than modifying constants. Now solving this decomposed problem is not the same as the coupled problem but the suspicion is that it's close enough. The first layer is the "combinatoric layer" where they use an evolutionary algorithm to search for combinations of operators. These combinations are discrete and are thus suitable to an evolutionary algorithm. The second layer is the "continuous layer" where they use standard real-valued optimization techniques (as encapsulated by SciPy's optimization library) to determine ideal constants to maximize the fitness (minimize the error) of a particular operation combination (chosen by the first layer). **TL;DR: Discrete optimization and real-valued optimization are two very different things so it's better to solve them separately than together.**
If you really want to be amazed, port it to Qt (PyQt or PySide). No kidding. 
I dont see any code on your page, only "Loading ...." where the code should be.
Say hi if you spot me! I'm the "glasshole" (promise I'm not) wearing a GitHub hoodie :)
what purpose does this serve?
How often is the counter of donations updated? Seems it's still at zero and I know I made a contribution so it should be &gt; 0 :P
I learned by just thinking of things that I wanted to be done easier. Just came up with projects for myself, and then tried to code them. When I ran into problems, I googled or went to [StackExchange](https://stackoverflow.com/questions/tagged/python) and asked questions. You can also try to answer other peoples questions, since that generally will make you have to learn enough to explain it to someone else. So StackExchange is a good source for both.
never tried pylint.vim, but syntastic supports pylint
You're right: if there's an analytic way to solve it, do it analytically. But it you're out of luck, trying to modelize an unknown system or a complex function that is not derivable, stochastic methods (monte carlo, EA, etc.) can be way faster to converge than brute force.
It's javascript that loads the Gist into the page. You may have NoScript or similar that prevents the loader to fetch the code. The first code is the one from the Wikipedia page (fast inverse square root) and the second is this one: https://gist.github.com/soravux/9673839
Absolutely not. Do not ever do that in production code. It is hard to maintain, undecipherable and slower (!) than what contemporary compilers would produce for machine code. Activating optimizations (-02 or -03 on GCC, for instance) and activating automatic vectorization while keeping your code clean and easy to understand will lead to performance way better than by achieving a simple reinterpretation trick. Your x86_64 CPU have silicon to produce multiple inverse square root with a single instruction.
You're right... But what if I had discovered an ever better solution?
Evaluating every possible float would be needed for every (new) individual of every generation. This would have been painfully slow to evolve. Granted, it would have been possible with 2 months of work and debugging and result analysis. But as I stated in the article, I'm a lazy guy!
Surprisingly fast and easy to build. Our data set is enormous as well, so the biggest issue is memory vs database reads. I thought scipy had old man fortran at the low level? I think it requires a fortran compiler.
every few days at best :/
https://chocolatey.org is a great way to install NSIS, it might be worth adding it to your instructions.
Where can I find instructions on how to reproduce the garbled memory failure? From the article: But if anybody has a clue about why a hardware watchpoint in gdb, set on one of the garbled memory locations, fails to trigger but the memory ends up being modified anyway... and, it turns out, by just a regular pointer write... ideas welcome.)
Excellent deduction and explanation. Just a small point I want to clarify: the "decomposition" isn't as simple as you seem to intend it. I cut the corners a bit by having a gradient method for the second step (making the hypothesis of having a simple function with only a single basin of attraction). Since the optimization on constants is heavily dependent on the discrete optimization, a better way to do it would have been to use global optimization schemes, but they are way slower and harder to tweak and converge. But you get the main point I was trying to make.
It appears this is on Haswell only?
Any idea how I can use this with my pygtk app ?
 Try testing-in-python-bounces@lists.idyll.org
I hope nobody is sick of my shameless proselytizing, but please consider cross posting to /r/pystats!
willing to provide a patch? =)
Let's be clear here: this thread is about publicly used Python packages, not your own huge code base. It started with a discussion of "the next package you want to use". I'm assuming you want to use a modern, well-maintained package if you have the choice. Almost all maintained packages have ported to Python 3. Even the huge ones. Django is doing just fine on Python 3, for example. The Django developers don't care if boto is third on the list and doesn't support Python 3, because there's no reason Django would ever depend on Boto. You implied there was some fundamental problem with Python 3 that made it not worthwhile to port packages other people use. But almost all of the people who develop Python packages *have* found it worthwhile. They'd be losing users if they didn't port. 
The trick as I remember it was to send a blob that encoded the information you need, signed with a key you can verify as your own. Likely a signed HMAC. Essentially a stateless verifiable document blob. Pretty standard protocol trick. 
&gt; this thread is about publicly used Python packages, not your own huge code base. Publicly used packages can be huge, difficult and expensive to port. &gt;Almost all packages have ported to Python 3. Even the huge ones. But not all, that's the point. &gt;The Django developers don't care if boto is third on the list and doesn't support Python 3 The developers and other projects might though. Django didn't wait, or care, for boto to port to python 3. However they had to wait for other projects to port first before they could get started with python 3 support. Same thing could (and probably is) happening to other projects with boto, at the moment. &gt;You implied there was some fundamental problem with Python 3 that made it not worthwhile to port packages other people use. No, there's nothing wrong with python 3. It's just not worth it in 99% of the end-user cases. Why port working code if you don't gain anything out of it? As far as the packages goes, they don't have any other choice really. Python 2 will stop being supported sooner or later, if you want your package used you **have** to port - whether you like it or not. The advantages/disadvantages of python 3, and whether or not they're worthwhile, don't really matter. If python 2 had the same support expectancy as python 3 almost no one would port their packages. 
I think the OP is asking the possibility of using Python for the front end, i.e. the UI, for an app that uses a database, but without using a web UI. Is that right, OP? If so, wxPython may be an option. i.e. wxPython + Python + a DB (+ optionally an ORM such as SQLAlchemy). Dabodev might help with that too: http://dabodev.com/ 
You can untick the Python installation in the installer, which will prevent it upgrading, but it doesn't tell you anything about Python versions already installed. It would probably be possible to provide more details, but it doesn't seem worth the extra complexity - end users shouldn't have to think about what bugfix version of Python is installed.
Someone has [made a start on this](https://github.com/takluyver/pynsist/pull/9).
Thanks, I hadn't seen that before.
God the Java Python was just awful looking. I realize the Value() wrapper class was silly &amp; pointless but I wonder if that's common for Java code. 
pygtk is Python 2 only, right? Once [Python 2 support](https://github.com/takluyver/pynsist/pull/9) is added, it should be possible.
Dead link?
Fair enough.
Nah she's my best friend / other so it's whatevskis. But yeah I packaged it in py2app and sent it to her
Good read! Though in production code, it better to not actually compute the eigendecomposition of the covariance matrix directly, but rather through the SVD. In terms of stability, it will scale better that way.
Even in Java that Value class is silly &amp; pointless, and would only be written by a non-Java programmer to show why their favorite language is superior to Java. Java code can be verbose, yes, but more often than not, the verbosity of a codebase is not due to the language itself, but to over-engineering by software guys who have just finished reading the Gang of Four's book and have some patterns to apply. But if I am picking apart a post that I am pretty sure was meant to be a joke, then I would also like to mention that C does have for-loops, and the print statement in that example should be closer to a C printf, something like print "%s" %(value) :)
IMO just another reason to follow PEP8
Yea, it was all tongue-in-cheek. The point of the `Value()` wrapper was to build the `toString()` method, since `str(value)` isn't very Javacious ;) The C print statement should probably be `print(value);` to be closer to `printf`, but oh well. And C does have `for` loops, but you construct them more like while loops `for (i = 1; i &lt; 101; i++)` so the while loop seemed a little closer than `for i in range(1,101):`.
Nice!
I'm already using it, but if I had to chose one library: Twisted.
So "Pythonic Python" is indistinguishable from "Fortranic Python?"
 sys.stdout.write() Made me laugh for some reason
This is my favorite way to say it. ['FizzBuzz' if 0 == n % 15 else 'Fizz' if 0 == n % 3 else 'Buzz' if 0 == n % 5 else str(n) for n in range(1,101)]
Doesnt print to stdout. Umemployment's your reward!
I have long wanted to see if I could do FizzBuzz in one line of Python. BTW I loved the Java looking Python. 
A cult is when the leaders know they are frauds, a religion is when the leaders are dead. Spaces vs Tabs easily comes under the category of religion now. It is one of my deep dark fears that 4.x will be spaces only and the language will die that day. 
[http://legacy.python.org/dev/peps/pep-0008/#tabs-or-spaces](http://legacy.python.org/dev/peps/pep-0008/#tabs-or-spaces)
Another one-liner (silly &amp; obfuscated a bit): print([['FizzBuzz','Fizz','Fizz','Fizz','Fizz','Buzz',n,n,n,n,'Buzz',n,n,n,n][n%3*5+n%5] for n in range(1,101)])
docstrings!
You can always configure your editor to interpret tab as 4 spaces. Also it makes for easier navigating
/r/pyramid
RHEL5 which is still widely used on servers ships with an ancient version of 2.x
What happens if you like tab size 2 instead of 4? Screwed.
ohhh, i see... I misunderstood how you did it, then. I thought you first evolved a good expression (using some default constants), and only AFTERWARDS find the best constant for that single, final expression
"Fortranic Python" would need a goto line, no? `import` in Python is basically just a goto... this could be a good one.
You should use 4 spaces for indentation in Python anyway
And here lies the true beauty of python. 
Hey, hey, don't forget `import` is a name binding operation too. &gt;&gt;&gt; yaml Traceback (most recent call last): File "&lt;stdon&gt;", line 1, in &lt;module&gt; NameError: name 'yaml' is not defined &gt;&gt;&gt; def what(): ... global yaml ... import yaml ... &gt;&gt;&gt; what() &gt;&gt;&gt; yaml &lt;module 'yaml' from '/usr/lib/python3.6/site-packages/yaml/__init__.py'&gt;
Bravo on that unpythonnhic whitespace.
are u ralking about an automated test system which run tests an then store results in a website. if so; take a look at "jenkins" with google. good luck
How do you make that whitespace pythonic? I always have that problem.
Why is the lispy and clojurly python different?
Amateurs. [print(e) for e in "1 2 Fizz 4 Buzz Fizz 7 8 Fizz Buzz 11 Fizz 13 14 FizzBuzz 16 17 Fizz 19 Buzz Fizz 22 23 Fizz Buzz 26 Fizz 28 29 FizzBuzz 31 32 Fizz 34 Buzz Fizz 37 38 Fizz Buzz 41 Fizz 43 44 FizzBuzz 46 47 Fizz 49 Buzz Fizz 52 53 Fizz Buzz 56 Fizz 58 59 FizzBuzz 61 62 Fizz 64 Buzz Fizz 67 68 Fizz Buzz 71 Fizz 73 74 FizzBuzz 76 77 Fizz 79 Buzz Fizz 82 83 Fizz Buzz 86 Fizz 88 89 FizzBuzz 91 92 Fizz 94 Buzz Fizz 97 98 Fizz Buzz".split()] 
ha
This is an excellent question. They are almost the same, but using a `lambda` felt more lispy, whereas in Clojure you often see something like `(take 100 fizz_andor_maybenot_buzz)`. I thought `map(fizz_andor_maybenot_buzz, xrange(1,101))` was about as close to that syntax as you could get. Edit: grammar
I use mostly Python 3 and love it. It was very easy to go up from 2.4 to 2.7 and then to make the bridge from 2.7 to 3.3 keeping both supports in the same codebase. The from __future__ import * allows a smooth transition. My secret killer trick: In Vim I hit F5 to run on py3k and Shift-F5 to run on py2. Then incompatibility issues makes no stress and progressively disappears. Now I never need to hit Shift-F5, except at work for a few old scripts based on "pywinauto". 
 print ['FizzBuzz' if 0 == n % 15 else 'Fizz' if 0 == n % 3 else 'Buzz' if 0 == n % 5 else str(n) for n in range(1,101)] 
I have the same problem with nested list comprehensions. I'd probably play with it for ten minutes and finally just break it out into pieces. And then I'd micro-manage where the lines were drawn for ten more minutes. f = cycle(['','','Fizz']) b = cycle(['','','','','Buzz']) m = map(operator.add, f, b) s = islice(m, 100) for i,r in enumerate(s, start=1): print(r or i) ... f = [''] * 2 + ['Fizz'] b = [''] * 4 + ['Buzz'] m = map(operator.add, cycle(f), cycle(b)) for i,r in enumerate(islice(m, 100), start=1): print(r or i) ... f = [''] * 2 + ['Fizz'] b = [''] * 4 + ['Buzz'] h = islice(map(operator.add, cycle(f), cycle(b)), 100) for i,r in enumerate(h, start=1): print(r or i) ... f, b = [''] * 2 + ['Fizz'], [''] * 4 + ['Buzz'] h = islice(map(operator.add, cycle(f), cycle(b)), 100) for i,r in enumerate(h): print(r or i + 1) ... f, b = [''] * 2 + ['Fizz'], [''] * 4 + ['Buzz'] for i,r in enumerate( islice(map(operator.add, cycle(f), cycle(b)), 100)): print(r or i + 1) ... f, b = [''] * 2 + ['Fizz'], [''] * 4 + ['Buzz'] for i,r in enumerate(islice( map(operator.add, cycle(f), cycle(b)), 100)): print(r or i + 1) ... f = cycle([''] * 2 + ['Fizz']) b = cycle([''] * 4 + ['Buzz']) for i,r in enumerate(islice(map(operator.add, f, b), 100)): print(r or i + 1) ... f = cycle(['','','Fizz']) b = cycle(['','','','','Buzz']) for i,r in enumerate(islice((fi+bu for fi,bu in zip(f,b)), 100)): print(r or i + 1) ... f = cycle(['','','Fizz']) b = cycle(['','','','','Buzz']) for n,w in ((n, fi+bu) for fi,bu,n in zip(f,b,range(100))): print(w or n + 1) ... f = cycle(['','','Fizz']) b = cycle(['','','','','Buzz']) for n,w in ((n, fi+bu) for n,fi,bu in zip(range(100),f,b)): print(w or n + 1) ... for n,w in ((n, fi+bu) for n,fi,bu in zip( range(100), cycle(['','','Fizz']), cycle(['','','','','Buzz']) )): print(w or n + 1) ... for n,fi,bu in zip( range(100), cycle(['','','Fizz']), cycle(['','','','','Buzz']) ): print(fi+bu or n+1) ... for n,fi,bu in zip(range(100), cycle(['','','Fizz']), cycle(['','','','','Buzz'])): print(fi+bu or n+1) ... n = [''] f, b = map(cycle, (n*2 + ['Fizz'], n*4 + ['Buzz'])) for n,fi,bu in zip(range(100), f, b): print(fi+bu or n+1) ... for n,fi,bu in zip( range(100), *map( cycle, ( ['']*2 + ['Fizz'], ['']*4 + ['Buzz'] ) ) ): print(fi+bu or n+1) ... for i, r in enumerate(islice(map(operator.add, cycle(['','','Fizz']), cycle(['','','','','Buzz'])) , 100) , 1): print(r or i) And then they'd take my dry-erase marker and kick me out of the interview.
Local last year was in California though
Ideally, yes. That was the route I originally attempted. However, my [initial patch set](http://bugs.python.org/issue19355) seems to have been ignored; it's sat dormant for 5 months. I've taken another route of submitting patches that don't specifically call out Open Watcom (as that seems to be a bad strategy) [here](http://bugs.python.org/issue20596) and [here](http://bugs.python.org/issue20597), but I fear those two were lost in the excitement of the Python 3.4 release. Rather than have this interpreter exist only on my computer, I thought I'd release it.
You should make the editor replace the actual tab character, not just show it as n spaces
It's also memoizing, in the sense that it won't go where it's gone before.
 print ('eJxNzbsNxDAMA9Ce2+hjfdoU2eUGuCbT52ALOFamKRBPoLg/zwPH9f' '09OyfqhF2JnI8YxHc8dUBy\nLk1jVajRXGP6gvZ/bgIb2ti2hLHuo7' 'vBSfeAj+6sL8VifY2+Cov0EMTowXokgvUcPQ1JegZy9GS9\nFMV6jV' '6FIr0FPXqz3olm/QU7zXAr').decode('base64').decode('zip') 
 i=1;exec"print'Fizz'*(1-i%3)+'Buzz'*(1-i%5)or i;i+=1;"*100
Java is inherently verbose. I love Java, but it is an annoyingly verbose language. It's slowly getting better, but it will always be relatively bad. While the Value class in the blog post may be stupid, it's only slightly more stupid than Java's lack of pairs or tuples, which necessitate the need for "Value" or "Entry" classes. 
That's a lot of options, and I would have no problem choosing for myself. But is there one or two of them that you would actually recommend using? I mean, with the 'only one way to do it'-mentality they say is so prevalent in the python community, I'd suppose it'd be more obvious, but I find that I would easily be satisfied by most of these.
I think one of these two forms [the difference is only formatting]. This form is the easiest for me to read because I see three iterators which progress at different rates, and that's what FizzBuzz is all about. for n,fi,bu in zip( range(100), cycle(['','','Fizz']), cycle(['','','','','Buzz']) ): print(fi+bu or n+1) for n,fi,bu in zip(range(100), cycle(['','','Fizz']), cycle(['','','','','Buzz'])): print(fi+bu or n+1)
What exactly are you looking for http://robotframework.org/ and if you want to do UI automation then look at this robot library https://github.com/rtomac/robotframework-selenium2library 
I still like the old one http://www.demiurgo.org/charlas/python-unittesting/img/python-logo.png
That doesn't explain *why*. The reason is this: People are too dumb to properly use tabs. In a perfect world, tabs are far superior to spaces, but people fuck it up on the regular, so we're stuck with spaces.
One of the more stressed features that I've seen had been autoboxing. I found it extremely convenient at times. Java isn't a terrible language, just a different mindset on how to solve problems (IMO).
here it is in "one line" (line is &gt; 79 chars, but it's a single statement) print("\n".join(["{0}{1}".format( "fizz" * int(not i % 3), "buzz" * int(not i % 5), ).title() or str(i) for i in range(1, 101)]) )
:) we were using Python 2.4 until 2009. At some point, it became silly. We skipped to 2.6 and after a year during a meeting about our wonderful software policy, I just frankly asked why are we still using a deprecated piece of software. It got a duhhh...we upgraded a few weeks later and implemented an 6 month upgrade policy and standard packages based on some policy feedback. Much improved. Still using 2.7 though.
Why is a system package in a python package service?
Thanks man, I appreciate it.
Well.. looky here http://conda.pydata.org/miniconda.html#miniconda
It's not needed in this specific example, but there is precedent: [MutableInt](http://commons.apache.org/proper/commons-lang/apidocs/org/apache/commons/lang3/mutable/MutableInt.html)
Hey, now I have a virus!
While I agree with you in general strokes, you can actually encode knowledge into EAs in places other than the mutation and crossover step: choosing an appropriate problem-dependent genome representation is a step often overlooked by people in the field.
&gt; SQLAlchemy In my experience, SQLAlchemy's strenth is not query building (which is what something like pony does well, but I am looking for something similar and more mature than pony)
Pony is by far the best you're going to get if you want a Pythonic and elegant query builder. It's not as mature as SQLAlchemy but it's still a very mature project, in my opinion.
If it didn't have the label Python, I will find it hard to recognize that those are snakes. More like..worms. I am not perceiving it as a plus, but I think it's more like Chinese Yin Yang symbol. 
I like how the comments are just people writing a shitload of clever one-liner solutions.
You missed a few: --- raw_fizz = enumerate(zip( cycle(["", "", "Fizz"]), cycle(["", "", "", "", "Buzz"]) ), 1) for n, (fizz, buzz) in islice(raw_fizz, 100): print(fizz + buzz or n) --- raw_fizz = zip( count(1), cycle(["", "", "Fizz"]), cycle(["", "", "", "", "Buzz"]) ) for n, fizz, buzz in islice(raw_fizz, 100): print(fizz + buzz or n) --- Umm... that's it. That's all I'd choose between.
So if it isn't well received you add the upgradable option, to make the $89 a more long term investment?
hmmm. what's the next best to pony?
&gt; "plain" indexes what are these "plain" indexes?
SQLAlchemy. Really.
Amazing, trying this today !
nltk
Help me out here then. There are 3 tables: Student, Course, Professor. What's the SQLAlchemy implementation for: 1. Get list of students who stopped enrolling in any course since 2012 2. Get list of students who are attending more than once course taught by the same Professor 3. Get list of Professors who stopped teaching any course since 2013 but is not retired
nice! Does it work well with SQLite/MySQL/Postgres to Oracle?
What happens if you like static typing? Screwed!
&gt; people who use Oracle are not the target market for Peewee why not? &gt; dipping to hand-formed SQL at times trust me, would make my life simpler. but I won't have control over which DB my code will work against, so a query builder it has to be.
I always forget about `count`.
Peewee maybe?
I was missing some inherences, maybe from an abstract class :)
It's a dependency for several python modules shipped with Anaconda. Utilising the same version across platforms makes it easier to debug if the problem is in your code or a dependency like openssl, and also to expect the same behaviour everywhere. You can't do that relying on a "system" version which may indeed have a totally different API let alone ABI. 
Everyone goes bonkers for SQLAlchemy. What you **actually** asked for: http://web2py.com/books/default/chapter/29/06/the-database-abstraction-layer#Generating-raw-sql Can be used without the framework. Generates raw SQL if you ask it to. Works with many, many databases. 
Not a single comment or doc string. I can't figure out how people can keep all that code in their head at the same time without them. Especially if one had not worked on it for some time. 
**Assumptions** 1. The Courses table must basically be enrollments (i.e. course code, year, semester, professor id, student id). 2. There are actual foreign keys between the tables (because SQLalchemy infers things from this). 3. The relationships for those keys are configured on the models. NOTE: If you autoload the schema, I'm unclear if the foreign keys will autoload. Also, this is all off the top of my head, so it may not work; but you'll get the idea, I hope. **Session Setup** from sqlalchemy import create_engine from sqlalchemy.orm import sessionmaker from mytables import Student, Professor, Course from sqlalchemy.sql.expression import func some_engine = create_engine('postgresql://bob:s3kret@db.campus.edu/') Session = sessionmaker(bind=some_engine) session = Session() **Queries** 1. Get list of students who stopped enrolling in any course since 2012 session.query(Student).join(Student.courses).filter( func.max(Course.year) &lt;= 2012 ).all() 2. Get list of students who are attending more than once course taught by the same Professor session.query(Student).join(Student.courses).join(Course.professor).filter( func.count(Professor.id) &gt; 1 ).all() 3. Get list of Professors who stopped teaching any course since 2013 but is not retired session.query(Professor).join(Professor.courses).filter( func.max(Course.year) &lt;= 2013 ).filter( ~Professor.retired ).all() 
That's awesome https://www.dropbox.com/s/2lvm646tilqvxjc/Screenshot%202014-04-10%2013.25.54.png but repaints super slow :)
Look up pyx12 - it's got some useful stuff. 
There you go: http://www.reddit.com/r/Python/comments/213k0c/who_needs_a_database_stateless_password_reset_in/
Gonna do this when my lastfm history is 8years old!
 print([('FizzBuzz', 'Fizz', 'Buzz', n)[y*2%3+y%5] for n in range(1,101) for y in [n**4]])
Still waiting for Perly Python example. In perl, that would be $ perl -E 'say"Fizz"x!($_%3)."Buzz"x!($_%5)||$_ for 1..100'
In ye old FORTRAN yes. New Fortran doesn't use goto
Here's mine: def fizzbuzz(x,y): for c in range(x,y): if not(c%15): yield "FizzBuzz" elif not(c%3): yield "Fizz" elif not(c%5): yield "Buzz" yield c for a in fizzbuzz(1, 101): print a
Huh? Arrows work for me.
Sorry, that was a very dumb name for an "index on a column with non-unique values"
Disclaimer: I typically use raw sql with pyodbc. What I dont get about using ORMs is: How is the above code any simpler than just writing the query itself? 
Honestly you should look at web2pys DAL. Its basically a functional query builder. You don't have to use it in web2py either. Take a look at the docs and see if this is along the lines of what you are trying to accomplish. http://web2py.com/books/default/chapter/29/06/the-database-abstraction-layer *EDIT* Also there is a section on [inner and outer joins](http://web2py.com/books/default/chapter/29/06/the-database-abstraction-layer#One-to-many-relation)
From my experience the ORM "benefits" come into play when rehydrating your objects/rows that have now been returned. Also instead of using a query where student.id = 1 you instead would pass the student object who has an Id of one to the ORM. I honestly don't see the benefit most of the time to using an ORM unless your models are trivial. If you have any sort of complexity to your DB setup or have an existing schema you are trying to work with I find even the best ORMs get in the way. For instance, I am trying to debug some old hibernate hql queries. Normally I would develop my queries in something like squirrel SQL then port them to whatever. However with hibernate you are referencecing objects and classes like they are actually just a row or table. Making debugging hql a total PITA such that I have to use java melody to capture the queries as they are actually sent to the DB.
A few ways. In no particular order: 1. Guaranteed escaping of input. 2. Type Conversion. 3. No string parsing for output. 4. Database agnostic (unless you decide not to be). 5. Schema Definition Through Declarative Interface 6. Migrations (with sqlalchemy-migrate on pypi) 7. Autoload functionality adds more possibilities for introspection. 8. Models can grow validations and other supporting behavior. 9. Collection Annotation (i.e. this relation is a dict keyed on X, this relation is a list) 10. Incremental Programatic Query Building (it's *much* safer to stack on .filter calls than to do clever string games with the query) 11. Caching 12. 2-Phase Commit with supported drivers 13. Better Logging When Configured 14. Intrinsic sanity checking for cardinality of responses (i.e. .one() or .all() eliminate wrapping / unwrapping logic, and make error handling uniform). 15. Explicit session management (i.e. multiple sessions for different roles, simultaneously. 16. More Testing Options 17. Wrapping queries in other generator contexts. 18. Probably a bunch more I'm not thinking of. 
Django's ORM is not ecatly flexible or portable and only supports a few DBs. Web2py's DAL is much better suited for this task.
Most of these have nothing to do with ORMs other than ORMs may implement some or all of these features. A solid query builder like web2py's DAL or SQA's core will do all of that with out needed an ORM layer.
One of my biggest problems with them is dealing with the entire objects that ORMs love so much. I have noticed when doing queries for web based code that I often want only partial results or even a single column from a complex join. I have never seen a library that tries to make that sort of usage more simple. I think the biggest benefit to an ORM would be adding columns and other schema changes. Not having to touch so many similar manual queries would be nice. Also not having to do the object conversion when that is required would be nice.
It was just a quick hack, it's not like OP was making production quality mission critical code or anything. Cut OP some slack :)
The neat thing about conda is that although it has a Python focus, it can install anything. So you can install different versions of Python itself, databases like Postgresql, etc. Should be very useful for integrating projects that use more than just Python code.
OK, how about: $ python -c 'for n in range(1,101): print(("Fizz"*(not n%3)+"Buzz"*(not n%5))or n)' Not sure it would be recognized as Perly without your Perl code right above it, though. There's just not enough "line noise".
why continue and not the more readable (imho) elif ?
Comments in python should be minimal. The point is the code speaks for itself. Please don't comment obvious things 
I just want a robust solution to check the function annotations in my programs. This looks somewhat promising, but rather ambitious.
I like the second one. The first one seems sad. ):
I had to sit through some boring classes today, too. [Naturally, I also made a 2048](https://gist.github.com/pyos/db31f5295afd20551d4e). Here's a [screenshot](http://i.imgur.com/6QENQ3Y.png).
&gt; I'm not sure I manage to make any sense of this part… mypy, as CPython, Pypy, etc. is a runtime (two actually, but anyway); Python 3.x is a specification for some language features. Yeah, my merging statement was a bit fuzzy. It seems to me that mypy started as a separate Python implementation, but evolved into more or less a regular Python 3.x module. That's at least how it appears to me: I was able to install it in virtualenv with `python3 setup.py install` and use `mypy` command to typecheck pure Python 3.x code. Frankly, it's all I need. I doesn't really need to be merged into 3.x, but I wish it becomes a standard, widely used tool at some time.
better unicode support, more things in the standard library return iterators instead of lists.
Nice trick to rotate the grid before and after every move.
more of a forum where you can ask questions, but I was hoping to find one on reddit. I guess I'll just stick with the google group I'm in now though
I came here just to mention the better unicode support. But the iterators v lists is also a great point.
yes we're setting up jenkins, I was looking for something more like a subreddit or something like it on reddit. I'm part of a google group, but I like the format a little more on reddit 
The code generally looks saner. No more `xrange()`, for instance, because now `range()` does basically the same thing. String code is also a lot cleaner and more type-safe. It's harder to confuse binary data, "plain text" (which [isn't](http://www.joelonsoftware.com/articles/Unicode.html)), and Unicode. 3.4 also introduces a boatload of new stuff like `asyncio`. `concurrent.futures` is not new to 3.4, but I don't believe it exists in 2.x either.
Not really, we've just been doing it this way for a while and no one has thought of switching. Thought I might gather some "ammo" and then start a discussion about it.
I found this to be helpful: https://docs.python.org/3/howto/pyporting.html Overall it looks like the biggest change has to do with improved type-safety for strings vs "byte strings" (which are really just packed byte arrays). Aside from that, I think the biggest advantage is going to be future-proofing. Community support will eventually make the jump, leaving 2.7.x to die on the vine. I assume that Django will, at some point, make that leap. Edit: There's also the change of removing the 'print' statement in favor of a function, which is nice for consistency. But you shouldn't have any print statements in a Django app.
Super easy to use IMO one of the reasons I keep using web2py
From the home page: "The mypy programming language is an experimental Python variant that aims to combine the benefits of dynamic (or "duck") typing and static typing. Our goal is to have the expressive power and convenience of Python combined with compile-time type checking. The long-term goal is to also support efficient compilation to native code, without the need of a heavy-weight VM. " Sounds like alot more than just a module to me. That said, I'd really like to see them succeed.
Not just *better* unicode support but Unicode strings cost less RAM in Py3.3+ than in Py2.7 thanks for PEP 393 - if you have a lot of unicode strings storing ASCII (i.e. Western characters) then a saving of 50% on their storage is possible (so Unicode in Py3.3+ is similar in cost to strings [not Unicode] in Py2.7) http://legacy.python.org/dev/peps/pep-0393/
Now you have stray square brackets and commas everywhere. You want print(os.linesep.join('FizzBuzz' if 0 == n % 15 else 'Fizz' if 0 == n % 3 else 'Buzz' if 0 == n % 5 else str(n) for n in range(1,101)))
You can already use print() in python 2 as well :)
A year back I noted that Python 3.3 on Windows had more monthly downlaods that Python 2.7 - I think we're going over the tipping point in people moving towards Python 3.3: http://ianozsvald.com/2013/04/15/more-python-3-3-downloads-than-python-2-7-for-past-3-months/ I'm not saying we're all suddenly going to switch (I do data science - repeatability is key so I'm not leaving the Py2.7 numpy ecosystem for a while) but I think people on new and potentially long-running projects, especially if dealing with Unicode, will benefit from taking the jump now. The time saving from removing Unicode bug hunting alone might be a good consideration. Library designers will have a hard time supporting both versions but if you're doing server-side deployments, I think you'll get a future win by considering the jump now.
To tl;dr /u/Iconoclasm: Your comments shouldn't say **what** you did, but **why** you did what you did.
As a very small aside, the print function exists in at least 2.6+.
GvR has posted some notes on the Python Language Summit that took place today at PyCon, it notes that they're not sunsetting Python 2.7 any time soon and discusses some ways of helping people move to 3.4: http://thread.gmane.org/gmane.comp.python.devel/147048
Better unicode support is cool, though it's been possible to do proper unicode development for many years in Python 2.x. It's just that Python 3 actively encourages it, while Python 2.x if you don't know what you're doing can confuse you instead. Though since Python 3 forces you to confront the issue you may have some learning to do that, if you happen to be writing code that only deals with ascii, you might not have had to worry about at all before. The iterators versus lists thing is kind of mixed; while iterators are more memory efficient they tend to be a bit harder to debug/reason about than plain lists are. Though it's my understanding at least dictionary keys and values and such try to mitigate this a bit. 
I really like the generators versus data structures aspect of Python3. This is the distinction in Python2 between `range` and `xrange`, where `xrange` returns a ~~one-time-use~~* generator, not a fully-formed (and sometimes potentially unwieldy or memory intensive) data structure. This is true for lots of stuff, including `filter`, `map`, `enumerate`, and others. The other day, for example, I was trying to see what elements were in a cache and I wrote the following: filter(bool, map(cache.get, a_bunch_of_keys)) With the lazy evaluation model the data is pulled through each step instead of having to build up data structures that are then iterated over. In addition (and this probably isn't really fodder for your argument), I really like destructuring: first, *rest = something_of_indeterminate_length You can also do: *init, tail = something_of_indeterminate_length And: first, *middle, last = something_at_least_two_elems_long It's kind of nice to be able to do this whenever I want the first of something: first, *_ = some_data_structure Combined with the above, my 'what's the most recent cache element that exists from these keys' was as follows: first, *rest = filter(bool, map(cache.get, a_bunch_of_keys)) **Edit**: one other note. A number of people have mentioned unicode support and I totally agree that that's a big thing. Switching to Python3 allowed us to cut out a lot of code that checks for unicode and converts to unicode. It makes that whole question just disappear (because for us in our web development needs at least, there's never a desire to convert to ASCII). **Edit**: Thanks, /u/Lucretiel for the [correction](http://www.reddit.com/r/Python/comments/22ovb3/what_are_the_advantages_to_python_3x/cgp2x6c)
It's not being deprecated like 2.x.
If it's hard to reason about laziness then there's a good chance you have side-effects in places you shouldn't.
TIL. I mean, the reference makes total sense now that you say it, but I had never looked for any meaning in the colors.
Django is already compatible with Python 3.
Not just [range](https://www.jackwearden.co.uk/blog/python-3-range-function/), either - filter and map now both return filter and map objects, which are lazily applied iterators with the same behaviour as in 2.x
Do you mean as in `from __future__ import print_function`? Print is still a statement in 2.6 &amp; 2.7. Eg you can't map(print, some_list)
cookies could be replaced by gmemsess maybe
You mean another threes rip off. Good on ya, but at least know the actual source :)
The challenge here is that the majority of SQLAlchemy documentation and advice assumes you're using the ORM. If you really only want to use core or sql expressions then you spend a lot more time than you should have to - trying to filter out irrelevant stuff and find what you need. Which is really unfortunate - because it's a great product and there's a ton of us that really just want to use the core.
I guess we're just taught differently for Python for GIS
One quick question: If I have a UTF-8 encoded source file, and I put accented characters in a string (like ***prpt="Bâchez l’école dans la côte sans être là"***), will I be able to output those totally transparently, or will I have a smogasborg of error messages???
I don't disagree with your analysis, but it is worth nothing that another consideration is that Python 2 is eventually going to be end-of-life'd, which means that Python 3 will be the only supported version going forward. Of course, it is also possible (and perhaps even likely) that some other group will pick up maintenance of Python 2.
You are conflating the ideas between minimal comments and readable code. If the code is readable, then its readable, if it is not, for **whatever** reason, you should leave a comment explaining the intent of the code. code is not one size fits all, you need to make decisions based on the circumstances. 
Until Selenium Webdriver is supported on python3 our organization cannot switch. I wish we could, however webdriver is a major tool we use and that is not currently supported in python 3. Unless you all know otherwise.
Lots of great comments here. I would add that 3.4 comes with pip. That has already made installing libraries and 3rd party apps much easier, especially on mac.
&gt; separator = ¶ i think you mean `separator = '¶'`, but it’s entirely possible to do this instead ;) ¶ = '¶' joined_paragraphs = ¶.join(paragraphs) ... code to look for and delete the separator where I wanted to get rid of separations... joined_paragraphs.split(¶)
No, I agree with you. 
Me aswell. I wish I could put aside my programming ocd and just do things, things that are useful not this stupid console simulation stuff I've been doing that noone cares about but me. I'm in this horrible cycle, where I have to do things the right and correct way, and then give up not even halfway through because it just feels like too much work and who is ever gonna use it. It's kinda all for nothing... 
Oh, I understand now, then sorry for my brash tone, lets take it as an elaboration. But yes you are right, now that I have reread the thread, its my least favorite javaism to do the following: /** This method returns the foo of the class * @returns the foo */ public Foo getFoo() { return theFoo; } This is a bad doc-comment, as its completely obvious. Sorry, my CS101 course is boring as all hell, and agreeing with you and being extremely verbose is much better than learning about function overloading in C++. I think what people disliked was that you used the word "minimal" as to imply that if you do use comments, it should be as little as possible.
This. :l I fail so hard on this point. Comments everywhere, i swear.. :S Example of my madness: def __repr__(self): "Returns a printable version of the internal 3d list." #Declares variables lsOutput = [] #Loop through all cells horisontally and vertically for iY in range(self.iHeight): for iX in range(self.iWidth): #Loop through all layers for iZ in range(self.iLayers)[::-1]: #Set o to this cells content in that layer o = self.lllo[iZ][iY][iX] #If there is content if o is not None: #Break out of the loop break #If there is no content in any of the layers in this position else: #Set the content to a space o = " " #Add the content to the list as a string lsOutput.append(str(o)) #Add a lineshift for every time we are done with a row of cells lsOutput.append("\n") #Returns the result return("".join(lsOutput)) 
Why are iterators better than lists?
Yes I had always thought that it was interesting that 2to3 never tried to make 2.x and 3.x source compatible files. It looks like he wants to add features to 3.5 which would make having a single codebase easier, which could make a lot of people happy, considering that adoption for 3 isnt great, I'm sure if 3.5 made that easier, people would jump on it.
Lol. It feels like you're assuming the reader is retarded. I almost feel insulted by the comments.
If you do `from __future__ import print_function` you can. However, in python 3 it still wouldn't work, because `map` creates a lazy iterator.
Oh that makes sense and is also really cool. Thanks!
Just want to point out a common misconception- Python 2 `xrange` and Python 3 `range` are NOT one time use iterators. They are `range` objects, which in many case can be used as a drop-in replacements for lists, even when you need to loop over them multiple times or do subscript access. They support many common sequence operations, including `__len__`, `__getitem__` (both subscripting and slicing), `__reversed__`, and `__contains__`. UPDATE: Apparently `xrange` doesn't have `__contains__`. Yet another reason to prefer Python 3.
Ahhh, I'm wrong. I thought you just meant using it in the capacity of print(&lt;object&gt;).
If you do list() with that, or do a for..in over it, it'll work fine. It's valid python - whereas the print statement *isnt*, was my point
&gt; There is however a significant use case for static typing in Python code, especially when many custom classes are involved. care to elaborate?
because optional annotations and compulsory annotations are two entirely different things.
It's not an issue with Haswell but occurs when using [memory references off the GS segment](http://clang.llvm.org/docs/LanguageExtensions.html#memory-references-off-the-gs-segment) (address space #256, i.e. %gs in assembly). 
The comparison with C++ is rather dull for Python I think. C++11 is backwards compatible and offers many conveniences for adopters right away. Python 3 offers relatively little different, except a saner, cleaner start. I like Python 3, but it doesn't have those huge simple new features like the C++ `auto` type derivation or lambdas.
I didn't remember that. Thanks. 
Well, it wasn't really _in_ English class, we had had a test, which I was done with early, and I couldn't go online and play 2048, so I made my own.
RPython? Its really rough around the edges, but it might be what you want if you squint really hard.
Can you explain what you mean by type-safe string code? Python is obviously not statically typed so I'm not sure how you can make a statement like this.
No, threes was unique work and I feel really bad for those guys because of the clones (i.e. 2048). Here's Patrick Klepek's great write-up on it: http://www.giantbomb.com/articles/meet-the-clones/1100-4891/
[Function Annotations do exist in 3.x](http://legacy.python.org/dev/peps/pep-3107/), but they do ***nothing*** on purpose, Mypy actually uses them. So its already 'merged', unless you meant the functionality of it, which I am pretty sure will not be merged anytime soon.
Really looking forward to the ansible and salt talks!
if I were to lobby for better dictionary comprehensions in ruby, I might ask myself why the hell i'm using the language in the first place. So I don't lobby, and instead solve issues with the tools available. or get a different tool. I don't wish to change others tools to fit my needs. I personally would not look forward to reading all the type boiler plate shit in python code that someone thought was necessary(but it really isn't) it's why I stopped using java and c#
Are generators instead of returning lists
Can you explain to me why that's helpful?
Sounds like you are a web programmer. What about usefulness for a scientific programming?
How about you remove the quotes, then we'll talk
What about the seemingly-likely addition of a new infix matrix multiplication operator in Python 3.5? :-)
Selenium supports 3.3 and even 3.2.
good point
Then you have to do additions always left to right. The internal state of the grid is a list of lists, so having to carry items through columns is hard, but doing rows is easy. 
*this* plus the maintainers have made it clear that their focus is NOT query building
you can still do that in python, but you have to use xrange instead of range you can actually make your own generators: https://wiki.python.org/moin/Generators
Type safety is not exclusive to static typing. Python will not, for instance, allow you to do something like this (though Perl will): &gt;&gt;&gt; "10"/5 In Python 2, there is a string type and a separate Unicode type. It was common to use the string type for any kind of text, particularly text which the programmer naively assumed to be ASCII, as it is the older of the two types. Strictly speaking, the string type was nothing more than an array of bytes, but it often behaved like quasi-ASCII in many contexts. This encouraged a variety of unsafe shenanigans. Often programmers would have a string but not know what its encoding was, because Python 2 did not require you to have that information. The Unicode type was nice, but imperfect. In particular, on so-called "narrow builds," it would index [surrogate pairs](http://en.wikipedia.org/wiki/Surrogate_pair) as two characters. In Python 3, the string type was renamed to `bytes` and acts more like an array. Indexing into it produces an integer instead of a length-one string, many library functions no longer accept or work with it, etc. Meanwhile, the Unicode type was renamed to `str` (the same name as the old string type used to have) and made to look more like a "real" string. Surrogate pairs are now handled transparently. Most library functions now accept, produce, and work with the new `str` type. Textual I/O is done with the new `str` and binary I/O is done with the new `bytes`. Some operating systems (particularly Unix) don't distinguish between binary and textual I/O, but Python 3 always does; textual I/O goes through a Unicode encoder/decoder and binary I/O is passed through as-is.
Yes, that's what I meant. It's probably not going to be merged very soon, but the project's exposure during PyCon may move it forward in this direction. I'd love to see this functionality as a standard module run with `python -m` or even as a extra flag to `python` command. Until then, the tool seems to work great when installed from `setup.py` and I'm definitely going to test its usefulness with a bigger project of mine.
Hmmmm. I never said that Core or something like it didn't implement these features, so I'm not sure what point you're trying to make (except, maybe you really can avoid objects if they bother you?). The ORM gives you much nicer syntax and gives you objects which can provide behavior. It also provides the session concept that lets you have objects hang around and be manipulated in a much more natural fashion. Some things are just easier with objects. Let me give three examples where the ORM made things very nice: 1. I had a system that needed to ingest data from an API into a database. The data was highly hierarchical and inter-referential. The best way to implement it was to have tables for each type of data with the URL as an ID. SQLAlchemy made it really easy to just ingest the data using some recursive functions and it seamlessly handled whether or not an object was already created in my session or not. Every bit of handling the API was in a set of functions on my table's classes and every bit of handling cached objects was implemented in about five lines of code that I slapped on with a decorator. 2. I had a similar system where I needed to generate HTML reports. By implementing a set of recursive methods (generators, actually) on the classes, I could just call User.report() and get back the input for my HTML template. 3. I had some code where I was reconciling two other data sources (one of which wasn't even a database, but rather a streaming logfile). I achieved this by, again, making a set of functions on the objects to validate things and generally implementing an API that allowed a chunk of code to walk over the two versions of the data and compare them. I could have done this with something like the DAL or raw DBAPI, but it would have been way more complicated. Is it necessary? No. However, there's not a really compelling reason to avoid it unless you like longer, uglier code or *really* need to avoid the overhead. I have avoided ORMs for when I needed to ingest a billion rows and run on an embedded system. What pain-point are you trying to avoid?
I worked with quite a few Python project and in my experience dynamic typing isn't an issue in production. I think I never saw silly `AttributeError`, `NameError` or such in production. However, in development phase people tend to make such mistakes more often, what is reflected in unit tests results. It's especially frustrating to new developers in the project who don't know API well yet. I think tools like static checkers are great help in this case, as they let you detect stupid typos and wrong parameter types much faster and focus on important stuff. There's also a political benefit. Sometimes you must sell Python to management and if you happen to have a troll in company which sabotages dynamic typed languages as "toys", then showing tools like `pylint` or `mypy` is a great help.
Let's be polite, shall we ? :)
Will do! Just saw this now. If you want to grab lunch sometime during the conference, feel free to reach out! https://plus.google.com/+JoelVasallo @joelvasallo
you can use from \_\_future\_\_ import division. Also the interpreter has a funky command-line flag so that anyone who runs your code can change the meaning of the division operator.... yeah. Always use the new division, IMO. (I'd also always use `next(..)` in Python 2.7, best to do everything you can to be ready for Python 3)
Nice. At least you can take an Archer joke, the rest of /r/python, well not so much. Oh well. Cheers!
If any of you could have a look at my code and criticize it that would mean a lot to me, thank you :X
and where does the "significant use case for static typing" come in? seems all your mentioning is a more sophisticated linter. and you wont get any argument from me on the value there. But if I have to start putting types on my variables and writing interface crap.... I'm gone. 
&gt; No more having to think about whether to use cProfile or profile. unfortunately, there is still a difference. `profile` is much slower (Python 3.4)
Good tip! Thanks, will do from now on :) Usually, I just did the `3/2.0` in my Python 3 code, but your suggestion is way more elegant PS: Absolutely agree on "best to do everything you can to be ready for Python 3", when I write Python2 code, I also use a `print('a')` instead of `print 'a'` to save the python 3 people some pain. 
You're not forced to use the usual static typing mess like generics and interfaces. You're free to mix static typing and dynamic typing in the way it's most convenient for you. I personally plan to annotate only the API functions and pieces of my code I consider highly prone to attribute errors, invalid parameters, etc. In the end the changes will be small, but I expect big rewards. The rest of the code works as usual.
Took a quick glance. In no particular order: * PEP-8. Line lengths are way too long in some sections, and method names don't follow the proper conventions. For example, onXMPPPresenceSubscribe should probably be on_xmpp_presence_subscribe. * I'd recommend against using `inspect.ismethod`. Use `callable()` instead. You don't want to force event handlers to be bound to an instance. What if they want to pass a lambda? * Not actually a problem, but a tip. In methods like onXMPPGotOnline you're calling presence["from"] a lot. For convenience's sake it might be good to assign that to an easier to reference variable at the beginning of the method if you're referencing it a ton. There are arguments for and against that though. * Another pythonic thing. If you're checking a boolean and returning True if it matches and false if it doesn't, like in isAdmin, it's probably best to just return that boolean. `return summonerId in self.admins` takes away 4 lines of code and it's still simple to understand. * Logging. Print statements have no real flexibility. The python built in logger is pretty darn good, but I personally love [logbook.](https://pythonhosted.org/Logbook/) Overall, great start.
Hmm, I would not recommend an ORM for reporting: too slow, too inflexible, not supported by reporting tools, etc. Unless you need just a very, very modest reporting solution, in which case it's probably great.
&gt; Python will not, for instance, allow you to do something like this (though Perl will): &gt; "10"/5 It doesn't allow it at runtime, but it's not checked statically of course, which is unfortunate. &gt; ... Interesting information, thanks for typing this up.
Thank you for the criticism, I appreciate it and I will definitely update it with what you mentioned :]
Memory savings, amongst other things.
Cool. At one point you say "Python has no case...switch control flow, but we could mock it using if...elif...elif...else". Sometimes it can also be done elegantly using a dictionnary.
Yes.
Whaa? Well what is it?
I think Brett Cannon explained it well at last years pycon. http://pyvideo.org/video/1730/python-33-trust-me-its-better-than-27
It's not that Python programmers don't want to move forward. If you're working on a large codebase with a lot of dependencies, it can be a lot of work to upgrade to Python 3 (and some of the third-party libraries you're using may not even support Python 3). To be frank, Python 3 really has little benefit for old projects that have been able to work around some of the ugly parts of Python 2 that 3 smooths over. 3 is great for new projects, but it doesn't necessarily offer enough benefits to justify the cost of porting a large legacy 2 codebase.
A flask.
Thanks Prime Minister David Cameron! ;-)
For such a smart guy he doesn't get that some people will never move without a deadline (see Windows XP). 
It isn't? I thought it was 156 or something thereabouts. Or do you mean 7-bit ASCII? Is Python 2.7.x limited to 7-bit ASCII? If so, then I guess I'm going to use GBP! :-) 
You're right! It's punctuation so it doesn't work, sorry. For the record: Unicode that *is* characters works, e.g. π or ∆.
There is some loss to the language introspectability though, especially for newcomers.
That's an interesting idea. Anyone want to experiment with a decorator and static analysis tools that can track it? e.g.: @mayraise(TypeError, FileNotFoundError) def foo(): ...
Any Debian (and it's derivatives like Ubuntu) distro has that module included. Yes even latest ones.
also in the .md markdown for python code you can specify ```python code ``` (3 backticks python 3 backticks) more here https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet ctrl+f python. it just looks better when highlighted 
"the question is specifically how to get python 3.4, which is not distributed with ubuntu yet, installed into ubuntu." Thats exactly what I use pyenv for, I run Ubuntu 12.04, and I have python 2.6.6, and 3.4.0 installed on my laptop using pyenv. I think you have the wrong understanding of how pyenv works. Please follow the install instructions (https://github.com/yyuu/pyenv) A picture is worth a thousand words (screenshot of terminal)[http://imgur.com/mAOwkEj] Edit: I re-read your post and it occurred to me to add the following: The thing to keep in mind is that pyenv works by manipulating your shell env. This means you cant use the installed python3.4 the usual way (e.g $ python3 ), you need to tell pyenv to switch to the "installed" version you want. (see the local, and global commands) After you have used pyenv to install python 3.4, tools like virtualenvwrapper, pip, and virtualenv wont just work (if you previously had them installed) To get them to work, you need to make python 3.4 global (pyenv global 3.4.0) then re-install, virtualenv, and virtualenvwrapper. Once done you can then switch back and forth with no issues or conflicts. 
pip install svn ?
unfortunately delta (∆) isn't allowed either. pi (π) is though. &gt;&gt;&gt; ∆ = "delta" File "&lt;stdin&gt;", line 1 ∆ = "delta" ^ SyntaxError: invalid character in identifier &gt;&gt;&gt; π = "pi" &gt;&gt;&gt; π 'pi'
Yeah, I know how to deal with laziness by making a copy. But that's what I mean by being a bit harder. A minor issue to be sure. It's just laziness has tradeoffs like anything else.
`concurrent.futures` is backported to 2.6+ actually.
 ):
Download it and register the package?
That's brilliant: Using Pypi as a form of ransom.
Raw: 11.64 MB in 1.0722s Convert to GB: 11.64MB / 1000MB = .01164GB Convert to Gb: .01164GB x 8 = .09312Gb Figure out average Gb per second over time provided: .09312Gb / 1.0722s = .08684Gb/s (Well, normally Gigabits per second, in networking, is "Gbps") Seems correct to me. (I rounded some) Also as a network engineer I've always seen a "Gigabit" (for a connection) as 1 000 000 000 bits/s. So when I figure out how much a server might be sending out a link, or whatever, this is the math I normally do.
I like the idea - but I'm now intrigued by your comment that deque.extend is faster - why is that so?
OK, that makes no fucking sense. Both are letters of the same alphabet. What.
something like this should work as well, and be less verbose while still readable def __repr__(self) lsOutput = "" #make a list of all possible xyz combinations, sorted by x-value cellList = sorted([(x,y,z) for x in range(self.iWidth) for y in range(self.iHeight) for z in range(self.iLayers)[::-1]], key = x) currentRow = cellList[0][0] for cell in cellList: o = self.lllo[cell[2]],[cell[1]],[cell[0]] # cell[2] is z, [1] is y, [0] is x if o: o = str(o) else: #add a space if there's no content in this position's layers o = " " if cell[0] &gt; currentRow: currentRow = cell[0] #linebreak after the row ends o += "\n" lsOutput += o return lsOutput (edit) nvm, it doesn't quite work the same (it's linebreaking after each entry instead of after each row.) I wasn't paying enough attention. It gives the idea, anyways. (another edit) I really shouldn't write while I'm drinking. Since you're just outputting a string anyways, you could start with lsOutput="" and just concatenate it as lsOutput+=str(o) instead of making it a list and doing a join at the end. Fixed both this and my previously-mentioned problem with the linebreaks.
Comments should exist to give context to what is going on, not explain the process (necessarily). The concept of "self documenting code" is often confused with "minimal comments". That's a misconception as that phrase is meant to encourage clear/descriptive naming (across variables, classes, methods, etc) and to write logically laid out code that isn't overly complicated just because it can be.
I was under the impression the last bit was never standardized.
In my own case, I think it trained me to think a bit differently because it forced me to think about how often I was repeatedly iterating over the same datasets and once I thought about it, I started building better habits. As a result, I believe the switch to Python3 has made me a better programmer.
yeah, who knows. here's a stupid (and evil) little script to find all the valid unicode attribute names (maybe limit it to a subset): #coding: utf-8 valid = [] hex_int = 0x0 while True: hex_int += 1 try: mychr = chr(hex_int) except ValueError: # reached the end of unicode support, done here break try: exec("{0} = 1".format(mychr)) except (SyntaxError, UnicodeEncodeError): pass else: valid.append(mychr) print("valid unicode attribute names:\n{0}".format("\n".join(valid))) 
speed as well. Over very large sets, you can see as much as 10x and beyond speedup.
I can't run this right now, but you might want to take a look at the "curses" library, which allows you more advanced control of the terminal than the basic "print()" function allows: https://docs.python.org/3/library/curses.html
 &gt;Python 3 offers relatively little different, except a saner, cleaner start. I like Python 3, but it doesn't have those huge simple new features like the C++ `auto` type derivation or lambdas. You see this is just making excuses. Today there is little reason to stay with Python 2.x on a new project. 
I'm not making excuses, I'm just saying what I think about comparing Python's upgrade to C++'s upgrade.
for ingame chat? or irc?
[ingame chat](http://imgur.com/HKCL3Ed)
nice sign-up modal design. ill "steal" it for my website :)
I'm not an expert on web2py, but as far as I know, web2py DAL is just Data Access Layer and not a real ORM. This means that with web2py after you load records from the database you should manually track changes and then explicitly save modified rows. PonyORM tracks changes automatically and then generates necessary updates upon commit. Since PonyORM (as well as SQLAlchemy) implements IdentityMap pattern, it caches objects within db session. If you try to find object which is already loaded into db session cache, PonyORM will return previously loaded object and skip unnecessary query to the database. PonyORM caches generated SQL as well as query results, and because of this PonyORM should work faster. In general, PonyORM allows you work with high-level objects, while with web2py you work with table rows. On the other hand, web2py offer full framework, including url routing, HTML generation and form processing, while with PonyORM to build complete application you should use additional components such as Flask or Tornado.
I have never seen someone else who plays Taric. I main Taric.
It's a tradeoff. Less RAM == More CPU. Slightly maybe but still.
Any reasons for the unpythonic file read/write?
Most people reading this thread will want to know what 'some loss' entails...
It's a pretty small bit of code, and the functions and variables are reasonably well named, so it's not bad. Good documentation is important for projects, but so is clean, readable syntax like what OP wrote (and Python makes easy). If you code in modular ways and maintain limited scopes in your functions and classes, you can get away with fewer comments and it makes it easier to organize your program. I have no idea how you program, but if you're having trouble keeping everything in your head for a given project (and needing to, for that matter), you might consider spending some up front time just working on the overall organization before writing actual code. Again, I don't actually know how you write, so this might be redundant advice. 
No problem, I could have elaborated or explained better, but I'm on a phone and was being rushed a bit in my reply by real life. :) I think there are appropriate times for comments for sure, most methods probably should have a comment indicating what they do, and my flaw is usually to under comment. But at least in python, when I read my code later I usually get what it's trying to do. Sometimes it makes sense to explain clearly what the inputs and outputs of each function should be. But I also think if the function isn't self explanatory, it could probably be rewritten so that it is--by renaming the function, or making lines of code more readable by splitting them up, that sort of thing. If your function doesn't do one thing and return a clear result, maybe it could be split into more functions that form discrete elements to solve. Anyway it's probably my least favorite part of coding, especially when I'm reading through comments to the code to ensure I understand what's going on. Worse than comments that are explaining what happens when unnecessary is comments that document code that has been refactored and no longer describes what is actually happening. Man I hate that. :)
Python 3.4 has reduced the steps for installation instruction in my documentation: http://selenium-python.readthedocs.org/installation.html#detailed-instructions-for-windows-users
You can add pip on v2 as well. easy_install pip
As I told flying-sheep, you used a ∆ in place of a Δ. Easy mistake to make.
The new range() isn't bad, because although it returns a generator, it's a special type of generator that informs you about what it encapsulates(eg range(0,4)). But yeah, that's what I mean. You can't see the 'contents' of an iterator/generator unless you consume it, and you can only do this once.
I'm the maintainer /creator of SQLAlchemy. I have *no* idea what you're referring to. Query building is the most central feature and function of SQLAlchemy. Please cite your source for this, thanks.
 in range(len( Aaaaugh.
There's no standard 8-bit ASCII. The ASCII standard is 7-bit, and when you ask for `'ascii'` encoding in Python, you only get 7 bits. This is important, because the other bit is used by UTF-8 (the really useful, really popular encoding of Unicode), and UTF-8 is compatible with ASCII, which it couldn't be if ASCII used all 8 bits. If you're looking at a "character map" with 256 characters on it, half of those are ASCII and the other half were chosen by your operating system. They change by the OS and by the decade. Maybe that will stop happening now that Unicode is everywhere.
I feel really dumb now. I never noticed 3//2 existed. I would always cast to integer via int(3/2). I just ran it through cProfile 100 million times and 3//2 took about 8.7 seconds versus int(3/2)'s 40.4 seconds.
That's not that great, though. If you don't use `print`, you get escape codes you can't read, as in `u'B\xe2chez l\u2019\xe9cole dans la c\xf4te sans \xeatre l\xe0'`. Python 3 would show you the actual characters. And if you *do* use `print`, it temporarily works, and then it crashes when you redirect the output to a file or a pipe! So to do this right on Python 2, you have to explicitly `encode` it as UTF-8, and then `print` it.
Even if you do nothing but cache non-sessioned pages for 15 seconds, Varnish is helpful; that will heavily mitigate the Reddit (Slashdot, etc.) Effect.
I highly recommend SA. It's really easy to set up. The code is minimal, I would hardly call it heavy.
Well, the problem with referring to it as "more portable code" is that the Python source tree is already riddled with special cases based on platform/compiler. My original patch sought to simply correct existing Open Watcom preprocessor definitions as Open Watcom probably hasn't been supported since Python for DOS. Some other patches, like handling all the special implementation-specific cases of *wcstok()* are already a mild hassle, and it could be argued that these patches add to the problem (although I don't believe this to be the case). The general problem is that the Python interpreter plus standard library are not a simple wrapper around the C runtime library like, for comparison's sake, Lua. In contrast, the Python standard library is a complicated beast with an assortment of workarounds to get things compiling on Windows, GNU/Linux, *BSD, MacOSX, and a host of other niche-but-supported platforms. Adding a "me too" compiler is bound to introduce some resistance from core devs just due to the additional complexity involved. However, I think Open Watcom is a special case because there are already remnants of support, albeit broken, for this compiler strewn about CPython. I don't think there's any harm in fixing them.
Well, I was wrong then. What are your thoughts about: http://www.reddit.com/r/Python/comments/22o4d1/recommend_a_minimalist_python_sql_query_builder/cgoui6w
I assume both in Python3!? What about running the same test in Python2, my guess is that `3//2`should be equal to `3/2` there, since it yields the same results...but you never know :P Also interesting: `3/2` vs. `3/2.0` in python3
&gt; non-virtualenv compatible binary installer Have you tried running easy_install on the binary installer from inside of your virtualenv? That should work. Or you could directly install to the site-packages folder in your env.
Wow, In [1]: str(xrange(5)) Out[1]: 'xrange(5)' In [2]: str(range(5)) Out[2]: '[0, 1, 2, 3, 4]'
ASCII is only defines 2^7 (128) characters. Any value larger than 127 is not defined by ASCII
One much needed feature for numerical programming will be the introduction of an [operator for matrix multiplication in Python 3.5](http://legacy.python.org/dev/peps/pep-0465/). Numpy has been needing something like this for a long time. Operations like np.dot(A,B) will simplify to A @ B . This might look minor, but goes a long way when you have complex matrix operations.
Happy days. Installable on express editions is a nice touch!
Yes, Python3.
these examples aren't correct because you can't use aggregate functions directly in the WHERE clause of a SELECT. filtering on aggregates directly involves placing them in the HAVING clause after you've partitioned the rows out using GROUP BY. I'd do them like this: 1. sess.query(Student).filter(~Student.courses.any(Course.year &gt; 2012)) 2. I'm not 100% sure on this one, it's something like this: subq = sess.query(Student.id).join(Student.courses).\ join(Course.professor).having(func.count(Professor.id) &gt; 1).\ group_by(Student.id, Professor.id).subquery() sess.query(Student).join(subq, Student.id == subq.c.id) 3. sess.query(Professor).\ filter(~Professor.courses.any(Course.year &gt; 2013)).\ filter(~Professor.retired) 
the examples look incorrect because it is applying aggregate functions in the WHERE clause of each query. I've proposed alternate queries at http://www.reddit.com/r/Python/comments/22o4d1/recommend_a_minimalist_python_sql_query_builder/cgpj00u
I posted an example in this thread actually. Yeah, i do sometimes write all the comments and doc strings first, before any actual code. 
Yah, much better. Again, top-of-my-head.
I've said that before and usually got downvoted to hell in this channel. I guess a lot of people who hang out here are Python enthusiasts ... Yeah there is just not enough of a carrot in Python 3 and not big enough of a stick in Python 2. The last point is more positive actually as it means that Python 2 is actually pretty nice language with a good library and Python 3 just has a hard time beating that. I would have to offer something really really good, 30% computational speed improvement, new shiny package manager, some integrated web framework, a largely expanded library -- I don't know, things like that. Don't want to be too negative but asyncio I think is a bad idea given the effort put into it. Anything based on promises and deferreds is just Twisted repackaged. As someone who wrote Twisted for many years, I fails to impress me. 
Object conversion is the tough part. I lose a lot of flexibility to easily obtain values from table schema and use them within an application. Far better to get them into a dataframe and go from there.
Wow. This is great Mathzx. You have a far more critical eye in implementing python in real world situations than I do. 
You have about 12 megabytes in about 1 second. That means 100 megabit speeds which is .1 gigabit. Why do you feel that your answer is wrong? 
&gt; Its the future. Really that is all you really need to know. I read it on Reddit, so it must be true. &gt; Contrast this to the C++ world and the rapid adoption of new standards by developers there. Compared to what C++11 brought to the table, Python 3 failed to. * "Oh we can do unicode better" -- yay! * "Print is a function! Let's break backward compatibility over it! * asyncio -- Ok so Twisted repackaged is part of the standard library, I can't wait to get me some hot inlineGenerator action! 
Finding down the road that a library you might use isn't compatible is a good excuse. 
Yeah, changing division like that is pretty fucking shitty, honestly. Shocking such a fundamental function would get changed like that. It's not like integer division with a single slash is so rare that it needed to be abandoned, either. Zealous person with power on the Python steering committee???
If what you need is to install Python 3.4, you can install the Debian package via ppa:fkrull/deadsnakes $ sudo add-apt-repository ppa:fkrull/deadsnakes $ sudo apt-get update $ sudo apt-get install python3.4 Source: [my Stackoverflow answer](http://askubuntu.com/a/446278/75760)
&gt; It's harder to confuse binary data, "plain text" (which isn't), and Unicode. On the downside, a simple `print()` to stdout can now throw an exception due to encoding error, which makes reliable scripting surprisingly tricky.
Unless you're putting really exotic characters in your `print()`, that generally won't happen. Regardless, [it's really easy to suppress exceptions](https://docs.python.org/3/library/logging.html#logging.Handler.handleError) if you use `logging` instead of `print()` (which, really, you ought to be doing anyway).
The `range` object (in Python 3.3 at least) is a special type of iterator which can be iterated over multiple times: `r5 = range(5); list(r5); list(r5); [x for x in r5]`.
By "really exotic," I mean illegal (e.g. U+FFFF). If you're trying to print illegal Unicode characters, it's a bug and you should fix it. Python 3 is *helping* you. &gt;You also don't really need to do anything more exotic then os.listdir() for this to happen, so it's really easy to write code that randomly breaks. This is because, for reasons which I still do not entirely understand, most Unix-like systems insist on using 8-bit strings with "no particular encoding" for their filenames. In practice, however, if you are using filenames which are not valid UTF-8, you are doing something very bad and wrong and you should stop.
Thank you very much, I agree with other posters that using the latest is the best practice and this doc is proof that it can be done.
Every time you start you start a new project in Python 2.x a puppy dies so theirs that.
What's wrong with that? I needed to loop through things, and know what the indices were. Do you know a better way of doing it?
Yes - I did not figure out how the exe package was made but it does not behave like a zip
Aahahahaha, so it's delta-the-mathematical-variable, not delta-the-greek-letter. I'd like to know the rationale for dividing those both, yet not, like, also introduce two Pis...
I switched for 2 month now. But they did something to urlib2 that screwed up some of my early scripts so I ditch the script. Other than that print has parenthesis and it uses xrange for range. These are the only ones I noticed right away.
It looks more like a drinking horn.. 
It's not that simple. You don't always control the names of files on the FS. They might have been extracted from a ZIP file. WRT the print() problem, just print everything with %r or {!r}.
Haha enjoy! We have been through many iterations of it. I think it works on most screen sizes too. I still don't know the best way to handle the error messages to help the user. 
Very true, but it's a lot of work for potentially no gain because *it's too early*. Concentrating on the other areas first would be a much better approach. Varnish can often hide serious problems, so should be used with caution.
How does it make it "surprisingly tricky"? I don't see how `print` is now any different from before. In Python2 it can *also* throw a Unicode error. Try to run the following on the console (in both Python2 and Python3): python -c "print(u'\xe9')" | less You will see, that in Python3 it "just works" while Python2 raises an exception. So, taking your words, you could say that Python2 in fact makes reliable scripting surprisingly tricky! Even worse, try the following in Python2: python -c "print('\xe9')" | less This is a common error! In Python2 you *must* prefix a string literal with `u` (to make it a unicode literal). Otherwise you will easily run into strange errors, even running the risk of corrupting data! Python 3 makes this *much less* error prone by making unicode literals the default instead of byte literals!
Great article, thank you
Gigabits per second, from total data transferred in bytes (D), and elapsed time in seconds (t): rate_gbps = D*8 / 10**9 / t Aside: The symbol GiBs would actually parse as gibibyte-seconds (where a gibibyte is 2^30 bytes), rather than gigabits per second. Gibibyte-seconds would be a unit of data * time, such as would be used for pricing cloud storage.
Oh there's no rationale in unicodeland. &gt;&gt;&gt; '\N{BLACK TELEPHONE}...\N{WHITE TELEPHONE}' '☎...☏'
&gt; So, taking your words, you could say that Python2 in fact makes reliable scripting surprisingly tricky! os.listdir() and friends didn't return Unicode strings in Python2. Something like this: import os for root, dirs, files in os.walk("."): for f in files: print(f) Works fine in Python2, but crashes in Python3 if you let it lose on a random set of files. &gt; How does it make it "surprisingly tricky"? How do you make this work cleanly? python3 -c "print('\udcda')" Note I am not saying that Python3 Unicode handling is bad in general, but this is a pretty common use case for which Python3 doesn't seem to have any clean solution right now.
We just have to use UTF-8 everywhere, and all is well. So sad that MS and Sun made the really bad decision to bake UCS-2 in their languages. It's what ASCII was back in the day, only worse, because it's less noticeable: good enough to make most people not recognize the problem, and fundamentally broken, since it can't represent everything. A char in Java is not an arbitrary character. It can also be garbage generated by chopping a glyph outside of the basic multilingual plane in half.
This will probably be burried along all the comments. But scanning through the comments, I didn't see any talk about the 2.7 packages that are also available in 3.x. [Here is a list of packages](http://python3wos.appspot.com/) showing this info. As much as I'd like to move to Python 3.x, in particular for the improved unicode support, which is a pain in the ass if (like me) you're dealing with lots of web text, I can't. I use NLTK *a lot* to process these texts, and it's only available for 2.7. So that's that.
pysvn requires lots of libraries to compile - it's not like you can just put it on pypi. It's really annoying ... but you have pysvn available as a ubuntu package. Just use `virtualenv --system-site-packages` :)
(smörgåsbord*)
An annoying one in python2 is a program that works in UTF-8 internally insisting on a different encoding to stdout
SOAPpy (https://pypi.python.org/pypi/SOAPpy) was ok for me. In general SOAP is a relic from the past.
But surely you could make a platform specific egg? 
This also has to work on Windows 32bit 
I just tweeted you, in case you were wondering who the hell that just was.
That's true for the people who learned Python 2 first, but for someone like me who started with Python 3.x, why look back at 2.x? There's not enough of a carrot for me to look at Python 2.x.
[This article](http://www.skymind.com/~ocrow/python_string/) is 10 years old but seems to be pretty accurate. I wrote [a quick test](http://pastebin.com/kES8mGLP) anyways to double check, and on the first run string += beat out ''.join no matter how big a loop I threw at it. A bit more testing and it seems like the tipping point depends on how large each chunk that's being appended is - anything more than a few dozen bytes per addition and string catenation slows down. So what's faster depends on what you're actually writing. Making a guess from what little I know of your function, I think you're working with pretty small chunks of info (since you're using a single space as a placeholder for info-less cells) But you're right, it's probably a good habit to use ''.join for preference.
I found several issues with the backported package (namely **lots** of deadlocks), so I had to scrap it. My choice these days (2.x and 3.x compatible) is `joblib`, which is truly amazing.
Python 3 is an embodiment of the idea that Unicode can be separated from the representation of Unicode. You have the one true Unicode entity and then you a bunch of encodings which you are not allowed to manipulate in any useful way. If you agree with this approach than Python 3 is lots better than Python 2. Note that this is not the only popular approach these days. There is a tendency to just use UTF-8 for everything and not worry about the philosophical difference between meaning and representation. If you prefer that way of thinking about things than Python 2 is actually a bit better (but not great). It will be interesting to see the direction the world ends up going in. If the Python 3 approach falls out of favour then we might have to change things again. The result would not be Python 2 either unfortunately... 
Just a quick note. Instead of doing this pattern in Python 3: def give_letter(word): for letter in word: yield letter You can do this: def give_letter(word): yield from word It was described a talk yesterday at Pycon by David Beazley. The 'yield from'-operator really opens up for some very interesting stuff! In general it seems like generators in 3.x have received a boost.
theirs?
you can use sse (server side events) and have a hidden message area in your website. you open a connection to the server which is one way (server can send to client only) and wait for messages. server sends {type:"error", msg:"failed"} or {type:"close"} and you have a on_received callback in js. You can also use websockets but in this case sse would be better i think. i made a flask example here https://github.com/papaloizouc/python-sse-example. If you want i can send you a screenshot of a real example.
&gt;I work a lot with django at work, we've been using 2.7. I want try and see if we could switch to 3.x for our upcoming projects but everyone online just assumes there's no support for it. I work with django and python 3 on (almost) all new projects at work. I think we have maybe one project that needed to be started on 2.7 due to a missing dependency. The features I like best in python 3 are: * chained tracebacks * the unicode support * zero argument super() * absolute imports and explicit relative imports * extended iterable unpacking * keyword-only arguments
A fully deterministic output from 'foobar' means that the result is no more secure than the password 'foobar'.
waiting for the opening keynote
Its a class that represents a 3 dimensional list, and this is the method for displaying that list in 2d. So if there is no object on the top layer, it will show the one one layer down if thats there. I use the 3d list as a "world" for my bots to traverse and mess around in. I have several subclasses which turns the list into terrain, and creates walls and whatnot. The entire world gets printed for every "round" in the simulation. After the bots had their go. So it does get run a fair amoun of times.
I recently found out about this from a coworker...Me being a dummy struggling with some exceptions and stuff with the original suds...:x
Will there be any livestream? [edit] Ok, seems like [it will be recorded and published](https://us.pycon.org/2014/speaking/recording/) at [pyvideo.org](http://pyvideo.org/) later.
A plethora of learning material? ;shrug
Meanwhile at Pycon 2014, an empty room. Huh?
Unicode support that isn't so resource intensive is ideal in 3.x. If your project contains a lot of atypical unicode character, that should be reason enough to begin the upgrade. Convincing everyone that a switch to 3.x will probably be fun though :)
This got me on the right track. Turns out it's a powder horn.
Hopefully no dongles ?
It's a little known fact that Python 3.4 has a built in cloaking module. It's in asyncio somewhere I think. The room is actually full.
Hey guys, those suggestions are great but I'm not the owner of this course... I think you could create issues for it on GitHub instead, I'm sure the original author will take a look at those. Cheers! :)
That bullshit was so ridiculous. Jokes are jokes!
&gt; That's pretty disappointing to hear. I'm sure it is - the work that's gone into the documentation shows. And I think it's excellent - given the complexity of the system. But - the final result is huge. Someone who isn't yet highly skilled at SA is confronted by a huge set of documentation: * How well will my code translate between MySQL, Postgres &amp; SQLite? * How do I define partitioning in Postgres? * OK, gave up on doing that with SQL Expression, how do I do it in raw sql? * I'm confused again about the various ways of executing statements - examples I'm seeing online aren't working for me... * Why is it so hard to find answers to my questions on stackoverflow? Given enough time people can overcome these points. But I find that most people that I've spoken with who are successfully using raw sql today find it hard to justify investing the time to get over the learning curve with SQLAlchemy. 
I think part of the problem you're seeing is that SOAP is largely out of fashion with the "cool kids" and it tends to be a feature only of enterprise-y frameworks that are Java- or .NET- oriented. JSON and/or REST are "the new hotness" although they're getting old enough that maybe something new is due to take over soon. I've used a handful of different libraries over time, including soappy, ZSI, and Suds. I felt like Suds was the easiest for consuming SOAP, and soappy was the best for writing your own service, and ZSI was really best suited for creating enmity and strife with maintenance engineers. So, now that I've said those things, take them with a grain of salt. Every time it came time to select a SOAP framework, the solutions available were always hard pressed to compete with "just use elementree and build the XML yourself." Every SOAP integration I've ever done has been just a little bit wrong and required significantly more work at the point of integration than I would expect out of such an established protocol. I'm not a fan of reinventing the wheel, but I would expect to spend some time on this one.
Unfortunately I'm forced to use web services as the system I am communicating with doesn't support anything else. But it does seem like SUDS is the preferred way still. I guess I was hoping for something newer and more elegant.
The stick of Python 3.x is that a lot of libraries are still not compatible with Python 3. Depending on your project you might or might not know what external libraries you'll be using in the future. Some of those libraries are large _existing_ codebases. But yeah for learning use Python 3.x but don't be surprised if on a real-world project you might end with Python 2.x
Fuck. My gender-balanced workplace generates at least twenty dick/vag jokes per day. Nice to know I could be character-assassinated by an uptight do-gooder if I ever attended a conference.
Yeah. I've been in the same position. The problem is that "newer and more elegant" starts with "so let's ditch SOAP, then...."
 if os.environ.get('PYTHONIOENCODING', None) != 'utf-8:surrogateescape': os.environ['PYTHONIOENCODING'] = 'utf-8:surrogateescape' os.execv(__file__, sys.argv) Make sure your script is executable and has a working shebang line.
You mean suds-jurko right? Because the one on fedorahosted hasnt been touched since 2010. Which is a shame. I tried SOAPpy, and SOAPy (notice difference), but they sucked compared to suds.
Oh, wow, this looks really elegant :)
Thank you. I used to work with an extended ASCII, but that was at an AS-400 shop (IBM) and didn't ever realize that it was their own internal thing. At least they didn't force us to use EBCDIC. 
Thanks!
Notice, Ive had a problem with suds (not the jurko version the old one) with really large XML files, suds way of parsing the xml to suds objects of some kind would eat up gigs of memory and hog the CPU. About 40% of the time was also spent in the saxparser used by suds. The solution was to tell suds retxml=True and then use lxml instead, lxml is 10000000% faster. Well, from 100ish seconds to 2 seconds. And the xml wasnt even that big, it was just a 15mb or so, I guess it was the structure of lists and lists in it that fucked it up. 
What are some more current technologies that people use instead of it? 
(I watched too much swedish chef in my younger years)
*Disclaimer*: I am not trying to militantly defend Python 3 Unicode handling. It is a very interesting topic, and I always hope to learn something new :) I find it annoying as well sometimes. But I believe that the limitations it enforces, prevent garbled data, and forces you to examine corner-cases. ---- `tl;dr:` Python3 may give you Exceptions when using listdir. But that's a good thing as it points to errors on your file-system. Python2 will silently accept whatever you hand it (depending how you call listdir). ---- The return value of `listdir` depends on input. If you run `listdir(b'.')` you will get bytearrays as return values. Leaving out the 'b' prefix will give you unicode strings. In Python2, the behaviour was similar. You will get the same type as return value as you put into the function argument. So, running `listdir(u'.')` would give you unicode strings. Notice, how the argument may well be a variable coming from somewhere else, and, if not careful, the same code may sometimes run on one or the other type, depending on how it's been called. This can be puzzling. But you have the same problem in both py2 and py3. In my opinion, it's a good thing python3 crashes on funny filenames, as it makes you aware that there's something gone terribly wrong on your system. Note that you can simply use the "b" prefix in listdir &amp; co on Python 3 to get a similar behaviour as on Python2. With the added benefit, that you now have byte-arrays. And Python3 prevents you from doing silly things with byte-arrays. I have been working on a system, where the sysadmin thought changing the FS encoding was as simple as modifying a variable in a config file. So he did. With the end-result that all files create *before* that change were lating-1 encoded, and everything thereafter was utf-8. Python2 programs did not complain about this (as you mentioned) and silently accepted the bytes it got from the OS. The application I was working on scanned filenames and put them into the DB. So the DB ended up having sometimes utf-8, and sometimes latin-1 bytes. It was a major nightmare. If I had used the "u" prefix in python2, I would have gotten exceptions at the right places (i.e. before storing something garbled into the DB). Unfortunately, I did not know yet that `listdir` had different outputs depending on input. ---- And concerning surrogates: The unicode standard charts say this about low surrogates (`0xDC00`—`0xDFFF`): &gt; Isolated surrogate code points have no interpretation; consequently, no character code charts or names lists are provided for this range. So how do you expect it to be handled? An exception seems perfectly fine to me. I assume that you wanted to use `0xFFFD`?
For simple use cases I just used lxml and requests. Here is a snippet that gets an auth token for Microsoft services: from lxml import etree from lxml.objectify import ElementMaker import requests SHAREPOINT_URL = 'http://mycompany.sharepoint.com' USERNAME = 'username' PASSWORD = 'password' NSMAP = { 's': 'http://www.w3.org/2003/05/soap-envelope', 'a': 'http://www.w3.org/2005/08/addressing', 'u': 'http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-utility-1.0.xsd', } NSMAP_2 = { 'o': 'http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd', } NSMAP_3 = { 't': 'http://schemas.xmlsoap.org/ws/2005/02/trust', } NSMAP_4 = { 'wsp': 'http://schemas.xmlsoap.org/ws/2004/09/policy', } S = ElementMaker( annotate=False, namespace=NSMAP['s'], nsmap=NSMAP, ) A = ElementMaker( annotate=False, namespace=NSMAP['a'], nsmap=NSMAP, ) U = ElementMaker( annotate=False, namespace=NSMAP['u'], nsmap=NSMAP, ) O = ElementMaker( annotate=False, namespace=NSMAP_2['o'], nsmap=NSMAP_2, ) T = ElementMaker( annotate=False, namespace=NSMAP_3['t'], nsmap=NSMAP_3, ) WSP = ElementMaker( annotate=False, namespace=NSMAP_4['wsp'], nsmap=NSMAP_4, ) envelope = S.Envelope( S.Header( A.Action('http://schemas.xmlsoap.org/ws/2005/02/trust/RST/Issue', mustUnderstand='1'), A.ReplyTo( A.Address('http://www.w3.org/2005/08/addressing/anonymous'), ), A.To('https://login.microsoftonline.com/extSTS.srf', mustUnderstand='1'), O.Security( O.UsernameToken( O.Username(USERNAME), O.Password(PASSWORD), ), mustUnderstand='1', ), ), S.Body( T.RequestSecurityToken( WSP.AppliesTo( A.EndpointReference( A.Address(SHAREPOINT_URL), ), ), T.KeyType('http://schemas.xmlsoap.org/ws/2005/05/identity/NoProofKey'), T.RequestType('http://schemas.xmlsoap.org/ws/2005/02/trust/Issue'), T.TokenType('urn:oasis:names:tc:SAML:1.0:assertion'), ), ), ) payload = etree.tostring(envelope) response = requests.post('https://login.microsoftonline.com/extSTS.srf', data=payload) document = etree.fromstring(response.content)
There is unfixed bugs, compared to the suds-jurko version and indeed Ive stumbled upon it and yet Ive only used suds to consume a simple webservice. Also suds-jurko works with python3 I think. 
we're using suds at work but it leaks memory and it's so painfully slow that we're only using it only to deal with the ws, we parse the XML by hand with lxml. yes we tried the fork, same result.
That's a very nice tip, thank you.
[Binary builds for windows](http://pysvn.tigris.org/project_downloads.html) 
What I'm seeing is that most of the time you define a REST api with data sent as JSON.
I looked into this a couple of months ago for similar project. The state of SOAP in python is sketchy at best. I found it best to just cook up a flask project that did its own XML serialization.
I think my preferred way would be to say "Thanks, but no thanks. I'll get another job elsewhere" ;-)
It is not setuptools compatible. It cannot be unzipped. It cannot be deployed into a virtualenv without extreme hackery. 
If adding an async lib to python is any indication of how fast features get merged into python.... it might be a while. My undereducated sense is if you design idiomatic python code bases with proper testing a type system is not a must have feature to the language.
libsaas
use enumerate instead.
ok. I work extensively with python on windows and like the binary installer approach. In my experience, if you try to treat windows like *nix, you will hate your life (and windows). When in Rome...
I have called a command to skip the checking of that. Then fabric should work. ssh -oStrictHostKeyChecking=no host@ip 'uptime' If you have previous keys on the machine already you might have to do: ssh-keygen -R ipAddress ssh-keygen -R dnsName
They realised this long ago. It just takes time to implement and for python 2.5 and older to die off (CentOS etc take a while to update). There are significant differences between 2.7 and 2.5 (and to a lesser extend 2.6) that make it much harder to support a single source file that also runs on 3.2+
To be honest this way of doing it (single source file for 2.7 and 3.2+) has been the "recommended" way for a quite a while, but things take time to put into motion, and 2.5 and older take time to die. (CentOS etc take a while to update)
I can only speak for myself. It's not that there aren't any good projects out there with camel casing (Twisted comes to mind), but if I'm looking at packages and I have two alternatives, one that's camel cased and one that's not, I'll almost always go with the non-camel cased one. It's not an entirely accurate metric, but when I see camel casing it's usually a sign that PEP-8 isn't being followed elsewhere. I won't frown, but I will probably skip over the package if there's an alternative available.
i don't get it
Will definitely help my fellow scientist here ;)
Awesome! Have been using its previous version. And totally love this.
Woops, it's not? Shame on me! lol Btw, the votes are interesting: not sure it will stay positive, zero or negative * I add a positive vote here! 1 point (51% like it) 16 upvotes 15 downvotes
&gt; So how do you expect it to be handled? Having `PYTHONIOENCODING=utf-8:surrogateescape` enabled by default on stdout if the terminal is UTF-8 might be a good idea. Right now it's really weird that you can read data from the filesystem or `sys.argv`, but can't `print()` it without a possible exception even if your terminal is UTF-8. Both reading filenames and `sys.argv` make use of `os.fsdecode()`, which generates an invalid UTF-8 sequence using surrogates to escape the invalid bytes in the input, but `print()` doesn't use `os.fsencode()` on the output: &gt;&gt;&gt; os.fsdecode(b"\xbf") '\udcbf'
Send me a PM. Happy to meet up. 
so I did: i = gg.GeneratorInterface() t = i.GeneratorGenerator((1,2,3,4,5)) s = t.Generate(1) # I've tried 0, 1, 5 and I get: TypeError: 'tuple' object is not callable Am I doing something wrong?
You're supposed to supply it with a class that implements Generator (so that it can generate instances of it for you). Also don't take it too seriously, it's mostly a thought exercise. (See the example at the bottom)
This reminds me of [Numbers for Humans](https://github.com/dcramer/numbers).
hahah, amazing!
TIL `lxml.objectify`. Great snippet !
This is a great place to start using flask. I've been looking for a reason to start dabbling with websockets too. Thanks for setting this up!
Nice work. Just from reading the code, I don't think Pandas can intuit how to put team logos on the scatter plot and remove outliers. Care to comment about how you went about generating the scatter plots on the website? I always struggle with fancy chart techniques. Thanks
brb integrating it into my codebase
I feel it is not business ready. It needs more package modularity. Only one class per file is really clean enough.
My preferred way to work with SOAP is to fire any client that requires I use it.
Was deliberately. Our target audience didn't have any knowledge of good practices in programming (i.e. they always let the file pointer open in their scripts). So I introduce exception handling (try..finally) together with the file read/write operation. In this way they can adopt the practice in their Fortran/C++ scripts.
If a cracker knows that you are using this. Also, it will take longer to crack the password, as it needs to be run through this, which will take a bit of time.
The guidelines for REST were actually developed as part of HTTP/1.1, which makes it a few years older than SOAP.
[D3](http://d3js.org/) is another tool to look at.
You should be able to do it with matplotlib as well. Still, awesome work!
&gt;I honestly stopped reading after you mentioned that you used per. &gt;.... &gt;That said, your conclusion is pretty spot on. Does anyone else see the contradiction?
Saw some posts presenting [matlab](http://en.reddit.com/r/pics/comments/21y9ks/wrote_a_matlab_program_that_converts_pics_to/) or [R](http://www.reddit.com/r/rstats/comments/21zt6m/r_script_for_ascii_art_oc/) scripts to convert an image to ascii art. Since I'm currently refreshing my Python I tried to do it in as little statements as possible (bonus: no explicit loops). Usage (after downloading and making the script executable): ./asciinator.py image scale factor parameters: image - path to your your image file scale - size scaling for the image (0.5 = half size, 1 = original size, 2 = double size) factor - gamma scaling (values smaller 1 enhance lower intensity pixels, values larger than 1 enhance darker pixels, a value of 1 uses the original intensities) to get snoo from an image for instance: ./asciinator.py snoo.jpg 0.5 2 Edit: usage example
What is `factor` in the code?
&gt; Then you can no longer pipe things into xargs and friends True. I was thinking more in terms of quick-and-dirty debugging. For actual output, obviously you have to encode it properly (if possible). Though you don't have to/can't explicitly encode output in Python 3, right? (I haven't really used it yet—I considered it largely broken before ~3.3, and `asyncio` is the first new feature that has grabbed my interest.) 
[spyne](http://spyne.io/) to generate an endpoint.
An interesting point -- but SOAP's heyday was really right around 2005, and REST really hit its stride around 2010 as AJAX became a fairly standard thing.
This is insanely cool.
There's actually some discussion from the latest python language meetings about defining symantics of function annotations. since MyPy seems to be the first thing that makes use of them that seems to have got people's attention, it may end up becoming standard
can people get that kind of data publicly?
I wish
It's a scaling factor for the intensity values. Values smaller 1 enhance lower intensity pixels, values larger than 1 enhance darker pixels, a value of 1 uses the original intensities. Also added some better explanation regarding usage in the original comment.
https://pypi.python.org/pypi/Scio/0.12.0 is what I used last time I had to deal with this, worth a look especially if you have a WSDL for the SOAP service.
The Host header is required for all HTTP 1.1 requests and any of yesteryear's websites on shared hosting would have been broken without it so you're pretty safe assuming it'll be there.
From the Python glossary: &gt; An object is hashable if it has a hash value which never changes during its lifetime (it needs a \_\_hash\_\_() method), and can be compared to other objects (it needs an \_\_eq\_\_() or \_\_cmp\_\_() method). Hashable objects which compare equal must have the same hash value. This does not necessarily hold for immutable objects.
Thank you for this. I've been meaning to find an excuse to play around with [LilyPond](http://www.lilypond.org/) and now I have one. Brilliant!
I actually gaped as I read this. Truly magnificent work you're doing.
wow - you should go work for the smithsonian. this is amazing work! very impressive and very well presented
&gt; Every time it came time to select a SOAP framework, the solutions available were always hard pressed to compete with "just use elementree and build the XML yourself." I've found this as well. The technique you describe has worked great for me too.
I think everyone agrees Python packaging is a mess, but it is getting better (with version 3.4+) and it is mostly a problem on Windows (but mitigated if you use Anaconda/miniconda). Python 3.4 on Linux using pip/pyvenv, I am finally comfortable in making a Python environment. On Windows at work even with no admin rights to my PC, miniconda has made it mostly problem free. Am I saying everything's alright now? No, but I think we've come a long ways.
Your definition of hashable is wrong. An object is hashable if it has an attribute `__hash__` that is callable, takes exactly one argument, and returns an `int` value. Instances of this class are mutable and hashable: &gt;&gt;&gt; class A(): ... def __hash__(self): ... return 0 ... &gt;&gt;&gt; a = A() &gt;&gt;&gt; a.attr1 = 1 &gt;&gt;&gt; hash(a) 0 &gt;&gt;&gt; a.attr2 = 2 &gt;&gt;&gt; hash(a) 0 You can create an immutable, but not hashable class by disabling `hash` and setting attributes like this: &gt;&gt;&gt; class Immutable(): ... def __setattr__(self, attr, value): ... raise NotImplementedError("Can't touch this!") ... ... __hash__ = None ... &gt;&gt;&gt; i = Immutable() &gt;&gt;&gt; i.a = 1 Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 3, in __setattr__ NotImplementedError: Can't touch this! &gt;&gt;&gt; hash(i) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: unhashable type: 'Immutable' But as always in Python, it's easy to get around this: simply redefine the class attributes like this: &gt;&gt;&gt; i.__class__.__hash__ = lambda self: 1 &gt;&gt;&gt; hash(i) 1 Sidenote: All new-style classes inherit `object`'s `__hash__`, so the simplest hashable and mutable class is actually this: &gt;&gt;&gt; class A(): # A(object) in Python 2.x pass &gt;&gt;&gt; a = A() &gt;&gt;&gt; hash(a) 8773527249905
&gt;SimpleXMLElement seems a bit cumbersome as well. SOAP: Something Obfuscated and Annoyingly Problematic.
H... how!? I am absolutely blown away in how clever this is! It's so cool, but also so discouraging as someone who wants to be a programmer someday haha
I got a PyBoner reading that. Fantastic job, excellent idea, and brilliant execution putting it all together. Big thumbs up.
Why is the same video posted 3 times? I'm so confused. Is that the video he jacked from the other piano roll with his results dubbed overtop?
Based on his focus, it looks like the anaconda python distribution (and conda) might suit his needs better. Use conda for the science packages, and pip for packages not on the repo (or outdated ones). As far as package management goes, conda has provided me with the most pleasant experience so far. I've used it in linux too, but in windows especially I now consider it a must.
There's obviously something lost in translation between the def I gave of hashable, which is my understanding of the glossary def of hashable (shown in another comment in this thread) and your def and use of hashable above. But that's ok I think because I think I get the overarching lesson. I absolutely appreciate your taking the time to explain this, and I follow much of what you're saying. I'm familiar with the concepts and can deduce much of the code that is called but there's a kinda fog for me in some of it... my brain tends to catch (like a sleeve on a branch as you're running thru the woods) on specifics even if i understand everything around it. The lesson I take away from this is that 'immutable' is a python concept/description, and hashable is a literal. and the 2 aren't joined at the hip. 
Shouldn't that be yield from word? 
Is `fsencode` / `fsdecode` not meant to de/encode *filenames* only? Hence the "fs" in the name? Because, strictly speaking, the terminal is not the file-system. So the FS might store names in latin-1, while you are using a utf-8 terminal. It's something I also mistakenly used a few years back. Because of the problem I mentioned above. I even went on to use `sys.getdefaultencoding()` which actually has *nothing* to do with anything os, or fs related. But I see your point. As far as I can tell, there is no reliable way to determine the encoding of the terminal.
The advantages to using a tool like sqlalchemy over writing SQL by hand and more importantly writing boilerplate SQL execution and result fetching code are so vast, that if someone isn't aware of them, then they aren't ready to use a tool. They should spend a few years writing repetitive SQL strings and boilerplate database access code until they get tired of it, then seek to learn a better, but conceptually much heavier, way to work. A few attempts at writing their own small SQL layers is a plus - the challenges inherent will then be very clear to such a user. If all the apps they write are so small that they are content with raw cursor access and plain SQL string concatenation and feel they are "successful" at that level, then they're done. They don't need to use any kind of tooling. Obviously it's a widespread view that as code becomes more complex and large, having lots of SQL strings, ad-hoc parameterization and cursor execution/fetching logic everywhere isn't helping anything and there are better ways to travel. SQLAlchemy does not have direct APIs for PostgreSQL partitions. Relational databases have thousands of platform specific features and behaviors - expecting sqlalchemy to support them all out of the box is not a realistic expectation. SQLAlchemy instead provides building blocks that allow the accommodation of the vast majority of special database features, but the developer has to handle this, or else locate third party tools for many of these features. For example there are recipes on the [wiki](https://bitbucket.org/zzzeek/sqlalchemy/wiki/UsageRecipes/PostgreSQLInheritance) regarding PostgreSQL partitions, building upon standard extension points. as far as executing statements this is explained IMHO pretty clearly first in the [tutorial](http://docs.sqlalchemy.org/en/latest/core/tutorial.html#executing) and then in more detail in [working with engines and connections](http://docs.sqlalchemy.org/en/latest/core/connections.html). As stated earlier, work is ongoing to add more "seealsos" and other cross-linking for more detail on concepts introduced. The newcomer to the documentation should run through the tutorials, then familiarize with the basic idea of each of the various sections detailed on the [main page](http://docs.sqlalchemy.org/en/latest/index.html). Finding examples "on the web" is not recommended, most of what I see on the web is of poor quality. Truth be told, SQLAlchemy is not intended to be the easiest tool in the world to learn. It's intended to be the most amazing and powerful once one *does* learn it, and this requires that a new user make an earnest investment in the documentation. This is the origin of using the name "Alchemy", in fact. Recently I've added [the library](http://www.sqlalchemy.org/library.html) which includes links to talks and tutorials. If you are seeking to learn core, my talk "Introduction to SQLAlchemy" might be worth watching. 
The PEP: http://legacy.python.org/dev/peps/pep-0465/
This is beyond cool! You should post this on [HN](http://news.ycombinator.com/) also (if you haven't done so already), I'm sure there are many people there who would appreciate your work also.
&gt; The lesson I take away from this is that 'immutable' is a python concept/description, and hashable is a literal. and the 2 aren't joined at the hip. That's right. They *are* related, because hashing is mostly useful for immutable objects. Dictionaries use the hashes, and looking things up in a dictionary assumes that the objects used as keys haven't changed since you put them in the dictionary. But you can construct mutable, hashable objects and immutable, non hashable objects, as NotAName demonstrates.
That was a fun read, and an uncommonly clear description of some of the math I use a lot as an electrical engineer. 
I love articles like this, because given the same problem I probably wouldn't know where to start. So I'm looking forward to digging into this to learn something new.
 ([], []) is immutable but not hashable. So no, these are not redundant.
Enjoyable read. A little tangential, but I would like to see some way to rank teams that accounts for the fact that good East teams have an inflated record since they get to play other East teams twice as much as West teams. Though this probably wouldn't affect your results by much.
/r/WeAreTheMusicMakers might be interested in this.
\*shrug\* Dunno. REST always seemed pretty common to me. Hell, WebDAV had its heyday long before 2010.
Holy crap. And you actually know how to play it, too.
Awesome work. I work in digital preservation at a national library. I'll be sharing your post with the music curators there and will see if we have any piano rolls in a suitable format... Can I ask a dumb question about this line: strike_times = (key_changes == 1).sum(axis=1) Whats going on here? `key_changes == 1` presumably evaluates to a bool object, which has no `sum` atribute 
If you are anywhere near Ohio, USA, you should do a talk about this at pyohio.
 pip install PyBoner
Ahh, cool. Thanks, that makes total sense. 
Great project and an interesting write up of it. I'm a pianist and python programmer so this really clicked with me. I also liked the syntax highlighting. I guess it's a pygments theme - which one?
You have to be much more than just a programmer to come up with this.
/r/learnpython!
I sort of dug around there for a long time. You're gonna get a lot of advice in past threads and the FAQ. The only thing that clicked for me doesn't get mentioned there. Peachpit's Visual Quickstart Python. And then I had to return it to my library Σ(ﾟДﾟ). 
As a fan of both Gershwin and Python, I salute you.
Thank for the insight! 
I use Sublime Text 3 with SublimeCodeIntel and SublimeLinter with SublimeLinter-flake8 plugins (SublimeLinter is an engine for linting plugins, you install the base plugin then your language specific linters). It provides great autocompletion and real time linting/flake8. EDIT: [An example](http://imgur.com/79mmAcO)
As an engineer who relies on Python every day, this makes me ridiculously happy. The example used in the PEP is actually very similar to something I've had to implement, and it would make that block of code about half the number of lines with an infix matrix operator. I can also see where this could be used quite a lot as an "extra" operator for performing all sorts of strange tasks. Now if only we could get a PEP accepted that allows us to define arbitrary operators...
Absolutely brilliant
I'm really glad they settled on @, it takes me so long to find ×, ⋅, ⊗, or ° on my keyboard.
I think this just adds more complexity, people who deal with multiple languages say R , Matlab , Python or certain C++ libs will now have %, .* and % to remember.
I know, many people will hate this: but VIM (or MacVIM) is still my editor of choice - you asked for scripts, thus an IDE would be almost overkill for this task, right!? - and VIM also has autocomplete (for variables) via ctrl+n. I also like IPython notebook a lot, it's great for trying things out, documenting it, and for inline plotting!
Resources: You mean "Code~~A~~cademy"? I wouldn't recommend it, and I don't think it is a good resource: It looks like it was done in hurry, rather like a quick and dirty tutorial. I would really rather recommend Learn Python The Hard Way, or online courses like Udacity's CS101. Here is an article that lists 10 good Python resources for beginners (9, if you subtract "Codecademy"): [http://codecondo.com/10-ways-to-learn-python/](http://codecondo.com/10-ways-to-learn-python/) IDE: I would just use the texteditor you are already comfortable with, e.g., VIM, Emacs, SublimeText ..., but also consider IPython Notebook, it is great for documenting and experimenting! About the Python Version: Don't worry about it for now! Just pick a tutorial and use the version they are using. There are important differences between version 2.x and 3.x, but they mostly apply to stuff you'd do on an advanced level, I think the only difference you'd have to consider for the tutorials is, e.g., Python 3.x `print('Hello World')` `3/2 ` evaluates to `1.5` `3//2 ` evaluates to `1` Python 2.x: `print 'Hello World'`, but also supports `print('Hello World')` `3/2 ` evaluates to `1` `3/2.0` evaluates to `1.5` EDIT: Ah, but if you are a VIM user, one more tip, since Python is crazyabout indents/whitespaces, pls add `autocmd Filetype python setlocal expandtab tabstop=4 shiftwidth=4` to your `vimrc` file, it will expand every tab to 4 whitespaces (this is the common Python style recommendation for indents)
Honestly, if someone can't handle the complexity of a single new operator, he should probably avoid writing scientific code and stick to making tumblr scrapers.
Use Anaconda. Seriously, just use it. Virtualenv and pip were not designed to really solve the use cases of the scientific community; conda (the open-source, cross-platform, cross-language package manager in Anaconda) was designed specifically for that. All of the libraries available in the Anaconda repo are built to be relocatable. You can easily, instantly switch between different versions of compiled libraries or entire sets of libraries, and be confident that the underlying C and Fortran libraries for them are compatible. This is simply not handled by virtualenv and pip. In fact, if you look at the Python Packaging Authority's page on tool recommendations, they suggest conda: http://packaging.python.org/en/latest/current.html We've had many very productive conversations at PyCon the last few days about how to better message about this. Use pip to do source builds of things - and managing compiler and library compatibility is *your* problem. If you are a webdev with no native code (or very trivial native code) dependencies, then you're in the clear. If you are a scientist or data analyst, this may be more of a burden - especially if you are on windows. conda provides a simple way for you to robustly manage *binary* packages with complex interdependencies at the C level, which applies to much of the scientific stack. The fact that it's cross platform *and* cross-language is added bonus. We have built R, Ruby, Node.js, and C++ libraries and manage all of those in conda environments across Windows, Mac, and Linux. 
&gt;“Don’t learn Python ... it’s ugly.” Really? I had never heard that before.
Of course, this makes email addresses valid python code: "foo@bar.com"
As someone who uses R, Matlab, and Python on a daily basis, this is infinitely better. Remembering to use @ and * or %\*% and * or * and .* makes you think for 5 seconds every time you switch languages. Having to type stuff like dot(dot(dot(dot(A, B), C), D), dot(dot(X, X.T), dot(X, Y))) is much worse.
Good catch! Yes it should. Thanks for letting me know, I will correct it right away.
anything but sublime text
It's the "Solarized light" color scheme.
whatevers fotm...
I wish :(
I like a combination of raw sql and something like sql expression: * Recognizing that no matter what - you need to know SQL and your database. * ORMs can make you more productive, but they take time to learn, and you may need to use multiple ORMs for different languages. * Allowing one to use higher-level abstractions where they can, and quickly retreat to raw sql whenever diminishing returns are encountered. I think the challenge is making it as easy as possible to for users to level up on the tool.
pycharm for IDE is great, the very best 2.7 is the weapon of choice 
 from re import compile as r line1 = "Cats are smarter than dogs" line2 = "Dogs also like meat" if r('Cats(.*)').match(line1): print("What's easier than a function call?") if r('Dogs(.*)').match(line2): print("'In-line regular expressions' are nothing more than syntactic sugar.") print("The examples on the pages you linked to are not equivalent.")
&gt; That Ruby has so little syntax that it can masquerade as C or Perl or Scheme I'm pretty sure I read an article about Ruby that said that the syntax was so complex and weird that all implementations of Ruby included one specific file from the original Ruby implementation because there just wasn't any reasonable way to define it... Anyone has a link?
I don't know much python and I think the syntax is weird, but damn am I glad I subscribed to this subreddit. That was an awesome article and a very practical solution to a real problem.
&gt; Why is the same video posted 3 times? The three videos are quite different (but they have the same music of course). If you see exactly the same video each time, you have a problem on your computer.
+1 for PyCharm
&gt; so that's why I use UCS-2 characters for everything! huh, where does he say that?
IDEs that do this **well** are also 'heavier', so maybe not ideal for small scripts, as they include 'project' stuff etc that you don't want to deal with. Text editors like Sublime Text and VIM can also get some kind of completion done, but the suggestions aren't nearly as "intelligent" or useful as PyCharm, Wing IDE etc. For small scripts one workflow I use is bpython interpreter + any text editor. **bpython** is excellent at autocompletion, and instantly showing you snippets like the documentation and parameter lists, and in my experience it shows you only stuff relevant to your current context.
I started a discussion asking for this very feature in this subreddit two years ago, some of the comments from back then are interesting in retrospective. http://www.reddit.com/r/Python/comments/mpt2f/can_someone_tell_me_why_we_cant_add_matrix/ 
Although I use vim + plugins i would vote for free PyCharm. http://www.jetbrains.com/pycharm/features/editions_comparison_matrix.html 
Vive la difference!
Hi there, if you'd perhaps like to have a look at something more than simple SOAP calls, please check out Zato ESB and app server .. https://zato.io/blog/posts/secure-scalable-and-dynamic-invocation-of-soap-services-with-zato-and-suds.html .. this still can use Suds - a stable and modern fork of Suds to be precise - but offers a lot more in addition to mere SOAP: https://zato.io/docs/ And if you don't like Suds, you can naturally use lxml https://zato.io/docs/progguide/examples/soap.html
Wow, you've earned yourself a fan! Great combination of Python and musical knowledge and the ability to actually play the piece pretty well. And that damn use of the Fourier transform to get the key locations was clever as hell.
It should be encouraging instead. The elegance of the Python code shown here makes it a much more attracting process to become a programmer than it has ever been.
Currently, I am with you :)
How is that a flask? It still looks like a hot pepper to me :/
&gt;stick to making tumblr scrapers. Don't jest my good man; I'm still stuck on developing soundboards! 
 os.urandom(20).encode("hex")
How about a random number? &gt;&gt;&gt; import os &gt;&gt;&gt; from binascii import hexlify &gt;&gt;&gt; hexlify(os.urandom(16)) '141ca3d31d22caa6d938bcddfa718cf0' 
FWIW, as someone points out below, please keep in mind that this blog post is from 2010, which pre-dates Anaconda and conda...
I am aware of Zato, but unfortunately it is not useful for this. I'm working on a web app fetching data from only one system, and adding Zato would add more complexity and another layer.
My primary OS is Linux, but sometimes I need to use Windows too. For Windows I found an excellent small free IDE called PyScripter. The installer is less than 5 MB and it knows the most important things: syntax highlight, code completion, Python shell, debugger, etc. Under Windows I will use this IDE from now on.
We're taught at university to use IDLE for Python. Personally, I prefer using vim...
actually I find the inline eval in strings(though it can be dangerous) more useful than inline regex. "#{user.name}: #{user.email}" still doesn't make up for the fact that it isn't python though. 
Agreed, in my few years of experience the companies I've been involved with are fairly slow to move over (for good reason, it's not much value add to refactor old working code). But in my own time, learning 3. has been worthwhile.
I like Komodo but it cost. http://komodoide.com/ Generic use of IDLE as well when stuck on windows http://en.wikipedia.org/wiki/IDLE_%28Python%29 
I agree its easier than all the dot crap, but still seems unpythonic to make you think an extra 5 seconds every time you switch languages, these 5 seconds can easily add up to hours or even days every year...
Where dont they show up? What exception or error are you getting? What IDE or interpreter are you using? You should be able to do: import numpy numpy.sin(0) numpy.tan(0)
A bunch of sticks said that...once. □
You already have to think those couple of seconds every time you switch languages for a ton of other stuff. Do I use [] or () for indexing, do I use range() or a:b:c for creating ranges of indexes, do I use len() or length() to get the length of an array, do I have to deliminate lines or not, etc. This barely changes anything. Also, for 5 seconds to add up to a whole day over a year would require changes languages 17,280 times a year. That's like 50 times a day. If you're switching languages at a more reasonable pace of 2 times a day or so, you're losing an hour a year. That's not a huge amount of time. Not having to deal with the dot syntax saves you a lot more time than that under any reasonable assumptions. Also, if you think it's too hard to switch, then just stick with the dot notation. It's not going to go away because of backwards compatibility. But, for me at least, it's a godsend that will save me a lot of typing and thinking about little things that I don't want to think about, like matching a million parentheses. 
But that's not likely to be very relevant for a *beginning* programmer. All of the major packages have all moved over, and I really doubt that anyone would need to use any of the ones that haven't when they're just starting out. And he definitely won't be using python to make money for at least a couple of years. Your point would probably be solid if he were an experience programmer picking up python or something. But its different for a completely new programmer. If and when he runs into a package or framework that hasn't been ported then he can easily learn the differences at that point. But that probably won't be for a couple of years, and the chances of it ever happening are getting lower every year and people switch.
In this particular case, I'm quite happy -- Guido did the right thing, and I think *most* people agree with his decision. NumPy is too important of a project to not invest in, in a language sense. On the other hand, I'd be worried if too many of these things were added to the standard language proper, for fear of our clean code turning into something that looks like perl. If python went the scala route, I worry about how binary operators work generally between modules (@ is fine for numpy arrays, but how does it work for other objects?). There are some who are advocating for scala like ability to add these operators at will. I generally dislike that approach for reasons of readability.
You can but you can just reply on here too. What OS are you on? How are you installing things?
Yeah, this looks like more of a "facebook meme infographic" library than a scientific visualization library.
I don't think that's too much of an issue. Guido has repeatedly rejected any more comprehensive addition of operators (e.g. [PEP 225](http://legacy.python.org/dev/peps/pep-0225/)). They didn't even add the @@ operator with this because they wanted to be conservative about it. As the PEP explains very clearly, there's a strong and unique case for adding an operator for matrix multiplication. It's hard to think of any other other similar situations.
Awesome analysis! I've been looking for something just like this in python/pandas. I like how you kept everything simple. If you ever get the time, I'd love to read an intro to data analysis with pandas post from you. I have Wes Mckinney's book, but it doesn't keep the beginner in mind. He even starts with list comprehensions, while they are awesome, it really tripped me up at first. Focusing more on the basic statistics would be much appreciated. Have a good day!
I have closet full of piano rolls and a player piano in my dining room so this was super awesome to read. I have a couple of questions though. How would this method deal with damaged roles? I've got a Rachmaninoff prelude role that is perform by the composer himself. If I were to film this,what would be the optimal way to film it? Would it be good to include the piano keyboard in the shot?
how about uuid?
Honestly, for Numpy/Scipy stuff, it's easier to just go with a [prepackaged distribution](http://continuum.io/downloads)
/u/catcradle5 and /u/yakiang have both provided good answers but the question OP needs to answer is do you need random or unique tokens? `os.urandom` will get you reasonably random tokens so long as the system has enough entropy but it's not guaranteed to be unique especially in a distributed system. Personally I'd always favor unique tokens over random and would use hex uuid: import uuid uuid.uuid4().hex And if you wanted a sha1 out of that instead: import hashlib import uuid hashlib.sha1(uuid.uuid4().hex).hexdigest() **edit**: /u/strftime is also correct, the above is technically based off of a random generator. The main difference though is, technically, the changes of collision are very low. Still does not really solve the random vs. unique problem though which in a distributed system is difficult fully solve. 
True, but where do you think uuid4() get's it's random number from? It has the exact same problem. Edited to add: The "low entropy" problem afaik only exists on Linux, and only after the very first boot sequence. After a reasonable amount of entropy has been collected once, it's safe to use, and your OS will carry over a seed across all subsequent reboots.
You can do something quite similar in Python: &gt;&gt;&gt; class dummy: pass &gt;&gt;&gt; user = dummy() &gt;&gt;&gt; user.name = 'John Doe' &gt;&gt;&gt; user.email = 'johndoe@example.com' &gt;&gt;&gt; '{0.name}: {0.email}'.format(user) 'John Doe: johndoe@example.com' &gt;&gt;&gt; '{user.name}: {user.email}'.format(**locals()) 'John Doe: johndoe@example.com' 
Hey man, I've been following your stuff for a while, you are brilliant! I love everything you do, please keep this up.
True, uuid4 will start off trying to use the system's uuid generator before trying os.urandom or random.randrange if that fails. It would depend on OPs needs and the scale too, even a namespaced uuid may not be the right answer here.
Doesn't the "low entropy problem" necessarily exist on every modern computer, regardless of OS, unless it has a hardware RNG?
That's really, really cool, but OP should be aware that piano roll transcriptions are rarely accurate; they were usually embellished extensively by hand after recording, to add extra octaves/harmonies past what a human would be able to play. *Edit: [found a video](https://www.youtube.com/watch?v=i3FTaGwfXPM#t=124)*
Did you install 32 bit Python or 64 bit Python? That error implies you're trying to mix 32 bit Python with 64 bit Numpy, which won't work. It doesn't matter that your OS is 64 bit, it matters which flavor of Python you installed. 
I'm not sure if it's available online yet, but the ipython tutorial I went to was excellent.
Not that I know of, but all talks are being filmed and will be online later.
The biggest two things Ruby did right for people trying to learn the language is a) package management and b) having one default web platform that was highly opinionated. Package management is a nightmare in python, and there is way too many cooks trying to build or improve a package manager. I shouldn't have to install a package manager to install the good package manager, which has similar syntax, but trust us, it's better. I can't believe how long it took to include pip in the base install. On the web side, "Well, you can use Django, but that's big ... so some people use Flask, but that's basically just like Bottle, and some use web2py, and then you can do SQLAlchemy or maybe bare SQL " is a much different statement from "Rails." 
I can't wait to see what ultra-legible hacks come out of an arbitrary operator :D
I hope those `\N` sequences work on Python 2, because some of my code is about to become more self-documenting.
The best Python IDE I've used is PTVS: https://pytools.codeplex.com It's free, fast and ridiculously powerful. I haven't seen anything come even remotely close to it's feature set, however it runs only on Windows.
&gt; Python 2 is eventually going to be end-of-life'd Not as long as enough people keep using it :)
I don't think he cares. Python 2 barely needs any development work at this point.
try [simpleflake](https://github.com/SawdustSoftware/simpleflake)
Right, that mythical new project where I won't want to drop in any code I've previously written.
XO Laptop?
yup
It's not meant to make passwords more secure. I use it to make throw away accounts who require passwords to have numbers and upper case letters in it. e.g. if a site forces you to make an account for something and you don't really care about it's safety I run `alphash -i adobe.com`
Python 2.x in a new library? Seriously? Do you know that making 3.x code work on 2.x is much much easier than the other way? 
Spyral is explicitly developed for the 2.5 million XO laptops around the world that are all running 2.5. Our primary goal is to ensure that it retains compatibility with those device. That said, our code might be 3.x compliant, we haven't really investigated because it's not a priority. Feel free to test and submit some pull requests if you feel that this is a valuable addition!
Actually, the code is mostly version agnostic, so getting it to work in Python 3 is likely trivial. The thing is that most of the code is rather old, some iteration of this library has been used in classrooms for over 3 years now, and if you read the motivations for the library, you'll find that we have a hard 2.5 target for the devices that this library was originally built to target. 
https://www.pythonanywhere.com/
Sorry, I read motivation after I submitted my comment. There is no way install for example 2.7 on these laptops? I think supporting 3.x might be somewhat hard from 2.5 typically it is advised to use 2.6+ or even 2.7 which has many things backported from 3.x.
Regardless of whether it is possible to upgrade to 2.7 on the laptops, it wouldn't do for most of them. It's easy to install new Activities on an XO laptop (which is how a Spyral game would be added), but changing system level things like adding a new python installation would be tricky. Keep in mind that most of these laptops are out in conditions with little-to-zero internet. Upgrading python would also require a lot of technical expertise and troubleshooting, both of which are largely unavailable with a project like this.
maybe its not exactly an IDE but you should check out IPython Notebook: http://ipython.org/notebook.html that's where I'm crafting the "scripts" these days.
Sorry my ignorance, but what's sdets?
No that list is empty.
Nice, but why not use more descriptive variable names, rather than one or two characters?
Can you imagine ~+= ~-= ~*= ~/= ~%= ~**= operators? I'm glad that it'd make you a sad _Panda, too. 
The lists in the tuple are not immutable, the tuple however is.
They were there earlier. I watched a few of them before they were hidden. Not sure why they've been hidden, but eventually they will all reappear on the pyvideo site.
OP, this guys know his shit, ignore everybody else (including my own post) You know it's funny....I just went through a bunch of training for replay attacks about six months ago and even use this library myself constantly. It's amazing the things we forget when missing a couple of days worth of sleep.....I should stop posting stuff haha.
I've started similar projects [once](https://github.com/Widdershin/PyGM) or [twice](https://github.com/Widdershin/Scroll). Seems really cool, I would love to contribute.
I really like Anaconda. It's better than Python(x,y) and WinPython.
Well, actually I share your thinking in that manner. But the truth is, ... why would anyone learn something (e.g. Python) without the thinking to generate revenue??? :D After evaluating that reason, I decided that (s)he still gains benefit if learning Python 2.7 too. But, yeah, the case will be totally different if he just want to learn. Nothing more. In that case, sticking to Python 3 is ... a wonderful utopia ;)
Why build it on top of Pygame? This would have been a perfect addition to PySDL2, more modern more functional...
Even though I am paid to develop in Java, I spend a substantial amount of time arguing that it is, in fact, a terrible language and no one should be using it. That being said, however, I disagree with the author's examples of why Java is weak. True that in languages like Python and Ruby the task of filtering is super-clean. However, his explanation of how this would be done in Java is pretty weak; his explicit statements about how one would go about writing a set of filtering functions basically misses a lot of how the language is supposed to work. He does state that it has been a while since he developed in Java, but I would argue he never knew it terribly well. I do agree in general, however, that boilerplate code in Java is a huge problem. There are far better ways to pick on Java. This isn't exactly Python or Ruby territory, but, for example, the nearly-inexistent templating is very limiting. EDIT: Grammar and more thoughts.
It's just as hard to understand during the lifecycle in a production environment as it is in an educational environment. Take mtpoe's post for example... as it is hard for some to understand due to the lack of descriptive variables. Well done, I just don't think that this argument is valid. Poor coding methods, a mean to the end? Maybe, but I think that it undermines what you are trying to accomplish by putting it out here for everyone. FYI your code is still technically "so many lines" even when there are descriptive comments. So if you choose to employ cryptic coding for the sake of pretty code, at least follow it up with solid documentation. Even a year from now if you looked back at this you would likely need some time to figure out what you were doing. But again I don't mean to come across harsh. Well done! Edit: followed up with heavy editing due to typos. Feel free to respond if you seek clarification on my statement.
Are you asking why we didn't make something that just works with SDL directly? Or are you asking why we chose to use Pygame instead of PySDL2 or some other competing solution (since there's more than one, as your thread yesterday discussed)? Mostly, it's because we wanted to make sure that our software would run on the XO laptop, and Pygame was a convenient way to ensure that - as long as we kept using Pygame underneath, we knew it would work on the XO. It's not like PySDL2 is natively built into that platform. There's also some historical momentum here since we started in Pygame when the course was being used.
the only thing that drives me nutty is the broken pager in Linux. I need to scroll up dammit! I also wish it's incredible rewind system worked better.
I do development on Linux, windows and osx- and PyCharm works on all of them. For simple scripting, etc, I use Kate, Notepad++, and TextWrangler (and BBEdit back in the day..) A lot of old hands will scoff at my use of Kate, preferring vim, emacs, etc. I could never get the hang of them, and never understood why anyone would use them this day and age (yes, I understand they're fast as balls if you have memorized every key command). The only time I wish I knew vim/emacs is when I log in over ssh and only have a shell.
&gt; NumPy is too important of a project to not invest in Numpy will probably be replaced by blaze in a few years, but yeah.
In the meantime I've put up some notes at https://github.com/guykisel/guy_pycon_notes but I'm not sure if any of my notes are actually of interest to anyone.
Posted a version with [some extensive comments](https://gist.github.com/cdiener/10567484). Hope that helps. Cheers.
I used Sublime Text every day for development in JavaScript, CSS, PHP and some Python. Every day I learn something new in Sublime Text. I have tried dozens of IDEs and ST is my favorite by far. The plugin repo is great! They have plugins like these for just about anything.
I spoke at PyCon, and it was my first talk at a major conference. If you have some time to watch, I'd greatly appreciate feedback! What is good about my talk? What is bad? How can I improve? Thanks! http://pyvideo.org/video/2578/cache-me-if-you-can-memcached-caching-patterns
I'm pretty sure the code Intel plugin supports all of the languages that you just mentioned. It doesn't do everything I want it to do, it seems to only do completion from code in my project and the standard libs, but I'd really like it too pick up 3rd party libraries like flask and numpy. 
Awesome- it makes me very happy! I've found that when finally giving a talk one feels just like after finishing a project- when all you can see are the shortcomings and flaws with it, and what you'd do differently. Hearing that people liked it is a nice way to keep the self-criticism (a little bit) at bay :)
Done. After reading the Java version, you might want to double-check because they don't seem to do the same thing.
"For the latest version of CityDesk, the web site management software published by my company, we decided to do everything internally in UCS-2 (two byte) Unicode." He goes on to extol the virtues of the defective two-byte `wchar_t` type.
I use Python n Ruby all the time. Ruby syntax is not complex n definitely not weird
Not just that.. when it comes to web development, python is split up into django, flask, bottle, Web2py n lots of other frameworks. While in ruby most of the Web dev community focuses on rails, conventions and human convenience.
And we'd love to have contributors (I'm the original author). There's still a lot of work and a lot of opinionated decisions to made and experimented with.
I wish that platypus was the python logo.
people constantly underestimate what a valid e-mail address is. some examples from wikipedia: * `user@[IPv6:2001:db8:1ff::a0b:dbd0]` * ``!#$%&amp;'*+-/=?^_`{}|~@example.org`` * `"very.(),:;&lt;&gt;[]\".VERY.\"very@\\ \"very\".unusual"@strange.example.com` * `" "@example.org` * `üñîçøðé@üñîçøðé.com` but since people are also underestimate what’s valid python code: this would be valid python, as well: &gt;&gt;&gt; üñîçøðé = 1 &gt;&gt;&gt; üñîçøðé 1 but still; a mail library built around that new operator would be funny: &gt;&gt;&gt; example_com = Domain('example.com') &gt;&gt;&gt; my_mail = 'me' @ example_com &gt;&gt;&gt; str(my_mail) me@example.com &gt;&gt;&gt; troll_mail = 'troll@' @ example_com &gt;&gt;&gt; str(troll_mail) "troll@"@example.com &gt;&gt;&gt; my_snowmail = 'me' @ Domain('☃.net') &gt;&gt;&gt; str(my_snowmail) &gt;&gt;&gt; me@xn--n3h.net
Probably waiting for the async support in 3.4. I think a few of the core Twisted developers helped with the async stuff so that would have slowed down development as well.
So Twisted's reactor in Python 3.4 is going to be based on asyncio? If so, does that mean that non-Twisted based modules will play well with Twisted as long as they're written using asyncio?
`AltGr-Shift-,` is “×” for me, and for pretty much everyone using a linux from this decade. I wonder why windows hasn’t followed. (no idea about mac)
That was a major goal of asyncio.
Komodo Edit, from the same link, is free, and includes the feature OP is looking for. It's not a full IDE, but I prefer to use it for larger projects, while KDE's Kate suffices for quick scripts (but doesn't include the requested feature).
Awww, is tulip not in 3.4?
Spyder. It comes with rope, which does the auto-complete you seek. It's also portable, but register-able. Comes with a great site-package folder pre-loaded.
I'd be surprised if any of them knew Python!
[It is.](https://docs.python.org/3/library/asyncio.html?highlight=asyncio#module-asyncio)
I love twisted; it has powerful features, well thought out design, and can do almost everything i want. But i think it has gotten too big. No other way to say it but big and hard to steer. 
There will be no Python 2.8.
The lack of Python 3 support has prevented me from using Twisted on anything other than prototype and personal projects. I don't want to release something in the wild and then find out it has to be converted to python 3 when python 2 becomes untenable.
[He just tweeted this.](https://twitter.com/gvanrossum/status/455354868916842496 ) Looks like Python 2 will be alive until 2020 unfortunately. 
My girlfriend actually made it for us; I can't wait to pass along your comment :D Thanks!
[This is old news.](http://legacy.python.org/dev/peps/pep-0404/)
Praise the sun! Python 3 is great, everybody. Stop messing around.
2.7 EOL has been extended to 2020.
wrong. http://hg.python.org/peps/rev/76d43e52d978
And that's good?
That is a really long time.
Not necessarily. That's 6 years from now.
http://pyvideo.org/category/50/pycon-us-2014
This is great, thanks!
Oh jesus. 
I think it means if the 2.x branch is no longer actively developed then more resources can be put in to working on the 3.x branch and moving people over to that. A new 2.x release might slow the transition to 3.x.
I think this twitter user is severely misinformed. I don't know where they get the idea that anyone promised that a 2.7.10 will never exist.
You're asking /r/Python to compare Python and Java? Are you purposely trying to introduce bias?
Most package / framework *have*, it's application code that hasn't.
If you learn python 3, it's not as if writing python 2 is now an economic impossibility if for some reason you need to go back to it... I don't know where you get that thinking from.
Unfortunately there are some libraries that have not converted to the 3.x (twisted I am looking at you)
On a related note, if anyone's interested, I've made an [os-level sandbox](https://gist.github.com/pyos/9558495). (Strictly speaking, it's not actually Python, but close.) It uses rlimits to limit CPU/memory usage, seccomp to whitelist syscalls, and asyncio to wait for the output. It's not entirely safe, though: you can still access the old process' memory (does anyone have any ideas on how to restrict memory access after a fork?), and I got lazy towards the end so you can `mmap` any file into memory (should probably restrict `mmap` to anonymous mappings; the reason it's allowed at all is that `malloc` may use anonymous `mmap`s to allocate big chunks of memory.) A simple example (same as the `if __name__ == '__main__'` at the end of the code): # you can only access already imported modules # from within the sandbox import sys import asyncio def sandboxed_code(): print(sys.stdin.read()) stdin = b'Hello, Little World!' # 5 seconds, 120 MB RAM including executable parts, block syscalls sb = sandbox(5, 120000000, True, stdin, sandboxed_code) loop = asyncio.get_event_loop() time, out, err, status, signal = loop.run_until_complete(sb) print('time :', time) print('status :', status) print('signal :', signal) sys.stdout.buffer.write(out) sys.stderr.buffer.write(err) Oh, and it only works on Linux (and requires cffi and libseccomp.)
If I was Guido, I'm not quite sure I'd do that, but I certainly wouldn't just backport Python 3 features to Python 2 and let people carry on willy-nilly with it. I'd do something more like this: * Every 2.8 file must have all four `from __future__ import foo` statements that bring in 3.0 features (i.e. `division`, `absolute_import`, `print_function`, and `unicode_literals`). It is a syntax error if one is missing. * Every 3.0.x feature which breaks existing 2.7 syntax or semantics gets a new `from __future__ import foo` in 2.8. No other features are introduced or backported. In particular, new modules like `concurrent.futures` and `asyncio` are not backported. Neither is anything listed as [new syntax](https://docs.python.org/3.0/whatsnew/3.0.html#new-syntax). Closely-related features (such as various library functions all returning iterators instead of lists) may be grouped together to minimize the number of new future statements. * In 2.9, all the `from __future__ import foo` statements introduced in 2.8 become mandatory. The language otherwise behaves identically to Python 3.0.x. * To port from 2.9 to 3.0, you just strip off the `from __future__ import foo` statements. Nothing changes, because 2.9 basically is 3.0. Once you're ported to 3.0, getting to 3.4 is left as an exercise for the reader.
Could it be any slower? Didn't someone post up stats showing that the adoption rate for 3 is about 5%? We've been told the 2.x branch is not being actively developed apart from bug + security fixes for, what, 5 years now? I would have thought there's more that can be done to bridge the gap between the two versions, and that 2.8 could have been part of that.
Why can't we just convert them our selfs, not taking in account the long time it would take, but isn't this possible? 
Okay, agreed :)
A lot of Twisted works in Python 3.x, and recent Twisted installs in Python 3.x. I think the main issue is that Twisted is big, and Twisted developers aim for a very high-quality port. From what I've seen, they have contributing rules that are quite strict (e.g. if some code is not covered by tests then to port it to Python 3.x it must be covered first, even if changes are obvious); this makes it harder to move forward, but helps with the quality level.
Last planned update is May 2015. The rest are as needed until EOL in 2020.
Memory hell, more like karma farming.
Agreed. I think Python used to have one of the best systems for upgrades with the `from __future__` system, and the breaking changes for 3.0 ignored all that. Another intermediate version or two that allowed a more incremental upgrade path would help a lot.
go right ahead and convert it.
You really need to teach them 3 now... it's way better than 2.7. Stop instructing people to learn something that stopped getting better 5 years ago and never will.
Does it make it the Windows XP of programming languages?
Which is one year less than the heads up we had to move from win XP. Which everyone did in plenty of time of course. 
Not exactly. The only differences between 2.8 and 2.9 are: * 2.9 requires a number of future imports that 2.8 leaves optional. These can be turned on one at a time in 2.8. * 2.9 has a number of features which do not interfere with older syntax or semantics (new modules, new syntax, etc.), and hence do not create compatibility problems.
We did an IPython user survey last year, and over 20% of respondents said they use it on Python 3. They were allowed to tick more than one box for that question.
I hear twisted is great, but is it possible in your case to just use the new asyncio?
Switch to Python 3.x (within the next couple years) because there will not be anything on the 2.x branch after the current 2.7 
It was time to show this picture. Python3 makes it possible to move further towards future. Continuing with 2.x would be devastating for Python, like the destiny of Perl. 
Yes. Forces people (myself included) and projects to finally switch to 3.x If you don't force people at some point, you get IPv6
What more could they really do? Most of the visible 3.x features have already been ported to 2.7. 2to3 takes care of bulk syntax changes (like library renames and print being a function). I started working on porting some networking code from 2.x to 3.x the other day and basically found that after running 2to3, all that was left was to fix Unicode/string/bytes issues. If a theoretical 2.8 were any more 3.x like, by that point you would just be porting to 3.x anyway.
Can't say I'm surprised. Python 3 doesn't/didn't bring much new stuff to warrant mass switching to python 3. If it were backwards compatible it could have been just python 2.7.something as far as new and useful features goes. And the fact is, it's still used a lot. What was the alternative? Leave it to vendors to support it?
Guido has long insisted that 2.7 would be the last version of Python on the 2.x branch- that all future development would be in 3.x. He was just confirming this at PyCon- there are presumably still some people who were holding out hope that there would be another 'transition' release on the 2.x line.
let me type that down: 2020 is six years away.
This thread seems to have completely missed the point. Up until recently the announced "End Of Life" date for Python 2.7 was 2015. That date just got pushed back to 2020. There was never going to be a 2.8, this picture is not news. The news is that that 2.7's lifetime just got extended another 5 years.
The original EOL for Python 2.7 was 2015. So more like 10 years.
You can scroll up in `less`. Not in `more`, though. Less is a better version of more.
See the [language summit notes](http://thread.gmane.org/gmane.comp.python.devel/147048) for some context, namely: &gt; IIRC Glyph and Alex Gaynor are going to compile a list of pain points for people. (I can't honestly say that I convinced Glyph and Alex and a few others not to pine for 2.8, but I also honestly don't believe it will have the effect that they expect. Nor do I believe any new feature we add to 3.5 can serve as a big enough carrot.) Glyph doesn't want Python 2.8 because he's allergic to the number "3" like Gaben, he wants Python 2.x to continue because porting Twisted while maintaining compatibility has been hard and tedious work, and there's already *plenty* of work to do for Twisted without the added complication. That said, much of that work has been done — [there are currently over 3000 tests passing in Python 3](http://buildbot.twistedmatrix.com/builders/python-3.3-tests/builds/2069/steps/shell/logs/stdio) — largely by contributors who were contracted specifically for that purpose. Twisted will take patches that follow that [Python 3 Plan](http://twistedmatrix.com/trac/wiki/Plan/Python3) you linked. As /u/kmike84 noted, quality control is pretty strict, to ensure not only python 3 patches keep compatibility, but that they don't introduce more technical debt than they fix. It's going to take a serious amount of engineer-hours to accomplish. If it's important for you or your organization to have Python 3 compatibility, please invest in it, either with your own engineering time, hiring someone to work on it, or contributing to the [Twisted Software Foundation](https://twistedmatrix.com/trac/wiki/TwistedSoftwareFoundation).^1 If you're in Montreal this week, Twisted will be at the [PyCon Sprints](https://us.pycon.org/2014/community/sprints/), which is the place to be if you have any questions at all about how to contribute to Twisted development. You do not need to be registered for PyCon to attend the sprints! Footnote 1: I can't say that donations to the tax-deductible Twisted Software Foundation, sponsored by the Software Freedom Conservancy, will all go to Python 3 work — charitable donations are different than work-for-hire. In the past, TSF funds have been used to fund maintainer's work to significantly shorten the wait time on the review queue, making it quicker and easier for all code contributions (including but not limited to Python 3) to get accepted.
And suck-ass Red Hat E6 that they make me use at work still has 2.6. I thought it was so cool that I finally got a job using Linux... :-(
I am not as familiar with the Python 3.4 asyncio as I could be, but I have not heard anyone say "yes, I'm planning on doing lots of work for Twisted on Python 3, I've just been waiting until Python 3.4 comes out." This sounds like wishful thinking. I would be *very happy* to be proven wrong about that. 
I can only see this as a huge mistake.
And then he moves the EOL of Python 2 to 2020? Yeesh.
I've found my new wallpaper!
That's the key fact here - libraries that don't port are going to get left behind and become irrelevant. PIL is a good example. 
Python can't be like Perl because Python uses LL(1) parsing. Perl can just keep going forever... (/joke)
I can see Python 2 forked/independently maintained. Definitely that's what would happen if they decided to declare EOL right now. We'll see in 2020. Alternative runtimes like Pypy, or ipython, or something new could perfectly well keep on maintaining the 2.x branch alive and current. That's the thing about FOSS, if there's enough demand you cannot deny people the right to keep it alive on their own. Personally, Python 3 has some characteristics that make it extremely cumbersome to me (esp. related to character encodings). If I had to switch from Python 2 for these tasks I'd stop using Python entirely.
The alternative discussion was around making a 2.8 
In 4 years.
Imho, Julia will be the end of Python in the scientific space. 
probably, but I dont want to rewrite around 3k lines. I need to tinker more with new asyncio too see if it is worth rewriting 
it is, but it is not possible for the exact reason you provided
If there was any mistake, IMHO, it was Python 3 itself. I've said it before and I'll say again: I've a strange feeling that a company will fork Python 2.7 and people will move there instead of Python 3. My speculation is that company will be RedHat.
What the difference between PIL and OpenCV?
I will consider your advice. 
if you treat raw bytes like text you will get burned. We don't live in the world of single byte ascii english anymore. raw data is not text. python3 lets you easily make this distinction, python2 does not. 
Vim is fast as balls even if you haven't remembered all the commands. Just after a few weeks I got fairly good at it. Check out vimtutor, it's quite long, but just knowing the basics is more efficient than an editor like Kate (which I have used before).
Pillow should replace PIL for most people.
Its not that hard to support 2.7 and 3 in the same code base, easier than forking and maintaining 2.7.
Thanks, I'll give it a go.
Isn't twisted quickly on the way now that asyncio is here?
In fact I use Asian languages profusely and that's where the problems arise. In regards to text, in Python 2 you can do everything you can do in Python 3 and more. In Python 3 there is no support for non Unicode data text. This bites me regularly when I need to interface with different encodings that are not under my control. This is not a problem for many people but for me it's massive. The workarounds needed for me to work with low-level bytewise URIs or packets are very cumbersome. It's very evident that the people in charge of that part are not fully aware of the problems it causes and when they designed it, they simply ignored them. Now the parching of that leaves a mess that IMO is much worse than the (far from perfect) Python 2 model.
until 2020 vs. 2015
OK, thank you. I think that these two links would help any confused people: Guido is a father of Python: https://www.python.org/~guido/ It seems as if Python 3 is finally going to be worth adopting, as Linux distros are making it the default: http://fedoraproject.org/wiki/Changes/Python_3_as_Default I know for me, that I have been sticking to 2.X, or at least compatible with, as that's what is on various machines I need to use code on. If RHEL machines ship with Python 3, then I will gladly be taking the plunge.
Hehe, 404: 2.8 not found.
you are not alone. I moved to C# and it was a better fit for me all around!
How does bytes() objects not meet your needs?
Hmmm... Was that there some recent discussion about that? I pretty sure that 2.8 was dismissed as alternative quite some time ago. I think the alternative, if this didn't happen, would have been vendor maintained/forked python 2 versions - and possibly (unofficial) python 2.8. Which would have been worse (IMO) for moving away from 2.7 to 3.x
Be wary of library support and then Praise the sun!!
I don't think I can add much more to this post by Armin Ronacher http://lucumr.pocoo.org/2014/1/5/unicode-in-2-and-3/ I've found similar issues. And so far, it's been a moving target as the patch stuff here and there. People in this subreddit get really defensive when someone exposes a problem about Python 3, so I'll leave it at this not to start a flamewar, which is not my intention. The top echelons are dead set on not bringing back non-Unicode strings for Python 3. So be it. That basically makes it a poor fit for my current usage of Python, which is I will remain using Python 2, and when I can't, I guess I'll switch to something else.
If they just had 2to3 do that in steps, you wouldn't need to release 2 version of python. Adding imports is not what is delaying upgrading. Breaking packages like with the change in the way opening files works, changing how dictionaries sort, working with binary files are bigger issues. Float vs int, print, and imports are trivial issues.
2020 is sooner in the future as the release of Crysis was in the past(2007 release, according to Wikipedia)
Snake but hole
I'm OP. 140 chars, so I couldn't fit it all in. Sorry about that. 2.7.9 will be the last *planned* release -- any other releases will be only "as needed", but end-of-life isn't until 2020. The key thing is, GvR says no to 2.8 (which has been discussed a bit in the Python community via blog posts) so people shouldn't *expect* core development efforts will continue to focus on 2.x beyond 2015, at least not beyond basic maintenance.
Everything is clearer in hindsight. 
Of course, RHEL7 will ship with 2.7 as the system python, and their support will continue for 10 more years.
https://docs.python.org/3/howto/pyporting.html
whoever it is, (s)he should have fun being irrelevant.
That's the whole point of my idea. You turn new features on one at a time, on a per-module basis, then convert to 3 once everything is on. It's not possible to do this automatically.
How I would put it is: "Immutable is a fact, hashable is a convention". If an object is immutable that is because it is flat-out impossible to actually change the object itself -- nothing you do is going to get a tuple or string to change. You can only create a new string or tuple and then stop using the old one. Its immutable because that is a feature of the language that some objects can not be changed. An object is hashable if it defines the \_\_hash\_\_ protocol, which **by convention** should always be the same during the objects lifetime. You can easily break that convention accidentally or on purpose, but if you do you'll run into strange behavior: &gt;&gt;&gt; class A(object): ... def __init__(self, value): ... self.value = value ... def __hash__(self): ... return hash(self.value) ... &gt;&gt;&gt; a = A("hello") &gt;&gt;&gt; hash(a) -1267296259 &gt;&gt;&gt; a.value = "goodbye" &gt;&gt;&gt; hash(a) -1813626378 &gt;&gt;&gt; x = {a: "Whatsup"} &gt;&gt;&gt; x {&lt;__main__.A object at 0x027D4270&gt;: 'Whatsup'} &gt;&gt;&gt; x[a] 'Whatsup' &gt;&gt;&gt; a.value = "hello" &gt;&gt;&gt; x {&lt;__main__.A object at 0x027D4270&gt;: 'Whatsup'} &gt;&gt;&gt; x[a] Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; KeyError: &lt;__main__.A object at 0x027D4270&gt; &gt;&gt;&gt; But its quite possible to create a mutable object that is also hashable according to the convention. This is usually done by selecting some subset of its state that you decide not to change, such as a unique ID or URL or something: &gt;&gt;&gt; class B(object): ... def __init__(self, name, value): ... self.__name = name ... self.value = value ... def _get_name(self): ... return self.__name ... name = property(_get_name) ... def __hash__(self): ... return hash(self.name) ... &gt;&gt;&gt; b = B("B1", "test1") &gt;&gt;&gt; hash(b) 406699637 &gt;&gt;&gt; b.value = "test2" &gt;&gt;&gt; hash(b) 406699637 &gt;&gt;&gt; b.name = "Argh!" Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; AttributeError: can't set attribute &gt;&gt;&gt; x = {b: "whatsup"} &gt;&gt;&gt; x[b] 'whatsup' 
There's another upcoming runtime, [Pyston](https://tech.dropbox.com/2014/04/introducing-pyston-an-upcoming-jit-based-python-implementation/) (JIT), announced by Dropbox, targeting 2.7.
What they are doing sounds an awful lot like Gitlab.. but an interesting read nonetheless.
Unless Rackspace has changed, they only allowed remote developers who are in the US and not overseas. The survey perhaps should have asked about US based versus overseas.
Too bad that was literally all I got out his talk. That man needs a speech writer for non technical talks
&gt; The key thing is, GvR says no to 2.8 (which has been discussed a bit in the Python community via blog posts) so people shouldn't expect core development efforts will continue to focus on 2.x beyond 2015, at least not beyond basic maintenance. But that's been core's position for the last few years... it's kind of sad they need to keep on repeating it, as if the python community can only learn it through rote repitition.
Shouldn't that be C++98?
Can't you use surrogate escape?
No, not for the people who have huge codebases in Python 2. 
Those are really great; proof that great talks don't need to be technical.
web2py: db.define_table('professor',Field('name'),Field('retired','boolean')) db.define_table('course',Field('start_year','integer'),Field('name'),Field('teacher','reference professor')) db.define_table('student',Field('name')) db.define_table('enrollment',Field('course','reference course'),Field('student','reference_student')) db.professor.insert(name='Max',retired=False) csc100 = db.course.insert(name='CSC100',start_year=2012) db.enrollment.insert(course=csc100, student=db.student.insert(name='John White')) db.enrollment.insert(course=csc100, student=db.student.insert(name='John Red')) db.enrollment.insert(course=csc100, student=db.student.insert(name='John Blue')) #Get list of students who stopped enrolling in any course since 2012 enrollments = db.enrollment.course==db.course.id subquery = db(enrollments)(db.course.start_year&gt;=2012)._select(db.enrollment.student) rows = db(~db.student.id.belongs(subquery)).select(db.student.ALL) # generates this SQL: SELECT student.id, student.name FROM student WHERE (NOT (student.id IN (SELECT enrollment.student FROM course, enrollment WHERE ((enrollment.course = course.id) AND (course.start_year &gt;= 2012))))); #Get list of students who are attending more than once course taught by the same Professor rows = db(db.course.start_year==2014)(enrollments).select(db.course.teacher,db.enrollment.student,db.course.id,groupby=(db.course.teacher,db.enrollment.student),having=(db.course.id.count()&gt;1)) # generates this SQL: SELECT course.teacher, enrollment.student, course.id FROM course, enrollment WHERE ((course.start_year = 2014) AND (enrollment.course = course.id)) GROUP BY course.teacher, enrollment.student HAVING (COUNT(course.id) &gt; 1); #Get list of Professors who stopped teaching any course since 2013 but is not retired subquery = db(db.course.start_year&gt;=2013)._select(db.course.teacher) rows = db(db.professor.retired==False)(~db.professor.id.belongs(subquery)).select(db.professor.ALL) # generates this SQL: SELECT professor.id, professor.name, professor.retired FROM professor WHERE ((professor.retired = 'F') AND (NOT (professor.id IN (SELECT course.teacher FROM course WHERE (course.start_year &gt;= 2013))))); Notice all filtering is done at the database level and not at the Python level. Python simply generates the query in the dialect of the provided backend database.
This. Also I don't think Py3 preachers here understand it.
C++98 isn't going anywhere.
Makes sense! thanks for the input!
Hey, this looks really cool, you might want to xpost to /r/kivy, they'd like some content, also, remember the kivy game challenge is coming up!
python 2.8 implies backward compatibility with an existing codebase. python 3.x is known to break it. I know I'm not the only person with a company that cannot afford the downtime caused by moving from a known-working code base to an unknown non-working code base. And the benefits of a 3.x codebase definitely do not outweigh the downtime getting there. It's a terrible business strategy to upgrade.
Surrogate escapes are dangerous because they propagate out of the surrogate escape aware context. I would consider them quite a dangerous workaround to the new unicode type. When you have a surrogate escaped string and you pass it to another function, at one point it will blow up unless that API is aware of surrgate escapes.
I feel like a lot of people who complain about Unicode in Python simply don't understand it. For example Java, started with Unicode from the beginning and no one seem to complain. Probably because they never needed to compare it to non Unicode version. I can understand for example lack of formatting on bytes, but I believe support for that was already added.
I really don't like how there's no pastebin code review site, or at least that I know of, but have some random comments. Personal opinions ahoy. 1. If your second argument to `setattr` is a constant, you don't need to be using `setattr`. 2. One typically relies on the implicity truthyness of values. e.g. `if len(args):` should be `if args:` 3. Old-style became old-style a while ago now. I'd recommend picking up a string habit of always adding the (object) into your class inheritance hierarchy. 4. I'd move the modification of sleekxmpp's logging level to global scope. If you're going to modify it, it's clearer to do it at import time than as a side-effect of instantiating an object. 5. Instance data in your class that you mean to be private should start with a `_`. e.g. summoner_ids_to_name or logger 6. Instance data that you want to expose, but users shouldn't modify can be protected with @property. e.g. username or region? 7. If your second argument to getattr is a constant, you don't need to be using getattr. I'd also recommend just try/excepting the AttributeError over using getattr. 8. You should probably set the daemon attribute on your Thread. 9. Your use of getattr/setattr for event registration could just use a dict. (Overall theme here of you should avoid using getattr/setattr, as it generally means you're doing something wrong.) 10. Avoid starting method names with two underscores, as you can invoke python's name mangling, which results in a lot of confusion if you aren't expecting it. 11. `set_status` seems like you could drop a lot of code by just doing `status.update(**kwargs)` 12. (line 344) `in` checks keys, so you can drop the call to `keys()`. You can also just return `data.get(summoner_id)` since you're returning None in the false case anyway. 
I'd like you to explicitly state why you think this is relevant. I find it an unrelated and vague result that is only tangentially similar in target.
If you listen to the more vocal pro-3.x faction, this is hand-waved away. The core developers as I experience them, in discussions on python-dev which I have had a stake in, have no patience for 2.x and have moved on. Who is going to do this "more", even if it can be identified?
This has been discussed ad infinitum elsewhere. The answer is that 2.x could be slowly migrated towards 3.x. In the past there have been incompatible changes introduced more slowly, and through "from __future__". But what we have instead is an apple and an orange, and people who need apples and people who think the people who need apples should do some magic dance and suddenly want oranges. 
This is what gives me night terrors. 
You may think that people haven't tried to upgrade, but that's a convenient assumption and not based on fact. Do you think people want to be on old versions of Python? Sure there's a vocal group of anti-3.x-ers, but I'd say they're the minority. Instead the pro-3.x faction keep banging their drum and upvoting vague appeals to how people should just use 3.x, and downvoting any inconvenient reasons why people aren't using 3.x. All the real world reasons why people do not upgrade are ignored. And we're still at 5% adoption or thereabouts. 
It costs people nothing to drop in and comment about how someone else should be doing something they likely can't do, just because the person who dropped by wants. They'll go on about how easy it is to just use Python 3.x and how there's so many ways to upgrade, and that people who haven't done it simply haven't tried.
Fortunately Twisted is open source. Feel free to submit a patch to the developers for Python 3 support.
RHEL 6 officially supports 2.7 and 3 through through the Software Collections repo and scl tool.
RHEL 6 officially supports Python 3 through the Software Collections repo.
Spam.
I thought I had read something on the mailing lists, but I'm unable to find it again, so maybe it was just wishful thinking.
But, it comes with Python 2.6 as far as I know. At work, I have to work on a lot of RHEL(CentOs) 6 machines that I'm not admin on, and have to live in whatever ecosystem is there. The admin isn't keen on installing *anything* more than what is absolutely essential.
&gt; Description of Data &gt; &gt; -1 - Company expressed no interest in hiring any remote developers &gt; 0 - Company expressed interest with limitations &gt; 1 - Company expressed interest in remote developers There are better ways to express the results of the poll than -1, 0, and 1. &gt; Summary &gt; &gt; The average company at PyCon is slightly more disposed towards only hiring on-site developers (with an average response of -0.022). Should we have any confidence in -0.022 as a result? I just ran sum(random.randint(0,2) - 1 for _ in range(48)) / 48.0 &gt; 0.0625 Is my pseudo-random number generator slightly disposed to favor 1? Why are we averaging these answers anyway? &gt; I hope to conduct this poll again next year in order to observe if there is a trend towards remote work. Barring a massive change, I think the only interesting part would be asking about the changes on a company by company basis.
Thank you for making all my progress in Python seem insignificant to the point of being negligible. That is one badass program you wrote. Thank you also for raising the bar of what I know computer programming can accomplish. I may be a complete neophyte but next-level shit like your post stokes my interest in programming more than I can say.
too late now, i was at the conference before
Well, I am inclined to agree that most of the people who could do this work are uninterested in doing the work. Such has always been the case with Python (see also: Windows installs being mostly useless out of the box for years, multimedia support left stagnant). The main thing I was pointing out is that we already knew 2.7 was the end of the line and yet that hasn't encouraged many to move, so this latest announcement wasn't going to change anything.
&gt; You turn new features on one at a time Forcing you to add an import is not a feature and is easily accomplished with a -3 option. Again, imports are not the issue. Unicode in Python 2.7 with all those imports is STILL different than unicode in 3.x. Random bugs from a single Python 2.7, 3.x codebase go away when you just write Python 3.x code.
PIL is relatively unmaintained, compared to its fork, Pillow, which supports Python 3. You're essentially using the old version.
Don't understand how old the Python 2 codebase is, how much technical debt it has, how much harder it is to continually add new stuff to, how many mistakes it has to keep due to backwards compatibility, the ways in which it got unicode string handling wrong, etc, etc?
If it was done, and it provided benefits, it wouldn't be irrelevant. For example, backports of new libraries and maybe 3.x features introduced as `from __future__` options would be attractive to anyone who is eyeing up a migration to 3 in the medium term but not right now (perhaps due to library dependencies). If it's true that only [2% of library downloads are for Python 3](http://alexgaynor.net/2013/dec/30/about-python-3/), then arguably it is that version that is irrelevant, unfortunately.
You kidding here C++98 is being abandoned as fast as is possible. There see huge advantages for adopters of C++11/14. 
The core devs are actually fine with this. If it doesn't make financial sense to port, then don't. Everyone knows there are still large applications in Fortran and Cobol, this is no different. But they were also absolutely sick of the technical debt and bad decisions in the python 2 codebase, which is pretty much the entire reason 3 came into existence in the first place.
This is Amazon's problem. RedHat has supported using Python 3 for ages.
Now available at [packaging.python.org](http://packaging.python.org)
Huh, I don't want to be a 'lecagy Python mantainer' in 2020. 
I am an [oDesk freelancer](http://odesk.com) and the amount of Python job there was way too much for us to handle. And I already talking about 60hours/week work!
C++11 is backwards compatible and includes most, if not all, of the specifications of C++98. As such, C++98 will continue to be available, unlike Python 2 OR Windows XP.
what footnotes ?
From [Software Collections](https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Developer_Guide/chap-RHSCL.html#sect-RHSCL-About): &gt; With the notable exception of Node.js, all Red Hat Software Collections components **are fully supported** under Red Hat Enterprise Linux Subscription Level Agreements, are functionally complete, **and are intended for production use**. What's [noteably listed](https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Developer_Guide/sect-RHSCL-Overview.html#tabl-RHSCL-Components) in Software Collections? &gt; Python 3.3 | python33 | A recent stable release of Python 3 with a number of additional utilities and a database connector for PostgreSQL. This Software Collection gives developers on Red Hat Enterprise Linux 6 access to Python 3 and allows them to test the compatibility of their applications with this version.
Everything here, plus be aware that you need to use time independent code to verify anything you hash.
You guys are not reading this between the lines. Certain companies (e.g. RedHat) have support arrangements for the software they package (Python 2.7). Python devs will actively stop working on 2.7, but am open to patches that others backport.
I bet if you asked a library developer or hosting company why they don't support Python 3, they'd give you something along the lines of "there's not enough demand for Python 3 to justify the difficulty of supporting it". It's a vicious cycle. People like you don't use Python 3 because various libraries and hosts don't support it, and those libraries and hosts don't support it because people don't use Python 3. Since Guido has elected to extend the deadline, this will create even more excuses for programmers and cloud providers alike not to make the transition anytime soon. I don't go around telling people to throw out their code. I'm not going to pretend that this is a reasonable thing to ask, or that every project's dependencies can be satisfied with the current state of the Python 3 environment. But I do think the proper way to move forward is to use Python 3 _when possible_ and nudge distribution companies and cloud providers that Python 3 support is something we want. That said, if Python 2.7 is really what you want, just use it, there's no need to rant to reddit about it.
PyCon APAC 2013 seems awesome in Japan: http://apac-2013.pycon.jp/ PyCon Taiwan 2013 was fantastic I can say: https://tw.pycon.org/2013/en/
and python2 and xp are not forwards compatible because they got something fundamental fundamentally wrong.
Julia's MATLAB-like, everything-in-one-namespace approach is a huge regression in my mind. I'd hate to be forced to leave python for it.
You don't have to throw anything out. The compatibility sweet spot that the community has arrived on is supporting 2.6, 2.7, and 3.3+ from a single code base. That is the route that a majority of packages that are green on the WOS have taken. If you have users on 2.4 or 2.5 that you don't want to strand, then you really can't realistically take the single-codebase approach, and your options are a lot more dire. Many projects have taken the stance that they will simply wait until they can drop those users. That's why there are still red packages on the WOS after all of these years. It's not laziness. Red Hat offers long support windows because that's what their customers want. RHEL4 was released in February of 2005 and shipped with Python 2.3. It is still supported with critical and security fixes for customers with an extended lifecycle subscription. This support window lasts until February 2015. RHEL5 shipped with Python 2.4 and will be supported until 2020, and RHEL6 shipped with Python 2.6 and will be supported until 2023. There will be people using Python 2.6 in 2023. That is just how the enterprise world works -- lots of large ships that take a lot of time to turn. There's nothing that you or I or the Python developers or the Python ecosystem can do to change that. If you have some externality that forces you to use 2.x, then use 2.x. I use 3.x because I can, and because I prefer it. Everybody's situation is different. 
Most of science and engineering is only recently transitioning from Matlab and other old language platforms to Python. They haven't even heard of Julia, and it's going to be even longer before all the libraries they use exist in that ecosystem. I could see Julia becoming quite popular, but it's going to take time.
Coursera: -1. How ironic...
So, I have been building out one flavor of SOA or another since mid-2000; before that it was mostly old-style PHP. In 2000, I used a common database to integrate the services (ouch) and I also used an old precursor to CORBA called ILU (double ouch.) In ~2004, I did a review of what people were doing because we had to replace ILU. Mostly people were doing Java and J2EE, but there were people using SOAP, people using XML-RPC, and some people using CORBA. I did not encounter anyone talking about REST or JSON for SOA work. To my shame, I selected CORBA, mostly because it fit quite well with our existing ILU solution. In ~2007, I did another review, and it seemed like JSON and RESTful APIs were really starting to increase in currency. Projects like Django's Tastypie or flask-RESTful still didn't exist, but there were plenty of blog posts full of opinions about how you should do it. Some documents on best practices existed. This was for a different employer, and we did RESTful things there (though I would hesitate to say they conformed to best practices.) By 2010, Javascript MVC and one-page apps were really encouraging RESTful APIs and there was plenty of support in the Python community. I still find many vendors offering SOAP or XML-based APIs, but I encounter almost as many who provide a RESTful API. I also see a lot of people using Thrift, and I am surprised by how similar it is to CORBA. So, maybe your experience was different? I would love to hear about RESTful APIs circa 2000; I didn't encounter any, or even see REST proposed as an API style until maybe 2004 or 2005. It was another four or five years before I saw anyone put those early discussions into actual practice. I guess WebDAV counts? I suppose technically speaking the World Wide Web in general is technically a RESTful service? But I think both of those are more complete applications than service transports.
&gt; Forcing you to add an import is not a feature and is easily accomplished with a -3 option. The `-3` option prints warnings. If you're forced to add imports, one would hope you'd first check to make sure those imports are reasonable to use. &gt;Unicode in Python 2.7 with all those imports is STILL different than unicode in 3.x. What, the narrow-vs-wide build problem? That could be its own import. You seem to assume everything must either be 2.7 with minor syntax changes or 3.x with minor syntax changes, and that's a false dichotomy. &gt;Random bugs from a single Python 2.7, 3.x codebase go away when you just write Python 3.x code. Obviously if you *can* "just write 3.x code," you should. The whole point is that there's a lot of 2.7 code out there and converting it is not a straightforward operation. `2to3` is just a program. It can't account for all the semantic differences between 2 and 3 and magically fix them all up.
+1 That is a good punchline my friend. I am with you in this regard.
&gt; What, the narrow-vs-wide build problem? I'm not familiar with that. &gt; You seem to assume everything must either be 2.7 with minor syntax changes or 3.x with minor syntax changes, and that's a false dichotomy. I run an open source project and most of the users us 2.7. I try and support 3.x as well, but I have to have a common code base. If I were to drop one, it'd be 3.x. I have a script that does really simple things to convert the code (remove __future imports, xrange to range, etc.) to a Python 2.7 version and a Python 3.2 version (yes I know 3.4 is out, but I haven't played with newer versions) because they are more stable, which in my mind is stupid. Python 2.7 was written to help porting. If it really did change the way unicode worked in Python to be what it is in Python 3, things would work better. It half implements it. I should never have discovered how the sorting method changed in Python 3 to not handle string/int keys. There's not a future import to deal with that. I also think there should be: from __future__ import dict, range, zip, file because they behave differently. I don't expect a 2to3 tool to be perfect, but I don't think it's unreasonable to have a -3 option that checks everything. 
Hey, what are you actually offering there? I'm starting up and I'm even jumping on offers that pretty much pay nothing and still don't get the deal... I've mostly jumped on web/data scrapes and didn't get a successful gig yet. Either my profile is a complete mess or I'm just really bad or there's bubkus.
&gt;I'm not familiar with that. In "narrow" builds of 2.x, a surrogate pair takes up two `unicode` characters even though it's supposed to be a single Unicode code point. In 3.x, it always takes up one character (and as of 3.4, you can't manually build surrogate pairs out of illegal Unicode characters). I assumed this was what you meant by incompatibilities between 2.x's `unicode` and 3.x's `str`. &gt; Python 2.7 was written to help porting. If it really did change the way unicode worked in Python to be what it is in Python 3, things would work better. It half implements it. I should never have discovered how the sorting method changed in Python 3 to not handle string/int keys. There's not a future import to deal with that. Did you actually read my idea? I'm not saying we should make do with just the four future imports 2.7 currently has. The whole point is adding more so that you can gradually import your way to 3.x.
I wonder what they would say if the question also mentioned the fact that remote developers would be cheaper. Like, we have a client in Washington State. We develop a lot of their stuff remotely. We charge way less per hour of work because we don't have to fly there, we don't have to hire people there, and we don't even need an office where *we* are.
I read your ideas. I don't understand how forcing imports help when Python 2.7 code with all the future imports is still not Python 3.x code without imports (assuming pure Python). The codes will still behave differently. Also, you already have the -3 option for all that stuff.
&gt; Most of science and engineering is only recently transitioning from Matlab and other old language platforms to Python. I wish :-(
The real question is: who is going to fork python 3.x and make it backward compatible?
*Currently* targeting 2.7. Python 3 support is a stated goal: https://github.com/dropbox/pyston#current-state
Read it again.
Count your self luck, we are using RHEL5 
Another thing Julia has going for it is that some of the R community is moving towards it. Hadley Wikham, a major figure in the R world, is taking an interest in Julia.
Julia be the end of python in the same way that us scientific computing users have moved to python 3..... it didn't happen (yet). Never underestimate the importance of working code and incremental improvements. Scientific software does not exist to admire its own architectural beauty, it is to answer questions of others. Trusting those answers makes us a lot more conservative than your average python web programmer.
Call os.listdir on your root directory, and only descend into directories that you haven't seen yet. Recurse.
What, a whole API just to search for Game of Thrones?
I can't see how is it similar to Perl. Perl6 wasn't even implemented properly for the ten years that they've been talking about it, while they've [Osborned](http://en.wikipedia.org/wiki/Osborne_Effect) Perl5 (a.k.a. Perl). 
Maybe.
I think a lot of people would regard the existing branch- which features a number of 'from future' imports as doing exactly that. If you've been using 'from future' imports and enabling the -3 warnings, there shouldn't be much transition left to do. Any release that breaks backward compatibility is eventually going to wind up as an apples to oranges transition- apples run on the old system, oranges runs on the new one. At this point your apples should be looking pretty orange-like if you've been taking advantage of the tools, but there will always be people who would like one slightly apple-ier orange before making the jump. There's no one right answer in terms of how you make a backwards incompatible transition without completely splitting the user base, but overall Guido and the core team have tended to err on the side of being conservative. There is no 'flag day' when 2.x code stops working, but successive versions of 2.x have given you the option of coming closer to 3.x. At this point- with most 3.x features available in 2.x, transition warnings available, and tools to manage the transition, I don't see a lot of justification for cutting a 2.8 branch. Something like 'make the -3 warnings mandatory' is pedantic and un-Pythonic- everyone knows what's happening already and no one who is a serious Python developer has an excuse for being surprised by incompatibility between versions.
&gt; No, it'll get forked. Possibly by RedHat. In another post of this thread: https://fedoraproject.org/wiki/Changes/Python_3_as_Default It does not seem likelly.
 Extend Python 2.7 life till 2020
I'm putting together a quick reading list for a friend to help fill-out their Python knowledge. This seems a good reference but too recent for reviews. Anybody got it? Thoughts?
This isn't how open source works. While there are people working on it; it will continue. If there aren't, it won't.
They've had over 7 years and have done nothing, just move on to a better framework that isn't as poorly developed and poorly maintained. Like plone before it, twisted has had its day and served its purpose, its now time for retirement. 
I asked the question recently: http://www.reddit.com/r/Python/comments/1yff3j/twisted_readiness_for_python_3/ Sadly, looking to the comments here, no more good news for near released of Twisted for Python 3. I'm really looking for alternatives at this point...
2.7.9999999999
Don't get the point of re-listing the videos, as there is a list [on pyvideo already](http://pyvideo.org/category/50/pycon-us-2014), except for getting a few visitors who will leave annoyed.
I don't think he said it was random, just that you can't just assign arbitrary numbers to 3 different positions and then average them expecting to get any useful information out.
I blame consoles.
This seems pretty close to ideal. Personally I prefer to use asyncio.async() instead of asyncio.Task() if I'm not dealing with the result of the coroutine/never want to cancel it, but that's (nearly) a purely stylistic choice. One shortcut that you may not know of is chaining `yield from`'s together.. For instance, you have: a = yield from waiting(1) b = yield from waiting(2) ... return a+b I'm not saying that you *should* change it, but you *could* change it to: result = (yield from waiting(1)) + (yield from waiting(2)) I only mention this as a possibility because I've found that a lot of people have no idea you can do that. Edit: Thought I should amend this with the explanation of the "(nearly)" in the first section. asyncio.Task only accepts a coroutine as the \_\_init__ argument. asyncio.async() accepts a future or a coroutine. If it's a future/task, it simply returns it; if it's a coroutine, it wraps it in a Task and returns it. It's more versatile, but I mostly just use it as a demarcation of whether it's a return value I intended to deal with.
But Whoopska uses a random number generator and I don't see the connection/ argument. There was no overt randomness in the survey. Likewise, the use of -1,0,1 is not exactly arbitrary and IMHO reasonable for an informal survey (sure, for a more formal survey I'd like a scale with better discrimination). Averaging is happening over N respondants not three numbers so this also seems valid. You have possibly seen the phrase "The average family has 2.4 children"? To be clear, I'm not arguing on behalf of the author, I sure he can come and do that himself. PS: I haven't down-voted anyone, I'm genuinely interested why someone might think the survey is not valid
The NLP / Rap talk was VERY well done. Highly encourage you to watch it.
I usually find it easiest to avoid the problem in a different way by using a different kind of plot. For instance, I often find visualise many thousands of scattered points using hexbin (a 2d histogram), which is not only enormously faster since it's crunching the numbers first and plotting far fewer actual colours/images, but also a superior visualisation since it eliminates optical illusions to do with point density. That is, there is no longer a cutoff after which there's no space to see new points. Of course this might not be suitable for you, I don't doubt there are times were matplotlib is unbearably slow for even reasonable plots, but maybe it can help.
And the answer from other Twisted devs is also "No"
Wonderful. I'm sad Raymond H. didn't give a talk this year. His enthusiasm gives a +5 to my coding all day after watching a talk of his.
In my experience Twisted is no harder to steer now than 10 years ago. The growth is mostly out, not up.
You may wish to consider svg for plotting because it can handle many points and is viewable / zoomable in a browser. I have used Svgwrite to create svg from python with 30,000 points. Svg is a general Scaleable Vector Graphics which does not have common presentation axis so you would have to create those.
What are "python regular expressions?" Shouldn't it be just "mastering regular expressions?" Regex is somewhat regular across languages.
This definitely seems like the most reasonable article on the subject. Interesting read, thanks!
Thanks for posting a condensed list of the videos.
No, I think he was right. Better learn how to write Python 3 code, so when he needs to write Python 2 code he probably wouldn't have too much headaches. The opposite isn't true, since Python 3 is somewhat a subset of Python 2 (except for the new libraries, new language features, etc).
&gt; Python 2.8 would actually help encourage those on Python 2.7 codebases to move towards Python 3, so they can use the library upgrades. You know what this will *actually* do? This will keep people on the same major version, version 2. This will *discourage* them from going to 3, because hey, they just got a new update for the 2 series, it's going to be supported for longer (2025 here we come!), and I don't *need* to go to 3 anymore! I can just stay! Porting or going to 3 is always going to be the *hard, active* option, everytime, compared with staying on 2. Do you know what developers prefer to be 95% of the time? Lazy. This will help them live on 2 for even longer, and they still won't give a stuff about 3 for another 5 years. If you have a big app with no tests, that you "know" works on Python 2, you're going to be shit-scared of porting to Python 3 whether its more similar or not, and its not because of how similar they are; it's because you don't have tests in the first place. *Real* solution: write tests for your product, so you're no longer afraid. &gt; we should actually break existing Python 2.x code in Python 2.8! We should have a minor version that breaks backward compatibility. Great. I bet all the linux distributions will positively *love* Python.org for that. And no-one's mailboxes will be filled with up with piles of spiteful hate when someone realises they just upgraded their 2.x python and shit no longer works. *tip: this is crazy stupid* ---- Ok, here's where this idea falls apart: None of these imports would work on Python &lt; 2.8. So you've already given up compatibility with other Python 2s; you now only work with this one. It's almost as if we've invented a whole integer that's between 2 and 3, and that's what we should have called this. And it has all the important behaviour of Python 3. Except maybe import names. And the internal codebase of the Python you're running is an absolute mess, trying to decide whether to follow 2 or 3 codepaths, but whatever. Guess what? You can now pretty much just run on Python 3! You've already solved your problems! Your app now works with unicode correctly! There's no *reason* for you to run 2.8 instead of a 3.x here! tl;dr: if you can run with a 2.8 that's so incredibly similar to 3 that its incompatible with anything &lt;2.8, you might as well (and should) just be running 3 instead. You've already done your porting!
This may be what they are after: a = 100 weight = "%d Kg" % kg
Anyone know why "The Birth and Death of Javascript" isn't on here?
You can create strings this way in python using %char within the string so: a = "Number: %d, String: %s" % 10, "Test" a == "Number: 10, String: Test" 
Your version seems correct. Anyway try this: a = 100 weight = "{0}Kg".format(a)
You was faster than me but : a = 100 weight = "%d Kg" % a :-)
"PyCon US 2014" was held in Montreal, Quebec, Canada. 
Good point! I suppose the fact that it's Python helps my friend since he is not a programmer as such, just enthusiastic about Python (and I'm not trying to turn him into anything more).
First of all, thanks for also posting the commented version, which is also a nice intro to Python. But back to variables, I came of age in the days of BASIC and two-letter variable names. Since then I've gradually weaned myself toward modern conventions: long descriptive names, using verbs for functions/methods and nouns for variables, camelCase/underscore_, etc. Now that autocomplete is everywhere, these conventions are easy to use. With good variable names, there is less need for comments (as debated/ranted on often here), and it doesn't expand the line count at all (as if that mattered). I actually did not find the code all that hard to understand (unlike other posters). But with better variable names, the intent is reasonably clear even without commenting. So please consider using the modern conventions, and thanks for your post (and the didactic follow-up).
People are already discouraged from switching to Python 3. Python 2.8 could be designed so it encourages and helps them to port their code incrementally towards Python 3. Unless we want to leave those codebases in Python 2 land forever, as legacy. But since so much new code is written in Python 2 every day, that legacy is a while off yet. I think the track record of people predicting what will *actually* happen with Python 3 adoption, or how it is done, hasn't been all that great. Hopefully you're better at it than most. So people need to write tests for large, working application code bases now so they can more easily port to Python 3. We can all say writing tests is good, but we know the practicality of business. I wouldn't say it's laziness that's holding back developers, but the practicality of your boss saying there's no time, or your customer not hiring you to write more tests or port code to Python 3. You can say all those people are idiots, but then they're the idiots paying people to do Python development, and that will impact the Python community. Concerning crazy stupid, the __future__ system in Python was designed to allow backwards compatibility to be broken. Apparently that PEP is "crazy stupid": http://legacy.python.org/dev/peps/pep-0236/ Backwards compatibility breakage has happened in the 2.x past. from __future3__ imports don't work on Python 2.7. You seem to have a problem with that, but that's what's been happening for 2.x releases (and 1.5 releases) since forever. Concerning absolute mess: it requires backporting Python 3 bytes type, and the Python 3 str type. That's not an absolute mess; it's just a few more types and some tweaks to the way Python interprets literals. Entirely possible. I do believe it's entirely possible to criticize my concrete proposals. There are actual flaws in my proposals -- see the comments I made in the blog post for some examples. But perhaps you need to do a bit more thinking? 
https://twitter.com/garybernhardt/status/455045879985356800
I guess if `i` wasn't just a number, but a more complex, time-consuming expression that you didn't want to compute immediately, this could be used as a primordial generator, although with the addition of actual generators that's probably irrelevent these days. Alternatively, if the outer function were some sort of decorator, you may well find yourself constructing functions inside it, in which case this may well bite you.
Where to find the slides? Videos are fantastic, however, no time to watch them. Thanks.
Enough with python 2! Drop python 2 development (except for bugfixes) on all the third party libraries and everyone will finally switch over.
Once Gary posts his version, we'll link to it.
Did you read that future pep? Read the nested scopes example, please.
PyVideo [has you covered](http://pyvideo.org/category/33/pycon-us-2013).
I can't. My customers have large python 2 code bases that my code needs to work with. What do you suggest I do?
They'll be organized in the coming days, however for now you can find them [on SpeakerDeck directly](https://speakerdeck.com/pycon2014).
Yes! I was going to mention this if nobody else had already, but always feel a bit bad about calling something blogspam. It is LeaseWeb, and some of the other posts on their leaseweblabs look like interesting reads, at least. The [other post appears to be this one](http://www.reddit.com/r/Python/comments/22uff0/pycon_us_2014_montreal_recorded_talk_videos/), although it was before all videos were available. Another interest one is [the post on HN](https://news.ycombinator.com/item?id=7577724). All I want, really, is a "officialish" post where we can talk about the many available videos, source out the great presentation and perhaps talk about them a bit. I can't watch all 138, so I just choose the ones that look interesting to me and even some of them are only decent. I would love to point people towards the standout videos. I'm not sure if /r/python ever does this, but it would be nice to see a sticky thread about the conference videos for a week or two to get some sustained discussion.
One has to be careful when hiring a programmer. Taking myself for instance (I am fairly new to python so can't comment on how good these questions are) but I have released many very good commercial C++ projects; and there is no doubt that I could write a C++ test that I could fail without delving too far into the depths of C++. Name all the different ways you can use static or const (two C++ keywords with many nuanced and very different uses). And a major technology in C++ is templates. I would fail almost any set of template questions that weren't fairly basic. But what I do in C++ is write lots of solid code that works well in a very short amount of time. Thus I am fairly certain that unless you are making a C++ compiler that I would be an excellent hire. So right now I am moving much of my development over to Python because my minimal knowledge of Python still allows me to develop most things faster and with cleaner code. So within the month my first commercial Python based products will be out the door and happily used by many people. But at this point I would fail this test miserably. So if you are looking for a Python Guru then obviously I am not the guy you want. But seeing that I can (and will only be getting better) can output huge amounts of functional Python code then I wouldn't be a bad hire. The key is that I have met many people who knew a language cold yet couldn't write code worth a damn. It wasn't their syntax or even their grammar that was a problem but their shitty approaches to problem solving. So my theory is that problem solving is very hard to teach and learn while the nuances of a language are far easier to teach and learn. So I'll take a problem solver with zero knowledge of a given language over a "Guru" who can't solve problems. 
&gt; So my theory is that problem solving is very hard to teach You can test for that. And you can also test for ability the engineer software, which again is different from being a master of a language.
But what if they made a python 2.8 and no one came? I suspect that those who are staying on 2 are mostly doing it because they don't care about 3 for whatever reason. If 2.8 isn't backward compatible with 2.7 and is actually just 3 lite then why would anyone bother with it? 
Its funny how PHP devs used to complain that their host did not have a new enough version of PHP, and now Python devs complain that they simply cant/dont want to upgrade.
The tuple contains the list. When you are hashing, you are hashing the whole thing. The value of a includes the lists. a is a tuple of list. a is not immutable because its value can change. Therefore, a is not hashable.
Might want to checkout /r/learnpython Also checkout the formatting help for how to format your code. Python is whitespace sensitive so it could be an issue related to that.
We use a high speed datalogger at work to record turbocharger speeds. If you forget to turn off the setting it defaults to record at 50KHz, we usually need to output at around 2KHz. I saw someone trying to manually remove quite literally GBs worth of excess lines of data from text files because he realised his mistake too late. God only knows how long he'd been at it but I automated it for him in less than an hour.
Syntax is: true-expression if bool else false-expression There is no colon and you can only have an expression (i.e. something that specifies a value) and not a statement. 
Could've used the [yes](http://en.wikipedia.org/wiki/Yes_\(Unix\)) command at boot and saved yourself 10 mins of coding. 
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Yes (Unix)**](https://en.wikipedia.org/wiki/Yes%20(Unix\)): [](#sfw) --- &gt; &gt;__yes__ is a [Unix](https://en.wikipedia.org/wiki/Unix) command, which outputs an affirmative response, or a user-defined string of text continuously until killed. &gt; --- ^Interesting: [^Unix](https://en.wikipedia.org/wiki/Unix) ^| [^List ^of ^job ^scheduler ^software](https://en.wikipedia.org/wiki/List_of_job_scheduler_software) ^| [^ExifTool](https://en.wikipedia.org/wiki/ExifTool) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cgsa7cg) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cgsa7cg)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Try running it. The closure refers to the variable `i`, not the value it has when the closure is created.
I was at PyCon and here are some of the talks I either heard mentioned a lot or personally enjoyed: [Character encoding and Unicode in Python](http://pyvideo.org/video/2625/character-encoding-and-unicode-in-python) Esther Nam and Travis Fischer [All Your Ducks In A Row: Data Structures in the Standard Library and Beyond](http://pyvideo.org/video/2571/all-your-ducks-in-a-row-data-structures-in-the-s) Brandon Rhodes [It's Dangerous to Go Alone: Battling the Invisible Monsters in Tech](http://pyvideo.org/video/2659/its-dangerous-to-go-alone-battling-the-invisibl) Julie Pagano [Getting Started Testing](http://pyvideo.org/video/2674/getting-started-testing) Ned Batchelder [Analyzing Rap Lyrics with Python](http://pyvideo.org/video/2658/analyzing-rap-lyrics-with-python) Julie Lavoie [Enough Machine Learning to Make Hacker News Readable Again](http://pyvideo.org/video/2612/enough-machine-learning-to-make-hacker-news-reada) Ned Jackson Lovely [Cheap Helicopters In My Living Room](http://pyvideo.org/video/2675/cheap-helicopters-in-my-living-room) Ned Jackson Lovely [Fernando Perez's keynote](http://pyvideo.org/video/2683/keynote-fernando-perez) was a pretty mindblowing demo of the power of iPython [Jessica McKellar's keynote](http://pyvideo.org/video/2684/keynote-jessica-mckellar) was an inspiring call to action on getting younger people into Python. [Guido's keynote](http://pyvideo.org/video/2686/keynote-guido-van-rossum-0) was hilarious, especially during the live coding. If you're nervous about coding in front of other people (e.g. doing pair programming), watch this video. I'm probably missing some but hopefully that's a start!
:D wow Thanks for the instant replies. Okay, i will check for formatting errors. I just started learning to code. 
I'm not actually asking about the interview question here, but the structure of the interview question.
Hey tnawaz, if you are just starting to learn to code I highly recommend downloading a good [IDE](http://en.wikipedia.org/wiki/Integrated_development_environment). Not to sound patronising but just in case you don't know, in it's simplest form it's just like a text editor but it helps you write your code by guessing what you are trying to write, making suggestions and highlighting where it thinks you may have gone wrong. As well at this they do a pretty good job at highlighting mistakes that you make and making suggestions as to how to fix them. [Here] (https://wiki.python.org/moin/IntegratedDevelopmentEnvironments) is a list of IDEs that work with python and I recommend the free 'community' version of [PyCharm](http://www.jetbrains.com/pycharm/download/) as it's pretty simple to get set up. 
We built our REST API deployment solution for this exact discussion. We got annoyed with how ambiguous setting up a service technology was. So we allow developers to take a GitHub repository like https://github.com/FlowStacks/hello-world and deploy it straight into a REST API that is unique for you. Build jobs to do anything and let the deployment take Inputs coming in as JSON via a POST into code: https://github.com/FlowStacks/hello-world/blob/master/src/ra_send_email_template_to_user.py#L14-L21 Outputs get written back out over HTTP as JSON too: https://github.com/FlowStacks/hello-world/blob/master/src/ra_send_email_template_to_user.py#L150-L154 We wanted a simple deployment to take a GitHub repository and deploy a REST API that could glue HTTP + JSON with our Python Job code. Let me know if you need more information. 
Unfortunately, language-specific interviews miss other critical knowledge. This month I've had to explain to about 20 people how hardware &amp; data redundancy in Hadoop &amp; MongoDB is not a complete replacement for backups. etc, etc, etc.
Sometimes it's about the journey.
I'm worried that if the discontinuity between 2 and 3 is not made smaller we'll find ourselves in a world of python 2 and python 3 in equal measures. Libraries in py2 that do not get feature upgrades would then make maintaining code harder... Of course I could be wrong.
this is merely a commercial for toptal disguised as actual information. otherwise known as spam or at the very least, information with a hidden agenda. I'll go with spam. 
&gt; def binary_operator():` &gt; return 'a%s%s' %(1,2)` As was said the last time someone did that, CPython will automatically replace that expression with `LOAD_CONST "a12"` at compile time, making the benchmark meaningless. Same thing applies to any operator for which all operands are compile-time constants, e.g. `1 + 2`.
&gt;but when I submit, it says: "Fail: you did not write _single_ expression" &gt;Also, the answer HAS to be TWO lines. 1. variable assignment 2. assign string to variable weight Ok, this looks crazy to me but what about: a = 100 weight = str( str(a) + 'Kg') 
Northern... Vermont?
From the article: &gt; Here are proven, effective techniques and questions for finding true masters of the language. followed by: &gt; It is important to bear in mind, though, that these sample questions are intended merely as a guide. [snip] At the end of the day, hiring remains as much of an art as it does a science. So, this article is kind of like the supplements industry: **Take these pills and live another 80 years!**\* **All claims made by this advertisement have no factual basis*.
I don't see what you mean. Past 2020 (if that's the most recent deadline), the 2.x family will finally be dead. If they don't want to be on an unsupported platform, their only option at that point will be to upgrade finally. In that sense, yes, guido is the BDFL of corporate decision-making as well.
I don't find the headline very helpful, maybe call it "New book about Mastering Regular Expressions in Python". Although I think the hard part about regular expressions is to memorize the syntax. Once you understood RegExp, the usage in Python is pretty simple, and I don't know if it requires a whole 110 page book to read up how the `re` module works... Anyway Here is a good (free) tutorial series (slides + video) from Software Carpentry about Regular Expressions in general: [http://software-carpentry.org/v4/regexp/index.html](http://software-carpentry.org/v4/regexp/index.html) And here is how you'd use them in Python: [https://docs.python.org/2/library/re.html](https://docs.python.org/2/library/re.html) [https://docs.python.org/2/howto/regex.html](https://docs.python.org/2/howto/regex.html) 
I don't get the impression anyone understands what the real problem is. There's no urgency for in house apps to upgrade to Python 3. if and when your clients decide they want to upgrade, they can budget for that. Or not. Tons of places still use TCL, COBOL, old versions of all kinds of software, and they'll never move. That's a certain kind of shop. If those are your clients, and you don't like dealing with that kind of client that never budgets for upgrading anything, find new clients. This is not a problem people are generally reporting, and if they are, please educate us about that instead. if we all understood your *actual* problem rather than all these blog posts about "2.8" things that will never happen, maybe that would be more productive for everyone involved.
It was mostly about web scraping. Please stop spending so much time scraping the web, everyone, and start by using APIs and services. Examples she could have used: &gt; http://api.wikia.com/wiki/LyricWiki_API &gt; http://www.chartlyrics.com/api.aspx &gt; http://www.lyrdb.com/services/about-lws.php
Thank you! I will try the svg backend. Hope it works. I have used gnuplot to show 12 million points from a text file. Excel choked, but gnuplot did it no problem. The last time I did it, though, I wrote a gnuplot file and used system calls to generate the plots. It felt hackish. Is there a gnuplot module, I wonder?
slides and other materials for this 4-hour long tutorial (!!!) are here: http://dabeaz.com/finalgenerator/
Use the agg backend?
You are so right. A programmer is rather worthless if he is really bad at problem solving. You wouldn't hire a mathematician, who is bad at math or has problems applying it, but got all the syntax down. Bronze for getting the job done. Silver for getting the job well done. Gold if he cares for his tools. 
Assigned too many blocks error, or sonething like that.
What's the point of this guide? Is it a cheat sheet to allow non-technical interviewers to ask technical questions? Or is it a cheat sheet to allow interviewees to answer them? In either case, it won't work. A non-technical person is not going to understand the issues well enough to evaluate whether the interviewee has answered the questions properly, and five minutes of lessons will not help that. And similarly, a job candidate who doesn't know what a decorator is will probably not be helped meaningfully by this cheat sheet. The only case I see this being useful is when a non-technical interviewer is hiring a non-technical candidate posing as a programmer. Both parties, armed with the "guide," will pass with flying colors. There's little chance of a false positive or false negative, although nobody gets what they really want. To hire a technical person, you need an interviewer with some basic knowledge; if the interviewer doesn't have detailed knowledge then it's pointless to ask detailed questions. Ask questions at the level of your knowledge, and let the candidate try to explain things well enough that their expertise becomes apparent.
I would change this to a formula. Tool knowledge=TK Problem Solving=PS Weighted Programmer Score =PS * 0.95 + TK * 0.05; 
&gt; Even cleaner use eventlet or gevent and forget all the yield nonsense. It's a feature! It really, really pays to know where your code can yield, both for general sanity and for testing.
Take this over to /r/learnpython and prefix every line of code with 4 spaces.
It seems to be an attempt to mimic lazy execution similar to Haskell and the main take away about lambda i is that it refers to its name not the value
PyQt is probably the best 'high power' option if you want a good looking cross platform GUI. If the GPL licensing is a concern for you, you can use PySide, which has almost exactly the same API, but is LGPL licensed. Tkinter is easy to use and included with Python, but it tends to produce ugly GUIs. For some uses, aesthetics don't matter at all, though. Wx also seems to have a decent community around it, but I haven't used it. I'd only consider Gtk if you know that your application will be used entirely on Linux. Gtk is cross platform, but in my experience Gtk applications on Windows/Mac look ugly, and there's a bigger community using Qt for cross platform apps. Kivy is a good new option if you want tablet/phone interfaces (or that kind of interface - it can also run on the desktop).
If you catch the exception, you can get the traceback as text using [traceback.format_exc()](https://docs.python.org/3/library/traceback.html).
The wall of shame still lists it as python2 only.
Also, HTML/CSS/JavaScript with python on the backbend.
You. We all vote you.
There's four main GUI toolkits, and then there's a bunch of other libraries that wrap one of these: * [PyQt](http://www.riverbankcomputing.com/software/pyqt/intro) * [GTK3+ via gobject-introspection](http://python-gtk-3-tutorial.readthedocs.org/en/latest/install.html) * [wxPython](http://www.wxpython.org/) * [Tkinter](https://docs.python.org/3.4/library/tkinter.html) If you're doing anything serious, its hard to go past Qt as its cross-platform, well documented, user-friendly license, has some nice tools for drawing GUIs (Qt Designer etc.) yet is still just as easy to learn (as anything else). I recently ported one of my apps from Tkinter to Qt and it was quite straightforward, which is nice to know you can learn one thing and almost chop &amp; change it for another. Most (if not all) of the toolkits use the same kind of paradigm - you add stuff to a canvas and show that canvas, implementing callbacks for buttons etc. One thing you might find handy, coming from matlab, if you install the [Anaconda](http://www.continuum.io/anaconda/) Python distribution, you'll get things like ipython, scipy, numpy, matplotlib, etc. by default and also the PySide bindings to PyQt. Its pretty much right up your alley if you're doing work that you would currently/previously done via matlab. 
I disagree and I have been programming Twisted for many many years. I know how it feels to know where your code yields and how it feels when I don't explicitly mark it as such. (Yes you can write Twisted as a series of yields instead of a chain of actual functions. Oh and by the way Twisted has semaphores and locks, and yes you do need them sometimes, and not, not just for resource pool!) So my verdict is it does not "pay". What pays? Clear. Obvious. Business Code. The actual thing you are trying to do " Step 1. Get customer cart ID, Step 2. Get cart object from database. Step 3. Update cart. Step 4. Return result". Notice no yields, no deferreds, not switching through 5 different errback and callback chains. Does my end-user (including perhaps a high level API layer) care if my database driver needs a yield or a deferred. Also, what if your database driver is written in Twisted, and your cache layer driver is for Pyramid, or Tornado, or asyncio. You can't mix and match them. eventlet and gevent do this mixing via monekey-patching, it is sneaky and kind of dirty -- but it is in one place only (you call it once at the start of your process) and then you can reuse regular Python code that perhaps relies on queues/threads etc. Yields, deferred, promises are bad things to have in your code-base. Sure, in toy examples like "hey check out my test key value store" work great for showing a yield or callback based pattern. But large code bases start to accumulate that cruft and it becomes ugly. 
(I should add, I'll let you discover the other libraries in Anaconda that will be useful to you... pandas, numba, blaze, bokeh, etc) 