If you're going to stick with Python 2.x, then there is no reason not to use the most recent version of 2.7.6. There are a bunch of nice features (e.g. set literals, dictionary views, argparse..)
I don't see why someone using PHP feels like they can laugh at anyone else in the world... even Javascript. 
No worries, it's a good little API withstanding. I agree with kankyo's point about setting the option as causing more problems than it would solve, but how about return an episode as a list of versions of that episode. This would work for the situations when an episode is rereleased becuase of a bad first upload too (happens from time to time).
Buy them this book http://t.co/7oIbPMiJ :)
Make it a python package with it's own (git) repository. Have a branch with the old reliable code and have a branch with the new code. You can install the package in development mode (`python setup.py develop`) and then switch between branches when a project requires one version versus the other. You could also have a virtualenv for both, depending on what you are more comfortable with.
roger that sir.
PHP beats Python on a few crucial aspects: * It is available on every shitty shared hosting service in the world. $1/mo or less buys you a shitty control panel, completely unprotected FTP access, a clueless support team, and an outdated PHP. Sure, for $1.50/mo you can get a basic VPS, but ssh is hard, servers are scary, and "there is no support". * Your sales department can deploy PHP. Using Windows Explorer. * Every idiot can build a dynamic website with PHP, investing an absolute minimum of time and learning effort. Insert `&lt;?php ?&gt;` tags into your otherwise static HTML, and voilà, you are programming. Never mind that you have probably just introduced vulnerabilities of all the OWASP Top 10 entries. Never mind that if you do this for more than a week straight, you'll end up with a completely unmaintainable mess. Never mind any of the six thousand other reasons why this is really really bad. * As a result of the previous, there are plenty of PHP developers for hire. Most of them are utter shit, but that doesn't matter - hiring people prefer picking from 200 shitty candidates over picking from maybe 2 excellent but expensive and quirky candidates. Frankly, I think you need to do one of the following: * Come to terms with PHP. It's shitty and painful, but it can be managed such that you can meet business goals without having to make too many concessions. If your job is great in all other aspects, this is what I'd do. * Run. Or, rather, build an impressive portfolio of Python projects (assuming that Python is what you want to use), and make sure in general that when a good job opportunity comes along, you are ready. * Solve the hardest most pressing problem in your company with Python. For this to work, you have to solve it faster, more efficiently, and better than any of the PHP guys, and the solution must be as easier to understand for a PHP programmer than the equivalent PHP solution would have been. In other words, you have to deliver a kick-ass solution, and then some. And when you have done it, you may still have to fall back to one of the other options.
Watching this [video](http://www.youtube.com/watch?v=oLHmoy9bKCY) would help you find arguments in favor of Python.
Thanks so much this is very good information I will spend today writing this cheers!
Thank you very much!
&gt;Using an Affine Invariant Markov Chain Monte Carlo Ensemble sampler to characterize a one-dimensional normal distribution is a bit like using the Death Star to destroy a beach ball Heh!
Except python 2.6 is no longer maintained and is officially retired.
The problem I was having when at first relative imports weren't working was then doing `touch __init__.py` in the `widget` directory, forgetting I already had one there that imports everything I want. That ruined every subsequent attempt for the next hour to get anything to import correctly. Now `from . import foolib` works. Thanks.
The problem is that I want them to be able to load simultaneously. If I have to switch between versions, the whole idea fails.
Yes. I was looking to have the same git repo in a more global area, and inside a package in that, and to allow each to be on different commits, but still work in the same Python instance. I think it's working now. I'll have to test a bit more to be sure.
I had an interesting conversation with a friend of mine in a javas hop and his question (that I couldn't answer) was how well would Python integrate with the Java stack? His theory was that a successful test would be to hive off one small project in an endless large product that could be done in python without anyone caring. Personally I am redoing much of my legacy code in Python because the very short time to redo it will be more than made up for with the massive productivity increase. Also the old code was begging for a redo but a same language (PHP) redo just wasn't justified. 
If you are using SqlAlchemy for just straight SQL then switch to plain old MySQLdb as it is much faster for boring SQL. SqlAlchemy seems to be optimized for its ORM and whatnot. Another key metric is that your total lines of code should plummet from PHP. I find my Python has around 1/3rd to 1/2 the code of the functionally identical PHP. 
Didn't realize it did that automatically. :) 
Build things in it and give them out. Code speaks louder than words - and arguing *never convinces anyone of anything*. Do all your unittesting in jython. 
what about autoit?
Interesting, I'll keep that in mind! Lines are not even fair to PHP. I had that in my metrics but python's was about 1/6.
I'm currently in somewhat of the same boat. We use CentOS so no python 2.7 for me either. What I managed to do is to find an rpm that installs python 2.7 just beside 2.6 since yum needs 2.6. From there I use virtualenv for my applications.
i think can be better if use memcached 
Ah yeah I guess I missed that. Your situation kind of confuses me. If I had to do something similar to what you are doing I would just add a module (or add to an existing module) with new class/object names to implement my new features. Do you really need the new library and the old library at the same time? Or is it more like you need new features and old features at the same time?
Rent a VPS from a reputable provider. You'll get the same functionality as from AWS, but much cheaper. AWS won't really provide you with anything that a regular VPS can't, if all you need is a server to run it on. AWS provides lots of features, but I'd guess you probably have no need for them at this point. When you start getting a lot of traffic, and don't want/don't know how to setup your VPS to handle it, then you should look into AWS. I use AWS daily where I work, and it's awesome, but it's "industrial strength" infrastructure with a price to match.
Why not use flexget? Written in python as well. I think they have an EZTV plugin in development (maybe you can help out the developers?), but using an RSS feed is just as easy.
&gt; I initially wrote this because I was tired of littering other people’s code with prints and logging statements just to fix one bug or understand how something works (see aspectlib.debug.log). Any reason you don't use a debugger for this? First thing I do when having to quickly grok a new code base (or fix a bug in a foreign code base): 1. Find __main__(). 2. ``import ipdb; ipdb.set_trace()`` I couldn't imagine having to rely on print statements. A debugger gives you significantly better situational awareness.
Assuming that you know linux and the command line, a VPS is great thing to have. I recommend DigitalOcean. A basic server is only $5/month and you can easily find a coupon for 2-4 months free. If you don't want to much around with a server or server administration, check out Heroku.
Beat me to it. Also: In [1]: base = { chr(i): i for i in range(ord('a'), ord('z')) } In [2]: %timeit dict(zip(base.values(), base.keys())) 100000 loops, best of 3: 3.57 µs per loop In [3]: %timeit { v: k for (k, v) in base.iteritems() } 100000 loops, best of 3: 2 µs per loop 
I need the new and old library at the same time. Things like renames and deletion of outdated concepts happen often in my libraries, as I'm doing a lot of inventing and fleshing-out right now. Meanwhile, they're also somewhat in use by the larger group of tools. I want the tools I'm not actively working on using the way the library was 2 weeks, or 2 months ago, and the tool I'm actively working on right now to have the freedom to push its own version of the library forward, and this will need to happen simultaneously, as I'm using many tools all the time, and even in tandem. I can circle back later and update other tools to take advantage of (or at least not break against) the later changes. Obviously I want these things to eventually be a bit more stable and dependable, and maybe then I can rely more on a distribution/dot-release style of development, but right now things are moving quickly.
I need to post a question in relation to this article compared to [this video](http://www.youtube.com/watch?v=jtqfcg23Ors). gtg
I use a combination of Heroku and AWS. For some things, AWS is cheap, such as serving static files from S3. Heroku makes deploying (with git) absurdly easy, so I can spend my time developing and not being a sys-admin. Heroku isn't the cheapest option once you grow out of the free-tier stuff, which for me was immediately. But it does allow you to add tons of great stuff with almost no effort, like MemCache, Redis, etc, and if you ever need to scale up, that's super easy too. The AWS documentation is pitiful. The user forum is a complete ghost town. Best bet to get ideas for using AWS is search StackOverflow. 
Look into the Software Collections repos. Official Red Hat maintained packages. You can run Python 2.7 and 3.3 aide by side with the system version 2.6. If anyone is running CentOS these are also now available as well.
It is still maintained by Red Hat and they will backport any major security issues.
what did it return? (you don't type the #&gt; part by the way, I pasted my prompt, sorry) Also, as indicated by other posters, you don't need the sys.path.append part. you should just be able to import hello hello.hello("hello") what is the 'crash' you mentioned? please post. 
Look into the Software Collections repo, it does exactly that.
The utility you're looking for is `cron`. Depending on your distribution you might have a folder `/etc/cron.weekly` where any script you put in that directory will automatically be run every week. If you don't fear not, here's how to create this functionality (and have more control by specifying exactly when to run the scripts). The first thing we want is a script which will run all scripts in a directory. It should look something like this. #! /bin/bash # Pass the directory to run as an argument. script_directory=$1 for script in "$script_directory/*" do if [ -f $script -a -x $script ] then $script fi end Great now if we save this as something like `execdir` or `rundir` we can reuse it multiple times. I would put this script in `/usr/local/bin`. Then we create the directory `/etc/cron.weekly`and edit the crontab to make our command run. Using your favorite text editor add this line to `/etc/crontab`. @weekly /usr/local/bin/execdir /etc/cron.weekly or 0 0 * * 0 /usr/local/bin/execdir /etc/cron.weekly I'm only specifying the full path because sometimes cron is weird about sourcing things. If you would like to specify the day and time for the command to run using the second example change the first 0 to something in (0 - 59) for the minute, the second 0 to something in (0 - 23) for the hour and the fifth 0 to something in (0 - 6) for the weekday. If you want to ignore the folder idea you can also (assuming the script you're trying to run is called `myscript.py`) add this line to `/etc/crontab`. 0 0 * * 0 /path/to/script/myscript.py an_argument another_argument
I'm guessing around $55k as a jr. dev. He and others are telling me that I'm way off and it would probably be much more. Are they right?
I'll explain my downvote: there's no actual question here, you're just asking for a solution after putting in seemingly no effort yourself. Do a bit of Googling then come back - if you haven't found what you need, you'll have at least some better questions to ask.
So this is probably the third or fourth article that I've seen recently about optimizing python with cython after-the-fact. I have no problem with this, of course, and in fact love these guides. What I'm always left wondering when I read these is why someone hasn't implemented a python compiler that will simply do this for us (or perhaps this exists?). What I'd very much like to do is write clean python code that can then be interpreted into a lower level language that gives me at least an order of magnitude improvement in execution speed. Is this prohibitively difficult? Am I just ignorant of the details or the existence of available tools? Unfortunately, as much as I write python code (and enjoy writing it), I don't actually have the time to optimize. My analysis team is very small and we don't often get the chance to revisit our projects once we launch into production — at least not for optimization purposes. I'd love to be able to use an optimization tool that would capture valuable cycles without great effort on my part. Does such a thing exist?
Check out PyPy. In general, Python's semantics make compiler optimization a hard problem, but PyPy is the closest thing to what you're describing, and is a highly regarded project.
Much more? For someone without experience? Sounds crazy, but NYC is kind of a bubble so maybe that's how it works there.
so let's assume I don't know linux and command line. What are my options in the near term?
Use virtualenv.
Whenever i post questions like this on stack overflow I get directed to documentation. I'm just looking for a clear walkthrough of what is what and the fewest steps it takes to get something live. I'm not at all familiar with terms like VPS, Heroku, etc. although I see these thrown around all the time. It's difficult knowing where to start when you have to have experience using something to understand how to learn it.
You need to learn Linux and the command line. If you really want to use Python in a server environment, you should be prepared to do administration without a GUI. Maybe you should [do a course](https://www.edx.org/course/linuxfoundationx/linuxfoundationx-lfs101x-introduction-1621).
What you need to do, in a nutshell is: * get a virtual machine (you can do this by using VirtualBox on your computer, start practicing with Ubuntu server version, with no GUI, or a desktop version, but use the command line a lot). When you know what you're doing a bit, you can get a VPS, which is a virtual private server, or a virtual machine hosted by somebody else. When you get it, you get access to it via SSH, which is a secure, remote shell (command line). * Now you have a server, you need to get files on it. You can do this with SCP, winSCP is a windows application that does it. Later you might like to use github or s3 as an intermediary in order to push from your machine to your remote machine * then you get your stuff running, you can set up a 'cron job' which is a scheduled task to run your python script, or you can use a CGI web-server thingy to set up a GUI so that you can do it remotely. All of the above is easy enough, it's just a process learning it. You can test it all in a VM on your desktop/laptop, so do that and learn. If you break it, start again! Also use source control. Git is good. 
make altinstall
Are you using Windows, Mac, or some Linux OS?
Just want to say that I've been using AWS's free micro instance for the past few years (yes, I just register a new account once every year...probably against the ToS but hey, it works), and for simple scripts and web apps that only a handful of people will ever use at a time, it works great. If you're going past the free tier, though, I agree that a provider like Digital Ocean will save you money in the long run.
Check out [numba](http://numba.pydata.org/) as well. In many cases, you can just add their @jit flag and see a nice speedup.
If I'm going to take the time to write it in some bastardized child of C and Python why not take the time to write it in C? Edit: Referring to just the Cython optimized function not the whole program
Do you want the program exposed to the web? I'd be happy to help with the initial setup on AWS or Digital Ocean (or any VPS really). You will need to do some DevOps unless you decide to use Heroku. Heroku should be your go to host if this is your first python program. And as everyone has stated before, you should start learning how to use the Linux CLI. The Linux Foundation course on Edx would be the best place to start. If you have 250$ you can even get certified. edit: read you replies; Heroku: Cloud application platform. Great for newbies and provides 750 hrs of server time (a year or a month? I cant remember) to run your app and provides no nonsense approach to setting up stuff like db's and redis VPS: Virtual private server (VPS) is a virtual machine sold as a service by an Internet hosting service. Git: You will need to learn git if you are going to do automated deployment or use Heroku (and you will use automated deployment, you will learn quickly the value of automating deployment.) what is the base operating system you are using?
If only 5% of your code turns out to be C...... Then why would you just go for C? I would argue that writing most of the program in python let's one use all the good stuff python has to offer while keeping the high maintenance stuff fast enough to not die from frustration of slow execution. Less guilt trips to the bathroom! 😀
That's your choice. The article is talking about profiling and rewriting just the slow code. Much like you'd profile C code and rewrite the slowest parts in assembly. In this case, the corresponding question would be "Why not just write it all in assembly?". The answer most of the time is the same - because the lower-level language is slower to develop in (assuming similar levels of expertise in both). Of course, assembly isn't portable while C usually would be but that's beside the point.
I find Cython a stepping stone to learning to eventually choosing C/C++ as the defacto low level language to write in. As of now, I'm using PyTables out-of-core storage with NumPy/Numba/numexpr speed (built with Intel mkl), and I at the moment don't really have the time to learn the c/c++ external libraries equivalent. But I still want the advantages of STL containers and static typing, even at the cost of verrrry ugly cython code.
It really depends on your requirements. For example, reddit is 98% or more Python, but has a few key math functions written in C (with Cython). It would be quite wasteful to rewrite the entire site in C just for a bit more of a speed boost.
If I have a particular piece of code that needs to be sped up to the degree that I'm writing a C extension I don't see the point in writing it in Cython, converting that to C, and compiling that. Just write it in C.
I'm not talking about writing the entire thing in C. I'm talking about just writing the pieces in C instead of Cython.
I'm not an expert on this but looking at all the widely-varying attempts over the years to solve this problem, I'd say it must be pretty darn hard. There have been binders to pure C/C++ like the Python C API, Boost Python, SWIG, Pybindgen and Py++. Higher level there are/were(?) things like psyco and cython. Then there's IronPython (Windows only and not supported for Python 3 yet AFAIK :( ). Of course there's also PyPy as /u/noteal mentioned. I haven't had experience with this since it was just a promising project. It's improved a great deal since then. &gt; Unfortunately, as much as I write python code (and enjoy writing it), I don't actually have the time to optimize This is no different than any other language. Speed is almost always an issue (if only perceived sometimes). If your business model/boss/... says you can't optimize, either stick with Python if it squeaks by or move to a compiled language. However, unless the projects are tiny or you're much stronger in the compiled language, the dev time will probably be longer with the compiled language - the difference being great enough that you could have isolated the slowest parts in Python and rewritten just those in C. Odds are that Python with some slow parts rewritten in C (via one of the above like Boost Python) is your best bet.
Cython pretty much is C, and it also lets you embed literal C while you're at it, too (like CFFI). The plus side is that it's way quicker and simpler to integrate it with the rest of your code. You can call pure Python from Cython and Cython from Python all in the same file. If you actually compiled some separate C, you would have to import it with ctypes or similar, package it separately into your project, etc.
Why would you ever want to do this? Just curious.
Your separate tools are all in their own package, right? So if you wanted to upgrade Widget X to the "new" version it wouldn't be run in the same Python interpreter as Widget Y? If so, you shouldn't have any issues. If not, you need to break them up into modular pieces.
&gt; I am at a loss as to which version of Python I should learn The version that comes with Red Hat/CentOS
Here's a thought: Write small parts of a larger system to work together. Decouple them by writing good interfaces and not sharing state. Then, if one part needs to switch over to the JVM or to C/C++, it won't be a problem. Program to the interface and everything will be alright. Writing C/C++ extensions in &lt;insert-your-favorite-interpreted-language-here&gt; is sometimes helpful. But, IMO, it mostly muddies the waters. Folks inherit a codebase where they have to speak two languages at the same time. It ends up being difficult to maintain.
How do you scrape a site that requires submission of login and password?
As someone in the blog comments said, pypy optimizes the runtime very good, too. 
Few months ago, the RSS was really buggy for EZTV. So I didn't continue developing using the RSS (fyi. https://ezrss.it/) However, I'll try to help out the developers and work on this. Thanks ! 
Go has exactly the same problems as described in this post.
Deploy it on a server and demonstrate what it can do on the web using a framework such as Flask. In my experience, the biggest problem that PHP devs have towards Python is their perception and expectation that it isn't as useful or practical in the web application problem domain. 
No problem ,if you have any questions just reply here and we'll see if we can get things sorted. Else Documentation and Stackoverflow are your friends with PIL ;)
I just tried this same example with pypy: &gt; python p1_timing.py Pure python function 0.859140872955 sec &gt; p1_timing.py Pure python function 0.0588479042053 sec That's pretty damn sweet for no change to the code at all.
How often do you debug programs with race conditions? Print statements would significantly affect any possible race conditions too. It's not slow until you hit your first breakpoint and the debugger starts collecting frames -- you can leverage that aspect to delay the breakpoint to later in the program, where it's closer to being relevant.
See my top level comment in this thread. I've added some numbers comparing cpython with pypy on this specific benchmark.
Would be nice with PyPy in the mix too...
the point is "take the time", if you wanted to take the time why not just write the whole thing in C
Show them ipython. Even better: ipython notebook. Show them requests, list comprehension, gen-expression. I do PHP daily, and there is lot of foreachs that would be great to write as list comp.
I think I need a sarcasm sign. &gt; But if your product is being deployed to a shitty server then you probably have a shitty product. If the product is deployed to a shitty server, it means that the people in charge gladly spend hundreds of man-hours on making stuff work on that shitty server, just to save $0.50/mo on the hosting. Given such management: **OF COURSE THE PRODUCT IS GOING TO BE SHITTY**. Shitty management makes for shitty software, simple as that.
But if what you do is databases and web, then those kind of posts simply aren't directed to you. I there's a fair amount of REST/databases/api blog posts out there. Computer science is vast and this kind of posts certainly do have a public.
All day long :) PDB is no silver bullet - it has some severe disadvantages (slow, quirky and you need what to look for and break on), try looking at some [other tools](http://blog.ionelmc.ro/2013/06/05/python-debugging-tools/).
When your write a for loop, internally Python automatically does this. Its not something we do :-)
&gt; My daily job is more like "make a restful api that gets data from a database, matches it with a parsed xml and returns it as json to the user that successfully authenticates via basic auth". Can I optimize this easily with cython? Maybe a little bit. Just compiling a module with Cython (with no numeric type annotations) could perhaps give a 10-30% speedup. But these posts are for a different audience: statisticans, financial analysts, scientists in many fields, etc. who are all using Python to process large numerical datasets. For example, my job involves running numerical simulations on tens of gigabytes of source data. For this, NumPy and Cython are fantastic: I have seen 1000x speedups while still writing almost pure Python. Cython is a great alternative when you are thinking "I should implement this function in C". That's what the type annotations + compiler do anyway, but with 1% of the effort of *actually* rewriting the code in C.
/r/pystats would greatly appreciate this, if you're so inclined to cross-post it. Thanks!
It's hard to do with Python's design. The Julia language does what you want and has access to all of Python's libraries but it's immature. OK for analysis but production would currently be brave.
don't listen to that, its rubbish. 2.6 is very outdated and is being widely abandoned for even backwards compatibility. It's been superseded (forgetting minor releases) by 2.7, 3.0, 3.1, 3.2, 3.3 and in a couple of weeks, 3.4. It is no longer in active development by the Python core developers (no more security patches). The only reason its even being discussed is that as usual RHEL holds the rest of the world back with its horribly outdated software - and even these guys finally saw the light (after Google broadcast it was ceasing all RHEL support because it was junk) and created RHSCL to curb the flow of users and shareholders to a better supported Linux distribution. Python 2.6 misses quite a lot of functionality everyone else with one of the six subsequent versions takes for granted. "latest and greatest" is not a fad, its a proven software development and distribution model normally referred to as "release early, release often" that the industry adopted almost 20 years ago. Its dissenters are a minority of people whose minds are stuck in the 1980's where horribly old, bug-ridden filth with security holes a 4 year old can exploit is their definition of "stable" (i.e. see RHEL - 6+ yr old software missing 6+ years of bug and security fixes, current software doesn't even compile on it because its toolsets are too old) Python 2.6 is dead. Or, to paraphrase it a more preferred way, _'E's not pinin'! 'E's passed on! This python is no more! He has ceased to be! 'E's expired and gone to meet 'is maker! 'E's a stiff! Bereft of life, 'e rests in peace! If you hadn't nailed 'im to the log 'e'd be pushing up the daisies! 'Is metabolic processes are now 'istory! 'E's off the twig! 'E's kicked the bucket, 'e's shuffled off 'is mortal coil, run down the curtain and joined the bleedin' choir invisible!! THIS IS AN EX-PYTHON!!_ 
Have you tried PyPy for this? Would be very interesting to hear what you have to say on this...
I actually figured it out! It was a few things. 1: I was using Python 3 which for some reason uses a "newer" version of the language where a print command looks like: print ("hello") instead of print "hello" So I deleted Python 3 because screw that and downloaded Python 2. After that it seemed to work, but I was having trouble calling functions. After playing around I realized to call a function in a file you can't just call the file, you have to go from file import function or from file import * After that, it all worked. Thanks for your help!
I just used the one that was included in [this installation guide](https://github.com/MrTango/django-lfs-bootstrap).
Isn't the point in the article to demonstrate that turning python to cython is merely trivial for code quality benefits? Why bother writing C and adding additional steps to your build &amp; deployment when you can just add the cython runtime then prepend all your variable declaration sites with type specifiers?
, and then you write something that uses numpy and suddenly pypy is no longer an option.
People don't use pypy for ML very often because pypy doesn't support numpy.
I believe Jython allows python to integrate quite well with java as I think that is its purpose(other than it being another implementation), same with IronPython and .Net
Well.. it supports some parts of it. Parts that are getting bigger all the time. I don't really know how much of numpy normal users of numpy uses...
Depends on which parts of numpy you're using... there is partial support.
I'm going to add a section on this. It's actually really simple. You simple have to use a session object in requests to make your requests, as this will store the cookies and send them with future requests.
I've been waiting for an article like this for a long time now. Especially since Tulip (now asyncio) was announced. I love gevent, but I have to admit, glyph makes some good points here. I'll be meditating on this for a while. edit: In the end the argument does end up boiling down to explicit vs. implicit. I admit that I ran into many issues like the example given at the end when I first started using eventlet. With experience, those issues stopped happening as I learned to isolate the asynchronous calls and got better at seeing where they were being made. In short, I can accept that the asyncio style will be better for projects involving many developers with different experience levels. But for my personal projects, I will continue using gevent.
I feel like asking for a PyPy benchmark routinely comes up whenever an article like this gets posted. I'm guessing it would probably do quite well for something like this, and I'm continuously impressed by how good it has gotten. That said, I believe the reason why you rarely see PyPy in the mix, is that it is a non-starter for a lot of people. This algorithm in particular is included in scikit-learn, which uses things like scipy and cython extensively, so no one using it would bother with PyPy because it just won't work within their standard workflow. I think that there is a niche for writing pure python code and leveraging PyPy, but the larger community wants access to things like Pandas, Scipy, PyTables/h5py, etc, etc, etc. For those people things like Cython, Parakeet, Numba, and the like make much more sense because you can use the full scientific/numerical ecosystem and then optimize the actual bottlenecks. It is certainly not as simple or elegant as jit'ing your entire language, but in my mind it gives you more flexibility given the current state of things and the ability to get work done now. Certain PyPy developers routinely trash this model (e.g. https://twitter.com/fijall/status/443648142777782272), but it works well for a lot of people and has enabled the community to thrive. Some dislike Cython because they see it as this bastard language mixing C and Python. Personally I like it. It allows me to tune what needs to be tuned without compromising which packages I can use, and sometimes what I really need is a C-array of pointers to records in a numpy structured array, and it can do that. Scientists have flocked to Python because, like Python itself, the scientific/numerical stack has gotten to a point where it comes "batteries included". PyPy isn't mature enough at this point to make the same claim. Someday it might get there, but until then, a lot of us have things to do. 
I'm just going to second Digital Ocean, I had a few servers from them for about a year and there were very few problems, and they had some of the best support I've come across.
/u/chronographer is 100% correct, so I first and foremost want to endorse his comment -- there really is no way around Linux. This having been said, once you get the hang of it, Linux is absolutely fantastic to work with. It's a bit challenging at first, but not unpleasant in the least.
most of numpy works. did you check what you're missing?
&gt; With the word “threads”, I am referring to shared-state multithreading What I think erlang got right was the immutability and share-nothing approach of everything. This alone allows the whole langage free from certain programming paradigms while allowing some very nifty optimisations. I would have loved if Python could have gone the same path, I think we wouldn't have those endless discussions as which thread is the lightest. &gt; As we know, threads are a bad idea, (for most purposes). It's a very interesting writeup but did we need such an assertion to begin with? 
I'd rather said, some programmers have some problems with understanding its program's flow and have too brave heart to protect it by some kind of synchronization. Even "yield from"-style coroutines will need lock at some moment. But relying on "eye visible" "yield point" will push programmer to think about synchronization at the last moment. I'd rather think of sync first, so that I will not fear to introduce yield points later.
No, it's like saying your english dictionary doesn't have the words ballista and knight. Maybe you NEED those words, maybe you don't.
To be honest, that would be my go to option. Let python handle the I/O bound stuff and drop in a C version of that one CPU bound loop.
&gt; you can just add the cython runtime then prepend all your variable declaration sites with type specifiers? These are pretty trivial changes, though. It's simple but there's a limit to the sort of gains you'll see from just doing that. Even in the example he's chosen to demonstrate it the significant gains come from using pure C libraries and effectively re-writing the CPU-heavy operations in C.
I had submitted this a week ago but with a snarky title that triggered the redbots to downvote it for fear of having to think. Good to see it's getting some views now though. 
If I understood the latest PyPY-Numpy Status update correctly, PyPy cannot use a user-specified BLAS, but always uses it's own C code. Since the whole point of NumPy is to have a nice wrapper around BLAS, I'd say it's still a far way off. EDIT: yes, there's also FFT, PRNGs and some other nice stuff, but essentially numpy is a high-level wrapper to some blazingly fast things other smart people wrote in C, Fortran or Assembler. Having most of the API on the Python side in place doesn't help too much if the backend is not there yet.
How is it perfect? I mean you just mentioned locks in the same breath which leads me to believe it is no better than current solutions other than maybe syntax which is not what I would call perfect, i'd call that pretty. 
You'd have to most more of your code. The error seems like you're trying to render an exception instead of a template.
I've had this library on the back-burner for a while now, along with several others, and now I'm making an effort to release more of my code. People like to handle their configuration in a lot of different ways, so I don't expect this library to work for everyone. It does work for me, however, so I wanted to release it in case anyone else could find it useful. The API isn't completely stable. I'm looking for input and use-cases to help me solidify things a bit. The documentation is [here](http://fig.rtfd.org/).
I had a similar problem (was trying to add further buttons). Realized I had failed to update the scrollregion of the canvas I was adding the buttons to. Changed that (and made sure to pack the buttons) and it works great.
To be honest, there is no code I have written so far. Basically all I did was a mixture out of these two Installation guides. http://docs.getlfs.com/en/0.6.3/introduction/installation.html https://github.com/MrTango/django-lfs-bootstrap I complete them, and as soon as I try to access the running server I get the error message aka debugger message on the localhost. I installed django and django-lfs via the requirements.txt and installed VS 2008 x64 as well. Server works too but I get the error message posted in the OP.
You could also do an actual MIT class on Python for FREE though their OpenCourseWare. [A Gentle Introduction to Programming Using Python (2008)](http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-189-a-gentle-introduction-to-programming-using-python-january-iap-2008/) [A Gentle Introduction to Programming Using Python (2011)](http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-189-a-gentle-introduction-to-programming-using-python-january-iap-2011/) There are also many, MANY other CS undergraduate and graduate courses available for FREE through [MIT's OCW](http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/). 
There are line profilers, I can't remember off the top of my head what they're called though. I just wanted to say that for cython, if you run cython - a your_module.pyx It will generate an html file of your cython code where you can click on a line and see what c code it generated, as well as give you color coding that indicates how much of that line has been converted to c and how much remains calls into python Just because it calls into python doesn't mean it's definitely a bottle neck, but it gives you a clue as to where to start looking 
You could find a charity in your area and see if they need a website or something like that 
[PyLongObject](http://docs.python.org/dev/c-api/long.html). Note that it also represents machine-sized ints on 3; *PyIntObject* was removed (contrary to what the name `int` would lead you to believe.)
First, have a look at the details of how to do Conda packaging: http://conda.pydata.org/docs/build.html Once you've prepared a package, request an invite for [binstar](https://conda.binstar.org/), and upload your package there. Then you can promote your channel to people who want to use your package. What goes into the Anaconda distribution is up to the people who make it, but once you've made a package and shown that people use it, you can ask them if they want to include it.
Heroku.com is a hosting provider. They provide a virtual private server (VPS) and they are a platform as a service, or PaaS. You pay them a monthly fee, and they take care of lots and lots of sys-admin type tasks. They have great tutorials on how to get started too, so that should appeal to your need for documentation. 
It will be based on entirely how much he learns and how he learns it. Wrote, just memorizing stuff probably 45-55k. Understanding the concepts AND the gaps and how to fill them, 90k+ He needs to be able to answer the question: How does a web request work? Preferably getting all the way down to exponential backoff in ethernet, tcp recv windows and arp requests. He should read about the _history_ of computing all the way back to Babbage and http://en.wikipedia.org/wiki/Al-Khw%C4%81rizm%C4%AB I Do believe that someone could give themselves what would appear to be a focused 4 years vo-tech degree in programming in about 6 months if done right. Read CS papers, learn how to read CS papers, read every RFC and document from the w3c. Explain the codec wars. **Understand** unicode. If he is just _attending_ class, it will on the low side. He has to feed his own brain after hours.
For things [like this](https://bitbucket.org/NYKevin/nbtparse/src/tip/src/minecraft/terrain/cVoxel.pyx), Cython can provide a pretty substantial speedup over [the Python equivalent](https://bitbucket.org/NYKevin/nbtparse/src/tip/src/minecraft/terrain/voxel.py) without significantly changing the appearance of the code. Yes, I know I ought to be using numpy for this. But: 1. It's a toy project anyway. 2. [This method](https://bitbucket.org/NYKevin/nbtparse/src/tip/src/minecraft/terrain/cVoxel.pyx#cl-417) and [its inverse](https://bitbucket.org/NYKevin/nbtparse/src/tip/src/minecraft/terrain/cVoxel.pyx#cl-454) would be considerably more complex to implement with numpy than by just fiddling with raw C arrays. 3. I haven't actually gotten around to learning numpy yet.
No, that's most certainly not how Python does it internally: &gt;&gt;&gt; from dis import dis &gt;&gt;&gt; def for_loop(iterable): ... for element in iterable: ... pass ... &gt;&gt;&gt; def while_loop(iterable): ... iter_obj = iter(iterable) ... while True: ... try: ... element = next(iter_obj) ... except StopIteration: ... break ... &gt;&gt;&gt; dis(for_loop) 2 0 SETUP_LOOP 14 (to 17) 3 LOAD_FAST 0 (iterable) 6 GET_ITER &gt;&gt; 7 FOR_ITER 6 (to 16) 10 STORE_FAST 1 (element) 3 13 JUMP_ABSOLUTE 7 &gt;&gt; 16 POP_BLOCK &gt;&gt; 17 LOAD_CONST 0 (None) 20 RETURN_VALUE &gt;&gt;&gt; dis(while_loop) 2 0 LOAD_GLOBAL 0 (iter) 3 LOAD_FAST 0 (iterable) 6 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 9 STORE_FAST 1 (iter_obj) 3 12 SETUP_LOOP 41 (to 56) 4 &gt;&gt; 15 SETUP_EXCEPT 16 (to 34) 5 18 LOAD_GLOBAL 1 (next) 21 LOAD_FAST 1 (iter_obj) 24 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 27 STORE_FAST 2 (element) 30 POP_BLOCK 31 JUMP_ABSOLUTE 15 6 &gt;&gt; 34 DUP_TOP 35 LOAD_GLOBAL 2 (StopIteration) 38 COMPARE_OP 10 (exception match) 41 POP_JUMP_IF_FALSE 52 44 POP_TOP 45 POP_TOP 46 POP_TOP 7 47 BREAK_LOOP 48 POP_EXCEPT 49 JUMP_ABSOLUTE 15 &gt;&gt; 52 END_FINALLY 53 JUMP_ABSOLUTE 15 &gt;&gt; 56 LOAD_CONST 0 (None) 59 RETURN_VALUE They are completely different. The `for` loop has its own dedicated opcode (`FOR_ITER`). You can think of the while loop as being what's happening *conceptually*, but it's not *actually* what happens as implemented by CPython. 
Hot damn, I wish glyph would write Twisted documentation of such length. I've dabbled with Twisted on and off for nearly a decade, and it's always a bloody nightmare simply because the documentation is terrible. Calderone's series on Twisted is great, but that's about it :(
Okay, I am a *very* ***entry-level*** guy in his early 20's fresh out of college, but I am having trouble understanding how: &gt; Write small parts of a larger system to work together. Decouple them by writing good interfaces and not sharing state. Then, if one part needs to switch over to the JVM or to C/C++, it won't be a problem. Does not result in "a code base where they have to speak two languages at the same time." I also perceive an inherit benefit to using Cython in this case since it *takes away* the overhead of maintaining an interface. You can import Cython extensions directly into a Python script via standard module loading. What am I missing here?
His salary will be at a junior programmer level -- at best. I suspect that's between 45 and 55 for starting. It takes at least 5 years at a 40-hour job to gain Mastery, and that only means you have excellent knowledge about corner cases -- not that you have full knowledge. I think /u/fullouterjoin stated this pretty well for the web/IT domain. But there are other domains that python is being used for; each has their own 'stack' of technologies that need mastering. The keys to gaining a better long-term salary: a) learn as much as you possibly can about your chosen domain b) switch as often as 12 - 18 months from one company to another. c) pick the right domain to master; web development probably won't go away any time soon, but it might be much cheaper for a company to outsource web development over the next decade than to keep it in-house. Make sure your domain is relevant in 5 years when you've mastered it. If you can handle the time commitment and the lack of stability and healthcare, then consulting will net you a much better income and a broader experience. If you're interested in managing or starting up a company, consulting is a great option to get your feet wet in the industry.
If speed really is an issue, and you have flexibility with what language you're using I'd recommend you look into [Julia](http://julialang.org/). It still has a ways to go before it hits its 1.0 release (read: if you need absolute, rock-solid stability, it may not be the best choice at the moment), but it allows you to code at a level slightly lower than Python with *massive* perf gains. Also, if you don't need a REPL, lots of people who code in [Go](http://golang.org) were Pythonistas/Rubyists who got fed up with dynamic typing. Of course, Go lacks some of the conveniences of Python (and it's compiled), but it's still really speedy. Of course, both languages are very parallel-friendly. In fact, both were designed with parallelism in mind, and you'll see this as you learn more about them. :) Good luck! 
that sounds elitist. Anyone can upload to PyPI. I think I will have to look elsewhere for where to package and supply my library. But thank you for your help. 
Erlang's process model is indeed a major strength, more things should imitate it. &gt; It's a very interesting writeup but did we need such an assertion to begin with? Yes, unfortunately. Threads are still taught as a good idea in many places.
&gt; In short, I can accept that the asyncio style will be better for projects involving many developers with different experience levels. As Alan Kay famously said, ["You can build a doghouse out of anything"](http://www.youtube.com/watch?v=oKg1hTOQXoY)
It depends upon the respect that this boot camp has in industry and his ability to demonstrate that he has a certain skill level. To be honest I don't think it will be enough to live decently in NYC. If all he can afford is this boot camp training he may have to look else where to make enough to live decently. There is also the issue of what this so called boot camp is focused on. Six months or so you will not get a decent CS degree level of training. In fact I suspect much will be glossed over. As such the training may be very focused, such as web technologies, which is fine if that is where his interests lay. The problem is it can take you out of the running for many potential jobs. In any event I see employers low balling wages from graduates of such a program. It might not be justified but when you have managers that spent four maybe six or more years of their life in college they will look down upon somebody claiming to be a programmer with a six month crash course under their belt. It is certainly a mental problem with a range of people in hiring authority so he may have to shop around for somebody that isn't as bigoted. 
there are some built in to the standard library http://docs.python.org/3/library/profile.html?highlight=profile#the-python-profilers
&gt; For simple stuff, like a few function calls, extending Python in C has a fairly reasonable learning curve. After a few times, you'll be well past the point where Python + a few C extensions will be coded up faster, if not much faster, than pure C. Thanks. Looked at the .c file that cython produced and I can see what you mean about the complexity of writing a C extension for Python.
Separation of concerns. You don't have to know both languages to contribute to the codebase, you just need to know the language of the module you're working on.
Thanks for the feedback. We are currently using Bootstrap, but I'll let the web dev know what there are still issues. Out of interest, what mobile OS/browser are you using?
The title is a little misleading to me as I think Configuration Management has been used for things like puppet, sensible, and chef the last few years. These being ways to manage servers "configuration". Also may be hard to Google because of https://github.com/orchardup/fig. Otherwise looks good!
pip install gives me an error: (python 3.3.5, anaconda) edit: i'm an idiot - actually on 2.7 Downloading/unpacking figpy Downloading figpy-0.2.3.tar.gz Running setup.py (path:/tmp/pip_build_derp/figpy/setup.py) egg_info for package figpy Traceback (most recent call last): File "&lt;string&gt;", line 17, in &lt;module&gt; File "/tmp/pip_build_derp/figpy/setup.py", line 10, in &lt;module&gt; import fig File "fig.py", line 104 def sync(self, *sources, format=None, include=None, exclude=None): ^ SyntaxError: invalid syntax Complete output from command python setup.py egg_info: Traceback (most recent call last): File "&lt;string&gt;", line 17, in &lt;module&gt; File "/tmp/pip_build_derp/figpy/setup.py", line 10, in &lt;module&gt; import fig File "fig.py", line 104 def sync(self, *sources, format=None, include=None, exclude=None): ^ SyntaxError: invalid syntax ---------------------------------------- Cleaning up... Command python setup.py egg_info failed with error code 1 in /tmp/pip_build_derp/figpy Storing debug log for failure in /home/derp/.pip/pip.log
Compared with most of other cooperative multitasking runtimes, Go's runtime is perfect. Don't be mistaken: if you use shared state you will need locks in any incarnation. "Explicit yield" does not prevent from need in locks, it just hides this need till the moment it bites your nose. If you do not use shared state, you need no locks in any programming environment. Golang gives you ability to combine light threads with scaling by CPU cores. It gives you stricter memory model (than C and C÷÷), so that, using locks is much less problematic. And Golang gives you CPS (message passing through channels) so that concurent programming becomes very easy (when you need no every nanosecond. otherwise, consider mutexes). Yes, it is a bit harder than singlethreaded Python with "explicit yield", but not too harder to be awful. It really pretty to write highly concurent code in Golang. 
I think I mostly agree with this, as running simulations is kind of what I do. Less data, though. Most of the time. But after (gosh!) more than two decades doing this, I have accumulated a set of "libraries" written in C and Fortran (yeah, I know, but it's not a bad language for this stuff) that run on lots of platforms. And is tested. And I understand (which is the major reason that NumPy is not my first "Go-to" tool, even though it is excellent). Where was I going with this? Oh, yes: I find Python to be potentially very useful for tieing all of these libraries together and driving them around in a coherent high-level way. But what I haven't found (Beazely's thing was a pretty good start), a simple automated way to "thunk" things into Python. Which is a long rambling way to ask: Do you know of a simple/automated tool to thunk C and/or Fortran libraries into high-ish level Python constructs? 
&gt; It's a toy project anyway. It is? May be. It presents itself as something useful for this type of thing. Although, I stick with C and Fortran. I do like the SciPy visualization stuff a lot, though. 
How is that not met by Cython extensions? If you don't know both languages you can still call the function in your Python code without knowing the language the extension is written in. You are still contributing, like your example, to the code base in the areas your language is used.
damn you're right. i forgot for a minute which machine i am on. sorry about that. i'm on my 2.7.5 machine at the moment. 2.7 not supported, then?
It wouldn't be difficult but I'd like to stabilize the API first. I will likely want to use it in some Python 2 projects at some point.
No, they're all in the same interpreter. I work in games. We use Autodesk Maya. We launch Maya, and Python starts up intertwined with it until you exit Maya. For your entire session, you're in the same instance of Python. No one powers down here ever, so some people have Maya open continuously for days, even weeks.
Just to be clear: &gt;so that both can be imported into your program at the same time. Do you mean into the same Python session? I don't want to import both versions of the module into the same other module. I want project A to be able to import the global version of the library, which is somewhat locked down across the tools, and then project B to be able to relatively import its own, local copy of the library, which is at a newer version. I know most people spawn and release Python sessions constantly, but I work in games, where Python launches with Autodesk Maya and remains resident for the entire time you use the tool, which at a minimum is all day long (while modeling, rigging, or animating), but can span days or weeks in some people's cases (everyone here hates the planet; never reboots or exits Maya).
&gt; If you do not use shared state, you need no locks in any programming environment. If you do not use shared state, you don't need threads or coroutines, and can just run your tasks in separate processes.
There's the [conda-recipes](https://github.com/conda/conda-recipes) repo on GitHub; you could fork it, create your package, then submit a pull request. Then it's more "official" and you can ask them to include it in Anaconda.
Surely the current example usage is incorrect? &gt;&gt;&gt; cfg.init('server.host', 'localhost') &gt;&gt;&gt; cfg.init('server.port', 8080) &gt;&gt;&gt; cfg.sync() &gt;&gt;&gt; cfg['server.host'] '192.168.1.1' &gt;&gt;&gt; cfg.section('server')['port'] 9090 
I use Python for data analysis. Numpy is in everything. I was so excited when I heard about pypy, and so disappointed to find numpy wasn't supported. I think I could get away without just about any other module...not numpy.
Note 3. It looks like it has to do with your job description section on top. Is it possible that it is part of the navigation bar which is fixed? when you scroll that section becomes fixed and starts covering some elements as I scroll. 
The "Borg" pattern is always a bad idea. (Not incidentally, everything on `code.activestate.com` is a bad idea.) If you need global state in your app, create an object and keep it in the global scope of a module, as described here: http://glyph.twistedmatrix.com/2007/07/functional-functions-and-python.html Of course, it's even better if you can avoid having global state at all.
The example is correct, though it is not obvious what is happening. The call to *sync* loads values from the config file, which is why the values are different. I should show the contents of the config file to make it clearer.
seriously nothing you mention sounds "perfect". so it stole from erlang and clojure and put some C-ish lipstick on things. Hardly perfect.
and GIL haters probably dont realize that removing it doesn't solve the real problems that are illustrated in the article. they just want their imgur scraping scripts to run on all cores.
Whether you choose Django or Flask or Bottle or anything else, I am yet to see a tutorial that covers deployment for a layman - I'm thinking along the lines of a WordPress installation here... I'd recommend you go in a way similar to what Randall Degges (/u/rdegges) has done with [`django-skel`](http://django-skel.readthedocs.org). You could, maybe, create an app along the way that evolves from simple to a little complex. For instance, start with a simple link-shortening app, then add in user login, then add in link-bunching, then add in link previews, then statistical data gathering with third-party plugins, then create an API for others to consume and this, I think, would be a good point to stop, I think. :) Anyone who starts following and implementing the tutorial should, by the end of the tutorial, have a link-shortener that is on-par with some of the more popular tools out there. Also, more than a heroku deployment, as a newbie, I would really appreciate if someone laid out the best practices involved in deploying to a standalone server - kinda like a DigitalOcean box or a VPS or something similar. Bonus points if your final project can be packaged and deployed with a single command. Massively multiple bonus points if your package can be dropped-in and installed like a WordPress installation. Double massive if you make the base package available as a cookie-cutter or a plain, old Django/Flask template! ;)
For gags and giggles, I give you the Highlander Pattern: class Highlander(type): born = False def __call__(cls, *args, **kwargs): if cls.born: raise RuntimeError("THERE CAN BE ONLY ONE !") # You cannot make more than 1 instance of a Highlander class, it's too dangerous to have 2 ! cls.born = man = super(Highlander, cls).__call__(*args, **kwargs) return man class MacLeod(object): __metaclass__ = Highlander man = MacLeod() man2 = MacLeod() # raises epic RuntimeError Now it's painfully obvious where you improperly share state.
PHP is web-app only right ?
what about it ?
I think you would be surprised about the speed of most of numpy's C code. The bindings to BLAS are well on it's way (it'll still take some time, I agree, but give us some time)
how much programming experience does he have ? what other (tech) skills does he have ? Pay is good in NYC but you need to be GOOD at it, very competitive. PS: He'll be competing against TONS of people, mostly from India
Never heard of Jr dev jobs, of any sort, in NYC. Been in this neck of the woods 12 years.
That wasn't exactly clear from your wording. "Use" is a very all purpose word. Just checkout a local copy of your new code and put it in the same directory as your application. The local directory overrides the global site packages. You can try this with anything mkdir requests touch requests/__init__.py Now fire up `ipython` and `import requests` you will get the one in your current directory.
why do this instead of just having a function that returns a global object? or just importing the global object you want to use directly
Just dropping in to say thank you for posting this!
Ah, well there's only one way to accomplish that, then. import foolib import widget.foolib as foolib2 There is absolutely no way to do what you ask without renaming one of the packages, whether you do that on disk or when you import.
Fair point, tho this is useful in situations where a class is actually needed (eg: for extensibility purposes) while still maintaining the single-instance-error-on-second-instance constraint. Why would want such a ridiculous constraint? Basically for all the reasons that a Singleton is bad - you're trying to use something that looks like local state (you just made an instance) but it's not at all. This sort of gymnastics are necessary in situations where you want polymorphism but your functionality will change the process in dangerous ways. Eg: instance 1 is created, sets up signal handlers, signal masks and all sorts of global changes to the process - do you really want to allow a second instance to exist and mess it all up ? Hell NO. EDIT: Some people call this 'defensive programming'.
You should really install all these in a venv and not mess with system packages. python3 -m venv some_venv_name python -m ensurepip --upgrade # needs 3.4
Just my own personal curiosity as I'm looking into the same thing.
Much appreciated.
First, I'd like to say that this is *far* from a complete project. On the contrary, it has just begun - I'm releasing it this early because I believe I've already reached the point where my package solves a problem that is not otherwise solved. The interface is inspired by Requests by /u/kennethreitz - I'm trying to treat the developer's experience the same as a Web UX expert would treat the customer's. Some high-level goals: I want to be able to support arbitrary altcoins, most of which are derivatives of Bitcoin. Because of this, I've written a generic `Key` class which handles dealing with translating from the various formats keypairs have. Over that, I have a class factory that provides the details that differ between altcoin implementations. Finally, I'm using this factory to create classes for the most common coins. Because of this, I see the vast majority of users simply using `from cryptocoin import BitcoinKey`. Power users who are working with an esoteric coin I've not dealt with can do this: from cryptocoin.key import key_factory EsotericoinKey = key_factory( 'Esotericoin', pubkey_hash='69', privkey_hash='96', ) From here, I plan to implement message signing, then transaction signing, and ultimately blockchain parsing and balance (unspent output) calculation. If you're interested in pitching in, the easiest thing at this point would be to implement new coins and add tests for them. While not complicated, it will help ensure that code I write going forward is generic enough to support other coins.
How's the performance using jython? Anyone played with it?
Pypy working on numpy support is great, and I look forward to the day when it is complete. But until numpy (and the ecosystem of other packages that depend on it) "just work" in pypy it will not be a viable option for anyone doing numerical work. We all kind of wish we could use pypy, but if numpy and the supporting ecosystem doesn't work (and I mean "just work" not "under development with full support coming soon") it's just not an option. We are talking about a community who still (mostly) use python 2.7 because they don't want to deal with the possibility that some of their packages might not work in python3. All the code being in matlab is a recent memory for many. You're not going to win these people over with partial support.
I kind of agree with Guido. This doesn't really remove the need for dict.get, which actually seems cleaner if not more obvious. Also, I feel that with generator expressions, lambda expressions, conditional expressions that it might make more sense to see if we can make all statements expressions instead of adding exception catching expressions. Or maybe we should jump right to the next step and introduce with expressions.
Alternately, you could just use macports. Its fairly trivial to install and maintain a pretty complicated scientific python environment (all of the listed packages plus a wide range of others like scikits, opencv, pyqt4, pandas, etc.) I've never really understood people's objection to macports - it really simplifies my life...
Installing scipy packages for Python3 on Mavericks, take two: 1. Install [Anaconda](http://continuum.io) 2. drink beer while the OP is still waiting for numpy to compile via pip, with less functionality as the OS doesn't have much in the way of acceleration for BLAS. 3. ??? 4. profit!
If I remember correctly, I used this in MacOS 10.8, but after the upgrade to 10.9 Mavericks I had some troubles with it. I think this was due to the GCC replacement by Clang (gcc is a symlink now). But it might be updated and okay now? 
Anaconda would be a legit alternative. However, I found it a little bit too "big" for my simple purposes and I wanted to have more control about what I install where. 
Hey man, I'm commenting to both say thanks and to save for later! I've almost finished the "learn python the hard way" and am hoping this can get me a bit farther
there's always their miniconda option that installs just python and the conda package manager. you then install only those packages you need.
Maybe so, but personally I rage every time I see a string literal passed to `getattr()` or `hasattr()`. It just looks so wrong.
What, did you think this was Ruby or ML or something? :-)
I have to say, Jessica is a great example of vocal fry
Global changes to the process should probably be done in a function called at startup or, if they're reversible, maaaaybe in a context manager. There's no point in having a class if you're not going to put some local state on an instance. 
I thought so. It's a shame. Anyway, thanks for the workaround.
Create envs with the packages you want. $ conda create -p ~/anaconda/envs/whatever python=3.3 numpy=1.8 scipy matplotlib ipython pandas
I don't like getattr either but I don't think catching AttributeErrors is much of an improvement. Maybe it's just the code I've dealt with, but I've found very few attributeError catches and I don't mind that they stand out.
Thank you!
&gt; If you need global state in your app, create an object and keep it in the global &gt;scope of a module Isn't that.... Java-y? 
I agree, this is something I would like to have, for the same reason: I feel like it would keep parts of my code a bit nicer. 
Can't unhear. As soon as someone pointed out that the offical matlab tutorial was full of fry I couldn't cope.
Ok, ur just trolling me now. Good work! You just contradicted http://www.reddit.com/r/Python/comments/20667r/how_can_i_use_multiple_versions_of_a_package_at/cg0zdm5 Do the rename and be done with it.
Look Before You Leap and Easier to Ask Forgiveness than Permission LBYL style is checking if a call is safe before making it, as in: if key in mapping: return mapping[key] EAFP style if to make the call and catch the possible errors: try: return mapping[key] catch KeyError: pass
This article is 6 years old. That guy had no idea what he was doing :-) Source: I am the original author. The general idea holds true: don't prematurely optimize. Write clean pythonic code until it's apparent that you need to speed up performance-critical parts of your code. In the past 6 years the tools have changed... Cython is still an option but in practice I tend to just put my data into numpy arrays or pandas data frames and use their built-in (and highly optimized) methods. The benefit is that vectorized operations are both faster *and* easier to read. PyPy and numba are also impressive in their ability to provide huge speedups with few code changes. They are great for standalone products but are more difficult to deploy/integrate with existing systems compared to writing your logic around numpy operations. 
Thank you for the detailed response! I still have a *lot* to learn when it comes to software engineering so I really appreciate nuts and bolts conversations about what, I am sure, seems pretty basic to more experienced people in the industry. I guess I still think that either way is just a slightly different way of cutting the same cake. Whether or not, at a technology stack level, you decide to write extensions or modularize by language you still are going to need people who know each different language/paradigm. For modularized design, you will straight up have to know the given language your modular sandbox is written in. Although it does eliminate cross-cutting frivolities. For writing extensions, you still have to know, to varying extents, the paradigms for the language extension you are coding for. Although it does, arguably, simplify some things from a hiring and specialist perspective. I have a sense...naive or not...that learning to write extensions is a bit easier a learning curve than learning an entirely new language. And, it does eliminate the overhead of managing an interface(s). I don't know which one is *more* prudent...although like you said there are limitations that accompany extensions, but if you can get away with it, I still think extensions are a pretty powerful design choice.
15 hours. That's nothing :) Honestly, you won't get it added unless it's a well used package. All of Anaconda's packages have to work together for a given distribution, so if you're just adding more work for them without a major benefit, you're not going to get added. Focus on making the package popular. I tried to get my package added to Python(x,y) a few years ago. There was a poll, and it had a semi-decent showing, but it fell below the cutoff point along with a few other packages that were in Python(x,y) and subsequently dropped.
Absolutely. Anyone who does any work in scipy, scikit-learn, pandas, GDAL, etc. assumes that numpy support is completely solid. Without that foundation in place, there's no reason to even consider PyPy aside from some stand alone scripts.
For many of us, Numpy is so intertwined with our use of python that it might as well be part of the standard library. Which it really should be IMO...
Writing the function itself in C is generally no problem. Writing the function in C so that it talks to the python API and can be imported as a python module... that is such a verbose, low-level, error-prone interface. Cython is basically a code generator to avoid having to deal with that shit. EDIT: Look at [this hello world example](http://en.wikibooks.org/wiki/Python_Programming/Extending_with_C#A_minimal_example) to see why the Python C API is so horrible and why Cython was necessary.
And pay for memory and context switch. 
I've actually done this when configuring loggers. Its not super mission critical, so I didn't mind making the logger a module-level global and then simply returning it if it was already instantiated. # myApplication/log.py _logger = {} def logger(name): global _logger if name not in _logger: _logger[name] = logging.getLogger(name) # configure custom logging return _logger[name]
It doesn't "stole" from anything. Golang's history as old as Erlang's one, and clojure is a baby compared with them both. Golang is deriative from aleph - first programming language for Plan9. Then were Limbo for Inferno OS, and some other. Now same authors accumulate all experience and build Golang. And, after all, I do not claim Golang is a perfect language. I think, its runtime is almost perfect. It definitely better than Python's tulip (and greenlets too), and I think, it is better than clojure's async and it is comparable with erlang's one (but Erlang have other goodies)
I'm not contradicting anything. I was wondering if you meant, for example, that I wanted to import foo@v1 and foo@v2 into widget, but I don't. I want to import foo@v1 into widget and foo@v2 into scrobble, but both widget and scrobble are loaded into the same instance of Python. Python has a single place for loaded modules, so even though each of these is pointing to different foo folders via relative imports (each at different git versions), one will win, and both will be using foo@v*n*.
Lots of comments below pointing out package-managed installations, such as Anaconda, homebrew etc. Some of which strike me as a little snarky, pooh-poohing the efforts of the OP. Well for those that intended that, snark back and pooh-pooh to you, too! Package managers have their place, and make things easier. But I, for one, would like to have the knowledge and ability to build my own Python environment natively and from scratch on my own box. And while the convenience of package managed Python environments are nice, they are no replacement for knowing and having full control of what goes on under the hood in your own home. So, OP, than you for sharing. 
Python just can't handle arrays without it. If you put it face to face with a program like Mathematica without Numpy it just doesn't compete. With Numpy it's a viable alternative, so I agree.
Unless you're somehow running Go without an OS (or in a DOS, maybe), context switches (I'm assuming you're talking about process scheduling, since context switches also occur twice for each syscall) will *always* happen. Modern systems also use copy-on-write semantics when forking, so memory usage stays nearly the same.
&gt; I think you would be surprised about the speed of most of numpy's C code. I am very well aware of the speed of numpy's C code and it's limitations. If the bulk of your day consists of multiplying very large matrices, you want the very best BLAS you can get, and that's not numpy's homecooked DGEMM.
I sincerely find the the python 2 vs python 3 issue extremely confusing and a bit embarrassing. So I wish it didn't exist.
Yeah, Python has a global namespace, so you will need to rename one of the foo, foo1 and foo2. I think you are conflating things by talking about widget and scrobble. I doesn't matter how many packages down you go, still a single namespace.
Yeah, we're on the same page. I fundamentally disagree with the way Python handles all this stuff, though, sadly.
Two unclosed brackets make me sad. ))
Might as well.
No, but it is strongly biased towards this use case.
I suppose that's a neat symmetry: pypy doesn't fully support numpy and numba doesn't fully support non-numpy. The next step might even be combining numba and pypy.
/r/pyramid
Luckily I don't know what vocal fry is, so I still don't have a problem :)
To me this is where requests comes into its own. I really don't get why urllib2 isn't ok for piping static HTML from a standard page into a parser, e.g. soup = BeautifulSoup(urllib2.urlopen(url).read()) but the moment you start talking back you should drop it and use requests.
They are porting numpy to pypy (numpypy), but the rest of the scientific stack will not be compatible (at least scipy)
urllib2 is broken in the age of the new web. It's a pain in the ass to do things that should be default. Would you use a browser that didn't support Gzip in these days? I doubt it. Why download data you don't have to. Requests automatically handles gzipped data if available. You don't want code like this littered everywhere: http://stackoverflow.com/a/3947241/2175384 That's just one example, there really is no reason not to just use requests. A good example of showing what you have to go through to make urllib2 sane at responses can be found here: https://code.google.com/p/feedparser/source/browse/feedparser/feedparser.py#3609 , they do a good job of it.
Not even going to justify this with an answer.
&gt; Do you know of a simple/automated tool to thunk C and/or Fortran libraries into high-ish level Python constructs? There are a few, but I'm not sure which is the best approach. * About 6 years ago I used SWIG: http://www.swig.org/ . Back then it mostly worked, and auto-generated Python classes from C/C++ header files. Getting it to work reliably in a build process was a pain though, and it couldn't handle complex C++ stuff. Might be much better nowadays, and might work great if you have just plain C. * Cython is supposed to support it as well: http://docs.cython.org/src/userguide/external_C_code.html . But I haven't tried it out, and it looks like you might have to write the header mapping yourself. * There's a bunch of other stuff at https://wiki.python.org/moin/IntegratingPythonWithOtherLanguages If you find something that works well, please do let me know too! I have a project coming up where I have to use a big closed-source C library (with headers provided) from Python. But the difficult bit there might be that the library makes lots of callbacks into user-provided C function pointers, and mapping these to python functions seems tricky.
Beazley's SWIG is what I had experience with, and it mapped my C headers (.h files, I don't use C++) ... directly. But to make it work in anything "pythonic", I needed to manually add a wrapper. Which is OK, if nothing changes. But it does. Thanks for your response. I am still looking! If I find something, I will let you know! :-) 
Actually he has some basis for EAFP over LPYL. In the glossary on python.org they make mention of the preference of EAFP. Now nowhere does it say LPYL is wrong. I personally go with what ever is cleaner or clearer and makes the most sense for my program flow. 
Beautiful.
I'm glad, they would add just too much stuff on a single line.
Okay, you convinced me, I added a section about Anaconda and Miniconda on top to let people now about this nice alternative(s) :)
This is something I never really got. Can you explain or point me toward a resource that shows how to use venv and why it matters? On a high level I get it, but I'm not sure how to actually get started and set up a venv and why I would need multiple for different installations. 
Thanks for the info. Did you remove the site? It is down... 
You don't need `global _logger` there, by the way, since you're not assigning to `_logger`.
2.6 is terrible, and the fact that CentOS doesn't ship with 2.7 out of the box (for some bizarre reason) is why my team transitioned to a different distro. 
Compared to what?
No?
Very nice, thanks!
For problem 1: Add the python scripts directory to your "PATH" environment variable. cmd.exe uses "Path" and git bash uses "PATH" for some reason. For problem 2: Always call "python" before the filename. So "python django-admin.py" instead of just "django-admin.py" When calling the file directly the system wide file type association takes precedence which is usually the default python.exe and not the virtualenv's python.exe
A lot of what I do for work involves the following: * Log into machine * Run a few commands * Log output * Exit It was a pain in the ass scripting all of that out in Python, so I just wrote a class that will do the same thing that takes the target's login info and logs in. Then you use the "talk" method to pass in a list of commands. The method returns a list of tuples, where t[0] = command run t[1] = text returned from that command Haven't tested it a ton, but it works on Python 2.7 with no external dependencies. Hope you get some use out of it. 
If you orphan a data structure, the visualization shows that the data is garbage collected instantly. It would be cool to add a feature to this visualizer that would also show some of the behind the scenes actions like garbage collection as well. (maybe have an option to turn it on and off, because I supposed it could be confusing for beginners as well.)
&gt; But I, for one, would like to have the knowledge and ability to build my own Python environment natively and from scratch on my own box Exactly! Thanks!
Try this build: https://build.opensuse.org/package/show/home:cavallo71:opt-python-interpreters/opt-python-hg89193
Alright, but my question is if there's an example of this being an actual useful thing to do. I don't doubt there is, I just can't think of any.
I know it's something Python does internally. I'm asking why would you ever want to create your own iterator
Yes, python is very well suited for doing something like this. You can use Beautiful Soup to scrape Reddit for your desired data. EDIT: On second thought, you could probably use PRAW (Python Reddit API wrapper) to simplify this even further.
Very elegant! Nice work taking the initiative!
Thanks! Standing on the shoulders of giants 
This argument could be made against every single expression-based syntactic feature. Comprehensions, ternary expressions, even statements via semicolons. If someone abuses these things, it'll make bad code, but a bad programmer can take almost any feature and make crap with it.
It took me ruining my Ubuntu install to learn this
Thanks, very useful.
&gt; Not incidentally, everything on code.activestate.com is a bad idea. Surely [Raymond Hettinger's recipes](http://code.activestate.com/recipes/users/178123/) are not (all) bad ideas? Didn't [named tuples](http://code.activestate.com/recipes/500261-named-tuples/) end up in the standard library? Or how about [Alex Martelli's recipes](http://code.activestate.com/recipes/users/97991/)?
As an example of the capabilities of Python: Reddit is written in Python.
This is a lot of fun to dump sorting algorithms into.
On line 14 why is the "hello" string shown in the left column instead of the right?
Have you looked at how `namedtuple` is implemented? You sure you want to call that a good idea? :) The "Borg" pattern is one of Alex Martelli's. There are probably some things on that site that are good by accident, but they're statistically insignificant. Avoid it entirely.
You might want to look into Python's [functools.wraps](http://docs.python.org/2/library/functools.html#functools.wraps) so that the methods wrapped by @before and @after keep the proper name/javadoc when printed.
I work in the healthcare space as well. We did this about 1.5 years ago - it can be done. Stay on it, you'll get it. If you need/want to outsource it, I'll ask my boss if I can help you with it. Boston in the house!!
&gt;I know that there are packages such as numpy but I would rather avoid them Why?
Forgive my ignorance. Thanks for clarifying. 
Everything is also the JSON, might be best for the real simple stuff: http://www.reddit.com/r/Python/comments/20bw6k/im_thinking_about_learning_python_but_have_close.json
I didn't ask a question nor beg a response. Titling this "Everything about web scraping in python" (or "Python web scraping resource") was entirely inaccurate. Your article failed to live up to this title and, really, should've been taken down for misleading link text. Your blog is also not a wikipedia page, so the idea that this is a "work in progress" is a silly excuse to generate pageviews.
I am interested in this as well. Let me know if you come up with possible solution/answer for it.
Why not just use brew or macports?
What is this "javadoc" you're talking about?
&gt; He'll be competing against TONS of people, mostly from India I'm a programmer living in New York, and I'm really, really dubious about that "mostly from India" part. It's not that there isn't offshoring, I see it quite frequently. But these guys aren't doing full-stack Python development, or as far as I know, Python development at all.
Yeah, I am not a fan of the messy look created by the (unnecessarily) repeated strings for printverbose. I quite like your idea, and at some point in the near-ish future I will probably implement it. I kept it conceptually simple for now, but will definitely clean it up later. Thanks for the suggestion!
I Love python, and I am developing a large website at the moment in it. But I always try to use the best tool for the job at hand. I use Cython and Jython sometimes as sometimes one needs speed or interfacing to someone elses libraries. Whenever I want to scrape websites, especially for phone numbers names etc, I use REBOL and the parse dialect. I have many small scripts for this type of service in the 20 to 30 lines area. Have a look at the sample code at rebol.org and you just might have relief. Rebol is not fast as far as running goes, it is just incredibly easy to do what you want. Sometimes you need a car sometimes a truck and sometimes a hammer. 
I'm just going to say that you just haven't seen it, because if what you're saying is true then it is also true that some how Python development is immune to off-shoring. I'd say that yes Python is far less likely to be off-shored simply because of scale/volume - Python is just not as popular a tech IN LARGE CORPS as java, c#..... My comment is strictly in the context of light-experience/low-cost python development.
Not strictly true, you can have pointers to them still. You can attach the same int 257 to two names x and y for example: &gt;&gt;&gt; x = y = 257 &gt;&gt;&gt; x == y True &gt;&gt;&gt; x is y True and this is different to: &gt;&gt;&gt; x = 257 &gt;&gt;&gt; y = 257 &gt;&gt;&gt; x == y True &gt;&gt;&gt; x is y False But for short strings and small ints (&lt; 257), CPython caches them in memory and so the second example would return True for the 'is' comparison still. It's a little odd, but the 'names are attached to objects and there can be multiple names attached to the same object' concept remains true regardless of whether the objects are immutable or not.
No course credit for using numpy?
How the hell do people remember this?
This is much harder to automate than you'd think. You can scrape for phone numbers and emails, but coordinating them to the right people and departments is a serious challenge. You're better off buying a contact list from a data broker or outsourcing the extraction on Mechanical Turk.
The short strings/small ints quirk is an implementation detail, so it's not something any well written code should ever rely on. You should almost never find yourself doing an 'is' check on immutable data. As for the 'everything is objects and names attach to objects', well, that's easy to remember once you've learned it because it underpins absolutely everything in the language and makes a large range of gotchas no longer surprising.
&gt; Which it really should be IMO... Things go to the standard library to die. The release schedule is fixed an you'd never be able to do something like get a new version of numpy on Python 2.7 despite it being more popular than Python 3.x for scientific computing. You can still get current numpy/scipy/matplotlib/wx to work on Python 2.4.
excellent point. if only there were some reliable, standard packaging system to manage python dependencies.. 
&gt; But I'm not sure how much it would help for non-numpy code. It's better on non-numpy code than it is for numpy code. It'll often slow down numpy code.
Info: While studying CFG's sometime last year, I wrote a parser to read python's grammar file and construct a flow chart from it. This was the result. I had to make it big for it to be legible. Printed out it makes a pretty cool poster, it took 12 pages I think? I just found this svg tonight and thought I'd share. Seeing it laid out like this actually helped me to understand Python (and CFG's in general) a little better. edit: forgot to add, imgur won't host SVG files. Not sure if there's a better image hosting site than this one.
I wondered the same thing at first. The answer is: because of the "inline primitives and nested objects" setting. You can change it to show all references as such, but it'll make the display much more messy. For example, `x = [1, 2, 3]` is rendered as x pointing at a list, which in turn points at 1, 2, and 3. I kind of wish there was a half-way setting: always have variables rendered as pointing at values, but inline "primitive" values inside of objects.
The one you chose is [open-source](https://github.com/MediaCrush/MediaCrush) *and* written in Python &lt;3
The fact that you are dealing with multiple websites for the same data, which are all in different formats probably means it's going to be really tricky. One idea would be to write an engine with some control flow to direct to the correct website and do specific scraping. For example, find all the sites that have a similar structure and write a 'sub engine' for that site. Rinse and repeat. This would be a lot of work, no to mention the brittle nature of webscraping... you might find the maintenance is a full time job.
beautiful!
Yeah, if you're dealing with matrices, it's hard to advocate using anything else.
Any comparison with zodb?
Now do C++!
I don't think it matters, map just requires any iterable so repeat and [n]*10 should both work. Potentially, using repeat might reduce the max amount of memory used, it might make it possible to pass the data to the subprocesses without creating duplicate copies in the current process - but on the other hand, i don't think [n]*10 actually copies the object n but simply creates a list of 10 references to it. Worth investigating.
good idea - I went through a lot of pain trying to do manual installs before I realized these packages did what I needed - they are all the average scientist needs and you should probably only do a manual install if you have special reasons for it.
I was thinking recently if there is a MongoDB-like pure Python database. Thanks for this.
It _is_ garbage-collected immediately. CPython uses reference counting as its primary method of lifetime tracking, GC is only used to collect objects that hold references to each other. And it's not triggered until the number of currently allocated objects doesn't grow by 20% or 700 ([by default](http://docs.python.org/2/library/gc.html#gc.get_threshold)) since the last allocation, whichever is greater. Though it doesn't show uncollected garbage even if it [should exist](http://www.pythontutor.com/visualize.html#code=class+C\(object\)%3A%0A++++pass%0A%0Ax,+y+%3D+C\(\),+C\(\)%0Ax.y+%3D+y%0Ay.x+%3D+x%0A%0Ax+%3D+1%0Ay+%3D+1%0A%0Aprint+'lol'&amp;mode=display&amp;cumulative=false&amp;heapPrimitives=false&amp;drawParentPointers=false&amp;textReferences=false&amp;showOnlyOutputs=false&amp;py=2&amp;curInstr=6).
&gt; Change all of the functions in this file into methods on that class. The tricky part is implementing the decorators then. But it can be done rather beautifully by implementing them as methods on Event, this way you can write @sleep.before def blah(self): ... and that gets rid of the dispatching by a string literal as well.
You could try taglib: http://taglib.github.io/ There are Python3 compatible bindings: https://github.com/supermihi/pytaglib There is also mutagenx, a python3-compatible version of mutagen: https://github.com/LordSputnik/mutagen
I actually sort of like the idea now that I understand it, but the motivating cases in the PEP are too weak. I do know, however, that I've often found myself wishing for something similar when writing a comprehension.
Wow, everything is so clear now. 
The main idea was to create a singleton class because I wanted this instance to be the only entry point to communicate with the website. However, it does not 'support' correctly concurrent call with different TV Show. Eg. thread 1 looking for 'TV_Show1' and thread 2 looking for 'TV_Show2', there will be a problem. Don't you think it was not worth it to implement it as a singleton ? 
Minimum we'd hire a dev for would be 90k, max for a new hire would probably be around 125. The figure would be based on your skill level. Although you'd need to be either an incredibly strong systems programmer, or a capable systems programmer with a domain speciality to really get onto our radar.
Look into what beets uses, it has some good examples.
Any instructor prohibiting usage of numpy for numerical computing should feel bad. If OP is a student and his instructor does that, he should feel bad too for having people wasting his time.
&gt; zodb I have to admit that I was unaware of zodb (https://github.com/zopefoundation/zodbdocs), it looks interesting though. The main motivation behind Blitz was to create a database that would be comparable to MongoDB in querying capabilities, but which could be used without installing any 3rd party software. So I think the main differences are the expressive query model and the possibility to use it as a frontend to other database engines, most notably MongoDB.
Thanks for your message, feel free to contact me if you want more information about BlitzDB or if you should run into any problems using it. we also have an issue tracker on Github: https://github.com/adewes/blitzdb
I do a lot of this kind of work and it really depends. At my last gig, we were getting graphs in PDF's and were expected to parse that :omg: I pushed back on that one :-) If every page really is different, then you'll have no choice but to write code to scrape each one individually. However, that's rarely the case and there will usually be sets of pages that have enough in common to allow a single scraper to work on all of them. For example, they were all written by the same person who just wrote the first one, then copied and modified it for all the subsequent pages. Or the pages were generated by the same CMS. And so on. You just have to dive in, take a look at it all, then figure out the best approach. It's definitely possible, but it's impossible to say beforehand how much work it will be. Scrapy and Python are great for this kind of work and while having structured, consistently formatted data certainly makes the job easier, it's not essential. 
Python 3.2 is an odd target for python, it's typical to do python 2.6+ &amp; 3.3+ because pre 3.3 python 3 releases didn't have good python 2 compatibility. Also, forward porting python 2 libraries isn't too hard if you use the `future` library, and the library has a good test suite.
Where's the Python?
What do you mean by using it as a frontend to MongoDB?
Though if it's an algorithm class...
Here's a direct link to the python repository https://github.com/ignacioelola/price_monitoring
&gt;if you try to connect with your lib on cisco equipment with your lib, you will fail to have any results I noticed a similar issue with some equipment that I use where it's a serial port served to a network with a serial server. Trying to implement a fix for that now. &gt;Yes, when a problem is not new, it means someone might already have solved it. A fair criticism. For some context, I wrote this so I didn't have to use some ancient spaghetti code that other folks I work with wrote using Net::Telnet. I also vastly prefer working in Python to Perl, so I'm playing to my own biases as well. However, I DID do a little googling looking for something like this, and came up with nothing. I'd never heard of pexpect until now; will definitely check that out. And I know about telnetlib - if you check out the source code, you'll see this is really two layers of abstraction on top of telnetlib. There's nothing wrong with telnetlib; it does its job just fine. But I find I write a lot of boilerplate with telnetlib (logging in is kind of a pain), and I wanted to do away with it. This was what I came up with, and I'll be the first to admit it's neither perfect nor original. 
Here are a few: http://bit.ly/1lDxgXl http://bit.ly/1lDxkGz http://bit.ly/1iJENqa
This is gold. I'm passing it along in an email.
I know bartenders that make more than your avg programmer in NY.
Well, BlitzDB supports multiple backends, which are responsible for storing and retrieving documents from a database. It comes with a native, file-based backend but also includes a backend that is a wrapper around MongoDB. So you can do e.g. the following: from blitzdb import FileBackend, MongoBackend #we create a document author = Author({'name' : 'Oscar Wilde', ...}) #creates a file-based DB in the local "test_db" folder file_backend = FileBackend("./test_db") from pymongo import MongoClient #Connect to a MongoDB database through pymongo mongo_db = pymongo.MongoClient().test_db #Creates a MongoDB-based backend mongo_backend = MongoBackend(mongo_db) #We save the document in both backends. mongo_backend.save(author) file_backend.save(author) In this sense Blitz is like SQLAlchemy in the sense that it puts an abstraction layer between you and the physical database, so you can use it with existing database systems.
This is for the first time I am using Parsley. So, any suggestions to improve the parser grammar is welcome :-)
The difference is that Erlang processes do not share state and coroutines do.
Python is gifted. It is fairly easy to backport code from perl or ruby, and to bind with libraries in foreign language (fortran, C, C++...). So, not wanting to code in Perl or ruby does not mean you can spare time by porting code into python or lurking what is done outside of the python ecosystem. I checked for instance pexpect is a port of tcl expect module in python. WSGI stack is inspired from ruby, flask from sinatra... You may have bias, as I do (I prefer python too), it does not mean you cannot not be opened minded. More than the code/syntax, the design matters. And the reason why you want pexpect or alike, is because even if a session in telnet is synchrone, interacting with a process through fd/fh is asynchronuous, you have to handle events (such as the pager, timeout of the socket). That is the core of the problem of interacting with a shell. You don't program sequentially in a telnet context, you are interacting asynchronously with a process. @immibis TIL is different of «look I have something that can help you»; by not using expect or asynch layers we have a NIH that could be a regression from the state of the art. I don't disdain his work, I am ticking on the title of the news: I just say someone who might find it "useful" will soon come into trouble. 
I thought it wouldn't be GCed until the variable was out of scope of the current execution.
But we are talking about what happens when you assign a different value to the variable. Since nothing holds a reference to the original value, it's immediately destroyed.
Your sarcasm was very convincing.
Price monitoring? I can only imagine that some greedy fucking asshole would want to do this. Why not write code to make society a better place? 
Clue me in to a project that I could start that will help make society better and that is interesting and I will start on that project. I wanted to save money. How is saving money being a greedy fucking asshole? Knowing that a company will change a price based on things like time of day is interesting data.
What an unfortunate name.
Anyone care to explain me what this is? I'm just a passer-by with absolutely no clue.
[Disco](http://discoproject.org/) seems like a more Python-friendly stack. Does anyone have any (positive or negative) experience with it?
what does this do that I can't do with requests and html parsing?
Are you talking about the Definitely bot? I only used it once or twice just to see if it worked, it was more of a learning experience than anything. The AMA notifier one doesn't spam anything, you just run it and it'll PM you updates from the AMA. I don't see how any of this is spam.
It looks like the website is taking it upon itself to generate "useful" graphs?
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Backus–Naur Form**](http://en.wikipedia.org/wiki/Backus%E2%80%93Naur%20Form): [](#sfw) --- &gt;In [computer science](http://en.wikipedia.org/wiki/Computer_science), __BNF__ (__Backus Normal Form__ or __Backus–Naur Form__) is one of the two main [notation techniques](http://en.wikipedia.org/wiki/Metasyntax) for [context-free grammars](http://en.wikipedia.org/wiki/Context-free_grammar), often used to describe the [syntax](http://en.wikipedia.org/wiki/Syntax) of [languages](http://en.wikipedia.org/wiki/Formal_language#Programming_languages) used in computing, such as computer [programming languages](http://en.wikipedia.org/wiki/Programming_language), [document formats](http://en.wikipedia.org/wiki/Document_format), [instruction sets](http://en.wikipedia.org/wiki/Instruction_set) and [communication protocols](http://en.wikipedia.org/wiki/Communication_protocol); the other main technique for writing context-free grammars is the [van Wijngaarden form](http://en.wikipedia.org/wiki/Van_Wijngaarden_grammar). They are applied wherever exact descriptions of languages are needed: for instance, in official language specifications, in manuals, and in textbooks on programming language theory. &gt; --- ^Interesting: [^Extended ^Backus–Naur ^Form](http://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_Form) ^| [^Augmented ^Backus–Naur ^Form](http://en.wikipedia.org/wiki/Augmented_Backus%E2%80%93Naur_Form) ^| [^Context-free ^grammar](http://en.wikipedia.org/wiki/Context-free_grammar) ^| [^Metasyntax](http://en.wikipedia.org/wiki/Metasyntax) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cg2pu4f) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cg2pu4f)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
The main incentive for using PyPy is for the increase in speed although in some corner cases someone may use it for reduced latency or reduce memory utilization. In many cases increasing the speed of execution has some monetary benefits. Such as if you have a web server that executes twice as fast you may need only have the number of servers to meet demand. For some that could be more than enough of a benefit to port a few CPython extensions using cffi. In most cases it's not like your porting over all the code for a given library but merely changing the wrapper code that exposes the library functionality to Python. Although, in some cases it may actually make sense to port a library written in another language to a pure Python library as the PyPy JIT has a greater opportunity to optimize it. Which approach to take depends on many factors. Such as how much work is performed in the library vs the over head to make the call into the library, how optimized is the current library, how much benefit you get from each porting approach vs the effort involved to do the port, etc.
...you probably don't want them using scikit-learn. You probably also don't want them using a lot of canned high-level stuff you'd reach for in an instant in the real world. OTOH, do you really want students reimplementing the basic linear algebra subprograms?
I don't think the syntax supports ML/Haskell style pattern matching since failed destructuring throws an exception. It's mostly syntactic sugar on top of if/else cascades though, isn't it?
Given that both Hadoop and NLTK are generally extremely slow at what they are built for (distributed computing and language processing, respectively), I assume that you might need a pretty nasty cluster just to perform equally to a well designed single-machine approach using LingPipe, OpenNLP, or Stanford Core NLP. And there is no way I'd believe Hadoop+NLTK can come even close to distrubted NLP systems such as GATE or UIMA with the same number of nodes.
Why does this post's title sound like some sort of crazy sex move?
Thank you, sir!
For libraries that already mostly invoke logic inside of C code and BLAS/LAPACK routines and only occasionally call back into the Python interpreter to yield a result, what place is there for PyPy to do drastic optimization? Which is my point, is that a lot of these libraries are not perfectly optimal but they're optimal enough to get the job done and there's drastic diminishing return in optimizing further especially if that involves a new implementation of a library. If anything the selective specialization ( C Extensions, Numba, Parakeet ) approach to this problem seems like a much more economical solution to people who want to invest time and money into making the hotspots in their code faster without having to reinvent the entire ecosystem to do it. It's not solution to the general problem at all, but strikes a nice balance between effort and performance.
So it's excel? I'd love to hear from /u/chrisalexander on this.
This bot has been done already, sorry. http://www.reddit.com/user/definitely_a_human
We contribute a lot of code to Reddit Enhancement Suite, including support for MediaCrush. Are you using the latest version of RES? /r/Enhancement may be able to help you get updated. There is even better MediaCrush support coming in the next RES update. [Here's some code we've offered to RES](https://github.com/honestbleeps/Reddit-Enhancement-Suite/pulls/SirCmpwn?direction=desc&amp;page=1&amp;sort=created&amp;state=closed), by the way.
I did something similar, using boto, and without using nltk for tokenization. I will check out mrjob. [code](https://github.com/raresct/freq_words_religion) Caveat: it's not documented (yet). I did a wordcloud (see .png) of 351 religious, philosophical or just weird texts from http://www.sacred-texts.com/download.htm . I managed to extract 343 of them, then ran a counter and sorter on Elastic Map Reduce from Amazon Web Services. Using 8 instances instead of 1 reduced the counting step from 43 minutes to 7 minutes. P.S. The word "page" is an outlier, I leave it to you to mentally erase it from the image.
Yeah, $5 off on a piece of electronics. What an asshole. Guess the kids won't get that in their college fund then. Dipshit.
Probably because you need to go for a run or find someone else who's into streaming double pendulums as much as you are.
the app doens't have write access to twitter, so you can't post with it. sending tweets is on the list of things to do -&gt; https://waffle.io/a-tal/pyweet it authorizes with your account because it can display your own timeline, and twitter likes to track people who use their api endpoints. I'm sorry that `pyweet -s` is terminating preemptively for you. does it exit with on an error/traceback? I don't have a mac shell to test on, nor do I know currently why the mac terminal emulator can't display a standard python print statement, but it sounds a lot like a bug with os x or it's terminal emulator (or it's included version of python). If theres any more debugging info or a traceback that you can provide, I can try to take a look at it (as much as I can without having to buy something from apple)
&gt; ver = "\n".join(sent for sent in nltk.sent_tokenize(raw)) FTFY. There's no need to build a list if you're sending the output into a function looking for an iterable.
I was just curious as to your design decision. I never formally took a software engineering class, so I'm always curious to understand the reasoning of how people implemented things. But personally, since you have only 1 class (aside from your exceptions), I would have not wrapped it as a class and kept the methods at the module level. Seems like it would accomplish the same thing, and it would make it easier to implement. Just my inexperienced opinion though.
&gt; Is there maybe an alternative for windows? http://www.ubuntu.com/download 
One can easely use coroutines without shared state, there is no prohibition of that. Beside separate per process GC there is no benefits from explicit prohibition of shared state. And erlang has shared state with ETS, and it is even not garbage collected :-) it is just heavily synchronised shared state (well, as well as separate database like MySQL, PostgreSQL, etc, but embedded)
Are there any stats on the game libraries most used? I thought PyGame was not being actively developed anymore...?
Cool, I am by no means a python expert. Thanks for the pointer.
Pygame isn't, but a colleague and I are working on something we think is a little better called [Spyral](https://github.com/platipy/spyral). We haven't done a big release yet since it's currently being bug tested by a classroom full of students, but it'll probably be ready by May. Still, our [documentation](http://platipy.org/en/latest/) is around and I think things are going super well :)
I will keep an eye on it! Thanks!
I'm not sure if you were unclear or I am just lost. I will say though: often when a programmer thinks "I like this thing from language X. How do I do it in language Y?" the problem can be that you're not coding the way the language is built. Consider having a look at Python code which accomplishes similar things to what you want to do.
HR = bozos. Can agree. Most of them are. One recently called me up and asked what is my work experience in Django. I told her a basic shopping cart app but I'm good in python, told her to see my computer vision project in python. She says that doesn't matter. I ask her why the fuck not? I made a computer vision app and know python better than most beginners, do why am I no good? Simply because I didn't have enterprise experience with Django dev. What the fuck. That, after she told me that the profile was for freshers with knowledge of Django and python. My brain had fucking melted that day. And I promised myself to make efforts in game dev instead; fuck these assholes.
&gt; One can easely use coroutines without shared state, there is no prohibition of that. Wrong.
It's been a while since this was updated - but I remember it worked beautifully when I used it 10 years ago: http://candygram.sourceforge.net/ - Erlang style pattern matching and process tracking
This must be an old article, because it's missing [generator send and throw](http://docs.python.org/2/reference/expressions.html#generator.send). More info: http://legacy.python.org/dev/peps/pep-0342/
I *love* generators. They're arbitrarily composable, and because they get evaluated depth-first they're very cache-friendly and fast. And they can be made to have very low overhead, because each generator in a chain can do its setup once and then drop into a tight for loop. Generators are fantastic.
I speak parse.
&gt;oaepub In verdana, the name of your program looks vaguely Cyrillic.
[release announcement](https://plus.google.com/+AnthonyScopatz/posts/8xWA7hfiL9R)
In your first paragraph it looks like you describing a scenario where say 98% of the run time is in the extensions. For this scenario, PyPy or any other approach will offer no additional benefits over just using CPython as at most all you can expect is the optimize the remaining 2% of the run time. I agree with you that many libraries used in extension are optimal enough. In order for these libraries to be used within either CPython or PyPy they have to be wrapped in some way. At a high level there are 2 approaches. Use the CPython CAPI or a foreign function interface (ffi) approach. For the CAPI approach, you can manually write this wrapper code, use Cython, SWIG, and a half a dozen other ways. For the ffi approach there is ctypes and and now cffi. In the past the ffi approach had too much overhead added to each function call so it only made sense to use if you make relatively few calls to the extension. For this reason, most extensions that needed to be called in an optimized way, were developed with the CAPI approach. The problem with the CAPI approach with respect to PyPy is that it exposes things that should be considered implementation details of CPython such as reference counting. For PyPy to use libraries that have been wrapped with the CAPI, it must emulate these implementation details which can add a significant amount of overhead. For PyPy it just does not make any sense to use the CAPI approach when performance matters which is why cffi was developed. The cffi approach to wrapping external code is far simpler and much closer to an ideal approach than doing it with the CAPI approach which can be very error prone and requires understanding many of the internal details of the CPython implementation if you decide to manually write it (of course almost no one writes it manually which is why there is so many helper libraries to write CAPI extensions). PyPy wants you to be able to focus on writing Python code and aims to make it so that it in many cases it will optimize the code so that you don't have to write specialized extensions. Ideally this is what we all want, to be able to be productive using just Python. But of course, to be practical, there still is a need to take advantages of many important and often critical libraries that were developed in other languages which PyPy prefers to be called through a cffi wrapper. The key thing to realize is that under PyPy there is a change in preference to how external libraries are wrapped. For CPython when performance is critical it is to use the CAPI but for PyPy it is best to use cffi. So we are not talking about the need to rewrite the external library but to rewrite just the wrapper to the library. Now not every library is performance critical. For these it just makes sense to write these today using cffi. They will run fine in CPython and under PyPy. For libraries that perform a large chunk of work in the extension vs the overhead associated with the external function call it also makes sense to write it in cffi so that only one wrapper needs to be maintained. For all other cases it makes sense to maintain both a CAPI and a cffi wrapper. Although, this is not ideal to have to maintain 2 wrappers, the cffi one is quite simple compared to the CAPI one that it only adds a small additional amount of effort to create and maintain both wrappers. For some libraries that perform relative small amounts of work during each external function call it may make sense to reimplement them in Python. That way the library is easier to maintain as it will be written in Python and the PyPy JIT can optimize a larger portion of an application that uses it since PyPy can not optimize the code executed inside extensions. But don't let the previous paragraph make you feel that PyPy wants everything to be reimplemented as that is not true. PyPy wants you to be able to write more of your code in Python and not have to worry as much about converting your code over to another language to fix every hot spot in your code.
&gt;ImportError: threading not supported :(
 xo my.file
Hm..command not found - do I need to add it to path or something?
Easy to write small things when you're standing on the shoulders of awesome package dependencies!
If I hold down an arrow key the cursor seems to move slower than in any other application. Limitation of the libraries used maybe?
This seems like a very unhelpful and discouraging comment to me, even tho that may not have been your intent. Maybe the project does have big dependencies, but the beauty of Python is it's available libraries. And I think comments like this might discourage a new programmer from beginning or continuing a project. Even someone just reading this sub to decide if they want to learn/continue learning python. I for one am impressed OP. I may take your advice and try making my own text editor. 
After installation I get this: $ xo usage: xo [-h] path xo: error: too few arguments ============================================================================= $ xo ehh.py Traceback (most recent call last): File "/usr/local/bin/xo", line 9, in &lt;module&gt; load_entry_point('exofrills==0.1.7', 'console_scripts', 'xo')() File "/usr/local/lib/python2.7/dist-packages/xo.py", line 843, in main main_display.main(line, col) File "/usr/local/lib/python2.7/dist-packages/xo.py", line 616, in main self.walker.goto(line, col) File "/usr/local/lib/python2.7/dist-packages/xo.py", line 454, in goto self._ensure_read_in(lineno) File "/usr/local/lib/python2.7/dist-packages/xo.py", line 412, in _ensure_read_in next_line = self.read_next_line() File "/usr/local/lib/python2.7/dist-packages/xo.py", line 392, in read_next_line edit = LineEditor(edit_text=next_line, **self.line_kwargs) File "/usr/local/lib/python2.7/dist-packages/xo.py", line 210, in __init__ super().__init__(edit_text=sanitize_text(edit_text, tabsize), **kwargs) TypeError: super() takes at least 1 argument (0 given)
I also found [the generator tricks for system programmers](http://www.dabeaz.com/generators/) quite interesting.
&gt; relies on Python 3 Here you go.
Came here for the same reason, saw this, called it a day.
I have Python 3 installed. The first line of xo.py is "`#!/usr/bin/env python3`". The command `python3` starts my Python 3 interpreter.
Try env | grep python And see what the python3 output is. Also, you could plainly try env python3 Or maybe which $(env python3) (Sorry, am not at terminal so can't give better advice off hand nor test my suggestions for usefulness)
I don't have any plans to to switch from vim, but 800 lines is sweet. I might be able to add vim keybindings and make it modal.
When you type "xo" it tries to launch it with python 2.7. That's your problem.
Django has more batteries included, allowing for a quicker startup of projects.. it also features a community vastly larger in size (which means a lot of plugins that will probaly cover most of your initial needs); and some big names in the industry (like Mozilla).. this gives people the idea they can trust django more than flask.
How to tell it to use Python 3.3? And if the first line of xo.py indicates python3, why is it not taken into account?
I don't think there is much difference in the philosophy of Pyramid and Flask. Both does the same work but slightly in different way.
Try py xo.py and tell me what happens.
I get this: /usr/local/lib/python2.7/dist-packages $ python3 xo.py /tmp/na.txt Traceback (most recent call last): File "/usr/lib/python3.3/site.py", line 75, in &lt;module&gt; import os File "/usr/lib/python3.3/os.py", line 659, in &lt;module&gt; from collections.abc import MutableMapping File "/usr/lib/python3.3/collections/__init__.py", line 17, in &lt;module&gt; from reprlib import recursive_repr as _recursive_repr File "./reprlib.py", line 3, in &lt;module&gt; from repr import * ImportError: No module named 'repr' The problem can be that `pip` installed it in `...python2.7/dist-packages`. Is there a `pip3` command?
OK, problem solved. If you have Python 2.7 and Python 3.3 on your machine, here is what to do: (1) install `pip3` as explained [here](https://stackoverflow.com/questions/11268501/how-to-use-pip-with-python-3-x-alongside-python-2-x) (2) `sudo pip3 install exofrills` This stuff should be in the official documentation... (edit: layout)
A related tutorial I wrote a while ago: http://eli.thegreenplace.net/2013/01/16/python-paralellizing-cpu-bound-tasks-with-concurrent-futures/ It also links to earlier articles that use other approaches for parallelizing (like `multiprocessing`)
Not really. It's very easy to hide a ton of programming behind import statements. Saying this is for "when nano is too much" is just plain stupid. I'd be like me saying "I wrote a bash script that does everything nano can do! In just one line of code!" and the it just being nano $1 It's interesting to see how far you can push a language in a certain direction to make your life easier, emacs is after all just a bunch of lisp macros for text editing, and it's something worth while in its own right. Trying to oversell it isn't. 
I have written projects in Flask/Werkzeug and recently gave Django a try on a fresh project. I'm quickly regretting it. Django interfacing takes up the majority of the code, makes it harder to reason about and I generally spend more time thinking "Ok, so what X do I need to Y" than just doing the sensible thing and returning a JSON string or whatever. This is probably my fault, as the project is very RESTy, so Django probably wasn't the best choice. Django REST framework was nice, until I had an edge case that required writing custom authorization classes and whatnot for a single endpoint. I get it, I get why these things are good ... but I want to *implement* and get things working, not try and build a cathederal of abstraction that i'm probably going to knock down anyway when feedback comes in. My current Django app then needed Websockets so I used nginx and Node, then quickly switched Node for Go. All Django now handles is handling static file pipelining, authentication and spitting out a Javascript app. Yea, it might be the wrong tool for the job, but I see a narrowing band of cases where Django is the RIGHT tool personally. In future i'll stick with Flask/Werkzeug and SQLAlchemy. Django's strength however is that it is Big Framework, so you know instantly when inheriting a codebase where things will be (or should be). This is like the Java syndrome where good structure saves money during development in teams where communication is key. While I found Django great up to the first 60% of a project ... I tend to find the last 40% you're fighting the framework. YMMV.
At the same time, the advertising is false to me as well, so I wanted to point that out. IMHO '*ridiculously* lightweight' and 'uses pygments' shouldn't fit in the same sentence, and it also undercuts the immense utility the libraries provide by making use of them. 
Very nice!
Martijn, you are doing wonderful job with Morepath. We were looking at Pyramid as a framework to use for our next big project and got very intrigued by your novel but very promising approach. Your take seems to be more streamlined and purposeful. Do not let naysayers to discourage you. When are you planning to have Morepath released? We are eager to try it. 
Even if you restarted ?
Well, if we're allowed to import libraries, how about: from PyQt5.QtWidgets import QApplication, QMainWindow, QPlainTextEdit import sys the_app = QApplication(sys.argv) the_window = QMainWindow() the_editor = QPlainTextEdit() the_window.setCentralWidget(the_editor) the_window.show() the_app.exec_() Granted, I estimate I would need another 100 LOC to add the File menu for New, Open, Save and Save-As, and another 100 for a Find dialog with full PCRE support. About 200 for syntax highlighting. OTOH, QPlainTextEdit supports text drag and drop and an undo-redo stack out of the box.
Why would you want something like that? To me this description screams "XY PROBLEM!!!"
&gt; I'm not really sure if this should be posted in /learnpython or not but I'm pretty sure I'll get a more definite description here. I like to help people but one big difference I think between /r/learningpython and /r/python is it's assumed that you already have some basic knowledge over here. It also also generally assumed that when you ask a question you provide all the necessary information so whomever posts a reply won't have to guess. So with that, I think you're going to have to explain your intent more. You're not describing what the class needs to do and with the minimal information here a metaclass would be complete overkill. Some will disagree but unless you know you need a metaclass, you probably don't need a metaclass. Without any additional information, the best I can do for now are some short examples which might give you some options. *These are not metaclasses,* but I seriously doubt you're going to want a metaclass based minimal information in your post. The following are some examples how how you might do something similar. The below was tested with Python 2 since that's probably the same as your system default, we're also assuming here that input to each function or class is always a string: from collections import namedtuple Noun = namedtuple("Noun", ["text"]) foobar = Noun(text="foobar") print(foobar, foobar.text) # (Noun(text='foobar'), 'foobar') class Noun(namedtuple("Noun", ["text"])): def __repr__(self): return "%s(%r, hex=%r)" % ( self.__class__.__name__, self.text, self.encode()) def encode(self, encoding="hex"): return self.text.encode(encoding) foobar = Noun("foobar") # could have used a keyword too print(foobar) # Noun('foobar', hex='666f6f626172') # It would probably be better to use the class above, just because # you *can* do this does not mean you should. def Noun(noun): def init(self, text): self.text = text def encode(self, encoding="hex"): return self.text.encode(encoding) def repr_(self): return "%s(%r, hex=%r)" % ( self.__class__.__name__, self.text, self.encode()) noun_type = type( noun, (object, ), {"__init__": init, "__repr__": repr_, "encode": encode}) return noun_type(noun) foobar = Noun("foobar") print(foobar) # foobar('foobar', hex='666f6f626172') &gt; Is it possible to have a meta class which creates those classes? Kind of, but using something like `type` or subclassing from `namedtuple` might be easier. It mostly depends on what exactly you need the class to do. So yes it is possible but more than likely not really how you want to do it. &gt; And if so, would I use a new -style class? Yes and in general unless you know you need an old style class, use new style classes, always. If you're using Python 3 this is a requirement. &gt; Can meta programming be explained in a big picture? I suggest you do some reading, there's lots of resources out there but here's some which should give you a decent idea: * http://python-3-patterns-idioms-test.readthedocs.org/en/latest/Metaprogramming.html * http://stackoverflow.com/questions/100003/what-is-a-metaclass-in-python (first two answers) 
*slicing* is relevant, so: for i, friend in enumerate(friends): friend.eat(cake[i::len(friends)]) Also, make sure you're the first in the list ;)
Yes. Uninstalled twice, restarted twice.
I stopped reading when I pressed the down arrow and the website wouldn't scroll. 
After you append this path to sys.path, you should be able to import ftpmirror. But just copying it into your git repo and including it in your normal deployment process is probably less of a hassle.
Great but hard. I only managed to make a 256 tile.
 globals().update({ name: type(name, (object,), { 'spam': lambda self: 'albatross' }) for name in ['a','b'] }) print a().spam() print b().spam()
This is probably not the way to go about things but I just started learning with python and django. I chose django because I felt like there were a ton of apps that I could use to get my site online quickly. I'm still very much a novice with python and at this point and feel like I know just enough to get myself into a hole and have to get someone with more experience to get me out. With ready made apps, I can plug and play and get things running without expert level knowledge of python. For example on the site in building I used userena for member signup, signin, profile, forgot password, change email, email activation, etc. That was all built in and it took me a week or so maybe to fumble through getting it installed and configured. If I had to do that same thing in flask or other framework without the help of an app, I honestly wouldn't even know where to start. 
Are you using ART ?
Did you guys take a wrong tu/r/n and forget to bring your sense of humor? This is /r/Python, right? Are you going to complain that `import antigravity` doesn't actually allow you to fly? For example, `xo` is an editor that prides itself in the shortness of its name: exofrills now has 50% less characters in its name than other industry leaders! vi 2 vim 3 nano 4 pico 4 xo 2 cat 3 less 4 emacs 5 Maybe it's because I know Scopz and find him funny, but perhaps you'll feel better know he wrote [XDress](http://xdress.org/) - a automatic wrapper generator for C/C++ written in pure Python whose tagline is "Goes all J. E. Hoover on your code."! 
Just because it's a joke doesn't mean it can't be a bad one. If what was said was merely akin to "Look at how you can combine some cool python libraries really simply to make a half-decent editor!" I'd be absolutely fine with it, and only think "yeah, that is cool" (I still think that anyway). Taking away from their massive contribution to the simplicity by starting to mention LoC is kinda banal, and the less keystrokes joke is just tired, it's been done a thousand times now (see `ag` for a recent example). Maybe I'm old and grumpy.
You need to install xo with a pip that's running/installed on your python3, not your python2.
Thanks, but I am on ubuntu and python is already in my path AFAI..
You could also use something like QScintilla. Here's a GTK3 equivalent: [http://i.imgur.com/EqqMpoA.png](http://i.imgur.com/EqqMpoA.png) In as little as *36* lines of code you get syntax highlighting with support for lots of languages and different styles, line numbers, undo/redo, automatic indentation and smart caret positioning on Home/End! ^\* ^gtk3, ^gtksourceview3, ^pango, ^cairo, ^python-gobject, ^Xlib, ^wayland, ^icon ^themes, ^syntax ^definitions, ^and ^styles ^not ^included. ^Additional ^terms ^and ^restrictions ^may ^apply. ^Please ^consult ^your ^system ^administrator ^before ^using ^the ^product.
Thanks. I guess all the Kivy's app might be in trouble cause of ART, i didn't got a chance to look at it yet, none of my device have the latest android version :/
Ah, good to know! So as long as we make a 1.0 release on or before April 11th, it'll be kosher for developers?
First, Django has been around much longer, so - yes, it's going to be much more widely used because of legacy codebases. There's no need to rip out Django, if it working and replace it with Flask. Second, you can get an application up quicker, in most cases, with Django . Django has a number of "batteries" included, plus the framework abstracts much of the development process. So you can write less and do more. You can focus less on those common parts of every site and focus on your product - and how to differentiates from similar products. Third, I used both Django and Flask. It all depends on the project. Fourth, look at the community. Both communities are large and hugely supportive, but perhaps Django has a slightly bigger community. Fifth, look at the packages and modules. How many are there for Django vs Flask. Plus, since Django has been around longer the code base is more mature and battle tested; and the same goes for the packages. Sixth, if you're a beginner, go with Flask. You have to do more, but you learn more. Develop with both. See which you like better. For example, I did the Django Polls tutorial in [Flask](https://docs.djangoproject.com/en/dev/intro/tutorial01/) and the [Flaskr](http://flask.pocoo.org/docs/tutorial/) tutorial in Django. Try that. Seventh, want to learn both? Check out [Real Python](http://www.realpython.com). I am a co-founder. We work through many of the same apps in Django, Flask, and web2py. 
I made a mistake, this will be resolved in few hours :)
Correct the hilarious typo in the loop variable though :)
If you know she'll get the reference, you can do cake = Cake() cake.lie = False
How is Kivy? Was this your first time using it? Would you recommend it?
I like this, anything for doing awesome in school? 
Django has been around in some form since 2005, Flask was initially released in 2010. Ignoring everything else, the tool that's been around for twice as long will probably be used more in the real world. Aside from that, Django gives you less flexibility but more built-in features. It'll save you time with things like authentication, but as others have noted, you may end up fighting the framework to do non-standard tasks. 
what does bootstrapping mean in this context? how was the first version made, if it was made with itself? also, [ed, man!](http://www.gnu.org/fun/jokes/ed-msg.html)
&gt; like treating integer division as float division, So like Python 3?
Why not just see if you can load python onto a TI calculator?
This is a very old problem. When I wrote the graphing calculator "sheet" for the eMate almost 20 years ago there was the same problem. TI owned K-12 and all the teacher resources were set up for it, enough so that I made a pretty serious effort to make the formulas interchangeable. (e.g. type "sin" instead of pressing the sin key, similar constraints on graph params.) Sadly eMate was canceled before we could really see how successful this was. But a similar project for the web and tablets would be really interesting! JavaScript would be just as practical as Python...
Definitely in Java - not so much in Python. [Performance of code using exceptions is within the same order of magnitude as code without](http://stackoverflow.com/a/2522013/1348109) Edit: Yes it's slower, but not enough to care about
Definitely going to try it out. Anyway, you have a typo in your Google Play description: "[...] itself based on 024 by [...]", it should say "1024".
I'm one of the author, and yes, i'm loving it. The game was working after 2 hours coding.
Thanks, fixed :) (give few hours for Google to update the description now...)
Doesn't have to be a 1.0 release - just *a* release with docs :) But yeah, that's the deadline.
from the [announcement](https://plus.google.com/+AnthonyScopatz/posts/8xWA7hfiL9R): "I bootstrapped it from the edit.py example in urwid."
rock on tito
My issue with try-except blocks is they're confusing and tend to allow bizarre conditions through assuming I'm not defining 20 exception classes, which is also stupid. If people would just use if-else loops, they'd be better off and find unplanned issues sooner and their code would be a tiny bit faster. I think there is a total misunderstanding of: &gt; It's Easier to Ask Forgiveness than Permission It should be used sparingly.
&gt;I think we should do away with TI calculators, and math students should use... ...pencil and paper?
Oooops =)
Nice game! My highest score is 2496 &gt;.&lt; !!! 
Lots of fun. 2.5 is wicked old, though, I wouldn't use it for a new project. For this project, I'd suggest 3.3, because it's unlikely you're going to use any libraries that aren't ported to Python 3 yet.
DUNDUNDANDUNDUNDUNDADADADUN
so he used edit.py to write the first working alpha, and then wrote the rest using the incremental versions?
Sounds fun. Is it like angband or more like "You see a grue, attack?" And don't things go alpha-beta-...gamma?
Haha fair enough. I'll tell my colleague and we'll plan for April 11, then!
But why?
I went ahead and mashed the keys and hit 3200. Is that good? Perhaps I should just read the instructions haha. 
xo.py isn't the script that's being run. The script called "xo" that pip installed is what's being run. It sounds like you installed it with pip for Python 2.7. You need to use pip for Python 3.3.
Yes, that is exactly right. And I messed up a few times and had to start from scratch :). Version control was super helpful here!
Your rouge did not make it through the maze then :(
&gt; I'm creating it in Python 2.5 Don't do that. Do it in 2.7 or 3.3. I'd also suggest looking into PyGame.
You could do this now with an iPad. The question is do you really want to do that. After all mathematics is not programming. 
Uhuu!
Strange. I had no issues with ART on the most recent CM snapshot on my Nexus 5. 
Great game :) Couple of bugs, though - first, I get random crashes, particularly on the first 1-2 moves of the game. If I can get 5 moves in, it seems stable. I'm running Cyanogenmod 10.1.3 (Android 4.2.2) on a Samsung Galaxy Tab 2 7" (GT-P3100). That's a 7" phablet, for reference. I'm about to swap to another phone, so I'd be willing to send you this one if you're interested in testing and just have you send it back when you're done. Also, there's a slight difference in your version in the web version - only the first pair seems to combine on any line. For instance - let's say the top line consists of 2244. In the original, moving right would result in the top line becoming 48. In your version, it becomes 228.
Thanks for the honest assessment. Too many times you see articles where someone is asking "which &lt;enter type of software here&gt; is better?", and all you get is "Oh, this is so much better than all the rest" opinions. Its nice to see someone give an opinion based on their experiences with a couple of the softwares in question. 
You dont really use a calculator in calc 1 and above anyway...
I did. In Calc 3 we even used "Maple" for weekly lab assignments. Maple is like a "babys first matlab" sort of thing. Between calc, chem, and physics the only no-calculator class was pre-calc/trig. 
I am glad braces will not be a feature that will be coming in the future
I'm still holding out hope for braces...
I teach Python in an American high school. Have to admit I've been wondering if I should switch to Javascript.
Ever heard of IPython?
My advice would be to work on your own project (game, utility, etc). That way you can learn the language and if you find a bug or feature you'd like to add to an existing project you could maybe contribute that way. You'd then be using/testing/enjoying what you're working and contributing on. If someone emailed me and said "I've programmed for a couple years and just started learning python can I add to your code base", I'd be hesitant (after finding out how much that person actually knew and the experience they had/the quality of their code).
Mathematics software is extensively used in applied math courses. For example, nearly every one of my applied partial differential equations problem sets required the use of Mathematica.
I don't understand why programming isn't taught in math. my coworker has a degree in applied math and didn't have to write any code. hmm... you know what's a great application of math? computers!
Just to re-iterate what others have said: Use python 2.7 or 3.3. 2.5 is way to old to be using for a new project.
I'm a TA in a college intro to programming class in Python. Switch to JavaScript only if you want the kids to make pretty Web pictures. Python is more appropriate for teaching computer science basics without being shocking or useless.
I can! Pen and paper is tedious, error-prone, and limited to the abilities of manual work. 
Sounds like a raspberry pi kickstarter to me. It's got it all. Programming, education, raspberry pi's, DIY...
I've been working on this IDE for about 2 1/2 weeks now. My time has mainly been spent on the debugger. It runs in it's own thread and has a fair amount of complexity. I would love for some other people from the Python community to contribute / help out.
&gt;@ will be used frequently -- in fact, evidence suggests it may be used more frequently than // or the bitwise operators. Personally, I use // frequently and the bitwise operators occasionally. I don't touch matrix code. Perhaps the author meant to write "it may be used more frequently *in numerical code*"?
Gah. Python 2.7. We're teaching 3 and not going back :(
nope, I'm pretty sure the author meant in aggregate, the entire corpus of python code, @ will be used more than //. I've used // maybe once or twice, so this seems plausible, see the chart of operator usage, though it only queries 3 numeric libraries + the stdlib, so it hardly represents a totally fair characterization of the entire corpus of python code.
IMHO discrete mathematics comes up a lot more often in development than continuous mathematics, since data science is intricately related to discrete mathematics. And in discrete math, `//` and `%` are a lot more useful than `/` (or indeed `@`). Or maybe I just write [unusual code](https://bitbucket.org/NYKevin/nbtparse/src/tip/src/minecraft/terrain/cVoxel.pyx?at=default#cl-132).
Have you herd of Node.JS?
&gt; construct I've never heard of that before. What is it? Also, this is Cython code, called in a very tight loop. If you're suggesting I call into a Python library of some kind, that's almost certainly a non-starter.
You'll need more than float division to do what common math software and calculators do. For example the precision used is usually better than that of [float](http://docs.python.org/2/tutorial/floatingpoint.html), sometimes even [arbitrary precision](http://en.wikipedia.org/wiki/Arbitrary-precision_arithmetic).
Yeah, I realized it was highly optimized after a while looking at it for more than a minute. But [construct](http://construct.readthedocs.org/en/latest/) is a binary parsing library. So you specify a "grammar" then you can transform data from python data-structures back and forth to packed binary data. It's a pun on "struct" (both the python module and the C type). But you can do things like specify an array of structs with 4-bit members, and then pack/unpack them. Code is very clean, looks really nice. The new version (construct3 by tomer filiba) is working on a compile to native code option for speed, but it's in the planning stages at this point.
Why doesn't it combine multiuple tiles that are in the same line? like, if there is 2244 and i swipe right, i should end up with 48 but instead i get 228.
Django strength for me is the ecosystem of easy to plug app: contrib.admin ( or other admins), forms, tastypie,...so I don't have to reinvent the wheel again and focus on doing my app. It takes a bit of learning compared to Flask but it's far easier to get the job done in my opinion. Especially with django 1.7, in a few minutes I have an admin interface, an authentification system and an api, compared to Flask where I have to put all the piece together myself ( taking the risk to lose time and/or to shooy myself in the foot with a bad integration) I also find the django structure really flexible (compared to rails or other kitchen sink frameworks). Like, you can put apps inside apps or you can have a custom ORM/template engine. My 2 cents
/r/ipython
I don't do much numerical computing, but why not use `**`? Is there already an often-used meaning for `matrix1 ** matrix2`, or does the precedence/associativity not match up with what is intended?
Indeed. Instead, we should teach kids to use these calculators to create their own functions for equations- I had mine do equations with 3 variables where all I had to do was input the values in the equations. This might seem like taking a shortcut, but the only way I was able to do it was by understanding the math behind it in the first place. Did the same thing for having it do the quadratic equation. It requires a much deeper understanding of the math, just so you can have a shortcut later. Plus, it's absurdly fun once you get it to work.
"Python Scientific Lecture Notes" **http://scipy-lectures.github.io/** https://github.com/scipy-lectures/scipy-lecture-notes
 Khan Academy seems to do a good job with presenting or not presenting a calculator for introductory algorithmic exercises. https://www.khanacademy.org/library #Math Realistically, I never use a graphing calculator to write reproducible, testable, verifiable analyses. In retrospect, I would have much rather been required to deliver a Python script which produced reproducible, testable answers. AFAIU, there's no analog of `%logstart -o problem_1.py` with existing graphing calculators from any manufacturer. I think understanding math as the tests for science is crucial. * http://www.reddit.com/r/Python/comments/1drv59/getting_started_with_automated_testing/c9tfxgd * http://www.reddit.com/r/programming/comments/1lgvw1/why_graphing_calculators_are_more_effective_to/cbza8zt * http://www.reddit.com/r/math/comments/1sfijx/do_any_of_you_know_of_any_good_graphing/cdxamh5 * http://www.reddit.com/r/compsci/comments/1tjmd4/high_schools_not_meeting_stem_demand_only_9/#ce8slqw
* http://code.org/educate * http://code.org/learn * https://www.khanacademy.org/science/computer-science-subject/computer-science (Python) * http://www.reddit.com/r/IPython/comments/1dl8wc/seeking_advice_for_introducing_ipython_in_high/c9rws29 
This might be Python 3's killer feature over Python 2.
http://docs.python.org/2/library/decimal.html From http://www.reddit.com/r/Python/comments/1k31m9/pep_450_adding_a_statistics_module_to_the/cbl5nj8 : &gt; From [here](https://github.com/brandon-rhodes/pyephem/issues/20#issuecomment-20021367): &gt;&gt; (TIL [Python floats](http://docs.python.org/2/tutorial/floatingpoint.html#representation-error) are like [IEEE-754](https://en.wikipedia.org/wiki/IEEE_754) [binary64 doubles, which have 53 bits of precision](https://en.wikipedia.org/wiki/Double-precision_floating-point_format) and that [BigFloat](http://pythonhosted.org/bigfloat/) wraps [GNU MPFR](http://www.mpfr.org/) in order to utilize arbitrary-precision arithmetic, while [gmpy2](https://gmpy2.readthedocs.org/en/latest/mpfr.html#multiple-precision-reals) implements "a new *mpfr* type based on the [[MPFR](https://en.wikipedia.org/wiki/MPFR)] library".) ... sympy also wraps MPFR: http://docs.sympy.org/dev/modules/mpmath/technical.html#precision-and-representation-issues
Throw the source at your students and tell them to update it! Great way to teach them how to deal with that kind of thing (which isn't too uncommon a thing). Then again that may be too difficult for them depending on their experience (because they're still being taught it's probably not an option for them yet).
wxPython does not support Python 3 at all. In addition to that, wxGTK (the Linux version of the library it binds to) depends on GTK2, which is *also* outdated.
I know this is a Python thread, but couldn't the argument be just as easily made that something designed specifically for math would be more appropriate such as Octave or R? One thing to consider on a graphic calculator is that there just isn't much screen space. With the required indentation of Python, you're looking at just 2 or 3 levels in and there's no space left on the screen. Plus these devices are small with tiny keyboards - it would be challenging to type programs with proper variable names, functions, classes, etc., just to do your math problems. For me, I'd rather have a small computer where I could run anything I want. But if I must have a calculator, I'd prefer something purpose-built with a good form factor like the HP48G. It's even programmable if there's a function I need that it doesn't already have. The other thing to consider is that a TI or HP calculator turns on instantly and runs for months or even years on a set of batteries/single charge. That said, maybe I just lack the vision you have - the best way to show me up is to just design the darned thing and prove me wrong.
Teachers and school establishments will not let this happen. They are stuck with this status quo and will keep it that way for atleast another decade. If they did this, the teachers would *shock* ...have to learn something new.
You should really organize the project structure a little better and not just put all files together, and use `.gitignore`. You should also include a license file...
Why not open source it now?
Terrible idea in my mind. With all the standard symbols available in Unicode you think they could come up with something better. Something that might relate somewhat to the math world. By the way, yes I think it is time for computer languages to move belong ASCII text range. 
I did this, but I distributed the programs I wrote to my classmates. I benefitted from a deeper understanding of the math, an introduction to programming, and greater respect from my peers. I helped some slackers skirt by, so I guess it could be argued I slightly hurt society. But I highly doubt my quadratic program was the sole reason these people were able gain a high school diploma.
Absolutely. I find it fascinating and a minor pain in the ass to use. Moreover, a good friend of mine whose knowledge is only limited to JS is now considered a potential programmer in demand, which I think is exciting. However, it is not the exact same JavaScript you'd run in a browser, and it is still a bad language to introduce fundamental computer science concepts. Source? Anecdotal evidence from small samples of my school's IT department and a couple of their students [re-]taking the reworked Computer Programming class we have in the compsci department, and I TA for next quarter. I'm on the ground floor of the kind of place that helps produce poorly-trained programmers. Our computer science department just relieved Visual Basic with Python to great effect, and it makes me happy to see the strict demands we [python users] make of our documentation and readability working - albeit begrudgingly - to start making better programmers. Better yet, it has made me, someone who has been involved in computing his entire life [literally], a better programmer. If that is being done in JavaScript, please show me so I can beat people over the head with it. :)
Maple is babys first matlab? They are totally different things. Matlab is numerical (just get a value out of your equations) and Maple is meant to be used symbolically (like get 'sin(x+1)' as your answer). Both are higher level tools, you probably just never touched the advanced functions.
Brain damage, in your case.
I don't care for this at all. The whole argument hinges on "I want to express my mathematical formulae like a mathematician would on a piece of paper" instead of taking advantage of the imperative, self-documenting nature of Python code. 
** is already taken http://docs.python.org/3/reference/expressions.html#operator-precedence 
Well, there are the Compose key on X11 and Option+* combinations on OS X.
I don't like it because I would not use it, but the PEP is well-reasoned.
I do not think linear algebra can be coded in a sufficiently self-documenting way that you can avoid having to read the paper to understand the algorithm. With that in mind, it should be coded in such a way as to make it easy to understand the correspondence between the code and the paper, and the README should include a URL where the paper may be accessed for free by the general public. tl;dr: Decomposing subspaces ain't like dusting crops, boy.
Portable Raspberry pithon calculator, dude, this is my next project O_o
That's not a very good reason to dislike something. 
That's not what I was arguing. Only that adding more obtuse Perl-style operators to Python to satisfy the demands of a mathematician who does a lot of dot products seems like a silly thing to me. His only argument is that it "makes it look like a mathematical formula" -- a specious argument in software development, where this complexity can be captured in a comment and with judicious use of variable naming and function composition.
Some of the scientific python projects such as `statsmodel` and `scikit-learn` need help if you want to help with reading research papers, implementing algorithms, and speed things up using `Cython`.
Agreed I switched too and not going back.
They did the better part of a century ago. We stopped because it was a bad idea. We're fortunate you don't have any impact in this area. And BTW, if you RTFPEP, this is discussed.
So, your argument is "I don't use it, so it must be useless"? Thing is, a lot of people using Python are not software developers, but researchers. And if you have ever tried implementing any method that involves linear algebra, then you *would* quickly notice that lacking a matrix multiplication operator is really annoying. Looking at my own attempts to move my department from MATLAB to Python, the lack of matrix multiplication operator is one of the things I am most embarassed about, since the readability compared to MATLAB is a lot worse. Example: MATLAB) xhat = K * R_1 * R_2 * X Numpy 1) xhat = np.dot(np.dot(K, np.dot(R_1, R_2)), X) Numpy 2) xhat = K.dot(R_1.dot(R_2.dot(X))) So, if we want Python to be a good tool for scientists/researchers, this is really a good thing. Personally, I hate the choice of symbol, but I agree that it is probably the only possible choice.
Python's known for its simplicity and the fact it doesn't have a million operators or other terse language syntax. That a bunch of scientists have started using Python -- indeed, *exactly* because it's easy to use -- and now want the language remade in their image is not a smart decision. I didn't claim it was 'useless' either; why do you persist with your strawman arguments? I can think of many features that I, in my own world, would love to see in Python. If I had my way it would basically be LISP. However, I do realise this is not for the good of the community nor what most people want. Python's a conservative language and adding random operators to appease a handful of scientists who can't handle prefix notation is not going to sway anybody. 
__^[wow ^so ^verify]__: ^/u/noreallyimthepope ^-&gt; ^/u/Rubykuby __^Ð50.000000 ^Dogecoin(s)__&amp;nbsp;^__($0.0417516)__ ^[[help]](http://www.reddit.com/r/dogetipbot/wiki/index)
You are literally awesome. Thanks!
It's not a random operator. It is a highly useful operator to make Python even better for scientists, or anyone else who use matrix arithmetic. Calling the scientific community for "a handful" is also quite absurd. It is likely one of the areas where Python is most used. And as someone who styles myself as both a software engineer, and scientist, I think this is something the Python community as a whole should be very proud of. I can see your point as well. But in this case it should no harm to people who do not use this operator and will be very useful for those who will.
Wouldn't a better notation be `&lt;a, b&gt;`?
For matrices though? What would be the use for exponential calculations with a matrix as both left and right argument? Scalar ** matrix only works for some matrices, matrix ** scalar only for some scalars and both are rather uncommon cases.
1. It's definitely going to be the latter, angband seems to be ASCII, and I have no experience with ASCII art in games. 2. No. Gamma is developer only, alpha is first version that players use, then beta, then release.
For now, EasyGUI. I know it sounds weird, yes, but I don't have that much experience with Pygame... Probably when I know enough, going to do some big update which changes the library from EasyGUI to Pygame anyway. Any things you think would help at all?
I think most of the kivy devs use vim, but plenty of people do use other text editors or IDEs. What operating system are you using? If it's windows (and possible osx) you'll need to tell pyscripter where to find the kivy distributed interpreter for it to be able to find the kivy libraries. Other than that, can you give more information on the problem?
I want to participate. I hope there will be good prizes, though I don't expect to win.
I have no anecdotal evidence (supporting JS over Python) as for I'm in no means interested in academia but I feel that it has some of the very basics that can be used for programming and shouldn't be ruled out. I actually wrote the curriculum for a computer science class at the high school I went to and the language they learned was Python using resources such as CodeAcademy. 
My mind went to that hardware issue first too. But then I went and counted the keys on a Ti-83+, the main key area consists of 8x5 keys (plus five function keys). I'm away from a real keyboard but my android keyboard is 10x4 keys. So at least by count it seems within the realm of plausibility for hardware design. That and if you knew the keyboard would be for a specific purpose a designer could optimize the layout some. Like make parentheses and the basic infix operators easily tappable with only one tap. 
It doesn't matter if you are new to programming, things like "idea" and how engaging the app will be given equal weightage with the rest of the things. Making it easy for even newcomers to have a chance to win the contest.
no.
Take the example from the PEP, which one is easier to read: S = (H @ beta - r).T @ inv(H @ V @ H.T) @ (H @ beta - r) or S = &lt;&lt;&lt;H, beta-r&gt;.T, inv(&lt;&lt;H, V&gt;, H.T&gt;)&gt;, &lt;H,beta-r&gt;&gt; The whole point is having an infix notation. Your proposed syntax only removes a few chars: ``np.dot(A,B)`` vs. ``&lt;A,B&gt;``.
Oooh. Open-sourcing our curriculum would be pretty neat. :D
Yup, open-source is a great aspect of programming. 
Numpy 3) xhat = K.dot(R_1).dot(R_2).dot(X) Really not that bad I think.
Should be a good choice. Python is a great language for engineering projects too.
Hi I work for a national lab (engineering background)and use the [PythonXY](https://code.google.com/p/pythonxy/) distribution which is a great distro you may want to look at as well. Made the transition from matlab very easy. 
I looked a bit at PythonXY and it seemed to be the most popular right now. But I was concerned about it not supporting python 3.x which I think I should learn (still new to programming in general) if that's what the future will move towards. And I couldn't find anything saying they had any intention to make an updated version that supports 3.x. 
The Blackberry, despite all it's crap, has an excellent keyboard. I can type as fast as on a regular keyboard on there almost. So it is possible to make a tiny yet good keyboard:)
But then it would cost 200 dollars. 100 absolute minimum.
Ah that makes sense. Yeah as far as I am aware it is still 2.7 based.
best solution would be to build this for Python3 using PyQt5. 
Forgot to mention that the good reputation of PythonXY helped me have confidence in WinPython because it's being developed by the guy who also does PythonXY.
Alright, with the help of [John](https://github.com/johncipponeri), all of the files are now organized, .pyc files are removed, the setup file works, and I fixed some bugs involving image assets! Right now I'm working on improving the theme.
Well, i don't know enough about both math and python to give you a really good answer. Maybe ** could be overloaded, but then its meaning would change depending on data types of its arguments, which i think is ugly. @ isn't pretty, but you won't see it most "normal" / non-numeric code; and if it appears somewhere in an expression even a beginner will go "huh, what's this.. better look up what that @ means", rather than beeing lead down a red-hering path because it is also the power-operator. 
A lot of the trig identities is just the pythagorean theorem in code. 
Sounds neat! Consider python 2.7 and libtcodpy. I would love to see the source. I want to work on something similar. Good luck!
Elementwise exponentiation. `[[1, 2], [3, 4]] ** 2 == [[1, 4], [9, 16]]`, `[[1, 2], [3, 4]] ** [[1, 2], [3, 4]] == [[1, 4], [27, 256]]`, etc.
do you have all the special characters on it?
And thank god for that!
Not to be a contrarian but I'm not sure of the practicality. Not every kid can get their hands on a smartphone, certainly not across all ages. Plus they would just facebook. Hell, even the TI's were mostly used for games when I was in HS.
Actually it does. Someone really put a lot of thought into it.
True, but if you just program them into you calc early and space out until your test your won't even pick up on that. It might not be a perfect example. I am a big fan of the idea in general though it's just there are some issues.
wxPython's importing is very... obfuscated. You pretty much have to individually import all subpackages and rename them normally. I fixed the wx.stc and fixed the issues you left. Thanks!
Currently I'm seeing a [~16x speedup](http://nbtparse.readthedocs.org/en/latest/nbtparse.minecraft.terrain.html#cvoxel-module) for certain operations by using Cython instead of Python. I'm not giving that up for cleaner code.
I believe pythonxy actually uses the spider IDE. It is quiet nifty.
Well done guys, i'm not able to go further than 1024 &gt;_&gt; Even one guy commented on the play store that it crashed at 4096. An Achievement and a color have been added for it :)
The crashes was my fault, i give java a python object, but i forgot to keep the reference of it. So when Python GC collect it, and when Java will try to access it, there is a chance of the memory pointer goes to nothing. If it goes to a valid python object, it will just throw and ignore a Cython exception. And the 2244-&gt;48 is fixed too. All the fixes is in the 1.2.0 version, which should be available within the next hours on Google Play. I've haven't been able to upload any graphics / apk the whole day, Google Play was broken (for many developers &gt;_&gt;).
I remember that sheet. It was pretty amazing at the time. 
Scrapy definitely doesn't expect structured and consistently formatted data. Heck, any scraping framework which expects that is definitely doomed ;) Disclaimer: I work for Scrapinghub which is the biggest Scrapy sponsor nowadays (it was founded by Scrapy creators). We're also behind Crawlera, a PaaS HTTP/HTTPS proxy downloader that's got a rotating pool of IPs all over the world to handle hardcore banning-techniques bypassing: http://www.crawlera.com
I used scheme as a calculator for years. I now use ipython. Back then I wrote a ton of bond and tvm calculations and would use it to check my math. These days I verify my test data in Python as I write my junit tests.
Keep us updated please. (i think reddit is all I go on) 
How hard is it to make a traditional Android app using native UI features in kivy? I looked at kivy once briefly but didn't find anything on making Android UI components. 
This is a great idea, and I'm somewhat surprised to see this much skepticism in this thread. It's unfortunate that there isn't a better operator available, but after reading the PEP, I think `@` will work nicely. The great thing about Guido van Rossum's (apparently imminent) approval of this PEP is that it acknowledges the growing scientific user base. It's good to know that, as a scientist, I'm a first-class citizen of the python community.
&gt; Maybe ** could be overloaded, but then its meaning would change depending on data type I don't follow. It means exponent. Scalars have well defined meanings for exponents and so do matrices.
&gt; With all the standard symbols available in Unicode That was discussed in the PEP. It's a common key on all keyboards. Also, what other symbol would you propose? That was also discussed in the PEP and other symbols honestly aren't any better. The author made a very good case against using unicode symbols.
That's exactly what I thought. Sadly numpy, scipy, and scikits aren't going to upgrade anytime soon. It's the first compelling reason I've seen to upgrade since I don't care about unicode and it's a good one.
&gt; That a bunch of scientists have started using Python -- indeed, exactly because it's easy to use -- and now want the language remade in their image is not a smart decision. This is a bit dramatic. Scientists don't want the language *remade* in their image: they want the addition of a single operator that is absolutely fundamental in mathematics, and which would make a large amount of code easier to read, write, and maintain. Python could be made a lot nicer for scientific programming; scientists use it in spite of its syntax, not because of it. 
Dang. That's what I thought. I just want to write a simple Android app that uses the maps api using python =/. Why couldn't Google have picked python! 
What is that supposed to mean? NumPy has supported Python 3.x since version 1.5.0 (released 2010-08-31) and SciPy since version 0.9.0 (released 2011-02-28.) And adding support for the new operators in a way that's backwards compatible with 2.x is not hard at all, since it's just a matter of defining a handful of double-underscore methods, a choice which can very easily be made at runtime based on version number. You already have to do such things for Python 2/3 compatibility, e.g. `__str__` vs. `__unicode__`. 
That's pretty impressive, I might have to work on the cython backend to construct3 some more... except I have like so many side projects that are actually almost done, like pylib7zip &amp; quamash... plus there's like my actual work that I get paid for.
Yeah, there isn't a "matrix multiplication" symbol, so I think @ is a good choice.
We just added custom keybindings that the user can set in their config file. vim key-bind away!
To be fair, this particular data structure is basically a specialized 3D array (and therefore all the common operations are O(n^(3)) for side length n). I could probably implement it in terms of numpy, but learning Cython felt like more fun, and I also wanted to keep the internal data format as close as possible to the on-disk format (which I don't have control over).
BTW: Is there a Python Police?
Irrelevant. This is not a conflict with the proposed syntax.
Readability counts.
What I mean is array can support it, but any code using C = A.T @ B @ A that has to also work under Python 2.7 won't be supported. They would still be typing C = dot(dot(A.T, B), A) inside scipy. It's not until you deprecate Python 2.7 support that you can upgrade the core of numpy, scipy, and scikits.
It doesn't really remake the language - if you don't in fact use matrix math, you'll never see it, so it won't affect you in any way. Of course, in this I'm biased, because I'm one of those pesky scientists using python :-) Seriously, the lack of a simple matrix multiply operator is a real pain - linear algebra notation is itself a method of expressing complex ideas and procedures in a compact readable form. Requiring you to use a kludged syntax for it makes it much harder to implement many algorithms*, and is the number one reason I can't get some of my colleagues to switch to python from Matlab. *readably, correctly, and quickly. I find it trivial to do it wrong... 
I came from Perl, so I think it's a totally reasonable character and $ for scalar, but to be clear, Perl is a horrific language. @ means array to me. The baggage is actually helping @.
Why does it matter what's in the internals of the modules? The point is that you as an end user want to use the new feature, no? There's nothing preventing code you write from using the new syntax, even if the internals have to use the traditional syntax to remain compatible. 
Timing smacks into PyWeek (announced 4 days ago) rather badly :(
Nice, I think I'm going to give a kivy a chance now. :)
Work on your project and browse open source Python projects and try to help when you can. I would say once you learn some frameworks very well you can start doing freelance work. When doing freelance work you should never start out with doing it for free, but if you doubt yourself on your task for whatever reason tell the potential hirer that you are new to a certain concept/explain to them that it might not be "good enough." If they still wish to pay you after then go for it. Personally the only time I code for free is when I'm coding for me.
NumPy can support the feature for users who are using Python 3 (and who don't care about Python 2) without themselves using it *in their own code*. I don't see how that's at all confusing. The internals of NumPy have no bearing on what end users can do with it. Say that Python 3.5 ships with the new operator, and NumPy 2.2 ships with support for it. People writing code that must be consumed by both Python 2 and 3 can continue using NumPy 2.2 and using the old syntax just as they always did. People that want to use the feature can install Python 3.5 and NumPy 2.2 and write code using the new operator. It will require Python 3.5 and NumPy 2.2 to run, of course, but maybe that's fine -- perhaps the script is part of their research or is specific to their company. Lots and lots of people write code that isn't distributed, and have no reason to care about backwards compatibility. The point is that everyone can make that decision for themselves. There's nothing holding back this fictional NumPy 2.2 from supporting the feature for people that want it because of concerns of backwards compatibility. Everybody wins. 
I think you meant to respond to the comment above mine, because I totally agree with you! This thread is interesting, because it seems to indicate that a large portion of the python community is not sensitive to the needs of scientific programmers. If that is indeed the case, then we have a serious problem. 
I find it strange that authors of new libraries think they have to support Python 2. The reason people still use it is compatibility; these people don't need your fancy new library, they've managed to survive without it so far. Or, if by "make use of it" you mean "use it in existing libraries", I don't see why would anyone want to do that even if `@` was added to 2.7 anyway. `x.dot(y)`, while not perfect, is OK, and changing it to `x @ y` everywhere wouldn't really pay off.
I would like to see a more complex example. E.g. how does it look like when implementing the CLI of the GNU tar tool? Is it a bunch of decorators where the number of decorators is determined by the number of options or parameters to the script? This must look pretty … interesting if there are many options to this script.
Please make that calculator using Micro Python! I would buy one! http://www.micropython.org/
Yes please! For example I have a media center program: https://github.com/boxed/cmi
Yes I do agree the admin interface and apps are good. However there is also things like http://flask-admin.readthedocs.org/en/latest/ (Flask Admin) which are cool. I'd rather have a loosely coupled framework (somtimes). I think no one framework is "better" than any other. Other frameworks could up their game on addons however.
You can look at the [previous contest page](http://kivy.org/#contest2012) for some of the apps that were entered into that one. Keep in mind that this was a couple of years ago, and that kivy has grown a lot since then (both technically and in user base), but at least it shows you some of the things people entered. Also, the theme of this contest will not be games like last time, so bear that in mind. That's not to say games will be forbidden, it just won't be the full theme.
The GitHub page is up! --- http://github.com/MrEikono/pyDungeon --- Also, I'm in the process of going from Python 2.5 to 3.3, in other news!
Well, maybe those who are familiar with ActionScript 3 will find this library more convenient to use.
&gt; , I don't see why would anyone want to do that even if @ was added to 2.7 anyway It's clearer. That's the whole point of the PEP. I switched out argparse for docopt for the same reason. **There should be one-- and preferably only one --obvious way to do it.** Argparse wasn't deficient in anything except that it wasn't obvious. &gt; I find it strange that authors of new libraries think they have to support Python 2. OK, in a year, should the libraries still support Python 3.4 when Python 3.5 is the latest version? I mainly code in Python 2.7 because my industry uses Python 2.7 and can't upgrade for the foreseeable future due to unsupported dependencies. Python 2.7 is a requirement for me. Python 3.x is not, but it's supported for 20% of the user base.
Seriously? If it was me I'd see the world. You can program anytime but traveling gets very difficult once you start working for a living. By the way that doesn't mean giving up on programming but rather taking the focus off programming during your travels. There will be plenty of time to break out the laptop to build your Python skills. In fact you may the constant fresh stimulation very advantageous when it comes to your programming projects. As what to focus on, I'm not sure how you can expect anybody to answer that question for you. After all we can't guess your interests with any accuracy. If you are just starting out with Python the obvious thing to do is to get a good text and start at page one. 
I'm confused as to what's being asked here. The post body seems unrelated to the title and is nonsensical. Can you rephrase the question?
The program is below in python, and...I just learned that PyGame is just a visual implementation thing.
one challenge for yourself each week. Build something using some new stuff, do a course, read a book..whatever. Over the first 5 weeks put a little time aside to starting thinking and planning some realistic ideas for what you could make (and get working) in the last 3 weeks.
Apply for jobs on odesk/freelancer so you can get practical experience and try out real software development... it'll be closer to the real world and you'll actually be making money at it!
Maybe the minotaur won't eat me if I am pretty...
Maybe if your into it. Make a few bots with Python. Maybe like a IRC/Twitter bot.
Thanks, I use windows and I have installed kivy via the stand alone download but I would prefer to do it in an IDE that corrects missing brackets and braces. I guess I may have to get vim again then. Does kivy work with ipython? 
Learn `pandas` and `matplotlib` you will not regret it. 
You can push business metrics to Stackdriver as custom metrics and show how they relate to infrastructure and application metrics. It's super easy to do, and really powerful. This primarily makes sense if you're running on AWS but can still make sense otherwise. Disclosure: I work for Stackdriver. 
You can write text on a PyGame window. You can also just use ASCII in a terminal and ignore the library entirely. I'm pretty sure you don't need anything special past that.
If I had two months to work on whatever, I'd pick an open source project I cared about that needed contributors to help port it to Python3 and then I'd work on that. It would be cool to learn someone else's project inside and out and it would also be cool contributing to the stuff available for Python3, which I really enjoy working in, personally. It would also be great experience editing and reading other peoples' code.
&gt; I would prefer to do it in an IDE that corrects missing brackets and braces Don't most IDEs do that? It certainly shouldn't be a problem. Kivy probably works with ipython, but I've never really used it interactively.
As a professional, if I had 2 months off I wouldn't program at all. But, if I wasn't a professional I'd spend the 2 months trying to find a job. Essentially, you can take one of two routes: Get extremely involved with an open source project or get a job working on proprietary software. I say extremely involved because you really won't learn enough by just fixing random bugs to consider yourself a professional. You'll need to actually design and implement a feature to start to learn a language truly. Work aside, if you really want to understand Python in particular, you should learn how and when to use metaclasses, descriptors, and other advanced Python features. They can be some of the easiest to make bad decisions with but the hardest to make the right decision. If you just want to spend the two months beefing up your resume, I'd suggest doing a mix of working with open source software and building something of your own. You can get a good feel for how large scale software works while also implementing features for your own personal project.
Ok I'm confused, what does this offer that IPython does not? IPython does pretty much everything this package does and much more without being nearly as limiting. Don't get me wrong this seems like a cool project that would be fun to play around with the internals some but I don't see why we need another Python shell in PyPi. I'm not trying to attack this package or the owner and I would not have spend the time on this reply if that was the case, I'm just trying to understand the why. Additionally, the bullet points at the top of the docs don't really describe the ''why' either. Some of them in particular leave more questions than answers. | &gt; Automatically import any object upon startup I don't see anything 'automatic' about it, you're still writing the Python code to actually do the imports. Same as you would in IPython except it looks like konch's scoping might be slightly better. &gt; Simple configuration syntax (it’s just Python code) Ok, simple how? I see it's structured, more structured than IPython in the most basic of respects, and there's not much that it seems to provide going by the documentation. If I want to do something more advanced this means it's no longer simple because I have to write the code myself now. &gt; Written in pure Python Great! I'm curious, what other languages would you write a Python shell in? &gt; No external dependencies "No external dependencies" is nice thing to have but tell me why it's necessary in this case. If you say "well, windows for one" I may be inclined to agree except getting IPython's setup is easy on Windows compared to all the other libraries I deal with. 
statsd and graphite are my typical go to. I'd love to find a simpler backend setup but it gets the job done quite well. Etsy [wrote the original write up](http://codeascraft.com/2011/02/15/measure-anything-measure-everything/) I believe, you might want to start there. Another bonus here is that you can use this setup outside of Python too. **Some Links** * [Python client](https://pythonhosted.org/python-statsd/usage.html#usage) * [statsd](https://github.com/etsy/statsd/blob/master/README.md) * [Graphite](http://graphite.readthedocs.org/en/latest/overview.html) 
Coming from an AS background this looks really interesting. Looking forward to having a play and seeing what performance is like.
You linked to the pygooglevoice docs which has installation instructions. They're Linux focused, so drop the "sudo", and it may work. Though if there's extensions, you may have trouble compiling them on Windows. I don't run Windows myself, so I can't help you with it's particulars. Try: easy_install pygooglevoice - if that doesn't work, you might need to do some research. 
Why would you need a framework to write a text game? Just use standard input/output in a console window.
There are many python courses online that you could go through to expand your knowledge. If you have any interest and/or access to ArcGIS, pick up a copy of Python Scripting for ArcGIS. People with a computer science background and strong knowledge of python are really in demand in the GIS field right now. 
If you don't have easy_install, 'pip pygooglevoice' might work instead. I'm also not familiar with how to install modules with Windows. =/ If you haven't already, you might want to post this on someplace like stackoverflow.com. You'll probably get a quick answer to it there.
You can implement a software UART, although C or assembly would be a better choice for a software UART than Python.
As well as providing performance monitoring for your Django web application, New Relic provides a means of recording custom metrics from your web application which can be charted using custom dashboards. New Relic also provides separate APIs and charting mechanisms for general metric data for services and business metrics. The New Relic software analytics product in particular may give you the flexibility you need with simple to configure dashboards usable by management. * http://www.newrelic.com/python * http://www.newrelic.com/platform * http://www.newrelic.com/software-analytics Disclosure: I work for and wrote the Python agent for the New Relic performance monitoring service. I have also written other nice stuff like mod_wsgi for Apache, which you may have heard of. :-) 
ProjectEuler.net ! Hands down the best way to get your sea legs in any language. There is a nice amount of arrays, dictionaries, string handling, large integers, and other math to make sure that you are able to kick as and take names. About the only area not covered would be graphics. So go make space invaders or some other 70's and early 80's games. Plus if you are applying for a job with real programmers and tell them what PE problem you have made it to then they will respect your mojo. 
I'm thinking about trying this eventually. At what level would you say a person would be proficient enough to apply for jobs there? I know it's a broad question but I only know the basics and I still don't feel confident about applying for anything yet. Perhaps you could give some sort of benchmark. Also, what's the pay like for Python jobs?
Hey this looks great! Thanks for the link.
Addictive little things. I have learned a ton of math bits. Do sign up as when you finish a problem you can then go into the forum and see how other people have done it. Sometimes you learn a new math thing that makes your code go like stink. Or sometimes it is a new way to do things. I did a bunch of the problems in C++ the first time 'round and then recently in Python. It took me less than an hour to do each problem (remember I didn't have to do the math thinking again). The Python was so much faster than C++ to program in. So right now I am redoing all my active projects in Python. It will terminate any further programming in PHP and vastly reduce my C++ programming. You have made a good choice to go with Python; welcome to the cult. 
Pythons do not have legs :) That said, I second Project Euler. Other than that, if you're interested in diversifying, look at classes on Coursera or something for topic ideas. Web programming, game programming, statistical analysis etc are all fun sub-areas you can pick up with Python.
I use Anaconda these days. It's so much better than Python(x,y). It's 64-bit and has an auto update feature.
I would avoid spreading efforts thin. Two months of productivity could mean the difference between nothing to all new startup material.
do some pygame projects maybe
`PYTHONSTARTUP=$HOME/.konchrc python`?
Idea looks fun, but when trying to run it I'm getting this traceback: Traceback (most recent call last): File "_core.pyx", line 82, in _core._event_handler_proxy (c:\projects\flappy_github\build\win32\release\_core\_core.cc:15581) File "C:\Python27\lib\site-packages\flappy\display\stage.py", line 260, in _process_stage_event self._event_map[event.type](event) File "C:\Python27\lib\site-packages\flappy\display\stage.py", line 240, in &lt;lambda&gt; self._on_joystick(event, 0), File "C:\Python27\lib\site-packages\flappy\display\stage.py", line 573, in _on_joystick raise NotImplementedError NotImplementedError &lt;type 'exceptions.NotImplementedError'&gt; &lt;traceback object at 0x022F8EE0&gt; I'm on Windows by the way, and I'm just running the example code. Very nice though IMO.
You'll want to install pip, which is a package manager for Python modules. pip can be difficult to install on MS windows. Luckily, Christoph Gohlke maintains an excellent repository of windows executables to install common (or difficult to compile) packages on windows. His packages are really well built. http://www.lfd.uci.edu/~gohlke/pythonlibs/ You can find pip there. After carefully choosing the correct version for you, install it, and then run a command prompt. You can interact with pip there. The documentation for pip is here: http://www.pip-installer.org/en/latest/, but you ignore the parts about installation. Anyhow, to install pygooglevoice, use: C:\&gt; pip install pygooglevoice That should download the package and install it to C:\Python33\Lib\site-packages, assuming that you installed Python to the default location. In the meantime, you might like to read about using python on windows: http://docs.python.org/3.3/using/windows.html. More importantly, you should read about venv. Eventually you're going to realize that you should have been using it all along. The documentation contains instructions for MS windows.: http://docs.python.org/3.3/library/venv.html?highlight=venv#module-venv 
The case was clearly made for @. It was not made for @@, @= or whatever the other weird versions of it were. I kinda wish it were @* instead of @, so it was clearer across operators, so you'd have @*, @ * *, @*=, @/=, @!=, etc. At some point you need to stop adding operators though. @ is coming. All the others...unlikely.
Right on. I now realize that the tagline is inaccurate. konch is not itself a shell but a shell runner that makes namespace configuration simple. I'm in the process of revising the docs to make this more clear.
Very neat! Nice demonstration, but why the label "Holonomic Constraints"? Isn't this a perfect example of a nonholonomic system? See the unicycle in [these notes](http://www.cs.cmu.edu/afs/cs/academic/class/16741-s07/www/lecture5.pdf). It seems the robot here has two degrees of freedom (two controllable wheels) but can change its location in three-dimensional configuration space (x-y on table, plus heading).
Start a project in Flask!
If you can do everything on [this](https://github.com/karan/Projects) list you'll be well on your way.
Well, I've actually been travelling the world for the past year or so. You wouldn't believe it but yes, it does become a bit of a chore to go out and see amazing things every so while. I took time off because I was bored with my previous jobs and the time taken off was to allow myself to find out what I truly like doing.. and well, solving programming tasks just happens to be one of them. And hence I'd like to develop that further.
This sounds ideal. I guess the reason why I would want to work for free is not so much the learning of python, but learning how the freelancer's workflow happens. How do they find work? How do they manage their time? Accounting and bookkeeping practices? I guess more of the small business mentality that I would like to start myself someday. Somebody to bounce ideas off. Things like that. Know anybody like that in Germany? I'd like to meet up :)
I do like Django and I've done a number of small projects. Being a soloist however, I find it frustrating when it comes time to making the site look pretty. I spend way too much time picking stupid details about colours and things like that. For this I'd definately need a front end developer with my tastes to help me.
I was a huge gamer in my past. I think I've spent my fair share of wasted hours playing and writing small games. I understand how this can teach me a fair bit about python.. I just don't have a passion for games anymore.
I'd work on [cryptography](https://github.com/pyca/cryptography) - as an OpenSSL-based proper (symmetric) crypto library is the only thing that the language lacks.
fixed!
Haha unfortunately I'm far from Germany. But most freelance coders range from $20-$60/hr. They don't charge for learning, they charge for time actually coding. They find work from networking and things such as reddit.com/r/forhire. 
Oh yeah!
My switch from 2.7 now &gt;.&lt;
Damn, I need to get off my butt and switch to 3--those features sound great.
I thought everybody switched over to Ruby by now. It's like Latin now, it's good for educational uses, but useless in its practicality. No good using dead languages to develop real projects.
You can also consider appenlight * https://appenlight.com/ You have full account for free with no time limit. Only limit is number of requests. Then you can move to paid plans.
This is the version that is going to make version 3 the common version of python instead of 2. pip is included by default as well as other version 3 goodness.
http://freemasonry.bcy.ca/fiction/monty_python/policemen02.jpg
The biggest hurdle is a psychological one: print -&gt; print() makes the whole thing feel foreign.
We're already on your free plan, mostly for server hardware monitoring and capacity management of the website. Is this something that could be done on this tier? Don't get me wrong I would love to go pro but we have one server and one app so its quite expensive compared to our infrastructure and its really hard to justify to management
Is it alright to use the same machine as the app for these sort of services?
I'd love to see this release get people switching from 2.X. Supporting libraries across releases is a giant headache.
You haven't been importing `print_function`? What kind of animal are you? On a serious note, I find it hard to go BACK to `print 'hello world'` whenever I have to jump to some legacy Python 2 code.
So how do I upgrade from Python 3.3 to 3.4 while making sure that all my installed packages on 3.3 are intact?
You understand the irony of you making this comment on reddit, right?
Old habits die hard :)
Do you understand the concept of a troll? Don't feed them! :)
Hahaha. Too funny to downvote :) Edit: For people that still have a sense of humour, the deleted message was a copy of RIGHT-IS-RIGHT's reply in capital letters.
With a pip running on your Python 3.3: `pip freeze &gt; installed.txt` Install Python 3.4, get pip on it: `pip install -r installed.txt`
Ask your editor to snippet+auto-parens so you still feel home.
Windows x86-64 MSI installer is throwing up "A program run as part of the setup did not finish as expected". Anybody else or just me?
I am/was a senior programmer but got knocked partially out due to Multiple Sclerosis and working on retiring. That said If you pick your own project, you're welcome to hit me up for advice/pointers. I can't go for more than 10-15 minutes actually writing code but I've still got all of my other mental facilities. 
I've always been similarly afflicted, Twitter's bootstrap CSS framework does make it a tad easier to get relatively pretty interfaces up and going without too much heartache.
I've been playing this game for a couple days now. I am addicted. Thanks for making an android app! I'm loving this. Small note: The sliding animation on the android app doesn't work when combining two blocks.
I hope so - 3 is the version I've been trying to learn, but keep hearing that it doesn't have enough support to compete. 
I didn't coded it, cause i have to deal with Z ordering, which i didn't wanted to do in the first try. Now... why not :)
Yeah I noticed in another one of your threads you're not the original creator, but glad to see you're giving credit to him and not commercialising it. Thanks!
Write an import hook to support the print statement
http://www.talentbuddy.co/ I've had so much fun solving all the problems (they are not all mathematical). And the best thing is that you can see other ppls solutions after you solve the problem your own way. I would definitely recommend it.
I have the exact opposite problem: I have super many private projects and very little time. https://github.com/boxed/ &lt;- Maybe something catches your eye and you want to try helping out :P
If you were using 3.4.0rc1, 3.4.0rc2 or 3.4.0rc3 you might have the mangled remnants of an uninstall job blocking the way. You can fix it by going to http://legacy.python.org and grabbing the appropriate .msi files. Repair the old installation, then uninstall it through the Add/Remove Programs dialog. The 3.4.0 release ought to install properly after all that. 
Hi richard, you should have gotten a reply to your mail, let's try and sort this out on the mail.
Emphasis on “hearing”
I chose to think that this actually works and screen readers for deaf people start shouting once they hit allcaps text.
The place I got confused was changing out `urlib2` I did not do it for all the code yet but ran into some errors. (I know I should be using `requests` instead but this code was made when I was starting to learn python) Edit: Typo
I wish `IPython` and `Pybrain` would switch
&gt; one server and one app When that goes down, what happens?
I did that too prior of learning `pandas`. But pandas allows you to do it in a few lines. You can also almost stop relying on excel too.
Then another gets spun up from the database replication. Should take us about 1 hour which is acceptable given our use case 
Thanks! I'm installing it into a fresh directory. Actually it looks like some pip update bug MSI (s) (EC:A4) [12:17:37:668]: Executing op: ActionStart(Name=UpdatePip,,) Action 12:17:37: UpdatePip. MSI (s) (EC:A4) [12:17:37:674]: Executing op: CustomActionSchedule(Action=UpdatePip,ActionType=3090,Source=C:\Python34\python.exe,Target=-m ensurepip -U --default-pip,) CustomAction UpdatePip returned actual error code 3 (note this may not be 100% accurate if translation happened inside sandbox) MSI (s) (EC:A4) [12:17:37:889]: Note: 1: 1722 2: UpdatePip 3: C:\Python34\python.exe 4: -m ensurepip -U --default-pip MSI (s) (EC:A4) [12:17:37:889]: Note: 1: 2262 2: Error 3: -2147287038 Error 1722. There is a problem with this Windows Installer package. A program run as part of the setup did not finish as expected. Contact your support personnel or package vendor. Action UpdatePip, location: C:\Python34\python.exe, command: -m ensurepip -U --default-pip MSI (s) (EC:A4) [12:20:11:292]: Note: 1: 2262 2: Error 3: -2147287038 MSI (s) (EC:A4) [12:20:11:292]: Product: Python 3.4.0 (64-bit) -- Error 1722. There is a problem with this Windows Installer package. A program run as part of the setup did not finish as expected. Contact your support personnel or package vendor. Action UpdatePip, location: C:\Python34\python.exe, command: -m ensurepip -U --default-pip Edit: Ok, my system-wide 2.7.6 installation interferes with 3.4 installation, so un-checking pip will install 3.4.. without pip. For some reason all combinations of C:\Python34\python.exe -m ensurepip ... invoke the 2.7.6 version and crash with Fatal Python error: Py_Initialize: unable to load the file system codec File "C:\Python27\lib\encodings\__init__.py", line 123 raise CodecRegistryError,\ ^ SyntaxError: invalid syntax
This is awesome. I have been using Python3.3 for all new projects at work and I've been looking forward to the release of 3.4. 
The software analytics products is still in beta phase. I know nothing about what terms it will eventually be made available under or whether there will be some sort of free tier. I believe platform plugins can be deployed as part of a Lite subscription, but I am not sure whether you could develop your own plugin and corresponding dashboards for it on a Lite subscription. I should find out about this one as have always wondered myself. I know that for custom metrics reported via our performance monitoring agents, you do need Pro to be able to create the corresponding dashboards.
Thank you - I felt pretty confident I'd made the right choice, but it's slightly demoralising learning a language and hearing it doesn't yet have the functionality to induce people to make the shift. Good news about the update. 
Initial reply from support team is that you should be able to develop dashboards for platform plugins on any subscription level. Do be aware that you don't need to publicly publish the plugin, so you can create it purely for your own purposes.
Afaik, the only big things missing from Python 3 are * paramiko * twisted There are also some special purpose libs missing, like some CAD thing I can't remember the name of and some Amazon cloud thing.
Oh nice! Simultaneous Python 3.4 release and only twisted left!
It seems to compare to http://docs.pylonsproject.org/projects/pyramid/en/latest/narr/commandline.html#extending-the-shell for some of the features. Konch seems to do more, but one thing that pserve does better (and that you might want to copy) is a nice and easy syntax for simple shortcuts (post = requests.post), along with a nicer way to present them on startup (requests.post, not &lt;function post at 0xbleuarf&gt;).
&gt; `requests` FTFY
`pygtk` is the library that is currently holding me back. That said, I know that they are in maintenance forever mode, and will never support Python 3. So, more that it's on me to switch over to `PyQT` at some point.
What concerns me the most is the availability of modules, that is what is going to make the change easier.
OpenCV is holding me back unfortunately. 
&gt; Finally enums as a native language construct! It's a a library implemented in pure python using metamumble magic.
&gt; This is the version that is going to make version 3 the common version of python instead of 2. I have a hard time believing that given the current usage numbers.
Thanks
What the ever-loving fuck.
Can I use pyvenv instead of virtualenv now? pyvenv in 3.3 was a little tricky, part of it was because you had to download distribute.py, then install pip using easy_install. With pip included in 3.4, I'm hoping pyvenv would be easier to to setup.
 1. If you're using `print` very often, your code is weird and possibly bad. 2. Several autoconverters can handle this for you.
It's really silly, like embarrassingly silly, to respond to this as if the change to print is an even marginally important.
There's no reason for pygtk to exist at all anymore. GObject Introspection provides typed bindings to all GObject libraries for lots of languages, including Python (both 2 and 3). For example, this is how you use GTK3: from gi.repository import Gtk window = Gtk.Window() window.connect('delete-event', Gtk.main_quit) window.show_all() Gtk.main() There's a [GTK3 tutorial](http://python-gtk-3-tutorial.readthedocs.org/en/latest/) and a [complete API reference](http://lazka.github.io/pgi-docs/index.html), too.
a fellow monkey.org guy who works a lot in functional languages (esp scala) and also python wrote this up on doing just this sort of pattern matching in python: http://monkey.org/~marius/pattern-matching-in-python.html see if that helps you. 
What do you use for writing to standard output?
Why would deaf people use screen readers?
port https://pypi.python.org/pypi/flup to python 3. so far i've only got it work on python 2.7, but it sucked at first because bad unicode support. For now this works from __future__ import unicode_literals 
That depends -- the logging module, some encapsulated-in-a-very-specific-place `print` or `sys.stdout.write`, for an interactive app urwid...For debugging I use automated tests and pdb. Pooping to stdout all over the place isn't a good design for many programs. It's hard to test, hard to maintain, and confusing to debug. Although "write some stuff to stdout" is common in intro programs, well-designed real programs seldom do it a lot, especially not in an unencapsulated way. If they happen to use `print` to do it, it's not 10000 `print` statements/calls, it's one or two within a function that handles output. Some tiny programs or bigger-but-still-small unixy programs can get away with a lot more `print`, but this is the exception, not the rule. ----------------- What is your purpose in your programs for writing to stdout directly so much? 
Could you explain why everyone is freaking out over asyncio? I'm kind of a novice so i can't really wrap my head around what it does.
If your program mainly uses a command-line interface you will obviously use `print` (or curses). Otherwise, I agree. Making a blanket statement about `print` being bad might be pushing it though.
I really find it hard to believe that you haven't run into having to do decode() and encode() due to Python's unicode support. These get me more than the print() function.
Wow, I'm retarded.
Oh, yeah, that was the one. Computer vision, not CAD
Interactive programs are command-line programs too.
Maybe it's good that twisted isn't ported. More momentum for asyncio
I thought IPython used whatever kernel you wanted it to. It can even use Ruby... 
So, how hard would it be to migrate my Django projects to Python 3 . . ? I'm rather tempted to make the switch to the light now. 
Yeah. It's a real pain. I'm not great wit python, but opencv is much easier to work with in python, and I'd love to start using py3, but I'm not experienced enough with python to help with the porting efforts...
I would love some help on Read the Docs: http://github.com/rtfd/readthedocs.org -- We host documentation for lots of Python projects, and it's mostly just a Django app. There are a good deal of interesting problems, and we'd love to have you help out.
im learning python and pygame is pygame look super sweet. 
That really sucks. Btw.: where are those porting efforts organized? Last time I researched, I couldn't find any.
Ipython most definitely works with python 3, and I'm fairly sure a couple of my friends are using pybrain with python 3 (not 100% though).
Any way to make Anaconda upgrade?
Does asyncio have nice support for dealing with synconous code? I work on a bunch of tools written in Twisted and feel bad every time I have to use `deferToThread` in order to wrap some synchronous library.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Selection algorithm**](http://en.wikipedia.org/wiki/Selection%20algorithm): [](#sfw) --- &gt;In [computer science](http://en.wikipedia.org/wiki/Computer_science), a __selection algorithm__ is an [algorithm](http://en.wikipedia.org/wiki/Algorithm) for finding the *k*th smallest number in a [list](http://en.wikipedia.org/wiki/List_(abstract_data_type\)) or [array](http://en.wikipedia.org/wiki/Array_data_structure); such a number is called the *k*th *[order statistic](http://en.wikipedia.org/wiki/Order_statistic)*. This includes the cases of finding the [minimum](http://en.wikipedia.org/wiki/Minimum), [maximum](http://en.wikipedia.org/wiki/Maximum), and [median](http://en.wikipedia.org/wiki/Median) elements. There are O(*n*) (worst-case linear time) selection algorithms, and sublinear performance is possible for structured data; in the extreme, O(1) for an array of sorted data. Selection is a subproblem of more complex problems like the [nearest neighbor problem](http://en.wikipedia.org/wiki/Nearest_neighbor_problem) and [shortest path](http://en.wikipedia.org/wiki/Shortest_path) problems. Many selection algorithms are derived by generalizing a [sorting algorithm](http://en.wikipedia.org/wiki/Sorting_algorithm), and conversely some sorting algorithms can be derived as repeated application of selection. &gt; --- ^Interesting: [^Clonal ^Selection ^Algorithm](http://en.wikipedia.org/wiki/Clonal_Selection_Algorithm) ^| [^Median ^of ^medians](http://en.wikipedia.org/wiki/Median_of_medians) ^| [^Selection ^\(genetic ^algorithm)](http://en.wikipedia.org/wiki/Selection_\(genetic_algorithm\)) ^| [^Quickselect](http://en.wikipedia.org/wiki/Quickselect) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cg4r23s) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cg4r23s)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
I have the latest release. Its just so slow when I move the spilt windows around. Its like it has severe lag. What I really want is Wings IDE, but im just getting into Python and dont want to put in any money yet.
not when you’re in a python3 mindset and keep metal tabs on objects being unicode or byte strings.
Thank you, rich person who supports extremely high income and wealth tax rates.
First thing, don't be afraid to check out the kivy mailing list or irc! There are lots of friendly people who can help with problems. You can get some help on reddit, but there are not so many experienced kivy users here. (Edit: I think also /r/python is not a good subreddit for questions like this, it's intended more for news. /r/learnpython may be better, but again doesn't have to many kivy users) &gt; My questions are: what IDE should I use? You can use any IDE you like, they should all work fine. &gt; what is needed to setup and start coding? Should I use kivy for windows or for Android APK I'm not sure exactly what you're asking here, you will need kivy installed on your normal computer to use it there. Kivy's android build tools take care of installing on android when you get to that, but you can develop on the desktop just fine. For windows, the easiest way to install is kivy's portable package, you can see the [documentation](http://kivy.org/docs/installation/installation-windows.html). This bundles Kivy along with some of it's dependencies (which can be annoying to install on their own). This isn't the only way to do it, you can also install it as a module in your normal interpreter, but I don't remember the details...someone on the kivy mailing list or irc can definitely help if you want to do this. &gt; Do I need Eclipse? Nope! &gt; also I know I will need some sort of emulator. Also nope! You can run kivy apps on the android emulator if you want to (if you use a recent version and have hardware acceleration enabled), but you don't need to, the android version will run just like the desktop version - you can even set the screen size and screen properties of desktop kivy to emulate a given android device. For actually testing on android, I just run it directly on the device. It's very easy to do so, and takes just a few seconds (and a single command) to build and push the apk. &gt; Are there tutorials to do basic kivy GUI stuff? There are a few scattered around, including some basic ones on the [kivy website](http://kivy.org/docs/tutorials/pong.html), some nice blog tutorials by [dusty](http://archlinux.me/dusty/2013/06/13/creating-an-application-in-kivy-part-1/), and my own series of [video tutorials](https://www.youtube.com/playlist?list=PLdNh1e1kmiPP4YApJm8ENK2yMlwF1_edq). 
Algorithms 4th edition, by Robert Sedgewick, page 345 
I disagree. Keyword-level print was a design mistake. You should have as few keywords as possible. Function-based print is important not for the sake of print itself (`print` is mostly just for debugging, after all), but for the sake of the language and its design as a whole.
It's not entirely trivial. You can do this whenever you realise that you've been littering a file with useless debug statements: print = log OK, it's not a great way to do things. But you can, if you have to.
Honest question, do you often need enums? I must say everytime I felt like using enums, I realised it was actually not necessary.
The [Python 3 Wall of Superpowers](https://python3wos.appspot.com/) says otherwise.
Ruby is like that, you're right.
But that's most often slow because of the concurrency model, not the inherent speed of the programming language. Python is also often loved because of its ability to glue super fast C libraries with its nicer, high-level syntax, so for processing most often the speed is of a compiled C inner loop, not plain python.
Thanks for the response I have asked on /r/learnpython before and got no response http://www.reddit.com/r/learnpython/comments/1yxeaz/installing_kivy_with_existing_python3_on_windows/ and I also used stackoverflow and got nothing so I guess I can use the IRC
I really wish there was an official Python 3 yum repo for RHEL-derived OSes. The brand-new RHEL 7 ships with Python 2.7; Python 3 isn't even an option. For better or worse I'm pretty mired in RHEL/CentOS; adding some Debian VMs just for Python 3 isn't very appealing since it would mean significant labor to get Debian integrated into my Kickstart/Puppet/etc. environment.
same here. i don't understand what the big deal is.
it is not a big deal, but a sweet spot for readbility and type warranties. 
You have a similar mechanism. You need to use run_in_executor, which will run the given callable in a ThreadPoolExecutor (by default) and you can wait for the result.
Woops! Good catch, these are nonholonomic as they're relations between the generalized velocities and coordinates. Fixed it. Thanks!
How do you "find" freelance work, and how do you know if you are up to it just coming in?
Browse things such as /r/forhire or other places where people are looking for simple things that take maybe a week. You know you're up to something if you can fully understand the task being posed, can lay out a skeleton model (meaning you know how to generally do it, which libraries you probably want to use and how to make it efficient), and preferably if you done something like it before. 
You can probably use kivy's distributed package and tell pyscripter to run programs with the kivy.bat (or kivy.exe, I forget) instead of its normal python, to get the effect you want. That's just a possibility though, it should also be possible to install as you are trying, but I don't know about this area.
i would say it might be a slow machine what you have there... i have a nice machine and I am flying with pycharm and a big project that i am handleing... so, maybe your machine is a bit out of date? 
Yes. Whenever you need to model something I find it very useful to give stuff explicit named aliases. It helps with readability and helps to test your assumptions about the model when you e.g. parse something and your parser suddenly wants to assign a value that you don't have an enum for. You have a ton of possible integer values, but only a handful of enums. Storing those values in regular integer fields might mean that you are parsing unexpected input without knowing it. It also makes it easier to navigate the code when you can look for references to "SomeEnum.SomeValue" instead of the value 1, which isn't particularly unique and could be used to represent a ton of different things. 
It's not going to change till they completely drop support of version 2. 
maybe something wrong with your os , try look at log file . actually it is very pleasant when you run it on ssd. but on normal hdd it is also useful and very mature ide.Google this "pycharm log file %your_os" your_os=what ever you use
Pretty cool, had no idea SymPy could do that. Maybe /r/physics or /r/MechanicalEngineering would appreciate this? 
[Check this out](http://lmgtfy.com/?q=what+is+an+API%3F) And yes, it would be great if you started out with 3.4
To be fair, even the parts implemented in C use metamumble magic. It's amazing how much of the underlying machinery uses the user-visible dunder-method interface to get things done. Class instantiation is just `__call__` on the metaclass, for instance.
Okay? There is honestly nothing wrong with doing a quick google search, trying to understand it and then asking a revised question, like "hey I know how API's work (in theory) but how does one go about working with one efficient" or "How does one start to write their own API?"
Are you on OSX? I had some problems with it that went away when I switched to the Windows version. 
If this is really to happen maybe they should remove the 2.7 download link that's right beside 3.4 and have a link to "older versions". If the community really believes that 3.4 is the latest, greatest and the one to be used then why confuse new users with a choice?
Yes. But even with Puppet, doing this on hundreds of systems, and getting all the v3-compatible libraries installed, and updating them all when there is a security issue, would be... less than ideal.
Without the parentheses it feels like you're writing BASIC, doesn't it? :-)
Ah dammit, you know what, I had `PYTHONHOME` set to where 2.7 is.
You can use mechanize. https://pypi.python.org/pypi/mechanize/
That's the problem with RHEL-based OSes: they're focused on stability, which means you're consigned to using software that's several years old as a consequence. :-(
From the Ministry of Silly Braces? :-)
https://github.com/pybrain/pybrain/pull/85 It's usable with Python 3.
So, what... 10 to 20 `print`s? Where's the big deal?
If you're developing for Linux, GTK+3 ≫ Qt.
*Upgrade* to Python 3.4.
exactly, which is why adding brackets around them to move from python 2.7 to 3.x should't be a big deal. Also, you don't have to move to 3.x before starting the migration. Any new module should include: from __future__ import print_function and use the new syntax. This will make future migrations much easier. Not to mention that tools such as 2to3 are extremely mature and will get you most of the way there if not all the way. The most tedious work will be done for you leaving just the serious migration stuff. That stuff of course could eventually be migrated with use of source control, unit tests and virtual environments so that production code is never in a state of flux. The moment the last library you depend on has 3.x support, or a suitable replacement with dedicated maintenance you can shift your code to 3.x and enjoy all the new features.
A problem, and a benefit, at the same time. Software Collections might help this, but it is not the same.
now i cant use pygame :(
But there is something perceptually wrong with pretentiously pointing them to a website devoted to slandering people asking honest questions.
I use Anaconda on several linux boxes and clusters. For me at least, I like using various conda environments for testing (so as a virtualenv replacement), I get mkl builds through accelerate which I wouldn't otherwise, and to keep uniformity across all of the machines I use and develop on. Installing the various libraries on Linux isn't nearly as complicated as on Windows or Mac, but Anaconda/Conda makes it trivial, so I just use it there as well.
Glad you solved it. When you have multiple python installs, it's best to not let any of them be the default path or home and just use virtualenvs. They're easy to get used to and might help avoid future problems.
Ah, I'm being an idiot. Sorry.
You may want to post the GitHub repo, so any potential helpers can take a look at the source code.
Obligatory /r/itsaunixsystem 
It's pretty slow, but super worth it. I avoided it a long time because the annoying slowness but it saves me from so many things that are even more time consuming so it's a good trade.
Maybe because it doesn't have the "Programming Language :: Python Programming Language :: Python :: 3" category in pypi? https://github.com/paramiko/paramiko/issues/16
I see where you are coming from, but it's not black and white. It would be like reading french philosphy book, while looking every word up one at a time. Sure you might get through the book, but you require fluency to get the higher concepts in any reasonably time scale. I mean surely you aren't suggesting students not memorize *anything*. In the real world you need to know some things by heart.
Step 1: code something. Step 2: talk about it. You're doing it the wrong way around!
On Windows: &gt; py -m venv myenv &gt; myenv\Scripts\activate &gt; pip install beautifulsoup4 
There is, its called Software Collections and is available on RHEL/CentOS.
Check out RedHat Software Collections. Its also available on CentOS.
I much prefer my distribution's package manager, to be honest.
Mac only for now, but the mac specific code is just ~1k lines, should be easy to add a Qt frontend I think.
Before using anaconda, I never had problems installing everything I needed on Linux either. Now that I use Anaconda, what used to be an hours-long "no problem" process now takes about 20 minutes – I'm talking specifically about setting up a dev/testing environment complete with Python 2.6, 2.7, &amp; 3.3, each with various permutations of versions of numpy, scipy, matplotlib, ipython, scikit-learn etc. in virtual environments. The fact that Anaconda also works flawlessly on Mac and Windows is icing on the cake, except when I'm teaching, and then it becomes absolutely essential. It's why I recommend Anaconda to anybody who's interested in scientific computing in Python. Do you need Anaconda on Linux? No, you can do pretty much everything with some combination of apt-get/yum and installing from source. But does Anaconda/miniconda/conda make the process of setting up a scientific development environment much easier? The answer is an unequivocal yes.
Thanks for the reply, will definitely help me. I'll spend the first couple of hours actually learning the language first though.
Why? What does it have in advance to Qt? I'd say the opposite: Qt has Qt quick, GPU acceleration, doesn't break compatibility (e.g. with themes) all the time, and is much better at cross platform (abstracts away staffers button layouts, the themes look more native and out works in more ecosystems) All stuff I like as a developer.
Python3 mindset alone doesn't help, as Unicode provides you with plenty of booby traps. Simple things such as reading a filename and printing it to stdout can explode in your face now, extra fun if it only happens on some OSs, but works fine on others.
Because the trove classifiers aren't updated yet. The release is 4 days old. Also I'd believe the release notes more than metadata.
Is there a Linux version for this release? 
On Linux/Unix after you've created your virtual environment: &gt;&gt;&gt; cd /path/to/your/virtualenv &gt;&gt;&gt; source bin/activate &gt;&gt;&gt; pip install "package name" if you need to install something with sudo permissions, sudo pip will use system default one, thus do the following: &gt;&gt;&gt; cd /path/to/your/virtualenv/bin &gt;&gt;&gt; sudo ./pip install "package name"
You're missing a `)` on line [13](https://travis-ci.org/garth5689/pyd2l/builds/20697547#L263)
Hey, it's that good.
U/P: demo@demo.demo / demo
Given that this has 10 upvotes so far it seems you're not alone. Unfortunately, I'm too much of a noob to even get /u/ivosaurus's thorough reply. Could someone please ELI5?
In general I'd agree with this but it entirely depends the application itself, the metrics you're logging, and the server or VM you're using. The answer would definitely be no if viewing and processing of the metrics interferes with the application itself or visa versa. There is not a hard coded limitation to this, it's entirely based on your needs.
This HN comment[1] points out that trying a pure Python quickselect implementation might not outperform sorting the list using sorted(), since it's implemented in C. I guess the overhead is more relevant than the nicer complexity, except for really large lists. Someone else mentions this other interesting approach[2] using a "lazy sorted" function written in C, which seems really efficient. [1] https://news.ycombinator.com/item?id=7417752 [2] https://news.ycombinator.com/item?id=7418060
It's also a huge pain to install numpy and scipy with MKL on linux. 
If you are forced to use an old Linux distribution (EL5 for example) which comes with 2.4.3 .. using something like miniconda becomes a nice way to use 3.3 for example.
We don't release binaries for Linux. But it's the easiest thing ever to build it yourself! If you want to install it system-wide, just run: # configure &amp;&amp; make install Alternatively, if you're on a recent Ubuntu, you should be able to find a PPA that builds it for you. My build environment is Ubuntu (13.10, 64-bit), so I assure you it works great on Linux :D
/r/raspberry_pi
I'm reacting to the attitude in the post at the start of this thread, which completely ignores the fact that sometimes pypy is not an option. Like it or not these scenarios are not some weird corner case, many people use python because of numpy and the surrounding ecosystem. Without these things we'd be writing code in matlab, not in pypy. I'll happily switch to pypy when the support is there, but I rely on too many cpython specific extensions to make this possible right now, and my situation is hardly unique. No matter how much faster pypy is for pure python, cpython is still relevant and is the only option for many. I'm not trying to diminish what pypy has accomplished. I just don't like seeing it thrown around as if it is a drop in replacement for cpython, because too many pieces are still missing for that to be true. Numpy support is just the first step on a long road. Look at how many people still use python2.7 because of the breaking changes introduced in python3 and consider how much bigger the step is from cpython to pypy.
Isn't the PSF paying people to convert popular libraries from 2 to 3?
The best explanation I've read of for enums was: "A class where you know all of the possible instances at write-time." After I started thinking of it that way I started seeing a lot more valid uses where it would simplify code and reduce the amount of nasty string parsing, keywords in function calls, etc.
Selenium WebDriver. It's much better supported than either Twill or mechanize. 
GTK+3 looks nicer, has good touch and multitouch support by default, good smooth kinetic scrolling, better widgets and is basically just a more modern toolkit. None of these things come for free in Qt (or GTK+2). Further, GTK+ is more standard. GPU acceleration is nice but unneeded. My themes *don't* break compatibility all of the time. The cross-platform point is valid but irrelevant because I'm referring to if you're developing for Linux. Unfortunately it does mean avoiding Qt's massive library of *things*, but that's a minor point when the end result comes out much, much nicer. Have you ever compared nautilus to dolphin?
I understand that there were some GIL improvements earlier in Python 3.2, but I don't see any further improvements in 3.4 here. Is it just unrealistic to expect real multithreaded support without a "Python 4" that again breaks backwards compatibility?
Never use sudo pip. Never ever!
Many things are possible, of course. My point is that it's almost *certainly* wrong to do that. No internet because of security reasons means they're doing something worthwhile to keep safe. Wouldn't they also want to keep the damn thing running?
Care to elaborate?
Wish there was an official, reliable way to get standalone files by now, instead of having to use unreliable third partie applications. Makes it a bit hard to distribute Python code :(
what about using pip for numpy installation? It might require some rights. But I'll be more than happy to change my practices, if you tell me more elegant way. 
For those of us still on 2.7, is there a consolidated wiki or change list? For updating your projects from 2.7 to 3.x
Someone doesn't use Windows. ;-)
Removing the GIL would break the entire C API, and every extension. If we did that I bet we'd call the result Python 4.
No problem. If you have some more questions when you are learning please post in /r/learnpython. 
thanks! it looks like the print function is the only thing i have to worry about, and maybe the open() changes
Because you have the power of programming, and I pretty firmly believe you have a moral duty to do something at least *vaguely useful* with that.
i did .net and java programming after pascal(delphi) and before coming to python/ruby. in .net the ONLY time I ever used enums is because the whatever I was doing with the .net framework required it. Never once, was anything I did implemented with enums. And I still got paid. 
But that does not give you the ability to run Python 2.7 and 3.3 (soon also 3.4) side-by-side. Also, the packages in Anaconda are kept more up-to-date.
I'm guessing.... be a real man and use "su"?
&gt;&gt;&gt; pip install pygooglevoice SyntaxError: invalid syntax i get this error after i installed pip and typed it into shell...the word "install" was highlighted
I have actually been looking forward to the statistics module. (My desires are humble...)
We have Python 3.4 packaged for Anaconda in our internal repo right now, for internal testing. We will be releasing it soon and then you can install it alongside all your other Python versions (2.x and 3.x).
Sweet, but I wish you guys had a public testing repo. 
Some of the devs kind of use their binstar.org channels for that purpose. We may eventually do this in some "official" capacity.
Hello, we might be willing to help you, writte to us at athelasperu@gmail.com we are webdevelopers with a passion for python. (We don't do design but that should not be a problem). If it's something simple (maybe just one page explainign the proyect and the link to github it could be done quickly in drupal.
Actually, having thought about it, you're right. I've changed the rate to $100 an hour, which I think is more in line with the amount of work required.
Both Debian and Arch (the two distributions I'm running right now) have separate sets of packages for 2.7 and 3.3. I would imagine most other distributions (outside of RHEL or something) do too? I agree you don't get the granularity of choosing 2.5/2.6/2.7/etc and things might be few days out of date, but it's one less thing to learn if you just need to install numpy/scipy on a system.
Learn both. They're virtually the same. If you have the ability to understand both `print("x")` and `print "x"`, there's no reason to restrict yourself to learning just one version.
well im addicted to auto-complete, so yeah im using it. 
Windows 7 here. 
my backup PC is missing a harddrive, so no. 
Same reason you don't run `make` as root, you don't know what is going to happen when you install a packages, a broken package could thrash your entire system when run as root.
The point of PIP + virtualenv is to install things to a project specific location, not globally. Keep the global namespace pure.
It gives a really useful framework for doing network programming, using a canonical event loop and coroutines (google if you're unfamiliar with the terms). 
And, given that the BDFL has stated they're never doing a huge, backwards incompatible release again, it isn't likely. The best bet at this point is Pypy's work with STM.
I'm on arch, and have both 2.7 and 3.3 running side by side. python takes me to 3.3, and python2 takes me to 2.7.
It allows you to do things and not wait for them to finish. In effect, this allows you to do lots of stuff at the same time. 
Yeah, you have to experiment with urllib2 because they moved stuff around. Requests is very nice, of course.
I could maybe afford it if it cost 10% of what you're quoting, but I'm sure there are enough potential customers in the first world who'd be able to. I wish you well with this, but if the experiment fails, please consider recording a session and selling access to the video at a much lower rate.
Because different python programs use different program versions. If you install it globally, you will be potentially breaking other python programs. You should keep a separate python environment for each python program for this reason.
I personally don't think it's that hard. Depends on the django version and libraries you're using. Urllib, for instance, takes some work because stuff is moved around but once you figure out where to import stuff from the behavior is pretty much all the same. You have to be a little careful with things that used to return fully formed data structures now returning generators in python3 (like the difference between `range` and `xrange`). This may take some getting used to, but I consider it to be totally worth it. At any rate, all of these can be addressed with some time in the REPL and some good tests.
Fair enough. I re-read my comment and realized I sound like a party pooper. I do believe there are enough people out there who a) have the desire to learn and b) can afford the rate. Certainly enough to fill your schedule 10x! To be constructive, you might focus on how much time you'll save someone. Your competition is "finding and mentally compiling dozens of tutorials across the web, each targeting different versions of python" -- it may behoove you to address this. Who are your target market? (Developers? Entrepreneurs who can't afford full time devs? Bloggers?) What do you think are the biggest problems your target market faces? (time, certainty of whether the information is "best practices" or "dark patterns"?)
Install in a virtualenv and simply use that. Or, if you must, install in $HOME as your user only is what I do, or in /opt or in /usr/local as another user + group. This "everything should be owned as root.root" madness in the linux community should stop, there's a reason why we have both users __and__ groups. * [PEP370](http://legacy.python.org/dev/peps/pep-0370/) * [sys.path](http://docs.python.org/2/library/sys.html#sys.path) 
It's actually not just about the versions of the Python interpreter, but also different versions of packages for each version of Python. Anaconda's package manager conda is able to create robust virtual environments that mix and match these, partly because of how isolation is designed in, and partly because all shared libraries &amp; extension modules in the Anaconda repo are built to be relocatable.
Also, if you are only giving one argument as is common, `print (x)` works the same in both 2.7 and 3.x (and probably older 2.x, but I haven't verified that); It's slightly restrictive -- multiple variable printouts require %formatting, and kwarg-controlled features of print() are not available -- but you gain by only having to remember one convention.
Other folks have commented on the key benefits, but one I'd point out is that of collaboration and deployment: if you have to run your code on a Linux cluster at your institution or a collaborating institution, and they run a different distro or a different base version of your distro, then what is your process for making sure your code runs? It's not just about version numbers of libraries: in many cases, the compiler flags and build options can affect performance dramatically. Maybe a particular cluster has a certain version of ATLAS or some vendor FORTRAN compiler that their numpy/scipy is linked against, and you're not allowed to bump that version number or displace it. Maybe you don't have root? Using Anaconda's environments and its portable Linux binaries means that you're a couple of conda commands away from being able to reproduce your personal dev environment on any modern Linux box, regardless of whether you have root and regardless of what system Python is installed. 
Wow, what an easy mistake. Didn't catch it since I was trying to resolve on github's editor. Thanks a bunch.
* Segregated networks (so no easy access to pypi for pip to work) * old, let alone current, versions of RHEL none of which come with any software newer than about 6 years ago - if you're lucky and its included at all. * multiple virtual environments - trying to build everything from scratch each time takes too long * no development toolchain installed (i.e. secured system) so pip is useless for C/C++ based python modules That's off the top of my head where the anaconda environment shines. On the first one, its easier to request [anaconda server](http://continuum.io/anaconda-server) and host conda repositories locally than to argue to get internet access to every restricted system that needs python. 
Python may be cross-platform, but Unix will always be its primary target. Just look at the names of all the functions in `os` if you don't believe me.
This is such an oxymoron. How can 6+ year old bug-ridden filth be "stable" ? 6 years worth of bugs and security holes. 20 years ago the industry moved on to "release early release often", if you're still advocating horrible old junk is "more stable" you're an idiot. Code with the same md5sum six years onwards is no more or less stable than it is _right now_, but it sure as hell will be less stable than the one with 6 years worth of more work plugged into it. 
I believe that conda installs dependencies as well, which can make it a lot easier for some packages.
 conda update conda conda update anaconda Of course, you'll need to wait until continuum release python 3.4 packages, unless you use a third-party repository on binstar. 
Like all monolithic godzillas of programs, you need to be running the best hardware possible to use it. You'll want at least a quad core i7 and 16Gb of ram, if not more (of both) Also, it does a fair amount of disk I/O so switch to some fast SSD's. The more you compromise, the slower it gets. Note that you can get autocomplete in better editors like Vim, Emacs and Sublime Text, which will work better for you on your older/slower system than PyCharm.
I grabbed Sublime Text 2 and it is a wonderful editor and very fast, I just dont know how to hook it up with running Python scripts. If you had a link to how this is done i would be very grateful. 
How does it look nicer and have better widgets? Please elaborate. What are you missing with Qt's touch support? And “more standard”: wat.
Depends on the distribution. Most people here are familiar with RHEL, Scientific Linux and the like, but I use openSUSE for my "development" (quotes, because I do research and not real development) work and should I want, I have access to the Open Build Service for extras. Also any reasonably recent distribution has a way to install py3 and py2 versions side-by-side (with "update-alternatives" from Debian, but borrowed in many other distros, to manage the default interpreter).
please don't mix it up. moving 2.7-&gt;3 requires changing all of your python code (I for one can't imagine doing this). Moving cpython-&gt;pypy requires some changes that vastly depend on the usecase (from impossible to outright trivial). I'm sorry you can't use it, but please don't dismiss existance of people that can.
This should get you started. [http://addyosmani.com/blog/custom-sublime-text-build-systems-for-popular-tools-and-languages/](http://addyosmani.com/blog/custom-sublime-text-build-systems-for-popular-tools-and-languages/)
I think the video idea is great. There are many tutorials out there for Python web development but only a few go into detail about deployment. If the videos were offered as VOD or a subscription (or best of all: free!), I would seriously consider purchasing. But $100-175/hr does not appeal to me. An alternative would be to have group meetings where paying customers (at a discounted group price) could ask questions.
If you can afford it (and you value your time) it's seems like a fair price. I enjoy learning by myself through forums, tutorials (many of yours),etc. Not everybody can afford the spare time to do it. Good luck with the project.
I thought posting your own stuff like this was against the rules. People's personal projects they want to show off are nice but this just sound like advertising.
that adwaita thing isn’t pretty imho: 1. like oxygen, it’s “OMG WE CAN DO GRADIENTS” all over the place 2. simple 1-pixel borders. that’s like the most programmer design possible. “let’s use border-left:1px here so we can see the border”. and then it stuck 3. the breadcrumb bar is higher than the buttons, and the margin between it and the buttons is less than the buttons’ other margin. rookie mistake. but margins are something that GTK generally sucks at 4. the scrollbar tries to be what ubuntu’s is, but isn’t. now we have one that still takes up space, but can’t really be hit with your mouse. i like the monochrome icons, but the other ones look like what i did in photoshop 10 years ago. “OMG 3D BORDERS” i’m currently using a flat QtCurve theme. also simple 1px borders, but no “fancy” harsh gradients that contrast them. --- Qt has [QTouchEvent](http://qt-project.org/doc/qt-5/qtouchevent.html). sure, it doesn’t come “for free” as you have to enable it on the widget where youwant to use it. so what? you’re going to write code specific for that widget anyway, so it’s one more line. --- GTK has better applications? don’t tell that Kate, DigiKam, Gwenview, Apper, Krita, … Dolphin’s semantic search is also pretty rad for those who use that kind of thing (but even if i don’t use it like that, i still prefer it over “let’s cut *every* corner. no matter is someone is currently standing on it” Nautilus) Granted: Gimp, Firefox, and Inkscape are pretty unrivaled in what they do. (I mentioned Krita above, because AFAIK it’s better for digital painting)
I'm not going to get too deep into an argument about whose aesthetics are more right, but I do have two points. One is that I've no idea what margins you think are uneven. It's worth noting the breadcrumb bar is purposefully oversized, which isn't the "fault" of the toolkit. The other is that complaining about gradients on that is like complaining about the edges on a spoon. It's really not at the point where it's them showing off. There are even flatter themes if you wish for them. --- Qt's touch event is like a bit of flour when really you wanted a doughnut. There's so much more to touch handling than just differentiating the presses. --- I still stick by my claim that GTK has better applications *on average*, and it definitely has more.
Why is the lack of a numpy dependency considered a feature?
has more what? widgets? OK, i give you that. i like those arrow panels and title bars, too.
No.. um.. More applications.
Same here, and this guy only ever submits stuff back to his personal site, which very much goes against the spam rules. I'm sort of amazed he's not been banned yet. 
Reddiquette: &gt; Feel free to post links to your own content (within reason). But if that's all you ever post, or it always seems to get voted down, take a good hard look in the mirror — you just might be a spammer. A widely used rule of thumb is the 9:1 ratio, i.e. only 1 out of every 10 of your submissions should be your own content.
Out of 50 submissions, he's posted his own content 49 times. The other one was a self post offering a discount on his book. So, there's that. 
I love this project, I've come across it many times looking at manuals for other projects. It'll take me a little while to get my head around how it all clicks together, but yeah. Maybe I'll look into it. Thanks for the heads up :)
I wish you the best of luck with your business and thought about if I know someone, that could use your service. But my contacts fall into two categories: 1. They already know how to deploy a Python application or just figure it out in 1-2hrs 1. They neither know or care, they just want it to work Furthermore, there are myriads of ways on how to deploy and run a python application. And understanding when to choose which way is not always as easy as it seems :-/ An idea could also be, that you teach multiple customers together, so you can lower the price for each one and they can learn form each others questions.
With 39 successful posts out of 50, he clearly has some interesting content. I recognized his name from [sandman](http://www.jeffknupp.com/blog/2013/07/23/sandman-a-boilerplatefree-python-rest-api-for-existing-databases/). At a guess, the admins haven't noticed the posts because they're spread out and usually upvoted. edit: That being said, I was thinking $2000 / $100/h for setup was a bit much until I realised that 1. that might be accurate for (est) 10 hours of teaching how to set up Linux (although you could just go through it and record with asciinema or something, let them go through what you did at their own pace), and 2. I have no idea how much things cost, as I did that exact thing this morning (minus the tutoring) in two hours for $50.
I prefer having one or two applications for each tasks and people contributing to them instead of reinventing the wheel all the time. Don't get me wrong, sometimes you have to reinvent the wheel by creating am application around a new idea (like Geary), but usually I despise forking or NIHing things because you dislike some details. Better make stuff more configurable, and you'll need only one.
As far as I've read while studying Xcode, while iPhones keep several applications "open" at the same time, only one is allowed to be active in the window. So if you're trying to superimpose your image over the other application, it won't work. 
But not *that* harmful. A bigger design flaw in the first listing is that Protocol is working directly with data from Tracker. It's preferable for classes to only work with their own data. It makes these kind of bugs easier to spot.
Oh god. There are *so* many things wrong with this article. Starting with circular references and action-at-a-distance in Protocol's constructor, and ending with the fact that if you want immutable structures, *how about simply not using append*?
I don't know hwo it works, but I start to think that Redditors don't even bother to read. I've written that it seems like there's no PIP installed while being in pyvenv (which pip -&gt; 'pip is currently not installed').
Can't say I've heard of PySDL2, but PyGame is pretty much a standard when it comes to game development, it also has a pretty huge community and PyGame is even used outside game development. So in terms of resources PyGame has your back. 
With only-python-as-a-dependency: [tkinter](http://docs.python.org/3/library/tkinter.html) Linux: [gtk3](http://python-gtk-3-tutorial.readthedocs.org/en/latest/) is pretty easy. Redistribute everywhere: [PyQt](http://pyqt.sourceforge.net/Docs/PyQt5/)
Not sure about 3.4 but as far as I am aware PySide and PyQt are the things you should look into. The biggest difference between them is the licensing and so far PySide only supports Qt 4.8, though it does have a friendlier licensing system. Personally I know only PySide and I'm pretty happy with it, the documentation is pretty good and the community is big enough to solve your problems over @ stack overflow, however I've heard Tkinter is pretty big and apparently it's de-facto standard GUI (source: https://wiki.python.org/moin/TkInter)
Thanks I actually got it setup for scripting in the Pyscripter IDE. But I get a traceback error which I posted on stack http://stackoverflow.com/questions/22477526/importerror-dll-load-failed-1-is-not-a-valid-win32-application-kivy-python Still could run it fine in the .bat file. So I am almost there.
I'm one of the developers, if anyone wants to AMA.
Since it's a "the right way" post, I find it a bit disappointing that implicit relative imports are used, which have been broken for a while. It should be # in your __init__.py from .file import File # now import File from package from package import File and not # in your __init__.py from file import File # now import File from package from package import File
In Python 2.6+, you can use `from __future__ import print_function`.
100$/hour. or 2000$ all together. These are prices that companies only could pay for, and my guess is that companies would better hire someone who already knows that stuff. If the goal is to reach out for the larger audience of individuals who -for a reason or another- want to learn that stuff, you gotta come out with a *much* cheaper pricing plan.
Is there a plan for Tar (+ compression) support?
or, depending on your needs: print = lambda *_: None Sometimes, you just want to turn the print calls off in a hurry, like if you're about to demo some code.
lol
I wasn't aware of this rule! I post my own content because it's generally well received, but I'll avoid doing so in the future. Everyone in this thread is absolutely right, and I apologize for not being aware of this rule.
Actually, yes. Ben Timby contributed fs.contrib.archivefs which is a wrapper for a C library that should add support for just about any archive format. I'm not sure what that status of that is, hopefully by the next version it will have moved out of the contrib module. In theory it shouldn't be too difficult to build from scratch. If you're interested refer to the ZipFS implementation as a guide.
well this doesnt work for me. Just built python 3.4 again. While installing I can see: Installing collected packages: setuptools, pip Successfully installed setuptools pip I create a virtual env: pyvenv-3.4 pyenv source pyenv/bin/activate pip install flask The program 'pip' is currently not installed. You can install it by typing: sudo apt-get install python-pip 
Not a question, just thanks/appreciation! I use this module in a relatively basic script that moves some files from my PC to my NAS. PyFilesystem made it easy to deal with the paths/transfer and this script was the only one keeping Python27 installed, all my recent work is in Python3. So, thanks for the great module and for the new update with Python3 support!
Not everything's a command line switch. AwesomeWM and i3 are similar projects but it makes a heck-o-'a lot of sense that they're separate. Same with Firefox and Chrome. (etc.)
I have used both, mostly pygame. Using pygame is easier, there are more resources and it's been tried and tested for quite some time. PySDL2 is more modern, is more streamlined (pygame can become messy very easily) and also has some very nice features that can be hard to do in pygame like particle effects. If you just want to play around a little I would go for pygame, but if you want to to some serious game programming I would take the time to learn PySDL2
You're welcome! Glad you find it useful.
Some thoughts about the documentation: * Most of the examples just define functions. It would be helpful to have fully-fleshed out examples, so interested users can actually see the library in action. The example page is where the front page directs users as a starting point, so make it beginner friendly. Better still, put one minimal complete example that actually does something interesting on the front page. (e.g., Insert a key/value pair, then fetch the value and print it.) * `asyncio` is brand-spanking new, so take a moment to explain what's going on. What are all the yield froms for? How does the event loop work? It doesn't need to be a complete tutorial--you can link to the official docs for that, but for a brand-new (to python) design pattern, a little hand-holding would not be unwarranted. All in all, it looks pretty sweet. Thanks for getting some working asyncio code out in the wild so quickly. This is exactly the kind of thing needed to facilitate adoption.
Yes. I just tend to not bother, since I hardly ever use the kwargs to print (or multiple arguments to print, either). (Plus some people here have to work with Python versions as old as 2.4.)
thanks, you just saved me loads of time, had the exact same problem.
Awesome. I know there are quite a few alternatives for Python Redis client using asyncio. I would be nice if these alternatives would included in the documentation so people have an easier time making the right choice.
&gt;But "`if var:`" is a common idiom in Python code I think you mean it's a common antipattern, unless `var` is supposed to be one of `True` or `False`. Testing whether `var is None` is faster, more correct, and more readable than just testing `var`.
I'm not Jake Edge and I agree completely
Sorry, by "you" I was referring to the author.
Interesting story. Btw: Is posting an LWN subscriber link to reddit in compliance with the LWN FAQ? "Where is it appropriate to post a subscriber link? Almost anywhere. Private mail, messages to project mailing lists, and blog entries are all appropriate. As long as people do not use subscriber links as a way to defeat our attempts to gain subscribers, we are happy to see them shared."
You should discourage the usage of from package import * and make sure that the code you are showing actually runs on Python 3 (besides Python 2). Python 3 forbids implicit relative imports, that might bite you there. So, within a package, always use explicit relative imports. I have also tried to explain that here: http://gehrcke.de/2014/02/distributing-a-python-command-line-application/
What's killing me is that your titleS always seemq to avoid mentioning it's your thing. That's odd for someone that doesn't know he shouldn't submit his own stuff.
Nice, did you consider create a cookiecutter template? http://cookiecutter.readthedocs.org/en/latest/readme.html#cookiecutter
Thanks for the pointer! I did not know cookiecutter before. At first glance, it looks really useful. I will look into creating a cookie :-).
I made a module for MongoDB/GridFS backed PyFilesystem about 3 years ago, one of the main motivators was being able to expose it via fuse &amp; sftp without writing any additional code in a naive attempt at doing clustered linux VMs with aufs + fuse + shared mongodb, it performed terribly :( iirc I needed some patches or something to support all of the FUSE/POSIX semantics and stat options. I should probably dig the code out of deep freeze and have another hack on it again, but what's the best route to contributing a new module and ensuring that the fuse expose can be `chroot`'d into?
IDLE? [From the docs:](http://docs.python.org/3/library/idle.html) &gt; IDLE is the Python IDE built with the tkinter GUI toolkit.
There have been plenty of improvements and fixes to the fuse support. Might be worth a try again. Plenty of support available through bug list and mailing list. It may never be the best solution to be honest. PyFilesystem was only ever intended to support functionality common to all filesystems, whereas fuse is quite low-level. With all the translation going on, you're probably not going to get first class performance. That said, there's a lot of people using it in this way, since it's much simpler than writing a fuse filesystem from scratch.
learn u some http, and client/server
I'm the lead editor at LWN; I'm also the person who posted the original subscriber link on r/programming, where it received rather less appreciation than it has gotten here :) Having an occasional subscriber link show up here is, as far as I can tell, only good for LWN overall.
Very worthwhile. I didn't know that myself. Thanks for pointing it out.
Django plus tastypie is a quick way to generate JSON.
Consider posting python-related articles here.
That's strange. I haven't tried 3.4 myself yet, but normally, in your venv, running `python -m ensurepip` should do the trick. But you're not supposed to have to do that...
This page has a few: http://code.google.com/p/tulip/wiki/ThirdParty This thread mentions a few more? : https://groups.google.com/forum/#!topic/python-tulip/7WJrtZqISUI
You need to use python -m ensurepip 
I recently deployed a Django app to Digital Ocean with no experience whatsoever. They are like $5/mo and include some great tutorials on getting Django deployed.
good idea
It is not more correct. Unless you use it with time objects, of course :)
I have found your other posts generally helpful (the ones that I saw anyways). I would hate to see you go, there's probably a reasonable way for you to get your posts flagged so they can keep happening. I think the issue here is that, much more than other posts, this sounds advertise-y.
In the general case, it is. User-defined classes can use whatever truthy semantics they like. Explicit is better than implicit in this case.
This is the primary reason for me. I work on RHEL5 and RHEL6 machines. Anaconda makes my life so much easier.
off topic, but I always wanted to know - why does your website looks like it got stuck in the 90's? I find LWN's content to be awesome, but the design is awful.
This accurately reflects my experience proposing things on python-ideas.
In the general case, when type is unknown, "truthiness" is not a meaningful or useful concept, since `foo.__bool__()` has no prescribed semantics other than "returns a boolean." When type is known, truthiness may be useful, but in that case you're not testing for `is None` in the first place (because you already know the type).
Thanks for the honest answer, and good luck!
It's worth emphasizing that the time is only false at 0H *UTC*. Which might be 10am for some people, or not at any time at all - if you have a negative time zone offset (such as all Timezones in the Americas). That level of inconsistency is hilariously bad.
Any particular reason why you haven't contracted a redesign out to someone outside LWN? It's more likely to get done if someone's assigned to work on it dedicatedly.
`if var` is not an antipattern, it works the way it does for a reason, and if it were a discouraged pattern, objects would not be able to implement `__bool__` Objects can define their own truthiness for a reason, so that way they can hide the implementation of what it means to be true or false behind itself.
&gt;obviously And what's the "obvious" difference? They look the same to me. If you want static checks, you've got the wrong programming language, I'm afraid.
`python -m bootstrap` will run `bootstrap.__main__`, by the way. I'd recommend to create that submodule and put the contents of `if __name__ == "__main__":` from `bootstrap.main` inside. (Really, doesn't `-m bootstrap` look better than `-m bootstrap.main`?)
Most of the time, when I use `if var:` or `if not var:` (rather than `if exp:`), the `var` is explicitly expected to be a collection type, and it needs to be handled differently depending on whether it is empty or not.
&gt; I think you mean it's a common antipattern No. The whole point of `__bool__` is to allow this useful pattern and avoid pointlessly long-winded `if container is not None and len(container) != 0`. &gt; Testing whether var is None is faster, more correct, and more readable than just testing var. Testing whether `var is None` has completely different semantics than asking if `var` is truthy. On purpose. As a result, it can't be "more correct".
&gt; They look the same to me. This is a silly thing to say, the implementation is the obvious difference. The word "immutable" has a very well-defined meaning in our field.
Seems to me that the coders should have written "if sometime is not None"; got sloppy and wrote "if sometime" and came a cropper with a badly implemented feature of Python. It does need changing the only False time would be back at the onset of the big bang and we don't need to base computer zero-time then ;-)
I have serious, deep love for [pyvideo.org](http://pyvideo.org), and the search is pretty good. e.g. * [metaclasses](http://pyvideo.org/search?models=videos.video&amp;q=metaclasses) * [iterators and generators](http://pyvideo.org/video/1709/iteration-generators-the-python-way)
That only works for container types. As you may have noticed from the article, dates are not container types.
That is correct, conda installs dependencies using a pseudo Boolean SAT solver.
Yup. It comes prepackaged with Windows installs, but most Linux distros seem to keep it as an extra, as does OSX.
On the political note, it's good to have a "king", if the king is very judicious in how he overrides consensus and bureaucracy. Guido Van Rossum has certainly shown himself to be worthy of the BDFL title, unlike some other project's equivalents.
&gt; It does need changing the only False time would be back at the onset of the big bang and we don't need to base computer zero-time then ;-) The time you're talking about (an absolute time stamp) has no relation with the time discussed (the time of day).
You may be of the personal opinion that if myFanceObject: ... is a bad syntax, but the language is specifically designed to be used that way. There is a universal API used to determine if a given object should be regarded as true or not specifically to allow people to write code like the above. Doing so is Pythonic. I would argue that it's not one of the best design features of Python, but it's definitely by design.
&gt; Yes, actually. Other objects don't have a len(), so testing their bool() Er… considering `__bool__` and `__len__` can be separately overridden, no. &gt; is a waste of CPU cycles. Now that's pointless nano-optimization at its finest right there. Bravo. &gt; If I see if foo: and foo is not a container, I'm going to be stuck wondering when it's supposed to be falsey and what the author knows that I don't. Considering the exact same question occurs with a container, that seems to be a sensible course either way. Also numbers. &gt; This is bad style. It still hasn't become bad style since your last assertion thereof.
&gt; Considering the exact same question occurs with a container, that seems to be a sensible course either way. No, it isn't the same question. *When working with containers*, `if foo` is just shorthand for `if foo is not None and len(foo) != 0`. I don't understand how you think that question translates to non-containers. Perhaps you think you can just chop off the `len(foo) != 0` part? But that's not what `bool()` actually does, so this translation is simply wrong. `if foo is not None` is clear and concise, and I know it doesn't have a hidden trapdoor in it, unlike `if foo`.
If you want to go over the descriptors then cafepy has some [very good material](http://www.cafepy.com/article/python_attributes_and_methods/python_attributes_and_methods.html). For metaclasses there's [this](http://www.cafepy.com/article/python_types_and_objects/python_types_and_objects.html) Cafepy is awesome imho :) 
A very well-defined meaning in *non-duck-typed languages*. Take Haskell, for example: f :: [a] -&gt; [a] f xs = ... Is `xs` mutable? No, it's not - f is known to be pure. g :: IORef [a] -&gt; IO () g xs = ... Is `xs` mutable? Yes, it's a freaking IORef. Now, same thing in Python: def f(xs): ... def g(xs): ... Is `xs` mutable or immutable in either of these? Hell if I know. Even if these functions use `append` or something like that, can you really be sure that `append` changes the existing object? And how do you prove *immutability* when anything done by either function can potentially have side effects? &gt;the implementation is the obvious difference Implementation is completely irrelevant here, the interface makes the difference. Did you actually see the implementation of Python structures? Are you aware, for example, that strings are internally mutable as long as they only have exactly one reference?
Python makes a point of allowing lots of false values. Contrast with Ruby where only `false` and `nil` evaluate as false in a conditional—`0`, `""`, etc are all true in Ruby. So clearly it's a very intentional part of Python, and nowhere is it said that `if foo` is a shorthand for `if foo is not None and len(foo) != 0` or that this kind of evaluation is limited to container types. It depends on what's returned by `obj.__bool__()`, which just happens to default to checking if `obj.__len__() != 0` if it's not defined. Obviously container types are the main motivation for this (thus the fallback when `__bool__` isn't defined) but if they were the *only* motivation then there would be no reason to have the `__bool__` (or `__nonzero__` since forever ago) magic methods. Python's culture is really, really picky about introducing concepts that they don't really, really mean to be there, so your argument that `if foo:` on anything other than a container (or the basic `0` or `""` kinda values) is bad style is just unfounded. edit : Obviously dates evaluating as false is complete nonsense though, and I personally would say `if d is not None` when dealing with a date because it doesn't have a sensible interpretation as a boolean to me. That is if `None` is the only non-true value you expect I do prefer explicitness as well... but you're a bit off about the container types thing.
It always could explode in your face. You run into the problem less often with Python 2, but it's harder to anticipate and understand it, so it's actually harder to write properly reliable code.
No, really immutability is pretty well-defined everywhere. It seems you're confusing values with variables. Asking a priori whether the abstract variable ``xs`` in the source language is mutable or immutable is not well-defined question in Python, in Haskell it is because of the constraints of type system. But that doesn't change the fact that are values with the property of being mutable and immutable that can be assigned to ``xs`` and this concept is very clear indeed. If ``xs`` references a *frozenset* then it's value is immutable, if it references a *set* then it's value is mutable. How the argument ``xs`` is used in the function ``f`` or ``g`` doesn't determine the properties of the argument passed to it though.
No, I'm not confusing anything. In both Haskell examples the *variable* xs is obviously immutable due to language design. The value of an IORef, however, is not. &gt;If xs references a frozenset then it's value is immutable, if it references a set then it's value is mutable. And what's the actual difference between a set and a frozenset? In CPython, they actually share an implementation; the only difference is that frozenset does not export methods like `add` and `remove` (well, that, and frozenset has a `__hash__`.) Unless the function you pass it to uses these methods, you can assume that the value it accepts is immutable, even if it's not represented as such.
&gt; And what's the actual difference between a set and a frozenset? One has the clear property of being mutable and other is immutable as determined by their implementation. If you pass a mutable set into a function and don't update it in the body of the function, it *behaves* identically to immutable set but that doesn't mean the value itself is immutable. Usage doesn't determine the properties of the data structure, the implementation does.
Ah so it's document-oriented? Cool. 
I am not criticizing Pythons Unicode handling in general, that's pretty good for most part. But that something trivial like: for i in os.listdir("."): print(i) Becomes a ticking time bomb is not only not exactly obvious, there doesn't even seem to be a proper way to fix it. Having print/stdout being basically unusable is rather irritating.
Uh, one word: Clojure.
I tried pyvenv on 3.3 and found it to be a black hole. But I just got up and running with pyvenv on 3.4 *very* quickly. I never even installed anything as root! $ cd Python-3.4 $ ./configure &amp;&amp; make [...] $ ./python -m venv ~/.virtualenvs/test34 /home/rspeer/.virtualenvs/test34/bin/pip $ pip install ipython [...] $ ipython3 Python 3.4.0 (default, Mar 18 2014, 17:41:21) [...] &gt;&gt;&gt; ipython was unhappy because it was missing sqlite and readline support, but I think that's because I just compiled Python, which I haven't done before on this machine. I probably didn't give it the right dev libraries.
yep. Its the exact same thing with the re module's Match objects: http://docs.python.org/3/library/re.html?highlight=re#match-objects &gt;Match objects always have a boolean value of True. Since match() and search() return None when there is no match, you can test whether there was a match with a simple if statement and probably a lot of other parts of the standard library. It makes sense for each object to define its own bool() method so that it can return false depending on the object. Since match objects always have at least 1 thing in it, it makes sense that it will always return true with datetime, it ALWAYS represents a date. always. the only time i could see it returning false if it was initialized to something like datetime(-1,-1,-1,-1,-1) or whatever. Midnight is a date, it should not be coerced to false, that seems like a C thing rather then a python thing (with 0 always equaling false no matter what)
That's a problem with API, not language design. The guy I replied to argued against the language design, which I do not agree with. I do agree with you, whereas the API is bad.
I think time and history have continued to show that science &amp; technology are at best amoral.
Brillant game mate, can't get enough of it, it's that Tetris craze all over again. 
I recommend using Pandas for loading, indexing into, and manipulating the data. I would then just libraries like numpy, statsmodels, scipy, pymc, and scikit-learn to do whatever modeling and visualization you need. Matplotlib's pyplot module gives a matlab-like plotting toolkit.
xlwt and xlrd work with Excel files.
I believe there was a pretty good consensus that a falsy 0 UTC was a bad idea on the mailing list. A long thread doesn't necessarily mean there was conflict, and the only other forms of conflict I can see are some small trips in the bug reporting system.
I went with PySide. You can to if it meets your needs, otherwise check out PyQt. Understand the licensing terms of each before you dive in!
That's the thing though. `bool(0)` is `False`. The question is whether or not a time object is close enough to a number. If `bool(0)==False` then should `bool(time(0,0,0))==False`? 
Doing `if foo` is not Pythonic, at least according to the Zen of Python. Explicit is better than implicit. The fact that you can do it is a side effect of the `__bool__` method, and not a part of the language that was designed specifically. If you want to check if something is or isn't `None` we have something for that: `if foo is None`. The only case to be made for the Pythonic use of `if foo` is for checking whether a container has elements in it. Otherwise we would have to use `if foo is not None and len(foo) != 0`. And a time is not a container. It is closer to a number, and `bool(0)==False` and `bool(0.0)==False`.
No, because time(0,0p) is not an integer. It semantically does not make sense for a valid time to equal false. Its not like an empty string that is a valid string yes but is still nothing, date)0,0,0) is midnight 
You don't need all those `if` statements, you can just do e.g. print('Midnight evaluates to ', bool(datetime.time(0,0,0))) 
But 0 is a valid number, why should it evaluate to False?
I haven't run the code, but you seem to have gotten it working. One thing I would strongly encourage is to use a real datetime column so that you can appropriately sort the sensor values. You're almost there. Ditch the Date and Time columns for a single DateTime column. import datetime dt = datetime.datetime.strptime(date + time, '%m%d%Y%H%M')
What does it even mean to say that a time is true or false? Why be all upset because an arbitrary computer concept doesn't accord with a different real-world concept? The relevant question might be whether is a time variable was defined or undefined, not whether it was true or false.
Very impressive, is it used in production? If so, tracking what sorts of data and volume?
I believe he's confusing it with Ruby because he later adds "—it works just fine for most objects, as they always evaluate to True" I like the falsyness of objects but for dates this is ridiculous, considering the epoch as falsy would still be silly but at least it would be just *one* falsy value.
I can see two more listed there and they are either inactive or not available.
If you want to check for None, just check for None.
I've made a 3.4 env already, and pip worked out of the box. That's supposed to be the exciting thing about it. I'm pretty sure it's using "ensurepip" internally. I don't think anything magical happened besides that -- making the venv and running pip was literally the first thing I did after compiling 3.4 from source.
I think people can read, it's just that your pip *should* work, and *does* work when other people try it, and so there's nothing to go on without more information. My guess is that there is something wacky about your Python setup. Here are some questions, then: * Do you have any environment variables set relating to Python? A few users have been having trouble with virtualenvs because they'd forgotten that they hacked their PYTHONHOME a long time ago. * Do you have some Python-related software installed that futzed with your startup scripts, such as your .bashrc? * What OS is this? What did you use to install Python 3.4? What package manager or installer did you use to install previous versions of Python? * If you just run 'python' in your new venv, do you get Python 3.4? (If you don't, there's something clearly wrong with your setup.)
That makes a lot of sense. So, if I understand correctly, `[x for y in z for u in v]` maps roughly to: tmp = list() for u in v: for y in z: tmp.append(x) That is, all the variables are in the same scope, and each 'for - in' clause adds a for loop to the *outside*. 
I'll just ignore the insult. Why don't you define what you mean by immutability because I believe you're referring to a different concept entirely that seems somehow related to runtime behavior in some way. My definition of immutability is orthogonal to the runtime behavior and typing discipline of the language so your comment about reading the article on duck-typing has me scratching my head about why you would say that.
A trick I've used on systems where it's hard to compile NumPy, but I don't want to toggle global site packages on in my virtualenv, is to just make a symlink to numpy in my virtualenv's site-packages directory.
I like how `from __future__ import braces` is *still* a SyntaxError there, but this time it says "hell yeah!!!" instead of "not a chance". Can't wait for them to come out with "C with Significant Indentation".
Thanks for the feedback, that's very welcome! I will improve the docs where I can.
http://pandas.pydata.org/pandas-docs/stable/io.html#io-excel
No, the order of the loops are exactly the same as reading the comprehension from left to right: tmp = [] for y in z: for u in v: temp.append(x) # should probably be u 
Okay, but that's not what's happening. It's timezones ahead of GMT when looking at midnight UTC that are false; e.g. 1am in St. Moritz. It's never false in New York.
why not? It's simple, addictive and I guess it's kinda new...
Datetimes versus times.
interesting, but what is this bootstrap ?
Thanks. However, cmd is off topic here. cmd is made for building so-called read–eval–print loop (REPL) programs. You can use this concept for building command interpreters such as interactive shells. 'Interactive' is the key word here, REPL programs usually read commands from user input on a tty. You know, your IPython, the GNU debugger, your shell and the Python interpreter (when started in interactive mode)... all of these programs are REPL programs. I agree that these are command line tools, but a special class of them. 
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Bootstrapping**](http://en.wikipedia.org/wiki/Bootstrapping): [](#sfw) --- &gt; &gt;In general parlance, __bootstrapping__ usually refers to the starting of a self-sustaining process that is supposed to proceed without external input. In [computer technology](http://en.wikipedia.org/wiki/Computer_technology) the term (usually shortened to __booting__) usually refers to the process of loading the basic software into the memory of a computer after power-on or general reset, especially the [operating system](http://en.wikipedia.org/wiki/Operating_system) which will then take care of loading other software as needed. &gt;The term appears to have originated in the early 19th century United States (particularly in the phrase "pull oneself over a fence by one's bootstraps"), to mean an absurdly impossible action, an [adynaton](http://en.wikipedia.org/wiki/Adynaton). &gt;==== &gt;[**Image**](http://i.imgur.com/XGcJiWC.jpg) [^(i)](http://commons.wikimedia.org/wiki/File:Dr_Martens,_black,_old.jpg) --- ^Interesting: [^Bootstrapping ^\(statistics)](http://en.wikipedia.org/wiki/Bootstrapping_\(statistics\)) ^| [^Bootstrapping ^\(compilers)](http://en.wikipedia.org/wiki/Bootstrapping_\(compilers\)) ^| [^Entrepreneurship](http://en.wikipedia.org/wiki/Entrepreneurship) ^| [^Bootstrapping ^\(finance)](http://en.wikipedia.org/wiki/Bootstrapping_\(finance\)) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cg6eaqk) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cg6eaqk)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Is python weekly inactive for a year or so? Last issue in archive is from march 2013?
One great interactive website for python is www.checkio.org, I found it in comment section last week right on this subreddit and have been in love with it since. basically you get tasks, you solve them and then you can check other user solutions, post yours, discuss them and so on. though most of the stuff is a bit above beginner level so be cautious.
Forgot [pathlib](https://pathlib.readthedocs.org/en/pep428/)
you can give http://editra.org/ a try. I think most of it is written in python(though I am not sure if it is python3). Something similar is http://peppy.flipturn.org/
Yeah, a giant 'if' statement for inventory items is not a game. I think he needs to actuality code something.
Looks like you have to log in to access any of the content. I wish sites would not do that. I like to window-shop first.
&gt; If we want to make a copy of the list values, we have to make a little tweak: list1 = list2[:] In [1]: my_first_list = [1] In [2]: my_fourth_list = my_first_list[:] In [3]: my_first_list[0] is my_fourth_list[0] Out[3]: True You're only shallow copying the list, however: "The difference between shallow and deep copying is only relevant for compound objects (objects that contain other objects, like lists or class instances)" [documentation](http://docs.python.org/2/library/copy.html) In [5]: from copy import deepcopy In [6]: list1 = [[1]] In [7]: list2 = list1[:] In [8]: list3 = deepcopy(list1) In [9]: list1[0] is list2[0] Out[9]: True In [10]: list1[0] is list3[0] Out[10]: False In [11]: list1[0][0] is list2[0][0] Out[11]: True In [12]: list1[0][0] is list3[0][0] Out[12]: True wanna see something fun In [25]: a = 1 In [26]: b = 1 In [27]: a is b Out[27]: True In [22]: a = 999 In [23]: b = 999 In [24]: a is b Out[24]: False [documentation](http://docs.python.org/2/c-api/int.html#PyInt_FromLong)
integrating with google play services is not nearly as interesting as how the actual game is implemented. https://github.com/tito/2048/blob/master/main.py