I think that at point (2) you mean \_\_getstate\_\_..
Also: bool('True') True bool('False') True You have to use 1 and 0 instead :) 
Thanks for benchmarking this! I didn't know about the timeit module. That's pretty damn cool (I've just been using time.time()).
Or you can use l.clear().
&gt; x, = f() &gt; x = y, Crazy.
You're taking the bool of a string, and any string besides `''` is true: &gt;&gt;&gt; bool('') False
[ideone.com](http://ideone.com) lets you choose between 2.7.3 and 3.2.3. 
Can't believe this project has existed that long. I'm still holding my breath for NumPy and Matplotlib support though, so I really hope they come soon :)
Thats why we have this awesome matrix multiplication operator...
Indeed. Tuples are how Python passes args to functions. Function args are seldom homogeneous. 
kinda cool, should support keyword args too but I can use my imagination on how that changes the implementation. 
Explaining new style vs old style classes is something I think only a season Python programmer could do. I say that because I've been using Python forever and I'm only vaguely familiar with the differences (slots, etc). Another thing I use to find really good Python developers, who have real world experience, is explain a unicode bug. It's the craziest thing. I ask a candidate, "what do you think it means if you see 'Â' where an apostrophe is supposed to be?" People with Comp Sci degrees from CalTech are stumped. Someone who's spent a year writing real-world Python code knows immediately: a utf8 document was decoded as latin1 (or similar). It happens all the time, especially if you get questionable data from a third party. That's the best test for experience I've ever come up with.
I have a feeling they will never be as complete as the CPython versions. Can you imagine how much work it would be to port NumPy, Scipy, Matplotlib, and Pandas from CPython to PyPy? It's taken at least a year to get about half of [numpypy](http://buildbot.pypy.org/numpy-status/latest.html) working. This will end up being like Python 2 + 3, with the scientists stuck on CPython for many more years and the Django/web/GUI-land people in PyPy land.
If 0 &lt; x &lt; 10:
it's not 0.2 microseconds, it's 65% of the time of list(x). It's a decent optimization of an already fast operation. Comparing any benchmarks on a 3 element list is going to be comparing very small numbers.
That probably should be the default behavior, honestly (warning mode at least).
I took some convincing to move to the notebook format from the repl format, but you're right. Watching a coworker just click one cell to rerun his setup code and then run a few different cells to see what was going on convinced me. Now I just need to get all the keyboard shortcuts remapped to something sane. ctrl-m is driving me crazy.
Maybe so, but it receives the apifunction as an argument so I still find it weird that it is in a class it has absolutely no coupling with. I'd probably make it a decorator. 
That is weird. Kinda funny, too.
I guess I don't mind if NumPy, SciPy, etc. aren't ported in their entirety, once there's an NDArray class and Python code runs fast (near C?) A plotting library is definitely a necessity though. Maybe one written entirely in Python with an HTML backend? 
 name = 'freshhawk' site = 'reddit' print "{name} is on {site} right now".format(**locals()) is fantastic for throwaways and one off scripts. locals() is fast but it seems dirty to do that in production code.
Since you're thinking of using app engine. How about doing a kind of stackoverflow for the different subjects in your school. That would be quite useful and pretty much achievable with your favorite python framework. Lots of them work with GAE.
`li = [0] * 10` 
Well, I do like the terseness of the ternary operator in C. It looks more clean, even if I believe it's less readable (but not by much).
I looked through 'man python', but didn't see any of the relevant configuration lines. I added the following to ~/.pythonrc try: import readline except ImportError: print "Module readline not available." else: import rlcompleter readline.parse_and_bind("tab: complete") Which I found here: http://docs.python.org/2/library/rlcompleter.html I could add it in my program, of course, but I'd rather not. Tab still does not offer suggested completions while in interactive mode. What am I overlooking?
Which is a framework for data analysis: http://pandas.pydata.org/
&gt;does exactly what you think it does A glowing endorsement of any syntax (no sarcasm)
Hooray for formatting. Parent fixed!
 # mymodule.py class OnlyOne(object): pass one = OnlyOne() OnlyOne.__init__ = TypeError 
Best thing since Matlab?
It can also be written l = range(10)
This is extremely useful when you want to iterate through two lists simultaneously, e.g. if unit testing: for e, a in zip(expected, actual): self.assertEqual(e, a) 
tup (like up) le (like pull) I'm Australian
2d array initialization gotcha: &gt;&gt;&gt; lists = [[0]*10]*10 #initialize 2d array to all zeroes &gt;&gt;&gt; lists[0][0] = 1 #set the top left value to 1 &gt;&gt;&gt; import pprint; pprint.pprint(lists) [[1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0]] Infinitely recursive lists: &gt;&gt;&gt; xs = [] &gt;&gt;&gt; xs.append(xs) &gt;&gt;&gt; xs [[[...]]] &gt;&gt;&gt; for x in xs: ... print x ... [[...]] Not really 'wat' level.. just kind of interesting.
I found this one day I was really bored and learning about iterated function systems: &gt;&gt;&gt; iterated = lambda f, arg, n: f(arg) if n &lt;= 0 else iterated(f, f(arg), n-1) &gt;&gt;&gt; iterated(repr, 'hi', 0) "'hi'" &gt;&gt;&gt; iterated(repr, 'hi', 1) '"\'hi\'"' &gt;&gt;&gt; iterated(repr, 'hi', 3) '\'\\\'"\\\\\\\'hi\\\\\\\'"\\\'\'' &gt;&gt;&gt; iterated(repr, 'hi', 5) '\'\\\'\\\\\\\'\\\\\\\\\\\\\\\'"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'hi\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'"\\\\\\\\\\\\\\\'\\\\\\\'\\\'\'' &gt;&gt;&gt; iterated(repr, 'hi', 8) '\'\\\'\\\\\\\'\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'hi\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\'\\\\\\\'\\\'\'' The number of slashes grows exponentially (2**n). 
You're right. In Java the scope of a reference is defined by brackets. I'm picking up a lot of Java lately, but I'm relatively new at the particular craft, and didn't know that. Always thought objects with what I imagine as "independent bodies" (functions, classes, methods, ...) delimited scope. Always thought of looping mechanisms as part of the containing object. Although, the Java way does seem to make more sense now if you think about the fact that the value of the variable (or its existence even) are dependent upon the conditions of those constructs. Hmm... Thanks. 
That font is really tiny and faint. Also, the text crashes into the right margin when I hit ctrl+ in my browser to increase the font size. 
Great point. I did not know that issue. Where I reside the receiver does not pay for the text message. This was a project done to solve one of my own problems. So I did not really look into how it would work in international markets. Thanks for clarifying the point. :)
Variable scope and nested functions python 3's bullshit division (let's change the semantics so translation is nigh impossible!) 
As someone who is still confused, what causes the error?
Build your own programs and add them to your portfolio. When a employer asks "what kinda of python experience do you have" you simply email him the file or better yet lead him to your website documenting all you have done. Oh if you don't have a website to showcase your abilities I suggest building one ASAP
It's not a Python book, but *Effective Java* by Josh Bloch has an excellent chapter about object serialization using the [`java.io.Serializable` interface](http://docs.oracle.com/javase/6/docs/api/java/io/Serializable.html). Basically, you should implement `writeObject` and `readObject` for your class and only serialize Java primitives and arrays of primitives. In Python terms, use `__setstate__` and `__getstate__` and make sure you pickle only Python built-ins. This way, newer versions of the class can still be compatible with older pickles, unless the changes to the class are really drastic. 
Look up `Ellipsis`. :-)
(In python 2.x only) if 's' &gt; 1: print "Foo" else: print "Bar" Now you'd expect an exception, but you don't get that.
What kind of programs would you recommend?
It's annoying that Python built-ins can't be monkeypatched. On the other hand, it's comforting. This would be evil: &gt;&gt;&gt; list.__len__ = lambda self: 42 &gt;&gt;&gt; officers = ['Kirk', 'Spock', 'McCoy'] &gt;&gt;&gt; len(officers) 42 But sometimes I'd like to be able to monkeypatch an *instance* of a built-in: &gt;&gt;&gt; officers = ['Kirk', 'Spock', 'McCoy'] &gt;&gt;&gt; officers.size = officers.__len__ &gt;&gt;&gt; officers.size() 3 Oh well. 
It's a python3 feature so I don't use it, but in Clojure it's common to do something like first, *rest = some_list If you know what type your dict value is you can unpack it at the same time as your key. ML and Haskell use something similar as standard practice.
Yes, if you're using an old (2.x) Python...
&gt; If you know what type your dict value is you can unpack it at the same time as your key. Hmm. Suppose I have friends = {'Fred': ['555-1212', 'fred@foo.com'], 'Sally': ['unlisted', 'sally@bar.net']} Are you saying I can use `*` to unpack each item as `name, phone, email`? How would that code look? 
This is Python 2.x only, along with some related "What?" moments. You can redefine integers: import ctypes value = 2 ob_ival_offset = ctypes.sizeof(ctypes.c_size_t) + ctypes.sizeof(ctypes.c_voidp) ob_ival = ctypes.c_int.from_address(id(value)+ob_ival_offset) ob_ival.value = 3 print 1+1 Take a guess as to what this prints? Hint: it's not 2. Also note that doing much of anything after this can easily crash Python - notably print 3 - 1 crashes for me after this.
You don't need * for that. for name, (phone, email) in friends.items(): print "{name} {phone} {email}".format(**locals())
Ha, good question. But seriously, in Python, you can't *rebind* variables in another scope (even an outer scope), i.e., a value not in your current scope cannot be on the left hand side of an expression (an "lvalue"). In the above code, g() creates a new scope. g() can *access* variables from another scope (i.e., `print x` would work fine), but it can't rebind them. Before Python 3, Python sort of solved this with the `global` keyword. You *can* rebind a global variable if you declare it global. For example: &gt;&gt;&gt; x = 1 &gt;&gt;&gt; def f(y): ... x = y ... &gt;&gt;&gt; f(10) &gt;&gt;&gt; x 1 &gt;&gt;&gt; def g(y): ... global x ... x = y ... &gt;&gt;&gt; g(10) &gt;&gt;&gt; x 10 But nested functions are an oddity. In my first code snippet above, `x` is *not* a global -- it is in the scope of `f()` -- so you can't declare it global in `g()`. Which means you can't rebind it at all. Python 3 fixed this by introducing a `nonlocal` keyword, which basically means "in an outer scope that's not the global scope".
And `pep8` (package, command) and `autopep8` (same) and some IDEs.
It is. But knowing two things should be a choice and not compulsion. In open source we can pick good qualities from one project and apply to another. 
You are most welcome :-)
True. But somehow your earlier comments implied I can use `*` to do that. Oh, well. Never mind. 
It's not easy to reflect back on everything you (or a whole project) tried and failed at. It's good to do though.
question, how do I pass just the keys of a dict into the url, instead of the keys and values into the params? 
Can you explain this better, why would x += y be x = x.\_\_iadd\_\_(y) ? The python docs don't seem to mention this behavior, it seems to imply that x += y is simply x.\_\_iadd\_\_(y). http://docs.python.org/2/reference/datamodel.html#emulating-numeric-types
Hm, what is crazy about this?
Figure out what you like doing in Python. Do a lot of it, and put everything on github. Every little helpful script, every failed and successful project, even brainstorms (on gist) and your resume, put it all on there. For interviews, brush up on core programming, and OO concepts. Learn and use TDD, read about Agile (Scrum, Kanban, etc), use version control, and check out Rob Martin's Clean Code. Even though I disagree with some of what he says is best practice (and find a lot to be less true for Python than Java), a lot of it is useful and interesting. Addendum: Also in interviews **ask questions**! Nothing says you're more interested than thoughtful questions about what goes on. My favorite I like to ask is what the company's policy on open source is and if developers are allowed to contribute to open source projects.
Is that the only effect that more programmers, developers, etc would have? I think it much more likely to drive innovation and improvement in software than devalue developers.
Will this do anything for me that PyCharm doesn't?
No, it wouldn't be the only effect. Overall it would be a good thing to have more programmers.
Note: This was years ago. At my high school, our deputy principal wrote a role call application. He placed bar code scanners all around the school and you can go up to any scanner and scan your student id to check in. There was also a printer so if you were late you'd get a late slip. This should be something that's trivial to do these days given the large array of devices and apis available. I'm actually extremely interested in this area (automating/improving school processes).
Is this just another way to say keep the logic and GUI separate?
Why use this over dict.get(key) ?
Here's what I think, in order of ascending mastery/comprehension of the language. Beginner: * understands the basic syntax * familiar with the most frequently used data types and commonly used parts of standard lib * can write scripts to do simple things such as retrieving data from a web API or manipulating a text file on disk * basically a beginner should able to use the language for simple tasks. Intermediate: * everything that the beginner can do * understands classes and OOP (when and when not to use them) * familiar with more advanced but still useful parts of standard lib as well as more advanced data types * can implement more advanced features, and implement them relatively efficiently (vs. simply implement them correctly) * knows about certain useful syntactic sugars (e.g. list comprehension) and general good coding styles * knows about and has worked with one or some popular frameworks (e.g. Django) or external libraries (e.g. Requests) * basically an intermediate Python programmer should be able to write relatively good programs that do most things that you may encounter in a day's work. Advanced: * everything that the intermediate person can do * understands the functional nature of the language * able to extend parts of the standard lib * has experience working with package managers like pip (not just using them to install packages, but to package own code) * knows how to profile code and optimize well * has experience with numerous frameworks and external libraries, and is able to read + understand most of how these frameworks/libs work internally (not just knowing how to use them) * some understanding of the internal workings of the language (e.g. interpreter, bytecode generation) * basically an advanced Python programmer should be able to do everything that you can do in the language for almost all productive tasks Expert: * everything that the intermediate person can do * able to implement C extensions * understands the interpreter, the different implementations (e.g. CPython, pypy), and their advantages + limitations (e.g. GIL for CPython) * basically an expert should understand (up to a certain extent) the inner workings of how the language works (not simply knowing how to write working, efficient programs to do things) Super Expert: * everything that the expert can do * understands how the interpreter is built and/or has contributed to Python repo * able to create (at least roughly knows how) own implementation of Python (which includes parsing the syntax, optimize to bytecode of some sort, and write the interpreter that can execute the bytecode) * basically a super expert is thoroughly familiar with the language standard GvR: * be GvR
Python 2 is still the more useful version and it's going to be around for years. There's more docs and tools available for it as well.
I was hoping one of them would come out as the clear winner, but you guys are actually pretty split.
I'd recommend either publishing your python program on github or bitbucket or so, so you can always show what you've written. Either you could work on some open source project.
Of course. Being a [certified Unix](http://en.wikipedia.org/wiki/Single_UNIX_Specification#OS_X) it should have. (Note that many non-certified Unix systems - e.g. Linux - have man pages as well :-). wrt to the .pythonrc, see if this works: $ python Python 2.7.3 (default, Aug 1 2012, 05:14:39) [GCC 4.6.3] on linux2 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; import readline &gt;&gt;&gt; import rlcompleter &gt;&gt;&gt; readline.parse_and_bind("tab: complete") &gt;&gt;&gt; readline. &lt;tab-tab&gt; readline.__class__( readline.__delattr__( readline.__dict__ readline.__doc__ readline.__file__ If it doesn't, I can't help you. If it does, see if you have this in your .bashrc / .zshrc / .tcshrc : export PYTHONSTARTUP=~/.pythonrc # tcsh should use set, etc. 
Sorry. Python 3 was a divisive move. :-/
Thanks! Didn't know that.
How does this qualify as `wat`? This does exactly what you'd expect &amp;#3232;\_&amp;#3232;
Humm true, it makes sense that the status is in the api class. Still since you're passing it everything else as an argument, you could also pass the status or even a function to get the status. Also "get_status" is not very pythonic. Anyway I'm sorry if I'm nitpicking I know it is annoying when you post code online and that happens.
http://upload.wikimedia.org/wikipedia/commons/7/7c/Supine_and_prone_2012-02-20.jpg
scipy, numpy, matplotlib all have Python 3 support, as does cython. scikit-learn is in-progress (and should be finished in the next couple of months). PIL has no Python 3 support but the Pillow fork seems to have some working Python 3 support (the author noted "by PyCon 2013" in bug reports - that's in 2 weeks), matplotlib notes that since it uses PIL it doesn't offer some JPG functions in Python 3. Django seems to have Python 3 support but 3rd party libs might not. PyPy is working on Python 3 (no ETA). The whole community is moving to Python 3, I suspect scientists (I'm one) will take longer as a lot of the underlying libraries are still being moved. More people switch each year. Personally I'm going to be a laggard (whilst playing with Py3), as I don't want to add experimental code to my experimental systems.
This just in: Python noobs make ridiculous claims. More at 11.
This has an advantage over just writing stuff by yourself, because it shows that you can work in a team, and write code of good enough quality that others will accept it. Although some independent work is probably good to show as well.
Be careful with that idiom though, it will fail if `l` is something like 0, "", (), {}, anything that evaluates to False. I would prefer one of: if l is None: l = [] l = [] if l is None else l
I don't see what is strange about this one at all...
&gt; Can you explain this better, why would `x += y be x = x.__iadd__(y)` well, if you think about it, it *has* to be. A simple `x.__iadd__(y)` can not work if x is immutable (like numbers and strings are, for example); the method call cannot change the object x, so iadd must in some cases create a new obejct and reassign it to x.
Doing a stackoverflow system fit for schools and with full features is ALOT of work. Another approach would be using www.question2answer.org which is a stack overflow clone ,open source , and supports plugins, so it's relatively easy to add new features. So while writing features needed by your school , you would also take part in an open source project and help users around the world. Also the fact that it is used in many places , would help you convince the school to deploy it in a live project. But it's written in php, which is a drawback. 
Because cheap workforce isn't just found under a Christmas tree, you know.
This is a property of not using a closure. Not really a wat, but thank you.
it's syntactic sugar for if 3 &lt;= x and x &lt;= 9: (with x evaluated only once of course)
In every other case in the history of written language, commas seperate items. &gt; 42, does not make &gt; (42, None)
Immutable objects should not implement `__iadd__` then, so that the default add + assignment path would be taken.
Yes, that is indeed awesome, but as Mr. Bernhardt says in his talk, if you ever actually do this - wat!
You would use * if your list had more than two items, to consume all but the ones you specified. It's like *args.
The last link is full of wat, indeed. And there I was thinking that different scoping rules between list comprehensions and generator expressions is the worst offender.
thank god it doesn't create a new scope... that would almost completely defeat the purpose in most cases where I use with statements
Holy shit
What are the practical use cases for that?
dict.get is good for when you're not sure if a key is in the dict and want to get a default value. collections.defaultdict allows you to skip testing for and initializing the key when inserting. Another example (from http://docs.python.org/2/library/collections.html#defaultdict-examples): &gt;&gt;&gt; s = 'mississippi' &gt;&gt;&gt; d = defaultdict(int) &gt;&gt;&gt; for k in s: ... d[k] += 1 ... &gt;&gt;&gt; d.items() [('i', 4), ('p', 2), ('s', 4), ('m', 1)] Without defaultdict, that would be: &gt;&gt;&gt; for k in s: ... if k not in d: ... d[k] = 0 ... d[k] += 1 It only saves two loc, but is more Pythonic and, depending upon how large/diverse s is, may be more performant. The collections module in general is just a few handy objects that make it easier to do something you could do yourself differently, but will end up with cleaner, more Pythonic code if you use the stdlib implementation. 
Joining a large open source project and helping newbies has the benefit of learning a lot while you try to solve their problems. It exposes you to looking at multiple problems in multiple ways. Reputation online weights A LOT these days. Build it any way you can. Also, if python is your first language and you feel you have some experience programming already, maybe it is time to start your programming mastery journey. You can do your own research about what books you need to read. My advice is to start with [CODE](http://www.amazon.com/Code-Language-Computer-Hardware-Software/dp/0735611319). CODE is like an adventure novel, full of interesting historical bits, full of action. I loved it. After CODE, move to [SICP](https://github.com/sarabander/sicp-pdf/). You can also go through [the 1986 version of the course](https://www.youtube.com/watch?v=2Op3QLzMgSY&amp;list=ECE18841CABEA24090). If your brain hurts too much... set it aside for a future time when you will be stronger but realize that you need to go through it. I wish I would have gone through it 15 years ago. With the [death of Moore's Law](http://news.techworld.com/operating-systems/3477/moores-law-is-dead-says-gordon-moore/), the skills you will get from that course are even more valuable. 
You repeatedly misspelled "though". 
I've been in the position of hiring Python programmers. You get *a lot* of resumes, and most are obviously gamed for the job. Once we put out two job listings, one for Java one for Python and I noticed an awful lot of duplicate resumes where for the Python job, someone did r/java/python/g and sent their resume in unchanged. (Protip: Don't claim to have extensive J2EE Python experience!) What at least gets you in the top 10% of all applicants, if not better, is a respectable github/bitbucket/whatever profile. It doesn't matter where, and they don't have to be your own projects. In fact, if you've got a history of contributing to existing projects, it shows that you can read code as well as write it, and you won't try to invent the wheel. It also lets the developer in charge of screening resumes see your code right off the bat, which is important. The top few percent of resumes in fact read like this: ----- Joe Shmo / jschmo@email.com / github.com/joeshmo PUBLIC PORTFOLIO: * Any projects you created that I can see, either work-related or not. PROFESSIONAL EXPERIENCE: * Company, title, dates OPEN SOURCE CONTRIBUTIONS: * Project, accomplishments, dates (then education)
Would have been a lot easier to follow this if there was a video of him actually performing the speech... Does anyone have a link to it, if there is one?
That's a really good idea, my school made late students go all the way to the commons to pick up late slips, which always seemed more disruptive than just ignoring it.
I am quiet new to python and I sort of do this to set variable to some default value. Is this wrong and if yes , how should it be done otherwise?
No, other languages separate creating a new variable from changing an existing variable. Python's behaviour is definitely worse. (Also, class scope is entirely crazy.)
At least with the actual slide notes you can follow along with it unlike a lot of other slide decks that get posted.
A mix of poor language design and poor implementations. Smalltalk and Self proved you can do dynamic AND fast. JavaScript does have one phenomenal implementation, V8, but it is hampered by the brain dead language it has to run.
&gt; I appreciate the nitpicking actually! :D Ok then a few more comments :) *mdelay* is not needed. The value in *delay* may be immutable but you can always assign another value to the variable. "delay *= backoff" would also work. For example strings are immutable so you can't do: foo = '123' foo[2] = '4' But you can do: foo = '123' foo = foo[:2] + '4' Don't worry next time you call the function delay will be back to it's old self. I'm not entirely sure of what *status* is doing here since you will be returning the function as soon as you are able to call it and not get a socket error. If it is possible that the status changes while you're sleeping and you no longer need to make the api call then you probably need some kind of lock. If the status is changed by the *apifunction(**args)* call then you should only return the result after checking it was successful. Basically what I would do is make the poll_api an independent function. That wouldn't be in any class whatsoever. In the arguments, along with *apifunction*, it could get, instead of *success_list*, a predicate *check_status* function to check if it should continue as an argument. In python as your code shows it's pretty easy to pass functions around since they are also objects so this should work. Another alternative, which is probably over-engineering for this, is to use the [command design pattern](http://en.wikipedia.org/wiki/Command_pattern) to separate the logic of running/checking a command and polling. In that case your inner loop could be something like. command.run() if command.successful: return command.result
His point is basically this: if you write Python code, but do it in C, your C code will be slow. No fucking shit. For that matter, I could take any Python program and convert it into a C program by embedding the source code in an interpreter. And it would be just as slow as the original Python version, if not more so. The point is that the Pythonic way of doing things is often less efficient than the C way of doing the same. The difference is that the C code can narrowly be used only for the specific purpose it was written, whereas the Python code (because of the abstraction) will most likely work in a much greater range of scenarios. You *could* write a C function that uses some kind of duck typing, but you wouldn't. In other words, high level programming is slower than low level programming. Yup. We know. What he touches on but never really addresses is that there is no language that lets you be high level when you want to be, low level when you don't. It used to be that C programmers regularly used inline assembly before compilers were as optimized as they are now. What would do the world a whole lot of good is a new language, that's optionally as low-level as C, but actually does have all the goodness of objects. Think, C++, but without the mistakes. Objective C is actually pretty damn close to that ideal. Too bad about its syntax.
Nor does it in python: 42, == (42,) != (42, None)
In case you didn't know, there's this: http://www.scipy.org/Weave
Interesting...
I love weave. 3 lines of C++ the other day and my code had a 220x increase in speed.
Cython
Did we read the same slides? 
Smalltalk isn't really known for being fast.
import requests
You must have skipped all the slides where he made comparisons to C. 
Check out pudb: https://pypi.python.org/pypi/pudb. It's like pdb on steroids. (graphical interface!)
Use cases I use decorators for: - caching / memonizing - logging - profiling - any and all cross-cutting other concerns - arbitary checks, e.g. permission to run function, skip function in dry-run mode, enforce specific parameters or force abort if in debug mode, etc, etc. - wrapping arbitrary callables with try except, contex manager, db transaction calls, whatever - as function factories, remember @ syntax is optional Basically anytime you have the same setup/teardown/guard clause in more than a couple places it's a candidate for being a decorator.
His point was that there are some things that C does really well that could be added to Python to speed it up.
Actually I think he was arguing that there are things we could implement in Python to make it more efficient. He's just using C as an example of a language that does some of these things efficiently.
C people say that about every other language ever made. If only it was more like C it would be so awesome.. If you like C so much why don't you marry it?
&gt; a, (b, c) = 1, (2, 3) outer parens are superfluous. &gt; first, *middles, last = range(5) Produces syntax error in 2.7.3. I'm not sure what you mean by functions used to do this but *args and **kwargs work in side function def and function call
&gt; And the same for dicts. And the same for any mutable. The key understanding is that the "code" in the definition line is run once at import time (technically when definition is read as definition could be within a block, dynamically generated at runtime etc.). It is not run each time the definition is called. So, def foo(bar=[]) means you have one list that is shared between all calls to foo. Which, very rarely (e.g. accumulator in recursive functions), is cool feature.
That's the point of the talk. Five years ago with CPython this was the case. Newer implementations like PyPy can generate much better code for the `self.x = x` case than `{'x': x}`. Assuming that they're the same leads to slow code (when using smart JITs).
Or set __dir__
It's common (or required in languages without multiple returns) to modify parameters. But, it's poor Python in most cases. Should return modified list. And relying on multiple references to same mutable is like relying on hidden global vars. There's more explicit and cleaner ways to code.
Depends on your browser I guess but it looks fine on every computer I tried it on. 
This makes complete sense. inspect.getargspec expects a function object, but you're passing it a built-in function. Try comparing the following: &gt;&gt;&gt; def func(): ... pass &gt;&gt;&gt; func &gt;&gt;&gt; map One is &lt;function func at ...&gt; while the other is &lt;built-in function map&gt;.
Why would you expect it to return a list of character in yes as opposed to a list with a single string?
Ah, okay.
But if you implement something like a struct in Python, then it's not really Python anymore, because it can't be used in the same way. There's no dynamically added attributes in a struct, for example. You can apply it to his string example, too: Sure, you can use character arrays and manually edit them, but (1) that won't work with unicode, (2) it's not half as flexible as Python's duck typing. It's like using slots. Sure, it'll speed up your instanciation some, but at the expense of flexibility. You do that everywhere and you're not using Python anymore. That said, the interpreter could certainly use a V8-style optimization.
Wow, what is this actually doing? I can see it's changing some sort of variable that's one size_t and one void* after value in memory, but what exactly is it changing?
Now try not to accidentally introduce buffer overflows. ;)
Any mirror of this video somewhere that'll load in my browser?
url_string.format('http://so-on.com?id={id}&amp;ext={ext}', **dict_variable) The {text} lines in the string correspond to the keys in the dict.
I enjoy programming in Javascript but I still think it is a lousy language. Coffeescript seems to be what Javascript should have been.
You! Alien creature! You must be the reason people keep posting talk videos on the internet. Can you explain why this is useful? I've always been confused.
Did we watch the same talk? His whole point was that with strong JITs like PyPy's we don't need things like structs. We *do* need to worry about things like string copies, and we need simple APIs to allow us to do string manip without lots of copies.
Okay, something wasn't loading and it took up quite a bit of screen, so I've been staring at nothing like an idiot. Thanks though.
*'I wanted to use a pure C hash table implementation, but googling "C hash table" didn't bring up useful stuff.'* Wat. There are many excellent, well-established hash table implementations for C. Googling that exact phrase, brings up some of them, as well as a stackoverflow discussion that details the strengths and weaknesses of all of them. You're holding a talk, and you can't be arsed to do 3 minutes of googling to support your argument? Just wat.
Since I started working with REST APIs, Kadir Pekel's [Hammock](https://github.com/kadirpekel/hammock) is a beautifull piece of code for those who need to issue simple URL-based calls. Instead doing this: result = requests.post('http://example.com/my/rest/url/path', data='hello-world') Hammock allows you to do this: api = hammock.Hammock('http://example.com/') aip_path = api.my.rest('url').path result = api_post.POST(data='hello-world') or as a one-liner: result = hammock.Hammock('http://example.com/').api.my.rest('url').path.POST(data='hello-world') Still looking for a good approach on handling REST APIs on the server side. Anyone?
No, I'm talking about serializing something into a bool. For example, if I receive a string and want to interpret it as a bool, I can't use bool('True') since all strings are True. I have to receive something like 1 or 0 then go bool(int('0'))
This is mind-blowing! When I first saw it, WOW! print '-' * 30 Gives you a 30-dash line separator.
You have to hit next slide. The first slide is blank.
But in creating such JITs, you end up limiting what you're capable of doing. rpython is simply not as expressive as python, due to the limitations required to make the JIT work. I hope someday that they can make PyPy work with the whole body of Python, but I don't think it's realistic to expect.
&gt; JIT is now smart enough to optimize your objects past the level of dicts JIT is still in 2.x land. As Guido said at PyCon 2012, CPython and PyPy will co-exist for many more years to come. 
What about all the slides on where the point was "Stop using dicts when you need objects or named tuples, because it slows down the JIT"? Or the slides where the point was "It sure would be nice to pre allocate some data, beacuse it lets the JIT work faster (example, C does this)". He didn't mentin, but probably shouldn't have had to, that many many languages do this, even if it's an annotation hint, not a strict requirement.
I thought Python rejects things that speed up at the expense of readability?
Delphi? :-)
What about lisp?
I wonder if GPU memory transfer can be optimized with the Blosc approach. I haven't heard of anyone trying it but I would expect it to give an even bigger gain than the RAM version.
I couldn't say.
&gt;What would do the world a whole lot of good is a new language I'm fairly certain what we don't need is ANOTHER language. This is reasoning that prompts EVERY standard/language.
Not quite. I can design a View with a nice separation from the model which can't be run via a scripting interface. Why does this happen? the code will depend on things like mouse events explicitly vs a value I can explicitly manipulate through code. E.g., class BarView(View): ... def foo_change_view(self, value=False): if self.mouse_enter_event() or value: # do something else: #do something else ... This may be a shitty example but I am sick so it's the best you're gonna get :\
Cool, thank you.
So he makes a total of 4 points to claim the language to be slow, 2 of which assumes a particular scenario that has nothing to do with inherent features of the language but hypothetical usage scenarios he sees "most people" doing, and the rest 2 of which doesn't have a dominating contribution to the "slowness" at all.. Data structures and algorithms indeed... - Even if we ignore the fact that he is comparing a static array in C to a dynamic array in Python, dynamic array will not be "terrible slower" with even the simplest heuristic of doubling the array every time it is filled, and will yield O(n) amortized time, quite comparable to guaranteed O(n) of static array. - Even if we ignore the IO nature of the thing while reading from file, buffer allocation won't dominate the O(n) complexity for both scenarios, whether reused or created new. - For string splitting, if efficiency is indeed the concern, nothing prevents the Python user to have int(string[string.find("-", 1):]). - Again, (mis)usage of dict for a struct has nothing do to with the language itself. - Finally, how attributing problems to misusage of the language and asking it to grant more APIs is not a contradiction? 
&gt; That's the point of the talk. Five years ago with CPython this was the case. Newer implementations like PyPy can generate much better code for the self.x = x case than {'x': x}. Assuming that they're the same leads to slow code (when using smart JITs). Yeah, but he's talking about implementations of Python and Ruby that hardly anyone uses yet.
&gt; int(string[string.find("-", 1):]). That still does a string allocation. The C version does not.
&gt; Even if we ignore the fact that he is comparing a static array in C to a dynamic array in Python, dynamic array will not be "terrible slower" with even the simplest heuristic of doubling the array every time it is filled, and will yield O(n) amortized time, quite comparable to guaranteed O(n) of static array. Actually, he could/should have used a string comprehension. That would have been clearer code and the compiler would have more information about what you're doing.
Yeah I meant it doesn't have to be as crappy as he tried to make it.
&gt; What he touches on but never really addresses is that there is no language that lets you be high level when you want to be, low level when you don't. I don't see how you can see that he doesn't "address it". It's the point of the whole talk. That's precisely what he's asking for. *If* there were low-level APIs available *and* there were JIT compilers available *and* the JIT compilers were used (i.e. compatible enough with libraries to *be* used) *and* people used the low-level APIs THEN Python or Ruby performance would be comparable to C performance. That's his point. These high-level languages should evolve low-level APIs because pretty soon the interpreter performance will not be the bottleneck: the user's actual code will be (especially if it was written with the assumption that the interpreter is the bottleneck).
Boy, do I hate the "Python doesn't have variables" meme. What you mean is, "Python's variables don't work like C's variables."
I agree with MBlume. What you're saying is the same as what the speaker was saying. &gt; But if you implement something like a struct in Python, then it's not really Python anymore, because it can't be used in the same way. There's no dynamically added attributes in a struct, for example. Right. That's why he said that you should use idiomatic classes instead of using a "dict". If you use idiomatic classes then the compiler will compile it to a struct if and only if you never add magical attributes to it. &gt; You can apply it to his string example, too: Sure, you can use character arrays and manually edit them, but (1) that won't work with unicode, Why not? He's talking about allocations, not the difference between bytes and characters. &gt; ... (2) it's not half as flexible as Python's duck typing. You're still misunderstanding. He's not trying to restrict data types. If you read the comments he says that programmers should still be allowed to do everything dynamic. He's saying that if you are trying to convert a string to an integer, you do not need to allocate a separate memory buffer. That's true no matter what the datatype of the string/array. 
PyPy runs any old Python code. RPython is just the language PyPy is written in.
Inheriting from tuple isn't all that great.
I expect that the right hand side of the assignment to be a sequence (the left hand side is a list), and 'yes' is technically a sequence of characters.
&gt; let Python have pre-allocated lists *I think this is a very fair point. Often, you know how long your list will be, so if you want to, you should be able to optimize your list* In Python you can either use a generator or use "[value]*number" syntax to instantiate a list of length "number" with "value" in every index. &gt;&gt;&gt; def dumb(): ... x = [] ... for i in range(25): ... x.append(i) ... return x ... &gt;&gt;&gt; def comprehension(): ... x = [i for i in range(25)] ... return x ... &gt;&gt;&gt; def preallocate(): ... x = [None]*25 ... for i in range(25): ... x[i] = i ... return x ... &gt;&gt;&gt; timeit(dumb, number=100000) 0.38496994972229004 &gt;&gt;&gt; timeit(comprehension, number=100000) 0.278350830078125 &gt;&gt;&gt; timeit(preallocate, number=100000) 0.2539360523223877 Honestly, though, either your inner loop is simple and you can fit it in a comprehension, or it's complicated and the ".append()" is a pretty small percent of your runtime, so you won't get 2x speedup from preallocating.
I'm really curious. What were those 3 lines of C++ and what did they replace?
I understand the "knowing it all" fast thing, but ... I'm wondering about the kind of web apps people are writing with these.
 for i in xrange(len(item1)): m[item1[i][0]][item2[i][0]] += 1 where m,item1 and item2 are numpy arrays became - code = """ for(int i=0;i&lt;len_item;i++){ int k = item1(i,0); int l = item2(i,0); m(k,l) += 1; } """ inline(code,['m','item1','item2','len_item'], type_converters = converters.blitz,verbose=2,compiler='gcc') It's a step in calculating the jaccard distance.
I have bad eyesight and a small screen, and I don't max my browser window. Reduce your browser window size. Also hit ctrl+ once or twice. 
I dunno. I just figured I'd make a sample "singleton" as an instance of something in a module. When you `import mymodule`, you get one instance of `OnlyOne`, and because the init method is trashed, you're discouraged from making another `OnlyOne` instance. Something off the top of my head. 
You haven't been paying attention. You can now write that as dict = @{ @5: @25 }; x = dict[@5] The language is improving at an incredible rate. I personally think its the best application language there is. It has the perfect mix of static and dynamic typing and the APIs are fantastic. Edit Also while I agree in some cases using keywords instead of methods helps readability, in general i like the verbosity of the language. You rarely have to look up what the parameters are for a method call, which makes it infinitely more readable. 
While I agree with the first part ("excuses"), the "hard" things mentioned in the second part are a) not that hard and b) solved issues (just not in PyPy). Hash tables: Both v8 and LuaJIT manage to specialize hash table lookups and bring them to similar performance as C structs (*). Interestingly, with very different approaches. So there's little reason NOT to use objects, dictionaries, tables, maps or whatever it's called in your favorite language. (*) If you really, really care about the last 10% or direct interoperability with C, LuaJIT offers native C structs via its FFI. And PyPy has inherited the FFI design, so they should be able to get the same performance someday. I'm sure v8 has something to offer for that, too. Allocations: LuaJIT has [allocation sinking](http://wiki.luajit.org/Allocation-Sinking-Optimization), which is able to eliminate the mentioned temporary allocations. Incidentally, the link shows how that's done for a x,y,z point class! And it works the same for ALL cases: arrays {1,2,3} (on top of a generic table), hash tables {x=1,y=2,z=3} or FFI C structs. String handling: Same as above -- a buffer is just a temporary allocation and can be sunk, too. Provided the stores (copies) are eliminated first. The extracted parts can be forwarded to the integer conversion from the original string. Then all copies and references are dead and the allocation itself can be eliminated. LuaJIT will get all of that string handling extravaganza with the v2.1 branch -- parts of the new buffer handling are already in the git repo. I'm sure the v8 guys have something up their sleeves, too. I/O read buffer: Same reasoning. The read creates a temporary buffer which is lazily interned to a string, ditto for the lstrip. The interning is sunk, the copies are sunk, the buffer is sunk (the innermost buffer is reused). This turns it into something very similar to the C code. Pre-sizing aggregates: The size info can be backpropagated to the aggreagate creation from scalar evolution analysis. SCEV is already in LuaJIT (for ABC elimination). I ditched the experimental backprop algorithm for 2.0, since I had to get the release out. Will be resurrected in 2.1. Missing APIs: All of the above examples show you don't really need to define new APIs to get the desired performance. Yes, there's a case for when you need low-level data structures -- and that's why higher-level languages should have a good FFI. I don't think you need to burden the language itself with these issues. Heuristics: Well, that's what those compiler textbooks don't tell you: VMs and compilers *are* 90% heuristics. Better deal with it rather than fight it. tl;dr: The reason why X is slow, is because X's implementation is slow, unoptimized or untuned. Language design just influences how hard it is to make up for it. There are no excuses. 
Currently 26 upvotes for 3.3, -1 for 2.7. I think there really is a clear winner. 
Yeah, but don't run this after you had run `False = True` :D
'False' is a string and as such evaluates to True. 
It is finding the internal representation of the integer 2 in Python, and then rewriting the value of said integer to be 3. The offsets are just to get to the portion of the integer that is the value of the integer itself.
Writing C professionally I use memory allocation all the time, but never thought about it in python. This will really change my python :) 
I too vote for 2.7. I'm currently completing a MSc in civil engineering ans I use python (x,y) and I'm happy with it. I won't switch until the distribution does.
Either 2.x or 3.x will serve you well for learning - but if you get a job coding Python I would say be prepared to spend most of your time in 2.x. Many companies still use 2.x because that is what their code base is written in. And all libraries work with 2.x. Python 3 will have its day but not any time soon. There is still Fortran and Cobol code floating around so you can see that companies are not in a hurry to upgrade to the latest and greatest. Source? Python 2.7 is what I use to put food on my table.
If this is the measure then the OP should count physics-libraries that have support for 3.x vs. 2.x. I have not done this but would guess that 2.x has far more libraries that support 2.x.
Are you aware of `scipy.spatial.distance.jaccard`? I just refactored a bunch of (admittedly naive) Euclidian distance calculation code to use the `scipy` implementation and got a huge speed boost. Also, it's a little late, but I think you could eliminate that `for` loop and write it as the faster: m[item1[:, 0], item2[:, 0]] += 1
If you ever need to iterate through lines of input, either from stdin or by file name, then the 'fileinput' module is amazing.
Yup! The video will be up some time next week I'm told.
i dont really think this is a WAT, this is just how closures work with references isn't it...
As someone who has used Django on Jython on top of both Tomcat and Glassfish extensively, I'm going to go out on a limb and say that J2EE Python experience is possible. That said, I've been both interviewer and interviewee in the last 24 months. The amount of immediate hiring managers who flat out told me I was lying about something that they believed wasn't possible is staggering. The bullshit I've heard from other programmers ("I don't need to test, none of my software has ever come back to me" or "oh yeah, I've done regular expressions back in college. we tried to build a regular expression engine as a class...we failed as a class") leads me to believe that you probably weren't running into people who actually had used Jython for its threading capabilities. 
Interesting point, I hadn't thought of Jython. Though in that particular instance, I had received an identical resume that said *extensive Java J2EE* experience shortly before receiving the one mentioning *extensive Python J2EE* experience. The former being submitted for a Java opening, the latter for a Python one. Not knowing anything about regular expressions, what about building a regex engine seems unlikely, out of curiosity? My bullshit alarm would not have gone off for that alone.
isn't 'foo'[::-1] a better example ?
Check out the py3k branch, definitely not ready for prime time but getting close :)
Yes I see your point. I still don't like making an assumption about a "typical Python programmer". APIs being extended still wouldn't change the behaviour of that typical programmer. Why not instead have that typical programmer learn better about the already existing APIs and use them as correct as possible. (For example something as simple as knowing that inserting to the head of a list in a loop will give you O(n^2) time compared to appending to the end O(n).) Yes, this will not still make it as fast as C, but when you have those APIs to possibly make it as fast as C, it doesn't necessarily make the typical Python programmer to make better choices of data structures either.
I personnaly don't like HAML and other templating language to far from html, but I admit I never use one of them. I am happy with Jinja2 and I have no need to change. 
Could you mention some interesting Python-based open source projects that are suitable for someone without a huge amount of Python experience? I use Python at my job every day, but mostly for smaller scripts (like 100 lines). I am mostly interested in the quantitative/numerical side of things, but anything would be cool, really.
Why exactly are you copying [Mike Pall's comment](http://www.reddit.com/r/programming/comments/19gv4c/why_python_ruby_and_js_are_slow/c8nyejd) without clarifying that it's a quote?
I really enjoyed the last two bullet points.
Even CPython is [doing stuff](http://bugs.python.org/issue13903) make instance dictionaries more (space) optimized than writing the dict explicitly, so using instances when you mean instances is preferable even there.
I'm not sure if this 100% fits this discussion, but I'll just throw it out. I'd recommend Shpaml (http://shpaml.webfactional.com/tutorial/1) for Django templates. We used it in my last workplace and we were quite happy with it.
I'd suggest you have a look at [rapydML](https://bitbucket.org/pyjeon/rapydml) Here is a sample: html: head: title: "Welcome to my Web Page" body: div(id="title"): img(src="banner.png", alt="My Banner") div(id="content"): "I haven't yet put anything on this page" div(id="copyright"): "Copyright 2012 by Me"
But they're nice languages.
The question I've always wanted to ask someone hiring for such positions would be whether or not there's a stigma to coding on primarily video game related projects?
HAML may be good when you develop a web app by yourself only, or when you integrate layout by yourself. When you work with layout designers html based templating engines give the advantage that they can be understood by them. It is just html mixed with some tags that are irrelevant from the layout perspective. Sure, haml is concise and elegant (maybe) but limiting in terms of team work.
When you read the JavaScript specifications and look at the tables which tell you how type juggling should happen between differing data types, it does make sense. It doesn't mean that it was a good idea to define things in that manner in every case, but there is rationale that comes into the way that automatic casting works in languages like PHP and JS. It's easy for us in the Python world in particular to misunderstand these because we don't do type juggling.
Please tell me how {} + [] == 0 makes sense conceptually at all. Sure there's probably some random rationale in the spec, but it doesn't take away from the fact that logically it doesn't make any sense, whereas here it makes perfect sense that Python cannot inspect a function that wasn't written in Python.
The Self project provide you can make things very fast, and while Smalltalk didn't have much of a rep for speed, Smalltalk VM's make mince meat of most modern VM's for dynamically typed languages (CLR &amp; JVM definitely kick their butts with statically typed languages).
theGedazz elaborated a little by swapping `["yes"]` for `"yes"`, but I think the intended "wat" is that attempting to modify the list contained within the tuple both raises a `TypeError` *and* successfully modifies the list.
Li*f*p? It'*f* *f*low...
This is awesome.
They compare equal, but they're separate objects. `bool` is a subclass of `int` (see for example `bool.__bases__`).
Pypy will likely never replace CPython. Why? It's written in x86 assembly, for one thing. Making it portable would substantially reduce its efficiency. Pypy is great, and so is CPython, for a completely different reason. I can't wait until PyPy supports py3k.
X
mostly I agree with you. However, one caveat, if you are (un)lucky enough to work with designers who only know how to drive photoshop, then inevitably it falls back on you to maintain the markup and the css and so you should make it as easy on yourself as possible because translating pixels into html structure + css rules is a HUGE time sink. 
If someone can do useful stuff in no time and with quality(which can be done in php, but harder than python), that all that counts.
Thank you for introducing this to me! I've been reading through the page and simply asking myself 'why didn't I already have this in my life!?'
PyPy is written in Python (or really RPython, a restricted subset).
X
Not exactly Python, but I think the visualization found on the site below shows things a bit better: http://www.sorting-algorithms.com/
{} is actually not an object, like is stated in the video. It is parsed as an empty block. So what you actually have us "+[] == 0". Before the unary + operator is applied, it converts is operand to a primitive. For arrays, this means it calls array.join(), so it returns empty string. Next, it casts the primitive value to a number, and Number("") = 0. Then it makes it positive, which it is, so you end up with 0. *Edit: The thing that will make this all make the most sense is when you understand that many built-in operators, but + in particular, takes it's operands to primitive types first. *Edit 2: I should say that {} is not an object in this context, because + can be unary so we still result in a valid parse. In the case of [] + {}, it is an empty object. &gt; new Object() + [] [object Object] &gt; [] + {} [object Object] 
I concur with this, I use this for all my web projects, it is as simple and clean as it gets. No problems with this whatsoever.
Of course by "layout designers" I really meant "the HTML/js guys" not graphics. (I just do not know what is the English word for this position).
This one looks better imho than haml
Wow, this is like a designer's nightmare. Why would you do that to anyone? 
I don't really see a point in using a markup language for writing html that isn't html. HTML is clean enough when indented properly and anyone else working with your code won't have to get used to anything new. If you hate writing html - i'm sorry to break it to you like this - but you have a shit editor. [This is how we write html these days](https://code.google.com/p/zen-coding/). For this reason, as already mentioned here, I'd use a templating engine and not a new markup language. I use Mako because its fast as flying figs and you can write vanilla Python right in it - this saves you from writing one-off filters or tags somwhere else for a specific task. I can't comment on any other ones, besides the django templating engine which I think everyone will agree is worse than Mako.
But its JIT outputs x86 machine code. I guess I did word the first post incorrectly.
http://www.pythontutor.com/visualize.html It allows you to visualise what the computer is executing at a particular time. Allows you to see you're your loops are doing and what constants are being assigned to your variables.
Nice list of demonstrations, I particularly appreciated the variety of inputs. However, OP gives us a nice, simple and very clear Python implementation, which is definitely worthwhile.
it does not let you give an estimate, so you have to carefully check for i. Preallocating can be a hint and if you miss it too bad (slower, but not incorrect). This is why [None] * n is bad.
Do you know why it does that?
sure, but in cases as this one, it doesn’t matter if a passed empty list is replaced by another empty list. good tip, though.
that’s not the wat. that’s how a list’s `.__add__()` and `.__iadd__()` methods work: they only accept other lists. to append an item, you concatenate a list with another list containing that item: assert [0, 1, 2] + [3] == [0, 1, 2, 3] or use `.append()` mylist = [0, 1, 2] mylist.append(3) assert mylist == [0, 1, 2, 3] if you do `mylist + "yes"`, you essentially do `for elem in "yes": mylist.append(elem)`. --- the wat is that although the above operation apparently failed, the list gets still updated, and that’s because two opperations happen: `mylist.__iadd__(mystr)` and `mytuple.__setitem__(1, mylist)`, the latter of which fails. and that’s quite unexpected.
or sequentially: assert sys.version_info[0] == 2 #python3 has that fixed False = True True = not False ;)
like other wtfs here: fixed in python3. one can happily use tabs now :)
you’re totally right: we have surprising &amp; wat-inducing, yet 100% defined and thus (for the expert) predictable behavior. and while everything you said is right, your code example implies that both expressions return an object, while in reality, both return the string `"[object Object]"`. and 0 is not positive, it’s 0 ;)
no chance, strings are strings. even in the more wat-inclined python2, there’s afaik nothing treating one-character strings implicitly as characters. only `ord` and the like to do it – explicitly
most of us discovered that when trying to do mynamespace = object() mynamespace.spam = 'eggs' #oops at least that’s what i think most try.
the only problem i have is that since matplotlib uses the PIL name, not Pillow, it doesn’t support JPG even though i do have a ported PIL (=Pillow) installed. but as long as you can just convert everything to PNG first, i’ll take that gladly for the vastly improved language. python 3 has many warts filed off, far superior sting/bytes handling, and new features will land there alone.
Thanks, this looks really interesting.
For my current projects, I am the sole developer (frontend and backend).
Who cares? Good JIT and GC beats a slightly cleaner language any day.
PyPy, V8, StrongTalk, Rubinius are all similarly fast.
This may be controversial, but you will have an easier time making things with 2.7 and most useful 3.3 features are either defaults or can be enabled. Also, PyPy is awesome and does not yet have a 3 version.
We commit scripts that invoke manage.py with complex environments (eg test scripts). How do you commit those without hard coding the virtual env path? 
I kinda like http://sortvis.org/, and it has reference implementations in python with it too :) 
On that note, MoinMoin Wiki is in need for developers. If you don't know much, they will help you, teach you if you know just a little bit, etc. Join them at irc.freenode.org #mon-dev. The project is well known, big and you can learn a lot besides getting a ton of recognition. Here are some technologies you would be working with everyday: http://moinmo.in/MoinMoin2.0 Enjoy!! :)
Depends what you mean by "scalable" and what's the nature of your app.
No love for Cheetah here? http://www.cheetahtemplate.org/ It's basically inline Python in any text document. Granted I haven't had much experience with other templating engines, but Cheetah is awesome.
Question is too vague to be answered IMO. What do you mean by "host" and "scalable"? Do you want the complete development to deployment to automatic scaling system like Heroku, or do you just want to run the app and able to scale up with some delay?
The DB is typically the hardest part to scale. Put your DB on a separate VPS with extra resources (or use dedicated hardware if you really want to be cost effective). Adding new app servers and load balancing between them is the easiest and cheapest part. Try adding a caching layer to stretch your database even further before needing to scale it out again. Other than that it depends on your app. Need more information.
sorry im late. but isnt this just the same as doing li = [0]*10 ?
[Cloud66](https://www.cloud66.com/) might be relevant to your question. Currently it only supports Ruby on Rails, but they're currently working on a Python version which should be out soon. 
Generating HTML from code is a thankless and foolish task. At the very least, any developer should want to avoid it because it needlessly puts the responsibility of the final output on the *developer* and not on the "HTML guy" or producer or designer or whatever you might call the guy who edits HTML. When you generate HTML with code, and there are problems with the output, then the developer has to fix it. This also increases the turnaround time for even the smallest of fixes, since you have to test that you haven't broken anything, whereas a change to a view only needs proofreading. So you are increasing brittleness and complexity for no real benefit, plus added extra responsibility for people who don't want it.
Use AWS and CloudFormation. You can do a fully redundant architecture with auto scaling rules. It's the bees knees. I also use Heroku Postgres for my database. It's a bit less known but much more useful than their cloud servers (dynos).
I've actually been considering this very architecture for a project since I really want to use psql instead of mysql. Are there any pitfalls I should be aware of? The only one I'm aware of is that you can probably only use aws us-east since that is where heroku is. Given this is not exactly a deal braker. 
Being a college freshman that knows a variety of programming languages, I liked watching this, but the glitters are not all gold my friends
The problem with your question is that it assumes that scaling is a uniform thing with a best practice algorithm that can be codified; when in fact it's more like dealing with unruly livestock. Worry about scaling when you absolutely have to, worry more about the traceability and debuggability of your application and it's infrastructure. If you can find out what your application is doing, you can figure out how to make it deal with the traffic you are seeing. If you're blindly trying things, or having to write new code to determine what is happening where in your application once the crowds come to visit, you'll be overwhelmed. People will give you lot's of advice about scaling, because it sounds sexy and is usually associated with profitability. Some of that advice may be good in context. But what's right for Twitter or Facebook may not be right for you. If you're serious about scaling things [the logging documentation](http://docs.python.org/2/library/logging.html) should be your daily reading for a while. 
I think the OP is aking how to do it without services like AWS etc. as well.
Daily snapshots are a minimum. Minimize usage of EBS if possible. Use chef or puppet to automate the creation of AMIs. Boot each production release from a new AMI. Centralize your error logging to an external service. I recently improved things a lot when I saw this comment that helped us rework my employer's deployment strategy. http://news.ycombinator.com/item?id=5135260 We're still considering going back to managed cloud or managed dedicated because dealing with occasional failures is such a nuisance and loss of productivity that could be outsourced. The lessons learned from AWS will carry over quite nicely.
I didn't know about the `[0] * 10` trick at that time.
`.env/bin/python ./bin/test` The key here is to make requirement that all scripts must be invoked from project root.
I have asked on Firebird General mailing list for testimonials http://thread.gmane.org/gmane.comp.db.firebird.general/157/focus=165 If you want you can join in the discussions http://tech.groups.yahoo.com/group/Firebird-general/
Exactly ! Here are some questions that might help you * What lead you to the conclusion you need to scale ? * Have you done proper analysis of your code and worked out bottle necks ? * django-devserver, django-debug-toolbar will help you * Are you using the ORM correctly ? i.e are you using aggregation &amp; annotations instead of doing; # instead of this sum[obj.some_int for obj in MyModel.objects.all()] # do this MyModel.objects.all().aggregate(Sum('some_int')) * How many users do you have ? How many concurrent users do you have ? * Do you use any caching ? memcache or redis etc.. 
Our company has a growing Django project which is currently sitting at 168 separate templates and fragments and I've got 68 of those in Haml. Do yourself a favor, use [HamlPy](https://github.com/jessemiller/HamlPy) or your web framework's equivalent. I can still use regular (Django or Jinja) html templates for those cases where I'm more interested in the precise html (say, variable attributes or classes that doesn't work as well in the Haml syntax). It might vary with environment, my Django template loaders pick based on extension so I can use either judiciously: template.html or template.haml. Here's why you should use Haml * Way more legible, you get a clear outline of your page compared to the jumble of html no matter how well you try to indent. * Less typing, duh (you'll notice when you have to switch back) * Diff/Version Control friendly because it's more line oriented (!) * Kind of an extension of the first 3, you'll more easily spot repeated blocks that you can generalize into common fragments for extra DRY. Like I alluded to, when I need to be more precise with the html (whitespacing, etc), I'll just create a regular template fragment. 95% of the time, the Haml syntax is superior. I think the idea that you have a designer that can work with html (which already is prob a stretch) or a frontened dev, but couldn't pick up the Haml syntax sounds like a lousy excuse. It's really just a pre-processor, so you can always give them the html as a working copy. Those same people usually eat up the Less/Sass and Coffeescript, so Haml is right behind. The alternative suggeestion is a ZenCoding/Emmet-type answer where your editor/IDE helps auto-complete a lot of the verbosity of HTML. Don't buy this. You spend more time adjusting, amending and modifying your templates. You write your base template once and probably change it 100 times where these auto-completion tools have less effect. That's why those points above are so important (readable &amp; easy to manipulate sytanx). It's prob a 2X productivity multiplier. Go for it! 
[Time storage technology](http://forum-images.hardware.fr/images/perso/bakk3.gif)! I think Sir Terry Pratchett [pioneered this field of research](http://www.lspace.org/ftp/images/bookcovers/uk/thief-of-time-1.jpg).
Totally true, but since CPython is already compatible with virtually everything running C, PyPy has a lot of catching up to do.
I meant: bash scripts :) #!/bin/bash [long configuration of environment] ./manage.py test foobar barfoo 
In general - you can't do this, because VPS is pay-by-machine-uptime rather than pay-by-resource (heroku). You need to find provider that bill cpu cycles and memory usage (not uptime). I don't know any provider who do it. If you use PAAS (like Heroku, EngineYard or Jelastic) - see advices from other reddits, it's may dramatically save performance (and cost also).
Ah! Well I guess it could do, if you really must have an object of a class as your singleton. Otherwise what I meant is that you can simply have your module act as the singleton and not explicitly write any Singleton-line-of-code at all.
setup chef-solo or a chef-server then bootstrap all of your nodes with chef-client so that you can manage the applications and scaling
You don't need to run Chef all the time. I just use it to bootstrap the services and dependencies for my application when I'm creating a new base AMI. Usually the only reason I need to run the full chef installation is when I'm upgrading my AMI to a new operating system, or doing a development build from scratch (to create a fresh base box) with Vagrant. Fabric is a great wrapper over rsync to get your code out to the instance so you can bake an AMI for a new production release. At the moment we use a thing we integrated with our repositories on GitHub to automatically create development builds from pull requests.
The following lines of code are in fact tab-delimited. The Reddit editor gets rid of it. class B(object): def __init__(self, C): self.C = C pass
I'm not sure what you're trying to achieve and why would you need such a structure but this code worked for me: class Planet: class Moon: def __init__(self, size): self.size = size def __init__(self, moon_size): self.moon = self.Moon(moon_size) # I can create a Planet object which has a Moon e = Planet(362570) print e.moon.size # I can also create a Moon without a Planet luna = Planet.Moon(405410) print luna.size Does this help?
This may well be an example of the X Y problem: http://www.perlmonks.org/index.pl?node_id=542341 Tell us why you're trying to do that and what you're trying to achieve. There is probably a much more Pythonic way to do it.
Wonderful, keep up the good work.
Small side note: Don't use actual tabs for indentation in python code, just spaces.
With Python 3: &gt;&gt;&gt; 'hello'[0] 'h' &gt;&gt;&gt; 'hello'[1:] 'ello' &gt;&gt;&gt; b'hello'[0] 104 &gt;&gt;&gt; b'hello'[1:] b'ello'
Do you still have these? Are they available for public consumption?
If you do, that line is a no-op.
In the shell, tabs are for readline auto-completion. I use 1-space indentation there as well.
The difference is that most of it still runs in Python 2.7.
We're talking about leading whitespace, where tabs are inserted literally in any shell.
there is a PEP-8 (coding style guide) that encourages 4 spaces indentation. I can't say that tabs have any disadvantage, but we'd better stick to one standard, and it was already written down in PEP-8. So rationale is legacy sandard without obvious need to change.
The Python REPL does tab completion, even at the start of the line. For me at least. I would love to set it up so that it doesn't do that, but I don't know how.
Exactly the problem the OP had: if you use spaces, the formatting won't get messed up, whereas tabs can be interpreted differently depending on the context.
Do you have a problem that requires scaling, or are you simply *anticipating* said problem. The most important thing to remember is that you should only attempt to solve the problems you actually have. You don't have enough information to attempt to solve problems you might have in the future right now. 
MereInterest is spot on, but also make sure to read this: http://en.wikipedia.org/wiki/Law_Of_Demeter
Since this is behavior of an interactive interpreter and not the language itself, writing this kind of thing in a script will get you this: NameError: name '_' is not defined But since it's used by humans as a convention for 'value I don't care about' you might also just reference some arbitrary recent value. It's better not to use the value of _ at all.
I very rarely modify arguments, I don't consider it idiomatic in most cases. And in those cases where I do, the function name makes that clear and the modified argument is the first one, and without default anyway. 
Rational is similar to enforcing one type of line ending versus mixed line-endings. The visual definition of tab's changes from one OS to another and then the problem is multiplied further by each IDE/text-editor involved. 
Making the standard REPL do tab completion involves a series of very specific steps, involving the creation of a `.pythonrc` file in your home directory. And I know it doesn't do tab completion in the beginning of the line, although I'm sure that's possible with even more specific steps. So either you remember wrongly or have a very peculiar pre configuration of your python installation. Either way, it's not the default on any flavor of python installation I've ever encountered.
Mixed tabs and spaces won't work, so it has to be one or the other. The rationale for choosing spaces is that you are doing what almost everyone else is doing. 
+1, it's faster too.
Well, this is basically my .pyrc: import sys import readline import rlcompleter readline.parse_and_bind("tab: complete") And this is a bit from an interactive session: &gt;&gt;&gt; if a: .... &lt;tab&gt;&lt;tab&gt; Display all 177 possibilities? (y or n) So yeah. And it's that way for me for every Python version I've used too, from 2.6 to 3.2. (Didn't use the tab completion back when it was 2.5.)
you’re right, i was wrong about `rlcompleter` not autocompleting in the leading whitespace area. but that still only applies to the python REPL, and only if it’s if customized with a `.pythonrc` using the `rlcompleter` module. every real shell, such as bash, zsh, fish, as well as all advanced python shells, i.e. ipython and bpython don’t autocomplete in the leading space area, and unconfigured python doesn’t autocomplete at all.
Thanks for your detailed explanation. Very helpful!
I am not sure how the question comes across as unclear. In the title I explained that I would like to have nested attributes. Like a car has wheels, wheels have tires, tires have brands. So I can create a car with all its attributes that also have attributes. I am just trying to learn Python... 
If you're just trying out how Python works, that's fine. The post can sound like you actually have a specific problem in mind, and andybak is saying that most likely there's a better solution to that problem than what you're trying here.
Really? Personally I really like the distinction between lists and tuples.
As I said as long as you make it a requirement the script must be executed from project root (you did, based on above example), it doesn't really matter what type of script. #!/bin/bash [long configuration of environment] .env/bin/python manage.py test foobar barfoo
I certainly agree there has to be a standard. But wouldn't the visual definition changing be a pro not a con? (That way people can render it as they prefer.) 
Thanks, that makes the decision for Python code quite clear. I dabble a bit in language design, and I would like to enforce this standard syntactically. My feeling is that tabs are better, because then people can render it how they prefer. (Also it seems semantically purer to represent indentation with one char.) Since spaces are the standard for Python (and Ruby), I worry that I'm missing a rationale other than existing standards. 
I would say Requests is better than urllib. 
Ugh. I think example code should be held to a higher standard, and this has lots of little things wrong. 1. BeautifulSoup will automatically use lxml as the parser if it's installed. It's not necessary to force it by passing `"lxml"` as the second parameter to the constructor. For example code, it would be better to let BeautifulSoup pick the parser, as there is more flexibility that way depending on what modules the user has installed. 2. The BeautifulSoup constructor can take a string or a file-like object. So don't read the whole file into a string and pass that, just pass the file: soup = BeautifulSoup(urlopen(section_url)) 3. BeautifulSoup v3 and prior used non-PEP8 method names written in camelCase like `soup.findAll`. They were [renamed in v4](http://www.crummy.com/software/BeautifulSoup/bs4/doc/#method-names), with the old forms being deprecated but left for backwards compatibility. Since this tutorial is using BeautifulSoup v4, it has no reason to be using deprecated methods and should be written with the new PEP8 names. 4. This is a personal preference, but I don't like it when a value that is about to be returned is assigned to a variable: foo = ... return foo You can make the argument that having a name documents the value, but in this case the function is named `get_category_links` and the name is `category_links`, so it just seems like extra noise: def get_category_links(section_url): soup = BeautifulSoup(urlopen(section_url)) boccat = soup.find("dl", "boccat") return [BASE_URL + dd.a["href"] for dd in boccat.find_all("dd")] You can even take this farther, though I'm not sure that it's clearer: def get_category_links(section_url): return [BASE_URL + dd.a["href"] for dd in BeautifulSoup(urlopen(section_url)).find("dl", "boccat").find_all("dd")] And similarly for this mess: def get_category_winner(category_url): html = urlopen(section_url).read() soup = BeautifulSoup(html, "lxml") category = soup.find("h1", "headline").string winner = [h2.string for h2 in soup.findAll("h2", "boc1")] runners_up = [h2.string for h2 in soup.findAll("h2", "boc2")] return {"category": category, "category_url": category_url, "winner": winner, "runners_up": runners_up} Compared to: def get_category_winner(category_url): soup = BeautifulSoup(urlopen(section_url)) return {"category": soup.find("h1", "headline").string, "category_url": category_url, "winner": [h2.string for h2 in soup("h2", "boc1")], "runners_up": [h2.string for h2 in soup("h2", "boc2")]} In this example I elided the `.find_all` since calling a Tag or BeautifulSoup object is the same as calling `.find_all()`. 
&gt; because then people can render it how they prefer I think over in the spaces camp, the opposing point of view would be "because then people all see the same code". Hard to argue against either idea. I can't find a reference now, but believe that one of the reasons PHP-FIG settled on spaces in PSR-whatever was that it made copy-pasting code samples from the internet lead to expected behaviour. This is an interesting external-to-syntax consideration. The other big pro-spaces consideration is that manually aligned statements across consecutive lines are error-prone when using a tab/space mixture (and can't be done with tabs alone). By error-prone I mean that you only get this right if you use tabs for indent, then spaces for the alignment. In tabbed projects, I always get this wrong, even though I *know* about it. It's a combination of not seeing the error unless you for some reason change your tab width, and your habitual use of the tab key to create spacing. Perhaps your syntactical enforcement could require tabs for indentation, but any spacing after the indentation must be spaces? I'm sure this has been discussed more rigorously elsewhere!
I dont like the provocative title. Slow is an ambiguous and relative term. For example, are you talking about development time? Because if you are then you are wrong; I wrote a python text file parser in 10000% of the time than it took me in C :p. Yes python code runs computationally slower, but we all knew that already and is a moot point.
I'm so tired of this kneejerk response every time `urllib` is mentioned. Please, in detail, tell me how using Requests will make the code any simpler or better than this: soup = BeautifulSoup(urlopen(section_url)) The answer is that it won't. `urllib` is just fine for simple tasks. It does not do your cause any justice to mindlessly scream that `urllib` is bad at every opportunity. Requests should certainly be considered when you have to do things that aren't simple, but simple things are the most common. 
Downloading the page(s) is what's going to be time consuming. If you have a large number you'd like to use something that is asynchronous. (The framework Twisted got some cool things to use) Have in mind that the page your python script is downloading might not match the DOM-tree in your browsers inspectors, javascript can mess things up.
What just happened?
Assign to `self.whatever` in your constructor. E.g. class Car(object): def __init__(self, wheels): self.wheels = wheels class Wheel(object): def __init__(self, tyre): self.tyre = tyre class Tyre(object): def __init__(self, brand): self.brand = brand car = Car([ Wheel(Tyre("Dunlop")), ... ]) print car.wheels[0].tyre.brand 
[concurrent.futures.ProcessPoolExecutor](http://docs.python.org/dev/library/concurrent.futures.html#processpoolexecutor) is even easier than trying to grok twisted
excellent resource for the scripts for scraping imgur, I look forward to more in depth examples that I can use.
you know what would make me believe you? if you could re-write the article using requests instead of urllib and then describe what benefits are to be gained by doing so. 
Also: for...else
Yeah, just use sys.stderr.write('foo\n')
The API is pretty fantastic for Imgur, I think it would be more efficient to use that over screen scraping, but that's just me.
If you have to hit a site a few times, you will want to be able to switch up user-agent really quick without having to enter 5-10 versions of your own user agent. When hitting the same domain multiple times, Requests wins by a mile.
You're kinda bike shedding a bit here.
I've heard good things about [Codecademy](http://www.codecademy.com/tracks/python). Hopefully this can help get you on track.
[multiprocessing](http://docs.python.org/2/library/multiprocessing.html#using-a-pool-of-workers) is also fine.
I agree with all of that and take this one point even further **and** make it cleaner :P def get_category_links(section_url): soup = BeautifulSoup(urlopen(section_url)) for dd in soup.find("dl", "boccat").find_all("dd"): yield BASE_URL + dd.a["href"] (It doesn't hurt to assign the soup to a variable ... for readability, you know.)
&gt; Downloading the page(s) is what's going to be time consuming. Agreed ... &gt; If you have a large number you'd like to use something that is asynchronous. ... but this is just evil. Look at [Scrapy](http://scrapy.org/), a whole crawler *framework*. It manages everything for you and even has an option [`DOWNLOAD_DELAY`](http://doc.scrapy.org/en/latest/topics/settings.html#download-delay) that let's you be extra-friendly to a website's server.
No, it's really quite painful to have code work across 2.2 and 2.7. 2.x is going away the same as previous versions went away, it is only a matter of time.
it uses multiprocessing. but if you want to manage ipc yourself.... go ahead. 
I'm not convinced you can actually write any code. are you a bot perhaps written with requests?
Personally I'm still new to python so anything having to do with `future` makes me nervous.
that would be an excellent article and contribution to the python shared knowledge. someone should write that. perhaps using requests. 
so requests takes care of urlencoding the payload..... WOW
Yeah, I'm sure whoever'd write something like that would be both handsome and fertile for *days*. 
futures is not the same as future what you are probably thinking of. it's part of the standard library in python 3 series and backported to the python 2.7 via library. and seriously if you need to do any ipc at all, you will end up writing abstractions very similar to what the library provides. it's real easy to deadlock process pools if you don't know what you are doing. 
indeed. I can't wait to read it. 
What does "bike shedding" mean in this context? 
Thanks for taking the time to compare. 
I don't think this is a wat, I'd expect a bare raise to raise some sort of Exception, not for it to infer it by context. I know it takes the last one, so this isn't surprising at all to me. This is why we do `except Exception as as e`.
I quite like this one, although it's a bit boring: &gt;&gt;&gt;&gt; False.bit_length() 0 
Requests is far better that urllib2. https://github.com/mattseh/magicrequests uses lxml and requests for easy data scraping. 
It may be useful to someone who's never written a script against a website before and needs help getting started.
Can this maybe help shorten the code? http://docs.python-requests.org/en/latest/
requests comes up with code about the same length as what I created. I decided to post the non-requests version so it can be used on Python 3 without having to install anything else. Although I am certain some people could devise better, more robust solutions by using requests.
Instead of Twisted, it's almost always easier to use something like Eventlet or Gevent for fetching URLs. All it takes is a few extra lines of code, and BAM!, you've got an asynchronous URL fetcher. Here's some example code: http://eventlet.net/doc/examples.html#web-crawler
For this particular article, the code differences would be slight, and the only benefits I can think of are: * The error handling becomes saner. The article didn't include error handling, but if it had, it totally would have become saner. * Persistent connections are useful if you're doing a fair amount of scraping from the same server. With requests, you just create a session (one line of code) and it will then handle keep-alive for you. * If you'd like to save bandwidth by using gzipped transfer-encoding, requests supports that automatically. Urllib does not.
[This](https://pypi.python.org/pypi/pyimgur) looks pretty useful.
I wish I'd known just how much awesome was in the standard library. I could have saved a lot of time/made a lot of things if I'd learned to stop worrying and use the builtins.
The author abides by pep8 just fine. He happens to be calling methods that don't and that's probably because he doesn't realise they're deprecated. I just like to say that I agree with all the points, however, I find it disappointing that the top comment is sledging the author's code style rather than discussing the actual content.
While its fun to roll your own, it should be mentioned that [Scrappy](http://scrapy.org/) exists.
this will help me with my million dollar startup. 
&gt; Requests is far better that urllib2 prove it with code. empirically..... right now. :)
&gt; The error handling becomes saner. ??? i was already aware of the other 2 but I wanted to see if Oncocerca could articulate their opinions. you jumping in complicates things. 
I may be able to help you, PM me if you want
http://docs.diazo.org/en/latest/index.html
Setting apart the API you're using to do this, you could alternatively throttle your own request rate, and not send any deceptive user-agent headers at all.
this one http://docs.python.org/2/library/csv.html
This will definitely save me multiple trips to the docs when working with datetimes. Thanks.
Did this guy knows something about amortization analysis? If we call list.append in a loop repeatedly, overall complexity will be O(N) if list implemented in a way that I think. I think that list.append doesn't allocate space in the each call and uses amortized doubling like std::vector in c++. And it's slow not because of bad algorithm but because of large constant factors from that O(N) amortized cost.
You need to figure out those ajax urls and call them yourself, you scrape them like a separate page. Developers Tools or Firebug both have network tabs that show requests, it should be enough to figure out what you need to call and what kind of parameters it expects. In return you will get json (yay) or html fragments (oh well, it's not that bad). Occasionally it will be difficult or impossible to get the information you want without running the javascript somehow, then you work with a combination of javascript code, an embedded browser like phantomjs or an emulator like [jsdom](https://github.com/tmpvar/jsdom), python code and a defined way for the two systems to talk. Powerful and fun, going to be frustrating for a beginner to try. Avoid it until you know exactly when and why you need it and it's obvious how to do it. If you are familiar with jquery already or if you just like that design then look at [PyQuery](http://pythonhosted.org/pyquery/), which uses lxml under the hood. And **don't** use urllib, **definitely use** requests. That good of an API is better for beginners and experts. Concentrate on the hard part, the scraping. Along with [Rhomboid's points](http://www.reddit.com/r/Python/comments/19lnth/web_scraping_101_with_python_and_beautifulsoup/c8p67ap) this tutorial could have been better.
Actually, my bash does auto-completion at the start of the line as well: ~$ &lt;tab&gt;&lt;tab&gt; Display all 4242 possibilities? (y or n) I really should check out IPython, though (but not because of the tab thingy, of course).
[botocore](https://github.com/boto/botocore) is.
It depends if you are downloading from one source or many. If it's one source then you are absolutely right.
The other rationale is that a tab can be interpreted as a different amount of space by different renderers, but a space is pretty much always interpreted to be the same length.
Here is how I do it: create a file called setup_windows.py and put this inside: from distutils.core import setup try: import py2exe except ImportError: print('[ERROR] For a Windows installation you need to download' ' and install py2exe') setup(windows=['name_of_your_main_module.py']) And from the command line (on Windows) you have to type: python setup_windows.py py2exe -b1 -c This works with PySide. However please note that on first shot there can be some packages missing and your app may not work. This may be due to a bug in the recursive package finder. To make sure you have everything, your main module must import ALL the dependencies that all your submodules import... For example, if you are using PySide.QtUiTools (to load .ui files), you must also import PySide.QtXml (even if you are not using it directly from your main module). 
I love how the first comment was by Linus Torvald.
Didn't read the entire thing but I noticed this: for i in xrange(len(item_list)): # do something not involving i This would be more pythonic like: for _ in item_list: # don't care about actual item Edit: in fact the author goes ahead and loops over the item list three times, right in a row. There's no reason to do this at all. It can just be one loop where producers and consumers are instantiated at the same time and items are put in the queue: for item in item_list: in_queue.put(item) t = Producer(in_queue, out_queue) t.daemon = True t.start() t = Consumer(out_queue) t.daemon = True t.start() No fuss 
someone below did
&gt; Tabs are a ridiculous idea. If they didn't exist, no one would ever think to invent them - they're a holdover from manual typewriters. I wouldn't say so. I was an advocate of using spaces just as you suggested, but being able to set the indent width myself by using tabs and a setting in my favorite editor *would* be a nice thing to have. I'd lose the ability to properly align comments that come after the line of code, though, so there'd be a trade-off. However, as you said, mixing tabs and spaces is a bad idea™—which is why PEP 8 exists in the first place. In the end, I'll gladly use 4 spaces if PEP 8 says I should, because consistency is definitely more valuable than the ability to set the tab width myself. Sorry if that was in any way unclear, I'm not a native speaker.
uh that example doesn't prove anything, and it certainly doesn't prove empirically that Lib A is "far better" than Lib B. it's just blind fanboyism. 
Hot damn, that is cool.
I'd say learn both: first 3.3, then 2.7. I agree with most of what the others have said: they are not that different in terms of learning to use them, 3.3 is much more awesome and has less warts, 2.7 is better supported by libraries and there are a lot of legacy projects written in Python 2, etc. Anyway, first learn 3.3: it is a much better and consistent language. Then learn 2.7, because you'll be using that mostly (at least in the near future). Blah blah blah, just my opinion, your mileage may vary, do what works for you, it doesn't *really* matter, you get the drift.
Useless in what sense? Many problems make sense to be thought of as independent threads each doing their own part -- even if there's no speedup, it's still the "right" way to think about it, algorithmically.
Dates are especially tough, especially when you deal with Datetimes and timezones, etc. This new project Delorean https://github.com/myusuf3/delorean has a lot of really great features built in to make dealing with date/datetimes in a sane manner really easy. Docs specifically for manipulating time: http://delorean.readthedocs.org/en/latest/ 
If you read the following articles you will understand what I mean. http://www.dabeaz.com/blog/2010/02/revisiting-thread-priorities-and-new.htm http://www.dabeaz.com/blog/2010/01/python-gil-visualized.html http://www.dabeaz.com/python/GIL.pdf http://www.dabeaz.com/python/NewGIL.pdf Using CPU bound threads in Python will actually cause a slow down in your code. 
Not getting a performance boost isn't what's bad about Python threads - that in itself would be not a huge issue. Especially if you just wanted to emphasize the parallel nature of your program. The problem is that you can actually get a rather large performance hit (~2x!) by using threads. You can also get weird effects involving IO bound threads being starved out of CPU time by CPU limited threads. The analysis linked to by placidified is very good and well worth the reading time. These counter-intuitive effects absolutely mean that threading isn't the "right" way to think about it. If it's multiple threads of execution you want, I'd go for the multiprocessing library (http://docs.python.org/2/library/multiprocessing.html).
A quick note to anyone parsing large quantities of datetimes. If the input is well formed, like in a db dump or something then it is worthwhile to write your own datetime parser along the lines of datetime(int(date_str[:2]), int(date_str[3:5]), int(date_str([6:8])) as even the built in strptime function is quite computationally intensive. I've had a couple of projects where date parsing has been a significant part of the overall computation.
I'm a big fan of using [PhantomJS](http://phantomjs.org) for those kind of things.
Please have a look at [nagare](www.nagare.org) and in general at [push style templating]( http://www.perlmonks.org/?node_id=674225) approaches.
Beyond that, BF hasn't been recommended for a few years, you should use `lxml.html` either with its own parser or with `html5lib`.
Yeah requests is nice for complex scenarios (e.g. session, HTTP auth), but for basic "GET a resource" scenarios it's a completely unnecessary dependency.
Does Scrapy support scraping from sites that require logins?
useful to tell them shit by wrong trems right from the gecko
Yeah, I know of tabs for indentation, spaces for alignment, but I always thought that it would mess up the alignment if I'd ever wanted to align lines with different indentations. Seems like I hadn't thought about it hard enough. Oh well. However, wouldn't alignment of comments after lines *with different indentation settings* still mess up the alignment if different tab sizes were used? That's rarely done, though, so it's not much of a sacrifice. So yeah, I'd probably have switched to TISA (oh god this sounds stupid) already if it weren't for PEP 8.
Probably, and if not you can register custom dialects with the register_dialect function.
Fair enough. My setup's just Apache running a Django webapp, so even using Chef for that seems overly complicated, since all I need to do is: 1. use boto's run_instance method to create a new ec2 instance 2. scp up a system package requirements file and use to install all packages, via yum or apt 3. scp up my iptables.conf, named.conf, apache conf 4. create virtualenv, install pip packages, and scp up my custom codebase 5. restart apache If any of those fail, which is rare, the error is usually obvious and easily fixed, since all I'm doing is running a shell command I would otherwise run manually. When I used Chef, the cause of errors were never obvious, and the only practical solution was to simply re-run Chef and hope the error didn't reoccur. 
I've used SpiderMonkey for that task. 
This only works if the notebook runs on the same device.
Python 2.x development overlapped Python 3.x development for a fair bit of time (with features from 3.x being backported and 2.x bugs being fixed). 2.7.3 was released just under a year ago. People kept using 2.x until their favorite library was available for Python 3. This took a while due to significant changes between 2.x and 3.x.
That is new in 3.x.
You could directly use `lxml.html`. XPaths are more powerful (and wayyy faster) than BeautifulSoup.
Doesn't matter. There's very little difference between them from a new user's perspective. The main impact it'll have on you is what libraries you can use, and these days numpy and matplotlib can support 3.3.
So basically have OP figure out what adults he dislikes, and make their job obsolete. Cruel and effective. I like it.
I think a better idea is to increase the lenght of the search string.. so instead searching for just "AIza" I'd search for "AIzaa", "AIzab" and so on.. if on result list has more than 1000 results i would append another letter.. so "AIzaaa" and so on.. With ~~this method there are no duplicates (or nearly no duplicates - because when the search string comes in the middle, it would be a duplicate) and~~ it will always work. The authors idea to split the dataset up by language could result in languages which have more than 1000 results - then it isn't guaranteed anymore to get all edit: forgot that duplicates would arise when a key is inside multiple projects of course
I don't think PyQt/Tkinter integration would be worth the effort... JavaScript is pretty easy to learn and in today's environment it's pretty much an essential skill… like it or not. Much like Java. You can love it or hate it, but refusing to learn it severely limits your possibilities. And JavaScript has become ubiquitous and *very* fast (V8). The right tool for the right job. Python is great for most programming tasks but sadly, web frontend development is not one of them and I doubt that will change in the future. IPython should include some simple widgets though, just to save time. I don't want to include a bunch of HTML or JS just for getting user input. There were some attempts to make something like GWT in Python (like Pyjamas), but none of them gained any traction.
Is there any reason you can't just have multiple python version available in your systems? On every system I use I have at least 3 versions pypi, 2.7 and 3.3. Works out great since our core product isn't moving from 2.7 any time soon but we get to spend lots of time getting ready.
I use Python for its simplicity. This is exactly what I'm talking about. Thanks dude, great API. Will probably start using it!
Sorry for the late response, I've been really busy. Thanks for the input! I think I'll seriously consider doing this.
I'm not really interested in coding PHP.
It's quite a bit more intuitive, though. It takes less brainpower to read the Requests example and know what it's doing. It's not about "what function does Requests perform more efficiently?" or even "how does it help me write less code?". It's about "How quickly can I understand the code" and "How clear are the abstractions?"
Javascript widgets are on the [roadmap for IPython 2.0.](https://github.com/ipython/ipython/wiki/Roadmap:-IPython)
Of course, I had to make one for the subreddit dedicated to the programming language that made all this possible! :-D script: https://github.com/rhiever/reddit-analysis subreddit: http://www.reddit.com/r/MUWs/
I really think you should've just filtered out "python."
What are your thoughts about a radical departure from character-based presentation of programs? Programming began with text files because that's the best the computers of the day could do. Unfortunately my experience with alternate ways of laying out program logic are ladder logic (example: http://automationstudio.com/pro/images/p6-images/plc-ladder-logic.gif) and a circa-2001 Mindstorms IDE. Both of these are not nice to work with. Still, I think there must be something like Code Bubbles (http://www.youtube.com/watch?v=PsPX0nElJ0k), but possibly reaching more into the line-level display.
The best advice that I can give you is to find the libs that work with what you're passionate about, either by using Google or GitHub directly, and have a look at their code. You can then look at their issues and start contributing.
Because += adds the elements of an iterator to the initial iterator. The iterator in this case is a string, so the elements are the chars. If you do += ["yes"] then the iterator is the list and it contains one element, a string.
It has an annoying tendency to deadlock sometimes, though.
Sort of. If you throw a bunch of money at an application, most of them will be fast. Performant insinuates that's it's also efficient.
I'm to sure how I feel about "test" being so little...
I think a primarily textual interface for program semantics will be dominant for the foreseeable future. Visual programming is one of those things that people keep trying, but it always fails because it just slows down professional programmers. However I do think visual programming has potential as a teaching tool. Here's Alan Kay's Ted talk related to this: http://www.ted.com/talks/alan_kay_shares_a_powerful_idea_about_ideas.html I would say Code Bubbles falls under the category of improving the UI of working with textual programs. There seems to be a lot of room for improvement in this area, although I haven't put much thought into specifics. I'll have to try Code Bubbles, it seems to be a better way to work with highly factored code, where the implementations are scattered. 
Glad to see 'function' so much bigger than 'object'.
Why?
Thanks for the Edit! That is exactly what I'm looking for.
Correct me if I'm wrong, but, doesn't beautifulsoup already use lxml for parsing? 
Never would have expected you here.
The idea that people refer to functions more than objects implies that they use them more often. Nothing particularly significant.
you're not wrong at all - in a way i was just associating what i already believe with what i see in the picture; given a different set of beliefs, i would have 'concluded' something different but then again, that's why i was posting it as a quick comment to a nice pic instead of a comprehensive study on either the language or its community
Haven't watched all the way through the talk, but he's reminding me a lot of "Lockhart's Lament" - http://www.maa.org/devlin/lockhartslament.pdf - I hope he mentions it :)
For any other language, they would have done this with a white background.
...and the conclusion is...hmmm....ok...whatever
Python users really love the movie Django Unchained. 
The biggest word I don't really understand is "time". I can see it being bigger than average, but not _that_ much bigger.
I cannot believe no one has tried it on /r/nsfw yet...
This is certainly a great idea- and one I most certainly considered. Unfortunately, you'll notice that most (if not all) keys actually start with "AIzaSy", though if you search for this, you'll get no results.. A comment on /r/netsec (on my phone or I'd get the link) indicates that the cause of this is likely how they've implemented Elastic Search. Thanks for the great suggestion, though!!
Thanks! Here's the sorted data. I use Python for small tasks all the time, but the fact that I used it to sort this feels ironically awesome. http://paste2.org/p/3046466
Nice. We should probably start outputting it this way too. :-)
I would've sent a pull request, but looking at the code, it's just a one line change. \_\_init\_\_.py at line 337: replace `sorted(popularWords.keys())` with `sorted(popularWords, popularWords.get, reverse=True)`
South is your only option for migrations in Django as far as I know. You're going to have to wait until every one of your apps is ported to python 3. Should be a few months or so for the popular ones I'd guess. I'm not sure what the community pressure to move to python 3 is like so it might be more.
bad logic
What link do you use to make these work? If you link directly to the subreddit front page it doesn't work.
I can never get these easy install applications to work... I installed the EPD, opened IDLE, and then running _easy_install_ I get the error &gt; SyntaxError: invalid syntax What could I be doing wrong? Edit: easy_install isn't a Python command, and I just successfully installed redditanalysis by running this in CMD. I'll promptly gtfo of here. 
As the author of this post, this comment is exactly why I posted it here - I wanted to get feedback. While [PCBEEF](http://www.reddit.com/r/Python/comments/19lnth/web_scraping_101_with_python_and_beautifulsoup/c8p9v1l) is correct in that I didn't realize bs4 had deprecated the camelCase methods (I've been using it since bs3), I appreciate that you pointed it out. Thanks.
It is, but it's also explicitly experimental so I'm not sure how quick the app developers are going to be. Probably won't be very long. That does seem like exactly the wrong kind of yak shaving to do if you're trying to get your feet wet.
Are you executing `easy_install` on the regular command line (not within Python)?
A lot less curses than the MFA version.
"Bullshit" only came up six times? I call bullshit, this is a programming community.
Aha, that's interesting. So I see why you came up with this solution then.
&gt;wrong terms ... &gt;right from the gecko
In this project you will write the code to encrypt and decrypt with ROT-13. ROT-13 is a simple substitution cypher. It stands for "ROTate by 13 places." Thus the cypher replaces any letter with the one that appears 13 sequential places behind it.
Try this, for instance: https://openhatch.org/search/?q=language=Python
Why the rotated text? It's like these "clouds" didn't have shit readability to begin with.
Here are some [Better](https://github.com/jameseric/mimesort) [alternatives](https://github.com/jimmyrcom/utilities/blob/master/sort.py) ? 
[Humanistic](http://wordnetweb.princeton.edu/perl/webwn?s=humanistic) isn't really the word you're looking for. Still, looks like a very comfortable interface to use.
I would recommend learning some basic awk for stuff like that. Unlike the vast majority of other UNIX text manipulation utilities, it is actually _sane_. It doesn't even do automatic string interpolation! So it's pretty easy to pick up just enough of it to do nice one-liners without needing to comb the manual for unsearchable weird special cases. For instance doing this particular thing would be `awk '{ print $3, $2, $1 }' | sort -nr &gt;sorted.txt`. Using python for that would be one hell of an overkill. It also has a pretty cute and powerful programming model, for instance `awk 'NR!=1 &amp;&amp; old != $1 {print ""} {old = $1} 1'` inserts an empty line before every line where the value of the first column changes. The program consists of a sequence of pairs "condition {statements}". For every input line for every satisfied condition the statement block is executed, in order. Omitted condition is true for every actual input line (see BEGIN/END below), omitted statement block is equivalent to `{print $0}`. The language defines several built-in variables, such as BEGIN (true before the first line), END (true after the last line), NR (current line number) etc. Undefined variables contain empty strings. Now you know enough to understand that pretty advanced and quite useful awk script!
I do know a bit about awk and unix' modular programs in general, but sadly, it definitely isn't the first thing that comes to my mind when I'm confronted with a problem like this. I really need to practice more and get used to it, since as you mention, it is very useful. To be fair though, I use iPython as a terminal almost. It's open all the time and I use it for small things like this all the time. In this case, `sorted([l.split(':') for l in inp.split('\n')], key=lambda x: int(x[1]), reversed=True)` did it fairly easily, but I do agree that it can be a bit overkill.
If you're testing for an empty string, nothing. Most of the time, you're really testing to see if a value was provided, in which case `if not some_string:` is the idiom I see most often. Besides, the parent wasn't speaking about only testing for an empty string. The whole context is: if some_string != None and some_string != '': In that case, `if some_string:` is much more concise.
I'm not sure that's a good thing. Don't get me wrong - shadowing True and False is monumentally stupid in every case I call to mind, but since when does Python go out of its way to keep me from doind stupid things?
Nice, had never seen that. I'll include as a link, its a super clean reference 
&gt; my school selected me to program some applications that would be useful to other students. In the future, this may expand to other schools. I see $$$ written all over this. While I don't have any recommendations on programs, don't let the school make money off of something you've developed. maybe i'm paranoid... but if you're looking at potentially developing a system that gets implemented in various schools, get yourself a contract stating something to the effect that you own the work and that under no circumstances are you transferring the ownership to the school for any grade.
"Intuitive" or "easy" or "simple" or "friendly" are all good words. Your English is better than my speaking of &lt;your language&gt; no matter what &lt;your language&gt; is.
Check out /r/officescripts, they recently started up and are asking for submissions for nice automation scripts in python.
Where's the commit? Or do you quietly turn autocommit on? (in which case, STOP) Does your connection accept the `read_default_file` parameter? It should, that way you can use the same .my.cnf to connect to the database as you use on the command line.
Why? Xamarin did the Xobot thing for advertising, they make money from selling C# / Android bridge products. Python doesn't need that.
Your link is broken. [https://openhatch.org/search/?q=&amp;language=Python](https://openhatch.org/search/?q=&amp;language=Python)
it is on by default. (https://github.com/emre/lurker/blob/master/lurker/configuration.py) It can be changed via configuration objects, though. For the read_default_file parameter, Connection class accepts everything you can send to MySQL-Python. (https://github.com/emre/lurker/blob/master/lurker/connection.py#L61) 
lol.
You are probably running Python 3 on your computer. The second example is required if you're using Python 3. Code Academy is probably using 2.6 or 2.7. Python 3 made a few fundamental changes to the language. print vs. print() being one of the most immediately noticeable. Even though there is an ongoing effort to update them, many libraries are still not compatible with Python 3. I think Python 2.7 is still the recommendation for beginners, but I'm sure someone will correct me if I'm wrong.
And here is mine https://github.com/thomasf/dotfiles-thomasf-base/blob/master/.bin/auto-archive It does not manager downloads only but also cleans my ~ and put everything not in a exclusion list under ~/auto-archive/year-month/ folder. 
&gt;Can i just install Python 2.x next to 3 and then change the interpreter in Eclipse? Yes. And 2.7 will get you by for pretty much anything Python, I don't work with Python all too much (but I appreciate it, that's why I'm here) but I've never *needed* to use 3.
Thanks, ill install 2.7 and use that from now on.
here is an example with autocommit=false https://github.com/emre/lurker/blob/master/tests/all_tests.py#L72
I thought python 3 was recommended for beginners, because that's the direction its headed.
Maybe. My initial feeling is that one of the nice things about Python is the huge range of libraries available and it's nice to not have to worry about which ones will work for you. I'm not really sure what the standard recommendation is. [This](http://wiki.python.org/moin/Python2orPython3) is linked in the sidebar, but it's almost 3 years old so I'm not sure if it's still valid.
/r/officescripts is a new thing, seems pretty cool
I think I can go one better: [dbkit](https://github.com/kgaughan/dbkit). I wrote it a while back to help fix up a bunch of horribly insecure and poorly written code written by a co-worker who was doing things like not using connection pools, not using prepared statements (rendering the code susceptible to SQL injection attacks), and hardwiring database connection credentials into code. The idea is that current connection is contextual, so you can do stuff like this: from dbkit import connect, query from contextlib import closing import sqlite3 ctx = connect(sqlite3, 'counters.db') with ctx: for counter, value in query('SELECT counter, value FROM counters'): print "%s: %d" % (counter, value) And so lazy people don't need to pass around connection objects, and cursors are cleaned up properly. It also has straightforward connection pooling (quickly hacked together): import psycopg2 from dbkit import Pool, transactional, query_value, execute # Pool size of 2. pool = Pool(psycopg2, 2, "dbname=namecounter user=foo") @transactional def save_name(name): if query_value("SELECT n FROM greeted WHERE name = %s", (name,), default=0) == 0: execute("INSERT INTO greeted (name, n) VALUES (%s, 1)", (name,)) else: execute("UPDATE greeted SET n = n + 1 WHERE name = %s", (name,)) if __name__ == '__main__': with pool.connect(): save_name('bar') That demonstrates transactions too. It's far from perfect (it could do with a less brute forced method of connection hardening), but it does humanize DB-API drivers quite a bit, and covers up a good number of their quirks. I use it in places where SQLAlchemy is overkill.
Have a look at [Kivy](http://kivy.org/#home). It's an app framework (similar to Qt--I think) that claims to send your code to Mac, PC, Android, or iOS. Their documentation is currently being overhauled, and can be a bit scattered (am learning it myself) but it's all very slick, and it seems to have some lovely abstractions.
I see that you have two or three quite often used projects on GitHub so I'm going to treat you as an adult. &gt; here is mine: https://gist.github.com/emre/805139. There are so many issues on so many levels with this. First and foremost: you provide a script that needs a config file but you don't show how it's supposed to look like. And you don't even show how to use the script. Some other examples of already mentioned issues: * Indention and code style in general is inconsistent. Lines 64-67 have 3 spaces instead of 4. The parts where you raise `OrganizerException`: why does it look like that? * The functions `getFileList` and `getRules` are both basically one-liners although in `getFileList` you assign the result to a variable before returning it and in `getRules` you don't. In addition both are only called once. So why do they even exist then? * This one is really weird. You have a function `getExtension` (by the way, [Python has this built in](http://docs.python.org/2/library/os.path.html#os.path.splitext)). The name suggests that it gets me the extension of a file and it does so ... more or less; it returns `False` if there is no extension. Why not empty string? But okay, that's not the weird part. This is the weird part: you call this function only once again ... to determine whether a file *has* an extension in `hasExtension`. And that one you call .. again .. only once. That makes one of these function completely pointless. But that's not the end of it. You use the latter function to filter out files without extension ([L63](https://gist.github.com/emre/805139#file-ddo-py-L63)) although right in the next line you call a function that matches rules from the config file against every found file. So why do you check for the existence of an extension again? Files without extension will never match a rule from the config file except there is one exactly for that case. There's more but I suggest ... **TL;DR** Delete this script and never speak of it again. **EDIT** Spelling and better word choice.
I wish I'd found this before I bought Hazel. Though I do love Hazel.
 class DatabaseConfig(BaseLurkerConfig): host = 'localhost' user = 'root' passwd = '' db = '' connection = Connection(DbConfig) Is this a typo? Should DbConfig be DatabaseConfig? It seems very strange that users should have to define a class for configuration rather than instantiate an object, what's the reasoning behind that? The page says "with Configuration objects" but that should probably say "with with Configuration classes".
I want to see a database library that implements ['named' or 'pyformat' paramstyle](http://www.python.org/dev/peps/pep-0249/#paramstyle), where you pass in a dict of values instead of a list. Everything I've seen uses 'format'. When you start writing long queries, it becomes hard to tell which %s goes to which parameter at a glance, and it's especially silly when you have to repeat parameters. In fact, my ideal system would allow you to pass an arbitrary dict or object whose values or attributes would be used in the query, and it would allow you to pass in more information than was actually used. This way you could be lazy sometimes and pass in existing objects instead of constructing new argument lists for every query.
It is. But a lot of places are still entrenched with Python 2 since they already have infrastructure set up using it. I'm sort of surprised that Codecademy uses Python 2. The basic rule is, unless there's a library you know you need that only supports Python 2, go with Python 3.
I find sickbeard pretty nice to work on ! And I'm surer there are plenty of things to code on that. http://sickbeard.com/
Do I have to run this as a cronjob or does it work as a daemon and monitor the directory?
In similar but more generic vein, http://flexget.com - we have much more features but we lack mature webui and yaml is too intimidating for casual users. We have had alpha level webui for quite some time but there aren't devoted developers for it. We're happy to guide new developers and point out areas that need more focus. 250+ unit tests and CI makes sure you're not accidentally breaking things too much :)
Also, it looks like you can `f.seek()` if your file has a header before the data. Sweet. I really want to use this on a project now, but is there a way to mask columns so it doesn't read them all in (and take up the extra RAM)?
This is awesome! 
Open Source is not only about code. Projects need help with much more. Unfortunately I've never contributed code to a project. But I'm sitting almost 24/7 in IRC channels and subreddits of projects that I like and use and I give support there. Sometimes there are problems that make me dig into the code base of a project to find an answer. I learn a lot because of that and I help people and the project.
No, but you can use `numpy.memmap` and some slicing magic, and/or `numpy.lib.stride_tricks.as_strided` to get the job done.
Not really informative for someone that's read the docs already. Also, I take it English is not your first language, so I will not criticize on that point except to say it's readable but not perfect. 
Using a mmap file as the buffer allows you to get just the pieces you need as well without reading the whole file in.
Big fan of numpy, but you can make your `struct` implementation a generator and load values lazily, if your data files get bigger than your RAM. Should be lots faster if you're not growing a list a trillion times.
Not sure how much it will help, but you can also use [Numpy with MKL](http://www.lfd.uci.edu/~gohlke/pythonlibs/#numpy) (Intel's Math Kernel Library) which should have better performance.
Couldn't make it up.
Looks good. Just a few tips though, OP: sumL = 0 for item in typesList: sumL += item i = 0 if sumL == 0: return others while (i &lt; len(typesList)) : typesList[i] = (typesList[i] * 100 * fileTypesPriority[i]) / sumL i += 1 maxIndex = i = 0 maxL = typesList[i] while (i &lt; len(typesList)) : if typesList[i] &gt; maxL : maxL = typesList[i] maxIndex = i i += 1 You can just use the max() and sum() builtin functions here. `maximum = max(typesList)`, `summation = sum(typesList)`, etc. Second, most Python programmers, and 99% of coders who are active in Python community, tend to use most of PEP8's style rules. The rules can be found here: http://www.python.org/dev/peps/pep-0008/ If you wanted to make it more PEP8-compliant, you should change all function names and variable names from camelCase to underscore_case.
Pandas uses NumPy under the hood right? Pandas is a fun way to do file parsing :)
Is this really mind blowing to some people? Seems obvious to me...
This. I sped up a binary file parser I wrote for work by a factor of about 5 by switching from struct to numpy to do the parsing. My boss loves it.
If you have 6GB+ of free RAM and Python is able to use it all effectively then it might be slower to use a generator-style solution. But the moment you start hitting swap all bets are off. Especially if you're reading the 6GB off the same disk that the swap file is on.
You could be totally right. Better to profile than to guess!
This is not professional by *any* means, but there are a couple of bugs my [media file renaming project](https://github.com/louist87/Scrappy/issues?page=1&amp;state=open). If this seems like the kind of project you'd be interested in helping out, I would greatly appreciate any bug fixes, suggestions, or additions. There are a few bugs that haven't been reported. If you're interested, I can provide details to reproduce them.
Hey there! Just to let you know, I'm an avid Flexget user, and I'm currently working on a plugin! Also, you guys have one of the friendliest IRC channels I've ever come across.
+1. with python &lt; {3, 2.7}, it is generally faster to instantiate a tuple than a list. not: set([1,2,3,4]) but: set((1,2,3,4)) * http://wiki.python.org/moin/TimeComplexity * http://stackoverflow.com/questions/68630/are-tuples-more-efficient-than-lists-in-python
* memory usage * startup time * CLI support * `%timeit` * ipdb
I guess it depends on the choice of patterns. Decorators are useful for http://en.wikipedia.org/wiki/Aspect-oriented_programming There are also times where it can be alot easier to decorate (or instrument) a class/function/method for debugging or tracing than to step through or `set_trace` and muck around. http://wiki.python.org/moin/PythonDecoratorLibrary
 _ = 'racecar' assert _ == _[::-1]
&gt; mangeDownloads.py You typo'd the filename...
Does anyone have any experience in benchmarking this against scripts that parse chunk at a time? for example if you had a 2GB file: with open('2gfile.bin', 'rb') as infile: while True: #Here would go code that grabs ~1k chunk of data, parses it into structs ... #Here would go code that acts on that 1k chunk of structified data ... #Decide if we are at the end of the file if file_end: break 
* PEP-8: Style Guide for Python Code: http://www.python.org/dev/peps/pep-0008/#other-recommendations * https://pypi.python.org/pypi/pep8 * https://pypi.python.org/pypi/flake8 
Nice! While we're at it. NumPy also has a fromtxt function, to read structured text files. It's very useful, and I can't believe how much time I spent writing my own parsers when I first started using Python (although, in retrospect, I did learn quite a few things doing that, back when I was taking my first steps in the beautiful activity that is programming).
You could use the reshape method. Given *a*, a 2D array: import numpy as np a = np.fromfile(File) a = a.reshape(rows,cols,order='F') Word of advice in case you are using floats: remember that a float in Python is equal to a real*8 in Fortran (i.e. a double float). If you are just using real in Fortran you should use float32 in Python. 
To be fair i think the numpy storage system occupies less ram to begin with.
I don't have benchmark data to back this up, but my guess is that on a modern OS this would not make a huge difference, because the underlying OS should notice you're doing sequential reads and start pre-buffering the file for you.
oh they're a lot nastier than just a few square matrices or whatnot, so I dont think it'll be that easy. So to give an idea, we have a header with a handful of integers and floats (dates, number of observations), then for each observation, there is basically a meta block and a data block...the meta has like 20 or so bits of information (some are floats, some are arrays as a function of this or that) and the data block has some more info, also of varying dimension. Then there's the fact that it's been built to have some sort of backwards compatibility. If I get bored some day, I'll post the code on pastebin for all to see. Simply put, the reasonable answer would be "jesus that should be HDF5 or something", but that unfortunately isn't the right answer for reasons that aren't necessarily good. I've also thought of building a more-simple wrapper in fortran, and attempting f2py.
Speaking to all introverts out there. I have just created an online course on Udemy about how to leverage the strengths and gifts of introversion in a world that congratulates extraversion. Its called the Introvert's Edge I am very happy to offer a 50% discount for you all expires Friday 8th March ...see link. http:/janterkelsen.com/udemy_discount
Javascript slide shows suck. I get no slides at all. The PDF link is fine, though. 
Thanks. Expect a pull request!
Hadn't heard of that before. It actually looks exactly like something I've been thinking of making. Will definitely give it a try. 
[Hachoir](https://bitbucket.org/haypo/hachoir/wiki) is quite good if you have to model or reverse-engineer a more complicated format.
How did you manage to botch the headline, this is almost entirely unrelated?
Just tested this on my MacBook Pro. Worked great, thanks so much! 
ONE SINGLE 8-word sentence for readme ??? you must be a joy to work with or to inherit code from.
I know hachoir uses generators heavily, but performance hasn't really mattered when I was using it, so I have no idea. Construct seems very similar from its PyPI page. Either implementation could probably take advantage of the declarativeness to optimise, say, random access (finding the tree path an offset is inside of) if they cared to.
Thanks for the tips. Constructive crticism is what makes this subreddit nice. 
Qtile is a project I wish I had a lot more time for, but use on a daily basis. It's a hackable tiling window manager, written and configured in Python. Very nice.
I also have had no programing history and have tried several books but found Michael Dawson’s book ...Python Programming (third edition) for the absolute beginner, to be very straight forward and easy to understand. great for newbies. 
Do you have example code? I'd appreciate seeing that done in Python.
Follow the docs at http://docs.python.org/2/library/mmap.html for opening a file through mmap. Then you could write a class that given an offset in the mmap, lazily loads things from it on property access or similar. 
Here is a lesson which includes a great set of resources including Books, MOOCs, Video Tutorials, Interactive tutorials, exercises which can get you started with Python. I have included my review along with some resources, which I have used while teaching Python myself. 
Why not making it database agnostic? There doesn't seem to be anything exclusive to mysql in this. I also may want to use a different driver (like a pure-python implementation). Personally I often use dbutils for connection pooling and it would be great if it played well with it. Other than that it's a good start.
Sweet! I look forward to it!
 I believe there's support for that in numpy as well. Edit: There's [`numpy.memmap`](http://docs.scipy.org/doc/numpy/reference/arrays.classes.html#memory-mapped-file-arrays) which sounds like what you describe. It seems to have the same interface as a normal `ndarray`. Edit2: `Numpy.memmap` does seem to be nothing more than a rather thin wrapper around `mmap` and `ndarray`, however. They even suggest using `mmap` directly in the docs, so YMMV.
&gt; Tokenizer support for non-ascii identifiers Wait, what, Python 3 has non-ASCII identifiers‽ I must have been living under a rock until now… Edit: Turns out I have. [PEP 3131](http://www.python.org/dev/peps/pep-3131).
https://python-gtk-3-tutorial.readthedocs.org/en/latest/builder.html
Ah, the days when I was a happy Arch and Awesome WM user. I no longer own a computer on which I can install my OS of choice, but once I get my hands on one, this will be one of the first things I try. Thanks a lot!
I will start doing this with the numpy and matplotlib irc channels, I think. They're the ones I'm most familiar with at debugging.
I don't think there's a way to do native apps There is this: http://kivy.org/docs/guide/android.html
Kudos for supporting those projects.
maybe not: * English: *a skin disease of mammals caused by parasitic mites* * Danish, Norwegian: *many, a lot* * French: declination of *manger*, *to eat* * Kurdish: cow
In the linked slides, [CFFI](http://cffi.readthedocs.org/en/release-0.5/) is recommended. Note that CFFI *is not about embedding executable C code in Python, unlike Weave. It's about calling existing C libraries from Python.*
10000%? So Python was worse by all accounts?
why not [partition](http://docs.python.org/3/library/stdtypes.html#str.partition)?
Right. I mentioned Weave because SwimsAfterEating talked about inline assembler in C and mentioned it might be nice to have something similar at a higher level. Weave is that thing.
Yes Python is the right place to go, no need for a plan, just do it. DiveIntoPython is a wonderful resource too, also "The Hitchhiker Guide to Python" is looking good. Better than excersises, start your own project with your own purpose, and improve it as you learn the language. 
Take a look at [Enaml](http://docs.enthought.com/enaml/) it wraps Qt and wxWidgets backends and has a constraints based layout i.e. flexible webpage layout style not a fixed GUI style.
Thanks, I didn't know this. I never looked at NumPy because I assumed it didn't have anything I would need.
I've tried android-scripting, but not for a long time and when I did I didn't do much beyond a simple test app: http://code.google.com/p/android-scripting/
Do you paid $25 for a thing like Hazel?? Come on last Lion was $29 ... Some Mac apps are highly overpriced, that's just abusive.
The batteries included option is the slower (though still pretty good I feel, don't really get his point), python html.parser. The recommended parser is lxml. http://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser &gt; If you can, I recommend you install and use lxml for speed. If you’re using a version of Python 2 earlier than 2.7.3, or a version of Python 3 earlier than 3.2.2, it’s essential that you install lxml or html5lib–Python’s built-in HTML parser is just not very good in older versions. Personally, I think arguing over faster HTML parsers for web scraping is an odd thing -- in normal use any parser on modern hardware is going to be faster than your internet connection.
If I were you, I'd go at my own pace, rather than try to schedule every lesson. Just do as many exercises as you feel like doing and then stop. Pick up from where you left off the next time. You never know; you might need more than one day for some of the exercises. There's no point in putting unnecessary pressure on yourself.
Calling it screen/web scraping/automation etc would let them find other resources. If someone read that, wanted to know more about the subject and searched for "reverse engineering" they'd find very different things.
That actually does native. Several apps in the Play Store are already using it.
I most definitely agree with this. Projects &gt; exercises. Even if your implementation of X is naive, the things you can learn from your own pitfalls and triumpths are far more valuable than any text or exercise can provide.
Three allocations.
Even if you're the sort of person who likes to structure everything, you'll probably want to go off and investigate what you find interesting instead of taking things in the order someone presents. I usually find myself investigating the weirder features like metaclasses and foreign function interfaces for fun rather than rehashing old problems in a new language.
I'll second kivy. I'm currently learning it. It's more of a full-featured App framework than just a means of getting your code to run on your phone. As such, there's a lot to get through to get your app off the ground but it does LOTS of useful things for you if you can learn its ways.
Just a comment about your post (thanks btw). Syslog is good for system wide logging: for security reasons it requires root permissions on the /var/log/message file. The logging mechanism in the python standard lib is meant to be used by applications (as well server running with special permision) *without* need to be superuser. You could adapt SysLogHandler to your need: is not that difficult and the logging module is very good. Thanks
Lepl isn't maintained anymore. Ply or pyparsing are also pretty good parser generators.
I am interested in learning python. The title of this post intrigues me, however there are an equal number of downvotes as upvotes. I am curious to the reasons this post being downvoted?
Why was this downvoted? Was it because it's just links rather than a tutorial or something?
Thanks mdipierro. Can you comment on what's new or changed about this edition?
That's a shame, it's a really nice package.
There are about 100 extra pages. Cover new scheduler, built-in wiki capabilities, more deployment recipes, new DAL api including geospatial API, and various other improvements and additions.
You absolutely don’t need root permissions to log to syslog: you’re communicating with a daemon, not touching the file itself. That’s also why you don’t have to care about log rotation. If your issue is that a regular user can’t read those log files, I believe you can tweak the file permission/ownership on a per-log basis. rsyslog is really flexible.
So I may have a scientific data analysis problem that doesn't seem to be solved by anyone. Is that the sort of thing you are soliciting?
It would certainly be something we'd be interested to hear about. If there's overlap with some of the problems we are dealing with, there may be collaboration potential; otherwise, we can try to get you connected to other groups whose problem space may be a bit closer.
Can anyone sum up why I would ever consider using this over logbook?
Logbook seems rather orthogonal. I’m sure it can log to stderr too so there’s no need to consider one thing over the other. The point is to use whatever you fancy in your app but have standardized formats/services that write your actual logs, rotate them, compress them and clean them up for you.
The whole point of an application log is .. well read it. Yes you could tweak it but the "tweaking" still need root permissions: on a multi user system that is not always possible. logging allows to chain loggers so it will be able to send it over syslog and/or a stream. 
Everyone is victim of their circumstances. :) Sure, if you can’t properly use/configure the system, syslog is a no-go.
SL4A is wonderful for testing out quick scripts and commands on the go. It's like a sketchbook for any script ideas I think of. It also allows for Python3, bash, and some others as well and even includes an API list for phone functions. Now, as for making an app, I think you need to get a bit tricky. Android IDE (in the Google App Store) could be used for making an app that runs the script, effectively keeping all your development on the device.
PyParsing seems to be in the same delarative style (whereas Ply is just Python Lex Yacc). LEPL has good usability, I hope moving away won't be a difficult transition.
Besides the webapp containers the article mentions, supervisord is a good general-purpose container to enable this approach (or runit if you are old-school). Forwarding to syslog doesn't really work if you aren't a system service, but things like svlogd can take care of logs just as well.
Centralising everything on a system that has a handful of hardcoded facilities, with everything landing in the "daemon" catch-all, isn't really elegant. Notice all the /var/log subdirectories which provide usable, specific logs and bypass syslog. That said, systemd's journal and its more flexible namespacing might make the centralised approach work again.
It's not just permissions, it's namespacing. User applications aren't singletons (many system services aren't either), and mixing all their logs in a single stream into a privileged daemon that has no notion of the (application, uid, instance) origin is a no-go. Asking every unprivileged application to apply for modifications to a privileged daemon's config is also obviously a no-go. The syslog approach is only good for monolithic appliances.
OHHHHHHHHH!!! Now I see what the python logo resembles!
You should be more careful with the word “obviously”. For *me* it’s obviously a no-go to use inferior NIH tools written in Python. Context matters, for many – or most? – it’s a non-issue to add a file to /etc/rsyslog.d – that’s what CM and .d directories are for after all. You also seem to vastly underestimate rsyslog and its capabilities. Basically everything you wrote is “obviously” wrong in my context. Does it make it wrong for you?
Do you hire remote employees?
I was setting a context here with «unprivileged», one which precludes the CM hammer. I am talking about distributing applications that don't care what the syslog implementation is and don't require admin privileges. A lot of the advice can still be valid, like logging to stdio and externalising logs, and one piece isn't, which is dumping to syslog.
Hmmmmm not sure exactly what this is. I'm kind confused. Would it be anything of interest to a Junior in High School who is interested in a career in CompSci? I live in Stafford, VA if that means anything.
Hate is a destructive emotion - it's generally more helpful to be constructive. You glossed over stdlib logging's support for `syslog` by saying that it doesn't support setting the app name out of the box. However, the app name is just an identifier at the start of the message sent to `syslog`, so it's not exactly difficult to get the same effect in Python 2 (it's certainly not a reason to avoid using the SysLogHandler in stdlib logging). There are several ways you could choose to do this; plus, you can easily avoid sending exception logs to syslog if you'd like to do that. You're also not forced to use `TimedRotatingFileHandler` for log rotation - stdlib logging plays well with e.g. `logrotate` and other external log rotators. I take it you're being sarcastic when you say you're not smart enough to configure logging - AFAIK numerous people manage to configure it OK, and as far as I know they don't claim to have an unusual excess of grey matter. Perhaps you should try it, and if you run into any problems you can PM me here, or post to `comp.lang.python` and someone should be able to help out. Of course, you can log any issues if you have concrete ideas for improvements - as logging's maintainer, I'm generally fairly responsive.
First post nails it ONCE AGAIN...
I see you guys are looking for interns, and I wanted to know exactly how much experience your looking for. Would this be suitable for a first year internship?
You may find this dated in the future. Think of how you would look at a FORTRAN tattoo on someone today.
What's your current level of programming? You're welcome to get involved with a small project to see if it's up your alley, and then apply for an internship. We will discriminate based on age, and I have had one highschool student already do a bit of work on the project, plus early-career undergrads. Shoot me a message.
It'd be like the old green faded navy tattoos.
If you're willing to work hard and learn, there are projects for many levels of programmers. Send me your resume and a cover letter, and we can talk details.
Oh dang, I thought you were going to show us a pic of your pet python :(
You guys need to relax. He'll just download the newest release of this tattoo.
I think this is awesome. I also don't care if this might be dated one day. You'll be able to look back and think about how much you liked python.
"Probably" is probably my favorite word. 
Maybe this is why he didn't made it 1:1.
Even not comparing it to the Python logo, its still a pretty nice tattoo. So, I doubt there's any issue. Anyhow, Yo, dawg. I heard you like Python, so you got some pythons on your pythons.
No! Your logic is not welcome here!
most of us here are programmers, we know how to deal with logic.... ;) 
Vinay there is a theme to your explanations: “do this, do that, then it works.” Why should I do all that if my solution is simpler and has less moving parts? What is the advantage? I’m convinced that NIH-solutions should only be used when necessary. For example the cases that have been mentioned in the comments where people can’t configure their syslog. Systems *I* work with consist of more than Python applications, so why should the ops learn a new configuration scheme just for Python apps if all it takes is logging to stderr and redirecting that to syslog? Look, the post struck a nerve with a lot of people (you may have seen https://twitter.com/swearyanthony/status/309320965207240704 – I was a bit shocked TBH to see how much bitterness is still going on) and it’s nothing personal and it certainly isn’t even due to any design decision *you* made. But if even Chris gets frustrated like that and Armin &amp; Georg feel the need to write a replacement, there obviously *is* something wrong. Fixes you make and end up in Python 3.4 in 2014 won’t help anyone with their logging frustrations in 2.7 now. I also really don’t intend to discuss with you *what* went wrong because I found a way for myself to make logging less painful and shared the results. There is *nothing* destructive to it. I didn’t discourage the use, I didn’t tout 3rd party solutions. Please note that my main point was that logging (noun, not package) is inconsistent across frameworks. They configure differently and behave slightly differently. I lost my temper and looked for alternatives after I tried and failed to configure Twisted’s twistd to behave like my logging-based web apps and my Pylons app occasionally swallowed log entries for no apparent reasons. And the solution is so simple: Use mature tools that exist for decades and look for re-implementations only if you have to. To stress it once more: the article is not just about logging the module but logging in Python in general. And I certainly didn’t mean to offend you – I felt the information is useful so I shared.
&gt;Naming &gt;"Python's name is derived from the television series Monty Python's Flying Circus, and it is common to use Monty Python references in example code. For example, the metasyntactic variables often used in Python literature are spam and eggs, instead of the traditional foo and bar." Quote: http://en.wikipedia.org/wiki/Python_(programming_language)
Agreeing with a couple of the posts so far, I think it's cool independent of the logo and it's not in your face about the reference. When Python fades from relevance and/or the logo changes, then I'll have a kickass tattoo that doubles as an old-school Python programmer detector.
Well yeah, but the logo is also two snakes.
Just curious, what did you think it was?
Bad assssssssssssssssssssssssss .^.^rimshot!
I like it! The snakes are good. The fire/ice is good. The link to python is abstract but the snakes are actual snakes. The tattoo isn't shit. Congrats.
It might not be exactly what you need in your specific setup .. But for web applications I use Sentry as logging server. It's pretty easy to configure and use and the interface really awesome. I'm on a phone right now so pardon me for not going into details, but you should really consider giving it a try. I couldn't live without it.
Yes. Just thought I'd be a dick like that.
It works on my Ubuntu 12.04 32-bit system, at least. Just follow the steps at the bottom of the question, along with the things that I mention in a comment. 
Exactly, snakes are cool.
Blog posts like these should **always** have a short "about" paragraph. I have no idea what Motor is but clicked out of curiosity.
Seems like a lot of work to go through when you can already do this with `wget`: wget -r -X excluded1,excluded2 ftp://user:password@host
We certainly need open source developers--everyone is welcome in that regard. If you don't mind, send me an email with your resume, so I can have it on file. There is always the potential of remote work in the future, and we will be sponsoring bounties and open source library work as well.
Pillow is a fork of PIL (Python Imaging Library) which is widely accepted to become the descendent of PIL since PIL does not work for Python3, can't be used with pip, and hasn't had a release since a long time ago. Fedora is planning on using it: [http://lists.fedoraproject.org/pipermail/devel-announce/2013-January/001009.html](http://lists.fedoraproject.org/pipermail/devel-announce/2013-January/001009.html) (not sure how long this link will last - not too familiar with the durability of threads like this). 
Yeah, but if you do `raise e` then I believe you lose the original stack trace. So if you want to add any information to an exception you caught in a way that might raise an exception itself that you need to catch, then you have to extract it into a function. Kind of annoying.
Your welcome, ;-). A couple of my commits contributed to this. I'm eager to get all libraries that I use off of Python 2, as I write only Python 3 now, and having to deal with mixed code bases is a pain.
Ugh, and I *really* want an Easygui! Not actually enough to take over the project, and not enough to finally add actionable tables to it. Just enough to use the shit out of it. Sorry if my lack of interest in taking it over offends - I have about a million things that I want to do. I simply can't run a million projects. But hopefully someone else is in the right spot and would like to do this.
Well that's one major obstacle out of the way for widespread adoption of Python 3. Great job pillow team! Thanks for saving us from the scourge of abandoned libraries.
But only on Linux (I assume) Windows has nothing like this, as far as I know.
https://en.wikipedia.org/wiki/Wget &gt; Written in portable C, Wget can be easily installed on any Unix-like system and has been ported to many environments, including Microsoft Windows, Mac OS X, OpenVMS, MorphOS and AmigaOS.
I've used PIL with pip quite often lately. It works fine.. I've been wondering what issues people are having with it that I'm not seeing..
A shame - the pure *easiness* of EasyGUI was quite wonderful, if limiting.
The problem I had with this library is it doesn't list all of the errors it can as it validates, which is useful for web forms. I made a version that does this - if the data structures match but the data doesn't, it will give you back all the places and where data is wrong and the error. Its not my best work but if someone is interested I might put it up on github.
Hi. While I'm a staunch promoter of Open Science, I have honestly no idea what you guys are doing (I looked through the website, but I don't run flash so I did not see the video). Are you trying to coerce scientists to use certain toolchain so results are more reproducible? (won't happen). Or what else? I'm not criticising, I'm genuinely interested. I'll pop in at the pycon sprint.
Thank you, i'll take a look. I was following the Google Lectures, they are good if you already know basic programming but not python, they totally skip the grammar, declaration, what is a variable, etc. Maybe this is a good complement to those videos.
&gt; Why should I do all that if my solution is simpler and has less moving parts? No reason - I'm not suggesting that *you personally* do this or that. Perhaps I should have used the impersonal "one can do this or that" - I'm just trying to show what is possible. Other people have different needs from yours - for example, syslog isn't generally available on Windows systems. &gt; Look, the post struck a nerve with a lot of people Did Sweary Anthony really add any value to anything? He needs to get out more - none of this is worth getting *that* worked up about. He certainly hasn't done his research - he talks about "porting directly from Java", for example. I rarely read Twitter because there's too much of this stuff going on - just shouting with no context. Let's remember that no one in general is forced to use stdlib logging - people are free to use LogBook, Twiggy or whatever else they'd like to. &gt; But if even Chris gets frustrated like that and Armin &amp; Georg feel the need to write a replacement, there obviously is something wrong. Some people don't like logging because of their personal tastes, not because it doesn't allow you to do something. As far as I know, Chris hasn't logged any issues recently. Any issues that are raised on the Python bug tracker are generally dealt with promptly. &gt; Fixes you make and end up in Python 3.4 in 2014 won’t help anyone with their logging frustrations in 2.7 now. The [logutils](https://pypi.python.org/pypi/logutils/) project is specifically there to provide logging features added in 3.x for users of 2.x. While not every *single* change is ported, most of the useful ones are. Perhaps if people actually articulate what their frustrations are, I could help (if they're to do with missing functionality - I can't really help if they just don't have the same tastes). But if they don't say what the problem is, how can anyone help? &gt; I also really don’t intend to discuss with you what went wrong because I found a way for myself to make logging less painful and shared the results. There is nothing destructive to it. I didn’t discourage the use, I didn’t tout 3rd party solutions. Sure, and I have no problem with your post. I was referring to the "hate" you mentioned - which was a link to Chris McDonough's tweet. &gt; And the solution is so simple: Use mature tools that exist for decades and look for re-implementations only if you have to. Horses for courses. A devop's logging requirements will be different from a developer's, which will be different from a support desk's, and so on. &gt; And I certainly didn’t mean to offend you I didn't take any offence. 
&gt; Basic Tenants Apart from that, a pretty good intro. 
This is what we have been working on. Win/mac 32/64 should work too
I've looked a little bit at some of the work you've done, and it's considerable! I appreciate all of this hard work and you guys putting it out for use by everyone else. 
FYI: List archives like that typically use stable URL formats for years, so you needn't worry about the link expiring. :)
On the plus side: it's not going to disappear. It's been pretty stable for quite a long time, and it supports Python 3, so if it works for you, just carry on using it. If you find a particularly pressing problem, dive in and fix it. If there are enough problems, eventually someone should bring all the fixes together and make a new version. If anyone's concerned, you might want to put it on Github now, and suggest that people fork from your copy, so it's easy to merge different changes later. It doesn't look like it uses source control yet, so you'd just have to import the last release.
I've realized that I misspoke, according to [Pillow's Git page](https://github.com/python-imaging/Pillow), PIL is not setuptools compatible - which means that it can't be used with easy_install (basically, you couldn't make eggs with it). More info can be found [here](http://mail.python.org/pipermail/image-sig/2010-August/006480.html) (a direct link to the python dev thread concerning PIL that the Pillow people linked to). 
Thanks for that confirmation, but as a separate question, which threads do have link expiration? By which I mean, how do I identify which ones are stable and which aren't? 
Be a good coder that isn't totally clueless about python. Seriously. If you have a position out for a "python developer" what they mean is a "programmer that can survive in python and is willing to learn to excel". A good C++ programmer should reach that level in 15 minutes of studying the language :P
I don't know what you mean by "elegance", but using interp+fsolve is not the best because it can miss roots, while the fact that you can process all available data means that you can find all roots (as far as the resolution of your tabular data allows, anyway). It would take a bit more than a couple of lines, and I don't know if it has been done already, but it shouldn't be that hard. First, use something like `sign_changes = numpy.flatnonzero(numpy.diff(numpy.sign(yarr)))` to find all indexes where the function changes sign, then for each index lerp between the values in the xarr (which you don't need as an array now, just calculate them on demand) there and at the next index (remember, diff returns an array shorter by 1) using values in the yarr if you want to calculate the root with more precision. The tricky part is to process actual zeroes in your data without accidentally counting them twice, including when zero happens to be the first or the last element. Either carefully check that the current item is nonzero as you loop through sign changes, then separately check if the first item is zero, or do something like `numpy.flatnonzero(numpy.abs(numpy.diff(numpy.sign(yarr))) &gt; 1)` (not tested) which would exclude all transitions involving zero, then add numpy.flatnonzero(yarr == 0). I think I would go the first route though.
I can't get it installed on Win7/Python33.I basically tried everything I could find on StackOverflow.With the latest MinGW version installed,path set to C:\MinGW\bin,and compiler setting changed in \Lib\distutils\distutils.cfg,I get the error: gcc: error: unrecognized command line option '-mno-cygwin' error: command 'gcc' failed with exit status 1 Does anyone know what I should do?
Will any of the ipython team be around during sprints? I'm around and hoping to participate in the [osf sprint](https://github.com/OpenScienceFramework/pycon2013/wiki) and it would be exciting to exchange ideas with people working on other tools. 
thanks, on my list of things to evaluate now. i like flask because it's fast to work with, but i haven't tried a large project with it yet. i dislike the routing via decorators (it makes tracing routes manually in the code slower than it should be as your project gets bigger), and it looks like pyramid uses a basic django style routes management system. thanks again. 
The reason unicode is hard to understand is because ascii text, which is just a particular binary *encoding,* looks for all the world like it is understandable by examining the raw bytes in an editor. To understand encodings and unicode, however, you should try really hard to *pretend* you cannot understand the ascii text at all. It will make your life simpler. Instead, let's take an analogy from music files like mp3. Say you wanted to edit a music file. To change the pitch or something. You'd have to convert the compressed music *encoding* which is mp3 into its raw form, which is a sequence of samples. You need to do this because the bytes of an mp3 are incomprehensible as music. (By the way this is exactly what a *codec* does, it decodes the mp3 to raw samples and plays them out your speakers.) You'd do your editing. Then, when it's time to make it a music file again, you'd convert it back, *encode* it, if you will, back into an mp3. Treat text the same way. Treat ascii text as an unknowable blob. *Pretend* you can't read it and understand it. Like the bytes of an mp3 file. To do something with it, you need to convert it to its raw form, which is unicode. To convert it, you need to know what it is: is it latin-1 encoded / ascii text? Is it utf-8? (similarly, is it an mp3 file? Is it an AAC file?). And, just like with music files, you can *guess* what the encoding is (mp3, aac, wav, etc.), but the only foolproof way is to know ahead of time. That's why you need to provide the encoding. Only when it is unicode can you begin to understand it, to do stuff with it. Then, when its time to save it, or display it, or show it to a user, you encode it back to the localized encoding. You make it an mp3 again. You make it ascii text again. You make it korean text again. You make it utf-8 again. At this point, you cannot do anything with it besides copy it verbatim as a chunk of bytes. This is the reason behind the principle of decode (to unicode) early, stay in unicode for as long as possible, and only encode back at the last moment. 
Every programmer should be aware that string is different from encoded byte array (e.g. UTF-8 string) of it as like image is different from encoded byte array (e.g. JPEG file)…
Well,it still doesn't work.Now I'm getting hundreds of other compiler errors and warnings.Thanks for replying though!
March 18th through March 21st are PyCon [sprints](https://us.pycon.org/2013/community/sprints/) and you can sign up [here](https://us.pycon.org/2013/community/sprints/projects/) to participate in the open science framework sprint. Just a reminder, you don't need to be registered for PyCon to participant in sprints. update: doh, I forgot to point out that people can sign up to participate in the science framework sprint, not generically.
Just out of interest, are you using MinGW or MinGW-W64? I'll assume you're talking about MinGW and 32-bit Python. I've also found in some situations you might need to locate the following in the same file: self.dll_libraries = get_msvcr() and change it to: self.dll_libraries = [] #get_msvcr() I've had luck with those changes.
This is unfortunate but it is the right step by the author. I wish more projects did this. I was looking for an easy gui. In recent Python's (2.7) that have ttk support Tkinter might not be a bad choice for a simple GUI. I am most excited about kivy and PySide though. 
Everything is perishable given enough time but [Cool URIs don't change](http://www.w3.org/Provider/Style/URI.html). Most cases of dead URLs I see are from dead services, some - from (poorly) upgraded websites. Neither are predictable, but thankfully there is archive.org sometimes.
I picked web.py based on that. I don't like routing via decorators. I like routing to be visible at the top and I like my resources to be classes and my methods to be ... surprise ... methods. http://webpy.org/skeleton/0.3 
&gt; for years For the fun of it - find a list archive that goes back not years, but decades.
Pyramid likes declarative (er, non-decorator) routing too. Pretty much all of the decorators are just syntactic sugar for a method of the Configurator object. In the case of `@view_config`, you can decide to have nothing to do with it, and use `config.add_view()` instead. Nor are the decorators magically loaded through some behind the scenes trickery - you have to explicitly call `config.scan("module-with-decorators")`, so everything in your project is explicit and surveyable. A decorator on it's own does nothing. (See the [url dispatch](http://docs.pylonsproject.org/projects/pyramid/en/latest/narr/urldispatch.html) narrative - though resource traversal routing is also kinda neat). I think Pyramid is more of a framework's framework - it can seamlessly handle a large number of different styles, and lets you pick which kind of framework *you'd* like to have, and use it that way. I'm still learning it myself, but I think that was what I initially found daunting - that you'd better have an opinion on how to structure things, because Pyramid doesn't :) 
When installing via pip in a virtualenv on Ubuntu 11.10, I could not get it to link against the system version of libjpeg. Pillow worked fine. Note how these instructions for getting PIL installed in a virtualenv requires first using sudo to create symlinks: http://www.mlewislogic.com/2011/09/how-to-install-python-imaging-in-a-virtualenv-with-no-site-packages/
+1 I clicked through &amp; still don't know what it is.
&gt; print("Hello {name}.".format(name=name)) There, you've now had to deal with it. If you don't do the right thing up front, you'll be plagued with bizarre, hard to diagnose errors down the line. That's practically the entire point of this guy's talk: Character encoding is actually a really simple concept, but people get confused because they have that attitude that they can pretend they don't need to deal with it, then try to patch on half baked fixes after they've already created a huge mess. 
Hi, Fernando, you have been on my list of people to get in touch with (congrats on the Sloan grant, by the way), and I was going to be emailing you soon to arrange a meeting at PyCon. Good timing on the message! I think there's some neat stuff we can do to connect iPython and the OSF; as I mentioned last year, iPython is at the top of the heap for creating reproducible research, and we definitely want to facilitate the use of it. I'll send you an email to make sure we find time to meet up.
I prefer to roll together something specific and applied with Flask and SQLAlchemy. Django's advantage is its large toolset and the way it enforces structure and convention. For a huge project or something with a lot of developers, the more-rigid-than-Flask design patterns help ensure consistency. Flask is a micro-framework; a webserver and a tool to map URLs to Python callables, as well as some convenience plugins (Flask-Auth, etc). This lets you create your own solution. If you're creating a simple REST API, all you need is a db cursor and a handful of GET/POST methods. Drastically simpler, but it's possible to mess up 'expansion' of your codebase because everything is hand-rolled. That being said, a "Coding Guidelines" article on a shared wiki, git, and regular *code reviews* can help ensure consistency in anything.
I've been programming for 10 years professionally and I haven't had to deal with it. Maybe I've been pretending but that has worked great for me so far. That is why I don't want to learn something that 1) doesn't interest me 2) haven't found a need to learn about. I'll just wait for the bizarre, hard to diagnose error to pop up. 
I suppose if you never take input from any source on the Internet, then you have chance of never seeing anything. More likely is that there are errors from your code, but you're passing them on silently to other people in the form of underspecified (i.e. not tagged with charset) or corrupted data, and answering their complaints with "works for me." 
&gt;"The Pyramid tenants are: Simplicity Minimalism Documentation Speed Reliability Openness Pyramid is based on Zope, Pylons, and Django. It supports small and large projects so there is no need to rewrite like you would with small frameworks. It's also the fastest Python web framework." I think the author will have a hard time to justify most of these. To me, the only advantage Pyramid has, in comparison to Flask for example, is that in some (but not all) ways, it's a little more flexible. For example, Flask comes with Jinja2, where Pyramid does not. But really, this is not tiny, tiny issue. On the other hand, the way Flask handles modules, blueprints, seems to be much more flexible. Simplicity, minimalism, documentation, I think Flask wins hands down. "[Pyramid] supports small and large projects so there is no need to rewrite like you would with small frameworks." Well, I hope the author can justify this statement. I doubt it is true. "It's also the fastest Python web framework." Is this based on winning a "hello world" contest as it appears to be? Seriously. 
This is why I love Python and this community. What a great, rnthusiastic and informative video. I'm going to dig for more of this guy for sure!
The biggest stumbling block I had was realising that Unicode **is not** an encoding!
That was my approach for a long time. THen you realize after you've got a big code base that it sure would have been easier to do the handling to begin with. 
&gt; I suppose if you never take input from any source on the Internet, then you have chance of never seeing anything. Bingo
Oh, I'm just wondering if there's an easy way to solve roots of tabular data in the form of say, z = f(x). The motivation is just for a solver for various engineering problems as pertaining to generating performance envelopes. 
&gt;&gt; I suppose if you never take input from any source on the Internet, then you have chance of never seeing anything. &gt; Bingo You realize that was somewhat sarcastic, right? Regardless of whether your application is directly connected to the Internet, you'll get data from *somewhere.* Aside from purely numerical, unlabeled data (since any textual labels could have non-ASCII data in them), I can't really think of any data that can be guaranteed to remain within the ASCII character set. If someone at a keyboard can enter string data into your system, some day, someone's going to enter a non-ASCII character. I've run in to people like you before – your documentation generally specifies something like "all incoming XML must use the UTF-8 character set," yet when I send you my list of customer names, you freak out at the 11th hour of the project because thousands of them legitimately have accented characters in their names. The world is messy, and Unicode code points are a way to generalize over that mess and avoid thinking about it. Pretending all data fits in [A-Za-z0-9 .\\-]* just leads to having to deal with *more* character set mess in the end, or requires ludicrous prohibitions like, "No, you can't use 'cafés' as a column label." 
A similar explanation - in prose rather than slides - is the classic [The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets](http://www.joelonsoftware.com/articles/Unicode.html).
"Bytes on the outside, Unicode on the inside" This is the best tip I've seen on Unicode. Input -&gt; Decode the byte string into Unicode objects -&gt; Work with it -&gt; Encode it back with the appropriate encoding -&gt; Output 
There's no easy way of telling. I've just seen that archive system (I think it's the default with Mailman) enough times to know that it's safe. More modern systems often have a 'Permalink' option, which should be stable.
The scalability from large to small is true in my experience (certainly more than django, but I don't have any experience of flask). I use jinja in pyramid, it works seamlessly.
Traversal is the killer feature of pyramid IMHO. Learn that over routes is my advice.
From pypi non blocking mongodb driver for tornado. I don't have a cool blog to put that sentence on. :) 
Not too much, unfortunately PyData is right after and I have to speak there. I think MinRK will be sprinting a little bit with Olivier Grisel from sklearn, but I don't know if they'll do it at the conference venue or in our lab space at Berkeley. The details are still a bit up in the air. Do stop by our booth though if you'd like to chat, we'll be there for the full three days.
There's a function to do that [in the standard library](http://docs.python.org/2.7/library/datetime.html#datetime.datetime.strptime).
It's nice to see widely used packages ported over to Python 3. 
http://scipy-lectures.github.com/intro/scipy.html#optimization-and-fit-scipy-optimize
Enjoy your gold as I will enjoy my new life without ASCII!
Great to hear - can you point me to an example? I saw no mention of tables anywhere in their documentation. The closest was an example of displaying two items - and rather than display them as lines they displayed them as two adjacent sets of data. Which was actually kinda bizarre. 
it would be nice if you could elaborate on these blueprint thingies. flask fans tend to throw that out there but fail to describe it for those who don't know. it would help your case. but you dont owe me any explanation I wont use flask anyway. :)
webapp2 is pretty good too!
It's a mechanism for abstracting a site or partial-site as a reusable component. You make a sequence of method calls on a Blueprint instance with a similar API to configuring a Flask instance. These method calls are 'recorded' in the Blueprint instance. Then you can ask that Blueprint to 'replay' its configuration on a Flask object [under some path prefix]. This allows you to decompose the configuration of a Flask object, so that larger and more complex configs are somewhat more manageable. I don't write a lot of Flask, though, and I feel that other frameworks do comparable things. Maybe a real Flask partisan can explain why this is better than the alternatives. 
actually webapp2 is pretty basic and I think it sucks. but I only evaluated it against non-trivial requirements for an application. it's one saving grace is that it uses webob. other than that, the request routing to views is very primitive. I will say it's easy to understand since it doesn't do much.
I appreciate that Pyramid is not Rails and is more focused on interop than Django. However, it does fit solidly into the framework pattern of "don't call me, I'll call you". Isn't that an opinion on how to structure things? 
&gt; I can't really think of any data that can be guaranteed to remain within the ASCII character set. Really? You cannot think of any other kind of data. Audio, video, images, sensor data. If anyone enters a non-ascii character for a text label it gets rejected. &gt; I've run in to people like you before Have you? Given by your short list of guesses of type of input a system can have, I would doubt you can accurately guess that you've met people like me before. &gt; The world is messy, and Unicode code points are a way to generalize over that mess and avoid thinking about it.The world is messy, and Unicode code points are a way to generalize over that mess and avoid thinking about it. I can tell you again, I don't dealt with that kind of data, which supports my original point, but somehow I feel you'll just reply that you know me better than I know myself. &gt; Pretending all data fits in [A-Za-z0-9 .\-]* just leads to having to deal with more character set mess in the end, or requires ludicrous prohibitions like, "No, you can't use 'cafés' as a column label." Yap. You can't use cafés in this system, sorry. It wasn't a problem for 10+ years even when selling to international customers.
If you want a big Django-like thing then I agree that webapp2 isn't one, and Pyramid is much closer.
thanks for the explanation. so in my head it sounds like reusable apps in django? if that's so the upside would be "reusable" components. and I put that in quotes because my brief experience with django I had forked a bunch of those apps to make them do what I needed to so I didn't find them as useful. But I suspect in a community as large as djangos some apps are better than others and so if you manage to pick the right pieces and those pieces work perfectly than you're good to go, if not brace yourself for hell fire. it also seems like what you describe I would think of as what [pastedeploy](http://pythonpaste.org/deploy/#composite-applications) does. by allowing you to configure in an ini a series of wsgi middleware and wsgi apps mapped to urls and passed configuration information in a standard way, this isn't specific to pyramid, and works with any wsgi but it does help manage complexity in configuration. For example, for the appengine project I maintain at the day job I have a base config that a small script calls to load which is called by appengines app.yaml because that's how appengine rolls. I think it's stupid but whatever...... The way my test suite rolls is via webtest(actually webobtoolkit now) calling the wsgi app directly. So my unittest app config ini file inherits from the main one but adds a few extra things like mocks for the blobstore upload handlers and a few other things that make integration testing nicer/possible without having to bind the app to a socket. If instead I wanted a common set of endpoints(like /login /logout) as part of my app that was a separate pyramid application I'd probably use some of the more [advanced capabilities of the configurator](http://docs.pylonsproject.org/projects/pyramid/en/1.4-branch/narr/advconfig.html#including-configuration-from-external-sources) but I've never needed to.
I sent you a message. If you have anything small to work on, just lemme know.
I disagree. but that's based on my experience. your mileage may vary. 
I think it's important to understand that data is always in some format or another. A "raw" sound file is still in 16-bit little endian to be played at 44.1 kHz (for example). Sound in mp3 form is smaller and easier to store, and has nice meta-information like id3-tags; sound in "raw" format is easier to play back and therefore what your soundcard expects (though soundcards nowadays probably want 48 kHz). Python tries to hide from the programmer how it encodes unicode internally and presents you with an abstract, immutable list of code points. So it makes sense to think of it not having an encoding if you're programming Python, but the same logic doesn't work if you're programming in C. In C, you need to always keep track of the format of your strings. What's most convenient might depend on your problem, but most of the time you probably want to have all your strings in UTF-8. I'd also like to talk about Unix filenames: On Unix, a filename is just a string of bytes (with '/' and '\0' not being allowed). This becomes a problem as soon as you need to output a filename (for example, show it to the user, like ls). On a modern Linux, since the locale setting will be UTF-8, you would probably try to decode the filename as UTF-8. However, the filename might not be valid UTF-8 and/or contain non-printable characters! So, Python wants to support unicode strings as return types/arguments to things like listdir() and open(). For that, it must somehow be able to decode broken UTF-8 filenames, and then encode the resulting unicode string back to the original bytes! So you can't just replace any invalid UTF-8 with question-marks or ignore it. So here's the trick (you'll need Python 3.1 I think): [PEP383](http://www.python.org/dev/peps/pep-0383/) (see also this [mail by Markus Kuhn](http://hyperreal.org/~est/utf-8b/releases/utf-8b-20060413043934/kuhn-utf-8b.html)). Invalid UTF-8 sequences get represented as [surrogates](http://en.wikipedia.org/wiki/Mapping_of_Unicode_characters#Surrogates) (there's also a "surrogateescape"-error handler for decode()), and these surrogates then get encoded back into broken UTF-8 when needed, thus making sure that the bytes in the filename survive the roundtrip.
Did you actually read the code? `strptime` is *not* what the OP has written, but it is rather simple and fairly easy to implement (it's only about 70 LoC).
&gt; Audio, video, images, sensor data. i.e. numerical data. Having Unicode based filenames (i.e. tags) when imported or exported, naturally. If you forbid all non-ASCII data out of hand, of course you rarely deal with it. The question is whether it's reasonable to demand that input data be intentionally misspelled to conform to the training limitations of your software developers. Perhaps 10+ years ago, "the computer can't do that" was a reasonable (or at least, credible) limitation. I remember dealing with the horror of code pages, and UTF-16's blowing up byte-based software. Now that Unicode's been around for ~25 years, though, telling your customers it's impossible is pretty clearly a crock. &gt; If anyone enters a non-ascii character for a text label it gets rejected. &gt; ... &gt; I can tell you again, I don't dealt with that kind of data, You don't say. 
Cheers mate. Glad you found it useful! 
I think you're right in principle, but python isn't often used as an end-to-end language, rather as a high level "glue" code. While many aspects of interacting with users are builtin, often you will use external libraries which will expect a certain encoding. I think qt gui python bindings will expect you encode text in utf-8, and even when printing things to the user via stdout you should take care to figure out what encoding the console expects.
So it is. Beg pardon; it seemed inconceivable that there wasn't an included battery for that. OP, you should should put the code on https://gist.github.com so pelple can fork it and post it to /r/officescripts.
These will cost you about the same energy: * Learn to use pyramid * Learn WSGI and write your own stack
yeah the tutorial looks very funded. also like the references. hopefully i'll have some time to dive into it later that week.
With Python 3, you can just put `open(filename, encoding="whatever")` when you read and write and Python will automatically do the decode/encode step for you. 
No, the reason Unicode is difficult to understand compared to ASCII is that Unicode is bloody complicated. Apart from the multiple encodings, you have to deal with things like variable-width encodings, combining characters and normalization, collation, and that's before you even get to cultural issues like Han unification.
Nice little piece of code
Goldylocks rule: This is all best summed up by the rule write the fewest classes that don't blow up. We've all seen the evil mega all consuming class that does everything under the sun. And we've all seen the architecture where something horrible happened and there are so many classes that do so little that you just can't wrap your brain around them all. So you should have the right number of classes which is often determined during coding. Your design might have been clean but then one class starts getting cluttered and demands to be broken in two. Or you have two classes that refer to each other so much it is incestuous and need to be combined into one. 
Here is the original announcement https://plus.google.com/118290124501648575087/posts/YPya9eQjhqs Improvements: - Removed dependency on presence of fbclient library at import time. This caused some confusion to new users when fdb install failed when Firebird was not (yet) installed. Bugs Fixed: - http://tracker.firebirdsql.org/browse/PYFB-25
Do you have any examples?
He developed it in the 1960s when he was a visiting student in Moscow trying to sort words for an algorithm he was developing! Imagine coming up with a world famous efficient sorting algorithm as just another part of your student project!
It's an interesting subject to me, but I think I had better stop myself from speculating on the intention of the design, or the lengthy and somewhat personal blog-style critique of it that I would like to do. If only there were a place where people went to discuss Python in detail... My impression is that Blueprints were meant more as a mechanism for internal organization/factoring than publishing the components like packages. Since I have some experiences probably similar to yours with Django's huge app ecosystem, I agree that the utility of the latter is open to question. Shopping for and integrating 'reusable apps' can sometimes take as long as building from a lower level. I've never been quite happy with the tools for testing WSGI apps and was just muttering to myself about webtest last week, so I'm interested to check out webobtoolkit. 
*stuff* calling your code: a framework Your code calling *stuff*: a library 
About time eh? Didn't know that this had happened, other than "Python 3 makes Unicode easier".
The real problem, as iterated near the start of the article, is that people still don't know what objects are or should be, and how and when to design them effectively. Classes are just one means to objects. 
&gt; Most people want to jump right into a new technology without reading the documentation or doing any actual work...which make sense...why waste your time if this is not the right solution for you? This is why they invented copywriters.
It shows the coverage in the gutter to the left of the code! This is much better than having a separate report.
Can't you make a Python 2.7 build for Wndows? The one here is kind of bad: http://www.lfd.uci.edu/~gohlke/pythonlibs/#pymvpa import mvpa2; mvpa2.test() T: MVPA_SEED=225501050 C:\Programs\Python27\lib\site-packages\scipy\integrate\quadpack.py:288: UserWarning: Extremely bad integrand behavior occurs at some points of the integration interval. warnings.warn(msg) C:\Programs\Python27\lib\site-packages\nose\util.py:14: DeprecationWarning: The compiler package is deprecated and removed in Python 3.x. from compiler.consts import CO_GENERATOR can't invoke "event" command: application has been destroyed while executing "event generate $w &lt;&lt;ThemeChanged&gt;&gt;" (procedure "ttk::ThemeChanged" line 6)====================================================================== invoked from within "ttk::ThemeChanged" ERROR: test_debug (mvpa2.tests.test_verbosity.VerboseOutputTest) ---------------------------------------------------------------------- Traceback (most recent call last): File "C:\Programs\Python27\lib\site-packages\mvpa2\tests\test_verbosity.py", line 145, in test_debug debug('SLC', self.msg, lf=False) File "C:\Programs\Python27\lib\site-packages\mvpa2\base\verbosity.py", line 611, in __call__ msg_ = ' / '.join([str(x()) for x in self.__metrics]) File "C:\Programs\Python27\lib\site-packages\mvpa2\base\verbosity.py", line 411, in get_vmem_from_status if rss[-3:] == vms[-3:]: TypeError: 'NoneType' object is not subscriptable ====================================================================== ERROR: test_simple_storage (mvpa2.tests.test_hamster.HamsterHelperTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "C:\Programs\Python27\lib\site-packages\mvpa2\testing\tools.py", line 131, in newfunc func(*(arg + (filename,)), **kw) File "C:\Programs\Python27\lib\site-packages\mvpa2\testing\tools.py", line 179, in newfunc return func(*arg, **kwargs) File "C:\Programs\Python27\lib\site-packages\mvpa2\tests\test_hamster.py", line 99, in test_simple_storage os.remove(filename_gz) WindowsError: [Error 32] The process cannot access the file because it is being used by another process: 'c:\\users\\ivanp\\appdata\\local\\temp\\tempfile_mvpa2.tests.test_hamster.test_simple_storagelnp0vw.gz' ====================================================================== ERROR: mvpa2.tests.test_dataset_formats.test_format_lightsvm_basic ---------------------------------------------------------------------- Traceback (most recent call last): File "C:\Programs\Python27\lib\site-packages\nose\case.py", line 197, in runTest self.test(*self.arg) File "C:\Programs\Python27\lib\site-packages\mvpa2\tests\test_dataset_formats.py", line 27, in test_format_lightsvm_basic f_ = open(f.name, 'r') IOError: [Errno 13] Permission denied: 'c:\\users\\ivanp\\appdata\\local\\temp\\tmpel1cwx' ====================================================================== FAIL: Very basic testing -- just to see if it doesn't crash ---------------------------------------------------------------------- Traceback (most recent call last): File "C:\Programs\Python27\lib\site-packages\nose\case.py", line 197, in runTest self.test(*self.arg) File "C:\Programs\Python27\lib\site-packages\mvpa2\testing\tools.py", line 131, in newfunc func(*(arg + (filename,)), **kw) File "C:\Programs\Python27\lib\site-packages\mvpa2\tests\test_base.py", line 23, in test_wtf ok_(len(sinfo) &gt; len(sinfo_excludes)) File "C:\Programs\Python27\lib\site-packages\nose\tools.py", line 25, in ok_ assert expr, msg AssertionError ====================================================================== FAIL: Test AUC computation ---------------------------------------------------------------------- Traceback (most recent call last): File "C:\Programs\Python27\lib\site-packages\mvpa2\tests\test_transerror.py", line 315, in test_auc 'AUC=%.2g among %s' % (mauc, stats['AUC'])) AssertionError: Single scenario lead to failures of unittest test_auc: on clf=&lt;kNN(k=5)&gt; : All AUCs must be above chance. Got minimal AUC=nan among [nan, nan] clf=&lt;kNN(k=5, voting='majority')&gt; : All AUCs must be above chance. Got minimal AUC=nan among [nan, nan] clf=&lt;kNN on SMLR(lm=1) non-0&gt; : All AUCs must be above chance. Got minimal AUC=nan among [nan, nan] clf=&lt;kNN on 5%(ANOVA)&gt; : All AUCs must be above chance. Got minimal AUC=nan among [nan, nan] clf=&lt;kNN on 50(ANOVA)&gt; : All AUCs must be above chance. Got minimal AUC=nan among [nan, nan] ====================================================================== FAIL: mvpa2.tests.test_misc.test_ttest_1samp_masked ---------------------------------------------------------------------- Traceback (most recent call last): File "C:\Programs\Python27\lib\site-packages\nose\case.py", line 197, in runTest self.test(*self.arg) File "C:\Programs\Python27\lib\site-packages\mvpa2\testing\tools.py", line 179, in newfunc return func(*arg, **kwargs) File "C:\Programs\Python27\lib\site-packages\mvpa2\tests\test_misc.py", line 170, in test_ttest_1samp_masked _assert_array_equal(ttest_1samp (d_[m_], t0), (t_, p_)) File "C:\Programs\Python27\lib\site-packages\numpy\testing\utils.py", line 800, in assert_array_almost_equal header=('Arrays are not almost equal to %d decimals' % decimal)) File "C:\Programs\Python27\lib\site-packages\numpy\testing\utils.py", line 605, in assert_array_compare chk_same_position(x_id, y_id, hasval='nan') File "C:\Programs\Python27\lib\site-packages\numpy\testing\utils.py", line 588, in chk_same_position raise AssertionError(msg) AssertionError: Arrays are not almost equal to 6 decimals x and y nan location mismatch: x: array([-inf, nan]) y: array([ nan, nan]) ---------------------------------------------------------------------- Ran 330 tests in 107.724s FAILED (SKIP=22, errors=3, failures=3) 
I had the same initial feeling. But sticking with it I realized that in trade for some slowness you gain A LOT of productivity and you make much fewer silly errors that remove entire debug/edit cycles. It even spell checks your code!
I could maybe agree until the author gets to the **The controller antipattern** section and the *LoginController* class. My problem here is, *LoginController* is just ridiculously simple. It would be soooo nice if the web applications I work on had all the controllers that simple, but they don't; they have lots of code and lots of state (and that's after the business logic has been separated out into models and the presentation logic into views). Once we have many such controllers, then the few simple ones are best implemented the same way for consistency. And calling the controller methods *state* is technically correct - they are attributes of the controller class - but misleading. By my understanding, *state* is something that changes, and the controller methods don't! Similarly the flask and pyramid examples that follow are so trivial as to be meaningless. I can agree with the general premise: don't use classes if you don't have to. But this isn't a good argument for that premise.
I'm using solarized (http://ethanschoonover.com/solarized) colorscheme with dark background (https://github.com/onjin/vim-startup).
A few things: * You should use a contextmanager with open: with open(filename) as fp: code = fp.read() this will automaticly close the file, even in the case of exceptions. * Use tuple unpacking: Instead of your 'temp1'-code temp1 = optimizeCode(userCode) fullyParsed = temp1[0] loops = temp1[1] write something like parsed, loops = optimize_code(code) * use list comprehension: cleaned = [c for c in code if c in "[]&lt;&gt;+-."] * avoid repetition. you can compress the code in optimizeCode like this... i cant get reddit to format my code like i want to. have a look at http://pastebin.com/NM2Usr2g
&gt;Python can scale to solve complex problems, as illustrated by the fact that it powers most of YouTube and DropBox, not to mention Reddit, Quora, Disqus and FriendFeed. And reddit is fast as hell.
I can agree on points but on the unittest you're barking at the wrong tree. First you used the assert statement: that's not the way the unittest is designed. Unittest provides all the sort of self.assertXXXX goodies to test the condition and display "useful" errors if they don't pass (like 1char difference between large text): all by default, no magic. Please (re-)read the documentation for it first. Second you use a "stupid" example of very short test (1 line). On larger tests the "class" approach add *exactly* 1 line "bloating". The reward is I can derive from that test and re-applying to different cases easily (like testing an api versus different implementations). I can add setup/tearDown methods on them without magic tricks and preserving the state. It's funny you're complaining about "stupid" classes and you take on the only clear cut case where they are useful: pity because the rest is an interesting reading. thanks 
i'm the author of webobtoolkit. i wrote it because I needed more flexibility than what webtest was offering at the time in terms of custom asserts and such. and we also needed a decent http client that worked with appengine. As an http client you are probably better off with requests unless you are already familiar with webob request/response, as a webtest replacement, I know they are doing more work on webtest so improvements are coming. But if you do end up using webobtoolkit, feel free to file issues if you have any on github, i've been looking for an excuse to get back in there improve some things. And again the blueprints explanation is much appreciated.
What is the point of daemonizing code now systemd exists? In fact, pretty much all of this functionality is just poorly replicating systemd. I mean, this is a daemon: #!/usr/bin/env python from time import sleep while True: print('Herp derp I'm a daemon!') sleep(5) Which you then create a unit for (either in systemd/user or systemd/system) and can start: [Unit] Description=My Daemon [Service] ExecStart=/usr/bin/mydaemon Re-implementing logging, forking, etc, is *fucking pointless* now. If you need output stuff and config, take a look at [clint](https://github.com/kennethreitz-archive/clint) 
This is not in any way new. In Python 2 you just need to import a replacement version of `open()`, and you can do the same thing: from codecs import open f = open('filename', encoding='utf-8') 
&gt; It would be soooo nice if the web applications I work on had all the controllers that simple, but they don't; I hear ya. I think a lot of these "dont do this do that" arguments that make for interesting reading fall a part when you bring ACTUAL requirements into the mix. But the right answers are not in a short digestible form that anyone would consume. 
Keep up the excellent work Mariuz!
SImple word of advice - stop using `#!/usr/bin/env python`. Either say that you're using `python2` or `python3`, don't make it ambiguous.
&gt; Unittest provides all the sort of self.assertXXXX yes, but no need for them to be instance methods, they're stateless. 
The method itself doesn't hold much of a state but it calls a _formatMessage to display useful reportiing message: the class allows you to define/override the beaviour of the self.assertEquals depending on the data being compared on a per class or instance. You can get the same effects with module level globals ... have fun with that and that would be just the begin. Beside making a point against a design adopted as *standard* by many languages giving as the only reason the dislike of that *1 line overhead* is not correct in my opinion. 
Backwards compatibility with old versions of python (just an out-of-my-ass guess)?
great answer. I guess Zed would put it this way: A. Seriously, shut the fuck up.
That doesn't fly. Put it in a virtualenv where you provide it with the appropriate python.
Using a solver on interpolated data is weird because the interpolator is almost certainly internally creating a function that can be solved analytically. Interpolation also can create strange artifacts to satisfy its constraints if you aren't careful. This isn't really a python question though. You should probably look for an R package that does the right thing and then recreate the behavior in python.
I use virtualenv.
`systemd --user` And at the very worst, supervisord.
Thanks for taking the time to go through my code. I'll try some of those suggestions out. As I said I'm pretty new to python so it's good to hear about all these best practices. 
Because fuck portability right? I mean this project really should be Python Little *Linux* Server Toolkit.
reddit is fast because it can afford a fuckload of crazy powerful load-balanced web servers, and because they have figured out a way to do large-volume databases efficiently. The python part has never been the bottleneck - after all, the processing it needs to do is trivial and most of it can be cached. As with any large-volume website, the most challenging problem is to efficiently store and retrieve data, because that is the one part where "parallelize it more" stops being a simple solution pretty quickly. The fact that reddit is fast says something about the way its engineers set up the server infrastructure, about the way they structure their databases, and about how their code avoids unnecessary I/O. Whether that code is written in Python or C or Brainfuck doesn't make much of a difference performance-wise, but Python is a much saner thing to work with than the usual alternatives.
I once heard that Reddit only has two tables, but I think that's not quite correct. Also: Would the data reddit stores be a candidate for NoSql which scales better?
Might be a dumb question, but why all the hate with supervisord ?
we’re fucking portability anyway. does this work on windows? mac? no, only on unixes that use sysvinit? then how is it oh-so portable? don’t get be wrong, this is nice and useful as an optional component, that can be used when wrapping your code into a dæmon… but /u/haywire has a point that providing a systemd unit file is more relevant nowadays. (and easier to create besides): better ship both to make everyone happy.
what are you talking about? #!/usr/bin/env python3 works just fine in a virtualenv. and that’s what ivosaurus means: specifying the version, not hardcoding the path. related: `#!/usr/bin/env python` *has* an usecase: bilingual code that works in both python 2 &amp; 3. nothing else should use python without version, though.
/u/ivosaurus talks about using `#!/usr/bin/env python3` instead of `#!/usr/bin/env python`. not about using`#!/usr/bin/python3`. so virtualenv has nothing to do with his/her argument.
How do you use VirtualEnv with daemons? It modifies your global environment variables so all of your daemons will be running the versions specified by the last one launched. Or do I have a fundamental misunderstanding of how VirtualEnv works? From what I read it prepends your system ENV with new entries that point to the virtual environment so those get accessed before the "true" system wide settings and therefore override them. How would VirtualEnv work with daemons then?
Windows is not Unix, but it clearly has support for mac. So yes, portable for Unix platforms. 
mac has sysvinit?
Flask can do [non-decorator routing](https://github.com/mitsuhiko/flask/blob/master/flask/app.py#L895). I used to use Pyramid and I liked it a lot, but at some points it became unwieldy. Flask has felt a lot more lightweight and less constrained, but Pyramid is still leaps and bounds over Django.
sure, but you might want to distribute your stuff some day, so it’s a good habit to do everything properly in the first place. and `/usr/bin/env python3` will also return the python3 in your virtualenv, so better use that.
I'm a huge fan of upstart.
This is a cool project. I only wish it was available for VS Express Editions
Yeah I just don't know how it works. My main computer runs Arch so I already had to learn systemd. My laptop runs ubnubnub, but I haven't dug into upstart. 
So if I write a program that works with python2 and python3, I want you to build a virtualenv that will bundle the python that you will use with it and not make me guess what you want.
What does daemonizing UNIX processes have to do with the init system? It is portable, as in it works on any -nix platform and doesn't rely on *external* dependencies.
This project has the greatest FAQ of all time. I'd buy this dev a beer in a heartbeat for their FAQ alone.
That does make sense, though my original code was just an example.
You can essentially get this by installing the Visual Studio Integrated Shell then installing Python Tools for Visual Studio. More details here: http://pytools.codeplex.com/wikipage?title=Installation%20-%20details&amp;referringTitle=Home
Hmm, then maybe it's because the dev's IDE puts `list` in a pretty color? Or maybe it's to mess with us? Woah, dude...
Its very well documented. Google the upstart cookbook.
What do you mean by global? What do you mean by daemons? I mean have a startup that does this: /path/to/venv/bin/python service_script or /path/to/venv/bin/service_script or you can use the activate, etc. tools to do this. But the overall issue is that if you want a particular environment, build the virtualenv for that environment, and deploy using that.
What does VirtualEnv do when you activate it? My understanding is that it adds overrides to your global Environment variables to point at the applicable virtual environment as opposed to the system defaults. When you disable it the VirtualEnv then removes those overrides. This is why you can only run a single virtual environment at a time. If I'm wrong please correct me, this is a question not a lesson. But this is how I understand VirtualEnv to work. If you have a link I would appreciate looking deeper into how this all works.
&gt;upgrading to Python 2.7 is trivial as most elements of Python 2.5 are forwards-compatible with Python 2.7 If I'm not mistaken, *all* Python 2.5 code should run fine on 2.7, no? Are there any exceptions?
No, all code won't run. I had run into an issue a while back, but I cannot recall what needed to be changed; it was a very trivial module and couple function name change.
&gt;Yes, yes, you can pass function pointers around in C++, but it’s so awkward that it might as well be black magic. Not any more. C++11 brings in all kinds of functional goodness such as anonymous functions and closures. Unfortunately people are still writing C++ as if it were Java. The author would do well to learn more about the language he so frequently disparages in his article.
Ah, interesting.
well, the obvious thing is newly introduced keywords: if you have a variable called with in python 2.5, it will not work in 2.7.
No coercion. We're incentivizing openness at the workflow level. Part of that is offering tools that support an open workflow and, when used, offer certain benefits. One doesn't have to make anything open to use the bulk of the tools we create or support (e.g., git), but we make it easy to go from private to public. And that's when the other benefits kick in. Hope to see you at PyCon. edit: level, support
The one I ran into a couple times was `as`, but yeah it was pretty easy to change `[a for a in as]` to `[x for x in xs]`.
Maybe I'm an old fart, but what's wrong with an init.d script?
What are the right reasons?
Wow this is an awesome service!
actually I didn't know that, since I figured that Environment variables were being modified I never attempted to run them in different sessions. Thanks for the link though, I will read it through. Edit: Actually, this is just reaffirming my understanding. From the article: &gt;So the activate script does three primary things: &gt;1. Sets a VIRTUAL_ENV bash environmental variable containing the virtual environment directory &gt;2. Prepends that directory to your PATH &gt;3. Sets the new PATH. The VirtualEnv is modifying the system path by prepending it's own environment variables. Also &gt;Starting with a call to deactivate ensures that any existing virtual environment is deactivated before a new one is created. Virtual environments are separate from each other; they can't be nested. Explicitly states that only one virtual environment is running at a time. I still don't see how you can run multiple environments at the same time. This article is just a better worded version of what I was saying earlier. edit 2: &gt;One other detail of source will be important. source runs the file provided in your current shell, not in a subshell. Thus it keeps the variables it creates or modifies around after the file is done executing. Since (almost) all that virtualenv does is modify environmental variables, this matters. that's even earlier in the article, explicitly stating that it runs in the shell, and not within it's own subshell. If you launch all your daemons from at the same time from the same shell each one is overriding the settings the previous one made. In the end only the last one will be active. I do see now that it is only on a shell-by-shell basis, so if I open up two terminal windows VirtualEnv is only modifying the PATH for the shell that it's running in, and not for the other one. So maybe this is a failure in my understanding of how daemons are launched and not so much with my understanding of VirtualEnv. Time to see how far this rabbit hole goes.
This is not Elixir. It's more like FormAlchemy and formalchemy_pyramid but greatly simplified and with Jinja
*passive-agressive comment about how I'll maybe look at appengine when they finally support Python 3*
It really helps me. Thanks!
This is not the proper place to report packaging bugs.
I think you could also still raise string exceptions on Python 2.5, while they're forbidden from Python 2.6.
The gallery gives the impression that it's all about games &amp; multimedia apps. Can you make regular apps, like things that run in the background, recieve notifications etc?
I've also seen some people have trouble installing PIL in a virtualenv on Windows.
I had a few minor things that broke. I don't remember details, but it was mostly cases where I was unknowingly doing something slightly wrong in usage of stdlib modules (e.g., missing an extra arg I should have been passing to some function) that happened to work out on 2.5. EDIT: Here's a real example of something that doesn't work anymore that I had to sort out: $ python2.5 -c'import locale;print locale.format("%s%.*f", ("$", 2, 3), True)' $3.00 $ python2.7 -c'import locale;print locale.format("%s%.*f", ("$", 2, 3), True)' Traceback (most recent call last): File "&lt;string&gt;", line 1, in &lt;module&gt; File "/home/bobby/affine/env/lib/python2.7/locale.py", line 189, in format "format specifier, %s not valid") % repr(percent)) ValueError: format() must be given exactly one %char format specifier, '%s%.*f' not valid 
*Upvote in agreement*
It's mildly interesting that both GAE and Python 3 were released in the same year. ...and they're just now retiring 2.5.
I can understand that I did post the code in the wrong format, and Im sorry for that, I honestly DIDNT read the sidebar...and I have only recently picked up Python as well, I have more experience with Java. Thanks for the advice, Ill try to live up to the standards of Reddit
I have a question with the `LoginController()` example: What if the LoginController manages server-side session state, authorize the user object some privilleges, will this makes it a good pattern? The author didn't seem to provide a solution to this, Dealing with URl like `/account/(login|logout|register)` is pretty common in any web applications, and I don't think it's cool to write a view function like if url=='login': elif url=='logout': elif url='register': 
Thanks for the PM. I did not have time to test the code thoroughly. I really need to find a better sandbox for Python. 
I believe you can; I get the impression they wanted to show off their fancy graphics ability more than the technical details.
See the TraitsUI docs: http://docs.enthought.com/traitsui/traitsui_user_manual/factories_advanced_extra.html#tableeditor 
Oh, and to answer your question, there are examples in the traitsui source code. See https://github.com/enthought/traitsui/blob/master/examples/demo/Advanced/Table_editor_with_checkbox_column.py 
I disagree. The FAQ is completely useless, because I would've actually liked to hear an answer to some of those questions. Instead, I get a big "Fuck you", which doesn't encourage me to look at the project any further.
As I was trying to suggest, I often name collections the plural of whatever's in them. So if I have lists of red, green, blue, and alpha values, I may call them `rs`, `gs`, `bs`, and `as`. I think it's a pretty good system in general.... for r, g, b, a in zip(rs, gs, bs, as):
I think you misspelled [pandas](http://pandas.pydata.org/), but I could be missing the point, I'm pretty tired right now...
I love the friendly interface, and your examples are perfect. Great job.
Similar parsing, but pandas is extremely focused on its end goal of advanced computation and isn't really easy enough for people who aren't already thinking in statistics. I'd guess that this was more of a replacement for the builtin library [csv](http://docs.python.org/2/library/csv.html), similar in spirit to requests for urllib.
How does this compare to [tablib](http://docs.python-tablib.org/en/latest/)?
loved the examples :)
This is a Mac OS X only script since it relies on a Mac system library, but a library probably exists for Linux systems. I did see Unison, but requires root access to install which may not always be available
[Watchdog](https://github.com/gorakhargosh/watchdog) supports Windows, BSD and Linux in a single library.
but you just linked to a page with all those basics explained
Pure python code should be fine. But python extensions are very version dependent.
Don't compete on price. You're building "Enterprise Software". Emphasize your availability for support cmp to overseas developers. Can you work as the project manager and contract/in-house the development? Then do it. For developing your product, customers, and market, I highly recommend Steve Blank's "4 Steps to the Epiphany". Basically, set your price high enough that you can bring on folks with expertise in every aspect. Enterprise sales cycles are usually very long, touch intensive. This leads to higher prices. For learning about the domain, try spending a week with the company "so you can learn how they work." There are resources for customer development and/or user centered design (hints: look for post it notes, they indicate processes that require hacks. Ask people "if you could wave a magic wand to get this accomplished, what would it be? What's the biggest P.I.T.A. regularly faced?") For pricing, make sure to model it on your business value. Blank's book has a section on understanding customer value. PM me if you want and I can scan a few pages and email them to you. To reiterate: don't compete on price. Figure out how much value your software creates for the company, base your price on that. Plan on working as the PM/interviewer, hire other people to do your coding. Find domain experts and hire them for a consult (or ask the company). Prepare for a long (6-12 month) sales cycle.
Also check out his blog at www.steveblank.com
I don't know when they added it, but the page is now showing a mac version. 
Are... are you kidding? You can't be serious. Pandas has some of the best documentation available. &gt; Maybe it would be more appealing if it had a page with the basics explained Oh, you mean like a page called "[10 Minutes to Pandas](http://pandas.pydata.org/pandas-docs/dev/10min.html)"? &gt; docs organized like a reference, If you just want vapid man pages, you're welcome to peruse the [API reference](http://pandas.pydata.org/pandas-docs/dev/api.html). I've never heard of anyone complaining that a developer gave to many use-case examples of their code in their documentation. Really, if you want to learn pandas, you should buy the book.
Eh it's almost never a problem. In this case I'd just call it `alphas`. :)
it seems like you agree with the parent to me. So I'm confused as to exactly what you are trying to say. 
Can you link to the stable-release version of "10 Minutes to Pandas"?
You should call it 30 minutes to pandas. Really.
check out the intellisense improvements in 2.0: http://www.youtube.com/watch?v=eIr9be6yroY
jra101 is correct. VS Express doesnt accept plug-ins, which PTVS is one. you can create your own Python Express by installing the shell + PTVS.
well that's reasonable way to write a account blueprint, but have you considered that login and logout views may share many common parts like query the DB for user id and setup a session state, or even perhaps create/destroy a websocket as a server/browser messaging channel. Which IMHO is perfect to fit in a class's `__init__ `
For querying the DB and setting up a session state, I would generally have parts of those as pre-defined utility functions if I'm doing them a lot. `user = find_user(ID)`, etc. And I don't really think I'd put Websocket logic inside login handling... I've never worked on a huge web app before (just small and medium sized ones) so there could be some cases where using classes would save me some lines, but I haven't really encountered that yet.
it breaks elixir :(
0.8 has been in beta for a while, I would have expected elixir to support it.
How is that even possible?
Do we even need elixir anymore? I thought declarative extension superceeds elixir anyways.
That reminds me of an ancedote that David Hansson (creator or Ruby on Rails) had. A recruiter actually called him and asked how many years of Rails experience he had. He responded "All of them".
Very nice writeup. Although it's not escaping "a Python sandbox", it's using the Python literals to access objects and methods to which they shouldn't have access under normal conditions. It's also a great example of why eval() shouldn't ever be trusted.
While I of course agree that the idea of trying to make eval safe in python opens a can of worms, I've yet to encounter a circumvention of the simple method of rejecting strings containing "__" and evaling remaining strings as expressions (with restricted builtins) Also code objects are not necessary. One can use nested lambdas with default arguments instead of assignments.
Not true, there is one!
The example in the article is no sandbox. There are lots of Python sandboxes, though. Edit: at least one – PyPy
Isn't the string addition performed before whatever filter you put between the string and `eval`?
why? if the REPL sees &gt;&gt;&gt; '""._' + '_class_' + '_' it will eval that to the string `'"".__class__'`, and not eval that resulting string. if however, you want to construct a member name, and access a member using it, that will neither work: &gt;&gt;&gt; getattr('', '_' + '_class_' + '_') NameError: name 'getattr' is not defined &gt;&gt;&gt; ''.__dict__['_' + '_class_' + '_'] SecurityException: you can't use names containing '__' &gt;&gt;&gt; vars('')['_' + '_class_' + '_'] NameError: name 'vars' is not defined in order to access a member of an object, one needs either to access it directly or from the object's `__dict__` (which in turn can only be accessed via `vars()` or directly) Now if you can't use anything containing `__` and can't use `vars()` or `getattr()`, you can't use a string to access a member.
That works, but it hardly lets you do anything at all. Sandboxes are more interesting if they allow some actual computation. For instance, an interesting exercise is to write something that will use `eval` to implement a small calculator allowing only basic mathematical operations. I think that's doable using `ast`. What the article is talking about is more complex again - something where you can call functions, access attributes, and so on.
&gt; NoSql which scales better This is for a given value of "scales better". To the extant that non-relational DB constructs would be an advantage, I believe Reddit already uses them. Heavy use of key-value data in Postgres and Memcache are a "nosql" approach. I can't say whether different products would be better or not (and I'm sure someone smarter than me has already thought about it for longer than I could afford to).
The thing is, that at this scale, the core platform for the site gets less and less relevant. I have absolutely no doubt that all of these would run faster if they were written in C (or D or C++) and the teams had as much time as they wanted, but they certainly run fast-enough and the other benefits that Python brings outweigh the rest of the performance shortfall. For every site in that list, if you're looking and content on a page that came directly from some Python process, chances are something has gone wrong or it's a cache-miss. If processing is happening as background processes to feed caches, the performance difference between C, Java, Python, JavaScript, Ruby or whatever just get's less and less important. When processing has to be realtime all the time (in say, high-frequency trading applications), no one if going to use a "fast enough" platform. Now I'm just rambling, so I'm going to stop.
pypy does not count.
I read the blog post. Impressive demonstration of exposed Python internals. Fun-looking CTF. The Python documentation does not claim that eval (with a limited set of locals and builtins to optimize lookups) is a sandbox. http://docs.python.org/2/library/functions.html#eval is not a http://en.wikipedia.org/wiki/Sandbox_(computer_security) Chroot is not a sandbox.
Elixir seems pretty dead, last release was in 2009
I wonder if chroot was used on the server side. And, if it was, then would being able to access stuff via the interpreter that you shouldn't be much of a problem? Of course, this is coming from someone who only has a cursory knowledge of chroot and hasn't used it in a production environment with python.
wow, nice thinking! that’s only python 2, though :( [this](http://www.reddit.com/r/programming/comments/1a0pg0/crafting_code_objects_to_escape_a_python_sandbox/c8t7nb4) is the example (python3) code that has yet to be broken…
You could use cherrypy. (www.cherrypy.org) The nice thing in your situation is, that you already have all accessor methods written for tk, so you can simply call those functions from a exposed cherrypy method. e.g. you have a button in html, that calls up the server using javascript (jquery) &lt;a onclick="$.ajax({url='localhost:8080/clickbutton1'})&gt;button 1&lt;/a&gt; now you can use a cherrypy method and expose it (see the quickstart on the cherrypy site) @exposed def clickbutton1(self): call_old_tk_method_here() and you're basically done. Now your web guy can HTML-foo like he wants to. Mind you that this is kind of hackish, but it gets the job done :)
Looking for Post-It notes is great advice, but keep in mind that the post-its themselves shouldn't be replaced; They cannot be replaced, don't try. If you do your thing right, they become a little less...
If you handle the code as bytes, the same trick would work on Python 3. Handling it as `str`, as you do, dodges that one. I'm going to give it some thought, but that's a really neat approach; have some upvotes. For reference, what builtins are you denying? Obviously `eval`, `exec`, `globals` and `locals` are out, but what about things like `callable`, `isinstance` or `super`?
nah, `globals` and `locals` are ok, they only give the user the stuff passed to `eval` anyway. `eval` and `exec` are out like you said, `callable` and `isinstance` stay in. `super` goes overboard because it’s only used in class definitions, just like the builtin decorators. `vars` and `getattr` are out, because they can be used to access members via string, which we want to avoid (i could wrap them but meh). then i throw out `type` (because of its general hackability, and because one should use `isinstance` and `issubclass` anyway). furthermore i throw out `setattr` &amp; `delattr` (because they are useless without `getattr`), and interactive stuff like `input` and `help`. then of course `open` and `memoryview`. oh, and `__import__`, because i left `locals` in and one could access it via `locals()['_'+'_import_'+'_']` if i wouldn’t throw it out. thanks for the interest!
After PyPy this is the Python project I am most excited about. I hope one day this will become they default GUI toolkit instead of tkinter. 
That was actually a joke but a recruiter did contact him. Source: https://gist.github.com/dhh/1285068
Have you [tried here](http://python.org/community/jobs/)? There is also a list of [python job boards here](http://wiki.python.org/moin/PythonJobs).
Obviously a problem that's been solved many times over, but I had a similar inspiration while working and needing to find content on pages that matched certain criteria, and so I wrote [PyCrawl](http://hg.dimo414.com/hg/PyCrawl/) which lets you easily define a crawl based on a start page, a filter for which URLs to crawl, and an action to do on each page (such as print out the page title). Simple, overdone, but I find it invaluable for my day-to-day work.
&gt;it runs as a subprocess with syscall interception How does this doesn't count? That's what most sandboxes do. Chrome's for example. &gt;It is possible to compile a version of pypy-c that runs fully “virtualized”, i.e. where an external process controls all input/output. Such a pypy-c is a secure sandbox: it is safe to run any untrusted Python code with it. The Python code cannot see or modify any local file except via interaction with the external process. http://pypy.readthedocs.org/en/latest/sandbox.html
Why?
Doesn't count in the sense that it relies on the OS to do the sandboxing rather than the language runtime providing secure execution directly. It's a valid approach, but it's an admission that your language semantics don't accommodate secure execution.
Copy operations look straight forward: http://boto.s3.amazonaws.com/s3_tut.html folder management isn't POSIX like: http://stackoverflow.com/questions/1939743/amazon-s3-boto-how-to-create-folder
Wrong, PyPy's sandbox doesn't rely on the OS. Read the docs and you'll see why. Chrome's sandbox entirely relies on the OS, but PyPy doesn't. Their code generation framework is amazing. They compile the entire interpreter without any of the dangerous features and assume that there are no memory corruption bugs as all code is generated programmatically. All system calls/IO is proxied. Amazing stuff.
We use PySide at work and pretty much it looks like the library is dead. Site is down, no new releases in a while, afaik code submissions is next to none. Your best luck would probably be if for commercial purposes to go for PyQt4 since they have a company backing them.
That's crazy... I thought PySide was officially sponsored by Qt, and arguably the more modern binding?
So it sounds like you built a simple mirroring library? A horizon is the list of urls emitted by the current crawl to be walked in the next wave.
I think it was sponsored by Nokia. Who have very little incentive to invest into further development now that Digia has taken over.
One of the things I like is that I don't need an IDE to use it. It lets me make Android apps without Eclipse.
It was developed by OpenBosa (Brazil) for Nokia, but when Nokia made the switch to Windows Phone they retired the funds and left to the community, which was too weak at the moment to support it, almost everyone stays on PyQt. (which IMO is super nice unless you're interested in commercial software and don't want to pay a license)
You should be using [Scrapy](http://scrapy.org/) 
Awesome! Congratulations u/zzzeek. :)
Heh, got me again, no idea what a mirroring library is either :P It doesn't actually run in waves, it simply does a DFS of the link graph from each starting URL. I realize it's not optimal but it was easy to code. The [crawl behavior](http://hg.dimo414.com/hg/PyCrawl/file/3a1cb8ec9c78/crawling/crawler.py#l94) is implemented like so: def _crawl(self, url, depth): """Helper method for crawl(), doesn't write "Starting ..." and "Hit ..." messages to standard error.""" soup = self.checkUrl(url) if soup and depth &gt; 0: for link in soup.find_all('a'): if link.has_key('href'): rel_url = link['href'] if(rel_url and self.test(rel_url)): self._crawl(uparse.urljoin(url,rel_url), depth-1) Where checkUrl does: def checkUrl(self, url): """Checks a given URL. 1. Skip URL if already visited 2. Visit URL and render BeautifulSoup object 3. Apply response handler if set 4. Run crawler's action against the page 5. Pass soup object up to be inspected for URLs to crawl """ The link following behavior in `_crawl()` could absolutely be a lot more robust, notably it currently doesn't respect nofollow or robots.txt (again, for my internal use case those haven't mattered) but easy to add if someone wanted them. .....
I still would like PyCharm integration. :)
I'm not using any IDE, but people reported successful usage of Kivy with Pycharm. Check https://groups.google.com/forum/?fromgroups=#!searchin/kivy-users/pycharm/kivy-users/xTpib2C8r_A/0TJHNIApSHEJ and https://groups.google.com/forum/?fromgroups=#!searchin/kivy-users/pycharm/kivy-users/avoM81uLK0I/Dd500kxxbr0J 
Wow, now that's a thing I never thought about! It would be such a huge step forward! But unfortunately PyQt and PySide are so advanced that there isn't much chance to get this project even close to their functionality, native look, dbus integration, ...
There is also a feature request open on the PyCharm bug tracker. I added my "yay" to it. Thanks for the links!
How big are the dependencies for each? That is probably a large consideration.
The project name conflicts with https://pypi.python.org/pypi/Flask-Bootstrap
That is true, I just thought of the software written from now on will probably want to run on mobile devices. So having a touch-centric GUI toolkit would be important. For desktop GUI, yeah, I would say PySide is now probably the best one.
This may be along the lines of what you are looking for: https://pypi.python.org/pypi/bakthat
Qt is as touch-centric as it gets, especially Qt 5.
You can fork it if you want, I'm open to any modifications anyone has to offer.
That's true, but renaming the project will break all the forks. I'm afraid it will stay with this name for that reason.
Nop, we have implementation for Window management, Input, Image loading, Text rendering and Audio player using Pygame. Pygame is _not_ mandatory, because we have alternative implementation for all of them. And we don't use Pygame or PyOpenGL for GL, we have our own gl library / bindings :) Even if there is no online document for all the differents implementation, you can have an idea here: https://github.com/kivy/kivy/blob/master/kivy/__init__.py#L188
Or [Beautiful Soup](http://www.crummy.com/software/BeautifulSoup/)? I seriously thought this was supposed to be one of python's "star libraries"... 
"ERROR The requested URL could not be retrieved" "Access denied" :( This seems to be a problem with the entire techblog for me. 
I think it's only you. Maybe google blocks you from blogger?
One of the problems with Python at large orgs is packaging and distribution. Do you guys run your own private PyPi or do you just checkout from source?
Are you working for Netflix now?
amazing. are things like video, audio, camera, and spelling optional? because in this case i can definitely see kivy included in the stdlib one day.
[This recent thread](https://groups.google.com/forum/?fromgroups=#!searchin/kivy-users/pycharm/kivy-users/xTpib2C8r_A/0TJHNIApSHEJ) in the Kivy Users Google Group says PyCharm works fine without any configuration.
They recent got some PSF funding to port to python 3 http://pyfound.blogspot.co.uk/2012/11/grants-to-assist-kivy-nltk-in-porting.html
I'm getting the same error, but it's possible to [view the article through Coral cache](http://techblog.netflix.com.nyud.net/2013/03/python-at-netflix.html).
All of the 6 forks? Really?
For almost two years! :)
There are a couple of ways to get packages. Since we bake full AMIs and typically use virtualenv, one way is to package up your entire env, which will included whatever version of the package you downloaded. It's all possible to specify packages for pip to install when the AMI is baked, which is a nice balance because you get the latest version, but since it is a baked AMI you don't have to worry about mismatches between running instances. Yet another way to get a package is to have the build team actually create an RPM with the package you want, and then include that RPM in your build spec. This is typically done when a library has a lot of C or other precompiled dependencies. Regardless of the method one chooses, the nice thing about baking AMIs is that you know that all your running instances are running the same code.
Hint: Check your proxy settings, or disable services such as mediahint. :)
To understand the answer, a brief history lesson is in order. When reddit was first ported from Lisp to Python, it is true that web.py was used. However, that version of web.py is barely related to the current version. It was basically incomplete, and a lot of stuff had to be written on top of it to make it work. So I wouldn't say reddit really every used web.py, at least not the way it is known today. As for Pylons, the main reason we chose it way back when was because Django templates were too slow and the community was unavailable to assist. Both of those things have changed dramatically since then. Also, the version of Pylons reddit uses is so heavily modified that it barely resembles the version of Pylons it is based on (.9 I think?) and can't be upgraded to the latest version because of all the changes. Now, to answer your question -- the first Python program I worked on at Netflix was CAG (see blog post). The program didn't need to be super high throughput, and at the time was mostly a proof of concept, so I wanted to get it out the door quickly. One of my coworkers had already started the work of making Python libraries to access the Netflix platform, and it was easy to use CherryPy to get something up and running quickly. As for the bottle decision, that one was done by one of my teammates, as he was familiar with it. Going forward, that will probably be how we do most API based services, since it is already integrated into the platform. However, for web apps with UIs, the typical choice is Django. 
Well, I wouldn't call it "Working." (Sorry, couldn't resist. One of jedberg's coworkers (and the coworker mentioned above who wrote the Python libraries to access the Python platform)
So what's the delta beside your name?
I'm not really clear why anyone ever switched to pyside. PyQt was always much more mature even at the peak of pyside....
as a current XBMC user, having Netflix on XBMC would probably turn me into a customer.
That's just a straight shooter with upper management written all over him. 
You're a professional programmer and you have unmatched parenthesis. How does that feel?
"chronos" is a very difficult word to Google, even in this specific environment. Is this what you're talking about? http://mojo.codehaus.org/chronos/
Wow, I didn't know this. I've always been impressed by Netflix -- and reddit -- congrats on your contributions to such great services!
haha me too. I was like "huh ? since when does Reddit/jedberg have anything to do with Netflix ?"
is there a thread about your leaving Reddit ?
Terrible. That's one of the costs of using an IDE (well, Sublime Text 2) to do all my Python coding. It's the same as using GPS and my rear view camera -- my ability to close parenthesis unprompted has atrophied.
Heh. The build team now tells you to do it yourself and ask them for help if you run into any problems :). Freedom and responsibility and all that Jazz. We have to pre-build packages that include any C components because instances normally (including the ones used for packaging, see Aminator) don't have a C compiler. The good news is that this process is really trivial.
Doesn't your editor highlight these things? I have mine set to *go-off-like-a-spunky-firework* over mis-matched parenthesis!
http://www.reddit.com/r/blog/comments/i29yk/all_good_things/
He's seen my code. Trust his assessment.
No, it's something we built ourselves and isn't open source yet.
We usually use it as a web server, but some folks have used it in WSGI mode with Flask.
Ah, on my phone so no hover as such.
See? In Vim, you can do this by just pressing [無](http://en.wikipedia.org/wiki/Mu_\(negative\)#.22Unasking.22_the_question). ^Don't ^worry, ^I ^use ^Vim ^every ^day.
it may pre-date 3.0. it is certainly not set up for being hosted as a WSGI application. the codebase contains no instances of "wsgi" (case-insensitive) outside of the included `cherrypy/` directory.
You get it wrong. Kivy doesn't require its own Python, not at all. We are shipping portable installation because some dependencies are hard to install for new users. Otherwise, you can still install Kivy in your own python installation, you just have to install all the deps too :)
Yes, if you don't use video/audio/camera/spelling, then it will be not loaded. But really, i doubt (and don't want) to be in stdlib, for tons of reasons. And even Guido told to the community _why_ it's preferable to get library outside Python stdlib (check guido talks in europython 2011 ^_^)
that's exactly what he's saying
Sorry, yes. Brainfart.
Very cool, and may your efforts be rewarded.
yeah, i just think that a good GUI library should be available inside the stdlib. and tkinter isn’t one :/
If pelican fits your needs I would probably go with it as it seems to be the most popular and frequently updated. Jinja is a templating language but it is pretty easy to use it to make static sites. Hyde is less updated than blogofile lately (unless there is another place to look on github other than hyde/hyde). Sadly there don't seem to be as many advanced generators as the ruby community (see nanoc and middleman). There's also a few smaller ones around if you look like cactus: https://github.com/koenbok/Cactus Nanoc has a decent list compiled: http://nanoc.ws/about/#similar-projects
It's fundamentally not safe. Don't even try, the approach is flawed.
sure. qt is not only a desktop GUI toolkit, but also a embedded and mobile one. standard stuff like two-finger-scroll work by default, and QTouchEvents are propagated like other input events.
this post is a challenge. go ahead and try to break out! i have no intention whatsoever using anything but pypy’s sandbox with user code, but i want someone to prove to me that this here can be broken. i’m trying too, but i couldn’t find a loophole yet.
&gt; this post is a challenge. go ahead and try to break out! The challenge is useless because you restrict the python language to the expression syntax (eval vs exec). This has been proven to be secure with wrapping and by only providing a limited set of functions. In fact, Jinja2 uses that as the basis of the sandbox. Though Jinja2 uses more reliable wrapping than rejecting strings with two underscores. //EDIT: in case someone would find a flaw in that particular example, you can trivially fix it by removing a function. But that does not translate to actual Python code that spans more than the expression syntax.
why do you say that the approach would be flawed then? and how is the two-underscore-idea less “reliable”? and for exec, you’d just have to ast-parse it and reject imports and stuff. interesting that jjinja does it, though! /edit: no, jinja [doesn’t](https://github.com/rdio/rdioquiz/blob/master/jinja2/sandbox.py#L113) do it more “reliable”, or even different, for that matter. it just adds python2 members like `func_code` to the equation, which all contain '__' in python3 afaik. also mro (which can’t be exploited for my set of builtins afaik).
As far as I know there has been no change in position regarding our linux client, or lack thereof. I believe the only way real linux support will ever happen is if the new DRM plugins for html5 standard that Netflix and Google are pushing for becomes a reality. 
Latest gevent seems to have fixed this - https://github.com/SiteSupport/gevent/issues/253
python expressions are turing complete. list comprehensions, lambdas with default arguments: it has everything! and as i said: i’ fully aware of the concept and don’t intend this not to be broken, but the exact opposite: please someone break it!
Well, they might be touring complete. Did not spend too much time contemplating about that. They are still restricted enough to the point where they are almost useless and definitely not hard to sandbox as shown.
That looks decent. I looked for a color list but cant find it, do you know if they list the values somewhere?
1. thought of DOSing, but that would need more sophisticated measures: timeouts, ip-bans, you name it. hard math is easy to create: 3456789876543234567899876543**345678987654323456789876543 this even blocks timeout solutions inside python (as the GIL is locked during the “atomic” computation). one would need to kill python processes after timeout in order to circumvent it. 2. oh, true. but not exploitable :) 3. wow, this indeed is unsuspected. damn you, `format` ;) but i suspect it can’t be abused, since one can only access the `str()` or `repr()` of forbidden things this way, not call, or use the result 4. not so much paranoia, but more simplicity. i could also parse the AST instead, and prune there, but that would be more than a 10-line-implementation (the main loop, which contains everything but the superficial code and the whitelist, is 12 lines) nice thinking with the format! and sorry for not mentioning DOS.
Is it "used" that way? Or does it just attach itself because his profile says it does? I have no idea.
Concerning #3, who do you expect will use "safe_eval"? Might they attach hidden information to globals, via "__" attributes, in the expectation that it will be safe? That is, how error-prone might this be in actual deployment?
look at the docstring: this is a challenge about trying to break out from the sandbox and obtaining dangerous functionality like importing or file access. i suggest using pypy’s sandbox if you want a real one.
Nikola seems like a good choice. Supports both markdown and unicode and it is actively developed. Also it is relatively easy to extend, if you need something extra. http://nikola.ralsina.com.ar/
Getting access to the password can be dangerous. ;) I do understand that you goal is to prevent code execution outside of the sandbox, and not just data access. I also wanted to make sure you didn't have larger plans for this code.
&gt; Since we bake full AMIs When are you going to be releasing Bakery?
You should come to our Open Source Open House on Wednesday. ;)
Would love to, but it's a heck of a commute from Michigan. Guess you'll have to mail me my Chaos Monkey t-shirt. :-)
Hi! Nikola author here :-) Indeed it's actively maintained, it's fully unicode ready, supports multilingual sites, python 2 and 3 compatible, has markdown support, etc.
&gt; teams seem to have free reign in developing in any language they choose. Does this ever cause problems? Sometimes, but our culture is about Freedom *and* Responsibility. While you have the freedom to choose your language, you have to be responsible for that choice, which means figuring out how to interact with all the other choices people have made. In general though it solves more problems than it causes since people can use the right tool for the job and do what they think is right. Since everyone here builds a restful interface with a published API, interacting with other services is just a matter of following the API. That's why it isn't as big a problem as you'd think. &gt; Why doesn't the company standardize? Would you want to work somewhere that dictated what tools you could use, even if you knew of a better tool, just because that is what everyone else uses? 
BTW, the pylons issues were that there were lots of deprecated things that were relied on so reddit couldn't upgrade past 0.9.6.2. I actually [fixed most of that relatively recently](https://github.com/reddit/reddit/compare/83f424c8d983ec3be12bddb99d2b41e0fd91d752...14f31880f3a044d3b688c36ecae1db3c99329925) and [upgraded to 0.9.7](https://github.com/reddit/reddit/commit/7a81779ad7d87edb87619dde66a3aa8da0f00e20) and it would be pretty smooth sailing to move to 0.10 from there.
It's kudos :-) but I agree!
Any idea how to get it in Sublime 2?
I think you mean `!=`. The difference is "round toward 0" vs "round toward negative infinity" ... I don't recall ever being struck by this so I did a quick test with some scripting languages that support integer division: $ echo $((-5/2)) -2 $ ruby -e 'print -5/2' -3 $ python -e 'print -5/2' --&gt; 3 -3 $ echo 'puts [expr -5/2]' | tclsh -3 $ ./div -5 2 # C program -2 ghci&gt; -5 `div` 2 -2 ... it doesn't look like Python's particularly on its own. Care to cite some more examples? :-) *EDIT*: I don't have Erlang installed but apparently [it has operators for both rounding modes](http://osdir.com/ml/erlang-questions-programming/2008-04/msg00488.html).
Yet, you support Android, Roku, and ChromeOS, which all use the Linux kernel, so this does not explain why there is only support for three closed Linux systems. Yes, ChromeOS has HTML5 with DRM support, but Netflix takes a different approach for Android. Why not tweak the Android code as a full-blown app that would run on most Linux desktops? Another way of looking at it: Hulu and Amazon Video runs fine on Linux... who do you think I watch more on my Linux Desktop compared to Netflix? ... With that said, I often fall asleep with Netflix running on my Mac Mini controlled by my Apple remote programmed with/by Mira.
pmav99, thank you for the suggestion. I was able to find my way to [this link](https://github.com/pshchelo/spyder-color-solarized) that has instructions and values for solarize. It looks decent, I'm going to give it a try and see how it goes. Still open for other options as well.
You can do it with ast. http://code.activestate.com/recipes/496746-restricted-safe-eval/ https://pypi.python.org/pypi/asteval/0.9
How could I run this? Python 3? $ python3 safe_eval.py Traceback (most recent call last): File "safe_eval.py", line 82, in &lt;module&gt; safe_builtins = {name: builtins.__dict__[name] for name in safe_name_set} File "safe_eval.py", line 82, in &lt;dictcomp&gt; safe_builtins = {name: builtins.__dict__[name] for name in safe_name_set} KeyError: 'callable' Give me a 2.6/2.7 version and I can hack you right away.
Relevant article explaining why it is this way in Python: http://python-history.blogspot.com/2010/08/why-pythons-integer-division-floors.html
I do have one question. As a driver of Python, how do you get the ball rolling at first? Let say someone is hypothetically in a shop with tons of Java and would like to move things to Python. What would the best ways to push it?
&gt; Why did you use your admin badge to endorse this post? It's a former admin badge, it doesn't indicate he speaks on the behalf of reddit in any way.
&gt;Both of those things have changed dramatically since then. I know this is a complex question to address, but I imagine the Django overhead would still be a lot higher than what Reddit has now using it's custom web.py implementation?
Yep :( Back to the Bay for now...
You mention that several parts of the Netflix toolchain are soon going to be open source. What does the process of open-sourcing something at Netflix look like?
You guys rely on linux *all* the time. I'm sure your company wouldn't be the same without it. Why can't you let your product run on the platform that runs your systems?
Looking forward to seeing you guys on Sunday! What talk are you the most excited for?
I wish I had time to stick around for the sprints! I think CherryPy is pretty nice, and it's great to see the devs recognizing that the documentation could use some work. 
Reddit was originally written in Lisp? That is awesome! The first programming class I had in college was taught using mit-scheme. Oh the nostalgia.
Awesome! Nice commit. :) I remember one of the harrier ones was making it so we could limit the size of post requests when we allowed people to upload images and css so they didn't ddos us.
It's actually really easy! You just ask the owner of the github account to give you permission to add a repo, then add your project as a new repo, run a script to update the homepage, and bam, you've opened sourced! You'll probably then write a tech blog post to announce it. Generally though folks will at least have someone take a look at what they are open sourcing and make sure it is kosher. But there is no rule that says you have to. The rule of thumb is, if it has to do with code, open source it, if it has to do with movies, don't.
you where right, I just changed the name.
There are multiple division operators, of which this is only one. I remember a paper that came up with all the combinations satisfying what division needs to be, since there is some freedom in: n/d = q + r
I stand corrected. I was a bit quick to post this. I didn't really mean "==" or "!=" but "how I want it to be", and I posted before I realized what that actually meant :) As for other programming languages, I didn't really do a survey, I just remember being annoyed at this in C/C++, C#, ocaml and assembly. It's interesting and cool that other languages do this as well. Thanks for the feedback! Edit: Looking at some other languages I've spent a fair amount of time on, both javascript and lua does floating point division for integers, so as a programmer you have to decide rounding for each case. Java does integer division like C.
Congrats guys!
I've only used bottle.py for simple things -- but I love it. You could set up a simple website in a couple of hours no problem.
Well its consistent with right bitshift by 1. -5/2 == -5&gt;&gt;1 
Please do pay attention to the 0.0.1 version number and the big "warning this is super pre alpha" warning if you actually intend to use this. :-) Right now it's something I've hacked together over the course of a Sunday afternoon. I'm pretty happy with it as a proof of concept, but it would be dangerous to treat it as anything more than that.
I Use Tomorrow Night on Sublime, Gedit and Vim. https://github.com/chriskempson/tomorrow-theme
Use a static blog generator like Pelican. If this is meant to be educational, try rolling your own. 
Here's a proven, battle-tested solution as used in Plone: https://pypi.python.org/pypi/RestrictedPython You can write almost any code with it, and give a fine-grained access to your real objects as well via proxies or some kind of ACL. 
I know that this isn't the point of your challenge, but I thought I would try to see if I could trigger a known bug in Python 3.3 - http://bugs.python.org/issue16856 . * Try to do evil stuff, I dare ya :) &gt;&gt;&gt; repr({[[f() for i in range(1000)] for f in [lambda x=[()]: x.append((x.pop(),)) or x]][0][0][0]: 1}) Segmentation fault You did say to try evil stuff. :) EDIT: for bonus points, this version doesn't touch the builtins &gt;&gt;&gt; "{0!r}".format({[[f() for i in "*"*1000] for f in [lambda x=[()]: x.append((x.pop(),)) or x]][0][0][0]:1}) Segmentation fault Of course, disabling 'lambda' makes this harder, but using the persistent globals() dictionary I could still do it. In which case, disabling 'lambda' and 'globals' makes building the deeply nested tuple even harder; perhaps impossible. Start locking things down enough and you end up with ast.literal_eval - which doesn't even support multiplication! I think your goal is to show that there is a safe eval-like function which is more powerful than literal_eval. That's a given; "literal_eval" plus hard-coded support for len() would still be safe. So, yes, you've developed one of the many safe-ish evals, where "safe" is defined as "can't execute code outside of the sandbox." But it's not safe against other attacks, and it depends on the user of the safe eval being very aware of all the limitations. (Like access to some 'internal' objects via format, denial of service attacks, and segfaults through implementation errors.) One mistake opens up the system, and we know that it's extremely hard for programmers to get to and maintain that level of awareness and care. Therefore, it's best to think of this approach as insecure by design. 
Netflix does run on the most popular Linux platform -- Android. I'm not sure about your statement though. Have you significantly contributed to the Linux kernel or infrastructure so that Netflix wouldn't be the same without your contributions? And do you feel that the open source license under which your changes were distributed was not sufficiently restrictive? I mean, just because you are running Linux as a desktop OS and a company is running Linux as a server OS doesn't mean there's some kind of bond that requires them to support you at a loss. You don't get free "reddit gold" because you run Linux or use Python either. Probably around half the net runs on Linux. I'm sure if it was safe (wrt DRM) and profitable, they'd do. You can see some indie games support Linux, e.g. FTL. 
It would be profitable. iTunes has already massively proved that as soon as you make a legal platform as easy or easier to use than piracy, it's trivial to make substantial sales off the media you're selling. Netflix already has an easy to use platform. If they implement it on linux, linux users that like to pay for their media will pay for it. In practically every humble bundle, it's also telling that linux users have been the highest paying.
I like cherry py but the documentation is _very_ lacking, like on how to actually use it if you don't want to use the built in server, and a lot of places the documentation just seems very slim.
While I have not been able to come up with such an attack, an 'exec' attack may be able to use the stack manipulation of a raise, try/except or with statement. These are not available to eval, and cannot be emulated with a lambda. 
Thanks for sharing, this was a very interesting read! CAG sounds extremely useful. I'm sure we would use it where I work if it were made open source. Are there plans to open source it? And if so, can you give an estimate of when this is likely to happen?
That was a pretty good increase in speed. Good slideshow. I'll have to take a look at the timeit package.
Tomorrow in combination with [Flux](http://stereopsis.com/flux/).
Add `"color_scheme": "Packages/Solarized Color Scheme/Solarized (light).tmTheme",` to your sublime text configuration (I'm unsure whether solarized already comes with ST2. If not, download the TextMate theme mentioned above).
I LOVE CherryPy! I use it all the time for small projects and for teaching people how to write web apps in Python. It is both simple to use and flexible enough to scale to some very sophisticated web applications. As long as you're not planning on having thousands of simultaneous users it is great! For reference, I wrote a MethodDispatcher for Tornado that makes it work just like CherryPy (for the most part): http://code.activestate.com/recipes/576958-method-based-url-dispatcher-for-the-tornado-web-se/ The key there is that you can port a CherryPy application to Tornado using the MethodDispatcher class in no time at all. So if you *do* end up having to support thousands of simultaneous users it won't be so painful--just switch to Tornado and use the MethodDispatcher class. You can convert most of your code with a few simple search/replace operations. Why not just use Tornado from the get-go? Because event-loop-based frameworks like Tornado can be complicated (asynchronous callbacks and whatnot). If you just want to stand up a useful web app in a very short time CherryPy is perfect.
Well sure, but I would expect that a senior dev shouldn't have less language knowledge than a junior/middle one. For one thing, having suche a senior would be harmfull to the project as it would be hard for him to establish any kind of authority required to actually lead anything. 
Take a look at pep8, or articles about idiomatic python. I recently applied to a python dev position and during tests I had to correct the code in which I had to turn some loops into list comperhensions, used enumerate() function etc.
Use package control, you'll thank me. http://wbond.net/sublime_packages/package_control
How should I know?? 
In python3 you just just use // to get the normal behaviour...
People in authority know less about technical details than the people under them all the time. A senior/junior is less that someone knows a specific framework or language expression and more about understanding the fundamental issues projects have and how to manage, design around, and deal with issues. A senior level guy has been around enough to pretty much see everything and know how things work. Any new job you go into is probably going to use a technology you're not familiar with. Getting up to speed with the new tech is really the smaller part of the job. At a senior level they're not going to be working with anything that conceptually you haven't seen before. 
I will! I actually have quite a nice grasp on language specific constructs, but it's always good to refresh. What about web technologies? E.g. what's the common used database tools, which web server if any is usually used. etc
&gt; all my knowledge lies in python2, should I spend time upgrading it to py3 or is the difference slight? Too much stuff doesn't support py3 right now for most folks to justify using it. For now just stick with python 2.7, and the 2to3 binary should convert most of your code for you when you're ready to make the leap.
3.1 afaik had no `callable` builtin: after guido saw that noone wants to import some abstract base class to test for callability, he either reintroduced it in 3.2 or 3.3: fix it by removing the `callable` line in the whitelist string. i chose python 3 only, because python2 1. python 2 allows for hackage like circumventing the test for `'__'` by prepending the string `'# -*- coding: unicode-escape-sequences -*-\n'` to whatever code you want, and then unicode-escaping all that. 2. python2 has many internal attributes like `func_code` not beginning with `'__'`, which makes the check for internal attributes harder than a mere `'__' in attr_name`
you obviously speak from experience: could you give me a possible exploit using that? say, we implement the check for internal attributes by walking the AST and rejecting access to attributes containing `'__'`, and the `import`/`from … import` statements. how can `exec` be exploited then, using a class declaration?
i found out that i didn’t block a generator’s `g_frame` attribute. that might be dangerous, too… (_ for _ in ()).g_frame.???
I would suggest [syte](https://github.com/rigoneri/syte). It is a great framework that supports lots of API integrations. Check out the site of the project author [rigoneri.com](http://rigoneri.com/). It was featured on [hackernews](https://news.ycombinator.com/item?id=4098430) a while back. The project has lots of flexibility and support. Local development is very easy and deployment is a breeze. I would be happy to help you get set up. 
&gt; how can exec be exploited then, using a class declaration Depends on the Python version you're invoking. On 3.x you can only create classes if there is a class build helper in the namespace (`__build_class__`) on Python 2.x that however does not matter. In the 3x. case you can inject custom metaclasses through a keyword parameter in the class base, in 2.x you can inject a metaclass through `locals()`. In both cases you can get access to the type object. Once you have a type object you can reconstruct attribute getters/setters trivially because you can do meta programming. I no longer need to write ``__`` anywhere to escape.
Yeah PyQT4's latest dev build is bound to QT5. It's only for Python 3 though ( which isn't too bad as it gives me an excuse to move to 3 ).
Licensing, QT5 has a LGPL that's carried forward into PySide. PyQT is a hybrid GPL/Commercial project.
One of the many things I love about CherryPy is that while it's very lightweight, it's pretty much production ready out of the box. Flask has far better documentation despite being a younger project, but Werkzeug from my understanding isn't really a production level server. Django of course has far more overhead in terms of actually learning the framework, with the benefit that it's really full featured and powerful. There were a lot of little things that bothered me with Django, and ultimately I felt like I wanted more control over certain aspects. CherryPy's documentation is an issue, but the community is very willing to help if you know where to look (the google group is more useful than IRC for the most part). For me personally, I've had the easiest time getting things up and running quickly with CherryPy, even with the documentation issues. There were some bumps along the way for figuring out how to do some relatively simple things, but once you get past that there really aren't any major weaknesses to using it.
I applied to python/django position and I got asked a lot about parts of django, for example: - whats the difference between templatetags and filters? - what are signals? - what would be the simplest way to add images to ModelA, ModelB, ModelC I was also asked about which databases I use for django development, whats my experience with other languages, what projects I've been doing recently and which version control systems do I use. I also got a homework to do after the interview and I did it and got the job :) 
Well they do know I have mostly PHP background, and didn't lie to them or anything. I just want to be in my best shape =)