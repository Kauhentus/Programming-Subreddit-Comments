The async nature is for a couple reasons. #1 - Sanic is an async framework. Therefore the endpoints are async by nature. #2 - There are several handlers for the developer to use to (for example) hit their DB to get user data. The package does not dictate how the user does that. If they are using something like aredis or aiopg, then there needs to be async support to allow the developer to use their code without adding too much complication.
Exactly. it is a hidden convenience method used to that for any of the end user/developer defined methods, they can be either `def my_custom` or `async def my_custom`. It is to make it simpler for the transition for the developer to merge this into their code.
thanks It helped me too
Woohoo!
The goal of this package is not to make things faster. That is for Sanic to do. The goal is to easily allow for developers to do what they need, add authentication, and not have to do any of the heavy lifting.
If it's not a bug then it's a missing (or unused) feature. I'm not as familiar with conda's own feature set, but given that these are pip installable packages, the upstream packages shouldn't declare PyQt (or PySide) as *requires*, but as *extra_requires*, and then downstream can decide to use *install_requires* to ensure that the they've got the GPL or LGPL GUI code of their choice. Really no package maintainer should ever include GPL code in *requires* without their own code being expressly GPL licensed, and that being their clear intent. If upstream packages are correctly using *extra_requires* and an automatic download is still being triggered then *something* has incorrectly set *PyQt* as an explicit or implicit requirement, and there's the bug. Again though an automatic download onto the end user machine *without use* is something that very likely should be fixed upstream, but most likely could pass muster as an unintentional at best infringement with no meaningful impact. It's the use that implicates the GPL. The one exception is when the incidental and unused download is then bundled into a distributed artifact (like a wheel or frozen exe), because now you're distributing the GPL'd code with your own.
Not sure if it's the kind of thing you're after but http://www.sympy.org/en/index.html may be interesting or you might want to hook up to an SMT solver with something like pysmt https://github.com/pysmt/pysmt
&gt; PyTest is really best used for unit tests. What kind of integration testing are you looking to do? We do a whole bunch of testing. Your right mentioning it's great for unit-testing (the build in support in stubs, fixtures etc), but we also use it for integration tests (between two services) and end to end (a whole bounce of services in a specific scenario). We didn't like Cucumber, and we couldn't find any other 'Spec' frameworks (like RSPec, Mocha/Jasmin/Jest etc).
Why send their business documents and reports to some external service?
&gt; 3\. Patching your dependencies blindly
Conda doesn't have such funtionality but it's a quite popular tool (you can set 'build', 'run', 'test' sets though). Thanks again for your answers! I guess removing PyQt from MIT/BSD modules would be the best way but I'm not sure how many time it would take and if it would be successful (I've already opened issues). &gt; Really no package maintainer should ever include GPL code in requires without their own code being expressly GPL licensed, and that being their clear intent. I guess that's all because of the Riverbank GPL exception. Without it there would be no rerived from GPL works that are not GPL themselves :) 
For anyone wondering: &gt; -O &gt; Remove assert statements and any code conditional on the value of __debug__. or using environment: &gt; PYTHONOPTIMIZE &gt; If this is set to a non-empty string it is equivalent to specifying the -O option. 
Without the actual code at hand I cannot see why it wouldn't work with pandoc, but I've seen code that exhibit similar kind of issues due to invocation written for command line invocation (e.g. double quotes around the filename) and the conversion to the safe `shell=False` invocation didn't properly convert the argument string into the list of arguments in a list of strings.
Thank you so much. This works
I'm just curious whether changing the name would effect the amount of hate :-) I have a suspision that the [previous title](https://www.reddit.com/r/Python/comments/8rpg23/pyappshare_cookbook_for_creating_crossplatform/) was misunderstood. 
That’s not what i was asking, my point was you can write this with a good ol’ fashion “def” and it will be just as good.
Wow, that is such a good and detailed requirements spec. Call us back when the customer starts with &gt; Uh, I'm selling car parts, and I'm not sure why I called you, but my brother said I should get an app to count the things I have in the shed. Do you have that, for less than the price of a buffing wheel? &gt; &gt; Oh, and it apparently has to fulfill ANSI 43xy67-2TRY32, because I did a job with NASA ten years ago. But I'm sure that's not a problem, it's just a 2,000 page long spec.
How can you install that to a virtual environment? `pip install` fails for me. It says "checking for GST... configure: WARNING: GStreamer 0.10 not available, falling back to 0.8". I have Ubuntu 18.04.
Still trying to figure out how it works. The documentation was not clear I tried adding the formats to the models, in the meta of forms.py outside the meta. nothing seems to be working 
It isn't fair to call it a security issue. It may present problems for those who distribute the software, because the users might configure the execution environment differently, but from a security perspective you are responsible for configuring your environment as needed for your application. If one of the requirements is to always run in debug mode then asserts are not a security issue. 
Me too. Never figured out why
Did your filepath contain wildcards or any other snippet interpreted by a shell? There's really no other reason why it shouldn't work to pass the arguments directly.
 It is very odd to have an article about python security practices without a discussion of what contexts you can even have a secure app. Outside of the client server context it is virtuality impossible to have a "secure application." The user who executes the code. If the end user directly executes the code, then they can read the code, so they could copy it and modify it to do whatever they wanted, so long as it is a thing they already had system privileges to do. The only way that could be different is if the executable is "setuid", and you cannot mark scripts of any kind setuid. That makes some of his points really weird... like timing attacks. He claims you don't need to worry about timing attacks over http (that's wrong, noise just makes it harder) and should use a library that adds noise to defeat timing attacks (what did I just say about noise?), but fails to describe a non-http client server architecture where it would matter.
Specifically created an absolute path, because I was anticipating that problem.
&gt; It adds a random element to the comparison so that timing cannot be repeated. Eek i hope not 1 + random is still more than 2 + random
Are there any advantages from using this instead of stlib socket?
I started building out our testing using pytest a few months ago, and had a bit of trouble with the documentation with respect to classes. I use test classes for testing classes, as it nicely encapsulates tests as classes do code. For example: class Thing: def __init__(self, name: str): self.name = name def do_something(self, value: int): if not isinstance(value, int): raise ValueError('Expected integer!') Can be tested using: class TestThing: @pytest.fixture(scope='class') def thing(self) -&gt; Thing: return Thing(name='name') def test_do_something_first(self): thing.do_something(value=1) def test_do_something_fail(self): with pytest.raises(ValueError) as excinfo: thing.do_something(value='Cheese') The use of fixtures with defined scopes are crucial--our classes tend to be pretty data-heavy so you don't want to create a new instance for every test. As I said, I'm really just getting started with this, but now that I'm using this structure I'm pretty happy with it. I'd love to hear from more experienced people with better ideas!
Even that bit of C has potential problems: `result |= *left++ ^ *right++` could be short circuited.
probably this: "If your Linux distribution has gstreamer 1.0 available then you can install the dev packages for that instead of the 0.10 version. For example: libgstreamer-plugins-base1.0-dev" from: https://github.com/wxWidgets/Phoenix/blob/master/README.rst
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [wxWidgets/Phoenix/.../**README.rst** (master → b77c88a)](https://github.com/wxWidgets/Phoenix/blob/b77c88a2800ca06b2f6b895798ca504ee2ca3f86/README.rst) ---- 
This is unrelated to Python
The point the parent is making, however, is there's no actual async going on.
Thank you for the advice I will repost on /r/LearnPython.
This post is better suited for r/learnpython 
[Blocktrade.com](https://Blocktrade.com) is recruiting. We have great company culture, team and ever evolving environment. We are located in Europe, Remote work is optional but we want our devs to be European so that we don't have problems with communication due to time-zone differences. You can read about all our open jobs here [https://blocktrade.com/careers/](https://blocktrade.com/careers/) For example: SENIOR DEVELOPER. We are looking for a driven and ambitious senior backend developer to help us build the first registered trading facility under the MiFID II regulatory framework, approved by the European Securities and Markets Authority, for trading with Crypto Assets, Crypto Traded Indices™ and blockchain related financial products. Once completed, the Blocktade.com exchange will be able to process more than 1 million trade requests per second outperforming the world’s biggest stock exchanges. ### What we offer A competitive compensation package, starting from 30k € to up to 90k € gross annually – the actual compensation offered to a successful candidate will be based on relative experience and skills. * Full-time employment or long-term contracting. * Stock options. * 22 days of paid planned leave. ### By joining us you will obtain: * experienced co-workers in fintech, * a seat at the table – you get to participate in the decision-making process * an opportunity to innovate and to develop state-of-the-art fintech technologies and * a chance to work on challenging and yet unsolved problems. ### In this position, you will be: * responsible for developing the Blocktrade.com platform, * integrating the platform with external service providers, * performing code reviews and * responsible for identifying bottlenecks and improving performance of all our systems. This is your excellent career opportunity to join a fast-growing startup in pole position. ### Requirements * Highly proficient in back-end Python coding, best practices and libraries * Experience with the architecture and deployment of complex systems * Positive, pro-active team player who is passionate about their craft * Desire for continuous improvement and learning * Passion for financial markets ### Nice to have * Knowledge of SQL and relational database technologies, specifically Postgres * Building web apps with Python web frameworks (Pyramid) * Experience building single page apps in Angular * Experience using message brokers in your projects (e.g. RabbitMQ) * Experience with Rust ### Additional perks * Flexible work hours * Remote work options * Paid tech conferences – attend (or speak at) the best tech conferences * Free breakfast at our offices and free coffee ### Culture * Keeping meetings at the minimum * Mentorship – you will be guided by the best in the industry to help you get started * Monthly 1 on 1’s with CTO and/or CEO * Quarterly OKR’s (Objectives and Key Results) – we make sure that your goals are aligned with the goals of the company (reaching all goals will result in a performance bonus) * Quarterly off-site team building * No open office spaces * Contributing to open source * 2h/week lightning (educational) &amp; developer happiness talks * Official Fridays – every Friday you come to office in your “Armani” suit (optional) ### About us Blocktrade.com is a high-performant, soon-to-be MiFID II regulated Crypto Assets Trading Facility. We are a fintech experienced team who believes tokenized securities are a logical next step in the evolution of global financial markets. There are many advantages of using tokenized securities for fundraising and trading. Superior speed and the simplicity of issuance, near-instant settlement, ease of transferring, fractional shares, etc. In the next decade Crypto Assets will overtake the financial world and Blocktrade.com will be the Trading Facility where these assets will trade. By building software architecture with supreme performance capabilities, we will be able to ensure that hundreds, maybe thousands of crypto assets will be traded at Blocktrade.com. You can be a part of the financial future. In order to achieve that goal, we are using the most recent advances in computer science. Continuous integration and deployment, dockerization, using OpenShift for DevOps, optimizing performance sensitive code by using faster programming languages, integrating faster and more reliable API protocols like FIX and FAST, etc., all being deployed in a high end dedicated server cluster located in Switzerland. Our offices are in Ljubljana, Slovenia. ### Application Send your CV, short motivational letter to [careers@blocktrade.com. ](mailto:careers@blocktrade.com) 
^ is not a logical operator; it does not short-circuit.
&gt;But it still feels like somewhat of an "overlooked" feature. Are you talking in the web space? Or overall? When it comes to building crud webapps it's pretty extensively used (or at least it feels that way from experience), not as much as Django or Flask; but they've had a decades head start.
Asyncio makes only sence if you have multiple processes, which are somewhat independent and are limited by io. Perfect example is a web crawler. But many problems are nothing like a web crawler. You should look at his much code is done in sync and how much in async. Many tutorials don't include async, because it is advanced. It is not something you explain a student at the begining together with what is a class. Besides i think your statement is not true. Even i played with async and i have no use case for it at all right now. You should ask people, who do lot of io, or threads, or... why don't they use async.
Hey, hr0m, just a quick heads-up: **begining** is actually spelled **beginning**. You can remember it by **double n before the -ing**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
Hey bot, tell Google to fix spelling in their Android keyboard. I swiped that 😀
[Here's the repo](https://github.com/JosephVallillo/ComicPy/commit/91f7151a54587c0aa6842030c1f547936363d77c) I finished it over the weekend, but forgot to push it, which I'll hopefully remember to do tonight.
`dir()` is just a [thin wrapper around `retrlines('LIST')`](https://github.com/python/cpython/blob/684bc3d67797f2b5ca9368fe7ecc1c3093d7b694/Lib/ftplib.py#L562). In fact, when called without arguments, they are identical.
The reason why it is an issue is because shell=True runs the process in the system shell, and therefore any of its syntax (like semicolons, or the ~ to signify the userpath) gets parsed before the actual executable is done. Basically without shell=True you're just primitively calling the executable with appropriate arguments via piping them. With shell=True you are calling the shell executable (ex cmd.exe) and telling it to run your named process and arguments as a command.
Because people use threads for general concurrency problems. Try writing your program above with threads and see what you get. The time spent is in a sleep() call which will release the GIL and let everyone finish their sleeping at the same time.
So firstly this is moreso 8 than 10 because two are extremely commonly yelled at you in the official python docs. Secondly &gt; Use secrets.compare_digest , introduced in Python 3.5 to compare passwords and other private values. ...or hmac.compare_digest from 2.(7 iirc), or your own function that bitwise xors each value).
I'm sure that you figured this out already, but it's not that they hate each other, it's that you're either running your code in a python 2 or a Python 3 interpreter, and whichever one it is, it's not going to understand the syntax from the other version.
I'd probably put both functions into one module, but factor any shared code into separate functions which could themselves go into a different module which the user wouldn't need to know about. You can use `__init__.py` to define what's convenient for the user to import. Instead of using the big if-else chain you could use a dictionary (potentially by defining each option as its own function, which would be the value of the dictionary, and addressing it like `methods[method](p, n)`). It's common in numpy to have use a string rather than an integer to choose a method for doing something. A pattern I like is to have something which is both compatible with typing in a string, and also is more self-documenting by using an `Enum`, or a subclass of it like this: from enum import Enum class StrEnum(Enum): def __str__(self): return self.value class PercentileMethod(StrEnum): EMPIRICAL = "empirical" AVERAGED_EMPIRICAL = "averaged_empirical" # and so on def choose_method(str_or_enum): str_method = str(str_or_enum) # do things with it In terms of structuring the project, I tend to follow Kenneth Reitz' suggestions: https://www.kennethreitz.org/essays/repository-structure-and-python
Unrelated but you can `mystring.lower() == 'reference' ` to do case-independent comparisons. 
C# has had aysnc/await syntax longer than python, curious if the same situation holds in C#. My reasons: Complete re-code - it is best to make the decision to use Async/await at the project start. All it takes is one blocking call... The development life cycle can quickly become non-trivial. API tightened rules and I had to add a semaphore. The project now had extra complexity with less benefit. Some people have been scarred by async JavaScript. When learning, I had to go down an abstraction layer to co-routines and eventually learned my task was best suited with a process pool. For a second project, [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html#module-concurrent.futures) served well.
Well, you mean that some people use threads. But the advantage of asyncio is that it is hugely scaleable. With threads you are limited to the number of threads you have. On the server side especially that is going to be a very serious limitation.
Just an FYI, there are no passwords in /etc/passwd. They are in /etc/shadow which only root can read. 
I'm talking about the `|=`. Can that no short circuit? Once "result" is True can it not skip the evaluation of `^` entirely? I'm not a C programmer so maybe this means something different in C than I expect.
Is there a module to mask the zeros in a sequence before computing mean over time on the output of the LSTM ?
ZeroMQ will automatically reestablish connections, and supports a variety of message routing strategies, such as push/pull streams, or pub/sub. It's most useful for distributed systems.
Pinning libraries is almost a mandatory thing for me because far too often library maintainers love to make backwards incompatible changes for minor version bumps (or sometimes no version bumps at all). There might be security holes in the library you're using, but blindly upgrading all the time isn't a solution for that (could be introducing new security holes, or a malicious maintainer could upload a bad version -- though that isn't fully stopped with pinned versions either). 
That's a cool idea, might use it for our uni-tests, thanks! :)
I am now really curious. Is it possible for you to post the raw command line `pandoc` invocation that trigger this problem?
Yeah, seriously. This was a good read, but the author clearly has never written or maintained a large application codebase.
Crash on errors and make it easier to stop and start logging to a file.
That's a bitwise operation, not logical. Also, the optimization happens during compile time, which can't know if result is True already.
added the command to my original post.
you can't make a statement like "that is going to be a very serious limitation" without knowing specifics. threads are quite ubiquitous in large scale server platforms. Python's issue is only the GIL which is not a big deal in an IO bound program. A threaded approach to concurrency is also not exclusive with the use of non-blocking IO, it's just "EVENTS" have plodded in such that nobody even knows how to do raw non-blocking IO anymore.
[Libraries for manipulating audio in Awesome Python](https://github.com/vinta/awesome-python#audio) might help.
Note that you also need to provide the command as an array of strings instead of a single string in that case. Regarding the other point in #1 (SQL injection), how can the article not even mention parameterized queries even though the Python DB API [specifies them by default](https://www.python.org/dev/peps/pep-0249/#id15)?
Interested to hear more. Is this a shift scheduling app?
Does it provide secured/encrypted traffic?
I've seen a few real cimilar to that, but that one looks nice. If I ever have to expand into other automation stuff I'll remember the name for sure,,,thanks.
This might help someone but it isn't written by a security expert. And hand written SQL is fine. The solution is not escaping user input, it's isolating it. You do that with parameterization. Use parameters in your SQL and use a list not a string for your subprocess call. Also don't use shell=True. Don't use some janky XML library because it's "secure" process the XML line by line with iterparse. 
go away bot
correct answer!
Missing a closing ) at the end?
Thanks, I will definately check out the libraries there ! 
Hey, myheadbands, just a quick heads-up: **definately** is actually spelled **definitely**. You can remember it by **-ite- not –ate-**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
Reading the second half of "Effective Python" Then maybe I will be ready to take on a project. 
Thanks, any advantages over rabbitMQ?
the above code is do about DDS( Direct digital synthesizer ) board (FSW01- Frequency setting word ) with computer to generate output frequency from 10MHZ to 200MHZ. 
Oh yeah, much of this list isn't "security" just bad code.
What do you think `print` is for? Logging has a separate purpose.
Some of these are covered by [bandit](https://github.com/PyCQA/bandit). I find it useful as part of a pre-commit hook.
Or use pytest and it's assert rewriting!
I'm sure this has been discussed to death on the mailing lists, but I'd make the naming schemes PEP8 compliant, leaving in the old names just aliasing to the 'proper' ones. Backport that to 3.4, stick in a deprecation warning with 3.9; deprecate them in python 4. That should give people about 30 years to move on. It's hard to justify to new python devs that they should follow standards when the core library doesn't. I'd also quite like loggers to not propagate or emit messages below their level. Sometimes I want to propagate warnings etc. (i.e. don't set `propagate = False`) but silence debug messages from all subloggers.
[pipenv](https://docs.pipenv.org/advanced/#detection-of-security-vulnerabilities) is pretty handy for this... let me introduce you to [safety](https://github.com/pyupio/safety) it's not a silver bullet, but it sure does help catch low hanging fruit.
Honestly, I'm so bored of these "top X" articles on the corporate blogs.
I never know of eli5. Looks very useful!
Yes, I charge $650 an hour 8 hour minimum. Payment in crypto-currency only.
Saved. 
RabbitMQ is a message broker, which means any messages sent are persistent, i.e. stored until removed. This preserves data even if there is a crash. ZeroMQ is fire-and-forget, so much lighter weight. You could say that RabbitMQ is to Django, as ZeroMQ is to Flask.
As far as I could gather, the objections were fear of censorship. Most of the people who replied didn't see the need, and thought that people were being too sensitive. Also, they think the reddit upvote/downvote system automatically polices things by nasty comments getting downvoted. Obviously, I disagree with that sentiment. However, it's up to the community to adopt standards. Obviously, r/python wants to remain loosely moderated. I have more thoughts on this, but it seems pretty unproductive to discuss them here.
Try the [`turtle`](https://docs.python.org/3/library/turtle.html) module.
Never once in my life have I looked at a problem where I wasn't forced into it by an already existing standard (I'm looking at you WSDL) and thought "this is the perfect place to use XML".
those last two look doubtful to me. true, if you're on a system where the system runtime is rotting around and so are your dependencies, that's a good idea - but such a setup is barely worth recommending anyway given that if it's not a python vulnerability that bites you, it's a kernel or web server or any-other-service-on-that-host vulnerability that'll get you. unless you have (or are) a security team that reads up on all candidate threats, i'd much rather recommend using a setup that has automated security updates for your system and lets the distribution handle those. the services recommended at 10. would still be useful if you have any dependencies that don't have security support in the distribution.
He's gotta be kidding, lol
Yes, this is a scheduling app specific to the healthcare industry. Prior to making this tool, sales would find whoever was available to set up their demo accounts and our support team also needed some additional test accounts. The idea was to automate the process with a randomized account saturation tool so they could both have fresh shift data and test/demo users.
Thank you for that. I have edited my original reply.
Commenting for later
[removed]
Specifically, a **sequence** of strings, i.e. a list or tuple of strings, first item being the path to the program (or simply the program name will do if it is in the `PATH`), and subsequent items are the arguments to the program. This is the main thing that trips programmers up, and [the documentation](https://docs.python.org/3/library/subprocess.html) doesn't clearly explain what or why with a direct comparison at the very beginning with a comparison (it could use the `ls -l` example with/without `shell=True` on a raw string).
Personally, I use `htop` which is basically `top` with better looking interface.
The thing is, I had it split into args before. It's the recommended approach, so I used that. And it exited correctly with 0. But it did not consider my template, instead it used the pandoc default template. The only way I got pandoc to use my custom template (without putting it into the default pandoc template dir) was to use shell=True. I ended up using the string instead of the argument-list because I found that to be more readable for me personally.
Thanks!
It's a project that supports eight languages of which python is one. I'm guessing python was just hacked out and is not the primary (or even secondary) language of the developer. So not knowing about pypi is not unreasonable. I don't do c# and would have no idea about common support sites for it.
But I need to draw a pixel on the browser window 
... you can also click Save
If you're using Python for any type of data science or analytics project, it would really be worth using **statsmodels** and **sklearn** to generate regressions. Python is very popular as a programming language, but is also great at statistics and machine learning. If you wanted to do a data-based project on a current issue, e.g. the World Cup, then Python would be great for this. Of course, I'm speaking from a data science background so your preferences may vary.
That could be fun, I don't know if I can organize everything well enough for that but if I get some energy and need a project that's going on the bucket list. Also if you have any questions, feel free to ping me on here. I don't know anything beyond the very basics but the learning curve is a little steep, having someone to talk to when stuck can speed up that *lightbulb* flicking on inside you, if you know what I mean. 
Wait: assert can be ignored by the interpreter? What?
No, check out the repository and you'll find out that he doesn't even have a setup.py. His library's root modules are at python2/ and python3/, which each have an __init__.py. How has this made it to the google organization?
The maintainer is clearly saying that they haven't heard of the website `https://pypi.org/project/diff-match-patch/` before, and someone else must have published it, and the maintainer doesn't have access. Not that they haven't heard of PyPI before. In fact, the person who uploaded the package to PyPI comments on the thread below, offering access to the maintainers&amp;mdash;thereby confirming that the maintainers don't currently have access to it.
I would expect that Google's internal build tools that work with Python don't require a `setup.py`.
Yeah - I mean that's completely understandable. I guess what surprised me is that this library does seem to be under active development, maintained by google, and yet the maintainer quickly writes off the original issue. When I opened the issue I pretty much knew that he didn't have access to the pypi repo - I'm just trying to prompt some co-operation here to get pypi package up to date.
Yeah - I pointed the pypi package's maintainer, Luke Plant, to this issue. I was trying to prompt some collaboration or professionalism, which I would expect from Google. I'm fine with trolling, curt responses, whatever. But if you're maintaining a widely-used software library for your employer - Google - you need to like, be nice to people.
why.
Have a look here: [http://practity.com/343-2/](http://practity.com/343-2/)
Try changing line 4 from 'import databases.database' to 'import .databases'.
This guy is a fucking retard https://neil.fraser.name/news/2018/04/17/
Wait...someone **working at Google** and who writes Python code professionally has never heard of PyPI?! Welp, maybe I have a good shot of passing a set of Google interviews, after all.
Thanks! Yea I was originally hoping that the Flask extensions would all work, but as you say the Python interface makes that very difficult. 
Well this extremely appreciated 
Why `pydot` over [`graphviz`](https://github.com/xflr6/graphviz) (the Python package, not to be confused with the original GraphViz C library written by AT&amp;T Labs)? The former has no documentation at all (save docstrings in the source code), and the latter has [decent documentation](https://graphviz.readthedocs.io/en/stable/) and also several examples. 
savvedd
Judge a book by its cover much? A lot of people might say bad things about you based on your Reddit username.
You can judge him by his response on this issue then
Google makes all of their own build tools, and it drives me nuts. Here's another example: Ever had to build an Android image? I have (still unsuccessfully). They overuse repos. There is a script called git-repo that fetches and updates the required repos using XML manifests that define their path and their location in the build directory. It assumes they all have a branch with the same name to check out. (What about git submodules, you ask? Good question. I'm not sure, but I guess this was before that feature was a thing and it never got replaced.) This ends up being 20GB+ of downloads. To try to speed it up, what they do is multithread the git calls. Yes, that's right, even the downloads. It's an absolute nightmare that kind of makes sense but barely works. To top it all off, I've been trying to get the build process working on Arch Linux which symlinks python to python3, because they're progressive and just want to be different, idk really. The issue with that is all of the python script shebangs for Android build tools are `#!/usr/bin/env python`, assuming it will be python 2.
I checked out your blog post, great work! Thank you.
Thank you.
lol. I actually thought his picture was funny, i even added it to my list of github avatars (https://github.com/nikolas/github-avatars), but yeah. People who make videos like this of their toddlers are depressing.
Why would anyone say anything bad about svn?
Awesome!
I'd throw [PrettyPrinted](https://www.youtube.com/channel/UC-QDfvrRIDB6F0bIO4I4HkQ) on that list, but otherwise solid.
Go and find one of those issues where some idiots come and try to push their CoC. If you look at the avatars it's all a freak circus 
I agree. I hate when developers are flippant or rude in bug report replies. Come on, kindness is free, treat each other like human beings.
read through the appengine sdk sometime it's quite entertaining in a facepalm kind of way
They're never going to be perfectly independent. An easy way is to construct the correlation matrix and check out if two features have a very high correlation. Dropping one of them may improve the fit.
Thanks mate! Much appreciated. 
I use a Macbook: * Docker for my build environments * Conda for environment and package control (Mostly) * Pycharm for project use. Vim/SublimeText3 for one off editing/re-testing I'm not gonna sell you on why a Macbook, as everyone has different taste. But my environment set up works for me, but YMMV
His avatar picture is freakin' awesome you nazi scum https://imgur.com/BSvzWsn
He looks like an evil genius. Cool!
There are so many channels. I'm now at first stages of python. Do know the basics, but struggling with more advanced stuff (classes, objects). Maybe someone could recommend which of these channels is good place to look at? Also I'm interested in Django, but as I do not have firm understanding of classes and objects, it's a bit difficult. Thanks in advance!
I added random.choices to my test run by defining the following: def using_choice(freq_table): # using builtin random choices population = list(range(len(freq_table))) cum_table = list(itertools.accumulate(freq_table)) return lambda : random.choices(population, cum_weights=cum_table, k=1)[0] # use x = using_choice([1, 5, 3]) # get population index: i = x() # 0 will have P(0) will be 1/9, p(1) will be 5/9 and p(2) will be 3/9
Did you try Linux? Worth getting macos Over.linux? 
Not sure if this questions really belongs here but ok.... I use a mix of macOS and linux. I prefer mac but am completely fine with both. A lot of my preference just comes from really liking BBedit. And the way mac treats different monitors as different desktops. In general, macOS will be easier to debug and has more support. But that comes at a monetary cost (and to a lesser extent, a moral cost of a semi-closed eco-system). My linux machines have really good sysadmins so I do not have to deal with it. My mac, while there is support, is mostly controlled by me.
What's wrong with that
People say one should do this, but it seems to me this is only a problem when accepting user input? Point being if I don't deal with user inputs then it's fine right?
Essentially OS X = Linux in a pretty coat of paint.
I see. So i can just buy windows hardware and put linux on it rather than getting expensive macbook just for MacOS right?
Well, since you're buying Windows hardware, why not run Linux in a VM with Virtualbox, even OS X can be run inside a VM, see which one you like best.
u/sentdex is what I would reccomend. This is his [website](https://pythonprogramming.net) and it had everything you just mentioned! He taught me all of the fundamentals of python, which really helped me my first semester as a cs student. Now i follow his more advanced stuff, which is equally as good. Best of luck! 
Thank you for this post
&gt; be nice to people. Like Linus Torvalds. Wait a minute...
Saved.... Never to read or look at again
Debian (Mate), PyCharm, Docker. For small projects or single files -sublime.
sorry. i dropped a `/s`.
You need to know handle of browser wnd. And after that draw try through from system api. But... if you are realy need it.. something went wrong...
Hey, everhideme, just a quick heads-up: **realy** is actually spelled **really**. You can remember it by **two ls**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
sentdex is amazing. He's got series on *everything*. Often you have to know what he's talking about though because things gets harder and more complex in his videos pretty fast.
99% of my "productive/educational" bookmarks...
Thanks, I'm learn English :)
Delete
they probably don't use PyPI much/at all internally. Based on what I've heard, they mostly maintain and build their own tools. They also don't use PEP8 but their own Python coding style, incl 2-space indentation etc. So, I guess it would be the most likely company where you might have people not knowing about it -- although, I think that it is more likely that the response was referring to **.../diff-match-patch/** in https://pypi.org/project/diff-match-patch/ 
LOL It does happen 
&gt; This ends up being 20GB+ of downloads. To try to speed it up, what they do is multithread the git calls. Yes, that's right, even the downloads. It's an absolute nightmare that kind of makes sense but barely works. They don't use git internally but their own version control (probably still Piper). So, I guess they don't have much real-world experience with git and/or map it to their internal workflow 
thenewboston doesn't make new videos and I'm pretty sure his site doesn't work anymore
Leave this thread, jairo. We only call out annoying Google employees here, not respected internet trolls.
OS X inside VM is nightmare. Unless you have top-tier hardware it's a waste of time. To be honest, the only reason to get a mac would be If I wanted to be an iOS developer.
For me, my build environments compile to Debian via Docker, so the host OS is just personal preference. I like MacOS because I'm used to it, and can navigate easily within it.
Linux with [sway](http://swaywm.org/), which is a bit experiemental so I'm not sure I'd recommend it in general. For someone who's not sure what they wan't I'd say trying Gnome for a' just works, even with high dpi screens' type experience. (A lot of distros default to it for a DE as well.) I'm on an XPS 13 - all of them generally do well with out-of-the-box Linux support and I'm pretty satisfied with it after using the same one for 3 years.
I don't know if any other specific resources that might help, off hand, but I have used upwork in a pinch. The key to getting jobs on upwork, in my experience, is persistence and making sure your cover letter stands out (make sure you read the description thoroughly, offer a rough solution in your message, try to value add wherever possible). It can take a long time to get an offer on upwork, but after you get that first job, and provided it goes well, it's much easier to get additional work. That said, Upwork very quickly becomes a race to the bottom, and there are a lot of people who expect the world for bottom-dollar. There are plenty of great clients too, just be wary of jobs that aren't clearly defined, and don't expect to get rich. 
What... Googles python style looks pretty reasonable to me and not too deviated from PEP8. https://github.com/google/styleguide/blob/gh-pages/pyguide.md
Great job. If I wanted to connect it with db, which lib/driver to you recommend?
Yeah, looks like some misinformation up there. Most importantly, they do in fact use 4-space indents, not 2, lol. Fucking trendy ES6 devs making the 2-space indent shit popular.
Location: Anywhere at all Job(s): I need someone to create two simple programs for me. I need the code itself to send to someone else who is going to mess with it afterwards. The firs program is a simple tool to convert dragged files to a different file type. The second is something that will display thumbnails for dragged images and then rename them as needed based on the selected images from the interface. PM me for further details and to discuss prices.
Here is a query to confirm this: [https://data.stackexchange.com/stackoverflow/query/864152/tag-popularity](https://data.stackexchange.com/stackoverflow/query/864152/tag-popularity)
Slices allow you to define a start, stop and step size. e.g. for the odd characters s[0::2] Will give you every second character starting from the first element (1, 3, 5, ...). Same can be applied for the even characters.
Take a look at this [tutorial](https://www.youtube.com/watch?v=ZDa-Z5JzLYM&amp;list=PL-osiE80TeTsqhIuOqKhwlXsIBIdSeYtc) if you struggle with classes. It helped me a lot!
Didn't say that it's not reasonable. Just saying that they have their own style guide vs using what's the OSS Python standard.
Old computers are ok but an SSD is a game changer.
SHHHHHHHHHHH
[asyncpg](https://github.com/MagicStack/asyncpg) as it is very quick and Postgres is an excellent DB.
What I am having trouble understanding is where mainloop is executed. Where is the code that is run during the mainloop? Is it everything under the __init__? An analogy to a standard while loop in the context of the tkinter mainloop would be very helpful.
&gt; Yeah, looks like some misinformation up there. Most importantly, they do in fact use 4-space indents, not 2, lol. No misinformation. In the OSS style guides, they listed the 2-space indent last time I checked their style guide (like 3-4 years ago). Anyway, they still seem to use it internally. E.g., see here in one their own resources: &gt; A common question beginners ask is, "How many spaces should I indent?" According to the official Python style guide (PEP 8), you should indent with 4 spaces. (Fun fact: Google's internal style guideline dictates indenting by 2 spaces!) source: https://developers.google.com/edu/python/introduction
Has anyone else looked at the load times on this? Im getting what seems like crazy fast execution times compared to similar laravel and codeigniter applications that I have running on PHP. How does this compare to the load time of other Python frameworks? Masonite 2: Request: 0.004588127136230469 GET Route: / Request: 0.0024170875549316406 GET Route: / Request: 0.0029621124267578125 GET Route: / Request: 0.0023229122161865234 GET Route: / Request: 0.002313852310180664 Average Time: 2.4ms
Did you use Python to generate the list?
This is literally the same setup I use. 
There are also substantial to seek good Python content elsewhere, at least judging by his series on 3.4
Haha no I didn't... but it would've been a nice web-scraping project for sure. With this sort of stuff I think the power is in the curation rather than just assembling a list. If it gets much larger I think we'll need to start splitting it up into different categories etc.
You might be better taking this over to /r/learnpython, and it would help if you could show us what you've already tried.
I intend to add argparse and ability to take in input in the form of the series name, an url, or a file of similar data. Might add the ability to take open tabs and see if the tab is a series url and if so download the comics. Turns out the first python project I've actually tried to do is pretty useful for my other hobies
Is there much value in factoring out common functionality, when one of the functions was only included for educational purposes?
 st = "ABCDEF" print(st[::2] + st[1::2]) 
Sounds pretty good ideas if you want my opinion. 
I don't really have any code to show right now. I mean, getting even and odd indexed chars isn't a problem, the problem is when I have to run it many times. I can't use recursive or iterative approach (which I tried) because it takes too much time. 
I won't work. It's too slow. And I can't run it recursively
I'm not entirely clear what you mean by "taking a newly concatenated string". I'd like to see your code because it will explain precisely what you are trying to do and it will show us what you've already tried so we don't try to suggest it again.
What do you mean by "run it recursively"? Do you mean your algorithm needs to be recursive? Is this for an assignment? can you provide the details of the assignment and what you have already tried?
Except for way more complex case, you do not need recursion. Iterative method is proven equivalent, and way more natural in python syntax. I could try different method and benchmark it tomorrow. What is the len of the string you have to work with? 
I'll throw [The Terrible Programmer](https://www.youtube.com/channel/UCYpYQNHs2NN-J-UC7Pn4G5A) in there...There's not a ton of content on this channel but the Roguelike Development series is pretty good if that's what you're looking for.
I bought a Dell XPS 13 with Windows installed but I just installed Arch Linux directly over the main (big) partition and never even booted Windows once. That laptop (and probably all of them) have a tiny recovery partition so, e.g. if I decide to sell the laptop, then I can just boot from that recovery partition and restore Windows.
Specs? Also, is dell xps 13 giving any problems? Heard bad reviews on it
Many academic institutions have need for research assistants. Most of is data migration and scraping but it’s a good place to start looking. 
It would be easier to explain s on example. As in my firs post, let's say I've got string "ABCDEF" as an input. I take even-indexed characters (A, C, E) and odd-indexed characters (B, D, F). When I concatenate them, I get "ACEBDF". And that was first run. The second would have "ACEBDF" as an input, and again I look for a even-indexed (A, E, D) and odd-indexed (C, B, F) chars. Now, when I join them, I get "AEDCBF"- and that's an input for my next run. And I can get bilions of such runs, and string can be extremely long. Here's my way of getting those chunks concatenated. Function sort\_my\_string need to return the output string- string after those bilions of runs. def indexed(string, start): return ''.join(list(islice(string, start, None, 2))) def sort\_my\_string(S): even = 0 odd = 1 return indexed(S, even) + ' ' + indexed(S, odd) 
wait wut
the google github org is a dumping ground for employee projects, a significant amount of that stuff doesn't see internal use, getting the right to publish there is basically filling in a form AIUI.
Isn't [pyvideo](http://pyvideo.org/) the ultimate list? 
The last line of the update callback can reschedule itself; you saved a copy of the root in the contructor. self.master.after(1, self.update\_clock)
I tried to explain this in my comment below
Length of the string may be extremely large. 
Yep I really like PP too
That's just for event recordings—but for channels run by independent content creators you'll need to head over to YouTube directly. That said—pyvideo *is* a fantastic resource :-)
( ͡º ͜ʖ ͡º) 
But they're taking in tutorials, too. The creator just has to put in a PR to the repo. But yeah, you're right. Not many peeps doing it.
You could try using a numpy array S to hold your initial string, and then make up another numpy array index of indexes \[0,2,4,..., 1,3,5,...\]. Then your iteration S\_next = S\[index\] for as many times as you need to do the mixing. Then pack it back into a string at the end.
Maths shortens this problem considerably. There's a fixed number of possible outcomes you could work out the pattern for each position and predict it exactly, but that would be very tricky. Less efficient, but much easier is shuffle and store the possibilities until you shuffle back to your starting position, then take the modulo of the supposed iterations and pick that out of the possibility set. def shuffle(s): return "".join(s[0::2] + s[1::2]) s = "123456789ABCDE" possibilities = [s] tmp = shuffle(s) while tmp != s: possibilities.append(tmp) tmp = shuffle(tmp) print(len(possibilities)) iterations = 1000000000 print(possibilities[iterations%len(possibilities)]) There are twelve possible shuffles of the string "123456789ABCDE" we pretend to do a billion iterations, end up at the right answer in 0.034 seconds.
I have the first model of the current design that was released, i.e. the 9343 model. It has been excellent and I have been superbly happy running Arch on it.
Not here to rain on anything, I love using Python, but are these metrics really that important or exciting? It’s well developed and widely known/known-about language, surely we’ve gotten past the point where these things are milestones. Open to any thoughts from the opposite way of thinking. 
Lots of code from Google is 2 space indented.
Never understood the focus on this site as a popularity metric. If I want to know the most popular car I wouldn't go to the auto parts store where people are wandering around hoping to solve their car problems.
I worked on Linux for a long time before stitching to Mac and honestly find it much easier to work with. Less shit goes wrong and when it does it's easier to fix. Im decent with Linux but I'm not interested in spending time fucking with my environment. I'm not a Mac fanboy at all I didn't think I would like it.
That is exactly what I was looking for! Thank you so much. And could you tell me a little bit more about working out the pattern? Not a valid code necessarily, but just the idea. 
&gt; The maintainer is clearly saying ... Ha, this is an incredible stretch. If they meant that they’d likely have said it
This is Neil Fraser, the creator of Blockly. He's extremely brilliant. I would assume he's joking, but even if he's not, he's not a Python guy. Which I guess is why he doesn't seem to be too upset that I named my research project BlockPy.
For what it’s worth, his self deprecating humor/ video game example finally made python classes click for me
It's a good idea to set yourself a goal. But why a "library"? Why not just work on something you're interested in? 
I'm with you. I'm actually concerned that this may be an indication that the language may be getting a bit convoluted and it's requiring more people to seek out this help. I know that I, for one, am still confused as to how decorators work, granted I haven't gone out of my way to try to learn about them. But I don't think I really ever had to go out of my way before to learn about language features.
That's super normal for most reasonably sized companies
Your last issue is easily solvable with virtual environments or pyenv. Which you should be using anyway. You shouldn't rely on system installs of python.
I have 2 years left at college and I will likely be working with a lab for most of that time, so I'd like to get experience creating relevant tools to help with those tasks. I'm not sure what it is I really want to work on at the moment anyways, but cybersecurity is my passion. 
Whether it be like it do or it do like it be.
+1
If you're moving large quantities of data it is far superior, in that it will automatically dump gigabytes down the TCP connection using multiple threads and put it back together again for you. It's effortless to saturate 1 Gb or 10 Gb connections with ZMQ, whereas with `socket`, it's a grunt and tends to come with a host of bugs. ZMQ also supports a bunch of different server/client models, depending on how you want to dispatch data. 
Correct. That's why they _did_ say it. Go read the actual ticket, without the title OP posted being primed.
https://pypi.org/project/hyperpython/
Not mine but: https://pypi.org/project/hyperpython/
Came here to ask why Anthony isn't on the list. There can be only one possible answer: RealPython is racist! Common Reddit, let's start the riot.
Wrong 
I see the point you’re making. Python is becoming a larger language (compared to other scripting languages like Lua), and I think it serves as a great middle ground between lightweight languages and heavier compiled languages like C++. It’s OOP nature allows for that. However, there does seem to be some bloat going on. Things like list comprehension drive me up a wall. For a quick for loop or generating a list they’re great, but when you start doing more extensive logic in a LC, I’m going to lose it. I’m an undergrad and our Data Structures course threw them everywhere. Syntactic sugar is a pet peeve of mine, I much prefer readable logic. There may be some performance gains with LC, not sure. I’m not a deep computer scientist or expert by a good light year, but just my 2¢. For some decorator knowledge, check out Corey Schafer. All of his videos do a great job explaining concepts in a practical way. The following three are on decorators: [Decorators](https://youtu.be/FsAPt_9Bf3U) [Decorator Argument](https://youtu.be/KlBPCzcQNU8) [@property Decorator](https://youtu.be/jCzT9XFZ5bw)
You’ve put it inside of a pair of string delimiters, get rid of the quotes, they tell python that what’s in between them is a series of characters to be stored in memory, not executed.
Take the str(I) out of the single quotes. Right now your just printing the text str(i) instead of the variable.
Still not sure is it a good thing or a bad one
Type Annotations - when I first saw them years ago in a very large py2 shop (having come from static langs) I dismissed them as pointless noise and ceremony as they are neither really enforced nor even mandatory and do nothing for performance. I had watched clojure's gradual typing make a short lived splash and then fizzle - in my opinion as it clashes with the vastly more freeform nature of clojure wrt structure and control flow - and expected basically the same with python. After switching back to a static lang for a while and coming back to pure and modern py3 I feel the total opposite now - it's my favorite part of the language. Enough freedom to do the crazy dynamic stuff I want, tool support that comes with it, and an ecosystem of tools built around the whole idea of python being a comfortable but slow language to glue together sharp but fast code. 
Those are shell commands, not python. No need to run python interpreter to use those.
1: read the sidebar 2: post in the right sub (see above) 3: read THAT sidebar 4: don't post screenshots of code 5: you can't execute OS commands from inside the python interpreter.
I just will tell you exactly the same as the other posts did.
Thanks, I'll check those out.
If you are on Python 3.6: print(f'my name is {name1} {i}') I love this new feature.
That worked great.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Ty
Ty
Yeah this. The reason people go to stack overflow is problems like bad or outdated documentation, bugs, and of course user error. They also might just be looking for a solution in :your_lang_here. So maybe this metric could be tuned? I am not sure.
\# Import the modules import sys import random ans = True while ans: question = raw\_input("I am CNN! Ask me if something is true: ") answers = random.randint(1,13) if question == "": sys.exit() elif answers == 1: print "It is certain" elif answers == 2: print "My sources say yes" elif answers == 3: print "You may rely on it to be true" elif answers == 4: print "Ask again later" elif answers == 5: print "Concentrate and ask again" elif answers == 6: print "Reply hazy, try again" elif answers == 7: print "My assignment says to say no" elif answers == 8: print "My sources say no" elif answers == 9: print "As a Journalist, I am an expert in this matter. TRUE!" elif answers == 10: print "I have to ask Mr. Soros" elif answers == 11: print "Hillary told me to say yes" elif answers == 12: print "Lets check hillary's emails" elif answers == 13: print "I don't rely on my ratings to keep my job. Thatway I can tell the truth. Yes that happened." 
Yeah, there have been a lot of variants of that over the years, but none are popular. Most people either use Jinja2 or Django templates. 
Having built a few roms myself on Arch, I think I can help. 1. Install python2-virtualenv and use that for the python stuff. 2. See halogenOS's android_manifest readme since they probably have the best setup guide for a rom. You can also use --no-clone-bundle, -c, and --no-tags to speed up downloads, as well as -f to continue syncing other projects if one fails. Anyways, yes it's dumb, but it was setup a while ago before git submodules were a thing and has been retained. And it doesn't have to be the same branch for everything, you can override stuff with a local manifest in .repo/local_manifests. The branch in the init name is the branch name of the android manifest repo.
b-but, muh secret club
I think the question is still good. What’s something you’re interested in that either has a problem or could use more functionality? Can you write a python module or application to solve that problem?
ಠ_ಠ
Lol that's just because a lot of us are self-taught hobbyists who need help a lot. It doesn't actually say anything positive about Python. 
is this list red pilled or...
* Use of globals everywhere is gross, sorry but just don't do that * imports are not grouped correctly, run it through isort to fix * everything in one file, no if __name__ is '__main__' guard * mixing camel case and snake case in variable names, just use snake case unless it's a class name * you do realise that here the brackets get cancelled out? description=(outRow)
Forgot siraj raval, great machine learning tutorials: https://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A
opencv has this exact same issue, you simply can't install opencv from pypi and that is a bit annoying. in the past I've had to resort to copying opencv into the virtualenv, it's a bit gross. off course we have docker now.
VS Code is just too nice to pass up. Try it out if you haven’t.
I got it working, thank you. Here is the changed code: self.update_clock() def update_clock(self): new_time = time.strftime('%H:%M:%S') self.current_time.set(new_time) self.master.after(1, self.update_clock) 
I suppose not.
What OS are you using? Does your computer have enough RAM to handle Pycharm?
Windows 10, I have 16 Gigs.
Pretty much everything is an instance, yes. But there are some exceptions, for example, a class definition creates a custom type of which you can create an instance.
I don’t think he’s as bad as people here make it seem. I wouldn’t recommend him as your only resource though. 
I use one called yattag. It uses context managers to properly close out tags.
I bet this correlates strongly with the use of Python in beginning programming classes and students googling their homework.
Depends what else you do as well, most developers (to my surprise, I'm a bit out of the loop I guess) in silicon valley etc. seem to use macbooks. Unix based anduses bash and everything obviously like linux, but there is a bunch of software only for OSX that, again, depending on what you do, can be a game changer for frontend design for example. I personally run win10 on my PC and ubuntu on my laptop, however I recently started using the somewhat new linux subsystem addition to win10 which essentially gives you a decently integrated linux (I use ubuntu) bash inside windows. I was hyped but already running into some issues now.
You should see the itertool built-in library and especially itertool.permutation!
https://datascience.stackexchange.com/a/12346
&gt;Fucking trendy ES6 devs making the 2-space indent shit popular. Google has been using two-space indentation for at least a decade. 
To be fair, many Android devs supposedly also hate repo. 
Yeah like.. let's not give people a free pass for being full of themselves just because they're "brilliant". That's how capitalism was created. And Blockly's nothing special.. any javascript developer could make that.
..... which is way too long to be using two-space indentation.
Thanks for the link but i failed to understqnd what he meant by parameters and internal object state. Would appreciate a simpler definition.
This post is better suited for r/learnpython 
Firstly, start in /r/learnpython. Secondly, your question makes little sense. "Block chain with python" is very vague and you won't get any decent answers to that. Blockchain and python are independent concepts. You will need to understand a bit of both, **independently** before you can start using them together.
if your primary motivation is forgetting closing tags, configuring your IDE or editor's code highlighting and warnings is probably the way to go. it will reduce the overall complexity of your application, avoid potential bugs, have more flexibility, and reduce maintenance costs. also, if you need a custom html tag, you won't have to wait for it to be implemented most IDEs and editors, if not all, have some version or interpretation of Emmet (formerly zencode) with tab expansion of html making it much easier to write html, and simple well-written html isn't difficult to work with
When you have a machine learning algorithm, you tend to have a training set and a testing set. But, you often need to normalize the values of the instances because some values are extremely large compared to other values. Generally, to normalize, you subtract out the mean and divide by the standard deviation (column-wise). The thing is that you don’t want to taint your test set. So you want to use the column mean and std deviation of the *training set* to normalize your test set. So when that answer says “parameters” the Greek mu is referring to the mean and the Greek sigma is referring to the standard deviation. The fit method calculates and stores those values. The transform normalizes a given array of instances using the calculated mean and standard deviation values. The fit-transform does both at once (which is handy for the first time you run it — on the training set). Any clearer?
it's important because it means we're going to be seeing more blogspam
Thank you so much i finally got it🙏🙏
How long until you master a language?
Most probably around 10,000 hours. 
It all depends your background experiences and how you define "master".
&gt; EDIT: Wait, it's even worse. That's not the actual root, the single .py file (other than __init__, which overrides the actual module with an inner member of the same name, WTF?) contains the entire library minus tests. Are you saying it's a _bad_ thing that the code is only contained in a single file? I just glanced through it and there does not seem to be enough complexity to warrant splitting it into multiple files. Having it as a single file makes deployment trivial. In fact, after glancing through the python code (and before seeing your comment) my first thought was that his mistake was not just putting the code in the `diff_match_patch.py` file directly into the `__init__.py` file itself to make deployment even more trivial. Given that it's a single file package and it only uses the standard library, I'm not that surprised that he hasn't bothered with pypi.org. I do think it's a bit surprising he hasn't heard of it, but his profile says he's been at Google for the last decade so maybe he just hasn't had much use for it.
The JetBrains IDEs are not the fastest, as they're Java based. However 15 - 20 seconds seems a bit too much. Maybe these help? https://www.jetbrains.com/help/idea/tuning-the-ide.html
Yep. If it's just your data analysis script and isn't communicating with other people in any way, then you're fine.
Older Macbook with Debian. Runs much smoother than MacOS ever did. 
 import swallow, sys from people import Person from people.nationalities import Indonesian def main(): return swallow(Person(gender="female", nationality=Indonesian)) if __name__ == "__main__": sys.exit(main())
Start by googling
And u/sendex lurks here! .
I wouldn't say a library with 2,000 lines is small enough to go in a single file, I try to split them way before reaching 1,000 (though an enforced hard limit would be stupid, it isn't bad practice in general). In addition, I was taught that generally putting your code directly in __init__.py was bad practice, that it should go in its own module and be reexported if it needs to be visible at that level.
ok thanks
Everything is an instance in python, because "instance" just means something that has a class. If X is an instance of Y then Y is the type of X. Objects whose type is `type` are instances of `type`.
I recently interviewed at Google. They have a different internal style guide than their public one.
Idk look at the table of contents? Just go write some Python.
The e-book is free online. Don't waste your money buying it. Just go to automatetheboringstuff.com
I know. I've seen it, but I want to invest money. It's a way to push myself. Also, having it as a physical copy laying onto my desk, makes more eager to pick it up.
What does that mean in the context of Python?
There's already a package that does that for Django - [django-fsm](https://github.com/kmmbvnr/django-fsm).
https://www.youtube.com/channel/UCoMAKPDECRWb7GEWF1lQZMQ/featured One of my favorites 
Just go ahead and download the book, it'll be a lot easier to go through it in PDF form side-by-side with a Python interpreter/editor.
You are misinformed: https://github.com/google/styleguide/blob/gh-pages/pyguide.md#s3.4-indentation
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [google/styleguide/.../**pyguide.md#s3.4-indentation** (gh-pages → c0c1483)](https://github.com/google/styleguide/blob/c0c148379285e11f112d30bcf836a20fe2c0a325/pyguide.md#s3.4-indentation) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply e0x2hic.)
Isn't it /u/sentdex ? 
Plus it's a great way to support the author. Its a good book. He has also created a video tutorials based on the book. You can get that on udemy. The book is more detailed though. 
Mature yes, updated no. &gt; Commits on Jun 8, 2017 
I'm working on learning python, started about a week ago, the only previous programming software I've used was MATLAB and have to say, really liking it so far!
You don't, really. People will know anyway.
Avoid and move along. More spam shit.
[Self-promotion](https://www.reddit.com/wiki/selfpromotion)
[Self-promotion](https://www.reddit.com/wiki/selfpromotion)
[Self-promotion](https://www.reddit.com/wiki/selfpromotion)
[Self-promotion](https://www.reddit.com/wiki/selfpromotion)
Hmm, I know reverse engineering compiled bytecode etc is pretty basic, but you know I want to hide the source code from laid-back developers only... like people who won't bother checking inside a library or something.... isn't there any other distribution apart from pypi
Would ya look at tha: More crap spam
Since you are new to programming, I suggest you start off with a text editor instead of a full fledged IDE like PyCharm. IDEs feature tools like refactoring and source control that are not really necessary for a newbie programmer. Text Editors are simple and get the job done since Python scripts are essentially just text files. Take a look at "Visual Studio Code" (the "Code" part is important) or Atom. VS Code is like ~50 MB total and is not that heavy on the system. 
Noone would use your lib if they couldn't read the code. Who knows if you put a back door in there. 
Looks interesting. Quite similar to something I'm working on now. Did you use the built-in curses lib? Have you ever considered modularizing your code?
There are only two classes defined in that python file and one of them is very short. Looking at the code itself, it all seems very self-contained and I see no reason to split it up. All of the logic is together as it should be. Separating it into different files would add complexity (due to indirection), but bring no apparent clarity (due to separation of concerns). There simply is _no_ magical number (1000 or 2000 or whatever) where having separate files makes things better. It has to do with the code itself. In this case, the organization seems totally fine. Also I don't know why you would have been taught that putting code in the `__init__.py` file is bad. It's quite a common practice. In cases like these where all it is doing is essentially just defining the external interface, the same thing can be accomplished by putting `__all__ = ['diff_match_patch', 'patch_obj']` in the python file itself. Btw you might want to consider that around 35 (by my count) of the files in the cpython standard library have more than 1000 lines and more than a dozen have more than 2000: https://github.com/python/cpython/tree/master/Lib You might also note that the code for the collections module is contained in the `__init__.py` file: https://github.com/python/cpython/blob/master/Lib/collections/__init__.py I don't want to claim that the cpython source code is the final arbitrator on what quality is, but it is at least instructive to consider it. Regardless my point is that separating code comes at a cost. Often that cost is paid for by the added clarity of the separation, but it's not a guarantee. Here I see no advantage to any added separation and in fact do see an advantage to just putting the code directly into `__init__.py`. Just my two cents anyway...
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [python/cpython/.../**__init__.py** (master → fc93bd4)](https://github.com/python/cpython/blob/fc93bd467e7a00f12a4f17e27f0f7a0b2c590880/Lib/collections/__init__.py) * [python/cpython/.../**Lib** (master → fc93bd4)](https://github.com/python/cpython/tree/fc93bd467e7a00f12a4f17e27f0f7a0b2c590880/Lib) ---- 
Why You are like this?
Just clean up your code. That's the best answer I can give. I'd like to see what you've made, but open source is as open source does. If you don't want to release it publicly but want to use it to get a job, put the use cases on Github or somewhere.
I commend you for wanting to support the author. I didn't. To answer your question: after reading through the free pdf version I was able to automate emails, get confused as hell by datetime vs time, build a stopwatch, scrape websites, and a bunch of other menial tasks. With the skills I learned, I was able to go on and understand a bunch of libraries, understand Restful APIs, and automate my investments. I still work for a living and I could automate a bunch more things, but that book is a good place to start.
It's completely trivial to reverse engineer python. Like you paste 3 commands and it's done. If you need to protect your code from commercial use make it GPL 3 or don't use python.
Well a couple things are you getting any output to the file ? Also are you sure the length of response isnt equal to 3 in your test cases 
If I run python blah.py &gt;&gt; test.txt I don’t get the full response. It will stop running before it prints the full output. 
Write in cython and distribute compiled version.
To refresh your data, you just make a function that'll make a new query to the SQL database, then... Redraw the infographic template with the new data from the database. Something like... `while(true){` `time.sleep(1000);` `refreshData(selectedTemplate);` `}` time.sleep(1000) stops the loop for one second, then refreshData() is called with a var param that contains something that tells it which template you're looking at right now, so you don't waste CPU resource pointlessly reloading templates in the background. Have a different function to change whatever's stored in the selectedTemplate var when the user changes template. Have you heard of threading? If you need your program to do many things \*at the same time\*, you want to do threading. If you give that loop its own thread, the user will be able to do all the normal stuff the user does when the templates refreshes. Beware of race conditions. [https://stackoverflow.com/questions/2846653/how-to-use-threading-in-python](https://stackoverflow.com/questions/2846653/how-to-use-threading-in-python) 
In Which file test1 or test2 do you not get the full output 
Whatever time you intend on wasting on a convoluted build process to distribute compiled binaries is much better spent on just cleaning up your code.
Check out r/learnpython
Can mods blacklist posts with links to certain sites. This spam is annoying.
When was the last time you audited pip code for security vulnerabilities? :). I guess there's the whole "what have you got to hide thing". Perhaps he could have his code behind a link with an NDA :). "I promise not to comment normatively on the quality of the code in any way positive or negative, but may report and security vulnerabilities found publicly" :) I buy the argument that open source can in theory increase security by making auditing possible... but someone actually has to do the auditing and this may well not happen for small projects with one author. I suppose a caveats is that if someone *modifies* your code they may well spot dodgy code. So perhaps an open source project with a few (verifiably distinct) authors is more secure.
The table of contents in the book has it all listed. Reading and writing files, web scraping, sending emails and text messages, scheduling tasks, manipulating images etc. If you're just starting, the first few chapters of the book will be most helpful. The first few chapters of all beginner level books start to look very similar after you read them. So don't worry to much about what you start with or finding the perfect book. The most important thing is to pick one and get writing. When you have questions that aren't answered in the resource, ask for help or find another resource. Then keep writing. Finally, you'll get the answer and have ten more questions. It's all part of the fun. 
Check out r/learnpython
For the interested reader, this post discusses this: https://www.reddit.com/r/Python/comments/6i42d4/reverse_engineering_of_cythonnuitka/ 
love it
I'd agree with this. I would note that the OPs concern is likely not *time* but rather lack of faith "real-or-imagined" in their proficiency in python as well perhaps as reputation worry regarding other people reading the code. One approach therefore might be to publish the code under a pseudonym - though in practice maintaining the anonymity of a pseudonym can be a moderate amount of work if you like talking to people in real life. 
Not sure if this is intentional, but you're mixing two different concepts here. On one side you're using python's own f.write to write into a text file (test2.txt). This file should contain a newline and the string "response" for every time you've run the script. Note, that you've put it in quotes, so it's actually writing "response" and not whatever you've stored in the variable `response`. On the other hand you're using your shell's stdout redirection (&gt;&gt;) to direct the output of your script into a separate file (test.txt). This file may contain whatever `response` is, but only if its length isn't 3. Without knowing what response is it'll be hard to figure out what to expect in that file. PS: For your own and everybody else's well being I highly recommend learning Python 3 instead of Python 2. You won't see much of a difference as a beginner but in the long run you're saving yourself some pain.
Thank you 
Pypiwin32 depends on pywin32 to be installed first. 
Not being rude :) Error is telling you what's wrong with the code. my\_list = \['test', 'nest', 'vest', 'zest'\] - You can call my\_list\[1\] - which will give you 'nest' because list have indexes. my\_set = {'test', 'nest', 'vest', 'zest'} - You can not call my\_set\[1\] - which gave you the error you mentioned because sets are not indexed. 
aahhh i see. i know whats wrong now. thank you 
The &gt;&gt; was just testing if I could do it that way, which it works but doesn’t output the whole thing. 
#/r/learnpython That aside: You haven't given a lot of information, specifically you haven't included whatever code you're using to define `booksborrowed` and `stuIDS`. I assume they are lists but you're doing something weird there by iterating over them for every single item… It's hard to figure out what may cause the error with missing code. To get a dict that maps each ID to the number of books they've borrowed: no_of_borrowed_books = {id: len(books) for id, books in lib.items()} 
It'll be hard to help you without more information. "Not the whole thing" is extremely vague.
Not only that, but more effort and full of bad practices. 
This looks interesting. A few more details on how to use it (possibly a demo.gif?) would be nice. As far as I can tell this would be a (much) more convenient way of doing what pssh does?
Sorry was responding at a red light. So the whole script pulls gps coordinates. Once I stop I will pull some examples. 
Please tell me you're not texting while driving.
Only at red lights. 
It's probably indexing. PyCharm needs to build up a cache of your installed libraries so it can quickly provide suggestions and completions later.
Missing a ) at the end of line 17
x = input('Enter h to indicate the guess Is too high. Enter l to indicate the guess Is too low. Enter c to indicate I guessed correctly.') epsilon = 0.01 step = 0.1 guess = 0.0 high = 100 low = 1 ans = (high + low)/2.0 print('Please think of a number between 0 and 100!') print('is your number' + str(ans) while x != 'c': print('is your number' + ans) if x == 'l': low = ans elif x == 'h': high = ans elif x == 'c': print('Game over. Your secret number was: ' + str(ans)) else: print('please insert a valid answer')
 x = input('Enter h to indicate the guess Is too high. Enter l to indicate the guess Is too low. Enter c to indicate I guessed correctly.') epsilon = 0.01 step = 0.1 guess = 0.0 high = 100 low = 1 ans = (high + low)/2.0 print('Please think of a number between 0 and 100!') print('is your number' + str(ans) while x != 'c': print('is your number' + ans) if x == 'l': low = ans elif x == 'h': high = ans elif x == 'c': print('Game over. Your secret number was: ' + str(ans)) else: print('please insert a valid answer')
I don't see a missing ). Maybe I need more coffee.
Yeah I think it would be a great project and really helpful for people to learn about writing emulators. I’ll be sure to ping you :)
Consider using a graph database like Neo4j or JanusGraph if you want to store a non-trivial amount of information. Pure python will not be too efficient for the size of social networks.
They don't seem to like people with an appreciation of package management. They rejected the author of brew because he couldn't reverse a binary tree on a whiteboard: https://twitter.com/mxcl/status/608682016205344768 It's probably not so much a coincidence that the state of package management in golang was utterly fucked for the first 3 years or so.
Damn, it looks like they're all up there for free except the one in OP's post :(
Ok so I have made progress. Python doesn’t like empty lines. Issue I have now is that for some reason when I try to work on the script from my phone it is using non-ascii characters... UnicodeEncodeError: 'ascii' codec can't encode character u'\u2019' in position 145: ordinal not in range(128) Line in question f.write('\n' + located_devices)
Yes, i use built-in curses lib. And please expalin what exactly do you mean by "modularizing code"?
&gt;possibly a demo.gif? I'll do it later, good idea. Basically after installing you could run curses interface by `sshch` and press `h` or run command line help by `sshch -h` As far as I know, there are many more sophisticated projects, for example dsh. pssh i have not seen yet. In my project, I tried to implement a simple functional, which I lacked for many years setting up servers. I really like to use another curses utilities: htop and mc. I wanted something similar to control ssh connections and aliases.
&gt;I'm guessing python was just hacked out and is not the primary (or even secondary) language of the developer. So not knowing about pypi is not unreasonable. If you're that naive in a language then you probably shouldn't be releasing open source software with it. I'd be terrified of relying upon code written by this guy in production. Furthermore, it's not just pypi, he seems confused about the whole notion of package management in general as well as trying to argue that pypi is some fly by night thing despite being 18 fucking years old.
though his youtube channel is not that active, but he is a GOD for r/flask community! :) add his youtube channel too! :) [Miguel Grinberg](https://www.youtube.com/channel/UCZJiXG_auf0o7LByqC1LHuQ)
Dunno why you're getting downvotes, but I don't necessarily agree that they're "slow" because they're java-based. I love Pycharm, its probably my favorite IDE I've ever used, but it is true that it chokes and stutters from time to time.
I hear that. My primary intent is to try to maintain visibility over the construction of a web page and make it “easier” to assemble pieces together be it tags or scripts (like js(file) -&gt; &lt;script type=“text/javascript” src=“{file}”&gt;&lt;/script&gt;). I also thought that a DOM is a tree structure and so a dict can be a tree structure, so I wrote a recursive walk of a dict d, to_html(d) that outputs what you would expect. d had “@“ key for attributes (dict value) and “&gt;” for children (list of dict value). “text” key for text. I’m still on the fence of whether or not it helped. You can’t just go in to the html to change something, you had to find out in the script where the change should occur, make the change, then rebuild. That interrupted my flow sometimes. Maybe this would be good for generating boilerplate? 
Why doesn't that work?
&lt;3
Derek Banas has a nice series for beginners too. I am currently watching it, as a first time programmer learning with python. 
Something I worked on a little while ago that you may get some use out of: https://github.com/clarkerubber/automaton/blob/master/automata.py
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [clarkerubber/automaton/.../**automata.py** (master → ad548ca)](https://github.com/clarkerubber/automaton/blob/ad548cabdec64214a8287a1cad09cd28e432c5a3/automata.py) ---- 
 while True: main_screen.onkey(jump, "Up") main_screen.listen() main_screen.mainloop()
Python has enums. If you're going to type `state == 'captured'` all over your code, you're going to have bug from a typo, and your IDE's ability to type check is limited.
I think a lot of things change in the context of Operating Systems. For example, locks are deemed to be great when writing operating systems, but quickly become tiresome when writing high level applications. A great solution to this is async, which eliminates the need for locks, but the support is not quite there yet and CPU bound tasks don't benefit with async.
I get what you're saying - it's not updated - but not everything needs to be updated. Some of the stuff in core utils hasn't changed in 10 years.
I responded to this: &gt; There's already a fairly mature and frequently updated package that does that for Django - django-fsm. And agreed it was mature but not that it is updated often. 
 This is perfect but with this I could only cluster 2 column but I want to cluster 8 together. 
Does this `X=dataset.iloc[: , [3,2]].values` explicitly only take 2 columns? What happens if you address more than 2?
So many things that need improvement. 1. Don't do all the work in one massive method. Split it up into individual methods so you can calculate only what you need. There should be a `count` method (to be exact it should be `__len__`), a `total` method, etc… 2. Once these are split up, turn them into dynamic properties. 3. Assuming you ignored 1. and 2. for some reason, why is `calculate` a public method and not a private method called automatically by the constructor? If you're not going to expose the various results as individual methods/dynamic properties there is no reason to require an extra method call that will always be necessary for the class to fulfill its purpose. 4. `data` should be an argument of the constructor. Having to assign it after initializing the object is unintuitive and requires additional lines. 4. Use docstrings instead of those weird block comments. (On that note, read PEP8!) 4. Don't use comments unless they actually mean something! A comment that just repeats the class/function name is nothing but pointlessly wasted space. 4. is_even doesn't need to be a method. Just extract it as a standalone function and put it outside of the class. 5. You can omit the first argument of range if it's zero, e.g. `range(32)` instead of `range(0, 32)`. Unless, of course, you prefer the longer version for being more explicit. 5. You can use `**` instead of `math.pow`. 6. You can use `sum` to get the total (not the total of squares, though). 7. Use `self.data[-1]` instead of `self.data[self.count - 1]`. 8. Please, for the love of all that is holy and pythonic, don't iterate a list via its index! Do this: for i, item in enumerate(self.data): print(str(i) + "\t" + str(item)) 9. List comprehensions are your friend. In the `main` function: data = [random.randint(1, 128) for _ in range(32)] 10. Don't use single character variable names (except for loop indexes). Ultimately your `main.py` should look something like this: from statistics import Statistics from random import randint def main(): data = [randint(1, 128) for _ in range(32)] stats = Statistics(data) print("----------------------\n| code-in-python.com |\n| Statistics |\n----------------------\n") stats.output_data() stats.output_statistics() if __name__ == "__main__": main() 
Because that argument hasn’t been relevant for at least a decade. I don’t even like Java but this sub spreads more Java misinformation than most other places on the internet. It’s 2018, people actually use Java specifically for performance critical situations. IntelliJ is slow because it’s doing a couple dozen background tasks at any given moment.
&gt; he seems to think pip is also a package manager ...it is. [Wikipedia](https://en.wikipedia.org/wiki/Package_manager): &gt; A package manager or package management system is a collection of software tools that automate the process of installing, upgrading, configuring, and removing computer programs for a computer's operating system in a consistent manner. And &gt; as well as trying to argue that pypi is some fly by night thing despite it being 16 years old. He never argued that. He simply stated the fact that in the project's life time countless package managers and repositories have blipped into and out of favor.
I'm still in the learning process for Python. I've written a SQL script to query for all user tables in a specific databsse, then build a table of all the table names, columns and data types. I'm now (almost finished) writing a python script that queries my test / production servers (using said SQL script) and shows me the differences. 3 developers making changes to the production server and I appear to be the only one letting the other 2 know what changes I'm making so I'm hoping this will be helpful. Half expecting someone to come along and say "just import this library and run this function it will do it all for you" but it's been a fun learning experience nonetheless. 
Say if I'm wrong but I consider permutations as quite inefficient. 
My toy language, written in Python and using LLVM: [https://github.com/syegulalp/Akilang/](https://github.com/syegulalp/Akilang/) The project has some included demos, like Conway's Game Of Life. I'd like to have as many of those kinds of things available right out of the box. I haven't done much work on this in the past couple of weeks due to other things taking up my time, but my next intended feature is functions that can take variadic arguments. (I already have a way to supply \*optional\* arguments, though, but this would allow a theoretically unlimited number of arguments.)
&gt; as they're Java based. Really dating your opinions with that statement.
D'oh I meant to say pypi. &gt;During the course of Diff Match Patch's life so far, we've seen the appearance and/or disappearance of PyPI, pip, ...
Well, I'm dating them to the software I'm currently using (which is up to date) ;)
Ahh got ya. I'd say he was talking more generally about sites/tools. He mentions pip, npm, yarn, bower, ender as well as PyPi, code.google.com, SourceForge, GitHub.
Point being that Java isn't inherently slow these days.
You're probably right, but Java-based software usually still is. Whether this is because of Java itself or because of Java developers I don't know (and I don't really care).
Better than how to exit from vim
super helpful answer! 
Please have a look at the code now. My code did not fail, it's fine. Want is to have clustering with 8 columns by understanding their correlation. Here I have have selected random columns from df2 (14 collumns), I want to choose only the ones that has importance. 
There's a guide here on how to do this: https://i.imgur.com/kpfKSui.png
You're welcome. Sometimes people forget that books contain a section and desscribe their contents in brief.
Define `amazing` first. Then `easily`.
&gt; Sometimes it's good to know how many unnecessary but interesting details Python hides from us. Not unnecessary, it needs this stuff to work.
anything you did you thought was amazing but you did it very easily. As in not involving complex machine learning algorithms or anything. Just using some libraries or packages, you did something amazing. Like a... chat bot maybe?! I'm not sure. I'm a beginner. 
I don't know if this is amazing, but.... For a meeting, I have to print out a bunch of documents that people send me. Some of them are Word docs, some are pdfs, etc. I wrote a program that would put a common page number across all the documents so we could refer to "meeting page #5" and everyone would get the right document. The way I did it is kind of stupid, but: 1. convert each document to pdf, if it isn't already 2. convert each pdf into a series of images 3. overlay a "page number X" at a specified location on each image 4. convert the entire pile of images back into a single pdf 5. print It's really a combination of Python and ImageMagick.
I think you need to manually iterate over the groupby's iterator, I had to do something similar. Basically: Sort your data frame by Person and col2, do the groupby Person and col2, and assign that to an iterator variable like group_iter. group_iter = mydf.sort_values(stuff).groupby(things) for k in group_iter.groups.keys() : #to process each group _stuff_to_delete = [] _g = group_iter.get_group(k) #grab the group _iter = _g[whatever].iterrows() # grab the group iterator _rowkey,_row = _iter.__next__() #grab the first row in the group while _row['col2'] != True: _stuff_to_delete.append(_rowkey) _rowkey,_row = _iter.__next__() mydf = mydf.drop(_stuff_to_delete, axis) Just spitballing this mostly from memory, I'm sure there's a better approach. 
What can I talk about in Italian? I want to know before I learn Italian.
Today data science experts have an extremely wide range of various tools available which they can use to cope with literally any issue they might face. However, there are two programming languages, which are commonly acknowledged as the best tools for [data science projects: R and Python.](https://db-devs.com/blog/archive/data-science-r-vs-python/) 
I never pick the guides that claim so badly to be "easy", "in x days" and such anyway.
NICE! I had some things I wanted to do with images and documents. Will check out ImageMagick.
I have some scripts to automate the management of a small cryptocurrency mining setup I have.
I meant that you don't need to know these details to write good Python code. Sorry.
Writing a script to scrape some stats (team names, shots, goals, etc) from all regular season games from the NHL 2017-2018 season using the BeautifulSoup library. Plan on using this data to do some statistical analyses on the season using pandas. For example, I’m testing the claim I once heard, “the team that outshoots their opponent is more likely to lose.” I’ve only been programming for about 9 months now and this is my first solo project so I’m basically teaching myself how to utilize these modules as I go. Things are going well so far but I have a ways to go (particularly in writing smoother, more organized code.). If you have any suggestions for someone new to using python to deal with data such as this, please shoot me a message!
I have a Bluetooth light bulb, I found a library for controlling it in python...pretty soon I was voice controlling the lamp. If you said "it's the police" it would cycle red and blue like a police siren with NWA Fuck the police playing. I made other triggers like "romantic". It was really easy to be honest.
Good bot!
Thank you, AGausmann, for voting on GitHubPermalinkBot. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://goodbot-badbot.herokuapp.com/). *** ^^Even ^^if ^^I ^^don't ^^reply ^^to ^^your ^^comment, ^^I'm ^^still ^^listening ^^for ^^votes. ^^Check ^^the ^^webpage ^^to ^^see ^^if ^^your ^^vote ^^registered!
Well the first thing you have to do if you want to improve performance, is gather baseline metrics. If you don't do this step, you have nothing to compare against post-optimizations. Additionally, profiling your existing solution will highlight the (relatively) slower functions and help point you at the right place to start working on performance optimization. Regardless, it's usually best to leave performance tuning till after you have a working application/script, and hopefully after you have some test cases written and passing. This way you can optimize with greater confidence. 
So disappointed. This is not football. This is soccer.
I don't get what you're trying to tell. The example is unclear and why execute it a 100 times? I'm curious for the subject and results, but this article doesn't deliver.
Nice work. I would add a .gitignore file to ignore __pycache__
That's... amazing! Can you tell me how you did it or what library you used, if that's not a problem?!
Working on my parser [Lark](https://github.com/lark-parser/lark), getting ready for the 0.6.0 release, and also working towards an Earley implementation with full SPPF support. Basically, that means it will be much more efficient with handling ambiguity than it is now, and therefore easier for beginners to write performant grammars.
It doesn't execute 100 times, it's processing 100 HTTP requests. Flask is a web framework, so I started a builtin web server and sent 100 page requests. ./python -m flask run ab -n 100 http://127.0.0.1:5000/
Creating APIs is helpful for some projects. 
Thank you :) the music played from my laptop or device running the python script. The library was called beewi.py I modified my script calling it jbeewi.
I'll definitely add an option to choose the sport. By the way, it's football! Don't downvote the guy, people! 🤣
Agreed. Don't let the handegg-people get to you!
Q1. Do you want to keep the first two rows where no `'col2'` is `True`? Q2. Another issue with your description: &gt; for example PERSON_ID = 2 has a True in it's second row it is actually the third row. Q3. Do you want to keep the row where `'col2'` is the last `True`?
In Sweden, the police decided to stop offering drop-in meetings to create new passports. And I was in _desperate_ need of a new passport. Instead you have to use their new booking service online to book a time for new passport. But they severly underestimated the need and the all free slots got taken imidiately resulting in 4-5 months long queue. The problem was highlighted in Swedish TV and newspapers that it was now practically impossible to get a new passport. And I really did not want to cancel the expensive flight I had already booked! The police promised to put in extra staff and said that they will randomly add some new slots on some random days over the next weeks (to indicate that they are "trying" fix the problem). Then I realized Python was the hero I needed to beat the system. I made a script using a project named pypeteer to navigate the javascript app the booking system was made of. If it found a free slot it would send me an email. I left i running on my computer, polling the system every minute. Sure enough, two days later, early in the morning, i got a email, immediately booked the slot before anyone else and BAM! Problem solved! Phu!
Thanks for your contribution to the Poetry ecosystem! A quick question: `poetry build` generates setup.py,l; does your tool generate the same file? 
`poetry build` creates sdist and wheel, not setup.py. Poetry can't makes setup.py. Poetry-setup creates setup.py and requirements.txt
Thanks for the correction! Great tool!
I have a keyboard for which certain keys aren't supported on linux (raspbian, specifically). I wrote a simple script that waits for those keys to be pressed and does a customized action (showing desktop, powering off, pausing/playing video, etc.)
It is football !
You can skip checking sys.path by utilizing Python's \`imp\` package: [https://docs.python.org/3.7/library/imp.html](https://docs.python.org/3.7/library/imp.html) Additionally, you can ensure that your package directory has write permissions for creating \_\_pycache\_\_, and lastly consider importing particular modules from pandas instead of the implicit \*.
How slow are your disks?
Cpu cycle wastage, but it serve a flexible purpose compared to useless crypto currency hashing that sole purpose is to gain money with nothing intellectual to exchange or keep
Nice! I would also add doc-string explanations to your functions 
I don't know what the `fig, ax =` line is supposed to do. Try `plt.figure(figsize=(8, 6))` instead.
instead of the massive if/elif/else why not do something like answers = ["it is certain","my sources say yes",...] print(answers[random.randint(0,len(answers))]
Nice. But I had come to understand the future was setup.*py-less? I'm confused.
Don't really know, and I don't control those! It's a high end Xeon server with 64 cpus, I'm guessing they are using some variation of ssd!
Sorry. You're wrong. It's soccer. 
Ooh could well do with this for my fantasy league... What's the delay like between the goal being scored and the notification coming through? 
LOL, this is phenomenal. Good job.
I'm actually on python2, but I've tried directly importing pandas using imp module, didn't see a meaningful improvement. Tried importing just the DataFrame from pandas, it shows some improvement. $ time python -c "from pandas import DataFrame" real 0m0.841s user 0m0.941s sys 0m7.547s
You see, it's the most simplest concepts and ideas that I love which makes a big impact! 
Thanks for making me aware of this cool text message API. Seems cool. I might use it
Is the SMS API you use free? Been looking for something suitable but settled with using Slack and getting android push notifications instead 
In future it would be deprecated. Pyproject.toml will be supported by setuptools and pip. But now we have only poetry and flit for modern packaging. 
You can read more about the Python packaging tools in my new article: https://github.com/orsinium/notes/blob/master/notes-en/python-packaging.md I want improve some details before public announce :) 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [orsinium/notes/.../**python-packaging.md** (master → 035d88b)](https://github.com/orsinium/notes/blob/035d88b4439d3e36985709f57370e56186201fe8/notes-en/python-packaging.md) ---- 
Will this relentlessly hammer URL with no delay between polls?
Absolutely. Emphasis on future. Distant future. There are more than enough systems where such backwards compatibility is needed due to older processing methods-- not to mention that Python by itself can't currently use pyproject.toml. The python packaging ecosystem in this way will forever be a mess until backwards compatibility is broken, or a patch is released to 2.7 and the 3.X versions to support the new finalized way. Neither are likely to ever occur. And as always, there is a [relevant xkcd](https://xkcd.com/927/).
To be clear, imp on Python 2.7: [https://docs.python.org/2.7/library/imp.html](https://docs.python.org/2.7/library/imp.html) Have you done any profiling of the import? FWIW, is your env over a remote connection? That is, is the pandas import calling files over the network instead of local filesystem?
Federation International de Football Association.It would have been called Soccer Association otherwise.The game originted in Europe and is originally known as football.You must be an American so I see where the confusion comes from.Take it as a TIL!
10s module load times seem high, that's why i asked.
Let's make the strings into arrays for the sake of notation. s[] is the source. t[] is the target. l is the length of the string. i is the number of iterations. The following rules apply to an odd numbered length of string. t[0] = s[1]. No matter what, that shuffle doesn't move the first char. t[1] = s[1+2**i%l]. t[2] = s[1+2**(i+1)%l]. position 1 gets set to position 2 every iteration so position 2 is whatever 1 would have been if there'd been one more iteration. You'll need to work out an underlying rule so you can calculate the rules for an arbitrary position. I'm not sure how to do that and it sounds like a bunch of work. Also: Even and odd lengths of strings will have different rules.
That's what I was just looking at, I'd love to see this with a requests log! That said, idk what a good scheduling method would be, but maybe have it determine if the team is currently playing or parse a schedule and only run it during game time
Handy reference! Thanks.
10 seconds because it'll send, at max., 6 requests/minute. I could probably lower it to 1 second and it would be OK anyway!
It is. 10 messages/month, with the option to pay for additional messages.
That's done. Thanks!
Even still, you'll want a delay between polls so not to hammer their servers. You'll get your ip firewalled.
Never done anything similar but will look into it! :)
Working on a pluggable framework for debugging some internal systems. The current spec is that I want to be able to run a handful of specific operations against internal systems and have it operate like a debugger. Initially this would spin up a flask server and expose all the actions via a rest endpoint and there would be a companion cli that consumes the rest api. For example setting a “break point” of “if condition T pause and action P if Y and V”. More simply I want to attach to a fire hose of information and when the filter conditions are True use some of that information to execute some actions (some sort of lookup, dump all the gathered info to a file, push it to somewhere, etc). The problem is replacing artisanal shell scripts that everyone writes themselves and are difficult to distribute and maintain. So far I have most of the information gathering functionality built out. I haven’t quite figured out how to structure the debug state class, or generally how that would work. This is the main learning point for me. I’m guessing it’s going to be some form of threading. In go I would just use channels, probably some form of structs and go routines. It would be pretty easy to write this out in go, but I want to see if it’s reasonable to do in python.
Check out r/learnpython
For sure, I'd throw in a time.sleep in the while True to start, esp while testing, but not having it poll 24/7 would be the next step. I think anything within a couple minutes of a goal would be fine? Idk, thats up to personal opinion of course.
No, it's soccer. FIFA is Fédération Internationale de Floppers Association. Football is the sport played mainly in the US. You can tell the difference because football players don't wear kiddy shorts and flop down on the field like a little snowflake if someone touches them.
Okay, thanks.
&gt; It would have been called Soccer Association otherwise Association Football Assoc. Football Socc-er (cf. ['rugger' for rugby](https://en.wikipedia.org/wiki/Oxford_%22-er%22)) "Soccer association" is not just wrong, but redundant.
I'd like to thank everyone who commented this comment for the feedback. I'll look into functional/smart ways to prevent hammering SportingLife's servers!
Thanks for the words! :) 
This one has a big bug. It will send only one message after first goal. This is because your code performs call to `ScrapeGoals()` only once (at the beginning of the `app.py`). And then it'll step into endless loop without any useful work. Advices: For parsing html you can use xpath or BeautifulSoup. It is easier and less error-prone. Also placing your source code into separate folder is nice practice. Also you probably should add error handling to your files. And please add timeout to your while True loop. This one will definitely eat your CPU and traffic. Add more flexibility. This app is very hardcoded. Also that conditional pieces # app.py if smth: pass are not needed. They redundant. Will txtlocal work with any non-UK phone number? Btw hope you had great experience creating this.
I'm going to ask once more. **What is your code not doing now, that you want it to do?** You're obviously not going to be able to visualise 8 dimensions. Check the coordinates of your cluster centers - if they have the right number of dimensions, you're fine.
Author of poetry here! Actually poetry generates a `setup.py` file in the sdist to keep backwards compatibility. So you can use the appropriate method to generate your own `setup.py`.
 Which source are you using for learning python? Exams just finished,hoping to learn a new language....
I'm working on fixing that bug. Yes, it works with any number. You can check it by yourself using an online disposable phone#.
I just learned the syntax from [Learn X in Y minutes](https://learnxinyminutes.com/docs/python3/). After that, it was just a matter of coming up with interesting projects and Googling a lot! :)
Nah, op's syntax is doing the same as yours, just with the addition of defining the variable `ax` attached to the current Axis. Your suggestion is still usable with op's syntax though. Additionally, there's a method to do that as a separate statement: ``` fig.set_size_inches(...) ```
Do(all the things)
I don't understand why all the @Home projects don't back a single crypto that is generated off the work you do. That at least has some intrinsic value as you're helping further science. 
Thank you! Maybe I will use it in future releases.
the term 'football' came about to describe a sport where the players do not ride a horse. there are many variations of football, the most popular being association football (soccer), rugby football, and gridiron football (american football)
Do what "big boys" have been doing for a while: SaaS (software as a service). Write a tiny dumb client, that communicates to your code via some grotesque HTTP RPC API, and hide your code on your server. Trust me, in most cases the "big boys'" code on the server isn't of a better quality than yours. That's how GMail functions for example, or Facebook etc.
I don't know about the etymology, but you are correct that in football, the players don't ride a horse. I don't think they ride horses in floppball or soccer, either. But it's not football.
k
It's a general purpose programming language, so pretty much all of it. Whether it's a good idea to write something in Python is a different question.
Did you look into Ansible? I think writing installations of this kind is one of its stated goals. Other than that, your solution might be very platform-dependent: what OS are you running on? How savvy are the users? What kind of permissions they have on their laptops? Are the users interested in your application, or is it some sort of enforcement they'd rather avoid?
No problem. Glad to help.
Anything you can do in a programming language you can do in Python. We could get into things Python does better or worse than other programming languages, but as a beginner you shouldn't be worried about it. Most programming languages are similar in how they work, so if you know core programming concepts in one language, you can easily transfer those concepts to another. So you shouldn't worry about which language to learn, because once you learn one you can more easily learn more. So the real question is what language should you learn *first*, and really Python is one of the best options out there. It has really easy syntax and a ridiculous amount of online learning resources for people of all skill levels, which are basically the only 2 things you should be looking for in a language right now. So yeah, go Python all the way. 
you can use to start something like for char in symbols: var1.find(char) and work with that..also you can use regex but that's a bit more complicated.
I had no idea that site existed. Python is nice isn't it.
https://news.ycombinator.com/item?id=17155048
You got a Github star from me here in NYC. Well done. I like this. You are pulling the scoring data from a free, public API? 
Thanks a lot, FunPlan! I really appreciate the support. :) I wish I could do that right off the bat, but I haven't digged deep enough into how to create my own APIs — but I will surely start looking into that! 
It really is! :)
I did, it all on a locally mounted drive!
I see not as a problem to recommend some course. Of course you think that you are very honest so you go to people posts and filling them with your hypocrisy. I share video with free tutorial, someone write it's spam, someone recommend something else, other hypocrite again write. 
For those who maybe interested found the presentation, DMTCP ([https://github.com/dmtcp/dmtcp](https://github.com/dmtcp/dmtcp)): [https://www.youtube.com/watch?v=1l\_wGZz0JEE](https://www.youtube.com/watch?v=1l_wGZz0JEE) Just tried it out, interesting tool, actually worked for some stuff. Doesn't work for me anyways, seem to for library I'm trying to load, apparently it establishes some messaging connection. And I get this error. Oh well it was worth a try! Thanks for reading... &gt;Message: Datagram Sockets not supported. Hopefully, this is a short lived connection!
Remarkable: https://github.com/nucleic/enaml/issues/276 packages maintenaners prefer not to notice and pretend nothing happen.
Python can't really make apps for the most part - you wouldn't make a browser, or a game, or really any user-oriented software in python.
Why not?
You generally wouldn't make a game or a browser in Python but you *CAN*.
Mostly because Python is interpreted, and thus pretty slow. You don't see people making apps in Ruby or PHP or R. I admit Javascript is an exception here, but it took years and it was special in this context because it was designed around building user interfaces. Because it's slow and thus not great for apps the infrastructure around building them doesn't really exist. If you want to build an app, all you have is stuff like GTK which isn't great. Maybe I'm wrong on this, as I never really made an attempt with python.
Two of the top five (maybe three) websites you visit everyday are written in Python.
Well, I wouldn't make enterprise grade desktop app or some AAA game in Python. But I think PyQt is viabale, what alternatives are there? Electron, JavaFX? C++/Qt would probably be better, but would take much more development time.
Yeah I mean you can but you'd have to do these things from scratch. You certainly couldn't do it as a beginner in the way you could in e.g. Swift. As far as I understand it, there isn't really an infrastructure and libraries built around making GUIs in Python in the way there is around making them in C or C++. Also, there are e.g. no great GPU bindings for Python. All this is because Python is slow and thus people don't really have a good reason to program those apps in Python.
May I ask what resources you used to get this far?
As in learning resources?
Yes. 
I just learned the syntax from [Learn X in Y minutes](https://learnxinyminutes.com/docs/python3/). After that, it was just a matter of coming up with interesting projects and Googling a lot! :) I think this process applies to everything you learn in life, to be quite frank. When you learn a new language (say, Portuguese), you need to practise; and how do you practise it? You speak, you write, you read about things you like. It's the same thing with programming — nail the syntax and try to complete tasks/finish projects that you are interested in. **Never** be afraid to Google how to do something you don't know, and take your time to learn why things are done in a certain way. You can spend your life programming and you still won't know how to do everything — Google and documentation pages are your friend! :)
Mamma Mia
You can also tell the difference between American football where on average there is only 11 minutes of action vs Soccer with about 58 minutes of action.
Why the downvote? Americans don’t really watch or care for soccer. It’s misleading title for Americans 
Cool app. But I’m disheartened by the fact that you’re creating something like this after only 3 months of python? Did you program prior to python?
This post is better suited for r/learnpython 
This post is better suited for r/learnpython 
This post is better suited for r/learnpython 
I've made some improvements to your code: for page_url in page_urls: page_num += 1 page_data = get_page_data_from_web(page_url) save_image(folder, str(page_num).zfill(3), page_data) #make_pdf_from_images(folder) With the leading zeros, the pdf isn't messing with pages order (1.10.11.12\[...\][2.21.22.23](https://2.21.22.23)) Then I've added this bloc to take the pictures and create the pdf : def traitement(folder): path = "./comics/"+os.path.basename(folder) print (path) dirs = os.listdir(path) for dir in dirs : #print("dir= "+dir) comicname = dir+".pdf" #print ("comicname= "+comicname) dircomplete = path+"/"+dir #print ("dircomplete= "+dircomplete) pictures = os.listdir(dircomplete) picturespath = [path+"/"+dir+"/"+x for x in pictures] print(picturespath) try: with open(path+"/"+comicname,"wb") as f: f.write(img2pdf.convert(picturespath)) except Exception: pass 
Hey man, thanks for the words. Back in the days, I used to script in Pawn, the language used by the SA:MP mod, but didn't do much to be honest, therefore I consider this to be my first programming experience.
Because, in general, what people care about is consistency, not specific stylistic choices. . 
I’ve had this problem in the past, and I blame it on PEP8. PEP8 says that module imports should be defined at the top of the file. This means that if you load pandas, or most likely your module, every single module and dependencies for all code will be loaded, regardless if you use it or not. For something like Pandas, scipy, etc, this is an absurd amount of unused code. You can usually cut the load time to a fraction of you lazy import the modules, or import within functions as needed (this is fine as long as it’s not a tight loop). At the last company I worked at, our command line tools were taking 5 seconds to load, for something as silly as “print the serial number of this thing”. I was able to get this down to ~1 second with lazy imports alone. Also, make sure the pyc are being generated, otherwise python will have to reparse text files every time.
Placing different parts of the code into different files (modules) and directories (packages). The MVC pattern is used for UIs and places different aspects of the UI into to different packages. Also, within one of those packages will be the application logic - which will consist of subpackage and/or submodules. These submodules and subpackages can be split in terms of their function - like network, authentication, database etc. In OOP it's referred to as "cohesiveness" (worth a look).
Can you please follow naming conventions? Preferably use underscores for function (and variable) names, maybe camel case. But never capitalised, unless it is a class.
What your program does: * downloads https://www.sportinglife.com/football/live/vidiprinter * if the team is not found, will loop forever in scrapegoals.py while True: * if it finds your team as the first entry AND it goals, tries to send SMS about it every 60 seconds until you close the program So your program happens to work only when the team you are interested in goals right before you start the program and appears as the first entry in that website you are scraping from. 
Dude, great Idea! XD If you are into watson libraries you could use its Speech to Text and Text to Speech and NLU. It would help a lot too. Congrats man!
Ciao, mondo!
The title is not directly addressed? In one you bench part of the repl, in the other you bench flask. You never bench the interpreter in its normal mode of operation. IMO, as well, # of objects created/destroyed is not useful. What is useful is, say, # cycles "wasted" (or time) and memory consumption.
Have you looked at the pushover api? Its a nice way to push data to my phone without the limits of txts. 
Pep-257
👍
I didn't know about that! Thanks!
Yes. The second version because of the point you stated. 
I've been doing python for 7 months and my projects aren't nearly this cool or organized :(.
Statistics for an empty script with only `sys` imported: Type str, allocs: 10990, deallocs: 5860, max: 5130, alive: 5130 Type tuple, allocs: 5575, deallocs: 3038, max: 2537, alive: 2537 Type frame, allocs: 3018, deallocs: 3017, max: 28, alive: 1 Type int, allocs: 2255, deallocs: 1607, max: 648, alive: 648 Type bytes, allocs: 1660, deallocs: 503, max: 1197, alive: 1157 Type builtin_function_or_method, allocs: 1207, deallocs: 662, max: 548, alive: 545 Type dict, allocs: 1069, deallocs: 526, max: 550, alive: 543 Type function, allocs: 934, deallocs: 417, max: 519, alive: 517 Type wrapper_descriptor, allocs: 916, deallocs: 5, max: 911, alive: 911 Type method, allocs: 692, deallocs: 691, max: 10, alive: 1 Type code, allocs: 663, deallocs: 125, max: 560, alive: 538 Type method_descriptor, allocs: 581, deallocs: 0, max: 581, alive: 581 Type list, allocs: 563, deallocs: 522, max: 45, alive: 41 Type weakref, allocs: 415, deallocs: 56, max: 360, alive: 359 Type float, allocs: 360, deallocs: 345, max: 20, alive: 15 
I'm sure this project is full of bugs, but we learn as go along the way. You learn by making mistakes and looking at other people's code. Don't be afraid to experiment with ideas and challenge yourself everyday, /u/spacebro550. Keep at it!
As long as you're not using quoted names it's not case sensitive. 
gestures irately with hands.
Is there a reason that the FileProcessor constructor has no argument (not even a path), while the load\_configuration and process\_file have the same arguments; that can't be right can it?
Certainly. Will look into fixing that. Thanks for the feedback! :)
&gt; misleading title 😕
How did you achieve that speed? I mean, what kind of particular problems does sanic has?
[https://github.com/channelcat/sanic/issues/1176](https://github.com/channelcat/sanic/issues/1176)
That’s called the NBA
As other's have said there are a couple of little bugs but that's ok. One thing I want add is that sometimes requests fail and return a faulty status code so it's good practice to get your r response object and just check try: r.raise_for_status() except requests.HTTPError: continue Or something to avoid crashes when reading the json
What about if the enemy team scores!? Can you imagine being all excited cause your team keeps scoring, but then you end up losing anyways!? BUMMER!
Beautiful work!
 from time import sleep then use this in your loop. sleep(time_in_seconds) 
I was skeptical about the benchmarks until I saw that a large part of the framework is written in Cython. Great job dude, looking forward to seeing how this project develops. 
Thanks!
How frequently does the data source update in any meaningful way? This is more important to scaling than language or platform choice.
Nim! Nim! Nim!
That's interesting, I do hate these conventions sometimes. Sort reminds me of c++, extra rules to make code fit conventions resulted in monstrosity. Kinda like python, cause they seem to trust the developer more. I ended up loading these libs in the background thread, so its kinda lazy, this way my server starts up 40 seconds sooner, takes that long to import a 400mb internal library. import threading def preload_libs(): import numpy import pandas threading.Thread(target=preload_libs).start()
Each function will have various, separate arguments and there are arguments for the constructor as well -- I just left them out for brevity. Edited the post for clarity. 
That's a perfectly valid response though. In all of this you may have misunderstood me somewhat; as I've been saying from the beginning, you're most likely far too concerned with trying to protect the users of your project from what you call GPL "infection". I've no idea why enaml includes PyQt as a *requires* in its setup.py, except that perhaps it makes it easier for them to test their own code, but including that dependency *does not* implicate the GPL. It *would* be nicer of them to use *extra_requires*, and to save concerns like yours they *should* do so -- since their project isn't meant to force anyone to use PyQt at all, and indeed provides a means to bypass doing so -- but for reasons I'll get to below there's no problem with them not doing so. The enaml project is BSD Modified, but as far as I can tell enaml doesn't directly use PyQt at any point, it merely delegates everything to qtpy, which acts as the actual abstraction layer. So we pass the first test, there is no use of GPL code. There's also no copy of the PyQt source anywhere in the enaml source tree, so there's no distribution. No use + no distribution == no GPL implication or involvement. The qtpy abstraction layer, in turn, is MIT licensed. It doesn't require PyQt, but it does use it if present on the system. That is fine, given the Riverbank exception, and the MIT license is appropriate. So use, but use allowed by the exception. Again no copy of the PyQt source, so no distribution. Excepted use + no distribution == no GPL implication or involvement. The enaml project, at this point, is a derivative work of an MIT licensed project. The chain to the GPL has effectively been broken, because of a valid use of the Riverbank exception to the GPL that allows that licensing to occur. Now, the setup.py *does* make it so that pip will automatically download and install PyQt on your machine, if it's not already present. But that's fine; you -- and your downstream users -- could have just as easily manually installed it, and indeed Riverbank makes it available for you to download and install at any time... when pip installs it for you you're ultimately receiving Riverbank's own distribution of the source code, not someone else's, so the GPL still hasn't "infected" anything. Now, if you release code that uses enaml (and therefore qtpy)'s properly licensed functionality, and *do not* in your own code either a) import and use PyQt directly or b) distribute a copy of PyQt with your source (ie via vendoring or in a bundled exe via something like PyInstaller or CX_Freeze), then you're fine, and so are your downstream users (assuming they follow the same behavior), because without directly involving the GPL-licensed code your work is a derivative of enaml, which is a derivative of qtpy, which is MIT licensed via the exception. At any point anyone wishing to work without PyQt need merely set the QT_API environment variable, or (post installation) force uninstall PyQt. That's not hugely convenient for someone making a frozen distribution or wanting to vendor their dependencies, but it's not entirely wrong, nor is it entirely their problem of their user is a little too concerned with the GPL. Now, if Riverbank had not created the exception (which seems to mainly exist to maintain Riverbank's rights to get any FOSS improvements made on top of PyQt back for upstream incorporation), then qtpy would be GPL, and thus so would enaml, and thus your code. That would seem to violate the spirit of the copyleft provisions of the GPL, but part of that spirit includes the freedom to explicitly add or create such exceptions for code you own.
I actually finagled my way through it. Took it one error at a time, made changes, retried, and eventually it is doing exactly what I needed. But next time, I will ask there though.
Are you referring to this? https://github.com/nim-lang/Nim/wiki/Nim-for-Python-Programmers If so, are you serious?
Yes. 58 minutes of action consisting of 13 minutes of running back and forth across the field and forty five minutes of flopping on the ground with a boo boo. 
It is about an indirect measure of "waste" (a corollary of performance), no? If python allocates 20,000 objects on startup, do I care? Well, the only reason I would care is if: (1) these slow my program down (2) these increase memory usage.
I found this one https://i.imgur.com/kpfKSui.png
[This](https://perso.limsi.fr/pointal/python:memento) is one of the best Python cheat sheets for beginners. 
Exactly *because* it is less configurable.
Try https://datasette.readthedocs.io/en/stable/
Location: doesn't matter I'm looking for someone capable of realizing a little script to make a gif (with Pillow maybe?) from a .txt file containing a list of 3D coordinates of a Voxel-like object: B(-2,-3,0,DIRT) B(-2,-2,0,LOG) B(2,-3,0,GRASS) B(2,-4,0,DIRT:2) B(-2,-1,0,LOG) (x,y,z,image\_filename), I will provide isometric images for each block already.
Like that it is non-configurable. Like the use of " vs. ' for string quoting. I can tolerate how it puts more parameters on a line than I normally like. Ends the formatting discussions. Code is very consistent. Compares the AST pre/post formatting so my trust level of the re-formatted code is increased (don't believe YAPF does that).
Well shit, that's interesting. I'd be curious to see this. Might try to port it over to fish...
Never thought about that before. It does help! 
Probably monthly, or weekly at most. Thanks!
Consider an embedded data source like solr.
 dic = {k: [v[1] for v in data if v[0] == k] for k in {a[0] for a in data}}
Awesome, will check it out!
If you think this is a lot after 3 months you need to rethink your strategy. Think of a simple project and just do it, youll be shocked at how simple python makes a ton of stufd
Will check out solr, thank you!
My team made https://github.com/baltimore-sun-data/salaries-datasette with datasette, but that was before the plugin feature was added, so we only scratched the surface. 
I’ve been learning python for several months already but haven’t made an app like this yet. But I have learned how to webscrape using beautifulsoup and Selenium, using pandas and seaborn to import data. I feel like I’m shotgunning and learning all the different stuff within python. Then I ventured into Django and learned how to make a simple static webpage but nothing dynamic yet. Kinda frustrated at this point 
does it support other regional phone numbers?
I think youre overestimating the complexity of OPs program. Hes just sending a sports site score requests for a given team then using an SMS api to text when it changes. Its not the programming thats hard, its comming up with fun ideas.
Hey, Metabyte2, just a quick heads-up: **comming** is actually spelled **coming**. You can remember it by **one m**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
Hey [u/Metabyte2](https://reddit.com/u/Metabyte2), it's perfectly okay to misspell things. I *actually* hope that you have a nice day. ***** I am a bot.
What the...bot talking to bot...
It should support any phone number :)
Same boat I just enrolled into Cody Academy pro course. It's a 3 month program designed for beginners. 
Great, now I have to choose between insane performance and an entire ecosystem of Flask projects. Seriously, though, excellent work. I'm thrilled to see a web framework leveraging the power of Cython.
You probably could have reported this and received a CVE.
 from collections import defaultdict def solution(input_data): result = defaultdict(list) for k, v in input_data: result[k].append(v) return result def solution_2(input_data): result = {} for k, v in input_data: try: result[k].append(v) except KeyError: result[k] = [v] return result if __name__ == '__main__': data = ((1, 'a'), (1, 'b'), (1, 'c'), (2, 'ad'), (2, 'ab'), (2, 'bc'), (2, 'cd'), (2, 'de')) correct = {1: ['a', 'b', 'c'], 2: ['ad', 'ab', 'bc', 'cd', 'de']} assert solution(data) == correct assert solution_2(data) == correct 
Machine learning is independent of Python. Start researching it and you’ll see how it is done. Plenty of guides. Check out Sentdex on youtube for some great tutorials of ML in Python
r/learnpython
Working on my new SaaS project [Scraper API](https://www.scraperapi.com), it's a tool that handles proxies, browsers, CAPTCHAs, and all the annoying stuff that you have to use to scrape popular websites. Just got my first paying users last week, so I'm really excited about that :).
I thought when I saw “static type” that you meant a python alternative. You can set data types for panda DataFrames. But yes, I was serious. Nim looks great and has a data frame like capability. It may be worth a look. 
u/delirious_lettuce is on point. You'll also likely want to check out r/learnpython.
You don't need very much python programming knowledge if you are planning on using scikit-lewrn or tensor flow. Most of the coding will be used for data cleaning. Pretty basic code tbh.
 out = {} for a, b in data: out.setdefault(a, []).append(b)
Don't be frustrated man! I was where you were a long time back. Take an hour to really grasp what you have learnt, and what you can do with that learning. Think of it this way - You learn bs4 and selenium to scrape some content off the website (data retrieval) Use pandas to clean and store the data that you have. Think of how this data can be useful to people. Implement an app - in Django or Flask, that uses this data in a meaningful way. The more number of times you take this path, you will understand many ways of data retrieval - APIs, Datasets, scraping, many ways to clean and store data, and more ways to present using that data. Use google as much as possible. If you feel like stuff is too hard to understand, spend some time in the discussion forums of these languages/frameworks. An interest to find and solve a problem will exponentially increase your knowledge in the matter, compared to watching countless YouTube videos. That being said, watch the videos, and build alongside. There is no way anyone can possibly build any application to its completion after watch a set of youtube videos. You WILL refer to resources a many times before it becomes second nature to you. It's that never-give-up attitude that makes someone a good developer.
Well, I'm a Browns fan, so can you just make it fire randomly once in a while?
To expand beyond simple sleep calls you may want to consider longer term functionality. As in, how might you scale this? One thing to look at could be scheduling libraries such as 'schedule': https://schedule.readthedocs.io/en/stable/ Nice work!
Impressive work! Are you looking for contributors?
Yes. The framework is still pending a lot of fixes/features and the reason I made this post was to gather some feedback and maybe a few fellows to help me :)
There is still a big room for Cython in Vibora, only a few hot pieces of it are implemented with Cython... The framework is still young and pending a lot of stuff but thanks to the feedback I'll keep going and improve it :)
When you call plot() the interpreter has to know which plot function you meant. So it looks for functions you have defined in the script and if it doesn’t find it, it looks through the modules you have loaded so far. If you haven’t loaded the matplotlib module, and you haven’t provided a definition for it, python doesn’t know how to execute the function called plot. 
Looks pretty neat, will definitely keep an eye on this. When I think of 'super fast python framework' I think of Japronto; could you add Japronto to the framework benchmark comparisons? 
Cool! sent you a pm
This is a typo bot more than anything else.
How come her's worked without importing it? Anaconda does have matplotlib.
Dude you are embarrassing yourself
I think [this article](http://www.diveintopython.net/power_of_introspection/and_or.html) explains it well. 
I don't know a ton about python, but I'm assuming it's because of the way 1 is interpreted. 0s are considered false and 1s are true, so when applying the boolean logic, the outputs would make sense. Hope that helps!
You can create your own API using django and DRF. Its pretty simple 
Thanks! Vibora is a performance focused framework but it's not throwing everything out of the window just to be fast... Japronto is kinda doing this and I really doubt it to get stable without sacrificing a good chunk of performance... (sanic/japronto for example violates the HTTP protocol by not sending the Date http header)... Anyway I'll add more frameworks (apistar and quart also come to my mind) as people wish... it's just that's time-consuming to add every test for every framework... I need time or pull-requests :D
You're a flopper. 
&gt; If you said "it's the police" it would cycle red and blue like a police siren with NWA Fuck the police playing. Oh man I love how much this could blow up in your face if the police ever really do show up at your door step. 
I've been using Flask for 4 years now and it's great that people are coming out with faster frameworks. Hopefully it will be a success. Good luck.
Because you have called `plt.scatter` before creating a figure, it seems that it automatically creates a figure. You then later call `plt.subplots` which creates a new figure. The solution is to move this line: `fig, ax = plt.subplots(figsize=(8,6))` to the top of the script. It may also interest you to know that matplotlib has two different philosophies. I'm happy for someone to correct me, but my understanding is they have one which mimics MatLab's plotting tools, and one that is object oriented (more pythonic). This makes it very confusing when getting started with matplotlib, but being aware of it could be helpful. In your example you have mixed the philosophies. If you'd like examples, see this [Sections 1 &amp; 2 here](https://jakevdp.github.io/mpl_tutorial/index.html). ## Example 1 # Create canvas plt.figure(figsize=(8,6)) # Visualizing the clusters plt.scatter(Data_Clus.values[y_kmeans == 0, 0], Data_Clus.values[y_kmeans == 0, 1], s = 100, c = 'red', label='Careful(c1)') plt.scatter(Data_Clus.values[y_kmeans == 2, 0], Data_Clus.values[y_kmeans == 2, 1], s = 100, c = 'green', label='Standard(c2)') plt.scatter(Data_Clus.values[y_kmeans == 1, 0], Data_Clus.values[y_kmeans == 1, 1], s = 100, c = 'blue', label='Target(c3)') plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 250, c = 'yellow', label='Centroids') plt.title('Clusters of customer') plt.xlabel('Gross Salary ') plt.ylabel('Customer Age') plt.legend() plt.show() ## Example 2 - object oriented # Create canvas fig, ax = plt.subplots(figsize=(8,6)) # Visualizing the clusters ax.scatter(Data_Clus.values[y_kmeans == 0, 0], Data_Clus.values[y_kmeans == 0, 1], s = 100, c = 'red', label='Careful(c1)') ax.scatter(Data_Clus.values[y_kmeans == 2, 0], Data_Clus.values[y_kmeans == 2, 1], s = 100, c = 'green', label='Standard(c2)') ax.scatter(Data_Clus.values[y_kmeans == 1, 0], Data_Clus.values[y_kmeans == 1, 1], s = 100, c = 'blue', label='Target(c3)') ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 250, c = 'yellow', label='Centroids') ax.set(title='Clusters of customer', xlabel='Gross Salary', ylabel='Customer Age',) ax.legend() plt.show()
Thanks!
Thanks!
The idea is not only be fast but provide a good chunk of features, hopefully I'll get there. Many thanks !
Thank you again :) So having the PyQt dependency for package manager is fine because users actually download PyQt package that is provided to them not by you but by Riverbank or Anaconda?
Boo boo better than that TBI and CTE.
Yea thanks. I found I spend more of my time on stack overflow than coding 😂
Step two: book spots as soon as they open, auction them back off for easy profit
Did you compare speed with falcon ([http://falconframework.org/](http://falconframework.org/)) ? if I am not mistake it is wrote on Cython too.
No. No it’s not. 
Completely forgot about it, I'll add it there in the next round (later this week), thanks for the tip!
The way or works is that it is evaluated from left to right returning the actual value of the first thing that evaluates to true in a Boolean sense. So True or 1: True is true so it will return true and not even look at the 1 1 or true : 1 evaluates to true as Boolean so it returns 1 and not look at the true False or 1: False is false so it evaluates the 1 which evaluates to true so it will return 1 You can guess the rest 
We just published the next installment of our beginners series on Real [Python](https://plus.google.com/collection/sWgEWE). If you're new to learning python I think this will help you get a head start on your learning.
Hi, can you please compare with bottle, web.py and cherrypy too ? Thanks. 
&gt; [ ] Deploy the project on GitHub pages and allow more people to use this without having to install Python on their machine. How are you planning to do this? Sounds fun!
\+1 for Falcon comparison, was about to ask the same!
Yes, please open issues so I can keep up with framework requests... Thanks for the feedback.
Vibora? Nice name. Are you from Brazil?
This post is better suited for r/learnpython 
This might be borderline illegal.
Yes. And I bet that you are too because you're the first one who says it. 3 folks already said they dislike the name because it has a weird pronounce in English hahaha
Unfortunately, I cannot use most of the automating stuff he explains, because in the department I am, we are automating things with scripts.
Both. It's compiled to byte code, which is then interpreted by the runtime. This is very similar to Java and the JVM. Keep in mind that this is also dependent on the implementation. If you run your Python code through PyPy, for example, it's JIT compiled. Python can also be compiled directly to machine code via tools like Cython or Nuitka. 
Haha great to see those nice projects coming from br folks. Take a look at bruno rochas dynaconf as well! Good luck there. I tweeted the project and showed to a few friends. I know Cython so maybe I can take a look after, but I know very little about async or network flow.
I only wish I had more downvotes to give
Just saw dynaconf, pretty interesting, I may add an extension later. Many thanks!
Yes.
Thanks a lot for the answer. As being a novice I would like to know sources to learn about things that you have just mentioned. 
Not familiar with it, but I remember hearing about [vyper](https://github.com/ethereum/vyper) before. You might want to start looking there.
Python itself is first of all a *language* - this doesn't immediately impose anything on the *implementation*. The default implementation is CPython, which *compiles* the source code into a custom byte code. The latter is then executed by a so called *virtual machine*. In the context of python it is common to name that an *interpreter*. In the context of Java I haven't heard that anytime, even if the JVM, the javac (compiler) and the sources behaves in the same way. Jython is an implementation of python for the JVM - so the byte code after the compilation is a different one than that of CPython. On top of that there are JIT compilers integrated in modern interpreters / vms. So the custom byte code gets compiled into *native* machine code of the platform it runs. This as a whole is very different from the *classical* interpreters! Those acted more or less on the source code and literally *interpreted* the program based upon the source code without much abstraction (the old basics often saved the command keywords as tokens, but that was the whole different to the typed source code) So I am no expert but there are two facts: # Python in every implementation I know of gets *compiled* into byte code # The byte code is executed by some runtime If the latter can be called *interpreter* then both is true: python gets compiled and interpreted. But then every language running on a VM can be called interpreted... I never heard this for Java or C#! 
Your seria and instatwat replies helped me a lot in landing my first gig for which I feel indebted.
Making projects like these are a matter of taking the jump. It is hard to get yourself into the mindset of actually making the project. There is non-programming skill of project designing that isn't taught and the only way to learn it is by trying it. If you would like, post an idea you've had for a project and I'll see if I can give you some direction.
Cool! I would suggest avoiding the Django path of having everything packed all together. Making vibora modular would allow us to have api servers without loading template/orm dependencies carried on.. This simplifies deployment a lot.
I fell in love with black because it doesn't allow configuration (except for --line-length and -S, but I wish those two didn't exist). I don't necessarily agree with all the choices in black, but I like not having to discuss it ever again.
Sure! I share the same feelings.
Yes, I understand, thank you for clarification. On the one hand - modular architecture is very good idea, but on the other hand - the script in one file also has advantages. Some system administrators may not want to install the package from the pip, but simply execute it as an executable file by placing it in home or other specific folder - a lot of files-modules somewhat complicate decision like this. Still, this is not a very complex project, I think it's better to leave everything in a single script file for now.
For CPU intensive tasks, sure. For IO tasks, threads might even be the better choice. Pick the right tool for the job is really what it comes down to.
Django, flask, even python itself is not what govern how your app scales. And by “scales” here I mean being capable of spreading a large work load over multiple servers. What you need for that is the ability to have the app perform independently from where the actual data is stored. If your app is a static website that shows every visitor the same stuff , you only need to create the app and copy it to as many servers as you like. They will all deliver the correct content Now let’s say your app is the new Facebook, with billions of users interacting, you need to make sure each server is accessing the same database so that it wouldn’t matter which server the user is connected too for that specific request. It would still give the user the latest update available in the cluster. In other words the database is the limit not python or its frameworks. luckily there are several options for you to get a database that can grow endlessly without any effort on your part. These are called database as a service (dbaas). Such as amazon Rds, dynamodb, google datastore or cloud sql. You basically get one universal address you can put in your flask or Django app and have the app being limited to pulling data from the database and serving it. This way you can copy your app to many server and the all will behave the same 
Oh that’s great! What happens of code tries to use a library before it’s loaded though?
I think you’re projecting or something. He’s showing interesting numbers, not that they’re wasteful or wrong. They’re not wrong or wasteful because this is a result and requirement of why python is so flexible and easy to use and a trade off we all understand were making when using an interpreted scripting language. 
Does PyPy reduce these numbers?
This is called *short circuiting*. I believe the Python docs explains it just right: https://docs.python.org/3/library/stdtypes.html#boolean-operations-and-or-not This also means that for example if you do this: def function_returning_false(): print('function_returning_false') return False def function_returning_true(): print('function_returning_true') return True function_returning_false() and function_returning_true() You'll see the message *function_returning_false* in the console only because as the `function_returning_false()` function returned a false value the result of the whole expression becomes false, so Python won't even invoke the other function in the expression (`function_returning_true()`)
Japronto was abandoned a long time ago and had unfair benchmarking.
Thanks for the answer! After checking up on Japronto today I hadn't realized it wasn't being actively developed anymore (So no need to add benchmarks - use that time instead to improve Vibora!). Next time I'm looking to build a hobby web app I'll definitely look into this project in more detail.
Vibora sounds pretty good, however I am from the Czech Republic so it really easy to read it for me. And the V python also looks good :) 
Just do something about numerical techniques and maybe highlight some of the really clever shortcuts people use to reduce the computation. It's actually a really fascinating field. 
I know only about [Bandit](https://github.com/PyCQA/bandit), no idea why they stopped working on OWASP tough.
You'd be surprised how many of those Macs run Linux though. Apple makes good hardware, and that's what a lot of developers are after so they typically dual boot osx and Linux. Though a lot do program in a pure osx environment too. 
I dont get it, why you send request to the sms service in every loop ı guess the script sends same message 
Thanks! Good cheatsheet)
Thanks Droider, How'd you make that screen look so smooth as heck?! Would love to know it! 
300.000 req/sec is a number comparable to Go's built-in web server (I'm saying this based on a rough test I made some years ago). Given that Go is designed to do exactly that, this is really impressive. My kudos to your choice to use Cython. You should include other languages high-performance web servers in your benchmark table. 
To be even more honest, most people are just io limited and async is perfectly suitable for them. I've noticed that async alone has been a game changer in terms of general python performance across the board. It's easy gains for no little to no hassle. Big projects like django etc take care of the multiprocessing for me so I don't have to. They even take care of the IO side too. That said, when you have to, a person can play in the muck just fine. 
OP, that link doesn't work for me now, but guessing that you want to build large website which interacts with database, I would do it like this: I would separate frontend and backend, backend would be REST API implemented in flask. As a deployment, I would use uWSGI service which can start several workers (of flask app) and then route requests to the available one. In front of uWSGI I would put nginx webserver. Frontend would be done in some javascript framework like vue.js, and everything will go through Cloudflare CDN. If there will be performance bottleneck, I would probably try to cache some database queries in redis. If that also isn't enough, this whole setup can be replicated to more machines, and then I would put another nginx proxy on top of it to do load-balancing between those machines. If also that wouldn't be enough or impractical to do manually, then one would need to separate the pieces into docker container and auto loadbalance them via something like Kubernetes. **TL;DR: flask+uWSGI+nginx**
I chose the quickest or easiest way and I found a Google speech to text function which I guess isn't the best choice :P
Line length is ok to configure, since it doesn't change how to code looks. I find the default 88 makes the code too narrow, I use 100.
You mean the terminal window i added in the screenshot? Checkout my dotfiles, manjaro branch here https://github.com/deepjyoti30/dotfiles
It is not configurable, because that's the long-term vision, that the code in as much projects as possible will look visually the same - and not in only one individual project. For example, I used to use single parenthesis for dictionary keys and string constants, and double quotes for strings intended to be read by humans. It worked well for me, but I sacrificed it for black's unified style. Also, as others pointed out, the great advantage is that you don't need to think about it anymore. Style will be this, end of discussion, let's move to coding.
My god the docs are really well done, and I'm a beginner and can understand it. Kudos to you sir, bravo.
Yes, that's why I was saying your import check wasn't very useful, the mere presence of PyQt on the machine *does not* mean that the GPL code within it has in any way been incorporated (as far as the license is concerned) in your code. If the user manually installed it, that's permissible use. If installing some other package led to it being installed in the same manner and from the same source as they could have manually installed it, that's permissible use. If the package that has that dependency isn't licensed GPL (as allowed by the Riverbank exception), then using that package in your code is also permissible use. You only "infect" with the GPL if you use the GPL code directly (thereby bypassing the dependency's license and making your code directly dependent on the GPL code) **and/or** create some form of distribution that incorporates a copy of some or all of the GPL code; *most* ways of packaging Python code do not constitute a distribution of the GPL source (since there is no binary linking step, and since vendoring the dependency isn't usually necessary or helpful). This is why trying to block "infection" doesn't work very well... in the specific case you've pointed to there's no "infection" to block, and you couldn't stop your user taking some action that would implicate the GPL in their own code without being able to read their mind. By blocking import of PyQt (without *knowing* that the import isn't perfectly valid use) all you're going to do is make life more difficult for your users, without much appreciable gain. The GPL isn't all that complicated. PyQt has made it slightly more complicated and confusing, but it's done so to ensure that it doesn't "infect" all the FOSS projects that use it unless they choose to cause that via fairly specific actions.
I question why you would use asyncio if you want to go fast, given that asyncio is pretty damn slow compared to something like curio.
LMGTFY...
Exciting! Great job. Did you really make it all in a week (according to GitHub)? :D
 import logging and just deliver a default config that logs to stdout/stderr. This allows the user / admin / operator (whoever configures the deployment) to decide for himself.
asyncio in its current state is pretty heavily geared towards networking. There aren't that many benefits for GUI apps which are already effectively async, at least as long as you're using Qt or GTK and not Tkinter. If you want to execute CPU bound tasks in parallel, `concurrent.futures` is still the way to go.
I second this!
Me too
This looks good! Also, good job on the dos, pretty sexy as well! ;)
Thanks a lot James. It worked and it helped me to understand what I was doing wrong. 
Yeah, you're right, I should have checked the year, completely ignored the last commit was in 2017 and not 2018.
Q
It's not only the deliberate backdoor case. It might just be sloppy handling of inputs which could leave the code open to exploit. I'd never use closed code in prod unless there was some contractual commercial cover on it. There are also analysis tools that can scan sources for vulnerabilities. Much harder to use of there is no source. 
Only if you are containerising your code. If you're writing a cli tool for example logging to file is probably desirable
Why? 
&gt; I've seen a presentation by one guy years ago, where you could basically freeze a process, sort of like windows hibernation but for a process and start of after a point when libraries are already loaded. I recall using fork for this: load modules, then fork. Forked processes inherit memory content and state of the parent.
What is this function documentation format? """ :param template_dirs: :param router_strategy: :param sessions: :param server_name: :param url_scheme: :param static: :param log: :param server_limits: :param route_limits: :param temporary_dir: """ 
&gt; concurrent.futures And also for simple multithreading, I just import ThreadPoolExecutor from concurrent.futures, and the implementation is much simpler as if I have to use asyncio.
&gt; fast Submit it here: https://www.techempower.com/benchmarks/
If you're writing a library, you should just emit log messages (possibly to a NullHandler) and let the application writer configure logging as fits their deployment. If you're writing an application, then your ideal configuration is going to be determined by your deployment situation, not by general trends. And remember, Kubernetes and Lambda-equivalents aren't by a damned sight the *normal* deployment mechanism for code. They're just a couple of stars in the ever evolving constellation. In other words I don't think there's a cohesive and universally or even widely acceptable argument to be made for a grand, industry-wide migration from files to streams or vice versa; the correct answer will differ from domain to domain and deployment strategy to deployment strategy.
https://i.imgur.com/w3PGZQb.png
Probably Sphinx[1]. [1] http://www.sphinx-doc.org/
You can swap out the event loop to use something like [uvloop](https://github.com/MagicStack/uvloop) though.
Great work! This a good idea. I did notice the word "for" missing from your first screenshot in the Readme.md file. I'll give this a go when I'm back on my desktop! 
This isn't quite a fair comparison though. Threads are fine in the great majority of cases where you'd want to use them. Just don't use them when a different thread seizes the GIL and never lets go.
In the traditional meaning the difference between a compiled language and an interpreted language is that in a compiled language source code is converted via a *compiler* and a *linker* (they're often the same program) into a directly executable binary format. If that binary file is *statically linked* -- most languages do not do so my default, as it means duplicating a lot of common code into every executable file -- then that file can run on its own and create whatever effect it creates with no other programs being required to support it. In an interpreted language your source code is parsed by an *interpreter* program into bytecode, which is then run by the interpreter itself. The interpreter is always required to be present in order to run your source code. Python crosses the line a very small amount because whenever you run your program the bytecode is kept and used again on the future (as a .pyc file), to prevent having to do all the parsing again. This is, technically, compilation, but only compilation to the point where the interpreter can run your program, *not* compilation all the way to where the computer itself can directly run your program without the interpreter acting as middle man. So your colleague is somewhat correct, but also somewhat wrong... in the usual case Python is a language compiled only as far as bytecode, and from then Python is interpreted.
I think she has already added matplotlib in her PYTHONPATH. That’s an environmental variable for your computer that registers where you want spyder to look for packages every time you launch spyder. Look at Tools -&gt; Set PYTHONPATH or something. It seems like she skipped a step. 
When you're writing GUI apps, though, best thing is to write to a log file.
You don't have to do them from scratch: PyQt.
Seriously sentdex is the reason I'm programming today. I had just learn the basics through [learn python the hard way](https://learnpythonthehardway.org/) but once I started applying it to real world applications using the sentdex tutorials I became an infinitely better programmer. 
&gt;sanic/japronto for example violates the HTTP protocol by not sending the Date http header Details like this are gold. You should really put it in a notes column next to the performance comparison. Also it's probably worth mentioning that japronto is abandoned there too (I wasn't aware of that and the people who read your readme might not be either).
Going to be working on a Fatigue Calculator for shift workers in the UK (Work / hobby project) hopefully will be picked up / used by some of the largest industries in the UK.. Lets see how it goes I guess.
For one, stdout is the user's way of communicating with the tool. You don't want lthe output cluttered with logging info. If you don't send it to stdout, where would you send it but to some file?
**Beautifier** is a simple library to **cleanup** and **prettify url** patterns, **emails** and so on. Library helps to **clean unicodes**, **special characters** and **unnecessary** **redirection patterns from the urls** and gives you clean date. Now added support for both **python3 and 2**. Thanks
Just looked at the readme and think that the library might be interesting for me since I'm toying around with parsers for a toy project of mine. The EBNF support looks appealing to me here since it's an independent standard and is supported by multiple tools. One thing I noticed is that the comparison table in the readme lacks a comparison with ANTLR and TatSu. Especially ANTLR looks to be a strong contender in the field of your project and I would love to know why I should use Lark over ANTLR.
stderr
I guess, I just think of the "intended use" of those as being different. stderr and stdout would work fine I suppose.
Usually you send the unexpected output (i.e. progress bars, help text that hasn't been explicitly requested, error messages, etc.) to stderr, while the actual output (which can be regular logging messages) go to stdout.
&gt; while the actual output (which can be regular logging messages) go to stdout. Logging usually goes to stderr (in fact that's the default), because logging is not program output but output *about* the program. It's a relaxed version of error messages (in that it's not always *error* messages).
Sure - but for things like daemons, "normal operations" logging goes to stdout - since that's the expected output from the application.
&gt; And remember, Kubernetes and Lambda-equivalents aren't by a damned sight the normal deployment mechanism for code. Indeed. I'd point out that developers running code on their machines is a pretty common form of deployment for your code. And depending upon your use cases it might be i) new developers, or ii) you in 2 years' time when something is on fire. &gt; I don't think there's a cohesive and universally or even widely acceptable argument What's your take on composability, rule of least surprise, discoverability, "convention rather than documentation", and lowering barriers to new developers. Streams seem to have benefits in these regards - all things being equal. Although I could imagine some settings (actor model, clear logical division of logs, log querying) where separate log files make sense - I guess this comes down to "essential complexity". I guess a half-way house for applications is to provide logging options on the command line. This kind of aids discoverability. ------ One of the most annoying things in the world is whole "just give me some damn logging" and "hidden option that would have give you the logging you needed". And I kind of feel that using log files can feed into this. I don't know this is kind of a documentation / step zero problem. There's an argument that goes "just read the damn documentation" / code. But it's all very good saying that when you wrote the documentation! On the other side new developers hate to read. I've actually started thinking about lots of problems llike this through the lens of "library/information science" and to think about lots of problems in programming as problems of *reading* more than anything else. Identifying classes of useful information, interesting subsets of these pieces of information, different views of this information, combining them in useful ways else. 
/r/learnpython
/r/learnpython
Check out r/learnpython
What are they?
Here and YouTube.
Look into Selenium 
Don't worry, skill comes with practice. Most of us sucked at the beginning. Just don't give up and use r/learnpython while seeking help.
Multiple ways to do that: requests, selenium, pyppeteer, etc. Look into those. And maybe try: https://automatetheboringstuff.com/ it is in this sub sidebar, those links are there for a reason. :)
Be prepared for English speakers to pronounce the name /'vɪbɜːrə/
viper, right?
Well, for starters, ANTLR isn't a Python library. It's a generator, which means you'll have to generate the parser separately each time you change the grammar. Also, ANTLR is LL, which means it doesn't fully support left-recursion, unlike Lark. And Lark also fully supports ambiguity. Overall, I think Lark's interface is a bit nicer, but that's rather subjective. If you decide to check both of them out, I'll be happy to hear your opinion as an impartial party.
More like severely illegal 
 Välfärd med pyton!
Thank you. 
You folks at WikiPython should read Reddit's page on self promotion: [here](https://www.reddit.com/wiki/selfpromotion). 
Daemons have neither stdout nor stderr by definition, so that's not very relevant, you can use either, or none.
There’s no such as sick. Keep practicing and reading/absorbing all the knowledge possible. Always. Those who suck are the ones that think they know it all :D
It's a lot faster to write to a file than to print to the screen. It's an easy choice for me.
How is it faster?
Nowadays, you can create amazing things easily using lots of libraries. If you know how to use requests you are good to go with many of them. Take a look here: [https://github.com/abhishekbanthia/Public-APIs](https://github.com/abhishekbanthia/Public-APIs)
It's not faster than writing to the stream itself, it's displaying that stream that takes time. Pipe it to a file (which is what the OP is really talking about, with the mention of Kubernetes and serverless) and it's just disk IO, but disk IO that will automatically be captured while the filesystem you're writing to is ephemeral.
There are many better ways to do deployments with Ubuntu Read about devops practices and technologies. I prefer docker but that’s me 
It might be overkill, depending on your usecase, but you could use a docker container. Install all your dependencies inside the docker container and deploy it on your server. Use one of those images as a starting point: [https://hub.docker.com/\_/python/](https://hub.docker.com/_/python/)
Try writing a loop that appends a billion lines to a file. Now replace that with **print** and time both. Writing to the stream itself isn't any slower, it's the displaying it to terminal that takes a while.
No I haven't worked with APIs at all. Except I used twitter api once. Are all these more of the same in the way they are used? 
How do you split views into multiple files without passing the global app object around? Like Flask blueprints or class based views 
[removed]
Honest question, what the advantage of a Telegram bot over a web page with questions?
I’ll definitely try it out, but I can’t dropping my precious flask for it... we’ll see though.
https://www.youtube.com/channel/UC4kU17BqNXaCKGFAYvrlawg/playlists some specialized videos 
&gt; I ended up having my head-of-control in the top directory and all dependencies in sub dirs but I hate it I don't know what is there to hate about this, it looks natural to me (or at least more natural than import from parent folder), but you have two main other choices: 1) Run your script with the -m switch, and then you can import anything from anything, like in your foo.py example, wherever it is located, you can do: from rootfolder.childfolder.bar import bar The disadvantage could be, that you need to specify this "path" in your every import. 2) As a small hack, if you just occasionally need to import from sibling or parent, you can add that import path to sys.path, like this: sys.path.append(os.path.join(sys.path[0], "..", "..", "bar")) Then you can do: from bar import bar Anyway, having dependencies in subdirs is a normal, pythonic approach.
If I use docker then, as far as I understand, I'm dependent on docker. And new dependencies is something that I'm trying to avoid. Otherwise I would just install `pip3` and my life would be simple. 
If you use docker, you are dependent **only** on docker. Everything else would be inside the container.
Sure but this is still _new_ dependency. I don't want to add any dependencies. 
You don't need pip or any other packages if your app doesn't have any external library dependencies. If your app does have external library dependencies, then having to download them and install them on the local system shouldn't be a headline news item no matter what language you're talking about.
nope. I want to delete every row that has a True in it, up to the top (top being the top of each groupby('PERSON_ID')
yes, what I've done is import the libraries again within the function that uses it. So if a call comes in prior to library being loaded it will wait for it to load, instead of throwing an exception. Since python modules are like singletons, the subsequent calls are fast.
Thanks, python - m looks good. The reason to hate is that I expect thing to work but instead I have to do workarounds at the very beginning of my journey. Probably it is more natural, as you said, but my first try was with siblings (cousins?) and I've had hard time to realize why is it wrong. Especially coming from Rust , C# and Ruby where modules are much, much more clear and systematic. 
Installing on the system requires root. Which I don't have. Installing to user directories failed with the error I mentioned previously. 
It'll be there for the next round :)
Vibora has blueprints just like Flask :)
Hahaha. I've prototyping this framework for a few months... Just moved from a private repo to the "organization" so I can add more folks later :)
You don't need pip to install packages, it's just the most convenient way to do so. "Installing" a Python package can be a simple as copying or including the code in the top level directory of your own package. Or you could use the slightly outdated [easy\_install](http://peak.telecommunity.com/DevCenter/EasyInstall) Blame Ubuntu for stripping pip out of their Python install by default.
GJ! 
Its an internal C++ library that exposes a python interface at a bank, has various models to price, store, communicate, and process every type of financial instrument. It's basically 100's of developers, many of whom are under tight deadlines, some are just plain bad, dumping their code into one huge pile over a course of a decade:). Happens all too often, I worked at one company that compiled all their code into a single 1GB statically linked binary, with some stuff that they've written decades ago and no longer had source for, just compiled object files.
Great job! I'm definetely gonna use that on my future projects
From a quick look at the project I would say that the author probably didn't want to bother with user authentication but still wanted to store and report history data. 
What kind of application is it? Are you using the server for processing power only? If there’s any kind of complexity at all, you will have to add new dependencies. Ex. Making a web app? Well you need a web server to field requests to the server plus whatever other stack dependencies you have for your front end. You’re getting into more complicated aspects of writing code, and there’s more things to learn as you go. If everything was only Python, I may not have a job. 
Thanks for not linking directly to the post. That was extremely helpful.
Why not a schedule task, which get weather data, financial quotes or RSS news from web and sent it to you by email
All docstrings look like stabs, without any actual docs... 
The for-loop question is based on a list being iterable... for grade in myGrades: total = total + grade 
with PIL/pytesseract it should be possibily probably
Falcon is pretty slow compared to Sanic! I've compared the two together before, the difference was at least 2x.
``` if platform.system().lower() == 'linux': dependencies = ['uvloop', 'ujson', 'pendulum'] else: dependencies = ['pendulum'] ``` Probably, you should constraint minimum and maximum versions of dependencies.
&gt;Me: Boo boo better than that TBI and CTE. &gt;You: No. No it’s not. SMH, I guess we all know why you keep acting this way in the post now. 
&gt;Great job! I'm definetely gonna use that on my future projects Wait until a stable release (soon enough) unless you're a brave early adopter :)
&gt;the I would love to see it being pronounced just like in Portuguese but I know it won't happen hahaha :P
Yes... I'll document them as soon as the API get stable enough. Right now the API is evolving quickly and that's why it's in "0.0.6" version
&gt;Probably, you should constraint minimum and maximum versions of dependencies. Sure, I'll lock down dependencies in the first release.
I'd prefer that the floppers get CTE so they are removed from the game and stop flopping. Not likely in floppball, though. Too bad.
My python app is just a set of helpers for developer (think of reading logs etc.). The company is not even officially supporting python so Im not going to install python dependencies (like pip), I'm trying to setup everything in one single directory 
For production/test grade inhouse developed applications, we publish everything to [Graylog](https://www.graylog.org)
He's showing a measure of "waste." I did not say his numbers are a waste. 
I can send free SMS via textlocal API? Limitless? No costs? That's a sick alternative to Twilio.
This is so sick man! If you don't mind me asking how did you learn? I feel like the best way to learn is just to do stuff, to actually write code but I feel like I don't have a strong enough grasp to be able to do that? I've tried reading other people's code and mimicing it but that's also kind of frustratingly difficult. Also, how the hell does it send an SMS?? Is it hooked up to yor phone? THIS IS SO COOL
Good one /s
Settle down floptard.
delete it and re-comment it somewhere else? You might also have escaping characters: https://docs.python.org/2.0/ref/strings.html
Looking at the discussion about what to do with stdout and stderr I think we miss clarity about what this supposed standard really suggests.
I think we all went through the "am i retarded" stage at some point. It took me a good few years to get comfortable with python and a ton of stuff still gives me headaches. You'll get there if you want to, practice does not require talent :) 
Call me whatever you would like. I'm not really much of a soccer fan at all but I just find that you are not very smart so felt I had to reply to at least one of your comments. I keep proving myself right with your lack of intelligence and creativity for each comment that you leave.
Are you talking about a /* */-style comment that can end before a line does? Python doesn't have that kind of comment. You might be able to spread the method call or whatever it is over multiple lines and then use a # comment for this filepath, though.
Definitely selenium. Be careful, ticket websites don't usually welcome bots. 
People now put emojis in commit messages!
I made a universal scraper that helps me monitor specific sites to check for status updates (like if a new chapter was released) and price updates. This is just a very basic "get and return data" sort of scraper but if you want to go fancy you can do your own sports pool/statistics which is what my coworker does.
I'm actually curious why more web frameworks *don't* do this now.
10 messages/month. :)
Thanks for the words bro! To reply to the first question, I'll link my reply to a similar question: [here](https://www.reddit.com/r/Python/comments/8s9ued/3_months_into_python_ive_completed_my_2nd_project/e0y6op6/)! It sends an SMS using Textlocal's API — we create a POST request with their API and a message is sent!
Python3 fixed the Unicode issues that Py2 had. I'm sure if you post some example code someone can help you explain. Also go to /r/learnpython for help.
Python 3 is more strict about unicode. So while this is painful it is also more correct (once you figure it out). It looks like the text is not encoded in utf-8 but probably a Japanese encoding, so when you try to decode the bytes to string using utf-8 the decoder sees stuff it doesn't understand. This problem is kinda annoying because plain text files don't have meta-data stating their encoding and you need to know up front. There are some package that can guess it but that is a bit of a kludge.
Can you use it to connect it to websockets
I am using abandoned, pre-beta python library and the error was thrown there. So there is no way to debug it. The code works on my company pc ( win 7 with python 3.5 ), but I couldn't get it working in my home pc ( ubuntu with previous installed python 2.7 and 3.5 )
You might look at `trio` as well. It's an async framework that doesn't use `asyncio`, and it's much easier to understand. You could easily use async to make data collection run more smoothly. It's not about parallelization at all, it's more about letting one thread do something else while it's bored (waiting for data). It's easy to dip your toes into `async`/`await` with `trio`, but in my experience once `asyncio` touches one part of your code everything becomes `asyncio`, so maybe ask yourself if you really need more performance. For instance, if you have a handful of instruments each producing data at different intervals, you would normally have to go to each instrument, ask it for data, wait for it to give you data back, and then move on to the next instrument. With `asyncio`/`trio` you go to each instrument and say "let me know when you have data and I'll come back". It sounds like you're in a lab/experimental environment, so maybe if you describe your setup I could suggest something more relevant. I'm in an experimental physics lab myself.
I used notepad++ to explicitly change it to utf-8
It's really simple. Just add this line to either .bashrc or .profile or whatever you feel like sourcing: complete -W "$(cat ~/.ssh/config | grep '^Host ' | cut -b 6-)" ssh It filters your the ssh config file and finds any line starting with "Host ". All these names are added as completion targets to the command `ssh`. `complete` might be bash specific, look for the equivalent in fish
Websockets implementation is still in-progress. Please beware that this project is in early-stage, I got way more track that I was expecting... I'll do my best to release a stable version soon enough. Thanks!
Will it be able to overcome "select the region containing car image" kind of captcha?
Awesome, that sounds like a perfect solution. Thanks for architecting that out, helps a lot!
Have you tried processing your text without trying to decode anything? With Python 3, Unicode is now the default. [Text Vs. Data Instead Of Unicode Vs. 8-bit](https://docs.python.org/3.0/whatsnew/3.0.html#text-vs-data-instead-of-unicode-vs-8-bit) (python.org) [Python’s Unicode Support](https://docs.python.org/3/howto/unicode.html#python-s-unicode-support) (python.org)
Great, that helps a lot with my understanding of the whole structure. It's about separating out the data storage in the databases and optimizing that portion, and then the front end doesn't matter as much what I choose, just as long as it connects to the databases and can pulls the data as needed.
I made one to automatically rename downloaded TV shows in a standard format. Grabbing the episode name from Wikipedia. Unfortunately not all the lists have exactly the same format so it only worked 70% of the time.
I'm confused, it works on Python3 at one of your machines, but doesn't work with Python3 on another machine? Python3 is not backwards compatible with Py2, so stick to one or the other (preferably 3).
I already made a wether forecast app but the news sending is definitely an interresting idea. Thanks! 
Thanks for that! Sounds more up my alley. I am just also a Python enthusiast and have felt left out of the asychronous party. But I can think of some code that would benefit from trio as you described it
Settle down, settling down, floptard.
This looks extremely cool. I have been working with Python for some years now, but didn't start any web development yet. Once I dive into webdev, I am surely going to give Vibora a try (or maybe see if I can contribute)
Use ISO-8859 instead of utf-8 usually clears this up for me.
I’m just trying to buy student tickets where there’s a 1 ticket limit per person. I’m not planning on buying up a whole stadium and scalping them. Do you think it will work in my case (Ticketmaster).
PyPy does not have the same tooling, but as far as I can tell it uses 30-60% fewer objects. 
Supermarket/grocery delivery service pricing data. Then normalize each vendor by product (1lb green beans, green beans 1lb etc). Additional challenge is that these are localized and time sensitive, same chain has different pricing for different areas and different weeks. Folks could save some money!
I recommend installing "miniconda" (https://conda.io/miniconda.html) on your target machine. It doesn't need root privs. It will give you your own python install in your user-folder. You can install into this any dependencies you like, as well as your own code. The 'conda' package manager is like pip but can also work with non-python requirements (like compiled C++ libraries etc.). This approach makes your application totally independent of the system-installed python so when you change OS version, your app doesn't break.
&gt; Settle down, settling down, floptard. Proving your intelligence and creativity yet again. Am surprised you are in a programming subreddit.
sounds great! I'll definitely check that, thank you!!!
Settle down floptard.
[https://github.com/reinderien/py-cat-times](https://github.com/reinderien/py-cat-times) \- Profiling various Python string concatenation methods. I'm going to write a separate post about this, too.
My team is going through a mountain of manual tests for the company software and automating them through Python 3.7b4 + Robot Framework + Jenkins using ESXi slaves. We're currently doing some really niche stuff on Windows, so there's a lot of \`[subprocess.](https://subprocess.call)call()\` usage. Soon we'll be touching PyShark :)
[tfw](https://i.imgur.com/azBMozY.jpg) I see 4 features I want that aren't in sanic Do you anticipate any serious API changes to vibora from this point on?
i know it's a little late, but how did you install it?
https://www.reddit.com/r/Python/comments/8s9ued/3_months_into_python_ive_completed_my_2nd_project/e0zx3sa/?st=jinczyar&amp;sh=872771da
Proving your intelligence and creativity yet again. Am surprised you are in a programming subreddit. 
Beside websockets I don't think so. There'll be a really big update at the end of this week, so keep calm and wait a little more :) Thanks for the interest! 
Thank you for all of your replies. I don't know if I manage to write it this way, but I'll think about that issue. ;) 
Checkout https://anthony-tuininga.github.io/cx_Freeze/ Also for lxml error, I guess your server doesn't have some libraries installed to compile lxml.
Settle down floptard.
the overuse of emojis in your commit messages gave me cancer. :-)
https://www.reddit.com/r/Python/comments/8s9ued/3_months_into_python_ive_completed_my_2nd_project/e0zy7qr/?st=jine431u&amp;sh=3fb61eaf
I understand this. What I was getting at is that stdout _is_ a file and it can be redirected wherever. I.e. it doesn't really make sense to say that printing is slower than writing to a file. So clearly we agree. Personally I would always just print it since I find redirecting stdout more convenient than having logging go to some path by default and maybe making that path stdout. Of course the perspectives are equivalent but I prefer to print first and redirect second. This all of course presumes that you can simply print errors to stdout and are not in a situation like a GUI program where that wouldn't work. 
Where are the areas where you are looking to add more Cython code? Would be something I would be interested in contributing to. 
I highly recommend that you use self report tests, those currently used are clinician rated tests. You can use MADR-S and HAD (https://en.m.wikipedia.org/wiki/Hospital_Anxiety_and_Depression_Scale). Both are free to use and designed for self administration.
Are you looking for any help? I've been looking for a project to contribute to and I like a lot of what you've done.
Don't limit yourself to what you can only do at work! Learn python to learn python (and programming in general). If you skip over things only because they don't apply to your current job role you will be severely crippling your knowledge. Knowlege that you might find useful later. It's also important to note that what you learn while doing things like "moving around a bunch of files" is not "how to move around a bunch of files" but rather things like: how to iterate over large lists. How to talk to file systems, how to validate work and reverse changes, etc. The excercise is just pedagogical.
I recently discovered [this](https://jcutrer.com/howto/dev/python/pipenv-pipfile) little factoid on GitHub that explained you need to type `exit` not `deactivate` when you want to exit the current pipenv shell. (Not very intuitive--I had trouble initally as well, because I'm used to `virtualenvwrapper`)
Re: Machin &gt; I am not sure how this would have been calculated in Machin's time or how much accuracy he would have achieved. The folks in Machin's time were using the Taylor series for arctangent. # returns the nth term in the Taylor Series expansion for tan(x/a) def atanSeriesTerm(x, a, n): twoNplus1 = 2.0*n + 1 term = ((-1)**n) * (1/twoNplus1) * ((x/a)**twoNplus1) return term #before machin, pi = 4 * atan(1.0) #machin found that pi = 16*atan(1/5) - 4*arctan(1/239). That taylor series converges much much faster sum_premachin = 0 sum_machin = 0 #sum the taylor series for i in range(0,25): term_premachin = 4.0 * atanSeriesTerm(1.0, 1.0, i) term_machin = 16.0 * atanSeriesTerm(1.0, 5.0, i) - 4.0 * atanSeriesTerm(1.0, 239.0, i) sum_premachin = sum_premachin + term_premachin sum_machin = sum_machin + term_machin print('{:3d} {:18.14f} {:18.14f} {:18.14f} {:18.14f}'.format(i, term_premachin, sum_premachin, term_machin, sum_machin))
[removed]
The Machin series converges quite rapidly. You get five decimal spaces in just 4 terms. You get 14 decimal places in 9 terms. The more obvious series which was known before is pretty much the alternating harmonic series. It takes forever to converge. It takes thousands of terms just to get 3 or 4 decimal places.
I didn't do MuPDF yet because the team elected to go with Weasyprint. We're generating html reports then the user can elect to download the report (or in my following issue, bulk reports) as a pdf. Don't know your experience with this product but it does not operate well. I kept getting "too many files open" so I forked each document to its own process. Then I got "out of memory crashes". With `lsof` I can see that the main process opens dependencies for each forked process and never releases them. I know this isn't what we discussed but I thought you might be interested. If you are interested I'll keep you posted. It might be something else stupid I'm doing.
AWS Lex and lambda might be something to look into 
Maybe write a self diagnose telegram bot for it?
Settle down floptad.
Also Rasa
It's official https://gitmoji.carloscuesta.me/
I think you'll need to look and find particular libraries which do this for you.
Ticketmaster is probably the most hardened of sites for scrapping.
I haven't used Weasyprint much other than trying it out briefly to see what it could do. If all you are doing is "downloading" a report though, I don't see why it would open up too many file handlers. One download should equal one PDF, correct? Personally, if I was doing this I would probably write an HTML parser and create the PDFs myself with ReportLab.
`pip3 install --user opencv-python` ?
I think if you are thinking of containers and clusters, you should write your logs to a logging server to unify logging among all nodes in the cluster. As others have mentioned, just use logging module (or if you use django, install the appropriate “destination” provider or whatever they are called for writing to a log server)
on the pi ? ^^?
Yes... I'll push some big improvements this week and set a clear roadmap that people can help me with... I pushed an incomplete version just to get feedback from community to know if I'm not alone on this... Many thanks!
I code for the best unofficial API for Google Search results (https://serpapi.com) It really depends on your end goals. If the web service is not adversarial, you don’t need to emulate a browser. Just watch your HTTP traffic with fiddler or wireshark, and write the simplest HTTP get/post requests you can make to interact successfully with the web service. If the web service is adversarial, you want to use PhantonJS or Headless Chrome to run a full browser. At this point, you want a flexible CSS selector for each form input. You don’t actually want to throw an error because the form looks a bit different or an input is missing. In both cases, I will be very lax on schema enforcing. Some users can have a good use case to submit dates in a different format for example. I will be written more logic for good error handling, being very explicit on what went wrong, and hints to how to fix it. A good a posteriori error and format handling allows your user to still use your API while providing more data about what went wrong. Good luck!
Using uvloop vs the default asyncio event loop can make a big difference. Were you using the same event loop between the two frameworks in your test?
Send a text to your phone every time there's a new post on r/gonewild.
Sorry to say it put you’re missing some vital points in statistics related to sample size and this “blog” post gives the wrong picture of the modules you’re trying to debunk (or whatever you’re trying to prove). 
I cant find any that even come close
Great idea! How should it send a text to my phone? 
I've used twilio in the past. A decent description is [here.](https://automatetheboringstuff.com/chapter16/#calibre_link-3490)
If it encounters one of those it simply routes the request to another proxy
Not sure which question you answered here. I think I can help, only if you provide a clear description.
Working on finding different ways to transfer data to SQL format using the different tools python provides for example from csv to SQL, pandas to SQL and also I just found out flask sqlalchemy can also be used to transfer data to your database. 
/u/frnkvieira not to put down your accomplishment, but if Vibora is heavily inspired by Flask in its API and creating a new project loses you the Flask ecosystem, why not just contribute the speed improvements directly to Flask?
Vibora is async, Flask is sync by design... They are not mutual exclusive...They serve to different purposes... Streaming stuff, dealing with high number of concurrent connections are tasks that an async framework do much better than sync ones... but that doesn't mean async is the solution for everything... each one has it's place. Hope I made it clear, thanks !
Awesome, can't wait! 
You did, thanks :).
About a year ago I was experimenting with cythonizing bits of some web frameworks. Where I was able to leverage it, I got what seemed to be some easy speed boosts even without doing much of anything specifically tuned to cython. It was going to need more work than I had time / mental energy for to really understand the guts of the frameworks to figure out if there was a better way to apply it and maybe submit patches, though, so I left it purely at the basic experimental level. I'm sure building the framework from the ground up to be able to leverage cython will give some serious advantages. Good work!
I'm learning Cantonese. I bought a Glossika "mass sentences" course, which comes with 1000 audio sentences and a corresponding ebook full of translations. I love the resource, but I dislike the format, where the sentences are packaged up in long audio files. I wanted the same data in a flashcard-like format (shuffle sentences, click to repeat the audio for individual sentences if I didn't catch it the first time, quiz myself going from audio to characters to English, etc). So I wrote a couple of python scripts which (a) split all the audio into individual numbered files, breaking on the long silences between them, (b) split the ebook up into corresponding entries, and (c) run a little command-line flashcard program that lets me practice listening &amp; reading comprehension, in a way that suits my learning style. I used pydub to handle the audio. It took a while, but it's already been extremely helpful! I could probably export it all to a more fully-featured flashcard program, but I like what I have now. It's not pretty at all, but it does what I want.
You can find the explanation of this numbers by reading this article in the Python Cookbook. https://www.safaribooksonline.com/library/view/python-cookbook/0596001673/ch03s06.html 
&gt; ever evolving constellation For that reason, for the infinite deployment model the world present, you want your code to be 'production agnostic' and log in the most neutral way possible so it fits into any platform. Stdout is the most generic medium that I'm familiar with - it works on my machne, Lambda, K8S, Heroku, custom VM, etc
Refactor it to fire on first downs!
That’s not what’s being tested here. Rather, the question is whether the observed performance across different Python versions is actually degrading, or whether there is something else at play. I’m pretty sure that the OP understands the immutability of strings in python.
That's an interesting web page. Here's a continued fraction approximation, from the formula [here](http://www.cs.utsa.edu/~wagner/pi/ruby/pi_works.html) (which also gives Ruby code). This code uses Python rationals. from fractions import Fraction from decimal import Decimal, getcontext print("\nFind a continued fraction approximation to pi.") max_n = 1000 # Maximum number of terms in the continued fraction. denom = Fraction(2 * max_n-1, 1) for n in reversed(range(1, max_n+1)): denom = (2 * n-1) + n**2 / denom rational_approx = 4 / denom print("\nThe rational approximation numerator is:", rational_approx.numerator) print("\nThe rational approximation denominator is:", rational_approx.denominator) getcontext().prec = 200 # Set the precision of the Decimal type. print("\nThe approximation converted to decimal is:", Decimal(rational_approx.numerator) / Decimal(rational_approx.denominator)) 
Django has a steep learning curve but will help immensely getting you up and humming.
Hey! Did you end up using local text for sending text messages cause it doesn't seem like it's actually sending it even though it shows in the API Message History that it's been delivered? :/
The world could use more json apis of data. Sports is a great example. Pick a sport and scrape all the information about every game in the last 30 years. Or every player. Put it in a sensical json structure and serve it somewhere for people to use in their projects. Espn is a good starting point.
did you end up getting it to work?
Hi, I got a good book that teaches me python and the language basics itself I know pretty good, but I am more looking for info about intergrating python code into like a website I have really found the answer in my book yet it focusses more on the language and less on this sort of aspects
Scrape info from LinkedIn. It's quite valuable data, and a challenge too, as LinkedIn has security measure in place to mitigate this. 
Just tried the same inside a Docker container which I use for testing... Time difference was in margin of error!
Surprisingly even to me, I actually really like this idea, but as an addition to proper commit messages. "Commit categories", if you will. Would make looking through a long list of commits much faster... 
Note that to develop a bot you generally need to test it first: this means actually buying a ticket on the site and recording the steps you took. Otherwise, you'll never know if the site wants you to confirm an email link or something in the process of buying a ticket, and if you don't code your bot to support it, it won't be done.
It's fairly well know that python 3 took some hits on performance because of the whole string/unicode thing. Specifically there was a micro-optimization in python 2 to speedup string concatenation (successive \`\`+\`\`). My guess is that optimization couldn't be applied to python 3 bytes because the underlying implementation changed, or nobody ever bothered to try applying it. [http://blog.mclemon.io/python-efficient-string-concatenation-in-python-2016-edition](http://blog.mclemon.io/python-efficient-string-concatenation-in-python-2016-edition)
Yes, we do agree, but the post before you was specifically talking about printing to the display screen, not redirection of the stream. Which I remember discovering was *very* different by accident when a ludicrously verbose process suddenly got several orders of magnitude faster when piped to /dev/null.
You might find http://www.obeythetestinggoat.com/ useful. It walks you through building a basic website with Django. 
I actually read it differently the first time. When he said "it's a lot faster to..." what I first thought of was that I personally find doing something like `python script.py &gt; path/to/file` much faster and more intuitive than needing to mess with the reverse process (i.e. converting a specific filepath to standard out). I.e. I find that I am able to use the script _faster_ and more intuitively when it's printing out instead of writing somewhere by default. But yes the realization you had is of course important for all programmers. It's very important to understand the rough timings involved in different kinds of IO operations. But it's also important to have the user interface setup right. In most of these cases, you want direct feedback immediately and using standard out is the most natural approach. Whenever in the end you deploy the scripts where the speed really matters you can pipe to a file or just redirect it to null. I think that serving the common case of development before deployment makes more sense than the other way around.
This. In most GC'd languages using actual character arrays as strings (v. ropes or something else similar), you expect concatenation to be O(n), and therefore successive concatenation to be O(n^2). The CPython optimisation relied on refcounting (which it still does), and if LHS had a refcount of one, it just realloc'd it and appended the RHS. I can't think of any reason why Py3 couldn't still do this, though.
My general preference is to log to stderr and stdout as a first principle, and only log to file (or to aggregator service, or what have you) when there's some requirement for machine parsing of logs and metrics that human users probably never have to read, so overall I tend to agree with you. I just don't see a need for any particular sea change away from log files for any of the enormous majority of apps that will never in their entire lifecycle move across even two of those boundaries, much less &gt;3 of them.
It makes more sense when you think about Python2 and Python3 as different languages with different performance characteristics. Python2 is also being sabotaged to force a userbase jump (profile-guided optimisation was disabled by default for 2.7.15 but the change was not documented and who knows how long it's been [broken for extensions](https://www.reddit.com/r/Gentoo/comments/8n38ak/devlangpython2715r104_enable_pgo_for_extensions/)).
That, and CLI tools often have either a verbose or quiet mode that allow you to choose whether you want 'logging' to stderr or not.
If you're asking how to put Python code inside a `&lt;script&gt;` tag, the answer is: you can't.
I generate up to 100 PDFs and zip them up for download. As the server ran I watched it with `top` and saw it's % memory usage gradually go up until Linux killed it. I don't want to bad mouth weasyprint until I ensure it isn't something I've done. There are bug reports on their github for similar issues and forking it eliminates the memory issue. However, I still get the "too many open files open" and setting a ridiculous `ulimit -n` treats the symptom for awhile but I wouldn't trust it in production. Reasons I use Weasyprint: 1. It's what they used before I got there. 2. It's so easy to create a pdf using html **and css**! Seriously, ignoring the memory issue, it's aptly named **easy**. I would still recommend it for small projects.
I agree that it is easy to use. We would create hundreds or even thousands of PDFs with ReportLab at my previous job and never had any resource problems. I wonder if rst2pdf would work better but that would require learning different markup.
Wow, that's legit awful. 
Yep I agree with him - dirt poor tactics for a site that could be ETHICALLY be a market leader 
... and a takedown notice/legal threat in 5.. 4.. 3..
Agreed, and given the number of times I've had to trace open file handles just to find out where some bloody stupid piece of undocumented debt was even logging to, I always prefer everyone start and usually end with stdout/stderr, I just read that post as speaking specifically to disk IO vs writing to the screen.
I'd not worry too much about small increased/decreased overhead, this always happens. There were performance issues with BytesIO: unlike cStringIO, it used to do a copy of data, and so used to be much-much slower in some cases, but these issues should be fixed in recent enough Python 3's. The most significant behavior difference between modern Python 2 and Python 3 is bytes += in Python 3. In Python 2 there were str (===bytes) and unicode types; for both of them += were O(N), though it is a CPython thing, and not guaranteed by language; AFAIK it is always O(N^2) in pypy. In Python 3 old unicode became str, and old str (==bytes) became bytes, but the optimization only got implemented for str (== old unicode). Complexity of this operation is not guaranteed, and shouldn't be relied upon for portable code - in pypy and pypy3 such concatenation is always O(N^2). BUT the problem is that the issue can be hard to spot while porting code from Python 2 to Python 3. In many cases, if someone wants to be strict, PY2's "x += u'foo'" gets converted to "x += 'foo'", and "x += 'foo'" gets converted to "x += b'foo'" while porting. Even worse if code has been already "modernized" in Python 2, to use "x += b'foo'". In this case there is no diff to review when porting, tests can't detect the issue, but an algorithm suddenly becomes quadratic. We made this mistake in Scrapy, and it was noticed only recently (see https://github.com/scrapy/scrapy/pull/3281). The original code was bad - it shouldn't have used +=, but unfortunately some amount of bad code is expected in large codebases; this particular code has been written when nobody cared much about pypy, and it survived drive-by reviews because authors were aware of CPython's refcounting hack (but not of its absence in Python 3 for bytes), and viewed it more as a style issue, or a pypy-only bug in a worst case.
When researching report lab was the best but is way more than I need. Ethically, I would have to pay eventually and even the smallest purchase is a headache for me. I tried some other stuff but CSS was a problem. Data is pulled from a database and an html report is displayed; the mvp was to reuse that. On a side now, always a pleasure chatting with you. My strengths are in sockets, ctypes, structs, ...basically all the unsexy backend stuff.
As your link mentions, you're supposed to do successive string concatenation in Python 3 with `.join()` anyways, wouldn't surprise me if it were faster in 2 as well (or if said speed-up was basically replacing successive `'' + ''` in the AST by a call to `.join()`).
Spot On. Udemy has the most annoying marketing campaign ever. I am tired of hearing that one asian dude, who probably knows nothing about coding, tell me how I should take a course to "get ahead". Stop telling me what I should do damnit.
I don't have twenty minutes to watch a video about this. What's the tl;dw?
Their whole business sounds a bit like a MLM I know its not technically one but there are some parallels...
If you are comming in complete from scratch, I'd go with [anaconda python3](https://www.anaconda.com/download/) and use [pycharm community edition](https://www.jetbrains.com/pycharm/download/) Fire up an anaconda prompt and install flask by running the command: pip install flask Then open up pycharm start a project and create a python file with the code below and run it: from flask import Flask app = Flask(__name__) @app.route('/&lt;name&gt;') def yourfunction(name): return f'hello {name}' app.run() Then open up your browser to localhost:4000/spicymemesboiii (port might be different, but it will tell you when you run it). This should set you up with something you can hack from. Looking up Flask to see how to build more or different applications. Jinja2 is a good templating engine. For database connections sqlite3 is nice and easily available but you might want to go for mysql/postgresql or other exotic choicse. Really just start digging around for things when you have a specific need or desire and build up your toolbox. 
I was considering signing up for a Udemy course so this is disappointing. Scumbags
Udemy (or someone else***) stole his free YouTube videos and put them on Udemy under his name. *** probably udemy
they mislead instructors and viewers/customers, they provide no monitoring for illegal/stollen content despite taking a cut of the revenue, can only DMCA on a per-video basis (not per course even if whole course is stollen), can only "verify" the videos are stollen by purchasing the course (and giving udemy a cut of the sale) in order DMCA the content behind the pay-wall (Despite text/images is obviously copied/pasted). I'm not doing /u/sentdex any favors by this summery, he lays out the situation in a much better way, would encourage watching the video despite it's length.
DMCA + lawsuit = better payout than he'd have gotten by signing up with them.
Yea, but the name and shame takes away business from them. I say he keep doing both.
I'm curious about this. Time difference between which methods? Because the difference between the best and worse is several orders of magnitude.
If you're looking for more in-depth resources than what you can find for free, check out Safari Books Online. You'll find that it's somewhat more expensive than any given Udemy course, but it's SO MUCH MORE. You'll get access to thousands of incredible resources for any given technology that you could want to learn. Full disclosure, I get access through my employer, but I'd wager that's an indicator of quality anyway.
For a long time I have found Udemy overall course quality is shitty compared to other MOOC sites. And the fact that courses are **always** 90% off make it look like a scam site to me.
Looking forward to it, thanks for the info. I tried running some of the samples but ran into problems ex. a SyntaxError on [this line](https://github.com/vibora-io/vibora/blob/1933b631d4df62e7d748016f7463ab746d4695cc/vibora/hooks.py#L38), not sure if I'm missing something or maybe you already have this fixed for the upcoming release?
I paid $9.99 for the machine learning A-Z and it did give me some level of education. I think I can find most of the information online myself, but udemy course did make it more organized and easier for me to learn. The content, is not very advanced though. I expect to skip things as I go. 
Now, I feel bad. I bought a course through Udemy recently.
I could be wrong, but whenever I read/watch items about these shady tactics, I think about the mantra of the startup ecosystem in general and how small amounts of deception are often used to "win". To be clear, I'm not saying that all startups are bad or that all startups employ deceitful tactics, but one thing that seems to be common across these types of situations is that deception often allows companies to scale quickly and generate significant profit, which are the two main tenets of startups. The problem I often see is that companies will say "we'll do the bad thing now, and figure out the legitimate strategy later", only the legitimate strategy never comes, but the money from the deception is still coming in. I think of it as "moral debt", in the same vein as technical debt is to software projects. I can think of two examples right off the top of my head. One company I worked for built a new app and seeded the production database with a ton of fake user data to make it look like a popular, highly used app. This is a very common tactic among young companies, and it's usually not a controversial move. I didn't think much of it until we started sending reports to potential investors with data on our user base, which included the fake accounts. We raised money on user growth metrics that weren't true. It really irked me, but what was a lone engineer to do? We also came up with ways to generate website performance metrics that meant absolutely nothing, but sounded really impressive to the people we were selling our product to, who were entirely unable to make an educated assessment on the validity of what we were doing. At another company, the founders would brag about how they raised a $1M+ seed round on an "app" built out of nothing but Twitter Bootstrap. It's also a fairly common strategy in the industry, build the "happy path" as they say. I joined after this happened, but it also bugged me a bit because they talked about that experience on a fairly regular basis, as if their success in tech was based on the "resourcefulness" of their demo, not the fraud.
I agree. I found the course I took very helpful. It's not a good platform for course creators though. They play very dirty with their marketing. I won't be buying from Udemy again. 
Yeah. I can’t really believe how the creators can survive with that 270 hours of videos sold for $9.99
What is a good alternative to Udemy?
TBF to the instructors, it really depends on who teaches the course -- they're individuals with Udemy providing the platform + marketing. Some great, some not.
It depends on what kind of data processing you are doing. If it's IO-bound (spend most of your time waiting on the network) you'll want to check out `asyncio`. To try to perform your tasks concurrently. This is especially useful if the network data you're collecting is generally lots of small IOs from many different clients. If you're CPU bound around the data processing step then you might be a in a bit of a bind. There's `concurrent.futures` which lets you create a `ProcessPool` that you can use with `asyncio` which can be convenient, but it depends on how expensive it is to ship objects between your processes as all of the IPC is based on `pickle` serialization. If it only takes a relatively small amount of input data to perform your calculation this could be a viable option.
Udemy are most definitely at a stage now where they could start to employ more ethical strategies. They never will. It's just funny because Sentdex is a completely self made guy who has built a platform where he can teach, take optional donations and run his own side buisnesses. I'm guessing he's a very wealthy man but it's such a sharp contrast to the type of "shrewd businessman" personas that these self-help/ influencer types are saying is the only route to success.
I never really liked udemy. Most of there courses are worthless and there experts are bogus. Other educational sites like edX and Coursera are much better they have actual free courses that are useful and they don't resort to predatory pricings and hunt for experts.
Depends what you're looking for. YouTube has so many great, fully fleshed out courses. Sentdex's channel is one of the best resources for learning advanced programming that I've ever come across.
Me too. I've been working through a data science course. I'm about halfway done and have been fairly pleased so far.
He explains in the video why DMCA is not as easy or as useful as it sounds. I highly recommend checking out the video or u/Ogi010 's reply to you for more information
As far as I can see, they don't have catalogue to see what's available once you sign up. Paying $39/month without knowing what I'm getting is pretty difficult to justify. If I sign up to the trial, I feel pressured to actually use it whereas I just want to see whats on there.
I feel bad because I learned many things from Sentdex before - especially Python, Pandas, and Flask. I bought a React/Redux course through Udemy. :( Most Python stuff can be found for free, but for some reason, front end stuff are not as abundant.
I don't know about you... but those revenue shares seem way bigger than on other web sites. They are hosting, advertising, and operating your content and you're getting 50%? That's amazing! What do you think you're getting from youtube? 1%? 10% tops? It's ironic considering that this is a guy that probably gives 90% of his content's revenue to youtube. Criticizing the content theft is one thing, but the revenue model seems pretty good. Sentdex points out the line "we are not in a position to determine legality", and then pines on about copyright infringement, despite the next couple paragraphs being about copyright infringement being the obvious exception, and how to report it. DMCAing content is the standard way to remove it, and he even says that's easy. But obviously, there could be a better way. I think this is a complicated issue and there's not a clear solution to it - Udemy is not the only offender. What does Udemy do? IDs can be faked, he uses an alias, etc... but he is right that they should be using a service to check for fradulent content. I've taken courses on Udemy. They're fine, but I like Coursera better due to to the quizzes / project submission.
I'll check it out! Right now I've been using Coursera, EdX, and KhanAcademy daily and it's helped a ton but the machine learning programs on Udemy appealed to me
The real TLDR here, for people who don't want to watch 20 minutes is: Udemy does not review any content posted, even for sale, on their site, hiding behind the DMCA as their excuse. \`Our marketplace model means we do not review or edit the courses for legal issues, and we are not in a position to determine the legality of course content \` \[source\]([https://www.udemy.com/terms/copyright/](https://www.udemy.com/terms/copyright/)) This is plausibly a valid excuse on a free platform, but, when you are pay-walling the content, this should not be an acceptable business practice. I am not able to buy every single course hidden behind a paywall to find the infringing courses.
I bought that course too! Very happy with it.
Youtube revenue share is 55-45 in the creator's favor, which is actually quite fair given how exceptional their organic algorithms are.
Udemy hides behind DMCA, including for paid content where they mostly get a 50/50 split. Their policy: "Our marketplace model means we do not review or edit the courses for legal issues, and we are not in a position to determine the legality of course content. " (https://www.udemy.com/terms/copyright/) DMCA works when a creator can reasonably defend their copyright. I cannot reasonably defend my copyright against paywalled courses. I can defend against free ones, but it's unreasonable to expect me to buy every single Udemy premium course just to protect my copyright and see if the course is infringing. My argument is they should be required to spend the first net profits from any paid courses to verify the legitimacy of those courses.
That chick that looks like Eli Manning freaks me out too. She talks to the camera like she's in love with me.
It's really more than that. It's that I cannot reasonably defend my copyright on Udemy, I cannot be expected to buy all of these courses just to see if they infringe. For the commercial courses that Udemy profits from, they should be expected to verify the legitimacy of the courses with the initial net proceeds before anyone gets paid out.
I think the bigger ethical issue is that so many instructors are happy to pretend that watching 20 hours of videos (usually without any sort of assignments) will teach you how to code well enough to get a job.
Ah, that revenue split is better than last I heard (I'm old). Either way, that seems to put Udemy pretty much in line with youtube. &gt;he is right that they should be using a service to check for fradulent content.
other than them turning a blind eye to blatant copyright infringement, i dont see a huge ethical dillemma to their marketing strategy. 
I’m pretty sure I recall hearing one of the core contributors state that Python3 (the later versions) are faster than python2.7. Initially some parts for python3 were built with python rather than C, but later versions got the patch. 
As someone who has been wooed by Udemy on multiple occasions, I can tell you that they mislead you into thinking you're going to get the 97%. The predatory practices both for getting customers to buy and creators to create on their platform is one thing. The real issue here is they do nothing to verify the legitimacy of the content on their site, including the content that is pay-walled. I cannot be reasonably expected to purchase every single python course in order to defend my copyright. DMCA only works when the creator can reasonably defend their copyright.
What do you want to improve? Making a "neural network" is easy - the hardest part is optimizing it. For this you need either numerical or automatic differentiation of the loss function with respect to every parameter. This is why frameworks like TensorFlow exist.
&gt;The real issue here is they do nothing to verify the legitimacy of the content on their site, including the content that is pay-walled and that they mostly get that 50/50 split for. &gt;I cannot be reasonably expected to purchase every single python course in order to defend my copyright. DMCA only works when the creator can reasonably defend their copyright. Which is why I said and have now twice quoted: &gt; he is right that they should be using a service to check for fraudulent content.
I've learned a lot from this guy in the last couple years without paying a dime, I trust his opinion and his generosity
Yeah I do mostly back end stuff too. One of these days I need to learn some more front end web development
For one: you don't need to spend time designing front end. And it can work on web/native apps as well as mobile devices.
Or you can use a free error monitor like Sentry (incredible service) 
I’ve had good experiences with Coursera, Udacity, edX and Cybrary. Depends on what you’re looking for because they all have slightly different focuses with regards to their offerings.
Their website's really gone downhill. But if the Safari service is the same today as it was years ago, you get access to electronic versions of every book they sell. Plus video content. And I think you probably get the books from their Pakt Publishing and No Starch Press partners, too. It's a fantastic resource. I can't spare the $40/mo, or I'd go all in; Safari lets you do text searches across their entire catalog, which makes it a fantastic resource on its own.
What do you prefer instead? The AWS certification courses are top notch. 
For `str` it's a special case in the interpreter for the + and += operators (which is already weird enough), and to do the same for bytes they'd have to do an additional type check each time an addition is performed. I guess it's simply not worth the cost.
Those features sound awesome, but ~£30 a month is a lot when my next contract doesn't start until September.
here's the code if anybody is wondering \#import print("let's see how long you have lived days, minutes and seconds.") name = input("name: ") print("now enter your age") age = int(input("age: ")) days = age \* 365 minutes = age \* 525948 seconds = age \* 31556926 print("has been alive for", days,"days", minutes "minutes and", seconds, "seconds! Wow!") doneFileName = 'isdone.txt' fdone = open(doneFileName, 'w') fdone.write('done') fdone.close() if os.path.isfile(doneFileName): from runSalome import \* myArgs={} myArgs\["killall"\] = True kill\_salome(myArgs) input() return (0) 
how did you execute it, by double clicking from explorer or finder? you need to run it from a terminal either by prefacing the command with 'python {application.py}' or by adding #!/usr/bin/env python as the first line in your program, then make it executable using chmod a+x {application.py}, then execute it using './application.py'
What would you say to someone who would have an interest in a Udemy course to look at as an alternative? Paid or not. Particularly a source that would have a variety of learning resources for a broad range of programming languages?
I know I was just trying to TL;DR it for him. You are right I 100% agree that it is on Udemy to 100% prove the author of the content before they host it, any less is BS. Also if they did it to you, they must be doing it with other videos as well. We need to reach out to David Bomball to see if he authorized this course: https://www.udemy.com/python-programming-for-cisco-network-engineers/ Because it is the same course that is free on youtube. https://www.youtube.com/watch?v=-1Z6ygHO--8&amp;list=PLhfrWIlLOoKPn7T9FtvbOWX8GxgsFFNwn Sentdex I have been watching you for a year and a half now, I love your videos and your enthusiasm for learning and teaching new topics. Please do not let those fuck heads at Udemy stop you. 
Maybe [os.scandir](https://www.python.org/dev/peps/pep-0471/) run faster.
i used atom to ride the code then saved the file as test.py and when i click it it open and close fast
Udemy profits off of many, many stolen videos. Some, like OP, release their "stolen content" for free, but many others are lifted from [paysites like Pluralsight](https://www.troyhunt.com/the-piracy-paradox-at-udemy/).
Udemy helped me a lot with my programming. Only buy course from Tim BulChalka that dude knows his shit. Also by Deep learning course from Kiril.
Same I prefer the deep learning courses on Udemy
If you happen to peruse my content, you'll be happy to know I've now banned my #1 advertiser on all of my platforms: Udemy. No more of that. ...now you'll just be inundated with Wix ads. :D
They used to do a free 30-day trial. I took advantage of that once back when I had no money and was in college. Maybe they still do?
Exactly. Don’t “click it open” ... you need to execute it as I suggested. 
A fair complaint. The only books I've not been able to find are academic. Though you can find a great deal of programming related content free online these days. However, there's also a lot of video content from generally well respected content creators. I'm not trying to pimp for them, but if you're _looking_ to pay for a resource, I'd say it's a good one.
Yeah, for machine learning I've been leaning towards more traditional education. But my math has always been weak. Teaching myself the complicated parts of Linear/Abstract Algebra isn't going to happen, lol.
Also Quart? 
Agreed. Have you found any other courses that are of a similar structure? 
&gt; stollen that's a [type of cake](https://en.wikipedia.org/wiki/Stollen)! You can remember it by only one L - someone stole the other one (and probably uploaded it to Udemy).
**Stollen** Stollen (German pronunciation: [ˈʃtɔlən] ( listen) or [ʃtɔln] ( listen)) is a fruit bread of nuts, spices, and dried or candied fruit, coated with powdered sugar or icing sugar. It is a traditional German bread eaten during the Christmas season, when it is called Weihnachtsstollen (after "Weihnachten", the German word for Christmas) or Christstollen (after Christ). *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Well, I purchased 2 other courses by the same creator: building Chatbots and Blockhain from A to Z. 
So, I want to give this a try. I wouldn't mind giving the free trial a look. But before I even sign up, I'd like to see the courses that they have to offer; from their homepage, it doesn't look like you can do that without directly searching something?
you're doing a great work keep it up :)
this is why i pirate udemy course :)
Most of the ones I've found are Indians with such deep accents and terrible English that it's baseline fucking annoying to watch their videos. 
I don't think so. But I just checked out my landing page and here's what's listed (mostly wait-listed, but whatevs): - Scala Core Programming: Methods, Classes, and Traits - Machine Learning in Python and Jupyter for Beginners - Design patterns in Java GUI development - Getting Up to Speed with Vue.js - Acing the CCNA Exam: Top 10 Tactics and Other Insights - Getting Started with OpenStack - Scalable Programming with Java 8 Parallel Streams - Clean Code - IPv4 Subnetting - High Performance TensorFlow in Production: Hands on with GPUs and Kubernetes - Digging deeper with PostgreSQL: Organizing Processes, Data and Evaluating Performance - Bash Shell Scripting in 3 Hours I dunno if any of that floats your boat, but when you tack on the books that are available, it seems like a pretty good deal to me.
Based on the repos, it looks somewhat abandoned since last year.
Thanks for typing that up! I found out that if I searched anything, it "opened the door" for browsing a little more. A lot of that are things that I am interested in, I have been trying to build up a broad understanding of various computing environments related to data analytics. I know a lot of R and use it for everything (bioinformatics for work), but lots of other opportunities can be found using different languages!
The good courses can have upwards of 20,000 students - it adds up, even at 9.99. Stephen Grider's Modern React course is sitting with over 100k students right now, assuming he gets half of that 9.99 that's a large amount of money, and he's got a half dozen more courses with probably 50k or more students as well.
I'll take a look maybe
I've honestly skimmed through a few books on there, and I really like having access. But I wouldn't pay for it if I were to lose my subscription through work. So many things are so well documented these days that the need for more in-depth training tends to apply to things that are conceptually quite difficult. I find that I need a lot of actual time practicing, or even having real classwork to make sense of. That said. I think that everyone learning python should read Fluent Python, and anyone wanting to write better code should read Clean Code. Neither is perfect, but they're some of the biggest steps I've made. Incidentally, what type of bioinformatics work do you do?
Looking up any other informative programming video on youtube and seeing a udemy ad will now make me find other means of finding that information. Great video though, sentdex is so right in talking about how the marketing strategy really is genius and the fact that their videos have now infiltrated all corners of the internet is fuckin crazy. 
I had a udemy "salesman" low ball my replies in a support forums just to plug his shameless sales pitch. Pathetic ...
/r/learnpython is a better place to ask such question. You also need to add 4 spaces before each line of code to format it like this.
Oh, I also found a really great Django course where the teacher walks users through building a Reddit like website.
Interesting. Do you remember the name? 
Yep, https://www.udemy.com/the-ultimate-beginners-guide-to-django-python-web-dev-website/learn/v4/content
Really as much as you can, read on lunch and commutes and practice/code every day for at least 30 min, 3 hours is better. 
Cool, thanks.
Thanks. I️ try and do at least 2-2.5 hours a day. Taking a Udemy course — but unsure of any other beginner level resources to try? 
Why do I trust you with my passwords?
Just found your site, looks good. 
I'd start with [Scikit-Image](http://scikit-image.org). You'd be able to take every image and do all sorts of transformation and analysis on them. Also since scikit-image images are backed by NumPy arrays, you could trivially take your CSV data and convert it into an image. There's a lot of built in functionality and it'll probably get you a long way towards your goal. The tutorials and examples for scikit-image are pretty good for learning to use it. 
The + operator is implemented for each type separately anyway, so there's no extra cost; you just look up the implementation of the `+` operator for the type on the LHS.
join always allocs a new string, so the + optimization wasn't equivalent.
You are not actually telling Python to use regular expressions. You need to `import re` and use `re.replace`.
That's why there are video previews., so you can hear it and decide. Actually many of those courses are popular because the accent is mostly neutral and easier for a non-european/american to understand.
There is an mit course on edx.org called 600.1 I think, free take a look
That's harsh on the instructors. They just provide the material, it's on the consumers to decide whether the format works for them.
Go pick up [Algorithms of the Intelligent Web](https://www.manning.com/books/algorithms-of-the-intelligent-web-second-edition) for $30. It's the perfect spring board for self-teaching ML. I went from no clue where to even begin to building novel classifiers within my industry in like.. a month.
Wow. Didn’t know about that sub before...
FYI, they 'answer' the question on what happens when a course you're enrolled in gets removed at the bottom of this: https://support.udemy.com/hc/en-us/articles/229603708-Lifetime-Access ...though, sounds like they maybe do nothing unless you contact them? I think your idea of the first enrollment fees going towards due diligence on the legality/legitimacy of the person submitting the content is great - it wouldn't even necessarily have to be done for repeat authors. I've gotten a lot out of Udemy (and Pluralsight, and Safari), but the stolen content issue is disturbing.