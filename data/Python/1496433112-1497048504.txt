I'm using pandas a lot along with the .pipe method to chain functions together. I'm not sure if you're using pandas at all, but here is an example read_raw().pipe(process_dimensions).pipe(process_values).pipe(load_new_rows).pipe(aggregate_daily) Each of my functions passes information or data frames to the next function. Read read data, process it, check data integrity, perform calculations and aggregations, etc. I have entire ETL scripts set up this way using the Airflow tool. There is a guide called Modern Pandas which I followed. 
Could we do this anyway? I'd love to see the processing framework you use. I'm processing tbs of data, and assume I'm woefully inefficient. 
I think the line-by-line method uses buffering so it wouldn't be too different to read the whole thing in.
Try /r/learnpython. Post the code you have [formatted for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin. Also, include which version of python and what OS you are using. 
Some hints: * You probably want to use a raw string as backslash is also an escape character in regexes.... :) * Start with a very basic regex (ie just look for href) and build it up from there. Having an interpreter handy here helps a lot.
Thanks! 
There may also already be a project for reading this file type, though it may need updating. I wrote a yacc parser a long time ago to read Valve's VMF files and that wasn't very hard. I wish I still had the code to share with you.
Yep ... now, in fairness, I will say that if you'd hosted the same thing on Google App Engine or Amazon's Elastic Beanstalk it could quite possibly have cost you about that much every six months, but with a somewhat higher learning curve.
I mentioned coconut (`data |&gt; biz |&gt; bar |&gt; foo`) in an earlier post. Depending on what you want, making everything OOP might actually be disadvantageous because you' ll have to build everything up and make sure that each object you return has the methods you want to apply. Function composition tends to be better for most math-related use cases. If, on the other hand, you're always operating on the same thing, then making it a class is definitely the way to go. If you describe what kind of functions you have, which and how the data gets passed around, we could give you more details.
Remind me, one day, to try and explain just how much reasoning went into why TV was 4:3 for so long. No, there wasn't a lot of specific reasoning, it's a round number that fit relatively well between what various typewriters, teletypes, and other hand-built machines had until that time used as their various "standards". A very large number of things we've received from the past were not reasoned into being, they just fit well into human perceptual biases. If the first punch cards had been invented by the Chinese there'd we'd be arguing about why 88 characters.
I came across this a little while ago, it is more of a reference than a tutorial, but it does cover a large range of topics on the Python language (Python 3): https://github.com/mattharrison/Tiny-Python-3.6-Notebook/blob/master/python.rst I also highly recommend you consider teaching using Jupyter notebooks, if you haven't already considered it and have the luxury of choosing the distribution and libraries you can use. The Anaconda distribution includes this, along with many other scientific focused libraries. I'll add that I do not often teach, but I do need to run code in front of an audience from time to time and using notebooks has been incredibly helpful to keep the discussion moving by avoiding bugs, spelling mistakes, etc.
Yeah, but if you read it ahead, then you incur the same penalty up-front. The only difference would be if there is a large penalty for switching between processing the data in the buffer and reading in more data. And even if there were, its actual effect would depend on how often the switching actually occurs (proportional to how big the buffer is). 
Apparently not. Thanks for the downvote tho üëç
Feel free to pm me if you need.
Hmmm, .pipe looks pretty useful actually! This could solve some of my problems.
A million lines is not that much. Any modern computer can hold that in ram. And parsing is really fast too. Millions of objects per second. So it is not even a matter of optimisation, just a matter of not writing bad code. Usually it is a case of code that runs over the same things squared.
I believe to goes to Level 8, from what I've seen online.
I hear ya, and I agree with everything, but, as someone that maintains a python program that is used by intelligent non-techies (i.e.: scientists) none of that matters. It doesn't matter who's fault it is, or how easy it is to install on linux, or how much space it takes up. They want this as their install procedure: * Go to website and download something * Double click that something * Maybe have to keep clciking "Next' for a while (not reading anything of course, just clicking over and over again) * New desktop icon appears * Double click desktop icon That's it. For better or for worse, that needs to be your install experience. Anything else will be a roadblock to acquiring users. 
IF im not mistaken e = exec e() Is possible
I may be completely wrong, but I'm gonna have to guess it's because Python is designed for open source. While publishing and dependencies have their caveats, pip is great for installing straight from the PyPI. In regards to issues with getting your students to install Python, it wouldn't solve issues with OS or performance issues since you'll need to package a version of Python with the program. This is the case for any language that doesn't spit out binaries and depends on its own environment, and various languages have approached it in different ways.
There's actually a library for that: https://github.com/ajul/pyradox
Sorry, but I don't thing this works with a Jupyter script. I don't think it is a beginner question in this context.
What version of Python is your code? If you installed pip and the twitter module with the defaults, they probably went into your 2.7 Python base. 
But lots of brancells were exercised in trying to figure out WTF?
Yes, it is async (it's based on Twisted). Scrapy is *excellent*. Very mature, *extremely* well documented. Hard to say from the toy example given in this repo, but writing a spider with Scrapy wouldn't be much, if any, harder. 
Iirc wagtail is a cms based on django - I've stumbled across it trying to find example deployables using django. No idea what wagxperience is though.
Did you seriously think someone seriously thought this was a good idea?
Oo, I didn't know about that either. Thank you for letting me know. It's very useful for functions that work on dataframes.
I've used it before without any issues to create binaries for mac and windows
Good work! You built a program, created an installation wrapper (two ways: pip, *and* from source!), set up a small piece of documentation, created a video to demonstrate the program, and shared it with the world. That's a broad set of skills you've showcased. See if you can automatically insert a date of entry/date of creation for each note.
you could use a throwaway variable: path, _ = get_local_path() 
Okay, thank you!
You could run the notebook server on some remote machine you have SSH access to and then use SSH tunneling to forward it to your local machine. Here are the steps (this all kind of assumes a Unix-like environment with SSH installed): SSH into the remote machine and start the notebook server with jupyter notebook --no-browser Note the port number and token, you will need it later. Now use SSH tunneling to bind the remote port of the notebook server to a port on your local machine: ssh -N -L $LOCAL_PORT:localhost:$REMOTE_PORT $REMOTE_HOST -N means no remote commands will be executed, -L is the tunneling flag. Now open a browser on your local machine and type in the address: localhost:$LOCAL_PORT You should see something. If it asks for a login, copy and paste the token from when you started the server. Edit: Everywhere you see $SOME_STRING replace with the relevant piece of information. 
The three projects in question have support / issue trackers which could probably always used help. Tooling in PyPI to enable folks to help is lacking also, unfortunately, but we're working on that.
Here's my random thought... take the 0-255 B/W value and turn it into a percentage... so 127 would be 50%, take that percentage and multiply it by the width of the gradient image to find the pixel X coordinate and pick the color at that coordinate to replace the B/W value. code using pygame: import pygame bw_image = pygame.image.load('bw_image.png') new_image = pygame.Surface(bw_image.get_size()) gradient = pygame.image.load('gradient.png') gradient_width = gradient.get_width() for x in range(bw_image.get_width()): for y in range(bw_image.get_height()): bw_color = bw_image.get_at((x, y))[0] bw_pct = bw_color/255 gradient_x = int(gradient_width * bw_pct) grad_color = gradient.get_at((gradient_x, 0)) new_image.set_at((x, y), grad_color) pygame.image.save(new_image, 'new_image.png') 
You can use a portable Python distribution like WinPython Zero, bundle this in a sub-directory with your program and use a launcher script that sets the path to this distribution before launching your own. The advantage of this setup is that updates to the program itself can be very small once the runtime is installed. On Unices, a Python distribution is usually available through the operating system's package manager.
I was just lurking; but that list is so perfectly true.
Software carpentry is a great resource to learn bash!
That's not the point. The point is to do data.biz() and have the calls to other functions be internal to your class
That's called a context. It's will be just a tiny bit slower but it will ensure the file is closed even if there is an exception. Reading lines this way is not faster.
Conda / virtualenv 
You think you're funny don't ya? Well I think you're just a stinker. 
Thanks for sharing this!
In practice it's not usually very challenging, though finding all your non-code resource files and getting them discovered by the builder can be a bit of a pain. I've seen plenty of large(ish) utilities and apps that were bundled with it. The majority of the time the hardest trick seems to be getting the file size down to a reasonable one for what the thing does, because rogue or unnoticed imports can cause the resulting solve to balloon up pretty quick, and by default it pretty much packages the whole of Python itself in there, including modules you're never using and codec files for obscure languages you're very definitely not using etc. Beyond a certain level of size and complexity I can't imagine you're not reconsidering the virtue or the wisdom of a static single executable running on a desktop, though, and simultaneously beginning to wonder why you're not already working in the languages that have claimed they space as their bailiwick to begin with.
Why has no-one mentionned cx_freeze yet ? it's a python packager that embeds the interpreter in your application, along with all of its dependencies. it's also crossplatform, but will only produce executable for the platform you freezed it on (ie .exe if you run on windows)
FWIW When I was learning OOP I found it helpful to think of a simple Class (no inheritance or anything, just the Class) as a Python "file" within a "file" (technically a "module" within a "module", but in this context, "file" or "page" can help). From there - - The class name is like the name of the module (page) - the class variables are the "globals" in that page - the `__init__` method is what you could think of as the `if __name__ == '__main__'` boilerplate (the setup), leading to.. - The instance variables (the ones setup in the `__init__` method) are only available once the "page" is run (once the class is instantiated) kinda like how objects created in the `if __name__ ...` setup are only there when you run a "page" (module) - and the methods are like functions declared in the page. They can use other methods (functions in a class), and all the class, and instance variables directly, because they are in the "same" file. This is called namespacing (hint: Tim Peters loves em, see `import this`) _plus_ you're already familiar with them while using imported modules. Let me try to write an example. file `Worker.py` - global_variable = 1 def my_function(a_number): return global_variable + runtime_variable * a_number # this_would_fail = my_function(3) # no runtime_variable yet if __name__ == '__main__': runtime_variable = 2 answer = my_function(3) # this works class `Worker` - class Worker: class_variable = 1 # this_would_fail = self.my_method(3) # No "instance_variable" yet def __init__(self): self.instance_variable = 2 def my_method(self, a_number): return self.class_variable + self.instance_variable * a_number instance = Worker() answer = instance.my_method(3) # this works The analogy starts to break down a little bit by this point, but you may be able to see the similarities. And of course there's more to it than that (this is a _far_ from perfect example), but you don't have to learn everything at once :D Cheers, and good luck! 
var = (input(str ()) Works for me.
Can confirm. I work in bioinformatics (BS in physics) but we have and would hire strong programmers with little science background. The IT folks have very little or no science background AFAICT, but that's not what OP is looking for.
The rule is "never ever use python 2's `input()`". It was a silly feature in the first place and that's why it's been removed in py3.
I don't know if it's really relevant today, but during my science studies I used [Matplotlib](https://matplotlib.org) extensively for plotting. Haven't used it for a couple of years, but it looks quite active on Github.
&gt; that's called a context You mean a "context manager" minor knit pick, but will probably help in googling.
Anyone else love that the background of the title image is php+html?
Keep at it! You've done quite well so far for your age. But one thing I noticed going through your repositories is that you've published also something else called EasySqrt to pypi, this package is probably not worth publishing as it is a one liner
According to this issue #265 over on GitHub, they're looking to build up a community around pyvisa for future development. https://github.com/pyvisa/pyvisa/issues/265 It might be worth checking out.
Thank you for your feedback! The EasySqrt program, was a simple program to learn how the PyPi works.
That intro gave me genital warts
[You might find this paper helpful.](https://arxiv.org/abs/1505.05425v3)
Not by any known measure of market share. Android has billions of users. MacOS has hundreds of millions. The entire family of BSD has, maybe, hundreds of thousands, but probably more like tens of thousands. FreeBSD has some fraction of that.
Also looks like someone asked a similar question yesterday https://www.reddit.com/r/Python/comments/6es1fw/where_can_i_learn_oop_programming_style 
Ok thanks
One thing I'll say is... just don't expect people who've never touched programming to fully understand behavior even with the very simplest parts like variables and assignment operators. When explaining through examples, it's easy to gloss over parts that you just take granted for understanding, like seeing: x = 10 y = x + 5 x = 20 ... and someone new to programming wouldn't be dumb for thinking that y might automatically change to 25 after the `x=20`. I think that actually showing a simple example and then stepping through with a debugger and showing the changes to variables as you step through it might help people a lot initially.
Yep, cheers, I'm looking into the docs now.
link leads to 404 now..
I highly recommend to point them towards the book Think Python (2e). It starts from the most basic concepts of variables and stuff and neatly weaves those things into how to use them in Python. The author has a free PDF version online, so any student can use it. Of course it won't hurt to mention there's a print version which one could buy as well.
I found this inspiring ! Thanks
Choosing a fancy name which is unique in pypi.python.org is not a easy thing. The aim of gain is making writing web crawler simple. What's the complex crawls you mean? 
No problem :)
Scrapy is fine and powerful. Gain just want to make things easier.
As a "classically trained" software developer who is often exposed to code written by really smart scientists, I would recommend learning idiomatic python and that they go through the challenge of turning their algorithm to a web service hosted on heroku. Make your curriculum point out why software should adhere to the advice from the 12 factor app. The single most important Python resource for people with a smidge of programming experience should keep this under their pillow: https://gist.github.com/JeffPaine/6213790 OK, I see now that your students are complete beginners. If you ever teach them for a class that is the next step up, I guess my advice is more useful. Thanks for making an effort towards creating a great curriculum for your students. Good luck.
You should post your benchmarking code, otherwise you're just making everyone else reinvent a bunch of wheels in order to try ideas. I'd say that you're onto something with using a hash, but don't use a cryptographic hash like MD5. Calculate the Python hash of the all-zeros block and compare against that. all_zeros_hash = hash(all_zeros_bytearray) # do this once if hash(some_block) == all_zeros_hash and some_block == all_zeros_block: ... The second part is required in case of a collision. Also, I'd try the regex of `r'[^\x00]'`, and make sure you're not re-compiling it every time in the hot path. (I.e. compile it once.) If you had posted the benchmark code I would be able to try this, but alas. 
So explain it? How can you write this script without a single 4-character line?
You are right. Tomd can't parse invalid HTML or even valid HTML. Tomd only has the ability of converting the HTML converted from markdown to markdown.
Ok, some sites (site confidence maybe) let you automate and scale out user journeys. Maybe the requests library and cssselect would be better for concurrency since it would be lighter. One other thought, you can use multiple tabs and sessions and profiles in selenium.
You can't run webdrivers (what selenium controls) asynchronously, but if you're looking at running a webdriver client in the same thread/process as an asyncio webserver, I'm working on something to do just that: https://github.com/hde/arsenic
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [python/cpython/.../**bltinmodule.c#L121** (2.6 ‚Üí 6c00321)](https://github.com/python/cpython/blob/6c003210943fc91e5911bcbabe1fe4b0030cf38b/Python/bltinmodule.c#L121) * [python/cpython/.../**stringobject.c#L1156** (2.6 ‚Üí 6c00321)](https://github.com/python/cpython/blob/6c003210943fc91e5911bcbabe1fe4b0030cf38b/Objects/stringobject.c#L1156) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply diehwud.)^.
Why no wheels?
http://pythonforengineers.com/python-for-scientists-and-engineers/
Your slicing of the bytearray is copying `block_size` bytes on every iteration. If you create a `buffer` instead (`buffer(buf, ind, block_size)`) it will just refer to the original data, you will need to convert you null_block to a buffer as well. That *should* speed things up a bit. Also your initialisation of both bytearrays is overly complex, you can just give it a length and it'll create an all-nul bytearray of that length: &gt;&gt;&gt; bytearray(42) bytearray(b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00') Also you should check that readinto(buf) is faster than just read(len(buf)) and processing the bytes, that's not always the case sadly. You should also look into increasing the size of your blocks, 1k is really quite small ("random small io" tests generally use 4k blocks‚Ä¶). See http://rabexc.org/posts/io-performance-in-python for somebody's experiment on IO speed in Python.
You don't need to use a mutable byte-string type. That's probably adding quite a bit of overhead. Instead of `sfh.readinto(buf)`, just do `buf = sfh.read(1024)`. Using normal (immutable) byte-strings (which in 2.x is just the normal `str` type): &gt;&gt;&gt; testblock = '\x00' * 1023 + 'x' &gt;&gt;&gt; nullblock = '\x00' * 1024 &gt;&gt;&gt; nullhash = hash(nullblock) &gt;&gt;&gt; %timeit testblock == nullblock 1000000 loops, best of 3: 211 ns per loop &gt;&gt;&gt; %timeit hash(testblock) == nullhash The slowest run took 20.44 times longer than the fastest. This could mean that an intermediate result is being cached. 10000000 loops, best of 3: 103 ns per loop I don't know if the warning is correct or a false positive. You'd have to test it in actual code. 
python 2 'raw_input' is now called 'input' in python 3.
Well there are 54 million of PlayStation 4 out there that puts FreeBSD to 54 million. Also add Juniper devices as they are almost non modified FreeBSD underneath. I'm pretty sure there are few millions bsd devices out there more. I contributed at least a 1000 myself back in my days. They are used extensively by professionals from 80s and 90s. Add every FreeNAS and pfsense and many other flavours. And you'd get at least a 100 million devices. That's not small at all Also ps3 is also bsd. That's like 84 million bsds additional. So we can surely say there is a billion of bsd devices inn the wild: https://en.m.wikipedia.org/wiki/List_of_products_based_on_FreeBSD
Reminds me of this old article: http://ridiculousfish.com/blog/posts/old-age-and-treachery.html Look into the Boyer Moore algorithm for string matching. It should work really well with your blocks of 0 bytes as you can skip chunks as long as the block size you're checking for.
Thanks.
Even more if we include OSX/MacOS/iOS ... though we're not, as they're as related to BSD as Android is to Linux. Didn't know about the PlayStation, but also didn't care, as its not in normal usage a general computer, neither are network appliances and devices, and for the same reason also not including the trillions of devices running VxWorks or OS-9 ... none of these are relevant to a discussion of packaging problems for Python applications (or any other explicitly-not-a-systems language, for that matter). At this point we're too far afield to continue.
I really wanted to use vim + tmux because I really liked the workflow, and I wanted to have mega cool vim-fu and it just looks neat having that stuff on my screen. However, as someone who is learning, I'm finding the features of a full IDE like pycharm are just too good to pass up. I don't have the autocomplete features set up as well in VIM and I'm not good enough yet to really know how to get all that going. If I'm ever able to get VIM to work the same as, say, PyCharm, I'd love to go with that. Plus, there's always a bit of lag when I switch between tmux tabs where I'll swap from one to another and then hit arrow keys or something, and it's still moving things in the previous tab. So I have to swab....wait, then do whatever I want to do. Very annoying.
I messed round with buffers a bit, but didn't see a particular speed-up, but I think I'll do some more experimentation on this - thanks for the suggestion. I'm using readinto as in my tests it was a lot faster (like 20%) than straight reads. I assume it's to do with the large number of alloc/garbage collection cycles it causes. I'm already using 8k blocks, which after much experimentation, seems to be the sweet spot. I've tried much larger (8MB blocks) and got markedly *slower* results. Thanks for the link - I'll take a look.
When I tested a naive read (this was the first attempt I made), I found that it takes substantially more time. The 100 million string allocs and subsequent garbage collection means that the read loop takes about 20% longer. Using mutable buffer alleviates this, as does reading 8k at a time (seems to be the sweet spot). This is why I was testing with bytearrays, because that's what I'm using.
You're still copying everything around by doing `buf[x:y]` for every block. But you should be reading much larger chunks than 8k. That's tiny. Why not read 10MB at a time or whatever? Or use the `mmap` module. 
Try C++ its easy to get it back as a python object using the python C api.
 state.atomic('waiting', 1) with state.resource(pid): // here state.atomic('waiting', 1) with state.resource(pid - 1): // here state.atomic('waiting', -2) state.atomic('tasks', 1) If I were to guess it would be where I commented, because the thing locks itself and then locks the process behind it. If the other process locked its own process and the next one is trying to lock it too while the current one is trying to lock the process behind it which is locked, they'll all be waiting. 
One of the most helpful resources that I feel gets overlooked surprisingly often is the original documentation for packages like [Pandas](https://pandas.pydata.org/pandas-docs/stable/index.html). In particular, the ["10 Minutes to pandas"](https://pandas.pydata.org/pandas-docs/stable/10min.html) tutorial within Panda's docs is a pretty useful introduction, and I refer to notes I took while working through it on a fairly regular basis. Advantages of using docs over other resources: * Up to date. You don't have to worry about what difference might pop if a tutorial was written years ago for an older version of the library you are using. You can go straight to the documentation for your specific version. * Comprehensive. Spend some time looking at the documentation for commonly used classes and functions. You might find some uncommonly used methods or keywords that end up being very useful to you. * I personally prefer working through written documentation over following video tutorials or lectures. My notes always end up being much more comprehensive when I'm going at my own pace through documentation, testing out examples in python on the fly to see if the functions and methods behave as I expected. My notes on Pandas concat, merge, join, and append functions where I came up with simple DataFrames to demonstrate the effect of each has been incredibly helpful, as I still mix up how each one works, what axis to concat along, etc. Downside: * Not always the best resource for tutorials and examples depending on the library (although I think the one for Pandas is quite good).
This is quite good for many basic physics problems. Thanks for sharing!
Learnpythonthehardway.com
Using a hash is a waste of time. A hash has to mix up information from all million bytes into a single value, but the OP doesn't need to care about the millionth byte if the first byte is non-zero. Testing for equality against a pre-defined constant block of nulls sounds like the perfect solution. It is implemented in C, it shorts-circuits (exits as soon as it hits a non-zero byte), and it does the absolute minimum processing possible: just comparing two bytes for equality, without any complex hash functions.
Upvote for linking to Old Age And Treachery.
Why don't you know what's in the blocks?
There is a lot of talk about Jupyter, Anaconda, IDEs, etc. Is there a way to fully configure Sublime Text 3 to do everything you need? I currently have it configured to be an IDE and function through cmd+b, but what about all of the other stuff? I'd prefer to stay in Sublime Text
I've been at it for 6 months and still feel totally clueless :)
Hope this helps you - https://www.quora.com/Can-you-give-me-a-roadmap-for-coding-Python/answer/Mradul-Dubey?srid=n0D4 
Thanks...I didn't mean to make it sound like I've made no progress...I'm doing okay with it. I meant more that the Sea of Python is vast :)
Because I'm reading sequentially through a 100GB sparse file looking for null blocks (holes). I can't use "seek hole" or "seek data" - tried that and it's not available on the version of Python I have available. I can't change that. The kernel *might* support it, but if not, I can't change that either.
What is accuracy? Is it a variable or is it a property whose getter references the global "np" variable? Edit: alternatively, if accuracy is a custom object, does the objects `__str__` or `__repr__` methods make use of the global "np" variable? 
Thanks for the heads up. Currently wrestling with a scraper of my own right now. None of the pages have a table like this, but this is still nice to know as someone still getting familiar with python, pandas, etc.
``accuracy`` is an int. ``np`` is used on the next line, line 201, but why is that not reflected in the traceback?
Is it possible that the .pyc is out of sync with your source file? Try deleting the pyc files and re-run.
Nope. No need to give it any effort. You know it all.
For a more complicated scraping situation, I've had really great experiences with scrapy. The API is kind of annoying to learn, but the tool works very well. You can even upload your code to their cloud service to quickly scrape for free on their machines. Pretty neat.
Whatever you end up using, you've given this scientist with middling Python skills a lot of resources to chew on by asking. Thanks!
pretty cool stuff
You probably need to import numpy. You certainly shouldn't be editing your code while you run it. If you do, you need to not add/remove lines.
tl;dr: The Pandas library has a [read_html()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_html.html) function for reading tabular data.
So the map would be fed all the links from a single page. I'll write something like this and post on GitHub on Sunday. I'm teaching some guys at work these concepts and I think it'll make a decent project. 
Do you have access to the ctypes module? If so, take a close look at ctypes.cdll.*, esp memcmp. Make the lengths of your scans powers of 2 to help out the vectorizing code... 
Yep. Helpful input. Glad I read your comment. 
Chrome has a headless mode now, is that an option? Otherwise, just start xvfb as a service and connect to it for you tests?
Try Requests and Beautiful Soup ... 
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Does anyone know how to use this for webpages behind a SSO page? I would like to scrape an Oracle BI report that I use for work, but it is behind VPN and an SSO page. The VPN is not a problem because I'll run it from my laptop after login. The SSO page is a 302 redirect to the authentication page. After login it redirects back to the report I am looking for. 
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
I downloaded all the longish (about three hours each) PyCon workshop videos off YouTube and have begun going through them. I've been doing basic Python stuff since 2010 for work--data entry and accounting, so just processing outlook emails, some web scraping, and spreadsheet processing, as well as integration with my AutoHotKey stuff (yuck). Now I want to switch to a career as a developer, so I wanna learn about the hairier parts of Python, as well as Pandas/SciPy/NumPy, how http works, Flask, and Django. I'm also nearly done with a local program that will help me choose the best course sections at my college by scraping my school's course catalog (Edmonds CC in Washington) and use the data from RateMyProfessors to tell me the rating of each teacher, but not based on their overall rating--just based on the rating average for that specific class. Next steps include creating my own web-based search that would let me search these classes the same way I can on the college website. So far the hardest part has been figuring out how to fake submit a form with cookies using requests (this is why I want to learn more about http).
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
I'm also learning Flask using Miguel Grinberg's PyCon video. How are you learning it?
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Can this land me a job at Wall Street or become a Quant programmer?
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
The SSO should be giving you a token or setting a cookie for you, see what it does in your browser's developer tools and recreate in the script. You'll end up calling the SSO and capturing the response and (likely) using that in the headers for your report request
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
That's awesome.
maybe not exactly what you are looking for but... # Libraries : - Numpy (mathematics) - Scipy (science and differential equations, also contains some mild neural net algorithms) - Pandas (scientific oriented library to read and write data) - csv (to read csv files, which are common. pyyaml, json and pyxml read their respective markup langages) - pymunk (physics engine, 2/3D) - matplotlib (plotting graphs) - OpenCV (computer vision) Those are libraries I think you need to teach your students (for scientific purposes only) and if you want to go the extra mile, teach them about tkinter, it's simple, pythonic and can do a lot of stuff (it's the standrad GUI library in python, quite ugly result, but you can most certainly make nice animations with it). # Algorithms : Before learning to program anything in a specific langage, you need to teach about how to think to solve a problem using computer science. Teach your students how to develop algorithms first, then teach them how to implement them. Examples of algorithms: - Gaussian pivot - Stacks (FIFO and FILO structures) - how to integrate and derivate with a computer (integration with squares, or trapezoids, this may be a good way to teach them about how step size influence calculation times and accuracy) #Python : As with any programming language, you need to start with the basics : - Variables - Conditions - Loops (while and for) - function definition - objetcs (strings, lists, dicts, tuples) - how to use the aforementionned libraries and look for documentation - eventually OOP (classes, metaclasses, properties, decorators, iterators, differences between functions and methods, special methods (`__init__, __add__, __sub__, __repr__` etc)
How does it compare to Numpy's loadtxt() or genfromtxt()?
However, I *am* considering using multiple threads - reader, null-scanner, and writer, so I can at least interleave the blocking calls with the computation part. But I'm quite close to my target of being to within a few percent of SCP on the worst case (i.e. close to no null blocks). Currently it does: Read Read Process Process Write Write But I suspect I can reduce the overall time by doing: Read Read Process Process Write Write 
Wohoo, prizes!
I really wanted to like concurrent.futures but in the end it's API is far too limited once you get away from very basic workflows and very short lived processes. In the end I ended up back in multiprocessing to do heavy lifting. 1. If you choose to use the Pool ( and the not quite so documented ThreadPool ) you have the option to do setup calls and a lot of other things that are just not possible in concurrent futures. 2. The Pool API is far richer with many map variants, specifically imap_unordered(func, iterator) which will call func with values from iterator and yield them as completed. No need to track futures! 3. From the library you can also DIY a parent/worker setup with a Queue object quite easily as well. 4. and more So your main loop could be simplified. with multiprocessing.pool.ThreadPool() as my_threadpool: for result in my_threadpool.imap_unordered(run, linkstocrawl.get()): # Do something SOURCE: Tar dedup for backups, I need to sort through 150TB/week and it requires a wide pipeline. I also went a slightly different direction and created a simple Queue iterator that presumes a None object represents a stop condition. If timeout is none then it will block forever waiting. def iqueue(job_queue, *, timeout=None, stop_condition=None): ''' iterate over a queue object stopping when item is equal to stop_condition or we encounter a timeout/Empty condition ''' with suppress(Empty): yield from iter(lambda: job_queue.get(block=True, timeout=timeout), stop_condition) This way I can simplify my workers for work in iqueue(my_work_queue): # do something 
Oh, come on.
pandas rocks. By the way another great tool for scraping, the one I go to the most is [pyquery](https://pythonhosted.org/pyquery/). If you know css selectors it's great.
OP is a marketer for Citus data. While Citus is cool, this has little to do with Python. Maybe look into database, PostgreSQL, DBA and SQL related subreddits.
And `parsed_html_data.to_json` and `.to_csv` methods for formatting and saving that data. 
Not too familiar with python but I can't seem to find out where pid=0 will try to lock pid=n. Unless python allows -1 to reference the last element in the array I would expect `def resource` to look like this: def resource(self, i): return self._resources[(i + n) % n] 
/r/learnpython
Yes, the purpose of the code is create deadlock. But in this implementation is bug, which causes the program to behave in not expected way, meaning it is breaking following rules. * N workers are repeatedly acquiring and releasing shared resources * main thread is waiting for deadlock * once deadlock is detected, main thread releases all locks causing RuntimeError in each thread The task is to find the bug. 
&gt;But the bad news is that the data lives inside a web page and there‚Äôs no API that you can use to grab the raw data. So now you have to waste 30 minutes throwing together a crappy script to download and parse out the data. It‚Äôs not hard, but it‚Äôs a waste of time that you could spend on something useful. And somehow 30 minutes always ends up being 2 hours. Well, you can always use Excel with external data and export as csv in less than 5 minutes but hey, Pandas is still faster (and free!)
If you name the console entry point `git-feed` then it should be invokable as `git feed`.
Bad day? 
I am the OP. Glad you think Citus is cool. :) (And yes, I recently joined the company in a marketing role this time.) Thx for tip on more appropriate subreddits, will look into it. (FWIW I didn't randomly post to r/Python :-), rather, I picked this subreddit because one of my engineers thought it would be useful for Python devs considering which db to use. Make sense?)
I use scrapy to scrape YouTube. Because the page results don't load all at once, you'll need to get the link to load more results, feed that URL into scrapy to get the json results and parse that for each video link. 
Hey everyone, I just want to thank you all again for the amazing feedback I got a month ago on Flaskex, this sub is awesome. Also I made a bunch of changes based on that feedback, most notably I completely redid the interface using the modern Bulma framework. I hope you like the changes and find this useful for you own applications. Special shoutout to /u/LightShadow /u/nerdwaller /u/Z0ja for the suggestions :)
You'll need to open up the YouTube site manually, find the Ajax link that is sent when a user manually clicks "load more results", and copy that Ajax link to your scrapy code. Look at this blog for some explanation https://blog.scrapinghub.com/2016/06/22/scrapy-tips-from-the-pros-june-2016/
Select all your code in an editor, hit TAB which should of course be set to four spaces, copy and then paste into reddit.
The main tread tries to stop the program by manipulating the locks. This will kill the worker that releases it, but an other worker may still be waiting to acquire it. This worker will proceed and if the timing works out will never be stopped. Even worse, the main thread may try to release a lock that is not acquired and stop prematurely. So #3 is is not guaranteed. Comes to mind that manipulating locks rather then asking a worker to stop asap (possibly interrupting any waiting or sleeping threads) is bad practice. 
This was a delightful read. If it looks greek to you, and you'd like to understand what this is, start with these youtube lectures. They certainly helped me! :D [CPython Internals](https://www.youtube.com/playlist?list=PLqm_hc_sQWjZD7a5Su7xm30qQ_Mfk87q3)
I know huh. I read the title and thought 'uh, I know how to use requests and beautifulsoup... why did this receive so many upvotes?'. I read the rest of the article and was like holy crap I could have used this on my last project.
You're still wasting your time looking at every single byte instead of short-circuiting.It doesn't matter whether using a simpler hash function is faster than a complex cryptographic hash. Of course it is. The question is whether it is faster than a short-circuiting equality test. It doesn't matter how little processing your hash function does, it still does more than is needed to compare bytes for anything not null. Quoting your own code: hash(some_block) == all_zeros_hash and some_block == all_zeros_block could be generally faster than just some_block == all_zeros_block Let's take three cases: - block is a null block; - block is all nulls except for the first byte; - block is all nulls except for the last byte. In the first case, your code has to look at every single byte, and mix them together into a single value; then, after its done that, it still has to do a string comparison in case of hash collisions. (Since you're not using a cryptographic hash, collisions are a real risk.) That's obviously more work than just doing the string comparison. In the second case, your code looks at every single byte, hashes them, and skips the equality test because the hashes are unequal. (Ignoring collisions.) But the equality test only need compare one pair of bytes, so it beats your code. In the third case, your code looks at every single byte, hashes them, and then (probably) skips the equality test. But the equality test still does less work: it too has to look at every pair of bytes, but that's a simple memcmp operation which is likely to be faster than any reasonable hash function you can come up with. (A *really dumb* hash function might do something like just return the first byte of the block; that's pretty fast, but you'll have lots and lots and lots of collisions, so you still need to fall back on equality.) So in the *worst* case of a block of all nulls except for a single non-null at the very end, your code is no better than a straight equality; in the best and average cases, it does a whole lot of unnecessary work hashing up bytes. The better the hash function, the more unnecessary work it does. Hashing the block might be justified if you need to compare it repeatedly against a whole lot of different targets that can be specified in advance, ("is is all nulls? how about all spaces?") but otherwise it's just wasting time and electricity. 
If you would have googled it, there are a few complete tutorials for libtcod that come up as the first link. 
Oh if you need those and you're on Windows you just download the whl file and you're golden.
Unorthodox recommendation but I really like using selenium for stuff like this. It's a browser automation library that allows you to grab information as long as you know the selector or xpath or etc. of a certain element. Also, you can use it for logins if the information is locked behind a user account.
I had no idea it would post like this. It looks terrible - thanks for the tips. 
Web app crashes in my browser. I guess i don't need that information.
Another tip create a session object with requests.Session(), it can speed up requests a lot.
Just tired of bad web design. I'd rather have geocities than some of the stuff people develop these days.
How well does this work on data that isn't formatted so nicely? 
not sure how sublime runs the code, but if it simply runs your code as a .py script via a Python binary, you prob want to add sth like print statements. e.g. print(df.head(10)) print(df.describe()) When working with pandas interactively, I highly recommend an interactive Python shell like IPython. Also consider Jupyter Notebooks, which show pandas DataFrames and Series as nicely rendered HTML tables
 How to parse Wikipedia with multiple tables? import pandas as pd tables = pd.read_html("https://en.wikipedia.org/wiki/List_of_United_Nations_organizations") print(tables[0]) This prints all the table!!
[Looks like it's been addressed in 3.7](https://bugs.python.org/issue30509). 
+1 for the name...
If there are no tables, it seems it will not produce anything: &gt;&gt;&gt; import pandas as pd &gt;&gt;&gt; import requests &gt;&gt;&gt; resp = requests.get('https://www.reddit.com/r/Python') &gt;&gt;&gt; pandas = pd.read_html(resp.content) ValueError: No tables found Although I did get this error trying a local news website that does contain tables: TypeError: ufunc 'add' did not contain a loop with signature matching types dtype('&lt;U82') dtype('&lt;U82') dtype('&lt;U82') 
Ty for doing this
[removed]
Things are never done. I've been working on a project for 6 years continuously. Not even close to being done.
Don't use `setup.py upload` to upload packages to PyPI. Instead, [the official recommendation](https://packaging.python.org/distributing/#uploading-your-project-to-pypi) is to use [twine](https://pypi.python.org/pypi/twine). The workflow is then either: python setup.py sdist bdist_wheel gpg --detach-sign -a (name of .tar.gz file) gpg --detach-sign -a (name of .whl file) twine upload dist/* or to shortcut: python setup.py sdist bdist_wheel twine upload -s dist/* 
Silly question but does x, = list give you the first element of the list? And since when? I like it. 
Yes it is possible .
what an `achievement` to hooli inc!
Can pandas read xml output to dataframe? I am using requests to get data from a site that gives output as xml. I want to parse that xml output to csv or something to use with excel
Tuple unpacking! Only works if it's a single element iterable, though.
r/learnpython
Unfortunately does not work for cloudflare based web pages and others which use ajax to grab their data. Or have I missed something? 
pycharm mostly, I use ST3 for quick edits for multiple file formats. I am using a lot of plugins like json to yaml, graphviz etc that are not related to a programming language.
[removed]
[Python 3 support is right around the corner](https://forum.freecadweb.org/viewtopic.php?f=10&amp;t=12534&amp;sid=4ccb9a39391dcf1e9ef635c294932fe8&amp;start=390#p176885) :)
Do you do any form of analysis? You could do some post-processing with python which could both show your python and analysis skills at the same time.
I tried to find projects relating to the 'computerized maintenance management', but I dont see much on it. Is there a link or any idea you may have where there are projects relating to CMM? I can pick a project then, practice it and use it on my resume perhaps.
I like this.
For those are starting &lt;sic&gt; up with Python 2: You are making a mistake, you should switch to Python 3.
This seems cool and useful. I don't understand exactly how I would incorporate it into a custom class, however. Say I created: class Person(BaseModel): name: str = ... and then wanted to define other methods in the class. Do I do it in the `Person` class above? If I want to define my own `__init__`, do I need to `super().__init__` too? Or do I somehow link the class that inherits `BaseModel` to another `Person`-like class that defines my `__init__` and other methods? Maybe adding an example for this could be really helpful too.
Python has broad use cases. Entry level for what kind of position or field? Data analyst? Data science? Web development? Systems admin?
Thanks
Thanks!
To find the index of the maximum number in a list (I'm assuming you mean python lists, not arrays): idx = lst.index(max(lst)) If there are multiple elements with the max value this will find the first. Then you can use that index in the other list. --- If you have more questions like this it's better to post them on /r/learnpython. Be sure to [format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin. Also, include which version of python and what OS you are using. 
Let's have two arrays: one called months and one called numbers. Have a counter and set it equal to 0. For every element in numbers, check to see if the element is greater than counter, if it is, update the value. This will find the largest value. Now you have the largest value in the array, run a linear search over numbers and return the index of where the greatest value is. Simply then return months[index] **Edit** Didn't realise that the option supplied in the other answer was a thing that can be used. Use that to replace the 'for' loop to find the maximum and then the 'for' loop to find the index, as it is much easier to code, easier to write, and is probably more efficient. 
I would say learn database and web languages. HTML/CSS/JavaScript is kind of like a single package. Then you could learn some database, like SQL or NoSQL. This could store data and then use the web languages to make that data available to your clients on their smartphone.
I would first see what you were using Python for. As others have said probably expanding into Databases or platform specific(C#/.NET) for automation of tasks would be good. Basic web which you may have covered will be helpful but I would advise going down the javascript rabbit hole unless you want to be keen on more frontend development. 
[removed]
Add the missing docstrings to all the classes and functions of a library you already know. Forces you to really understand the logic while doing a great service, and attaches your name to an existing project.
&gt; Python has hugely helped me out with all areas of my legal practice, and as a result, I'm one of the most efficient lawyers I know. I am incredibly curious about what uses a lawyer has for programming. Just some brief examples would be awesome :)
Now I may not be a lawyer, but I can't imagine too many legal tasks could really benefit from C. I mean what's he gonna do, write control software for a subpoena? Major +1 on the git suggestion, though. It blows my mind that no other disciplines learn revision control. Git should be mandatory knowledge for _anyone_ who creates _anything_ with computers.
Really wish the the back end was open sourced. Would be nice to be able to run a private node as well as be able to contribute to the project. If it doesn't happen in the near future I might just have to build it a backed myself, would be a good little project I suppose.
Either SQL or Rust, depending on the tool you need. Realistically, SQL has such a small surface area, you can learn most of it very quickly. I highly recommend the free, online Stanford Databases course. Rust is my recommendation for a powerful, crossplatform language. I think it is a far better language for semiserious programming than C, lacking the gotchas and historical mistakes of C. If you're only interested in Windows, then C# may be better, but you can do anything C# can do in Python with IronPython, so Rust would be more of a new tool.
Could you share a little more about what you do with python to help you in practicing law?
Author and date are exposed in the API; don't scrape. https://developers.google.com/youtube/v3/docs/videos#resource and https://github.com/youtube/api-samples/tree/master/python
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [youtube/api-samples/.../**python** (master ‚Üí 875d380)](https://github.com/youtube/api-samples/tree/875d380396ba5771322f7d1bf678bbf42b63ecc6/python) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply digc8qk.)^.
Here's another vote for SQL. At some point you're going to deal with a lot of relational data and relational databases are still the best tool for the job. Learning the finer points of index creation and usage could prove very helpful after the initial syntax and concepts are dialled down: http://use-the-index-luke.com/
Latin?
&gt; Some 1000 hours [You're 1/10th of the way to being a master](http://gladwell.com/outliers/the-10000-hour-rule/)!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Look into JavaScript, specifically AJAX.
Will do! thanks!
This is cool, dude. I hope you don't mind me asking, but what sorts of things have you been using python for? One note on learning programming languages, by the way. When you learn your first language, there's a lot of new stuff coming at you at once. You're actually learning **four** distinct but related skillsets: * The syntax of the language. * The semantics and design theory of the language and paradigm (object-oriented, functional, and so on and so forth) * The theory of how to program. * The knowledge of the language's libraries and toolkits and their idiosyncracies. Actually, you could add a couple more ideas to that list -- this is just what I've personally discovered as a programmer and a teacher. So why's this important? _Learning any new language or tool will be easier based on your progress in those topics._ In your case, since you've learned python, you've got a good grasp of the high-level theory of programming and you've probably picked up some object-oriented design concepts (though Python isn't strictly OO). If you wanted to pick up another high-level object-oriented language like C# or Java, it wouldn't be that big a leap -- you'd just need to learn the syntax, the libraries, and a bit of idiosyncratic language semantics. On the other hand, if you wanted to learn Haskell, you'd basically be starting fresh with the functional paradigm, so you'd have that much further to go. Which isn't a bad thing -- it's a matter of whether you want your skillset to be broad or deep. _But regardless of what you want to learn next, you've already got a basis in those four topics, so your next language will certainly be easier than your first._ ^(unless you want to learn Rust which is just really damn hard)
Spyder feels like an awkward in-between between a full IDE and a text editor. If you want a full-featured IDE, go with PyCharm. For a text editor, try VS Code.
Are you looking for a website monitoring tool, or are you trying to write a web client for monitoring your own long running python process?
Indent four spaces to make the text be treated as code.
You've told me how I can do this, but you failed to tell me *why* I should do this. Given the existence of PyPI, why would I repackage a Python package as a Debian package?
SQL is data, and data is power these days ;)
If you have an NLP/ML background, text summarization, document clustering/classification, named entity extraction, web scraping etc. are areas with high ROI potential. From a more general perspective, automating administrative tasks can be really useful as well. Source: I'm a data scientist and my wife is a lawyer. TONS of interest in using machine learning in a legal setting. 
SQL is a good suggestion. If being practical for a lawyer is a main deciding factor, then another option is VBA aka Visual Basic for Applications. (I know that many people here do not like it). For example, I have a VBA script that categorizes my emails in the Outlook (moves them to different folders and deletes some of them based on a custom score). This is the only way I found to keep them manageable. VBA is the scripting language of the MS Office. It is useful for all kinds of calculations in Excel, mail merging and sending or printing out Word documents etc etc. 
I started in Python and began learning web development. After 2 and a half years I realized I could use python AND develop for the web. I have been having a stupid amount of fun ever since. 
Thanks! I'll look into those.
Take Scheme and go with SICP.
VBA, it's great for office use and helps to automate a lot of tasks 
Take a look at sqlalchemy then.
AWS! Of course there are SO many things on Amazon AWS these days but I would focus on things like Lambda (serverless compute), EMR (Big Data), and other Analytics tools. Your primary job will benefit from the ability to leverage large sets of data and turn it into actionable information. 
If you have a complex package and need to include compiled code for different architectures. 
Lawyers need to do absurd amounts of reading. Anything that can both cut down on chaff and point you in new, useful directions is highly lucrative.
Really? How would a person get into that? I have been spending some time with machine learning lately but haven't found a project to really sink my teeth into. Every idea I have I either find a project that is already ridiculously good or just no data to train on.
LaTeX/TeX for optimal document typesetting 
Isn't Python great for office use and automating tasks?
I like the interesting help questions (not the basics). For instance, the barcode scanner one or the music one a while back, weren't the "do my homework for me" crowd, but were "help me fix this annoying issue". Relatively uncommon, and even if the solution is simple, it's nice to read about what they're using the language for.
You could try turning both of the list comprehensions for poss_words into generator comprehensions to avoid creating those big intermediate processing lists. I am not sure how much time this will save but it will save on memory. 
How's your accuracy been? I've found open source OCR tools to be a bit hit and miss (I do research with medical records for one of the big 5 health insurance companies). Curious what you've been using and what kind of accuracy you're getting. 
Python is a language that makes it easy to use libraries from many other languages - C, C++, C#, Java, PHP, Perl, R, Julia, Fortran, Lua, etc. What about a complementary language that makes it easy to call it from many other languages? [Haxe](https://haxe.org/) is a language that can target C++, JVM, .NET, PHP, Javascript, Node.js, lua, Android, iOS, and even Python! Between Python and Haxe all of your bases are covered. 
I agree with everyone that recommended SQL. While it's not a programming language, I'd recommend regular expressions if you haven't learned it already. It can be used easily in Python and can add some real magic to searching through large amounts of text for specific or ambiguous things.
Yeah, I dont see much reason for a lawyer to learn C. But learning how to use PyPy or Numba to speed up computationally intensive parts of his applications
If you already have pandas then no problem. But adding it just to parse an HTML table or CSV in some build script or whatnot is overkill. That said the more it is used the more likely it will be already present when you need it. For CI environments look at Docker to avoid unnecessary rebuilds.
Sorry to be a little off topic. I am wondering now. How difficult, according to you, would be to become a lawyer for a seasoned python programmer? Just curious. 
Just starting messing around with Lambda a few days ago...so freaking cool. It's like having a free rapsberry pi in the cloud.
Learning something to manipulate data in a managed way like in a database is very useful indeed. Although in my experience it is often easier for people without CS background to learn how to use some type of NoSQL. Some examples you may consider: * MongoDB for general purpose data storage/analyzing - Very easy to work with from python, since it stores everything in json like format so it maps beautifully to python's dicts. * Neo4j it is what is called a graph database - Here is a good [explanation](https://neo4j.com/developer/graph-database/) NoSQL solutions often provide more logical data storage compared to traditional DB. It is much easier to use NoSQL store effectively without much knowledge about theory behind it. The more I learn about relational databases I become increasingly convinced that without taking advanced DB course at uni or reading a few fat books about how to take full advantage of database it is difficult to utilize relational db to its full potential and you are very likely to come into issues.
How much is a Mathematica license again?
GO improves on areas where Python puts it all together, but I would recommend something that you can use to compliment your Python knowledge or to help with work... Maybe something to allow for better dataviz or data manipulation... I'd recommend SQL, JavaScript, and a long shot of R or LaTeX. 
From the other side of things (Computer Engineering for a while and just got my JD), I'd go data mining and database based stuff. That, or web based languages (Javascript and frameworks like Flask, Node.js, etc). Possibly PERL for text parsing, but I think python works well enough for your needs. The idea here is that you have all the data you have access to, but you need to be able to find the data you need (hence databases and mining) or you need to be able to communicate with others (hence web based tech) I do embedded development primarily and I don't see the system languages being of great use to you (So, no C, C++, Rust, etc). Java maybe if you want to mobile apps (but webapps would probably work just as well, hence the above comments). Functional languages probably wouldn't be a strong asset but would be interesting (So no LISP and similar).
I was thinking along the line of finite element analysis, but it pretty much can be anything. However, it would probably be best to link it together with something you have studies. Another idea would be to contribute to an open-source project. 
"From reading unintelligible code to reading unintelligible code - my transformation from lawyer to coder"
Seems petty cool! 
Woah. Can we all three start a conversation about this? I too am a lawyer and I also code for fun but I've never used programming in the context of practice. I'd be fascinated to hear how you all do.
Interesting you'd post this. I'm a Document Management Admin at a major firm, and use Python on occasion for some SQL jobs to maintain the DMS systems. I'd highly recommend SQL and looking into different Document Management platforms, like NetDocs, or iManage. iManage in particular is looking to do some very cool things with REST API in their new releases, and has been talking about AI type search capabilities going forward.
What about javascript driven websites?
I'm a coder who works from a coworking office that happens to also have a few lawyers as members. A couple of months back I heard a couple of them talking lawyer stuff as I walked by on my way to the kitchen. I stopped and commented that this must be what we (coders) sound like to everyone else. They got a good laugh out of it.
/r/learnpython please
Single Coding Lawyer Fighting for her client Raising null exceptions And being fully compliant Hey.... Im pretty good.
Haskell. It changes the way you see programming and helps you be more cautious against any kind of error. Parsing in it is a very pleasant experience.
Imagemagick for image manipulation. Tesseract for half of the OCR. Then I got my firm to spring for the Acrobat Pro license, and have used that for the remaining OCR. I would say they were comparably accurate (but both not perfect). I feel like tesseract did better with images that needed rotation. Acrobat was meaningfully faster, but they were both so slow that I'd set them to work on a few hundred docs on one computer and then do something else on another. Tesseract is nice because you have the option of setting it up to output a separate text file. For manual doc text searches I've been using DocFetcher, because Acrobat's search sucks hard. I manage it all in Excel. 
I don't know what kind of law you practice but if it's contract law, you may want to complement your Python knowledge with cryptocurrency like Bitcoin or Ethereum: https://www.ethereum.org/greeter
This is awesome, thanks for putting it together.
I would buy this.
Hey I'm a lawyer and I know Python. Learn Swift if you use Macs. I've used it to create a small batestamping app for discovery. And lots of little things. When filing motions with exhibits, I created a swift command line program that attaches a page in front of each exhibit that says "Exhibit xx" or whatever. Also one that attaches little exhibit stickers to PDFs. If you're not on a Mac, I might suggest you find the window equivalent of swift. Python is great too. I use it to manage some of my more voluminous discovery. :) 
Just wanted to say as a developer that lawyers with programming skills are devs with wings. You guys will be the last to be automated when the robot overlords take over. 
kaggle.com is good practice. Curated data sets and you can see other people's solutions and learn from them.
Google really painted themselves into a corner with GAE: the original implementation (now called the "standard environment") achieved security and isolation for Python apps by using a home-grown in-process sandbox. Implementing this kind of in-process sandbox is extremely difficult even when a language environment is designed with this as a goal from the start (cf. all the Java sandbox escapes over the years). That they managed to retrofit it onto an implementation like CPython was incredibly impressive, but not really sustainable: even 2.7.x -&gt; 2.7.y upgrades basically requires they redo all that expensive security auditing. The big news here is that they finally managed to get off of 2.7.5 (released &gt;2 years ago). Everyone now agrees that putting the sandbox in the process is a bad idea, and that the sensible strategy is to instead put the process in a sandbox (using containers or whatever); the problem is that since they shipped GAE with the first strategy, they're stuck supporting it. The "flexible environment" is basically an attempt to migrate to an architecture that is less, like... doomed. I'm extremely curious what their plan is for supporting python 3 in the "standard environment". "On the roadmap" is pretty vague ‚Äì I won't be surprised if it turns out to be wishful thinking. 
We aren't a site, but there is a large python slack group (note: not official or sponsored, 100% community driven). By large I mean we just past the 6000 member mark a little bit ago and have a pretty good distribution around the globe (USA, Venzuela, Mexico, Canada, UK, Belgium, Spain, Russia, India and Australia - at least those are the most active ones I can recall, but the list isn't exhaustive). There are channels for most the big things: Django, flask, help, learning, general chat, etc. If you're interested in joining up we'd love to talk python with you: https://pythondevelopers.herokuapp.com/ Disclosure: I'm one of a few admins there. Edit: looks like the heroku app may have exceeded the free limit - I think the invite form on https://pyslackers.com is working as an alternative.
Once you learn SQL, an Object Relationship Mapper (ORM) is useful for doing high level abstraction to a database. A popular one for python is SQLAlchemy but I really like PonyORM so try both
Upvote for Golang
+1 to this. Learn Solidity!
Chinese
I've done lots of dynamic language dev, and so far JavaScript on V8 (NodeJs) is an absolute pleasure. You get the optimized engine that major deep pocket companies have been working on (V8), combined with a great evented model (which is hard to replicate in Ruby or Python), and with add-ons like Typescript, you can have type checking like compiled languages (albeit more restricted). I hated writing unit tests in Python after using RSpec in Ruby, but JS can do deeply nested DSL's like Ruby, which is super powerful. Also, Node has a nice module system, which I love above Python, and which lacked in Ruby. Expand your development to the net for MAXIMUM FUN!
&gt; How much is a Mathematica license I think $150 if you're a student and just under $3,000 a year if you're a non-academic professional. That's about the range for an individual account. 
IANAL, but I agree that SQL is a good idea.
Ehh most time is probably going to be spent getting files, accessible data and parsing. Lawyers don't really do numerical work, so I don't think he'll see much of a speed increase
It seems germane to mention that my brother, a lawyer, got into a long discussion/debate with me and another brother (also a computer scientist), and he came to the conclusion that both of us would be good lawyers. I think there is a common cross-over for the kind of mental processing that that serves both disciplines well. 
Yes, but you should learn and become proficient in SQL first, then look at an ORM. I'm primarily on rails now and love Active Record, but being proficient in SQL is a bigger help to my development than Active Record is.
It's pointless to learn a random language. You should have some sort of a need/requirement/area of interest for us to recommend a language. A few things I could think about for a lawyer * R - statistical analysis and data manipulation * JavaScript (Angular, React etc) for building simple web applications, interactive data visualizations using libraries like [D3.js] (https://d3js.org/)) * [Go](https://golang.org/) for web application development, data manipulation * SQL or PostGres for understanding relational databases, schemas for efficient data storage and querying
Rust is another good, practical language to use. If I may, what practical "legal" problems have you solved with python? (I'm interested and curious how you used it to your benefit!)
You might want to check out Ethereum smart contracts. There might be a ton of value in the coming years for someone who is a lawyer and also knows how to program smart contracts. There's two languages used, one looks like JavaScript and the other is similar to Python in syntax, so that would be a natural jump, but you would have to learn how contract oriented programming works.
I've only had a problem with it when working with extremely large numbers or data sets. Even then, I can typically solve the problem by rewriting using numpy. I didn't believe the difference until I wrote my first C++ application, though. If you haven't tried it yet, write something in Python then implement the same thing in C++ so you can see the difference yourself. It's hard to describe otherwise. 
https://docs.python.org/3/library/tempfile.html#tempfile.TemporaryDirectory can be used as a context manager, not sure what this package really adds.
Would you mind sharing how you went about that? (generalized or detailed, doesn't matter). I'm about to work on an extremely similar project and would like to see if I'm on the right track. I've tried out a number of OCR modules for python, and I think I've settled on ImageMagick and Tesseract as well. I'm also curious on performance too. Thanks in advance!
/u/opfeels /u/opfeels
/u/opfeels is mostly positive! [view results](http://ruadick.com/user/opfeels/) - Ranked #3587 of 86102"
"Judge, I only killed him because he uses tabs!" "Oh, okay. You're free to go now."
cheers!
Oh dang, thanks! I've been wanting something like this actually!
No problem. Discovery docs were handed over on a bunch of DVDs with the docs in tif format. On each disc there was a loadfile for concordance, summation, and one other ediscovery format. There was also a readme file explaining the fields for each. One of the fields was the starting bates number and the next was the ending bates number for the doc. I think you can guess the rest from here. I loaded all the DVDs locally (so I can put the originals away safely). Used imagemagick to combine all the tifs between BatesBegin and BatesEnd into a single multi-page tif for each doc. Rename the combined tif to a tif with the starting bates number. Save to a generic folder where you're keeping all the combined tif files. Harvest all the information from the loadfile into a csv file that you can open in excel. Or if you don't know how to do that open it in Notepad++, copy it, paste it into Excel, then convert text to columns. Over and over. I did make a mistake by applying OCR with tesseract for each tif as it was made. Don't do that. Make your big combined tifs per batch in one process, then go back and do the OCR. It's too slow otherwise. Convert to PDF with either tesseract or Acrobat. Then create hyperlinks in excel to the local PDF file. Now you can click through and open fully OCR docs with all the meta data. 
Sure - http://www.austintaylor.io/lxml/python/pandas/xml/dataframe/2016/07/08/convert-xml-to-pandas-dataframe/ Then once the XML data is in a DataFrame object, just use `.to_csv()` or `.to_excel()` to save it to a file.
I can't answer for him, but I've used python to scrape court opinions from administrative websites so I could search them. That was huge. It was a local administrative agency with something like 300ish decisions "published" each year on its terrible website with zero search functions. So I scraped all of the decisions for 25 years and wrote my own search tool to text search the cases. I found what I needed and won the shit out of that case. Too bad I never had another client in front of that agency. I could've cornered that market.... Edit: I didn't read your last sentence, so my post isn't really responsive. But leaving it up.
I am learning Python while working on a Masters in Business Intelligence. I'm not a lawyer, but I have a Paralegal certificate and work in IS purchasing/Software Licensing. It's not obvious, but a large amount of my job involves data management and harmonizing data from multiple sources. I've been an Excel junkie for years, including using custom functions to use Regex. I'll second the suggestions for SQL. I am just finishing up a class in Machine learning in SPSS, and want to try it in Python over the summer. 
u/opfeels u/science4lyfe 
You can use pip's built-in [hash checking mode](https://pip.pypa.io/en/stable/reference/pip_install/#hash-checking-mode) to tell it the expected SHA-256 hash of the package. Then pip will calculate and verify the hash before installing, and bail out if any package hashes do not match the expected values. You can also script things to grab PGP signatures (if the package makes them available), check the signatures of downloaded packages before proceeding to `pip install` them, and bail out on a signature mismatch, though pip currently has no built-in features. There is [distlib](http://pythonhosted.org/distlib/), a third-party package which builds on top of the packaging infrastructure and, among other things, provides [an API for verifying package signatures](http://pythonhosted.org/distlib/tutorial.html#verifying-signatures).
Javascript. Learn Javascript. If you need a UI it will probably involve Javascript.
Another good for SQL and relational database design.
I suggest you leverage your knowledge of Python and learn a framework like Django. And while there move on to Django REST Framework as well. Between those two you can make interactive web sites, back-ends for mobile sites, or shareable APIs that others can use to build cool applications on top of yours. Django also gives you Pythonic wrappers around databases so you can use them to easily access SQL-based databases.
No, that's an excellent example use case, you should definitely leave it up. 
I generally write in Atom and use Spyder to run the program.
Right, my apologies 
or NLTK
C (Rust, Nim, etc.) Also allows you to write Python modules. That let's you write Python for the most part and drop down to a lower level language for any slow parts.
Haha. Yes.
I'll make the same recommendation as /u/SchwarzerKaffee : JavaScript. I hate it but it's the only programming language that allows you to run Code in a Browser (as far as i know). With Javascript you can write Web apps (you might need to learn a bit html and css, but those aren't programming languages and you can probably learn the basics in 1-2 hours). Basically JS allows you to run apps on any device with a browser and you can make it communicate with python code that runs as/on a web server. 
It's like studying to be a doctor. If you have a bachelor's then you go to law school for 3-4 years, then you have to pass the bar exam and get licensed (in the US at least). 
Python is a great language for you really, and will satisfy most of your needs. For some of us the second language to help would be C/C++/Rust so we can write high performance modules for Python, but I don't see that really helping you so much. It's less about automation and more about performance. You might start dabbling in different Python technologies that might aide you more. Like others have mentioned, SQL is a good thing to know, but it's pretty simple and quick to learn. Elasticsearch is another great one, as is Mongo (but ES is better for complex and fast queries). I would honestly recommend a Document DB (Mongo/ES) as opposed to a relational DB like the SQLs because I would think Legal might make much more use of things that are easy with a document DB. You might even be interested in a Graph DB like titan or Neo4j. You could basically ingest legal stuff and query it incredibly quickly if you set it up right. Another thing you might look into is web scraping in general with scrapy and requests and beautifulsoup. I imagine web scraping could open up a lot of potential for you. You could even do web development with nginx/gunicorn/flask or nginx/uwsgi/django. This opens you up to building interfaces for your programs so you can just browse to a webpage and use stuff you wrote. Python really is a swiss army knife, and you might benefit from learning different things you can do with it more than a whole new language. You might know python, but you probably don't half of what it can do. Web development, web scraping, ingesting and querying for documents... lots of different things you can learn that will take a while but open up tons of new possibilities. You might learn Linux and learn about setting up servers. Yeah, you can write python now... but you need a platform to host your code and run it in the background. Sure, running a script is easy enough from your laptop, but what about hosting a web scraper on a server and have it crawling a legal site 24/7 building out your database for quick queries? Knowing how to set up linux servers and deploy your applications to them opens you up to a ton of new things you can do. In conclusion, I suggest that you keep up with Python and just find more ways of using it and learn related technologies that let you use it in cool new ways: SQL, ES, Mongo, scrapy, Linux, web development, statistics, big data analysis, etc. Python on its own is great, but you'll be amazed at what kind of things you can do if you learn how to use it in a much wider arena. Really cool to hear yourself and others are finding use with programming outside of tech! Keep it up
I had a lot of problems with concurrent write access with SQLite. Really dissapointed that I can't track basic access to the data within the database itself. More than even one concurrent user completely choked the process.
Find a cool project you will be passionate about. That's one of the best way to learn. What would a good carpenter's answer to someone asking: "I know how to use hammer, a saw and a tape measure. What's the next tool I should learn?" be? He is unlikely to suggest you learn how to use a press drill next. He might show you some nice projects he is currently working on because he likes them and they might inspire you. It can be hard to learn what's possible out there. Check out what others are doing. Go to conferences. PyCon is great for that. Browse the open source projects on Github. Follow the development news. Everything that needs a ledger, some form of permanent records or some kind of programmable contract is likely to move in some kind of blockchain technology. There might some interesting ideas out there for you.
Great article about puzzle solving with Hypothesis. How would you do the Fox, Hen and Grain problem with this? Please help.
I've been writing Python for about ten years now, and I tried many other languages. I would suggest you try to see past Python itself. Really, Python gives you access to a unmatched variety of tools (machine learning, databases, information retrieval, docx generation, web site building, etc etc). Unless you have special needs or specific curiosity, you might just explore a new area, using the language you already know. To make an analogy, you'd learn French because of the access to French culture it affords you, but if that were accessible in English, would you bother? If it's really just curiosity, then you might try something really different. SQL was a good suggestion here, since you can already use it from Python. Elasticsearch might be interesting too, especially for a lawyer. 
These tools are available on Windows too.
There are already some massively helpful suggestions on here, but I just wanted to add the (probably obvious) comment that the best choice here is wholly dependent on your goals. Also some languages will add power and flexibility to what you do with Python, while others will let you do something that python can't or teach you something more about programming generally. Here are a few examples: - If you want to be able to process big structured datasets more effectively with Python, combine it with SQL ‚Äî learning about efficiently structuring databases and queries will be as useful as the language itself, and will help you understand how to use a package like SQLAlchemy effectively even if you never write a line of actual SQL - If you want to put a simple Web-based interface on the programs you write in Python, learn HTML, CSS and a little bit of Javascript, plus a web framework like django or flask - If you want to learn something with a similar scope to python but different strengths and style, try Ruby or PHP (popular for Web development), R or Julia (great for statistics and machine learning) ‚Äî note that aside from personal preference, one big reason these languages are used for specific things is the communities that have adopted them and built toolsets on top of them, rather than anything innate in the language - If you want to learn something completely different that will make you a better programmer, you could go with a functional language like lisp, Haskell, F#, Clojure, any of which will give you new conceptual tools and change the way you think about python programming - If you want to overcome bottlenecks in your python code and learn more about how computers work at a lower level go with a compiled language like C, C++, Fortran (only joking) or C# ‚Äî D and Rust are looking interesting in this space too and will protect you from mistakes a bit more kindly into the bargain - TBH, if writing faster code is of interest, you'll get much more from learning about data structures and algorithms than learning a compiled language, and python has some great tools for experimenting with those (e.g. the timeit module for comparing speeds of different implementations) If you have no specific goal and just want to learn something new, I recommend you take a look at Haskell. I hope that helps! 
How will you tell if a website is "local"? What if it is not fully local, but a part of it is?
Wow. Python and law together. Very unusual combination in my country.
In my experience, most performance problems can be overcome by a change of algorithm or a change of tools, e.g. using numpy and/or pandas instead of pure python for-loops for data crunching. I haven't tried it myself, but I've heard good things about Numba's ability to speed up python code with little or no effort. You could also try a different python implementation: PyPy is supposed to be much faster for some cases, and IronPython will play nicely with your C# code and let you use any .NET libraries (ditto for Jython with Java libraries). 
[removed]
I keep thinking about this so let me throw more fuel on the fire. Imagine during discovery a company turns over 3.5 million emails. You might be able to use command line utilities to grep some interesting facts, but that has its limits. Maybe you'd write a program to filter out all the emails sent to your client by one suspect individual. Ok, now you have 55 emails that your client already had. What about people who were sent client emails as a forward? Well, you'll need to write another program that searches the text right? All these programs are 1-offs that will really grind on you. What about using bigquery SQL Write a program that uploads all the data to bigquery as json using the format {'unique_id': something, 'all_people': [addresses...], 'to':[addresses...], 'from':someemail, 'anycc':[addresseses], 'text':email-body, 'subject':subject-line, 'timestamp':TS} Now query it! # This could be useful, maybe what you already know though. SELECT subject, timestamp FROM `discovery.emails` WHERE 'jim@myclient.com' in all_people AND 'suspiciousguy@baddudes.net' in all_people # Did they incriminate themselves talking about my client after his emails? SELECT fwd.unique_id fwd.text, # Subquery strips 'fwd:' designator and ensures that my client was not already included. FROM (SELECT TRIM(REPLACE(subject, 'fwd:', '')) as subject, unique_id, text from`discovery.emails` WHERE $MYCLIENT NOT IN all_people) as fwd INNER JOIN `discovery.emails` AS de ON de.subject = fwd.subject WHERE $MYCLIENT in de.all_people 
I definitely agree with all your points - except for classifying C# as low-level. IMO, any language that constricts your use of pointers to the point that no-one uses them isn't really low/level.
Golang. Still simplistic, like python. But in practice more like an expressive C language. Some of the best benefits of the language involve the end result being a dependency free executable on any platform. No need for python (golang) to be installed previously etc.
That seems fair. I've not really used C# myself and tend to think of it as low-level *compared to* Python because it's compiled, statically typed and has "more syntax" (static, private/protected, etc) but it's not really in the same category as the others. 
Now that you can use Python for server development, you may learn Kotlin for some client end development.
I have a big question for lawyers who have embraced coding here. Would it be possible to write a law into code? Defines words, possible interactions, etc... using a test driven development. The main idea is that if you want to change the law or any law that might cross-over this law, you should be able to make the modifications and "test" the law for potential bugs. This would shorten the work of legislators and potentially stop some "bugs" with conflicting laws. Would that be possible or is it a dream? Imagine if you could have one international "law coding language" how treaties would be done!? Am I dreaming? Do you know of anyone trying this out?
Are you allready using Python to pluck information from websites? Although I agree with the popular opinion that SQL will prove tremendously useful, HTML/Javascript is also definitely worth looking at. Most importantly because it will let you automate a lot of web-related tasks. With 3 lines of code you can log in to a website and retrieve information from a table or paragraph. In 20 lines of code a script can regularly ping a site for updates, and mail/text you new information. You'll be the first to get notified of whatever you find relevant. Or scrape a repository to get an overview of precedents, to name some possible uses.
That's fine, but I won't set up a 2.7.6 environmentto play with this. I wouldn't mind writing 2.7 code if someone paid me. But for fun and self improvement it has to be python 3 Still, up to level 3 so far all python3 code worked fine. I only had to make sure that all integer division was cast to int.
If we're going for a Lisp language, I'd recommend Clojure instead.
Just answered here: https://www.reddit.com/r/Python/comments/6f8ina/im_a_lawyer_and_i_know_python_and_want_to_learn/dihaaby/ Sometimes you don't realize what tools will improve your life until you've found them. Python's standard library has done tons for me, but I wonder what else I might be missing, hence the request for another language to learn. I'm just looking for pointers in the right direction, any.
Thank you for the suggestion!
While I do agree that Mathematica is excellent, I'd have to disagree on the recommendation. SageMath is about as good, free, and, for an adept python user, very easy to learn/use. 
What do you use Python for in your practice? I am an engineer trying to find more ways to implement some improvements within my own work.
I'm already using Git -- spent a full day learning nothing else but it, and I love it. All of my are now version-controlled - and no more awkward "draft 1/2/3/4/5" suffixes. Although almost all of what I write are command-line based (save for a few with Tkinter), I've yet to see a useful application for Unix command line tools in my workflow. Not discounting the possibility, since I don't know enough, but can't quite yet see the benefits of that.
Side note: I've read/bought his book, and I use his gorgeous 'Equity' font for all my court papers. Will look at Racket, although I'm not too convinced just yet. 
I'm on the same boat with JavaScript, but then I played with Node on a pi and I actually liked it. However, there's no doubt that JavaScript is a valuable language to know. Try jumping to the jQuery library. It's a lot simpler. The basics of SQL can be learned in a few hours. It's well worth the time.
I totally agree and you might as well add the final piece to the holy trinity that is Python, SQL and Panda DataFrames. Use all 3 in Jupyter Notebooks.
Took 4 years on my end. Would be the same for most others. Without going into civil procedure, and to answer your question directly, and honestly: 1. Programmers would find the law easy. Compared to coding, it's a breeze. Poring through badly written decisions and arguments, while a pain, isstill is a walk in the park compared to trying to read and understand/debug/diagnose bad code. And legalese will make sense after you've been at it for a while. (Badly written English never does though.) 2. What seasoned programmers would find difficult though: the uncertainty. This is the main difference between the law and code -- you can never be certain with the logical application of the law as compared to the logical sequencing of code. The law has tons of gray areas, arising either from the law itself or from the application of facts to the law or the people involved with its arguments/adjudication. In a way, this is unavoidable: if all laws were always rigid, unjust outcomes would result. Therefore defeasibility is essential to the law, and contrasting syllogisms/arguments are usually possible. Very logical people -- programmers being the pinnacle of this, in my view -- will find the uncertainty very hard to accept. (I myself had to take my time to accept the law and its practice for what it is.) 3. With the law, sometimes there can never ever be a right answer. Contrast with programming -- yes, there may be more than one way to do things, but there's often just one _right_ answer, which is certain enough. That logical 'certainty' that code provides draws me to programming, above all else -- I treat it as a respite from the uncertainty of the law. 
I agree. Both crafts apply and strive for logical application in their respective subject domain.
Thank you very much!
Already heavily embedded in Git-based VCS. I use it for all my legal documents. C, being very low-level, might not be directly practical to legal practice however.
Thanks! Except for Linux and Elasticsearch, I routinely use all the other stuff you've mentioned. It's what I love about Python! Also, at this point Python's performance exceeds satisfactory for my usef cases, and performance is not something that I exclusively look for in a language (yet).
I would suggest C or C++ as well. Both will teach you how things work in the low level world as well as give you some basis for ctypes/Cython etc. So when something is too slow in Python you may be able to speed it up. SQL is also useful in concert with Python. 
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [ajayns/amoc-project/.../**Spotify_generate.py#L13** (master ‚Üí 7674d02)](https://github.com/ajayns/amoc-project/blob/7674d02c4c9d3892c6d2d7aab99aca4dd62b6d94/components/PyMusicMood/Spotify_generate.py#L13) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dihd0cc.)^.
Thanks for the link + the pyvideo.org site looks awesome, I wonder how come I've never heard about it before.
many small restaurants for example only have a facebook page, not their own site.
C if you want to learn more about how things work in-depth. It will teach you about memory management and data structures and you can use it with the Python C API to build faster Python modules. JavaScript if you want to build UIs. It's what you use to build browser apps, and is super convieniant tool for visualizing data generated from Python. When I do data crunching in Python I usually output to JSON and then visualize it with a JavaScript app and D3 (a JavaScript vector graphics library).
Not sure how popular this will be here - but I'd recommend R. R has a ton of great tools for data processing and visualization. It's a great chance to brush up on statistics and it's got a very gentle learning curve. It's typically not used to write "programs" so much as scripts and scientific notes. Start with r studio! If you find that you like R's dataframe construct, take a look at pandas(python darascience line) and you can use that structure in your python as well. 
You're welcome. It's a pleasure. Yes this site it's cool. I try to watch one video per day, and shared here.
It's not for him to learn his lesson not to commit credentials to code, but to everyone else who stops by and looks. An issue would only be seen by the developer. 
I am not familiar with windows, but I think you should look into the main ~~Process~~ `Popen` class of `subprocess`. Then you have total control including killing it at the end. Also, this is better suited for /r/learnpython EDIT: I meant `Popen` not `Process`
hi not sure how to make a python program a windows service but you can check out [NSSM](http://nssm.cc/) (non sucking service manager)... hope this helps. Edit: yes Services are somewhat equivalent to a daemon you can make a windows bat (script) file to invoke your python script and then use that as a target in NSSM and make it a windows service. 
will look into this, thank you!
Document Automation? could you expand a bit on that? Are you using Python to create documents for word/libreoffice/latex?
Interesting! That's a pretty awesome way of getting things done.
Consider learning the basics of VB scripts. It's the language in which you can write macros for Microsoft applications. I use it to create macros in Excel that do a bunch of stuff I'm too lazy to do - send emails to people, send itself as a database, clean up worksheets, and highlight certain words wherever they appear in a sheet. I'm guessing that you do a lot of repetitive actions in Word. Having a macro to deal with that is really helpful.
Kinda curious, how have you dealt with word docs and git? Pretty sure they don't play well together. 
Note the documentation of subprocess.call: "Run the command described by args. Wait for command to complete..." You don't want to wait for SSMS to complete, so you shouldn't be using this function. As jwink3101 noted, you probably want proc = subprocess.Popen (['C:\\Program Files (x86)\\Microsoft SQL Server\\130\\Tools\\Binn\ManagementStudio\\Ssms.exe', 'C:\\Users\\(myuserfolder)\\Documents\\SQL Server Management Studio\\Projects\\SQLScripts\\NewSQL.ssmssln']) You may also want to be more careful to handle errors, but that's a whole different issue :-) Read the documentation for more details.
Try installing into C:\Python Some modules do not like to be installed in a place that has spaces in the path.
I don't think that's the right way to teach a lesson. Write a blog post -_-
I wonder if there's a read count on average reddit comments. Maybe it's even higher than that of my average blog post. 
Not sites, but have you tried the #python channel on irc freenode, and the live chat on stack overflow?
What kind of document automation? Like template generating? 
An integer is not a sequence (in Python), so using len to get it's length makes no sense. Or, more correctly, integer objects do not implement the \_\_len\_\_ method. 
Cool thanks!
This. Freenode is amazing. See also channels for #flask, #pyqt, #numpy, etc. depending on what subset of python you're working on. Additionally, it's a great place to do development discussion.
If you imagined implementing it, what would you want `len(10)` to return? Based on your example -- `len(str(10))` -- it seems like you want it to return `2` -- the number of digits. But number of digits is not a meaningful property of integers. An integer is a single value, which can be represented in different number systems. In another response, you asked why `int` is not a sequence. The reason is that a sequence is an iterable collection of values. An integer is a holistic single value, not a group of individual values.
The book 'Learn Python the Hard Way'
len isn't sizeof, so it will not tell you the integer size. 10 is not a string until you create the string for it.
SECTION | CONTENT :--|:-- Title | Modern Dictionaries by Raymond Hettinger Description | Abstract Python's dictionaries are stunningly good. Over the years, many great ideas have combined together to produce the modern implementation in Python 3.6. This fun talk is given by Raymond Hettinger, the Python core developer responsible for the set implementation and who designed the compact-and-ordered dict implemented in CPython for Python 3.6 and in PyPy for Python 2.7. He will use pictures and little bits of pure python code to explain all of the key ideas and how they evolved over time. He will also include newer features such as key-sharing, compaction, and versioning. This talk is important because it is the only public discussion of the state of the art as of Python 3.6. Even experienced Python users are unlikely to know the most recent innovations. Who and Why (Audience): This talk is for all Python programmers. It is designed to be fully understandable for a beginner (it starts from first principles) but to have new information even for Python experts (how key-sharing works, how the compact-ordered patch works, how dict versioning works). At the end of this talk, you can confidently say that you know how modern Python dictionaries work and what it means for your code. Bio Raymond Hettinger has also served as a director of the Python Software Foundation, and has mentored many people over the years on their contributions to the python-dev community. He is also well known for his contributions to the Python Cookbook, and shares many pieces of Python wisdom on Twitter. He is a frequent keynote speaker at Python Conferences around the world and has received the Distinguished Service Award at PyCon 2014 for his exceptional contributions to the python community. Other info: This talk is delivered at SF Python's 2nd Annual Holiday Party for Python Devs in SF Bay Area, CA. In you are in San Francisco area looking to meet other python devs, please check our schedule for meetups on http://sfpython.org Length | 1:07:41 **** ^(I am a bot, this is an auto-generated reply | )^[Info](https://www.reddit.com/u/video_descriptionbot) ^| ^[Feedback](https://www.reddit.com/message/compose/?to=video_descriptionbot&amp;subject=Feedback) ^| ^(Reply STOP to opt out permanently)
Packaging Python code using Debian packages is not an unreasonable thing to want to do. For those who have already decided to package in this way this guide might save them some time in getting started. If you don't know why you would want to use Debian packages, then you probably don't need them, and that's ok. I don't think the article needs to say why someone would want to do this to be useful. Having said that I will try to provide one answer to your question. In a company where there are lots of development teams writing code for different services in different languages it can make sense to want to standardise on what packaging system is used across the different teams, so you don't have drastically different deployments for the various services. If you're deploying to Debian/Ubuntu servers, then one option is standardising on using Debian packages. That way you could have an internal Debian package repository that contains the company's proprietary software that your CI build dumps a package to, and your CD pipeline deploys from.
len(10) according to your question would have to depend on the base you use for representation: Base 2: len("1010") == 4 Base 10: len("10") == 2 Base 16: len("a") == 1 
While it does not support sql functions you can write python functions and add them to the sqlite instance for much the same effect (as long as you won't be leaving python or sqlite) https://docs.python.org/3/library/sqlite3.html#sqlite3.Connection.create_function
This link is gold!! Thanks a lot!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Right now I'm leaning towards a mix of the top 2 options: * Remove help requests that are downvoted sufficiently, and gently guide people towards posting in /r/learnpython * Require flair for help posts
A linter is a tool that reads your code and looks for possible problems. For example, a linter may find that missing an exception handler, or returning from a function inconsistently. For large projects, linters can do wonders for maintainability.
r/learnpython Python is a scripting language. You don't compile it, you just install python and run the code itself.
Definitely a question for r/learnpython. Theoretical answer: Python is, like any other programming language, [Turing complete](https://en.wikipedia.org/wiki/Turing_completeness) and can thus do anything that any other programming language can do. To understand what this means: You can write an interpreter for any other Turing complete language in Python and thus run a program written in any language through Python. Whether or not that's efficient is a different question (hint: it's not). Practical answer: Python is a general purpose language that is easy to write and useful for many kinds of projects. It is however fairly slow, so it's not quite as useful for things where high performance is important, such as real time games, browsers, operating systems‚Ä¶
Nope, I fully agree that a megathread isn't a good idea for things like this. I am thinking about doing more daily threads though.
[**HIRING** Experienced Python Developers in *Austin, TX*] If you love Python like a dog loves a bone and you speak fluent virtualization, we want you on our team! (yes, I am aware that was a bit cheesy). Cylance is looking for candidates with 3+ years of experience to join the team full time. PM me if you are interested!
It's not really the same effect because you can't change the functions in the database and have it have an effect across all the applications using the database. This is less of an issue with sqlite since it's often used within a single application, but it's worth understanding the difference.
It looks like you may be attempting to use return outside of a function. Usually it would be used in a way kind of like this. def test_function(edmg1, fdmg1): if edmg1 &gt; fdmg1: print ("The Robot has dealt more damage than you!") complete = 0 return complete You want to just use the print option if it is not in a function, so your code posted would need to look like this. if edmg1 &gt; fdmg1: print ("The Robot has dealt more damage than you!") complete = 0 print(complete) The best piece of advice I can offer is if you can't get help here be sure to check out /r/learnpython , it is meant for questions like this! *Edit, formatting. 
I never really used a book, I took a couple Database courses in University and self-studied through the reading of official documentation for anything else I needed. I will say that learning the theory behind RDBMS (Relational Data Base Managment System) is more important than becoming an expert in a specific SQL dialect. Basically, the RDBMS is the actual engine that powers the database and SQL is how you talk to it. There are lots of different RDBMS out there and they each have slightly different SQL dialects, but they all follow the same basic theory on how best to store data. The wikipedia article [here](https://en.wikipedia.org/wiki/Relational_database) is a good place to start. I'd stay away from books that focus on teaching SQL and try to find a good book on Relational Databases. Since understanding Relational Databases is far more important than being really good at SQL, since you can just google that stuff when you need it, but you have to have a good understanding of the relational database under the hood.
&gt; Just gets a bunch of errors. Yeah, those are your first and, by far, most important clue. If you're gonna write code, error messages are your bread and butter. Read them. Breath them. Live them. And most importantly, if you're gonna ask for help, POST THEM!
I don't have code to share - but there is no reason why it wouldn't work - you would need a Canvas object, and bind to the Mouse and Motion events - and process them accordingly. Note though that the Canvas object is not very efficient for complex objects. It doesn't keep track of which regions to redraw - it basically redraws everything.
Interesting analogy. Why so?
It is likely to be an issue with indentation - sorry to be so vague. All returns from a function must be indented at least to the level of the first statement in that function - i.e. the first statement AFTER the def ..
Well, you can do this a bit differently though. You create a python package for your model layer, and share that across all applications that use the DB. We do this all the time, it's super handy.
&gt; For OP, learning another general-purpose language isn't very useful, but for someone whose main task is software development, learning other languages is valuable when switching jobs. That's exactly my point. And even there, I'd say that as a professional, what you need to learn is how to transition quickly, and for that you just need familiarity with several different *styles* of languages. But the era of the "C++/whatever guru" is gone. Only a handful of people know languages like the back of their hands and their role is to make things like the Boost library or compiler level stuff. For the rest of us what's more critical is being able to read documentation/SE etc.
I know but it seems kind of complicated?
You won't know until you try 
This is more appropriate for r/learnpython, but you should look at the 'subprocess' module in the standard library. I honestly do not know what you are trying to do but writing data to a file isn't the same as writing a command to a terminal. https://docs.python.org/3.5/library/subprocess.html
I'm myself exploring [Nim](https://nim-lang.org/) to bypass some Python limitations: - more expresiveness in the language (metaprogramming √† la lisp macros, because sometimes only `with` statements and decorators isn't enough, and frustrating), - building an executable, even for a web app, - speed, - catching errors earlier (static types), - writing web apps server and front with the same language (instead of html with a templating engines and javascript with a js framework (vuejs)) (with [karax](https://github.com/pragmagic/karax), quite new) 
Well, no more than they would be from sharing a database. You make a python package who's job is only to be the Python representation of the db (a thin model). Alembic, by the SQLAlchemy author, makes migrating and versioning your model package dead easy. The only part that *needs* to stay in sync is the table definitions, which in SQLAlchemy are (under-the-hood) decoupled from your model classes anyway as it's a Data Mapper ORM. I've done it a lot and never regretted it, it's been a huge time saver. Basically, if more than one application package is going to use the same database, it's just as easy to have them share the same model package. I do this a lot for families of distributed micro-services. 
The gil is a global lock held by the python interpreter when executing bytecode. This means that if there are multiple threads running and they are all mainly executing bytecode, they will generally be no faster than a single thread running. This could happen, for example, if the code is mainly "pure python" and not doing any or much IO. Given the direction that CPUs may be going, I would argue that yes it is becoming a bigger problem. There are ways to avoid the issue (e.g. execute long-running tasks in C extension modules that release the gil or to instead use the multiprocessing module), but if the solution that makes most sense for you is to have many threads running pure python code, then you probably should use a different language (or a different python interpreter).
GIL doesn't stop you from multi-processing or even multi-threading exactly. GIL exists to take away thread-safety issues running CPython bytecode within a single process. asynchronous I/O operations, numpy calculations, things like this do a fine job multithreading in python. You are limited when you application is running in a single process that's CPU-bound, there I would recommend looking for another tool for the job. 
GIL creates problems, when you need big CPU resources. For example - you work with hard math. But if you work with IO (for example network application), or create site - in most cases GIL is not problem.
The only way to do that is by recompiling CPython from source. And you're probably going to have other problems, because the build system is going to naturally favor the latest version, because the only reason an older version is kept around is to support existing old binaries that were compiled against that version. (I.e. it's usually not possible to build new code against the old version, since that's usually insane.) 
&gt; For example - you work with hard math. I don't think that's necessarily the greatest example. If your math is done in pure python computations, then yes you're probably right. But if you're using numpy/scipy/etc. many operations will release the gil. If you write your own C/C++ extensions for your mathematical operations, then you can be sure to release it yourself.
I have used pdfminer+pypy with very good results.
Script file: https://www.mediafire.com/?jo1eti3wvybumt8 
Neat! I notice that your tests check that specific examples give the correct output - this is clearly useful, but you may also want to check the invariants in a more general way. [Hypothesis](https://hypothesis.readthedocs.io) is a library for property-based testing in Python, and supports [stateful tests](https://hypothesis.readthedocs.io/en/latest/stateful.html) - the example is actually to test that a binary tree stays balanced. You could test that `list(tree) == sorted(list(tree))`, that [all these properties hold](https://en.wikipedia.org/wiki/Red%E2%80%93black_tree#Properties), etc. [How not to die hard with Hypothesis](http://hypothesis.works/articles/how-not-to-die-hard-with-hypothesis/) is a more fun intro to the topic. from hypothesis import strategies as st from hypothesis.stateful import RuleBasedStateMachine, rule, precondition, invariant class RedBlackTreesTestmachine(RuleBasedStateMachine): tree = RedBlackTree() @rule(x=st.integers()) def add(self, x): self.tree.add(x) assert self.tree.contains(x) @precondition(list(tree)) # Don't try to delete an element from an empty tree @rule(data=st.data()) def delete(self, data): x = data.draw(st.sampled_from(list(self.tree))) self.tree.remove(x) assert not self.tree.contains(x) @invariant() def is_sorted(self): assert list(self.tree) == sorted(list(self.tree)) # Add other invariants here RBTest = RedBlackTreesTestmachine.TestCase 
##Red‚Äìblack tree A red‚Äìblack tree is a kind of self-balancing binary search tree. Each node of the binary tree has an extra bit, and that bit is often interpreted as the color (red or black) of the node. These color bits are used to ensure the tree remains approximately balanced during insertions and deletions. Balance is preserved by painting each node of the tree with one of two colors (typically called 'red' or 'black') in a way that satisfies certain properties, which collectively constrain how unbalanced the tree can become in the worst case. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://www.reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://www.reddit.com/r/Python/about/banned) ^| [^Information](https://reddit.com/r/WikiTextBot) ^]
the celery package has a rdb module which allows you to debug a live running process by connecting to it via telnet. Extremely useful in debugging python web apps with weird runtime behavior
Correct as this was originally written with 2.X in mind. I agree they're very similar (the module is a very thin layer over tempfile) but I prefer having an object interface vs. what tempfile offers. With TemporaryDirectory, you would still need to be responsible for passing around that directory path to every call to tempfile you make in order to keep files bound to that directory. **Scratchdir** import scratchdir with scratchdir.ScratchDir() as sd: tmp = sd.named(...) **TemporaryDirectory** import tempfile with tempfile.TemporaryDirectory() as td: tmp = tempfile.NamedTemporaryFile(..., dir=td) These simple examples don't really help serve my point but in more complex codebases where I've used this pattern, such as a scratchdir per thread, I've found it much easier to just deal with a single object instance instead of continuing to pass values into the dir keyword argument for all tempfile functions I need. 
All of the front end frameworks are pretty well suited for the back end equally. They are interacting with the back end via http so there shouldn't be any real difference, outside of maybe how the back end converts request objects or something like that. But they are 99% the same.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Here's an overview of Python threading. I hope this helps clear up some confusion: 1. Python threads are **real** OS-level threads. 2. Python is not compiled to native code, so only the interpreter knows how to execute Python code. 3. However, the CPython interpreter will only execute Python code from one thread at a time (because CPython's internal structures are not thread-safe). 4. The interpreter gives each thread a turn to run Python code, one at a time. If you create 4 threads running pure Python code, the interpreter will divide up the time fairly, and each thread will run little chunks of code as the interpreter gives it a chance to run. When the interpreter is running a thread, all the other threads are doing nothing because they aren't being driven by the interpreter. 5. C modules can choose to release the GIL when they aren't using Python objects. If a CPU-heavy function is implemented in pure C, it can release the GIL using Python's C API. This allows the interpreter to run Python code for another thread. 6. Python will release the GIL when waiting for I/O. If you just want to run code while waiting for a network request, threads will work as expected. 7. If you're running CPU-heavy code in Python, splitting the work into threads will not utilize additional CPU cores. As explained in (4), each thread will take turns running code. Your program won't complete the work any faster, and may even take longer. So how do you take full advantage of your CPU? 1. Write CPU-heavy functions in C/Cython and release the GIL inside them. This works perfectly if most of your CPU work can be implemented in C. You can create many Python threads calling the C functions and they will run in parallel. 2. Use the `multiprocessing` module. This will spawn subprocesses, each with their own interpreter. This is an easy-to-use, pure Python solution. They don't share a memory space like threads do, so `multiprocessing` has some helpers to transfer data using `pickle`. This will add overhead if your data is large. Or you can figure out a different inter-process communication (IPC) method. Is the GIL a problem for Python? Yes. It's painful having to rewrite stuff in C or struggle with IPC. Many projects don't need parallel processing until they are more mature, and by that point, "don't use Python" is a pretty silly "solution".
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
https://notebooks.azure.com Full disclosure - I work on this. It's hosted Jupyter notebooks running on Anaconda on Linux on Azure. We're still limited in ways you can share, limit access, etc... but it might do what you want.
Probably being down voted because it's obvious you're more interested in cheating a game than actually learning to program.
* I find ipdb nicer to use than pdb, especially for tab completion. * Automatic debugging on error with `%pdb` magic in IPython. * Conditional breakpoints in pdb/ipdb are fantastic for catching infrequent bugs inside nested loops. * Use `!` to override pdb commands, for example to set a variable called `n` you need to do`!n = 7` otherwise it treats it as the command "next". * Use the `logging` module rather than `print`. 
' if state == "on" ' is inside a " while state == 'on' " So it will always be 'on'. So that condition is not required. Your code will work exactly the same way without it. 
if state == "on": state = raw_input("Type 'on' or 'off' to continue) This if statement here allows you to continue the script without opening it again. If you input 'on' it will loop again, if you input 'off' it will stop the script. http://imgur.com/ObNVEtL
Thanks!
My favorite ones are the one from Azure and the one from the peekaboo-vision blog.
I'd expect something like this from /r/machinelearning not this sub, but this is great.
So what you are saying is, "Yes, the GIL is a problem for python". If the language can't handle multithreading in today's age, then it's useage cases don't extend very far from, quick script to do some small task with.
I saw this solution around: [Auto assign self attributes in \__init__ using PEP 484 (Python recipe)](https://code.activestate.com/recipes/580790-auto-assign-self-attributes-in-__init__-using-pep-/)
Tried inPyCharm, no completion for x, y, w as I expected.
You're right but the advantage of pyvideo is tidy by events.
First thing thanks for your help! also, planet python is super cool. Can you please elaborate on: "However, the recommended way to get what you want is to use github as source + pypi API."? how can i do this/ what API do you meen? 
Well, since each shop has a config file that explicitly tells which parser to use, it's simpler to just do a dynamic import on the parser module and instantiate a `Parser()` object. After all, this is an in-house script for importing, the tool is hosted in an internal Gitlab repo, and updates get deployed by simple `git pull` on the server to which the shops upload their data.
how would you change this to avoid dropping the table but just inserting the data in pre-existing table? 
Looks into the attrs module instead
As I understand it, the GIL has been left in place because even though solutions have been developed which improve performance on multiple cores they also reduce the performance on single cores. Since single core systems are becoming more and more rare, this decision should probably be reconsidered.
The stack used to replace matlab is usually - Numpy (give access to fast numerical data container + base manipulation) - Scipy (high level routine: optimization, signal analysis, numerical integration...) - Pandas (stats and stuff) - Matplotlib (visualization) And you can add Spyder, a numerical analysis oriented IDE. (Take a look to jupyter, it's a very good tool for prototyping..) If you look at the Anaconda distribution, all these library and tools will be pre-installed. Good luck!
Actually its not the 'if' that allows you to continue the script. Its the 'while'. Try your code by removing the 'if'. It will work exactly the same way as you showed in the demo above.
Awesome link, man!
Does Cython provide thread-safe data structures with same/similar API as python (set,dict,list) ?
[removed]
[removed]
Cant you metaclass inheirt‚Äã from the sip's metaclass? 
From the latest presentation at PyCon, they reduce performance on multiple cores as well.
You want this: http://www.attrs.org/
This is like the best post ever on GIL, threading, IO vs CPU.... well done :)
You can learn to write / produce documents or templates with Python &amp; LaTeX
How reliable is PGO (profile guided optimization)? How can I use it with my application being profiled, and not the interpreter's test suite?
You're absolutely right, I knew it caused the self-reference but I didn't think of that causing memory issues. I tested it myself and was able to recover an object using gc after all accessible references to it were gone, which doesn't work the old way (thankfully). I was able to solve the issue using del(self.self), but, that attrs module a couple people mentioned looks better anyway. EDIT: actually, as it turns out, gc.collect() was enough to get rid of the self-referential object, so I think it would get killed off eventually anyway. It just doesn't become immediately inaccessible like the other one. Still, it was nice to discover a new module.
Within the domain of numerical and scientific computing, the GIL isn't really a problem to begin with. We either use a different approach towards parallelizing our calulations, or we drop into a C/Cython/Fortran/compiled extenstion which releases the GIL.
In a different program (notepad)
That is kind of difficult. Programs usally do not keep the disk file open that the user is editing. Some programs like Word keep a lock on the file, but I think Notepad does not. What you could do: Enumerate all top level windows and check the window title for the filename you are looking for. I do not know of a platform-independent way to achieve that. But here is a windows-specific way: https://sjohannes.wordpress.com/2012/03/23/win32-python-getting-all-window-titles/ Google for "enumerate top level windows python" to find more. HTH
If you are in a GNU/Linux environment, you can use a subprocess to call lsof to find which processes are using/holding on to the file. Something of this kind would do the job. from subprocess import Popen, PIPE def check_open(file_path): lsof = Popen(["/usr/bin/lsof"], stdout=PIPE) grep = Popen(["grep", file_path], stdin=lsof.stdout, stdout=PIPE) lsof.stdout.close() output, err = grep.communicate() if err: raise SystemError("Unable to check system state") return file_path in str(output) 
It doesn't like this line ```view = ColorDieView(self.win, center, size)``` Try just getting this to work. from cdieview import ColorDieView win = GraphWin("Dice Poker", 600, 400) view = ColorDieView(win, center, size) 
One thing I'd like to see addressed as quickly as possible in the presentation is the notion that Django requires all this work to get up and running. I've seen relatively minimal Django configs, so some discussion of how a lot of the features in Django are not mandatory (last I checked, anyway) would probably be good.
&gt; In that case, where are you supposed to go to get help relevant to getting a Python script to work even if you're not interested in programming? If you're not interested in programming, don't write code. If you are, read. Read tutorials, read documentation, read a book. Try to figure it out and don't give up at the first sign of trouble. In short: Don't expect other people to solve your problems for you unless you've made a discernible effort first.
Checking the window titles for a filename seems kinda unreliable. If you're going to call windows APIs then I would try to open the file with [OpenFile](https://msdn.microsoft.com/en-us/library/windows/desktop/aa365430\(v=vs.85\).aspx) Send it Write-only permission, if that fails then get the [System Error Code](https://msdn.microsoft.com/en-us/library/windows/desktop/ms681381\(v=vs.85\).aspx) with [GetLastError](https://msdn.microsoft.com/en-us/library/windows/desktop/ms679360\(v=vs.85\).aspx) and hopefully that error message will tell you it's already opened by another process.
&gt; never wrote a single line of multi-threading code but found the concept of cpu cores and multithreading quite fascinating That is indeed common. They didn't need to use it before, want to use it now and realize that they can not do it as easily as they would like to. &gt; working on CPU intensive task which needs to be done at least in cython anyway There are many cases where Python performance would be sufficient, but lets be honest - the language and interpreter internals make using modern hardware hard. All ways of doing cpu-intensive tasks provided by Python have serious drawbacks. There comes the time for every tool that your needs will outgrow it.
Matplotlib isn't always the best option. Here is a talk from PyCon 2017 about different [visualization technologies](https://youtu.be/FytuB8nFHPQ)
SECTION | CONTENT :--|:-- Title | Jake VanderPlas The Python Visualization Landscape PyCon 2017 Description | "Speaker: Jake VanderPlas So you want to visualize some data in Python: which library do you choose? From Matplotlib to Seaborn to Bokeh to Plotly, Python has a range of mature tools to create beautiful visualizations, each with their own strengths and weaknesses. In this talk I‚Äôll give an overview of the landscape of dataviz tools in Python, as well as some deeper dives into a few, so that you can intelligently choose which library to turn to for any given visualization task. Slides can be found at: https://speakerdeck.com/pycon2017 and https://github.com/PyCon/2017-slides" Length | 0:33:31 **** ^(I am a bot, this is an auto-generated reply | )^[Info](https://www.reddit.com/u/video_descriptionbot) ^| ^[Feedback](https://www.reddit.com/message/compose/?to=video_descriptionbot&amp;subject=Feedback) ^| ^(Reply STOP to opt out permanently)
I made a mistake. The python program will open the file, and it should check if the file it opened is still open.
Wow, crossbar.io? I was checking them out a couple of days ago, how is it? How do you couple crossbar with Django? With uwsgi as in with Django or somewhat another way? I'll take a look at vue, although not handling ajax is quite a little bummer 
You can attempt to open it yourself and acquire an exclusive lock on the file. If another process has it open, this should fail (You'll also need to specify non-blocking or it'll wait till the file is closed instead). The way to do this differs a little depending on the OS you're using - on unix, the builtin fncntl module can do it. On windows, you'll likely need to use the win32file module, though there may be other higher level or portable modules that wrap these. Eg. if using fcntl, you'd open the file, then call `fcntl.lockf(fd, fcntl.LOCK_EX | fcntl.LOCK_NB)`. If this succeeds, you know it's not currently open. Otherwise, it'll throw an IOError, with error code EACCESS or EAGAIN.
There is no generic recipe. Some algorithms require no data synchronization between spawning and joining subthreads, others a lot. It really depends on what you do. The image processing algorithms I work with are practically all parallelized to exploit all available cores. A lot of growth of CPU speed today goes into more cores / threads, much less into faster execution of single threads than 10 or 20 years ago. A language that makes parallel execution notoriously difficult will certainly have a disadvantage in the long run, as it will not benefit from performance improvements as much as other languages.
I think form handling. I still get flustered when dealing with forms in django because it seems to work great in an ideal situation where your form fields match a model (or contain a subset of fields), but more often than not, forms will contain fields from multiple models and you will have more than one form per page and things seem to get very messy very fast. I very rarely use django forms because of this, but I have a feeling I'm just missing something - I can only assume there's others out there who feel the same.
While I haven't used Celery, I can add that the multiprocessing module can be quite fragile if you start using it for more complex tasks. Especially in the area of managers and proxies. 
Obvious troll is obvious. 1. Python can handle multithreading. 2. Some Python interpreters (IronPython and Jython, at least) don't have a GIL and make full use of multiple cores when threading. 3. Threading isn't the only, let alone the best, model for concurrent or parallel code. The obsessive focus on threading indicates a failure of the programmer. 4. The idea that Python isn't suitable for anything much more complex than "quick script to do some small task" simply doesn't match up with reality. 
&gt; I haven't heard about this but it seems unlikely unless done terribly wrong. Oh, well since you're obviously an expert on the CPython internals, and how to remove the GIL without it impacting performance of single-threaded programs, perhaps you should do it right instead of the clueless idiots who have worked on it up to now. Right? &gt; But since it's faster on multiple cores It isn't. 
A sensible IDE like pycharm will save you a lot of keystrokes, at least, in this task. You just write the signature then alt+enter, enter on each one, I think. Explicit is better than implicit.
Can I make a suggestion? As an intro python user and intro Django user, I was pretty bummed to write full views and then delete those views to replace them with generic views in the tutorial and the tut at coding for entrepreneurs. Maybe switch that around and show generic views, explaining what they do, and then write one view in its entirety to show what you need to do when generic just doesn't cut it?
Sorry about that, I'll make sure to post there next time. Also, Windows.
The best i have seen, thank you
Custom Managers. Very few tutorials go through this, but any non-toy-project is going to require them sooner rather than later. 
Two things I remember from when I did support on IRC: HTTP and that it is stateless was often a source of confusion and many people just didn't get that template rendering is basically just string manipulation and that it happens on the server. They'd ask confusing questions about how to mix template functions and JS functions.
It should be pointed out for taking advantage of #2: Plan ahead. Since it requires pickle, you have to make sure your data structures can be pickled. Tacking on multiprocessing at the end of a project won't go very well if you've created some hybrid of a data/operator class.
On many distros some Python processes are an integral part of the system. Killing them might not be a good idea.
NUMPY FTW Numpy, which is what you use to write high performance numerical code in Python, is written in C and releases the GIL. Many other computational packages do the same.
Threads can be useful for parallel computations nonetheless. An simplified example might be something like the following: 1. You have a matrix with m columns and n rows data. 2. You pass in a vector of length n and take its linear dot product with each row to produce a vector of length m. 3. You want to do something with this final vector (say sort it and return it) which requires (at least somewhere down the line) global information about the vector. 4. The data involved is large and you want to keep latency as low as possible. Assuming that your matrix is constant you could shard it across subprocesses, but depending upon your final algorithm you may need to send the final length m vector back to a main process for some final global computation. This memory IO can be a bottleneck. You might try to do something with shared memory instead, but I think threads are perfect for this sort of thing. I.e. they are great for a parallelizable computation in which you want your result to be in the same address space for the next steps of your algorithms. This example is overly simplified, but there are definitely cases where parallelization is handled very well by threads.
Full website: https://2017.pygotham.org/ Registration info: https://2017.pygotham.org/registration/
Trying to develop a flask server with a websocket connection for a live monitoring of some data. I am no good This is hard haha 
Good move. Pytest is full of well-tested awesome.
not myself, but I do use an open source console twitter client, which is written in Python, it is fully featured. probably a nice reference. [rainbowstream](https://github.com/orakaro/rainbowstream) 
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [orakaro/rainbowstream/.../**README.rst** (master ‚Üí 24a80d7)](https://github.com/orakaro/rainbowstream/blob/24a80d733cabb2d5ad2f61886d3b447a9e148882/README.rst) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dijcolc.)^.
Do I take a performance hit for this? Does run time functionality change at all? 
You've got 9 million entries per dataframe. Assuming they're all of type float64, that's about 72 MB in RAM for each one. So if you keep increasing their size, eventually you'll hit your computers max (probably 8 or 16 GB) . However, unless you know that you'll likely hit these limits, it's overkill to try and use different solutions that keep the data in disk. Reading the whole thing into RAM is what you should do for data processing where the data fits comfortably in RAM. As for why it's slow, you should try and figure out where the delays are. It might just be on the reading the file or writing the results ends of the task in which case there isn't much you can do. If its in the middle, it's possible that your numpy code isn't optimized well and that could be the culprit - hard to say without knowing exactly what you are doing.
Getting ready to start my first programming python class next week
Certainly. So I redirect any stdout to a textbox widget within Tkinter. But when running the program (windows console comes up for getpass credentials), after the credentials are entered, the GUI comes up and you perform your functions...when you hit submit, the multiprocessing should start...but all of the processes, print out to the console and not to the Tkinter widget. I'm assuming that has something to do with the child processes not being apart of the Tkinter class (as the main functions performing are global functions not class specified). I hope that makes sense.
&gt;In that case, where are you supposed to go to get help relevant to getting a Python script to work even if you're not interested in programming? You're supposed to go to the person who wrote it.
yes. currently doing that
Not OP, but a pytest convert. unittest looks more like Java than Python. There are lots of assert methods you need to leverage, and all in Java's camel-case-like formatting (e.g., assertEqual(), assertGreaterEqual()). pytest reads more like Python. There's no need to remember all of the methods; you just write assert statements (e.g., assert a == b, assert a &gt; b). This was my principal reason for switching. Once I was comfortable with its basic uses, I dove into fixtures and parametrization, which made my unit tests cleaner and clearer still. And the plugins are also great -- I'm a big fan of having automatic coverage stats with my test suite, and I really like seeing the colorful test reports I get with pytest-sugar.
Will there be any way to watch your tutorial without attending DjangoCon? I m far away :X
I believe the DjangoCon organizers will be recording the tutorial and uploading it to YouTube afterwards.
&gt;You could very well argue that single threaded programs don't care about performance. Outside of embarrassingly parallel math heavy operations, I have never seen a use for multiple threads (At least in my experience). Either the code is I/O bound and you can use an event-driven style or queue, or there is some CPU heavy work that can be split up among separate processes and the IPC overhead keeps you safe since you're not sharing memory I've actually *sped up* multi-threaded c++ programs by moving them to a single thread and worker queue. I did it to squash some timing bugs (which are a total bitch to debug) but I was able to remove all mutexes, locks, etc. It turned out a lot of the threads were wasting time waiting on mutexes anyway, so there was very little *actually* happening in parallel. In the end it ran faster and had no timing bugs. 
I see. Just to be sure, did you redirect GUI stdout to text by assigning sys.stdout to be some function that writes to the text box? It seems that when python create child processes, the child process inherits the most fundamental OS-assigned stdout object instead of user supplied python file objects. Check this out: from multiprocessing import Process,freeze_support import sys def foo(): #the next line should appear on the console print 'from child',sys.stdout if __name__ == '__main__': freeze_support() old_stdout=sys.stdout #the next line should appear on the console print old_stdout with open("tmp.txt",'w') as f: sys.stdout=f #the next line will go into tmp.txt print sys.stdout p=Process(target=foo) p.start() sys.stdout=old_stdout p.join() 
Use of templates and generic views to get going quickly, then forms and models in detail as well as the information flow between sites and views using POST and GET Lastly, how to get the damn thing onto a host (digital ocean or linode) (the one click installs make it very easy, but have some pitfalls and configuration quirks.
Sorry, I haven't looked at much Go code, so I don't understand what's going on in your example. So maybe I'm missing something, but why wouldn't python's threads work for this use case. Th GIL isn't a problem while you're doing I/O (hitting the server) or while you're rate limited. Setting up a producer/consumer might not look as nice, but from a GIL perspective, I don't see there being much issue?
Why does textract need speech recognition?
Experimenting with and deeply learning/understanding Tkinter!
In general, I try to keep a couple things in mind: * If your data contains a lot of repetitive values, you can reduce your memory quite a bit by converting that column to categorical data in pandas. If your data contains all numbers, then this probably doesn't help but data like states, countries, etc work really well as categorical values and save a lot of memory. * Try hard not to do any looping over your data. Try to vectorize your calculations as much as possible. * Reading from disk or databases are slow so try to minimize that (i.e. read in all the data at once vs. multiple hits to files/dbs). * Some file types are much slower to read in and save to. Excel is slower for i/o than a proprietary format like feather or even something like csv. * Can you pre-process the data or cache it for future use? For instance, if you're comparing the results to the results last week - keep a processed version of last weeks data stored somewhere instead of re-running it each time. Other than that, you should try to profile where the slowdowns are and see if there is an easy code refactor or if this is a more advanced approach. Finally, keep the performance in perspective. 15-30s may be great if it is a process you run once a day and used to take 3 hours. If this is supporting a website request then 15-30s is probably too long. In other words, think about how much of an impact converting this to a 1-5s process would have in real life. Hope this helps. 
Thanks for the long answer! I will definetly check out SciPy :-) 
How do people prefer Tkinter over libraries like PyQt? I never understood that, if I'm the outsider than I'd like to know why. And I'll just throw in my experience here. I've been using PyQt for about a year now, and as long as have Designer open, I can punch out an extensive program in a week. As always though, I have multiple StackOverflow tabs open.
That doesn't really answer my question but sure, the interpreter needs to tag along.
&gt; hey have to be pickleable objects That's all I meant. Not all python objects reduce into pickleable things. 
Mentioning Python 2.7 seems to attract downvotes here.
Yes
Learning Pandas again! Been a while since I've used it
Sure, Python can do it. But do *you* have a solution for the problem? Python is just a tool, it doesn't make things magically work. What's your plan to approach this problem?
I was thinking about doing this exact thing lately, my case being I have Plex running on two of my own servers for various reasons (one is public with good performance, one is less public with lower performance), both pointed at the same exact media and wanted them to sync watched status since it's literally the same files. Looks like that library makes it even easier than I thought it would be and your PR was already merged too!
You don't take a performance hit because the interpreter tags along. It's the same interpreter, running the same code, just installed somewhere else on the computer. For run-time functionality, you might need to do something special to get it to recognize and bundle additional resource files - consult whatever bundling program you're using for details.
That's a [metaquestion](http://www.urbandictionary.com/define.php?term=metaquestion).
Well how did you configure the script to launch at login? Have you tried undoing that configuration? 
I've fiddled with Django but I live in SciPy world...If we're talking 0 then I'd start with what Django can do for you. What problems does it solve (and does it not solve)? Why might we use Django as opposed to other tools out there? I think spending a little time upfront establishing a motivation to learn Django is crucial because you'll have people excited and ready to learn!
No idea, hoping I can get sone direction from this sub. I have no real literacy with python, any pointers on where and how to start? 
&gt; Explicit is better than implicit. My thoughts exactly, unless it's code golf
I'll have to mess around with this example. Yes, I assigned a class to do all the processing of stdout and I assigned that class to the stdout within Tkinter. I found a workaround currently by just using the console from windows as my output window instead of the widget for the processes...it's not as clean but it works.
I want to profile a bunch of common (both in use and between languages) standard functions between a few languages and measure their performance. 
Use TweePy. There are plenty of examples of how to use it.
That's why I hated it. If one thread got hung up the whole thing would choke. With Celery I can make simple small atomic functions and then just smash it with as many CPUs as I have in the house. 
As someone who isn't a beginner anymore: That's the most frustrating thing in every tutorial I have ever seen, to the point that I refer to it as "teaching backwards".
I've used pytest in the past before, and use it now at work.
I'd like to hear about the state of Django hosting. Questions I had as a beginner when trying to get my little "Hello World" app hosted on my hosting provider: * Do I need root access? Do I need httpd.conf access? * What is WSGI? * Which hosting providers are Django-friendly?
I watched a pydata video where a guy went through many unit test libraries and by the end he basically said "just use pytest". Compared to unittest, like the other poster said, it is clean python, and not java derived like unittest. 
No. The domains Python is popular for don't need parallel executing threads, and the domains that do need them are already not using Python.
Maybe the issue is that there's so little learned between the long way and the short way. From the tutorials I have been through, I'm told "This is now class based and you can delete everything here and it does the same now, see!?" But I'm not deep enough into understanding python that I can hop into the documentation and review the whole class and understand it. In fact, maybe I'm not supposed to yet, I'm just supposed to rely on it. But this is the first part in training where I'm told "Don't worry about, just know it's saving you time and reducing the amount of code." So yeah, maybe I'll need to know how to really manipulate that class later on, but if I really don't need to know it now, don't teach it to me at all.
It's kind of a catch-22 either they do it that way or they omit it and the second generic views start seeming limited you'll just assume that's a Django thing rather that just a generic views thing.
Enough that you aren't constantly changing files to find things, few enough that you don't get lost in a file. That is to say: no, not one that would get broad agreement.
What didn't work about it when you tried those things? "Didn't work" is pretty vague. Did it say "command not found?" Did it say "Permission denied?" Did it say "bad interpreter?" Did it not behave as expected?
"Chmod cannot find file with that name" even with the full file directory there, and the python file then said it was an executable file, and asked if i wanted to run, I clicked run and it flashed a window and nothing else happened 
What are you using to try to do these tasks? I'm guessing you're not at a terminal window. For the last part, what are you hoping will happen? Most of the time when you run commands like that from graphical file manager it will just open a terminal, and once the command finishes it will close the terminal automatically.
Drivel
thanks
The problem at hand has nothing to do with a programming language. You should solve the problem first before looking for a tool like a programming language to implement something.
Add the key **'verbose': False** to your network device dictionary. More information on the [Netmiko Standard Tutorial page](https://pynet.twb-tech.com/blog/automation/netmiko.html)
Not all problems can be parallized: sometimes your task is inherently sequential in nature. First you do this, then this, then this, now you're done. If your threads are spending all their time waiting for the previous thread to finish before they can even start, then you've just wasted your time writing complex (and likely buggy) threaded code that does nothing but run slower than the single-threaded equivalent. And even if they can be multi-threaded, doing so is at least an order of magnitude more difficult than writing sequential code. If I need to (let's say) process a bunch of files independently, I can: 1. spend a lot of time writing multi-threaded code, dealing with all the complexities of such, debugging deadlocks and livelocks and the rest, and handle the threading in Python; 2. or in a tenth of the time, I can write a simple, single-threaded script which processes one file, and then call it from the shell multiple times, letting the OS handle all the parallelization. The point is, #1 is not the only way to do things. Programmers who focus only on threads are like carpenters who only have a hammer. I won't go so far as to say that [threads are evil](http://www.szakmeister.net/blog/2008/nov/15/threads-are-evil/) or even that they should be [considered harmful](http://wiki.c2.com/?ThreadsConsideredHarmful) but the focus on threads beyond all else really is harmful. I wonder whether there is an element of programmer's machismo here? "Threads are really hard, I can write threads, therefore I'm a rock star and I ought to use threads always!" The bottom line is, except in a very narrow set of circumstances, using threading for performance is an anti-pattern. It is an anti-pattern encouraged by many languages and cheerfully followed by many programmers (at least until they have to spend a week debugging some subtle race condition bug, or a deadlock brings their application to its knees), but it remains an anti-pattern no matter how easy it is to do threading. 
[Black Hat Python](https://www.nostarch.com/blackhatpython) ([Amazon](https://www.amazon.com/Black-Hat-Python-Programming-Pentesters/dp/1593275900)) is oft-recommended. So is [Violent Python](https://duckduckgo.com/?q=violent+python).
To play devil's advocate, maybe part of the reason they aren't using python is that they need parallel threads. 
What happens when you try to run it?
I agree that building something without a framework is unnecessary. Go with Flask. Some resources: - http://flask.pocoo.org/docs/0.12/tutorial/ - https://github.com/mjhea0/flaskr-tdd - https://realpython.com - https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world
Ah, I missed the "different languages" part. Yeah Alembic is fantastic, its autodetect of migration changes has been perfect so far even with postgres, the pickiest of the RDMBSs I've used.
Having them do `pip install requirements.txt` not possible?
[PyInstaller](http://www.pyinstaller.org/) is a really great distribution package, I recommend it.
It is, but the issues I know I've had in the past with multiple python3 versions installed and then getting packages to install correctly - I was just trying to avoid that. Your suggestion is my 2nd choice. 
Take the time to learn setuptools. Getting a well written setup function will do much to reduce distribution headaches. https://setuptools.readthedocs.io/en/latest/ 
Can you clarify/elaborate? Do you mean try to find a tool someone may have already made?
well, i've tried to pick up the language a few times, but i always stop a few lessons in because, let's face it, introductory level is boring. so if there are any tips on how to stay more involved with it, that would be awesome.
Neat, a small tidbit though: set(list(map((lambda x: x.title), conn_1.library.section('TV Shows').search()))) Is much simpler as: set(x.title for x in conn_1.library.section('TV Shows').search()) Or even as: {x.title for x in conn_1.library.section('TV Shows').search()} if you're running a version with set comprehensions (chances are good, it was added in 2.7 and at some point in 3.x)
I created a little tool for projects that use a changelog. If you have multiple people adding to the same changelog, it's prone to cause merge conflicts which is a bit of a headache. My tool solves that by generating the changelog from a directory structure. https://carmenbianca.gitlab.io/changelogdir/README.html It's pretty nifty :)
Nice try layman. Keep your illiterate hands of my .py files. 
r/learnpython
Lol. I wish it were that simple. 
Thank you for the books you recommended to me. I was just wondering if I would need prior knowledge of penetration testing to complete those books. Im just a little confused as I see some courses online that advertise python penetration testing and then some courses just penetration testing with tools. Would I have to know the latter to be able to do penetration testing with python? Sorry for so many question, and thank you for your time Thank you
I don't know. I will guess, and it's just a guess, that library has a useful lexicon for parsing text.
https://www.amazon.com/gp/help/customer/display.html?nodeId=200203300
u/opfeels u/automoderator
This looks interesting, I will have a look later. I'm rather partial to a nice tui.
Thank you. I think I'll look here first. 
It would be interesting to get a better understanding of the capabilities of this custom built tooling vs building on top of a framework like Fabric. 
How so?
it's compressed :(
Automate the Boring Stuff is available for free. Simply google the title for the free pdf or web version. It is a book to get you started writing simple scripts. Thst being said, I found Python Crash Course to be an extremely valuable book to learn python as a noob. After delving in, try to write some programs to solve problems in your life or as a form of entertainment (a game perhaps).
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
SQL is a Data Definition Language. Your friend suggested you learn Python because computer programming will allow you to do something with the data. Check out Pythons SQLite3 and SQLAlchemy packages.
You can do any number of things, off the top of my head: 1. Use a concurrent.futures.ThreadPoolExecutor with a limited `max_workers`, this would only allow `max_workers` running concurrently at a time. 2. Run the Cron every 15mins and just batch 1/2 of them per run 3. Put some arbitrary sleeps to offset when connections are made during the run
There's a really nice module I like to use for scheduling purposes: https://github.com/dbader/schedule
I think gspread is the easiest library for manipulating google spreadsheets
attrs does look interesting. I'd not come across that package before - thanks!
I'd be curious to see speed differences. The biggest thing I've noticed over something like ansible is that rollingpin is *fast*. I've used fabric in the past, and while it seemed fast, I wasn't deploying to hundreds of servers, so I can't say for sure. Fabric also takes a different approach of having you define your stuff on the client side from a list of predefined commands that fabric supports (I think -- I'm going entirely off of multi-year-old memory at this point) and then it executes the commands remotely, whereas rollingpin has you drop your deploy script remotely and gives you the full capabilities of the python stdlib as well as whatever else is installed on the remote machine. Someone feel free to correct me if I'm misrepresenting fabric at all.
To a certain extent, yes ... as you'll see in the demos that ship with it, you can indeed create a game or other app that uses tilt, taps, swipes etc to interact with your code... but there's only limited options for sharing that code (there is a way to share as a Github gist, or to email, SMS, or post to Facebook, etc) and these are of limited use unless the receiving person also has Pythonista.
Maybe you use a Telegram Bot. It's easy to use with Python. 
If you've already got local pypi, then, yes, distribute by copying to the local pypi and have everyone `pip install` from there.
Thanks man. You're a life saver. 
Put it in a container. I just ported an "OMG how many dependencies oh hell it needs a compiler includes and all that claptrap" Python command line app to Docker. In my particular case I needed to dynamically set up some port mappings ... but you can map bits of the host filesystem into the container, then basically gather up the command line flags and send them to the app running under Docker. https://gist.github.com/RantyDave/1c610d4622e5fb4dc335fb88caf7fa8f I spent lots of time getting Pyinstaller to work properly - including the patch you need (https://github.com/pyinstaller/pyinstaller/pull/2517 - ignored by maintainers) to have it working under macOS. Could just not get it to work consistently. Docker? Muuuuuch muuuuuch easier.
This is a joke right?
At runtime the interpreter always knows the type of each variable and throws errors when you try to do something obviously stupid.
No Arch/Manjaro/Antergos? *Users*, maybe, but not devs.
Thank you for your comments. I agree with you. However, unlike most Python packages, my repository actually contains multiple packages, with multiple levels of component packages/libraries, that share the same document set and while the repository is expected be installed on a general purpose development system, only a single Python 2x or Python 3x package (Development Sandbox or Site Package) is expected to be installed on an embedded system. To enable anyone to maintain and enhance the repository, I've released copious notes and issues explaining what I've done and why.
Websockets and event source
Fair enough. I'm honestly glad for the work you put into it! Have you thought about putting it on pypi? That would certainly help adoption (as would a name that's a bit easier to remember/spell). I know I'm far more likely to try a package if I can quickly install it with pip and play around with a short example that I can copy from the readme. :)
Seconded.
The more I look at it the less sure I am. The readme, directory sturcture, those comments. Is it a joke? Does it stem from some weird-ass corporate requirements? I'm baffled.
&gt; I want to prevent having a user get in the weeds installing them &gt; Docker? Muuuuuch muuuuuch easier. I don't think this is true for the type of user the OP is describing
two weeks sooner [I was starting a little project of mine](https://github.com/helldragger/ModularProgramming), today I'm upgrading it further! after automating remote source code insertion with a little algorithm database, I just automated source code dependency management, to automate the insertion of even more complex algorithms easily! :P (Now working on the network side of my project, I still have to make a first TCP protocol to send large source code)
Mhmm, still working alone on my projects currently but I might keep an eye on this for next year projects! :P
pypi did not support a heterogeneous mix of Python 2x, Python 3x and their associated component packages and modules. Keeping the heterogeneous arrangement enables me to use DeltaWalker (a folder and file comparison tool) to easily copy new features and bug fixes from one development sandbox/site package to others and ensure that I maintain the platform independent operator and application programming interfaces. 
I would suggest filing a bug at https://github.com/pypa/warehouse/issues, to ask to be allowed to upload bigger files, as there should be support for this: https://github.com/pypa/warehouse/issues/346.
I do accept Bitcoin. ;-)
The Getting Started document refers to a set of demonstrations modules. Examine the demo and library source code. Aside from downloading the repository, you can just run each demo from the Python 2x or Python 3x Developer Sandbox.
`pip install pygame` should work most of the time.
The result of some investigation: --- [`YoutubeDL.extract_info`](https://github.com/rg3/youtube-dl/blob/4bede0d8f5b6fc8d8e46ee240f808935e03eafa2/youtube_dl/YoutubeDL.py#L735) is a good place to start; it checks a provided URL against the extractors (from the [`extractor` package](https://github.com/rg3/youtube-dl/tree/4bede0d8f5b6fc8d8e46ee240f808935e03eafa2/youtube_dl/extractor)) [that are known](https://github.com/rg3/youtube-dl/blob/4bede0d8f5b6fc8d8e46ee240f808935e03eafa2/youtube_dl/extractor/__init__.py#L11), each of which has site-specific rules for extracting content URLs from a web page. Once an extractor returns a URL and other metadata, it eventually calls [`downloader.get_suitable_downloader`](https://github.com/rg3/youtube-dl/blob/4bede0d8f5b6fc8d8e46ee240f808935e03eafa2/youtube_dl/downloader/__init__.py#L32) on the content URL provided by the extractor to determine what protocol to use when downloading. The implementation for each protocol extends [`FileDownloader`](https://github.com/rg3/youtube-dl/blob/4bede0d8f5b6fc8d8e46ee240f808935e03eafa2/youtube_dl/downloader/common.py#L19) which provides the general interface for downloading a file. Depending on the requested options, it may need to postprocess downloaded files, for instance remuxing the requested video and audio tracks into one file. Code for doing these things is in the [`postprocessor`](https://github.com/rg3/youtube-dl/tree/4bede0d8f5b6fc8d8e46ee240f808935e03eafa2/youtube_dl/postprocessor) package.
Numba is really neat, I was actually toying with writing some code that would enable it to use annotations myself. For the simplest cases I think this would actually be quite trivial - just read the type annotations from the function object and pass them to the `@jit` decorator. Of course the remaining 80% of the work is likely going to be dealing with all the edge and complex cases...
The docs ignore it because Django gives you all the pieces (JSONResponse, AJAXcalls, etc) and you have to put it together. If you want a more all-in-one solution look at django-rest-framework. 
Just making sure, did it work? ^^ I can help further if you encounter any more issues
You've just hit on the basic definition of what we graybeards in the business call a *webapp* ... Yes, **Flask** is a great choice -- though, to be even-handed, it is one of many *web frameworks* for Python, albeit my favorite one personally -- and you simply use that to serve your data via compiling HTML (and possibly EcmaScript) using Flask's templating engine (**Jinja2**) into the *content* the user sees in their browser. You also provide CSS -- possibly itself compiled from **SASS** -- to style that content into however you want it to *look*. Oh, and *if* you want a desktop app instead of a webapp, you then use **Electron** to package up essentially the same content into a (somewhat large) desktop app... people who complain about speed there should look at **Visual Studio Code**, which has leveraged Electron pretty well.
Are you storing them in a .txt file or a file that doesn't have a .txt extension? 
First off, I'd encourage you to look at how to format code on Reddit (look in the navbar on the right). That'll make it a lot harder to help you fix it. Second, in this case I would suggest you have a look at your use of ab and checking your substring against it. Literally walk through why you're doing it that way and what it is supposed to be doing. Then read back what you wrote and tell yourself what that's doing. Some other small tidbits: * z is never changed or updated * current == longest is a check for equivalence, not updating current. * longest is never updated 
Are you sure this isn't an issue with the text editor you are using to view the file? I've never had python 'wrap' a string I've written to a file, and I've done that a lot (I've done it a lot this morning).
Are you sure that your list is actually a list and not some other data type? If it's some other kind of container, it might do some kind of pretty-formatting when you call `str` on it. You can perhaps avoid the issue by handling the formatting of the items yourself, rather than calling `str` on the container and then stripping the brackets. Try something like this, which should replicate the default `repr` format of a list, without the brackets: f.write(", ".join(repr(x) for x in t_collapsed[offset_i:offset_i + dims[this_rank + 1]]) + "\n")
/r/learnpython
Thanks a lot! It was actually a numpy array (it was passed from somewhere else and that made me miss this) and you were right about the pretty-formatting. I did a quick fix by turning it into a list and stripping the commas, like this - f.write(str(list(t_collapsed[offset_i:offset_i + dims[this_rank + 1]])).strip('[').strip(']').replace(',', '') + '\n') - and now it works as it should. Thanks!
BlckKnght solved it (see his answer), but just for completeness it was not the text editor (gedit). It shows the line and column number and it was clear that they were actual different lines.
BlckKnght solved it (see his answer and my answer to kigural): It was not the text editor.
The problem is now solved - thanks to everyone who replied: I really appreciate it!
Ah, that makes sense. Cool!
The documentation reflects my background developing embedded systems for mission critical industrial (electrical power plant) and military (avionic and armored vehicle) applications. It begins with a system overview of requirement goals and non-goals, design components and organization. I include a copy of the applicable Military Standard document outline templates. The size and complexity of the repository required its own overview description. Please ignore those pieces for which you have you have little, if any, interest. I provided it to enable others to maintain the software or adapt it to their own needs.
I think that is mostly correct. Fabric is just some glue code. Nothing would prevent you from calling out to random python commands on the remote system, or uploading a script and then calling it. Ansible to me is mostly the next evolution of Fabric, in that it has a little bit more reuse baked into things. It makes it a little bit less hassle to have a script shuttled to a remote machine and run (say deploy.sh or deploy.py). But you could totally do the same in either tool.
I meant that the connections are happening one after another every 30 minutes. The links are iterated over in a simple for loop right now.
Thank you! 
Thank you! 
Please don't do the strip stuff, just `"".join(list(...))`
You'll have to learn *a lot*. Good luck.
So it looks like I'm going have to use a mix of Flask/Python, Jinja2, and HTML/CSS/Bootstrap. After 4 hours I was able to create a site that displays my nested dictionary in a tree format using all of those, it's not much but it's a start lol.
pyenchant
"You must be fun at parties".
Great answer, I appreciate the bolded names, they were a good starting point. So after 4 hours of playing around I was able to make this haha: http://imgur.com/a/I0AY6 It's the most basic view of how my dictionary is to be displayed. Now I'm trying to figure out how to put them in drop down menus instead of having all of them displayed at once (which I'm having a hard time finding a starting place for on google). edit: nvm found out how
Nice! Thanks.
it sure does! 
Start with the basics. Is there a file there? If not, where is it? When you find it, symlink the directory to the desired location. If that doesn't work, we need to know more. 
For twitter accounts 30% is about average. So you are less Trump than the average deranged lunatic on twitter.
`"".join(list(X))` only works if all elements of `X` are strings.
Hm. Hard to tell without knowing where the data come from? Are you expecting a relation between them? You can use pl.tripcolor() if you want a map of your unstructured data. Take a look to `pandas` and `seaborn` if you want more stat oriented tools. And `scikit-learn` contain all you'll need for "big-data" processing as PCA, SVD, clustering and stuffs like that. Normalization algorithms too.
`"".join(map(str, X))`
Functional, not elegant.
&gt; Pyinstaller I've been waiting üé∂ for a girl like you üé∂ to come into my life üé∂ Seriously, I've been longing for something like this. Good to know this exists, will definitely keep it in mind for future projects! Thanks for sharing.
Working on the next iteration of https://howtrumpareyou.co and pitching it to new clients 
Those are not mutually exclusive. Elegance improves functionality - `import this`. They have `_TESTS` as class variables for live web-pages and 100 more things that are anything but functional and definitely not elegant. 
Ohhhh, *lay*man.
/u/dbader you make me write better code. Thanks for what you do!
You can compile Pythonista code to a native iOS app using the XCode template provided by OMZ, [provided here with instructions](https://github.com/omz/PythonistaAppTemplate). There are also a couple of forum threads with information, and you can always jump into the Pythonista Slack.
youtube-dl is quite massive, it supports way more than youtube. However, on a high level, it scrapes the web page to find video URLS. However, for sites like youtube, they are much more complex. I know in the past year, they have to put in code to decrypt signatures and such, because youtube go to great lengths to prevent downloading of content from the large channels, such as Vevo. 
Well, django-rest-framework is outside of the main project. But there's more to it than just encoding. For example, if I'm using a SPA framework, I'd presumably want JWT over cookies for authentication, websockets for notifications from the server, a CORS policy if I'm using npm outside of Django to generate the frontent, or if I'm sticking with Django, a way to serve frontend code that's generated using webpack. There's a lot to building an SPA besides json encoding, basically. As it stands now, you have to figure each chunk out on your own.
Here is it: https://github.com/cython/cython/issues/1672
I do as well, but just test it on another (preferrably clean) computer. DLLs are frequently not packed in, but you have the DLL. You user who is not a coder rarely does. 
Well, what type of data? Where did it come from? What is it? What purpose are your using it for? What questions do you want to ask and how can this data answer them?
Objects have types, not names. `MyNumber` is a name, and doesn't have a type. The objects that it refers to do. At the C level a reference to an object is a pointer to `PyObject`. Such a pointer can point to any Python object. PyObject *foo; foo = PyLong_FromLong(1L); ... foo = PyUnicode_FromString("a string"); (Reference counting omitted for brevity.) 
/r/learnpython
&gt; &gt; Python lack the tail recursion. &gt; &gt; Both are a features. Not only features, but Guido addressed [tail call recursion](http://neopythonic.blogspot.com.br/2009/04/tail-recursion-elimination.html) directly in a very long post explaining why it doesn't make sense in Python.
Everywhere, the extractors architecture is laughable to put it mildly. Take a look at [crunchyroll.py](https://github.com/rg3/youtube-dl/blob/4bede0d8f5b6fc8d8e46ee240f808935e03eafa2/youtube_dl/extractor/crunchyroll.py). We have tests, configs and extending of private methods (every method is private) in one module. 
https://www.youtube.com/watch?v=YYXdXT2l-Gg
That's not true at all. With shit-ton of javascript, cloudflare and all kinds of other backwards-minded technologies it's getting increasingly difficult to extract content from web-pages - especially media. 
This sounds like a statistics/data analysis/physics problem, not a Python problem.
There is a free four part course on Coursera called Python for Everybody, in python of course. The professor of the course wrote a free book called Python for Informatics. The course covers its material and it's great for beginners. The course and book will take you through the very basics to web scraping and using databases with python. www.coursera.org/specializations/python
There's no pull request to fix this, there needs to be a fork of some sorts. In my opinion there's no way to salvage this - the framework itself is so broken and badly designed that this project should be rewritten from ground-up. 
Does youtube use Cloudflare all of a sudden? I wasn't aware of that deal between the two. I'd have figured Google's peering directly with service provider networks in many locations would negate the need for a CDN, but maybe not.
Youtube-dl can do way more than youtube - that's the problem. It supports so many websites that it gotten so complex and ugly that no one can really understand it anymore. Checkout [extractors package](https://github.com/rg3/youtube-dl/tree/4bede0d8f5b6fc8d8e46ee240f808935e03eafa2/youtube_dl/extractor)
There was a kid on youtube who did an amazing job, unfortunately he cuts off his python project but at that point i was dangerous. http://www.youtube.com/playlist?list=PL6gx4Cwl9DGAcbMi1sH6oAMk4JHw91mC_ Next i found a class on udemy that was incredible and thorough. It was on sale for $10. Udemy is always having these sales so wait for it to happen then strike. I am taking Complete Python Bootcamp: Go from zero to hero in Python, on @udemy. Check it out - https://bnc.lt/Xfid/dbLlm7OVMD
Multiples of 9
Imho the ``_bootstrap`` method is a **no go**! I don't want my domain model be cluttered with cross cutting concerned code. The necessary fields for the ORM are probably acceptable, if your application is quite tight to a database and especially for CRUD apps with thin domain layer. But code for generating test data is really nothing I wanna have their.
Aha, I see.. Though I have one more question: is this supposed to be an example of code not to follow?
Alright.. I appreciate all your help and time, stranger! ^_^
And you are welcome to do that while the masses continue to use it without looking under the hood.
[pygtkspellcheck](https://pypi.python.org/pypi/pygtkspellcheck) ?
&gt; First commit june 3 2017 &gt; python 2 only 
I installed Python 2. Then deleted it. After that I moved the Python 3 file to my desktop to do something. But then python was not working properly. So what I did was delete the file. When just tried to install Python again I get the "Modify Setup" screen. But when I click "Uninstall" I get an error saying " No Python 3.6 installation was detected. How do I fix this?
I don't think this has anything to do with Python.
I'm not sure what's your point here. Popularity == functionality? The program barely works, there are 1.5k open issues on github, so calling this package functional is a bit of a stretch to say the least.
Hi there, this post has been removed as it is not directly related to the Python programming language. It might be more topical on /r/programming, /r/coding, or /r/technology. Cheers, /r/Python mods
Ok my bad
If you wanted to do a review of what you built, or the python algorithm that you used to build this, that would be acceptable.
I might do that although we are in talks to build some others so giving away our methodology might not be so smart
Lots of options here: https://stackoverflow.com/questions/16086962/how-to-get-a-time-zone-from-a-location-using-latitude-and-longitude-coordinates If it were up to me I'd use the Google API
&gt; As I said this talk will focus on what is included to get started with Django. Building an SPA would include multiple third party packages, or if you are building it from scratch with Django, much longer than 3 hours. Fair enough. But I would say: That's sort of the problem. ;) Making a CRUD with Django is pretty well-understood and documented. Making an SPA is not. Maybe an idea seed for future talks??
No it's not. Testing data should not be part of the core model. It is preferable to isolate it from the beginning to avoid ugly code like that. I use factory boy and faker, never eared about elisabeth before, and with factory boy, you create a factory that generate random data for a model which is more clean. See https://github.com/FactoryBoy/factory_boy/tree/master/examples/flask_alchemy for a concrete example. 
Extremely noob question (I have decided to teach myself) but uh, how do I update python? I am on a mac currently. Also I'm using the book "Automate the Boring Stuff" 
This looks interesting though not as flexible as I was hoping. Out of curiosity, even with 2.7, why did you use `os.popen` instead of `subprocess`?
This is the answer. Package and push to pypi. Then all the "layman" has to do is "pip install your_package" This will require work on your behalf, but will be a very useful skill to have for any future Python projects. 
Thanks. I just started poking around the docs after seeing the error and figured the spec file was part of the solution to my problem. I just came back to edit my comment and ask if I was on the right track. Looks like it.
So, there's this: https://stackoverflow.com/questions/42245620/python-libpython3-5-dylib-not-found Sounds like your exact issue. Seems to be a solution in the comments as well. Let me know how it turns out. 
Look up Homebrew.
Thank you so much!
Thank you for your reply. Your suggestion would definitely work. My issue with putting the local modules on PyPI is that many of the modules are simply convenience modules with settings and/or parameters based on personal preference. Probably not useful enough for anyone else to warrant a push to PyPI. Do you think that's a valid issue or something not worth worrying about? As far as distributing as a single sdist/bdist/wheel, I don't want to surprise the end user with additional dependencies that may conflict with something they already have on their local system. They download something called neato-package-1.0.tar.gz and the only addition to their installed python packages is neato-package. As you mentioned this could be mitigated by pushing the extra module to PyPI which would handle namespace conflicts, but the problem of pushing a bunch of personal use modules to a public system still exists. How do you handle this? Do you push everything you need to PyPI?
Why all the downvotes? Not long ago, it would have been unheard of to use JavaScript on the server. Before that, it would have been unrealistic to use Ruby for back-end development. If that's currently the case for Python in the browser, fine. But what would it take to get to where it's no longer so unrealistic?
Maybe you still need some JavaScript, but how much? You still need a compiler/interpreter to use TypeScript and newer ES versions. Why not use a Python compiler/interpreter instead? I'm not hating on JavaScript, I'm just wondering what people's experience is with trying to use Python for front-end stuff.
I love Shafer's stuff - great videos and not annoying
I'd hope you aren't getting downvotes for a simple question like this, but as a guy who's been doing Python and web stuff for 15ish years, the other comments are spot on. Currently you probably shouldn't use Python for web front end stuff beyond trying it just for trying it's sake. Javascript's ES6, and particularly React, converted me from "won't touch front end with a 9-foot pole" to "hey this is actually kind of fun." It's probably worth learning in the short term. Now, in the long term (for some ambiguous definition of long), we can hope that WebAssembly leads to a functional, native Python interpreter in the browser. Right now that's just a hope, though.
Thank you. I might try it for trying it's sake. 
you might be able to pass credentials to the main project's build run from its gitlab controls (eg. an ssh private key with read access to the repo). the the `pip install git+ssh://...` can work. then again, this probably better answered in /r/gitlab, given that it is not really python specific. (then again, so few questions are...)
If you need to see a patern, regression should be the way to go. PCA will "reduce" your (x,y) to one dimension so if it varies a lot, you will lose some signal in the process.
It's not the same. Using JS on the backend is relatively simple. Using another language on the frontend isn't, because browsers don't support it - that means you need to transpile, which means you still need to understand JS in order to do debugging within the browser. But mainly - why would you want to? What possible benefits do you think you could reap from such a thing?
I added the 'that will be better than' clause in case someone's made a python-to-JS compiler. Javascript is the only language that runs in web browsers. The only way around this is a transpiler. Transpiled languages are built around Javascript and its limitations. Python is not. Your server-side analogy is inappropriate, because you can run whatever code you'd like on servers. If you're committed to this idea, injecting python-like syntax (maybe getting rid of curly braces) in a new transpiled language is a way to go, like in CoffeeScript. It would be a large project.
I like Python, and I'd rather use it than not-Python. Also, if it's not currently easy, making it easier could be a worthwhile challenge.
Ok, that's a good point. Why would you need to limit it to a subset?
Just use the free tier if you have no traffic? 
You should learn how to use your computer before you think about programming. And I'm not even being sarcastic.
Right now I'm working on creating a version of Monopoly using Python. I'm also going to be writing an AI for it that uses Markov chains to calculate the probability of landing on a property, and uses that probability to calculate the expected value and determine whether it is worth buying the property. Inspiration comes from [this video](https://www.youtube.com/watch?v=ubQXz5RBBtU). Pygame is handling all of the UI aspects of the game, and I'm planning on using NumPy for all of the matrix multiplication and computing the AI needs to handle. I've never really done a Python project before, so this has been an interesting learning experience.
Interesting. Haven't taken the test, but I'd love to know what this bases it's judgements on
You might also join the Netmiko channel on network2code Slack. It has been quite helpful to me. The Netmiko developer hangs out there too. https://networktocode.herokuapp.com/
Here's the current attempt at a transpiler. https://transcrypt.org/
Great
Yeah - this is being passed off to a normie, not an engineer. 
It's not very clear what you're trying to do. What's the error you're trying to fix? Which operating system are you using?
Well [the Scrapy site gives a good idea of the difference](https://doc.scrapy.org/en/latest/faq.html#how-does-scrapy-compare-to-beautifulsoup-or-lxml) and from that deciding what you actually *need* is best. As for Scrapy's installation.. its a bit tedious. Its Python 3 support isn't stellar and requires you to use Anaconda/Miniconda to install it if under Windows. Last time I tried it (I believe Scrapy 1.3) It failed to work at all do to some missing files which could not be resolved yet. If you don't need a swarm of spiders or something Id just go with Beautiful Soup + LXML (Though html.parser is ok) it will get the job done and installing is just a matter of `pip install bs4`
I like this method, but is there a way to do this that would allow the sub-module to be reused or universally upgraded without having to maintain multiple versions? For instance, I have neato-package-1.0 and foo-package-1.0 both of which include sub-module-1.0. How can I do this without maintaining two separate sub-modules, one in neato-package and one in foo-package? Or if I want to upgrade sub-module-1.0 to sub-module-2.0 in both neato-package and foo-package how can I do that without having to edit both packages separately? This may seem trivial with two packages, but imagine the same situation with 10+ packages all using the same sub-module.
Something like this? cd submodule/ git checkout version-1.0 cd ./ cp -ar submodule/ ./packages
Scrapy is really more targeted for more complex scraping work, like when you need to parse all pages on a site. For this I'd use BS4 &amp; Requests, it's simple enough to plug them together and get what you need. BTW, It really helps to use pdb.set_trace() with BeautifulSoup, so you can interactively explore the HTML and figure out what you need to put in your script. 
I'd save it as a JSON use using the `json` module.
I'm on mobile now so I can't test but did you try that alternative suggested by romsson?
That seems doable. Any idea why this kind of thing has to be so klugey with Python? Compared to something like C where you have versioned headers, objects, etc. and you simply link to whatever you need in the build without having to copy the entire source into the project. Everything is versioned and reusable without much fuss. Am I just thinking about it from the wrong perspective?
Awesome thank you!
As far as I know it's just the current state of Python packaging...
This is the right decision, kudos to heroku!
That's unfortunate. Maybe a safer way to achieve the above might be to use git stash like this so you don't lose any work by checking out a different branch. Disclaimer: I'm not a git expert so I wouldn't recommend using this for anything mission critical. cd submodule/ git stash save git checkout version-1.0 cd - cp -ar submodule/ ./packages cd submodule/ git stash pop 
I'm writing a parser combinator for my library that talks to SpamAssassin so I'm not relying on a bunch of regular expressions that I thought was messy.
I appreciate the advice. I'm picturing incrementing the key for each created list like this: {'list_1': [1,2,3], 'list_2': [1,3,4]} or this: {'old_list':[1,2,3], 'new_list':[1,3,4]} But I'm not sure yet how to keep track of which lists to compare each time it crawls. The logic might be simpler only having an old_list and new_list. But I'd still need to compare old_list to new_list, then overwrite old_list with new_list, then remove new_list for the next crawl to replace it. Is that the right thinking? EDIT: Or I just name the lists whatever and compare the last element in the json array with the second to last item? I'm overwhelmed with options.
The python change is great but I have to say this: From my experience at my current job, please get off heroku as soon as possible. It's great for prototyping, but it's hardly a service to run a business on. 
What makes you say that
Try using `python.exe -m pip install pygame`, leading with a path to wherever your Python is installed.
You're calling input() 2 times, change this line term = inpuT[7:]
Thank you!! 
Generating the AppleScript code like that through simple string formatting of parameters looks really vulnerable to injection attacks. You should escape your input or something (maybe even create separate AppleScript programs for each function?)
What features do you need? Whats traffic like? Will it grow anytime soon? How much devops do you know? Whats your budget? 
Of course. [Here](https://gist.github.com/lk-geimfari/461ce92fd32379d7b73c9e12164a9154)
üòé
If you got many options pick one of the simpler options. You only need to save one list, and compare it with the new one, then overwrite it with the new list. Repeat.
I strongly agree with OP that you'll want to move off of Heroku eventually - its just a matter of when. Both AWS and GCE have slowly started moving up the devops stack, so its become significantly easier off late for someone with little knowledge to start using them. GCE has a [nice page](https://cloud.google.com/python/django) on their django options. Depending on how much effort you want to put into devops AWS also offers [Codestar](https://aws.amazon.com/codestar/) or [ElasticBeanstalk](https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create-deploy-python-django.html). 
tricky part is, these projects are used by many people, so putting my password in secret vars which can be easily seen, isnt good option :P 
ElasticBeanstalk has been great to work with. Deployment and updating is really easy through the AWS CLI. Throw in a Postgres database through RDS, domain with Route53, and you have everything you need. Use the free tier of AWS and you probably won‚Äôt pay much, if anything, for a year.
Already advised OP to use `subprocess` to pass arguments safely over on [/r/applescript](http://np.reddit.com/r/applescript/comments/6fujo6/applescript_functionality_for_python/), so hopefully he'll sort that shortly. (Python stdlib is such a bloated dog's dinner it's no surprise users have trouble knowing good APIs from bad.) As far as "more flexibility" goes‚Ä¶ &gt; Look on my Works, ye Mighty, and despair! &gt; &gt; Nothing beside remains. Round the decay &gt; &gt; Of that colossal Wreck, boundless and bare &gt; &gt; [The lone and level sands stretch far away.](http://appscript.sourceforge.net/status.html)
It is possible your python installation might be botched. Try running `pip3 install pip3 -U`. That might fix your problem.
And how would that work in a browser?
Here's a story from the folks at Instagram: https://engineering.instagram.com/dismissing-python-garbage-collection-at-instagram-4dca40b29172 They opted to make some changes to Python at some point. They ended up disabling GC from their Python code. Either way it's a worthy read.
Hey, I've written for fun against some stock market APIs without investing for real, but they haven't been python specific. I googled fast and found this interesting project http://gbeced.github.io/pyalgotrade/, they give examples with Yahoo's CSV files, which is nice if you just want to play around and simulate at your leisure. 
On Windows it doesn't like overwriting the pip binary from itself. Start pip from python -mpip instead: python -mpip --upgrade pip
i remember this happening to me. what a pain in the ass. sorry.
Its basically fixing up their internal infrastructure to support it. Same reason AWS Lambda only started supporting py3 recently.
i gave you an upvote for the text... still at zero, though. :)
Thanks
almost 35,040
Oh hey there sexy man in the caption.. 
This looked interesting, until I saw this in a sample notebook: &gt; After downloading the dataset, upload it to OneDrive or Dropbox as "mydatafile.csv" and import it into this notebook using the "Data" menu. I know you only need to (theoretically) do this once per notebook, but would be so much nicer to just be able to read directly from a URL into a dataframe, as opposed to the three step process above.
Awesome!
just babysitting. No interesting thing to chat.
I agree with your arguments. The reason for the format is based on how PostgreSQL represents things. If you were already used to that syntax it won't be that confusing, I think. I might change it in the future, but unless someone provides a more compelling format, I think it'll stay.
I don't know, probably 100-300.
Elasticsearch isn't a reliable primary storage solution. By all means use Elasticsearch in your stack (cos it's awesome), but if occasionally losing data is a major issue, it should also be backed by a resilient storage system.
They've also changed their CLI out from under us a number of times, or changed default behavior that breaks an app. They say you're not supposed to use their CLI to script, but since they don't provide public APIs you have little choice if you want some automation. The biggest change in recent memory: * Deciding that any time you provision a database, you want to promote it to the DATABASE_URL even if you already have one. I woke up one morning and our prod database was gone.
One can hope.
GCE
You can go to r/learnpython, you'll find good resources listed in the sidebar.
I'll look into it! Seems like there are many options : codeacademy,coursers,udemy and etc.. 
Thanks. I didn't know that sub existed.
https://howtrumpareyou.co it's done
So it can detect sub/superscripts? Would you advise reading the Excel file in as a .csv or a .xlsx? This is due by tomorrow, and after struggling with VBA for a week, I'm trying to use another language (I don't know Python, but it seemed more manageable). I wasn't given much notice for this. I'm kind of freaking out. Thanks for your help. 
Well, I released it early! Jokes aside, it has kind of grown organically over years and it just reached critical mass where I felt it's "complete"
Django ORM follows the Active Record pattern while SQL Alchemy follows the Unit of Work pattern. The first seems more readable at first but has more limitations. I believe you shouldn't be concerned with which one is the better, but which ones suits better the needs of a particular project, and that choice really depends on the complexity of the project you're implementing as well as if you're using django or other framework (like pyramid or flask, for instance).
&gt; Operations like a + b + c will reuse temporaries on **some platforms**, resulting in less memory use and faster execution. I would be nice if they were more specific about which platforms they're talking about (I'm guessing improvements don't apply for Windows, but maybe that's wrong?).
Peewee is lighter, extensible, and it has a large community like Django ORM and SQLAlchemy :) 
If you're storing lots of files, why wouldn't you use the file system? Come up with a way to logically shard the data into folder structures and access it that way. If you need to actually search the content you should be doing entity extraction on the raw files and putting that in a search index. SomeWebsite.com -&gt; md5(contents) -&gt; mkdir md5[0:5] `0/b/2/a/c` -&gt; file goes here.html If you need to be able to find individual files faster you store the references in a relational database (postgresql) and do the lookup that way. (create an index on `MD5 + REL_FILEPATH` for fast lookups) `ID SITE UUID MD5 CREATED UPDATED REL_FILEPATH INDEXED`
A good starting point for generators and coroutines is the extensive [talk](https://www.youtube.com/watch?v=D1twn9kLmYg) from David Beazley. He also made an also extensive [talk](https://www.youtube.com/watch?v=sPiWg5jSoZI) about meta programming. Both are roughly 3 hours long. James Powell made a good [talk](https://www.youtube.com/watch?v=JasPrZqImxo) about the general advantages of generators, also very good and helpful. Brandon Rhodes made a good [talk](https://www.youtube.com/watch?v=Er5K_nR5lDQ) about design pattern and how to use them in python. The video is kind of glitched, just start at 17:25. I think these are good jump starts for the topic and all of the mentioned speakers are really good at their job. You should look out for other talks from them, I recommend them all.
Love peewee.
Precompiled Windows Binaries built with Intel MKL available: http://www.lfd.uci.edu/~gohlke/pythonlibs/#numpy
This is my own experience, but it is a good deal easier to learn basic sysadmin/operational skills if you already know Python. If you have a modest stack, you can cheaply, and easily, maintain your own systems and databases. AWS and GCP are quite nice, and you can have a handful of scripts provision the entire environment for you. Then, you pay just for the infrastructure, and not the 'value adds', and you can get away with paying far less, and have a far more intimate understanding of your environment.
I figured it out, for those interested go here: https://stackoverflow.com/questions/20159566/cx-oracle-importerror-dll-load-failed-this-application-has-failed Make sure that once you have done everything in the instructions to restart your computer! Then it should work.
Check out [Real Python](https://realpython.com), if you're looking to learn the syntax and then move into web development. Note: I am the co-founder/author Real Python takes an experiential, learning by doing approach so you build interesting projects. Happy to provide a discount. Email us. Cheers!
I'm in the middle of a project with gantt-like overlapping date ranges and this is definitely of interest! Thanks for opensourcing it, greatly appreciated.
This is very similar to my initial use case as well. Happy coding!
Are you using machine learning for this or some sort of rule based algorithm? :) 
Well searching the error you're receiving brings up https://raspberrypi.stackexchange.com/a/28189 which suggests that you need to install `libffi-dev` using `apt-get` Also note that one should not use `sudo pip` You can use the `--user` option instead e.g. `pip install package --user` to install into your *$HOME* directory.
This question is really vague, be more specific.
You can also use Scrapy's *"parser"* as a standalone library http://parsel.readthedocs.io/
further down they say &gt; On platforms providing the backtrace function [...] Looking further to [here](https://mail.scipy.org/pipermail/numpy-discussion/2016-September/076034.html) where the developers originally discussed this, it says: &gt; It currently only supports **Linux with glibc** (which has reliable backtraces via unwinding) and **maybe MacOS** depending on how good their backtrace is. On windows the backtrace APIs are different and I don't know them but in theory it could also be done there. (things might have changed since that original discussion, feel free to dig deeper) 
Kinda both, I have a good base to make a model for learning but none of the real dynamic learning stuff is in yet, so far it's only rule based and basic math. You can see the code if you want! [GitHub Repo](github.com/akmadian/Machine-Learning) 
Thanks. I was afraid I was missing some obviously much simpler approach. So I'm glad to get confirmation that I'm on the right track.
When announcing a release, please put some context in the title and in either the submission text or a comment. 
 pi = 0 sign = 1 for n in range(10000): pi += sign*4/(2*n+1) print(pi) sign = -1 if sign == 1 else 1
I am excited about two updates: 1. Multidimensional `unique`. This ended up being critical for my work and I had manually grabbed the PR awhile back. 2. Multidimensional `apply_along_axis`. I do a lot of functional style programming and this method enables condensing some previous code.
&gt; I like Python, and I'd rather use it than not-Python Those are exactly my thoughts!
Why should we not use sudo? I have a raspPi I run a simple script off of every so often (I don't care if I have to reflash eventually), but it requires 1 library I installed with sudo.
A better version of `np.bmat` that returns an `ndarray` instead of a `matrix`.
It's also common to represent intervals this way mathematically‚Äã. May not be "Pythonic", but not everything has to be. I personally enjoy when syntax can be idiomatic, expressive and short as is the case here. 
An $5/mo Linode or something in that price category? I mean, at what multiple of 1 QPS do you think their single core offering will become insufficient?
I used to work for a DMS. When I left we had 630 million documents...like, real documents (docx, pdf, xls, etc) that needed to be 100% fulltext searchable with 100% "findability." Using a file system scales better than you think it does. There are some formats designed for this, https://en.wikipedia.org/wiki/Comparison_of_file_systems#Limits
With your knowledge in C, I'd stay away from "copy/paste" courses. You won't need to spend any large amount of time learning the basics (the syntax is pretty easy). I'd go for an intermediate course and look up any syntax questions.
A great time to release something that is 2.7 only.
You can PM me if you want. If it's for your benefit I wouldn't mind answering questions and looking over snippets when I have a free minute. If it's for your company we can set up some kind of code review consulting deal.
&gt; That is a little sobering. While many projects on GitHub are just trying it out and may not be active on the web. One hopes private repos for serious business are much better than that. That's true. I'll write a follow-up blogpost looking at active/popular projects in depth. &gt; I only recently integrated with pyup.io on one of my project. It was annoying when Requests had 4 releases in a day. But it makes it really easy to process the pull requests and let Travis verify everything was still good. Have you looked at the `schedule` config? https://pyup.io/docs/configuration/#schedule-updates
Either you somehow started running your code using Python3 (without noticing because most of your code is accidentally python3 compatible, which would be really weird), or some of the libraries you use updated and started returning unicode strings in some circumstances which you then use incorrectly or pass to some other code that uses them incorrectly. It's hard to say anything further using my telepathic powers alone. Oh, and if you're confused about what it all is about in the first place, Python2 has two string types, `str` (an encoding-less array of bytes basically) and `unicode` (a proper string of actual characters). But, like, everyone used str's most of the time because it's easier. To confuse everyone further, a lot of standard library functions are sorta multilingual in this sense, that is, if you do `os.listdir(u'.')`, passing a unicode string literal to it, then it would return file names as unicode strings as well. Even furthermore, ordinarily unicode strings just transform byte-strings to unicode when you concatenate them and return unicode, so totally unknown to you a large portion of your strings could be unicode. And that particular error, as Google tells me, is likely to happen when someone writes weird code like `str.lower(s)` instead of `s.lower()`. Because the latter would work for any type of string, while the former only works for `str`-strings. So yeah, something somewhere decided to use unicode strings and then something else broke.
There are two things for alleviating this, schedule and selecting security only. The rapid updates from pyup is actually impressive. It was just surprising how fast PyPi versions of Requests were being made. 
Seems like Toxicity lays their eggs everywhere. Kill it with fire!
PM me with details, will be happy to help :)
God I hate these videos
care to elaborate?
How do you handle migrations with Peewee? I love it, but hate hand writing my database changes
They lend themselves quite well to a MVC design pattern. Most GUI frameworks have a very similar signal/slots mechanism. I've also been doing some nodejs work lately and it's a recurring theme there. That and I guess I just felt like it :) For anyone wanting to read more on signals and slots: https://en.wikipedia.org/wiki/Signals_and_slots or MVC pattern: https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller
How far down to I have to scroll to see the reference?
The video should have been "Build a neural net in 10 minutes" and contain an additionnal 6 minutes to make the video more informative and less "just copy-and-paste that and BAM!".
And conda packages for Linux, Mac (linked against MKL or openblas), and Windows are already available. They even already compiled scipy, pandas, scikit-learn, etc. against the new Numpy.
That's a different reference, mate. Though it is referencing the same thing that Python is itself a reference to.
Holy crap, that's amazing! Does it work for any stock?
Thanks! I'll look into both books.
[Are you serious?](https://en.wikipedia.org/wiki/Monty_Python)
Would it make sense to provide a configuration option so users could take their pick?
Maybe... What? 
For most things I like to avoid using any ORM at all, plain SQL is often more readable. A simple SQL query embedded in the Python code is readable and has the advantage that you can build it by testing first in the psql command line and then when you're happy with the result you can simply copy it to Python, add a `%s` or two here and there, and you're done. I honestly don't know why is everyone so obsessed with ORMs.
WANTED: Python programmers with experience in backtesing CryptoAi is looking for new members with experience in python and backtesting to help us in growing our in-house fund. Currently, our team is composed of eight members. Collectively, we have a diverse collection of skill sets, covering hedge operations, physics, quantitative finance, trading strategies and machine learning. The concept behind the fund is to exploit the seemingly abundant amount of inefficiencies found within cryptocurrency markets. A wide variety of indicators are being explored, ranging from price and volume studies to sentiment analysis from text based data. At the fund‚Äôs center is our custom built trading system. Signals from our proprietary indicators are displayed into signal feeds, alerting a fund manager of potential setups forming in the markets. An OMS and EMS for the system are currently under construction. These will allow for complex order types currently unavailable by most exchanges and enable us to bypass the lag experienced by the various exchange interfaces. The roles we are currently looking to fill entail running simulations with our indicators in order to improve the signals in the signal feed. We have constructed a custom backtester and are seeking new members with the resources to build upon it or to implement their own system. Interested in the role? Or feel that you could contribute in another way ? Contact us at: dave@cryptoai.io www.cryptoai.io https://github.com/Crypto-AI 
PM me. I'd like to connect with you - we can talk code!
Any particular challenges that are difficult to tackle without the bio background?
The development PyInstaller version from Github supports Python 3.6 [\[1\]](https://github.com/pyinstaller/pyinstaller/issues/2329). To install it: $ py -3.6 -m pip install https://github.com/pyinstaller/pyinstaller/archive/develop.zip
pyinstaller is the first option, but depending on your usecase, you might be able to use a simple Flask wrapper and make it available as a simple website. Cross-platform compatible, no installs on the user side (so they don't need admin rights), and you can update whenever it suits you. Not perfect for every use case.
Everything you just wrote is objectively false.
When you are working on larger and more complex applications, raw SQL turns into spaghetti fairly quickly. It's also nice to have a language-native interface for your data. If your application is small and simple, raw SQL makes a lot of sense until it doesn't. As your application grows, more and more operations need to be implemented. At a certain point it will become very difficult to remember which operation does what. You will also find a lot of duplicated code. Is saving a blog post any different than saving a comment really? No, so you merge the save operation into a single function that can operate on any row of any table. You find that most models can be updated in the same manner as well. You expand your save function to handle updating existing instances as well. After a while you will end up writing your own little Db interaction library. The problem is that this library is specific to your application. You then find that you need to add a couple of columns to one of your tables. You go through and update every single function that operates on rows from that table. Be careful you don't forget one! Oops! You forgot about SQL injection attacks! Better write a sanitizer for all incoming data. Your app continues to grow and now you are encountering performance problems. After benchmarking, you are able to find the particular Db operations that are bottlenecking and refactor them. A new feature needs to be developed that involves heavy use of indexing. You spend some time to write a small library for dealing with indexes. After all of that, you take a look at your work and realize that almost every single ORM handles every single thing that you just built from scratch. You wasted countless hours on NIH syndrome. That time could have been used to build new features or improve the UI or the API. That said, if you are not planning for your application to grow past the small and simple phase, raw SQL is absolutely acceptable and, in many cases, better. This long-ass post is in response to your curiosity: &gt;I honestly don't know why is everyone so obsessed with ORMs.
This is awesome. I am in a similar position. I will post on GitHub. The app code is very small, utilities a bit bigger to support multiple RDBMS and externalized SQL, sqlrunner, integration testing, my first python app. Posting to bookmark.
If all else fails, there's Python bindings for [selenium webdriver](http://www.seleniumhq.org/projects/webdriver/) which drives an actual, real browser. It's not python, but the best tool I know for troublesome site automation is [autohotkey](https://autohotkey.com/). I may or may not implement game bots with this.
Or use `conda` / Miniconda / Anaconda, and get that plus the rest of the science stack (including geospatial stuff, which is a PITA to compile otherwise).
Add the `conda-forge` channel if you want fast updates - it released [yesterday](https://github.com/conda-forge/numpy-feedstock)!
Can't find speed comparision with cpython 3.5/3.6. Did someone have success with speeding up your code? Couple months ago I tried to run my simple puzzle solver and I did not see any speed up on pypy (puzzle solver have no io, and no c-libs are used, pure python).
You can use PyPy for Python 3, but has it yet gotten to the point where you actually should? They previously warned that using it for Python 3 could very well be even slower than CPython. 
How this compares with PySignal?
Your problem here is not Python, your problem is that to impose order on chaos you will have to write or at least check the patterns manually. The best heuristic I can think of is to take the filenames in a directory, and try to cluster the stems in a way that balances length-of-stem with number-of-clusters (then stems are controllers, etc). This is unlikely to work well, with so little consistency in the names. How do you do it at the moment? Automating that process is probably easier...
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
so is 90% of web dev
&gt; The server can now run on a machine with as little as 2GiB of RAM. Considering that number has only dropped that far... Yeesh what is all the memory still spent on? 
Thanks! I PM'd you. The app I'm building is for my company, but I'm more specifically looking for feedback on my coding style, and to point out my bad practices so I can improve upon them. Anyways, I appreciate any feedback!
Two question, Is it safe to use pypy with numpy? Can i use pypy with opencv?
Why tornado instead of Django channels?
PMed! Thanks!
PySignal is based off Qt style signals, so it has more features. It's been around longer and is likely more stable. _But_ it's slightly more verbose. Take a look at hooking up a signal with PySignal compared to Ku√†i (from PySignal github) from pysignal import Signal, ClassSignal, SignalFactory, ClassSignalFactory def greet(name): print "Hello,", name class Foo(object): started = ClassSignal() classSignalFactory = ClassSignalFactory() classSignalFactory.register('Greet') def __init__(self): super(Foo, self).__init__() self.started.connect(greet) self.started.emit('Watson') self.signalFactory = SignalFactory() self.signalFactory.register('Greet') self.signalFactory['Greet'].connect(greet) self.signalFactory['Greet'].emit('Sherlock') self.classSignalFactory['Greet'].connect(greet) self.classSignalFactory['Greet'].emit('Moriarty') ended = Signal() ended.connect(greet) ended.emit('Mycroft') foo = Foo() # Hello, Watson # Hello, Sherlock # Hello, Moriarty # Hello, Mycroft With Ku√†i every class in the MRO is a singleton instance, so you don't have to instantiate anything. Something similar with Ku√†i is (updated to Python 3.6 syntax).. from kuai import Kuai, Ku√†i def greet(name): print(f"Hello, {name}") class Foo: started = Kuai classSignalFactory = Ku√†i() def __init__(self): self.started.on('started', greet) self.started.emit('started', 'Watson') self.signalFactory = Kuai() self.signalFactory.on('signal-factory', greet) self.signalFactory.emit('signal-factory', 'Sherlock') self.classSignalFactory.on('class-signal-factory', greet) self.classSignalFactory.emit('class-signal-factory', 'Moriarty') ended = Ku√†i ended.on('ended', greet) ended.emit('ended', 'Mycroft') foo = Foo() # Hello, Watson # Hello, Sherlock # Hello, Moriarty # Hello, Mycroft I tried to illustrate the fact that _every_ Kuai (or Ku√†i) in the script is _the same instance_. And really all you need to remember is `Kuai.on('event', callback)` and `Kuai.emit('event', *args, **kwargs). So it's not the same as PySignals in that all events are exposed through Kuai where the above instances of the various Signals are somewhat encapsulated. Also ------ The backends are loaded with [pluginbase](http://pluginbase.pocoo.org/), so you can extend the backend by overriding two methods. That's it, then you load them in like from kuai import Ku√†i, set_backend set_backend("priority") ... More on that here: https://github.com/Duroktar/Kuai/kuai/backends It's definitely not perfect but I _really_ would love people to contribute to help make it better. I won't be stingy accepting pull-requests **I promise** :) Anyways, gotta go. I stared Kuai yesterday morning and have barely stopped haha, (my SO is gonna kill me) Cheers edit: 1 damn word
Not without magic...
Awesome! I PM'd you. I'd love to talk code!
From their blog posts, the codebase is now at parity with PyPy2. In my tests it's much faster than CPython (as expected). 
Thanks! I'll look into Lincoln Loop. I'm not sure I'm quite ready to hire consultants, but it could be an option a little further down the line.
ORMs turn into spaghetti as well. The trick is to centralize access to the database and hand out non ORM objects to the rest of the code. This addresses two big issues I have with *any* sort of database access: * Persistence modeling and Object modeling are inherently different. * Avoiding unnecessary and hard to test IO of of other parts of the application. Ad hoc queries become a little more difficult in this model but you can always do a little evil if needed, and joins can become burdensome if you're rigid in your adherence. But these two are smaller issues compared to the two above. 
"Games" is too broad of a category to answer. You could certainly make a high-quality chess game in Python. Would you make Zelda: Breath of the Wild in Python? Probably not. But: https://gamedev.stackexchange.com/a/5044
Python is written in C, so I think it's impossible. However, I hope it can be faster than Java :)
If it uses a JIT compiler, and uses runtime code path usage optimisations, then in many uses cases, probably. The advantage of a JIT compiler is it can analyse with real usage data and make better optimisation decisions than a statically compiled code. But there are also trade-offs with JIT. It takes time for code analysis to run before swapping out interpreted code for generated machine code. That could be a problem if predictable performance is far more important than faster performance.
Time to try pythonnet with pypy again: https://stackoverflow.com/q/42152122/2230844
The docs mention that Zulip only runs on Ubuntu. Why is that? What non-Python requirements are there for the project?
The only missing feature for NumPy in PyPy is the use of UPDATEIFCOPY, since it currently is triggered via the destructor of the base array. PyPy's garbage collector is different from CPython's, so the trigger is sometimes missed. This flag is common when using an "out=" keyword for some NumPy functions. If you do not use those semantics, PyPy should be %100 compatible with CPython. I have not tried OpenCV with PyPy. You would have to rebuild the python wrapper telling cmake to use the PyPy interpreter instead of CPython.
Difficult? Not really, we are almost there. Give it a try, you may be pleasantly surprised.
Ah. I'm on python3
Don't feel bad. Half my own packages end up releasing a .0 and a .1 the same day since I *always* mess something up the first try.
Great to hear! I seem to have out of date info then.
Hey Terence‚Ä¶ I'm just reading through /r/Python and I noticed this comment. Pray tell, why are you so excited? Gooble Gobble :P
They said 170 mb
Thanks for sharing, I was not aware of this project at all.
It's amazing. Every time you update a package...it breaks everything. I hate you pandas, proxy numpy.
Its 2017 and sometimes Python 2.x is still used for new projects...
I don't ever remember having a problem on Windows. pip install -U pip has always Just Worked‚Ñ¢
&gt; I can't say the is really a project and you are missing the point *It is* a project, a very small one but a project nonetheless.
I changed just -&gt; finally to make things slightly less titlegore material.
It's probably easier to monkey patch the library if the format is a concern. I don't think a configuration option is the way to go. I might however try to find a new syntax for it since there are many who seem confused by it. Yesterday I even got a pull request to "fix" the README from a confused user: https://github.com/runfalk/spans/pull/9
I can make a special _for humans_ release, just for you ;)
They said 170 megabits not 170 millibars
Tornado can do Asynchronous HTTP requests. Can Django Channels? I just tried googling and couldn't find anything. If not that would be a good reason. 
Hi /u/jmmcd, Thanks for your advice, I won't forget it for the next release !
&gt; Any sufficiently complicated C or Fortran program contains an ad-hoc, informally-specified, bug-ridden, slow implementation of half of Common Lisp. - Philip Greenspun
These are the client applications. The server application seems to be Ubuntu only : &gt; Zulip in production supports Ubuntu 14.04 Trusty and Ubuntu 16.04 Xenial. Work is ongoing on adding support for additional platforms. The installation process is documented at https://zulip.org/server.html and in more detail in the documentation.
Oh okay, my bad :)
We used to use zulip at work and I miss it. Wish the clients were better and I'd be pushing to use it at communities. 
Hi /u/liiight000 I am really happy to read your comment :) I don't know which YAML parser library you are using, but if it provides a way to output a python dict, it should be a breeze to integrate Scalpl in your project ! If you give Scalpl a try, do not hesitate to send me some feebacks :) Have a great day !
https://codereview.stackexchange.com/ This is where you're most likely to get good answers.
There are instructions for installing on other Linux's https://zulip.readthedocs.io/en/latest/dev-setup-non-vagrant.html#installing-manually-on-linux
It is time to drop Python 2.7 to focus on Python 3.6
https://gitlab.com/carmenbianca/schaakmat/pipelines/8811743 Have a look at this maybe. I run automated benchmarks against a little chess engine that I'm writing (and that is far from done!). You can find benchmark and profiler results in the job artifacts. PyPy appears slower. The normal test suite runs in 3 seconds for Python 3.6, and 20 seconds for PyPy 3. The results probably show why, but I've not yet looked into this. Python 2.7 is much slower than Python 3. But I think this may be due to the fact that I'm using `future` and a backport of `functools.lru_cache`. I'll work out some of the performance details after I've finished writing the important parts :p edit: Hoooold on. PyPy is actually *faster*. It runs the tests much slower for some reason, but it runs through the profiler of a pseudorandom game much faster. (The pseudorandom game uses the same seed, so it's basically the same game each time.)
How about JSON?
Post in /learnpython. JSON is the way son. Unless you can store the dict data to DBtables with SQLITE or similar.
I haven't personally used it before but skimming over documentation maybe try MongoDb.
Good answer!
I tried JSON with TinyDB, but the query language it's not so powerful and it's very slow. I don't want to setup an Elasticsearch server for it, I think I'll give a try to MongoDB.
you don't need a query language. hardcode them in Python.
&gt; I cannot use a SQL DB Yes you can. Several approaches here: - Some DBMSes support spatial data types, e.g. PostgreSQL has `JSON` (textual disk format) and `JSONB` (binary disk format) data types that can represent JSON data, and with `JSONB` you can even query into the data. - Even without spatial types, you can flatten a nested dictionary into a `path` + `value` list. - Another option is to actually represent the tree structure in your relational model; there are two basic approaches for this, same-table-foreign-key (add a `parent_id` field to your entry type), and the "PQ" approach, where each record has a "P" and a "Q" field (sometimes called "left" and "right"), representing an interval on an arbitrary value axis, such that a child row's interval is a subset of its parent interval, and sibling intervals are non-overlapping. PQ makes insertion and deletion expensive but querying is cheap; same-table-foreign-key makes insertion and deletion cheap but querying across tree levels is expensive. Other options: - Try a document-based database (e.g. CouchDB) - Serialize to JSON; since Python's go-to JSON implementations are strict, that is, they don't allow streaming, it's probably best to serialize each dictionary separately, into a file of its own. - Serialize to XML, and find a library that supports streaming. Question is, how do you receive the data, and what are your querying needs?
Maybe the [shelve module](https://docs.python.org/3/library/shelve.html).
Does it work with multiple screens?
No/yes. You can access python data structures such as list/dict/set from Cython, and then all the normal CPython rules apply. Python data structures are mostly thread-safe, as long as the operation being executed corresponds to a single opcode. There are good discussions of this if you google around. On the other hand, when you use any CPython data structures from Cython, you will be unable to release the GIL. You can use C++ STL data structures from Cython, but I don't think these are thread-safe. You can, however, release the GIL when using these.
What I'm seeing here is that Kuai is more verbose. PySignal: self.started.connect(greet) self.started.emit('Watson') vs Kuai: self.started.on('started', greet) self.started.emit('started', 'Watson') Quite redundant, even.
&gt; Try a document-based database (e.g. CouchDB) This could be a good idea. The other one are a little unpratical. &gt; Question is, how do you receive the data, and what are your querying needs? I'm receiving data by scraping sequentally some webpages. I would like to have statistics, this is why I would like to have a query language to extract just the data that fill my needs.
Hello, taking a chance here. Is there a list of compagnies using pypy in production? 
You mean "convert", not "cast". Python doesn't have casting.
Try r/learnpython not here. Read the sidebar ---&gt;
Read the python cookbook. That's how I learned advanced topics and it's seriously amazing.
Thanks for the advice, I added some docstrings, changed method names and removed that old import. You were right, there was no use to have the name-mangling.
Your login form will get #$%^&amp;*-ed continuously by random bots and crap. If two-factor authentication is a bit too much then at least add a brute-force protection thing like django-axes, check the logs and be grateful. 
I would recommend setting a rate limit in nginx instead. I think brute force attacks are better handled before they even get to django.
Learning some Django this weekend, never played with it before. started playing with cgi and bought one of those courses from udemy for full-stack development. started it last night, but won't really dive into it till tonight. Lately I've been trying to rewrite some of my old programs to work through a browser interface. started with a very basic program and have been moving to the bigger ones as I get a better grasp of what I'm doing.
Whatever you can in your situation. Doing it in nginx doesn't work if you run on a cluster or serverless. Some cloud providers have some cool stuff as well, like AWS WAF. Just don't let the wild internet silently abuse your naked forms.
You forgot to initialize the signal. So it's self.started = Signal() self.started.connect(greet) self.started.emit('Watson') But I didn't mean to offend anyone calling it more verbose. edit: Since Kuai is always initialized it's usually called like this. Kuai.on('started', greet) Kuai.emit('started', 'Watson') And you don't need to import 4 different kinds of signals. from pysignal import Signal, ClassSignal, SignalFactory, ClassSignalFactory just from kuai import Kuai Sorry for the long posts :) Cheers
Virtual environments? 
Very interesting project! Can the server run on a raspberry pi with 2gb or ram? 
I'm working on a pet rat monitoring system using a webcam. So far I can detect motion, save images (and metadata to an db), retrieve images. Next step is to make some simple computer vision/machine learning algorithms to identify behaviours how full the food bowl is etc. This is the first project that I've tried to apply some coding standards too, I've used multiple files (!! haha) and am using Pycharm which im loving!
http://lmgtfy.com/?q=openstack+contribute+open+source :D
Yeah, that's usually it for me to. Kuai just cuts out the initialize steps and let's you focus on hooking up signals. I made a demo app this morning for it, [have a look](https://github.com/Duroktar/Kuai/examples/paint) edit: fix permalink
I used to work for a company that was one of the top OpenStack contributors. What I've seen lately is that they fired a lot of people, and in general there's significantly less investment money going OpenStack way. But there's RedHat which, what looks like, successful with making money of OpenStack. It's not going to be easy to get your commits accepted. But you can start with simple and easy stuff. You kinda need to make a name for yourself to get more attention to your commits. Select a project of OpenStack that you feel comfortable with, I'd suggest you start with one of their testing or benchmarking frameworks that way you'll get to learn most of the OpenStack projects(components). You can find a lot of information on the wiki https://wiki.openstack.org/wiki/Main_Page
**Here's a sneak peek of [/r/inventwithpython](https://np.reddit.com/r/inventwithpython) using the [top posts](https://np.reddit.com/r/inventwithpython/top/?sort=top&amp;t=year) of the year!** \#1: ["Automate the Boring Stuff with Python" ebook is $1 in the Humble Bundle! (Ends August 28th)](https://www.humblebundle.com/books/joy-of-coding-book-bundle) | [2 comments](https://np.reddit.com/r/inventwithpython/comments/4yr3a1/automate_the_boring_stuff_with_python_ebook_is_1/) \#2: ["Automate the Boring Stuff with Python" is in a pay-what-you-want humble bundle to benefit the Python Software Foundation](https://www.humblebundle.com/books/python-book-bundle) | [1 comment](https://np.reddit.com/r/inventwithpython/comments/63qwck/automate_the_boring_stuff_with_python_is_in_a/) \#3: [New, free book from Al Sweigart: "Scratch Programming Playground"](https://inventwithscratch.com/book/) | [0 comments](https://np.reddit.com/r/inventwithpython/comments/560j5u/new_free_book_from_al_sweigart_scratch/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/5lveo6/blacklist/)
Django channels didn't exist at the time we wrote Zulip's real-time push system. Last year, I asked the author whether it was ready for production, and he wasn't using it in production yet. We may switch, but given that our complete push system is only a few thousand lines of code and hasn't been a source of trouble, it's not a priority for anyone.
I also wrote a little program to extract data from a directory full of old excel files and populate a postgres database. The sad thing is that it took a couple hours to write but when I finally finished and ran it, the program was done before I had time to refill my coffee. It was almost anticlimactic.
As of Zulip 1.6, it can now!
There actually aren't many differences about these concepts. Some things to keep in mind: * Threads in python can't use multiple cores because of the GIL, though it's ok to use them for easy IO concurrency (in a smallish scale) and single-core non-blocking code (care about locking / atomic queues / race conditions still apply). For large scale IO concurrency it's better to use something like asyncio, curio or gevent. For multi-core parallelism the best way is still using multiprocessing (concurrent.futures makes it easier to use, but still has all the inter-process complexities that can't just go away, unfortunately). * Performance in python usually boils down to doing less things in python. The builtins and stdlib have very powerful constructs for doing things at a high level that are actually implemented in very optimized C, so if you have some tight loop in python, check if you can replace it by some itertools function instead, or if you're doing heavy array/matrix operations, numpy is the way. * OOP in python is closer to smalltalk-style OOP than C++/java OOP. * Watch every talk from David Beazley and Raymond Hettinger you can find, they're amazing speakers and will teach you deep and advanced topics in a way that will make them look very easy and fun.
Amazing! 
here's an example (windows). sorry for the formatting i'm on mobile This will create a directory on your desktop, then identify all files on your desktop that end in a given extension, and copy those files into the directory that is created. import sys, os, shutil dir_nm = 'copy_file_example' dir_root = os.path.expanduser("~\Desktop") dir_work = (dir_root + '\\' + dir_nm) if not os.path.exists(dir_work): os.makedirs(dir_work) os.chdir(dir_work) else: print(dir_work + ' already exists, we will continue...\n') pass files = [] exclude = os.listdir() for dirpath, dirnames, dirfiles in os.walk(dir_root, topdown=True): dirnames[:] = [dirnames.remove (d) for d in list(dirpath) if d in exclude] for file in dirfiles: if file.endswith('.sql'): target_file = os.path.join(dirpath,file) files.append(target_file) print('The files to be copied include:\n' + str(files) + '\n') for file in files: shutil.copy(file,dir_work) 
Learning English separately is great, but I feel lack of speaking practice, and speaking practice is crucial in learning languages. Why 'upper-junior' is funny? =) Guy from my job called me 'upper-junior' once. 
If you don't get anywhere with OpenStack why not try [Python Core Development Mentorship](https://mail.python.org/mailman/listinfo/core-mentorship)? If you can't get a decent apprenticeship from them who can you get it from?
I should probably report to pandas that they crash of the new version of numpy due to a change in how masking is done. Make sure you have testing!
&gt; from kuai import Kuai, Ku√†i Non-latin character in import? What is the reason for this?
I don't actually know but after a search how about [Bioinformatic pipelines in Python with Leaf.pdf](https://github.com/pcingola/BigDataScript/blob/master/doc/Bioinformatic%20pipelines%20in%20Python%20with%20Leaf.pdf). [QIIME: Quantitative Insights Into Microbial Ecology](http://www.qiime.org)
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [pcingola/BigDataScript/.../**Bioinformatic%20pipelines%20in%20Python%20with%20Leaf.pdf** (master ‚Üí 480c353)](https://github.com/pcingola/BigDataScript/blob/480c353c568463e1e4b081882148a2112251a4c8/doc/Bioinformatic%20pipelines%20in%20Python%20with%20Leaf.pdf) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply diocem2.)^.
don't fucking post pictures of code
No.
Ah. fair enough.
Programming was never necessary, you could always do math by hand in paper, and that's how it had been done for centuries before programmable computers replaced human computers. Programming is a tool to express computation in a repeatable way, that you can reason about and prove facts about it, and that's never going away. Abstraction is a natural part of programming - it would be fairly stupid to keep writing the same programs forever if you can do it once and reuse it - and with it you can program at increasingly higher levels. Having said business intelligence tools and "low code software" at hand, what you should be asking yourself is not "will programming become obsolete?", but "in what way can I use programming to combine these tools to achieve bigger tasks in more efficient ways?" I didn't even mention Python itself, since it's just a language. Perhaps it will adapt to future ways of doing things, or will be replaced by them, but "programming" itself will never go away (unless someone finds out that P = NP and the world burns).
Yeah, there's a strange balance between "let's take our time and fix this the right way" and OMG EVERYTHINGS ON FIRE ITS NOT WORKING PERFECTLY FOR EVERYONE :)
Wow, I'm actually surprised by the complexity of setting it up manually!
If speed and size matters for example. Also if you consider the usage of [grpc](http://www.grpc.io/) üòâ On top of that you get validation for free!
Nobody is being "shitty and pedantic", but if you say a Python library took 4 years, you are both being self-important cuz you built said library AND it may discourage people who want to do that and then say to themselves "4 years? Funk that. I'm not even gonna try to build a library." Instead of just saying an approximate of the hours. So if for some reason you really just can't comprehend time, don't talk shit and get a clock. And to further ramble...It's like a gal I talked to (hadn't met yet) said "let's get together later". I said OK what time? "I don't know." ABOUT what time? "I don't know." So I'm supposed to go about my day, without a plan, waiting for your call for a time? It became an big time argument where she was mad at ME for wanting to know a time. Funk dat. Time is one of the most precious things we have. Make full use of it.
Installing Django Axes might prevent brute force logins on Django admin. It might be a good idea to install since you can block user or ip after some unsuccessfull login attempts.
That's understandable. I just hate having Tornado as a dependency when there's a native Django solution. Anecdote: I've been using Django Channels for about 9 months in production and haven't had any issues. 
What a nerd.
I would probably consider building two different databases in the case that any information will be truncated during extraction or something like I suggest in the edit above. In other words, you download all the data in a raw form and slam it into a database (or it could just as well be a single table). From their begin extracting the data and building the other tables via parsing. The reason I would consider these two separate databases is I consider them two different run-times. You have the scrap one time that builds raw data. and then you have a pre-process runtime that normalizes. After which you design all the queries to flush out the desired statistics. This approach is nice in that if there is considerable time scraping and building the scheme, that you could re-design the schema without the extra loss of time or migration scripts.
Hi there, I'm looking for a python script for instagram. Basically I want the script to be run every hour, check if there are any new photos from an instagram account and immediately download the images. Is this an easy task? 
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/electronjs] [X-Post: How to Build an Electron GUI for a Python Module](https://np.reddit.com/r/electronjs/comments/6g9n2n/xpost_how_to_build_an_electron_gui_for_a_python/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
Great Question! I have no clue why! 
Probably because of "struct.pack()"? 
Just installed tensorflow and looking forward to learn it.
It is, but you can make any combination of waves however you like, including a wave from a soundfile.
/r/learnpython Why can't use you pip?
Huh, wow. 
We at TimeFounder are using mongodb + elasicsearch via mongoconnector (all docker containers) but you can almost choose what you want for your needs (you can be ambitious on your needs) The good parts of storing files on dbs is that you could use clustering for server replication in a much advanced way that rsync and similars Mongo has the mongo gridfs and elasticsearch the attatchment type
I'm really not sure but when I try to run the command 'pip install scipy' it's showing pages of NOT AVAILABLE statements that I don't understand.
Always go to [that uci page](http://www.lfd.uci.edu/~gohlke/pythonlibs/) for scientific modules
Its like saying "im almost 13" when you're 12 3/4 -- hence the funny part :P
TIL about mypy, it looks really nice and handy!
Thanks!
&gt; Now I have to truly figure out the best way to install and manage multiple python installations on OSX/Linux. It's a hot mess. What was it in particular that is giving you trouble? IME, virtualenv (and virtualenvwrapper) solves this problem pretty well.
Great!
[Not amused.](https://soundcloud.com/skakri/generated-music-bitwise) ^^^^sierpinski ^^^^triangles
&gt; Al Sweigart Oh, you're right! I think I was just confused by the fact that the books have the same theme as the cover page. . .same publishing company, I guess, haha. 
Is this homework? I will give the sine wave since the op already kind of had it. Google square wave and make a function for the graph. It's better to do this once yourself to better understand how your code works. Then you can make up some really sick audio effects. import math def makeTone(x, freq, hz): y = 32000 * math.sin(2 * math.pi * freq * x / hz) return int(y) ... value = makeTone(i, 440, 44100)
To install scioy and numpy from source you need available: C compiler/stdlib FORTRAN compiler Libblas Liblapack ATLAS UMFPACK FFTW Without all that, functions that depend on the corresponding library will not be available.
Uncomment the square wave and sawtooth lines in the linked post?
I find it odd that `scipy.signal` is used here, but [`scipy.io.wavfile`](https://docs.scipy.org/doc/scipy/reference/io.html#module-scipy.io.wavfile) is not. [`wavefile.write`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.write.html#scipy.io.wavfile.write) makes it even *easier* to write the generated sound to a file.
If you're 12 3/4 you are pretty much almost 13
Audio signals are one way to learn digital signal processing which is the theory and mathematics behind telecommunications, audio and video compression, sonar, radar, CNC, GPS and inertial position tracking... almost any use of computers to control something in the analog world involves signal processing to condition analog inputs for computer analysis and construct useful analog outputs. 
https://solarianprogrammer.com/2017/02/25/install-numpy-scipy-matplotlib-python-3-windows/ Thanks guys, this link solved my problem.
Also of possible interest to you. `xrange` in python 2 returns an iterator compared to `range` which returns a list. It's important to note because this represents one of the major differences between 2 and 3. In python3, `range` is essentially `xrange` in python2 and indeed many objects became iterators in python3. Others include `zip`, `map`, `filter`, `reduce`. And the list goes on. Hope this didn't come across as didactic. it's just that this was an important revelation for me.
There is A LOT of magic here...I can't even determine if you can trigger multiple states concurrently. Your examples also make it look like you've solved polymorphism in Python...but I don't think you have? Too confusing for production code.
Make sure you have control of the volume.
Bloated Electron type software is a cancer and should never be used to excuse performance concerns.
Google app engine
/u/opfeels /u/ultimatemanan97 
Please don't. 
On my OSX install, I have python and python3 (both installed by homebrew). When I want to create a new project, [I can use either](https://stackoverflow.com/questions/1534210/use-different-python-version-with-virtualenv). So I have about 30 different python environments on my machine, based on those two base homebrew installs. Also have used these on Linux with no issues. I know that virtualenv also works on Windows, but I don't have any personal experience with it.
I think this is more of a question for r/learnpython
Generating audio signals is dead easy. Generating them to sound the way you want without aliasing is of basically unlimited difficulty. If you just make a square or saw wave by drawing the graph, you get a very garbagy signal out the other end because its aliasing all over the place, reflecting the wave form and introducing all kinds of unwanted noise. To do it properly is a whole different game. There are folks out there working at synthesizer companies who's whole job is try to make digitally generated signals sound as good as their analog counterparts. 
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [shopnilsazal/validus/.../**validators.py** (master ‚Üí b0139b8)](https://github.com/shopnilsazal/validus/blob/b0139b827c32110be547d19a0b4667eb3ef79072/validus/validators.py) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply diotpuj.)^.
&gt; Python 3.7 is as fast as Python 2.7 on most benchmarks It is a good news. I am migrating my Python projects to Python 3.7
I feel like if you're generating complex sounds (e.g., amplitude modulated sounds), you would probably have a good enough handle on the data to use matplotlib to visualize it. I, too, just write my own code for looking at this kind of thing, so maybe I'm being overly optimistic about how easy this is.
Python3 has gathered a critical mass and it is the future.
Speaking of SlumberMachine and sine waves (although not Python), I sleep to this every night: /usr/bin/play -q -r 8000 -c 1 -v 100 -t sl - synth brownnoise band -n 1200 200 tremolo .1 40
Made an implementation of a [homophonic substitution cipher](https://github.com/vesche/pmhsc) and hacked together a little [headphone jack kill-switch script](https://github.com/vesche/killjack).
Sounds like a really cool place you found to develop your niche. I hope you enjoy the work. I definitely can't wait to see the Puget Sound when I visit the pacific north west one day. 
Pastebin would work too, you know. That place is fucking cancerous. &gt; from Crypto.Cipher import AES I'm out.
I just wish the default `wave` package did have such a shitty API. I mean, unpack and pack using `struct`, really? I much prefer [scikits audiolab](https://pypi.python.org/pypi/scikits.audiolab) but frustratingly it hasn't been ported to Python 3 yet. Hm.. maybe I should take the time to do it.. it has the downside of not being 100% Python though, it depends on libsndfile.
Unless you have a specific reason to learn 2.7 (Like, say, learning the language to do a specific job that uses 2.7 as it's primary language), learn 3.
If you want to distribute a Python library, that's the way to go. If you want to distribute a program for people to run, it's not much help. For that, you don't want to assume that the user has Python installed or is comfortable with the command line.
There will only be a single state. I'm not sure what you mean by the polymorphism part from the examples but can try and explain if you've got an example.
Python = Python 3
If you want to get into this stuff for real, the first step is to get one of the various great books on computer music. :-) "The Audio Programming Book" is a good primer.
Assuming you are on windows, find your python executable. If you used defaults, it will be `C:\Users\&lt;your username&gt;\AppData\Local\Programs\Python\Python&lt;version&gt;`. Navigate to the path in an explorer window. Now open a `cmd` window. Find the executable `python.exe` or `python3.exe`. Drag and drop it in to the cmd window. Hit enter. Now you should see a prompt `&gt;&gt;&gt;`. This is to check if your python installation was correct in the first place. If there are no errors, your python installation is good. Find the idle exe path, and drop it in a new terminal window. This should produce some error messages. Post the errors and that would help find the cause of the errors. Also, check your system architecture (32 bit or 64 bit) and make sure you installed the correct version of python. 
therefore Python 3 = Python so it doesn't matter?
You're converting the whole list to unicode, I guess you want each element as unicode: data = ('first_name', 'last_name', 'email', 'password') udata = [unicode(e) for e in list(data)] # or udata = map(unicode, list(data)) edit: changed data to list(data)
Oh, good call. I usually don't vary much since I use 2.7 day to day. I've heard good things about pyenv, but also I don't have any personal expertise. Good luck!
Are you saying that you can't change this line? mylist = unicode(('first_name', 'last_name', 'email', 'password')) or that you can't change this input? ('first_name', 'last_name', 'email', 'password')
If you are passed the whole list as a unicode string - you can use a regular expression to pull it apart .. Assuming : &gt;&gt;&gt; mylist = unicode(('first_name', 'last_name', 'email', 'password')) i.e. a tuple contained in a unicode string &gt;&gt;&gt; import re &gt;&gt;&gt; c = re.compile(r"\'(.*?)\'") &gt;&gt;&gt; entries = tuple(c.findall(mylist.encode('ascii','replace'))) &gt;&gt;&gt; entries ('first_name', 'last_name', 'email', 'password') &gt;&gt;&gt; type(entries) type &lt;tuple&gt; &gt;&gt;&gt; len(entries) 4 