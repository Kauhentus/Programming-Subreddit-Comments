Anyone else having trouble with this in conjunction with mypy? I installed mypy with pip 7.1.2 against python 3.5 and I get `from typing import Undefined, Dict, List, Tuple, cast, Set, Union` `ImportError: cannot import name 'Undefined'` every time I try to run mypy.
locals() is terrible and frowned upon anyway. Explicit is better than implicit, sure it can take a few extra lines but for readability(easy understandability) sake format() is perfectly fine.
Pygame will be the best choice if you're still learning Python. On the other hand I wouldn't recommend developing games in Python unless you're doing it purely for the purpose of learning.
probably not for now there is the official documentation https://docs.python.org/3.5/reference/compound_stmts.html#coroutines and the pep
Ah! That seems to have fixed it. Thanks!
/r/learnpython
well, what is the error you get and what are you trying to accomplish ...
When you activate the new conda environment, it is the default in the sense that conda list, install, update, remove, etc. will act on the py35 environment.
[KivEnt](http://kivent.org) is a 2d Game Engine built IN Python (and Cython) leveraging the Kivy ecosystem to enable you to build Python games while deploying to mobile and desktop platforms. The engine is still young (we just had our second major release a few months ago), but you will already get significantly better performance than Pygame.
Congratulations! Library versioning is such a rare problem that few people build in detection for it.
As written, you have no operator after "0.5" (presume you mean "*")
Thanks! Yes, well I'll certainly be more careful about it in the future. :) Intel's scripts seem to be adding the old version of the library automatically and it's not obvious to me why that is. I'll need to investigate further.
We are all aware of what dynamic typing brings to the table. Unfortunately, it makes it hard to glean semantics when reading code or doing static analysis. This is the attraction to function annotations and optional typing: we can cherrypick the advantages of static typing and blend them with a dynamic environment. Notice it is OPTIONAL typing. People that want the clarity, enhanced IDE behavior and in the future a typechecker now have an enhanced option of more descriptive types from the typing module for their annotations. Having written code without annotations and with: when given the opportunity I will write them with annotations. It saves me the time spent looking in the function body for the kind of object the function expects as a parameter. I don't have to scan the body to realize that parameter_a is an object that implements the iterator protocol and yields a series of 3-tuples. I can just look at the declaration or hints my IDE shows. Being able to quickly check that your parameters are "correct" or what return type to expect becomes valuable. I find it also makes it easier to read a foreign codebase and to understand how data moves and is transformed through it. Right now there is no typechecker so I can write: In [1]: def func(a: list) -&gt; dict: ...: return set("abc") ...: In [2]: func(10101) Out[2]: {'a', 'b', 'c'} Which is still completely valid. Annotations have no meaning to the interpreter and probably never will outside of an importable module.
Which version of python are you using? Can you show us what the full program looks like after modifications, as well as the complete error text? 
I'd also love some tutorial with real life usage, like making multiple big HTTP requests / SQL queries / file reads. For cases like HTTP requests, is it possible to use it with [Requests](http://www.python-requests.org/en/latest/) or am I forced to use asyncio-aware library like [aiohttp](https://github.com/KeepSafe/aiohttp)?
Im on python shell &gt;&gt;&gt; def main(): t = int (input("Enter a temperature in fahrenheit between -58 and 41: ")) w = int (input("Enter the wind speed in mph: ")) y = 35.74+.6215*t-35.75(w**.16)+.4275*t*(w**.16) print ("The wind chill index is {}.".format(y)) main() SyntaxError: invalid syntax
Yes but while you are upvoting the good news, in fine you give the guy who just posted the link that every single Python coder knows about all the rep for it. Kinda break the trust system, doesn't it ?
Is it that time of the month again where someone posts this talk?
I think you'll need to wait for them to do a new release of miniconda before the default environment has 3.5. Until then, you'll have to explicitly create an environment for it.
Thanks! I just did that though and it broke Matplotlib.
Type inference is great, but it can't do everything, especially when you're using some of the more dynamic features of the language. Type hints let you give the IDE/type checker more information when it can't automatically work out what types are going in and out of functions.
This isn't StackOverflow. Karma isn't rep. It is meaningless and no system features are tied to it.
actually, getting above a certain ammount of karma here disables capatcha, while getting low/negative karma will start restricting one's comment rate, I've seen it go as much as 10minutes between comments
its available now
I have a very large multi-process app I've built and this exact problem used to bite me all the time (especially in ipython shells). I've solved the annoyance of multithreading by building a super tiny class called "processSafeDBSession" and instantiating it like a singleton in the source file it's defined in. I'll have to get you source when I'm not on mobile but the jist of it is: the class stores two private dictionaries for engines and sessions keyed by multiprocessing's pid function. I then override the getattr method. When you call an unknown method, it instantiates a new engine and session if needed and then passes the getattr call to the correct pid's session.
Ask my cat http://www.talkigy.com/chat/poppy-cat/can-you-make-up-a-story? (she actually uses the Okapi BM25 alogorith to decide what to say next)
My current policy is: If the package in question didn't update to python3, I don't need it.
Excellent talk but yeah, everything on the internet is brand new to someone at any given moment so they feel the need to instantly push the share button. 
Please read the top post: Questions go on /r/learnpython. 
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
Now I can't give advice about leaving school or not, however I can give my experience of self teaching and the class for CS I've just entered. I learned the majority of Python self taught (and the first portion of it was Codecademy until I had the syntax and such down) for 2 years. This year I've enrolled in a C++ class (computer programming I i think) and while I have known the basics of how it worked (while loops, for loops, if statements, blah blah) the professor really goes in depth as to how programming actually works, which is stuff I didn't really get into self teaching. This might be useless but I typed it out and didn't feel like not posting it. gl with your decision 
Thanks! I'll check it out!
I see that you removed the post so I guess you solved it ?
Yes, I was saying that I had previously thought the that learning 3.5 after 3.3 would require learning just a few new things. I guess I wasn't terribly clear on what I meant though.
How? `conda update python` won't work.
`conda install python=3.5`, but be careful!
I didn't find much about that on Google. How do Python 2.7 and 3.5 compare in terms of performance? Are there any benchmarks?
Yeah there's no way I'm not finishing my marketing major I only have 8 courses left. Doing 4 this semester and 4 next semester to keep full hours for financial aid. I agree that marketing is definitely useful. I've learned a shit ton about how businesses operate and it's made me a lot more critical of every business in my daily life. I enjoy analyzing how different companies try to market their products, layout their stores, what kind of advertising they're using, which of the 4 Ps of marketing they're relying on to get business, how they treat their customers etc. It's been a good experience overall but I'm burned out on it, but that could just be me being burned out on school in general and not just marketing. Maybe self teach is the better way to go since I do prefer to learn on my own. Decisions are hard man haha
Conventional wisdom is that Python 3.x got speed parity with 2.7 around the time of 3.3. They're not exactly equal; Python 3 is faster at some workloads, Python 2 at others. But for most people they should be equitable. And we're not done yet! There are exciting things in development for future versions of Python... like a JIT! https://www.youtube.com/watch?v=_5vLWe4d8X8
+5 for what you did, -Infinity for no documentation C'mon man
Good idea, but I just wanted a backend to log events from a perl application, so having a logging handler wouldn't help me there.
If you want a fast scalable Falcon based RESTful API with significantly less effort, I encourage you to look at hug (https://github.com/timothycrosley/hug) Here's the note service demonstrated in this example, rewritten on hug: '''The note API allows you to save and retrieve notes''' import hug from db_client import * @hug.get() def notes(id:hug.types.number=None): '''Returns an individual note if an id is provided or all notes if not''' if id: return {'note': r.db(PROJECT_DB).table(PROJECT_TABLE).get(id)).run(db_connection)} note_cursor = r.db(PROJECT_DB).table(PROJECT_TABLE).run(db_connection) return {'notes': [i for i in note_cursor]} @hug.post('/notes') def add_note(title:hug.types.text, body:hug.types.text): '''Saves a new note''' id = r.db(PROJECT_DB).table(PROJECT_TABLE).insert({'title':title,'body':body}).run(db_connection) return 'Succesfully inserted {0}'.format(id) Not only is it significantly less code, you get validation, documentation, and easily configurable access logic, for free. Additionally, testing this endpoint / using from other Python code is easy and transparent (you can call notes from Python as if it was a normal Python function and not an HTTP endpoint.) 
It's such a good talk I'm more than happy to have a biannual review.
Not sure if you've learned about recursion, but think about what a factorial actual is: it's a start number * start number - 1, ... etc. If you haven't learned about recursion, go take some time to learn it and then think about how you would construct the function.
I agree completely with naming and documentation. Names will not always capture what an annotation can, however. def process_request(request): if request. How does my IDE know what methods and properties to display for the request parameter? PyCharm and other IDEs use type inference when it's possible and not expensive. Explicit typing, I'd imagine, would save cycles and battery life. It also allows me to tell the IDE that it should look up requests.Request for tooltip content. Both make my life easier and impede no cost on anyone who doesn't like the convention.
What happen if I install third party library in Python 3.5, Is it works?
I tried googling how to do this, all I find didnt make any sense to me at all. I feel like I'm missing something very obvious.
&gt;Wait, what? Official from whom? Some guy named "Larry Wall". Seems legit....
 import os for (path, dirs, files) in os.walk('/your/path'): print(path) print("Subfiles:") for file_item in files: print(file_item) print("Subdirs") for dir_item in dirs: print(dir_item) Recursive through all subdirectories of the current path. Output all subdirectories names, all subfiles names and current path. 
Official from Docker. It's a fairly critical part of many deployment workflows so I'm not the only one who's blocked on using 3.5 properly without it. I didn't mean to imply it was Python official.
There is a sticky on this subreddit for a good reason... You should have posted this in /r/learnpython. From your screenshot it looks like there is C code inside the library, so it has to be compiled first. There is a good chance that this won't work, since you are apparently using Windows. You can try running python setup.py build python setup.py install in the command prompt from the directory you are showing. Don't expect it to work (there will likely be a compiler error), but if there is an error, this can help understand what you need to do else. Edit: I didn't notice first, but it seems like you are trying to install Pillow. The standard way of doing this is running `pip install Pillow` [Edit: fixed Pillow spelling]. If this fails, use Anaconda: http://continuum.io/downloads (make sure you download the correct version!) Anaconda is a Python distribution that makes most common libraries work out of the box. Using the standard Python distribution from python.org is not recommended for Windows users.
You can use ```python setup.py install``` in that folder, or you can copy the whole folder to ```C:/PythonXX/Lib/site-packages/``` where ```C:/PythonXX``` is your Python install directory. You can create a subdirectory for the library you're using; you'd put the files in your screenshot in ```C:/PythonXX/Lib/site-packages/PIL``` or something.
&gt; locals()['key'] = value Writing to `locals()` is not guaranteed to work. It will work in IronPython, but not in CPython.
Why does it make you so upset? Anyway, have you just explained that it is the name of a programming language you like?
ROFL WHAT IS THIS POST
I found this in the pyserial documentation: &gt; The RTS and DTR lines are switched when the port is opened. This may cause some processing or reset on the connected device. In such a cases an immediately following call to write() may not be received by the device. A delay after opening the port, before the first write(), is recommended in this situation. E.g. a time.sleep(1) Unrelated, but it is easier to use a context manager rather than manually opening and closing.
Yeah, C++ and Python is a good combo.
you shouldn't refactor format() expressions back to python 2.6. new python versions insist on .format() usage. old-school formatting doesn't make your programs twice as fast on real world cases. if you have massive string format operations, then it may make a tiny difference. 
First, it makes a lot of syntax much easier. Using the same value multiple times, using dictionaries, being able to select only the values you want from a given dictionary, numerical formatting, padding, etc. In a lot of cases, a few tens of nanoseconds vs. a few hundred nanoseconds isn't going to make much of a difference. In those cases, the more flexible syntax can provide a lot of advantages. On the other hand, where the string interpolation is a significant performance bottleneck, then the faster approach is still available. For me, where I deal with a lot of operations on the order of hundreds of microseconds to milliseconds. Even the per-run variability in many operations I do is in the order of microseconds. So the a few hundred nanoseconds here and there isn't even detectable. 
Because you're testing with two string literals, Python will actually optimise the `%` operator away when it generates the bytecode, so you're actually timing it doing nothing at all in that case. This optimisation is called constant folding. Look at the difference when you make it a variable: In [1]: %timeit "foo %s" % "bar" The slowest run took 45.98 times longer than the fastest. This could mean that an intermediate result is being cached 10000000 loops, best of 3: 32.7 ns per loop In [2]: a = "bar" In [3]: %timeit "foo %s" % a The slowest run took 9.70 times longer than the fastest. This could mean that an intermediate result is being cached 1000000 loops, best of 3: 247 ns per loop It's still faster than `str.format()`, but they're both less than a microsecond. In most programs, [other things](https://gist.github.com/jboner/2841832) (like disk access or network requests) will take so much longer that the difference is utterly inconsequential. Python is generally designed for readability rather than fast execution. In the simple case, the different formatting mechanisms are about equally readable, but for more complex string formatting, `str.format()` can be clearer.
You should introduce your brother to unholy trinity then - Linux, python, eclipse. Also there is nothing to fear: The Accountant: Satan is simply the warden of a very large prison. Quiet man actually, thoughtful and he's well read. And I happen to know the idea of sacrificing children in his honour annoys him greatly.
&gt; new python versions insist on .format() usage That would be news to both me, and to my (passing on Python 3.4, and likely on 3.5 as soon as I set it up) test suites.
I'm curious what the image that you pu up was...
[PyFormat.info](https://pyformat.info/) is pretty interesting. 
The last few days I've been working on this little script to make a version of the default interactive interpreter that has syntax highlighting. There didn't seem to be anything currently available that did *only* that. I had to use some very nasty hacks to get it working - I'd be interested to see if anyone can do better! The hardest things were making it do the highlighting immeadiately after typing, and (because I had to use PyOS_InputHook), making it have the normal Ctrl-C behaviour. Enjoy! ---- Here's a bonus 20 line version that doesn't do Ctrl-C, has a 0.1s delay on the last character, and doesn't deal with multiline strings - http://paste2.org/8IhwyKPY
&gt; Not to be a annoying Yes, but, you just killed my quota. Thank you very much.
&gt; for more complex string formatting, str.format() can be clearer. str.format also allows rearranging positional arguments (very useful in i18n contexts), mixing positional and keyword arguments and implementing custom formatting (which datetime does), so it provides way more advanced features. Also a confirmation on the constant folding: &gt;&gt;&gt; def f(): ... return "this is %s" % "it" &gt;&gt;&gt; dis.dis(f) 2 0 LOAD_CONST 3 ('this is it') 3 RETURN_VALUE if the second literal is moved to a local: &gt;&gt;&gt; def g(): ... it = "it" ... return "this is %s" % it &gt;&gt;&gt; dis.dis(g) 2 0 LOAD_CONST 1 ('it') 3 STORE_FAST 0 (it) 3 6 LOAD_CONST 2 ('this is %s') 9 LOAD_FAST 0 (it) 12 BINARY_MODULO 13 RETURN_VALUE 
&gt; And we're not done yet! There are exciting things in development for future versions of Python... like a JIT! You mean pypy?
Good, good. Welcome to the dark side ;)
As for the dictionary, if you don't want to break it down, why not "go all the way"? return { "+": add, "-": sub, "*": mul, "/": truediv }[operator_symb](float(operand1), float(operand2)) (I don't actually recommend this.)
- PyCharm is much slower than Sublime even on a very fast machine, I can type faster than it can scroll the view when doing an incremental search. It works, but it's not as smooth. - PyCharm is loaded with a bajillion of features that look cool on paper but turn out to be bloat - Still missing some of Sublime's editing features -- in fact some of them appeared in recent releases (4.x) like 'add next word to selection' etc -- they're catching up but not there yet - There's a ton of good plug-ins for Sublime - e.g. code completion, code analysis, python-specific formatting, flake8/pylint linting, automatic docstring generation, jump to definition/symbol etc. You choose yourself what you opt in to.
Python-specific: - Anaconda - AutoDocstring General purpose must-have: - Alignment - BracketHighlighter - SideBarEnhancements (obviously, to be installed via Package Control)
First of all, upboat for the effort! Compiling is not exclusive to CPython, you also need compile other stuff like libxml, libmysl-client, libev, etc. Heck sometimes you have to compile GCC to use a newer version of it. Think there's billions of Linux computers around the world, if we all have binary packages that's a lot of energy save!
If this is a learning exercise, not sure why we need to be clever about it. I would say recursion is a perfectly fine way of doing this.
So what exactly is python play? It isn't clear from the first post. 
I think it's *nix only
Thanks! I learned something new. :) (Actually happy to see that it doesn't work. )
Right, that explains the difference I see in my actual programs. In [1]: a = "it" In [2]: %timeit "this is {:s}".format(a) The slowest run took 13.16 times longer than the fastest. This could mean that an intermediate result is being cached 1000000 loops, best of 3: 214 ns per loop In [3]: %timeit "this is %s" % a The slowest run took 9.14 times longer than the fastest. This could mean that an intermediate result is being cached 10000000 loops, best of 3: 127 ns per loop Overall, this changes nothing of what I said: If you think `str.format(param)` is nicer than `str % param` that is fine and your personal style preference, I wont debate that. But twice as fast/slow programs are not up for discussion for my needs.
Cool, that's a very creative use of ``PyOS_InputHook``! Out of curiosity, what is the reason for not using an alternative REPL? (I'm the author of ``ptpython``, so very interested in whatever you'd like to see different.)
Yeah, well, I do data mining with Python - so this stuff is extremely noticeable to me. Imagine waiting 2 hours for your compiler or just one - in my case, that is, for my system to finish generating features and learning another model from it.
Have you looked at Basecamp yet. If all you need to do is plot the image on a projected coordinate space this should get you there with not too many dependencies. If the image you have is like a GEOTIFF or similar you might not have to do much more than load the world map, load the image set the coordinate system and the draw window. 
You can install pyreadline on OS without readline, such as Windows.
Right, but that only affects individual users. Karma is meaningless in the long run and as a whole. It doesn't matter what my karma is, except for the votes on this comment, and maybe this thread. The difference is that the focus is on fostering good conversation, and as such you're rewarded or punished based on how the community perceives your contributions.
sorry, used the wrong word. it's recommended as @TheBlackCat13 said. btw, regarding old style formatting, from the documentation: https://docs.python.org/3.5/library/stdtypes.html#old-string-formatting "Note The formatting operations described here exhibit a variety of quirks that lead to a number of common errors (such as failing to display tuples and dictionaries correctly). Using the newer str.format() interface helps avoid these errors, and also provides a generally more powerful, flexible and extensible approach to formatting text."
Yeah, memory optimization is not a big problem for me; my maximum dataset is about half a billion points, leaving lots of RAM free but taking HOURS with my shitty code. So, thank you! It'll much less shitty quite soon :)
chown -R baphomet.baphomet *
https://learn.sparkfun.com/tutorials/serial-communication Make sure that RX connects to TX and TX connects to RX on the opposite device. 
But type inference can't always work, especially in a language like python where sometimes values and function etc. are built at runtime. So, being able to say "the argument "l" is an Iterable, treat it as an "Iterable" everywhere within this scope so that even if I'm getting l by dynamically evaling some user input, I know how to treat it in this function.
For a long time, I've advocated that engine.dispose() be called at the top of a new process. That way the connection pool is flushed out and new connections begin. However, in chaotic environments like Openstack, we also have a per-connection checker: def _add_process_guards(engine): """Add multiprocessing guards. Forces a connection to be reconnected if it is detected as having been shared to a sub-process. """ @sqlalchemy.event.listens_for(engine, "connect") def connect(dbapi_connection, connection_record): connection_record.info['pid'] = os.getpid() @sqlalchemy.event.listens_for(engine, "checkout") def checkout(dbapi_connection, connection_record, connection_proxy): pid = os.getpid() if connection_record.info['pid'] != pid: LOG.debug(_LW( "Parent process %(orig)s forked (%(newproc)s) with an open " "database connection, " "which is being discarded and recreated."), {"newproc": pid, "orig": connection_record.info['pid']}) connection_record.connection = connection_proxy.connection = None raise exc.DisconnectionError( "Connection record belongs to pid %s, " "attempting to check out in pid %s" % (connection_record.info['pid'], pid) ) engine = create_engine("....") _add_process_guards(engine) Neither of these approaches can help if you actually are sending an ORM Session or core Connection across the process boundary. If you use NullPool (e.g. no pooling at all) and are still getting errors, you'd want to look at that. **Update**: added this to the FAQ: http://docs.sqlalchemy.org/en/rel_1_0/faq/connections.html#how-do-i-use-engines-connections-sessions-with-python-multiprocessing-or-os-fork
In python, the default recursion limit is 200, so that's probably what will be hit. I think it's important for people to understand both techniques (regular iteration and recursion), but default to non-recursive solutions when there's a single loop without much state.
&gt; just one worker right but then I also want concurrency for processes other than this one-at-time process so i have 2 workers
Um, nope it doesn't, at least not without explicitly asking you about it. Just ran the latest miniconda installer (bash, linux64): Do you wish the installer to prepend the Miniconda install location to PATH in your /home/.bashrc ? [yes|no] [no] &gt;&gt;&gt; no You may wish to edit your .bashrc or prepend the Miniconda install location: $ export PATH=/home/miniconda/bin:$PATH It's your choice how exactly you use it's /bin and whether you prepend it to PATH at all. Like, you can always just use the full path to Python executable or alias it or whatever. And, wait a second, whose GUI is written in Qt? What does conda have to do anything with Qt? Install log: PREFIX=/home/miniconda installing: python-2.7.10-0 ... installing: conda-env-2.4.2-py27_0 ... installing: openssl-1.0.1k-1 ... installing: pycosat-0.6.1-py27_0 ... installing: pyyaml-3.11-py27_1 ... installing: readline-6.2-2 ... installing: requests-2.7.0-py27_0 ... installing: sqlite-3.8.4.1-1 ... installing: tk-8.5.18-0 ... installing: yaml-0.1.6-0 ... installing: zlib-1.2.8-0 ... installing: conda-3.16.0-py27_0 ... installing: pycrypto-2.6.1-py27_0 ... Python 2.7.10 :: Continuum Analytics, Inc. creating default environment... installation finished. 
Hmm. Is it just me or is it weird that every time you run an async object it throws the StopIteration exception? Seems like a hack 
Why no TenVer and Py3 support?
For a simple example of recursion sure, but you'll have problems if you try to do a factorial of a large number.
and?
Is there an equivalent of Michael Hartl's Rails Tutorial for Python?
How long before a GUI installer is released?
coroutines are based on generators internally, and use StopIteration to return values: async def f(): return 'spam' f().send(None) will raise StopIteration exception, with 'spam' in its args. It *is* an implementation detail. You should never see that StopIteration, your framework of choice will handle it behind the scenes.
Very interesting, never heard about gooey before. Seems to be a easy solution for creating GUIs for simple scripts such as the one I'm developing atm (I'm using calculated "blurriness" and brightness values and auto tagging photos using EXIF).
Awesome post! A couple things I noticed: The code at the bottom does not have the Gooey choosers in it, but the code on Github does. Also, after the picture of successful completion, there is a typo. Runt should be run. &gt; This is really nice if you need to runt the program multiple times with different inputs.
Do this: # cd &lt;anaconda_dir&gt; # ls -al lib | grep libQt IIRC it's Spyder (which serves as central anaconda GUI) that is a PySide or PyQt app. Anyway, I don't remember being asked, I specifically remember none of it's cli available upon install, then I started some binary and got it's stuff in .bashrc, .zshrc, .profile and /etc/profile. Great if it was just a freaky thing in one particular version. I stand corrected as it currently is. However, for what valid usage reason should it have qmake on the directory it suggests adding to the path?
We use it all the time with the logger functions in our Django application. logger.debug("message: {0}, error: {1}".format(msg, error))
P.S. TIL Spyder is official Anaconda GUI :) It has nothing to do with conda, they just apparently tend to ship it along with Anaconda distribution in the noob-friendly format. Also, note the difference between conda (http://conda.pydata.org/docs/) and Anaconda distribution (https://store.continuum.io/cshop/anaconda/). Anaconda runs on top of conda (or, rather, it's conda + a big set of pre-selected packages), but you don't need the former to use the latter.
Also, interpolating the string before passing it to `debug` and its ilk will generally prevent the logger from coalescing logger messages. For example, when using Sentry, repeated messages like these will be coalesced: logger.debug("message: %s, error: %s", msg, error) Whereas repeated messages like these will be seen as unique and separate messages: logger.debug("message: {0}, error: {1}".format(msg, error))
Pyo looks cool! Some guy coded up some [guitar pedals](http://www.matthieuamiguet.ch/blog/diy-guitar-effects-python) already. [This guide](http://wiki.linuxaudio.org/wiki/raspberrypi) also looks like a fantasic resource for optimizing the pi to do realtime audio.
It really depends on what you mean by "designed for nose". Green supports nose-parameterized (see https://github.com/CleanCut/green#nose-parameterized ) -- but that's the only nose-specific stuff green is aware of. It will certainly run anything that is written using the classic unittest style (as will nose). I would just try running it against your nose-designed-tests and see what happens.
Yea. Usually people actually refer to conda when they say anaconda. Anaconda is really *nothing else* but a single meta-package for conda, with a bunch of pre-selected dependencies. See for yourself: http://repo.continuum.io/pkgs/free/linux-64/anaconda-2.3.0-np19py34_0.tar.bz2. You can literally do a "conda install -y anaconda==2.3.0".
What very specific problem are lambdas intended to solve?
Yeah but in the whole chicken/egg aspect of it all Anaconda was the general idea -- having a scientific python distribution like Enthought Canopy, but their own and based on all open-source stack. Conda, on the other hand, was just a piece that was custom developed to facilitate that idea. I'm not even sure that first Anaconda distributions had conda installer or Miniconda barebones distro.
Yea, conda's been there from the very start, that's the backend for the whole shebang, but miniconda appeared later. You could still use a command line Linux installer back then and then remove stuff you didn't need which is what I'd been doing. TL;DR things have gotten better
Actually I was having a problem about parsing xml in Py3 so I decided not to support it at the moment. Having Python 2.7 in most os is usual after all. Not supporting py3 does not mean; not gonna work for py3 project(setup.py) by the way. You can manage any kind of files defined as supported in documentation after you install it. I don't know anything about TenVer. Could you please lighten me; I looked but I don't understand.
Are you sure? I don't see how. To the logger system, a &gt; logger.debug("message: {0}, error: {1}".format(msg, error)) is the same as &gt; logger.debug("message: constant, error: constant") and I would expect logged constant strings to be as coalesced as strings with parameters. Can you explain why having a parameter makes things more coalesced than one with only a constant string?
D'oh! Thanks for catching those items... No matter how many times I review it, I still miss something. I will update it this evening with those corrections.
Only in a language without tail recursion, which unfortunately includes Python.
Basically when you need a one-line anonymous function. Lambdas are generally passed as function arguments for map/reduce type stuff or even callbacks. The anonymous part is important. As a general rule as soon as you assign a name to the lambda such as: function_name = lambda x: x*2 It should be a def instead.
The logger is going to see a different string for each log message if it's interpolated first. Consider this: x = 1 logger.debug("x is {}".format(x)) x = 2 logger.debug("x is {}".format(x)) x = 3 logger.debug("x is {}".format(x)) The logger will receive 3 strings: x is 1 x is 2 x is 3 However, given this instead: x = 1 logger.debug("x is %d", x) x = 2 logger.debug("x is %d", x) x = 3 logger.debug("x is %d", x) The logger receives only one unique string: x is %d And so it will coalesce the 3 messages into one.
Hey there! Posts about learning Python are more appropriate for /r/learnpython. I recommend heading over there; I'm going to remove this, but here's an answer: There's a variety of things that I'd recommend having a look at, but the best way that I've found to get into Python is to find an app that would help you in your day to day life and then write that app. I usually get people to write their apps in Django (it's pretty easy to get into, /r/django for more information). So pick something that would help you around the house. Make a personal library loaning application, or a grocery checklist app, or a movie ratings app. Do something that is related to something that you like, and then keep adding features. Use it, and figure out what you want to do. If web apps aren't really your thing, you can do something like Project Euler or HackerRank for less web-by python.
By convention, when you overwrite the `__iter__` magic method in a class you're supposed to `raise StopIteration` when the sequence is finished. It's a little weird, but it's pretty common IMHO.
It becomes a problem when you're trying to compute factorials of larger numbers.
After trying to install it myself, I still haven't gotten it completely to work. This is what I did: First install all dependecies: sudo apt-get install mysql-server libmysqlclient-dev nginx supervisor python-virtualenv git python-dev create your database (db_name = reddit): mysqladmin -h localhost -u root -ppassword create reddit clone the repo: git clone https://github.com/codelucas/flask_reddit cd into the directory: cd flask_reddit setup the virtual env: virtualenv env start the virtualenv: . env/bin/activate install all requirements: pip install -r requirements.txt create your config: cp app_config.py config.py edit the config: nano config.py change the line: SQLALCHEMY_DATABASE_URI = 'DATABASE://USERNAME:PASSWORD@localhost/YOUR_DB_NAME' to SQLALCHEMY_DATABASE_URI = 'mysql://root:password@localhost/reddit' move the kickstart.py to the root of your project: cp scripts/kickstart.py . run it: python kickstart.py try to run the gunicorn server: env/bin/gunicorn flask_reddit:app now you can connect to http://127.0.0.1:8000 and see your running server. you can cancel it by pressing CTRL+C edit supervisor conf: sudo nano /etc/supervisor/conf.d/reddit.conf input the following: [program:reddit] command = /home/&lt;username&gt;/flask_reddit/env/bin/python /home/&lt;username&gt;/flask_reddit/env/bin/gunicorn flask_reddit:app user = &lt;username&gt; directory = /home/&lt;username&gt;/flask_reddit restart supervisor: sudo supervisorctl reread &amp;&amp; sudo supervisorctl update When this is finished, try to connect to http://localhost:8000, you should see the website. sudo nano /etc/nginx/sites-available/reddit.conf server { listen 8080; server_name reddit; location / { try_files $uri @savelinks_proxy; } location @savelinks_proxy { proxy_pass http://127.0.0.1:8000; proxy_redirect default; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } make a symbolic link: sudo ln -s /etc/nginx/sites-available/reddit.conf /etc/nginx/sites-enabled/ restart nginx: sudo service nginx restart Now you can connect to http://localhost:8080 to see the website.
Be much simpler and more reliable to use a socket in your python code. https://wiki.python.org/moin/TcpCommunication 
Are you trying to open .py files or read in other files using python?
Do you have the repo somewhere? 
Yes, of course. But OP needs the factorial of 12. 
Thank you for the information, anaconda seem to be what I'm looking for.
Ok - Now you're just showing off!! Thanks for pointing it out.
It's a great project so I'm glad it could get some visibility. Thanks for putting it together.
Interesting, I had no idea this was even possible. Thanks for sharing! What are some other sort of things I would be able to do aside from sending emails? For example could I automatically create word documents, or excel sheets or something? I have no idea what else is possible.
I just py2deb my stuff. Sexy debian packages make for a decent install story. But I'm also semi-amateur at this stuff so maybe I'm missing something big.
I deal mostly in Office 365 APIs, so that involves accessing information from Outlook/Exchange, OneDrive/SharePoint, and Azure Active Directory. You can also build Office Add-ins to make Word, Excel, and PowerPoint apps. If you're interested, I'd suggest checking out [dev.office.com](http://dev.office.com) for info and my team's [GitHub page](http://www.github.com/OfficeDev) for more examples. This is our first Python sample, I'm glad it's being pretty well received so far!
We have an existing production stack. I have latitude to improve the devops situation, but bringing in Docker is way too large a change right now. 
Thanks for the link I'll definitely check it out. Like I said I'm still pretty new with Python. I just started up a few weeks ago going through some tutorials. I'm a net admin by trade, trying to learn programming. :)
I've begun reading a book earlier today that has dipped my finger into a bit of DSP knowledge. The difficulty is equal learning programming all over again. My first goal is not necessarily to produce effects, but something more like a loop pedal. When the user begins to hold the switch down the application begins to record the input, and as soon as the user lets go the application begins to loop the sound. Thank you for these sources, I've bookmarked them. 
OK, I'm definitely getting closer with the link you've provided me. My only problem is that the program when you connect via netcat or direct TCP gives an opening statement to input the password and 4 digit pin. My only problem with my code now, is that I see the received data from the welcome message, but I don't see the failed or success messages. Here's my current code: import socket PW = "UoMYTrfrBFHyQXmg6gzctqAwOmw1IohZ " guess = 0 for num in range(0,10000): TCP_IP = '127.0.0.1' TCP_PORT = 30002 BUFFER_SIZE = 4096 MESSAGE = PW + str(guess).zfill(4) s = socket.socket(socket.AF_INET, socket.SOCK_STRE$ s.connect((TCP_IP, TCP_PORT)) s.send(MESSAGE) data = s.recv(BUFFER_SIZE) s.close() print "received data:", data print MESSAGE guess = guess + 1 Any suggestions or links as to how I can fix my issue would be appreciated. 
How so? Are there legacy kernels that you can't being to sunset? Do you not have access or ability to dictate requirements on the host systems? 
Here is a pretty full example from a now-defunct startup: 1. Build configs using Omnibus: https://github.com/balanced/omnibus-balanced 2. CI recipes using Chef: https://github.com/balanced-cookbooks/balanced-ci/tree/master/recipes 3. Deploy logic was just `apt-get install` from an S3 hosted repo.
Write a very small test case to see if it works. Something like: text.txt Just some random whatever in a file. open_file.py f=open('text.txt', 'r') print(f.read()) If you run `python open_file.py` it should print out the contents of the text.txt file. note: python3 
This is awesome. There's now no excuse for not having a simple GUI for even simple but reusable scripts. QOL improvement.
You said you looked into pants, which uses pex under the hood for packaging up python. You can instead use pex directly - is this something you considered? This is what I am currently keen on trying. https://github.com/pantsbuild/pex
I know that. But if I have a function in the mathematical sense, one input that doesn't get altered, one output that is only dependent on that input, then I usually use lambda functions because I usually not want all of the Python magic that happens in the background when creating a function with "def". Because I don't need it. I did not want to imply that the two versions are equivalent, I would have just used the lambda function but since newer Python users tend to get a bit befuddled by those I wanted to include the normal function definition.
Yes, that's always an option. To my knowledge, lambda functions can be thought of as anonymous shorthand definition for functions that have the same or less functionality compared to normal function definitions.
The flask server itself is probably best for development, but you can also run uwsgi locally and have it restart when there are changes by using `py-autoreload` in your uwsgi.ini file like so (where DEBUG is an environment variable set to 0 or 1): [uwsgi] ... py-autoreload = $(DEBUG)
 with open('text.txt','r') as f: print f.readlines() f.close() also helps. .
Having one scripting language available on all OS would make everybody's life so much easier. *crossing fingers while hoping Ubuntu does ship with Python 3 by default this time as they failed this goal 3 times already* As for OSX, I guess we can wait untill 2020. But hey, I prefer to have to write a script that must run on Python 2 and 3 but will work on all my machines than a script in bash and a script in powershell, or worst, an Python installer.
Would be nice, but the reality is that even on Linux you have to install Python by yourself, cause the binaries are always outdated.
Fedora it's pretty up to date with it...
what? Haven't seen any distro that didn't include python aside from scratch distros.
This came up at Pycon, but there was concern that people wouldn't update the included Python, so in a few years, we'd all be stuck writing code for the version that was included. It was also suggested that there could be a dummy `python.exe`, and when you tried to run it, it would let you easily install the latest Python version. OS X does something similar for tools like `git`. But that could have some of its own problems, e.g. if code checks for a `python` command to see if Python is installed.
It depends of your goal. For scripting, even Python 2.4 would be better than having to create a powershell and a bash version.
Of course, python 3.x being forward compatible and easy to upgrade with windows update, it don't think it's such of a big issue. But an old Python version is better than None. I'm happy to write script with Python 2.4 if it's what's necessary to have code running out of the box on Mac, Windows and Linux. Right now, you have to write at least 2 different scripts, and on windows, with a scripting language that sucks a lot. 
Parent isn't saying they aren't in the repos. He's saying the versions in the repos are out of date. I've experienced this myself. The version that shipped was a major rev older than I needed. I had to build the newer version of Python and quite a few 3rd-party packages. It was quite a hassle. A lot of user space apps in Gnome (at least) use Python and various packages. Learning how to get them to coexist took some effort. Ironically, doing the same on Windows was trivial. (The code was cross platform).
One thing is that it's really easy to up Python from 3.x to another 3.x. You could almost roll it as soon as it's released since the old code will still work. It's the 2.7 =&gt; 3 that is hard, as usual.
&gt; As for OSX, I guess we can wait untill 2020. May as well share [this](http://www.apple.com/feedback/macosx.html). Edit: I filed a request to include Python 3.
No way, https://en.wikipedia.org/wiki/Embrace,_extend_and_extinguish Even if microsoft wont do this on purpose they will definitely screw up compatibility. Where are guaranties it wont be IE level of inconsistency (on purpose or not)? Or they standardize some old python version so most projects will be torn between easy windows install or modern python.
It gives me a True sense of satisfaction.
I'm conflicted. Should we help Windows to be better or should we help it to die sooner?
The upgrade argument is moot is we are talking about python 3.x and windows 8 and+: - python code is forward compatible on major versions. - windows update can update python very easily and is is up by default. - we are used to work with old Python versions. Better have 2.4 than powershell. - MacOS have been very slow with python upgrades. Yet you can write scripts running on MacOs and Linux, but still not on Unix and Windows.
Even if suddently tomorrow Windows was a commercial failure (which it's not), MS has the money to keep rolling with it for 20 years while bleeding cash (and it's not). So given Windows is a hard reality, it wouldn't hurt to have it. Plus, if windows has it, it's a strong argument you can use to influence phone OS to include it as well.
The upgrade argument is moot is we are talking about python 3.x and windows 8 and+: - python code is forward compatible on major versions. Upgrading python won't break any code. - windows update can update python very easily and is is up by default. - we are used to work with old Python versions. Better have 2.4 than powershell. - MacOS have been very slow with python upgrades. Yet you can write scripts running on MacOs and Linux, but still not on Unix and Windows.
Also while you're at it, it would be nice if windows came with an x-server.
They won't do it. Why do you need Python when Powershell got all you need? If you need Python, you're doing it the wrong way... /s
Considering that at least the Linux world is moving to deprecate X, that seems unlikely.
I think I'd rather they included a compiler (or at least made one trivial to install). Python (along with a plethora of other dynamic languages) become much easier to use when their is an easily accessible C compiler available. For Python 2.7, there is an easy to install Visual C bundle available, which makes life a lot simpler. For Python 3.4, etc, life is not so easy and the developer is left hunting for the relevant pre-compiled C extensions (often only found on third party sites).
That would not make cross plateform scripting any easier.
What about wayland ? And systemd ?
My distro has Python 3.4.3 which seems acceptable since 3.5 was released only 2 days ago. I will probably have 3.5 by next week.
noone really uses wayland yet. Systemd though? Not sure why windows would want a unix startup/management daemon.
Still a long way away - maybe in 5 years it will be deprecated.
It's not quite that easy to update - compiled extensions for 3.x may break on 3.(x+1). And even pure Python code sometimes breaks - pytest is currently broken on Python 3.5, for instance (there should be a new release of pytest soon to fix it). But I broadly agree that it would be worth the trouble.
No way even MS believes this. PowerShell is a shell language like bash. But even close to pythons power
&gt; But even close to pythons power Neither is Windows even close to Linux power, yet they still develop and sell it. 
oh...but I was deadly serious! I always use remote x-clients on one of my computers 
I doubt if embrace, extend and extinguish would be as effective a strategy for Microsoft today as it was in 2001. You need to have a dominant (if not monopoly) position in the market to manage that, and Apple, Google and other players are now large enough that that's arguably no longer the case.
&gt; windows update can update Python as easily as the rest. People are still using Windows XP. And IE 7-9. Microsoft does not have a good track record with making old versions of their OS die. It's only starting to lessen now that they finally did the EOL last year for XP. But Vista and 7 are still kicking, and Python versions wouldn't be pushed in most maintenance updates.
Without having tried twython, I think you would do something like this: output = json.loads(xx['user'][1].decode('utf8')) screen_name = output['screeen_name']
Look, a company will always push for their own products, as it's in their best interest to do so. Quality and features matter less when it comes to this. 
&gt; Microsoft does not have a good track record with making old versions of their OS die Why should they "make them die". The user paid for the OS and it is the users responsibility to use it wisely and with prudence. Where I work I have many machines that are old XP boxes that run propritary pieces of software. They are air-gapped and are just a tool to get other jobs done. No need to kill them. 
When I see comments like this I have to wonder whether it is trolling or just stupid.
No. Just no. Let Windows keep sucking. Please.
&gt; This has only remotely been a problem for me if I'm editing a module written by some inexperienced programmer who feels they have to put the entire application in one 5,000 line file. Oh yea really? Ever tried working on big open source projects? Here's an example from a library I casually hack on sometimes: https://github.com/pydata/pandas/blob/master/pandas/tslib.pyx. I wouldn't go as far as to say pandas was written by inexperienced programmers. &gt; Some of that can be removed, some will come in handy later. Bajillion is a vast exaggeration. Dozen or so is more accurate. Umm, nope. Sublime has a dozen, PyCharm has bajillion. Once I removed everything I could remove from PyCharm, it still had ten times more of what I actually needed... &gt; Granted I've never spent all the time necessary to get a decent Sublime install tailored for Python, so maybe there is one or two things it does better. The time necessary is about 10 minutes once you know what to do, I've just installed it for a colleague not so long ago and that's what it took. Edit: it took me over an hour to configure PyCharm (mostly removing things, disabling some "smart" features that it imposes on you by default and making it look less ugly). &gt; How is the debugger? Non-existent, of course. Sublime is a text editor, not an IDE and doesn't pretend to be one. I tried using PyCharm's debugger a few times, but didn't like it and just used these ever since: - https://pypi.python.org/pypi/ipdb - https://pypi.python.org/pypi/pudb If you run your scripts on a remote cluster, it's a much better/faster option anyway than setting up ssh tunnels and injecting things into the remote interpreter (which is how PyCharm handles it, I think). 
The issue is Microsoft maintains support for an inordinate amount of time instead of EOLing them in a timely manner, so users think it's okay to stick to older versions, and that creates the constant issue of a large mass of users running old software that some developers think should be supported for things.
a bit out of topic but can you please calirify what do you mean by 'pytest uses so much magic' ?
&gt; Why wasn't zip_longest() functionality rolled into zip() as an optional keyword? Much larger implementation divergence (you can implement a reverse sort in terms of a sort, just invert the comparison function, not so for `zip` vs `zip_longest`), and it would require *two* non-orthogonal keyword arguments (one is needed to provide the optional `fillvalue`). And the behaviour of `zip_longest` is somewhat abnormal and rarely useful/necessary, and activating it in place of `zip` can literally break the program (a `zip` involving infinite iterators is a fine thing, a `zip_longest` doing the same is a non-terminating program)
Then set a reasonable minimum OS version for your product, or require that users with an older OS manually install the latest Python.
...and Microsoft wouldn't push Python into a Win XP system by Windows Update. If the system is using a supported OS level, it's going to get updates, and those updates can include Python. But beyond that this is still a non issue, or at least isn't special to Windows. RHEL and Cent users (and anyone else using yum to my knowledge ) are locked into Python versions, and the users have to make pretty big changes to go even from 2.6 to 2.7. That isn't near enough argument to hold back from saying Python should be always available by default.
xx is an object of type DataFrame, so there's no function call on it decodes. I read the data in from 'output.csv' using the pandas method read_csv What would your equivalent of xx be? I assume it's just a string or dictionary with the tweet and all associated userID/etc? XX, in my case, is a dictionary list (then wrapped into a Pandas DataFrame), so for example there is xx[1] which corresponds to 1 tweet + Meta info, xx[2] which is a second tweet, etc.
Sounds like the OpenGL header file that was forever stuck on version 1.0
No, I was being serious. Why is it stupid, educate me.
While it is annoying to write one script that is compatible 2 and 3, it's still easy to do and beat the crap out of writting 2 scripts or writting powershell. Plus, Linux distro are on their way to upgrade to python 3, so by the time windows ship with it, only mac os will remain. At which time it will be a strong argument to convince them to upgrade too.
Please save yourself the aggravation and install Anaconda.
Neither is powershell. But you do need tools to script windows. Plus it would open the door for very easy cross plateform coding, including small GUI tools that end users would end up using.
"Don't fix the road 80% of the planet uses, in 30 years maybe they'll stop"
The world has changed. It's not just Windows and you have to use that because you need it for Word or Excel. There are alternatives: Linux, Chrome, OSX, Google Docs. There will be more. There will probably be some Cloud-base OS in a few years. What I am saying is that I (I personally) don't see a bright future for Microsoft. They will just fall into the background. Can anyone think of anything Microsoft provided that we didn't have already? What have they provided this world? Did they advance computing? I don't think they did. Microsoft are not my champions of computing over the past 35 years....and Windows don't come with Python. Oh, I don't think they have that much money anymore. I don't know that, it's just a guess. But they must have taken a beating on 8.
What you're saying is that the benefits will not be "total and instantaneous". It never is in IT.
I guess this explanation i can buy, though still not entirely convinced because: assuming both are implemented in C which probably they are and you are not willing to work on the relevant condition checks to make them universal then you could just cram both C implementations into an if. Purity of implementation details is not relevant to people using api, hell, namedtuple works by evaling shit. Optional keywords not making sense in certain contexts are not unheard of and i am sure i'd find a few examples of that while trawling core modules. Python is reportedly a language for adults and it doesn't take a rocket scientist to figure out that infinity is infinity and that a bit of foresight is nice.
The correct way to run a Python 3 script is `#!/usr/bin/env python3` anyways.
Yes please 
How is it coming to the end of its shelf-life? About 90% of laptops and PCs are using windows. https://en.wikipedia.org/wiki/Usage_share_of_operating_systems Plus thousands if not millions of commercial/enterprise units that are much harder to upgrade/change. I can tell you don't like it, for whatever reasons you have, but that doesn't mean other people don't like it. https://yourlogicalfallacyis.com/anecdotal
Sure, but such a script won't run on a distro that just has Python 2 (like OS X).
People using hashbangs to point to the environment python know enough to install multiple versions side by side and use virtual environments
That's a strange comparison - Powershell is for simple scripts whereas Python is a programming language. Also this is more for the tech/development side of things which the casual user doesn't need.
Python is embeded as a scripting language for MacOS and Linux. They don't use it for its crazy introspection capabilities and metaclasses. Python can do simple script better than powershell as it has a bigger stdlib, while still being able to do small GUI tools and big projects, and cross plateform. So basically, you would have a scripting language that would run anywhere, with a clean syntax, a huge stdlib, 1000 of external libraries you can just embed in your script (python can run zip files), and that is still relevant as your program grows in size.
Omg this would be amazing..
First, you can do 95% of any scripting with just the stdlib. Secondly, you can use many 3rd party libs without needing c extensions. Specifically, parser libs such as pyyaml has only optional c extensions and provide a pure python version (http://pyyaml.org/wiki/PyYAMLDocumentation). Thirdly, using msi installer suffer from big problems : - for big companies, you still have to deploy it on all machines which means work to support it, document it, request it to hierachy, paperwork and the like. - for the end user (not a dev), it's a deal breaker.
If you have applications that require it you are going to have to go through that process one way or the other. Either you are going to have to have to run an installer or you are going to have to upgrade the OS and verify there are no problems between other existing applications and the OS.
Javascript (and VBScript) are embedded as scripting languages on Windows but lots of people don't know this. You use [Windows Script Host](http://www.robvanderwoude.com/wsh.php) to run them.
Even if we don't like it, Windows will be here for the next 20 years. Despite mac, linux, google, the mobile scene and else. And people will have to work with it. The thing is, if we don't put Python on windows, eventually we will have one language everywhere : javascript. So if I have to choose...
Yes but it's not on Linux and Mac. And JS is a terrible scripting language. It's a terrible language in general, but particularly bad for scripting.
You're right, there is now a [stable ABI](https://docs.python.org/3/whatsnew/3.2.html#pep-384-defining-a-stable-abi) for extension modules, but they have to explicitly opt in to using it, and limit themselves to a subset of the C API. Extensions that don't do that will still break on each new version.
Python 2 or 3 couldn't save the Titanic and it certainly isn't going to save Windows.
The phrase "Microsoft" and "And people will have to work with it" is the way it has been since Microsoft started. Because Bill made sure that he got a slice of every PC we bought then (to have a Personal Computer you had to have MSDOS) and now (try buying a PC without Windows). Anyhoo, good chatting with you.
&gt; Python is embeded as a scripting language for MacOS and Linux. No its not, but many, if not most popular distributions do include it. ###UNIX/Linux has a mechanism that automatically supports ANY interpreted language. That's probably why you think Python is "embedded". It's not embedded. You can run any interpreted language script on UNIX/Linux automatically by using the #! directive. (called "shebang" or "shabang", long form "Shell Bang", or "Pound Bang") On the first line of any script, put: #!/pathto/interpreterexecutablefilename For example, a bash script is started with : #!/bin/bash So ANY - Absolutely ANY interpreter is already automatically supported on UNIX/Linux platforms. Calling them "embedded" implies a level of intimate official support that does not exist. To UNIX/Linux, Python is just another interpreted language, just like the command line shell. or perl, or tcl, or dash, or ksh, or pdksh, or csh, or awk, ... well you get the idea. EDIT: ###great article w/background info on #! (Shebang) http://www.in-ulm.de/~mascheck/various/shebang/
This is just semantics: remove Python from most linux distro or Mac, and it breaks. On Fedora, the only way to install cleanly a package is yum, which is written in Python. The entire system depends on it. On my Ubuntu, a quick apt query gives me what depends on Python: aisleriot alarm-clock-applet anki apt-xapian-index apturl bluewho calibre calibre-bin cdbs checkbox-gui choqok compiz compiz-gnome deja-dup deja-dup-backend-gvfs dreampie dstat duplicity electrum flashplugin-installer gcj-4.9-jre-lib gconf2 gimp gir1.2-ibus-1.0 gksu gnome-user-share grass grass-core grass-gui gstreamer0.10-gconf gtg guake gufw gvfs-backends gyp ibus ibus-pinyin ibus-table indicator-bluetooth inkscape iotop kde-runtime landscape-client-ui-install libapache2-mod-wsgi libbonoboui2-0 libgcj-common libgcj15 libgksu2-0 libgnome2-0 libgnome2-bin libgnome2-common libgnome2-perl libgnome2-vfs-perl libgnomeui-0 libgnomevfs2-0 libgnomevfs2-common libgnomevfs2-extra libnss-winbind libopenscenegraph100 libosgearth3 libosgearthannotation3 libosgearthfeatures3 libosgearthqt3 libosgearthsymbology3 libosgearthutil3 libpam-winbind libpurple-bin libreoffice-gnome libsmbclient libxine2 libxine2-misc-plugins libxine2-plugins liferea mat meld mercurial mercurial-common nautilus-pyextensions nautilus-share ndiff node-gyp nodejs-dev npm oneconf oneconf-common pdftk picard pidgin pidgin-libnotify plainbox-provider-checkbox samba-common-bin samba-dsdb-modules samba-libs samba-vfs-modules sessioninstaller shutter smbclient software-center software-center-aptdaemon-plugins solaar soundconverter steadyflow system-config-printer-common system-config-printer-gnome totem totem-plugins transmission-gtk tribler ttf-mscorefonts-installer ubuntu-desktop ubuntu-release-upgrader-gtk ubuntu-sso-client ubuntu-sso-client-qt ubuntu-system-service ubuntu-tweak unetbootin unity unity-control-center unity-control-center-signon update-manager update-notifier update-notifier-common utext virtualbox virtualbox-dkms virtualbox-qt virtualenv-clone virtualenvwrapper vlc-plugin-samba webaccounts-extension-common winbind xdiagnose xul-ext-webaccounts y-ppa-manager zeitgeist zim libgnome2-0 depends on it. unity. ibus. So yeah, you may dislike the word "embedded", but it's kinda a symbiotic relationship. 
Last time I checked, having a common language between plateforms made the transition easier, not harder.
No company in their right mind would do that because they end up having to support it. It's not difficult to download and install. 
Because you don't script with C. Because you don't need to mass deploy you c compiler on a park of machines : you just deployed the compiled version. Because compiled languages and interpreted languages don't have the same usages. Because right now Python is the best interpretted language for scripting AND building small tools AND testing AND doing network analysis AND doing data parsing. But I agree on windows size. Although the problem is a different debate.
I really want WinRT projections for Python.
Fair enough
If you're using Python 3.5, I wouldn't change a thing. If you're using Python 3.4 and below, I would switch to the scandir module's scandir.walk method. It's much, *much* faster than os.walk, and Python 3.5 has replaced the os.walk implementation with that of the scandir module. Same syntax.
Use a tool like cxFreeze or my personal choice, py2exe, to create a real executable program that can run without a Python environment needing to be installed. Stub out a make script in python to call the above and create the executable package. You can schedule your tasks to run using the built in windows task scheduler.
Hello data is &lt;type 'dict'&gt;, and that's the raw return I get back from my Twython object. I build these into an array, tweets=[] .... tweets.append(data) which I have then been converting to the Pandas DataFrame type values = pd.DataFrame(tweets) This operates as you would like/expect for a Data Frame object, except that values['user'] has the complication described above. If I re-cast this, I can then access things that I want, but my question is is there any method which will do this at scale without being clumsy, i.e. something like this but more elegant: import ast for i in values.index: tmp_str = data['user'][i] data['user'][i]=ast.literal_eval(data['user'][i]) such that I can then do data['user']['screen_name'] Does that make more sense or am I still confusing the issue? Basically I'm looking for a method that will convert all of one field of a DataFrame into a dictionary from a string.
At this time, I'm not so interested in targeting a Windows installable app. I've done that before. I'm looking more at the recommended way to develop on Windows. So you create a custom Python script to run your common commands during development?
&gt; and it would require two non-orthogonal keyword arguments (one is needed to provide the optional fillvalue). Theoretically you could use only fillvalue, but you'd have to use something like `zip(a, b, fillvalue=zip.DEFAULT)` instead of `None` of course. That's kinda convoluted and still not entirely waterproof, actually I'm not sure if you can implement waterproof sentinels like that in Python at all. Other arguments are without merit, I think: implementation divergence on the contrary is non-existent (a single `if` where you're deciding to stop iteration, having a single function would make the implementation _much simpler_); `zip_longest` is not abnormal at all when zip itself is an iterator, as it should be of course; you're not going to "accidentally" specify `fillvalue` any more than you might accidentally type `_longest`.
It's a bad thing because it means they are unable to take a step forward (as in, they give us the same product over and over again, it just has more shiny things). In my mind there is a big difference between "innovate" and "invent". If I could be so bold as to say: Apple empower their users, where as Microsoft constrains their users. I mean, my 4 year old can use an iPad but even I can't use a touch-screen Windows 8 (it's really difficult to use, I found). Saying this, Windows 10 failed to install on my machine (even though it said it would). So, maybe, Windows 10 will usher in some wonderful new technology, maybe they will take a step forward.
And Ubuntu is supposed to have 3.5 next month. "supposed"
Arch master race; no problems here either.
It is inevitable. Everything dies. But it will be slow. Very slow. I'll probably be retired when it will begin.
&gt; On Fedora, the only way to install cleanly a package is yum, which is written in Python. The entire system depends on it. I guess you never heard of RPM's :-D #BWAHAHAHAHAHAHA What are you, 8 or 9 years old? All of Redhat's distributions, including Fedora use RPM for installing. Source code is here (its written in C, and sh and some other tools as well, like makefiles!! ) https://github.com/rpm-software-management/rpm yum is a more recent tool built on top of the infrastructure created by the rpm utility. :-) No, you don't need yum to install packages to Fedora. 
"Download python" is not somthing most non dev user will do. Most of them will think it's a virus.
For more info: http://pybites.blogspot.ca/2011/07/behind-scenes-of-pytests-new-assertion.html Quick explanation: it rewrites your test modules so that it only executes assertion code once, but will still dump nice output about the values at the time of the assert. 
It's just reality friend. Microsoft has entered its terminal 3Com stage, all money and very few brains. Microsoft owes its success to Copying other peoples products, stealing other peoples products (a consist pattern of IP theft, they lost over 20 law suits, one with a payout of 2 Billion dollars), and strategic but illegal monopoly licensing agreements. Microsoft has never made good software and they have never made good products. You like because its the first thing you learned. 
If you're managing such amounts of machines I'd hope you have some provisioning tool in place... But yeah it would be easy.
Why don't you just bundle python with your release?
&gt; MS has so much money they can litterally loose money making new windows version and paying people to use it for 20 years without going bankrupt. Yup, just like 3COM. (who??? ) 
Because that defeats the purpose of using a scripting language: it's a lot of work, and needs a lots of testing. If you want to spend so much work to script "list outdated files, archive them and delete them", then you just use Go. And 
Sorry, to clarify: The DataFrame constructs a dictionary of all the fields in the tweet, that's absolutely fine. The issue comes in on some of the sub-fields. For example, one of the dictionaries are: type(data['user'][1]) &lt;type 'str'&gt; Within this mapping of 'user', we find many useful values, such as the profile_image_url, the followers_count, the id_str, the screen_name, etc. What I want to do is translate that string into a sub-dictionary, such that I can then do: data['user']['screen_name'] As above, I can do a line-by-line conversion of this with some for loop, but it seems horrendously inefficient. tl;dr There *should* be a sub-dictionary in the DataFrame object for the ['user'] dictionary, but instead it is just a string. Is there any way to automatically convert this for all rows of my DataFrame into a new sub-dictionary
You think you want this, but you really don't. What you'll end up with is writing a script that has to run on N different configurations of python, with different versions that are years apart, different bugs in the runtime and libraries, and different available third party libraries. As a developer, you're much better of bundling your dependencies or installing them on demand. As an end user, do you really want your OS to ship with a bunch of different scripting languages that you may or may not use but have to pay for anyway?
And I would say that if bundling the runtime is a lot of work, that's a failure of the language. Distribution needs to be easy.
If we're going to Microsoft with a shopping list, I think a better one is asking for C11 support (just skip C99, it's too shameful that they don't support it) so Python can use some modern Cisms. AFAICT, [the reason CPython is stuck with C89 is because Visual Studio won't support anything more modern](https://mail.python.org/pipermail/python-dev/2012-February/116251.html). Many Linux distributions don't come with Python and one installs it with the package manager. Windows users can do the same with [Chocolatey](https://chocolatey.org/). Maybe they should provide Chocolatey by default.
Why stop there? Let's provide a Ruby interpreter as well! Maybe we can go a little wild and include TCL! Why should Microsoft provide an interpreter for your favorite language? I'd rather they just include a decent C compiler and some standards-compliant build tools. This would solve more problems than bundling a version of Python with the OS would ever solve.
It's not because it's my favorite language. It's because : - Mac and Linux already have it pre-installed and us them a lot. This proves both robustness and usability. - Python is the only language that is good at scripting AND many other things. Usually you have either good scripting OR other things. E.G: ruby has a great ecosystem in the Web, but is less competitive in other area - C-compiler is an entire different issue. Embedding python doesn't target primarily app dev, but scripters, so they can share the script with non dev, or deploy it on a lot of machines on an heterogeneous park.
Well you can't do that for Windows because they don't include ssh by default, either.
That is correct. I get an object 'data' which is &lt;type 'dict'&gt; I have to then append this myself to a list tweets.append(data) type(tweets) &lt;type 'list'&gt; The DataFrame then comes into this as, it seems obvious to me to convert a list of identical dictionaries to a DataFrame object: xx = pd.DataFrame(tweets) **Big edit** On further investigation, the Twython return is multiple level deep of dicts, i.e. type(data['user']) &lt;type 'dict'&gt; So I guess the fact that this is a sub-dictionary is being lost in the conversion to a DataFrame. The following operation, for example,: x['user']['screen_name'] is perfectly valid on the **original** data object. It's the conversion to being a DataFrame that is killing me. My apologies for the mistake, thanks for pointing it out and making me check. Does this mean my best option is to sub-convert the ['users'] dictionary, and then add a new field to the new DataFrame object which has ['user_dict'] or similar?
Ssh is a very specific tool. While I think it would be good to have ssh one windows has well, it's another debate: python is a much more general purpose tool, with already some great MS support.
&gt; Why should Microsoft provide an interpreter for your favorite language? I think it's simply to have _an_ interpreter that can be used cross platform. At least one. There exists no interpreter that is a) bundled and b) cross platform across Windows, Mac, Linux today.
That sounds like an awkward design choice by Twython. I would use another library. But, if you stay with Twython, you will need to parse each JSON string into a dict using json.loads as I mentioned. Alternatively, I use [TwitterAPI](https://github.com/geduldig/TwitterAPI) which returns each tweet already parsed.
Sorry, please see my edit, the error is in the conversion from the tweets array to the DataFrame object, and you were right about Twython returning a deep list of dicts.
Ok, well if you're trying to sell people on the idea, then maybe choose an examlpe that will actually be possible on Windows once you get python installed by default.
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
What ?
I could only imagine how they would mess it up.
This isn't exactly "gradual, step-by-step", but I recommend getting some inpiration by going through https://speakerdeck.com/pyconslides/python-3-dot-3-trust-me-its-better-than-python-2-dot-7-by-dr-brett-cannon to get a first impression. It refers to Python 3.3, but everything explained there applies to 3.5 as well. Only the part about function annotations is slightly outdated now, because they are now decided to be used for type hinting. If you want more in-depth information, read the most prominent accepted PEPs for each new major version. They are mostly very well-written, informative and, most importantly, they explain **why** they were introduced. Edit: IMO there is no need for a real tutorial like for vim, because Python 3 doesn't introduce a completely different coding style like C++11 vs C++98. Most of the changes are cleanups that improve consistency in the langauge and make it easier and more obvious to do common things in the best way (like e.g. renaming xrange to range). Just reading what has changed and then rewriting some old programs with this knowledge should be enough to make the transition.
Actually no. Powershell is insanely powerful with tight integration with Windows and .NET. I have Python installed on my Windows boxes and I still use Powershell *all the time*. You can't compare bash/Python in Linux and Powershell/Python in Windows. In Linux, everything is a file and is manipulated through stdin and stdout. Python is a good choice for system administration here. But Powershell, everything is an object, and Powershell is powerful because it exposes .NET and COM objects. Also, Powershell lets you add in MMC snapins, which unlocks a lot of very commonly used administrator tools. You couldn't get this functionality with Python out of the box. You would see the opposite of what you described. Sysadmins and powerusers would use Python for the "quick stuff" since the language is so nice, but for anything serious, people would stick with Powershell. Of course, unless Python gets the same tight integration with Windows.
 &gt; Mac and Linux already have it pre-installed and us them a lot. This proves both robustness and usability. Faulty assumption. I administrate at least one Linux system (that I can recall) that does not have Python installed. I agree that it is *common* for Linux distributions to have a Python interpreter installed, but it's not all roses and candy. RedHat is using python 3.1 for craps sake. &gt; Python is the only language that is good at scripting AND many other things. Usually you have either good scripting OR other things. E.G: ruby has a great ecosystem in the Web, but is less competitive in other area That's just like, your opinion man. Don't get me wrong, I love Python, too, but I know a number of Ruby programmers that would say exactly the same thing you just said, and they would be no less right or wrong than you are. &gt; C-compiler is an entire different issue. It is *the* issue. Since there is no standardized way to build software on windows (vs OS X and Linux) then it is difficult to deploy python and python plugins to windows. &gt; Embedding python doesn't target primarily app dev, but scripters, so they can share the script with non dev, or deploy it on a lot of machines on an heterogeneous park. Then why not Bash, or some simple implementation of a Unix shell, existing as a subset of Bash? If all you want is heterogeneous scripting, let's go with the path of least resistance. EDIT: Also, I just realized that, if Microsoft were to produce a *sh implementation, they might actually be forced to fix their faulty shell handling! Win-win for everybody!
I think Bash would be a better candidate, then. It's less political. It's simpler to deploy (nobody writes Bash plugins), and arguably more stable than Python. Look, I love Python, but I don't see why it's something that should be bundled with Windows.
That's the kind of integration you can get with either: - a pure python lib using ctypes to do so. You can just zip your script with it, Python can execute zips. If you see people installed by default on windows, you'll see such lib pop out in a week. - a provided Python api by MS, since they provided Python, they may want to use it. Either way, it's not very important : if you are only on windows, you will use powershell just because it's here. But if you have to make a script than runs on mac, windows and linux, right now, having Python installed on windows would make the situation much less shitty.
That's a very short sighted way to program something. Regardless, yes, he only needs 12 but it is good to know that this problem exists. 
So, in big companies, this goes like: - you ask your superviser to install it; - he/she asks the chain of command; - there is a meeting about it; - paper work; - you need to follow it during all this time; - you deal with useless debates about versions and you end up choosing an arbitrary one; - then you plan for doing it; - then you deploy python; - then you document it; - then you ensure new machine will have it; - then you let know your new team members about it. Yeah, it's work.
I wish it wasn't installed in OS X. At least a once a year I find myself trying to eradicate one version or another to make the latest work. I get into the situation when I try to install it with homebrew. Just give me a decent pack manager and let me decide what to install. 
&gt; a pure python lib using ctypes to do so. You can just zip your script with it, Python can execute zips. If you see people installed by default on windows, you'll see such lib pop out in a week. &gt; a provided Python api by MS, since they provided Python, they may want to use it. Having the same tight integration with Windows is more than just using ctypes. And providing an API by MS is a lot of work of work. You're basically asking for IronPython to be installed (and improved) instead of CPython. &gt; Either way, it's not very important : if you are only on windows, you will use powershell just because it's here. But if you have to make a script than runs on mac, windows and linux, right now, having Python installed on windows would make the situation much less shitty. Sure, if you need to target all 3 platforms, then this would be great. I'm all for it. But don't think that Powershell is the "less worst option" that nobody would use if Python is installed by default.
You mean the Microsoft that released .Net Core as an explicitly cross-platform .Net runtime and are actively developing it? Or the one that open-sourced their compiler so that* it can be integrated with Mono? \* well, that wasn't the primary purpose
Maybe better to switch to unix (FreeBSD, Linux)?
I counted well. 80% of the planet (having electricity, which is not that much of the planet ^^) uses windows. That doesn't mean they don't use Mac and Linux as well. It's not an OR, it's an AND. They touch windows at work, or at home, or when they use bank/insurance/state administion systems. And of course, in Asia, Africa and South America, Windows has still a strong presence.
Alternatively, it's a good intro to recursion. From there, one can get a nice intro to dynamic programming. And then, hey, here is why recursion doesn't always work: stack overflow. Learning how to make things work and how to break things is important. 
A less minimalistic browser using nearly the same technology (Python 3, PyQt5): https://github.com/The-Compiler/qutebrowser
&gt; Got a source on that? This is just for the purpose of arguing. You know I don't, but you know I'm right. &gt; Admins are using the right tool for the right job, that may or may not be Python, it's often Bash, or even Perl or &lt;insert obscure language of the week here&gt;. Python isn't a special snowflake in this regard. No, but if you have to choose ONE language to port to windows : - you won't do perl because long scripts are really hard to maintain; - you won't use bash because it's file oriented. &gt; &gt; bash is file oriented (unix philosophy) while python is general purpose oriented. &gt; Wat. Try to manipulate COM objects or XML files with bash. It's just not handy. Making small GUI with bash is terrible too. Scripting doesn't mean only reading file and writting to it. Bash is turring complete, it can do anything. But it quickly because a mess when you got complex logic. But to be fair, I'd rather have bash ported to window than nothing. I would be content with that. Only they will most likely port Python, since they are already working on it. &gt; It's pretty clear it is a matter of preference to you. and &gt; Nothing about this is objective. Just because I like Python me doesn't make my arguments illogical. You have a general purpose language, with versatil use cases, a strong ecosystem developped in more area than most langages, doing great job at scripting, installed in 2 other major OS, and on which MS already work. &gt; Same could be said about any language if you try hard enough. No other language has that. None. First, most of them are eliminated at the "installed on major OS" stage. Then you need the strong scripting capabilities. And you need the strong portability. Now you take than, and you find something that is as readable as Python, with an integrated debugger and GUI lib. You can look for a long time, cause it doesn't exist.
&gt; It is the issue. Since there is no standardized way to build software on windows (vs OS X and Linux) then it is difficult to deploy python and python plugins to windows. Since when is the way to build software standardized on OS X and Linux? Plain GNU make, autotools + GNU make, CMake + GNU make, CMake + Ninja, scons, ... the possibilities are endless. They only don't break between compiler versions as often as Visual Studio projects. But calling it standardized is more than bold.
NO! NO NO NO NO NO! I do NOT want this! It would literally be the worst thing to happen to Python in Windows. It would co-opt the definition of "Python" to be "the version on Windows" *all* of Python software would be written to conform to their version, with whatever modifications they decide to make. The best thing that Microsoft could do for Python is to provide a standards-compliant C compiler and build environment. Beyond that, their contributions to make Python work better in Windows are enough.
You do have a fair point. I concede that it's not Microsoft's responsibility to do it the way Linux/OS X do it. In that case, I wish only that they would standardize on a set of build tools and *include them with the operating system*.
&gt; Any Linux admin worth their salt can install Ruby in 10 seconds. If you're worried about clueless end-users, don't. There are none in the Linux world. That's beside the point. If you have to install your runtime on all your sever, it's work. If you have to install it on Windows AND Linux servers, it's even more work. See my other comments about that. It's a LOT more work than just ssh and apt-get/yum install in big companies. &gt; Ruby is, in my experience, far more popular than Python for web development. Python does a good job, for sure, but the culture is with Ruby on this one. Yet Python hold the comparison, and is more used at scripting. Good thing we are talking about scripting. Cause here, we'll have the best option + a decent option for the web. &gt;Twitter invested in Ruby, Github invested in Ruby, Hulu invested in Ruby... &gt;We can do this all day. Given that Linux distro editors, MS and Google are all OS builders and Twitter/Github/Hulu are websites, one are more important than the others. &gt; Moot points. The same could be said for Java or Flash. Bash is arguably even more popular. It's not a moot point : the all purpose is easy cross plateform scripting. Nor Flash or Java is installed by default on most linux distro. Again I'd be happy to see bash installed on Windows. I'd prefer Python, but I'd go with bash. Only MS will never invest in bash. And using bash to access COM API would suck. &gt; And here's the crux of the proplem: They will modify Python. You are assuming in advance they will screw this up. I know they have a shitty track record, but the Azur Python support seems to go well. What your saying is : "it may go wrong, so let's not do it". Let's not do anything then. Let's shudown all computers cause our entire job is to build stuff that go wrong. &gt; What's worse, they won't fix the core problems of developing and distributing applications written in Python on windows. THAT IS NOT THE POINT. For the 1000th time, the purpose is cross platform scripting and sharing small GUI tools. There is noway you can destroy Python to the point it can't run tkinter. And i'm no assuming they will destroy Python. This is pure assumption. &gt; You're not making windows better with this. You're making Python worse. Assumption, assumption, assumption. You are saying my love for Python cloud my judgement. Fair enough. I'd argue that your (shared) digust for MS is clouding yours. Your all post is about trying to find faults instead of trying to be right, so much that you mixes up all possible arguments : it may go wrong, you could use another language, it's not fixing {not the topic}, etc.
To help reduce the pain he has to endure when he has to use a Win box.
I suspect this will result in the exact same thing happening as when they included macro programming in all of the Office apps -- viruses. Viruses, trojans, malware everywhere. And to all the people saying "but it could be included in updates:" by that logic there must be no more malware out there exploiting old flaws. Yes, you will update your system, but 10,000,000 grandmas will not and those machines will be great targets for cybercrime platforms to launch other attacks.
Right now you know what's is the best version of Python ? None. Nobody knows what to target. Nobody knows how to do cross-plateform scripting. Nobody can share a quick python script with a non dev on windwos. So you assume it will be a problem (which stays to be proven, since 3.x is forward compatible and can be upgraded through windows update) and provide a solution that does not solve the cross plateform scripting problem at all.
I write python 2.1 and what is this?
&gt; That's beside the point. If you have to install your runtime on all your sever, it's work. If you have to install it on Windows AND Linux servers, it's even more work. Sure, but I never use the supplied Python interpreter on my servers. I always end up having to build my own because the linux distributions can never seem to get it right (See: Python 2.6 on RHEL). I'm a Linux admin, though. I have a lovely bash script for that. &gt; See my other comments about that. It's a LOT more work than just ssh and apt-get/yum install in big companies. Big companies have big resources. I'm not worried about them. They'll be fine. Even Microsoft knows this. &gt; Yet Python hold the comparison, and is more used at scripting. Good thing we are talking about scripting. Cause here, we'll have the best option + a decent option for the web. Great. Now all the web frameworks will target the version that runs on Windows. &gt; Given that Linux distro editors, MS and Google are all OS builders and Twitter/Github/Hulu are websites, one are more important than the others. Says you. I say that without web companies, we wouldn't even need operating systems as capable as we have. No vendor is more or less important than any other. &gt; It's not a moot point : the all purpose is easy cross plateform scripting. Sure, but you still haven't provided a good reason for why Python is the right choice *for scripting*. &gt; Nor Flash or Java is installed by default on most linux distro. They're arguably installed on more computers, though. &gt; Again I'd be happy to see bash installed on Windows. I'd prefer Python, but I'd go with bash. Only MS will never invest in bash. They've provided a KSH implementation in the past, though. Any implementation of standard SH features will do. &gt; And using bash to access COM API would suck. It already sucks to do it in Python, so I don't see how this would be any different. &gt; You are assuming in advance they will screw this up. I know they have a shitty track record, but the Azur Python support seems to go well. Their support of Java on Windows NT went well, too. Initially. &gt; What your saying is : "it may go wrong, so let's not do it". Let's not do anything then. Let's shudown all computers cause our entire job is to build stuff that go wrong. Now you're getting into hyperbole. I'm just saying that I don't want the standard version of Python to be the one that Microsoft ships. &gt; THAT IS NOT THE POINT. &gt; For the 1000th time, the purpose is cross platform scripting and sharing small GUI tools. You want to use *PYTHON* to do *GUI* work? Now I'm convinced that you are crazy. &gt; And i'm no assuming they will destroy Python. This is pure assumption. No, it's a judgement based on their history. Based on their *actions*. They may not even do it intentionally, but they will do it. Worse, they'll do it in subtle ways that are hard to track down. You think they're just going to ship the version hosted on python.org? Really? &gt; Assumption, assumption, assumption. History tells me I'm right. &gt; You are saying my love for Python cloud my judgement. Fair enough. I'd argue that your (shared) digust for MS is clouding yours. I have no disgust for Microsoft. I use their products on a daily basis. I write software for Windows without any issue (unless I'm using Python). I understand how they tick. OS X has done horrible things for Python 3 by bundling Python 2 for so long. Microsoft will do the same, or worse. &gt; Your all post is about trying to find faults instead of trying to be right, so much that you mixes up all possible arguments : it may go wrong, you could use another language, it's not fixing {not the topic}, etc. I don't want Microsoft to ship a version of Python. I don't want another major vendor stagnating the advancement of Python. I'm not trying to find faults. I'm telling you you're wrong. 
Sorry, no. Linux is already ahead. 
Not this fucking spiel again. It adds nothing.
If we fix the bundling problem, the scripting problem goes away, too.
Yes please, we need more bloat!!
I don't know if this is intentional or not, but if it is: please don't hijack the back button. I clicked on the first link in the post, and was brought to the login page. Clicking on the back button did nothing. Sites which disable basic browser features are a massive pet peeve of mine.
&gt; Got a source on that? &gt; This is just for the purpose of arguing. You know I don't, but you know I'm right. Are you serious? A very lazy Google search comes up with http://w3techs.com/technologies/details/os-linux/all/all - Ubuntu: 29.7% - RH: 4.3% Even if you adjust it to mean "Debian and CentOS as well" it's nowhere near 90% &gt; No, but if you have to choose ONE language to port to windows : &gt; &gt; you won't do perl because long scripts are really hard to maintain; &gt; you won't use bash because it's file oriented. I will use whatever language is best for the job. "Porting" one language is ridiculous, there's a reason why there's tons of them. I still don't know what you mean by "bash is file oriented". The UNIX philosophy is "treat everything as a file", but that goes way beyond Bash (in fact, Bash came along much later). &gt; bash is file oriented (unix philosophy) while python is general purpose oriented. &gt; Wat. &gt; Try to manipulate COM objects or XML files with bash. It's just not handy. Making small GUI with bash is terrible too. Scripting doesn't mean only reading file and writting to it. Bash is turring complete, it can do anything. But it quickly because a mess when you got complex logic. Again, use right tool for the right job. Python may be a good match for XML parsing, but for sysadmin type work Bash is probably better suited (or PowerShell in Windows). A GUI *should* be decoupled from the backend. Write your backend in whatever language is best for performing the actual task, then you can have 50 GUIs in whatever assortment of languages you desire. &gt; &gt; But to be fair, I'd rather have bash ported to window than nothing. I would be content with that. &gt; &gt; Only they will most likely port Python, since they are already working on it. I doubt they will do either, but not because of technical reasons. It doesn't make business sense for them to do either one. &gt; &gt; It's pretty clear it is a matter of preference to you. &gt; and &gt; &gt; Nothing about this is objective. &gt; Just because I like Python me doesn't make my arguments illogical. You have a general purpose language, with versatil use cases, a strong ecosystem developped in more area than most langages, doing great job at scripting, installed in 2 other major OS, and on which MS already work. I didn't say illogical, but when you say things like "Python can do more than bash" and "you know I'm right" it's hard to say you're being objective. &gt; &gt; Same could be said about any language if you try hard enough. &gt; No other language has that. None. Ever heard of CPAN? &gt; &gt; First, most of them are eliminated at the "installed on major OS" stage. Then you need the strong scripting capabilities. And you need the strong portability. On a vanilla OSX install I have Bash, Python, Ruby, Perl. All of them are considered portable and have strong scripting capabilities. &gt; &gt; Now you take than, and you find something that is as readable as Python, with an integrated debugger and GUI lib. &gt; &gt; You can look for a long time, cause it doesn't exist. You can make unreadable code in any language, and an integrated debugger/GUI libs aren't *essential* to the functionality of a language. P.S. Spellcheck is your friend.
Dude, i think your enthusiasm for python is great, but don't go around bashing other languages blindly. You just make us look bad by doing that. 
During development, I run the applications from the python source files on the command prompt. When it comes time to create a build for production use, we create an application using a python "makefile" as described above.
I think you guys are arguing past each other. It just comes down to using the right tool for the job. If you're a 100% MS shop, Powershell with a touch of python for special cases is probably the way to go. If you're a multi-platform shop using Python with let's say SQLAlchemy for differing databases would be the way to go. Another option would be scientific analysis is probably stronger using SciPy, NumPy and iPython Notebook. It's all about the right tool for the job. Each of you is looking at your job and telling each other it's the right tool.
That's exactly why you include the python3, so that it will fail if they don't have python3. If your app supports both 2 and 3 then you just use python and it will work with the default system version. 
You are right. 
It's still platform-specific, though. Even if it's in the same language. You're going to have three scripts in one file instead of three scripts in three files. I don't see any value in this.
Repository of the trusted apps and tool like apt-get -- this is what Windows really needs.
I've written plenty of scripts that work cross platform. Anything that doesn't affect system files will be fine. Simple example, you want to process 10,000 photos and convert the RAW images into web jpg images. This script would be 100% the same on both Windows and Linux. Launch the script, choose the input/output directories, and away you go.
&gt; If your app supports both 2 and 3 then you just use python and it will work with the default system version. No, it won't. Most systems with Python 3 but not Python 2 (with the notable exception of Arch) do not install Python 3 as `python`. They have Python 3 as `python3`, and nothing as `python`. Ubuntu's live CD / default install is an example of this, I believe.
Ah! But now we have a problem. What native windows tool will you be using to convert those images? How will this work without installing extra software before running the script?
Install the "Visual C++ Redistributable for Visual Studio 2015" &lt;http://www.microsoft.com/en-us/download/details.aspx?id=48145&gt;
Windows 10 has a package manager. Assuming all works as described it should be just like *nix or Brew now.
I find powershell to be better for things that need to be maintained for long periods of time. Bash I find is better for quick commands. The long fully qualified class names just makes it difficult to quickly throw out a script, but makes it a joy to test and maintain for years. Personally I prefer python to both. But they each have their place preference be damned.
they don't even include .net which is theirs
True, which is why I'm offering the alternative view to this. 
I would rather not see any python.. less hasle afterwards. Obviously they would break something or include some shit version. 
Do you have a link to some documentation on where to find it? I know they announced that they would work on it, but I've seen no such announcement saying it's landed.
Yes, but it's probably the same process for getting your Python scripts run, so you're already jumping through those hoops anyway. You really need to reconsider your plan if you want to push python out to all Windows users globally just so you can save yourself from an [AOB](http://www.abbreviations.com/term/101600) entry in maybe 2 meetings.
Considering Windows does not ship with a C# compiler, why Python? You would expect that they would promote their own stack first…
no way. As long as they are bundled with every sell computer they will not die
To be honest it wouldn't be terrible if it was would it?
so i wrote a quick and dirty implementation of flexible zip that stops after a set number of iterables running out of elements, which makes it more potent than zip() and zip_longest() combined #!/usr/bin/env python3 def zzzip(*args, countdown=1, filler=None): if countdown &lt;= 0: return elif countdown &gt; len(args): countdown = len(args) iters = [ iter(a) for a in args ] while True: result = [] for idx, it in enumerate(iters): if it: try: result.append(next(it)) except StopIteration: result.append(filler) countdown -= 1 if countdown &lt; 1: return iters[idx] = None continue else: result.append(filler) yield tuple(result) test = [range(8), range(5), range(3), range(2)] for c in range(5): print( list( zzzip(*test, countdown=c, filler=-1 )), 'stopped after', c, 'iterables running out' ) countdown goes toward zero with each StopIteration and once it reaches it the party is over. The code produces: [] stopped after 0 iterables running out [(0, 0, 0, 0), (1, 1, 1, 1)] stopped after 1 iterables running out [(0, 0, 0, 0), (1, 1, 1, 1), (2, 2, 2, -1)] stopped after 2 iterables running out [(0, 0, 0, 0), (1, 1, 1, 1), (2, 2, 2, -1), (3, 3, -1, -1), (4, 4, -1, -1)] stopped after 3 iterables running out [(0, 0, 0, 0), (1, 1, 1, 1), (2, 2, 2, -1), (3, 3, -1, -1), (4, 4, -1, -1), (5, -1, -1, -1), (6, -1, -1, -1), (7, -1, -1, -1)] stopped after 4 iterables running out so how would something like this be an entirely different thing rather than a generalization of existing zip functionality almost for free? 
Fun and educational.
For 99% of Windows users that would just be huge amounts of bloat.
I've run into the problem of having to build packages on a Windows machine with the appropriate compiler &amp; headers. If you use PyPI, binaries might not be available or they might reference libraries you don't have. Running pip3 install -r requirements.txt on a bare Windows instance will eventually fail for projects depending on C extensions. The other option is hoping someone compiled a binary for the version of the library you require and that you can trust it. For cross-platform deployment, this is a problem.
&gt; And of course, in Asia, Africa and South America, Windows has still a strong presence. Windows has much less penetration in those regions. Ironically PC's and Software costs more in those countries. 
99% of my Python package installation and setup woes have been caused by Windows. If a package requires compiling C extensions, I don't even bother with using them on Windows anymore.
Not at all. I'm all for it. My point was just that most of the things people are complaining about are not really related to Python, but instead to the way Windows works.
That was my comment actually, and I'm curious what you mean by your comment. 
Aside from the normal issues that have been brought up, the link says *Ship Python 3 and Python 2 with Windows 10*. Why would Python 2 need to be included? Official support for it ends in 2020. Why include something like that in the newest release of Windows? Already off to a huge headache by including both of them. Anyhow, including Python (any version of it) in stock Windows primarily only benefits developers and administrators. As much as I love Python, it's not gonna happen, nor does it need to. Just bundle the Python interpreter (the version of your liking) with your application and be done with it.
so it's no different than zip_longest() that needs to track all those things, fill missing values and zip together stuff. So why does zip_longest() exist and is not considered an overkill? Also next to nobody gives a shit about the number of concerns in implementation details. Do I need to ask filesystem for bytes or can i ask open() to do magic for me? Doesn't utility beat purity, as evidenced by the recent f"" addition? I swear i thought i was in r/python, which is about a language that values generality over reinventing the wheel and rolling shit by hand C-style at the drop of the hat. 
I did. It was down voted instantly. Same exact post. I always get much more help here.
in other words mentioning infinity is a meaningless argument because predictable scenario is predictable.
I'm seeing it in /r/learnprogramming, but not in /r/learnpython. Is that what you're talking about?
This is something I had not thought of.
Oh yes, my apologies.
NO. Then everybody will be stuck on one version of python. One single buggy defect filled version that cant get updates without corrupting the system and needing to fully re-install windows.
http://blogs.msdn.com/b/powershell/archive/2015/06/03/looking-forward-microsoft-support-for-secure-shell-ssh.aspx Maybe not. I seem to have it as part of cmder and post-git integration.
That was almost 5 years ago sorry, didn't keep them around, but have a look here http://www.mygamefast.com/ . I spent a weekend religiously following the initial tutorials from panda3d website and then spend a few more nights on thae mygamefast and after that, wrote a space shooter based on mygamefast, and then a car racing using the vehicle physics example from the panda docs. I must say the doc and the panda3d forums are very helpful. 
It sounds like a really silly decision on the part of distro maintainers then. Any idea why is it so?
&gt; It will not run on a (non-Arch) system with only Python 3 installed, because there is no command named python anywhere on that system. The only Python command on such systems is python3. No major distro fits this pattern. On what have you encountered this problem? Certainly Debian, Ubuntu, Fedora, RHEL, CentOS, ARch would all be OK with it - in fact most of them would break without it, as they depend on Python. I am not sure about BSD but they seem sane: Not supporting it is an odd choice that is guranteed to break code.
 x = l.search_s( 'OU=Users, OU=HQ, OU=JiveCommunications, DC=jive, DC=jivecommunications, DC=com', ldap.SCOPE_SUBTREE, '(sAMAccountName=%s)' % (user.lower(),))
I see! Maybe I'll throw a comment in. The advantage of keeping the key there is that someone can just run "migrate" and then "runserver" and they're up and running. Thank you for the heads up!
Debian, Ubuntu, Fedora, and RHEL/CentOS all depend _on some version of Python_, but they're all very actively trying to get everything moved over to Python 3, so that by default Python 2 isn't installed. None of them are quite there yet, but on a minimal server install of Ubuntu 14.04, you can `apt-get remove python2.7` and nothing breaks (other than `landscape-common`, Canonical's management service that most people don't use, and `update-notifier-common`, for printing a message when security update requires a system reboot, but those are hardly core parts of the OS). On the current nightly live CD of Ubuntu 15.10, it looks like the biggest breakage from removing `python2.7` is `unity-control-center`, which as far as I can tell is the result of a packaging bug (another package declaring an unneeded Python 2 dependency despite providing a Python 3 module), not any actual requirement for Python 2. The live CD remains usable if you get rid of `unity-control-center` along with `python2.7`. As none of the distros are quite done with Python 2, it remains installed by default under the name `/usr/bin/python`, and Python 3 is `/usr/bin/python3`. But once they are done getting rid of internal dependencies on Python 2, and that package is no longer installed, `/usr/bin/python` will stop existing until someone decides to do something else with that name. I made [a pitch](https://ldpreload.com/blog/usr-bin-python-23), which some folks think is reasonable, but a handful of other folks (both Debian and RHEL/Fedora) seem to think just killing off the `/usr/bin/python` name is a fine approach. (I don't have a good sense of where the BSDs are, but I didn't think many of them had Python in the base system/default install anyway.) The one thing that is guaranteed to break code is to provide `/usr/bin/python` as Python 3 without any attempt at Python 2 compatibility, as Arch does. (Seemingly Arch hasn't run into many problems in practice, to be fair, but I bet that Arch's target audience and e.g. RHEL's target audience are different.) The two languages are incompatible, and since Python 2.7 will continue to exist until at least 2020, it's reasonable for it to be installable as `/usr/bin/python`, even if it's not there by default. If Python 3 takes that over, what happens if you download some Python 2-only code from GitHub and try to run it? If you `apt install python2.7`, where is it supposed to end up?
Pretty awesome actually. Had a lot of fun and learned some stuff at the same time.
This is perhaps the major failure with Windows and Python. Anything more than trivial usage requires C compiler or prebuilt libraries. Even on a Mac there is less resistance to getting a Python installation to work as XCode is free and easy to install. 
This thread highlights one issue with the Python community and with the Windows community at large, that is the obsession with the past. If the intent is to offer a new feature to Windows, Python, there is no rational reason that the 2.x python series should even be mentioned here. New capabilities shouldn't be focused on the past but rather should move forward to extend the operating system. I just find it perplexing that so much of this thread is focused on backwards compatibility for a feature never offered by MS. 
I might be mistaken, but Linux distros and OSX aren't just shipped with Python; Python is a fundamental component needed for their operation.
Because I don't trust Microsoft to do it right and I think that anything that is shipped like this will lead to version issues down the road.
So I guess I'm going to spend rest of my life with those stupid simple errors. Sigh... 
&gt; You just pick the smallest version your target, and you are good for the whole major version. Or you could do what they do with .Net and just install every version as needed. Otherwise, you'd use Python 2.2 for Windows XP, 2.6 for Vista, 2.6 (or maybe 3.1?) for Windows 7 and 2.7 or 3.3 for Windows 8. Those are lousy choices. The problem is Windows users don't update frequently enough. Like most people, I skipped Vista and Windows 8 and plan to skip Windows 10. It seems crazy that you can't easily install multiple versions of Python, so python22 or python27 and python35.
[removed]
/r/HomeworkHelp 
But what if I want to have None as my filler value?
Great recap of the string formating situation and it's future 
Please submit this to /r/LearnPython, not /r/Python. Thanks.
True, i'm pretty sure they would deploy one of their own home grown languages like F# before a 3rd party language.
In all 3 cases it was included because a few default included apps in each OS *used* Python not because they wanted to add it in for fun. Also I think newer versions of OSX have stopped shipping with it by default. Windows has it's own languages to push and did not write any of the default software in Python.
Do you know how to best remedy problems with third party libraries not patching to support new versions of a platform? I'll give you a hint: not by including a dated version of the platform in a long term supported version of Windows. 
They include the latest version by default in 10 at least, 3.5 and older I had to activate during the first install of an app that used it.
&gt; Because right now Python is the best While an opinion if this was true and universally accepted this statement still says what's wrong - it's what's liked right NOW. If they included everything that was popular every time they would be in trouble, they design their own scripting and compiled language families so they can keep it integrated and consistent across all versions. 
Hey so you might not need to do that to debug. In debug mode, if flask crashes while processing a request the webpage will turn into an interactive interpreter in which you can jump into _any_ frame in the stack. (which would probably be why pycharm doesn't attach; because flask technically doesn't crash)
 null = None I almost feel dirty.
It isn't about Python being someone's favorite language. Python is rapidly rising to the top of the list of most desirable languages to know. Its robust, easy, can run anywhere there is a C compiler (which is almost everywhere except windows), and powerful. Its not a fair comparison to a language like Ruby, or Lisp, or whatever else you want to list, since it is so much more popular than those are. 
Or `/usr/bin/python` is linked to `python3`. Like on Arch. Which breaks a lot of python scripts. (I normally just sed the source to use `#!/usr/bin/env python2`)
... you can just install it
I think you have this backwards. Microsoft has a great track record of supporting legacy systems. It is so great that they probably innovate less often than they should in their OS and when they do people complain. In fact, they have realized this recently and so the move from 7 to 8 to 10 has included phasing out a lot of legacy support in systems that didn't need it anymore.
I like that almost everywhere except windows excludes most computers.
Mmmm.... How about Lua instead.
I've found the online book ["Python 3 Porting"](http://python3porting.com/) to be quite useful. Also, O'Reilly have just release a [short video tutorial series ](https://player.oreilly.com/videos/9781771374514?toc_id=223674) on Python 3 porting.
Maybe they will change the whole file extension mess too? 
hello when I type mysqladmin -h localhost -u root -ppassword create reddit this shows up:mysqladmin: connect to server at 'localhost' failed error: 'Access denied for user 'root'@'localhost' (using password: YES) I googed around and can't find solution
It is debatable whether you can call this *tracking*, as it's rather more an example of *detection*.
This is awesome. And thanks to you all for posting in /r/Python 
I'm not going to get into this zip/zip_longest argument, but the issue you bring up is easily solved with a [sentinel](http://www.ianbicking.org/blog/2008/12/the-magic-sentinel.html). 
Besides this, you can't really install or update any packages in the system Python without potentially screwing up your whole system. You have to have a virtual env if you want. For this I wouldn't mind if they just hid the system python under a different name.
python installs pip installs python installs pip...
 for c in [1,3]: print( list( zzzip(*test, countdown=c )), 'stopped after', c, 'iterables running out' ) $ ./zzzip.py [(0, 0, 0, 0), (1, 1, 1, 1)] stopped after 1 iterables running out [(0, 0, 0, 0), (1, 1, 1, 1), (2, 2, 2, None), (3, 3, None, None), (4, 4, None, None)] stopped after 3 iterables running out problem? 
&gt; When zip_longest was introduced, Python didn't support keyword-only arguments, so it would be hard to do. Since zip accepts any number of iterables, you would have to put the keyword at the front, which means you couldn't give it a default. but we are in py3 now and ancient history doesn't matter. Many things were upgraded, extended and/or rolled into an unified interface even at performance penalty, at least initially, eg range()/xrange() &gt; There might be ways around that, by collecting **kwargs, but the implementation is messy and ugly. named_tuple is messy and ugly with its evals, but people don't use it for its internals out of sight, but for its exposed functionality. &gt; Also, there is a design principle espoused by Guido that functions shouldn't (as a general rule -- there may be rare exceptions) take an argument that is (nearly) always passed as an constant. huh? `sorted( reverse=True )`, as basic building block as it gets. That's why i wrote my post in the first place because i noticed a lack of symmetry. The core functionality is the same in both cases, a relatively minor detail is different and yet in one case it's solved by a simple keyword within a one true tool and in the another it's solved by writing a superset algo and throwing it into a peripheral module. and if longest=True/False is bad, then maybe instead of true/false the function could expose the counter to the user? 1 being the default zip() behavior, len(args) being zip_longest()? Look at the python pseudoimplementation of zip_longest. https://docs.python.org/3/library/itertools.html#itertools.zip_longest It implies there is a master counter and it goes down towards 0, which is pretty much what i wrote in my quick and dirty example. There is EVERYTHING in there that is required for a generic 1..len(args) solution. It's just that somebody didn't see forest for the trees and didn't expose the counter. What would be the problem in that? You see somebody asking for something between zip and zip_longest and you have to come up with monstrosity that would be for free if the counter was exposed. Just look at that completely intuitive solution slapping a bunch of itertools toys on top of each other. http://stackoverflow.com/questions/13341224/is-there-a-middle-ground-between-zip-and-zip-longest The only reason i could see for separate implementation (fast zip/generic zip) would be huge performance penalty in case of N=1, but i am not seeing it &gt;&gt;&gt; timeit.repeat('list(itertools.zip_longest(range(10000), range(10001), range(10002)))', repeat=5, number=100) [0.208297497999979, 0.18986536300008083, 0.18984539599989603, 0.19005514699995274, 0.18995707700003095] &gt;&gt;&gt; timeit.repeat('list(zip(range(10000), range(10001), range(10002)))', repeat=5, number=100) [0.19202816699998948, 0.17055670800004918, 0.17061998700000913, 0.17034331600007135, 0.17032316699999228] and even then, if this marginal difference if any is a problem (but why would it be, python3 reportedly sacrificed a lot of performance during cleanups and improving generality?) you can always write a fast track path. Everybody who ever wrote function prime number check did so without splitting shit into separate functions (fasttrack code with %2 for evens and then going to grind with odds ( 3; sqrt(); 2). Writing less than pure code hidden behind pretty apis for performance reasons is a fact of life. if counter == 1: fast zip algo else: generic zip_longest algo
Yes, did you replace yourpassword with the password you created when you installed mysql?
&gt; Python can do simple script better than powershell as it has a bigger stdlib I agree that Python is much better language, but the statement that Python has a bigger stdlib is probably false. PS can readily use any .NET library including the huge-huge BCL (installed v3.5+ where powershell is available).
Don't worry about doing it "the right way" - that will paralyze you. Just do it and in time you'll learn better ways.
OK I think I understand your point. In (some near time in the future) when 2.x isn't installed by default, then `usr/bin/python` will still default to 2 and programs will be unable to find the interpreter. I had thought that when Python 3 was the default, they would switch `/usr/bin/python` to point to 3 like Arch, but Ubuntu etc seem to disagree.
1. Don't like the work you're doing? Get the fuck out. 2. Run/ride a bike/go to the gym. Don't get fat. Get in shape. 3. Make sure your working environment has clean air. If not, get the fuck out. 4. Sleep enough and sleep well. 5. Your work doesn't complete you or define who you are. Don't work overtime, or work so hard you can't enjoy the evenings. Leave that to managers who get paid twice your salary. 6. You do not have time to spare. Go out of the house. 7. Don't like what is happening? Change it, remove it, or get away from it. Aka, listen to your body and your mind. These are the things that have fucked me up over the last ten years.
You could use py2exe
&gt; PHP web applications gets a clean slate at the start of every request. With python, this will be different. If you do not keep this in mind until you completely forget that model from PHP, you might end up with weird bugs. Can you propose a resource that explains the python's object lifetime between requests?
Is it for creating official API's ? Or for unofficials API's like scrapy-rt does ?
All the time spent to think about: 1) data structures, function/method parameters and return values 2) separation of concerns is spent well. A good overall design of these leads to good code. 
Maybe this: &lt;http://quant-econ.net/py/index.html&gt; The course teaches how to set up a Python installation and basic programming in Python (imports, lists, for-loop, ...) before diving into financial topics with Python as a tool. And you'll learn a little about NumPy along the way.
Author of the post here: Next week I'll be doing a true post on *tracking*, where you can determine up, down, left, right, etc. as the ball is moving in realtime.
What is your baud rate? How fast can your microcontroller handle incoming bytes? At what rate are messages sent to the microcontroller? If speed is your problem, you can change the baud rate for the computer with pyserial when you open your connection to the micro. Remember, you'll also have to change the baud rate on the UART of the microcontroller. You'll also need to make sure your microcontroller is running fast enough to empty the UART RX buffers. 
It's at 9600. Shouldn't pyserial run at that by default?
I haven't read through it yet, but I'm wondering: if a price series was just constant, would the randomness tests think it was non-random? Because a constant price is consistent with price being a martingale (i.e., no predictable profit opportunities).
9600 is the pyserial default. I'm asking you if 9600 is fast enough. 9600 is bits per second, including start, stop, and parity bits. How fast do you need to send your packet before another ready to send? Do you have a buffer set up to handle any potential overruns on both computer and arduino side? 
No. My vision is to apply pressure on the developers of Numpy, etc to support you, instead of letting Python become the next IE 6 of the windows world. 
Stop reinventing wheels and learn the built-ins and itertools ASAP.
It is for creating official API's. Thanks for asking. There is a sample project up at https://github.com/buckmaxwell/sample-neo-api. 
That is an interesting thought - I'm still thinking about it but what I can say is that the code works with returns, so a constant price series would result a sequence of zero returns which are represented by the binary string '01'. So the binary representation of the price series would be 010101 ... which obviously exhibits a pattern and would therefore fail almost all of the statistical tests (except the Monobit). 
I recently used Python OpenCV in a project for work and used this guys blog to do so. So many things are badly documented elsewhere, I found it really helpful. Installing is still a major pain, I couldn't get it working on OS X at all, although it worked fine on Windows after some fiddling.
You could check out these [Finance with Python Tutorials](http://pythonprogramming.net/dashboard/#tab_finance)
Thank you :)
Thanks :)
I kid you not: I went to this subreddit today hoping to ask a question on a gui for pandas scripts. Thanks! 
bummer, looks like this repo has been taken down and the package that was once on pypi is gone. C&amp;D? What's the story, benkroop?
Excellent work. Plus, your code is very good. Just one thing: [module/package names should be lowercase](https://www.python.org/dev/peps/pep-0008/#package-and-module-names).
&gt; bummer, looks like this repo has been taken down and the package that was once on pypi is gone. C&amp;D? What's the story, benkroop? wow.. and /user/benkroop is gone too... 
Best thing that I could say to my younger self is: stop asking questions that don't have finite answers. And, know when good enough is good enough by getting the business to tell you. Also, work your ads off _before_ you start a family or get married.
As an educator using Python, this is exceptionally exciting. Spyder has been serviceable, but it's never been tuned for beginners. And these course creation tools seem stellar!
Do I want a buffer? Cause if its running off a live stream I want it to only worry about what's happening in this frame, and to ignore previous frames.
If by finance you mean stocks, there's an awesome video series on YouTube that's at a very beginner-targeted level. Search for "python matplotlib stocks" and you should find it - there's a playlist of about 20 videos. (Let me know if you can't find it, and I'll look it up for you later tonight.)
First question no idea, but why would you need one as Python has been described as "pseodu code? Second yes :)
There is a book as well - http://shop.oreilly.com/product/0636920032441.do
I'm not sure what you're generally doing with Macros, say encapsulating repeatable code or looping, but all of these are built-in functions with Python e.g. %macro whatever(var); data new; set ....; run; %mend; Can simply be encapsulated with functions def whatever(var): #Do functions pass 
I am not very familiar with SAS but [pandas](http://pandas.pydata.org/) is a good tool to look at and will do a lot of what you're describing. It even has some docs that compare pandas and SAS - http://pandas-docs.github.io/pandas-docs-travis/comparison_with_sas.html
I love a nice HTML document. Hate opening PDFs. Great job!
What did well for me was joining an open source software community. It gave me the opportunity to talk to, learn from, and work with people who have been developing software for a long long time. It takes me around the world to join meetings, sprints and conferences. It's really nice to work on stuff because you want to, not because a company is pushing you to do so :D
So say we all
[So Say We All](http://i.imgur.com/zRG0Kcb.gif)[!](https://github.com/convenient/SoSayWeAllBot)
How do these NIST standards compare with data compression based methods (e.g. Lempel-Ziv or context tree weighting)? This paper specifically looks at forex markets but the same methods could be applied to other market time series. http://www.eng.tau.ac.il/~bengal/28.pdf
Wow, that is way easier than I expected. Thanks!
I really like this! Nice job! Can I ask what framework you used in developing it?
Thanks! It's built using AngularJS and Node.js.
Python questions go in /r/learnpython
why would someone need to import a module in func ? 
thanks so much for taking the time to write back to me. I'll give it a try.
Looks like Anaconda Cluster isn't available to the little guy?
It looks like you have way too many dependencies. I prefer to use the smallest subset of dependencies.
What are you trying to install it on? Tbh it might have been because I was using the El Capitan beta. If it's Windows I put together this for the group: &gt; Install Python 2.7.10 &gt; Install Microsoft Visual C++ Compiler for Python 2.7 &gt; Check that the python installation has been added to the PATH variable: Control Panel -&gt; System and Security -&gt; System On the left hand side, click the option 'Advanced System Settings' Click 'Environment Variables' Under 'System variables', select 'Path' and click 'Edit' Add to the end of this line: ';C:\Python27;C:\Python27\Scripts' (without the inverted commas). If your installation directory is different then just change it to wherever you installed it. &gt; Open command prompt (cmd) and run the following commands: pip install numpy pip install matplotlib (not strictly necessary but worth having). &gt; The tricky(ish) part - actually installing OpenCV. Download OpenCV 3.0.0 binary The installer is actually just an extractor - choose C:\opencv as the directory to extract to. Go into C:\opencv\build\python\2.7\x86\ and copy cv2.pyd to C:\Python27\Lib\site-packages Go to the Environment Variables window again (from step 3), and under System Variables, click New, For Variable name enter 'OPENCV_DIR' and for variable value enter 'C:\opencv\build\x86\vc12' and click OK. Edit the 'Path' variable again as in step 3, but this time add to the end ';%OPENCV_DIR%\bin' You should be able to use OpenCV now but as a sidenote I've found you need to specify exact filepaths whereas in most tutorials relative paths work fine. All of the functions are, somewhat confusingly, in the cv2 namespace.
that's weird I thought I was on the right subreddit. I've deleted the thread
Unfortunately at the moment its not. Hopefully soon you should be able to use it for free with a 4-node limit. You can find some free (not as complete but functional) alternatives on github if you search little bit ;)
Ideally, you won't buffer. In the case of real time, you'll just chuck anything you don't have time for.
Thanks for your interest! I agree, and I use Python 3.x whenever possible. In the blog post, we used Python 2.7 in the conda environment because PyHive and Impyla (used by Blaze to talk to the Hive/Impala servers) only currently work with Python 2.7.
Crackers.
 &gt; But why do you need portability when Microsoft has all you need? Except Python. But why do you need python when Powershell has all you need?
I have been that route and the problem with that approach is that those images get outdated really quickly and updating them is a pain. Anaconda Cluster (and other tools) start from regular (ubuntu or centos) images and bootstraps the needed frameworks, it take a little longer but in my experience its much easier to develop and maintain.
The short answer is "they probably don't, so they should stop." There are conceivable situations where it would make sense to put an import inside a function, but they're often ridiculous and I highly doubt the average programmer would ever encounter one. In ninety-nine point a bunch of other nines percent of scenarios, the benefit of having all your imports run first at the top of the file like normal so it's clear what's going on is superior to doing it any other way. You might want to only import something until just before the code that relies on it runs so you aren't wasting resources on a module you won't use, but it's highly unusual for an import to be some kind of unacceptable luxury. Most Python programmers aren't working on highly optimized or embedded projects where that amount of resources is a serious consideration. If you're running a script on a desktop, you can pretty much import as much as you want and it won't matter. The seconds you'll waste over the script's lifetime aren't compelling, especially if it takes a human an extra few minutes (or hours, or days) to figure out why something broke because he can't make sense of the imports. Note that this only makes sense if you expect that the function won't actually run most of the time. If the script uses the function repeatedly, you'll run the import more often by putting it in the function than you would by just having it up at the top like normal. Also note that subsequent imports aren't as slow as the first one since the module is not re-imported from scratch. This reduces but does not eliminate the performance hit from repeated imports. Another advantage might be version conflicts. I've never personally encountered a dependency issue so complex that it made sense to put an import inside a function, but that doesn't mean no such issue exists. I've also read this is a realistic way to resolve circular imports (module X imports module Y and then defines Z, Y calls Z, but Python doesn't know about Z yet because it hasn't gotten to that part of X) but plan A for resolving circular imports is to avoid having circular imports. [This stackoverflow answer](http://stackoverflow.com/a/128859) provides an interesting view: If you expect to move a self-contained function to a new file, it's much easier to see which dependencies will come with it if the function imports everything it needs and there are no top-level imports. This makes the most sense in modules that are collections of utility functions you expect to run independently of each other. Each function carries its own baggage. I suspect that most projects don't resemble his and aren't composed of so many self-contained parts, but it's something to keep in mind.
I think I've posted about it from this account before...it boils down to the shortest path problem, and integer factorization. They can be solved, but it involves some form of trial division, followed by generating a [sum,difference,product] to a known modulus, as you traverse the puzzle to generate the final [sum,difference,product]. The pathing defines a binary value, 2 bits at a time. Currently it is used for identifying a known peer over the internet, using a hint system (pathing information) but it requires a secondary communications channel, its caveat. I think it would be perfect for something akin to generating a cryptographic identifier to a group of peers, but it takes too damn long in its current state.
CentOS 6 doesn't even support docker...and it's not THAT old. We had to put in a request to upgrade our VM's just for docker support.
I guess the installation/setup process could all be scripted with a bash script. Of course this would work only if nothing goes wrong in the process!
no problem!
Use version control! It took me 2 years before I started using git religiously. I would have gotten off the ground as a programmer much faster if I had learned git at the beginning.
/r/forhire is a good place to start. Also from the sidebar: http://pythonjobs.github.io/ and https://www.python.org/jobs/
There are also more reasons why an static image will make thing harder. In Hadoop/Spark and more distributed tools have a couple of config files that usually point master/compute nodes using the hostname or the IP. If those values are hard coded then reusing an image will not make those nodes connect, you can of course set /etc/hosts but then you have to edit that file in all the nodes or have a DNS server. In Anaconda Cluster and similar tools (again, github search ;)) we use a configuration management tool (salt) instead of writing a bash scripts because no one wants to maintain a huge bash script. Salt makes it easier to maintain and write the logic getting the same results as bash, it also makes connection much faster. Like you mention it only works if nothing goes wrong in the process which of course happens from time to time, specially in non tests OSes. This is a similar approach to what Cloudiera does for Cloudera Manager, in that case I think they rely only on ssh and support a fixed number or linux distros and versions.
I'm one of the lifers. I'm just expressing my thanks for a cracking list of resources which will be useful to everybody.
No, there is no reason and thats basically what Anaconda Cluster is: Salt instead of ansbile + some curated formulas for spark/impala/and more + Apache libcloud to create instances in the cloud.
The only place I've seen it is in custom commands defined in setup.py. Say you want `python setup.py test` to run py.test when called. You need to subclass `TestCommand`, [something like this](http://www.jeffknupp.com/blog/2013/08/16/open-sourcing-a-python-project-the-right-way/). class PyTest(TestCommand): def finalize_options(self): TestCommand.finalize_options(self) self.test_args = [] self.test_suite = True def run_tests(self): import pytest errcode = pytest.main(self.test_args) sys.exit(errcode) If you `import pytest` at the top of the file, then it won't run because pytest isn't installed until setup() gets called and your `tests_require` argument is read.
I can also help out with that. I've been working with Python for quite some time, and have done scraping for previous jobs (specifically retail stuff). Send a message if anything.
Looks really cool. I would suggest posting this on hacker news, r/datascience, datatau , r/pythonstats and pydata google group 
I would starts with this excellent intro slideshow: http://nbviewer.ipython.org/format/slides/github/twiecki/pydata_ninja/blob/f3476390ea57fb47bff29dc1720c73594fa26379/PyData%20Ninja.ipynb#/ 
Windows only? Fuck you too.
Thinking about this more, I think this is crucial. The interesting thing is whether markets are predictably wrong, not whether they are predictable. (Since prices are martingales, the present price is the best predictor of the future price.) It's only interesting if you can beat the market. Otherwise, my example of an asset whose price remains constant (e.g., because of no news) would be flagged in your analysis, even though there's no inefficiency!
I must not be searching the right terms on Github :(
Why some clusters if you could smack it onto 1tb ssd drive and filter it like there was no tomorrow? 
You could definitely do that with this particular data set! Following a similar analysis with [Dask and Castra](http://blaze.github.io/blog/2015/09/08/reddit-comments/), you could efficiently query the 975 GB data set on a single beefy machine. The purpose of our blog post using Impala is to describe a setup that you could use with much larger datasets on the order of terabytes or petabytes, and using Blaze, you can write the same queries regardless of the particular data storage system, either 100s of MBs of CSV files or 100s of TBs of data in an Impala cluster.
blaze by itself sounds pretty amazing...
I heard about the boto/boto3 difference today and have done some checking. The issue I'm having with boto3 is : How do I extract the Access and Secret keys for use in credentials being passed to RedShift? This has probably morphed into more of a boto/boto3/aws question than a generic python question but I hope you can still help.
Investigate the IPython.embed function (you have to import IPython), it will start an ipython session in the current scope. You can also use ipdb for debugging purposes specifically, but you can drop into it from ipython anyway. 
I can definitely help you here - I've recently implemented web scrapers for a major real estate network, pulling down sold listing data from a number of websites for the purpose of market monitoring. Your goal should be relatively easy to achieve. Message me if you're interested!
My guess would be a single pass statement.
Thanks! I have achieved what I wanted with 2 simple steps: 1) Start a separate Worker and specifying a name for the new queue: PS&gt; celery worker --concurrency=1 -A celeryapp -Q Qone 2) Sending the task to Celery: TaskQone.apply_async(args=...., queue='Qone', routing_key='Qone')
Send me a PM if you still need help. I have experience in many languages including python and have some projects you may be interested in.
Noob here. Why download all the data? I haven't looked but there is probably a reddit api you could query, no? 
I don't know how I did any data analysis before I started using pandas. I think it is a must use if you are reading tables of data (or at least highly recommended).
You cant run queries without the data downloaded
/u/Stuck_In_the_Matrix used the reddit API over a 200 day period to query and gather the 1.7 billion comments, then [posted the data for download in July 2015](https://www.reddit.com/r/datasets/comments/3bxlg7/i_have_every_publicly_available_reddit_comment/csxknkt). We downloaded the data, decompressed, and loaded onto Amazon S3. Then, for this analysis, we loaded the data onto the cluster, converted to Parquet format, then loaded into Hive/Impala. Then we can perform queries on the entire data set in 5-30 seconds instead of 200 days. :)
http://stackoverflow.com/questions/32623492/gunicorn-server-not-working
Thanks for your work in making this awesome data set available!
threejs with a websocket to tornado is actually a pretty good solution. The realtime and interactive plotting tools in python are pretty lacking compared to the flexibility the browser gives you. I wrote a simple 0mq-&gt;websocket bridge to do this type of thing so both the data generating code and the js could run in the same ipython notebook. It largely got supplanted by later improvements to bokeh but they don't seem to support 3d yet.
It's the same as why use any framework? It's a common platform providing a set of pre built services, with a defined structure to enable you and others to pool your efforts for the common good. It enforces certain norms and conventions in order to standardize configuration and deployment.
Huh, well maybe that's not such a bad idea after all then! I'll start throwing together a quick and dirty visualizer + socket and see how it goes. Thanks for the tips!
matplotlib *should* work fine with Python 3. Does it just not work at all on Ubuntu? What errors are you getting?
In LaTeX you can use the `listings` package. Very useful if you want to generate reports. See [here](https://en.wikibooks.org/wiki/LaTeX/Source_Code_Listings) for more. \documentclass[12pt]{article} \usepackage{listings} \title{My python script} \date{} \begin{document} \maketitle \section{Introduction} Let me tell you this: my python script is really cool! \section{The script} \lstinputlisting[language=Python]{source_filename.py} \end{document} 
You can have a look at the [pyqtgraph](http://www.pyqtgraph.org/). Its easy to install and quite powerful. 
Only two of the tests deal with non compressiblity namely the Universal test (which could not be applied due to insufficient data) and the Linear Complexity test which uses the size of the linear feedback shift register computed using the Berlekamp–Massey algorithm as a measure of compression. The markets did fairly well on this test i.e. came up random. In a follow-up I'd like to extend the suite with some other tests. Thanks.
Did you try IPython Notebook? You can eventually paste your code in a Notebook session, then "File &gt; Print preview" and this should be okay. And you can have more than plain code in a Notebook (text, formulas, interpreter outputs).
It might be some sort of problem with the backend (complete guess). Can you try doing: import matplotlib matplotlib.use('TkAgg') ...at the beginning of the script? There is an old [SO post](http://stackoverflow.com/a/12685979/754456) about interactive mode requiring a millisecond pause to allow matplotlib to update. I see you have the pause in there, but it's *before* the update. Does moving it after help?
Because YAML is simpler than Python last time I checked :\ I haven't really looked that far into Ansible though, I prefer Salt.
I've recently been using [Vispy](http://vispy.org/), in particular I replaced all my use of mayavi with it. Its high level stuff does exist but isn't fully complete (though it's being actively developed) but it's powerful and you can do most things even without learning much about the opengl backend. There's also [glumpy](https://glumpy.github.io/) which is faster for some things and has a different api, but last time I checked it was probably a bit lower level and wasn't so well documented. That could have changed though.
Just use None and check for that. def kek(args): if args: return ['monkey', 'nut', 'fire'] foobar = kek(True) if foobar is None: # handle error else: # handle normal case
I need more cases than two.
Second on pyqtgraph. It's easy to use if you follow the examples, integrates with pyqt and has high performance. 
Sublime does a lot of things, but print is not one of them. I never understood why.
You can use the `Enum` library (horribly contrived example): from enum import Enum # Enum(descriptive name for enum, space separated list of values) Status = Enum("Status", "ready working done") def something(): return Status.ready if something == Status.working: print("Currently working.") elif something == Status.done: print("All done!") elif something == Status.ready: # do work 
Oh, no, true, but it exports to HTML which you can print from a browser. Good point, I totally forgot that.
Oh you can‽‽ How do you export in Sublime Text 2? I can't seem to find it.
Sharing some psudeocode would really help in working out what the pythonic solution would be. As-is, I'm not sure if you should be raising and catching exceptions (they're a little different Python and C), or just returning some value. TL;DR - the solution to the question you asked is apparently not good, so I need more info on the problem.
It's possible that, for your use case, a Python script is just as effective as an Ansible playbook—this is definitely the case if your script is less than 10 lines. In that case, use Python. When you're doing nontrivial system setup, though, Ansible can be valuable: it allows you to rely on their implementations of many common system administration tasks rather than write them yourself.
The app is for tracking pen testing results. The APIs are basically CRUD for a number of different entities (Job, Target, Vulnerability, etc.) An example of complexity is that when we load/save a Job, we want to access two levels of relationship: Job -&gt; Target -&gt; Vulnerability.
I've got a new project coming up that seems to have similar requirements, and I'm going with django and DRF. The nice modular structure and lack of boilerplate sold me.
Very cool! 
That's also how [Pony ORM](http://ponyorm.com/) does it's magic: http://stackoverflow.com/questions/16115713/how-pony-orm-does-its-tricks/16118756#16118756
Then return an int or a string if you want to be more explicit and then have a dict mapping the possible outcomes.
Because now you're not maintaining the glue classes between SSH and the config, and because at your next job they'll know what Ansible is, as opposed to "our custom python deploy scripts"
Advanced 3D rendering can be done in VTK, which should support python3 AFAIK. Matplotlib3d also should work in Ubuntu - what python are you using? If in doubt I strong recommend Anaconda python or Enthought python, since they should be set up to Just Work (i've often found using system python on any platform can be hard when you want to use graphics libraries)
I cannot recall if the animate function works with 3D matplotlib, but here's a [tutorial on the animate function with matplotlib](http://pythonprogramming.net/live-graphs-matplotlib-tutorial/). I share this since in your comments and OP it looked like you were trying to have live graphs with matplotlib, without using animate. You may need to stray away from Matplotlib, and maybe even Python for this job. You can have python doing the data, but then feed to something else, there are tons of javascript and webgl graphing tools.
I build/maintain a smallish web site with an API aspect to it. I've moved from web2py with it's built in ORM to flask/SQLAlchemy to postgresql returning json as result and just piping that to the client. _by far_ the bottleneck is in decomposing request/auth/composing response. The actual query doesn't take much time at all (relatively). So, my solution, is to get as close to the metal as possible in request/response, forego traditional http auth in favour of an API token method that requires some hashing of the request headers, and let the DB deal with authorization and composing the response. flask (for routing mostly) + sqlalchemy.core + a fair bit of postgresql. The result is a horrible frankenstein of a thing, but it's as fast as I can get it without moving from python. I don't know that this is state of the art. I work somewhat in a vacuum. It's my 2¢ anyhow. 
(Note: I did not make this)
That is interesting. I'm not as performance sensitive as you, but it's always good to be efficient. How do you have postgres perform authorization?
Thank-you. I'm getting the feeling flask-restful may be the answer here. Authentication is handled fine by Flask-Auth. And right now I don't do much in the way of authorization or pagination - although this is likely to change in the future.
Hello it works till sudo supervisorctl reread &amp;&amp; sudo supervisorctl update, when I run the server it gives me page not found. I ignored it and ran through the commands, but "sudo ln -s /etc/nginx/sites-available/reddit.conf /etc/nginx/sites-enabled/" gives me ln: failed to create symbolic link ‘/etc/nginx/sites-enabled/reddit.conf’: File exists which occurs probably because I tried more than once. I restarted nginx but it still doesn't work. Can you please help me out? 
Do you plan on having markup environments besides reST? For example, I would prefer Markdown (CommonMark in particular) to reST for creating print documents. Plus, supporting a LaTex math environment as an extension would probably be necessary for adoption by mathematicians. Maybe Rinohtype could have a system like troff, with layers of environments and their respective pre-processors. That would fit well into your current model, since Rinohtype already has a base language and one pre-processor.
as someone working in finance and learning python, your videos have been invaluable.
I do need to check out - thanks for the reminder. I know people rave about it. I was looking for something web-based to start, and hilite.me seems to do what I want.
I'm struggling to see why installing Jupyter and using the WebUI is difficult... &gt; pip install jupyter &gt; jupyter notebook
In Python you need an object to have a method. Your examples don't give either.
Small integers are only pre-baked in CPython.
You've asked for a Mac app in addition. There is an OS X-native Python Notebook if you prefer: http://nwhitehead.github.io/pineapple/ I just discovered it this morning, on Reddit.
My domain is pretty pedestrian so I'll avoid getting into too many specifics. The API keys I mentioned map to membership in groups, which can inherit from each other in a tree structure. A single user (API key) can have membership in multiple groups. A lot like Active Directory. The 'business logic' for determining what an API key can see/affect involves a lot of testing of group membership. This used to be done in python, which required reading a lot of group/membership data into memory, and then a lot of hairy logic wrt. cacheing and when/how to invalidate the cache. Over time this got migrated to the DB, membership testing becomes a case of invoking a function (stored procedure) with the user as parameter that reduces the membership tests to a table that contains per group, what are the rights of the current user. Finally, I took some inspiration from this: http://blog.databasepatterns.com/2014/12/postgresql-row-level-security-rls-vpd.html I don't use the USER structure in postgresql because of my more complicated membership use cases, but the introduction of WITH CHECK OPTION in 9.4 allows me to restrict select and _insert/delete/update_ based on the 'role' that the current user is assuming. That's the basic technique. I admit that I've tied my fortunes to postgresql pretty heavily, but I feel that it's a safe bet. All that to say: if you don't need the performance, stick with Flask/SQLAlchemy. It's a lot easier to write/debug/and maintain. 
[removed]
Looks great, don't know how I hadn't heard about this until now. I'll give it a shot, thanks!
You can avoid launching in the command line if you use the anaconda launcher - this is probably a better way for newcomers to the notebook Cool find on pineapple!
Great material, thanks a lot.
[PyChess](http://www.pychess.org/) and [Lucas Chess](https://github.com/lukasmonk/lucaschess) are witten in python. Surely there are more.
People use Python and aren't able to install libraries/programs from the terminal? How else are they installing libraries or running Python? How does the browser UI get in the way?
The app doesn't run because it cannot find flask_reddit.users.views I believe.
I'm sorry I misunderstood your problem. I always just set the the credentials in the environment, both locally and in production. Then I get them with `os.getenv('AWS_ACCESS_KEY_ID')` etc etc. Sometimes I'll use [django-environ](https://github.com/joke2k/django-environ) which will check both a local .env file and environment variables for the given key. Which makes it real transparent. 
Remove the config file and try again?
/r/learnpython
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Show them that you've tried to solve your problem and you can get all the help you need. Cheers &amp; best of luck!
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Show them that you've tried to solve your problem and you can get all the help you need. Cheers &amp; best of luck!
I thought he was looking for advice on how to get a programming job without having to prove he can code, lol. I'm still not 100% sure what they are even asking....
If this could work with the shell_plus Django extension in a virtualenv, I'd use it every day.
https://github.com/drewconway/data_science_box https://github.com/danielfrg/datasciencebox
Nice initiative ... but, the very first tutorial about variables starts with a huge misconception, which confuses a lot of people that are familiar with other languages. In the tutorial, the author talks about creating a variable and assigning it a value. For example, let's consider a = 7 He says that writing a creates a variable, then that the equal sign a = is used to assign a value. This is NOT how Python works. In Python, what is on the right-hand side of an equal sign is an object (which may results from some computation). What is on the left-hand side is a label (or named) used to reference that object. In other words **names refer to values (or objects)** (think of an arrow pointing from the name to the value); you do not assign a value to a variable (think of an arrow pointing from the value to the variable). Anyone interested to find out more (and expressed much better than I have done above) should really have a look at http://nedbatchelder.com/text/names.html 
Read it all. Learned something or two. Very well done, content, language, examples, references... This is a fine piece of work!
Learn Python the Hard Way is something that we encourage our students @CodingCampus to pick up. There are some great resource s on Lynda and Treehouse that we use to explain it to students as well.
I find it messy to have the notebook UI nested inside the browser ui. Its the same problem all web-apps have, you're basically running and application inside an application, with keyboard shortcuts overlayed/conflicting each other and UI elements repeated - e.g. you have the "file" menu from the browser and then the 'file' menu from the notebook inside it. You have the extra visual noise from ui elements you need for browsing but not for the notebook. It's just not very neat design, and on a laptop screen it eats quite a lot of space. As for how people are using libraries without the command line, they could be using a python distribution and simply work only with what comes installed, editing and running using IDLE. Everyone has to start somewhere...
To write `.xlsx` files I have been using [xlsxwriter](https://xlsxwriter.readthedocs.org/). To read `.xlsx` files there is [openpyxl](https://openpyxl.readthedocs.org/en/latest/). If you have to work with `*.xls` files then there is xlrd for reading and xlwt for writing. You might want to check [this link](http://www.python-excel.org/) since they do have some relevant links to docs, source code, discussion, etc. about working with excel files from python.
Thanks! :)
Why use Python instead of manually flipping bits in memory?
Yeah, "beginner tutorial" and "complete knowledge" are quite contradictory statements. More like "complete tutorial containing beginner knowledge" or something.
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Show them that you've tried to solve your problem and you can get all the help you need. Cheers &amp; best of luck!
"Learn Python the Hard Way" is excellent for teaching and learning Python **2**, BUT, the authors really need to update it to Py3. By now, not supporting Python 3 is simply a bug. It's just wrong, and a disservice to students and to the Python community. Py3 is the present and the future; Python 2 is, by now, legacy. (Don't believe me? Ask Guido.) Every big important package in the Python scientific stack has long since migrated (only exception I know: OpenCV); it's unlikely that XYZ Corp's Py2 applications are more complex than, say, numpy or IPython (unless XYZ's complexity is self-inflicted and for complexity's sake). Py3 was introduced in Dec 2008. It's now Sept 2015, the current state of the language is 3.5 with changes back-ported to the 2.x branch for recidivists. It doesn't help the community or the language to continue flogging the dead horse that is Py2 -- you can't ask her to run much any more. I too would love to be able to recommend "Learn Python the Hard Way". to students and to developers coming from other languages, but until it rejoins the world I cannot.
Is your course based on Python 2 or on Python 3?
I wrote an [article](http://pbpython.com/excel-file-combine.html) that walks through a basic scenario similar to what you're trying to accomplish. It should point you in the right direction to investigate further.
According to the second link the requests module "Downloads files and web pages from the Internet." which sounds exactly like what you need.
I also use pandas for this. People love giving me data in excel format and this makes it mostly painless
Having everything in a single dmg is very handy for teachers.
no thanks, i'm gonna stick with the perfectly functional system that provides transparent remote access and doesn't require it's own hacked up package manager.
So I can write assembly in Python now? Sweet!
If it's just straight data and no formulas I always just convert to and from CSV. 
I'm going to assume, based on the fact that he is asking this question, that this is complete overkill.
Properly Done setup.py. Travis ci and coveralls. 
What i ment was that, I want to be able to make the "bot" take a screenshot if necessary &amp; save it on the computer, &amp; I also want to be able to take some information (Also if needed) from the website without using BeautifulSoup, if it makes any sence.
 with Function("DotProduct", (x, y), float_): # Request two 64-bit general-purpose registers. No need to specify exact names. reg_x, reg_y = GeneralPurposeRegister64(), GeneralPurposeRegister64() # This is a cross-platform way to load arguments. PeachPy will map it to something proper later. LOAD.ARGUMENT(reg_x, x) LOAD.ARGUMENT(reg_y, y) # Also request a virtual 128-bit SIMD register... xmm_x = XMMRegister() # ...and fill it with data MOVAPS(xmm_x, [reg_x]) # It is fine to mix virtual and physical (xmm0-xmm15) registers in the same code MOVAPS(xmm2, [reg_y]) # Execute dot product instruction, put result into xmm_x DPPS(xmm_x, xmm2, 0xF1) # This is a cross-platform way to return results. PeachPy will take care of ABI specifics. RETURN(xmm_x) The assembly code looks like python function calls. How does it manage to be faster?
There's a couple bug reports for install instructions, it's mostly about the inevitable Windows problems though. I'm going to give it a try from Linux once I make sure my qt4 examples still work with PyQt5, then change the imports to use PySide. I've been meaning to write something wayland-capable for a while after all ...
&gt;I like having a dedicated app for my notebooks Me too, so I always have it in a separate tab reserved for ipython notebooks :). Pineapple looks cool, but I'm not sure that it solves a serious problem for me yet.
I've never looked at it that way.
This is great news!
Haven't even heard of this, and I do a lot of pyqt and matplotlib. It looks great! 
So, how are your build rules for that? Do you set up a virtualenv for each job runner, or set it up inside the build job?
And also, how do you get/track pep8/flake8/pylint changes?
I did a lot of development with PyQt and tried a bit with PySide for Qt4. For the most part, it was good. But various bugs really burned a ton of time. I ended up feeling like the codebase was constantly fragile. That I can write Python that looks perfectly reasonable, but without knowing the nuances of the Qt bindings and the underlying behaviours, it can segfault at a moment's notice. Is this just a property of any binding of a complex set of libraries and Qt is no different? Is it going to be any better in Qt5 for PyQt or better yet, PySide?
str(123) == str(321)[::-1]
This is excellent. I'm quite happy with the Qt4 PySide for the time being, but it's great to see that the project has a future and won't become hopelessly obsolete in five years.
Hi OP here, just to clarify exactly what the program is doing here. I'm a data scientist in training, writing some programs to exercise both my skills in algorithms, statistics and data visualization. What we're doing 1. Write a couple ways to sieve prime numbers. 2. Track the runtime and memory usage of the algorithms 3. Analyze them over different values of n and make conclusions on whats going on Some things I've observed * The utilization of cache causes optimal performance at low n * Running out of memory causes it to be swapped to disk causing performance deterioration. * Numpy arrays are an optimal data structure, they are both space and time efficient since we already know the size of the array beforehand. * Improving your memory profile means ultimately improving your runtime efficiency! Therefore an even more optimal data structure would be a BitArray. If someone has a BitArray implementation that can plug into Numpy let me know! Just thought I would share and get peoples opinions!
It doesn't seem to work in Python 3.5 (there is no prepared wheel, for one): Collecting pyside Downloading PySide-1.2.2.tar.gz (9.3MB) 100% |################################| 9.3MB 54kB/s Complete output from command python setup.py egg_info: Traceback (most recent call last): File "&lt;string&gt;", line 20, in &lt;module&gt; File "C:\Users\GSchizas\AppData\Local\Temp\pip-build-m0pkjjgm\pyside\setup.py", line 89, in &lt;module&gt; from utils import rmtree File "C:\Users\GSchizas\AppData\Local\Temp\pip-build-m0pkjjgm\pyside\utils.py", line 10, in &lt;module&gt; import popenasync File "C:\Users\GSchizas\AppData\Local\Temp\pip-build-m0pkjjgm\pyside\popenasync.py", line 26, in &lt;module&gt; if subprocess.mswindows: AttributeError: module 'subprocess' has no attribute 'mswindows' The `mswindows` attribute it's referring to is undocumented (and in Python 3.5 it has become the proper `_mswindows`. In any case, you should be using `sys.platform == "win32"` - which is exactly what `subprocess.mswindows` or `subprocess._mswindows` is anyway. EDIT: This has been corrected in code, so if you do a republish it should be ok. Until then we can use `pip install --upgrade git+https://github.com/PySide/pyside-setup2.git`
Agreed, Maybe "complete" was meant to be placed before the word "beginner"?
&gt; For the most part, it was good. But various bugs really burned a ton of time. What "it" are you referring to? PyQt? PySide? Both?
Two of the "Online books" linked to on the righthand side of this page are good and are for Python 3: [Dive into Python 3](http://www.diveintopython3.net), and [How To Think Like A Computer Scientist](http://interactivepython.org/runestone/static/thinkcspy/toc.html). David Beazley's "Python Essential Reference, 4th Edition (2009)" is an excellent reference. Although by now a 5th Edition would be welcome, it will be spot-on for the basics of the language. It's 'around' as a pdf, but I'm not sure if the free (or "free") ones are sanctioned by the author or publisher. You can fire up an IPython interpreter in your browser without even having Python installed: go to [https://try.jupyter.org/](https://try.jupyter.org/), click the New button at upper right, and choose "Python 3" from the dropdown. You can also click/run the existing notebook "Welcome to Python.ipynb", which imports matplotlib, numpy and pandas, and draws a graph with them... but it may be a while before you want those things :)
It is now, thanks to the relatively new development of Python Wheels. These are python packages which allow for easy installation including built dependancies - they are not too widespread yet but they exist for numpy. You should be able to download the .whl file from PyPi and add it to your system path: import sys sys.path.append('/path/to/my/numpy.whl') import numpy as np (At least in theory - I'm not 100% sure if this is how you manually add a whl). Of course if you have the option to install your own python I strongly recommend Miniconda as others have - it will save you a lot of trouble
Thanks... I should have said "I'm prepared to throw away my whole stack EXCEPT PYTHON" ! Laravel does look good. A couple of people have pointed me towards Hug, which I'm hoping will be "Laravel for Python".
Great reply, thanks a lot. BTW I really liked the original wooey, I hope this one can match it in terms of reliability!
Oh wow, didn't realise that the job console output (and progressive detection of saved images therein) had been removed. That's a regression compared to the original isn't it? 
It is, but its a regression that I plan to fix. Previously it was starting up jobs by forking off processes from the running webserver, then polled these processes (and on-disk files) to retrieve status (on each page load). That's OK when you've got one person running scripts, but it's not very scaleable. Now we're using celery for the task scheduling which takes all that out of our hands (good), but does make job monitoring a little more complicated. But I think it's very important to be able to see the script is doing 'something' for long running jobs.
start with [python tutorial](https://docs.python.org/3/tutorial). For more advance use you will need to masterize the [python standard library](https://docs.python.org/3/library/) hint: even the basic types are documented here (under the names Builtin functions, constants and types)
Are there any plans about support for mobile platforms? Will we ever see PySide2 on iOS/Android?
Thanks I look into it. 
At work we use custom celery states to report progress. You can redirect / capture the celery job stdout, but then you have to have an out-of-band channel to pass that back. But this is an inherent annoyance of the celery architecture - I actually liked the last version of wooey because it did the simple file-monitoring thing. When I saw that a rewrite was in progress months ago I wondered if using celery would architect you into this very corner :-(
Check out tox https://tox.readthedocs.org/en/latest/ it does all the virtual env and package install/setup for you. It's great and I used it on CircleCI which prefers it to be used.
I was just looking at the custom celery states for this, and think we should be able to monitor the output using it. The execution of the script from within the celery task just uses Popen so we should be able to redirect the stdout from there (which was what it was doing before), pass it back through with the custom state while waiting for the execution to complete. We can probably do something similar for the file updates, checking from the task end for updates to the folder and sending filenames/etc. back to the server. Watch this space ;) 
You can install packages through Pycharm? That's nifty.
Another idea is to use a cache backend for storing the job output/state information for jobs which are currently executing. That would mitigate database issues, allow wooey to still update across networks, and be robust enough against failures.
Kudos to them for the achievement but my devil's advocate question would be ... why? * PyQT has been around for ages and it works today (and it is reliable) * It has always had a double license model * The company's making a living out of this | (and they give back to the corporate guys the warm feeling of a supported product, believe it's a make-or-break point to adopt anything in a company) * It is giving back the community a highly polished product (including the nice side things like sip) 
For me personally PyQt is not an attractive option, because I prefer more liberal licenses to the GPL. I also prefer not to be forced to dual license my code just for the sake of using the GPL everywhere, so I tend to steer clear of GPL dependencies. So having a LGPL library is really great news for me.
Why not just release your code under a more liberal license, which is GPL compatible? The GPL means that the whole, combined work must be released under the GPL, but if there are some parts that are more liberally licensed that's fine. That way, if people want to make changes to your code and release the source, they can do so, under either the more liberal license or the GPL as they see fit (again, the whole thing will be released under the GPL). If they want to release a proprietary product, they can pay the license fee for the commercial PyQt license, and then they have an appropriate license for that part and the rest is under a liberal license, so they're fine there too. The only reason why you would need something that was LGPL rather than GPL is if you want people to be able to make proprietary forks without paying anyone a dime. I mean, I suppose some people might want to do that, but it seems a little too much like charity for for-profit corporations that way.
Because not all of my code is capable of being liberally released ;)
Also it is pre-alpha, contrary to what I wrote previously, so it most definitely does not have wheels yet.
Meant pre-alpha anyway.
Depends on the platform. It should build on all of them. What platform(s) are you trying to build on?
Well that's why I wrote “For me personally”. It ultimately is a question of taste, I happen to prefer simple and readable licenses without much restrictions. If “public domain” was a thing where I live, I'd probably use that for most of my stuff. You see it as corporate charity, I see it as ultimate freedom. Thats also why I ended with the FreeBSD crowd, and use mostly clang instead of gcc. Not because one is ultimately better than the other, but because I prefer the philosophy. That said, for a commercial company having a proprietary version and a GPLed version of a software makes a lot of sense. As does having a single BSD/MIT/ISC licensed version. If I were to write commercial software based on Python and Qt, I'd probably use PyQt because of the support alone.
&gt; If someone has a BitArray implementation that can plug into Numpy let me know! I am surprised Numpy or scipy do not have a built-in for bit arrays. It seems like a strange omission for such a library.
Because the only option for license with a PyQt app is GPL. Very restrictive in choice. This also makes Python less generally desirable for building GUI apps in, if they want to use Qt (now arguably the best cross-platform toolkit for Win/Nix/OSX). Suddenly their app has to be completely free and open source or they have to pay. This discourages people from using python when they could just use another language instead, which simply doesn't enforce GPL. It's also a bit wonky given the original C++ code is LGPL while this is not.
 if ("+") or ("-" in x[0]): print x Probably not what you meant, but that's how Python interprets what you wrote. 
Maybe update the installation instructions in the readme?
You want to use `startswith()`, like: for x in diff_list: if x.startswith('+'): do stuff elif x.startswith('-'): do other stuff BTW, please post these type of questions in http://www.reddit.com/r/learnpython moving forward. Cheers!
This sounds awesome but.... documentation?
+1 to requests
We need to know what is wrong specifically in order to help you with your problem. Which version of Python are you using? Are you trying to run a program?
What is this "paper" you speak of?
`False` and `0` are the same type. Python does not have implicit type coercion so `False` is not equal to `''`. Otherwise you'd get a nice bunch of WTFs straight from the PHP world: if `False == ''` and `False == []` then `[] == ''` and so on. Edit: you seem to be confused about the difference between conditional statements (that check for "truthiness") and the literals `True` and `False` (which are just examples of a truthy and a falsy expression respectively). Consider this: `5` is truthy but you don't expect `True == 5` to be the case.
This. Pandas is perfect for generic data parsing. If you need to read .xls files along with regular .txt or .dat files that have slightly different formatting you have one package that can read in essentially everything you throw at it as long as you know how the file is formatted. You can read in all the files into a common data format (DataFrame) [albeit maybe not as familiar if you haven't used 'R')] Then you can do all sorts of table-style manipulation of the data similar to what could be done in Excel or R. The library is well documented, there' plenty of tutorials, its widely used so generally finding help to do what you need isn't a large task
&gt;In python, 0, empty tuple (), empty string "" evaluates to False. This is incorrect. An empty tuple is an empty tuple and an empty string is an empty string. These values do not "evaluate" to false. They are distinct values. &gt; But when I try the equality test &gt; False == 0 returns True, but &gt; False == () returns False and &gt; False == "" returns False &gt;Shouldn't False == () and False == "" return True? Should () == "" return true? The reason it is often mistakenly said that empty strings and tuples evaluate to false is that they are called 'falsey' values. A 'falsey' value, in a Boolean context, is understood to be like False. Conversely, a 'truthy' value is understood, in a Boolean context, to be like True. The == operator produces a Boolean value, but does not, itself, produce a Boolean context. For false, what you want to use is 'nor'. Python doesn't have nor, but you can just invert the result of 'or' to get the correct results. &gt;&gt;&gt; False or 0 False &gt;&gt;&gt; False or "" False &gt;&gt;&gt; False or () False EDIT: The above example is wrong. you have to actually negate the expression to get the desired result.
Makes sense. Thank you for the reply.
I wish I knew.
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Show them that you've tried to solve your problem and you can get all the help you need. Cheers &amp; best of luck!
I imagine PRAW only does 30 requests per minute because it is intentionally throttled... Are you sure this program doesn't violate reddit TOS?
If you want schools to be able to access this, you may need to remove the military image on the front page (the soldiers aiming rifles) as it may get stuck in their war/violence filters.
wow, this is awesome. i will try it too. however if wheels is something that needs to be supported by the native python i might be out of luck.
Here's the github.io page + a short video. Still no docs though... http://gutomaia.net/pyNES/
&gt;`False` and `0` are the same type. more specifically, bool is a subclass of int: &gt;&gt;&gt; isinstance(False,int) True &gt;&gt;&gt; isinstance(False,bool) True &gt;&gt;&gt; issubclass(bool,int) True
&gt; False and 0 are the same type They're not the same type, one is type `bool` and the other is type `int`. But `bool` is a subclass of `int`, which means all booleans can be used where an integer is expected, per the [Liskov substitution principle](https://en.wikipedia.org/wiki/Liskov_substitution_principle). This is also why you can do things like use `sum()` when dealing with a sequence of booleans: &gt;&gt;&gt; sum(s.startswith('a') for s in ('arcade', 'book', 'castle', 'arpeggio', 'default')) 2 
The machines are alive and computer programming is a conspiracy to conceal it. Wake up Sheeple!
The point of using dynamic bindings is you wouldn't have to write everything. Most of the heavy lifting would be done by Qt's meta object introspection. The bindings would provide a generic wrapper around the meta object system. This would also work with third-party Qt libraries. I know this isn't necessarily easy, but assuming Qt supports such a system, it would be considerably easier than writing static bindings like PyQt and Pyside do.
I'm totally pronouncing this like penis. I don't even care. How big is the package?
Thanks for the suggestion! Ill correct it right away!
Very common in Europe. 
We try to cover the basic python language like the others but we also try really hard to get some advanced topics into the mix which we didn't find in other places and we had to look around a lot to know those. For instance check out the articles in the advanced category: http://www.pysnap.com/category/advanced/ also some more cool language features: http://www.pysnap.com/category/ninja-techniques/ 
pip by default will try to install things in the system folders, which need root permission. You should generally avoid that. I think the error message should convey this better. The best way to install python apps is to install them to a user owned location. You can create a user location for python by using virtualenv... its very easy, so don't despair. Just follow along. mkdir ~/notebooks cd ~/notebooks sudo pip install virtualenv virtualenv venv source venv/bin/activate pip install --upgrade pip pip install notebook echo "source venv/bin/activate; jupyter notebook" &gt; run.sh chmod +x run.sh ./run.sh This will install and run your notebook server. At any later point, all you need to do to start the notebook server is... cd ~/notebooks ./run.sh 
And even more interesting, bool can't be subclassed. 
The reason Pony uses Bytecode is because there's not a way (I'm aware of) to get to a generator's AST. Otherwise they'd probably just skip the Bytecode and dis steps.
That's how I'd do it (UK). Same with the SNES. sss-ness
http://www.pysnap.com/ninja-design-technique-in-python-iv-memoization/ If you are going to have a blog about python it might help to have your blog support the white space syntax that python requires to be functional. 
Yesterday I encountered a program that does EXACTLY this and it comes with Python source code https://forums.frontier.co.uk/showthread.php?t=68771 It's named EliteOCR. It is a tool for 'commodity' trading in a game. You take a screenshot from the market in the game. The program reads the saved screenshots folder, and if there are new files, it performs OCR (optical character recognition) on the screenshot, builds a spreadsheet and uploads it to a website. This enables players to check prices globally instead of just at their local market.
That's how everyone I know in the states pronounces it, too.
It's a technically correct answer buried under sarcasm and requring computer science knowledge to understand. i.e. a typical programmer's joke. :-) It's a simple project. I posted a link to an open source project elsewhere. "Turing completeness" is part of Computer Science theory and deals with the fundamental limits of what is, and is not, computable. This isn't about computing power (machine speeds) but about concepts that can/cannot be computed, for example due to logical paradoxes. He is reminding us that Python (along with all common modern programming languages) is "Turing complete" which means they can implement a "turing machine", which means they can solve any computable problem, because we define computable problems as "problems which can be solved by a turing machine". So one doesn't have to ask "Can we do this in Language X?". Rather, we should ask "Is this problem solvable by a turing machine?" and if the answer is yes, than all programming languages you've likely heard of can do it. Realistically, the implementation is different from the theory, and some projects are impractical in some languages, but yours is fine as it's simple, and Python has fast library support for it.
Bah, you're right. I was typing on a phone. I forgot about the silly assignment shortcut stuff. You actually have to negate the result for my example to work. &gt;&gt;&gt; not ( False or 0 ) True &gt;&gt;&gt; not ( False or '' ) True &gt;&gt;&gt; not ( False or () ) True
 class Bit(object): def __init__(self, varname, bit, options=False): assert bit &gt;= 0 and bit &lt; 8 self.varname = varname self.bit = bit Is this normal, an entire class instance for each bit?
There was always a bit of blurring on the last S as I recall, making it halfway to a soft "z"
Taking a screen shot, yes. Why don't you want to use beautiful soup? What information do you want?
Well if you want to talk about individual bits in a byte, maybe yes. I've used embedded systems where you can have a bit variable that when set affects one bit of an I/O address
So with this, could I theoretically create a game, and then run it on my RetroPie NES emulator on my Raspberry Pi?
please stop spam for your site. You did not even read the standard library doc. Otherwise how could you have missed `re.X` also named `re.VERBOSE`
For an NES not really. Lots of flags and stuff are individual bits out of a byte, I can see why it would be convenient to abstract them away in this way.
This looks really cool! I was running five or six bots simultaneously for a while and now am in the process of rewriting them. This will be really helpful for getting them rolling again. I'll let you know how it turns out, but from reading through the docs it looks very useful!
I can't see the reason. We already got namedtuple for these kind of stuff, also a factory function could assert the value before creating the bit... 
https://xkcd.com/1013/
Ew. assert 0 &lt;= bit &lt; 8
lol. wrapperception. But, in reality, that's pretty much all programming seems to be. Abstractions upon abstractions, until we are able to do what we need to get done. 
I can see how it might be that way. Part of me thinks "snesz" at times but I'll usually always say ssness.
Not even a readme...
I'm curious why you think this is interesting - were you planning on [adding `FILE_NOT_FOUND` as an instance of your `bool` subclass?](http://thedailywtf.com/articles/What_Is_Truth_0x3f_) I can't think of any interesting operation you would want to add to `bool` that would justify subclassing it, bu perhaps that's just because my imagination gland isn't working today.
&gt; when we teach C or C++ we must distinguish between "variable" and "pointer". I don't agree with this. What is your definition of variable? &gt; Assuming everything in Python behaves like a "variable" leads to problems (which can't be easily resolved with a type declaration) so it can sometimes be detrimental to use this term when teaching Python. What problems?
From the article you linked &gt; Some people like to say, "Python has no variables, it has names." This slogan is misleading. The truth is that Python has variables, they just work differently than variables in C. So... what? Python has variables.
So it's fairly well-developed?
Line 9 creates a bash script file named 'run.sh'... and populates it with 2 commands separated by the semicolon - "source venv/bin/activate; jupyter notebook". The "source venv/bin/activate" configures python that it should look for library files, which includes jupyter and other things that we just installed, in the venv folder, instead of the usual system folders. The "jupyter notebook" command starts the notebook server, which I am sure you already knew. The semicolon is just a separator for having 2 commands in 1 line. Line 10 makes the run.sh script executable. Without this, bash will not run the script. Its like changing the extension of a file to .exe in windows. Line 11 executes that script and starts the jupyter notebook server.
If you wanted to do something that looks like your first suggestion You could do this: b01 = [] for x in a01: b01.append(x[:10]) That would give you a new list called b01 which had all elements cut down to the 0:10 of each element in the first list. 
&gt; But the link ends in stating that Python does indeed have variables. This is true. Python does have variables. The problem comes when someone thinks of them as some other language's variables and make statements like "a=4 assigns 4 to a" which is what started this whole thing off. It does not assign '4' to 'a'. If a person thinks about it that way, they will get into trouble for the reasons explained in the link. &gt; And what if a Python student asks you? See the paragraph above.
Since I thought this was great - and wasted a few hours of my life on it, I thought I should make some suggestions. A couple things that would be nice: - Ability to play with friends (I invited a few people, it would be cool if we could play together) - Ability to select answers with the keypad (eg. 1,2,3,4) - As mentioned, questions do tend to repeat - I saw you were attempting to make a user submission option, just thought I would throw it in my suggestions The cool: - Your profile graphs - I love data, so this is a nice representation of what I am doing - Interface is stellar One question: - Am I always playing with other real people, or do you have the "computer" fill in when there are not enough players? Thanks for sharing!
I take you understand why I am saying that "a=4" doesn't assign 4 to a (in Python)?
Yeah but the file can he compressed by tucking it into your waistband.
You take. Yes. I don't see why that means Python doesn't have variables. They act differently than other languages. Okay. Most languages have subtle differences to how variables act. Does this mean no language has variables? No, it means you teach beginners what a variable is in that language.
Thanks very much for your great feedback! &gt; Ability to play with friends (I invited a few people, it would be cool if we could play together) This is definitely in the works, although we're still deciding on how exactly it will work. For example, what if your friends are not online? What if they are online but ignoring your game requests? Would you be waiting for a short time and then the game would time out? &gt; Ability to select answers with the keypad (eg. 1,2,3,4) Great suggestion! I'll look into this. Although, would it be unfair for mobile users? :) &gt; As mentioned, questions do tend to repeat This is our top priority. The problem is while readymade databases of trivia questions are available for purchase for more common topics such as Science, Geography, Harry Potter, etc., we have to manually write every single question in specialized topics such as Python. And due to the nature of the game, we can't have questions like "What is the output of this below code?" and have a block of code (since you have only 10 seconds to answer). This is why we are working on adding a feature where users can submit their questions, apart from working extra-hard to generate more (quality) questions. &gt; One question: - Am I always playing with other real people, or do you have the "computer" fill in when there are not enough players? We can neither confirm nor deny that we use bots! :P But seriously, we always try to match real people with each other. However, when there aren't enough people to play a particular topic (especially since we've just launched), we do have bots jump in. However, they are destroyed immediately after the game and therefore do not get on leaderboards or "learn" the questions, and always answer at random. Thanks again and would love to hear your thoughts on my responses.
see [here](https://github.com/PySide/pyside2/issues/2) for directions. Re-posting what I wrote there: here is a _rough_ guide for building: 1. Get OpenSSL, cmake, and Qt 5.4.x or 5.5.x. This is very platform dependent. It should be very similar to [these instructions](https://pyside.readthedocs.org/en/latest/building/index.html), except you should get Qt from [the archives](https://download.qt.io/archive/qt/5.4/5.4.2/) 2. `git clone --recursive https://github.com/PySide/pyside-setup2.git` 3. `cd pyside-setup2` 4. `python.exe setup.py install --qmake=/path/to/bin/qmake --cmake=/path/to/bin/cmake --openssl=/path/to/openssl/bin --ignore-git`. Note that the `qmake` and `cmake` are looking for something to execute, but openssl is just looking for the bin folder. 
So we agree. That's cool.
As others have pointed out, what your code is doing is merely creating a new "x" variable that references a copy of the first 10 characters, rather than changing the value in the list. To add one way you *could* do what you want though, try: for x in a01: x[:] = x[0:10] Here the `x[:]` references the **elements** of x (ie the list items). Specifically, ti references all of them (it's the full slice, with no start and stop indexes). So this basically means "replace the **contents** of the list x refers to with the value on the right hand side - x[0:10]" Likewise, you could do the same with: for x in a01: x[10:] = [] # Replace the elements from position 10 to the end with an empty list. or for x in a01: del x[10:] # Delete the slice starting at index 10 Often though, it's cleaner not to modify existing lists, but instead create a new list that has the elements you want - this is less prone to errors if that list happens to be references elsewhere in the program, and might break if it gets changed beneath its feet. For that, you *could* just build a new list as you go, so: newlist = [] for x in a01: newlist.append(x[:10]) But there's some useful syntax to make this kind of thing more concise, called a list comprehension, so the above could be written as: newlist = [ x[:10] for x in a01 ]
Sure. I'll also note that it reads and writes from a binary data file holding all the words it knows. Any way I can put that here, too? I would copy past the data, but its all weird symbols.
I would just like enough docs to get it to work then make a ton of PRs on it.
Uploaded to git. Also included source code.
What video?
There's tons of info about such processing on the web, what is it exactly you're trying to do that you cannot find references ? Something similar I have done was * reading data from csv &amp; Excel * insert the data into Sqlite database * With raw data in db, run SQLs that combine &amp; summarize the data, applying any necessary transformation logic and finally... * pull query result back into Excel for presentation/reports 
Can you think of any Assembly tutorials that would go along with this?
This is like that episode of TNG where they accidentally made a strong AI on the holodeck but less plausible. 
http://gutomaia.net/pyNES/
You might be able to use this - http://nicolas.kruchten.com/content/2015/09/jupyter_pivottablejs/ I have no experience with it but thought I'd point it out.
Look out the window, if you have one. See the ledge? Stand on it. &lt;bursting paper bag&gt; -- there's a trigger. Ohhh, you're a whitehat, well, why didn't ya say so? Sure, we're all friends now... Why should anyone believe that? This is an irresponsible question.
A friend used to call it "any ass tickle". We LOL'ed.
&gt; I replaced all my use of mayavi with it. Isn't mayavi made by Kitware who also develops VTK, which only supports Python 2?
You can figure it out. Do some tutorials. You can't just "get information" without specifying an algorithm for extracting the information. Programming isn't magic; you actually have to **do** everything in exact detail. Bs4 is actually an amazing tool that lets you **do** information extracting from html very easily compared to not using it. Welcome to programming. Take small steps and relish the sucesses you earn.
Most confusing post I've read in a while.
 import requests url = 'http://example.com' r = requests.get(url) r.text #contains the whole html document requests is an extremely convenient way of automating http. if you want to actually extract specific information from the html doc it might be worth putting a bit of time into understanding BeautifulSoup, it's probably gonna be a lot easier to understand than manually handling string manipulation. Things like lxml might suit you better but I'm not sure they're much simpler conceptually. 
Minor nitpick: position = 0 for item in sys.argv[1:]: users_to_download[position] = str(item) position += 1 There's very rarely a reason to use counters and indexes when iterating in python. See Ned Batchelder's excellent [Loop like a Native](https://www.youtube.com/watch?v=EnSu9hHGq5o). In this case, you don't even need to iterate. sys.argv[1:] is already the list you're trying to create. 
Sorry, Yuri told us not to help you. In fact, he told us to inform him as soon as you start asking others for help.
If you're tired of Wolfram's Elementary CA, you may find the concept of the[ Single Rotation Rule](http://dmishin.blogspot.co.nz/2013/11/the-single-rotation-rule-remarkably.html) using the [Margolus neighbourhood](https://en.wikipedia.org/wiki/Block_cellular_automaton#Neighborhoods) interesting. Also see /r/cellular_automata.
Booleans are a subtype of integers. `isinstance(True, int)`
To say more about cpython's `if` and `==`, The `if` statement calls [`PyObject_IsTrue`](https://hg.python.org/cpython/file/tip/Objects/object.c#l1230), a rough translation of PyObject_IsTrue's semantics into python code is def PyObject_IsTrue(o): if hasattr(o, "__bool__"): return o.__bool__() if hasattr(o, "__len__"): return True if o.__len__() &gt; 0 else False return True The `==` operator calls [`PyObject_RichCompare`](https://hg.python.org/cpython/file/tip/Objects/object.c#l700) def PyObject_RichCompare(a, b): ta = type(a) tb = type(b) # test first with b == a if b's type is subtype of a's type if ta != tb and issubclass(tb, ta) and hasattr(b, "__eq__"): ret = b.__eq__(a) if ret != NotImplemented: return ret # a == b ? if hasattr(a, "__eq__"): ret = a.__eq__(b) if ret != NotImplemented: return ret # b == a ? if hasattr(b, "__eq__"): ret = b.__eq__(a) if ret != NotImplemented: return ret # same object/instance ? return id(a) == id(b) for `0 == ()` being true, either `(0).__eq__(())` or `(()).__eq(0)` must return true.
You need to reverse pipe the asynchronous scaling delimiter. Once that happens, open up the port and buffer overflow the gopher protocol with cascading trimetric bits. 
How big a matrix are we talking? Do you have a minimal working example? The one I see there uses range rather than xrange for a start.. 
Did you check/delete the config directory in $HOME/.idlerc
Huh, I guess you're right, but they're still less popular than the game of life right? Ok, maybe not, but I do plan on exploring the subject in more depth in the next posts.
shit just got reaaaaal
The `??` syntax isn't that attractive IMHO, but this seems useful. 
Same as in c#, works well imho
Hey, so I see you filed a bug. Can you respond on github?
If I'm reading that correctly, you can shorten that further to y ??= []
I think this is pointless. The author suggests that: A ?? B is more readable than: A if A is not None else B ...but when reading the former the language that goes through my head is pretty much the latter verbatim. It can't get much clearer than that.
Found it! https://github.com/minimaxir/facebook-page-post-scraper/blob/master/how_to_build_facebook_scraper.ipynb
Sometimes you need a list, dictionary, or object, but won't always have one to pass to the function. The side-effect of a shared mutable object is rarely wanted unless you're memoizing or caching (though I would argue a decorator is always preferable in those situations.) Here's a trivial example of where you'd have to use a None if you don't want to force the caller to create a new list before calling: def append_five(l=None): if l is None: l = [] l.append(5) return l Obviously you can't use [] as a default there, but you don't want to make it a required argument and force the caller to do m = append_five([]) every time they want to use it. This sort of stuff comes up in my code all the time, and I see it in code I look at all the time as well. I'm glad you don't run into the problem often, but I promise you a lot of people do.
Maybe someting like `ifnone`? As in: `A ifnone B` (or `if_none` or `ifNone`) Though `ifnone=` doens't look particularly nice. I don't know, just thinking out loud here.
&gt; if foo is not None then continue the expression, otherwise stop evaluation and just give None. Sounds reasonable, but I bet there are a ton of edge cases I would want to see considered. Like if `bar` takes an argument, and that argument is an expression, does it get evaluated if `foo` is `None`? foo?.bar(dosomething())
It's a completely useless feature, if you ask me.
I'm not sure about this one. It will only eliminate a few words of code while making it less readable for those who are unfamiliar with the new syntax. I can see an unsuspecting programmer accidentally letting Nones persist in their code when there should have been an exception raised, because they didn't see or understand the '?'. Python is readable because all the operators make intuitive sense, and it is already terse enough without adding unintuitive operators.
It may have been a poor example. I agree, it isn't a realistic or good API. Here's an example out of actual code (Django, specifically): class SimplerXMLGenerator(XMLGenerator): def addQuickElement(self, name, contents=None, attrs=None): "Convenience method for adding an element with no children" if attrs is None: attrs = {} self.startElement(name, attrs) if contents is not None: self.characters(contents) self.endElement(name) def characters(self, content): if content and re.search(r'[\x00-\x08\x0B-\x0C\x0E-\x1F]', content): # Fail loudly when content has control chars (unsupported in XML 1.0) # See http://www.w3.org/International/questions/qa-controls raise UnserializableContentError("Control characters are not supported in XML 1.0") XMLGenerator.characters(self, content) You couldn't use attrs = {} in the function definition, as each time you create a new generator they'll share the same one. You also can't require the argument, as it's obviously optional to have any and it would make the API terribly confusing to require an empty dictionary on object creation. However, you always want to pass it along to self.startElement, which may modify it, hence why you can't share it. Edit: Another example, this time from my own code and having no ambiguity. class Crawler: DEFAULTS = { "crawl_depth": 5, "external_depth": 1, "max_concurrent_requests": 20, "respect_robots": True } def __init__(self, root_url, options=None, seen_urls=None): self._root = root_url self.options = options self.seen_urls = seen_urls if options is None: self.options = self.DEFAULTS if seen_urls is None: self.seen_urls = set() `seen_urls` is to allow resuming a previous crawl. It is modified during the crawling process, and thus definitely couldn't be initialized with a [] as default in the arguments as you could have multiple crawlers running simultaneously.
&gt; I don't exactly know how the rest of your code works, so I can't really comment on testing for None multiple times. Are you sure it's necessary? Could you not have something like: Not really, because `None` was also a perfectly valid choice there and `some_code` mostly worked the same whether `instance` was `None` or some other instance. I didn't need any other special cases for `None`, so `?.save()` would be a great way to say "also, if `instance` exists, save it now, thanks." Simply speaking, there was more behind the scenes and AFAIK what I wrote originally was the best way to do it.
Thanks! I've been using Atom in the meantime, but I've only been able to run it out of Terminal which doesn't like the input() function much. I'll try out Pycharm as well.
Wouldn't that evaluate both the arguments regardless of whether a is None? 
Wasn't the Eskimo operator a consequence rather than a design?
None is quite often used as the default value for python functions. Part of the reason for that is because when you define a function like this: def f(x, times=1, values=[]): for _ in range(times): values.append(x) return values You end up with this: f.__defaults__ == (1, []) Clearly the `1` in there is fine, since you can't change the values of tuples in place. However, you can mutate members of tuples (if they are mutable, of course), so now you have a different result each time you call the function: f(10) == [10] f(11) == [10, 11] Even worse, doing this: my_nums = f(10, 2) my_nums += [12, 13] results in this: f(11) == [10, 10, 12, 13, 11] This might be the behavior you want. I've certainly encountered uses for it. One example is something like this: new_string = re.sub(pattern, lambda match, values=[1,2,3]: match.group(1) * values.pop(), old_string) It obviously did something more interesting than that, and was a bit more complicated, but still: replacing each match with a different value is tricky otherwise. Anyway, the point is that arguments that take a default argument of a type at all more complicated than a string, boolean, or builtin numeric type will instead accept `None` as the default. So testing for `None` is pretty common. That being said, I don't see this syntax being accepted. It isn't particularly intuitive for someone not coming from C#, so I don't think it will qualify as "pythonic"
I'm not sure that's even English. 
Sorry my window doesn't have a ledge, do you have any other ideas?
Only when I'm awake.
I was so confused. 
Thanks! I have updated it to not use a position character and instead use .append() on the users_to_download which I also changed to be a list instead of a dictionary (dunno why I had that in the first place) https://gist.github.com/anonymous/08a5f27373cf450ee86d Edit: Just understood what you were saying about sys.argv[1:] being what I need as a list. Updated the link
I think one of pythons greatest assets is readability. In every example the syntax is definitely *shorter* but it is also *less clear and explicit* which imho goes against the Zen of Python.
Yeah that's the main issue with this approach. The second argument could instead be a lambda, but that is probably uglier than the if ... else syntax
This isn't a bit of storage; it's a reference to a bit in some other, named byte. Scroll down to where a few are instantiated.
&gt; 1 (212) 479-7990 Ouch
 def f(x, times=1, values=[]): values = values or [] for _ in range(times): values.append(x) return values Bam! Same as ?? with the same char count. Only thing I like about the PEP is object?.attribute access. ?? is absolutely useless though.
It definitely goes against readability.
This is complicated... let's not.
[Be careful with that](https://bugs.launchpad.net/pylockfile/+bug/1419127).
I'm somewhat split on this. For one, the choice of `??` feels *remarkably* unpythonic. It's downright ugly. Not to mention that it's introducing Yet Another Way to solve something which is trivially handled by features that either already exist in the language or are equally easy to implement. Further, the examples are rather poorly chosen. `requested_quantity`, being that it is a.. *quantity*, or *count* of something, should probably just default to zero in whatever imaginary handler that uses it rather than `None`. There ya go. Problem is no longer a problem. The most compelling case for the whole PEP, which really doesn't say much for the PEP, is the `title.upper()` example. It is _mildly_ inconvenient. It would be nice if Python had some monad-ish access patterns that better dealt with values that may or may not be present (like Scala's `Option`). But, ultimately, they just don't fit into the language all that well. Point being, do we really need a new ugly control structure to avoid an `or` or a `ternary`, or just choosing better defaults? 
If you want to be snippy about it, you really should do: if not hasattr(obj, 'append'): raise TypeError('Must be a mutable container object that supports append!) The .? operator would not save you from passing an int to a function that calls append on it.
Took a quick look. Doesn't seem to help much with serialisation.
What happened to explicit is better than implicit? 
I agree. ?? is not the best idea for readability. I love None?.method() and None?['key'] though. I could remove much two line if x is not None s or even uses of getattr with a default. so I really like the feature. the syntax is a problem though I think. tiny ?
but...but... how about chaining? json?[key] and obj?.method()
&gt; Status: Draft 
Please no. If your problem is you're writing "my_int or default_value", and surprised when it triggers on both 0 and None, you have no one to blame but yourself- certainly not the language. FFS, just write "my_int if my_int is not None else default_value". Is PyCharm now charging you per character typed? Python is supposed to be readable. 
As I said in other response, because of the way I used multi-table inheritance in Django, `None` isn't an error state but a perfectly valid result that actually works nicely with the rest of code - the only difference being *if* I actually get an instance, it deserves to be saved.
Exactly this. Having a `None` when your code expects a value should be a case that is explicitly handled and stands out as a piece of logic all it's own. if data is None: # do something here and don't hide it behind perl-like syntax madness data = [] Or if you *must* have it one line, what is wrong with data if data is not None else [] Or make a (gasp) function handle_none(data, list) All three are completely in line with the explicitness of the Zen of Python. OTOH data = data ?? [] data ?= [] is just not the language I know as Python. 
I'm testing it with a 200k x 200k matrix, 200k non-zero values. It's maybe not a minimal example, but here is a very simple test: import pyviennacl as p import numpy as np import time t = time.time() matrixSize = 200000 nnv = 200000 B = np.ones([5,5]) x = np.random.randint(0,4, nnv) y = np.random.randint(0, 4, nnv) values = np.random.rand(nnv) print time.time()-t t = time.time() for i in range(nnv): B[x[i], y[i]] = values[i] print time.time()-t t = time.time() A = p.HybridMatrix(matrixSize, matrixSize, nnv = nnv) x = np.random.randint(0, matrixSize, nnv) y = np.random.randint(0, matrixSize, nnv) values = np.random.rand(nnv) print time.time()-t t = time.time() for i in range(nnv): A[x[i], y[i]] = values[i] print time.time()-t the output is 0.009929895401, 0.231116056442, 0.0151200294495, 45.079169035 So it builds the list of coordinates and values quickly, and can loop through them setting values in a numpy array in .23 seconds, but it takes 45 seconds to set these values in the GPU array. This is crazy slow, so there must be a way to set them "all at once". What I really want is to be able to type something like A.setvalues(rows, cols, values) Sadly, I have not been able to find another example of setting values, and doing it one at a time like this is just too slow to be useful. (32+32+32) bits * 200,000 = 2.4 Mb, so I'm moving effectively .053 Mb/s onto the card- about the speed of a dial-up modem. Something is very wrong. Thanks for your interest in the question! I'm pulling my hair out just trying to get some sparse matrix/vector multiplication going! EDIT: I'm using HybridMatrix format here, but I have tried them all, and there is negligible difference. 
That's your opinion, and I'm not going to try to convince you it's wrong, even though I disagree with you. Personally, my logic is this. If a function can't work with all variables of type `X`, it shouldn't work sometimes, just because the variable passed happens to evaluate to `False`. Finally, here's another example where your function will perform incorrectly: import arrary f(10, 2, arrary.array('q')) # == [10, 10] # != arrary.array('q', [10, 10]) Trying to pass any empty object will lead to the return value being of type `list`. Your `hasattr` check won't work here either.
&gt; That new f-strings thing and now this? What is bad about x = 4 print(f'x={x}') other than the f? It's easier than: x = 4 print('x=%s' % x) 
Maybe PyAV for ffmpeg bindings?
Technically true but it's not a problem in practice. If callers are treating arguments like that it's almost certainly bad API design.
Here's the corresponding thread on python-ideas: [Null coalescing operators]( https://mail.python.org/pipermail/python-ideas/2015-September/thread.html#36289).
How would the serializing differ from what the redis-collections module does?
Thank you. (Hint: append " j/k".)
I said hasattr as as in "use hasattr in lieu of the or operator". Not use both at once. Hasattr is good for determining CAPABILITY. "Or" is good for monotyped functions (as I HINTED at). You probably shouldn't use them together. Those patterns serve different purposes. You constructed a marvelous argument over a complete and utter misread. 
True, my comment was just about the `??` operator. I agree there's nothing quite like the single-`?` usage.
For it to make sense without adding `None.__call()` it'd have to be something like: title?.upper?() That being said, having a no-op function `None()` might be a useful thing by itself.
Python discovers the Maybe monad :)
Django: it seems to me this could (and thus should) just default to `{}` - `attrs` are never mutated AFAICT. If I'm wrong, it should still probably just copy the input to shield the caller from the mutations anyway. Your `Crawler` example is certainly well motivated, however. I do doubt it's sufficiently common to add 3+ new operators, though.
By smooth, do you mean linear? If so you can find the standard deviation of the differences, lower means more smooth. For example, the differences for the first array is `[1, 1, 1, 1, 1]`, the second one is `[1, 1.6, .7, .7, 1]`. Or do you mean in a differentiable sense? For example, x^2 is smooth while |x| is not. Here what you would want to do is the same as the linear method, but localized (only search within -5 and +5 points). You would need a lot of points though. Let me know if you need me to explain why this works.
Looks great. Looking forward to future releases
Smooth is a continuous first and second derivative I think. You might be looking for a different but related idea though.
Because there should be one, and only one, obvious way in which to do it. Speaking of which, you could also write that same code: x = 4 print('x={}".format(x)) Or there's also x=4 print('x=', 4, sep='') Or channeling my inner Pascal: x=4 print('x='+str(x)) The new string thing has a very limited use case and we still have the old, superceded '%' syntax as it is. 
Top of the thread: &gt; I assume that this has never been brought up in the past because it's so heinously un-Pythonic that you'd have to be a fool to risk the public mockery and shunning associated with asking this question.
I think that a better recommendation would be to not try to make shortcuts for all this logic. Ternary/inline if statements, list/dictionary comprehensions, and this recommendation for "??" seem to only exist because people want to do more things in one line. Can we stop pretending like the number of lines is a bigger problem than complexity of the function itself? Does this not solve the problem easily enough? def coalesce(*args): for arg in args: if arg is not None: return arg
One way to do this is the following... The key idea I am thinking of is that of a "radius of curvature". For each set of n points, you can find a polynomial of order (n-1) which passes through all the points. For each such polynomial, you can define the notion of a "mininum radius of curvature (minroc)". Now, we hypothesize that "the curve with the smaller minroc is rougher than the curve with a larger minroc". The idea is intuitive enough... the smoother of the 2 curves is the one which has the less sharper bends. The sharpness of a bend is its radius of curvature. Smaller the radius of curvature, the sharper the bend. To find the radius of curvature at each point of the function, you can approximate it numerically by using the equations given here... http://mathworld.wolfram.com/RadiusofCurvature.html The minimum value found above is the minroc for that function. Now, repeat this for each set of values and compare their respective minrocs. Of course, a single sharp turn in an otherwise smooth function will result in a low minroc for that curve. Alternatively, we can define an 'averoc', the average radius of curvature. This will smooth out those local findings. 
Most general way is probably to fit (say) a polynomial and look at the variance of the residual. If it it's a straight line then you can try the variance of the forward difference: `np.var(np.diff(x))`. Compare that to a threshold. 
 output = {} with open('fasta.txt', 'r') as file_handle: for line in file_handle.readlines(): if line[0] == '&gt;': key = line[1:].strip() else: output[key] = line.strip() print(output)
I've been using xlsxwriter myself and it works very well
&gt; Improving your memory profile means ultimately improving your runtime efficiency! I expect there wouldn't be much of a difference as you would still need to evaluate for all of the prime numbers eventually.
/u/Sir_not_sir has the correct info. I'll add that you should ask this in /r/learnpython next time.
[This book](https://pragprog.com/book/gwpy2/practical-programming) and [this site](https://docs.python.org/3.4/).
You are a good person, thank you!
Note that the function thing doesn't work for common use-cases, where one wants conditional evaluation of the default, `data ??= expensive()`. This certainly isn't a necessary addition to Python. Frankly, there should be a syntax freeze until the version debacle is over.
This is pretty awesome. Thanks for sharing it!
You should look into implementing a segmented sieve. This will reduce your memory requirements from O(n) to O(sqrt(n)), while retaining the same runtime complexity. I'll post some code later if you like.
Please define "smooth" :) It usually means C^∞, having derivatives of all orders, which are then necessarily all continuous. Given a finite set of argument/value pairs, there are uncountably many (continuum-to-the-continuum many) functions satisfying those conditions; some are smooth, most aren't even continuous, and some of the latter don't even exist in all models of mathematics (set theory).
Take a look at [pickle](https://docs.python.org/3/library/pickle.html). It can work with many user-defined classes automatically, but if not your class [can customize the behaviour](https://docs.python.org/3/library/pickle.html#pickle-inst).
Well, you should not have 0 be falsy value, to begn with. Sane dynamic language should only consider `false` and `nil` to be falsy.
And I can clearly see that the only obvious way to format string with known format is to use f-string. `str#format()` should then be used only when the format string is dynamically built. That is, you only use the version that takes keyword parameters for replacement.
what sort of development have you been doing ?
I love : "The {x} shop is {y}".format(x = 'Cheese', y = 'open')
I don't get it. What is it
repost yet again
rejection hotline
You might like [MoviePy](http://zulko.github.io/moviepy/) the docs are great and it's constantly updated.
This looks so unpythonic to me I hope it gets rejected.
You could do that thanks to first-class functions: def is_none(original, new, *args, **kwargs): if original is not None: return original if len(args) &gt; 0 or len(kwargs) &gt; 0: return new(*args, **kwargs) return new Then you could use it like: &gt;&gt;&gt; is_none("Hello", "Hi") 'Hello' &gt;&gt;&gt; is_none(None, "Hi") 'Hi' &gt;&gt;&gt; is_none(None, sum, [1, 2, 3]) 6 
That rule is too restrictive (and it's questionable whether different methods for different configurations of string and variables doesn't violate one way to do it or special cases not being special enough to break the rules). last_name = "Smith" first_name = "John" print("{0}, {1}: Mr. {1} is a good employee.".format(first_name, last_name)) No keyword parameters but you've avoided typing the variable name twice. 
I'd think their examples would be more valuable if it wasn't possible to just throw a 9 line decorator at it def deepcopy_defaults(func): defaults = copy.deepcopy(func.__defaults__) kwdefaults = copy.deepcopy(func.__kwdefaults__) @functools.wraps(func) def wrapper(*args,**kwargs): func.__defaults__ = copy.deepcopy(defaults) func.__kwdefaults__ = copy.deepcopy(kwdefaults) return func(*args,**kwargs) return wrapper @deepcopy_defaults def somefunc(eggs,spam=[],etc={}): # Works as expected and then suddenly defaults work exactly as one reads them, syntax requires no changing, function definitions are usable, etc etc etc not that this is alone enough to say, no None coalescing operators, but it does feel like a fairly massive motivating usecase
Eeeek. The "Null-Aware Member Access Operator" doesn't make sense? Presumably *title.upper* should evaluate to *None* if *title* is *None*. But then *title.upper()* should throw an exception because that is *None()*. To make it 'work' *title.upper* in that sitation would have to a evaluate to some special version of None except that it is callable (with any arguments) and returns *None*. Looks like a disaster waiting to happen .... 
I am aware, but to be more explicit in what I'm talking about: any 'slightly more than a function call' situation, e.g. chaining method calls, adding items together, etc etc, all require a lambda thrown in as well
why not `somedict.get(requiredkey, somedict['optionalkey'])` then?
This really was one of python's more stupid design decisions: x = "" if not x: print "because fuck you, that's why" x = 0 if not x: print "because fuck you, that's why" x = midnight if not x: print "because fuck you, that's why" Sure, they *finally* got around to fixing the third one (I still saw people defending it to the end, though), but the first two are still out there causing horrible obscure edge case bugs. Explicit over implicit my ass.
Remember when people said python ternary operator wasn't good for readability?
I get why they did , but I agree it was a stupid fucking decision.
While I don't think this PEP should be accepted, &gt; is just not the language I know as Python. is a stupid fucking reason for not accepting it. Also, see [here](https://www.reddit.com/r/Python/comments/3lkaxc/pep_505_none_coalescing_operators/cv7kmg5) for why your third solution gets very complicated very quickly.
Here's the results: https://www.youtube.com/watch?v=v3d_LKi4hRo * Basically it burns straight up until it hits 100 m/s * Then it starts to turn east, until it hits 0 degrees at 30km altitude (parallel to surface). It also watches terminal velocity and slows down to stay a little above it. * after that, it tries to stay close to its apoapsis, keeping its altitude around 10km away from it, while slowly rising it to 75km apoapsis * By then, it's got about a 14km periapsis, and will wait until it hits 8 seconds before its apoapsis and slowly burn, wobbling right on its apoapsis, until the periapsis matches. Seems pretty efficient! I'm sure it could be more efficient, but way better than my first iteration of this code (and probably way better than anything I've done manually).
[removed]
How would this handle a craft which is physically incapable of making it to orbit? Do you think you could detect that eventuality during flight and do some kind of return to earth?
What if you need to go 4 levels deep and each level can be None?
I'm sure there's a way to fail gracefully. If it detected it started to flip upside down, or that it wasn't making progress in general, you could have it attempt to slow its fall and trigger the abort easily enough. All you'd really need to do is put in detection logic for some general failure (velocity increasing towards surface, direction pointing down), then have it click abort, and if it's near 2000 terrain altitude, trigger parachutes. If you're talking about the rocket landing vertically... very difficult but possible. Chutes make life easier.
This is when I most frequently discover I need to use this sort of functionality.
Python is strongly typed. Making requested_quantity = None a synonym for zero seems like lazy programming that should not go silently.
Tried to build the package with pip but it fails. Hopefully the package is fixed soon as I'd love to try this out
I use openpyxl for both reading and writng Excel file on a number of reporting projects - works very well. The documentation is sometimes a little lacking for more advanced formatting (I found myself reviewing the source) but for what you're looking at I imagine it would be very a good match.
It's discussed in the PEP. with your syntax, any falsy `y` well be replaced with []: def boop(x, y=None): """y should be a list. We append x to it and return it.""" y = y or [] # Trouble here; see below y.append(x) return y my_data = [] boop(3, my_data) # Unfortunately, at this point, my_data is still the empty list. The correct way to do that is to write y = y if y is None else [] which gets long and annoying and redundant (imagine if you were working with `long_variable_name` instead of `y`).
APL might have been a little much, but it's the classic example of choosing brevity of code over readability. Read your code out loud and I hope you'll see what I mean.
"Foo equals bar maybe dot baz defaulting to 3." Even out loud, I think this is readable. Perhaps this is a matter of personal style, and neither of us will be able to convince the other of our opinion. edit: I still don't think I'm choosing brevity above readability: I'm choosing brevity _and_ readability above complicated code. Similarly, I will continue to use `or` instead of using only `and` and `not`, because it is both briefer _and_ more readable.
This is such an awesome proposal. I could particularly see something like this being useful for basic web logins for things like Flask and Django (I know there's stuff for them, but nice for it to be part of the standard library).
 **Violent Python: A Cookbook for Hackers, Forensic Analysts, Penetration...** |||| --:|:--|:-- Current|$32.21|Amazon (New) High|$37.41|Amazon (New) Low|$24.10|Amazon (New) |Average|$31.15|30 Day [Price History Chart and Sales Rank](http://i.imgur.com/SOmtAQ0.png) | [FAQ](http://www.reddit.com/r/PriceZombie/wiki/index) 
That's actually a really good PEP. Cryptography has always been the future of computer science and we should very well prepare for it.
Yeah, we can't really tell you what to do unless we see the text file, but after that it's trivial.
The [modern consensus](http://sockpuppet.org/blog/2014/02/25/safely-generate-random-numbers/) seems to be to use the OS random number generator directly, without an extra PRNG on top.
Significant problem with the API you're using as a base: It doesn't accept movie titles with only one character. The issue is that there are a lot of movies with a title of only one character.
Then use the .splitlines() function on the text file to create a list where each line is a new item, and since it's one password per line, you now have a list of the passwords you can cycle through with the for loop.
yes, your problem is, that you're trying to find a password that literally has a space at the end, which does no occur in that file. Every line ends in a line feed (probably, depending on your OS and how you saved the file). Seeing how every single line is just a single word, you probably can just line.strip() every line, to get "clean" passwords (i.e. getting rid of line-breaks at the end), and do exact matches using "==" rather than "in".
Thanks man :D
I'm not familiar with the APIs for keychain, DPAPI, etc. Are the various os secret manages similar enough that a cross-platform wrapper on OS X, Windows, and major \*NIX distros would be reasonably maintainable and provide a reasonable feature set? There's nothing wrong with OS-specific code, but the standard libraries should strive to abstract away the specifics of the machine, I think.
Did you write this comment in 1940?
I'm not going to teach this syntax to students even if it gets accepted. They should learn idiomatic python, phpython or perlton or worse Py#.
Pickle is ok, but I think [shelve](https://docs.python.org/3.5/library/shelve.html) Would be better. You can use it to store key-value pairs (Basically python dicts). And access it like any other dict Example: import shelve d = shelve.open('d) d['a'] = 10 d.close() And to get the value back: import shelve d = shelve.open('d') print(d['a']) It still uses pickle as a backend, so it can deal only with values that pickle can, but I find it much more convenient when I have to keep &gt;1 value 
JSON is conceptually different from Pickle (and some of the numpy binary formats). With JSON you are creating a textual representation of the object, and rebuilding that object when you re-load it. This creates overhead in the saving and reloading, but makes it portable and human readable. With pickle you are saving what we can consider to be a memory dump (an exact clone of system memory - although the interpreter likely doesn't work that way). This makes it non-portable and not human readable, but it is vastly more efficient. If you wanted to take a snapshot of an array so you could resume your process after a halt, pickle would be the way to go. If you wanted to exchange that array with someone else on another system, JSON would be more suitable.
This is roughly adapted from a book on computational physics. Using the method of least squares, fit a second degree polynomial to each set adjacent set of three points and look at the average value of the coefficient of x^2.
Ok, this is the impression I'm getting so information is matching up. Thanks for the help. 
&gt; Speaking of which, you could also write that same code `print('x={}".format(x))` and `print('x='+str(x))` are both calls to print with a string argument. They're the same. `print` takes an arbitrary number of arguments and a separator, it converts the arguments to strings and it joins it. In regards to string formatting (e.g. fixed precision), you have to do it at some point, so that they support it isn't a bad thing. &gt; Because there should be one, and only one, obvious way in which to do it. We should probably get rid of `x+=1` then and things like `x=[None] * 100` then. We should also get rid of lambda. None of those are obvious. However, Python is generally a very simple language. It's simple enough.
Ok. I have yet to test shelve but from skimming over the documentation I agree that it seems to be the better option. Pretty much pickle with a more convenient interface. 
I don't think you've succeeded in explaining what this is _for_.
This PEP is nice to see. I reworked the very old registration stuff at work recently, so it seems like I'm frequently looking at password reset tokens and junk like that lately. Dealing with crypto always makes me feel like I never can know enough to make safe things, so I appreciate when others are keeping the interests of devs like myself in mind. It's absolutely true, though: those comments about developers either naively or under time constraints cutting corners on this stuff and when exploits happen they do have the potential to make us all look bad. I myself have seen in production code examples of googled, soft solutions for crypto. Some of the attempts at randomness I've seen include triple hashing and taking the first ten chars or including string values of functions. Also, I liked this footnote: &gt; Tim Peters suggests that bike-shedding the contents of the module will be 10000 times more time consuming than actually implementing the module. Words do not begin to express how much I am looking forward to this.
I haven't updated to 3.5 yet.
https://developer.gnome.org/libsecret/unstable/py-examples.html The (Linux-y) GNOME Keyring documentation gives examples in Python. I'd imagine there are bindings for other platforms' keyring APIs too.
There definitely exist system keyring bindings you can install. But to have acceptable subsets of them bundled up in the standard library would allow people to build simple and standalone Python scripts that handle their secrets securely.
Some variation of `foo.get('bar', {}).get...` has occasionally worked for me.
Batteries included. There's value in just being able to plop an useful script to a system with a recent Python and have no other set-up needed.
Having done a bunch of hackathons, here are some tips: - Pick a project that has a nice visual component. For example if doing networking, connect it to a data visualization library or a dashboard with charts and graphs. Bokeh is a nice python library that is easy to integrate. Everyone likes pretty pictures :-) - Put together a nice looking 'project overview' slideshow that quickly describes your team's idea and sets the stage for what you've tried to build. Show that before your final demo so everyone knows what's cool about what comes next. That way you also don't waste a lot of valuable demo time talking and can quickly jump to the actual demo part. - NEVER show code unless your idea is a new IDE. - Take a screenshot of your app working and have it as backup. If during the demo things don't work you can switch to the static shots and show what it would have looked like. Everyone understands that demos glitch. Don't waste time trying to get it fixed or start from the top. Switch to the static shot so people can at least see how far you got. - Lastly, if you don't get all the parts of your demo built don't worry about it. As long as the idea is cool and you have a slideshow describing what you planned to build, people will understand that time is short. I was once in a hackathon where another team had a really nice slideshow with a really big idea. At the end they had zero actual working code but they ended up winning the whole thing because their idea was so much bigger than anyone else's and the judges really wanted to see the product built some day. They also had a pretty cool concept video that they had built ahead of time. So think big and have fun. 
Mutable degaults are a huge python-no-no. There is no need to call that into question. Google it: thousands of votes on theissue on stackexchange, top gotcha in countless articles and mentioned in probably most python books.
It's unlikely that they'd be simple to abstract, but it certainly could be done (many common applications do it). I got my hopes up thinking that's what PEP 0506 was going to provide, that's all.
No. Randomness testing has nothing to do with security, it only tests the statistical distribution of the output. The Mersenne Twister, the algorithm used by python's `random` module, passes numerous tests for statistical randomness. Nevertheless, observing 624 output values from this generator is sufficient to completely predict all future generated values with 100% accuracy. Generally, new cryptographic methods take many years before they are adopted. Especially for projects like python: the generator will be in used in many programs and cannot be easily replaced. Choosing an algorithm that later turns out to be insecure could be extremely disastrous, so it is preferable to choose an algorithm that has been tested and used successfully in the field. 
Before you roll your own I'd try [scipy](http://docs.scipy.org/doc/scipy/reference/).
No, it is not. The program above doesn't really modify kerbal Space Program at all strictly speaking. It only sends some control information. Kerbal Space Program is a game with very good support for mods. Someone has built a mod called kRPC, which is able to receive data from other programs and computers. It implements a "language" of sorts, a protocol, through which other programs may control the game. Then, someone built a library, in this case for the python language, that "speaks" this language and allows a python programmer to write python code describing actions to take in the game. So in total, having these two programs talk to each other is quite a lot of complicated work. It just turns out that in this case most of the work has already been done by other people, and can be reused fairly easily. 
Sadly i don't know how to do that- I installed using pip. I'm trying to figure it out though (It's about time I learn all this git business), and it should be worth it. Thanks for pointing me in the right direction!
Ok. Well we clearly have different pieces of anecdotal evidence.
Cool, good to hear!
And Keyctl on Linux...
Good idea, bad name choice.
With shelve you have to pay attention to the underlying database if you think about moving the db file to another system.
Does a youtube search with your query and downloads the audio from the (several?) video that result. Seems like it'd always take the last video on the page. Not the most robust script. Like even if it's the related video or something.
This isn't a Python question. On Linux, `kill -9 ` and the process ID. The `&amp;` puts it in the background. On Windows (what I use most of the time), no idea beyond just crashing it.
I originally typed out a similar response but decided against posting it for fear of pissing people off. So you are not alone. I actually think that it would be better idea to expand the documentation (and make the warning a bit more scary and explicit), including as much use cases as possible and how to use the functions in the existing library properly. That way you will educate the programmers instead of keeping them in dark for ever. 
Oh soory, and thanks!
We just started using this library at my job, and I like it. The configuration changes look interesting, I'll have to play around with my static analysis Jenkins jobs when I get in to work tomorrow.
It is really curios how different we all are. Because I find the first one completely obscure and total prefers seeing the latter. And Python already have things to accomplish what you say (about making it clear what it is doing ie set foo). foo = bar.baz() if bar else 3 Constructs like your first example is exactly why I don't like this pep. 
the [keyring](https://pypi.python.org/pypi/keyring) package on pypi provides a nice cross-platform interface to those very apis. 
 # Links are relative on page, making them absolute. video_link = 'http://www.youtube.com/'+video_link command = ('youtube-dl --extract-audio --audio-format mp3 --audio-quality ' + DEFAULT_AUDIO_QUALITY + ' ' +video_link) # Youtube-dl is a proof that god exists. print ('Downloading...') os.system(command) Kind of makes me want to get a job at YouTube and put `&lt;a href='&amp;&amp; rm -rf /'&gt;&lt;/a&gt;` in the footer.
This is actually a reasonably benign use of metaclasses, although it suffers from the usual problem that it becomes difficult to multiple-inherit from two classes with distinct metaclasses. There is an undocumented `__subclasses__` type object method that achieves a similar effect, without requiring use of a metaclass: def get_class_subclasses(cls): return cls.__subclasses__() ````
As an Ansible user, the configuration problem is solved by templates and having ansible variables that get replaced in those templates. The Ansible variables can live inside the inventory files. You can version control your inventory files. I would stick to pure Ansible as it can probably do both provision and deployment - (check modules for git and virtualenv). The only real feature that I like from Capistrano is the rollback mechanism. http://docs.ansible.com/ansible/playbooks_best_practices.html There's nothing fundamentally wrong with your approach.
:(
`bg` will tell you what processes are running in the background (protip: you can also push a process into background by pressing Ctrl-Z). `fg` will bring it back, so then you can safely kill it with `Ctrl-C`. Or just `kill -9` + the PID (from `ps aux | grep ___`).
&gt; else: &gt; response, prev_resp = talk(inp, prev_resp, data) &gt; print("BOT: ", end = "") &gt; for word in response: &gt; print(word, end = " ") &gt; print() When I run this i am told that there is a syntax error at print(BOT, end = " ")
About 1.5 years I was looking for an answer to a very similar question. You can do it with PyAudio to a certain degree but when it comes down to it, I'm not sure that Python is the best language for working directly on media files. I use Python for a lot of things but if I need to do anything with audio or video files, I end up using C and the ffmpeg libraries. You might be able to get away with PyAudio if its very simple. Maybe it's improved since the last time I looked at it.
This is why we never run as root, kids. ...although that said I wouldn't be much less devestated by '&amp;&amp; rm -rf ~/*'. Sanitize yo' script, OP.
Because Python prevent hard to find bug, when you allowed an assignment operator in conditional statement. This is one of design mistake of C language that almost every language allowed to used. 
Pygame does those things - don't let the name fool you, it's useful for much more than just making games.
&gt; kill %1 If you have more than one background processes, you can see them by doing &gt; jobs
Python is my go to as well. it's why I'm currently prototyping a video program in Python with OpenCV as a proof of concept but will be taking it to C/C++ if I can get someone to sponsor my research.
Just `kill`. `kill -9` should be a last resort as it does not give an application the chance to respond and clean up and is very rarely necessary.
Check PyPI, with `pip search` or just through the site. If not there, check github and bitbucket to see if anyone tried it before. If google fails along with everything else, you might be tasked with doing it from scratch, in which case you can ask people who have done similar things for suggestions or you can just start reading documentation and experimenting. If kRPC didn't exist, you'd have needed to look into writing C# and modding the game first, so you could emulate what they did, write a server that lets you read and modify things from an arbitrary client. Most of the work here was done by others with that kRPC mod. They opened everything up to let you play with it. And kerbal space program is openly moddable. If something is not that open to mods, you'd have a lot of trouble doing something like this, but it's always possible if you can read and write directly to the program's memory.
What is coverage.py?
Pro tip: just like pasting any random string into a [SQL query](https://xkcd.com/327/) is a bad idea, pasting it into a shell command is an even worse idea (as /u/ckinsey says). Suppose you have this code: import os my_arg = "/ ; echo LOLHAXEDBRO" os.system("ls -a " + my_arg) `my_arg` has a malicious value that injects code to get run into your system's shell. That's very bad: . bin dev etc initrd.img lib lost+found mnt proc run srv tmp var vmlinuz.old .. boot .docker home initrd.img.old lib64 media opt root sbin sys usr vmlinuz web LOLHAXEDBRO Instead, use the `subprocess` module. It takes a *list* instead of a string, and makes sure things are concatenated correctly and safely as arguments. Like this: import subprocess my_arg = "/ ; echo LOLHAXEDBRO" subprocess.call(['ls', '-a', my_arg]) Which has the output: ls: cannot access / ; echo LOLHAXEDBRO: No such file or directory Your system is now safe from running errant commands that get injected. [Congratulations](https://i.imgur.com/74UlpLe.gifv)!
What? You don't want to avoid typing variable name twice just for the sake of it. This format string want to output the same variable twice, it makes sense to write it twice. And why do I need to do mental mapping of what variable `{0}` or `{1}` refer to? 
Some project ideas : - a decent crossplateform GUI for Git. - a pure Python image manipulator using cffi and os libs to do the job. - a twitter stream manager : backup, search your stream, keep searches of others streams with filters, etc. - distributed encrypted pastebin. - local network chat and file sharing with autodiscovery and groups. - simple and quick image editor. - Contact details web service with synchronized offline version. Really, just pick something you can't do properly right now and tackle it.
https://www.reddit.com/r/Python/comments/1y8ae8/a_reddit_clone_built_with_flask_and_python/
Sounds like refactoring the dict might make some sense, in that case. Or, if it's really important that it stay structured in that way, it might be a better idea to turn it into a real data model class that can handle the data in a more structured way.
X-Post referenced from /r/programming by /u/tender_programmer [My weekend project: covuss - CVSS calculator](https://www.reddit.com/r/programming/comments/3lrsld/my_weekend_project_covuss_cvss_calculator/) ***** ^^I ^^am ^^a ^^bot ^^made ^^for ^^your ^^convenience ^^\(Especially ^^for ^^mobile ^^users). ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher)
An excellent tool for measuring and reporting test coverage on code. Works well with nose and pytest.
https://www.reddit.com/r/Python/comments/3lpgzz/instantly_download_any_song_without_knowing_the/cv8pwx1
You might be able to get away with no rollback is your environment is simple enough. This anistrano does look promising.
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Show them that you've tried to solve your problem and you can get all the help you need. Cheers &amp; best of luck!
Most "consensus" have talked in the context that we don't happen to have a good, fast, PRNG just lying around. Which has been true the last couple decades. This is starting to change.
Maybe something like this is what you want? It is looping over a generator, which has a conditional statement in it. for i in (j for j in lst if j == x): Though in reality this is nothing different then: for i in lst: if i == x:
Is this not going to suffer from the same problem that's keeping requests out of the standard library: security practices change faster than the python stdlib release cycle?
Pickle and shelve are both great. Also check out joblib.dump It's definitely the most straightforward interface, and I believe it's the fastest as well. 
How do you get the static analysis and coverage reports back to developers? I'm generating coverage for fresh builds of an entire yocto system however I don't think any of the other devs check unless one of the failure parameters is exceeded.
For scientific simulation, absolutely, no question. For other stuff, running the RNG can be a big source of power drain in order to power other cryptographic processes. If you suddenly have a fast PRNG that's also cryptographically suitable, suddenly your power bill can go down.
This and [fuckit](https://github.com/ajalt/fuckitpy) should be added to the standard library.
just to make things clear, I am not the author
I'm pretty sure device doesn't work on Windows, but I'll look at pysndfile
Why is the space legal in `label .begin`? So I had to try it with everything, and lo and behold: Python 3.4.3 (v3.4.3:9b73f1c3e601, Feb 23 2015, 02:52:03) [GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; import sys &gt;&gt;&gt; sys .version_info # There's a space there. sys.version_info(major=3, minor=4, micro=3, releaselevel='final', serial=0) Ok, why? edit: OP, it's late September. School has started. This is positively the best time you could have released this! :-)
Cool, didn't know that.
oh dear god
AFAIK no-where in Python is space used to delimit tokens, the only time it has syntactic meaning is when indenting.
why did i not know about it before?! best module ever
goto is like any tool in the programmer's toolkit. Use it sensibly and you end up with cleaner code, use it badly and you're into spaghetti code.
1. As someone who is writing a programming book, it's literally impossible to not make some mistakes 2. They basically want the book to teach everything there is to know about Python. That's ridiculous. 3. Some of these complaints contradict each other e.g. &gt; Does not teach with for processing files and &gt; Exceptions are finally taught in Ex 48, after the setup script. This is the first time a string is converted to an integer and exceptions handled appropriately. conflict with &gt;Really backwards teaching order, files taught before any control structures. How early do you want to introduce the with keyword and exceptions? 
I'm exaggerating more because I've come to hate those 4 letters because of lazy programmers. There are legit uses, but at the same time it does encourage a ton of bad behaviors. 
2.7.somethong
go to hell
So that the bytecodes don't move from their original positions, which would require re-writing lots of offsets through the whole function.
I think there are some fair criticisms on that list. Note that the individuals who compiled the list answer a lot of questions on StackOverflow, and they seem to believe that a lot of the worst questions seem to be from people using LPTHW. I think it's worth a read and your consideration. Cheers!
Embarrassed to ask but what is Goto?
Check the wiki: https://en.m.wikipedia.org/wiki/Goto
I always thought the purpose of a hackathon was to show/share code with other attendees? I've never actually been.
Wait, what? Why does that happen?
The https://www.python.org/dev/peps/pep-0394/ refer to this problem and says that `python2` and `python` should refer to the same application.
 import os os.system('eject') This only works if you have eject install on linux.
Only if `python` is source compatible with both. Thanks for that. That maybe enough. 
&gt; Or by adding a backslash at the end of the first line The backslash is important, but /u/nemec still has a valid point, as Python will interpret the line as "a s d f g h j k l".split() .index("g") which remains valid as the whitespace does not affect the lexical parsing of the statement.
 password = raw_input("Please enter your password").strip() for line in open("passwordlist.txt"): if password == line.strip(): print line There was a bug (of course, not tested on real data). The above code should work - its tested. The previous one was reading an extra newline character.
Thanks
Yeah. The issue here is specifically the newline, not whitespace in general.
Yup, @, the equivalent, is a language feature. Of course. 
Yeah, its one of the differences between python 2 and 3. I wrote the program on python 3.
Except in this [case](https://www.reddit.com/r/Python/comments/3lsh1d/goto_in_python/cv9288k) where the space does delimit the tokens and makes a difference. 1.__str__() SyntaxError: invalid syntax 1 .__str__() # A space between 1 and the dot. '1'
Couldn't I do that with function calls and break statements?
These two lines of code produce different tokens: if a == 1: ifa = = 1: This is what bugs me about people complaining of Python's "significant whitespace". **Every** programming language has significant whitespace.
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Show them that you've tried to solve your problem and you can get all the help you need. Cheers &amp; best of luck!
Pretty cool site actually. Good work.
Seems more like poll results rather than a poll.
then you will love this shell command ~~~https://github.com/ajalt/fuckitpy’~~~ https://github.com/nvbn/thefuck Sorry, wrong link 
One more CLI tool written using the awesome Python Prompt Toolkit. https://github.com/jonathanslenders/python-prompt-toolkit If you're looking to write a REPL, you should look at prompt toolkit. It has plenty of examples and very friendly community.
&gt; **Every** programming language has significant whitespace. Fixed form fortran has no significant whitespace within the statement itself. However, every source line has to start in the 7th column with optional comment or line continuation markers in the 6th column. The first five columns may contain a number - a feature that was very useful back in the days of punchcards. From the 7th column onwards however you are free to insert or delete as much whitespace as you like without changing the meaning: go toast is the same as: goto ast
Pick a number 500 times in a row and i think you would lose the will to live, let alone win the game
They acknowledge that [here](http://www.utf8everywhere.org/#faq.python) and still argue that it's not good enough, though they don't convince me.
Thanks for this! I really enjoy the format and explanation, looking forward to reading all of them.
Shaw's Learn Python the Hard Way is my go-to for offering advice. This particular lesson, [on classes and inheritance](http://learnpythonthehardway.org/book/ex43.html) is simple but might get you thinking about classes and functions. Worth a read in my opinion!
Your question reminded me of [this](http://img0.joyreactor.com/pics/post/gif-baby-geek-242032.gif). i think this was done with a BASH script but you get the idea.
&gt; And by the way, a break statement is a goto statement in disguise. Shhh! We're all supposed to pretend that's not the case and also that `break`ing out of nested loops is somehow different too.
`random.randint(1, 3)` seems like a terrible strategy even if it were allowed. You can beat it by playing 3 every game: A third of the time you will lose 1 point, a third of the time you will gain 2, and a third of the time you'll stay equal. EV = 1/3 * (-1) + 1/3 * 2 = 1/3 You're up 1/3rd point per game on average. `randint(1, 4)` isn't much better: playing 2 against it every game will get you 1/4th point per game on average. In fact, against every strategy `randint(1, x) with x ≠ 3`, playing 2 every time will win on average. The larger the range, the larger your advantage: you'll gain an average of `(x - 3)/x` points per game. Even with `x = 3` you're on equal footing. For x &lt;= 2, you can never lose. It seems in general that playing 1 is always bad, it's better to just play 2 instead. Both win against every number larger than 3, and both have a single number they lose double to, but 2 wins double against 1, while 1 doesn't win double against anything. 
I am sure you know, but for the benefit of others, `inline` is a *suggestion* to the compilier and not a command. It isn't required to inline it.
Learn Java. Only half joking here. You will understand when OOP is useful, when it is frustrating, and how people think when every line of code is part of a class. Understanding how to structure a project is arguably the hardest aspect of software engineering so a a few pages outlining syntax isn't going to help much.
I primarily code on a control system (DCS), and I have to use a lot of GOTO statements (want the code constantly looping). The GOSUB return stack also only holds a few items so I have to keep them under control, too. OFFLINESTEADYSTATE: # SEQUENCE GOSUB DO_SOME_STEADY_STATE_STUFF GOSUB UPDATE_IMPORTANT_STUFF # OPERATOR COMMANDS IF START_CMD THEN GOTO STARTING IF STOP_CMD THEN GOTO STOPPING GOTO OFFLINESTEADYSTATE
Awesome, lasagne is that recipe management framework, correct? For chefs and cooks. ALWAYS GIVE A DESCRIPTION OF YOUR PROJECT SO WE MAY GIVE A SHIT
Yes
&gt; Still getting errors? Chain fuckit calls. This module is like violence: if it doesn't work, you just need more of it. I like this thing
True, though unless the functions uses loops or recursion, it almost always will.
Because clicking is hard?
If `break` is a `goto` in disguise, then an exception handler is a [`come from`](http://hydra-media.cursecdn.com/dota2.gamepedia.com/5/5d/Dro_respawn_06.mp3). 
OK, in python 2, input should be raw_input() So any inputs just change to raw_input
I can't disagree with your rough assessment of my co-worker. I did see the free ebook, and have visited scipy and gotten must of the science packages. I've been stockpiling plenty of stuff posted by this community for use later I'm going through tutorials now, and have another co-worker versed in python that should be able to help. Thanks!
The most infamous debate in programming language design - allowing programs to go to a specific line. This was replaced with structured programming where with a combination of loops, if-then statements, return, break and all that jazz you prevented spaghetti code and could actually tell where a program started and ended. Delete a line in a program with a lot of gotos, and you can cause the entire thing to come crumbling down. The paper "Goto considered harmful" is the source of programmers talking a lot about "safety."
It's a bit of a buzz word, but search for a company working on the "internet of things"
&gt; tests.py 100% COVERAGE TRUST ME IM A PROGRAMMER PROBABLY 
But that makes the value being stringified a float rather than an int.
We don't really. In the various companies that I've worked in that have measured code coverage, the results have always been available to the developers via the CI tool, and at my current gig, we have certain Jenkins jobs hooked into Slack, so if someone managed to bring down the coverage percentage a significant amount, they (and everyone else) would be notified of the results. But really, in my experience, code coverage isn't something particularly relevant to individual developers as they're coding. I mean, you obviously want everyone to be writing tests and for the coverage to be trending higher. But really, I've mostly seen it used as an indicator for a senior/managing dev (or maybe even a PM) to know where weak spots are. Maybe a particular component has low coverage because it's untestable, or maybe it just needs some love the next time someone goes in to add a feature or fix a bug. The coverage report doesn't really tell you much on it's own, just where to look for problems. And that type of analysis is more of a high level task than the typical dev should worry about. Anyway, to answer your question. Everyone on our dev team (actually, everyone in the company) has access to our Jenkins dashboard and can view all of our job status results (coverage report, lint analysis, mess detection, cyclomatic complexity -- the whole shebang). There are probably ways to have Jenkins (or whatever CI tool you're using) pull out individual job artifacts and deliver them via some communication channel (chat, email, some third-party dashboard, etc), but this has never been a necessity for the companies I've worked for.
AFAIK, for years it has been the case that it a decent C++ compiler will frequently inline things even without being asked.
What is this supposed to show? My example clearly demonstrates that python does use whitespace to delimit tokens. Rather or not there exist another syntax to achieve the same thing is irrelevant.
Yup, anaconda is what I picked up and installed... Just working through official tutorial now
Sa vs Samoa. Still 80%. How does it compare to the bookies? 
If accepted, this will get me to finally switch from 2 to 3
Too bad they ask for so much personal information!!!!!
Uh that Rails is a Ghetto link is fantastic, so much of what he's saying there is true that it's a ridiculous amount of sunlight on an industry full of vampires. That guy deserves a medal.
I think you forgot the closing /s tag. It only asks for name and e-mail address. (Both of which can be faked without any retribution.)
Sure, with the unnecessary overhead of function calls.
You should totally learn python. It is the most beautiful of all the languages that I have learnt, and I have learnt various languages to various degrees... like Matlab, C, C++, Java, Javascript, Scala, Haskell and Swift. In addition to all the scientific feature support, it has a lot more. You will enjoy programming much much more... it is a language in which I relish solving problems. It takes the minimum amount of effort to get a program going in python, while still retaining the capability to do anything. Also, I have written 3D graphics UIs using wxPython and PyOpengl. I state that here to say that its possible to make programs with slick UIs using Python. Surprisingly, the screenshots at http://www.wxpython.org/screenshots.php are out of date... our python app's ui looks indistinguishable from any other windows / linux app. 
input pennies dollars = pennies // 100 pennies = pennies - dollars * 100 quarters = pennies // 25 pennies = pennies - pennies * 25 dimes = pennies // 10 pennies = pennies - dimes * 10 nickels = pennies // 5 pennies = pennies - pennies * 5 There is a way to do this with modulus but I'm forgetting it at the moment. Also, /r/learnpython 
Done before at least 3 times: http://www.dr-josiah.com/2012/04/python-bytecode-hacks-gotos-revisited.html
&gt; what is Goto The singer that was in Midori. Mariko Goto. https://www.youtube.com/watch?v=AlAf3YVMlag
Not quite. Space is _ignored_ between tokens but its presence can change what is parsed as a token. It generally matters when operators are involved: i += 1 # ok i + = 1 # SyntaxError The sibling post by /u/kirakun shows another example with numeric constants.
Is it really that difficult to take two seconds to go back and read the relevant code? &gt; def is_none(*args): for arg in args: if arg is not None: if hasattr(arg, '__call__'): return arg() &gt; return arg &gt; &gt; and then use partials for any function call parameters that need parameters of their own: &gt; from functools import partial &gt; &gt; is_none(item1, item2, partial(func3, f3a1, f3a2...), ...) partial doesn't just replace the function with another function call, it also holds the arguments given to it ahead of time. This allows you to provide a function call with arguments, but not actually evaluate the function until you call the partial object. In the above example, `func3` isn't ever called at all unless both item1 and item2 are None.
Yeah this is typically a case of "I'm an expert, and fuzzy character iterations is not accurate enough for my use case", ignoring the fact that most people don't care about his/her use case and just want to iterate on a "good enough" approximation. 
/u/99AFCC gives a good answer, I'll try to give the explanation. In the future, you may get better help at /r/learnpython. When you have 229 pennies, for example, you want the least number of "items" (whether that be coins or bills). It stands to reason that you want to put as much of the value into the higher-valued items as you can, without going over the limit. So how many dollars can you get out of 229? 2, right? But how did you come up with that? Your reasoning might have been, "Well, a dollar is 100 pennies. I can only fit two of those evenly in 229 without going over." In other words, you divided 229/100 and took the quotient (whole number part) (which is 2). But the other part, the remainder is important too - you still haven't accounted for those. Right now, you have 2 dollars and 29 pennies - you may still be able to express the pennies in fewer coins. 229/100 = 2 dollars remainder 29 pennies Now that you can't fit any more dollars (if you do it right, you will always end up with a number of pennies less than the value of the denominator), you try quarters (the next most valuable). Similar idea. 29/25 = 1 quarter remainder 4 pennies Note how the remainder is always in pennies (this is displayed in the fact that pennies is always the second element in /u/99AFCC's answer). Just keep dividing the remainder by the pennies-value of each item, until you get to pennies (which necessarily will leave a remainder of 0: can you prove why?). Once you hit 0, you know that you've exhausted all the value.
A tip on coding: note that the code right now is very repetitive. Can you generalize it to work with any value-coins I give you? For example, 95-cent coins and 33-cent coins and 1-cent coins (why does there always need to be a 1-cent coin for this to work on any input?). Try writing a function that, given a sorted list of coin-values (like [95, 33, 1]) and a value, will return the number of coins needed in that order. For example, for the value 97 cents, you would return [1, 0, 2]. You will need to use either some sort of loop or recursion. Note, nothing about this function assumed a unit. So this function will work for time too, if you just give it [365, 30, 7, 1] as an input.
Good. Having it in proper PEP form is the correct way to have it rejected with proper documentation of the rationale so you can have a place to point people every time this pops up. def coalesce(*args): for arg in args: if arg is not None: return arg
&gt; I've had to teach programming classes and write out instructions for downloading, installing, and configuring IDEs. Having all of that done when you install the Python interpreter removes a SIGNIFICANT hurdle to getting people to code. Have you done much with Anaconda and Spyder? I did my first stuff in Python using Eclipse plus terminal windows, etc. But my recent dabblings in Python with Spyder make it look like a decent and not-too-complicated IDE.
Just took a glance. 393 pages that are filled with a lot of content. Actually it is a curated collection of chapters from the O'Reilly Data and Programming Library: Python for Data Analysis, Effective Computation in Physics, Bioinformatics Data Skills, Python Data Science Handbook So it is not a real book
The first bookie site I found currently has SA at a 90.71% chance of winning the match against Samoa. So our model is less confident of this being the outcome. However, we know very little about how bookies operate and obtain their estimates. In addition, the aim of the project for us didn't really include any desire to do sport betting. But I still enjoy looking at bookie estimates and find it interesting to see how we compare. 
Goto is one of fundamental building blocks of Spaghetti Code.
Do you mean: for x in product(*iterable): ...
No specifics but you might want to look into how HomeBrew does this on the Mac. 
Because you might not have redistribution rights?
Exactly what I was looking for!
But, but, it's guaranteed random http://xkcd.com/221/
[Image](http://imgs.xkcd.com/comics/random_number.png) **Title:** Random Number **Title-text:** RFC 1149.5 specifies 4 as the standard IEEE-vetted random number. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/221#Explanation) **Stats:** This comic has been referenced 367 times, representing 0.4437% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_cva0wx9)
Agreed. They really don't explain PEP 393 correctly -- it's not specifically about optimizing for character indexing operations (by "character", I mean code points, not graphemes) and completely ignore the memory optimization aspect. PEP 393 has been a big success for Python - it saves meaningful amounts of memory; - which in turn leads to a moderate speed increase; - gets rid of the old "narrow build" (UCS-2) versus "wide build" (UCS-4) dichotomy; - and has fixed the old problem with astral code points being treated as two invalid UCS-2 characters. By the way, Pike is another language that uses the same sort of flexible representation. As for graphemes, well, that's an *incredibly* difficult problem, and as far as I know there is no programming language that defaults to strings-of-graphemes. For example, "ij" would count as two graphemes in some languages, but one grapheme in others -- and even then, only for some words! 
Bah fine, I'll bite. Wonder no more; 5, 6 and 14 do not cover everything there is to know about Python. It doesn't say teach with in the file chapter (although the with syntax should be used there, even if it's noted that it'll be fully explained later). What it says is it's not taught at all. Also, the position of the file chapter would also be up for debate, so making its position one of your argument's axioms seems odd. The exceptions thing is saying it's a weird order to teach exceptions (which are not very hard in their basic form) after setup scripts. Your logic only holds if you think exceptions are much harder than setup scripts, which is unlikely. This feels more as though I'm doing English comprehension now, so hopefully it can stop here.
Yeah I love Rails is a Ghetto.
you dont even have to verify your email, just put in a random valid email if you are concerned. Or you know, sign up for a free webmail account in about 1min and use it for any stuff like this so your main account doesnt get spammed.
I guess there is not enough data for it at this stage? Its basically followed the form book and got it wrong where there is an upset (SA vs Japan). Be useful to apply to say premiership football, longer timespan, more data etc. Great work though!
this should be installable with pip. or at least a legit setup.py,
They also think that strings should be indexed by code units (a single character could take many code units to represent - in UTF8, how many it takes is variable). I'm pretty sure they don't do much programming, because that would create absolute chaos.
This varies **wildly** for me depending on the size and nature of the project. I choose between env vars, ini, json and yaml. As such, I really have no "primary" strategy at all.
yeah, that is one of our major shortcomings at this stage - insufficient data. We have a huge amount of data on the top tier teams, but with the lower ranked teams the data is not as strong. As an implication of this, the predictions for lower ranked teams are less reliable. We are doing analysis as the tournament goes on and it is/will be interesting to see how the strength of the predictions generated for past games changes based on the newer data for these lower ranked teams. Yes definitely something like that would be interesting - we were also considering super rugby except there are so many changes for next year so its not really viable.
Great idea. I learned a lot about how setup.py and PyPI works as well, so that's great. https://pypi.python.org/pypi/getsong
&gt; You're getting information and pay for it with contact info Pay? It's supposed to be free.
&gt; Every programming language has significant whitespace. [Brainfuck?](https://en.wikipedia.org/wiki/Brainfuck) Esoteric language doing its job: creating programmer rage! :-)
Binary search is implemented in the [`bisect`](https://docs.python.org/3.5/library/bisect.html) module `bisect.bisect_left` and `bisect.bisect_right` give insertion points for a value that will keep a list sorted. Accessing the index returned by `bisect_left` is equivalent to binary searching.
`(1).__str__()`
Thank you for following up with this link. -Someone who googled the same question.
I knew when I typed "every" that I would get counter-examples... "Almost every, and every one that you're likely to use any time soon!"
This reminded me I have a Data Analysis book that I have yet to crack for about two years. 
you should check out [blessed](https://pypi.python.org/pypi/blessed). It's based on [blessings](https://pypi.python.org/pypi/blessings). Which has a slick progress bar written for it called [progressive](https://pypi.python.org/pypi/progressive).
http://ranger.nongnu.org/
What does python have to do with this? A curses UI will look and feel the way it does regardless of the choice of underlying programming language.
The first one you mention is the answer I received on StackOverflow when I asked that very question. The second one doesn't do matrix multiplication though, since the result should be a matrix itself. That's why they end up with the nested list comprehension (I haven't checked it though). I think it's easier to just use `numpy`.
So you want to nuke your work environment at random intervals, this seems like a bad idea.
Python 3.5 Shell IDLE -&gt; Options -&gt; Configure IDLE -&gt; [Fonts/Tabs [Tab] -&gt; Size -&gt; Increase as necessary](https://slimgur.com/images/2015/09/22/f11c5a0d5ff204d47b7f9fd5cc370161.png) Welcome to programming.
I suppose the true test will come when more evenly matched teams square up.
&gt; I don't mean to update the libraries but my own program, perhaps &gt; I worded that wrong. Ummm, if you just want to update your own software, what is wrong with git pull?
Thanks. This is a weird "curated" collection of chapters from various places, with somewhat inconsistent prerequisites and style. However: it's pretty good content. I've recommended it to some of my students.
I would suggest that you install ipython notebook for learning python. http://richardt.name/blog/setting-up-ipython-notebook-on-windows/
I haven't used it before, but I'll put it on my list of things to look at.
What do you have so far? Do you want someone to just do your project for you? I'd consider it, for the right price.
I have the original rock paper scissor
Right click the shortcut, go to "Properties", "Compatibility" and check "Disable display scaling".
What about a drop-in replacement, `securerandom`, which provides the exact same thing as random, only it can't be seeded and reads from the system RNG (/dev/urandom on *nix, and whatever windows uses). You could even do `import securerandom as random` to avoid replacing existing code.
Example: https://github.com/Tillsten/MPLslides/raw/master/example.pdf
Here's the link to their page for it: http://www.oreilly.com/programming/free/python-data-for-developers.csp It's more polite than linking directly to the files.
https://github.com/wardi/urwid/wiki/Application-list
I wrote a program called [Reddit Terminal Viewer](https://github.com/michael-lazar/rtv) that uses python and does a lot with the curses library directly. I also looked into blessings but found it limited for full applications and I wasn't a fan of their API. You can do a lot of cool stuff with curses, it's a shame the documentation is so bad. Also, if you haven't found them yet there are a few demos that used to be bundled with python and and are still hanging around in the svn trunk. http://svn.python.org/view/python/trunk/Demo/curses/
Nice! But you have 2 very distracting misspellings: "Top Lanaguages..." in headings.
It can never be a drop-in replacement. from random import * state = getstate() number = randint(1, 100) setstate(state) print number == randint(1, 100) # True
I wish they would add it to your account though. I own many of their books. Really enjoy them 
http://www.jython.org/ ?
mitmproxy uses urwid, iirc
We use [pyjnius](https://github.com/kivy/pyjnius) with Kivy to access native Java APIs on Android, but it works fine on the desktop too. There's not that much activity on it, but that's largely because it works pretty well for us and (as far as I know) doesn't have a lot of standalone users, so bugs mostly just get fixed when they come up with Kivy.
Yes, that's my point - I replaced my use of mayavi with vispy, partly because vispy supports python3. That said, I think VTK recently finished python3 support (mentioned [here](http://www.vtk.org/Wiki/VTK/Python_Wrapper_Enhancement#Python_3_.28done_as_of_Aug_31.2C_2015.29)). I don't know how long that will take to trickle through to mayavi though. Edit: But I don't think mayavi is developed by Kitware, nowadays it seems to be backed largely by Enthought.