 SyntaxError: not a chance
Sign-up to be notified when back in stock. That system works really well. Adafruit is undergoing a massive growth spurt right now. They've been releasing a ton of great products and finding a lot of new customers. They've rented another floor in their building and are getting new equipment in to keep up with demand. Another option is check out digi-key. They also carry Adafruit products. But only the ones actually designed and built by Adafruit, Digi-Key doesn't mirror the entire store.
Does it mean that, if I want to write concurrent programs, I should avoid asyncio and learn/use this or gevent ? The only advantage of asyncio is to be in the standard library and thus is able to run on every platform ? Can we expect better performances from asyncio in the future or, as David Beazley says, it is "overly complicated", "dependent on esoteric magic" and doomed to be slow in comparison because "simple code also tends to run faster." ?
Segmentation fault (core dumped)
When you know you're being messed with: `TypeError: 'callable-iterator' object is not callable`
Neat. I'll try it as my main shell for a bit.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, we are sure you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, we are sure you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
This is from a deprecation, likely. `exit` sans parentheses probably used to work, and then it was changed to use parentheses, and then it required parentheses with this message as a backwards-compatible warning. **edit:** TIL that message is the result of `exit.__repr__` so, technically, python didn't know you were trying to exit at all, it thought you wanted the string representation of the `exit` function, which is, literally, `'Use exit() or Ctrl-D (i.e. EOF) to exit'` for more fun studying `exit`, check out `type(exit)` and `dir(exit)` **edit 2:** More fun: &gt;&gt;&gt; class CustomQuitter(exit.__class__): ... pass ... &gt;&gt;&gt; CustomQuitter.__repr__ = exit.__class__.__call__ &gt;&gt;&gt; exzit = CustomQuitter('exzit', 'Ctrl-D (i.e. EOF)') &gt;&gt;&gt; exzit Creates a custom subclass of the exit quitter, binds `_sitebuiltins.Quitter.__call__` to the custom quitter's `__repr__` method, instantiates the custom quitter as an object, lets you use it without parentheses to exit 
Yea, it wouldn't hurt, just for kicks. Hey you never know, might slip up and get a job lol
Hi there, this post being removed as it is not directly related to the Python programming language. It might be more topical on /r/programming, /r/coding, or /r/technology. Cheers, /r/Python mods
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, we are sure you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, this post being removed as it is not directly related to the Python programming language. It might be more topical on /r/programming, /r/coding, or /r/technology. Cheers, /r/Python mods
Ooooh, now that's interesting. What I meant by "python knew what I meant" is that almost every other language REPL worth mentioning implements `exit` as a way of closing the REPL, even ipython. It's such an obvious piece of functionality, and yet when you try it in `python` it just sits there and pedantically corrects you on how to exit "the python way".
Yep, my choice too.
I think it has something to do with which flavor of visual studio was used to compile a package your trying to download with pip. Unfortunately some of them only work with 2010 but it's impossible to find a copy of that anymore because fuck Bill Gates.
Not python but when using python to scrape twitter: 420 Enhance your calm
Convinced about using other people's decorators or convinced about knowing how to role your own? Personally, I love decorators and know how to write them if and when needed. However, back when I first encountered decorators like @property, I was content just treating stuff like that as if it were just language syntax. You can actually do quite a bit while remaining oblivious on how to make decorators yourself. I did.
It doesn't *always* know what you mean. &gt;&gt;&gt; exit Use exit() or Ctrl-Z plus Return to exit &gt;&gt;&gt; exit = "hello" &gt;&gt;&gt; exit 'hello'
A thing of the past now (py2), apparently: `func() takes exactly 2 arguments (2 given)`.
not using anaconda
I was kind of thinking that the master branch would be the version that would be installed and imported into other projects and that the dev branch would do all the testing but I hadn't looked into multiple .gitignore files yet so I hadn't done that yet. Maybe I'll just change it so that master and dev have tests and just tag stable versions. 
I'm pretty good with python. I am well versed in algorithmic thinking and problem solving. It's just a title for my real question. I appreciate the advice though. I'm polishing up my skills and creating my own little projects. Practice makes perfect.
You monster...
Thanks for the tip :)
I recall being really frustrated when I hit this for the first time back when I was first getting started with python. Good times, indeed!
Hey, is there a getting started with micropython doc somewhere? 
Then use Control+D?
Ofc that's for 2.7 only,and that's because 2008 is no longer available. For 3.4 or 3.5 you need 2010 or 2012 which is a 6gb dl for no good reason.
I love how this one sounds: `TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases`
*sigh* SQLite is such garbage. You're spending this time trying to get around a problem that a database shouldn't even have. Use connection pooling with MySQL or PostgreSQL to prevent paying the connection setup/teardown tax for every request _and_ to handle concurrency. In addition, you gain actual type systems and higher database performance. MySQL and PostgreSQL are just as easy to prototype with as SQLite, so don't be deterred by anybody saying SQLite is easier to use for rapid development. As for SQL Injection, I wouldn't 100% trust the API's docs. Not that they're lying to you, but doing some basic input sanity checking is always time well spent.
This, selenium is for when you literally need a render of the page, and can't get it any other way besides a full browser. 99.9% of the time, you don't need this. Stop thinking like a user, start thinking like a programmer. What does the browser do to get the data to display to you? Do that.
i.e. being a scrub 
How did you trigger this? *edit:* my question has been [answered](https://www.reddit.com/r/Python/comments/4ivd2k/what_is_your_favorite_python_error_message/d31pir9?context=2)
yeah fuck microsoft its not like they havn't [set up a VC++ compiler just for python 2.7 since 2014 which anyone can find in 5 minutes](https://www.microsoft.com/en-us/download/details.aspx?id=44266) or anything
I think Bill was out long before any of that particular mess was made. I have no great love for microsqish, but the founder is actually a pretty swell guy.
Why not just use ipython and get the other thousand amazing things it provides, as well as this?
Huh? Do you have an example of code that would cause this error? What was the fix?
Just fix it in your Python startup files. It bothered me too until I did so.
Thanks for the offer, I'm in the DC metro area, but if I'm ever up that way, I'll send you a PM ;) So, your ETL processes are going to have a lot of complex rules. When field abc = '123' do xyz; type stuff. Some of the most common problems I have run into, even from 'sources of record' were inaccurate/malformed fields. We all hate constraints until we need to consume the data in a predictable way ;) Writing unit tests for all of these functions inside your ETL scripts is going to help you. Something like adding another column in a select query (E part of ETL) can have several cascading effects on your codebase if you're doing something like: for f in fields. I recommend using pytest, pytest-cov, coverage. Here is a library I'm working on that uses these tools: https://github.com/michaelgugino/pylw coverage is really nice because it tells you what portions of your code do not have test coverage. Writing tests for pulling from a database and uploading to a different database is really hard, especially if you're using a proprietary db like Oracle and you can't just spin up another instance for testing. Hopefully your organization has some read slaves that you can mine data from (ideally, known data), validate the input data during testing, run that data through your ETL, and then run the load against a staging/qa database. If your ETL behaves differently when a row exists in your target db (postgresql) or not, you should test that case. This part is really messy and will take a lot of manual fiddling until you are able to automate the mess. Your upstream data providers will be changing constraints and schema without telling you, and your ETL software needs to be able to detect these changes and abort before you corrupt a bunch of data downstream.
I know, Bill Gates has actually done a lot of good stuff since he stopped being the microshaft
I really like MagicNumberError because the first time you see it you're like what the fuck... edit: I mean bad magic number
Tbh, I can't think of the last time I used the `exit` command, I pretty much always Ctrl-D out. That said, every time I have used `exit`, I've typed `exit`, then `exit()`...
def a(b, c, d='foo'): pass a(c=1, d='bar')
Heaven forbid anybody ever be satisfied with the reference Python implementation!
 **HiLetgo New Version NodeMCU LUA WiFi Internet ESP8266 Development Boar...** |||| --:|:--|:-- Current|$6.59|Amazon (3rd Party New) High|$11.99|Amazon (3rd Party New) Low|$4.00|Amazon (3rd Party New) |Average|$6.82|30 Day [Price History Chart](http://i.imgur.com/UVaFH6c.png) | [FAQ](http://www.reddit.com/r/PriceZombie/wiki/index) 
Yep. It's even weirder when using some simple RPC. I ended up writing a wrapper that caught that exception and checked if there's an obvious mistake. The error message is better in python3 now, anyway. Not as verbose as my wrapper was, though.
Guido once said he likes `KeyboardInterrupt` the most.
This is really awesome in more than 3 ways.
Algorithmic thinking and problem solving huh... and you came up with "python" for a title on a python forum?
Care to share the Python code you used so we can scrutinize it?
Sorry, just staying pragmatic with responses, especially taking into account that this is *Python*, not *ESP8266* reddit. A long response would be "No, to the best of my knowledge. Actually, to the knowledge of ESP8266's own vendor, because they use bitbanging in their code either. However, we can't discount possibility that they withheld the information and publish silly code for lulz. Actually, it's known there's hardware I2C interface. But it's internal one, used to control PLLs. But the way you pose your question makes me think that you know a way to do HW I2C on external interfaces, so... &lt;see above&gt;". 
As Python doesn't have great support for LZO, I used subprocess like this, for example: def process_file(fname): lzop_cmd = "lzop -cdq {fname}".format(fname=fname) lzop_proc = subprocess.Popen(shlex.split(lzop_cmd), stdout=subprocess.PIPE) for line in iter(lzop_proc.stdout.readline, ''): if SS_LINE in line: splitted = line.strip().split("\t") field = splitted[3] print(field) lzop_proc.stdout.close() lzop_proc.wait() def main(): # os.listdir() in a common case fs = iter_files() joblib.Parallel(n_jobs=12)( joblib.delayed(process_file)(f) for f in fs ) if __name__ == "__main__": main()
I'm not sure if you mean MicroPython's or Arduino's Neopixel library. MicroPython's was released and available long ago.
You're right, sqlite will handle the parameter correctly regardless of what the user enters. It's string substitution in user-facing raw sql statements that's the kiss of death. If you want, hammer as many different injection strings into the API as possible until you're able to sleep at night but you'll come to the same conclusion. Edit: and as for the other comment, why in the hell would you want to add additional complexity in the form of a client-server database if the application doesn't need it? That seems like the definition of premature optimization. With the right indices and reasonable timeouts sqlite seems to do just fine for many applications. Write a script to hammer the database with your program and you might be surprised at the load it can carry. Do you buy a school bus when you have your first child just in case you're going to have 25 more? Plus it sits in a single file which is one less thing to have to manage and/or migrate when you're reconfiguring your site. [Here's a recent article](http://charlesleifer.com/blog/five-reasons-you-should-use-sqlite-in-2016/) that does a pretty good job of highlighting the benefits of sqlite. 
Sure, start at http://docs.micropython.org/ and make your selections at the bottom right, as MicroPython supports bunch of boards. Here's ESP8266 tutorial for example: http://docs.micropython.org/en/latest/esp8266/esp8266/tutorial/index.html
Do you want it to be one-liner or a proper code without wasting CPU? There is a difference.
Ok the last time I tried to import the Neopixel library it only let me use the built-in neopixel function and not the actual library. . . But obviously a bunch of stuff has been released as of late ;]
So, just off-hand, I can see that you're using subprocess. Subprocess is SLOW, and using PIPE only makes it slower. Have you tried using the python-lzo module? I've never used it, but it seems to be well-maintained.
`callable-iterator` indeed shouldn't be callable. It's the object which is returned from `iter(callable, sentinel)`. That iterator repeatedly calls the passed function, stopping when the return value is equal to the sentinel. It's an iterator of callable objects, not a callable version of an iterator.
 from __future__ import braces
Unfortunately, there was an issue with 1.8 release of Neopixel library, such issues are tracked in this topic: http://forum.micropython.org/viewtopic.php?f=16&amp;t=1869 . It's already fixed in the master branch. 
Welp, sounds like a great opportunity for a new project.
Using windows 
Luckily, del locals()['exit'] Restores exit back to its usual state at that point.. but that's a bit overkill when Ctrl+D will suffice.
I prefer it. Call me old-fashioned. Hell I'd still use IDLE if the font didn't look ghastly on the mac.
Are you really being sensitive over a title bro?
I'd replace the awk components with Python if that's not your bottleneck. That's likely where you want your complicated bits of logic anyway. I love python, but Unix is hard to beat when you're doing data processing tasks. Don't underestimate the power of grep, sort, uniq, and cut.
Seaborn won't let you use the 'jet' colormap: &gt;&gt;&gt; import seaborn as sns &gt;&gt;&gt; sns.color_palette('jet') ValueError: No.
/u/Musique31 Can you delete this piece of shit submission please?
How is the performance?
I had no idea what any of this means until I took an OS course. Now I know what these mean and I know I can't fix them myself (especially if it's on Python). That's even more frustrating!
The speed is amazing! I'm waiting for an opportunity at work to play with it.
curio is an alternative API to the asyncio API, while uvloop is an alternative implementation of the asyncio event loop, while using the same API. For the vast majority of people, uvloop is likely to be the better choice when optimizing performance, including me, even though I don't like the design of the asyncio API.
Absolutely. This is only a big what-if discussion anyway.
Not from Python but I'll post it here anyway
&gt; I need to find a solution for threading thousands of mathematical calculations, transferring output, and reading in and interpreting input. Checkout mpi4py, as it's perfect for what you want to do. Although I think the performance will leave something to be desired, unless your calculations are done via a lower level C library. Either way, it's a good way to prototype your code, the logic, etc before you move to C/Fortran. Here is a very, very basic tutorial to start out: https://pythonprogramming.net/installing-testing-mpi4py-mpi-python-tutorial/ More advanced would be here: http://materials.jeremybejarano.com/MPIwithPython/
2 or 3?
Makes sense, in case anyone here isn't aware - handling unicode effectively was the main reason for the break in backward compatibility from Python 3 onwards. 
... because last time I checked compiling things on 3.5 on Windows didn't work at all? Was I lied to?
They do beat apple, and are the second best OS, but the problem with microsoft is an ethical one due to their business practices. 
this
 &gt;&gt;&gt; from __future__ import braces File "&lt;stdin&gt;", line 1 SyntaxError: not a chance why this shit ?
Python isn't _untyped_. Objects still have types and they don't convert from one type to another willy-nilly. The correct term is _dynamically typed_. As for the question, IoC is most often not necessary. Due to highly dynamic nature of Python, you can replace/mock/patch/stub everything you need inside an object w/o having to receive it as constructor parameter. You can even temporarily alter `import`ed module dependencies, including builtins. Basically, the test surface exposed by Python code by default is just sufficient.
Naturally. It's the only time crashing out to a stack trace is behaviour that's both what you expect and what you want. ... and now that I've said that, I'm sure someone will fondly reminisce about a program that hangs forever if it breaks and crashes when it works properly.
One better exit.__repr__ = exit
It's not pedantically correcting you. `exit` is a function, so when you just type `exit`, the REPL calls `exit.__repr__()` like it always does when you want the string representation of something. So python doesn't actually "know" that you wanted to actually execute the function. It thought you wanted the string representation.
How does Pypy perform? 
Why exactly do you want to have it in python? What you posted just uses python to call out to shell...why not just stick with shell? I sometimes run into this exact problem (i.e. large data processing running with gnu parallel and my general rule is that if is basically a shell script, then I write it as a shell script. I love python, but this doesn't seem like the right application.
thing.py: def pointless(text): return text test_thing.py import thing import pytest @pytest.mark.parametrize("input, expected", [("foo", "foo")]) def test_one_thing_pointless(input, expected): assert thing.printer(input) == expected @pytest.mark.parameterize("input, expected", [("foo", "foo")]) def test_two_thing_pointless(input, expected): assert thing.printer(input) == expected $ py.test ... E MarkerError: test_two_thing_pointless has 'parameterize', spelling should be 'parametrize' Strictly speaking, both spellings are correct in English. I always type the wrong one.
Depends on who you ask. I really enjoy using inversion of control and dependency injection. And I really don't like monkey patching if I can avoid it. 
I'm not even going to begin to understand how that works. 
You win the thread. 
I'll agree it's not as cool to hate on them as it used to be. But I'll still hate on them every time my system pisses me off. No, I don't want to reboot Windows to install updates when I'm in the middle of using the machine, why didn't you ask when I was done with my work for the day? 
Try :q to get out of vim
sometimes you have to shout it :q!!!!!!!!!!!!!
I was just as disappointed as you. I tried lots of stuff, but it looks like you can't change that behavior in one line. 
Why is subprocess slow in python? Doesn't it just spawn different processes as if you had launched them in the command line? Does it just have to do with the buffering of input/output (e.g., if you were subprocessing jobs that wrote to files instead, would it be just as fast)?
Python novice here - I feel there's a joke I'm missing. Care to explain?
It's a response to all people who complain about using indentation instead of curly braces.
It doesn't *just* do anything. Check out the source for it. It constructs a nice cross-platform abstraction of spawning processes. Just check out the source code. It's quite interesting. https://github.com/python/cpython/blob/master/Lib/subprocess.py
Most languages use braces to set aside code blocks Like this public static void main(String[] args) { if (args.length == 0) { System.out.println("hello there!"); } else { System.out.println("goodbye!"); } } (java) Python does this with indentation alone. The idea is that, by using the indentation as the delimiter itself, you force people to format their code well, whereas that java example would work just as well if there were no intentation, no spacing, no newlines. Some people don't like that because it's not normal, and it connflates best practices with actual syntax. Some people want to be able to write ugly code and have it run, in Python, you have to make it look good, or else the interpreter yells at you. \_\_future__ is the module that contains functions that might be implemented in future versions of python, but aren't yet, because they would break compatibility. So, if you're working in python2, and you want the division operator to work like it does in python3, you use "from \_\_future__ import division", and then the / operator will do mathematical division instead of integer division. 
https://www.adafruit.com/products/3032 is the one I have, came pretty much all setup, good kit with battery. its pretty much ready to go out of the gate
Sure it looks like there's a bit of setup to make it all cross-platform and I don't mean to disparage their work there. But it all seems like it wouldn't add much overhead - unless you were spawning/destroying many processes quickly
Shameless self-advertisement: http://mitmproxy.org should roughly fit what you are searching for. :-)
I very badly want this to open a browser and [just show me grumpy cat instead](https://zbeads.files.wordpress.com/2014/11/grumpy-cat-no-1.jpg).
[If you really want braces, Python probably isn't the language you should be using.](https://www.reddit.com/r/Python/comments/4ivd2k/what_is_your_favorite_python_error_message/d32bz27)
There are times I wonder what arguments I passed into my decorators.
I have a 128gb hard drive on my work laptop. This extra download made life tough.
Did you really think he was serious?
Because Apple *became* what it is. Microsoft entered and conquered the scene in a tremendously shady fashion, and then basically adopted the Starbucks model for fifteen years: sell us a controlling interest in your cool thing, or we'll clone it, and ship a free demo with every copy of Office until you bleed money. Apple, by contrast, originated the fancy-pants GUI OS (Microsoft was contracted to write Word as launchware, simplified.) They were the scrappy ones for a long time. Macs appealed to newbies, Grandma, and power users, but nobody in between; the semi-walled garden originated as a way to protect Grandma from herself, as the computer-literate grandchild was not yet a ubiquitous feature of the nuclear family. Microsoft enjoyed tremendous commercial success, and catered to media consumption and gaming while Apple was busy catering to artists and creative types. Result: for 15 years the current version of Mac was plainly, unambiguously more stable, and the hardware was an order of magnitude more reliable, but between the price point and Windows' domination of the PC gaming market, Apple lagged commercially. The iMac and OS X started to tilt things a little, but only a little until the iPod rolled out. Apple cornered digital music early and almost totally, and their revenue shot through the roof. Only then did they finally, fully morph into the consumer-hating overpriced corporate mass we all know and hate today. If you're older than about 20, though, you remember these companies as they were, and it's frankly easier to stomach Apple as the world's wealthiest company, rather than Microsoft. In fact, it seems almost poetic.
Surely it works. It's one of the greatest features of Python at all times. You can try reading David Beazley's slides from here, for example: http://dabeaz.com/generators-uk/index.html
I can totally write it all in shell, and I actually do it currently. But most of our team's command line tools are written in Python and I can't, for example, make setuptools create shell scripts instead of Python scripts on package installation, so it all would be similar.
 import antigravity
I'd say that the pythonic solution is to write less complex lines of code, but more of them.
Hey I really appreciate the response. I think there's a lot of things I'm going to learn from your response.
Codecademy's python course isn't bad for getting started.
You're not trying hard enough then! &gt;&gt;&gt; exit.__class__.__repr__ = exit Exit seems to call its class repr directly
[`import this`](https://www.python.org/dev/peps/pep-0020/) says it best &gt;Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. ...
Quick, write a bot that quotes the Zen whenever anyone uses the word "pythonic"!
1. This sub is not here to do your homework. 2. Why don't you just try it out in python? 3. You might want to go to /r/learnpython
Ask you python interpreter :) $ python Python 2.7.11+ (default, Apr 17 2016, 14:00:29) [GCC 5.3.1 20160413] on linux2 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; [2, 33, 222, 14, 25][:-1] [2, 33, 222, 14]
/r/learnpython
/r/learnpython
You mean "indent" rather than "intend", right? I believe it has a standard "reformat selected lines" option that should do this for you, but it's been a very long time since I've used it. Have you tried the spyder-specific communities and support channels?
 $ killall python3.4 (or whatever your version is)
That was the link I mentioned on the post. It seems to me that the project is stuck, so it haves little to none activity
Looking good... I'll check the git page on these days..
Do you still need to indent in this case? Or you can just write everything unindented? I can't check now (not that I would use this or leave everything unindented, just curiosity)
Works perfectly for me. Just install Visual Studio with C++ support. 
The lexer sees this as one logical line so there is no indentation required.
FAForever is really a great project, play FAF myself from time to time. Wish I could help, but cannot say I am a senior python developer. I mainly use it for machine learning, but I am still learning. I have more experience in in C/C++.
You shouldn't need to properly indent what's inside braces of the if body. However, there's a catch. While the code in my example is valid python 3 (and, with some modifications, python2), it's a horrible exploit of a couple of python features, and the style shouldn't actually be used anywhere. Bonus points for figuring out why it works :) .
When Apple was going out of bussiness, Microsoft bailed them out because they felt IT industry needs more competition to move forward as a whole. For every shady thing they did they also did something good. The reality is that copyright and patent systems are very exploitable and if you don't exploit it, you will get fucked over by people who do exploit it. It's not Microsoft, it's the reality of the current world.
Inversion of control is not unpopular in Python, it's just that very often, it's not needed : - Python provide mecanisms to not need it; - the dynamic nature of Python makes it just as easy no to use it; - the project is not big enough to care; - you have some sort of inversion of control, but it's light and you don't see it. 
The CPython repository contains an [entire directory](https://hg.python.org/cpython/file/tip/Lib/test/crashers) with examples of Python code that segfaults the interpreter. No doubt there are more segfaults just waiting to be discovered, some of which are going to be bugs and not just acceptable compromises.
Doesn't have anything to do with pentesting but [cryptography](https://cryptography.io/en/latest/) is a great project that could probably use more people.
Okay now try to put more than one statement per branch, clever boy.
/r/learnpython
Gotta hand it to him, it was a clever idea and it probably fooled a couple of readers :)
I did this but why does it remove element 25?
would have been great if they used the [colormap haiku](https://twitter.com/michaelwaskom/status/512344441873367040): you have some data that needs to be colorful, don't fucking use jet.
Oh I got it thanks a lot
Reminded me of [this](https://s-media-cache-ak0.pinimg.com/564x/85/20/b0/8520b03104185d291070cf504c453754.jpg).
So... Much hate
Really? A newbie should start by learning a large library/framework on top of Python, instead of just learning how to complete a trivial task in the language itself?
This is a very good learning problem for Python - so I suggest you spend the time required to understand how to do it on your own. It will help you accomplish similar text-munging tasks in Python in the future: Some tips: 1. Open the file (or just use `sys.stdin` if piping through) 2. Use `readlines` to read lines 3. Create a dictionary with the keys/values as needed from these lines 4. Use `json.dumps` from the `json` module to create a JSON string from it 5. To strip whitespace and punctuation, consider using the `strip` method of strings, or a regular expression if you need more complex things
The irony of my wording was not a mistake 😃
Spawning the process, setting up the buffers, wrapping every operation in a nice chunk of sanity checks... it all adds up.
if we are talking about the right way - vim i was suggesting alternatives
Thanks, I'll get this done myself now! 
Sounds like something that could be done with the `@property` decorator, which would get methods at runtime. It would then be easy enough to cache and always return the first result. If you really really need definiton-time binding, I think it's down to a custom decorator for the class!
Ok, we seem to have two operations here. You want `x.get_group_id()`... which is equal to the maximum `x.len_res()`. The simple solution is `[max(x.len_res() for x in my_grp)]`. More completely: lst = [max(x.len_res() for x in my_grp)] if lst[0] not in {x.get_group_id() for x in my_grp}: lst = [] Really, the `len_res` and `get_group_id` methods should have the `@property` decorator on them...
Similar sure, but EB is wildly different to Lambda. EB provides an entire three-tier stack, Lambda is just compute. I'm sure eventually EB will support Lambda application layer.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Have you tried to allocate more RAM for you Lambda function? RAM, CPU and networking are correlated in Lambda, so you might get very different results.
First, note that your decorator isn't actually right here - you're trying to take additional arguments **and** the method, but once you call this (@classmethod.register("death")), you're getting what this function **returns** (which is None), and using that as the decorator. Also, your decorator needs to return the method, otherwise you're overwriting it with None (this may not matter if you're **only** using it through the registered event, but you probably still don't want all those weird `None` values attached to your object). You'd need to write this as: @classmethod def register(cls, key): def decorator(method): cls._registered_methods[key] = method return method return decorator For your main issue, one approach is simply to move this logic to a seperate class. Eg: class EventHandler: def __init__(self): self._registered_methods = {} def register(self, key): def decorator(method): self._registered_methods[key] = method return method return decorator def execute_for_event(self, obj, event, player, killer): if event in self._registered_methods: self._registered_methods[event](obj, player, killer) class FinalStrike(Skill): description = "Strike your enemy for one last hit after you die." _eventhandler = EventHandler() @_eventhandler.register("death") def death(self, player, killer): killer.health -= player.damage def execute_for_event(self, event, player, killer) _eventhandler.execute_for_event(self, event, player, killer) However, there is a big flaw with this, which is that you're going to have to declare a new EventHandler in each class, otherwise you're going to share the parent class's handler. Which is not ideal - you don't want to be repeating stuff like this in every class - forget to add the `_eventhandler = EventHandler()` line to every class and suddenly you're overwriting base class events. (This is also true of your workaround, except it's even worse there since you need to redeclare the register function instead of just creating an eventhandler object). This is all stuff that ideally you'd want to put in your Skill class and have automatically applied to all subclasses. There **is** a way to do this automatically, though it's a bit on the advanced side. Ultimately, you want your classes to come with particular initialisation done, just as objects come with the initialisation done in the __init__ member. So you want the equivalent to an object's relationship to it's class, except for classes themselves. These are called **metaclasses**. Just as classes define how to create objects, metaclasses define how to create classes. So we could have something like: class SkillMeta(type): # (metaclasses inherit from type just as classes inherit from object) def __init__(cls, name, parents, dct): # This is like a regular __init__ for an object, except the object happens to be a class. # name is the name, parents are the base classes and dct is a dictionary of all the methods / class attributed defined. # We are going to look at all the methods, check if any are marked to be registered, # and add a new registration dict mapping the name to the methods registered. # First though, we call the regular type.__init__() method to do the regular initialisation type.__init__(cls, name, parents, dct) # Now we add our modifications: registered_methods = {} for key, val in dct.items(): if callable(val) and hasattr(val, "_register_event"): # Only look at methods that have been "marked" with an event. registered_methods[val._register_event] = val cls._registered_methods = registered_methods # Our register function is pretty simple - it just "marks" the classes so the metaclass can pick them # up and add it to its dictionary later. def register(event_name): def decorator(method): method._register_event = event_name return method return decorator class Skill: __metaclass__ = SkillMeta # (In python3, declare the class like: class Skill(metaclass=SkillMeta) instead) def execute_for_event(self, event, player, killer): if event in self._registered_methods: self._registered_methods[event](self, player, killer) class FinalStrike(Skill): @register("death") def death(self, player, killer): killer.health -= player.damage All the logic should be present automatically on every subclass of skill. Ie: f=FinalStrike() f.execute_for_event("death", player, killer) will work as is. OTOH, metaclasses as a bit too magical for a lot of things - personally I'd be much more inclined to go with the naming convention route, though I'd probably call them something like `on_event_death` rather than just `death` to avoid name clashes with other potential methods. Simplicity has its own advantages. One other thing I'd add is to consider subclassing. What should happen if you subclass FinalStrike and add a new event and/or add a different handler for "death". Should both get executed when the event occurs? Should later ones overwrite earlier ones? Should each class be a clean slate with none of the parent events invoked (which is what the above does). You may need to modify the above to search through parent classes as well if you want such behaviour. 
I'm way too used to i++
Your question has some strange assumptions in it. Are you suggesting that dynamic typing increases the number of errors? [Studies have found](http://games.greggman.com/game/dynamic-typing-static-typing/) the opposite effect. Shouldn't 100% coverage be more desirable in languages like C and C++, where one misstep makes your whole program blow up? Do you also question why IOC is not very popular in C?
For completeness, you can circumvent being unable to access current class as it's being constructed like this, for example: def make_register_decorator(_registered_methods): def register(key): def f(method): _registered_methods[key] = method return method return f return register class FinalStrike(object): _registered_methods = {} register = make_register_decorator(_registered_methods) @register('death') def on_death(self, player, killer): killer.health -= player.damage print(FinalStrike._registered_methods) Because you, of course, _can_ access members of class dictionary, just not the class itself (because it doesn't exist when its dictionary is built by executing its code). Though of course I like /u/Brian's approaches better, except I'd make event_handler callable or just a function itself, something along the lines of: def make_register_decorator(): def register(key): def f(method): register.methods[key] = method return method return f register.methods = {} return register class FinalStrike(object): register = make_register_decorator() @register('death') def on_death(self, player, killer): killer.health -= player.damage print(FinalStrike.register.methods) But yes, you could get into all sorts of trouble with inheritance, so if you want inheritance you'd better first explicitly write down the policy for dealing with name conflicts, then implement that policy as a metaclass (note that you only have to do specify the metaclass in your base class).
Does anyone here using Cython for their web apps? Any pros/cons you have?
This is also the direction I took with KivEnt for Kivy. I find Cython to be one of the most enjoyable languages to work in since you can handle all types of low level concerns that come up when working with OS level features such as windowing, sound loading, and openGL interaction, but you also have the ability to fallback on Python concepts if you need something that isn't easily provided by C/C++. Also, I find it is much easier to read Cython C/Python code that say CFFI-wrapped C code in Python. IMO Cython is one of the biggest advantages in the Python ecosystem. It is a lovely language!
Now if only I could get TensorFlow to work on Windows :( Screw it, I'll try dual booting.
Braces?
Hey, I am one Python developer and interested in this. Bo
[Implementation](https://github.com/alex-sherman/deco)
Python zen, what pylint/pep8 checks and why, testing everything. But really the best way to do a technical interview is to have a homework - make sure that the interviewee is in the most comfortable coding environment that he is used to with full Internet access and know editor and config, working iPython and all that stuff. Then give them a task. It should be well specified and clear, with example inputs and outputs, it should be something that you can do in around 1 hour. Give them 3 hours and ask them to give you the best code they can for their definition of "best" in that timeframe and to show their skills. And then leave them to it. After the 3 hours are over, take whatever they have to deliver at that point and then review it in the team just like you would a normal code review for a task done in your team. This will tell you how they will function in your team day to day. That will likely tell you much more than any interview ever could.
I'm very comfortable with Python, JavaScript, and other dynamic languages. I know the principles of static programming, but never apply it. Would Cython be a great way to get experience with this? 
The downside with this though is that now: &gt;&gt;&gt; help(exit) &lt;python exits immediately&gt; &gt;&gt;&gt; __builtins__.__dict__ &lt;prints a few builtin functions, then quits when it reaches exit&gt; There are good reasons why it doesn't do this.
So I'm understanding your suggestion, I can use the PostgreSQL file as an out-of-memory storage solution for the data while the program is running, as well as use it to load &amp; save the JSON files I already use?
pgsql is a database management system. it persists data to files on disk, so no, you're not limited to whatever you can fit in RAM, and you don't have to refresh/reload the data whenever you restart your application program. integrating with a database is a non-trivial task though, but it might be your best option. in any case, my aim here was not to start on a tutorial for how to work with postgres. just thought it might be a good lead for you to investigate while you're looking for technology to use for your project. 
If anyone's interested in some Python hacking, the MusicBrainz project is currently working on [ListenBrainz](https://listenbrainz.org/), an open alternative to last.fm (now that they have launched their new website, that not everyone likes). It's still at the alpha stage, mainly because of a lack of manpower, which YOU could change ;)
Thanks, I'll look into this.
My understanding of how this would work def some_class(object): # all of your class stuff as normal @property def group_id(self): # whatever logic required to get the group id return group_id If you do this, when instead of calling x.get_group_id(), you can just call x.group_id and the object will use that property method to return that value. 
[From Wikipedia:](https://en.wikipedia.org/wiki/TensorFlow) &gt; TensorFlow is an open source software library for machine learning in various kinds of perceptual and language understanding tasks.[3] It is a second-generation API which is currently used for both research and production by 50[3]:min 0:15/2:17 different teams in dozens[4]:p.2 of commercial Google products, such as speech recognition, Gmail, Google Photos, and Search.[3]:0:26/2:17 These teams had previously used DistBelief, a first-generation API. TensorFlow was originally developed by the Google Brain team for Google's research and production purposes and later released under the Apache 2.0 open source license on November 9, 2015.[1][5]
&gt; Packaging in JS is as bad as in Python. Have you ever used Node and NPM? Because it's laughably trivial in my experience (I'm assuming your repository is on Github. Here's how you start a project: mkdir my-project &amp;&amp; cd $_ npm init echo node_modules &gt; .gitignore When you're done developing and your code has been committed to Github, and now you want to deploy to a client: git clone https://github.com/path/to/repo cd repo &amp;&amp; npm init That's it. There are no packaging config files to edit. Here's another guy who actually took the time to compare packaging in the two and concluded Python is much more complex. https://github.com/toejough/pypi-vs-npm
I started after 30 and have a son. I'm a .Net developer. It is a struggle for sure but can be done.
Harrison, you are awesome! Thanks for sharing these.
What do you mean by "webapp". To me webapp means the Javascript that runs in browser and reads a backend api. So Cython/Python isn't an option (without transpilers). For 99% of web backends, I/O (network, database), is the bottleneck not CPU.
This seems really interesting. I've always been very interested in machine learning but I've never gotten around to actually trying it. Thanks!
Of course being an experienced coder and knowing some coding are different skill sets. I was a full time c++ coder in my early 20s when I had your enthusiasm so I get this. I wish I was in my 20s. There's some weird Ageism thing in IT though. What I see here for you is a massive opportunity to build technical coding company. For example when I was hiring coders I would give them a test. If you can build a team of coders, you can very easily make shit loads of money. Especially if you pride yourself in actually delivering results the client wants. If I Was you I would, then sell the business 5 years later for millions and then have fun.
If you look through the math, you can solve this directly pretty easily.
I recently gave a talk (at PyCon Israel 2016) that addresses just that issue: [How to make Python perform like C](https://drive.google.com/file/d/0Bw5McUt95YdeMlNiX2VSR1lFRHM/view)
I think the TL;DR of that is: multiple inheritance plus metaclasses = a bad day
It's really simple - you can download the installer [here](http://conda.pydata.org/miniconda.html). Once you've got it installed, you can create new Python environments with &gt; conda create -n environmentname python=3.4 package1 package2 package3 And then switch to the environment with &gt; source activate environmentname To install something, e.g GCC, you can just use &gt; conda install gcc 
Thanks for the kind words :D
Thanks! Happy to share them and have been enjoying producing them. 
Cool, I will check that out.
Yeah, I am wagering that the .whl doesn't have the designer. See if you can find the standalone for it on riverbank's site, start here: https://riverbankcomputing.com/software/pyqt/intro and maybe poke around their downloads. You could even failsafe and grab the version for 3.4, install it, and just keep the designer.
While networkx is a good at analyzing graphs, it's quite lacking when it comes to drawing them. The layout is very bad and it's not very usable imo. Consider pygraphviz instead.
It's probably a good time to be a pharmacy executive, not so much for a research chemist.
This is awesome to read. I wish more people looked past the barrier of "I'm not a programmer" and got started. Props to you for that and sharing the knowledge.
Would you mind taking a look at a [class I wrote](https://github.com/gappleto97/python-utils/blob/beta/net.py)? Supposed to be an RSA-encrypted socket. I have a feeling there's quite a few holes in here, though.
Tried it, had some issues getting TensorFlow working right. I'm now the proud owner of my first dual boot system with Win10/Linux Mint. 
Stumbled upon your videos when I began learning to program about a year ago. Thanks for the intensity of the uploads the uniqueness of your content. Lots of tutorials only cover general scenario cases, but you really go in depth with how to go about programming for specific scenarios. Keep it up!
You can skip entire sections, I don't recall saying there was any "requirement" to follow in order. If you want to wait until the NN or deep learning sections, feel free. I wouldn't suggest that though, seeing as how topics like linear regression show up in neural networks... :P There are many algorithms that can be covered under the umbrella of machine learning, the ones I chose were very specific. For example: Linear regression - Linear algebra in general might be the most integral building block of any ML concept. If you're going to skip something, it really should not be linear regression. K Nearest Neighbors - a super simple, yet extremely powerful ml algorithm that works linearly and non-linearly, which is where we first illustrate the value of understanding linear vs non-linear data and algorithms that can support both types. SVM - A not-so-simple, yet very powerful, algorithm that introduces you to MAJOR machine learning concepts such as optimization, working with vectors, kernels, transforms, and more. Skipping any of those algorithms would mean skipping major concepts that those algorithms teach you and show how mathematics overcomes serious challenges. When we get to clustering, this is where we first begin to introduce notions of unsupervised learning, and methods for that. Again, skipping this would be really just doing yourself a disservice. Machine learning is a layered field. It's akin to asking me why bother learning algebra, and that you'd rather just skip to multi-variate calculus. You can use modules and skip around, getting away without understanding the fundamentals, but the objective of this series is to break down all of the concepts, which, in my opinion requires breaking down the algos that I plan to. If you disagree, you could attempt skipping and see what happens. I could be wrong!
Source: https://github.com/celery/celery/blob/master/celery/__init__.py
That's fantastic. I hope it takes off! Seems well worth donating a little manpower.
This isn't a hack. It's a documented feature. 
I love this - anyone can import scikit-learn and use predict(). This is really neat to see how the technique is actually implemented.
You are awesome, loved your financial trading video series as well, cheers!
&gt;I'm not worried about the JSON file getting too big (my personal use case probably won't get very large) as soon as you say that, you can be rest assured that it will become to big. (programming since 1998, I've been told it won't many times and guess what.......it did) Consume the JSON data and store it in a db. Keep only a few key pieces so you can query the db for data, then clear your JSON data from your program
I am not reading all of this because you open by mistaking intellectual theft for good business.
You could use SQLite. 
Watched the intro video and about to continue, great stuff!
What about an `if` or a `while` statement within the branch? :P
I learned Flask from your videos! I'm mildly interested in ML, but he fact that you did a series is enough to fully pique my interest. Thank you very much for all the time you put into making your videos!
I learned pretty much all I know from your videos. Thanks for dedicating the time to help us newbie strangers.
Just want to say thanks for the videos.. Learning python and your videos have helped a lot 
I stumbled onto your ML videos on YouTube and have been hooked ever since. You have a knack for teaching and get complex topics across in an understandable way. Thanks, I've learned a lot already!
Sounds great!
What are some examples of when you'd fall back to Python?
I haven't been able to watch these yet. But I definitly will! Your tutorial on Flask was a godsent for me. And really pushed me over the hill to "get it". I can actually make something now! :D Thanks!
This is cool ... useless, but cool.
 &gt; whatever Python 2 executable is currently in the path That only works if you do not need any addons and you donot care about more precise version specification (e.g.2.7) &gt; Then why would you be executing it with a specific Python executable inside the outer script that the user calls, instead of just executing it like a regular executable? The issue is that this "executable" is a python script, if this python script uses "#!env " shebang, then your change of PATH may break it. YMMV, of course, depending on your site size, package management and policies.. 
Yes. 
I didn't start learning how to program until I was 27 and at Uni and way before all of these online resources really existed like they do now. I think having the desire to learn and the need to be the best you can be for your kids can be very compelling drivers for learning. 
hows it ment to know whats going on in the game though
Checkout partial from itertools. 
Nice! Will there also be a log of the chat available afterwards?
/r/learnpython
[Here's one way](http://code.tutsplus.com/tutorials/how-to-build-a-python-bot-that-can-play-web-games--active-11117). In the future, you'll get better answers to learning questions on /r/learnpython.
Outsourcing is a problem in software too. Try and look for something specialised (maybe a job that combines programming with your pharma experience?) because those roles are harder to outsource.
This is super easy. Probably 15 lines of python. I'll send you working code and help you get it set up for 150 USD via a half hour phone call. I'll send you the code for 25 bucks, balance when it's working and your happy. PM me. 
discussion on HN: https://news.ycombinator.com/item?id=11684745
Except it's generally good enough in Python to know just the Truthiness of a value, rather than if it's literally a boolean. I can think of two situations over the last four years I've used Python that I absolutely had to know if something is literally a boolean - and both dealt with the same weird internal service.
format conversion? anyway, I just hate editorialized headlines
Which operations you do the most? I'll try speed up them too.
If I need speed I use opencv more often than PIL/LLOW
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Yes! I need to get into Python for development reasons after 2 years of R, and it's hard to restart. I think I'll just follow this. Thanks man.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
&gt; Might steal it. I should warn you, that snippet is licensed under the [WTFPL](http://www.wtfpl.net/about/). &gt; the toolz library You just made my fucking day.
The advantage of opencv is that it can use **more** hardware for the same task. You can find more info about different techniques of performance improvement in "Why SIMD" section of the readme.
Works for me, anyway. Both my pay-job at [socialserve.com](http://socialserve.com) and personal project [jlr-photo.com](http://jlr-photo.com) use pillow for rescaling. A quick real-world test between pillow and pillow-simd/sse4 for single-threaded rebuild of images at jlr-photo.com (downscale + compositing) on an i7 going from 3m46s to 2m43s, a healthy improvement!
Great to hear, hope you enjoy the series! I enjoy putting the time in to the videos, and learn a lot myself. 
Great to hear, thanks for the support! I am planning to keep going for a long time. I've got ~ the next 2 years plotted out with content ...and keep getting more to do :P
That's really awesome to hear! 
Thanks for the kind words!
Probably still a month or two away. About to start the SVM section, then clustering, then neural networks, THEEEEEEEEEEEN deep learning. 
That's really great to hear. I remember when the python web dev lightbulb finally clicked for me. It took me a verrry long time and many tries, but it was very much worth it. 
Nice explanation, thank you
[Deleted]
Hey @NWRoaster, Thanks for the comment! The code is on my github if you want to have a look...here's a direct like to the looping piece: https://github.com/rkipp1210/data-projects/blob/master/hockey-shot-blocking/shot-blocking-selenium.py#L64 Not pretty...but it gets the job done :)
[Deleted]
I do use `Image.alpha_composite()` for compositing the signature over the scaled-down images at jlr-photo.com. After doing poor-man's image analysis to try to determine which corner to place it in and also whether or not it would stand out more being white or black (`ImageOps.invert()`). So thanks for producing and advertising pillow-simd! Although I'm now also motivated to write the extra 30 or so lines in order to farm out my image processing to a `multiprocessing` pool. Pillow vs. Pillow-SIMD will be of far less consequence than going from single- to 8-way concurrency on this i7. Thanks! 
Generally when I find myself thinking about frame hacking, I have to ask myself if it's actually a good idea or even worth it. In this case, I really don't think it is. 
Does this work with nested dictionaries? d = {1:2} myJDict = JDict'filepath.json', {"d": d)} myJDict[d][1] = 4 # does this trigger a write? 
I do wish people wouldn't use ImageMagick as a benchmark. It's slow, incorrect and inflexible. I've never understood how it became so popular, particularly when better alternatives were already widespread at the time it was created.
What kind of other alternatives would you suggest for command-line image editing ? I tend to use it mostly for conversion, resizing and mosaic… and if there is something widespread, easy to use and faster/more flexible, I'm game. But the command-line part of the requirement is an absolute necessity :)
netpbm
Is that something you'd come across in the wild though? Will it be this obvious on your everyday picture?
There's something wrong with your ImageMagick results (weird configuration options? CFLAGS?). Here's a quick run on my box (FX-8320E@4.4GHz, "performance" CPU freq governor, running Gentoo ~amd64, imagemagick-6.9.3.10, pillow-3.1.1) using [this input image](https://upload.wikimedia.org/wikipedia/commons/1/13/WP_20150821_17_30_00_Pro_highres.jpg): With RUNS=1: stefan$ ./ImageMagickTest.sh WP_20150821_17_30_00_Pro_highres.jpg Triangle 16x16 04.349 Catrom 16x16 04.430 Lanczos 16x16 04.610 Triangle 320x180 00.209 Catrom 320x180 00.280 Lanczos 320x180 00.459 Triangle 2048x1155 00.650 Catrom 2048x1155 00.690 Lanczos 2048x1155 00.840 Blur 1px 00.500 Blur 10px 00.719 Blur 100px 03.060 With a reordered output to match the shell script and fixed units, because time.time() gives you seconds, not milliseconds: stefan$ ./PillowTest.py WP_20150821_17_30_00_Pro_highres.jpg &gt;&gt;&gt; 16x16 bil 0.11943 s 268.00 Mpx/s &gt;&gt;&gt; 16x16 bic 0.22531 s 142.06 Mpx/s &gt;&gt;&gt; 16x16 lzs 0.33033 s 96.90 Mpx/s &gt;&gt;&gt; 320x180 bil 0.16760 s 190.98 Mpx/s &gt;&gt;&gt; 320x180 bic 0.28711 s 111.48 Mpx/s &gt;&gt;&gt; 320x180 lzs 0.41067 s 77.94 Mpx/s &gt;&gt;&gt; 2048x1155 bil 0.42432 s 75.43 Mpx/s &gt;&gt;&gt; 2048x1155 bic 0.53887 s 59.40 Mpx/s &gt;&gt;&gt; 2048x1155 lzs 0.75270 s 42.52 Mpx/s &gt;&gt;&gt; blur 1px 1.57347 s 20.34 Mpx/s &gt;&gt;&gt; blur 10px 1.59433 s 20.08 Mpx/s &gt;&gt;&gt; blur 100px 1.57941 s 20.27 Mpx/s Also, when benchmarking SIMD or multi-threaded software, you might want to compare it with GraphicsMagick (I have 1.3.23 here) because it usually has better performance than ImageMagick so that's the one you want to beat: stefan$ time convert WP_20150821_17_30_00_Pro_highres.jpg -filter Lanczos -resize 16x16! bmp:/dev/null real 0m5.025s user 0m3.064s sys 0m1.956s stefan$ time gm convert WP_20150821_17_30_00_Pro_highres.jpg -filter Lanczos -resize 16x16! bmp:/dev/null real 0m0.533s user 0m1.907s sys 0m0.041s As you can see, the reported user time is the sum of user times on each used core, so compare using the "real" time. 
Why do people use it at all? Is it easy to install or come bundles with popular tools? It is quite ubiquitous in the low end of the market (like cheapass shared PHP hosting).
Me neither. I think it's important for an access modifier not to have any overhead. In this case you get a little bit too much of that for even a simple getter-setter. 
 the quality is awful. Look at the "Your scaling software" text. It's horribly blocky. Count down. You are using Pillow for the first time and have no clue how resampling works, aren't you? By default Pillow uses NEAREST filter *with no resampling* that is why the result is so awful. What about gamma error: for now Pillow doesn't do gamma correction. In some very rare cases this hurts an images. But author of the article definitely spreads the panic. Gamma correction shouldn't be done in 8bit colorspace and this is the main barrier for gamma-correct resampling in Pillow.
stackoverflow?
 &gt;&gt;&gt; from __future__ import braces File "&lt;stdin&gt;", line 1 SyntaxError: not a chance 
You'll almost certainly want to look into using OpenCV-Python.
&gt; Try to use MAGICK_THREAD_LIMIT=1 before script. Nothing changes. I guess those operations are not parallelized. &gt; Pillow and Pillow-SIMD faster than ImageMagick on the same hardware. As opposed to what? You think I ran the benchmarks on different hardware? &gt; By the way, you shouldn't measure IM's with time because this time includes decoding and encoding time. Did you notice I was comparing ImageMagick and GraphicsMagick that do the exact same decoding? Or that the whole point was to show that the latter is much more efficient than the former? 
Interesting concept but man what a terrible web site. Just try finding the license. 
Cool library! While there's no real reason to offer it, [IE7/6 technically do support Data URIs by way of MTHML parsing from Outlook](https://rymc.io/2010/06/17/you-got-your-base64-in-my-css/). It's a ridiculous hack but amusing enough to note. Pretty sure IE8 also has size limits on Data URIs (32kb IIRC?).
Out of curiosity, what's your usecase for hardware SPI? 
Maybe it's part of the testing framework.
[pt-br]Faz um try foda-se.[/pt-br] You can try this: def int_input(*args, **kwargs): try: return int(raw_input(*args, **kwargs)) except ValueError: print("Please, sucker, enter a valid integer") return int_input(*args, **kwargs) num = int_input("Enter a number: ") This is a common pattern in Python. Exists two common styles you can implement that task, this above, whose is called [EAFP](https://docs.python.org/3/glossary.html#term-eafp) (Easier to ask for forgiveness than permission) or you can try another implementation avoiding try/except blocks checking if a string is digit [LBYL](https://docs.python.org/3/glossary.html#term-lbyl) (Look before you leap.) def int_input(*args, **kwargs): raw_result = raw_input(*args, **kwargs) if not raw_result.isdigit(): print("Please, enter a valid number") return int_input(*args, **kwargs) return int(raw_result) num = int_input("Enter a number: ") 
I like the idea to write the lists and dictionaries to json but how does it compare to using a database? Is this a quicker way to store and retrieve the data.
Learn the ways from this classic http://www.tldp.org/LDP/LG/issue83/evans.html
Cool, thanks!
It was posted a few days ago http://alex.vector57.net/deco/ I don't think any of those libs are quite comparable to deco, which seems to be a real innovation.
it's been a long time since I've used imagemagick but dont they have a gpu accelerated version?
Thanks, this very helpful and i can tell its going to take a lot of practice to get this. 
I think he's referring to Matlab's "Smart Indentation" tool, accessible via cntrl+i on a selected code segment (I prefer to cntrl+a -&gt; cntrl+i personally). Based on this: http://pythoncentral.io/comparison-of-python-ides-development/ it looks like IDLE, Eclipse with PyDev, and PyCharm are the best bets. 
Well I am not quite sure how it compares as I haven't compared them side by side. Considering the entire thing is written in python I would imagine it would probably be slower but it is definitely simpler. I am looking in to using Cython though. One thing to consider is that; the only time an object is ACTUALLY reading from the .json file is when the object is initialized. Otherwise it is reading from other objects, to keep everything in sync with the database so that improves performance quite a bit. There is a trade off of not being able to edit the .json files directly with a text editor at runtime but I believe that is an acceptable trade off for the performance gains. :) The only time an object writes is when a variable is changed i.e. if I use `myJPyon.myVar = 5` if myVar does not exist it will write but `if myJPyon.myVar == 6:` when I do `myJPyon.myVar = 5` it will write every member variable the object has to a .json. It does this by making a copy of `myVar` in `__setattr__()` before calling `super(JPyon, self).__setattr__()` function and then compares the old `myVar` with the new `myVar` which then calls `self.write()` if needed. There might be more efficient ways to do this (i.e. only writing the section that needs updated) and I will definitely look into that, but I only started development on the project about 3-4 days ago.
Here you go: [Quantopian with Python series](https://www.youtube.com/watch?v=RxjIOXstxCk&amp;list=PLQVvvaa0QuDeN06s5ervxTfTcVvt-xpZN) [Matplotlib for custom candlestick charts](https://www.youtube.com/watch?v=u6Xd3kRHhJI&amp;list=PLQVvvaa0QuDc2QjQOkZ4rtLYZVll_sZFZ)
This is a bad idea. It runs counter to several suggestions from The Zen of Python. *Explicit is better than implicit.* Using the leading underscore conventions allows a package designer to explicitly signal the intended use of names. And the leading double underscore allows one to make names which are harder, but not impossible, to access. *(Although) practicality beats purity.* The OO methodology is enabled in Python, just as are the functional methodology and other methodologies. But Python code authors are not required by the language to practice any particular methodology other than what is required to use library modules. *There should be one-- and preferably only one --obvious way to do it.* Again, the leading underscore convention provides a method to signal that names are internal to a module or class. If necessary, remind class users of this convention, but adding more decorators seems unnecessary. There will always be proponents arguing to including favorite features from other languages into every language they encounter. Are these features necessary additions, or intended simply to increase the familiarity of the new language with the old.
I could use a high-speed rotate &amp; crop operation.
Plotly is pretty. I thought you had to use their servers to store your plots so I never gave it a try. Now I think I'll check it out a bit more 
All you have to do is follow the flash TV series philosophy. Oh problem X stumps everyone, never fear we can figure out how running really fast can overcome it. Oh problem Y is completely different, now just run really fast to solve that too. All problems are solvable if you just use your imagination (and speed)! 
&gt; By the way, you shouldn't measure IM's with time because this time includes decoding and encoding time. Lol what? That's funny... I could swear there's a way to remove the effects decoding and encoding on overall times if that is even necessary(it's not). What's it called again? Subdition? No that sounds wrong. Addtraction? Not right. Somebody must know the answer! If your code's encoding and decoding doesn't compare to IM that's an important point to note. If they are the same then the time diff with or without them won't make a difference. 
I'm stuck with selenium trying to click on the damn date on a calendar pop up. Happen to have any resources to learn how to accomplish that? Once I slept my dates I can export data and then play with it in pandas 
As far as I can see there is zero documentation there. Would anyone be able to explain what the code does?
This is my new python application for converting Youtube playlists and channels into podcast rss feeds. I have a version running on [podtube.aquacash5.com](http://podtube.aquacash5.com/). I would love to hear any feedback.
&gt; Gamma correction shouldn't be done in 8bit colorspace True, but there's no obligation to use 8bpc *internally*, and thus no reason to assume that gamma correction is off the table for 8bpc images. (cf. [ImageWorsener](http://entropymine.com/imageworsener/), for example) The article is very accurate IME; for scaling down especially, there are quite clear quality differences between with and without gamma correction. You don't need pathological cases like the author constructs to see that non-gamma-correct rescaling can substantially dirty and darken downscaled images. There is really no comparison between gamma-correct and gamma-incorrect in terms of reliability of results, no matter your input.
I'm certain the functions would have just been called `assert` and `assertNot` if `assert` wasn't a reserved word in Python. The current names are a little unfortunate. That said, I certainly don't see any suggestion that we shouldn't use `assertTrue` and `assertFalse`. I'm not sure where you're seeing a recommendation that `assertIs` is somehow superior. I also think your helpers are a bad idea. You've now added a level of indirection for some tests and not others, and for almost no gain. How often do you really need to be testing that booleans are booleans?
Obvious no, apparent yes. The larger the downscaling factor, the more severe are the errors caused by downscaling. If you are downscaling by a factor larger than 2, to produce a static image, I would strongly recommend [ImageWorsener](http://entropymine.com/imageworsener/) or another gamma-correct rescaler. These problems also effect things like calculation of gradients / blending of brushes in paint programs. For example, get a bright yellow #ffff00, blend it over black #00000. In linear space, you get a nice black/reddish/brownish/orangish/yellow transition, which is more or less true to life. In sRGB space, you get an ugly black/green/yellow transition.
Interesting about the Axiom of Comprehension as the theoretical basis, and nice that Python takes the pragmatic route of cleanly extending it to dicts and lists. In fact one could consider that the predicate is always there, but its default form is simply "True". I have used all those and still did not know that a generator comprehension was a thing. I have a hard time imagining a use case -- maybe as the driver of a "for x in ..." loop?
True story. Work is happening on the distutils-sig to make this less awful though. A hard thing is rocking the boat hard enough that you make waves, but not so hard that you get wet.
Yeah, I use list and dict comprehensions a lot, and while I was aware of these, I haven't needed them and I'm having a bit of a tough time imagining where I might want a generator comprehension/display/whatever. What do people use them for? Seems like all they would be good for is transforming the values yielded from another generator, is that about it? 
This fails with inheritance and superclasses: class A(object): @private def _foo(self): return 1 @public def foo(self): return self._foo() class B(A): pass b = B() b.foo() 
&gt; What happens when you encounter dynamic content, like updated via Ajax. I assume the content that is originally loaded will disappear. And when you open the HTML it will try to reload? From the README: "Note that this will only work with static pages. If an image or other resource is loaded with JavaScript, HTMLArk won't even know it exists."
I haven't done any sort of benchmarking, I don't imagine this would help performance at all. It's important to remember base64 encoding will increase data size by about a third, any speedups you get from reducing the number of requests will likely be insignificant compared to the slowdown from the size increase. This tool is more for when having a single file to manage is worth the trade-off in size, e.g. if you have a collection of saved webpages and don't want to deal with managing external resources alongside the HTML. If you just want to embed some small images into a webpage for performance reasons, I recommend using another tool to do the encoding, HTMLArk is made for converting an entire page.
In theory, HTML with embedded data URI files like this should behave more or less the same as a static HTML file loading said resources from files. So if you visit a webpage that loads content dynamically and save it to disk, you'll end up with whatever was part of the page before the JavaScript kicked in. HTMLArk simply moves those original files into the HTML, it has no control over what the Javascript loads. What happens to the page in the end depends on how the JS is programmed. If it still loads content after being saved to disk, it should still load it after being embedded into the HTML (though the resources loaded by the JS will of course not be embedded).
I think I should have added to the title that this is not a generator expression tutorial but a proposal to call them "generator comprehensions".
Cool article, but just a heads up, you can download the JSON file straight from the website instead of using Selenium. For example, [here's](http://www.nhl.com/stats/rest/individual/skaters/game/realtime?cayenneExp=seasonId=20152016%20and%20gameTypeId=3) the JSON for [this](http://www.nhl.com/stats/player?reportType=game&amp;report=realtime&amp;season=20152016&amp;gameType=3&amp;sort=hits&amp;aggregate=1&amp;pos=S) table. To get the data you can use the requests library. [This](http://www.gregreda.com/2015/02/15/web-scraping-finding-the-api/) blog post does a good job going over how to access the api, but uses the nba stats website as an example. A similar process can be applied to the nhl website.
If we're just dealing with JPG images, then it's also possible to use VIPs or EPEG. Both are about 3-4x faster than Imagemagick.
I use celery&amp;flower too but on redis. Mostly run our bioinformatics pipeline on cpu. 
Thanks for the answer! I think it will have many uses, if you have small json files, which you don't change too often. I was thinking about storing something like words frequency and those would change too much, creating too many disk writes.
Thanks! 
An easily fixable syntactic sugar: iterating over a filtered sequence. Now: for a in some_list: if a is something: do_something_with_a() do_something_else() or: for a in (x in some_list if x is something): do_something_with_a() do_something_else() Could be: for a in some_list if a is something: do_something_with_a() do_something_else()
The world is quite big, did you have any location in mind? 
I second this, G'MIC is awesome. And it does much more than image resizing...
You know; I was considering only writing in the deconstructor and seeing if that would work...I am a little worried about what happens during a crash though; but I suppose even during a crash the objects have to get deconstructed...that would also mean though that the .json files wouldn't be up to date during runtime but I think that is acceptable. however; right now writing isn't the bottleneck...it's actually instantiation but only really when instantiating JPyon objects...JDicts and JLists work great for the most part...
&gt; Nothing changes. For IM: -limit thread 1 For GM: -limit threads 1 &gt; I guess those operations are not parallelized. Just look at the "time" output: real 0m0.533s user 0m1.907s sys 0m0.041s Real time is 4 times fewer than CPU time. &gt; As opposed to what? You think I ran the benchmarks on different hardware? I pretty sure that IM and GM use more CPU cores by default. &gt; that the latter is much more efficient than the former It only effective on 16x16 conversion. It just fixes some bug which prevent IM to resize in parallel. But you are right, I should want also to test GM.
&gt; You are using Pillow for the first time and have no clue how resampling works, aren't you? Yes, I'm using it for the first time, but I do have quite a good grasp of how resampling works. What I expect is that when I resize an image, the defaults don't give me terrible output. Maybe I can specify a filter that will give better results. 99% of your users will never know about that and half of those that do won't bother.
You can ask either in the forums here: https://pythonprogramming.net/community/ or on the comment sections in the videos.
&gt; This is a serious issue that the dev team is actively avoiding. By "dev team" you mean me, because there is no dev team, It's just me. Coincidentally there's no real ops team either, there's me and when he has time Ernest. In addition, I'm not so much "actively avoiding" the issue as I am just seriously overloaded. Not only am I the primary/only person keeping PyPI going, I'm also one of the main driving forces behind pip (though thankfully that has additional folks working on it too! Not with as much "available" time to dedicate to it though) and one of the main driving forces behind working through a variety of PEPs to try and improve packaging as a whole and the primary developer of a PyPI 2.0 that will hopefully replace this decade old rotted code base that we call PyPI. &gt; Both the website and command line pip can not correctly search and install for an increasing number of packages. Search is broken and download stats are broken, installation is not. &gt; In fact, due to the shitty attitude on this bug report, several new and identical ones have been submitted. You want it fixed faster than I'm able to do it? Clone the code and figure out if you can reproduce the bug locally. If you can, fix it and submit a PR, if not update the issue. Other options include: * Convince your company to dedicate SRE and/or Developer resources. * Convince your company to donate to the PSF and ask them to use said money to hire dedicated SRE and/or Developer resources. * Help get Warehouse (PyPI 2.0) developed so we can finally replace the horrible ball of mud that is PyPI's code base. You know what's not a great way to get something fixed? Whining on Reddit about the efforts of one guy who is trying to almost single handily keep a site that did 787 million requests and used 77TB of bandwidth in the past week from completely falling down around us while also trying to fix the systemic issues that make this task harder than it needs to by replacing the proof-of-concept code written a decade ago that somehow became a critical part of the internet's infrastructure. The simple fact of the matter is if it weren't for a handful of companies donating services that allow us to offload some of this off of me and onto them, PyPI would not exist right now because otherwise I couldn't do it alone and I don't see anyone else stepping up to help.
Anywhere you would use a list comprehension but it's better to have the result lazily generated (eg. because you are not directly storing it, but using it as the basis for another calculation) For example, suppose you are fetching data from a bunch of websites and compiling stats. You could write that as : for i, data in enumerate([get_data(site) for site in sites]): lo,hi,mid = np.min(data), np.max(data), np.median(data) totlo += lo tothi += hi totmid += mid update_progress(i / len(sites)) But that would mean you would be front-loading the data fetching -- you would fetch all the data before you processed any of it, making your progress bar essentially meaningless. It would be more sensible to unfold that loop, like this: for i, site in enumerate(sites): data = get_data(site) lo,hi,mid = np.min(data), np.max(data), np.median(data) totlo += lo tothi += hi totmid += mid update_progress(i / len(sites)) But, if you used a generator expression, there would be no need to unroll: for i, data in enumerate((get_data(site) for site in sites)): lo,hi,mid = np.min(data), np.max(data), np.median(data) totlo += lo tothi += hi totmid += mid update_progress(i / len(sites)) Data would be fetched as needed, one site at a time, and the logical structure 'we're looping over the data from these sites, the sites themselves don't matter' would be clearly shown in the code.
Before scraping a site I suggest you check if it provides an API as it's (usually) easier to use/integrate in your code. The issue here is probably `soup.select()` (CSS selector) not finding any image. @cheezyc is right, you can check this by printing out the content of `res` (html you are parsing).
Funny, just spent this past week at work manually implementing web hooks between two internal systems. This would have saved us several days of work/testing!
Cool project! I guess there will be natural limitations on pages that make use of XmlHttpRequests to load additional assets. I'm curious, does it also inline web font files?
use arrow for dates and times
&gt;Python as a language/community has elected Pypi/pip as _the tool and repository_ for sharing your packages. So we select another one if the current one is "shit". You are free to lead the charge. There are other ways to get Python packages. &gt;Would you consider it entailment to complain if you input 2+2 and got out 6, or nothing at all? **Yes**. Did you read the piece I linked? This is **free software**. If you don't like how it works a pull request goes a long way. If the devs don't accept it tough shit, forking is a thing. 
The webpage simply hasn't any elements with class 'photo-list-photo-interaction': $ wget "https://www.flickr.com/explore" -O - | grep "photo-list-photo-interaction" Remember that soup / requests doesn't execute any Javascript. Edit: Seems like all images are loaded using Javascript. You can see the source HTML by right clicking anywhere in the document and clicking 'view source' (or by pressing CTRL+U). 
TKinter is kind of a joke. I'm talking Pygame or something equivalent.
We could do it at my house.
Thank You. That totally slipped my mind when writing the README.
Why does /r/python need a discord server?
Sweet. See ya at 5.
I use generator expressions a lot.
Wow, I never realized (and I bet others haven't either) that PyPi is maintained with so few resources. Thanks for all the work you've done with this.
The ideal would be SMBus support. I'm building a modular system of sensors and actions for photography, with sub-millisecond response time, so assuming some back and forth between multiple modules and the controller I was worried about the slower speeds of bit banged communication. ESP-12F controller with PIC modules, utilizing the addressing and alert event advantages in SMBus. Although right now I'm looking into adding another PIC or a dedicated I2C/SMBus capable chip to sit between the ESP and the modules.
Tldr fun experiment, well written to describe the process, but stick with gensim's cython implementation.
Then do stuff in Python. Don't worry about improving your Python skills, worry more about getting things done, while using Python. Have you taken a look at the literature in the sidebar?
Can we organize some sort of carpooling to your house? It would make life easier
common problem, without a project you have no direction Go for PyQt, knowing how to do GUI will give considerably more possibilities for projects [zetcode tutorial](http://zetcode.com/gui/pyqt5/) is a great little intro
Don't worry about that warning, it's not significant. 
Dumping function code is as simple as using the astor package. Source: any library/package that I work on that uses code generation requires astor so I've an obvious way to view function definitions.
Elucidate.
Learn Flask and SQLAlchemy, and build a web app or make a RESTful API.
[yes, I'm aware of that and intentionally avoid it](https://www.reddit.com/r/Python/comments/4j61f8/ned_batchelder_generator_comprehensions/d357g2w)
Am there, doing that.
 #How to make sure the user enters a number (integer) - www.101computing.net def inputNumber(message): while True: try: userInput = int(input(message)) except ValueError: print("Not an integer! Try again.") continue else: return userInput break #MAIN PROGRAM STARTS HERE: age = inputNumber("How old are you?") if (age&gt;=18): print("You are old enough to vote.") else: print("You will be able to vote in " + str(18-age) + " year(s).") 
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
This is a good description of the various options, but I'm curious if anyone has done any comparisons in terms of performance. What are the pros and cons of each method?
For a single computer definitely multiprocessing. It's the easiest, and built into python [1] For multiple computers, something else (iPython clustering is probably the easiest if you want to do stuff interactively, MPI is probably the most powerful in terms of splitting the problem up in clever ways) [1] The major caveat with the multiprocessing module is that it's the only module I know of with radically different default behavior between platforms. It forks the process on OSX/Unix, and spawns a new process on Windows. Two completely different things, which will lead to some very strange behavior cross-platform if you are not aware of it! You can change the default behavior (e.g. to always mimic the way windows works) on startup, though. 
Python and its libraries are just a tool with which to build a solution. Do you know how to design a solution? OOD / design patterns might be a next step. Have you written any test code to ensure what you've written works as performed? Unit testing / integration testing might be another thing to look at. I've used Google's mox and nosetests to do most of my testing with great success.
/r/pygame
Everything said here and in the sibling comments is correct and useful for examples. I just want to add a word of caution; while generator expressions (laziness) are very powerful, there is an overhead to creating the generator data structure, and its cache behavior can be (significantly) worse than lists/dicts. They're especially useful when you have either absurdly huge data structures, where putting everything into memory at once and page swapping would have worse performance than creating a buffer with overhead; and, as mentioned above and in siblings, for when you want to create an "inline" loop without having to manually unroll it.
A few of these exist and they are starting to be built into window managers. However, none of them really work the way I want. They aren't customizable for different screen resolutions or don't work great with multiple monitors. So I found a similar (now defunct) project, updated it to use Python3 and Gdk3, and made it super easy to customize. Edit: missed a word. 
Now it's more like bang your head against code for an hour then posting it on stackoverflow and getting the answer 10 minutes later.
Thanks for the awesome work, I couldn't count the number hours you have saved me.
Footnote four really deserves to be more than a footnote. 
 &gt;Now it's more like bang your head against code for an hour then posting it on stackoverflow and ~~getting the answer 10 minutes later~~ having it closed as a duplicate. 
IP theft never occurred, because they never lost the IP in court. Its theirs.
For example, Openbox has some similar features, and with this features i use a floating wm and a tiling wm (if i need it) at the same time. Feels more flexible. (with awesome wm, i use a tiling wm and a floating wm(if i need it)) And i need a floating wm more than a tiling wm. So, these type of features defines a gray area. Some users need it.
It's 2016, can we not have [footnotes](http://i.imgur.com/AhrYU6M.png) without popups when you hover over them? I'm not planning on scrolling all over the place when reading.
PLEASE port this to Windows! I'll hire buxom maidens to fellate you for eternity!
Post something on Stack Overflow, have it immediately removed by Mods for being redundant. Ask in IRC, get berated by some asshat that wonders why you didn't read through the core files first. Post it on Reddit and get accosted by armchair "experts" questioning what you are "really" trying to accomplish, siting something they call X != Y. Finally figure it out and realize everyone you talked to suggested the right solution you just didn't understand what they meant.
I still want fifths though. :(
Divvy?
Yes i thought about it. I can just read from an old json file and write to a new one at the end. I think that will be a real fit for my situation. Thanks!
First time to try a python-anything because your doc made the install seem easy, and I've been interested in learning python, but I gave up after this. &gt; Failed building wheel for greenlet Command "/usr/bin/python3.4 -u -c "import setuptools, tokenize;__file__='/tmp/pip-build-r_6698h_/greenlet/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))" install --record /tmp/pip-cej_7da7-record/install-record.txt --single-version-externally-managed --compile" failed with error code 1 in /tmp/pip-build-r_6698h_/greenlet/ and All I did was `sudo pip install Jolla` .. 
Nice! Do you think you could add some setup instructions to your readme for a python newbie? I'm not exactly sure how to get started. Let me know if I'm missing something. I've actually been looking for a much simpler alternative to a window manager to use on my ubuntu gnome setup. Nice work. 
I'm pretty sure you can pay him or someone else to port it to Windows. Might be even cheaper than a bunch of buxom maidens . 
i am sorry,i dont make it clear,it was based on python2.7
I did for a high performance place and gevent is great,so i make them up ,and design a useful route system and a some details for doing the calculation a something in back end and send them as json to client end
Please don't encourage people in your documentation to `sudo pip install ...`, that's rarely necessary and flat out dangerous. AFAIK there is no formal review process for PyPI and security and you're granting root rights to a machine. Use `pip install --user` for anything you need (user) system wide and a virtualenv for any time you need it just for a project.
How did I NOT know `psutil` existed! Looks awesome =)
Don't tiling window managers require you change your whole window manager to their way of thinking and setup? I generally don't want to force my windows into a tile and prefer clutter using Gnome-Shell. But when I program it's nice to just push a window or two into the corner. This gives me exactly that. **EDIT:** I should clarify, this is a tiny 200 line script that I have been using for several years and does exactly what I want it to do. I just recently decided to clean up and share with others. A lot of people are saying this script is not needed and I should just install i3 or awesome. I think the void this script fills is those like me that personally don't want to install another full blown window manager, learn how it works, learn how to configure it, then learn how to use it on top of another window manager they already prefer using.
Sure thing. I'll put some basic install instructions later today. What distorted are on?
I'm on ubuntu 16.04. using gnome. 
Write the test first. This forces you to qualitatively think about what the method should to before you implement it. The other way around the test just checks for what the method does and thus is equally flawed. Edit: writing the test first also ensures that your method is testable to begin with. This way you focus more on the parameters and a useful return value.
For some reason the python that is being used by `sudo pip` is 3.4 on your machine. I imagine you would find this is if you ran `sudo python --version`. In any case you should look into using virtualenv or conda instead of `sudo`.
Well at least instead of using `os.system` to run .py files you can just import them all and run them as function calls.
&gt; instead yes,i would not put `sudo` again
&gt; compared gevent+uwsgi?i did not try it before,i once used gunicorn+gevent,but i think it's slow,and uwsgi is fast,but gevent is great
It seems useful to me! Mark!
Alright. It's not a tough install at all and I'm running with the same setup. I'll have something tonight. 
This is actually the article that got me started. I was real tired of trying to figure it all out and settled on this to just get going. An excellent read in my opinion for anyone interested. Thanks!
Congrats on releasing your first open source package! Just a thought, but the first thing I check before I use a new library is the test coverage. It does not look like you have any unit tests for your module yet. If you want people to start using your library, I would highly suggest creating a test suite, and linking the tests into your build process with something like codecov.io or coveralls.io.
QA Engineer here. * Any test is better than no test at all. Assuming that the test actually tests something and the result is meaningful. * Use code coverage tools if you can, gives a nice overview on what you're still missing from your tests. Personally I use pytest-cov, but that requires pytest. * From experience, you can usually skip on some tests, but when some major refactoring moment arrives, you'll need them and have to write them anyway. If you don't, the work will be 10 times more difficult. * If your test fails because it's not complete, but you don't have time to work on it, don't run it at all, it'll only get you used to failing tests. Consider the area as not covered. * Your goal is 100% green. Anything less indicates a problem somewhere, it might be the code under test, or the tests themselves, or badly specified requirements, or the test environment. Considering the comments that appeared, I feel I should clarify some things: * 100% green means 100% test cases pass, that is your goal, if a test fails, you have a problem somewhere * about point 4 and failing tests: tests that are broken and fail regardless of code under test, should be fixed first, run second. * getting used to fails is a very bad attitude, if you always have some failing tests, because they are broken, or not finished, you should not run them until you fix them * if the code under test consistently fails the tests, then that is a valid scenario, because the tests are still fine. However you should be ready for requirements to change over time and suddenly your perfectly valid failing test is no longer valid 
Thanks for the kind words. Making a setup.py is on my todo list, but I wanted to get the functionality working first. I've never published a package before so I'll have to learn how to do that.
I heard that [pytest](http://pytest.org/latest/getting-started.html) makes testing fun again ;-)
You can just try it. Install [i3wm](https://i3wm.org/) or [awesome](https://awesome.naquadah.org/) (available in all major distros' package repos) and check them out, no commitment required.
Yup: may write a blog about this at some point. 
That makes sense. Thanks!
1) Start testing at the far edges of your application (i.e. the interface with the 'outside world' and *not* implementation details) and be very cautious about testing at a lower level. 2) Write the test first. Write one test for any new behavior you are adding in the form of a story and one test for any bug (also in the form of a story). Once the test is running (and clearly failing), write the code that makes it pass, bit by tiny bit. That's enough. You shouldn't write more tests than that. 3) Bear in mind that it often *should* take longer to write the test that accurately replicates the conditions your code needs to invoke your feature/bug than it takes to actually write the code to make it pass. 4) Don't worry too much about code coverage. It would help if you told us what kind of application you were testing. There are various tools/libraries for different kinds of applications which it makes sense to use and you do *not* want to reinvent those wheels.
Funny (and neat) project of yours. you don't use software that download the right subtitle for you ? I use smplayer http://smplayer.sourceforge.net/en/info and the subtitle is always good ! There's also subdownloader (to batch download).
yeah i later found out vlc player can search with title and even hash! but it's still nice on my phone or an android tablet, or when a sucker doesn't use vlc.
oh VLC also ? :) is your project open-source ? I'm curious to have a glimpse on how you did that.
I know Mochi is: https://github.com/i2y/mochi It's a functional language with python 3 syntax that compiles to python3 AST ! Looking forward to v1 and more tools.
How do you write bots? Using requests or mouse/keyboard simulation or something like selenium? 
I have a question that is is abit on the side, but how was your experience learning python to eventually make a webpage? I want to start learning how to code (for website development),but not sure of which programming language to start with and go all-in at. I've heard python is good. 
In a perfect world what I'm about to say isn't true, but realistically, a lot of coding best practices are not applicable to unit tests. It's okay to repeat yourself, for the sake of clarity, for example. It's also okay to me overly verbose for the same reason, and your tests don't need to be optimized (to a point, CI principles guide here). Like another commenter said, some testing is better than none, and I see tests go unwritten all the time because it's a hassle to write great tests. Just vomit into the test directory, and spend a little time cleaning it up, but don't hold back on test cases just because you can't get the test code to look as beautiful as the actual code.
The complete multi vendor network device configuration generation for the largest commercial satellite internet provider in the United States. Before that it was the customer provisioning for Level 3's 8 million managed modem ports serving Microsoft, AOL, NetZero and every other major dial up provider in the early 2000s. Plus, I organized my wife's recipes.
No. You need to download and install a new Anaconda, with python 3.5 
Yes, I'm using Unix python on windows. Are you saying that they are two different things and that I can't access the the python.org windows download with cygwin? I'm just confused because the guide prompts to download python from python.org but cygwin is already using its own installed package of python. EDIT: I figured it out the answer to my question. I'll look into ipython and ipython notebook, though. Thanks for the reply!
What was your experience using Dask? I tried Dask on a 400k line dataset locally, and didn't get any speedup compared with regular Pandas.
Instead of using mocks, try passing the context to the function. example def parse_url(url): res = some_url_library.open_url(url).read() return parse_text(res) is harder to test than def parse_url(url, opener): res = opener(url).read() return parse_text(res) 
My first script was for my work (ex-gov reseller). It was a script that updated the hosts file to null route hundreds of malicious domains. Second was a Windows Activation program (essentially pushed the inserted Windows key into slmgr). Because we use clonezilla to image machines I had to create the third script, which automatically extended all hard drive partitions to max. Edit: Fourth script was to send files to specific channels in slack. Fifth script was to determine if our server had gone offline and if so, send a message in slack.
As a followup, these are some great services which can help to accomplish the above. Every time you push a commit you can run your entire test suite against multiple versions of Python: * https://travis-ci.org/ - Continuous Integration (Linux, OS X) * https://appveyor.com/ - Continuous Integration (Windows) * https://codecov.io/ - Shows code coverage results. Bonus: * https://readthedocs.org/ - Build and host your documentation. One final note I'll make: *Keep test cases simple.* Try to test one thing and one within a test case so if one fails you have a better chance of discovering the bug. It also feel faster than writing really large test cases too. 
It's nice that you are supporting Python 2.7, but I don't look at anything that does not support Python 3.5 these days.
Testing is an art / discipline / lifestyle. Like programming it takes years to become good at it. So I'd say the 5% you need to know is that you have to learn the other 95%. Testing is not quick or easy. Expect to spend 1/3 or more of your effort on tests. Unittesting isn't really about big T testing. It is much more a software design / software development methodology. It allows rapid iteration, confident refactoring and most importantly to be easily unittestable your code must be divided into "units": well defined, isolated, self-contained, layered.
Integration tests and path coverage over unit tests, imo. They will give you the best semblance of whether or not your code is 'working'. I've met too many engineers that go overboard on unit tests for functionality that is never used. And keep in mind that test code is still code. The more tests you have, the more you have to maintain those tests and the more likely you are to either introduce a testing bug or forget to update a test for a change in standard code. Less is more. Finally, you want to vet the interface while you create it. I disagree with writing tests first because I may decide I want the interface to look/feel different to the user. What a waste of writing twice the code when I'm not even sure that the initial interface will work for me. I would prefer to go for prototyping first, getting feedback and finally evolving examples into tests from the prototyping phase. I think a few others recommend pytest. I agree with that. Also, I'd add Tox and Travis (if you're open source) or Jenkins (if you're not). Tox you can use locally with a variety of different environments and tox will integrate nicely with pytest.
I use fifths as well, but with only 4 windows. I have two windows on one side 2/5th wide and 2 windows on the other side 3/5th wide.
Thanks!
https://en.wikipedia.org/wiki/Test-driven_development
This is true, but there's a balance. When the test fails, it should be obvious what's going wrong, either because the test is written clearly or because there are comments. What you don't need to do is factor every little bit of redundant code out, or spend hours designing the test classes.
Pulling the latest xkcd comic (every MWF) and posting it to one of our slack channels at work. A co-worker and I thought about this and I finally got around to it this weekend.
&gt;It's also the most burdensome to maintain. Any change to your application tends to break the test as well. I've found the exact opposite to be true. Indeed, major refactoring is really *only* possible with end to end tests since unit test are tightly coupled to the implementation. Only end to end tests are coupled to the desired behavior. Changes to the application only break the end to end tests if you're doing something dumb (like relying heavily on xpaths with selenium). &gt;These tests are the most brittle since they encapsulate the entire system. Any test that does not properly isolate is brittle. It happens with unit tests as well. The only difference between end to end tests and unit tests re brittleness is that there is more stuff to isolate and people just tend not to do it. &gt;People tend to lose confidence in the tests People lose confidence in *shitty* tests, regardless of what level they're written at.
Russian testing dolls. I like that concept 
We'll probably need to end up deciding to disagree and be okay with that. The goal of testing should be to prove that the code you've written works under system load and has a sane/expected method of handling the unexpected. I want to qualify my next response with some information so you have an understanding of my evolution of thought on this. I spent 9 years developing flight controls software (of which maybe 70% or so is writing tests - unit, integration, system, performance, regression, white/black/grey boxes, etc.). Additionally, I've had approximately 20 years or so of total experience writing software in a professional capacity. And over the past 7 years or so, I've been working in a start-up setting with multiple companies. So I've been around long enough to see a lot of methodologies. Every single one of them has at least one great idea at its core, but absolutely none of them are perfect. So I actually started with your current viewpoint. I prefer to keep my process as closely aligned to how I generally need to create software: with minimal or no specs/requirements. That means I'm generally writing software in an evolutionary prototyping loop until I have something that works for my business use-case. At that point, I can massage the examples I've created for my prototyping into documentation and tests, of which a majority are integration. A large majority of unit tests are covered indirectly by my system integration tests, which begs the rhetorical question - do I need to actually cover every edge case if my system never has those edge cases? Rarely do I say 'yes' there. I understand your use-case for having long running tests for a single change. And there's a clear need for having a quick turn-around on whether or not you are actually producing code that will work for your requirements. But I would argue heavily against writing unit tests as your base mechanism. Instead, I would argue that creating unit tests should be a rare thing as it increases technical debt over time. Instead, stick with the API level and the loose coupling you see around integration and performance tests.
That fifth one is so simple but so useful. 
Just yesterday I wrote a server that translates various third-party commands into my smart home's components' various commands. For example, when I drive into my garage, my phone connects to my home wifi and knows my GPS coordinates were not but are now at the house. I have Tasker on my phone make a POST request to an API endpoint on this server telling it I'm home, and the server translates that API call into a message to my entryway LIFX light bulbs to turn on so I have light in my house. That kind of thing. Oh my favorite thing is actually some moisture sensors in my lawn and an irrigation controller you can configure via API calls. Poll weather forecast, check moisture in lawn, determine whether to tell irrigation to water the next day.
Python CGI scripts just vomit HTML via stdout to the web browser for rendering. For simple things, there's really not much to it. I had no problem getting things up and running on an OOTB Apache install. 
If you do write tests with mocks, please don't be clever. It seems surprisingly straightforward to dry up mocks across multiple files by implementing a class that inherits from TestCase, or maybe a mixin. The problem comes 6 months down the line when you've forgetten what the the actual code your testing does and which mocks it needed.
Have you made a flat html file that works? If so, just see what the difference is with the template generated one. Make sure you can get the static resources to load.
&gt; Don't tiling window managers require you change your whole window manager to their way of thinking and setup? That is generally implied by the term 'window manager', yes (only one window manager can run at once). If tiling is a sufficiently small part of how you work, I guess that wouldn't suit you. I run QTile myself, with mostly single-tile (maximized) layout; occasionally switching to multi-column layout. Of course there are some apps that I don't want tiled, so I keep them floating; but mostly, automatic tiling saves me a lot of time (eg. terminals, browser windows, IDEs, paint programs) ; I hardly ever manage windows myself at all, which IMO is the way it should be.
Can you tell us which planes use your flight control software, because I have *never* seen an approach based purely on integration tests produce anything but barely functional software, and I would personally like to avoid placing my life in your hands. Seriously!
http://sahandsaba.com/thirty-python-language-features-and-tricks-you-may-not-know.html
What do *you* think we're talking about?
Yeah I use Python for most of my backend scripts
Currently working on a script to manage users, HBACs, groups, sudo rules, etc. for an IPA cluster I built at work. The idea is to have a config file act as the source of record for all of the previously mentioned objects and have it run every x number of hours through jenkins. I've worked with IPA before and it ended up being unorganized nonsense and I want to avoid that this time.
Thank you very much! EDIT: For anyone else who reads this post and encounters this problem, make sure you use a *UNIX text editor* (Sublime Text 3 &gt; view line endings &gt; UNIX) to put this line in your home directory .bash_profile file.
https://github.com/learnbyexample/scripting_course/blob/master/Python_curated_resources.md#tips-and-tricks
I tried to use this in one of my projects and was dismayed to see that python 3 isn't supported :(
 In [18]: %timeit subprocess.call("/usr/bin/true") 100 loops, best of 3: 2.33 ms per loop 2.3 ms is acceptable. 
1. My server backups, one to make main backup on my NAS and another to upload a copy to my dropbox. 2. Telegram bot that every morning tells me the date, forecast for today and status and size of last backup of my server (also another bot that sends me daily cat facts).
[removed]
Porn downloader. There, I said it so no one else has to admit it themselves. 
Piggybacking on your reply, I wrote a script that scrapes MTGO replays and saves cards that are played. Useful until Wizards disabled replays... :(
&gt; that maybe it's a kind of trend,but python2.7 is great enough
ok! Thank you for your suggest, I would do some TDD next time
Webscrapers
So far it has matched (exactly) the speedup with multiprocessing; want to try it across multiple nodes to see if the parallelization is improved/speed improves. 
You know there's an app for MAL, right? Could've saved you all that trouble.
Delete `/usr/bin/python` from `C:\cygwin\bin\python`. It's obnoxious.
Once a month, I scrape a particular website (about 5000 static pages), reformat the pages for better readability, use them to create several epubs, convert the epubs to mobi, and upload both epubs and mobis to dropbox. All of that takes two commands - one to scrape the site into an sqlite snapshot, and another to do everything else.
&gt; but that requires pytest But using pytest is quite a good idea in general. &gt; Your goal is 100% green If there's a test that is not currently working and you can't fix it yet, disable it (especially easy with pytest) and e.g. make it possible to run it explicitly or by enabling some environment variable.
If you are talking about Pocket-MAL is very nice, but I'm with hate of smart-phones these days (personal feeling). Is very more simple to me use the command line when I'm watching anime (personal thinking). Besides, I'm fan of CLI interfaces and simple things (personal taste). And anyway, is fun to code, so don't have problem at all for me with this. Thanks.
A good end-target for making testing fun is "if you can test it manually you should be able to automate it about as fast". Certainly you run your code anyway before pushing, right? And if so, you can make a minimal test by at least saving the input and output of all deterministic functions. And with some good helper functions you can do that for some of the non-deterministic ones (such as the ones using a database).
Asking for node to be installed to run the programs kind of ruin the stand-alone requirement.
Smaller functions are easier to test. If you have a function that does a bit of work, then does a different bit of work, then does something with the result of the previous 2 steps, you should have 4 functions: three small, easily testable functions that do very little, and one that uses those functions one after the other to get a task done. With 8 functions and 500 tests, I'd say your functions are way too big – for example, a better ratio would be 50 functions with 10 tests each. Mocks shouldn't be necessary for unit tests, save them for integration tests. If you're mocking in unit tests, your functions need to be split or reworked to make them cleaner.
Why are you running cygwin? If you're just starting out it would be much easier to run python natively in Windows. You'll learn all the same stuff and it'll less of a hassle.
The only person talking about compiling into stand-alone binaries is you. I certainly wasn't talking about that. You tried to change the subject to stand-alone software and I ignored you trying to move the goalposts. Go back and re-read the subthread. There's like seven responses back and forth, including you arguing that "packaging" is hard in JS just like Python directly in response to us criticizing the setuptools system. Finally, deep into the discussion, you go "it's the stand-alone binaries that's tough." No one but you was ever talking about it, and you were only talking about it as an aside. I wish you would have been clearer up front; I wouldn't have wasted my time talking to you because I and the other person I was responding to were utterly uninterested in discussing the production of stand-alone binaries since almost no one gives a shit about stand-alone binaries in the grand scheme of things. Can you direct me to a single serious Python package that is distributed as a stand-alone binary and not using pip or something else like it?
I just finished a script that reads a file directory and then compares the contents of that directory to a master list of files that should be in there. It reports back how many files are in there, how many files are missing, and how many files are present. It also then has a separate option for transferring those files to a separate folder for our once a month archive process.
use flask, its perfect for tasks like that, dont even have to vomit html to stdout :D
In my experience, I'd say the thing to aim for is coverage. Python is one of the few languages that will happily run your app when you have a clear syntax error or blatantly obvious type error, so you want to find those problems early. For me, that means writing tests that call as many of my methods as possible, just to get that code executed and find stupid errors early. Using a coverage tool then lets me see what code I'm not covering and extend the tests to do that. Constructing elaborate tests with all kinds of different input is interesting and feels productive, but ultimately it doesn't buy you much if the test code tests a scenario that you're extremely unlikely to encounter in real life. So I aim for basic coverage first and only add specific edge-case tests either when I encounter that edge case and need to verify that I've fixed it, or if I'm sure that case is likely to come up.
Did you use something like Heroku to integrate it?
Anaconda can create a new environment with a different version of Python, using the command I showed in my previous comment. No need to install another Anaconda!
A program that texts a phone number a random Kim Kardashian fact every hour / day / week 
First thing I do after installing windows is uninstalling IE. Obviously I'm not good with memories and I usually forget to download firefox prior to this but never forget to install python (nothing is wrong with me). So, last year I wrote a script to download firefox latest. Also years years ago, when chromium for mac didn't have autoupdate I wrote a script to install and regularly update the chromium browser in 2011 I guess . Finally I automated my password generation method. I don't know any passwords I use, I enable 2 step in any service I use, I save my passes to keepassx which cheks for a key file and a password. Anytime I need a password I call my script that generates a password in my desired way and copies to clipboard. This is ofcourse not secure but I really don't need to remember anything this way, and I can focus on my other security concerns, like https, fake ssl certs, possible malwares like keyloggers and trojans, etc. 
fabric?
I was speaking of lines, 100 vs 500. The 8 functions in 100 lines so far seem covered by 8 TestCase classes and 35 tests in 500 lines.
My rule of thumb is that if something makes my work "boring" or make me lose sanity points - automate it.
I will be messaging you on [**2016-05-21 11:06:35 UTC**](http://www.wolframalpha.com/input/?i=2016-05-21 11:06:35 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/Python/comments/4jhma7/what_did_you_automate_with_python_scripts/d37ch6i) [**6 OTHERS CLICKED THIS LINK**](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/Python/comments/4jhma7/what_did_you_automate_with_python_scripts/d37ch6i]%0A%0ARemindMe! 5 days) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! d37ch9w) _____ |[^([FAQs])](http://www.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^([Custom])](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^([Your Reminders])](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^([Feedback])](http://www.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^([Code])](https://github.com/SIlver--/remindmebot-reddit) |-|-|-|-|-|
Built a little web app that compares movie casts over the weekend. Still needs some love, but I find myself constantly saying, "Is that that person from that movie we just watched?" Probably going to integrate it with Plex so I can populate fields with currently and recently watch movies from there. Though, I wish Netflix still had an open API. Or that TMDB would return the full cast for TV shows. 
There's a site I go to where people offer to critique your writing before you post it. There is very little organization, and it takes a lot of digging to find someone who's actually good at writing, and still active. So I have a script that iterates over the readers, estimates activity and quality based on certain stats on their profile, and spits out a list of URLs to readers I should request. 
I wrote a script that listens to meetings I'm supposed to be paying attention to and pings me on hipchat and slack when my name is mentioned. It sends me a transcript of what was said in the 30 seconds before my name was mentioned and everything within 30 seconds after. It also plays a wav file out loud 15 seconds after my name was mentioned which is a recording of me saying, "Sorry, I didn't realize my mic was on mute there." I've only had a chance to use it in production once so far (just wrote it last week). Went ok. I'm using IBM's Watson API for the audio-to-text. Google's seems good, but they won't respond to my api key access request. 
did you per chance write: {% for message in messages %} &lt;li&gt;{{ messages }}&lt;/li&gt; {% endfor %} instead of: {% for message in messages %} &lt;li&gt;{{ message }}&lt;/li&gt; {% endfor %} That is: `messages` inside instead of `message`? If that's not it, please post your code - it's really hard to guess without seeing the actual code. *Edit: also, this is something that should be posted in /r/learnpython*
I don't really watch anime much, but I recently asked a weeb for suggestions and watched some, so I might try this out.
Now you just get to worry about home internet limits D:
Using a linter like MyPy will save a lot of this tedious work. 
import antigravity
Well amongst other things, one of my big projects was to scrape Google for URLs (to get data for Machine Learning). So far I've managed to get to 10,000 URLs per day per IP without getting my IP blocked. Planning on expanding to other search engines. I also wrote a script to DDOS a website: https://repl.it/CRNC
Hehe, nope, but I do fake cat facts
I've worked as a Python programmer on SDLC tools intended for use as production releases. - Write an acceptance test that tells you your code works, then keep writing more of them as you expand your expected functionality. - Classmethods setUpClass and tearDownClass run once per TestCase (be sure to use the @classmethod decorator - attributes you give to the class are naturally available from self in the regular methods) - methods setUp and tearDown run before and after each test_* method - Try to use asserts other than assertTrue - you get more information about what went wrong, whereas assertTrue just says "It's not True." - Don't use the assert&lt;Types&gt;Equal methods, just use assertEqual - Test for Exceptions with assertRaises as a context manager. - Run your suites of unittests in clean, production-like staging areas before you release your code into production/the hands of the masses. - Write a smoke test that works under expected use conditions and lets you know when something goes wrong (if something does) as soon as possible. - Have a peer review your test code with the same or higher level of scrutiny as they would review your program's code.
Hahaha I like this one the most. Fuck 'em.
Not libraries. Software. Like dropbox, which is in Python but is installable. This is one of the thing that is easy to make in Go or Rust and hard in Python or JS. Packaging for simple lib is very easy in Python or JS, nothing hard about it. Procuding an exe or a deb is another story.
This has always been my favorite part of Python, ever since I've learned how to program in it. You can make nearly anything and it usually wont be that many lines of code.
I never really use SSH for VMware stuff. I used the pyvmomi library which is a python wrapper for VMware's API. I used telnetlib for telnet scripts. I didn't know about fabric but I might use that for some other projects...
BEEP BOOP:: REQUEST RECEIVED:: 01000100 01110101 01100100 01100101 00100000 01101001 00100111 01101101 00100000 01110011 01101111 00100000 01100110 01110101 01100011 01101011 01101001 01101110 00100000 01110100 01110111 01101001 01110011 01110100 01100101 01100100 00100000 01110010 01101110 00100000 01100110 01100001 01101101
I personally just hosted it locally. It's super easy to do it using Slacker. https://github.com/os/slacker
why not capture a few sentances before and aftter the difficult words?
[My gists and dot-files](http://github.com/cuducos/getgist)
I have to add titles to a whole bunch if music videos, like the MTV "in the bottom left corner" titles. This is really tedious, so I wrote a set of scripts to do it for me. This involves first using a Dropbox downloader script to pull all the videos from a submission bin, then it puts all the filenames into a queue file. From there, I have to manually add the titles to the queue, though I intend on doing this with a form eventually. Then I run a script that reads through the queue and adds titles to the videos based on configuration parameters. Then, it renames the files to indicate that they have been titled and moves them into another directory. Finally, these are dumped back into Dropbox for archival storage and sent to the proper people. Manually this would be a royal pain, as I would need to manually fetch a .zip from Dropbox (as it is on a different account from the one on my PC), manually edit all of them with a template and set them to render, remembering to rename everything as I go, then move them to the Dropbox one by one with the uploader.
I would it if there were any other options. Comcast is literally the only isp I can use
You monster
RemindMe! 15 days
Yeah, you pass in a dictionary and the workers update the dictionary with their result. See the requests example on that page.
Also, DOSing is not just sending lots of requests. It's particular incomplete requests that hog lots of resources.
Still don't see it. On a mac I can do exactly that. Install multiple versions from Python.org. The Mac OS distribution (2.7) is in /System/Library/Frameworks/Python.framework/Versions/2.7 and the others are in /Library/Frameworks/Python.framework/Versions/3.* You can make as many venvs as you like, just specify --PYTHON_EXE= with a path to the desired interpreter and --always-copy. When you activate a venv, that's the python you are using.
This is brilliantly hilarious. I want to know how future usage goes.
At least you are using PyCharm, it statically checks code while you type.
&gt; Now, 28.9 seconds is much more than 8.4 seconds so it's still a win to multiprocessing for this kind of CPU bound work. However, stampeding herd of doing 8 CPU intensive tasks at the same time can put some serious strains on your system. This is probably the hyperthreading effect. Some operations are slower when you load all of the virtual cores instead of just the physical core count. I wonder if you re-ran the test with `@concurrent(processes=4)` if the runtime would be better than 8.4 seconds. If anyone has seen a good guide on what we can expect hyperthreading/SMT speedup on, and when we should expect a slowdown, I'd love to see it. All I know is experience may vary.
Yeah, I'm the same. But every foreign language textbook I've ever had has been using the new glossary followed by text approach. I wonder what the latest research on language studies recommend?
Just because the article mentions, in passing, that a python script was used to make a spreadsheet doesn't mean this submission belongs in /r/python
https://docs.python.org/3/library/faulthandler.html can help. https://pypi.python.org/pypi/faulthandler/ for py 2.x
So, that's basically just a wrapper package for `multiprocessing` providing 2 decorators that make multiprocessing more convenient? I don't mean to criticize; I am just wondering if I understand it correctly and am not missing something. It looks great btw!
It tries.
Running too many processes impacts more than just your cpus. Depending on the nature of what you're running you could saturate your network, your disk, etc.
Got it! Celery Looks like a good framework... I've heard of it before. VirtualEnv helps manage separate software / requirements? A good first step for security would be to run as a separate user... I thought virtualenv did that but it looks like my memory is throwing some faults
Way back when I set up a script that would read a Starcraft 2 replay, check to see if I was streaming on twitch during the time period the game was played, and if so would automatically create a highlight from the given time period.
Oh cool, that seems good. Just to be safe though I better ask about race conditions. Any chance of 2 calls writing to the dict at exactly the same time and causing problems? 
Seems like it, but I think it's great. Multiprocessing could use some wrappers. Often I just want to concurrently run a basic thing and get the results, and I shouldn't need to google to do that
The one major turnoff about this is the use of multiprocessing.Pool. Multiprocessing in general is a mess, but Pool in particular does something kind of grossly naughty by forking off a child thread (this is a good way to wind up with hosed semaphores, and in general mixing threading and forking is a quick path to huge problems). Taking a broken implementation and hiding it behind more layers of obfuscation seems like a recipe to have bugs that most developers won't ever be able to understand. Otherwise, this is a relatively interesting idea.
I assumed the 100% green here was meant "no failing tests" not 100% coverage.
I disagree that unit tests are a form of coupling *in general*. I try to write two kinds of unit tests: 1. Ones that test the interface - no matter what implementation I give to this test, I can expect the same answer. These are what J. B. calls "contract tests" and I find them to be the most valuable. 2. If a specific implementation has other public attributes or executes it's interface differently, I write specific tests for it. Think of a cache system. The implementations of redis vs memcache will vary wildly and I need to make sure they talk to their collaborators correctly. These are less valuable than the more general interface test, but still very important. But since they're testing a specific implementation, of course they're more coupled - and there's nothing wrong with that. I guess it's also in how you define *unit* as well. I've taken to thinking of unit tests as testing a complete unit of work, rather than just this one specific method in a vacuum. 
That is a race condition though. You really need a mutex or lock to mitigate this. Looks like multiprocess Manager has a dict() that is really a better choice.
I think that I'm missing something. In the requests example, the modified dict is not read. Are you sure that the value is available to the parent? If the process is forked, you have to get the value from the child, since every children updates its own copy of the object. 
The linked article is incorrect, Deco is not actually based on pydron. Pydron is simply a piece of related work.
Do you know if it has to be a vanilla dictionary, or would a pandas dataframe work?
[Here is the code for Google's Parsey McParseface that was just released Open Source](https://github.com/tensorflow/models/tree/master/syntaxnet)
Been around for a few years, neat stuff https://pex.readthedocs.io/en/stable/whatispex.html#how-do-pex-files-work
[Github](https://github.com/certbot/certbot)
We're in the process of supporting other concurrency backends, but we chose Pool initially because as far as parallel computing in Python goes it is sort of a standard. The 'naughty' spawning of child processes is extremely necessary in the case of CPU bound Python programs, because vanilla threads are limited by the GIL.
I disagree very much. Unit tests run in seconds. I run them all the time. They tell me the error right after I make it. It's obvious or trivial to figure out error. Integration tests take long time. Typically only run them on/before merge. They often don't give any indication which of the many changes caused error. I then have to spend debugging. Also, I can write unittests any time, I have complete control over them. Integration tests often require lots of infrastructure (test systems, database, realistic data). Integration by definition tests often include lots of parts that I have no control over. Integration tests are sometimes responsibility of another team/dept (QA) and there is friction in getting them to add tests. Integration tests, test your app works. Unittests, test your software design works.
Tests that fail because they are broken by themselves don't deserve to be run until they are fixed. Tests that fail because the code under test is broken, are valid fails and should be run.
Have you checked out Dask for dataflow paralellism in pure python and numba to accelerate and release the GIL on numeric code? I wonder if there is synergy here. 
Hi there, this post has been removed as it is not directly related to the Python programming language. It might be more topical on /r/programming, /r/coding, or /r/technology. Cheers, /r/Python mods
That is awesome
You can also specify the base interpreter when creating a virtual environment with the `-p` flag. http://docs.python-guide.org/en/latest/dev/virtualenvs/#basic-usage
[&lt;/3](https://myanimelist.net/modules.php?go=api#verifycred) is a lack of love. Almost all methods need a POST/GET key username:password. T_T I was wondering a way to improve that... any ideas?
They could use oauth like many other social networks. I wanted to make and publish a chrome extension, but I would have had to store the user's login information without encrypting it (as Javascript encryption for extensions is useless). It would also be nice if MAL had a newer API for accessing a users list, instead of making us fall back to the old API (which uses a different date format, among other things). In addition, theres some information you can't get from the api, like a list of characters, genre, author, or more statistics. 
1) Technically, a WSGI application stack is stateful, so any module-level global variables should persist within a single Python interpreter process. This is because a WSGI application is not an "application" as such but a Python function object that is called for every request. Read PEP-333/3333 for more details. However, some WSGI server implementations may run several Python interpreters for performance scaling, each with its own globals. So you would need to use some inter-process storage like Redis for shared data.
Can you share the source on github? Would be awesome to see how this works. 
I am very excited right now Edit: link. This is so cool https://github.com/alex-sherman/deco/blob/master/examples/climate_model.py
A denial-of-service is anything that overwhelms the server. A particular kind of incomplete request might be one technique, but is not the only technique.
One of my favorite YouTube channels livestreams sometimes, but doesn't post the vods. So I built a script that frequently checks their livestream page, and if they are live, it starts to capture the download using the same name as the stream. In addition, if the capture fails for some reason, the next time the script runs, it will see that there are old attempts a at recording, and start a new file with a similar name to continue the capture anew
From the paper: &gt; These inser- &gt; tions are made by the @synchronized decora- &gt; tor, which traverses the synchronized function’s &gt; AST recursively tracking potentially mutated &gt; data. When it encounters a later reference to &gt; one of the mutated data it first inserts calls to &gt; wait(). That seems pretty magical, in the "be wary" sense of the word and makes me wonder how well that aspect is tested?
&gt; Tests that fail because they are broken by themselves don't deserve to be run until they are fixed. I disagree. It's known bad functionality. You've never fixed a test unintentionally while trying to fix another bug? That should be flagged as a problem because then you know that you should change what the expected status is.
that... is goddamn amazing. too bad there are waaaay too many guys here with the same first name as me. 
Yes! Would be really better if they update your very outdated API. About more information we have, unfortunately, use scrapping T_T and this is so error propose because the HTML changes easily with the time passing...
I think you may be missing a subtle but very very very important point about programming languages and their implementations. A language is just a specification. A design, basically. The implementation of that design can vary and there are many different implementations of some of the more popular programming languages. The JVM that Oracle maintains is not the only JVM in existence. Android doesn't use that one. Android only uses the Java language, but its actual runtime (the implementation of Java it uses) is different. The original Android OS used the [Dalvik Virtual Machine](https://en.wikipedia.org/wiki/Dalvik_\(software\)) implementation of Java. Later versions have updated to a similar architecture with some tweakd and adjustments made by Google. similarly, there is more than one implementation of the Python language. the "reference implementation" is usually called CPython, because the interpreter for it is implemented entirely in the C programming language. There are many other implementations of Python though and they have different performance characteristics and other various technical tradeoffs relative to the reference implementation. So to answer your question: yes, Python (the language) could have been used as the application programming language for Android. It would probably have needed to use a different (i.e. more performant) implementation of the language than CPython though to account for the lesser computing resources available on a mobile device compared to a desktop PC or server. I believe Java was chosen for market-share purposes, essentially. It is still (afaik anyway) the most widely known programming language in the world. 
/r/learnpython
There's a big difference between "I don't know which value got stored" and "The value may be anything, and isn't necessarily any of the values that was written to the key." In some cases, either worker's answer would be acceptable. But it's never acceptable to just get corrupted gibberish.
Nothing to fear. You only download the songs that you don't have in your playlist. But yeah, Comcast sucks :)
are you planning on running all of this (logging, data processing, IoT client endpoint, etc) on one server? That might not be a good idea, last thing you want is one job (ie: data processing) knocking out the other jobs. You'd want to separate each layer of concern. Also, single language doesn't necessarily mean lean either, it might even end up bloating it up more; use the best tool for the job.
I didn't read the whole thing, but given that you search for the strings "donald" (a common name) and "trump" (an English word, and a substring of words like trumpet) in the text to check for mentions of our future god-emperor, it's not surprising that it seems like he has so many more tweets than any of the other candidates.
Speaking of WSGI implementations, our enterprise environment is a bit of an odd-ball. It runs Python WSGI apps through Microsoft IIS, using the Fast-CGI module and the `wfastcgi.py` handler. When an application page is requested, an instance is launched and will remain open unless no requests are received for a few minutes, then it will terminate that instance, meaning the Python app is not running at all until it's spawned again by IIS when requested. Additional instances are launched by IIS when IIS determines it will be better for performance (2,000 requests per instance or something is the default). However, if two applications sit in separate app pools, they do not share instances. Those are the default behaviors anyhow. Settings could be changed to make it a persistent process and the number of instances and requests per instance can be limited/expanded per app pool.
I recommend anyone viewing this give [David Beazley's talk on concurrency](https://www.youtube.com/watch?v=MCs5OvhV9S4) a watch. In 45 minutes, he explains (and live-codes) how to leverage concurrency in Python and even move around common problems like the GIL.
pedantic and irrelevant. should I have said "most widely known memory-managed language?" 
I don't think pip-tools requires that either. To confirm this, I did mkdir test cd test mkvirtualenv ptt echo "django" &gt; requirement.in pip install pip-tools pip-compile requirement.in python -c 'import django' &gt; ImportError: No module named django
I was in the audience for that talk. It was legendary and extremely inspiring.
What....? Do you mean sneaker as in shoes? And.... What.....? 
It really is inspiring. That video encouraged me to go and get the Python Cookbook from the library, which was authored primarily by David Beazley. A lot of neat stuff in that book. I am also a fan of Raymond Hettinger's talks. When talking with my coworkers, I find myself putting my fist down on the table, prompting my coworkers to reply "There must be a better way!" as an introduction to my Python-crafted solutions.
thanks for this insight
I got sick of multiprocessing and the facade of simplifying concurrency when it is only making things more difficult. I just broke down and simply used `fork()` and IPC because they're well understood UNIX concurrency primitives despite everyone saying otherwise. I haven't played much with the Python 3 async stuff, but I've finally come to the realization that Python concurrency is crap.
1) No, though I suppose it depends on how you deploy it. 2) I don't know, but it's a good and valid question. You'll probably need to hack the request object as it seems that's the only meaningful object passed from module to module. 3) Good idea? Yes. Fall out of sync? No. You are most likely looking to squeeze performance out of a method or object that has a large startup cost and who's data is relatively static. If performance is your concern, you might want to consider another framework as django is pretty slow. Though, coming from a PHP background, performance is likely going to seem lightening fast anyway.
As and avid gamer, I am really glad that you've chosen a completely wrong approach :P
Cool projects, I'm going to try to fork your smurf checker and see if I can do the same for League if you don't mind.
Damn right I say.
Nice! That's good to know, thanks.
I agree. I think this is why Django and Flask are so appealing.
Well executed! I have a feeling that using an edit-distance algorithm (which you mentioned) would yield more reliable results - not sure about speed though. It's nice we live in such an age where using a ML method is more simple than coding the (already very simple) dynamic algorithm. You could try to generate your test words by randomly changing the existing keywords. What misses in this simple idea and what I'd like to see as an extension to this is perhaps some threshold of similarity (e.g. using some regression models) where you wouldn't suggest anything if the word typed is not close enough to any of the keywords. 
is there a prebuilt .bin for this? 
I hang out on #python IRC pretty frequently, and one of the most common questions is how to use multiprocessing. The docs are not good in this area (imo), and lack clear examples for some very common use cases. I think a couple simple decorators like this might make a huge difference.
Js for ui? God no... PySide works just as good as pyqt and license is good.
It's just two short scripts, which call some longer scripts, which call some very long scripts, which call some command line utilities, scrape some data, and move some files around. Nothing particularly groundbreaking or interesting. I have almost all of it on github. Here, for example, is the part that makes epubs: https://github.com/anqxyr/pyscp_ebooks/
Thanks, I saw it. which one is useful for you? and do you have your own tips?
/r/learnpython
&gt; does it pass this simple input. Simple pass fail, doesn't validate internal state. Not the way I do it. Is the answer the same; all 1000 answers, which are hopefully a summary of your results (e.g. the final weight in a weight optimization, the range in a trajectory optimization). If it's not, you diff the thing and find out why the answer changed. If you approve of the change, you commit the answer as the new "right" answer.
You could put jobs into a queue (rabbitmq/0mq/redis) and have an application server that just gets jobs from there and processes them. Unless the queue overflows, this can be a very reliable system. The system I worked on had 4 Tornado application servers that were simple HTTP API endpoints for a few thousand devices, these did some light processing on the data and shoved that into two rabbitmq servers. Then there were two heavy processors written in Python/C that did the bulk of the processing - they picked up the data from those two queue's, worked on it, and shoved it into a postgres cluster for storage. This setup handled fluctuations where the system would get hammered with 20x the amount of traffic during the day vs at night - I can't remember the numbers right now, but it was something along the lines of a 2-4 million requests/hour.
&gt; I want to write Python code that spits out the HTML and JavaScript required for these interfaces and I still want to handle all the logic in Python. Is it possible? Lets say I have a web app A and I host and serve it on my server. Instead now I want to ship the whole damn thing as a desktop app, which also includes the browser and runs my python app. Something like electron, but with python. Is that possible?
I really don't either. It's become really common in open source that there's some kind of indignation that you want to be reimbursed for your time. As if I'm supposed to feel bad that some megacorp is making tons of money off the time I spent working on something, and that I feel as though I should be reimbursed. It's seriously made me consider more heavily how I do licensing because companies just will NOT pay the people who make software they use in their products.
&gt; How multiprocessing figures this out I don't know but I can't imagine The code is open. I'm not going to trust a library where the author refuses understand the libraries they are using. The number will presumably come from the effective CPUs of the main process.
&gt; The build system dependencies will be stored in a file named pyproject.toml that is written in the TOML format Python package management is over complicated piece of crap, each one tackles only a fraction of problems. There I said it.
&gt; I’m sorry, but if you need an FAQ section for people to understand how they can legally license your product and still be able to have control over their work, then you’re still living in the 90s wat ? &gt; Given the openness of the community and the popularity of MIT licensed code, I just don’t consider this viable anymore. oh I understand now: he is one of those "give me your work for free, but I don't want to do the same" person
Check out remi
I would say now is the time to throw in more development to Kivy. It already has experimental SVG support, things like KivEnt have proven its possible to make the graphics pipeline much more efficient. We can rebuild things like D3 and the other nice parts of the JS ecosystem, and we can ensure they run on all platforms including mobile. What we need is more effort to build things like efficient data grid systems and such, not starting over from the ground up. I think it is telling that even facebook doesn't use JS for their mobile apps and goes native instead. 
Remi does the whole thing https://github.com/dddomodossola/remi
&gt; It's become really common in open source that there's some kind of indignation that you want to be reimbursed for your time. To be fair though, it's become equally as common to shout someone down as a corporate apologist just because they slap an MIT license on their work.
Thing is people expect it to be *gratis* while it is *libre*. They should realize PyQt is commercial software. My problem with their licensing is steep prices and requirement for yearly subscriptions. Big companies may have no problem with that but people who do not make much money from their software (if any at all) are left in cold water here. Oh well, there are other options.
&gt; Maybe you replied to the wrong comment? The quote was from TFA. I replied to the comment that looked like the author might get my point, and it might be at least tangentially related.
tkinter...its the future I tell ya :)
Cool, thank you for your courage in expressing this very controversial belief. More seriously: ok, it sucks. Got a suggestion for fixing it?
Thank you.
It doesn't really work to replace strings but it is very helpful in augmenting them. You see news sites put irrelevant stockfoto's in their articles for this very reason - without it, all articles would look like the same wall of text.
*Every* test couples to something. They have to in order to be able to test. The nature of unit tests (at least when they're testing small units) is just that they are coupled to more. &gt;Ones that test the interface - no matter what implementation I give to this test, I can expect the same answer. These are what J. B. calls "contract tests" and I find them to be the most valuable. These tests are only valuable if they're with the "outside" world (i.e. systems you do not control). Testing contracts between subsystems you control is usually a bad idea since as soon as you've wrapped them you have 'locked down' that interface and cannot refactor it without turning tests red. &gt;If a specific implementation has other public attributes or executes it's interface differently, I write specific tests for it. Think of a cache system. The implementations of redis vs memcache will vary wildly and I need to make sure they talk to their collaborators correctly. That's where unit tests fail miserably since you're testing against what you think the interface of that subsystem will be (e.g. redis or memcache) instead of what it *actually is*. Not only is it expensive to mock all of those external systems it's not even necessary. You can just run redis and test your code performs correctly against it. That gives you much more confidence that your code actually works.
I prefer this too. Doing this with end to end tests (ATDD) gives you a lot of freedom of movement when refactoring as well as confidence that you've delivered working code. The more incrementally you write the test and the code (e.g. change one step in the test, change 4 lines of code to make it pass), the faster I develop and the easier it is to stay in 'the zone'.
Apart from remi, is there a reason you wouldn't want to just distribute the server code and have it automatically serve to localhost and just open a browser to localhost at some port and path? I've seen plenty of projects handle it that way. That also gives them the option to serve the app and their data to anyone they want.
TOML? Are you joking me? What's is this crap? I mean seriously, let's compare PyPies: [TOML 0.7.0](https://pypi.python.org/pypi/toml/0.7.0) vs. [YAML 3.11](https://pypi.python.org/pypi/PyYAML) It even says here: &gt;TO DO: &gt; - Make sure the library keeps up with the spec as it evolves. And the rationale is just absurd. &gt;This format was chosen as it is human-usable (unlike JSON [7] ), it is flexible enough (unlike configparser [9] ), stems from a standard (also unlike configparser [9] ), and it is not overly complex (unlike YAML [8] ). JSON is human-readable. TOML is as much of a standard as a language someone made up yesterday and created a github page for it. And what's it about YAML? "Oh, I don't want to use JSON because it's too simple and not human readable enough, but I don't want to use YAML because it's too complex and too human readable." If anything, the build system dependencies should be stored in a project.py file which is a python module that just does `requirements = [a, b, c, d...]` or something.
Real users are happy with command-line options. And if that don't work, command-line shell. And if for some reason neither of those perfect things are enough, ncurses is as far as any UI needs to go. If it can't be represented in ASCII it is an impure art form.
There's a lot of megacorps that have blanket restrictions on licenses (e.g. no GPL). It can probably be frustrating for developers who work for these companies not being able to use great GPL software. Those developers are likely not raking in megabucks either. I really wish there was a way to easily charge license-sensitive corporations for separate corporate licenses on OSS (while keeping it libre). Why github hasn't leapt on this as a way of making money is a mystery to me.
Totally agree with all points made. 1) I was thinking exactly that, about the complexity of coding an ML algorithm, and that's why I did that. You can tackle so many problems that previously needed specific domain knowledge by just having a good feel about how ML works that is impressive. I actually forced my self to not look up any implementation or algorithm for word similarity and just try to implement a solution in a matter of hours with only my intuition. 2) Benchmarking against an existing solution after I have a created a good set of test cases may be my next afternoon project:P 3) I was thinking that this approach is missing only the incorporation of a threshold, just like when for example git is not suggesting anything because what you wrote is too far away from anything. But now you gave me a hand on that too. 
&gt; Cheeseshop, Pypi, setuptools, distutils, PIP, wheels, they should all be merged under one name, then iterated and improved. They are. Cheeseshop and PyPI are the same thing, so that's one down. setuptools and distutils have also merged, so that's another. So here's what we have: 1. The package index: PyPI. 2. The package management framework: setuptools. 3. The command line tool: pip. 4. Package formats: tarballs, wheels. Is that a lot of concepts? Sure, definitely. But the problem isn't much better in other languages. For example, consider Node.js (Golang doesn't really "do" package management so let's ignore it for now): 1. The package index: NPM (the website). 2. The package management framework: npm (the tool). 3. The command line tool: npm (the tool). 4. Package formats: tarballs. Does this have fewer concepts? Yes, slightly: the package management framework and the CLI tool are the same. That's somewhat helpful, although you still need to learn how to write a `package.json` (analogous to `setup.py`, which is the only place most developers ever touch setuptools). Additionally, Node.js is missing some things that are arguably pretty important. Let's consider wheels for a moment. Wheels exist as an alternative distribution method because the tarball distribution method doesn't allow you to distribute compiled binaries for a target platform. Wheels allow you to do just that, and support is plugged right the way through the ecosystem: PyPI knows about wheels, setuptools knows about wheels (via the wheel extension), pip knows about wheels. On the other hand, in the npm ecosystem nothing knows about binary packages: there is no formal npm support for binary packages. Python packaging *is* complex, no question. But it's also a bit misleading to pretend that there are multiple standards here. There is only one, and it *is* iterated on and improved. Wheels represent an iteration and improvement. So does pip. This proposal here is *also* an iteration and improvement: it's a further step away from the dynamism of setup.py and moving towards the staticness of wheels. The core problem here is that, at each stage of improvement, the PyPA have wanted to avoid breaking things that already work. That leads to this kind of problem: things need to be attached to the side rather than changing what already exists. Node.js, had fewer of these problems. IMO the best language package manager around is Rust's Cargo, and that has had the advantage of learning all the lessons that Python had to learn the hard way.
I like TOML - it feels like a more flexible and standardised version of INI config, and it's pretty simple. I expect a declarative data format to be a lot simpler than a programming language, so comparing YAML to Python isn't very useful. I also dislike YAML because the main Python implementation includes an extension module, which makes it harder to install. It has a pure Python fallback, but that means you have two parallel codepaths plus extra code to switch between them. Also, if you load YAML the obvious way, it can execute arbitrary code on your computer! Remember, if you're using pyyaml, always call `safe_load` instead of `load`.
Thanks for the long reply There are few things missing though, in practice, we have to deal with others like * anaconda/miniconda * venv (isolate package versions) * pyenv (isolate Python versions) * `(name for name in permutations(all_names_above, 2))` * buildout (this fucker even inserts shit ton of `sys.path`) * pbr You can say it's not packaging, but it's the shit end-users have to face in their daily development life. Like said, PyPA tried very hard, things got better and I really appreciate all these, but packaging for Python is still an over-complicated yet unsolved problem. 
&gt; It's much harder to improve things without breaking things for all of the packages and workflows that are already out there. Since Py3k is such breaking change, I hope it at least points a direction to a better designed packaging mechanism.
I'm not sure that /u/snuxoll meant **PyGTK**. PyGTK is actually deprecated, **PyGI + GTK** is the way recommended by PyGTK authors.
Django with Django Rest Framework will enable you to use models and DRF's serializers and generic views, which are great for creating simple to moderately simple APIs. While using pure API as a backend, I would rather do the rendering in JavaScript (so that web app is just another independent client, just like mobile app). There are several quite convenient tools for that - unless you need to support no-js or very, very old environment (like ie6) - take a look at React + redux or Angular. There are ways to have server side renderin in Django as well - you can have model/manager methods doing business logic in Django and wrap them in DRF's views and native Django views,
The first one first sorts the list, then reverses it, thus requiring two passes over the list; the second one does both in one step by simply inverting the swap condition for the sorting (i.e., it uses `a &lt; b` instead of `a &gt; b`). See: [Documentation for `sorted`](https://docs.python.org/3/library/functions.html?highlight=sorted#sorted).
Python 3 does not really change packaging much. Python 3.0 was released in 2008, before most of the pieces that are now improving packaging. pip was in its infancy. For Python 3.4, they tried to put a new `packaging` module into the standard library, but eventually decided those things would be better developed outside of the standard library.
We are developing and testing different things. I think it would productive to create new concrete terminology to describe what we are doing and the phases of development we are in. Our enemy are those who don't test at all. The majority of my dev is doing PoCs, figuring out problems, proving it can work and getting demos out there. In these cases, any effort I put into proving my design is largely wasted and slows down development. `source | transformation | sink` I test end to end, it takes seconds, it is run continuously and tells me exactly when things break but not what. The what is the code I just changed. Commit often, use `git bisect`. When code turns difficult, absolutely needs to be correct or is part of an external interface, unit tests are critical. As the OP asked for the critical 5%, unit tests are not it. A single test that verifies the main path is functioning is that 5%, everything else is refinement.
Strange that the PEP does not mention [setup.cfg](http://alexis.notmyidea.org/distutils2/setupcfg.html) from disturils2 or [pep-0345](https://www.python.org/dev/peps/pep-0345/). Wasn't that the exact same thing for the exact same reason?
In my experience, GTK works well on Linux, but on Windows it's inconvenient to distribute and the applications don't look great.
Side note: if anyone makes a convenient Python interface around Electron, it should clearly be called Positron. ;-)
Doesn't PySide also use QT? So wouldn't it come with same license restrictions as PyQT?
Thank got this did not introduce path literals (`p"/some/path"`). I was afraid for a second.
Please show. If not the repo, at least some screenshots.
This is awesome! 
You beat me to it! Read the article and thought... I know what this guy needs haha. I've not used it extensively yet but it's pretty good so far!
multiple_instance=True 
Oo, that's great. Thanks.
Ok, if we want to be pedantic, I disagree that unit tests are *tight* coupling in general. I *want* to see tests go red when I change the code they're testing. If they don't and I expected them to, then those tests are probably garbage anyways. And how is it not valuable to ensure that an instance of Foo and an instance of Bar interact properly regardless of who wrote them? That's the entire point of a test in the first place. Unless you're defining a unit test as "only tests this one little method in a complete vacuum" which are hardly useful tests in the grand scheme. Finally, okay, the cache example was a bad one because cache implementations generally rely on out of process stuff. Here's a different one. I have a generic bank account class and then three more specific ones that talk to different collaborators. I'll have a suite for the common elements, and then more specific suites for SavingsAccount, CheckingAccount and InterestBearingCheckingAccount since I need to be sure *these* specific types of accounts behave correctly and talk to their partners the correct way. 
Yeah... but it's basically formalising .ini file format and looks quite handy. 
Yeah i took your advice in the end, i swear i couldnt get any of them to work, just using sqlite now and damn it feels good to actually begin working. 
If you write your own custom build system, I guess using pyyaml correctly is the least of your worries. The part that most people are going to write is the build config file, not the code that builds the package... It makes sense to have the file as accessible as possible, even if it makes the parsing a bit more complicated.
Huh, TIL. https://wiki.gnome.org/action/show/Projects/PyGObject/IntrospectionPorting?action=show&amp;redirect=PyGObject%2FIntrospectionPorting
&gt; What’s the drawback? It’s great for games and smaller applications, but I find it harder to use for business apps that need to represent a lot of data, like complex tables. There are people developing line of business software for native GUIs instead of the web? I'm actually a little surprised. *Even if* you think that development of business software on the desktop is easier (something I'm deeply skeptical of), what business team is going to say, *yes, let's go with a native desktop app instead of a web app. We're betting big on desktop computing this year.* Heck, unless it's a single-user application (because those are a *great idea* for business software), what does he even do about data synchronization between users? Is it native desktop apps syncing with a SQL database? Is there an application server? If your attitude is that business data is best served with native widgets and executed locally, why not just go full 1990s and write a Delphi app? EDIT: Sorry if I'm coming across a little negative. I really am just surprised to learn people are writing what sounds like line-of-business (CRUD-like) software for the *desktop*. I recommend against it.
Mine can't even keep their rooms clean
+1. People want everything for free, and not do any work. Well... no.
Yes, this is what I thought of. Although I never used it, this architecture makes it really easy for the programmer, with all the logic server-side. However, it feels slow when basic things like validation of form fields requires a server round-trip (especially with 2002-era web browsers and connections). Also, it was not great at handling multiple tabs in the same session. And of course, intranets can handle a generic-looking UI, but most websites want something with more control -- meaning you still need a templating system, even if there is an option not to write HTML yourself. Definitely something that can be learned from if it is going to be reimplemented in Python.
While I share doubts with you, TOML is interesting because: - it worked for the rust community; - it seems .ini compatible; - it's easy to get right and to read. JSON and YAML have so many pitfalls. Big JSON are hard to read, and I always get a parsing error because I forget a trailling coma or use the wrong quotes. Then you have to agree on a date format. Don't get me started on YAML, I always get parsing errors no matter what I do with it. JSON and YAML are not bad, but I know I wished more than once that they were a better format for configuration, and I'm ready to give TOML a chance.
I had very inconsistent behaviour with it on Windows...
Yup! Today I found yet another reason to invest time in tests: I had a very foggy brain and needed to refactor a small piece of code out in a separate method and create a few new variables to make it work nicely... Wasn't focused enough to do it right, but of course the test suite (well, and flymake) handled my fogginess by failing until I got it right just out of insistence. I got a coffee after that.
Thanks for this! I like the bullet point approach. Its effective and straight to the point.
I'm looking for some pro tips on setting up a production server. My team has enough skill to prototype an Internet of Things hardware, and app, and a twisted web server but we've never been responsible for some thing that has to have 99.99% uptime.
Yes. I'm looking at twisted because its so adaptable. We have an IoT product so we will always want to be revising our protocols / changing stuff. I'd like a server that can be adaptable without alot of work.
pathlib is one of my favourite additions (elegant plus less cross platform breakage). Great to see it becoming easier to use in the standard library - less `str(path)`
Nope, not targeting the same space as pyjs. It's not meant to be a responsive web ui framework. It is not really meant for hosted web apps. Think more from the desktop side and less from the web side
My local high-school posts a list of cancelled classes to some crappy web-page every morning. Unlucky for me, they always posted them when I was already on my way to school, so I had to get there, realise my class was cancelled and head back home on my bike again. Once I got fed up enough with that, I used Beautiful Soup to parse the schools webppage every half-minute and, when a class I had to take was cancelled, would let it send me a text-message through a 3G-USB-Dongle and some command line magic. Worked extremely well (Spared me half the way to school plus the entire way back more often than not) and got me into Python and automation in the first place.
 import requests try: r = requests.head("http://exmaple.com") print(r.status_code) except requests.ConnectionError: print("HTTPS failed")
&gt; If you see inside the gui.py source file, you can notice how simple it is building new widgets. No, it's not: if self.layout_orientation == Widget.LAYOUT_HORIZONTAL: if 'float' in self.children[key].style.keys(): if not (self.children[key].style['float'] == 'none'): self.children[key].style['float'] = 'left' else: self.children[key].style['float'] = 'left' This is not how Bootstrap, UIKit, or Foundation float elements, ever. So, no, you're not adding new widgets based on web standards. How would you go about building, say, the [Bootstrap Components](http://getbootstrap.com/components/) demo using this? &gt; The integrated webserver/websocket server has a lot of advantages, first of all the installation simplicity (zero dependencies). Except that in the real world, everyone uses WSGI for everything. And *that* is truly zero dependencies. Compare setting this up on Docker, AWS Elastic Beanstalk, or Heroku.
I even opened a ticket which was closed as non reproducible. Basically randomly at startup i was getting a race condition in internals of kivy.
Certainly not, but the OP is discussing datatables and business software, displaying complex business data, etc. If that's what you're doing, you really have no business using anything except the web.
Django, Flask, etc. If you're averse to doing too much web hassle, I recommend UIKit+CoffeeScript. CoffeeScript makes JavaScript readable, and UIkit gives you responsive design and useful widgets (date picker, etc).
Is this known by the Python core developers? They love squashing these bugs. P.S. This isn't in the core library, but you can segfault Python all day by using some of the stuff in Scipy. Those methods are basically wrappers around c and fortran libraries and the error handling in the native portions leaves something to be desired. 
So.. lots of complaining and no solutions. Great read. /s
Googling for "report python bug" gives https://docs.python.org/3.5/bugs.html . I hope it helps.
Alright, fair enough.
Have you done any apps with Kivy that have graphs and charts? The GUIs we build almost always have matplotlib embedded with lots of curves plotted. This is our #1 needed feature, so when switching GUI toolkits we have to know that we can make pretty graphs. It doesn't have to be matplotlib (although it's preferred since there are libraries like seaborn that build on top of it), just something that can make some colorful squiggles on the screen.
this doesn't actually count, but just for fun (linux only though) __import__('subprocess').call(['pkill','-11','python'])
This is how Javascript's string templates work and I like them. But I would rather we all do things the same way in Python, so yeah, not a big fan of this addition.
What's Wayland? There seem to be no hints or clues
You can either save $2000 or $3000 from burning. Sure $2000 is *enough*, but there's no difference between grabbing $2000 or $3000 so don't be stupid. It's not a "trend", Python 3 is a newer version with less issues and more features. Python 3 is the future and you're designing your game to be played on PlayStation 2.
It's the successor to X, the window manager. It's on the verge of becoming default on Desktop environments like Gnome. 
I've been using nsiswrapper from the Fedora project to build installers for my Vala/GTK apps - not too bad to package up GTK executables on Windows and for the most part Windows users don't even know what "native" looks like because of the shitshow that Windows UI's.
I tried updating with pip install praw -U But nothing changed, still getting the same error. And thanks for the heads up about spoofing, wasn't trying to, just found some code that looked like that already.
This is not something that will change. Kivy's goal is to enable the programmer to produce a single application that behaves and looks the same across all platforms. There are other projects if a native UI look is your desire. This is a "con" shared by any browser based gui technology of course. Who only uses apps with the native OS look anyway? However, it is possible to use [plyer](http://plyer.readthedocs.io/en/latest/) in order to bring up native file choosers and other such widgets where I think it is actually important for the user to get a "native" looking interface. 
So, we're lobbing a bunch of flimsy complaints at selected existing GUI solutions, then setting off to storm the castle with a new solution that sounds like it'll be of the "lets make a web app, auto-generate all the icky front-end code, and bundle it with a browser widget to make it seem local" variety. Because who wouldn't want to deal with that loveliness when the unbearable alternative is *reading a licensing FAQ*?
You could use the Pyobjus tool to interact with the objective-C API for the OSX menu bar and do whatever you want with it. Kivy does not stop the top of the screen menu bar in OSX from appearing or you from using it with its API. In fact, and this is true of every major OS, between Pyjnius, Pyobjus, and Cython, Kivy provides you with the tools to interact with any native api on any platform whether its Java, Objective-C, C, or C++. The only area we don't have is C# for .net, but theres usually a C way to do those things I think.
:-D remi allows and don't constraints to use hardcoded sizes
Yes.
[removed]
setup.cfg could include this - though I don't think it actually does as described in your link - but it's trying to entirely replace `setup.py`, which is a much more ambitious goal. PEP 345 specifies fields for package metadata, but the PKG-INFO file is normally something that's written by build tools as part of distribution, not something written by humans for build tools.
Do you have a widget gallery?
Psst...read from memory...
It works, as long as you don’t mind working with the ageing Qt 4.
&gt;I think you underestimate the prevalence of Java in the entreprise software world. It's quite literally the HPV of Enterprise IT.
could you please share the script? would be awesome to see how this works, want to see if this is possible with spotify
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
What is the most complex example of what it can handle? 
Yes, unfair of me to judge your comment without context of OP, my apologies. I agree that most line-of-business apps SHOULD be written as web applications. At the very least it removes the need to distribute the software and reduces support overhead. 
With the "stable" branch, a single source file with includes. The "master" branch has new work that generalizes the system to any method of extension (c++ with pybind11, c++ with boost::python, C with direct CPython calls), and allows substantial customization of the build. I'm using this in a couple other projects, so what I need for those projects is driving which features to implement. Let me know if you have suggestions.
Well, Qt already has such an abstraction (and similar abstractions for tables and trees and context menus). Why should I switch to Kivy?
If you can do what you want in Qt, you should not. However, for people who want a framework built from the ground up to handle alternative inputs such as multitouch, object recognition, motion tracking, the flexibility to write efficient GL rendering code, and a forward thinking provider structure that doesn't just limit you to the functionality that can be effectively abstracted across all platforms, but also gives you the ability to make use of platform specific features, Kivy is your best choice by far. Kivy has a far better handling of inputs for widgets, and a far better handling of resolution independence then even CSS + HTML, in part because it is much newer than all those other technologies and has been able to benefit from hindsight.
&lt;3 Python
I know you /s'd it and all, but really the guy described where current solutions are lacking, proposed a framework for implementing something better, and then pledged to start working on it himself. Short of having completed it, what more do you want?
It still needlessly has characters like = ["", "", ""] which are not standard on all keyboard layouts out there and especially Python IDEs should have good support for auto-indenting with spaces anyways. Also, why explicitly mark strings with "" and have them in a comma separated list when you can just write them on different lines? Makes diffs cleaner and the vertical layout gives a better overview too. Imagine a list with 1 dozen packages or more... Edit: Also (I'm not 100% sure about that one) YAML seems to have a canonical format while this TOML stuff could probably be written in various different ways. Do we really need another formatting war again?
Qt4 does the job well. Qt5 pyside is in the works too.
Better tell me what does not work. I know just one minor case of QApplication.winEvent not being wrapped for which I had to patch and rebuild pyside. Other than that it has been great for me.
Tk?
What doesn't work? Try: a recent version of Qt like Qt5. PySide simply isn't at the same level of maturity as PyQt. 
As a Mac user, I greatly prefer native OS widgets and style. UI cohesiveness is a major plus of the ecosystem, and these dumb JavaScript app's stick out like a sore thumb...while being clunky compared to app's made with native widgets. Spotify is a bad case of this: the old native application was much more reliable to use than the present JavaScript one. Simple things like reordering playlists worked smoothly and like any other application. Now it's slow and awkward.
Very similar. I didn't like the "f string" idea when I first heard about it, but after using template strings in Javascript, I have realized how nice they can be.
I agree, but you eventually learn how to scan licenses to determine whether or not you can use the software. I'm not sure how I feel about being good at this.
The biggest licensing issue with PyQt doesn't come from Qt. PyQt itself has separate license terms from Qt because it is made by a third party, and those terms are more restrictive than the terms on the main Qt libraries and tools.
Have you thought of using something like Hypothesis (http://hypothesis.works/) to make sure your transforms can handle bad data?
I did not know Tryton. Anyone has experience using this in a small company ? How hard was it to install it / teach people how to use it ? I see it supports accounting. Is it aware of accounting standard such as IFRS or US GAAP ? Is there a location where I could find more about the security in Tryton ?
I for one welcome our new fspath overlords. But kidding aside this pep solves a real annoyance when using pathlib with existing "legacy" code.
[The Manual](https://docs.python.org/3/tutorial/index.html) /u/jgardner is referring to.
[Source](https://github.com/ryukinix/decorating)
Hammers are garbage!
1. Write the pseudocode into text editor of your choice. 2. Save the file with the ".py" extension Congratulations, you just wrote Python script!!!
Except matplotlib also has interactive elements, and when I'm plotting something like 150-200 curves of 2000+ points each across 8-16 axes on multiple panels I need somewhat decent speed too. Redrawing the enter image on every update is needlessly expensive. Trust me, I've gone that route before and it doesn't work. I need more than "show an image".
Could someone use this to make an Imagemagick binding that's better than using c-types?
[It might happen soon.](https://groups.google.com/d/msg/pyside-dev/pqwzngAGLWE/kXUpXBhILAAJ)
Yes matplotlib is CPU based, but switching to a model where it has to redraw the entire figure instead of just an axes, then send that image to kivy or some other gui toolkit to be drawn would be far, far slower. Right now in order to get matplotlib fast enough for us we only redraw the artists that need redrawing. I'm pretty sure that matplotlib can't do this when generating static images, which again is not something that would work well since we also need the plots to be interactive. I understand that matplotlib is by nature inefficient, but what you're proposing would be at least an order of magnitude slower than my current code. I know, because when I first wrote the software it was redrawing the entire `FigureCanvas` on each update and it was so slow that the software was unusable. I don't need super-ultra-realtime graphs, I just need graphs fast enough to keep the whole GUI from locking up.
It's indexing your codebase so you can search through it easily. (double-tap shift, cmd-O, these commands use the search index). I think it also indexes 3rd party libs?
And tail recursion optimization is pretty easy in Python if you need to do it. # Function that returns tuple of [method], [call value] def find_zero_tail(num): if num == 0: return None, num return find_zero_tail, num - 1 # Iterative recurser def tail_optimize(method, val): while method: method, val = method(val) return val tail_optimize(find_zero_tail, 1000000)
or ```python2.7``` and ```python3.4```
You can use the new Pillow fork which is also 10 times faster than Imagemagick afaik.
Doesn't work for me for some reason..Despite that being in my environment variables.
Not in a website yet, but the kitchen_sink.py in the repo is a demonstration of all currently functioning widgets.
I think this can get you started http://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=python3&amp;lang2=gpp This is so cool, think of Python as the car and C++ as the engine.
Mind taking a screenshot?
Yea but unless you write them down and really study them you're not going to remember them. Learning an IDE is really hard. It requires a lot of time. Most people gradually pick it up over the course of YEARS. Honestly if I could go back in time to when I first started using Jetbrains products I would take a week and read the whole damn manual.
Imagemagick in some cases is faster to resize than PIL, and Imagemagick has seam-carving built in.
The creator of the project mentioned that c-types is pretty annoying to use wrapping imagemagick since its basically a C++ codebase. 
Create a py.ini in your \Windows directory. Inside it put: [defaults] python=3 This way when you write py &lt;myscript.py&gt; it will be executed with Python 3, while if you use py -2 &lt;myscript.py&gt; it will run with Python 2. pip install will run using the first pip.exe it finds in your Windows PATH variable, so if you want pip install &lt;some_package&gt; to work with Python 3 be sure to have \Python3\Scripts directory before Python2\Scripts directory. That way pip install &lt;some_package&gt; installs it for Python 3 while if you want to install it with Python2 you can use pip2 install. pip3 install of course works as expected. 
Their acceptance of bytes for some but not all applications of `__fspath__` will bite them in the ass. Namely anything that uses Path and PurePath will surprise developers with a wonderfully random exception.
So possibly ignorant question. Isn't this what Boost Python does?
Note: the examples that have external dependencies have been removed from the neat-python repository and package, but they will shortly reappear as a separate package. *Edit*: The examples are now located [here](https://github.com/CodeReclaimers/neat-python-examples). 
Yes I did. I'll blame that on the mobile app I'm using :)
Oh, this can actually compete with `Rcpp::sourceCpp` call. Good, I was missing it in Python.
Maybe it checks for a compiled version already and checks modification times to know if it needs to recompile. If it doesn't, it certainly should, imo. 
Ya I don't see how this is significantly better than just having a make file to do all the things for you. I'm using swigg and C functions and when I edited the c file I just have a make file that compiles everything it needs to, and then adds the new object to the correct folder and the python module as well
It does -- actually it compares checksum of file contents. But, that's not really a big advantage since almost any build system worth its salt should do something to allow partial rebuilds.
Okay, but a properly designed build setup should also be able to do that.
Yeah. Up-arrowing to make is what I've done for years. I think there are a few ways in which this is easier: 1) I often forget to recompile before running the python and then stare at the screen for 30 seconds thinking, "Huh... why didn't that edit fix my problem? Oh, dur, I didn't recompile." This kind of thing can throw me off. 2) I like having the build info in the same file as the code (this is something that's not apparent with cppimport unless you look at the master branch where I'm working on new stuff). This is personal preference. 3) Finally, it's just easier to have one command to run than two.
Another similar idea is "pyximport" for Cython.
I think you would still need to inform the linker about fileA.so when linking fileB.so. 
Interesting choice to use TOML. Is a TOML parser coming to the standard library? Otherwise it would seem like a bad idea to make standard configuration files that can't be parsed using the standard library. It also seems like the simplicity of the file (in general) makes using an uncommon format a little less justified. I'm not really against TOML. It seems to be a well designed format and would certainly be a good replacement for .ini files. I just feel it might not be a good idea to use it for such simple configuration files while it is still largely unused.
The biggest practical problem with yaml is there is no simple library that implements it.
Pick a project. Start solving it with Python. No better way to learn than practice.
It depends on your threat profile. If you're concerned that an active attacker is trying to switch files on you, the md5 for file integrity is indeed dead. If you're just using it as a checksum, then sure it is fine. But crc32 works too and is faster.
This website is a gem if you already know programming. Learn X in Y minutes, where X=python https://learnxinyminutes.com/docs/python/ 
You can still certainly pull that off. Simple flask app: #!/usr/bin/env python import webbrowser from flask import Flask app = Flask('testserver') @app.route('/') def index(): return 'testserver' webbrowser.open('http://localhost:8888') app.run(port='8888') I created a launcher on my Desktop ("launch server.desktop"): #!/usr/bin/env xdg-open [Desktop Entry] Version=1.0 Type=Application Terminal=false Icon[en_US]=python Name[en_US]=launch testserver Exec=python /home/d4rch0n/testserver.py Name=launch testserver Icon=python When I click it, it launches it without me seeing any terminal windows and the browser opens, and I see "testserver". For installation, assuming they have python you can just script something real quick that checks whether the dependencies are installed and installs them if not, then launches it. If no python, a bash shell script would work, but that starts getting annoying. But Linux and Mac are going to have python. You'd just need to run get-pip.py for them first otherwise on a fresh system. I mean, it does get a little complex and it's certainly not portable to windows, but it's definitely one possible way to do things. It's not terrible to have the dependency of them having python and pip preinstalled, and if those are, the rest is easy. But if you end up handling installing python, then pip, then the packages... you should probably be writing an actual framework to be handling this rather than the application itself.
I agree, although 'terrible' might be an unfair descriptor. Kivy is funny in that it's the most powerful current Python GUI, and yet possibly the most annoying. It definitely lacks in cohesiveness, documentation, and intuition. But for now it's the best we have...
wot?
Thanks, it seems to make sense!
I'd say Cython is much more convenient for realistic use-cases, even without pyximport (compiling stuff in setup.py is the usual way to go). 
Kivy is a good first-start to cover the most platforms with least work. The moment you think it is worth having a **faster** native-looking version of your app for a particular platform, you use the Kivy version as the prototype and build the native app, possibly not even in Python. Basically, treat native version as an optimization (which, clearly, shouldn't be premature).
&gt; was trying to get wand to do the same, but I can't figure out what method to use. What's "wand"? Have you read the documentation? Do they have a mailing list or user group you can ask for help? If you [google for "wand resize"](https://duckduckgo.com/html/?q=wand+resize) the very first link that comes up is documentation for resizing and cropping. Suggest you start there.
... and iOS support is Qt5.
&gt; Can someone explain what it was doing please? Wasting your time and contributing to global warming. *wink* (Not a big fan of "proper IDEs".)
Eli5 plz
You sound a bit condescending.
I had a couple helpers for doing almost that for a while already, but in practice I pretty much never use them. At most I do `some_tpl % locals()` with doing all the computations (e.g. `idx_one = idx + 1`) explicitly beforehand.
Is this benchmark using Imagemagick with libjpeg-turbo? That's the branch that supports the SIMD instruction set.
Python can already zip large files without loading them entirely into memory, but they have to be regular filesystem files. The [SO question](http://stackoverflow.com/questions/26849328/how-to-zip-a-very-large-file-in-python) prompting this deals with retrieving files from some cloud service, I think, and writing them directly to a zip file. Python 3.6 will make this possible, by allowing you to `zf.open('...', mode='w')` to get a writable file-like handle inside the zip file.
We have installed it in companies from 3 to 10 people without difficulties. About learning it, Tryton tries to apply and re-use similar concept all over the modules. So once those principal concepts are known it is quite easy. About accounting, Tryton has a generic design that should be able to support any standard but of course it requires parametrization and it could be missing some automation features. But as it is highly modular, the missing features can be implemented in a module. About the security, there are 4 levels of access rights: http://doc.tryton.org/4.0/trytond/doc/topics/access_rights.html By default Tryton comes with common predefined groups and access, but they can be customized for your needs. About authentication security, Tryton stored hashed and salted password using bcrypt (or sha1 if bcrypt is not available). There is a exponential delay on wrong attempt to prevent brute force attack. On the next release (4.2), there will be possibilities to add 2FA with for example SMS: https://bugs.tryton.org/issue5530
&gt; You can use bspwm (and I believe i3) with KDE and XFCE What you meant wasn't clear, admittedly.
Next time, check out something like Aciinema
I like it, I tend to use tqdm a lot, but that only works well for things that can be treated as a series of repetitive operations, this would be nice for single slow things that may be external for instance.
Not similar. `pyximport` requires you to write in Cython, not C++. I already had several use cases where this difference actually matters.
&gt; And you should get a RecursionError or maybe a MemoryError. You can't do that *and* rely on the C stack, the info just isn't there. You overflow the C stack[0], you start accessing unmapped (or guard) pages and you segfault. The only "fix" is to stop using the C stack and start using your own custom heap-allocated stack, except now you can't trivially call into C anymore[1] because you don't have a C stack, and the overhead of C calls blows up tremendously[2], which is pretty obviously a terrible idea when your interpreter is in platform-standard C. [0] whose size is system-dependent [1] more precisely "platform-native calling conventions C" [2] that's exactly the issue of cgo and why calling a C function is ~100 times more expensive than calling a Go function if you aren't using gccgo
I need to get into the habit of virtualenv...getting a bit bogged down in packages, especially with learning Django. To be honest, specifying py -2, py -3 and pip3 is working for the moment, so gonna leave it at that.
It's a good way to compartmentalize projects for sure. 
You could still use all the low level tools. Open will still accept a bytes object for a filename. The fact is you have to do lots of sanity checking to your path inputs anyways. You have to verify that the files they reference exist and that the process had permissions at that location. Adding one more requirement that the path be "good" adds a little bit of overhead to that process while preventing errors from being introduced layer on. To me it is just basic fail fast design.
Cool, are the slides available somewhere ?
This looks like it would be great for benchmarking pypy vs python, by asciifying some images many times.
This is sick, I like it. Wouldn't use it anywhere, but it is cool Definitely add a README.md with some examples, and possibly a note not to use in real life.
Maybe - it didn't sound like that to me though. And that wouldn't make sense in a huge company.
Ditto. I'm a QAE/SDET and work almost entirely with Python, so I'm in PyCharm for 40+ hours a week for the last 2 years. I'm still finding things on a weekly basis I had no clue existed.
A CRC32 has wayyyyyyyyyyyyyyyyyyy more collisions than md5 lol. Dunno what you're talking about. 32 bits compared to 128. md5 is way more expensive to calculate.
I did confirm from the Qt rep I spoke to that we can use it for free for internal products, but our actual software team is relatively new, having recently split out from another engineering group. We're still mainly supporting existing projects but our new development is more geared towards external use. Eventually (within the next year or two) we want to sell our software externally since our customers have expressed interest in our internal tools. Until we know more we aren't making any decisions that would require us to spend a lot of money on licenses just to be able to sell the product.
I think that maybe a bug, I would contact the mods. Alt. you could use the reddit enhancement suite and downvote by pressing the "z" button to downvote instead of using the mouse-over
 f'Well {this} is currently the {feature} that I am most looking forward to in {3.6.0}?'
You sure they didn't mean Conway's Game of Life? Very different and probably much easier to program than a clone of the actual "Game of Life" board game.
What about PySide and [PyQtGraph](http://www.pyqtgraph.org/)? That was awesome for me. And it finally works with Python 3, too.
Thanks man, that was a valuable suggestion. The time taken to read all filenames recursively got reduced drastically. I have updated my post as well :)
PySide is licensed so that we can't use it commercially, and PyQtGraph is based on either PySide or PyQt, so same problems there. If it's Qt based technology we have to pay for it, and paying for it is currently a problem for my group. I'm not against using those, particularly for the Python 3 support (I'm still stuck on 2.7 until we can get wx working reliably on &gt;=3.4), we just can't make the licensing work right now. It's really unfortunate because Qt is a very high quality product, it's fast, cross platform, good looking, well supported, and feature rich; that understandably comes with a price tag.
What Python interpreter is Pycharm configured to use? What Python interpreter are you using when you run the code outside of Pycharm? It sounds like you have multiple interpreters installed, in which case the solution is to not do that. (Or else install the necessary modules under both interpreters.) 
"dead" is a bit of an exaggeration, but with papers like [this](https://www.iacr.org/archive/eurocrypt2009/54790136/54790136.pdf), I wouldn't bet a lot on it holding for a lot longer.
Yes, provided that your system's pip is found before anaconda's. The command which pip will tell you which pip is found.
Yes, the (taking the link from wikipedia I guess?) paper showing a 5 bits from brute force method for pre-image, when I specifically mentioned **2nd** pre-image is what you need to find. Call me when I need to be worried.
&gt; more potions for type hinting (AnyStr, Type[C]...). Like potions of polymorph? levitating? flying? 
Well, you still have to use Qt, which has its own licensing. PySide is LGPL versus PyQt's GPL. It allows you to bind to Qt with less restrictive licensing, but you still have to have a license for Qt itself. Qt comes in a commercial license or a GPL license. GPL is not an option for us (sadly), so our only option remaining is the commercial license. Last I checked the commercial license costs about $3k a year per developer for a subscription or about $5-6k for a lifetime license per developer with 1 year of updates and support.
Thanks hoss
&gt; Qt comes in a commercial license or a GPL license. Qt does not have a GPL license. According to [their site](https://doc.qt.io/qt-5/licensing.html), they also have an LGPL 2.1 or LGPL 3 license depending on your preference. Would that help?
When I spoke to the representative from Qt he said that for our external purposes we would need the commercial license but we were free to use the LGPL license internally all we want. Basically, the Qt company themselves told us directly that for what we wanted to do and the restrictions we would have to place in our code's license we need the commercial license because LGPL would potentially allow someone to reverse engineer parts of our applications. The company I work for doesn't want anyone reverse engineering any part of our applications. My hands are tied in this situation. I wish we could get the budget right now for licenses, maybe it'll happen next year, but not this time around =(
Glad to be of help!
Very good article. One thing to mention is that you can actually do this with just more than one VM to test it out on your local box. Very good though :)
I know tqdm, is really nice! As rad_badders said, I have some problems with operations whose is not 'predictable', not iterating something, only a request GET/POST (at example). The original ideia comes from here: [MAL](https://github.com/ryukinix/MAL)
Thanks for posting this, it helped :)
Exactly! This was my proposition when I write this. In something moment I was thinking very slowing the requests GET/POST of one [application](https://github.com/ryukinix/MAL) mine, so I write this. 
Made a pull request to allow setting the message on the decorator. Old one still works too. Why aren't you using context managers? It could allow you to be more versatile. You could decorate `wait_for_connection`, which would be the same every time, and also do something like: with decorating(message="moving to ({}, {})".format(x, y)): move_robot(x, y)
So, showing my ignorance about PP here, but why would you use PP over e.g. [IPython Parallel](http://ipyparallel.readthedocs.io/en/latest/)? I didn't poke around enough the PP website to see what it offers that's different to IPyparallel as they call it nowadays.
Now that you talk about usernames - perhaps you should take them as seed.
&gt; - type hints as comments (work on 2.7 and 3.6); That effectively makes the comment syntax the defacto version. Might as well find a new use for the original syntax. ...and they wonder why 2.7 won't die. 
http://stanford.edu/~cpiech/cs221/handouts/pythonTutorial.html 
Sorry for the late reply, didn't see your comment! As for why i'm using cygwin, I will be doing research starting this summer under one of my professors doing molecular modeling and simulations. He wants me to be familiar with Bash and Python. His lab uses Mac OS X so it uses UNIX shell. However, I am using windows OS at home in the meantime. So far, cygwin has been working great. 
PR accepted. My real mess up! Why i don't used this!? Seems so nice. I will try this in soon! Again, thanks for one more suggestion!
You could use subprocess.Popen functionality to spawn an independent process.
But I can pass only a `function` to subprocess?
You da real mvp. 
I think I cannot do that. When I search about this, (whose I tried), something said [that](http://stackoverflow.com/questions/2046603/is-it-possible-to-run-function-in-a-subprocess-without-threading-or-writing-a-se) about using multiprocessing! HAHHA Now someone is talking about use subprocess.Popen. Great! ping/pong question.
Return some value and check for that value. 
[StackOverflow Thread](http://stackoverflow.com/questions/37308905/how-i-can-run-a-function-in-parallel-and-after-the-main-program-exits-he-still-c?noredirect=1#comment62138965_37308905)
There's lots of great sites, you could make a repo on [GitHub](https://github.com/), create a [gist](https://gist.github.com/) or just a [ghostbin](https://ghostbin.com/).
Sorry, only just saw this... hope you've got it figured out now.
No, you provide the script and parameters in the *args*. Popen(['/bin/sh', '-c', args[0], args[1], ...])
No, it's not. The only way would be to manipulate the fun bytecode, which is a horrible idea. 
Well, [a good deal of Instagram is written in Python](http://instagram-engineering.tumblr.com/post/13649370142/what-powers-instagram-hundreds-of-instances), so it's very doable ;) But "Instagram-like" is a vague as it gets, what do you want to do? 
Users must be able to submit images into a common pool. Images must load into a 3 x 3 grid, on the main page or home screen. Loaded images must follow specific auto-assigned search filters.
&gt; return ERROR Bad. Learn to use try/catch/raise. &gt;if week &lt;= 1 and week &gt;= 0: So, if week is smaller than or equal to 1 AND if week is greater than or equal to 0? What are you trying to do here?
Ok I will build soon an example about this.
I'll be there giving a [talk](https://us.pycon.org/2016/schedule/presentation/2040/) about game development and python covering packaging and performance solutions we use in the Kivy and KivEnt communities. I hope to convince you it's time to move beyond pygame!
Yes... this I know, but I want just execute a simple function. That way, maybe I need separate the files and use this? (output &amp; notifications). Hmm, I really don't want do this, actually... but in the last case I maybe must do this. Someone (at StackOverFlow) points to me about `python-daemon` for this problem, appears be cool. Maybe I can solve my problem using this, whose is more pythonic.
Amazing! Thanks!
To execute a function, you can just use `python -c 'import foo; foo.bar()'`. I would also consider the double-`os.fork` followed by middle `os.exit` (to ensure reparenting) way though, but many runtimes are not really designed to deal with that (you have to ensure that there is only one thread, no open files except those you explicitly intend to pass, etc). Wrappers like `multiprocessing` and `subprocess` sometimes make life much easier, and sometimes just make life difficult.
On the mailing list, they talk about a 5% speed up on the benchmarks.
:)
Let's see: https://twitter.com/sam_et_max/status/733057067049725952
&gt;&gt; return ERROR &gt; &gt; Bad. Learn to use try/catch/raise. That makes sense :) Will do it asap :P &gt;&gt; if week &lt;= 1 and week &gt;= 0: &gt; &gt; So, if week is smaller than or equal to 1 AND if week is greater than or equal to 0? &gt; &gt; What are you trying to do here? Oops. That's actually a relic from an earlier version. I tried to say something like `-7 &lt;= week &gt;= 0`.
I'm also still quite new to programming, but have spent several weeks now languishing in some weird purgatory of online articles trying to evaluate my options for making web applications like you describe. **Advice** 1) Use a web framework: Django for features, Flask for minimalism. I've worked only with Django, but highly recommend it for you. While Django allows for direct manipulation of the database, it also allows you to manage your database through "migrations" of "model" data. Models are basically just special python classes, and performing a migration is as simple as two one-line statements. Two other main features of Django are html templating and an extensible REST framework (Django Rest Framework). The template engine basically lets you render pythonic data using special variable syntax embedded within HTML templates. The REST framework seems really cool, but hold off on it for now. It will be useful for making your program work with alternative front ends (such as mobile apps, 3rd party programs, and javascript front-ends like AngularJS). The design of a totally decoupled front-end is super appealing, but I found it all to be too much to swallow while still learning so many basics of python and Django. Since a javascript frontend like AngularJS would largely bypass many other core features of Django, such as the URL routing system, you would deprive yourself of a lot of useful experience by jumping into this particular domain too early. Also, recommended database for Django is PostgreSQL. Just use it so as not to be a contrarian. 2) Use a CSS library - https://github.com/edvm/django-materialize-cssmaterialize-css/ . There are many alternatives to this, such as bootstrap, and all of them have their own nuances and complexity. Installing this allows you access to a super duper set of core resources for developing mostly static but dynamically generated HTML pages, which is what Django really focuses on. 3) Look into Celery - Celery is a program which happens to be written in python that allows for asynchronous/distributed processing of requests. I'm just now starting to learn about it, but it essentially runs as a webservice that runs and helps to manage your CPU work load in a way that doesn't hold up the web browsing experience during computationally difficult tasks for the server. For example, it sounds like you may have some image processing to do for your site. If someone were to upload a bulk of photos, I would imagine it could take time to process all of that work. Celery would allow you to handle that process in the background while allowing your web server to continue responding to new requests, and would create a queue of such tasks to be handled all in background. Something that I found quite weird at first is that it requires another type of program called a "message broker". The default example is this RabbitMQ program, which apparently works very well for Celery. I gravitated more towards Redis for a small variety of reasons, but there are articles comparing the two out there which you should probably consume. 4) Look into Docker - You are running Django; Redis; and Celery. You may even want to run some kind of other network services to handle specialized tasks such as machine learning, image processing--anything that would take a lifetime of work to code and has already been implemented by those who are smarter than us. Docker is a great way to try out some of these services without time consuming and system-altering installations, and you can ultimately leverage it to create easily redeployable environments on remote servers very quickly. It literally caused me physical agony to start researching yet another system after ambling around between async systems, databases, message brokers, Angular....but Docker is actually really easy to use and I would describe it as being purely beneficial to your sanity with very little academic overhead. I'm a slow reader/learner, and I was able to get a firm grasp on it's usage in just a day of reading. **Warnings** 1. Unless you've already dealt a bit with javascript and some of the various systems out there for managing it, stick with static HTML pages rendered by the server (i.e. Django's default way of handling things). If you are posting here, it means you're reading about websockets and other cool technologies for making beautiful web apps with super dynamic data, but after several weeks I can honestly say that those lofty goals have served only as a distraction from achieving more practical goals. You can learn those things in the future. In the meantime, there are many javascript elements available in libraries like MaterializeCSS that will give your site a very responsive look and feel without so much learning overhead. 2. Realize that there are endless options for this general type of system (Web frameworks, REST, front end frameworks, special databases, asynchronous processors, etc.). Research them all gradually for your own enrichment if you like, but choose your core systems and develop it to a working prototype. Revise from there. Do not get distracted by the variety, and resist the temptation to implement an entire framework to implement some fancy feature that you are months away from even working on. 
As someone who has interviewed programmers and seen many resumes, I can share what I think makes people stand out from the crowd. These are not requirements for job candidates these are just things that would set people apart from the majority. - Have your own website. Have your own domain and your own email address. Post content once in a while even if it's short. A Medium blog with a gmail address is not the same. It takes at least a little bit of effort and knowledge to get your own hosting set up, but you can do it for very cheap and it makes you look a lot better. A virtual citizen in a way. - Have something to show. The website should be your first thing you can show. It is your resume essentially. Code is also an important thing to show. Projects on GitHub are good enough here. A quick glance at the GitHub history with 0 commits in the last year is not very impressive though. It's easier to show off applications than source code, but sometimes a library doesn't have anything but source code. - Have side projects. This is a question I ask in almost every interview and when someone comes up totally empty handed it makes me wonder if they even like what they do. - Clear spoken. This is mostly for non-native English speakers that I interview. If you have a heavy accent, please don't mumble and talk quietly, it makes it that much harder to understand. I normally have no trouble understanding even the heaviest accents, but some people will just mumble in to a phone and you have to ask them to repeat themselves throughout the whole interview. That is a huge turn off. - Well written resume. I cannot tell you how many resumes are provided with inconsistent formatting, misspellings, and typos. If you have consistent formatting, no mispellings, and you double checked everything with a proof-read, then you *stand out*. EDIT: I decided to post this on my blog because I do see this question a lot and I hope it helps others. http://www.devdungeon.com/content/how-make-your-resume-stand-out
&gt;What do I have to demonstrate? Your ability to find a problem, and come up with a solution to that problem, using a programming language. This can come from starting a project from scratch, naturally running into problems, identifying the problem, and patching. That process is a good demonstration. Use some version control and share your code with the world. (github/bitbucket) &gt;What would set me apart from other applicants that makes me irresistible? Working with technologies they are interested in pursuing. If they are interested in automation, and you are writing automation, they will be interested. If you are writing web automation, and they are a web platform, they will be more interested. If you expose yourself to many problems and techniques to solve the problems they would run into, before they actually run into them, you will be irresistible. You gain that from exposing yourself to those problems, there is no Elvis dust to cover yourself in. &gt;How can I determine what to build that is useful to me AND others (without doing something that has already been done better than I can do it). Why does it have to be first to market? Code can be written in many different ways. You can tackle the same problem as someone else, the end result can be exactly the same, but the underlying code will be fundamentally different unless you copied code. Who cares if it is useful for others? Your goal should be to make something awesome that is a problem for YOU. If it's a problem for you, there is a good chance it will be a problem for others. I think it's best if you are the consumer of your own product. (More passion, more creativity, more motivation.) &gt;Ultimately, I want to work with data, predictive models, text analytics, machine learning. This is where you start when you are deciding what project to take on. Depending on your current skill level, some of those things may be more appropriate to pursue than others. You should ask yourself, what problem do I have that I could use (insert programming method/function/library/module/style) to solve?
I agree with your point 1. The other two points fall squarely in the category of "premature optimization". Make a prototype that does what you want using flask or django, write the front end in html/css/js and think carefully about the database part. Once all these work together, then get all the performance you can out of it on a single server. Worry about scale later. Of the three (front end, database, Python server), putting some thought into the the first two is probably most beneficial. I think the python part is probably the least complicated. 
nah. not everyone cares about python 2 compatibility. i've got a project at work written in python 3.4 and we're happily using type hints in the non-comment version.
I disagree, the database should conform to the needs of the application. And the front end shouldn't dictate anything to the backend. That's not to say that these aren't important things to get right, but a "database driven" approach almost always leads to crud apps (in both senses of crud). The most complicated and most beneficial to get right is the server code. This is where almost all the interesting stuff happens. Once you hammer out what the data the server is working with, choosing and designing a database is a cake walk. And once you know how the server will respond to requests, designing a front end is pretty easy, too. 
Does this mean more Python videos soon? 
Solid list.. Thanks
Not really. Text posts and discussion differentiate it.
Once again, just a skeleton of some tools built around Ansible.
Thank you for the shout out! I'm glad he liked the card.
i already did that , that just handles the exception , i need to copy the selected text into the clipboard. is there any way to do that? i added pyw extension , so its in windowless form.
Take a look at collections.counter to make this much more straightforward.
Can I ask why you are leaving? * I am not affiliated with Linode, I just happen to use them for a few things
This may sound facetious but it is not..... Just be so damn awesome that employers cannot afford to ignore you. Make major contributions to the most well known open source projects. Speak regularly at conferences. Be a world renowned expert in something. Speak at one software meetup every month. Write a major, complete project, have it out there online. Speak in a clear and articulate manner. Write a book. Most people don't do any of this... they just hope they'll get a job the easy way.
So you just use 'this' instead of 'self' in your method definition. I mean, that's evil, but it is still Python.
Well, in my project, I used casenumbers as the seed. That's how all this started.
user name checks out 
Is this contract work or homework?
Curate: Select, organize, and look after the items in a collection Presumably this means being selective about a list of active links. No annotation necessary (though obviously it loses on value).
Sorry for barking at you, I'm just fed up with people who think that if something isn't on Github, it doesn't exist.
Thanks for the reply. Can you recommend any resources for playing more with the interpreter memory?
Have skills, knowledge or experience with something beyond just programming. There's thousands of programmers but a much smaller pool that can understand what a business actually does and do more than blindly translate specs into code.
Slightly off topic. But holy shit for all the good pygame does that website is garbage. 
That's weird, I always use dropbox and I never had that need. Do you have a slow internet connection?
Don't have slow conection, but, running a project with Visual Studio with sync turn on and my old laptop sucks
Windows 7
Might be a rabbit hole but here is something.... https://metacpan.org/pod/App::dropboxapi
You do realise than Cpan is *The Comprehensive Perl Archive Network*?
No, I just lurk on the mailinglists sometimes. - But also do like to try and use it on my own projects from time to time + check speed.pypy.com. 
I'll have a look at it. The theme is fairly old and needs a bit of work.
Reminder all attendees must follow the [code of conduct](https://github.com/python/pycon-code-of-conduct). If you find yourself harassed sexually by any python programmers, the harassment procedure, based off the [Ada Initiative's Guide](http://geekfeminism.wikia.com/wiki/Conference_anti-harassment/Responding_to_reports) can be found at https://us.pycon.org/2016/about/code-of-conduct/harassment-incidents/. Thank you
I already feel afraid of going to my first pycon. I hope I don't get harassed in any way. If your intention was to create a "safe space", you must be living in a high tower with no empathy toward me as a women whatsoever. Maybe its just me, but all these GeekFeminism wiki and other things make me afraid. I'm sure its there to scare away "perverts" and "harassers", but even to me, it reads like a threat shadowy people will confront me to harass and grope me. Further, if you are a programmer, regardless of your gender, I can't help but feel sorry for you, because you're paying to go to a convention and being simultaneously insulted. It's like paying to go to pycon is signing up for a sex offender registry. Maybe men are the people getting the short end of the wedge for the past couple of decades. In any event, I'm sure if you really value safety, you can have the integrity to take my opinion anonymously. Please note some feedback: it doesn't make me feel safe, its like reading warning signs I'm entering a bad part of town with a high likelihood I'll be troubled.
Just don't talk about dongles and forking and you'll be OK.
Happy Cakeday! This is what I did on my cakeday - [link](https://kekday.herokuapp.com/) and [github](https://github.com/avinassh/kekday)
The code there is a shell script, and the magic you speak of is research and knowledge. The attacker didn't just write that code and it magically worked, he had done a lot of research to be able to know what to write in the first place. One could just as likely have done this in Python, C or VBscript.
Nope. But I do now. :-p 
Is Adria going this time?
Looks nicest. Two fifths on the left with IRC/Skype/whatever, three fifths on the right with chrome.
Docker and celery are "important and useful for his stated objective"? Here's Celery's pitch from their homepage: Celery is an asynchronous task queue/job queue based on distributed message passing. It is focused on real-time operation, but supports scheduling as well. The execution units, called tasks, are executed concurrently on a single or more worker servers using multiprocessing, Eventlet, or gevent. Tasks can execute asynchronously (in the background) or synchronously (wait until ready). Celery is used in production systems to process millions of tasks a day. This sounds like something you would want if you are processing "million of tasks a day", not building a prototype. Docker is container software and is an operations tool, not a development tool. Materialize is a great idea for a beginner project. 
Ipyparallel is independent of IPython/Jupyter (it was bundled with IPython in the past, but it was just a normal package that got separated into it's own recently). Adding nodes is quite straightforward (just chucking node names into a file, and the number of "workers" per node). The dependencies might be a problem (never had problems with them though), but the fact that you have the ability to transparently run the same code from a multicore computer, to a NFS-LAN cluster and to a batch queue is quite cool. MPI is not necessarily relevant here (I don't use it most of the time, but it has its uses)
I probably shouldn't go; what normal person doesn't joke about those kind of things occasionally?
Gotta love the downvotes. Anyway, I wouldn't while I was there. http://techcrunch.com/2013/03/21/a-dongle-joke-that-spiraled-way-out-of-control/
Edited my post!
&gt; and mildly sexist Boo hoo.
The rational is that type hints will help people in their code base migration. It's espacially important for big companies, and Guido introduced this features because of his work at Dropbox.
Playing with cleverbot in python is a lot of fun. My favourite project of mine was combing cleverbot with the python tinder API. It was amazing to watch the conversations that were had. 
I wrote my doctoral thesis on Twitter sentiment and used pandas, Numpy, Scipy and NLTK during the data analysis phase. Thesis can be read here -&gt; https://www.researchgate.net/publication/271702248_Analysis_of_Twitter_Messages_for_Sentiment_and_Insight_for_use_in_Stock_Market_Decision_Making
Whether I'm using a virtualenv or not (default interpreter), I'm still unable to find and install the package within PyCharm.
Wow that's great! how you combined cleverbot with Tinder API?
&gt; Codes of conduct are the norm now for conferences And based upon what reasons? You don't just plop warning signs up for problems that don't exist. You mean in programming conventions I assume? I've been attending conferences outside programming for well over 20 years and haven't seen such a fuss. &gt; They don't mean it's a boring, joyless experience where you can't joke about anything. Didn't some guy have his life ruined basically for making a dongle joke? Also, I'm a female, and consider myself a feminist, but this GeekFeminism wiki that PyCon uses is like, not quite the scholarly stuff I remember from school. This is cringey. The political agenda is completely overt. I'll be refunding my ticket in the coming days. Probably a drop in the bucket, but just to let you know, not all women find these hysteria welcoming.
Sorry I just took down my public notebook server that I was using to host my pandas projects. Will move to git and post. I am using pandas to perform basic signal processing on tidal data in estuaries to determine if the tidal regime is changing. Boring for people maybe but important if you are an estuary plant.
 B I R T H D H A P P Y Y
Is it open source? Otherwise, why do you believe that your announcement is relevant for this sub-reddit?
Sure, [here you go](https://github.com/joshnewlan/say_what). I'll try to clean it up when I get a chance - I haven't had a chance to put much time into it. Currently the script relies on Splunk as a data store, but that could be changed to any other timestamp-based index I guess. This [PyAudio and API wrapper module](https://github.com/Uberi/speech_recognition) does most of the heavy lifting on breaking the input into phrases and can be optimized to improve mic input sensitivity and silence limits between phrases. The speech-to-text accuracy is far from perfect, but if you get the input audio at a decent volume and a reasonable speed it's pretty good. I'm thinking about running the output through a natural language processor to determine whether it's gibberish. Parsey McParseface looks interesting. 
Why not start off by working in data/predictive analytics from the get go? We've been looking into the career paths and prospects for those in the analytics space recently. Two things jump out. Firstly, it's important that you start networking (http://www.northeastern.edu/levelblog/2016/05/10/anatomy-data-analyst-resume/) with your end goal in mind and purposefully design your resume (http://www.northeastern.edu/levelblog/2016/05/10/anatomy-data-analyst-resume/) to help you hit those goals. 
You can get a job with no degree, it really boils down to experience, passion and personality. See also /r/cscareerquestions
What makes you think that OP'S code in peticular has solved it?
&gt; And based upon what reasons? You don't just plop warning signs up for problems that don't exist. I think that was the whole point, they do exist. The whole point of a code of conduct is to remove any doubt and give everyone a set of guidelines of which to act by. To be honest it should be super simple. As per life, don't be a dick.
Degrees are just a nice-to-have; what gets you a programming job is not a degree, but demonstrable programming skill and experience, ideally in the form of an extensive track record or portfolio. By all means get the degree, but more importantly, learn to program and keep practicing, expanding and refining your skills.
Thank you! I really wanted to make it look nice. One question though, why do you have both `url` and `url2` if you only use `url2`?
Probably not what you were looking for, but I just put out an Entity-Component-System based on numpy. https://github.com/Permafacture/data-oriented-pyglet An ECS is something that you would use in a game engine or physics simulation. In the examples, I use it to replace pyglet batches.
I'm a little late here: what a terrible idea.
Implement your own call stack instead of building your emulator's call stack on top of Python's.
Ah, fair enough. I was kinda hoping you had found something in their code. 
I analyzed 65,000 of my text messages using Pandas/NLTK on my phone (because I never delete them). [GitHub Link] (https://github.com/atandy/text_message_analysis) 
You can try looking at the Udacity's github for the ML course for datasets. The student data dataset might be sufficient for what you're looking for. https://github.com/udacity/machine-learning/tree/master/projects/student_intervention
Hey there, I'll be at PyCon this year. I am planning on sticking around a day or two after so I might be interested in helping out with a sprint.
Changing the bytecode of the function would only affect the later calls. You'd need to change the bytecode on the stack, which isn't possible (ctypes might make this possible).
[Visualizing the 2010 census at the block level](http://nbviewer.jupyter.org/github/patmarks/blockbyblock2010/blob/master/blockbyblock2010%20examples.ipynb)
In short, don't use the word "dongle" or make jokes involving the word "dongle". 
Man, that story pisses me off so much ...years after reading about it. What a complete collapse of judgment for nearly all parties involved.
PyCon's code of conduct (CoC) was put in place in the years soon after other conferences were in the news for some inappropriate things (DHH's girlie slides at that Ruby conference, etc.). It's quite possible that ugly things have happened that I'm wholly unaware of but my perception was that the CoC was largely driven by a desire to differentiate the Python community from stuff that was going on elsewhere: "Not here. At PyCon you shouldn't have to worry about stuff like that." I saw no external pressure forcing the PSF to institute a CoC; the effort was proactive and came from within the community itself. When it was announced, I was an immediate fan of the CoC--and I still am. Kicking someone out of a conference for being an asshole is easier (and legally safer for the organization) to do with a CoC in place.
A few years ago I worked on a small program that would calculate the chance of success for *any* kind of roll when playing a table-top RPG. You would input what dice you were rolling, what modifiers there were, what target number you were going for, and the same for your opponent if it was a contested roll, and it would give you your chance of success, using the binomial coefficient to calculate the odds. This accounted for &gt;95% of all rolls that occur in an any RPG, but for games that use a dice pool it becomes a lot more complicated, as what numbers you roll can either let you roll additional dice or subtract away other dice, giving a potentially infinite Markov chain of possibilities. For these kind of rolls I would do a quick Monte Carlo simulation that would simulate the rolls 10000x or more times and then report back the results to give you an estimate of the chance of success. It all worked, I used numpy for the number crunching and matplotlib for the plots, but I never integrated into a gui or anything like that.
I haven't, but the data collection code is just using Twitter's stream API and collecting tweets that have Cashtags in them (e.g., $AAPL, $SPY, etc). Take a look at [twitter-pandas](https://github.com/wdm0006/twitter-pandas) by /u/wdm006 for an easy to do twitter collection approach (This is awesome BTW). For the analysis, I'm doing fairly straightforward natural language processing and other analysis approaches - most likely won't be sharing that code any time soon since I've commercialized some of this work.
Nice work
The demand is low. DJango and Python are in decline.
Actually the conky itself in my problem is nothing more than print to stdout. You don't need worry about that, this is not the problem here. You can think I wants only print the RSS titles to stdout and exit my program, but while this happens, the notifications needs be showed expecting the user click (in another process | daemon). For notifications I use the GTK, nothing about conky (again). The problem is for paralellizing the two routines: the main script and notify() function, independently. 
&gt; So the ideal solution would be to run your script at regular intervals. Can't you somehow make Conky do it? I already do this, but this is not the problem. The problem is print to stdout without expecting the notify() function, but the notify function needs continues running independently the main program exit. 
I swap between them for testing. url is the url I actually wan to capture from. Url2 is the one I use for testing. In hindsight, they should have both been just url and then I could comment out whichever one I didn't want to use.
Awesome !!!!! I stopped my drake playlist to read how awesome this library is. Thanks a lot for sharing!
&gt; Try asking in /r/Conky, /r/Conkyporn, /r/linuxquestions or /r/linux, because it doesn't seem like a Python problem, it's a Conky problem Is really a python parallelizing problem. I don't have problems with conky, he works fine about I wants. The problem is simple, the script runs, get some rss title and read from the cache. If something is new, put notifications on the desktop using GTK. The notify routine needs to expect the user clicking or the notifications closed to finish, but the main program (whose calls the notify function) needs to finish without expecting this. How this is a problem with conky? I would be wish need the same feature without using conky and this is will continues the same problem.
sure, np
What are they being replaced with?
It's not working.
Is this Linux only? It looks really cool!
I know you specifically mentioned Web, and from what I can tell it definitely isn't as popular around NYC as it may have previously been. With that being said, if you drop Web from your requirement, there's still a lot backend Python work available out here.
Since you asked: IOSACal is a radiocarbon calibration program written with Numpy and matplotlib :-) The source code is at https://gitlab.com/iosa/iosacal but you can have a quick look at the basic features from https://iosacal.herokuapp.com/ There is little of great interest from a general perspective but I manipulate ndarray objects in a few ways.
I'm working on a Reddit social network mapper that's built around pandas. Right now it's just a scraper, but I'll be adding more functionality for data analysis and visualization in the near future. https://github.com/haaspt/panopti
When I run ```pip install vprof``` I end up getting 0.22 instead of version 0.3. Of course, installing it via pip and the latest tarball works. Interestingly when I run it, I get a lot of exceptions like this: ```Exception happened during processing of request from```
Excuse me, I thought it was possible but I haven't found a good way to create restful api with remi. I will work on this in the future.
I really really didn't, this is an approximate solution 😉
That would be beyond awesome... And a bit sad that I didn't spot it myself! 
Thank you! I really enjoyed doing this. It was a nice little challenge for myself 😉
If you like these kinds of tasks, try CheckIO. They have a ton of tasks and puzzles to solve with python. Many are similar to the crossword problem.
Not answering your question, but have you looked into BitTorrrent Sync? I'll never use dropbox again!
&gt;blame me for talking about is python problem No, you were right. Until this issue came up, it *was* a Python problem. &gt;I need to figure out how I can put this on conky without wait the child finish (now, this is the problem). Well, I'm not sure, but maybe Conky waits for the process group to finish or the child process remains attached to some virtual terminal and Conky knows it. You can try calling ``os.setsid()`` (with no parameters) after forking and before calling ``notify()``.
Docker is an operations tool, but people use it to demo network services and make easily reproducible *development* environments all of the time. It is a tool. It makes things you likely have to do anyway *easier* and *more consistent*, so he should *"look into it"*. Not optimization--Advice for his learning, and for managing his environment. Celery is definitely prime example of optimization--I'll bow to you on that. I would defend the recommendation further as being a logical design choice to achieve normal types of functionality in this sort of project, but it certainly isn't necessary for a beginner project. 
Then I don't know what else to do. Good luck.
This is very cool and definitely not boring. I'd love to see your code if you don't mind sharing.
This is cool, it's reminiscent of my packages (mentioned [here](https://www.reddit.com/r/Python/comments/4k2aww/do_any_of_you_have_projects_with_numpy_scipy_or/d3bjvq7)). I think it would be interesting to have a collection of similarly structured (data from x in pandas) libraries, maybe eventually with a common interface to all of them.
I did all my phd thesis analyses in python, largely with numpy and scipy. Gene expression evolution in mammals. 
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
I read his thesis for a paper last semester. Cool guy from the sound of it!
Yes, that's a major part of the question: if a custom Python rather than a custom Java VM were used, would it work? I don't think so. All clever Python runtimes try to win by making dynamic things static at runtime via clever analysis; that analysis isn't free, isn't immediate, isn't perfect, and in most cases needn't be done for Java (which can also benefit from runtime cleverness, and can go further because it needn't waste time on "can this dict lookup become a memory load"). Maybe Google could've done some magic there and come up with a mobile-specific Python runtime (not Unladen Swallow) that improves performance enough to be worth the effort, but I doubt it. You'd have to _strongly_ prefer Python for even a good-as-Java (best you can hope for) effort to be worthwhile, and it'd likely require type annotations and restricted functionality, making it not really Python. You _can_ write mobile apps in Python now, and it's been possible for a while, but as a default language for the platform, it's would've been a terrible choice in early Android, and realistically a questionable choice now. *[Caveat: I don't know about Cython, so maybe that would work, I don't know. From what I understand, it is a way of optionally writing C in Python syntax, doesn't support all of Python, and requires a C compiler. An alternate syntax for C might be practical performance-wise for Android, but would still be an uphill battle on tooling support. Possibly a reasonable choice.]*
Sony's tutorial video: https://www.youtube.com/watch?v=eWtVWF0JSJA And I brought the original Google Code docs over to the Wiki.
Awesome work!
I've seen some really similar studies in my linguistics training, and I've wanted to do this kind of work for a long time. Looking through the bibliography, I see a lot of finance and economics, but it's light on linguistic theories. What are some strengths and weaknesses you see in regression models as opposed to manually tagged parts of speech?
I made pretty visualizations of the g-forces on various roller coasters: http://blog.robindeits.com/2013/11/11/roller-coaster-visualizations/
Sad to be missing it this year. My company bailed on it. Have fun all!
I have a large music collection. I've been having a blast using Numpy, Sklearn and TensorFlow to analyze music. I have an algorithm for classifying music by genre. And another to predict if I will like new music. You should add sklearn (scikit-learn) to your toolbox (http://scikit-learn.org/stable/). It's pretty powerful and works nicely with numpy and scipy.
Oh cool, I'll definitely check these out. That sounds like a great idea. I should really get around to polishing my repo up and getting it from the "I made this in my garage" to the "usable tool" stage.
K&amp;R should set you up just fine. The main differences for C99 is that you don't need to declare all variables at the start of a function, and inline functions. The Peter van Linden book is definitely a good one for C programming, but it's something to read after really going head first in C. I don't personally think it will help Cython code very much. The standard of C that Cython targets is technically C89, and C99 if requesting to use C99 complex number types. Again the main difference is whether variables are declared at the beginning of a function.
First thing you should do is move the response generation code into a function that takes a single argument and responds with the appropriate output. Then instead of using a bunch of named variables and lots of if statements you should instead use a table. Essentially a list of lists. In this case the table would be a list where each element is a list containing a set of inputs as the first element and an output as the second output. Your code would have to go through each list in the table using a for loop checking to see if there is a match. If a match is found then it would need to get the corresponding output from the same match and then return it.
What does it take to remove the npm dependency?
When i try to learn a new language i tend to read far too much before just coding. I read several books and understand the language well. Then I start to code and cant even remember how to read a file. If you are experienced in python, then you really just should start coding. Python is like formalized well structured c code after all. The syntax of c is easy to look up as you go along.
So, they but have to be turned on? It is not exactly what I look for but I can put an eye on it
No ruby on rails app should have this much power ! (github is down)
For some reason currently pip installs 0.22 instead of 0.3 by default. Current workaround is explicitly specify vprof version pip install vprof==0.3 By default vprof does not print all error messages, in order to see them, please launch it with --debug flag.
npm is used to manage js dependencies and to build UI statically. It's not necessary, if you are installing vprof from pip.
Can you provide more details? Thanks!
Hey, I'm actually interested in this. Would you mind outlining a little bit more of what you're doing? 
Yes, essentially. This is why it's known as a viral licence - it infects the code it's linked with.
Nah its working fine,kust be a region issue
I have heard good things about this one: http://icube-icps.unistra.fr/img_auth.php/d/db/ModernC.pdf I haven't read it yet, though.
Nice! I've been following vprof for a bit now and I'm impressed by the updates and features. Good job! I've only used it on a toy project so far, but I've got a big ugly legacy application that I've been profiling using stuff like cProfile and snakeviz and I'll move onto vprof to get another perspective on the data. It's a really great addition to my debugging tool-belt.
I just used cython for the first time yesterday, and it's very easy to get started with. I optimized my python code to run about six times faster, which was "good enough" for my use case. The things I've learned were: * use a variable for one thing. I.e. if you used "i" as a loop-index, then don't use it for another meaning outside of the loop * always cdef variables. "cdef type type_of_x" makes a huge impact compared to simply "type_of_x = type(x)" without typing. * pay close attention to the order of if-elif blocks. * use c types whenever possible. "bint", "Py_ssize_t" etc. * when you have an if-statement with a very unlikely else-case, then they to put the else-block in an extra function. This gave me a huge speed up * avoid duplicated lines of code in a function. This went against my intuition but try-finally was A LOT faster * the smallest changes have the biggest impact. Measure, measure, measure
Cython is almost like its own language (you do have to know both languages intimately to develop using it though), but if you are not using C++ you may as well use something else. I would wager that CPython is probably a lot easier to use.
Brett's blog is often interesting: http://www.snarky.ca/
Great. Using curses is much overkill, one of the aim of the repository is avoid using heavy dependencies. The spinner can be a way, maybe I can pass the padding function now as a param I implemented as so the spinners left &amp; right. 
By the way, I implemented a way recently to handle the nested context managers. Works fine here. [gif](https://i.imgur.com/iF7VElK.gif)
https is a web connection to a specific location. A vpn is a tunnel between you and an end point. I'm not entirely sure of the question but if you're on a vpn connection all traffic will be tunneled over the vpn.
Congratulations Brett, the honor is well-deserved.
Amateur programmer here, been doing it for the last 7 years, completely self taught. I can write Java and Python and Javascript, and a little C, C++, C#. I'm not saying I'm good, just that I've had a lot of time. I have never read a book. Am I missing out on some really important stuff? Is there anything you'd recommend? edit:- I can't imagine how a book could do what a few searches could not.
No Silicon Valley jokes yet?
The main usage, of the first meanigful implementation, is here: [boring-gif-from-hell-of-satan](https://camo.githubusercontent.com/b95d8236277198ec3967e4457a01669ede2e0360/68747470733a2f2f692e696d6775722e636f6d2f686a6b4e7645452e676966)
A VPN will likely not help unless your end-point will be inside the virtual network. I would recommend using hash-checking mode of PIP (see: https://pip.pypa.io/en/stable/user_guide/#installing-packages) or download the packages directly from pypi.python.org via HTTPS. 
Thanks, I can 100% see where it came across as "The docs suck, so I'm glad you blogged about it". I should have done a better job making the focus more clearly about my experience "I wanted to learn, but got immediately overwhelmed, and gave up, thanks for the blog which helped me over the hurdle". That I had given up is on me, not the docs. I was giving kudos to the author. Thanks a bunch! 
Books have less value than they used to. But they are usually better structured and has better examples. The author has an overall idea about what they want to show you. So paying $20 to read in a few days what would take your a long time to figure out is usually worth it. Just for the better structure. But a lot of tech these days has very good documentation.
That's true in any language. And the rules vary from language to language. Getting a profiler and understanding what's happening under the hood are vital tools.
Are you planning to upload this to pypi? 
Exactly, the main benefit of a book, in my opinion, is how the author is presenting ideas to you. Sometimes I find just reading documentation to be a bit terse and blogs tend to have spelling or coding mistakes (albeit, sometimes gets fixed later). It can sometimes make grasping a concept more difficult whereas a book will usually be vetted by experts and if you go the ebook route, easily updated.
Yes, it does. Better readable code runs faster, I would never have thought it possible. :)
I'm curious about the else-case/function statement. Can you point to code?
I haven't looked much into Cython yet myself, but I know as much as to get the parts about C types and cdefs. I wonder what's the deal about if/elif block orders and 'else' cases? Is the contents or number of lines (since placing the clause in a function helped a lot) slowing down the execution even if they are never evaluated??
I'd be curious to see the C code. Under the hood, it **should** be just creating a large "else {...}" block in C, which the compiler is responsible for dealing with. My guess would be some sort of end-of-function cleanup, where Cython is doing more than it needs to when it doesn't take the expensive path. 
Every extra variable in a function seems to impose a few GC calls even if they are never used. If you are only using C types, then you are fine, but if you can't then you should use a subfunction if an unlikely case adds a few `object` variables. But passing `object` arguments is expensive, too, so I guess you'll have to `%timeit` to find the sweet-spot.
Exactly. I tried to do python setup.py install_lib, and now the module is presented in the /usr/local/lib/python2.7/dist-packages/ folder, but I get the same result: &gt;&gt;&gt; from blacklistscheck import BlacklistsChecker Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; ImportError: cannot import name BlacklistsChecker &gt;&gt;&gt; 
I have written c extensions to Python but have not used cython. One thing that makes writing extensions easier is if you can let Python own the references to the objects (numpy arrays and other structures) that the c code will be manipulation. In other words, pass a Python-owned empty array to c and let c fill the values rather than having c create the Python object and then pass the object off to Python. If you follow this design, you can avoid much of the reference counting tasks (which require a better understanding of C to get right), and get useful code with less knowledge about C. 
If you're getting circular imports when writing Python modules, NodeJS might be a good choice for you. If you can't handle Python 2 vs 3 issues and unicode vs. str issues... NodeJS and NPM is basically that 24/7.
Thanks, I'll give it a try.
Here's another piece of advice that might help: - If you're sure you don't need any python functionality (list/dict lookups, bigints, strings), get all your data into cdef'd variables and put your code in a "with nogil:" block. That should remove all the GC and other overhead.
Not if you have a venv somewhere where you have write permissions.
User will be on browser interacting with few forms or canvas objects and server should be able to convert his actions into a legit code. 
Importing modules is such a trivial nonissue I'm having a hard time taking any of this seriously.
I agree. I wish my code would look like that !
I did that some time back. I used pystache (it's the Python version of Mustache), check it out. What I did was writing small components (if {{condition}}: .. {}) that I imbricate with each other with some logic. It's not super complicated. At the end, you write the generated stuff to a something.py file and call os.system("python something.py &gt; output.txt") I'd do it like this
This is good news, perfect timing!
this is quite cool
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Something tells me that this guy is a bad programmer. I don't mean to be disrespectful, it's not easy after all. But he seems to be diving head-first into all the bad practices you could possibly find...
V2 : from itertools import product char_extension = "abcdefghijklmnopqrstuvwxyz" len_extension = 3 char_domain = 'abcdefghijklmnopqrstuvwxyz' len_domain = 3 #10 char_mail = 'abcdefghijklmnopqrstuvwxyz0123456789.-' len_mail = 3 #30 total_mail = list(itertools.permutations(char_mail, len_mail)) total_domain = list(itertools.permutations(char_domain, len_domain)) total_extension = list(itertools.permutations(char_extension, len_extension)) for mail in total_mail : for domain in total_domain : for extension in total_extension : #print(mail) mail_result = ''.join(mail)+"@"+''.join(domain)+"."+''.join(extension) result.append(mail_result) print(len(result)) print(result)
I think it really depends what you are planning to do with it. Some efficient cython code is extremely python-like and some is extremely c-like. You're definitely going to need to be familiar with c's numeric types though. If you want to do complex numerical stuff, you might get to the point where you need to understand some of numpy's internals too. I believe cython also has good support for c++, though I've never used it. Definitely look at cython's -a option, which generates an html report about your code. It lets you click on lines of cython code to see the C that has been generated from them, and any lines where the C code is calling into the python API are highlighted, which can help with optimization.
Bro it doesn't even middle out compression 
Yes. I did it. I have no degree. You'll get screened out of the process early at large organizations that still care about degrees over experience... but you likely wouldn't want to work there anyway. It was easier to sneak in when I started around 2000, but still very doable. Look for startups and innovators and get to know people in your area. People-Networking is the most important skill regardless of your industry.
&gt; Python has PIP, which is great. However, I frequently find more up-to-date and modern modules on NPM. One year later: &gt; All this to say that it feels like the Node ecosystem is constantly moving. Not in a good way. New tools that “trump” old tools seem to come out daily. Theres always a new shiny thing to replace the other. You’ll be surprised on how easily this happens to you and the community seems to encourage it. Yeah, I didn't see that one coming. I watched this happen before with Ruby (which is now settling down quite nicely), and am unfortunately in the midst of this with Docker. I really find that tools start working best after they've finished their year of fame.
You go to UCI? I'm an incoming freshman! I'm assuming you're majoring in Computer Science since you are asking about Machine Learning. I'm also going to be a CS major, can you give me your honest review of UCI and it's CS program? That would be awesome, Thanks!
https://en.wikipedia.org/wiki/Hype_cycle
Yeah, author supports this a bit. Hickeroar: &gt; The original post leads me to believe that the decision to switch to Node was simple a result of tech restlessness and a desire to learn a new system and have new toys to play with. Gavin Vickery (author): &gt; I would agree. At that time I was getting pretty bored and was excited to try Node. The issues with Python in the original post are real and things we deal with on a regular basis. However, the realization that there really is no silver bullet was like a slap across the face.
Same goes for the "it's so easy... I published my first module in 5 min!" in the first post, vs. the "Easy to learn, impossible to master" section in the follow-up. Node is new, shiny, easy, etc. Very neat &amp; lean. Also very hard once you get into things. We're full time on node now. I wish we'd chosen python.
He does sound a little reckless (which he somewhat confirms in his comments). But the story isn't really "bad programmer", so much as "wishful thinking." His exact story is playing out many places. Node looks to address all the pain points you find in python (and other languages). It's neat, fast, lean, efficient, different... just really refreshing in the first few days/weeks of learning it. Then after a few months it gets harder. Then a year later (like this), you've learned what it's good for and bad at, and you demote it from "panacea" to "useful but not perfect tool".
Back when I was a grad student in computational biophysics, I built a data analysis library for molecular simulation data (MDAnalysis - http://www.mdanalysis.org/), mostly on top of Numpy (pandas wasn't around back then). Most analysis libraries at the time required writing compiled code or scripting in FORTRAN (yes, you heard right - see Charmm - https://www.charmm.org/charmm/). Most of the students in my lab would script FORTRAN to print out relevant data from trajectories (basically 3D arrays of positions, forces and velocities), parse the text data in perl, and then do any calculations that were difficult to do with the Charmm's fortran language and output gnuplot files for plotting. I realized that the underlying binary data could be streamed directly into numpy arrays (my first foray into the CPython api - this was before Cython/Pyrex was a thing) and then all the capabilities of the numpy/scipy stack could be leveraged and plotting could be handled inline with matplotlib. This reduced the feedback cycle for analysis from hours/days to minutes. I'm no longer involved, but others took up the project and it is still thriving and being used by scientists around the world. The architecture is definitely feeling it's age - if I was to redesign it today I would leverage some of the modern pydata stack like xarray, dask and numba.
you could replace the strings 'abcd...xyz' with the following to ensure DRY: import string char_extension = string.ascii_lowercase (...) char_domain = string.ascii_lowercase (...) char_mail = "{}{}{}".format(string.ascii_lowercase, ascii.digits, "._'") I assume you are running python3 since you are using the print function instead of the statement. Do you really need to generate all possible extensions, domains and names? Maybe you could list some of them instead of calling itertools.permutations on them (only using it on the name, for instance). Python3 is smart and returns [generators](http://www.python-course.eu/python3_generators.php) in lots of places (python3 range is the same as python2 xrange, map, filter and reduce return generators in python3, etc) and those are iterable, so you don't need to call list on them before entering those nested for loops. The great thing about generators is that when iterating over them the whole list is not returned at once, so it doesn't take too much memory space. So, unless you need to print total_mail, total_domain or total_extension, there's no need to call list on them, you can change it to: (...) total_mail = itertools.permutations(char_mail, len_mail) total_domain = itertools.permutations(char_domain, len_domain) total_extension = itertools.permutations(char_extension, len_extension) You could maybe also refactor the rest of code and create functions to select random TLDs, extensions as you called them, domains and names. edit: adding generator information and code
Github. 
I'm sorry I can't hear you over your moms constant groans while I fuck her to death
Happened to me a lot in Django when I was a couple of years in. Doesn't happen so much any more. It's really really easy to happen when you create this neato helper function in utils.py, and you import that helper function into your models.py file, but then the utils.py file makes use of one of the classes in models.py, and boom. You've got a circular import. Like I said I don't run into these problems much anymore, but when I do I decide which file needs the top level imports more, and then in the other file move the imports inside of functions or methods. So it's a combination of subtly altering the way you code but also just knowing really really simple workarounds that are fairly straightforward.
I mean, I am an "experienced" programmer in that I've been doing this shit for going on 20 years now. But I still wouldn't *call* myself an experienced programmer. I know what I'm doing, but I also know, if I'm having a lot of problems with a language that's almost 100% on me.
&gt; Later you realize all the ORM tools suck and a basic driver is your best bet. Now you’re stuck implementing redundant model and validation logic. I don't see how *all* available ORM tools could suck so much that rolling your own is actually a better alternative. 
It's one thing if it was a typo in some relevant source or something, or if the typo interfered with the meaning of the sentence. But, you know, it's literally a typo typo. So there's that, added to which this is not the right place to report it. And then you complain about the downvotes which is just going to bring on more retaliation. Anyway, that's my guess for the downvotes.
I really like WingWare's Python IDE -http://wingware.com/ Yes, you have to pay for it, but I think its debugger beats PyCharm's hands-down. PyCharm is a decent alternative though. Eric is still pretty popular as well. See also https://opensource.com/business/15/10/top-open-source-python-ides
.NET Core was announced (note: not released) ~a year and a half ago, and is still technically in the RC stages. If you expect an RC to be stable, I submit that you may have put on your crazypants this morning. :) If you look at any (actively developed) language's experimental branch, you're going to be seeing a lot of movement, and .NET Core, as an RC, is pretty much entirely in the experimental branch right now. You'll probably see the standard settle down a bit once it's officially released. Node, on the other hand, seems to be all-experimental all the time, and the micro-import culture of node development is pants-on-head retarded, as the people relying on left-pad found out.
&gt; As in, they don't want to bother with python 3, but they hate how python 2 handles unicode (and which python 3 has fixed, but they don't want to use 3) This is what is killing me at my current job. Many of my coworkers believe that there's no compelling reason to switch to python 3, and simultaneously bemoan python's poor unicode handling and asynchrony support.
Honestly, this is not about languages. The author is just to quick quick to jump on conclusions. But that's fine, wisdom comes with experience.
I think I got one once, and was like "oh, why was I doing that?"
Submit to news.ycombinator.com with "Show HN:" (no quotes) in the title. 
These problems aren't specific to Node: they exist in the frontend JavaScript space, as well.
something something Snack Dick.
Circular imports are annoying, and even people who have been using Python for years encounter them. But, they are easy to find, and easy to fix.
Nah, it's based on QtWebView https://github.com/EricsonWillians/Open-Browser/blob/master/run.py#L154 Which in turn is based on "native APIs," which basically means on mobile it uses the mobile OS's built in web viewer. It's not clear to me what's it's based on on the desktop; my guess is that it's an Edge/Safari/Firefox?? view.