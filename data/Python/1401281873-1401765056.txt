I've used both komodo edit and pycharm and like them very much. I would highly recommend either one to use as your IDE of choice. They aren't exactly lightweight though. But your system specs aren't exactly shabby. They're better than mine. You should be alright running either of them.
It seems to me that it's really hard to find a good light weight python IDE. I've tried: * PyCharm * Eric5 * Ninja-ide * Idle (included with Python) * scite * vim * evim * gvim * cream * and emacs python-mode My system is similar to yours and all of the above worked perfectly well, although PyCharm seemed a little sluggish in comparison with the rest. My current favorite is Emacs, but it's a pain in the ass to learn. Edit: Formatting 
You can't autocomplete dynamic things without executing the module, which is obviously not feasible.
&gt;&gt; One of the great strengths of Python 2 is the long tail of 3rd party libraries to do, well, just about anything. Python 3 doesn’t have this. &gt;It is time for this talking point to die. Of the top 200 3rd party libraries, 80% have Python 3 support at the time of this writing. Of the remaining packages, many are things like supervisor and Fabric that are stand-alone applications where nobody cares what version of Python they run. To say that Python 3 “doesn’t have” 3rd party libraries is not just wrong, it’s completely absurd. The author doesn't have any fucking clue what a [Long Tail](http://en.wikipedia.org/wiki/Long_tail) is; because the Long Tail is not the Top 200, it's the exact opposit, it's the metric tons of other packages which are only used by a few people. And most of thoses don't support Python 3 yet.
Give Geany a try. Works very well on Linux and Windows. It's gratis and free.
I recently started porting a small library, and this website/book was very helpful. Thanks a ton to author for all the good work.
&gt; This simply isn't true. Inertia is a huge factor - people justify what they currently do but ultimately the real reason they do it is because that is their habit. Habits are more powerful than cost-benefit analyses, as a rule. History proves your habit theory is wrong. Over the years the vast majority of Python projects have been migrating to newer versions. I have been using Python since the 1.5.2 days (1999) and only recently have we have seen this phenomenon of large number of production projects not migrating to newer version. In the past, projects would run on the latest version or the past 2 previous versions. You are always going to have some projects on the bleeding edge while others are going to lag behind. This worked well for well over a decade. Now the majority of projects are on 2.7 and it will be that way until there is a compelling reason to migrate because at the end of the day whether you like it or not cost-benefit analysis do matter.
&gt; A lot of people do claim they stay on Python 2 because Python 3 doesn't offer any incentive to move, so that's why they are thinking like that, I'd guess. Nope, most people have no problem installing the latest 2.x version, outside of rare corporate environments. I've never seen anyone discussing whether Python2.7 is killing Python, compared to the Python3 migration this is a complete non-issue, a red herring. What people who say that Python 3 doesn't offer any incentive to move mean is that it doesn't offer enough incentives to overcome the significant hurdles. Remove the hurdles and this objection would disappear. &gt; &gt; libraries must support both versions for quite a while until most applications have migrated. &gt; Right. And having more new features in Python 2 is not going to change that. This is going to make supporting both versions much less painful. &gt; That's really only relevant if you still want to support Python 2.5. Otherwise you don't use 2to3 anymore, but use a common codebase. Which is painful, otherwise we wouldn't even have this discussion. I'm not talking about backporting all new features, I'm talking about backporting all backward incompatible changes and changes required to write basic Python3 code, to be enabled with `from future import`, ideally including renames and everything that `six.py` takes care of. The idea is that a library maintainer should be able to port his library to Python3, then insert "from future import py3_compatibility" and have it running on Python2.7 and Python2.6, whatever they used before, with no further code changes. If that were possible then the whole Python3 migration conundrum simply would have not existed. The only choices that library maintainers would have to make is whether to use actual new Python3 features, same they have to make re: collections.namedtuple wrt Python2.5 compatibility etc. That would be their private business and have no effect on Python3 adoption. &gt; &gt; "I can't be bothered to install Python3 in order to remove all those from future import's and compatibility libraries and stuff that I added to be compatible with Python3, I'm just fine with awkwardly using Python3 features in Python2." &gt; Huh? I'm sorry, that makes no sense. Well, you said that backporting Python3 features to Python2.8 where they are enabled with `from __future__ import` and compatibility shims "would lessen the incentive to move to Python 3". So there's this guy who writes de-facto Python3 compatible code using all that stuff but refuses to move to actual Python3. That makes no sense, my point exactly.
If you link to a GPL licensed work you are creating a derivative, which has to be licensed under the GPL. Whether you modify GPL code is irrelevant. 
My vote is at DreamPie, best way to just bang out some code and even get autocomplete features.
Both the GPLv2 and GPLv3 require downstream projects to be licensed and distributed under the same license or any future version of the same license (so GPLv2 projects can be "upgraded" to GPLv3 by downstream projects). The "any future version" clause is superseded if the project explicitly disallows that option though, because Linux, or at least Linus's contributions, is GPLv2 only.
I noticed this as well. I think shows that the author is in a defensive mood, and is not really considering the points the article is making, but rather rushing to refute the claims whatever they are without reading them properly.
I dont know Learning Python but read a bunch others and the best book I know for learning as well as for looking up stuff is Python Essential Reference from David M. Beazley. I could even learn a lot new stuff after about 4 years of Python coding.
That's not entirely true, as long as you do not distribute the OpenSSL libraries with the program itself you can link to it all you please, because it is counted as a system library. I hope I don't have to point out the obvious, but distributing your own version of Libre/OpenSSL is a horrendously bad idea in the first place because your users may be running a compromised version (see: Github and Heartbleed).
&gt;&gt; A lot of people do claim they stay on Python 2 because Python 3 doesn't offer any incentive to move, so that's why they are thinking like that, I'd guess. &gt; Nope, most people have no problem installing the latest 2.x version, outside of rare corporate environments. I've never seen anyone discussing whether Python2.7 is killing Python, compared to the Python3 migration this is a complete non-issue, a red herring. What? I don't understand the relation to what you and me said before. &gt; That's really only relevant if you still want to support Python 2.5. Otherwise you don't use 2to3 anymore, but use a common codebase. Which is painful, otherwise we wouldn't even have this discussion. Going up in the morning is painful. It's all relative. Using the common codebase for Python 2.7 and Python 3.3 is not really very painful. I wrote Pyroma for Python 2. Then I added Python 3 support with 2to3, with almost no changes. Later I decided using 2to3 was silly, and went onto a common codebase. Here's the changeset: https://bitbucket.org/regebro/pyroma/commits/b81cbe0085ff0bb71fd048b011808a5aee616867 When I wrote Hovercraft, I wrote that for Python 3. There are reports that it works under Python 2 as well, if you just add argparse as a dependency. So it seems to work with no changes. I just wrote in a "common codebase" automatically. It's really not very painful. Especially if you use six. The common codebase is pretty much Python 3 coding, with some future imports, and lacking some of the new Python 3 features like "yield from". &gt; I'm not talking about backporting all new features, I'm talking about backporting all backward incompatible changes and changes required to write basic Python3 code, to be enabled with from future import So in fact, what you are talking about when you say "new features" is "not new features". Yeah. That was clear. I have previously answered you as if you actually meant "new features", which is where much of the confusion is. The question then becomes exactly what incompatible changes you want to backport. &gt; ideally including renames and everything that six.py takes care of. Sure, but then again, you can just use six for that. So that's not an actual hurdle, and you mentioned hurdles. ;-) 
&gt; A lot of people do claim they stay on Python 2 because Python 3 doesn't offer any incentive to move, so that's why they are thinking like that, I'd guess. On the contrary: businesses cannot afford to stop development on new features to move their code base to a new version of python. To do so would erode their market edge. Businesses cannot afford the upgrade path. Python 3's upgrade path really needs to improve. The only other thing that would compel businesses to upgrade is a 'gee-wiz' game changer feature that wasn't in python 2: for example a JITed GIL-less python with performance nearing c or an extremely easy-to-use threading model the works on multiple cores that isn't a multiprocessor hack. This makes the upgrade cost affordable because there is a high value in moving. Right now, python 3 feels more like the developers decided to refactor the code and have added some bug fixes on top of it. And they are holding those bug fixes hostage from python 2. In addition, they're spreading propaganda (in some cases it feels like they're beating our heads with how much better python 3 is) about how much better python 3 is but not highlighting much value difference between the two. Of course businesses are not going to jump on a new version. Why would they when the cost to move is so high compared to little value? The choice is: add 6 months of features vs refactor code for 6 months with no real difference (except possibly a performance slow-down) and allow the competition to catch up. Why would any business switch? Edit: And here's the part that I think is really scary. While python 3 developers have been refactoring python 2, other languages have highlighted the major issues with python (e.g. threading model, GIL, multi-core processing, etc.). They've come up with performant solutions for these problems, and people are starting to move away from python. Even the python developers are eyeing these new languages and looking at them as something interesting to develop. As much as I enjoy python and have over the past decade, even my personal projects are starting to move away from python and into something more performant. The python development has basically stalled over the past 5 years and its no wonder businesses are now starting to move away from it. 
&gt; A lot of people do claim they stay on Python 2 because Python 3 doesn't offer any incentive to move, so that's why they are thinking like that, I'd guess. &gt; On the contrary: businesses cannot afford to stop development on new features to move their code base to a new version of python. I don't see how that relates to what I said. &gt; To do so would erode their market edge. Businesses cannot afford the upgrade path. Python 3's upgrade path really needs to improve. OK, so exactly what is the problems with the upgrade path and how can we improve it? &gt; The only other thing that would compel businesses to upgrade is a 'gee-wiz' game changer feature that wasn't in python 2: for example a JITed GIL-less python with performance nearing c or an extremely easy-to-use threading model the works on multiple cores that isn't a multiprocessor hack. This makes the upgrade cost affordable because there is a high value in moving. You are now arguing against my claim that backporting new features to Python 2 would lessen the incentive to move to Python 3, with saying that there are not enough features unique to Python 3 so there is not enough incentive. Which to me seems like you are in fact agreeing with what I said. &gt; Right now, python 3 feels more like the developers decided to refactor the code and have added some bug fixes on top of it. Well, Python 3.0 did yes. That's pretty much exactly what it was. But new features *are* being added to Python 3, you know. ;-) &gt; And they are holding those bug fixes hostage from python 2. No, that's absolute bullshit. Please do not discuss this issue if you don't know what you are talking about. &gt; In addition, they're spreading propaganda (in some cases it feels like they're beating our heads with how much better python 3 is) about how much better python 3 is but not highlighting much value difference between the two. Again you are saying there are not enough difference as an incentive. As a response to me saying that backporting features to Python 2 would lessen the incentive. 
That's demonstrably not true: proprietary Linux kernel modules exist, they link to the Linux kernel module interface, and are still legally distributable. If you distribute a GPL licensed work with your project, and you link to that GPL work, then you are correct. But there are exceptions in both the GPLv2 and v3 to allow programs to link against system libraries. Furthermore, if the project you want to link with does some cool stuff like annotating their symbols and bindings with the license for that symbol/binding (like Linux does), then they can allow proprietary "derivatives". See here: http://www.tldp.org/HOWTO/Module-HOWTO/copyright.html
Python 3 might be fine, but I see no compelling reason to commit time and effort into moving to it. Sure, it has plenty of "exciting" features, but I'm a professional developer who writes boring code meant to last for years, if not decades. "Exciting" new features look fragile and unproven to me. The OSes I develop for (and on) have Python 2 distributed with them, and provide hundreds of pre-compiled packages for them. Going through the effort of compiling my own packages and having to fight against the OS' version of Python just for a few new language features sounds like tilting at windmills to me. As we're fond of saying in defense of our language... Python is good enough. I'll take that and extend it a bit: Python 2 is good enough for now.
You appear to be replying to your own misrepresentation of what I said -- I see no other reason why you would feel the need to assert 'cost-benefit analyses do matter'. Please stop that if possible. Nice account of history.
The differences really aren't that big. Porting to Python 3, the book, is 145 pages long, and it covers a lot of things not covered in Learning Python. It's so big because it's very detailed and very talkative. 
&gt; It also makes the mistake of trying to be both an introduction for people who know absolutely nothing about programming and a completely comprehensive language reference book at the same time. Isn't that exactly what OP said? It should be two books?
I'm happy working with Sublime Text 2.
Geany is my default, it's awesome and lightweight. If you want something more powerful and bloated, try PyCharm.
&gt; There is a real cost associated with moving a large code base from python 2 to python 3. This cost is measured in months of refactoring. "Months". &gt; There is little value / incentive for a business to move from python 2 to python 3. Right. &gt; Fixing either pain point would improve Python 3 adoption rate. Sure. &gt; However, improving the upgrade path would be far easier to develop than creating a wiz-bang feature that pulls companies to python 3. Sure. &gt; the tulip rehash of twisted :rolleyes: &gt; The mental gyrations needed to use either library are still ridiculous and error-prone. multi-core processing is not a trivial problem. Nothing will magically appear that makes it so. &gt; The best way to improve the upgrade path would be to create a version of python (2.8) that straddled the new features/bug fixes of python 3 but was backward compatible with python 2.7. Please note that backporting new features contradicts your second point. It would make the incentive to move to Python 3 *even less*. Also, it would not reduce the pain, as it does not help the upgrade path. Bugfixes are already backported, so that's a moot point. If you are saying that you want to backport some of the incompatible changes in a compatible way, I will ask you to state exactly which changes you want to backport. 
Cool!
Python 2 killed Python 1. Hurrah!
"Excuse it". You make it sound like it was broken lightly or by mistake. Backwards incompatibilities were introduced because they made the language much better. Also: Ten years of support and bugfixes apparently doesn't count as "LTS" for you.
WingIDE has a free version, and it's pretty lightweight. Check it out.
&gt; Sure, but then again, you can just use six for that. It sucks to use `six.iteritems(d)` and the like.
Yeah, it seems like Apache 2.0 is a good balance. Its permissive, but also has more definition in the usage of patents (if needed) compared to BSD/MIT and is pretty well defined.
I think you're overthinking it, and also presenting things as very one dimensional. I might suggest that had you started with C, you might now be posting in a C subreddit about how you maybe should have learned python first because C has spoiled you with its fine control and now you find it hard to give it up. I do think that there are arguments both ways (though I think python is a great first language regardless), but I don't think your perceptions here are a very good one. I bet they'll quickly change when you need to do something in C++ that you *can't* easily do in python...and if you never do such a thing, then you didn't need C++ in the first place.
I don't know if I agree with that because I went the same way you did from easy to hard. Specifically ruby-&gt;python-&gt;java-&gt;c++ and while it wasn't easy nor did i particularly like it, it worked for me. ruby/python helped me learn the basics and kept me interested and then when I need more from the language, java/c++ helped me learn more in-depth stuff. There's a lot of things c++ is good for and I think you might just not like it because of how used to python you are. It just takes some time to see the benefits in it. But then again, there are a lot of people who feel that it isn't worth it. So I'd say, learn a compiled language so you know that there is an alternative and then stick with python if you want to. 
That's just you discovering how great python is compared to other languages. Besides, Python has taught you a great many programming concepts that are still applicable to C++ or any other language. IMO it's a lot more overwhelming to have to deal with type declarations, more complex syntax, etc. when you are only just starting to master statements, expressions, and loops. 
I learned C++ first, and frankly I think I benefited a lot from doing so... if only because its shown me where Python really shines.
&gt; If you link to a GPL licensed work you are creating a derivative, which has to be licensed under the GPL. Whether you modify GPL code is irrelevant. The test is rather more complicated than this. I can link against glibc without my project being GPL. See for example Python.
Yeah that is why you would then use a GUI editor that generates the boilerplate code for you when you program in the C family languages. With dynamic languages, you really don't need a fancy GUI editor due to the less terse syntax.
Well, it's ugly, sure. "Sucks", maybe not. And that is an interesting example, because what do you want Python 2.8 to do about it, specifically?
&gt; Why should the volunteers care? They make what they want to use, they aren't employed by the businesses. Should they hold back their ideas and their project because it's too expensive for some business? You're right. The devs have every right to just do what they want. They're not beholden to my bottom line. But my point is, if they do that, that means they're ok with Python not being useful to other people, and they're ok with Python's user base dwindling away. But if the Python community was ok with that, they wouldn't brag about Python's success. Python.org wouldn't have a gigantic "Success Stories" section. Python wouldn't bother to promote itself at all, because it's just a bunch of volunteer devs having fun. But that's not the case. You can't have it both ways. If Python's success among the broader programming community is a good thing, then you can't just say "here's a phone, call someone who cares" when that community raises concerns.
&gt; No, I'm suggesting that it should be one focused book that doesn't try to do everything. Well, which thing? And are you then saying that the other things should not be done by ANY book? ;-) 
&gt; that means they're ok with Python not being useful to other people, No, that just means they put the project and the vision of the project above what commercial business users want it to be to suit their own commercial and financial means. Python remains useful to other people, it's just that those people aren't the ones that are tied up with legacy code, and are willing to change and make better, new things. And it's not like the core devs are forbidding the use of older python versions. It's not like 2x is suddenly going to become unavailable and apps all over the world are going to crash. Older versions are available and they can be forked, and modified and hacked. It's just that *they*, the core devs, want to move onto other things, better things. If bussineses have a financial interest in maintaining old code then they should be willining to spend money on it and either do it themselves or pay someone to else to do it. They should be proactive about it instead of expecting the core developers and the community to do it for them. &gt;and they're ok with Python's user base dwindling away. Is there any evidence of this trend? 
In the alternate universe in which you started with C++, you may have simply given up on programming, finding it too hard and not enjoyable. Now at least you have gotten the basics of programming structures down, and are ready to take on the remaining pain of C++. But don't forget to revel in the idea that you can finally compile to native code and wind up with a small and much faster executable than you can with Python, and sometimes that matters, *and* you're much more employable after adding C++.
With all the plug-ins, you can turn Sublime into an awesome, productive tool. 
Have you heard of PyPy STM ? http://pypy.org/tmdonate2.html
I use notepad++ at work, and I flirted with using sublime, but I think I need more of a convincer. What plugins would you recommend? Cheers dude.
&gt; PyPy basically says "C is lame, we will be faster, who uses numpy anyway" which is, lets say, a bold claim. That's not true, PyPy is just incompatible/slow with the C extension API, if the C API was more implementation independent, PyPy would be fine with it.
Given the title, I would probably prefer if it focused on teaching the basics of Python in a newbie-friendly way rather than trying to be a language reference as well. I'm not really sure how to take your second question. Suggesting that one book should be more focused does not in any way imply that I think other books couldn't or shouldn't focus on different topics. I'm not sure how you could read my post and come away with that impression. Edit: Sorry if that sounded a little defensive, the question just struck me as weird. I don't have any problem with multiple books filling the space that "Learning Python" currently occupies. I think that it's unlikely that you could take "Learning Python" and split it or rework it somehow to produce two or three better or more useful books without essentially rewriting the whole thing. I hope that clears things up.
"concerted" is the key word. There's been a ton of effort, but none of it took into account the competing values of single threaded performance and parallelism -- not to mention attempts such as STM might be considered so complex that the community isn't willing to accept it. My point is that a large amount of sophisticated technical work has been done with 0 results because they failed to take into account the bigger picture of competing social problems (performance, complexity, backward compatibility, etc).
You could simplify that to def N(n): if n == 0: return 1 else: return 4 * n + N(n - 1) or you could use the closed form: def N(n): return 1 + 2 * n * (n + 1) EDIT: I discovered the closed form by mucking about in [WolframAlpha](https://www.wolframalpha.com/input/?i=f%28n%29+%3D+4+*+n+%2B+f%28n-1%29).
Post a job on python.org/jobs
aha - I knew there had to be a simple closed form non-recursive answer Thanks! Wolfram alpha saves the day again
This completely glosses over the collaborative/group project benefits, as well, but again those will come to you naturally in time. Just focus on the simple "I can go back in time" aspect for now.
I have and sounds nice. But until pypy is actually working fine in that regard, I'll just use some other language that already works fine for what I need. I'll still use python for other things though.
http://c.learncodethehardway.org/book/
Sounds like something to write a patch for. I might even do it myself (about time I actually contributed to CPython). On the other hand, I'll probably forget.
Hah, we learn something new everyday. I knew most of these but I still managed to learn a few new things about Python 3 with this. Did not know about the rounding behavior, for example.
This is why Python is a good first language; you *should* hate C++.
Just to clarify, I'm not suggesting that there's some type checking on arguments `a` and `b`. Maybe you were expecting `self` and `radius`, with optional `angle`, but you were just sending `angle`. The failed function call would immediately remind you, with no need to check the docs or call for help. I have the time to contribute this myself, and I would love to. I just think that maybe there's some obvious reason why it's not done (maybe inspect is actually a horribly taxing call, even if called only on errors? maybe a lot of underlying processes cannot be inspected?)
I've seen a lot of hate for every low-level language I know of. Are there any that *aren't* hated on?
You should learn both git and mercurial. And specifically learn how to do local feature branching in both systems. They are very alike and vet different at the same time. But invaluable if you are working on a big project. 
Guido says his second favorite language is C. Edit for source: [here](http://www.youtube.com/watch?v=ugqu10JV7dk&amp;t=101m30s)
I'm not disagreeing. If I were a Python dev, I would want to make a clean break from Python 2 and develop new innovations in Python 3. Backward compatibility sucks for keeping a language clean and efficient. And that's what they did, and now the core Python community is talking about all the great things Python 3 can do. But that is naturally going to put off folks who manage production code bases in Python 2. Those people, who otherwise love Python, get the shaft. It's very hard for them to justify the risk and cost of upgrading working code. So if you're going to promote Python 3, you have to be a bit sensitive to the fact that a lot of Python users are going to say "that's great, but it doesn't benefit me at all." My take on this is that Python 3 proponents have to stop pushing Python 3 on people. And pushy is how it comes across. Everyone has to weigh the costs/benefits of moving to Python 3 for their own purposes. Some speaker at pycon, no matter how authoritative, does not have a valid say over whether I should port my code from 2 to 3. If you want people to do something, don't tell them to do it, make it as easy as possible (e.g. 2to3.py), and then let them decide if/when to do it.
Well, the obvious answer is making that block of code *really fast*, and probably using much less memory in the process. Irrelevant for most tasks, but absolutely vital for others. Another good example is true multithreading...not an option for any python interpreter with a GIL. A third answer, related to the first, is for low level systems programming where you might simply not have the memory or processing power to run something like python.
Why are people surprised/angry that Python 3 is not fully backwards-compatible? Breaking API changes are what major versions represent according to [semver](http://semver.org/). angular.js 2.0 is coming out later this year and I expect I'll have to modify my projects to switch. Using `__future__` now can save you a lot of time later when you decide to move to Python 3.
For what you describe, git + github.com is ideal. IMHO
Git is excellent but I recommend you look at mercurial instead. It's very similar to git, but many consider it to have a much more intuitive command set. As for whether it's worthwhile -- definitely, yes. Even as a solo developer, a VCS can help you organize and isolate your changes, and a DVCS like git or mercurial are great for coding on the go. edit: For hosting, bitbucket.org supports both git and mercurial and allows unlimited private repositories. github.com only supports git.
I wouldn't say those are the key differences between pythons, just key points in upgrading a codebase. For instance, syntax for keyword-only arguments and exception chaining are key additions but don't belong on that list.
(value_if_false, value_if_true)[condition]
Let's go back to the beginning. What is involved in learning how to program?... Let me try to list things in order of required understanding (i.e. need to understand step 1 before going to step 2) 1. Learning to write down instructions in a precise way. Computers do not forgive syntactic errors. Thus, having a programming language which is easy to proofread is really helpful. Python, which uses much fewer non-alphabetic symbols is easy to read which makes it great from this point of view, much better than C++ 2. Learning how to group often-repeated lines of code into some "structure". Here again, Python has simple functions. 3. Learning how computers can make decisions and repetitions i.e. control flow (if/elif/else, while and for loops). Here again, Python's constructions are easy to learn and easy to proofread. 4. Learning how to **use** basic data structures. Python is great in that respect with built-in lists, tuples and dict ... one could even consider strings (as a collection of more basic "char" variables) in that category. There is a lot more to learn from that point on (e.g. how to create your own data structures, etc.) but these 4 general ideas/concept can be a huge stumbling blocks for beginners. Python's syntax (and Ruby's and other similar languages) make learning these concepts much easier. As you wrote yourself, Python "spoiled" you and you are frustrated now ... imagine going back to step 1 above (learning the syntax and avoiding typos) as a complete beginner, starting with C++: how frustrated would you have been then? ... I suspect that you would have been much more likely to feel like quitting than you ever had as you started with Python.
I would argue that an IDE is unnecessary for learning, or even building fairly complex applications in Python.
Cool, how does it compare with Octopress or Pelican ?
My opinion is that my opinion does not matter. To quote Raymond Hettinger, "Python is Guido's language. He happens to be letting you use it, but it's his."
I don't want to discourage you or anything, but if semicolons and static typing are the worst things about c++ you've seen so far... hoo boy, you ain't seen nothing yet.
I agree, but if OP is jumping into Kivy he's starting to build projects- and version control is incredibly helpful for GUI projects, especially as a beginner to GUI.
I use Eclipse with PyDev. It runs on Java so it's cross platform and fully free. I use GIT for code management and EGIT is also a nice plugin to have on Eclipse. I recently started using PTVS (Python Tools for Visual Studio) and it has a few cool tools. However, it is a big download. 
Define 'bloated'.
git+github or git+bitbucket, or mercurial+bitbucket &gt; would git make that easier? Yes. Yes it would.
I just built a Python app that required sifting through a bunch of old .dbf files. I used [this](https://pypi.python.org/pypi/dbfpy/2.2.0) module called dbfpy. It worked like a charm, and with very little hassle. Let me know if you need any help! 
I would expect the TypeError to say `TypeError: grader() was provided "score", "max_score", and "class_max", but required argument "student_age" was missing` Without typing it's impossible for Python to know which argument goes where, but given a simple # of required args mismatch, the error should tell me what it expected in terms of argument names. I can easily check to see if what I provided makes sense (in your example "oh, the THIRD argument I'm providing is the age, and it should be the fourth").
Well, balls.
♬sounds like sooomebodyyy needs to uuuupgradeeee♬
If you like simple GUIs try GNU Bazaar (Canonical sponsored)
err.... https://docs.python.org/3.4/library/functools.html
Stick with IDLE while you're learning. Adding a full-fledged IDE at the same time will just lead to frustration and disappointment. 
Clearly wasted effort on my part.
Why bother trolling if you are going to do such a bad job of it. Take some pride in your work.
Any plans for python 3 support?
php? lol lol php /r/lolphp QED
That's **single** dispatch. Says so right in the name, even.
You missed your bottom boundary by a pixel I think, the snake can override with the bottom border line.
I would like to see that too!
And Canonical abandoned now
What's your goal? What do you mean by "get serious" with creating GUIs? Why have you defaulted to Kivy or PyQt merely because you "never really invested a lot of time in" other widget toolkits? That doesn' make any sense.
&gt;But from what I gathered Qt lacks the cross platform functionality of Kivy Um, say what???!!! Qt supports the same platforms kivy does and has been around longer. See this link (http://blog.qt.digia.com/blog/2014/05/20/qt-5-3-released/) for a quick read of the latest version of Qt However unlike Kivy, Qt isnt a pure python GUI library (its C++ based) but has python wrapper libraries: * PyQt (http://www.riverbankcomputing.co.uk/software/pyqt/intro) * PySide (http://qt-project.org/wiki/PySide) 
C and python have some similarish features so it makes sense. Example: Struct members are always public, and you can create functions that take a struct pointer as the first param and you basically have Python style classes (not exactly but still you have an explicit `this`). I think C is a better language than C++, if nothing else it just works better with systems code and the C++ class definitions are filled with gotchas.
As a kivy developer, I'd say...it doesn't matter! Both are great toolkits that can do awesome things, but they are very different in some ways including having quite different focuses. If you have some specific goal then one or the other might be better (e.g. android app -&gt; kivy, highly integrated desktop app -&gt; qt), but other than that I think it's most important to just pick a project and framework and dive in. You can always learn the other (or any other framework) later, but right now there's nothing to be gained from agonising over the decision.
Just wrote this post after seeing the OP: http://jugad2.blogspot.in/2014/05/another-simple-python-debugging-function.html 
I didn't say that I gathered much I just scanned the PyQt wiki for "android" and saw it wasnt there, unlike the Kivy wiki
Well, I misremembered. Sorry
Qt is a pain in the ass to port to android though. From my experience.
Really? What were your issues? 
Will this run on heroku?
This actually makes more sense than anytime else I've tried reading. Two questions: 1. If I'm using git and not GitHub, what's the difference? Where do my files go using only git? 2. I know I've read some things about not including all files in your initial commit. What files should exclude? And once they are excluded, do I have to keep excluding them with every commit or is it set it and forget it?
Darn. I was hoping you were right and I'd missed something. ;-)
While I skimmed the article, I kept thinking, "Hmmm, someone hasn't upgraded to Python 3.x..."
1) With Git, all your files and revisions live in the .git folder that is created during `git init`. Some copy also exists in the root folder itself, which is the code you have checked out and are working on. Github is just a website that mirrors your .git folder for easy collaboration. 2) As a general rule, add all files that cannot be generated and exclude all those that can be. For example, documentation extracted from your source files with javadoc can easily be generated, and so does not need to live in got. To ignore files, create a .gitignore file (which you may or may not add to git itself) and enter one ignored file per line. You can also add directories and file globs, e.g. `*.pyc` to ignore files generated by the Python interpreter. Files in the .gitignore file can still be added manually to got, it just won't nag you about them.
As far as I know, this isn't possible with Windows' *cmd.exe*. Perhaps Powershell has something similar?
I don't remember exactly.There was one tutorial of how to port over a project they made for you. I followed it and it worked. When it came time to port my project over I had no idea how to get it to work. There were so many compiling errors that I couldn't resolve. I gave up and started with kivy. I am so glad. Qt was created before android so it's no wonder it is hard to port over. Kivy was developed after android with android in mind. 
&gt;1. If I'm using git and not GitHub, what's the difference? Where do my files go using only git? With git, your files are all stored in your local repository, which is in the .git directory under your working tree. This is true whether you use GitHub or not. &gt;2. I know I've read some things about not including all files in your initial commit. What files should exclude? And once they are excluded, do I have to keep excluding them with every commit or is it set it and forget it? You normally have to include files explicitly. There is a .gitignore file you can use to exclude files when you add entire directories. [This](https://github.com/github/gitignore/blob/master/Python.gitignore) is the default GitHub .gitignore file for Python projects. It's a good place to start. Basically, don't include files that get rebuilt (.pyc files, etc) or temporary files. 
&gt;I wanted to try a low-level language, so I tried C++. C++ is *NOT* a low-level language. It is a high-level language that allows you to operate with low-level features if you want (pointers, memory mgmt, etc.). Anything with classes, structs, inheritance, polymorphism, etc., is a high-level language. The level of abstraction is what makes it high or low level. I think you may be getting confused about high/low level because C++ is *statically typed* - meaning you declare your datatypes when creating an instance. This does not make it low-level. Python is *dynamically typed* - meaning that the interpreter will figure out your datatypes during runtime. But they are both high-level. You have to go to C or Assembly to get low-level. 
I personally tend to keep my .gitignore file in the repository, and adding it is typically my first commit.
Difference is the repository is local vs remote. If it's local, the files still stay in the folder you ran git --init on (under .git). Remote is nice for backups and sharing code easily. If you're working in python, exclude .pyc. If you're working in an IDE, it can also create files that you don't really want stored in your repository (like I don't want my .iml files, or the .pj files, or for my pytest stuff I don't want any pytest_report directories included). Excludes tend to be pattern based, but that works if you're trying to exclude a specific file. Just to clarify, there is the .gitignore which ignores based on patterns. For what you're committing first off, commit all your source files, don't worry too much about it. 
I agree with this statement. I've used Qt for desktop development and it's *really* nice and I have no complaints. Recently decided to port it over to Android and quickly changed my mind. It's a mess. Maybe if I had originally planned to make an android port, it would have worked better, but now I'm going to use options like Kivy instead.
Are these modules other peoples packages? Usually people release their libraries as installable python packages. When I provide my software to others I create a python package (setup.py, etc) and then include these non-standard modules as dependencies. When people install python packages (via pip) the dependencies are automatically downloaded and installed. Virtualenv is another thing to look into if this is new to you. Edit: I will add that if your code layout is fairly simple, your other modules are one or 2 files, and packaging is overkill then you should just be able to do something like this: my_package/ __init__.py do_stuff.py deps/ __init__.py my_dep.py Then in do_stuff.py you would say "from deps.my_dep import dep_func". That should work.
man of few words eh ?
I rather think jobs come to the "experts"
I'm trying to decide between CherryPy and Flask --- Never worked with any framework before, been away from web dev for a long time
If you’d like a very clear explanation of version control systems, check out [this free book](http://www.ericsink.com/vcbe/). Thanks to reading that book, I’ve always had an intuitive grasp on concepts others find harder to understand, like branching. I mainly use Mercurial. I like it much much more than Git, but Git seems to be the one you have to learn to get along with nowadays. Both have chapters in that book.
I learned Mercurial with [this free ebook](http://www.ericsink.com/vcbe/). It explained it clearly enough to me that its use is totally intuitive. I think it’s important to take into account the difficulties you’ll avoid when using a VCS, even as a beginner. Breaking your own project with no way to fix it can be one of the most frustrating problems for a beginner.
Yeah. Basically, I might make a series of web related functions using the requests modules. I'd need to make sure that requests gets installed. I might make programs for Mac and Linux users who are not technically inclined and would not want to manually install pip and modules. They should be able to download a program and have it "just work." I could call files manually, but some modules have many files. If there's a central file that can be imported once, that would work.
I disagree. OP is comfortable with `bash`, so I anticipate that learning `git` is not going to require mental gymnastics on his part. It's too useful to put off. It's like raising kids: if they're interested enough to ask questions, then take advantage of that momentum and run with it! Of course, you have to walk before you can run, but `git` is very well suited to taking baby steps. Edit: Also, OP, since you're a `bash` and Linux guy interested in version control, let me introduce you to the [dotfiles repository](http://dotfiles.github.io/) concept. Using a tool like [homeshick](https://github.com/andsens/homeshick) makes this all very much easier. *Your life will never again be the same.* Now that the scales have fallen from your eyes and you have seen the light, go forth and make disciples of all interwebs!
&gt; Common Mistake #1: Misusing expressions as defaults for function arguments Am I the only one who much prefers just *"Mutable Default Arguments"* ? Then again I'm somewhat of a minimalist.
RHEL compatiblity is the reason my employer packages a python interpreter as a custom RPM. In our case, it's currently packaging 2.5, 2.6.9 and 2.7.6 for RHEL 3 to 6 but the point stands and this could be done for python 3 as well. So you can ship your own if you need to. Since we had RHEL 3 as an official supported platform until recently, we had to do that to avoid 2.2 *shudder*
Check out the [Python Packaging Tutorial](https://packaging.python.org/en/latest/tutorial.html#creating-your-own-project) for information on how to make this into a package people can automatically install with pip.
Would be nice if the [quickstart](http://urubu-quickstart.jandecaluwe.com/) had instructions. Looks neat but c'mon
Direct link to [`functools.lru_cache()`](https://docs.python.org/3.4/library/functools.html#functools.lru_cache).
Git is a great tool. I recommend it. Github and Bitbucket are both great repository hosting sites. 
You're assuming there is no overhead, which is wrong. All `lookupCheck` contains is a single call to a C function, while `bruteForceCheck` has a lot of Python code (which is slower due to invisible type checks and other stuff.) There's also the fact that checking whether two numbers are equal is obviously going to be faster than calculating a remainder. That's why algorithmic complexity of algorithms (i.e. the number of operations an algorithm needs to do) is normally written as `O(something)`, e.g. `O(n*sqrt(n))`, not just `n*sqrt(n)`; that `O` means "less or equal to that number *multiplied by an unknown constant*". Also, you should probably brush up on data structures - lists are not optimized for fast search, [sets](https://docs.python.org/3.4/library/stdtypes.html#set) are.
I use Pandoc for stuff like this, just use fenced code blocks: ```python print('Hello world') ```
Don't mess with hettinger: http://code.activestate.com/recipes/578078-py26-and-py30-backport-of-python-33s-lru-cache/
Use both. Both Python and Java have their own strengths and weaknesses but if you're doing it right you can gain the strengths of one and mitigate the weaknesses of another. The cost is you have to be better at what you do. Instead of hiring "Java developers" you start looking for generally talented individuals. Anecdotally - I've been using Java and Python (along with some other technologies, ZeroMQ for example) very successfully and have built a software stack that is capable of scaling out, up, and does continuous deployment as a matter of course.
Oh nice alternative, didn't know that! Thanks! I assume it also works with other programming languages? Does it have auto guessing? And if so, can it be easily turned off? Because sometimes I want to show certain code blocks without syntax coloring... Have to look how codehilite can handle that ...
This is perfect, thank you.
I've just taken a quick look into that and it seems that [Crammit](https://github.com/rspivak/crammit), which is one of the dependencies, does not work on Python 3 yet. That being said, I will definitely do a bit more research on this. It would be a shame not supporting Python 3 since the whole thing is a mere 200 lines of code.
To be perfectly honest, those two seems to blow it out of the water, feature-wise. Pelican also has: * reStructuredText and AsciiDoc support * interface with distributed version control systems and web hooks * articles in multiple languages * atom/RSS feeds * import from WordPress, Dotclear, or RSS feeds while Octopress offers: * easy deployment strategy using Github pages or Rsync * built in support for POW and Rack servers * easy theming with Compass and Sass On the other hand, the reason I didn't include any of these features was because I didn't need any of them for my own usage. I guess it's part of it being really simple.
# **My advice** Do it, but don't share it unless you feel confident in charging for your time. Otherwise you will work for free for a long time. "But I get to learn!"... Yeah, but your time is also very valuable. # **Where to start:** - https://docs.python.org/3/library/index.html - https://docs.python.org/3/reference/index.html
http://urubu-quickstart.jandecaluwe.com/start.html
List is not a good structure for this. Set should be faster. &gt; The amount of logic tests that have to be conducted for brute force in mathematical terms: Sum from n = 0..100 000: sqrt(n). Which is 21 081 693 tests. It's less. You're breaking out of the loop as soon as you find a divisor, so for example, for every even number only the first iteration is executed. The lookup version walks the whole list, always.
&gt; When sorting, use key instead of cmp Didn't notice this one.
I’ll keep using pelican for now, but will keep an eye on this project.
Thing with C++ is that it is statically typed, but it's type system is not that good. Look into Haskell or Scala to understand benefits of type systems. If you just want performance, golang is pretty good here, not as fast as C++, but much easier to use. Thing that you are asking about, low-level language: none of these above are low-level. Programming languages are designed for humans, so we can express our ideas better and have easy time when communicating them with other programmers. Real low level languages are exposing metal, and it is mostly to get maximum performance. Goal is usually not for low-level language to be generally nice to use, but to make it easier to write programs in way that is closest to how computers work currently. 
This depends on the shell. Bash (the shell in macs, taken from GNU) does expand wildcards to a list of files. All/nearly all linux shells do this as well. cmd.exe doesn't.
Thank you for the advice. I do agree with this for my current school. However I am more interested in solving a real world problem that I see in schools. If nothing else it would be good for my own personal learning and a resume builder. Most of the tutorials I've worked through are for straight forward type problems. The problem I think here is the idea of creating various combinations and either letting the program decide which would be good or a person decide which is good. I do use the docs often when I'm problem solving, but I guess I'm wondering potential routes of completing the solution. Maybe starting off by making a scheduler that isn't concerned about all the different special cases, and then build in the special cases. Then this goes into working on an algorithm to sort the items in a particular way.
Or use memcache - now your cache is distributed :)
Yes, unless you can actually say *exactly* what you want included in a Python 2.8, calling for it is a wasted effort. People who call for a Python 2.8 often seem to just assume that not only can they demand that somebody else does the job, but also that these people haven't already considered a 2.8 seriously. 
Yes, strictly speaking you are correct.
No, obviously all languages have their detractors. C++ just gets a lot because the additions to C are complex and kinda ugly. It's a massive language that is hard to use with tons of pitfalls. But it *is* a sort of semi-portable object oriented assembler, so, I guess that goes with the territory.
&gt; So the problems with Python3 adoption are caused by something else or don't exist? The slow Python 3 adaptation is NOT because dict.iteritems() is gone, no. &gt; That's an interesting question, now that I think about it. I guess a dirty hack to make such objects present different methods to code compiled with that from __future__ import. Right, what is the future import supposed to do? Have different dict types? Make the type behave differently in that specific module? (That's tricky at best.) The only option there was really to change the behavior of dict values, and hence break backwards compatibility. This is one of the changes that can't be done in a good backwards compatible way. 
But you then reasonably think that there should ALSO be a Language reference. And that would then be two books. :-) You ARE saying that "Learning Python" is trying to do the job of two books at once time. This *does* mean that you are answering "Yes" on OP's question. But you insist in answering "no". This is funny to me. :-) Note that OP's question is not "should it be rewritten", but "should it have been". That's a hypothetical question about the past. 
Oh! A Troll! And I missed it!
&gt;&gt; Long running Python jobs that consume a lot of memory while running may not return that memory to the operating system until the process actually terminates, even if everything is garbage collected properly. That was news to me, but it’s true. What this means is that processes that do need to use a lot of memory will exhibit a “high water” behavior, where they remain forever at the level of memory usage that they required at their peak. https://docs.python.org/2/reference/simple_stmts.html#the-del-statement https://docs.python.org/2/library/gc.html#gc.collect &gt;A way to get around this is to fork child processes that are short lived and that do not keep large complex objects around for the life of the parent process. +1 &gt;In addition, I would *not* recommend using threads for concurrent middleware when writing in Python since you can't compartmentalize its memory consumption to the life of the thread (this was my theory as to why I chose not to use threads, though I don't have proof of this behavior in the wild). This is why cgroups exist at the OS level. &gt;After working with messaging and middleware for a few years now, I would recommend using ZeroMQ (if you don't want/need to run a broker) or ActiveMQ (if you need a broker, which it seems like at the enterprise level you might). While fast, 0mq does not solve for reliable delivery or transport security.
You just said that it is bad to fix mistakes in a language. That is a position that I do not find even worthy to spend time to argue against. I will just let you simmer in your own shame for a while. Your example of apply() is particularly crappy, as it is a function that serves no purpose and has been deprecated for ages, and, whaddayouknow, it even throws a deprecation warning (if you enable them). 
My employer pays for commercial support from one of these small shops, and while they don't do language development they provide much more than "open source packages they're working on". I work in science/engineering where MATLAB is #1 and Python is #2.
If you want to make mobile apps then kivy otherwise qt.
On Macs, this is done by the terminal, not by Python. On Windows, you can use [glob](https://docs.python.org/3.4/library/glob.html) to do the same thing manually: import glob arguments = ['data*.html'] files = [x for arg in arguments for x in glob.iglob(arg)]
Sure, I never said Python wasn't a small section of the software space. However, I would not attribute this to the language not being commercially developed - look at C, C++, javascript. And honestly, PHP.
Also, WTF? I get 78K for java and 29K for python, 35K for C#, 35K for C++
Reading the first answer was a very humbling experience. 
Good stuff. If I'm honest, only a few of those would bite me and my python code and the changes would be trivial (being mostly selecting the forward compatible variant available in python 2.7). What's all the fuss about then? Am I just not a power python user?
So, GIL?
Damn, the accepted answer went down the rabbit hole _fast_.
This one even comes with tests https://pypi.python.org/pypi/repoze.lru
Works much faster as a set instead of a list. I modified the loadLookup to generate a set (based off a list of primes I found online, I didn't see the CSV included). **Modified code** _lookup = set() ... def loadLookup(self): with open("primes.txt", "r+") as prime_file: self._lookup = set((int(x) for x in prime_file.readlines())) **Output** From brute force: time: 0.464555 seconds primes: 9592 ----- From lookup table: time: 0.035472 seconds primes: 9592 List of primes downloaded from [mathisfun.com](http://www.mathsisfun.com/numbers/prime-number-lists.html) Edit: As another note, do a Ctrl+F on semi-colons, don't need those in python. Edit 2: Take it up to a million to really see the time difference. **Output** From brute force: time: 12.328389 seconds primes: 78498 ----- From lookup table: time: 0.416160 seconds primes: 78498 One last thing, don't use lists to pass in data like that. Either pass it in as a tuple or just have two separate variables. def bruteForceCount(self, start=0, stop=1000000): ... for i in range(start, stop): 
Aye, I need to get an hour to really reread it but he definitely went a lot further into it than I would have given the time to.
On tuple unpacking, doesn't python 3 support * to unpack a list, at least for certain situations? https://docs.python.org/3/reference/simple_stmts.html#assignment-statements I saw no mention of this in the article. a, *b = [1, 2, 3, 4, 5, 6, 7, 8] &gt;&gt;&gt; a 1 &gt;&gt;&gt; b [2, 3, 4, 5, 6, 7, 8] edit: It's defined in PEP 3132.
Hehe, amazing what kind of things add overhead in an interpreted language... *comprehensions*, which are basically just syntax sugar... :x
I loved his use of dis.dis to observe the immediate additional instructions. I think it's time to research and acquaint myself with dis.. :)
Thanks, I will have to watch out for the precision bug.
One big reason is probably that lists are actually using an iterator which means that an iteration step is a pointer bump plus length check whereas strings do not have an iterator and instead are constant offset calculations from the start and also require putting a box around.
I've started using tuples more heavily instead of lists for constants. I think it also helps with memory, but I'm not sure.
Added link to book site here http://py3readiness.org :)
Have you thought of creating a lookup from a sieve? Create a lookup where every number is prime then starting at 2 go through and mark every multiple of 2 not prime. Then use 3, and mark every multiple as not prime. etc etc Uses more memory but is usually the fastest way to create a lookup table.
This is great. Thanks for this. @jandecaluwe how does one specify the columns of information under the jumbotron in the home page. Is that simply coding the appropriate html in the home template? or have you already provided some other mechanism ?
Take a look at [SchoolTool](http://schooltool.org/) and note that it is written in Python and uses Zope.
&gt; The GPL only requires licensing derivative works if the code of the derivative work is distributed. Define "distributed". Does hosting my codebase on Github constitute distribution? How about sending it to Heroku to host it? What if I hire a developer to work on it, does their having a copy of the code to do their job constitute distribution? What if someone *steals* my code and releases? For GPL-licensed code, would distribution via theft require that I release the entire codebase? Note that the above arguments are not mine, but were the ones I was confronted with by corporate legal at a large company, when I was planning to use GPL-licensed libraries in production. As far as I know, none of them have been answered by a US court.
I generally release code under the most permissive license available - generally MIT, BSD or CC0, depending on what other contributors might want. I also happily issue specific licenses upon request - so if you *need* a GPL-license for my code, I'll happily provide it. I don't like the GPL on philosophical grounds, as I am opposed to the legal concept of intellectual property. The GPL attempts to improve freedom within our community by using the same mechanism that was used to restrict it. That strikes me as wrong. That said, the Free Software movement (RMS, et. al.) has been effective in doing what they set out to do, so please don't take my own objections to the concept as minimizing its impact on the world.
Buy Jeff's book. It is excellent and full of these kinds of tips. Source: Not Jeff. Happy customer. 
Why would you *refuse* to use a useful tool? Or did you mean "I don't bother to use git for small projects"? Personally I use version control for any code which I am going to work on for more than 30 minutes or so (100 lines of python code is not insignificant in my book). There is virtually no overhead and I have comfort in knowing I can rollback if I need to. 
He just posts the code as a conclusion. Just like &lt;code&gt; there you have it! Doesn't go into any actual analysis at all so it's not surprising you didn't understand.
According to sys.getsizeof, tuples are a smidgen smaller.
This. You don't have to learn git (though it's one of the better ones), but you absolutely should learn some form of version control if you're doing much more than programming textbook exercises.
You're definitely not the only person to think this. If you can give me hints on *how* to clarify it, I shall... ...maybe after exams, though :P.
Just the usual: People making a mountain out of a molehill.
Yes, strictly speaking this only list things that are backwards incompatible, and not new features.
Not a problem in the language, but in the implementation. Also not a big problem. Also crazy hard to solve.
You might be ok doing that with requests, but if you ever use a package that has some kind of extension (C or otherwise) then just providing the code won't be enough. You likely won't have one file to import. If the package is simple enough you could probably download the source tarball (.tar.gz), untar it (tar xzf file.tar.gz), and put that package's directory into your main code directory. Similar to my previous comment, but remove the "deps" directory and have one directory for every dependency (that you get from the tarball). This again might be overkill, but another solution might be to have them use Anaconda or a similar (all-in-one) python environment and then have them run your code. This is more important in the scientific community where you have a lot of C/Fortran/File-Format libraries to install. Edit: my_package/ main_script.py requests/ ... code from downloaded requests tarball ... This way in "main_script.py" you should be able to do the normal "import requests". Note that I'm just guessing that this will work, no idea if it will. I'm still going to suggest that if your code gets any more involved you switch to packaging, etc. 
Thanks, i'll take a look at sets. 
I'm assuming you're referring to these [htmlmin](https://github.com/mankyd/htmlmin/) and [cssmin](https://github.com/zacharyvoase/cssmin). The later seems to no longer be maintained, but I will definitely look into htmlmin because I was really curious to see what kind of difference it would make to minify the html as well. As for the plugin system, I didn't really think about it, but I guess it could be pretty useful, so thank you.
I did, but in a different way. I tried to make the lookup function check for divisors in the prime array. If it has no prime divisors, than it must be prime itself. But it turned out 3 times slower than just comparing to all values in the list.
How would I fix a bug in that code? Even if I understood the characters (which I don't), I'd need a means of entering them on my keyboard (which I don't have). By all means, use whichever characters you want in string literals and comments. But by keeping identifiers down to a sane minimum set, you ensure global compatibility. I have the same objections to i18n domain names.
Sorry for the semicolons, i'm used to it because i used to do a lot of php, and because they don't generate an error i always have to strip them off in the end. I should've included the csv, i figured that if anyone wanted it they could use the save() method. Why is it wrong to use a list for passing in data? Are lists really so inefficient that they mess up with just two values or is there another reason?
good point!
I hear ya, for me it was brackets, luckily it fails on those lol. Avoiding list has nothing to do with speed (it might actually be faster?), more is just unpythonic and could be dangerous. It's very easy for others to identify what needs to go into a function if you just have named variables. Also if you ever accidentally make a default value for a function mutable it can [lead to problems](http://www.toptal.com/python/top-10-mistakes-that-python-programmers-make). Also when passing a list in the reference to the object is [pointed to, not recreated like variables,](https://www.inkling.com/read/learning-python-mark-lutz-4th/chapter-18/argument-passing-basics) meaning changes to it will change the original object, still being used on the larger scope. In your code currently you are modifying it in anyway, so no danger there, just wanted to give a heads up :) 
Thanks for a very well researched article. I saw only a couple of places for improvement/correction: 1. the `apply` function was removed because it was replaced by the more flexible list comprehension; 2. the result of integer division with the `/` operator is always a float type even when the result is a whole number.
You may switch to [webassets](https://github.com/miracle2k/webassets) for managing jss and css. According to [this](https://github.com/miracle2k/webassets/issues/194) discussion on Github, the package supports Python3 now.
Even better, use a generator expression and get the same result. if any(needle.endswith(e) for e in ('ly', 'ed', 'ing', 'ers')): print('Is valid') else: print('Invalid') Also /u/sweettuse has the correct answer, so I'm merely pointing out that generating a list then checking isn't as elegant as creating a generator.
PyCharm is the first rich IDE that made me move away from emacs for my daily development tasks. I had to work with Eclipse at work and it was pain. Even though pydev is rich and powerful, the underlying Eclipse platform felt slow, unresponsive andon the verge to break if I moved too fast. Pycharm seduced me right away and I switched to it quite happily. At home, I still use emacs but it's mostly an habit.
It's not an article, it's a book. :-) In point 1 I don't see what you mean. But you are right about point 2, that's a mistake that snuck in. Will fix in the next release.
Nothing to do with virtualenv, whatsoever. When they say "Create and configure lightweight, reproducible, and portable development environments", they mean virtual machines. And it's totally bad-ass.
And it's great.
Yeah, only paid version has Django support.
1.) you can enter mandarin characters on a QWERTY keyboard, I'll leave the proof of which to the reader as an exercise 七点 2.) you want the whole rest of the world to learn English just because you may have to debug someone else's code?
Oops! Was someone a little too quick to push the "post" button on his blog?
Sorry, in my first point I was confusing `apply` for `map` which can be replaced by a list comprension. Please disregard point 1.
Was going to say that as well. One, less unneeded clutter, two it doesn't have to build a list in memory, and three this way any() can short-circuit.
Pycharm in my mind is the by far the best IDE for python and specifically django development for me. I still use emacs for smaller python scripts but whenever I have a medium-sized project with a virtualenv/vagrant setup, project overview, vcs etc pycharm just have too many features hels me being productive.
I'm pretty much the same as you. I still use Emacs for quick n' dirty stuff, command line stuff and as a file browser and editor of random weird files. But for my main Python+JS development, it's PyCharm. The debugging experience is a little smoother in PTVS (Visual Studio) but PyCharm beats it in most other respects.
Vagrant create a virtual machine where the whole virtual machine actually may be setup to include python versions and libraries in the same way as a virtualenv may. But on top of this also any applications such as web-servers, databases or OS-based libraries may be installed isolated in the vagrant environment instead of in your own environment. 
Just tried it, bug continues. I think the issue is that when I x out of the gui, it completely terminates the parent process, and thus the "finally" is never executed. I might just try a workaround and just use a system call to execute the cpp program and read from stdout.
I wonder if [this page](http://stackoverflow.com/questions/110923/how-do-i-end-a-python-tkinter-program) will help?
They've finally fixed some long-standing issues with PyQt, although http://youtrack.jetbrains.com/issue/PY-4299 is still open :( Whatever, I've just renewed my personal license; even with a few warts, it's still the best cross-platform Python IDE out there.
Out of curiosity, is this script available?
1. I'm not saying it can't be done. But by default, a large percentage of the world's population won't be able to do it. By default, pretty much the entire population can enter ASCII characters. 2. If they're coding in python, they *already* have to know a minimum amount of English. Python's keywords are all English, for example. 
source?
I swear the free version anti-supports django. I think they've set up their automatic formatter to purposely fuck up django template tags.
&gt;a large percentage of the world's population won't be able to do it. This is not true. &gt; I'd need a means of entering them on my keyboard (which I don't have) You do have a means to enter them, you simply lack the skills required to do it. Why should everyone else have to conform to your lack of skills? &gt;If they're coding in python, they already have to know a minimum amount of English. That doesn't mean their variables have to be in English. if they create an object that describes a restaurant in their hometown, why should they have to give the object a name that **YOU** (with your deficient skill-set) can understand?
In Tkinter setup a handler for "WM_DELETE_WINDOW" and terminate the subprocess there. That may do it. Something like... def handle_close(): # terminate process here... ... # Hook up the event root.protocol("WM_DELETE_WINDOW", handle_close)
Threw this together real quick (the script I use is part of a much bigger module that requires tons of extra dependencies). Python file: http://cl.ly/code/3c2h1j2O1J0R You can invoke it manually like: python http.py http://google.com OR You can add a bash alias (assuming you're on OSX or Linux) like this: alias get="/Users/yourname/Scripts/http.py" So you can use a terminal command: get http://google.com &gt; page.html 
Exactly, you have good goals, just in my opinion bad ways to reach them. C++ is common, and I think main reason for it is that it is entrenched. Kind of like PHP and Javascript, lets use them because everyone uses them. (They both suck as languages) I do not want to be rude, but programming is so much more then syntax. Way you are currently going, you are turning yourself into code monkey. If you are coding only for a year, you are probably just starting to grasp why we have design patterns, why is clean/good code important and all other nice stuff. Learning C++ is easy, I learned it in 2 days. (That is what I thought at time). Thing is that you need to learn how to think in abstractions and how to be creative problem solver, and figure ways of organizing code to keep it maintainable. Learning Haskell or Scala might be of much more benefit, because it will show you alternate ways of thinking that can be applied in C++ world. And also you will see benefits of static typing. And if you know Python, and want to end up using C++, I strongly recommend that you first learn Haskell/Scala or similar, and I do not mean only syntax, but how to use all that power that language gives you. Then you can learn C, just syntax is fine. And only then C++. After all of that you will see why C++ is not "good" language. It can be used, and is used but that does not make it good. Also, if you want to live in professional world, in my experience C# and JAVA are much better choices than C++. I barely know each, but from what I can tell C# is better than JAVA as language. My personal thing is that I dislike politics of both, .NET being mainly Windows oriented, and somehow Oracle being steward in JAVA world rubs me wrong way. One more sidenote, if you did not even hear about Scala or golang (Google Go) you might want to read more about programming. Find some cool blogs/forums/groups and do a bit of reading. there is also /r/programming and some other nice subreddits. Just be vary of who and what do you trust on Internet, everything that I wrote here may be total bullshit. Read up on your own and reach your own conclusions! (I strongly believe that "my way" is better when compared to path you want to take and that many other programmers take, but I really dislike bad code, and that is becuase I have experience with PHP and javascript, and also I had boss who wrote so bad code, that even now I am wondering if he did it on purpose...)
Think of vagrant like spinning up an EC2 instance to develop on, but on your own computer. It's very useful if you have a bunch of people coding on different platforms - they can all have their own Linux box to develop on, configured to be identical right down to the OS level. If you work on OS X or Windows and an OS update has hosed your dev environment, or you've ever had to jump through hoops to install some OS-level package only to deploy and find it is subtly different on your servers, you should look at Vagrant.
I wish PyCharm was fast to load and responsive, I'd love it otherwise. It actually discourages me from coding because of how painful opening it is. Does anyone know how to stop it making http requests and what the point of skeletons are and why they take forever to be processed on startup?
Vagrant can be thought of as a thin layer over VirtualBox, which is a way to create and provision virtual machines. Vagrant makes it much easier to do this.
this doesn't work for me. i got any('feed'.endswith(e) for e in ('ly', 'ed')) Out[173]: &lt;generator object &lt;genexpr&gt; at 0x00000000163ACF30&gt; any(['feed'.endswith(e) for e in ('ly', 'ed')]) Out[174]: True i'm using python 2.7, btw edit: why the downvotes? i literally just pasted what the hell ipython spit out edit2: this is weird. it only does this if i run my ipython instance with the `--pylab` flag. 
[ipython](http://ipython.org/) is a very nice upgrade for your repl. for testing, I find the built in unittest module to be more than adequate for quite a lot of tasks, but sometimes a little sugar is nice to have. I've always enjoyed [Nose](https://nose.readthedocs.org/en/latest/) for making testing prettier and easier. pdb is my usual debugging tool. however, and this is important, I never use it without ALSO having test coverage for what I'm debugging. sometimes its actually much faster to just put print statements in the test code. pdb only gets used when something really strange is happening and I need to inspect the runtime environment in much more detail. this is infrequent. for small apps I find just plain old virtualenv to be a great tool. for more serious projects where I'm going to be deploying to a different environment than my local computer I like to use [Vagrant](http://www.vagrantup.com/) to create a virtual machine as my development environment. being able to have the development VM perfectly match the production environment is really useful. 
&gt; * Multiple carets and selections &gt; &gt; * Full debug support in the interactive Python console &gt; &gt; * New ‘Github’ color scheme for the PyCharm editor Count me in. Edit: Having used it for about an hour now, it all looks great. There's just one niggling point that I'm annoyed hasn't been improved in some way. So, you call `loop = asyncio.get_event_loop()` to get your event loop. The next thing you want to do with an event loop is generally use it. So you type in `loop.` and wait for the friendly list to pop up with `loop.run_until_complete` and the rest of your friends, but alas it never does. I understand that there's no easily accessible list of methods because of event loop selection, but I'm pretty sure there's a common subset of methods they could pull from the various event loops.
Automatic scheduling is fun, and is a very well studied problem. That being said, it's not a *simple* problem to solve. To get started, I'd look into [Preference-based Planning](http://en.wikipedia.org/wiki/Preference-based_planning).
Must be a python 2 issue, from the example on his page he is using python 3. In python 3.4 I get the following. In [1]: any('feed'.endswith(e) for e in ('ly', 'ed')) Out[1]: True In [2]: any('feed'.endswith(e) for e in ('ly', 'q')) Out[2]: False Even so, in this case you were correct in that you should use the tuple parameter, and my solution is just to point out that any works best with generators in similar situations, with the caveat that it must be 2.7.
Vim + Git + Python in the shell + Documentation in the browser was my setup for years. It never steered me wrong.
And here's a giant editorial with more details [Editorial 1.1: Another Step Forward for iOS Automation](http://www.macstories.net/reviews/editorial-1-1/).
Actually, I was mistaken, the clipboard stuff doesn't require any weird modules, I was thinking of my growl utility. Here's a version with the clipboard enabled: http://cl.ly/code/2s1M1P2S0H3T Invoke the same way as above, except don't pass the url as an argument (just make sure it's in your clipboard). Let me know if it doesn't work.
My workflow is far from perfect, but I'm pretty happy with it: I do most of my programming in Sublime 3 with the Flake8 plugin for linting and SublimeCodeIntel for basic autocomplete. For small edits, I'll often just make them in vim. For quick testing of code and experimentation I use bpython instead of the built-in python REPL. I never really got into ipython, and bpython adds just enough features to make interactive stuff nice. For testing I've recently switched from using the built-in unittest framework to nose. I'm not completely sure of that switch yet, but am definitely happy about the nose test-runner because it allows me to run coverage at the same time. I also run all of my code against pylint because it results in nicer code. While work currently limits me to 2.7, I run all of my code against 3.4 as well in the hopes that one day I can just switch over. I use brew's python installation instead of my Mac's built-in python (if only so I can pip install without needing to sudo). Embarrassingly, I'm not using virtualenv right now because I keep putting off learning how to use it.
I use git, pdb, and vim, but I am writing my own IDE, similar to vim (console based) for what concerns editing, completely written in python. I will release it when it's ready.
Yes, Vagrant is simply a nice wrapper to [VBoxManage](http://www.virtualbox.org/manual/ch08.html).
Just to clarify for OP: Vagrant sets up the virtual machine. To install python, libraries or other things on the virtual machine Vagrant uses provisioning frameworks like Puppet or Chef. However if Puppet or Chef are not your thing then you can also use shell scripts.
I use Eclipse with the PyDev addon. I'm totally spoiled by it, and I consider that a good thing. The difference between having and not having as-you-write syntax checking is comparable to the difference between having and not having to do your own memory management, at least in my opinion.
I work on a windows machine using cygwin. I was unable to configure cygwin's python interpreter in pycharm in previous versions. Any updates on that?
bpython (specifically the new [bpython-curtsies frontend](http://ballingt.com/2013/12/21/bpython-curtsies.html) for it) and [pudb](https://pypi.python.org/pypi/pudb) are some of my favorite tools. I mostly use vim with pyflakes and YouCompleteMe, and with hotkeys to send code to bpython, run the code, or run tests. Occasionally I'll fall back to [winpdb](http://winpdb.org/) for debugging something with threads or that takes over the terminal. I've purchased [dash](http://kapeli.com/dash) on [recommendation](https://news.ycombinator.com/item?id=7813043) from [a friend](https://twitter.com/FiloSottile), but it's not under my fingers enough that I always use it instead of a web browser for docs. I switched up to virtualenvwrapper from virtualenv when I started doing all my development in a Dropbox folder - I didn't want the dependencies syncing, and though I could have created the venvs somewhere else, it was once I decoupled projects and environments that virtualenvwrapper made sense for me. I probably ought to use an IDE for a while to learn what I'm missing - every time I see someone else's workflow I try to figure out how to get it in vim. A big advantage of an IDE is discoverability. Sometimes I start small projects with [doctests](https://docs.python.org/2/library/doctest.html) instead of unittest, but once a project gets a bit bigger I add doctests too, and try to restrict doctests to examples useful for documentation.
&gt; If that's the case, then would it be better to use Vagrant over virtualenv, vice versa, or what? In practice you should use both. Vagrant and virtualenv are designed to make devops easier for teams. Since devs in a team may have different operating systems and different versions of libraries installed. This makes testing a lot easier since devs can run an instance that is a lot like (if not exactly like) the production environment. Vagrant allows you to install and provision (install software and configure) an operating system in a virtual machine environment. Vagrant uses provision frameworks like Puppet or Chef to automate the provision process. Although it supports shell scripts if you prefer. Anisble is another Python provision framework that has gained lots of popularity. Virtualenv is designed to ensure that the python and its dependencies are localized to the application you are running. Some larger applications consists of independent applications that may use different versions of the same library or different versions of python. With virtualenv you don't have to worry about conflicting versions. Ideally virtualbox abstracts system software (like the web server, configuration of the system, etc.) and virtualenv abstracts the python libraries used by your application from the rest of the system.
How often do you need to open it?
That's probably because C++ is horrible. Learn C and assembler for a RISC architecture, MIPS is well suited here. Learning the basics of C is fairly easy and MIPS is simple enough that the entire language fits on a single page. Nevertheless understanding the relationship between the two will give you valuable insight into how stuff actually gets done. Apart from that having a basic understanding of C is in my opinion just as important as having an understanding in the languages usually advocated for other paradigms like Scheme but a lot more useful in practice, as you can use it to create bindings to libraries etc. Also keep in mind that Python is only simpler for the things you've tried, try doing embedded development, writing garbage collectors or kernels in Python ;)
Gvim, with a keybinding that runs the script in the vim console (F3 for 2.7, F4 for 3.4). Will probably work PDB into this workflow soon enough. I tried pycharm and hated it. I also used sublime text (which i still like a lot) for a while, but vim/gvim just always seemed above it all. Like playing on a Stradivarius. Also ipython for my REPL and code experementation. I do a lot of code experimentation, especially when I am learning frameworks. 
Awesome! Thanks :)
I'm using Sublime Text 2, sometimes Vim, GitHub for VC, Travis CI to run tests, this is new, I started to use this month and is very good. For debug I use print and pdb and it's very good for me. I never tried something like IPython, I just really like the good and old terminal with python, on Linux I use Gnome Terminal and when I'm on Windows I use PowerShell. The only thing that I miss sometimes is virtualenv, but I don't use so much libs, and most of then I include in my project.
An SSD would likely be a worthwhile investment for you. That and perhaps more memory. In the interim: when I was investigating pycharm I did some searching of /r/python and came across some good discussion of what can be disabled if you don't use it; resulting in better overall performance and load times. Although as a sibling commenter already alluded: I think most users like me just leave it open until rebooting for an OS or pycharm update ;)
PyCharm 3.4 and Anaconda 2 updates available.... Awesome!
Your first example works for me in Python 2.7.3
No prob!
Lack of **good** shell. Emphasis mine, although I hear PowerShell is pretty good, never used it yet myself.
confirmed: both pycharm and anaconda updated and life is good!
Are you able to elaborate on the problems you experience with kivy? How does it feel and look off? Are you having performance problems, or api problems, or both (or neither)? In general, kivy works fine for making apps for showing data, but there are certainly problems you may start to encounter with many widgets. These can sometimes be mitigated or entirely removed by structuring things differently or using some of the lower level tools available, but it really depends. I think there's certainly a lot of room to mature in that area! If nothing else, knowing more about your problems will help us target them better.
I just don't Python, cause you know.. Python is crap. LOL.
Awesome, can't wait for the new Pythonista!
I've never seen this before! Very cool. I'll have a look at this in more detail. Since it is open source I can look over the source code and see if I can build my own while using it as a guide. Thanks!
1) Think about it as having multiple copies of your repo. You can just have your repo locally, make commits there and get all the benefits of having a VCS, just without the ease of collaboration with others. When you start to use github you will push code remotely where other people can access it. Unless you want to make code available or have more than one person collaborating on a project then just having a local repo is enough. As for "where do they go" see chapter 2 here: http://git-scm.com/book/en/Git-Basics-Getting-a-Git-Repository and/or http://wildlyinaccurate.com/a-hackers-guide-to-git#repositories 2) You should only include files you want to version, i.e. edit and have the history of. For this reason files that are not of interest to other people e.g. some IDE-specific files, editor configs, debug log files, .pyc files, coverage reports, etc. To ignore them add them to the .gitignore. See http://git-scm.com/docs/gitignore 
No problemo. I've done similar things in the past, albeit not in the scheduling department. One of the downsides is that when you search you're almost definitely going to find more things about processor scheduling since that's what CS people tend to care about. 
I do mostly Linux development, but some projects are either deployed or partly developed on Windows. Often I've got ancillary Bash scripts that perform maintenance or packaging-related tasks. It's nice to be able to use them the same on Windows (with Cygwin) as Linux. Also, about to have a laptop that will have Windows as the primary OS, and I won't be able to install Linux on it, it will be nice to have those tools available so I don't miss having a good CLI.
I see you're already using dbfpy, but my DBFReader.py may be of use instead, if you don't have a lot of code to throw away. It's part of my xtopdf toolkit, but can be used standalone. There should be a sample program there that shows how to read the DBF headers (file and field headers) and the data records, separately. Calling that may work for you. https://bitbucket.org/vasudevram/xtopdf 
this is the fastest isprime function i can find def isPrime(n): """"precondition n is a nonnegative integer postcondition: return True if n is prime and False otherwise.""" if n &lt; 2: return False; if n == 2: return False; if n % 2 == 0: return False k = 3 while k*k &lt;= n: if n % k == 0: return False k += 2 return True 
Well, Powershell is pretty good. I could probably help you port your scripts.
Yeah, that's exactly the problem. (There *are*, however, other complaints that the types work differently, and you can no longer do texty things with encoded text.) Not allowing you to mix `bytes` and `strings` (or `unicode` and `str` in Py2 parlance) is a good thing. But Py3 takes its all-text-is-Unicode assumption too far. Instead of the core devs admitting that some things are `bytes` and there's nothing that can be done (command-line arguments, HTTP headers/URLs), they've instead decided that they must be coerced to Unicode instead, and the Unicode should be invalid if necessary. That way, Py3 doesn't blow up, but the developer's code does instead, so it's his/her problem. So, while Py2 code will die in flames if you mix `bytes` and Unicode and the `bytes` turn out to contain non-ASCII data, that's your fuck-up. And while Py3 will fundamentally choke if you try to combine `bytes` and Unicode regardless of what's in the `bytes` (a good thing), it will also provide you with 2 different flavours of invalid Unicode, in order to perpetuate its charade, which need to be rooted out every bit as much as non-ASCII `bytes` in Py2 if you want your program to not crash and burn. And ultimately, it's easier to fix a Py2 program that's passing around data of the wrong `class` than a Py3 one that's passing around the right `class`, but which Py3 silently broke before you even got the data :( 
PyCharm doesn't really have any problems with OpenJDK anymore. I know it used to have some real drawing issues, but I haven't noticed any issues in the past few versions and the warning method when running it from shell has disappeared too.
I've been checking for it almost every day for the past few weeks :P
guess its time to leave gedit and try out pycharm
You could easily write a web app using a web framework such as django to create the forms and display the info. However, you will need to find an existing scheduling script and re-form it to your needs or write your own to actually carry out the logic of scheduling time slots. Here is a sample script of how you could write the scheduling logic. I just whipped this up in the last 15 min so just use it to get an idea of how you can leverage dictionaries, lists, and functions in a scheduling script '''Constants, confence times, and days of the week conferences are ''' ############ conf_times = ['3:00','3:30','4:00','4:30','5:00','5:30','6:00','6:30','7:00'] days = ['Monday', 'Wednesday', 'Friday'] # random names of students students = ['Piper Luettgen', 'Mrs. Effie Hickle', 'Caden Schowalter MD', 'Gwen Feil', 'Hans Howell', 'Kecia Brown', 'Dr. Arlan Schowalter V', 'Elroy Kessler', 'Carly Altenwerth', 'Genie Vandervort', 'Miss Kendra Wilderman MD', 'Abdiel Willms', 'Hans Pollich I', 'Miss Iva Murray', 'Ms. Enid Mayert MD', 'Alonzo Dooley', 'Domenic Ernser', 'Marion Ebert', 'Ana Larkin', 'Wenzel Balistreri IV', 'Ms. Roena Metz PhD', 'Lacie Pacocha', 'Elbridge Armstrong IV', 'Leila Nikolaus', 'Mr. Ethan Harris Jr.', 'Eddie Schumm', 'Dr. Valinda Haley DDS', 'Dian Kris', 'Perri Rempel', 'Dr. Dimitri Jerde MD'] ############# # function to create a ditionary object to store a students prefered days and time def pref_time(student, day1,day2,day3,time1,time2,time3): student = { 'student':student, 'days' : [ day1, day2, day3 ], 'times' : [ time1, time2, time3 ], } return student #master schedule of possible conference days... "" values will be replaced by the name of the kid shceduled that day Schedule = { 'Monday':{k:"" for k in conf_times}, 'Wednesday':{k:"" for k in conf_times}, 'Friday':{k:"" for k in conf_times} } # Create some students for test data student = pref_time(students[3], 'Monday', 'Wednesday', 'Friday','4:30','5:00','6:00') student2 = pref_time(students[4], 'Monday', 'Monday', 'Friday','4:30','5:00','6:00') student3 = pref_time(students[5], 'Monday', 'Monday', 'Friday','4:30','5:00','6:00') student4 = pref_time(students[6], 'Monday', 'Monday', 'Friday','4:30','4:00','6:00') student5= pref_time(students[7], 'Monday', 'Wednesday', 'Friday','4:30','5:00','6:00') student6 = pref_time(students[8], 'Monday', 'Wednesday', 'Friday','3:30','5:00','6:00') student7 = pref_time(students[9], 'Monday', 'Monday', 'Friday','4:30','5:30','6:00') student8 = pref_time(students[10], 'Monday', 'Friday', 'Wednesday','4:30','4:00','6:00') # list of students to schedule students = [student, student2, student3, student4, student5,student6, student7, student8] ''' Recursive function to schedule a student based on availability and preference Schedule a student based on availability. If all is taken it will attempt to bump other a conflicting person and reschedule the bumped person to another spot based on secondary/tertiary preferences''' def schedule(student, bump=False): for x in xrange(len(student['days'])): day, time = student['days'][x], student['times'][x] for DAY, TIMES in Schedule.iteritems(): if day == DAY: if TIMES[time] == "": TIMES[time] = student['student'] return True if bump: day, time = student['days'][x], student['times'][x] for DAY, TIMES in Schedule.iteritems(): if day == DAY: if not TIMES[time] == "": student_bump = [x for x in students if x['student']== TIMES[time]][0] TIMES[time] = student['student'] schedule(student_bump) schedule(student, bump=True) notsched = [] '''Goes through the list of students and invokes the schedule() function. If there is an error, which happens when 3 or more people have identical schedules, it will NOT schedule the person and add them to the nosched list which will be displayed in standard output ''' def schedule_all(students): for x in students: try: schedule(x) except: notsched.append(x) for k, v in Schedule.iteritems(): z = {a: b for a, b in v.iteritems() if not b == ""} print k, " ", z if notsched: print 'There was an error scheduling the following people due to conflicting best times' for x in notsched: print x['student'], " ", x['times'], x['days'] schedule_all(students) 
" many reads/writes to the local filesystem" file io is blocking in gevent
When you're using PyCharm on Linux, what do you do about the jaggy fonts? Is there anything that can be done? Google searching reveals that some people have found some obscure ways to patch the Java environment, most of which seem to not work anymore, and many of which are broken links.
This breaks a lot of fancy optimisations in JIT python, use classes for fast attribute lookup and dictionaries for fast key add and remove
Thank you for your time to write up an example solution. I definitely need to sit down and look it over and try to break each piece down to understand exactly what is happening but it will certainly give me ideas on how to think about creating my own solution. For your time have a gift of gold(My first time too)! 
Can someone help a Django-newb out with a question: 1. What is the benefit of Pycharm for a Django developer? I've used Pycharm's free edition some and I like it. But, I guess I don't understand how the IDE makes it easier\smoother developing a Django project? That's pretty much what's holding me back from spending the money to get a license at the moment - I don't quite understand what I'm getting over the free edition. (Right now, I've been using ST3 to learn Django and build my first project, so I haven't used Pycharm in a little while)
&gt; You'll see that the more buttons/labels are added, the more cramped it gets. Removing size_hint_y: None gets the oposite effect and takes the whole vertical space. I would expect a much more natural sizing. Should I add a default height to the labels/buttons perhaps? Here's an example of how to do what you want. The difference is that by default kivy's layouts are all static, they keep a constant size and arrange their children according to that size. In this case we want the opposite effect, which is achieved by manually setting the size of all the labels and buttons then using the GridLayout's minimum_height property to make it grow to exactly the right size to contain them. I also threw in a ScrollView so it'll behave properly if the buttons don't fit in the screen vertically. The same kind of idea is probably what you need to make your main grid work properly - you'll want a child class that knows how to layout the image and text, and has a fixed height. Then you can add as many as you like to a GridLayout with any number of columns, and use the same trick as below to make it grow to the right height. Of course you can also add other tweaks like changing the number of columns according to the screen width. from kivy.app import App from kivy.lang import Builder from kivy.garden.navigationdrawer import NavigationDrawer ui = Builder.load_string(""" BoxLayout NavigationDrawer: anim_type: "slide_above_anim" ScrollView: SidePanel MainPanel &lt;FixedSizeLabel@Label&gt;: size_hint_y: None height: 50 &lt;FixedSizeButton@Button&gt;: size_hint_y: None height: 50 &lt;SidePanel@GridLayout&gt;: cols: 1 size_hint_y: None height: self.minimum_height # minimum_height = sum of child heights FixedSizeLabel: text: "Header 1" FixedSizeButton: text: "FixedSizeButton 1" FixedSizeButton: text: "FixedSizeButton 2" FixedSizeButton: text: "FixedSizeButton 3" FixedSizeLabel: text: "Header 2" FixedSizeButton: text: "FixedSizeButton 1" FixedSizeButton: text: "FixedSizeButton 2" &lt;MainPanel@BoxLayout&gt;: Label: text: "placeholder" """) class MainApp(App): def build(self): return ui if __name__ == "__main__": MainApp().run() 
If you spent less time talking about what you're doing and more time doing it, you might not be 2 years behind everyone else.
*sigh* The decoding of unicode with surrogate escapes is documented in the Python manual. If you are not checking for this in your python script, your script is wrong. It's irrelevant whether you run it from the shell, from within cron, via uwsgi or whatever. You need to get out of the mindset that US-ASCII is the only bytes you will ever receive. Strings have been unicode (in Python) for 7 years now, you need to treat them as unicode and stop making the same mistakes that plagued other Python libraries. Yes, it's more difficult to deal with Unicode over blindly assuming all your text is US-ASCII, ignoring error checking in your code, and hoping for the best and whinging when your untrapped error condition blows up your dodgy script. 
I used to code with Pycharm, but suddenly it corrupted all the files of the project of my game and I was dumb enough to overwrite my backup with the files. The result: I'm coding entirely with the default IDLE and I'm not being lazy anymore. IDLE has everything that I need, and I wish it had more attention. I don't want "projects", I just want to python.
"Anaconda includes almost 200 of the most popular numerical and scientific Python libraries used by scientists, engineers and data analysts, with an integrated and flexible installer." It sounds like most Anaconda users have 195 packages that they don't need or know how to use.
If you're on RHEL, you don't need (and never should, anyway, irrespective of platform) depend on the system Python. https://access.redhat.com/site/documentation/en-US/Red_Hat_Developer_Toolset/1/html-single/Software_Collections_Guide/ Fully supported Python 2.7 and 3.x for your RHEL setup. Redhat have committed to keeping SCL updated (since they're losing customers to better Linux distributions that don't come standard with 6+ year old outdated crap filled with bugs fixed a decade ago upstream) 
In Windows I use Notepad++ for the editor, DreamPie for REPL, ConEmu for my terminal. I've tried IDEs but keep going back to this setup.
Just use the standard java and objective c. It took me 2 weeks to port my code from the wxpython desktop app to mobile without ever having used Java or objective c. Reusing code to access a sqlite database isn't a reason to stick with python. Your problem is likely you don't understand mobile development. What you are doing is straightforward mobile work - just use the standard views. This will a lot easier going with the standard dev tools. 
How does that work with hg tags and branches? Are you free to work with them and have a 1to1 replication on github? Also, what's your official project "home" including the bug tracker? bitbucket or github?
fair enough
&gt; corporate legal at a large company They are asking you legal questions? Open source licenses are built on copyright law, it shouldn't exactly be unfamiliar territory for a legal department at a large company.
PyCharm has had HiDPI support [since 2.5.2](http://blog.jetbrains.com/pycharm/2012/06/pycharm-2-5-2-better-performance-fixed-github-and-retina-ready-editor/) (for the editor) and [2.7](http://www.jetbrains.com/pycharm/whatsnew/whatsnew_27.html) for full HiDPI supprot.
It should be possible with powershell 
It's no Sublime Text though, is it?
There's something wrong with your machine if that's your experience. It runs fine on my £150 laptop.
Well, it entirely depends on where your interests lie. Python is a general purpose language, and it is used, at some level, for almost everything. If you liked the multimedia stuff that it sounds like you've already done, maybe try doing some games? Pygame isn't a bad start on that front. Very nice community there. But it's a wide world. If you want to branch out, you could try some mobile development. Personally, I've been doing some UI development for the raspberry PI on the side so I've gotten to know kivy fairly well. But kivy is(as I understand it) geared mostly towards mobile development, so it may be ideal for forging into the mobile world. At my day job(grad student in particle physics), I end up doing quite a bit of data analysis(When I'm not being an underpaid Electrical Engineer, that is; Debugging circuits is hard :) ). In any case, python happens to be very well suited for data analysis. In particular, the combo of numpy(fast data processing)/matplotlib(graphing)/ipython(orgasms) combined with, perhaps, some web-scraping aided by requests/beautifulsoup enable some really [cool stuff](http://nbviewer.ipython.org/github/ptwobrussell/Mining-the-Social-Web-2nd-Edition/tree/master/ipynb/). If you have some question that could conceivably be answered by data online(or elsewhere), take a shot at it. It's really not as hard as it may seem. The tools are out there, one just need to find the proper grip.
"Sample code presented here is written in Python 2.4, unless noted otherwise." Say whaaat.
I have 2 main workflows. For analysis, I use Ipython Notebooks until I know what we're going to be building. For writing 'real' code (implementing models and the jobs to build them usually), sublime text or vim. I always use Ipython as my REPL (tab completion!) and pdb for debugging. Git for source control. 
Totally agree. `conda` is so good, there really isn't a need for a huge bundle like Anaconda. Just use `conda` to install what you need when you need it and save yourself a half gig of hard drive space. 
http://www.jetbrains.com/pycharm/features/editions_comparison_matrix.html For one the free version only has extended features for python code, the professional bundles extended features for html, css, js as well.
Not working in [Linux](http://youtrack.jetbrains.com/issue/IDEA-114944) or [Windows](http://youtrack.jetbrains.com/issue/IDEA-124304).
 Schedule = { 'Monday':{k:"" for k in conf_times}, 'Wednesday':{k:"" for k in conf_times}, 'Friday':{k:"" for k in conf_times} } Does this line here **'Monday':{k:"" for k in conf_times}** , mean the key for the Schedule dictionary is 'Monday' and the value can be found in another dictionary whose key is k. The k is then found in the list conf_times? If this thinking is correct why have the double quotes **k:"" for k in conf_times**?
You could. But hosting a static site on a PaaS provider like Heroku is ~~not a good idea~~ generally not recommended.
 The Schedule dictionary is a dictionary where it's keys are the days of the week and the values are nested dictionaries with the conference time as the key, and an empty string as the value. The line your are talking about it simply uses a dictionary comprehension to create the nested dictionary by iterating over the conference time list. 
Cygwin really works! It's *almost* a full Linux-esque shell in windows.
They were questions that were posed as unanswered by the legal department - in other words, they were posed as a rhetorical device to justify prohibiting GPL-licensed code inside the firewall.
Since I upgraded to 3.4, it has been starting up *so much faster* than before. At least, that has been my experience so far, YMMV.
I'm pretty sure the author's intent was to cover all recent 2.x versions. Are you aware of anything that would be wrong in this discussion b/c of changes introduced in later versions?
That makes things a bit more clear. I haven't seen the nested dictionaries before so it was something new to me. I'm having fun running through the code trying to break it down and understand each piece. I'm also trying to modify it so it can be used with teachers. As an example if there are 5 teachers who have certain constraints having the program provide each student with a time with a teacher at a particular time. Maybe when I'm done I will post it (though it may take a while since I want to make sure I understand what I'm doing rather then just copying and recreating). Thank you again.
Why would I need an IDE when I'm working with Python?
Just get a prebuilt package of the stable version. Building the bleeding edge version might cause you problems because of upstream bugs.
Thanks, that is what I have done to solve it. Just annoying as I wanted a way to distribute the environment to work colleagues. As everything else we have is pip installable.
&gt; The decoding of unicode with surrogate escapes is documented in the Python manual. If you are not checking for this in your python script, your script is wrong. That is my whole point. And because of that, Unicode on 3.x is significantly harder to get right than Unicode on 2.x where you could perform typechecks. &gt; You need to get out of the mindset that US-ASCII is the only bytes you will ever receive. Strings have been unicode (in Python) for 7 years now, you need to treat them as unicode and stop making the same mistakes that plagued other Python libraries. My libraries have excellent unicode support on 2.x from the beginning.
It appears to be hitting dependency hell: are all the non-python dependencies installed? SDL, libogg, etc?
Yes
I prefer to keep content out of layouts (templates). If fine control is needed, like on this home page, I use html in Markdown files. This works fine as Markdown processes html transparently. For the column specs itself, Bootstrap provides ready-to-use html classes. You can also easily combine them with iteration over content files in layouts. I often use that in index file layouts. For example: http://dev.myhdl.org/meps/ 
This is a nice getting started guide that made me switch from Sublime to PyCharm: http://pedrokroger.net/getting-started-pycharm-python-ide/
Try and contribute to an open source project or make your own and learn as you go, practice makes perfect and forces you to learn on the fly.
PyScripter : https://code.google.com/p/pyscripter/ I wanted a free and fast editor for Windows. I need syntax higlighting, customization and auto-completion. PyScripter is not updated but I don't have bugs.
I'm on Kubuntu and have a nice AA'ed main font. (DejaVu Sans Mono) I don't recall doing anything special to get it like this. The JVM does have some options for turning AA on or off or system default. The search terms which might help are swing.aatext and awt.useSystemAAFontSettings. 
I use them. They give private repos without any extra cost. I signed up with academic email, now I have private repos with unlimited collaborators. 
even with map also it works: any(map(s.endswith, ['b', 'c', 'd']))
It also runs just fine for me on my $1200 machine...sometimes you have to pay more for better results, ala PyCharm, Visual Studio, Photoshop, Eclipse, Excel.
Apples and oranges, ST isn't an IDE.
It allows people who have specific version and application requirements to isolate those from their developmental system. It's like if you were a freelancer and did work for two companies. One required Postgres 8 and the other needed Postgres 9.3. Before you'd have to have two postgres instances installed and operating on your development box. Vagrant allows you to push each postgres instance into a nice self contained unit. That way, not only can you know that shutting down that environment means your system is now clean of extra processes that could have been running before. But you can also throw your vagrant config to another developer that is taking over and he can be up and away without a lengthy setup.
[PyCharm](http://www.jetbrains.com/pycharm/) as IDE, git for version control (I prefer GUI tools over CLI so I use [smartgit](http://www.syntevo.com/smartgithg/) for that). virtualenv+[virtualenvwrapper](http://virtualenvwrapper.readthedocs.org/en/latest/) for managing virtual envs. `pip` of course for installing modules. [Sphinx](http://sphinx-doc.org/) for documentation. [tox](https://testrun.org/tox/latest/) for testing, especially if it's for multiple py versions. [cookiecutter](https://github.com/audreyr/cookiecutter) if I'm creating project from templates. [ipython](http://ipython.org/) /ipython-notebooks for testing out/writing short code snipppets. That's the stuff I use often, of course setup/tools vary from project to project but those are pretty much the basic ones that I use.
Sometimes I read math papers just to see smart people in action. I got the same feel from your post. Thanks for it, brilliantly done.
Have you ever loaded an excel file with millions of dynamically populated cells? Sounds like you have something wrong with your computer if you can run industry-standard applications fine, but not PyCharm which doesn't even come close in resource intensity.
Should be quicker with this at the end: if 0 &lt;= n &lt;= 1: return False Because otherwise it will force that check on every number you feed into it, and you only want to do that if finding a divisor fails. Also, 2 is prime.
&gt; I don't know how well it works with multiple collaborators Tolerably well, but if you merge pull requests, the bookmarking sometimes gets mixed up. There are two bookmarks: `master` and `git/master`. These are synced up by a `push` to a Git repo. It's best to have a section [bookmarks] track.current = True in your `hgrc`. You sometimes then have to do bookmark -f master after merging a pull request. IIUC `hg-git` will send any changes between `master` and `git/master` when pushing to a Git repo, so `master` should generally be at `tip`. This doesn't always happen after a merge, hence the need to `bookmark -f`. BTW I use Mercurial most of the time, but a lot of my repos have GitHub mirrors so that I can use Travis. 
for emacs I suggest elpy-mode that integrates those tools in a simple setup
Cool stuff. Was hoping to see you crash the ship in the video, though. :P
Both with Python 3.4 support :D
Makes sense. Thanks!
PyCharm and git for everything. Work, private, large, small. I also recommend trying type hinting in docstrings. It's pretty powerful and can give you most of the advantages from static typing (except speed) because PyCharm will check the code for you. 
Try using "wheel convert [packagename]" on the .exe installer from http://www.lfd.uci.edu/~gohlke/pythonlibs/#pygame ; the resulting file will be pip installable.
I usually use `dp(50)` out of habit, though I think android's guidelines suggest anything to touch should be at least this big...or something like that, I don't remember. I used just 50 in the example to keep things simple, you're right that using dp (or sp) is preferable.
I use vim and really like python-mode https://github.com/klen/python-mode I know a lot of people don't use plugins, but one feature I really love that could be added to a simple vim setup is mapping a key to toggle a breakpoint on the current line.
I've tried Anaconda a few times because it seems as though it would address some common problems. Unfortunately, I always end up going back to my default Python install pretty quickly. No virtualenv (I get that this is a design choice), broad but incomplete support for modules I want to import (nibabel most recently), and other minor problems have led me to uninstall within a day or two of each new installation. Still keeping an eye on the project, though.
I use Emacs with a bunch of extensions (https://github.com/balle/emacs) such as magit for git integration and ipython as repl. Try out Ipython its really amazing especially the newer features (notebook and parallel computing). For testing I am using nose and jenkins and of course the list of tools wont be complete without virtualenv per project and pip. Last but not least I sometimes fire up pudb for debugging purposes.
Hey, that's a great idea. Gotta find my old Cassiopeia :P
giggity
I'm somewhere in between python beginner and python intermediate, and I've been cramming in a bunch of Django learning over the last few weeks. One of the things I couldn't grasp last year, but suddenly do this year is the "virtualenv" setup. It's basically a process of putting the virtualenv folder in your project folder, "activate" it (`source bin/activate`), then you have your "virtual environment" to install whatever you need (for me, things like Django, South, etc). Then you can `pip freeze &gt; requirements.txt` to save what you installed to a txt file for your app. When you deploy, it's then easy to install only what your app requires without having to worry about figuring out what makes it work on your computer. Abstracting that a bit, it's basically separating your working python app folder from your system's python install. So it doesn't take into account what modules you've installed on your system, only what you install in the virtual environement (venv). Like I said, I'm not expert, but this all made a ton of sense in my head. Hope it helps you out!
Functions are objects. Objects are (essentially) fancier dicts. I'm not sure if it's too useful, but it's pretty obvious when you know how the type system works.
Could you set up a virtualenv?
My co-founder taught herself web development using online courses and resources. This “Learning Path” outlines the resources she found most helpful, and lays them out in a sequence that a beginner should be able to follow. We realize this is *a* curriculum, not *the best* curriculum. We'd love feedback on what we might change or add -- by way of content as well as features (e.g. progress tracking). 
Good start to a game, I'm assuming we'll be seeing more of it in the future? :D (not entirely related but I'm intrigued) What did you use to convert it into an .exe? I only ask because I've tried freezing code using cx_freeze, but the result seems messy and py2exe is only for python up to 2.7 edit: found a py2exe for 3.4, I'm assuming this is what you used :D
That behavior is exactly what is expected in a dynamically typed, late binding language with first class functions. Your code is no different that this, just less explicit: class Foo: n = 0 def bar (x): return n * x Foo.n = 2 Foo.bar(6) # returns 12 I would argue that it is never a good idea to treat a function as a persistent object by giving it properties. It is an unusual thing to do, and does not have any notable advantages over the many alternatives.
Yes, just think of the `foo` function's single line as equivalent to: return foo.__dict__['bar'].__call__(n1,n2) Maybe that makes K900's point clearer.
I too am an emacs user and I do a lot of Django, so I spend some time in the REPL with access to django settings and configurations. I often will use the REPL to inspect database objects, flesh out unittests, and plan out how I want to approach a problem. I love emacs for its extensibility and its incredible ecosystem. Just the other day, I was thinking about writing a custom auto-indenter for django templates (which can have three languages mixed together: js, HTML, django-template-syntax), and then I realized that something probably already exists. Sure enough, something in web-mode can handle that; I just had to associate it properly with my files. I've never found an IDE that competes with emacs. I consider it a great friend.
a quick note, dont delete the alien and bullet until 1 loop later. Let the player see the collision. 
Interesting. I've occasionally had to ``bookmark -f``, even without any pull requests. So that doesn't sound bad at all.
virtualenvs are not portable, at least not with the bundled virtualenv with Python3.4. This is on windows. env\pyvenv.cfg # This file stores an absolute path to the base python install env\Scripts\activate.bat # This file stores the absolute path to the virtualenv It would be nice if virtualenvs could be portable but it does not seem so.
Jaggy fonts? I'll have to go home and look, but I don't remember having any font problems. I use the dark theme, so maybe that's it. 
git is a source control system. GitHub is a web based hosting service for project that use git. If you're new to source control and git, just concentrate on using it locally first. You can set up a local repository and commit to that etc. Further down the line it is possible to connect to a remote repository to commit and push your work there.
Tremendous find! I love that it's over 80 hours! And she covers everything, even version control. 
you get the compiled packages with conda, which is almost essential for windows users and saves a lot of time for linux users. 
WinPython looks like it could work. Portable and python 3.3.5 I will download it this weekend and try it next week. Thanks! (sourceforge is also blocked at work by websense as being an evil place where you can download freeware, go figure)
Yes, but the problem with portable python is that it's only python 3.2 and flask does not support it(not sure what would work or not though)
Glad to hear you guys enjoy using conda! The reason for the "omnibus mega-package" is that there are many people who are just getting started with using Python for scientific or data science, and they don't know what packages they need. They just know that their book or web page tutorial tells them to bang out some script which imports a pile of stuff. We see our service to the community as making it as painless as possible for those folks to succeed with Python. 
&gt; I've tried Anaconda a few times because it seems as though it would address some common problems. Unfortunately, I always end up going back to my default Python install pretty quickly. No virtualenv (I get that this is a design choice), broad but incomplete support for modules I want to import (nibabel most recently), and other minor problems have led me to uninstall within a day or two of each new installation. Still keeping an eye on the project, though. anything that you can install on your default python, you can install on your conda installation. if its not available in the conda repos, but present in pypi, simply pip install (assuming that you've installed pip in your conda installation) for the environments, what is lacking in conda's environment feature? (i'm genuinely curious, because i don't use this feature much, other than to have a python 2.6 env available to occasionally test some backwards compatibility stuff)
I think someone was going to port it to the teensy board which could be had pretty cheaply. https://www.pjrc.com/teensy/
There's also some stuff for the Teensy in the micropython repository, but I'm not sure how complete it is. I imagine that micropython on an AVR would be quite limited compared to it on ARM, but it's still a really cool idea.
pycharm, for small edits etc sublime, dont usually use a repl, i write some code in a tmp.py then run it, then move it to a unit test, or doctest.
I certainly don't use all of them, but quickly glancing at the list, I probably use 40 or so packages on a fairly frequent basis, including dependencies. 
This turns me on.
The new teensies use ARM chips. &gt; MK20DX256 32 bit ARM Cortex-M4 72 MHz
What separates this from something like the Raspberry Pi - which comes with built in support for python as well as GPIO, SPI, I2C, USB, HDMI, Ethernet, etc all for a shockingly low price. I am currently involved in a project using the Raspberry Pi and python as a microcontroller for condensed matter physics epxeriments
This was added in python 2.1 ([PEP 232](http://legacy.python.org/dev/peps/pep-0232/)). Prior to that, there were a few standard function attributes (eg `__doc__` or `__name__`), but you couldn't add new attributes. Python 2.1 gave functions a `__dict__`, like many other objects allowing arbitrary properties to be set on them. There are a few useful usecases for these - you'll sometimes see frameworks that add various attributes as a decorator that indicate special handling by something doing some introspection on the methods (eg. you might set a "published" attribute to indicate what methods should be exposed to the web in certain frameworks)
ahhh right - hadn't considered that
Oh, nice! I'll have to check those out.
Compared to the Raspberry Pi, there are some pros and cons. Just off the top of my head... Pros: * No OS - The MicroPython board runs Python on the bare metal, which gives you fewer moving parts software-wise to worry about. * Lots more IO * Much smaller form factor * Lower power consumption * Standard microcontroller peripherals - timers, ADCs, interrupts, etc. Cons: * No OS - The Raspberry Pi can run a full Linux OS, which gives you lots of high-level functionality (e.g., databases, networking, user interface) that is difficult, limited, or non-existent on the MicroPython. * Less powerful * No "higher-level" peripherals - HDMI, Ethernet, USB, etc This isn't comprehensive by any means.
As another commenter has mentioned, you can run `wheel convert pygame-..-.exe` to get a pip installable wheel out of it.
A better idiom for this, by the way, is to use a dict. Like: ops = { 'add': lambda x, y: x + y, 'div': lambda x, y: x / y, 'mult': lambda x, y: x * y, 'sub': lambda x, y: x - y, } op = input("Pick an operation (add, div, mult, sub): ") x = int(input("Enter first number: ")) y = int(input("Enter second number: ")) print(ops.get(op.lower(), lambda x, y: False)(x, y)) 
Everything is an object. 
An arduino pro mini is $3, and has 8 analog pins. It's the best combo with the pi.
Why don't you just try py2exe? Bittorrent - as mentioned on the py2exe's front page - is using it. And it runs out of the box.
PyCharm with Python 2.7.5 and 3.3 (mostly 2.7). Tried a few different editors. Eclipse, Ninja-IDE, gEdit, IDLE, butPyCharm stuck, its featureset and functionality are great.
Is it already out? Because it says May 31 EDIT: I could already install it via pip. Seems to be just a typo on the website :)
You're welcome. 
For those with the professional edition, how often do you have to renew your license? Right now I'm using the community edition, but I'm thinking of making the jump. I only program in python for personal projects.
You don't really need the dict in this particular case, because all functions in `ops` are implemented by `int`: op = input("Pick an operation (add, truediv, mult, sub): ") x = int(input("Enter first number: ")) y = int(input("Enter second number: ")) print(getattr(x, '__%s__' % op, lambda y: False)(y)) The `__truediv__` thing is ugly, though. They should've called it `__div__` and `__floordiv__`.
Just got mine yesterday. Haven't had a chance to play with it yet. I've read all the tutorials on their site already though. This is a much lower barrier to entry for learning micro controllers than Arduino. Python is a much easier language to learn than C, coupled with the fact that you just have to drag &amp; drop your code onto the device. Still though, it'll be a while, if ever, for micro python to have the same number of shields, libraries and resources available for it. But it's exciting non-the-less. Edit: the language is also being ported to the Due, Teensy 3.1, and to a few other 32 bit micro controllers.
I have just started to check your list, so: - EffectWidget (on master) gives Exception('FBO Initialization failed: Incomplete attachment (36054)',) and I see black screen. Ubuntu 14.04 plyer is next... :)
It's really neat. Plug in the USB, connect using PuTTY or screen to get the REPL and off you go. I've never gotten a development board that was usable this quickly out of the box before.
Just curious how well MicroPython is running on the Teensy. I just haven't had a chance to play with it yet. Is it worth trying to get it running on there? Is it difficult? Are these stupid questions that 10 minutes of my time searching could have answered?
The two features I'm most excited for are asyncio (not sure if implemented yet) and "yield from" These will really nice features for retrieving and working with sensor data without having to rely on nested loops, nested conditionals, and interrupts (you will probably still need interrupts for MUST DO NOW code though)
Thanks for the helpful reply; being able to pip install instead of conda install is interesting. Regarding the environtments, I use flask and a bunch of related modules to maintain a small website, and that the whole site-app runs in a virtualenv container for easy portability.
I never thought of those, but they'd be a really nice fit for a lot of embedded applications!
where are you finding the pro mini at $3?
I guess it depends on how you define "well". I put together a little demo bot: http://blog.davehylands.com/2014/01/micropython-running-on-teensy-31.html My brother originally started his uCee crawler using teensy: http://blog.huv.com/2013/12/uc-microcrawler.html I think that https://github.com/JonHylands/uCee-py/blob/ae786466a725fefb390faeb89fc63f7dd91a4116/memzip_files/src/uCee.py was the version of code that he was running on the teensy, and it was consuming about 50K of the RAM. The 50K was measured in late Jan. Lots of stuff has changed since then, so I'm not sure how accurate that is on today's firmware. MicroPython also has a couple of different code generators (it can generate ARM assembler) and once the ability to have compiled python be stored in flash, then larger programs will be supportable.
Python 3.4 official support and sqlalchemy are huge (imo). Also joining single indexed dataframes with multi-indexed ones is awesome too...actually this update seems very good all around.
Well, clone but absolutely equivalent. [Here](http://m.ebay.com/itm/181401411104?nav=SEARCH) is just one example. I buy them for $2 in lots of 10.
MicroPython supports a microSD card using the FAT filesystem. It also has a small internal (about 112K) FAT file system as well. These can be shared with the host (so it looks like a thumb drive) and you can just copy your new code in.
awesome, thanks for the response.
You don't ever have to renew your license if you are ok with using the version that is out 1 yr. after you purchase. You get updates for a year, or you can purchase an update subscription that lasts a year at a time ($59). I just renewed my update subscription this morning because I wanted this update. Had I not wanted it I could have stayed on my old one "forever". Being honest though who among us could do that if we are still coding in and using it....
This is true, I was explaining in general terms how the two types of boards differ. There is definitely crossover in some areas. Maybe my memory example was a poor one to choose.
Python 2.7.3: TypeError: unbound method bar() must be called with Foo instance as first argument (got int instance instead) Hmm. Python 3.3.1: NameError: global name 'n' is not defined Hmmmmm.
You mean other than not needing a compiler on windows, being able to easily create isolated python3 and python2.7 environments, being able to install non-python packages and binaries, having precompiled scientific libraries that just work on linux, windows, and osx? Other than that, it's meh. 
Isn't it the same as creating a conda environment? 
It's not a mystery, as you can set arbitrary attributes on some objects, but it's arcane and you shouldn't do it on any functions because arcane is bad.
This looks really neat, congrats!
I use IPython for prototyping some things, shorter scripts I use vim, and for big projects I like pycharm.
I use Pyramid daily, and I think you're making an apples to oranges comparison. Pyramid makes no claims to be a microframework while Flask makes that claim in their homepage title element. Just taking a quick glance over the Flask extensions, a number of them are included in Pyramid's core (or at least as part of the default install): babel, mako, upload handling, just to pick out a few. Additionally, many of the other things there are official Flask extensions for are supported through unofficial Pyramid plugins. I would say the strongest suit of Pyramid is that it's not just a framework but a scaffold. For both official, unofficial and even core functionality, almost everything has defined interfaces and provides the ability for you to override the defaults. Want to write your own request/response handlers? Not a problem in Pyramid and definitely not monkey patching. If you want to just plug everything in and write minimal amounts of code to reach an MVP, both Flask and Pyramid will get you going. If down the road you want to switch out one of the libraries (say move from memcached to redis for session caching), Pyramid will give you a much smoother ride. You simply implement the defined interface for redis (which somebody has probably already done), and everything continues to work. Pyramid is frankly the ultimate pluggable framework, it has been designed from the ground up to be pluggable. If you dig into it you'll find all the goodies we use in our production applications like the Authentication Policy system, fine grained controls over middlewares and callback handlers, and especially the joys of reify (which admittedly isn't Pyramid specific but Pyramid seems to be where most people meet it, just don't abuse it). Pyramid also has mechanisms that make it easy to bootstrap your Pyramid application for functional testing or even running cron jobs, celery tasks, CLI programs (so you don't have to write separate code to bootstrap your ORM or cache or other components).
If you change it to: class foo: n = 0 def bar(x): return foo.n * x foo.n = 2 foo.bar(6) It works, but I'm actually confused about something. Not sure if it's because I'm just typing stuff into shell or what. But self.n does not work, and if I set def bar(self,x) it complains about not having two arguments. I guess it's due to not having instantiated the object. 
Nice! I finally got around to contributing, so a couple of very small bug fixes in this one came from me. For anyone who wants to give it a go, the fact that they've got a really thorough testing framework set up means you can make changes and easily check whether you've broken everything.
It is apparently possible to run gdb on the microcontroller board, but I haven't done that myself. There is a "unix" port of micropython, and I've use gdb to identify bugs on the host. I normally test non-board specific stuff under the unix port and then move it to the board. There currently isn't any support for debugging the python, but I know I'd like to see that.
Thanks! I'll try that out.
Google Tango with Django, I've been enjoying/learning a lot from it.
There's several things going wrong here, but in the first instance you need to upgrade your conda environment because that pangocairo linking error was fixed late last year. Next, you should use conda's intrinsic support for virtualenv's so you get all the benefits of a proper python packaging tool, such as linking existing packages into the env instead of downloading/rebuilding each time (as with pip/virtualenv): http://www.continuum.io/blog/conda 
Python 3.4 was in the repo not long after release, you just needed to initially state "conda install python=3.4" because it wasn't in the anaconda metapackage for python 3. Note this is also true for many of the packages; continuum.io often upgrade the packages without making the new one the default until after its received considerable testing. "conda search" is your friend (if you're prepared to hang out with ... umm... the occasional friend who uses ;) 
Just as an aside, I believe you can get this now with the inclusion of "wheels" in pip - so long as somebody has bothered to upload the wheel; however conda was doing it years earlier, consistently, on 3 platforms. Also as others have pointed out, pip wants to create a new copy in each venv whereas conda will link existing packages instead, saving gobs of redundant disk usage. 
I don't want to confuse you too much here, but the earth is a sphere &amp; some people live on different parts of it to you. 
Radio Free Python http://radiofreepython.com I just know a few so I'm not sure that this is the best one, but I really enjoy it. 
Thanks, wish I knew that earlier!
put it in a browser, most computers will have those. http://pyjs.org
Wait really? That's so weird, but then again 3.2 was a pretty underwhelming release
Thank you. Yes, I plan to implement more features. :) I converted it with Py2exe. :D 
I've come across this issue a lot. There is a lot of down time at work, but I'm always in different places. Only real non-hacky solution I found was to get a VPS or amazon aws server with your stack and SSH. You can run putty off a thumb drive anywhere you go and any mac or Linux will have the shell. There is also a nifty shell client that you can run off chrome which is awesome as well.
Thanks for contributing!
It *is* may 31. Has been for 10 hours, now. Wes really can't help it that you live in the wrong part of the world ;) 
Thanks. Haha, perhaps in the next video. :]
Yes, didn't expect them to be so far away from the Eastern US time zone... But when I thought about it ... "Pandas" and Asia, it makes sense ;)
Yeah, I'm not in the habit of using dictionaries yet for things that I probably should. I gather the second arg in the 'ops.get' call is a fall-back for if the key fails? That's pretty handy. 
If you want it to be a hit with this crowd you better call it "for humans".
Fair enough, I'll give it another try at some point.
Seems pretty interesting.
We've recordered a second episode, but Kenneth hasn't had the time to do the editing on it yet. Source: I am Alex Gaynor.
If I told you for sure I would probably make myself out to be a liar. I thought it was to get major releases only, but If that is the case then they considered this one to be a major release. Maybe it is more like v3.3 to v3.4 to v3.5...v4.0. Or perhaps it is any update, I am not 100% sure This was my first year to renew and honestly I new I wanted the updates and did not feel like questioning and arguing at this point.
Looks good. Love the foundational Huffman Udacity course too. What do you think about adding a piece about repo hosting like github or bitbucket to the git section? Could be useful for the beginners. Small typo in the "FRONT-END" section summary: "is can be".
Thanks! Sorry there hasn't been a new episode in a year. Editing is the bottleneck here too ;-)
This is the neatest functional code I've seen yet in Python. Almost reminds me of Clojure. Nice! Question: If you used generator comprehensions instead of list comprehensions in all the functions except for crack() wouldn't it be more lazy? (i for i in seq) instead of [i for i in seq] Also in freqs() shouldn't alphabet be pulled out as a constant instead of the same list of char created everytime. And then move then just get rid of n=lowers() line and just do the lowers right in the list comprehension. I don't know how necessary the latter suggestion is, as a I guess variable assignment inside a function is the samething as a let in clojure.
We've actually worked out some of the issues - and there are many different issues referenced via that one post. For instance, LD_LIBRARY_PATH problems are discussed on the issue tracker (https://github.com/conda/conda/issues/296). In the particular case cited above, you'll note that the actual problem was independent of virtualenv &amp; anaconda interactions; rather, it was that Emacs was being messed up by LD_LIBRARY_PATH. The fix for this is to alias "emacs" to having an explicit LD_LIBRARY_PATH env var that omits ~/anaconda/lib. This may seem like a strange "solution", but the awkwardness of it is stems from the behavior of the dynamic loader itself, and is one of the reasons why people oftentimes recommend against setting LD_LIBRARY_PATH in the global environment.
So couple questions. Is this a subset of the python language or the entire thing? Does this compile down to machine code prior to deployment or do you have the overhead of a full parser and interpreter? 
Is the Teensy port still in progress? Sounds like it was abandoned. 
How's the library support for it? I'd hate to write my own everything from scratch.
It's worth waiting for :). I really like your style and the podcast is very informative. Keep up the good work!
&gt; being able to pip install uh you didn't know this ??? yet you "tried Anaconda a few times".... 
All I did was explain why you were wrong. Nothing I said is insulting in any way, so if you feel insulted by it, then the problem is all on your side. 
does it take similar amount of resource as an actual VirtualBox VM ? 
Thanks for the reply. I should probably just email tech support (you'd think they'd have more info on their site).
so why not just stick with the good'ol VBox VMs ?
This is fantastic! I'm teaching a course to non-majors that requires them to do some plotting at some point. This may be a great tool to hand them, so I'm not forcing them to learn the Matplotlib API intricacies as they learn to program :) Question! I see it's very clear on how to make line graphs. Are there any plans to expand the library to support [easy creation of other kinds of renders](http://matplotlib.org/gallery.html)?
There is portable python for 2.7 which Flask supports just fine. It just does not support Python 3 before 3.3.
identical resources. its running exactly the same VM that Virtualbox does. Vagrant is just a more convenient interface to the Virtualbox API.
I've been using for a while, but they've really stepped up their game lately. 
You might want to check this out: http://kivy.org/
Nice, I'm looking forward to hear.
Personally, I think python is awesome for accomplishing repetitive tasks with little effort. Yes, any language can do this in theory, but python's structure makes it quick and easy (and fairly minimal, too). I've built small programs to spit out SQL queries (where I need to create tables or rows with dates or other sequential numbers) and save a ton of time. Python can absolutely be used for larger projects (and certainly is). I just think it's important to remember the little things too!
Yeah. In Python 2, you'd need to use `@staticmethod` or `@classmethod` for it to work. In Python 3, there is no concept of unbound methods, which means that when you call a method on a class, it doesn't pass in a self, but it does when you call it on an instance. Calling a regular method on a class would usually involve passing an instance of that class as the first argument.
Flash is a different platform and language, so no, you cannot. You can use something like Kivy to make games, though and iirc they'll be playable on Android, iOS, Windows, OSX, and Linux. Pygame is also something you might want to look into. I'd highly recommend starting with text-based games though, at least until you get the logic down.
Does Kivy have anything to do with Python? The installer's name has py in it. 
Thanks dude.
Yes, you're absolutely right on all points! Not claiming this is the most optimal solution, just an experiment in writing functionally in python. Maybe you can submit an improved version? 
[Yes it does](http://en.wikipedia.org/wiki/Kivy)... I recommend you put a bit more effort into looking things up, as that's truly 1/3 of programming.
Cheers.
off the top of head, I think 'n' as declared is part of the *class* (which is itself an object) and so it isn't part of any particular instance (thus not part of self) 
Surely not without some (at least minor) adjustments. Python 2 has no yield from, and you have to `raise Return(some_value)` or something I think it's nice that trollius exists for people that can't upgrade, but the syntax is ugly: there's a reason they paved the path for asyncio syntax-wise in 3.3. I won't wrote stuff supporting Python 2 anymore.
My first Python program was a scrapper that downloads a lot of images from an image board. Back then there is no Python 3, so I used `urllib2` and `re`. Today you could use `requests` and `lxml.html`.
Reddit https://github.com/reddit/reddit
Some of my recent, open source, projects: * [pysub](https://github.com/Nikola-K/pysub) search and download subtitles for tv shows, the CLI interface is stable enough for usage. There is also GUI, using pyside, but it needs bit more work - [screenshot](http://i.imgur.com/EsQTSuw.png). * really simple script to gather data about reddit thread comments, votes and create graph out of it: [github](https://github.com/Nikola-K/reddit-thread-graph) - [example graph](https://cdn.rawgit.com/Nikola-K/reddit-thread-graph/f4c108022c74a9c2ab3f9351a6459257d7571db1/example_graph.svg) (load scripts if they are blocked so it looks nicer) * [fpage](https://github.com/Nikola-K/fpage) something like waay simpler version of reddit using flask + boostrap, so it's also responsive. [screenshot](http://i.imgur.com/yVQKNgb.png), [mobile view](http://i.imgur.com/dk7rHmA.png). I also have a bunch of half finished projects that aren't uploaded anywhere - I rarely share my projects, and some apps that are for private use only. 
Because vagrant adds some niceties that virtualbox doesn't have out of the box. Some good things: * Downloads virtual machine box if it's not cached locally * Sets up ssh to the virtual machine * Mounts host directories on the virtual machine * Easy to configure port forwarding client-&gt;host * Runs provisioner * Can handle multiple virtual machines All of this has to be done manually when just using virtualbox, which is just a waste of time + everything needs to be documented.
Thanks, I can see how that could be useful. Also, thanks for catching the typo, will fix.
I did the bulk of my data analysis and manipulation with Pandas. Saving me lots of time compared to Exceling it. 
* A administration tool (web) for Battlefield servers, using django with a few other frameworks. * Back-end for deploying game servers, with a api for controlling it (api is written with flask and the other part is with zeromq) * Rconlistener, a system for monitor what's happening on the servers, and puts it out on a websocket (using tornado). We are also working on a open source project for handling battlefield servers. So maybe more programmers will find it interesting.
Terrible interface, why break the web browser. Content was quite good once I worked out to press PgDn
btw it uses old version of Django right
What can be done? Brilliant things such as: http://www.cherrypy.org/, https://www.djangoproject.com/, Reddit, etc. 
most of these cool things have nothing to do with python3's break-everything philosophy or the unicode chaos, python2 users could have benefited from them trivially if there was a python2.8. the potential cost of upgrading are tons of hours to fix things that worked and losing a whole bunch of powerful libraries/tools, your future development could be limited. the gain is basically some nice syntax which makes your code look better(i love my code look good though). however shipping beats perfection, they are cool but not cool enough to drop what i already have. (i see a downvote-to-death coming)
I've been using the main Python distribution for programming tasks since 2001, most often under Windows. From that perspective, pip is a relatively recent addition on the one hand, and not always the best tool to install modules under Windows on the other.
Just keep in mind that the devs don't get paid ...
My house has a 1/4 mile long electrical wire to control the water pump for my well. The wire failed, and it would have cost quite a bit to get a trencher and re-install it. The ground is hilly, and there is a creek in between. So, I used an Ethernet relay to control the pump directly, and Python to receive the pump commands over the internet. A Python program polls the Inbox of a e-mail account for commands, and commands the relay based on the desired ON time contained in the message. I have another Python program that monitors the pressure of my house's water tank, and automatically calculates the ON time required to fill up the tank. I am not quite confident in the reliability of the whole thing to have my pressure-monitoring Python program automatically send the message to command the water pump: I still manually intervene. I need to add some more logic to detect failures in the pressure monitoring before I go to that point. Not that there have been any failures, but this needs to be robust. I used Python a bit before the project I described above, but **this** project was when I realized that Python was something special. The ease with which I got the whole system up and running was amazing. The documentation and the community saved me quite a bit of cash, and helped me learn.
Try http://pynsist.readthedocs.org/en/latest/
They've built this against python 3.4's unit tests. So it's full python 3.4. However not all of the built ins have been fully ported. The project is still young, but has a strong community with a lot of interest already. 
According to the Kickstarter page: * This is the full Python 3 language, but a subset of the standard library * This is a brand new implementation, written from scratch * You have the overhead of a parser and interpreter (very small compared to CPython), but you have several modes of execution: purely interpreted (default), compiled (each opcode replaced by machine code, takes more RAM, runs much faster), and compiled with integer optimization (each integer is assumed to never go bigger than 2**31, so more optimized machine code can be used). The modes are enabled on a function-by-function basis using decorators. All functions can call each other independently of their execution mode. * There is also support for writing functions with inline assembly, for maximum speed.
Why drop? Use the import future statements and write code that can easily be ported when the time comes. You don't have to rewrite everything you have, but anything new should be written with the fact that Python 2 will eventually lose support in mind. If you start now the new code you write won't have to be updated when that happens, and old cod can be refactored as you go. 
&gt; Because **you refuse** .... nice premise. starting off being accusatory is an awesome way to get your audience interested in your message. I'm guessing the author is not a parent(or a bad one), or had a rough childhood. see slide 2 http://www.slideshare.net/athenamilis/principles-of-writing-a-great-persuasive-speech 
downvoting doesn't make it any less correct :)
Too bad there is no PgDn on my phone. 
Also don't forget that programmers have all the time in the world and love working 80 hour weeks to meet two deadlines now ...
Is that supposed to be some kind of retrospective defence of the compatibility breaking decisions in python3? Not being paid doesn't excuse you for making terrible community breaking decisions, no matter how well intended. Lets just get on with fixing things and moving on with working to slowly migrate over rather than being apologist about it. 
The built-in memoization decorator is pretty cool.
Despite the interface I enjoyed this and even learned a thing or two, despite coding Py3 for ages. :) Didn't realise lru cache was a new feature, keep forgetting it's there. It's pretty wonderful, deserves more usage, especially for pure functions. Haven't toyed with enums either, and Guido's elegant, if mind boggling, asyncio example is intriguing.
Does anyone have this in a non-retarded layout?
thanks so same disk space requirement, like n GB for OS ? do you get to choose a OS ? (my guess is not) 
Swipe up down across the entire screen. I'd still prefer a simple post to slides but it's possible to read the entire presentation.
The space bar, bottom arrow and right arrow also work for me. It's a set of published slides from a presentation given at a PUG ([APUG](http://www.meetup.com/austinpython/) according to the last slide), not a blog post.
ahahah bitbu sucks aimirite?! hail our social coding overlords at github XD
## feature 2 The presentation doesn't make it clear but it completely decouples *default* and *keyword* parameters: Python 3 lets you write def foo(*, bar): pass `bar` is a required *and* keyword-only argument. The one and only way to do this in Python is ``**kwargs`` and ``if 'bar' not in kwargs: raise TypeError("foo() missing 1 required keyword-only argument: 'bar'")`` The one thing which remains impossible in pure Python is positional-only parameters. ## Feature 10 Mentions function annotations, does not mention [Signature objects](https://docs.python.org/3/library/inspect.html#introspecting-callables-with-the-signature-object) which are about 1e24 times better than the P2 introspection APIs on their own, but on top of that they can be easily set on e.g. decorator wrapper functions to easily allow nice (and augmented) introspection. ## Feature X No mention of ``nonlocal``.
_"I have no idea how to use this feature or why it's any good, but you totally can't use it because you're not using Python 3! Also, Unicode variables! And a bunch of syntactic sugar! And... and... a handful of additions to the standard library that you'll probably never use! Did I mention Unicode variables!"_ Grasping at straws much? If you refactored that list down to meaningful changes you're down to three give or take, most of which have very little impact on the majority of code your average Python programmer is writing. I'm so tired of the Python 2 vs 3 discussion. It makes me want to move elsewhere. Use whichever version works for you and stop trying to force your environment on to others because you have some false notion of what's best.
[Jesus Christ...](http://asmeurer.github.io/python3-presentation/slides.html#15) ಠ__ಠ
Is a [terribly broken web interface](http://i.imgur.com/K4cIWiY.png) one of the features?
I was just nitpicking, this really is some nice functional python!
[There you are](https://github.com/asmeurer/python3-presentation/blob/gh-pages/slides.html)
&gt; Presentations are generally accompanied by a speaker who expands on each point. Except when they're not. This is a bloke who posted a presentation of a talk he gave to his PUG, not PyCon. &gt; While it may be cross platform, the navigation needs to still be on the page. Websites are also cross platform, but far more user friendly on various platforms. If this were done in a website fashion (since it's a website and all...) rather than a slideshow fashion, there would've been less issues. If this were done as a website, it wouldn't be done at all, he just published his PUG slides. Hell, he might have given the presentation from the gh page directly.
Django ORM is not bad at all. It's one of the best ORMs out there. We are working on a project with pretty huge database, dozens of models, millions of rows per table, etc. We started a long time ago with raw SQL. Later we switched to SQLAlchemy and later we switched to Django ORM. And from our experience overall performacne of Django ORM is almost same as SQLAlchemy or raw SQL queries. The point is that you have to learn how to use each tool. People usually spend months or years to learn SQL. Then they start using ORM and they thinks that they can master it in days. But ORM isn't magic wand which instantly solves all problems. It takes some time to learn it, like learning SQL does. But in the end, using ORM, especially Django ORM, helps you write your code very fast. And your code is easy to test and maintenance. In fact, the problem with slow SQL queries is usually not because of ORM. With huge database, the database engine will be not fast enough even if you use raw SQL queries. And you will end up using Redis as fast index over your database. But that's different story.
Being condescending when people disagree. I'm guessing you are not a parent(or a bad one), or had a rough childhood.
NoScript activated? JS has been part of the internet since forever. Putting yourself back to stone age is your own fault.
&gt; Presentations are generally accompanied by a speaker who expands on each point. This would've been better as a video of his speech, or at least a transcript. Maybe OP doesn't have either? &gt; If this were done in a website fashion **(since it's a website and all...)** rather than a slideshow fashion, there would've been less issues. It's not a website just because it runs in a browser.
I think the other kinds of graphs we're most interested in generating are line graphs, scatter plots, histograms/bar charts, and map/image plotting (e.g., heat maps, or even just a marker at a location). It sounds like only the last one is really challenging to make?
Not sure what that has to do with anything given where this was posted and the title it was posted with. Sure, the list might have been made with his PUG in mind _(though I doubt it was any more relevant)_, but now it's being presented to this subreddit that sees this topic come up on a nearly daily basis and so I responded in kind.
Replacing MySQL with PostgreSQL is huge boost too.
For the record, you can get a functional backported asyncio in the [trollius module](http://trollius.readthedocs.org). Though I imagine some of the hoops it jumps through to work around the lack of `yield from` may be ugly.
_Sigh..._ &gt; Maybe it's just you who isn't using enough features of Python for the switch to matter. Maybe it's just you who is using a specific subset of Python that makes the switch worthwhile. I'm glad the switch to Python 3 is worthwhile for you. It isn't for me. Why can't you use Python 3 and be happy, while I use Python 2 and be happy, while neither of us try to force our preferred environments on one another?
Why can't people learn or teach themselves Python without advertising the fact all over the internet? Do you feel cooler now?
Oh, I totally agree: the real mistake was linking to a presentation slide deck which wasn't designed for the web
&gt; looking for trouble Are you going to fight him? 
is this not an internet fight?
I hope so. Submitting it would get someone a ton of karma in one of the cringe subs.
i'm too cool for karma. 
Feature 0: Matrix Multiplication Feature 1: Advanced unpacking Feature 2: Keyword only arguments Feature 3: Chained exceptions Feature 4: Fine grained OSError subclasses Feature 5: Everything is an iterator Feature 6: No more comparison of everything to everything Feature 7: yield from Feature 8: asyncio Feature 9: Standard library additions Feature 10: Fun (Unicode variable names etc...)
pyInstaller is really easy and works with little to no modification even for large programs with lots of library imports. It's also the only cross platform exe maker out there.
Um, Python 3 saw its first release in [2008]( https://www.python.org/download/releases/3.0). That's hardly what I'd call a "cool new trend". The reason these pro-python3 posts are popping up is because Python 2 is dead. The chances of seeing a Python 2.8 are pretty slim. You can argue all you want about whether Python 3 is worth switching to or not, but at the end of the day Python 2 is dead. The BDFL has killed it, and any continuation of the code base is going to have to be a fork which would be an even worse situation than we're already in. Frankly the arguments against making the switch sound an awful lot like why IE6 is still around. If it just works, fine, but you can't expect the rest of the world to accommodate your choices. Python 2, and by extension its users, are on the wrong side of history. Whether that's good or bad is beside the point, that's just how its going to be.
 ["%02x" % n for n in range(1, 0xff)] this might help too.
It seems odd to me that python library developers all seem to want to support both versions. In every other example of loss of backwards compatibility, developers have generally said, alright guys, as of v2.3 only NewVersion will be supported. Doing this promotes the migration to newer versions. For some reason this wasn't done in the python world.
It's only "cross platform" in the sense that it double crosses mobile users. 
Don't think that's any more convincing the their time you say it...
Sure, it's cool for presentations but I'd rather have the handout version for reading it myself.
That's pretty awesome! May I suggest reading up on "Finite State Machines" as a model for writing highly robust code of the sort well suited for utility automation? It's a programming paradigm that requires you to explicitly state every possible state your code object can be in, and handle each as a separate case, explicitly stating when and how it can change to another state. You minimise utterly your use of variables, because every variable added is another factor to predict in advance. All of your variables should have predefined states, too. Coupled with Python 3.3's enums (which are perfect for tightly constrained variables and states) it can be pretty effective. Ugly as Python code goes, but easier to predict and debug.
It showed up as an editable text box for me. https://imgur.com/bT75EOB
It's not really a library developer's responsibility to promote migration to newer versions, nor is it really in his immediate interest. In any language. Python library developers usually want to share code with a larger audience, and the largest audience right now is the union of Py2 and Py3 users. If I took some library that I had released a while back which had run under Py2 for years, and made it Py3 only, a lot of people would complain, and they'd just use something else. Which, to be honest, sounds pretty good about now, but that's a different topic entirely, and isn't representative of all lib devs. ;-)
mind helping me out? this whole working through the cmd is new to me here's what my script says: cmd "/c cd ANACONDA\Scripts\ &amp;&amp; start "" "ipython.exe" --profile econometrics" could you elaborate on running cmd.exe with the /K flag even means? Sorry lol thanks for any help! ***EDIT***: ok so i ran it with the /K flag and the message is "The system cannot find the path specified" any ideas how to fix the path?
I can't upgrade. I'm a tools/pipeline dev for Autodesk Maya. We're stuck in Maya 2012 for the next several years, and it has 2.6 (not even 2.7) baked into it in a way that's difficult to change, especially across multiple studios' worth of people. All of this antagonism about 3.x has honestly pushed me away from Python. I'm enjoying Clojure, Haskell, and various other languages and coming back to Python and feeling very incapable of doing the rich things I'm doing in those other spaces. Shovel on all the bitching about 3.x, and I've honestly stopped praising and recommending Python to anyone. I've also noticed that tutorials, books, and tech talks increasingly *don't* mention Python when they talk about dynamic languages. They say things like "If you're using a dynamic language, like Perl, Ruby, or Javascript..." I've noticed this distinct lack across mediums no fewer than 5 times lately, and I'm starting to join them. "...because you refuse to upgrade to Python 3?" Fuck you.
More like CANT upgrade because python3 doesn't support things we need from 2.7
A pdf version is now available: http://asmeurer.github.io/python3-presentation/python3-presentation.pdf
Is it just me, or is the thought of changing def func(a, b, *args): pass to def func(*args): a, b, *args = args pass infuriating? 
For those not running Windows, if this script does what I think it does, adding xterm-256 support is trivial. `color`: import sys sys.stdout.write('\033[H\033[48;5;{}m\033[J'.format(int(sys.argv[1], 16))) sys.stdout.flush() `cls`: import sys sys.stdout.write('\033[H\033[J') sys.stdout.flush() Then: chmod +x color cls PATH=$PATH:. python2 disco.py The only problem is that the script runs `color 0f` at the end, and it's highly unlikely that `0f` (white) is your default background color. Use `echo -ne '\033[49m\033[H\033[J'` to fix that.
This is my largest project I've made. It uses the standard library extensively so you might learn something https://github.com/boarpig/issue It's a little issue tracker I made because I use my Raspberry Pi as a git server with cgit fronted and cgit doesn't have an issue tracker.
Definitely not just you. I have no idea why he included that.
Python 2 is dead in the same way that ANSI C is dead: so dead that it remains the language's de facto standard despite Guido/ISO telling everyone to move on already. Python is a programming language, not a religion. No one cares if they are on the "wrong side of history"; all that matters is if you can still use it to write cool programs.
Not to mention, the decision to make everything unicode makes Python 3 next to useless for Linux users, as the file system still uses ASCII.
I see it being more useful with iterables in general. I don't think I'd ever consider using it with *args, personally. I do know that there have been plenty of times I wanted to use `first, *_, last = my_iterable` in Python 2...
Of course, I agree. I still use 2.7 and probably will for a long time due to legacy reasons, but rest-unpacking is something I find myself wishing I had quite often. This presentation has a lot of good stuff in it, but it also has a lot of bizarre examples and useless slides.
Ah yes, you were referring to the choice of example for that feature. Indeed, some of them were not the greatest.
&gt; Why can't you use Python 3 and be happy, while I use Python 2 and be happy, while neither of us try to force our preferred environments on one another? Because &gt; Grasping at straws much? If you refactored that list down to meaningful changes you're down to three give or take, most of which have very little impact on the majority of code your average Python programmer is writing. If people like you would stop acting like no one uses these features, when they probably wouldn't have made it into the language if there wasn't a good reason, then more developers and library authors might be encouraged to make the switch. If you're using a subset of Python that isn't impacted much by the changes then what's the big deal for you?
Meh, come back when it has at least 3x+ performance over current Python 2. All those things are still not worth bothering to switch for me.
From the PDF you linked: (PDF page 17, text page 5) &gt; If Anaconda is not added to the system path, it is necessary to add the &gt; ANACONDA &gt; and &gt; ANACONDA\Scripts &gt; directories to the PATH using &gt; set PATH=ANACONDA;ANACONDA\Scripts;%PATH% I'm not totally sure if that'll stay permanent, you can try that and if not just do it from the GUI. Full explanation how to do that here http://superuser.com/questions/284342/what-are-path-and-other-environment-variables-and-how-can-i-set-or-use-them Relevant default dirs to set being "C:\ANACONDA" and "C:\ANACONDA\Scripts" it'd seem.
"You know, I really think Perl got function argument passing right. Lets make Python do that!"
To some degree it depends on the system, on Ubuntu and Mac I would not attempt to update the system Python it may bork the system let the release/update manger handle that. On Non-system provided Pythons,, you are probably fine to update.. (within series, eg 3 series and 2 series)
It is not so mind-boggling once you get used to it. I attempted to implement a coroutine style asynchronous I/O interface in Python 2 because I wanted to do a little bit of io bound work at the time while controlling the rest of the event loop. It worked great, except for passing values back up N generators (where n&gt;1). Suddenly, yield from became an exceptionally useful idea.
I think you may be wrong: https://github.com/kdave/btrfs-devel/blob/master/Documentation/unicode.txt Hell, Linux even supports Klingon. That being said, if you use UTF8, you will have backwards compatibility with ASCII. 
What's holding my team is a MIT licensed MySQL/MariDB connector which is safe/fast to use in production.
the very same hoops guido used when he had a similar api working on appengine(ndb) basically using raise in new and exciting ways. https://developers.google.com/appengine/docs/python/ndb/async 
virtualenv doesn't actually install Python into the environment; instead, it creates symlinks to the ones already available on your computer. Also, different versions of Python do not conflict with each other, so you can install 3.4 and have, say, 2.7 and 3.3 available at the same time with no problem. You can choose which one to run by appending the version to the name of the command, e.g. writing `python2.7` in the command line would start 2.7, while `pip3.4 install something` would install a package for Python 3.4.
Having not ported my work projects to python3 yet- whats missing that 2.7 has (other than 3rd party modules)?
&gt;Maybe OP doesn't have either? Clearly he doesn't. The suggestion is to get one. &gt;It's not a website just because it runs in a browser. False.
This is missing: &lt;noscript&gt;This needs JavaScript.&lt;/noscript&gt; 
Feature 12: $ python2 /usr/lib64/python2.7/test/pystone.py Pystone(1.1) time for 50000 passes = 0.457157 This machine benchmarks at 109372 pystones/second $ python3 /usr/lib64/python3.3/test/pystone.py Pystone(1.1) time for 50000 passes = 0.536222 This machine benchmarks at 93245 pystones/second
Gotta learn somehow! Your first issue is actually probably the `cd` command (that is "change directory"). Unless you are in a folder that contains "ANACONDA", the path is not known by the system. Options 1 is that you provide the absolute path to the folder (something like `C:\Users\You\ANACONDA\...`) as opposed to the "relative path" (relative to where you are running from). It appears, at least according to your command, that there is an executable in the Scripts folder called "ipython.exe", so you shouldn't actually need to edit your `%PATH%`. Note how windows checks for an exe (I don't recall which is first user or system, but that is seemingly irrelevant to the first issue): 1. Local directory 2. User %PATH% 3. System %PATH%
Thanks! Actually, it is not the software that I am worried about as much as some other aspects of the system. I have two worries about robustness: * The commands are going over the internet. The internet is not very reliable for this type of control. The Python program that is polling the e-mail Inbox is working over satellite. * I don't want leaks/broken pipes to flood my basement. After setting this system up, I had an incident where a plastic to copper fitting failed, and drained all of the water in the tank in my basement. If I had implemented the automatic charge command, my basement would have been flooded. I have already tested out using Xbee radios (instead of the internet connection) to send the relay commands. I have been using a Xbee to monitor the pressure in my water tank (to save me the trip downstairs everyday). So, I am pretty comfortable that I can make it work. For the leak monitoring, I need to write some code to watch the pressure sensor for anomalies. 
Python 2's keyword arguments are nothing more than a way to reorder parameters if you see fit or explicitly list the *name* of the positional argument you're filling. def f(a, b): pass f(b=1, a=2) Everything else is (conceptually) positional arguments annotated with default values (in case they're not specified).
&gt; other than 3rd party modules Nothing. Some people need those third party modules, but I suspect it's easier to upgrade than most people give Python credit for.
Thanks, it's starting to make a lot more sense! I ultimately just tinkered around and got it to work by changing: &gt; cmd "/c cd ANACONDA\Scripts\ &amp;&amp; start "" "ipython.exe" --profile econometrics" into: &gt; cmd "/c cd Scripts\ &amp;&amp; start "" "ipython.exe" --profile=econometrics" I guess i was starting in the anaconda directory to begin with?
Looks like it! Good work.
They made improvements to the language - Open a notepad - Change some syntax - Stop crying
Now that that's working, I've got one last question! If you look at the code under section **1.5.3 Configuring Python** on page 8 (as they're numbered at the bottom): any chance you could shed some light on this part?: &gt; "import os", "os.chdir('**c:\\dir\\to\\start\\in**')" this is giving me troubles in my ipython_config.py file so originally I wrote it in verbatim cuz I had no idea what I was doing lol, but after errors and looking at it, I realized that the author is telling you to write in the directory to start in. I can't tell what directory is the appropriate one for this. I ultimately just deleted those bits altogether to get it to run, but I figure they were there for a reason so I should get it right lol
Even with NoScript disabled, it doesn't get much better.
Yeah, I disabled it and saw. Depressing either way, and the info doesn't even need javascript to be presented in that manner.
The NullHandler seems counter intuitive, considering people use logging **to print/stream things**. For most uses, StreamHandler is what you want.
Thank you! That makes sense 
I see now. Thanks a lot
Thanks. The gitignore file was what I was thinking about. I've seen people talking about it and excluding files from the repo but wasn't sure what files to include. 
Thanks. That helps a lot. I'll check out those links. 
Thanks. I think this is where I went wrong initially. I never really knew there was a difference between git and GitHub and tried to push everything to github initially and was completely lost. 
I second the Python 3 Object Oriented Programming book. It's so clear and things just made sense once I read through that.
Yes very annoying! Line 645 in excel.py is the culprit.
i started reading the python design patterns. but it has camel case functions and a very simple loop doing list.append that could easily be a list comprehension. not sure if i can trust that book anymore :s. also this `def defectList(self, list, category):` naming a list param as list is like naming your dog as dog
Yeah, let me retract 'pythonic' and in it's place put in 'using python.' On the list front though, it's not *great*, but overriding defaults isn't necessarily a terrible thing. I override `id` and `hash` every single day. I wouldn't personally ever override `list` or `dict`, but I can't fault a person for doing so. To be honest though, I only skimmed it when I got it. I was hoping for a more in depth treatment, but I thought it looked fine at first blush and that's why I recommended it. Perhaps 'great' was a bit of an overstatement.
In most cases where you're logging things, what you want is almost certainly by default to have no output. After all, if you imported, say, requests, and it started printing out everything it was doing to all sorts of outputs you'd probably get a bit annoyed. Unfortunately, `logging` requires the presence of at least one log handler for messages to go to, and if you're after silent-by-default logging, you need to put a log handler there that just doesn't do anything. Of course when you import your logged-up module into your main app and start debugging it, you can turn on output by adding a second handler to the logger. And then when you make it into production, you can remove the second handler, and add a new one that logs to file, and an email alert handler for critical failures, and whatever else you like. People give `logging` a lot of stick, and tbh it deserves some of it for the mediocre documentation, the need for NullHandlers, and the fact that probably too much logic is shared between Loggers and Handlers. OTOH, for complex applications that require more than just three files, it's probably the best logging system in the Python ecosystem, and it works brilliantly. It should really be used more often.
&gt;&gt; It's not a website just because it runs in a browser. &gt;False. Define "in a website fashion" then.
yeah my main concern is that a person who wrote it maybe a great programmer who knows how to explain patterns but its something i learned on a pycon talk. "dont follow tutorials who import * unless they do mention is bad and its only for practical reasons that is done for the demo" (not exact quote but something like that). If i learn to implement a pattern in a non pythonic way i will be twice as bad compared to not knowing the pattern. (i dont say this is the case but could be)
What's wrong with using the root logger?
&gt;The one thing which remains impossible in pure Python is positional-only parameters. Hopefully not for long, as there's a pep open for them. That should be point 0 - You miss out new development in Python 2.
Is there a guide on how to write new 2.6/2.7 code to work with 3?
Since it's the Python subreddit, I assume you want Python related answers. My favorite Python related book is "Expert Python Programming" by Tarek Ziade. After reading it, my Python skills became aloud better. I'm eager to find the next book that will bump me to next level. If I would be a Python newbie, I'd probably choose LPTHW instead, but I started diving into Python long before this book was written.
I think [six](http://pythonhosted.org/six/) aims for this (or better said, aims for code that can work in both), never used it so I'm not sure if it has a "guide" other that its own reference.
you don't realize people don't like to be forced to do stuff just for the sake of pleasing a few core devs. in most other communities I know (PHP, Ruby, Js) these kind of changes are welcome because the basic language is so broken that any improvement is worth the compatibility issues, people hate version X so they jump into version X+1 at the first opportunity just to stay away from the previous, this isn't the case for Python. Python 2 works, there's room for improvement and that is accepted but there's not enough motivation to leave it because it's not broken, it's as simple as that. I can compare this situation with Java, Java people also have a very stable and robust core language so when new versions are released it takes decades for people to stop using the old ones.
&gt; it's all about empowering programmer kids to feel cool, right? And the coolest people jump on the coolest new trends with no concern for their maturity or usefulness, simply because they're so damn cool. this was always the feeling I got from the Ruby/Rails community, it's *so* sad that it's being forced upon us now.
I went ahead and signed up. Been looking for a way to get started and this looked perfect. Just need to order the book now...
Nine times out of ten, when I use logging, I want to see it logged. When other modules I've imported printed stuff I didn't want, it was as simple as locating their logger variable and mute it. 
I won't discuss how long it took me to work this out, and whether or not I gave up for a bit and just downloaded/read the PDF before coming back to it.....
&gt;Actually a pretty cool thing because it's actually cross-platform. Yes. it's equally confusing no matter what you're viewing it on. ;-)
Thanks. Stopped after 10 slides being 99% empty and repeats. 
It's just such a well written book. I find OOP to be one of the hardest concepts to get people into, and this book explains why OOP *can* be appropriate better than I ever can. Edit: I love giving it to Java programmers particularly. They tend to go OOP fucking crazy in Python, and they seem to immediately grok the lessons of when OOP is appropriate when they read this. Edit 2: OOP is sounding funny with how many times I've typed it today. OOP.
I think scatter plots shouldn't be too difficult since their use case is almost identical to line graphs. Supporting histograms and bar charts can be more effort if I want to make it useful/easy to use within the wrapper. The simplest approach would be to just support all the matplotlib `*args` and `**kwargs` for bar plots and forward them along, but there are other things like bar labels, and aligning them correctly, etc. Normally one has to do this externally using the OO matplotlib model and by operating on the axes instance. Prettyplotlib has some support for making the labeling easier in bar plots. I guess what I'm saying is that it would take a bit of thought and planning to support some of the other plot types if the goal is to make the wrapper truly useful and easier to use. Additionally, supporting other matplotlib plot types will result in the need for a major update to EasyPlot because I will need to break the current API since in its current form, the EasyPlot object is implicitly assumed to be a line plot object. I think I will probably try to work on this in my spare time as and when I can, but it will likely take a while to release a comprehensive update as I will probably need to think hard about how to design things going forward with the larger scope of the library. I'll probably have to do a decent bit of refactoring too. Of course, help from other contributors is always welcome ;-). I'll try to ping you if and when I do manage to release an update. Cheers
Hmmm ok ya I just had no idea what destination I was ultimately looking for haha Ok so if the anaconda folder is directly on the c drive (c://anaconda), will the param just be *os.chdir(c://)*? Or is the param just unnecessary then? Not able to test til tomorrow Also thanks a ton for helping me out with this. I've learned a bit of python but all of this "path" and working in the cmd stuff is all Chinese to me but I like that it's starting to make more and more sense to me!
&gt; If I took some library that I had released a while back which had run under Py2 for years, and made it Py3 only, a lot of people would complain, and they'd just use something else. It's not like the old versions of the library stops working. Why does everyone care about keeping up to date with everything except Python itself?
_Alice in Wonderland_ is the best book for the novice.
For library code, I'd just as soon use `logging` and avoid an extra dependency.
The `NullHandler` docs specifically recommend using it in precisely the way shown. It prevents the logging system from barfing on "this log message isn't handled anywhere." **When writing a library**, such barfing would be extremely annoying to your clients. Since libraries shouldn't generate logs without the client application's permission, this is the Right Thing to do.
The `logging` docs [disagree with you](https://docs.python.org/3/howto/logging.html#library-config). IMHO a library should not just spew random things on stderr, but if the client application asks for logging (e.g. via `logging.basicConfig()`), you should provide it.
Why would anyone want to do that? Then the caller has no idea that a and b are required, right? Or am I missing something.
Is this on a Windows machine? If so, it's a little confusing because installation involves registry settings and who-knows-what-all. That said, you can install a second version of python and you shouldn't run into many difficulties. On Linux or a Mac, you can simply extract a different version of python into a different directory and all should be fine. You can then setup aliases so that, say, `python` refers to 2.7 and `python3` refers to 3.4. All that said, the best solution I think is to use Miniconda and just create Python environments as you need them. For example, setting up a python 2.7 environment is as simple as conda create -n py27 python=2.7 And then to activate the environment: activate py27 or if you're in Linux or a Mac: source activate py27 You can still use `pip install` as normal to install packages, but even better is to use `conda install` whenever packages are available through Conda. 
Thanks! I'll keep an eye on the repository. I have a lot of other concerns to get this course up and running this summer, but I'll add this on the "wishlist".
i say it "num" + "pie"
Technically, I imagine it should be "pie", to match sci-py, etc. But more Pythonically, Numpee, because that's how Cleese would say it.
You'd think virtualenv would have this feature. Makes a lot of sense. 
Rust seems like an interesting upcoming "lowish-level" language. http://www.rust-lang.org/ Maybe you'll enjoy this more?
You're right, it's definitely "num" as in number + "py" as in Python.
https://en.wikipedia.org/wiki/John_Cleese
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**John Cleese**](https://en.wikipedia.org/wiki/John%20Cleese): [](#sfw) --- &gt;__John Marwood Cleese__ (/ˈkliːz/; born 27 October 1939) is an English actor, comedian, writer and film producer. He achieved success at the [Edinburgh Festival Fringe](https://en.wikipedia.org/wiki/Edinburgh_Festival_Fringe) and as a scriptwriter and performer on *[The Frost Report](https://en.wikipedia.org/wiki/The_Frost_Report)*. In the late 1960s, he co-founded [Monty Python](https://en.wikipedia.org/wiki/Monty_Python), the comedy troupe responsible for the [sketch show](https://en.wikipedia.org/wiki/Sketch_show) *[Monty Python's Flying Circus](https://en.wikipedia.org/wiki/Monty_Python%27s_Flying_Circus)* and the four Monty Python films: *[And Now for Something Completely Different](https://en.wikipedia.org/wiki/And_Now_for_Something_Completely_Different)*, *[Monty Python and the Holy Grail](https://en.wikipedia.org/wiki/Monty_Python_and_the_Holy_Grail)*, *[Life of Brian](https://en.wikipedia.org/wiki/Monty_Python%27s_Life_of_Brian)* and *[The Meaning of Life](https://en.wikipedia.org/wiki/Monty_Python%27s_The_Meaning_of_Life)*. &gt;==== &gt;[**Image**](https://i.imgur.com/dw865RX.jpg) [^(i)](https://commons.wikimedia.org/wiki/File:John_Cleese_2008_bigger_crop.jpg) --- ^Interesting: [^Wine ^for ^the ^Confused](https://en.wikipedia.org/wiki/Wine_for_the_Confused) ^| [^Monty ^Python](https://en.wikipedia.org/wiki/Monty_Python) ^| [^A ^Fish ^Called ^Wanda](https://en.wikipedia.org/wiki/A_Fish_Called_Wanda) ^| [^Fawlty ^Towers](https://en.wikipedia.org/wiki/Fawlty_Towers) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+chw696t) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+chw696t)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Well, Python isn't pronounced "peethon" so I'd say you're right.
What about [oursql](https://pythonhosted.org/oursql/)?
Ouch. If it makes you feel any better, I know exactly what you mean. That (embedding python) was one of the major breaking changes in the 3.x line, and it's a real pain to fix. I strongly recommend you guys have a look at embedding pypy; http://pypy.readthedocs.org/en/latest/embedding.html They're actually really on the ball, and the pypy guys are really helpful about it if you ask. 
I'm not sure what you mean by this. Are you saying we should embed Python 3 into Maya?
You couldn't say which?
All but 5,6 and 10 could be backported to Python 2 and they should. 10) is a really BAD IDEA. variable names should be in ascii. Software has brought people together across continents because they could share their code and understand it. They should not write code that can only be understood in their native language. 5) simply breaks everybody's code. having range and xrange was fine. In fact being able to do "print range()" helps explain to newbies what loops are about. Now you cannot do that any more in python 3. 6) Why? Why can't I do this ['a',1,None].sort() any more if I want to? It does not matter that the order is unspecified outside of the language itself.
pypy will (going forward) apparently support both py2 and py3 code; and is significantly eaiser to embed than cpython (see http://pypy.org/py3donate.html)
Numpee, and Scipy is pronounced skippy.
I am inspired to start pronouncing it NOOM-pie, since "num" is derived from the former name, Numeric, which is pronounced with a "noom". Of course, no one will hear me, because I am alone.
Sci pie See the docs. http://www.scipy.org/. And num pie as in number.
Iterators causing silent errors? Have you even tried them? I've been devving with iterators for ages, never had a problem sourcing a traceback, and they fail just as fast as lists. If anything, the stricter comparisons around types kill most of the sorts of silent/submarine errors one would create in loops and iterations in the first place. As a native py3 dev, I was surprised to learn that Py2 *ever* allowed that dumb JS-like comparison format.
Damn skippy!
Numpy, like "numpty" without the t.
Thanks. It would have been terrible if we'd *all* missed that acknowledgement in my first comment and gone straight to the humour. 
"In my day we were looky to 'ave a noompee!"
Well, we actually *spell* "aluminium" ~~better~~differently, so that's hardly the same. But new words tend to be more standardized, because there's less time for the pronunciation to diverge.
The guy at your internship is pronouncing it wrong. Unpythonically, even.
&gt; My take on this is that Python 3 proponents have to stop pushing Python 3 on people. From the article: &gt; Not everybody can forget about Python 2 completely right now, but not everybody needs to move to Python 3 at all, or to use any particular programming language for that matter. Go do what makes you happy. &gt; What makes me happy is using Python 3. --- The only reason people seem to do this is because people *attack* Python 3 with so much fervour. Move when you want. There are *masses* of support for people using Python 2. Nobody sane is arguing with that. We're just asking you to allow people *not* tied down to be able to use version 3 without having a hundred "Python 3 sucks", "Python 3 can't do bytes", "Python 3 is killing Python", "Nobody uses Python 3" posts thrown at us. 
On the other hand, I have found it useful *many* times if a library does logging. My most used example is `sqlalchemy`. In my opinion it adds a lot of debugging value to a library. But only if used correctly! And the "used correctly" is not easy to get right :( For example: An error in a library can easily be seen as a `debug` message in to application which uses the library. If on the other hand, the library does not do any logging whatsoever, you need to pull out the interactive debugger. Which is still nice, but sometimes more cumbersome than simply increasing a logger's verbosity.
Loggers are organised in a heirarchy: that is, the logger for `requests` is a parent of the logger for `requests.adapters`, and so on. You can affect the output of all child loggers by changing the parent, so if I want to change all of the requests loggers in one go I can just set values on the parent logger. However, if I want to change one specific part of the library's logging, I can do that too. If you log using the root logger, however, you can no longer single out your logging. The only way to turn your logging on is to turn everyone else's on, and the only way to turn your logging off is to turn everyone else's off.
&gt; "Exciting" new features look fragile and unproven to me. If Python 3's features are "unproven" (maybe other than `asyncio`) to you, you better not release any code until millions of people have used it rigorously for five years.
I can totally see that, but I've had to gut libraries to the core before because of performance concerns. The most notable one I can think of is the `construct`library. I want to encode a few million structs with a single pascal string? Be prepared to incur a few million rounds of logging. Looking at the source now it looks "fixed," but it was so unbearable under PyPy that I had to write my own struct packer. My solution? We need a better optional flag than \_\_debug\_\_ that totally disables debugging without the current if/else concerns. There has to be some fucking way.
Sure, that works for simple apps where the logs are the program's way of communicating with the outside world, or when you're quickly trying to debug a fault. But in that sort of case, `print` is probably your best friend, not importing logging and messing around with that. Logging from a library is generally something you want to be doing for long-running processes, or processes where you aren't going to be around when the library breaks.
Especially when writing a library, using the root logger will pollute the library-user's log messages. Loggers are attached to each other forming a tree (the `.` in the name is the branching point). So by using `__name__` as the logger's name will give you a tree-structure mimicking your package/module structure. Each logger can be enabled, disabled or configured to your heart's content. If left unconfigured, a message will travel up the tree structure (triggering each handler on the way up) until it hits the root logger. You can prevent this "bubbling up" of messages by setting `propagate` to `False` on a logger however. This means, that I as a user of your library can always silence *your* logger *only* whenever I want to. Or attach different handlers. F. ex. redirecting all log messages from your library to a separate file, with filters if need be. If you use the root logger, I am *forced* to do all these operations for *all* log messages. Even my own.
People still hate PDFs, but at least FF's pdf.js helps ease the pain a bit.
&gt; Unfortunately, logging requires the presence of at least one log handler for messages to go to Hmmm... I never encountered this problem. I found that if there's no handler defined, Python 2 will simply emit a warning that no handler is configured, and Python 3 will create an implicit handler logging everything above `WARNING` to stderr. In which scenario does Python *require* a handler?
http://dilbert.com/2014-05-22/
Or spicy 
I remember reading somewhere that the general consensus is to use [`isEnabledFor(lvl)`](https://docs.python.org/2/library/logging.html?highlight=logging#logging.Logger.isEnabledFor). But to me this seems just a bit like an excuse. The rationale behind it is that with only one if-statement you can skip the whole logging machinery which *is* quite heavy. But it's *so* verbose that I have never seen someone use it. Imagine wrapping *all* your log statements with a separate `if` statement... -_- You could argue however, that a library which is prone to be called upon a few million times should have the discipline to add these branches. At *least* on critical locations. It's sub-optimal, because you *still* have to execute that one branch, but it is better than nothing. I like the way it's done in google-closure. It has `goog.DEBUG` and it that is set to false, the compiler will rip out those blocks from the output. As if they had never been there. Pretty much like a precompiler condition. [ ... 5 minutes later ... ] I made a quick test: def foo(): if __debug__: print(1) def foo2(x): if x: print(2) import dis dis.dis(foo) print('------------------------------') dis.dis(foo2) And here's the output (without the optimized flag): › python foo.py 3 0 LOAD_CONST 1 (1) 3 PRINT_ITEM 4 PRINT_NEWLINE 5 LOAD_CONST 0 (None) 8 RETURN_VALUE ------------------------------ 7 0 LOAD_FAST 0 (x) 3 POP_JUMP_IF_FALSE 14 8 6 LOAD_CONST 1 (2) 9 PRINT_ITEM 10 PRINT_NEWLINE 11 JUMP_FORWARD 0 (to 14) &gt;&gt; 14 LOAD_CONST 0 (None) 17 RETURN_VALUE And now *with* the optimized flag: 2 0 LOAD_CONST 0 (None) 3 RETURN_VALUE ------------------------------ 7 0 LOAD_FAST 0 (x) 3 POP_JUMP_IF_FALSE 14 8 6 LOAD_CONST 1 (2) 9 PRINT_ITEM 10 PRINT_NEWLINE 11 JUMP_FORWARD 0 (to 14) &gt;&gt; 14 LOAD_CONST 0 (None) 17 RETURN_VALUE You can see that there's no difference for `foo2`. They handle the branch in both the "optimized" and non-"optimized" execution. The call to `foo`, which is using the `__debug__` branch is actually very different. It seems that the Python compiler is aware of the `__debug__` flag an much smarter about it than I thought!
The author and most Scipy community members pronounce it to rhyme with "numb pie". I do occasionally hear "numb pee" and even "noom pee" (by some Europeans iirc), but never "noom pie". Scipy is almost never mispronounced, although it's pretty hilarious when someone does. ("Skippy", anyone?)
i have this book :) 
Because everyone has to use the same parts of a language? Yield from adds little to nothing in terms of new capability, and ways of doing asynchronous IO (in effect) already exist in 2.
Slow implementation becomes slower.
Nice, thanks.
got this book since April, early release... I highly recommended it
0: '@' was added by request of the numpy team. The argument is that S = (H @ beta - r).T @ inv(H @ V @ H.T) @ (H @ beta - r) is much easier to understand than S = (H.dot(beta) - r).T.dot(inv(H.dot(V).dot(H.T))).dot(H.dot(beta) - r) especially given the original formula &gt; S=(Hβ-r)T(HVHT) -1(Hβ-r) See [pep 465](http://legacy.python.org/dev/peps/pep-0465/) for details.
data = headers, not headers = headers.
Still necessary. `c:/` should be fine for the parameter. That said, normally windows uses `\` to delimit the file path (but that's an 'escape character' in most programming languages, so they often allow you to use `/`).
 &gt;All but 5,6 and 10 could be backported to Python 2 and they should. 10) is a really BAD IDEA. variable names should be in ascii. I have to disagree with this point completely. ASCII is way to limiting when it comes to expressing succinct code even in English. This especially the cases for math symbols, Greek and other common languages (alphabets) used in the sciences. I actually sit here wondering what took so damn long for any language to grow outside of the world of ASCII. &gt;Software has brought people together across continents because they could share their code and understand it. They should not write code that can only be understood in their native language. You do realize that ASCII is based on a native language, in this case English right. If you are a native to another country anything beyond the core symbols in code is Greek to you. I have some experience here with code written in Germany and frankly without a dictionary you won't understand it. They used the ASCII character set too. &gt;5) simply breaks everybody's code. having range and xrange was fine. In fact being able to do "print range()" helps explain to newbies what loops are about. How does "print range() help explain loops to newbies? Seriously guy if you are doing this to a newbie you are not doing him any favors. &gt; Now you cannot do that any more in python 3. 6) Why? Why can't I do this ['a',1,None].sort() any more if I want to? It does not matter that the order is unspecified outside of the language itself. Some people are stuck is a BASIC world and can't move forward. I went to Python 3 as soon as I could because I was smart enough to open my mind to the new concepts and realize that yeah this makes for a better language. Some people have great difficulty doing that. That doesn't mean that Python 3 is perfect just that it is a real improvement over previous versions. 
The funny thing here is that the interface didn't bother me as much as the tiny type. Frankly it doesn't matter if you are reading on an iPad (me) or on a projection onto a large screen, people tend to use fonts that are way to small for such presentations. Yes I'm an old guy but I think the point is valid, one should waste so many pixels on white space for no good reason. Given that I did like the content of the presentation. 
Thus my comment above about font size and excessive white space. If we ignore the content and just focus on the audience, especially the people in the back of the room, I think you would get similar comments about the legibility of the slides. To my mind the lack of readability detracts from the content no mater if you are in support of the content or not. I just think people need to think about the audience to a greater extent when designing their slides. 
PDF's are fine these days. Seriously I seldom have trouble with PDF's compared to really bad web sites. Of course simple HTML should never be a problem, but with PDFs im reasonable sure I can print the data or forward it to somebody. 
I've heard of Stata, but I don't know too much about it. But I've been a data analyst for 16 years, so maybe I can provide some insight. The field of data analysis is so broad, but since that company is using Stata, I will assume the position will involve doing statistical analysis work. What I find are some of the the determining factors on which tools are useful for data analysis hinges upon how "clean" or readily available the data is, how it needs to be stored and how you need to present or share the data. The more dirty and disparate the sources of data is, or basically, the more things you have to do outside of strictly data analysis, the more likely you'll need to use a general purpose programming language like Python. Where I work, the data I have is dirty or in a format which is not very useful in its initial form. So what I usually do is format it or transform it. This is sometimes refer to as data munging or data clean-up in some circles of data analysts. Then I also have to save the data permanently into a database. Again, because Python is a general purpose language, it has libraries that allow you to perform data munging and database processing like inserting, retrieving, updating records in a table. Then of course, I can analyze the data in Python or Excel or whatever appropriate tools are available. One advantage of Python is if you have a need to share your data or findings with other people, you can run a Python web server or IPython notebook server. Again I am not too familiar with Stata, so it may or may not have these other capabilities, but my guess is it doesn't. I think it is a domain specific language or tool for statistical analysis. Again, not knowing the working environment of that position, the prospective employer may or may not find these tasks or skills relevant. In some companies, these tasks above can be done by IT or systems people and not done by data analysts. I guess people may consider me a full-stack data analyst or data scientist. But I am not too keen in all the buzz words surrounding data analysis. I just adapt or learn the skills needed to perform my job well and efficiently. Hope this helps and good luck! EDIT: Depending on how complex or statistics heavy the position requires, Python's ecosystem for statistics may not be as robust as Stata. In Python's world you have scipy and statsmodels for statistics-related packages. They may or not be up to par with what Stata can provide.
I learned it for work, horrid third party software was using a gimped python interpreter for their user scripting. I slowly rebuilt said third party software entirely in python/cython/c. So I have a package that will take interferometry data, mask it, extract the phase, unwrap the phase, and apply zernike fits to the wavefront, stick all the relevant numbers to an excel file for later data processing. Fun side note, I had to email 700 pictures from a trip to Atlanta to my mother, each picture was 8mb. In about 10 lines and 15 minutes, I had a script crawl the directory and convert every image down to 10% it's original size.
 &gt;Is that supposed to be some kind of retrospective defence of the compatibility breaking decisions in python3? You do realize that this is a major revision going from 2-3. From the standpoint of software in general. API get Broken, updated and otherwise deprecated all the time, at least here there is a clear translation. Beyond that most of the constant whining seen in forums like this wouldn't even exist if developers had got on board when Python 3 was first being out forward. How many years has it been now? Really the whining makes about as much sense as a C programmer that can't move beyond K&amp;R. &gt;Not being paid doesn't excuse you for making terrible community breaking decisions, no matter how well intended. It is your opinion that the changes are terrible, many of us feel far differently. The changes effectively give us a platform that will be good for decades. &gt;Lets just get on with fixing things and moving on with working to slowly migrate over rather than being apologist about it. This is certainly a good idea. The problem here is that most of the crap heard on the forums wouldn't even be a problem if people had started to adapt when Python 3 first started to come on the market. Really this negativity reminds me of the stories about the Luddites afraid of new methods going about destroying the machinery that could keep them employed and productive. 
Which is no different than what you are hearing here about support for Python 2. Make a library that is Python 3 only and you get shit even though that is the right thing to do. The interesting thing here is that in the programming world in general, library developers write code for the latest language standards not the historical ones. It doesn't really matter what the language is, in the end the library creator leverages what is new to make for a more robust solution. You can see this in C++, Apples Objective C and many other common programming languages. None of these new libraries would work on older compilers nor should they. Yet in the PytHon world we have a bunch of idiots that are apparently to self important to adapt. So I have to ask what makes them so special? I have a theory here that the problem is that Python attracts the wrong types of developers. That is people that choose the language as a crutch to support their lack of skill and commitment. Not that that is a bad thing as I often use Python for exactly that reason. The problem is when such people are in the position of developing libraries and such as they effectively become a big anchor on the entire community. It is to the point now that I'd rather see these boat anchors move on to something else and free the Python community from their ignorance and slough. 
I found a copy of Learning Python, the second on the list, and a bunch of others on a trade market. I'm new to python and want to learn it, IS the book still viable to use with the newer versions?
&gt; Why can't I do this ['a',1,None].sort() any more if I want to? because you can't do `x = 'a' + 1 + None` in Python 2 either.
/r/pystats/ offers a lot of information to learn about data/statistical analysis. 
 &gt;Python 2 is dead in the same way that ANSI C is dead: OK so how many revisions of C has the world seen? &gt;so dead that it remains the language's de facto standard despite Guido/ISO telling everyone to move on already. Python is a programming language, not a religion. Exactly and like all languages they either evolve over time or become a part of history. This isn't any different than C programmers being told to put away their K&amp;R's and use the latest libraries and features. The reluctance to. Move forward here is at best perplexing and at worst a sign if deep problems in the Python world. I don't know of any other platform where developers are so reluctant to adapt to what is new. &gt;No one cares if they are on the "wrong side of history"; all that matters is if you can still use it to write cool programs. Then you have a perspective problem. Cool programs that aren't maintainable and upgradable over time are not of much use to anybody. It would be like a C++ programmer proclaiming that he has this cool program that targets a C++ compiler from the 90's. Hell it may even build on a modern compiler, however if it doesn't use modern techniques is anybody in the C++ community going to care? Probably not and in fact such a programmer would likely catch hell. This would even be more so if we are talking about a library intended for wide usage. So what in the hell is wrong with the Python community that such people are being supported at all? 
Purchased a few days ago. Fantastic so far! 
Raising an exception and issuing a log message are appropriate to entirely different scenarios. I don't see how one can replace the other.
Algebra 101. The existence of an ordering relation does not imply a Group in the mathematical sense. i.e. you can define a&lt;b without defining a+b. You define "a"&lt;"b" even if "a"-"b" is not possible. With your logic you would not implement "a"+"b" because you cannot define "a"-"b" for strings. 
and slower.
&gt; non python books can still make you a better python programmer Agreed. Loved Martin Fowler's book about refactoring, it was life changing as well.
 &gt;Frankly the arguments against making the switch sound an awful lot like why IE6 is still around. If it just works, fine, but you can't expect the rest of the world to accommodate your choices. This is almost exactly what the problem is. Some people find any reason they can to continue iE6 support instead of cutting the cord. It is a mentality that is hard to understand as people could have been migrating to HTML 5 and other modern standards years ago. The funny thing here is that I've seen examples of applications that where tied to iE6 as little as a year or two ago. Anybody with any sense would have started to migrate their code to emerging standards years ago and thus have had minimal effort required to support the new browsers. Nope instead they can't seem to grasp the value in learning the new ways. In the end I see this as the major problem with the Python community, it is an unwillingness to learn the new ways. Sort of like the high school student that actively refuses to learn trig because he can't see any value in it. Often the value in something isn't realized until after you understand it and can apply it in the real world. 
 &gt;Not to mention, the decision to make everything unicode makes Python 3 next to useless for Linux users, as the file system still uses ASCII. Even if that was true, it isn't precisely, what does that have to do with the value of Unicode in Python 3? Nothing really as the two aren't even related. Unicode is something all languages should support especially for variables as it can lead to concise and common character usage. Just about any non trivial science makes use of alternate alphabets, and symbols not found in the ASCII space. Why would you not want to make use of these symbols, many that have been around for millennia, in your code? Especially if they have been used in the problem domain you are working in for as long as that technology has existed. In a nut shell I haven't seen one excuse, supporting the resistance to Unicode, that makes any sense. It has been a long time coming and frankly I for one am happy to see a programming platform that actually has gotten with the times. 
In the second line under the about section, I suspect "get" should be "let".
[**@kamy22**](https://twitter.com/kamy22): &gt;[2014-06-01 14:32:19 UTC](https://twitter.com/kamy22/status/473109794644303872) &gt;Now my computer can recognize colours! I explained it how to do :) [#python](https://twitter.com/search?q=%23python) [#scipy](https://twitter.com/search?q=%23scipy) [#numpy](https://twitter.com/search?q=%23numpy) [#kmeans](https://twitter.com/search?q=%23kmeans) [#clustering](https://twitter.com/search?q=%23clustering) [*pic.twitter.com*](http://pbs.twimg.com/media/BpDS2Z3CEAI8WaZ.png) [^[Imgur]](http://i.imgur.com/B7VGPXl.png) ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/2715o2%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
 &gt;you don't realize people don't like to be forced to do stuff just for the sake of pleasing a few core devs. That is a perception problem, it isn't about pleasing a few core developers, it is about pleasing a large user base that is moving to Python 3, lazy library developers or not. People switch to Python 3 because it is a remarkably better platform to code upon. &gt;in most other communities I know (PHP, Ruby, Js) these kind of changes are welcome because the basic language is so broken that any improvement is worth the compatibility issues, people hate version X so they jump into version X+1 at the first opportunity just to stay away from the previous, this isn't the case for Python. I have to disagree here, people get on board because it is the right thing to do. Being selfish just holds a platform back. It is interesting that you mention three horrible platforms there but seem to not realize that this get on board attitude applies to most language communities. Why? Probably because of a belief in a common good. One only needs to look at how quickly developers are making use of new C++11/14 features in their libraries to see a stark difference between the C++ community and the Python community. It isn't a case of C++ being horribly broken! it is just that the new ways of doing things will pay off in the long run. Apparently Python developers can't see past today and imagine a tomorrow. &gt;Python 2 works, COBOL works too and frankly so does BASIC. Neither one of those adapted to technology, user needs or fixed outstanding problems. They are still around but that really means nothing. &gt;there's room for improvement and that is accepted but there's not enough motivation to leave it because it's not broken, it's as simple as that. First off you aren't leaving Python if you go to Python3. This is probably one of Python 3's biggest perception problems, it isn't that big of a change. Beyond that the whole point of Python 3 is to fix what is broken in Python 2. Python 3 is the improvement you are looking for in Python 2. Really guy if you are a programmer you should be able to grasp the logic here. 
neat. if folks weren't aware, youtube-dl can grab soundcloud tracks. I've use curl+grep+youtube-dl to download entire users before.
This is for you, but also for any other Python users facing this problem. Python is open source and has a large community. That means it's free and the scientific community means that it's supported and continually developing. But most importantly methodologies and techniques are well documented each of the examples here, http://scikit-learn.org/stable/auto_examples/ , has code that can be rapidly applied to tasks. That page is good because it demonstrates in a visually crushing way what Python has that perhaps only R can compete with. Nobody else but R even remotely comes close to the same package of ease of use, range of analysis libraries and graphing/visualisation. So I'd say to them that while your skills are transferable and you can work with more than one language there is a very good case for Python. Python is not only readable, maintainable and has a long future ahead of it but it opens up the door to leaving proprietary for open and gives you access to a vast world of techniques simply not available in Stata. If they are open to the idea of Python at all you have to look at it from their point of view and sell Python as extremely low risk with very high potential gains. Python isn't so much the main point, it's just steady and reliable in this picture we are painting, the main point is that it is a steady and reliable way to gain new knowledge for the business not available from Stata. In terms of realpolitik don't push the point too hard if you need the job, your first priority is to get the job rather than preach Python. Languages are a tool to achieve a goal. You need to make it clear you understand the goal, analysis or statistics for the business, on a conceptual level and can use any tool to get there. There could be defenders of Stata in the interview, the boss could have used it on his way up and have some cloudy nostalgia for it and feel like he'd lose his street cred if the tech changed. If you tell the truth that it's ridiculous that they aren't using R or Python, or planning to move to them or some other open technology, then you could tread on toes. Unfortunately management and human resources are severe problems when it comes to tech. Unless you have recruiters from Google bashing on your door, you have to deal with these kinds of issues. tl;dr say "My skills are transferable between languages, but Python is this very solid low risk and high gain option. It can do everything Stata can do, plus it has all this other stuff. If you have current scripts in Stata, we could start with the very low risk project of translating a few into Python, then we'd have the data in the right formats to explore it for insights with the libraries and techniques Python makes available"
Isn't the obvious answer here to install Python on those machines? I've done some scripting that has to run on several machines and I find that this is the easy way to get things distributed. Keep a master copy on a server and up you simply download your scripts. Even the script downloads can be automated. In this case I'm using a minimal of external libraries which obviously makes the whole thing easier. Even here a few scripts can go a long way to keeping the actual Python installs synced. Maybe it is just me but if someone wants to use my scripts I sort of expect that they will be willing to setup a similar environment. If you have more than a couple of scripts to deal with this becomes even more important as you cut down on wasted space to support all of those *.exe's. More so ever script is using the same environment. 
Yes that seems to be a pretty fair criticism.
I wouldn't touch the system Python, but I think that if you do it right, there shouldn't be a problem with that. But why would someone want to do this? I would definitely go with virtual environments, it's just the risk free approach and if you make a mess it can be easily cleaned up afterwards. 
... and from my experience, most projects having a hard time porting because of unicode issues is because they have been careless. There *are* exceptions of course. If I recall correctly, mitsuhiko had a couple of very valid points regarding flask. But that's a corner-case. In Python 2 you could read from a network socked and just *assume* it was `ascii`. Python 2 did not force you to make the necessary research. Now, with Python 3 you are *forced* to de/encode data on the appropriate boundaries. This is a very good thing! And making it clear that you get `bytes` from a network socket and not a `string` is a very important distinction! Reading from such a source and `encoding` the result is playing with fire... Yet Python 2 allowed it. Yes, Python 3 has made this more verbose and more of a chore than it was previously (and I reckon that is why people are complaining). But it forces you to at least think about encodings where necessary and may avoid nasty bugs.
Stata is a fantastic but very limited tool. If it covers all of your use cases then it really is a nice piece of software, but the moment you want to do something that it wasn't explicitly designed to do then you're going to have a nightmare. If all you're doing is managing, cleaning, merging, etc. your data and applying standard statistical methods, then Stata is going to be perfect. I also find that it's much more intuitive and simple to do most common data manipulation tasks in Stata. But if you want to do any thing else, Python is going to blow it out of the water. More sophisticated or custom estimation or optimization procedures, especially when the data model doesn't fit the "one large matrix" model, are generally extremely difficult and slow to implement in Stata. Other stuff like web scraping, hosting a server, accessing databases, running multiprocess code on a cluster, etc. are going to be impossible. But, as someone who uses a significant amount of each, it's not hard to simply use both. I use Stata for most of my data cleaning and simple statistics problems, and move to R or Python for the more custom procedures and any web scraping or whatever that I need to do, then mostly use R for plotting and figure creation. R and Python (through Pandas) can both read Stata's data files, though I now tend to just pass all my data around in csv files. Each of the tools has its own strengths and weaknesses, and you should learn and use them all when appropriate to take advantage of this.
I have been contemplating about replying to this now for some time. I am afraid this is an apples/oranges discussion especially as you are shifting attention from syntax to performance, but I'll bite... Yes, the line I wrote down will be slower than "naïve" sort. Much slower even. Simply because the key function has to be applied to each element before sorting. The more interesting question however is: *Should* `['a', 1, None]` be sortable? And I'm sure that this is a very polarising question. Clearly, during the Python 3 development process, they decided against it (or it simply is a side-effect of other changes). Personally, I like the change as it can avoid subtle bugs which can be hard to track down. It may sound silly and dismissive, but if you really want to sort mixed type, you can always write a C function for that. I also believe that the example with `['a', 1, None]` is a very contrived example. I cannot think of a situation where you would get something like this as a return value. Much less so about a situation where you would need to sort something like this. This is not to say that such a situation may exist. Maybe you are speaking out of personal experience. But I think that this is a corner-case. The problem can be solved with a key function as demonstrated. And *if* you run into performance issues, it can still be written in C.
you can define + for a string plus int plus None if you want. Just override `__add__()`. Just like you can override `__ge__()` if you want sorting, or just do the correct thing for either python and say `['a', 1, None].sort(key=id)`. The point is, the + or &lt; operator in the generic sense for strings vs. ints *makes no sense* without an explicit definition for the use case at hand. It is a bad practice for &lt; and + in the same way. Programming 101 ! ;)
It's a great stepping block to better understanding more robust frameworks in general, too. In flask, you get the bare essentials and you have to add/configure things as you need them, which is an awesome way to let the developer know "Hey buddy, this is a thing that exists to make your life easier". But then you transition to a heavy framework like Django and you're all like "cool beans! A built in ORM and db admin page?! For free? No way!" Full disclosure: I love both Flask and Django equally. I really enjoy Flask's bare essentials but modular extensible philosophy. I really enjoy Django being the OOTB heavy web framework.
Too bad that there's no good music on soundcloud.
i've found some rather good music on soundcloud...
Why not use logging in PyPy? What if you need performance AND logging?
I read the Flask Mega-Tutorial; it was fantastic. I wish I could get this book, but I can't. It is literally impossible for me to buy the book. I live in Iran, which as you may know, is cut off from international financial services as a result of sanctions. So no money transfer to or from another country, no bank accounts in foreign banks, no credit cards, no PayPal, etc. I loved it when some authors, e.g. Pydanny, Jeff Knupp and Randall Degges offered free e-books to those of us who could not get it otherwise. It is one of the best showcases of the friendliness of Python community. I wish it was more prevalent. I understand that it is not desirable or even possible for everyone to do so. For example in this case the contract with O'Reilly may forbid distribution in this manner. But a boy can dream, can't he?
Heh, Skippy sounds like the way to go. I haven't heard my higher up saying it that way, but here's hoping.
This was written in an older version of python :P I updated it because i have 3.4 :D http://pastebin.com/vC3nxwgv
&gt; Hopefully not for long, as there's a pep open for them. There being a PEP says very little. PEP 457 is informational, it's not on implementation track at this point, it recapitulates knowledge and discussions. &gt; That should be point 0 - You miss out new development in Python 2. Wat? There are no new developments in Python 2 (the language), and won't be until and unless it's forked by a third party. If PEP 457 is ever accepted and implemented, it will be for Python 3.
Thanks!
Hater.
It can lead to confusion. Good luck.
so yes performance is an issue if the library author isn't paying attention to it, but that's not an issue intrinsic to logging, that's just an overall thing. For logging specifically, you need to use isEnabledFor() at strategic locations (as isEnabledFor() itself is expensive), set a straight flag like `self._should_log = True` and then check that before any call to logging. You'll note if you run SQLAlchemy with logging turned off, you'll see virtually no calls to the logging module in a profile. Libraries should absolutely use logging, otherwise there's no way to see what said library is doing within a debugging context. If the library invents some other event system as a substitute, then it's reinventing. logging should be the standard we all get behind.
Tried Pycharm, it is by far the best IDE I've used. Even though I'm only on the community edition it still outdoes itself. I couldn't recommend it enough :D
Why? Why should Chinese dev's have to use germanic variable names? Just because a feature exists doesn't mean you have to use it. If I personally come across π as a variable name I will refactor it out to pi, for all the reasons you would argue. But why should someone fluent in Mandarin use variable names that have no meaning in their language?
Agreed.
+ Writing Idiomatic Python. It's great. For beginner's: Think Python.
I was thinking about that but then i read an erlang and a racket one instead. But probably still worths reading it
It's difficult to give accurate advice without knowing what OS you are on. That said, I can give you advice specific to Red Hat / CentOS, which is what I'm familiar with. EL5 comes with python 2.4, and EL6 comes with python 2.6. Many system tools such as yum are written against those versions, so upgrading the system python will horrible break your system. However, there is a safe alternative. The IUS community repo offers python packages that can be installed in parallel with the system python. They are named based on the major/minor version of python they provide: python27, python32, and python33 (python34u is currently in the testing repos). `python` is still the old system version, but `python3.3` is the newer version. https://iuscommunity.org/pages/TheSafeRepoInitiative.html#parallel-installable-packages Edit: fix link 
Miguel is the man!
 &gt;Don't be so condescending! Don't say people are stupid for not migrating to Python 3! Did I say that? However now that you brought it up, some of the excises seen in this thread are grossly stupid! Far to many of the comments here amount to somebody saying this is the way I believe it should be and to hell with you for disrupting my life. Sorry but life is full of disruptions that is what makes life so interesting and frankly what keeps humanity advancing. 
I learned on Python: Programming in Context (2nd edition) by Bradley Miller in college, so I am somewhat biased towards that text. In terms of computer science textbooks, however, it is definitely the favorite one I used throughout my compsci courses.
Goddamn... you read that whole comment, didn't you, guy? Huh? Version control? What's that, dude? Did you learn that on Reddit? Big, fancy words... look out, those are dangerous. Tell me about big data next. You use the cloud, brother? Worship the cloud... store and retrieve your data from any computer with Sun OS, cloud system. Linux-CK user spotted!
You wrote your comment from the point of view of having released code into the wild that didn't work. I responded from that same point of view. Also, I really, really, really hope that you don't think version control is just some Linux fanboy hipster thing. If you're not using source control I seriously fear your code base.
Maybe that is why I never really had a problem with PDFs. I've been either on a Mac or Linux platform for so long I miss the issues seen in the Windows world. I'd like it to be different but right now PDF's are the only way to create a single file document that incorporates a bunch of non text media in a reliable and widely supported way. I can only wish that it was that easy to do with HTML. 
My code base is fine, thanks. He calls if he's going to be late and sometimes picks up dinner on the way home, after which I read K&amp;R to him until he falls asleep.
This sounds to me like your log level might be too low. If it has a performance impact, I think you have &gt; DEBUG lines in loops in your application, which is fine for most cases I've run into, but you may want to either set the log level of the loop to WARNING (`logging.getLogger('application.subapplication').setLevel(logging.WARNING)` or in your config) or make all of the INFOs in your loops DEBUGs so they are filtered out at the default log level.
Use PyInstaller for what you need, and if you need to include some custom DLLs, I suggest using an installer software such as InnoSetup.
Haven't found an chat program that does actual chat. There's a few echo examples out there, but not actual chat. Maybe this is helpful to someone, for me I just wanted to test out Python3 (was stuck on 2.7 for my other, non-FOSS-able work), the asyncio module and submitting an actual open source project. Should I create a setup.py file and submit it to PyPi? What can I improve for my (maybe) next project? Please let me know what you think.
If you are on linux or osx platform, give pyenv a try.
 &gt;Thats not what I was talking about. The point is what you are talking about is a creation of the people resisting change. The community doesn't have to break up, all they need to do is get onboard the same train. Instead we have too many trying to derail the train. &gt;The single point I was making is; dont pretend this wasnt a massive community breaking fuck up. It was. It is. Its 5 years later and this thread exists shows it still is. It appears that that might be the case but who's fault is it? I've shown a number of examples of other communities that have gone through change, sometimes massive change, and everybody gets on board as soon as feasible. So what makes the guys in the Python 2 community so special compared to those in the C++ or Objective C communities? Frankly I've never seen a community so hell bent on self destruction as this one, there are just to many people that don't give a damn about the community as a whole and rather avoid the little extra effort required to do the right thing. &gt;...so dont parade out the excuse that this is a community project by voluteers, so its fine for them to do whatever they like, without critique. They made their decision to do what they did, and they get to live with people telling them it was a terrible idea, because *clearly it was*. It wasn't a bad idea at all. This is the fundamental problem with this discussion, people ignorantly thinking Python 3 has nothing to offer them. Apparently too many in the Python community have this idea that change is bad, so they take this premise and label Python 3 as a bad idea. In the C++ world you have just the opposite happening! people can't wait to transition to C++11/14, especially library writers as the new standards offer a lot for that sort of development. Of course when discussing C++ people will claim it is backwards compatible but this really isn't the case. Modern C++ code! especially libraries, won't compile on old compilers because developers leverage the new features and concepts to write better libraries. The LLVM/CLang guys have moved to C++11 and left the world of C++ behind! and did so rather quickly. Nobody in that community whined about the difficulty in the move, the effort required to refactor code nor the fact that old compilers can no longer be used to build the platform. Yet here in the Python world we have belligerent people actively undermining progress so you have to ask why. &gt;(not making python 3, to be clear, breaking the community) The community, if broken, broke itself. It is pretty obvious that there are far too many people involved in the Python community that just don't get it. The language either has to move forward or it will die off as alternatives pop up. All of the nonsense we are currently seeing would not exist if five years ago a few idiots would have pulled on their big boy pants and started migrating code actively. Instead all we got was a bunch of crying about the value of the changes. In the end it doesn't matter if you as a programmer don't put value in specific features of a language, you are either additive or subtractive to the community as a whole and at this point the bozos that can't come to grips with Python 3 are very much subtractive. 
Reading K&amp;R to your codebase (even if it is python) is the first thing you've said that I agree with. Next step: implement git or mercurial.
Just ordered. I've always wanted to learn flask, never had really the time to. Hopefully this will force me to dig a bit deeper into it. 
Thank you. Thats going straight to use when I get to work. I'm not 100% clear whats going, but there is enough for me to figure it out. I'm actually more interested in the youTube by user component, I've been asked for a way of bulk grabbing content. (I work for a National Library). 
&gt; Why should Chinese dev's have to use germanic variable names Uh, exactly my point?
 &gt;Or just use virtualenv for each project needs? I don't but I don't have a lot of unrelated projects that stray far from the standard library. &gt;I'm confused about the fact that when I install Python v3.4, v3.4 stays on my system. I'm confused about what you are saying there. However you can install 3.4 on most systems while keeping the default install functional. &gt;Any related explanation would be greatly appreciated. TIA Unfortunately there are many ways to do things. As such you need to decide what is best for you. In theory you can have as many Python versions as you want installed. 
That's like asserting that there's no good code on github. Sure, there is lots of rubbish, but there are plenty of good things too.
I recommend it to every beginner flask person. Great book!
Is [Rapid GUI Prototyping with Python and QT](http://www.qtrac.eu/pyqtbook.html): * Good for experienced python programmers who have done some GUI work before? * Easily translatable to PySide (I 100% believe this to be yes, but yell at me if I'm wrong) * Still up to date? * Usable as a reference later? I've seen lots of recommendations for this book, but was hoping for some specific context. I've done some GUI work with Kivy (ground up app), and a little maintenance work/bug fixing in PyQT. I've found and followed some PyQT web tutorials before. I've also heard that if you're doing self web learning of PyQT etc, you might find yourself doing a lot of C documentation translation, and I'd like to avoid that for now.
I agree. Authors should give their books out for free. But don't worry, as soon as I see it on bittorrent I'll let you know. Knowledge should be free for all!!!
Oops, sorry. Most people in this thread are slamming the content. Thought you were too. Sorry for the misunderstanding.
basically, the script does this: download the HTML for the page "http://soundcloud.com/markusschulz" =&gt; send the downloaded HTML to a pattern matcher looking for the string "http://soundcloud.com/markusschulz/" =&gt; save matches to a file called "list" youtube-dl, download $this, where $this is the contents of file "list". all the cleverness of this is in the `grep` statement. the user page contains links to song pages. I manually inspected the HTML for the user page and noticed that all song pages are in the form of `http://soundcloud.com/user/song-title`. feed that into a pattern matcher and bam. if you're interested in grabbing bulk content, Linux is a great platform. much like Python, you can construct a shell pipeline interactively: run `curl`, look for data you care about. run `curl | grep`, see if that data looks like what you care about. optionally add more `grep`, `awk`, `sed`, `cut` to process data further. Python is an awesome language but simple UNIX tools can be used to great effect for data processing and web scraping. if you want a tool that can be used repeatedly across a varied set of data and maintained for a long period of time, Python is great. if you just want to scrape a site **right now**, `curl`+shell is probably faster. `wget --spider` is pretty cool too. [edit: here's a link to [youtube-dl](https://rg3.github.io/youtube-dl/) too. it's a Python tool that's grown into an all-purpose internet media downloader.]
Awesome, thanks heaps! this is really useful! I see the curl | grep voodoo every so often, and just about the get the basics, but not to a level where I can poke it myself. You've absolutely given me the starting place I need. Thank you. Appreciated. 
Don't forget to watch his 3-hour tutorial from the 2014 PyCon: "[Flask By Example](https://www.youtube.com/watch?v=FGrIyBDQLPg)". 
Not useless! If you had a friend who loved word searches, you could troll them masterfully. 
On top of what others have said, Python has become the language of choice for a lot of top machine learning research groups, displacing Matlab. Particular fields use other tools though, such as R in econometrics. You have to consider what your work product is going to be. If you want to produce an answer to a question (Is this factor significant?) or a paper and its charts, you have very different requirements than if you want to deploy a real-time analytics system. Tools like Stata and R are aimed at the analysis side and you'll struggle to deploy the models you develop with them. There's a related issue based on the type of data you work with. The python data munging library pandas isn't as mature as what you get from R, and I personally think its interface is unintuitive. Where you'll do well in python is when you have more raw data than you can manipulate easily in memory. The more of your processing is on large files or databases instead of clean tabular data, the more python will beat the standalone environments.
Logging introspects stack frames to see where a call was logged from (because people often like to know this), using `sys._getframe()`, which PyPy can't speed up. There are easy ways to tell logging you don't want to collect certain information - see the docs on [optimization](https://docs.python.org/2/howto/logging.html#optimization) for more details.
I work on http://www.wordbaseapp.com/ and decided to take this a step further. I present you a Wordbase board with all English letters, but no English words: C S Z U I W X G U Z T J K E U B W U I A F R J Z J X G K Z O X V S V P L Q G I E L P V M X Z L Q A Q D Q B D R N F V K Z B H D W B T N W R K M D Y K D S X Q G F F Z K D X D W B H R H Q U Q L M G K G F X J Z K T N S M R V Q C I J P Z D X W N X Q J K W D K P Q S
Can't recommend this book enough. 
it contains the word "a". it also appears the letter frequency is off from english. it's easy making no words if you can use uncommon letters a lot.
Isn't the premise of Python3 is that it would be much faster, with async IO and such?
I can't show you the code which is part of Wordbase, but this is what I used to generate this board: https://gist.github.com/halst/e145af9e0c4ba3c1b736
I've built a robot website at http://roboplex.com. Both the server and the robots are controlled with Python.
Given this is your first post, your username is pyslow, you're not doing your own benchmarks for things you actually care about and this seems to be your sole reason for not wanting to use Python 3 I'm going to assume you're either trolling or just lazy (sorry not much else to go on here). If it happens to be the latter then have you tested it against things that matter **to you**? Python 3 is in fact slower in some places but that's [not always the case](http://mikewatkins.ca/2008/12/06/python-3-performance-a-red-herring/) and it was often done either because there are other benefits (memory usage) or the devs are following the "make it work, then make it faster" philosophy. You should test Python 3's speed against code that matters to you instead of relying one someone else to do that for you because their answer will often be wrong or incomparable with your own program's performance. Additionally, if you're this concerned about speed why are you using an interpreted language and if you must use an interpreted language have you tried writing your code differently to better suit the situation (threads, multiprocessing, async, etc)?
Maybe add asyncio support to pyxmpp2? 
depending on the size of your dictionary it might be a tad tricky.
Miguel has to eat, you know
It's a pretty standard web scraping scenario. You'd want to first scrape the first page to get a list of the integer IDs for each value in the dropdown. That ID is used to form a URL to the results page: newWindow = window.open("DiversityBWDataPages/" + (msaform.place.options[msaform.place.selectedIndex].value) + "msaBWCt.htm") Then you'd retrieve each of those result pages and scrape their contents. I suggest writing things out in a CSV format which is trivial to import into Excel, rather than worrying about learning how to actually write .xls files. There's a module you can use for that, but it's still probably a lot more complicated. The usual suggested modules for web scraping are BeautifulSoup and Requests. You could also use Scrapy, which has a slightly higher level interface. 
What package? I'm always surprised by this dogma, basically all top tier packages support Python 3 these days. Some industry or field specific packages may still be stuck. Could you port it yourself? The truth is that this 2 vs 3 debate is ephemeral. The BDFL has decreed that 2.7 will be mothballed in the next few years. At some point it will cease to be a developed and updated version of the language and after languishing for a while in open-source limbo it will eventually be forgotten and all these unmaintained libraries will be gone. Python 3 is Python, that's what we should all keep in mind.
was that bruteforce or did you have backtracking in it?
I used immutable data structures, which allowed to roll back to any previous board state. However, in this case it was necessary to only go back a single step: https://gist.github.com/halst/e145af9e0c4ba3c1b736
I didn't suggest that you're supposed to rewrite all your code. If you're really considering porting your libraries then you should take your current code base and find the fastest and slowest areas and abstract those into small scale tests for Python 3 and use that as your benchmark if all you are concerned about is speed. In addition to that if you have a couple of bits of code that are run several thousand times a day then you should test that in the same manner too as the cumulative execution time in this case would have the biggest impact. In the end Python 3 should have a useful business impact in order to really be considered a version to switch to and speed alone is not much to go on, though it is useful in some cases, especially in large code bases. What I meant by lazy or trolling (I didn't say both) is that you didn't take a reasonable approach to determine if Python 3 is actually slow in your case. I could care less if you switch or not, it's not about making me happy, it's about doing what's right for your code yourself instead of just relying on a benchmark or someone else's input which could be a completely different use case than your own. I choose Python 3 when it's the right architectural choice not because it's the coolest thing on the block and I'm saying that you should do the same by testing it. The suggestions I made were to the same effect and if I really was trolling you I would not have bothered to try and explain it the first time. I was calling you out as troll (or lazy) because of the lack of research, post history, examples, and the provocative user name. Sure I could have left that out and if that ticks you off I apologize but there was not much to go on and some trolls will walk away when called out. As for if the article is relevant date does not determine relevancy as much as interpreter version. In many areas Python 2.6+ was faster, at least in my own experience, over 2.5. But 2.6 to 2.7 often did not have as large of an improvement so comparing 2.6 to 3.x is relevant for most use cases. **EDIT**: By the way what industry is this for? I ask because depending on the industry and your current code base the performance issue could be irrelevant due to how much you'd end up having to refactor anyway or 3rd party libraries which block your advancement. 
I am a total novice but I did manage to make a script that alerts me whenever there is cheap ammo on gunbot. I was pretty proud when I got that going because it was the first script I actually wrote for myself to solve a problem instead of mindlessly copying something out of a book.
Can you provide the script you used for your tests? http://svn.python.org/projects/python/trunk/Lib/test/pystone.py is not compatible with python3 EDIT: 'Check for bottle necks'; Python 2.6.6 (r266:84292, Jan 22 2014, 09:42:36) [GCC 4.4.7 20120313 (Red Hat 4.4.7-4)] on linux2 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; import cProfile &gt;&gt;&gt; from pystone import main &gt;&gt;&gt; cProfile.run('main()') Pystone(1.1) time for 50000 passes = 1.04 This machine benchmarks at 48076.9 pystones/second 1100013 function calls in 1.060 CPU seconds Ordered by: standard name ncalls tottime percall cumtime percall filename:lineno(function) 1 0.000 0.000 1.060 1.060 &lt;string&gt;:1(&lt;module&gt;) 50000 0.149 0.000 0.370 0.000 pystone.py:137(Proc1) 50000 0.032 0.000 0.032 0.000 pystone.py:153(Proc2) 50000 0.043 0.000 0.060 0.000 pystone.py:164(Proc3) 50000 0.019 0.000 0.019 0.000 pystone.py:174(Proc4) 50000 0.018 0.000 0.018 0.000 pystone.py:181(Proc5) 50000 0.040 0.000 0.055 0.000 pystone.py:188(Proc6) 150000 0.050 0.000 0.050 0.000 pystone.py:207(Proc7) 50000 0.097 0.000 0.121 0.000 pystone.py:212(Proc8) 150000 0.049 0.000 0.049 0.000 pystone.py:225(Func1) 50000 0.060 0.000 0.077 0.000 pystone.py:233(Func2) 50000 0.015 0.000 0.015 0.000 pystone.py:250(Func3) 50002 0.031 0.000 0.031 0.000 pystone.py:45(__init__) 50000 0.059 0.000 0.090 0.000 pystone.py:53(copy) 1 0.000 0.000 1.060 1.060 pystone.py:60(main) 1 0.000 0.000 1.060 1.060 pystone.py:67(pystones) 1 0.319 0.319 1.060 1.060 pystone.py:79(Proc0) 100000 0.032 0.000 0.032 0.000 {chr} 1 0.000 0.000 0.000 0.000 {method 'disable' of '_lsprof.Profiler' objects} 100000 0.020 0.000 0.020 0.000 {ord} 50002 0.027 0.000 0.027 0.000 {range} 4 0.001 0.000 0.001 0.000 {time.clock} If you believe Python3 is slower, why not find out where it is slower. cProfile is a nice tool to help you with it. **Use the following, and run your tests again** import cProfile from pystone import main cProfile.run('main()')
Here is the official docs: http://micropython.org/doc/module/pyb/ Each of the major communication protocols are supported: I2C, UART, and SPI There is also ADC, DAC, timer, servo, and accelerometer libraries ready to go. There will be wifi and bluetooth libraries as they were part of the kickstarter campaign, but they haven't been completed yet. As for other libraries, I saw in the forums that someone has a working LCD library, and there are probably some other useful libs floating around too. So you won't have to code everything from scratch, and if you stay active in the forums a lot of people may be able to help with the code you do have to write.
1. binstar.org has more than one user 2. the site is operated by continuum.io, who you're already trusting for your python runtime. That being said, obviously they have little control over uploads by third parties, so treat as you would any other source like pypi (which is no different, really, just a different site). 
:) Think about it... your python app throws an exception, Michael Bay directs the special effects, ... instant justification of the IT budget ;) 
Thanks for your reply. I'm not saying that your advice is not good, on the contrary, it does make sense and it's the route I would go down, should I decide to move my own (not work related) code to Python 3. When it comes to my job, it's quite unlikely that my employer decides to move their code to 3 any time soon, though. Python is mostly used for testing and monitoring purposes and, to be honest, I'd be afraid of even suggesting the switch until I'm fully confident that we're not going to be hit by massive performance degradation. As you said, you can always optimize post hoc, but that's not a walk in the park in terms of time and resources and there would be little to none business value in doing so (currently our tests would not benefit from Python 3 Unicode handling, but it would be terrible if they started running 20%-50% slower because of Python 3 poor performance). What I'm trying to say is that it would be much better if Python 3 was "neutral" performance-wise compared to 2.x. That would take a potentially critical issue off the table, so one could focus only on the other porting questions. Instead, after seeing the numbers above, I can't help scratching my head and thinking how risky Python 3 is **also** in terms of performance. 
No, I have never heard that we it's overall aim.
Ooh, neat! That code is a lot more cleaner than mine. However, it uses the same hack as my code does. (I always get excited when I have the opportunity to explain the hacks I use in my projects) Basically, you can get a URL to stream any Soundcloud track, but it relies on a 12-character string, unique to each track. One way to get this is through the Soundcloud API. In the returned data, the URL to the track's waveform image contains these twelve characters. So basically, all you need to do is get the waveform URL, extract the twelve-character "fingerprint", tack it to the end of a streaming URL, and `urlretrieve` it. I was under the impression that I was the first person to find and utilise this little hack, but I was wrong. On the same breath, I'll make sure to take note of that link, read through the code, and improve my version based on that one. Thanks a heap!
Thanks for your comment. I grabbed pystone for Python 3.4 from here: [pystone.py](http://hg.python.org/releasing/3.4.1/file/ea310ca42bb2/Lib/test/pystone.py) The svn repository is no longer used, they switched to Mercurial. I'm aware that I can run a profiler to identify the bottlenecks, but before starting my personal investigation on why Python 3.4 seems to be so slow, I wanted to listen to other people's experience to decide if performance is indeed an issue worth looking into. Let me know if you have a chance to run the 3.4 pystone on your machine and what results you're seeing. Thanks! 
Thanks! I'm glad I could help, and that - more importantly - it works.
Sweet, thanks for the link to youtube-dl! Yeah, what your script does is very similar to what mine does. However, the pagination was never an issue for me. You'd probably have an easier time just using the SoundcCloud API to get all of a user's tracks. [Here's a run-down on how I used the API to accomplish it.](http://www.reddit.com/r/Python/comments/270k3m/a_script_to_download_a_soundcloud_users_music_all/chwskr6?context=1) In the last implementation of this script, I used a web scraper to plug each track URL into [Soundflush](http://soundflush.com). However, they changed how their site worked, and my script was left broken. Web scraping *is* good, but whenever I can, using an API is far more convenient. It's much easier, faster, and solves silly problems such as pagination ;) --- And I agree, Linux *is* the perfect platform for data grabbing, manipulating, and processing. The basic command line tools are invaluable, and things like redirection and piping have become so necessary for my day-to-day use that I often have trouble working on Windows!
If you work on a Linux command line at all, learning things like grep, piping (that weird | character), redirection (`echo 'Hello world' &gt; file.txt`), and Bash shortcuts (`!!`, `!$`, etc) are absolutely invaluable. One command I like using to check what disks and partitions are connected is `ls /dev | grep sd`, which lists all directories and files in /dev, then only shows you the files/dirs starting with `sd`, such as /dev/sda, /dev/sdb1, etc etc.
How does it read? Is just the [Flask Mega-Tutorial](http://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world) in book form? 
I realise this is not /r/cscareerquestions but would you mind giving us a very brief overview on how you got into data analysis? What are your qualifications and what was your first job?
Most of my time in Python is spent with Data Analysis...and Pandas *just* moved to 3.4 officially earlier this week. So there is that...
&gt; I run the standard benchmark and I see the values above. And I've run other benchmarks and seen Python 3 perform slightly faster than 2.7. One isolated simple benchmark doesn't tell a complete story about the performance of a language.
Why not just use a framework like Django that already had this baked in?
You just may get your wish.
If we're going for fun, can I pronounce Guido Gooey-doo?
I went through the Python standard library and wrote out samples of (nearly) everything the each module I worked with was capable of. I got better at Python as well as programming in general.
To me, their docs aren't as easy to read, and stormpath seems simpler to implement and requires less code for more results. Just a matter of preference.
Plant some subliminal suggestions!
Are pugs the new Bitcoin?
Perfect, a strong community is better than a large community.
yeah what rhomboid said: use Beautiful Soup, and probably lxml to import your data (you'll probably want to use the view source option and a 3rd party browser plugin to find out which CSS selectors will actually grab the table you want). You might also want to look into how search cursors work. After that, there's a pretty simple CSV module that's a standard part of python. It even has an 'excel' default for CSV formatting. I just did something like this for a course assignment. PM and I'll send you some code when I can pull it off the school server.
When you apply for a position, assume you will be using whatever they are using and not that you'll argue them into a change.
If you read my replies you'd find I'm not being defensive of Python 3, I'm being defensive of testing before jumping to conclusions and using the right tool(s) for the job. As for why others are so defensive of it who knows, my guess is just lack of experience in trying to work with large code bases or it could be they want to use 3.x for some the the features it offers and think others should too (but that's all speculation.)
Fair enough. 
Not a problem, I helped contribute to that one before someone recommended youtube-dl to me (I haven't looked through youtube-dl to see how it retrieves the track from SC, but I assume it's the same if the track's not set to download by the track's author).
Just to play devil's advocate, I use Stata for most of my web scraping and find it pretty well suited to the task even if it's not an intended use. 
In server.py instead of storing all of the clients as a list you could store them as a dict with the key being the peername. Then in send_to_client all you have to do to get the correct client would be something like: client = self.clients[peername] print('Sending to {}'.format(client.peername)) client.writer.write('{}\n'.format(msg).encode()) return Now send_to_client will do the client lookup on O(1) time instead of O(n).
Yours ß
The only hard book that I really found useful was Mark Summerfield's PyQt book.
That was my first and only book (everything else has been web) and I found it fantastic. 
Well, they're worth just as much
There are quite a number of scrabble words in there, like "AI," "KA," "KI," "OE," "OI," "QI," and "ZA." Dunno if that matters. Here's a list of them if you decide you want to add those in too: http://phrontistery.info/scrabble3.html
I just wonder where these developers would go. The attitude displayed here wouldn't be accepted on other platforms. I can't imagine the C++ world having any patients at all with the Luddite attitudes displayed by some of the Python library developers out there. This makes me wonder what is the programming worlds equivalent of a burger flipping job? Maybe becoming a Visual BASIC for apps developer. 
Didn't Pandas officially support Python 3.x a couple of years ago? Python 3.4 is a major point release, lots of packages are a few months behind that. Biopython also just released official 3.4 binaries. As an aside, if you are always needing the latest Python, you might try pulling from the dev repositories with Git since frequently code will work a long time prior to the release. But I think we are splitting hairs. 3.3 vs 3.4 is much different than 2.7 vs 3.x.
Also created after another anti-Python 3 troll's account was deleted. Just saying. 
It was my impression, although I could be wrong, that Pandas had not officially supported any version of Python 3 until this point. Just to make sure, I went ahead and quickly combed through all of the Pandas release notes back until 2011. Back in October of 2011, Pandas added Python 3 support using 2to3. Of course, there were known issues and this wasn't the same as "official" support for 3. This is why I was pleasantly surprised that they have added "official" support for 3.4. Regarding pulling form dev repositories, I use Python because it is a quick and dirty scripting language. I don't spend a *whole* lot of time writing python code, but when I do I am "slinging" code and just want to get something working quick. In this case, I don't want to mess around with the bleeding edge stuff...so it makes more sense for me to just use 2.7. Of course, this is changing. With the Pandas official support for 3.4, I am hoping that I can start using 3.4 by default.
1. Pystone is a very artificial test that isn't particularly useful to anything much. But it can be used to give you a rough indication of how fast pure Python computation is on a machine. It's not useful at all to benchmark different Python versions against each other. Python 3.0 was for example extremely slow in some situations, but that was because the I/O library was written in Python. Something that would not have shown up when running Pystone. 2. I have no idea what Continuum Analytics or Anaconda is, or why you are not running the pystone test that comes with the stdlib. 3. Python 2 *is* faster on Pystones, but the difference is not 50%, rather 25%. This is partly because Int and Long is merged, partly because under Python 3 there is at least one bug in Pystone that means it calculates with floats when under Python 2 it would use integers (I will submit a bug report later today to go through the whole code) and probably partly for other reasons as well. 4. The general view is that indeed Python 3 is slightly slower. It's not significant though, and definitely not 50%.
C++ is just different. If you want to smooth the transition and want to stay OO, move to Java first. At least you will have garbage collection and reference semantics. Alternatively, go with C (it's always good to know C) and then ramp up to C++. Keep into account that there are two school of thought when it comes to C++ programming: object oriented (class hierarchy) and generic (templates). You can certainly mix them, but the direction the language is moving in the latest years is generic programming. Just use a decent compiler (llvm) otherwise you will be baffled by the compiler error messages.
&gt; what are the good things about using C++ over python performance, multithreading and many others. You would be surprised how bad python is when it comes to memory allocation strategy. In some contexts it will fragment the memory so much and jump around so much you will basically work without cache, and you have little or no control on this, unless you go down at the C level. Then, you have the GIL problem, at least when you use cpython, so no real multithreading in python. 
No. Never update the Python version installed on your system. Install the other versions in parallel but don't replace the main version. You do this either by installing it in a different directory that /usr/local (by specifying --prefix when you run ./configure) or by installing it with "make altinstall". I'm not sure what you need explained, as you don't really say what questions you have. Perhaps this helps: http://regebro.wordpress.com/2011/02/02/newbie-hint-on-installing-python-and-its-modules-and-packages/
Why not? Everyone else does. ... don't they?
Dang, that's a short and sweet but not quite trivial example of how to use asyncio properly (or at least I assume properly). Where did you learn how aio works?
Same.
I'm gonna be *that* guy and point out http://en.wikipedia.org/wiki/Genie_(programming_language). It's quite like Python except compiled and also influenced by D, and compiles to C.
please, move your tests inside your package (and write a setup.py) 
Thanks very much, indeed! Exactly the figures I was looking for. So, so far it seems fair to say that Python 3 is noticeably slow than Python 2.7 on all major OSs. Not a show-stopper but definitely something to take into account when planning a migration. Thanks again. 
Wow, scrabble is weird.
yes and unfortunately this is what's happening. I say 'unfortunately' because it has caused a divide on the Python community which once was strong and united.
we as a community all agree that progress is good and we all want to see the language moving forward however this particular route wasn't proposed by us and it didn't had the reception it should, just compare it with the release of py2.7 now this is what people isn't getting, the community didn't approve this there was of course many people making the effort, myself included, just out of good faith but as a whole it was a failure and instead of working towards a better solution now it's being forced, pushed and demanded as if people weren't able to have an opinion and a decision on what's best for themselves and what's best for the community is what's best for the majority of its participants so yeah, we should 'stop crying' but it isn't as if the reaction was unjustified.
&gt; The performance issues in a general sense don't help the argument either. The problem is that even with testing it's difficult to make a business case to non-engineers who stop considering it the second the words 'it's slower in some areas' come into play That's my main concern in fact. I'm not willing to risk promoting something that can backfire so badly. I can think of a particular project manager (admittedly a non-tech guy) , who's never been keen on using Python, if the big test run ends up taking one and half hour instead of one hour: I'm not sure I can find good excuses, no matter how much " but Unicode works better now" I throw around :) Thanks again for your time. 
&gt; And I've run other benchmarks and seen Python 3 perform slightly faster Can I please see your numbers, sir? Or are you just making this up? &gt; One isolated simple benchmark doesn't tell a complete story That's why I was asking for more data points, in case you missed the subject of this post. 
it is forced because a large portion of the community has expressed against it and has been ignored. many people have mentioned a 2.8 release as a possible bridge between the two to ease the transition, I don't have as many problems as library developers so I'll refrain from suggesting any but it's clear that people wanted more help on this matter and the current stance is "migrate and stfu" as this post and subsequent comments illustrate. I don't think anyone disagrees with the advancement of the language but we disagree on how to proceed, it doesn't mean people doesn't want it to move forward.
Truly awesome resource :) Miguel's the man!
&gt; I'd be afraid of even suggesting the switch until I'm fully confident that we're not going to be hit by massive performance degradation. You will not. People would have noticed (and would complain loudly) if it really was massively slower. It's not like you are the first person to use Python 3. ;-) 
&gt; Pystone is a very artificial test So why keeping it around? Is there anything better? &gt; it can be used to give you a rough indication Which is exactly what I did. And I think it's the correct procedure to get some quick, albeit rough and incomplete, figures before embarking on an important migration. Do you have other benchmarks to suggest? &gt; I have no idea what Continuum Analytics or Anaconda is Then you don't know a lot about the Python ecosystem (or how to use Google, for that matter). &gt; or why you are not running the pystone test that comes with the stdlib I'm running the pystone from stdlib (I even included the link in one of my previous comments). &gt; Python 2 is faster on Pystones, but the difference is not 50%, rather 25% Not sure where you get this figure from (my run says 50% faster: 95000 pystones/sec vs 64000). But even accepting 25%, that's still a lot faster in my book. &gt; there is at least one bug in Pystone [...] I will submit a bug report later today Interesting. Please let me know the ticket number, so I can follow it. Strange, though, that no one noticed it before and/or core devs didn't bother to fix it if the test is spitting out such bad numbers. &gt; The general view is that indeed Python 3 is slightly slower. It's not significant though Glad you see my point at last. Whether it's significant or not, it's a subjective opinion depending on your own environment, goals, resources, etc. Even a 10% loss in performance would be a severe hit in my case (especially compared with the minimal gain of migrating). YMMV, of course. 
Of course, regular for loops do this as well: Python 2.7.6 (default, Nov 10 2013, 19:24:18) [MSC v.1500 32 bit (Intel)] on win32 Type "copyright", "credits" or "license()" for more information. &gt;&gt;&gt; i Traceback (most recent call last): File "&lt;pyshell#0&gt;", line 1, in &lt;module&gt; i NameError: name 'i' is not defined &gt;&gt;&gt; for i in range(5): pass &gt;&gt;&gt; i 4 &gt;&gt;&gt; I think they still do in python 3 but I'm not certain.
Yes, in 3+ list comprehension are given their own execution scope just like generator expressions.
Just saying BS, apparently. I'm not the guy you think I am. Not even sure what you are talking about. Is it the standard answer here that any question doubting the greatness of Python 3 is immediately classed as trolling? I see you posted a more meaningful comment below, so I've replied there to your points. But refraining from offensive innuendo would be greatly appreciated. Thanks. 
That's quite impressive and I really like the parts I understood.
 print("¡Hola mundo!") I am a master of obfuscation.
http://en.wikipedia.org/wiki/Active_noise_control
In Perl, this is the standard way to do a Hello World.
&gt; It's not like you are the first person to use Python 3. ;-) Nah, probably the third one ;-) 
I like any language that favors simplicity and easy of use. In the university I went to many moons ago, I learned Fortran, C, and Java. But for interactive, exploratory data analysis, obviously, those languages were not well suited for this. That is how I found Python. Due to its simplicity and REPL-based environment, I think it is well suited for exploratory data analysis, especially when using the IPython notebook environment. Genie requires compilation of source code, so I'm not sure if I would like that when I want to be able to interact with the data and see the results quickly. That is why I prefer REPL-based langauges. Which is also why I am closely watching [Julia](http://julialang.org/) programming language. It seems to be gaining momentum and touts performance close to C.
Python is rad. 
Not sure providing my education background will matter much. There are data analysts with various different backgrounds from statisticians who happen to know how to program to CS-related majors who minored in statistics. But if you must know, I received my degree in industrial engineering from Georgia Tech. If I was a hiring manager or someone part of the interviewing process, I would definitely prefer industrial engineers for data analyst position. I know that seem biased, but based on the curriculum of industrial engineering which includes statistics, programming, and business/management related courses, someone with this background is a perfect fit for data analysis (and of course in other fields). In my opinion, an industrial engineer has a more complete understanding of what it takes to improve business processes and business profitability overall. I got into data analysis on accident really and is a field that is unavoidable for me due to the ubiquity and available of mass amounts of data. I started to use SAS and Excel, but much later discovered Python.
Watched Guido's presentation on Tulip (asyncio) - https://www.youtube.com/watch?v=aurOB4qYuFM Read the docs - https://docs.python.org/3.4/library/asyncio.html Read the Source when I didn't understand what it was doing, control-click on functions in PyCharm is super handy. And a decent amount of trial and error and print statements :) I don't know if this is the proper way to use asyncio the way Guido intended it, but it works and it looks pretty pythonic.
&gt; So why keeping it around? Why not? &gt; Is there anything better? Better for what? Better for measuring your processors Python integer performance? No. &gt; Which is exactly what I did. You cut off the important part of that sentence. No, you did not use it to make a rough indication of how fast pure Python computation is on a machine. You tried to use it to make a rough indication of how fast different Python versions are compared to each other. That's two completely different things. &gt; Then you don't know a lot about the Python ecosystem (or how to use Google, for that matter). You complained when I said that you appeared just after another troll's account was deleted. Yet you continue trolling. &gt; Not sure where you get this figure from (my run says 50% faster: 95000 pystones/sec vs 64000) I don't know why you get those numbers, nobody else get numbers like that. I don't know if it depends on the Python distribution you use, if there is something in what you did to make the Python 3 version of Pystone run on Python 3, if there was something else running on your machine slowing it down, or if you simply made them up. &gt; if the test is spitting out such bad numbers. It isn't. &gt; Even a 10% loss in performance would be a severe hit in my case (especially compared with the minimal gain of migrating). You are highly unlikely to see a 10% loss in performance, unless what you are doing is integer calculation. And here is another relevant question: How much performance gain do you get with PyPy compared with CPython, and why aren't you using PyPy? I mean, if performance now is so important for you as you make it out to be, what have you done to improve it? 
I will, when you stop trolling.
Great idea. Thanks. Committed.
Nobody told you to ignore it. Again you are just trying to come up with some excuse to not use Python 3 or complain about Python 3 without base. Python 3 may be a lot slower for you, if your code spend time doing some of the things that are significantly slower. But that's actually quite unlikely. To know how much slower (if at all) your code will be, you have to, as NeedsMoreTests pointed out, either run your own benchmarks or at least profile your code to figure out what it is doing that takes time. 
I'm confused..
Ok, I see there is no point in trying to have a constructive and civilized discussion with you. I've asked if you can point me to more meaningful benchamrks and you've got nothing to say other than replying to a question with another question. You mentioned that pystone is broken and you were going to file in a bug report and now you're saying pystone output numbers are fine. You can't understand that the pystone link I sent was specifically requested by another poster and it was for Python 3 only, so he could run the benchmark (he already had pystone for Python 2). And another user could run both benchmarks just fine, but you're still babbling about the wrong pystone version! I ran the benchmarks myself on Windows and published the figures. I didn't omit a thing. You could run it yourself and show me your numbers (which is what I asked for in the very subject) as others did, instead of calling me a liar. You keep repeating that everything is due to this integer calculation issue. Do you mind explaining it better, so it can be fixed? Just file the bug report you mentioned, for example, and see what the devs think of it. The fact that you don't know what [Continuum](http://continuum.io/index) or [Anaconda](https://store.continuum.io/cshop/anaconda/) are (they are both widely known in the Python community, believe me) and that you call me a troll for pointing out your ignorance speaks volumes about your own trolling attitude. 
I love these. For a similar sort of thing, I really enjoyed reading [Programming with Nothing](http://codon.com/programming-with-nothing) which goes through writing FizzBuzz using nothing but lambdas (it's in Ruby, but the principle is the same). It feels a lot like building up the natural numbers by starting off with sets - the idea that you can have an empty set, or a set which contains something. 
You should've obfuscated `getattr`, `__import__`, and `chr` as well, wth `__builtins__.__dict__` :)
This is much less of a Python problem and more of a sound engineering problem.
Definitely proof that they haven't totally abandoned 2.7.
Definitely not. A good example is [PEP 466](http://legacy.python.org/dev/peps/pep-0466/) which was accepted recently. The author of this PEP wants to backport security enhancements into Python 2.7.x. &gt; Enhancement patches are restricted to the default branch that becomes the next Python version. and &gt; [...] this PEP allows a critical set of network security related features to be backported from Python 3.4 to upcoming Python 2.7.x maintenance releases.
&gt; Ok, I see there is no point in trying to have a constructive and civilized discussion with you. You haven't tried yet. &gt; I've asked if you can point me to more meaningful benchamrks and you've got nothing to say other than replying to a question with another question. You have already found more meaningful benchmarks, pointing out that on average, Python 3 is not significantly slower. You decided to interpret them as if it's 25% slower. http://www.reddit.com/r/Python/comments/272bao/python_34_slow_compared_to_27_whats_your_mileage/chx2nwc More significant than that is only possible if you do what NeedsMoreTests recommended that you do. I did respond with a question. It's relevant. That you get angry that I asked that question it is further confirmation that you aren't posting this to solve a problem, you are just trolling. You don't actually care that much about performance, if you did you would have tried PyPy and/or Cython. You also consistently refuse to actually try to figure out if Python 3 will be slower for you. Instead you are busy trying to misinterpret people and finding excuses for not using Python 3. If you really aren't trolling, then you should stop doing that. &gt; You mentioned that pystone is broken and you were going to file in a bug report and now you're saying pystone output numbers are fine. I pointed out that this is one of the reasons Pystone is slower. I've also told you that it changes it from 20% to 25% slow-down, so it's only one of the reasons. I don't know what you mean that I'm saying that "pystone output numbers are fine". &gt; You can't understand that the pystone link I sent was specifically requested by another poster and it was for Python 3 only, so he could run the benchmark (he already had pystone for Python 2). Well, it's in the standard library, so he had it for Python 3 as well. &gt; I ran the benchmarks myself on Windows and published the figures. I didn't omit a thing. You are running it with "from pystone import main" which does not work in a standard distribution, so there is definitely something extra going on there. &gt; You could run it yourself and show me your numbers (which is what I asked for in the very subject) as others did, instead of calling me a liar. I have not called you a liar. I'm telling you my numbers are that Python 3 is 25% slower. After the bugfix it's 20% slower. What is unclear in this? I've tested this before, in different versions of Python and on different computers, it has consistently been around 25% for me. I don't see a point in posting actual numbers as this doesn't change anything, and since pystone is not a relevant test anyway. It's not a useful test to test real-world performance, or compare Python versions, which has already been pointed out to you multiple times by multiple people. &gt; You keep repeating that everything is due to this integer calculation issue. No, I never said anything even remotely similar to "everything is due to this integer calculation issue", I don't even know what that means. What I have said, multiple times, is that pystone is a test of integer calculation performance. That's all it tests. &gt; Do you mind explaining it better, so it can be fixed? It's fixed now, in fact, and will make it into the next release. http://bugs.python.org/issue21634 &gt; The fact that you don't know what Continuum or Anaconda are (they are both widely known in the Python community, believe me) and that you call me a troll for pointing out your ignorance speaks volumes about your own trolling attitude It's the way you pointed it out that makes you a troll, by doing so in a rude way. You are hence NOT trying to have a constructive and civilized discussion. 
I doubt it: Python 2.7: &gt;&gt;&gt; timeit.timeit("[x*2 for x in xrange(1000)]", number=10000) 0.486644983291626 &gt;&gt;&gt; timeit.timeit("(lambda y:[x*2 for x in y])(xrange(1000))", number=10000) 0.5336780548095703 Python 3.4 &gt;&gt;&gt; timeit.timeit("[x*2 for x in range(1000)]", number=10000) 0.6790744459999587 So Python 3 is still slower than the lambda-based list comprehension in Python 2 :( Edit: actually, it seems like it's just range that is slower, Python 3 is faster than Python 2 lambda (but still slower than the "broken" listcomp of course): 2.7 &gt;&gt;&gt; timeit.timeit("[x*2 for x in [1,2,3]]", number=100000) 0.045584917068481445 &gt;&gt;&gt; timeit.timeit("(lambda y:[x*2 for x in y])([1,2,3])", number=100000) 0.05614590644836426 3.4 &gt;&gt;&gt; timeit.timeit("[x*2 for x in [1,2,3]]", number=100000) 0.05098462300020401 (I also checked with 10000000 iterations: 4.43 (2.7, lambda) vs 4.20 (3.4))
This guy would be an excellent Brainfuck developer.
When people ask for a demo or screenshit of a cms they normally are referring to the backend. 
&gt; So, you see, something useful came out of this troll's post. Yup. &gt; And my numbers were indeed correct Well, that does not follow. And what does "correct" mean anyway? Unless you are lying the numbers are "correct" for a certain value of "correct". That does not mean that the numbers in any way reflect any real world situation. The patched version does speed things up for you, but the difference is still much bigger than anything else I have seen. 
&gt; There is also chance that it will go faster. Which is akin to say "roll a dice" and hope it'll go faster (since the benchmarks say it's on par on average, but with great variance). &gt; that's true for ANY Python version change Except that other version changes didn't require the same amount of work when upgrading, since they were *backwards compatible*. Instead, now, the idea is: - spend a lot of time upgrading - roll a dice and hope performance won't be so badly affected So, yes, you're right, I'm refusing to migrate given the above. If that makes me a troll at your eyes, then suit yourself. 
pysoundcard provides a nice way of grabbing / making the sound (it's the more modern version of pyaudio). You will probably want to do the audio processing using numpy. You might be able to get help on the dsp stack exchange. http://dsp.stackexchange.com/ Post anything you make :)
Look, these are the values I'm getting, they are not tampered with, that's what I mean by "correct". Can you please stop implicating that I'm lying? Since, as you acknowledge, these numbers are a bit concerning (to the point that you spent time to improve the benchmark), I posted here asking for confirmation from other users (see the subject of my post). If anyone with a similar Windows setup as mine can publish their figures, I'm the happiest bunny in town. 
&gt; Look, these are the values I'm getting, they are not tampered with, that's what I mean by "correct". Can you please stop implicating that I'm lying? I've never implicated that you are lying. I've said that I don't know why your numbers are so different from all other numbers I've seen. One possibility is that you made them up, but that's only relevant since you demand numbers from everybody else, apparently then "implying" that everybody else is lying, with your own logic. I've said that I think you should try this with the standard Python distribution. I still think you should try that, it will not take long. It's possible that Python 3 integer operations for some reason are extremely slow on 64 bit AMD at least under Windows, but that would surprise me. In any case, it isn't particularity relevant, unless the things you are doing with Python are heavy integer arithmetic, and if it was, you would know, and then you would have said so. All I did was explain why pystone is slower on Python 3. Other than that I agree with NeedsMoreTests, that to get any useful information you need to have tests more specific to you. Something you probably would have had now, if you had followed his advice instead of trying to come up with excuses not to do that. 
I don't think that is meaningful for a file-based static CMS like Urubu. But there is an extensive [manual](http://urubu.jandecaluwe.com/manual/) and a [quickstart site](http://urubu-quickstart.jandecaluwe.com/). Moreover, both sites have public repos on GitHub.
Truth is you were so worried of the numbers I posted, that you rushed to fix the benchmark to try and squeeze out as much juice as you could, while calling me a troll all along. Trolls are usually ignored, but you didn't ignore me at all, quite the opposite. You put a lot of effort to defuse my arguments, so they were valid, hence that was not trolling :) I think I can call you a **Throll** instead (a troll on mission to defend Python Three at any cost). 
Is it? I know TMTOWTDI, but I always threw a cat at my keyboard and ran the result.
Yes, we can stick to that. What in your question do you feel is not answered?
The dependencies of my app is like this http://gyazo.com/0c8d66ba1e303028a49229892e117b95
&gt; Truth is you were so worried of the numbers I posted, that you rushed to fix the benchmark to try and squeeze out as much juice as you could, while calling me a troll all along. No, I just looked at the code to see what it was doing, which I haven't done before, and I noticed a bug. My mistake was that I mentioned this to you, and you have now hooked onto that like it has any significance whatsoever. It doesn't. I don't know why you go on about it. I gave you a list of reasons why pystone is slower on Python 3. One of the reasons was a bug. A fix has now been committed. It does not change anything else I said. &gt; Trolls are usually ignored Oh god, that's the most idiotic thing I've heard so far. Trolls are people trying to start a fight, or making people angry, for no actual reason. You are clearly a troll. I WOULD have ignored you, if you weren't also busy spreading FUD as a part of the trolling. &gt; You put a lot of effort to defuse my arguments Yes. &gt; so they were valid If they were, I would not have been able to defuse them. 
Ow, my brain.
The Python developers are their own worst enemies for encouraging the adoption of Python 3.
Figured it was something like this. Can't really think of a case when I used a class without instantiating it myself. 
Still waiting to see pystone numbers from a Windows 64bit set up. Do you have any?
Can't wait for them to go the way of Firefox and eventually have a 2.7.29 since, "There will be no 2.8."
for python2.7, add the following statement at beginning of the script: from __future__ import print_function
With all those parentheses, I thought that that was lisp.
My dear Throll, explain why I was spreading FUD just by posting a couple of numbers. I run a benchmark, post the results, ask for an explanation and I'm labelled a troll (since the very first reply, mind you). What's the matter with you, Throlls? So worried that the beloved Python 3 is not being embraced by everyone and their dog? Seeing FUD everywhere won't help your cause, unfortunately. 
I can't wait for the day everyone just finally moves to 3.x...
OK, meta-discussion it is. NeedsMoreTest: "Given this is your first post, your username is pyslow, you're not doing your own benchmarks for things you actually care about and this seems to be your sole reason for not wanting to use Python 3 I'm going to assume you're either trolling or just lazy (sorry not much else to go on here)." I agree with that assessment. Now, everyone can make mistakes, and I'm willing to gove anyone both second and third chances. The username "pyslow", and the headline "Python 3.4 slow compared to Python 2.7" could have been excusable if you had changed your attitude. You didn't. You have instead spent time actively trying to misinterpret people, including Brett Cannon's tests, and generally been rude. You have also showed an active disinterest in actually figuring out if Python 3 would be slower for you. It's completely obvious that you posted this as trolling/FUD to try to claim that Python 3 is much, much slower than Python 2. And when you encountered reasonable responses to that you have mostly ignored them, or been rude. You are also writing very much in the style of the Python 3 troll whose account was deleted, so unless you stop trolling pretty soon, my mind is made up on the issue, and I can only hope this account gets deleted to. If you want to have constructive and civilized discussions on the issue of Python 3, these are welcomed. But being rude and misinterpreting everyone else is not. 
See [here](http://redd.it/272bao) for another thread on pystone (with results of Python 3 on Windows being even worse). 
Good to know for loops still leak. If they didn't I'd have a lot of code to change migrating to 3.
No, I don't, just 32-bit. Which are around 25% there as well. Are you running it in a virtual machine?
Yes, integer performance is slightly slower in Python 3. This is supposedly mostly because long is merged into int. This will only affect you if you make a lot of integer arithmetic. pystone is useful to compare pure python performance on different machines. It's not useful to compare different Python versions.
Hey, I'm not the one who started calling names on others. As you pointed out, NeedsMoreTest initially replied assuming I was a troll (because of my username???), then we had a civilized discussion and we came to some sort of agreement on Python 3 performance issues and what the best route to a migration could be in light of that. And that was the end of it (check it out, if you wish). Then you chimed in, immediately implicating that I'm an old troll with a new account, without any evidence of that. Quite a civilized way to start a conversation, don't you think? And then it was just lecturing and patronizing all along with spurious reasons and innuendos. Tell me, for example, where I misinterpreted Brett Cannon's benchmarks. He says that Python 3 has, *on average*, the same performances as Python 2.7, but such average comes with a noticeable variance (look at the charts of slide 33 for yourself), so certain operations can be faster and others slower. I said that I didn't want to take the risk of ending up with the slow ones, if I had to upgrade. You can disagree with this, but you can't say I misinterpreted anything. You are seeing the rosy side of Python 3, I'm concerned about the not-so-rosy one. This does not make me a troll and I expect some respect for my point of view, even if you strongly disagree with it and you fear that this kind of discussion can dent the image of Python 3. As for being rude, just count how many times you used the (offensive) word "troll" against me since the beginning. Or all the times you implicated that my numbers were fabricated and that I was lying. Or being slightly threatening by mentioning that my account can be deleted. 
Very true, do you know of a better subreddit? I know I've seen the occasional noise canceling library , I was hoping someone had written one in Python. 
Thanks for the advice. I will. 
Thank you for this. I generally eat, sleep, and breath any new tasks I take on. I guess it's my personality. I don't like doing things half ass and I hate being bad at things. I'm only 6 months into python and I've gone varied between phases in that time. I'm either all in, or annoyed at my lack of progression and take some time off. Consistency is the key and I've dropped the ball on it. 
One thing I don't do enough is asking for code reviews and read other developers codes. I guess I should take more time to read through other developer's projects and figure out/ask why they do things a certain way. 
Yeah, but it was the binary operators that gave it away ;)
Thanks. It means a lot to me, regardless of the outcome.
&gt; He said he started looking at everything differently. His code, life, the way programs worked, etc. His *life*? Wow, batteries really *are* included.
You might find /r/learnpython a better sub for this kind of thing.
I'll only be waiting as long as it takes for the major outliers to finally migrate (Twisted comes to mind). It's still library support that's the issue, the version of the language itself is pretty rock solid. I personally will only touch 2.x when I absolutely must (and even then it's full of "__future__" imports). 
Python and raspberry pi are fine for this. The noise from the fridge is largely periodic. You can sample for a little while (100 periods or so) to find the periodic signal, then compute the canceling signal. Now the latency is going to make the next part tough, but not impossible. You start transmitting the canceling signal, recording the combined signal for many periods (~10), then offset your signal in time. Keeping doing this until you find the right offset to minimize the noise. This can all be fully automated. Is this going to be perfect, no. Is this going to be extremely cool, yes.
I don't know of a good way to handle this using Python. Others have mentioned that hardware latency is going to be an issue - it will. Python itself may also induce latency as well thanks to its interpreted design. Since you're trying to do active noise cancelling, the key is to emit an inverted sound-wave to cancel out the sound being generated. You'll want to sample as fast as possible, invert, and emit just as fast. My gut tells me this is as simple as using direct pin I/O for a microphone and an amp/speaker, but I have no clue how to do that. One thing should be obvious: involving USB devices is going to cost precious latency and may not work as well as one would hope. Some much smarter people have already discussed all this, with a rather inconclusive thread: http://www.raspberrypi.org/forums/viewtopic.php?f=37&amp;t=8766 Maybe that will help. The hacker route would involve taking apart some active noise-cancelling headphones, and to wire the output to a bigger speaker. But I've never tried this, so YMMV.
Hm, interesting. You begin to fall down a hole though; should we obfuscated `__builtins__` too? `chr()` is a fun problem, though. Instead of using the function, we can implement it using `hex()` and the `string_escape` codec: &gt;&gt;&gt; chr2 = lambda n: ("\\" + hex(n)[1:]).decode("string_escape") &gt;&gt;&gt; print chr(100), chr2(100) d d You'll have to deal with hiding `"\\"` and `"string_escape"`, though. I think `hex()` can be replaced with another recursive function.
So, my suggestion is try to get job with your current skill with an possibility of working as programmer. Everyone gives some suggestions to learn programming or get better at it, but none of them worked for me. So, I can't really suggest other people on what to do, except above. 
Smells like Haskell... don't you agree, OP? ;)
&gt;Is it the standard answer here that any question doubting the greatness of Python 3 is immediately classed as trolling? Mostly, yes. Usually you just get downvoted, occasionally you get called a troll in comments.
Lessons learned: people want t-shirts in their backer rewards.
Feels dirty to me. I expect a decorator to return a function. On the other hand, not a lot of functions take a function and nothing else, so it's hard to *really* misuse. If your function is longer than one line, isn't it nice for it to be reusable and testable?
Good stuff! My coworkers and I are toying with the idea of Open-Sourcing our HTTP Server and Psycopg2 libraries that are written purely in AsyncIO. Any interest from the /r/Python community?
I mean the way he interpreted things in life. Not his outlook of life. A small example would be that instead of looking at a car and saying "wow, that's a bad ass car" he would look at it and ask himself "how" and "why" it was designed like it was. 
Yep it's one of the standard packages in 3.3+: from BDFL import Enlightenment, Revelation, Sanity 
&gt; If your function is longer than one line, isn't it nice for it to be reusable and testable? Of course, but that kind of function would be defined on module or class level anyway and not in local scope. As soon as a function deserves a name, I would not use this pattern. 
Yes. I'm working on a project now that could use both of those. Any idea what license it would be released under?
&gt; software that makes the world a better place is this a silicon valley reference?
&gt; TMTOWTDI I hate acronyms like this.
This seems interesting. Cycling through command history using up/down arrow keys comes natural to anyone who ever used a terminal. As a python newbie, the fact that the cursor moves (instead of cycling through history) when pressing up/down keys in the default IDLE drives me crazy. Thanks for bringing back the sane behavior. Matplotlib support is an interesting feature that I will definitely check later.
What is so sad is that I've had this in my resume/profile bio for years, Silicon Valkey totally nailed it when it came to making fun of startups :)
Feels dirty to me as well. The lack of anonymous functions is an unfortunate, but unavoidable consequence of having no end tag in the language. To my knowledge, no one has come up with a clean syntax for them. Guido has [commented](http://www.artima.com/weblogs/viewpost.jsp?thread=147358) on this, and I agree in this case.
I disagree. I don't think this is dirty at all. The whole point of the decorator syntax is to allow you to put logic near the top of a function declaration which would previously have needed to go at the end. This "Ruby block-like" idiom is a clear example of this situation. Assuming the deconrator is well constructed to return the thread object in place of the function (decorators are not restricted to returning function), I don't see any downside. I think it should be down to the naming and documentation to make it clear how the decorator should be used, though.
I wanted a mug, actually. Honestly though, I would have probably donated only slightly less had it not been offered.
Thank you. Stock IDLE uses Alt-P and Alt-N for cycling command history and is nearly impossible to discover. Also, IDLE has Matplotlib support if you are using the TkAgg backend. See http://bugs.python.org/issue989712
[If you want to remove the numbers from that code.](http://www.jsfuck.com/#)
Ah, now I finally have a reason to upgrade to Python 3. I'm still with 2.x: import QuietDesperation as mylife
*shrugs* I don't see a point in continuing the meta-discussion. You come in looking as a troll, and you continue to behave like one. I'll stop calling you a troll when you stop trolling. &gt; Or all the times you implicated that my numbers were fabricated and that I was lying. I have done no such thing. &gt; Or being slightly threatening by mentioning that my account can be deleted. That's hardly threatening. *I* can't delete it. And if you are worried that your account might get deleted for trolling, then stop trolling. Easy. 
Damned if you do damned if you don't.
64 bit Windows 7. Standard Python distributions. Intel i3. C:\Python27&gt;python.exe -m test.pystone 1000000 Pystone(1.1) time for 1000000 passes = 9.48239 This machine benchmarks at 105459 pystones/second That's the base. C:\Python33&gt;python.exe -m test.pystone 1000000 Pystone(1.1) time for 1000000 passes = 12.3544 This machine benchmarks at 80942.6 pystones/second Python 2.7 is 30% faster on integer calculations than Python 3.3 on this computer (not factoring in the bug, meaning it's rather 25%) C:\Python34&gt;python.exe -m test.pystone 1000000 Pystone(1.1) time for 1000000 passes = 11.8415 This machine benchmarks at 84448.9 pystones/second 2.7 is c:a 25% faster that 3.4, not factoring in the bug. C:\Python34&gt;python.exe -m test.pystone 1000000 Pystone(1.2) time for 1000000 passes = 11.1486 This machine benchmarks at 89697.2 pystones/second And with the bug fixed, it's down c:a 18% faster than 3.4, on a 64-bit Windows. This is very similar to what I get on Linux, except that I there get the same for 3.3 and 3.4. I suspect the bad 3.3 performance here is just a "fluke" but I can't be bothered to sit and run this over and over. Because yet again, this only measure's integer calculation performance, and is **completely irrelevant as a real world measurement** unless you are doing a lot of small integer calculations, and you aren't, because why the heck would you? I still suspect, as I did from the start, that there is something fishy in those distributions you are using. Although perhaps it has to do with you using AMD. Anything is possible... 
Well, it's not like that if you keep saying troll, Python 3 will suddenly become faster. But if that makes you feel better, go ahead, my dear Throll. 
Again the claim that Python 3 is slow as a blanket statement, contrary to evidence. And still not one single attempt of actually proving anything you say, listening to what others say, or even an attempt of figuring out what takes time in your code. Ie, you are still just spreading FUD, and not trying to be constructive. You don't actually care about the performance of your code, this is just you trying to find things to complain about Python 3.
Good ol' &gt;+++++++++[&lt;++++++++&gt;-]&lt;.&gt;+++++++[&lt;++++&gt;-]&lt;+.+++++++..+++.[-] &gt;++++++++[&lt;++++&gt;-] &lt;.&gt;+++++++++++[&lt;++++++++&gt;-]&lt;-.--------.+++ .------.--------.[-]&gt;++++++++[&lt;++++&gt;- ]&lt;+.[-]++++++++++.
&gt; The whole point of the decorator syntax is to allow you to put logic near the top of a function declaration Here *I* disagree :-) That's *not* the point of decorators. PEP 318 describes the motivation as follows: &gt; The current method of applying a transformation to a function or method places the actual transformation after the function body. For large functions this separates a key component of the function's behavior from the definition of the rest of the function's external interface. [...] This becomes less readable with longer methods. It also seems less than pythonic to name the function three times for what is conceptually a single declaration. Decorators were introduced for *transformation* of methods, to avoid patterns like def foo(): ... foo = staticmethod(foo) They are meant to signify to the reader: "hey, the following method has some special properties", and while a decorator might have some slight side effects (like registering the function to a global registry (think Flask's routes)), it shouldn't cause the function to be executed in one way or the other. In other words: decorators do not exist to save the programmer from typing an additional line; they are there to communicate a distiction between "the following method will be transformed by foo" as opposed to "call foo on the method and store the result". The latter implies some kind of execution. Therefore, abusing decorators in this way is unpythonic IMO, because they make the intention of the code less clear. Remember that you are writing code for humans first, the computer second. It's ok to write another line if it makes the code more readable.
Considering I cannot write Python on my iDevice without purchasing a separate app (Pythonista), it is a very strange comparison for them to make. ObjC is the only honest comparison. It clearly did pilfer a few things from Python, such as tuples, and some of the destructuring looping things look an awful lot like Python, though I'd imagine there are other C-like languages that have the same thing these days. If you grab the book, spend some time looking at the love given to the "swtich" statement. Still not sure how I feel about the generics add-ons.
I find the pattern unpythonic as well. See my response to /u/bryancole for a longer explanation. Basically, by using decorators in this way, you blur the distinction between transforming and executing a function, which was the whole point for the introduction of decorators. I don't expect a function's code to be executed until I see the name referenced somewhere, if I see code like def foo(): @blagarble def task(): ... return 42 I do not expect that ``task`` is actually called. I would have to check the code for ``blagarble`` to see that. (Which I won't, as I'm not interested in ``blagarble`` at the moment, I'm trying to find a bug in ``foo``)
Oooohh, some numbers at long last! After so many words... See, it wasn't that difficult, was it? I'm using Intel as well and the two distributions are supposed to be optimized for scientific usage, so can't say why my numbers are so different. But, really that was all I needed to know, if only the discussion wasn't hijacked by all that trolling fear of yours. Hopefully someone else can also provide other values to compare. Having said the above, 20% is still a bad number in my opinion (hey, I've said *my* opinion, don't go ballistic with the troll thing) and, since it's in line with Brett's "bad half" of more meaningful benchmarks (25%), it's definitely something to consider when deciding whether to upgrade or not. 
Well MacOS/Obj-C development had a long history before iOS, and Apple ships Python (and NumPy) with every Mac, so it's not very strange to me. Not to mention, of course, that Python is incredibly popular. 
Blanket statement, my a... I've proved that Python 3 is slower as per the pystone benchmark, don't you agree? If you don't, then show me the pystone numbers (actually, you've just done it in another comment and it turned out Python 2.7 is still ~20% faster). I've proved that roughly half of Brett's benchmarks are slower under Python 3, don't you agree? If you don't, then point me to the relevant slides, as I did. Now, ball to you: prove me that Python 3 is actually faster, then. 'Cause the best you could do so far was to prove that it's the same as 2.7, *if you're lucky*. What is *your* evidence? There is nothing that makes my code slow right now, it works just fine, I don't need to care about its *current* performances: it's switching to Python 3 that could make it slower and that is what has been worried me since I started this thread. 
Single platform language? How about no. I use C++ with cocos2d-x to make apps that work on many platforms. I use Python to make things that work on many platforms. And I used QT with C++ to make things on many platforms. When I started iOS app programming I learned Objective-C and never again will I learn a single platform language. 
Try Kivy. It works pretty well. I suspect that within a version or two that it will rock some worlds. 
~~Wall of Shame~~ [Wall of Superpowers](http://python3wos.appspot.com/)
I think the underscore-in-numeric-literal syntax comes from Verilog: wire [31:0] oneMillion = 32'd1_000_000; Also, Scala seems to be an influence on things like the `switch`, `var`, and `let` statements.
I think a divided Python community will stall the language and ultimately hurt its growth in the free market of languages with almost no barriers to entry from open source world on one hand and massive influence from major corporate players on the other. Apple just released Swift, while Google developed Dart and Golang, and Microsoft enjoying success with F# in .NET world. Ruby community doesn't seem divided, in fact Rails has seemlessly integrated CoffeeScript within their framework - which Javascript officially endorses as their future direction while maintaining a monopoly over browser client scripting. Python community ignores CoffeeScript while fighting over Python 2 vs Python 3, and chooses to hack together a pythonic equivalent rather than endorse it. So it seems that Ruby is setting itself up politically to continue to succeed in its domain, while Python may not grow any further outside of scientific computing. I probably don't know what I'm talking about.
How does one think up some of these? How do you go from 'ok I know what comprehensions, sum() lambda, and ord() does' to 'lets use a anonymous recursion to hide a string as an encoded number' To me, this is like saying Ok, give me some of those legos. Ok, heres your warp engine. 
If I understand correctly, asyncio should be great for Twisted, and Twisted on Python 3 will soon be better than it was on 2. But I may have misunderstood.
I believe you are correct (it's how I've understood it). asyncio will make it easier for *all* of the async-based libs to function.
Maybe you could do something like: def spawns(func): @functools.wraps(func) def result(): return gevent.spawn(func) return result # ... @spawns def func(): print('hello') task = func() EDIT: Although, it doesn't seem to help much in this case. 
Man Ive spent far too long on this today but I think I understand all of it. Theres a lingering interesting issue though. The part where he sums the ords, I get : 802616035175241117369516189000 he gets 802616035175250124568770929992 The funny thing is, they both decode to the same thing. Any guesses as to why this happens, and how they decode the same?
I believe the top one is `"Hello World!\n"` and the bottom one is `"Hello world!\n"`. I know, technically the competition said I should've used the the top one, but I made a mistake and decided to stick with it. The algorithm will work on either, though; you'll just end up with a slightly different result.
There's definitely no way around including at least 1 valid and existing Python name, I think. You could hide `__builtins__` and `__dict__` with `eval`.
&gt; I've proved that Python 3 is slower as per the pystone benchmark, don't you agree? No. The pystone benchmark does not prove that Python 3 is slower. You seem to still not understand what the pystone benchmark does. &gt; I've proved that roughly half of Brett's benchmarks are slower under Python 3, don't you agree? If you don't, then point me to the relevant slides, as I did. And half were faster. &gt; Now, ball to you: prove me that Python 3 is actually faster, then. See above. &gt; 'Cause the best you could do so far was to prove that it's the same as 2.7, if you're lucky. You seem not to be able to read. You claim that Bretts benchmarks prove that Python 3 is slower, since half of them is slower and half of them is faster. Don't you really see the problem in that logic? &gt; There is nothing that makes my code slow right now, it works just fine, I don't need to care about its current performances: it's switching to Python 3 that could make it slower and that is what has been worried me since I started this thread No, that's just an excuse. If performance is fine now and you don't need to worry about it now, then you don't need to worry about in in Python 3. All of this is just an excuse for you to complain about Python 3. 
in python3 Tkinter has changed to tkinter, all lowercase. hopefully this is all you need. If you have a problem with numpy then sorry, can't help yah :D
&gt; But, really that was all I needed to know I was telling you this from the start. It's approximately 20-25% difference. All I did now was find a 64 bit Windows to see if that was the difference. It was not. &gt; if only the discussion wasn't hijacked by all that trolling fear of yours. What a ridiculous excuse to troll. &gt; 20% is still a bad number in my opinion You clearly still think this is a relevant number. The only possibly reason that you can think this is a relevant number by now, despite two people having told you it is not, and explained why, is that you are clinging on to this number as an excuse. &gt; it's definitely something to consider when deciding whether to upgrade or not. If you are worried about performance, which you clearly are NOT, then performance is indeed something to consider. And then you need to figure out what the bottlenecks in your app are. Which you have not. Because you aren't actually worried about performance. 
Ahh I see the difference now. Man Ive learned a ton from that code. Got any more?
Getting [SciPy and NumPy](http://www.scipy.org/scipylib/download.html) It would also help to know what OS you're using. If you're on Linux it's easier.
How to [install tkinter](http://tkinter.unpythonic.net/wiki/How_to_install_Tkinter)
Neat! You should x/post this to /r/cellular_automata
The first link on that page gives a 404. The 2d link is to the regular python install page and says that using that page to install python will also install tcl/tk and tkinter. Well, that's how I installed python, but I don't see those packages. I used pip list, and it didn't show them.
&gt; (Python.org doesn't seem to have this topic anymore.) Doesn't you package manager have tkinter and everything else?
Do you mean pip.exe? pip list shows only pip and setuptools. Nothing else. 
No, I assumed you were on linux. Sorry. The sad state of package management on Windows leaves me befuddled.
&gt;Swift is a compiled language so at some level there is strong typing even if it is hidden behind magic This does not sound right to me, what does compiling have to do with typing?
pip search accepted 'tkinter', and gave me a long list of stuff that had tkinter in the description but not tkinter itself! 
Can someone give me a link to the final obfuscated version only? I'd like to look at it and try to understand it without "spoilers" before I read about how they did it.
While an electrical engineer by trade, I've been programming since I could type. Sadly, much of my output could have been, charitably, refereed to as engineering code. Not awesome. What really turned the corner for me was writing a library for internal company use. I had to sit down and really think about how things should be organized and how others would actually use my library (a [GDS](http://en.wikipedia.org/wiki/GDSII) library but you are probably better off using [gdspy](http://gdspy.sourceforge.net/) which didn't exist when I started).
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**GDSII**](https://en.wikipedia.org/wiki/GDSII): [](#sfw) --- &gt; &gt;__GDSII stream format__, common acronym __GDSII__, is a [database](https://en.wikipedia.org/wiki/Database) [file format](https://en.wikipedia.org/wiki/File_format) which is the de facto industry standard for data exchange of [integrated circuit](https://en.wikipedia.org/wiki/Integrated_circuit) or [IC layout](https://en.wikipedia.org/wiki/IC_layout) artwork. It is a [binary file](https://en.wikipedia.org/wiki/Binary_file) format representing planar geometric shapes, text labels, and other information about the layout in hierarchical form. The data can be used to reconstruct all or part of the artwork to be used in sharing layouts, transferring artwork between different tools, or creating [photomasks](https://en.wikipedia.org/wiki/Photomask). &gt;==== &gt;[**Image**](https://i.imgur.com/9bgOrIr.png) [^(i)](https://commons.wikimedia.org/wiki/File:Silicon_chip_3d.png) - *A rendering of a small GDSII standard cell with three metal layers \(dielectric has been removed\). The sand-colored structures are metal interconnect, with the vertical pillars being contacts, typically plugs of tungsten. The reddish structures are polysilicon gates, and the solid at the bottom is the crystalline silicon bulk.* --- ^Interesting: [^Design ^flow ^\(EDA)](https://en.wikipedia.org/wiki/Design_flow_\(EDA\)) ^| [^Electronic ^design ^automation](https://en.wikipedia.org/wiki/Electronic_design_automation) ^| [^Integrated ^circuit ^layout](https://en.wikipedia.org/wiki/Integrated_circuit_layout) ^| [^Open ^Artwork ^System ^Interchange ^Standard](https://en.wikipedia.org/wiki/Open_Artwork_System_Interchange_Standard) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+chxk18e) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+chxk18e)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
The path is in the environment path variable as C:\python34, just the way that the python.org installer set it up. How SHOULD it be set?
True, but the syntax is otherwise pretty different I believe. 
The cleanest proposal I saw used a syntactic construct similar to Haskell's `where` clause: gevent.spawn(?.func) given: def func(): print('hello') [Here's the PEP](http://legacy.python.org/dev/peps/pep-3150/). EDIT: fixed syntax
It's here: http://codepad.org/UzSmoxF2. If you prefer the version without line breaks (a bit more obfuscated): (lambda _, __, ___, ____, _____, ______, _______, ________: getattr(__import__(True.__class__.__name__[_] + [].__class__.__name__[__]), ().__class__.__eq__.__class__.__name__[:__] + ().__iter__().__class__.__name__[_____:________])(_, (lambda _, __, ___: _(_, __, ___))(lambda _, __, ___: chr(___ % __) + _(_, __, ___ // __) if ___ else (lambda: _).func_code.co_lnotab, _ &lt;&lt; ________, (((_____ &lt;&lt; ____) + _) &lt;&lt; ((___ &lt;&lt; _____) - ___)) + (((((___ &lt;&lt; __) - _) &lt;&lt; ___) + _) &lt;&lt; ((_____ &lt;&lt; ____) + (_ &lt;&lt; _))) + (((_______ &lt;&lt; __) - _) &lt;&lt; (((((_ &lt;&lt; ___) + _)) &lt;&lt; ___) + (_ &lt;&lt; _))) + (((_______ &lt;&lt; ___) + _) &lt;&lt; ((_ &lt;&lt; ______) + _)) + (((_______ &lt;&lt; ____) - _) &lt;&lt; ((_______ &lt;&lt; ___))) + (((_ &lt;&lt; ____) - _) &lt;&lt; ((((___ &lt;&lt; __) + _) &lt;&lt; __) - _)) - (_______ &lt;&lt; ((((___ &lt;&lt; __) - _) &lt;&lt; __) + _)) + (_______ &lt;&lt; (((((_ &lt;&lt; ___) + _)) &lt;&lt; __))) - ((((((_ &lt;&lt; ___) + _)) &lt;&lt; __) + _) &lt;&lt; ((((___ &lt;&lt; __) + _) &lt;&lt; _))) + (((_______ &lt;&lt; __) - _) &lt;&lt; (((((_ &lt;&lt; ___) + _)) &lt;&lt; _))) + (((___ &lt;&lt; ___) + _) &lt;&lt; ((_____ &lt;&lt; _))) + (_____ &lt;&lt; ______) + (_ &lt;&lt; ___))))(*(lambda _, __, ___: _(_, __, ___))((lambda _, __, ___: [__(___[(lambda: _).func_code.co_nlocals])] + _(_, __, ___[(lambda _: _).func_code.co_nlocals:]) if ___ else []), lambda _: _.func_code.co_argcount, (lambda _: _, lambda _, __: _, lambda _, __, ___: _, lambda _, __, ___, ____: _, lambda _, __, ___, ____, _____: _, lambda _, __, ___, ____, _____, ______: _, lambda _, __, ___, ____, _____, ______, _______: _, lambda _, __, ___, ____, _____, ______, _______, ________: _)))
There are a few other similarities: switch without falling through by default, the fallthrough keyword, Swift protocol =&gt; Go interface
&gt;This is something small that seems cool: `let oneMillion = 1_000_000` That one was borrowed from Ruby, actually.
Yeah, just thought that was cool. Would be great if Python adding that.
&gt; I think a divided Python community will stall the language and ultimately hurt its growth I've been a python beginner on the side for a while and this is what I am seeing. It's very discouraging. I've been eyeing Golang. 
The fact that this is possible in javascript is hilarious and wonderful.
For quick game development, Swift should be good: faster than Object-C, that is it. But for advanced techniques which have been implemented in Python, e.g. Face Detection in Open CV, surely Kivy rocks.
 Dónde está la bliblioteca?
Pystone is a benchmark and produces some numbers "somehow" related to performance. We can discuss forever on what "somehow" means in this instance, but if Python 3 is slower on that benchmark, then that's it, it's slower on a benchmark that is supposed to provide basic performance guidance. You don't like pystone? Ask devs to dump the tool and replace it with something more meaningful (and maybe more friendly to Python 3). The Brett's benchmarks thing is getting ridicolous. Hopefully a simple metaphor will help. Say, you are sitting in a car comfortably going somewhere at 50 km/h. Now, someone stops your car and forces you into another one that has only two driving modes: either 100 km/h or 0 km/h. On average this second car is still doing 50 km/h like the first one: a fleet of 100 of these cars would clock 5000 km in an hour (hence 50 km/h on average). So, no big deal on average, but would you really prefer this second type of car to go somewhere? Sure, if you're lucky, you can drive at 100 km/h, but, if you are unlucky and get the 0 km/h version, you wouldn't go anywhere at all. Better the first car, that always takes you everywhere at 50 km/h all the time. See any similarities with Python 3 being slower than 2.7 in 50% of the benchmarks? Your final point makes no sense to me and it seems to be a way for you to write the word "excuse" one more time (along with "troll" it peppers your exposition, for some reason). If performance of my code is fine now and I don't need to worry about it now, then I don't need to worry about in in Python 3, *as long as* I don't move to Python 3. Should I decide to migrate, then I had to start worry and that should not be the case (as it was not the case with previous Python versions). Hence the complaint about Python 3: ideally there should be no need to worry about performances when moving to a newer version of a language. Finally, I always appreciate your offensive attitude ("You seem not to be able to read"), but then again, everyone's a brave big mouth behind a keyboard, myself included :) 
I played around for a bit and came up with something. Built-ins are accessible as an attribute of frame objects via `f_builtins`. You can't normally get frame objects without `sys` or inspecting tracebacks, but they're also accessible within generators via `gi_frame`, and generators can be created anonymously: &gt;&gt;&gt; (_ for _ in ()).gi_frame.f_builtins["__import__"] &lt;built-in function __import__&gt; So if dynamically created objects and attribute access are acceptable, then yes, you can call built-in functions without directly using a built-in function.
I have no idea.
Isn't that the whole point of decorators in a library such as Flask? I mean, sure, it's not what decorators were meant for, but I think it's a very good use for them.
You are right, you can have compiled languages that support dynamic types albeit with some extra overhead. I think I'm more referring to it's lineage from Objective C which uses underlying C types directly. Also I think I remember Cook mentioning type inferencing which further supports my claim that it is statically typed (IIRC).
I *wanted* to hang out with LeVar and wear the VISOR...but I also wanted to stay married to my wife. The latter overrode the former.
Thanks for the link. **TL,DR:** *Python2.7 is better at running the pystone tests.* ============================== | | | |------|------| | **CPU** | i5-3230M | | **Kernel** | 3.14.4-200.fc20.x86_64 | | **GCC** | 4.8.2 | My results are as follows: **Python 2.7.7** --------------------------------- Python 2.7.7 (default, Jun 2 2014, 13:47:28) [GCC 4.8.2 20131212 (Red Hat 4.8.2-7)] on linux Pystone(1.1) time for 500000 passes = 4.24083 This machine benchmarks at 117901 pystones/second cProfile Pystone(1.1) time for 500000 passes = 6.7549 This machine benchmarks at 74020.3 pystones/second 11000013 function calls in 6.820 seconds **Python 3.4.1** --------------------------------- Python 3.4.1 (default, Jun 1 2014, 16:34:24) [GCC 4.8.2 20131212 (Red Hat 4.8.2-7)] on linux Pystone(1.1) time for 500000 passes = 5.24793 This machine benchmarks at 95275.7 pystones/second cProfile Pystone(1.1) time for 500000 passes = 7.5993 This machine benchmarks at 65795.6 pystones/second 10500014 function calls in 7.676 seconds Seems like pyton2.7 is quicker. *Python2.7 completed MORE functin calls, in LESS time* **However...** $ file /usr/local/bin/python3.4 /usr/local/bin/python3.4: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 2.6.32, not stripped $file /usr/local/bin/python2.7 /usr/bin/python2.7: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 2.6.32, stripped As you can see, I stripped the debugging symbols from 2.7.7, but not from 3.4.1. (I am not sure if it makes a significant difference) Another difference is the pystone files I used. For 2.7.7 I used: http://hg.python.org/releasing/2.7.7/file/4b38a5a36536/Lib/test/pystone.py For 3.4.1 I used: http://hg.python.org/releasing/3.4.1/file/ea310ca42bb2/Lib/test/pystone.py Best Wishes 
Python GUI with build support for IOS, android, ...
Benchmarks are probably the wrong thing to focus on for Python in general. Tools like cython make it (almost) trivial to optimize python as/when required. Python excels in developer productivity, clarity and testability which are arguably hard to compare quantitatively. 
Nice! Didn't know that actually.
Ruby does it too iirc.
[PEP403](http://legacy.python.org/dev/peps/pep-0403/) (found via [PEP3150](http://legacy.python.org/dev/peps/pep-3150/) as referenced by /u/mebimage) actually proposes a syntax very similar to this: @in task = gevent.spawn(func) def func(): print("hello")
Beat me to it!
What made it "click" was five years of practice.
TALEWTDI
Rastor GUI with prickly pear architecture for Gamecube, Xbox, ...
Well right, but even on a Mac, don't you think Python should be able to compete performance-wise on the same tasks as C? Or perhaps is the mere fact that C is a compiled language responsible for the apparent performance difference?
This is almost exactly what happened to me. It's disheartening to be straddling two versions. I'd love to fully upgrade to 3.x but the Linux distribution we use at work is sticking with 2.x solely. That's why I started playing with Go(lang), and even though there are certain things I don't quite agree with (like those mentioned in comments above by iv597) overall I've been very pleased. The absence of exceptions takes some getting used to, but it's not a deal breaker because nearly the identical functionality exists, only in a different form. Other idosyncrosis seem to be growing on me the more I use them. I do miss list comprehensions though, even the exact same thing can be accomplished via a for loop (which in all honesty leads to more readable code even if it's not as fun to type). I'm slowly trying to migrate at least my pet projects over to golang because even though I believe Python will be around for many many years to come concurrency will be a big(ger) ticket item shortly. Once I'm more functional in the language I'd love to start to migrate some work projects over since most of our Python projects are still in relative infancy and not using any third party libs that can't be replicated in go, I figure it's best to try this switch out early and see where this rabbit hole leads... :)
I agree that there is no "a priori" ordering relation. I do not have a problem with Python defining one for me. Some times you need an ordering relation and you do not care what it is just so that you can, for example, serialize a set in a deterministic way. I think this should be a feature of the language.
The ability to have an ordering in a set of otherwise unordered objects is important else you cannot compare them efficiently. I do not care what the order is, I just want one. Before Python did provide one. Now it does not and I have to define one on my own. It seems to me a battery was removed because somebody thought it may one day leak acid.
the book is amazin!
I agree. The sooner you shed imagined restrictions away like *generators are made for you to put in a for loop* or *decorators must return callables* to focus on their core function(ie. *generator functions return interactive iterables*, *decorators take a callable and replace them*), the sooner you will see really neat applications for them, like ``@defer.inlineCallbacks`` or ``@asyncio.coroutine`` with generators.
~~Python 3 has it with different syntax (ie. 1'000'000)~~ My apologies, I misremembered this upcoming C++ feature addition as being in Python 3... Sadly, it's not true for Python.
I love it, I'm just trying to find an actual use for it.
why not ipython
Yeah, vanilla IDLE is pretty horrible. Can't even run a script without saving. VIDLE slightly improves on it, but this seems to be the extra boost it needs. There's still a lot of room for improvement but this is a good start.