This is awesome! Is the source code available anywhere? f I understand right, the XML save includes data about what items are placed where on the map? Does it generate the screenshot based off that?
These are all really good points. I've mastered JS somewhat, so a lot of these points wouldn't really apply to me anymore. I agree though, if I was going to do something like this being a novice in both languages, I'm sure I would have chosen Python without any hesitation. 
Frankenstein is a surname, which the Monster, as Frankensteins son, would have inherited. The proper distinction is that one is Dr. Frankenstein, and the other is Mr. Fankenstein.
&gt; No more GPG signatures You can still upload them, and the API still exposes them. They're just not shown in the web interface, because that's about the least useful place to show them. &gt; because the API was (probably still is)? broken in certain use cases Have you [filed bugs](https://github.com/pypa/warehouse/issues) for the use cases you think are "broken"? &gt; Why disable the web upload feature? Not sure why they did it, but personally I've never used the web interface to upload, and [the official recommendation](https://packaging.python.org/guides/tool-recommendations/#packaging-tool-recommendations), which I agree with FWIW, is to use [twine](https://pypi.org/project/twine/) for uploading.
So what, my point is that git, the software, is not aware of them. They're conveniences built on top.
No one 'needs' to learn standard C. C++ and Java both do what C does and is object oriented. The reason why one should learn C (and how C made python easier) is C teaches you how to program instead of what. In python you're telling the interpreter/compiler what you do. The details are irrelevant to you as a programmer. That's fine if the program does what you want it to do. It's problematic if it doesn't, and you don't understand the underlying principles. Learning C has drastically shortened my debugging cycle in python.
Used a library built off tensorflow called tflern to train a model using a highway network. We used a 4 dimensional tensor that described each audio sample. I can link you to the github in a DM. 
Frankenstein is a surname, which the Monster, as Frankenstein's son, would have inherited. The proper distinction is that one is Dr. Frankenstein, and the other is Mr. Frankenstein.
"Warehouse is a web application using the Pyramid web framework," 
Yeah, the XML save includes information as to what's on the map. We take that information and make a dictionary of what's at each position, then copy the corresponding asset from the asset sheet and place it in place. (In practice it's a bit more complex than that of course, because it's a website, not a commandline tool.) The source code is [on github](https://github.com/Sketchy502/SDV-Summary) if you want to have a look!
Thanks man &lt;3
I used to prefer aligned but after some time I now prefer the way pep8 suggests it. Here are two reasons: If one variable has a longer name than the others, all the others end up with a huge gap. This can hurt readability quite a bit since it becomes harder to visually determine which value belongs to which variable (if there are a lot of them). A lot more importantly, though: Every time you add/remove/rename a long variable name, everything else needs to be adjusted. Not only do some editors lack a convenient feature to do this, it also shows up in your git diff (or whatever vcs you're using). That makes it very hard to detect which lines were actually changed and which just had some irrelevant white space adjustment. Lastly, you're quoting "beautiful" and "readability". I've already mentioned why I don't think it's more readable. It's also not what I'd consider beauty in code. You're talking more about an aesthetical beauty, like a nice pattern on a wallpaper. Beautiful code is more about elegance and consistency, in my opinion. 
IDEs will do that for you, I use vim with easyalign and it does not mean any effort at all. When values are aligned it is easier to identify problems if values are similar/related so actually it becomes useful, ej.: args_feature_x = "a very long and complex string" args_feature_y = "a very long and complex text" It becomes easier to spot differences if both values are aligned in cases like that.
Python has an extensive standard library with lots of useful functions on builtin types. JS has… basically nothing. If you're trying to keep your dependencies slim JS is not the right choice. 
&gt; Adrian Rosbrock outrageous typo
That still leaves you with duplication. I’d prefer: prefix = “a very long and complex” args_feature_x = f”{prefix} string” args_feature_y = f”{prefix} text”
I use PyQt, because Qt has a WYSIWYG editor, but Kivy and wxPython are viable options as well.
PyQt is great because it has a GUI editor, so you can just position all the elements you need and then connect the logic code to the GUI with a few lines of code. You can also transfer your PyQt GUI to C++ fairy easily. 
Twitter is pretty easy to do with the APIs available for Python (tweepy is what I last used). I've never done Instagram, though. 
Haha the term 'schemaless' really threw me there. I think hyphenation is important.
Here is a link for a coding site called Coding Game...looks interesting to learn some basics for creating games. https://www.codingame.com Hope this helps you, Robert 
I've had the most success with pyqt. However, unless I'm missing something, you have to be able to understand the qt/c++ docs because there's not much Python specific documentation. I think they're working on documentation but I can't confirm. IMO the c++ docs aren't too hard to grasp though. There's also pyside, which is similar to pyqt.
I have a background in javascript and ruby. So no not starting at zero. I'm aiming for 4 hrs a day for the next 3 weeks then a lot more from there on forward. Our tech stack will be all python for the foreseeable future.
TY 
Step 1: read the sidebar.
Aww man I can hear the pompousness in your voice and it makes me want to die. You are the worst kind of dev. The naysayer. Anything is cram-able brah. you just gotta work hard enough
https://automatetheboringstuff.com/
Yeah, have you used Casper with node? It makes things so much easier and clean imo. I used BS4 and it didn't hit me like casper did. Scrapy may be something that I will check out though. I'm sure that would be more comparable to casper 
&gt; However, its uploading routines increasingly failed to fully record new releases (causing HTTP 500 internal server errors), which led to a ~10% error rate by June 2016. It's explicitly mentioned why web uploading was disabled.
This and the updated design (the 1990s look enraged me) make me inclined to use it more often.
Reminds me of the RAT named Cerberus.
&gt; haven’t tried on Linux can confirm: works on Linux 
This doesn't seem to have anything to do with secrets at all. It's just a dumb function that takes a single name, then tries reading the file with that name, or an environment variable of that name. When would this be useful? What if you intend to read the environment variable, but there happens to be a file with the same name in the current directory? And as I said, none of this has anything to do with secrets.
How can this: a = 1 a_really_long_name_that_has_some_meaning_but_is_really_long = 2 be better than this? a = 1 a_really_long_name_that_has_some_meaning_but_is_really_long = 2 I cannot imagine why you like reading across vast expanses of unnecessary and inconsistent whitespace.
It actually looks pretty interesting. It's basically GraphQL but at database level. Can't wait for it to reach a stable enough phase to use it.
^^ Yeah, for me the dependencies aren't the issue at all. Actually preferred if the process is easier. I'm interested in other views though, especially if there are things that you can't do in one, but can in the other. As well as speed and memory
Follow up question, is Kivy the only viable module for publishing for Android?
As a data guy this is very interesting but what does it have to do with python? I'm assuming since this is leveraging postgres that all the standard admin/maintenance functions can be done the same way as a normal postgres instance?
You have to enjoy the difficulty and the problem solving. If you don’t it’s probably not for you. If you do then just know that it can be difficult and push through it. 
There is nothing special about Flask. In mod_wsgi [quick configuration guide](https://modwsgi.readthedocs.io/en/develop/user-guides/quick-configuration-guide.html) there is a detailed example with minimal wsgi application. Just go through it, and after that replace minimal wsgi application with your own Flask wsgi application.
Depends, I don't know what `first` and `last` are. Could be any arbitrary number for all I know.
Interesting, I'll be sure to look into this in more detail. Slightly tangential comment: I read that pandas 2 is possibly going to be implemented in C++ (at least the internals). There was some work happening towards a prototype a while back: https://github.com/pandas-dev/pandas2
So that `s[x:y] + s[y:] == s`. 
Maybe if you’re just looking to solve the problem detailed IFTT would do the trick
Pycharm knows how to look inside your docker and see the installed packages
&gt; While the industry seems to be obsessed with solving the problems of scale, there are no serious attempts to solve the object-relational mismatch on the database side. I'm not really sure what this means. Do they not consider things like MongoDB "serious"?
Yes re/ future Pandas. Please read my comment above re/ apache arrow
Looks very interesting and well thought out! 
I think I tried caspar and I remember it being ok. I guess I'm so used to using lxml and xpath/cssselect and not dealing directly with async that I found node in general pretty cumbersome. Granted, I haven't done any scraping with node for at least a year.
Soon! :)
Casper makes the async issue almost non existent for basic tasks using it how it’s intended. Of course there will be instances you have to over come the async nature though. I guess I’m so use to Async that I don’t realize how bad it could be lol
You have to look at it like slicing bread. In fact, it's called slicing in Python. The ":" is where your knife cut. [0:5] will start at character 0 and after the slice will be character 5...but you don't want 5 and on. If this helps lmk and I'll gladly elaborate on all things slicing.
Why numbering should start at zero: https://www.cs.utexas.edu/users/EWD/transcriptions/EWD08xx/EWD831.html
This is great! Thank you very much for sharing, going to dig my teeth into this later. 
I conveniently left out the step size because that screws it up 😂
Async isn't bad, I'm just not really used to it. I can't remember if async was the issue I had with casper or if it was xpath, but at some point I said `fuck it` and went back to Python and got the same job done with less effort.
You're right, that's not a (formal) term. I was talking about strong or static typing, basically when an object of a type is assigned that differs from the declared type, it should be disallowed, with an error either at runtime or compile time. Also, I disagree that runtime checks don't help - for example javascript has all kinds of things that fail silently and that bothers me a lot. I'd rather have my code crash immediately than crash later on in a much more complicated way, or produce incorrect results.
Just because you *can* go crazy with f-strings, doesn't mean you *have* to go crazy with them. Just use them sensibly. I love f-strings, the syntax is much less verbose than `str.format()`.
This is sick! Looking forward to seeing where this project goes :)
will usage of the client APIs require asynchronous programming paradigms in order to fetch results ?
Considering nobody uses dataframes in production and Python is a far superior language for data manipulation / visualization / ML, what exactly is the point of this? 
Can't wait to finally see this open-sourced. This project has been on my radar for at least a year
[Cheerio](https://github.com/cheeriojs/cheerio) It allows you to select items from the DOM using a syntax similar to jQuery. That's just as easy as beautifulsoup. Just use request and cheerio and you can scrape away in no time!
EdgeDB runs as a standalone server with its own network protocols, CLI, tools etc. PostgreSQL bits are abstracted away completely. No specific paradigm is required from the client other than the ability to speak the protocol.
Yep, Cheerio is awesome
Access as in Microsoft Access? It uses the JET engine, not SQLite. You can't open an Access database directly with sqlite AFAIK, though I haven't used Access since the 90s.
It's _far_ easier to parse a long f-string than a comparative format based string. It becomes even easier if your editor has syntax highlighting and understands f-strings.
But... the link on the main page just takes you right to the docs, which describes it in the standard location. You had to click directly on the comments to come here, right? I see no reason to put down the post, and find this practice totally acceptable--even preferable in some cases. 
Another recommendation for Black Hat Python here. I think a great way to start learning is to build your own tools. A lot of folks write their PoCs in python these days too, reading source code is always a good way to learn something IMHO.
In that case I'd go do projects. Lots of projects. Anything you can think of. I like to do simple games (guess the number) then move up to something a bit more complex (connect 4) and eventually complicated games (chess).
You haven't shown exactly what you are doing. I just did the following on my Arch Linux RPi2 using all stock python3 which worked fine. Try exactly the same lines (which will not affect anything on your system outside of the env dir). This also ensures you are using latest pip. python3 -m venv env env/bin/pip install -U pip env/bin/pip install numpy
&gt; Rows will be selected only by integer location Does this mean no boolean indexing?
&gt; `STRING[FIRST:LAST +1]` Another way to think of it is `STRING[FIRST:FIRST+n]` where `n` is the desired length of the substring. 
Would you recommend getting a network+/ccent or can I just dive into this? 
Sqlite3 is for opening sqlite database files. You cannot open Access database files. The reason you don't get an error is because the tables don't exist, so the queries don't try to drop or create a table.
Treehouse is a pretty awesome video series of tutorials that also has code challenges and tests. It's kind of like Lynda I think. I used it to get my jump into Python and I really liked the teacher but he's not for everyone.
EdgeDB is not really a graph database. Although the data is conceptualized as an "object graph", we do not optimize for deep link traversals, patterned paths, semi-structured data analysis or other things that a graph database is good at. EdgeDB targets regular application workloads where a relational database (with or without an ORM) is appropriate. That said, many graphdb use-cases can be implemented efficiently in EdgeDB as well.
Your logic: I found a way to use it in a dumb way so there can be no good way of using it.
Oh, I was talking about this dexplo
yes...this explains a lot, thanks!
Pardon my vast ignorance here...is PYODBC run from Python in the way SQlite3 is?
EdgeDB language bindings will essentially be thin protocol wrappers adapting to the class model of the target language. For example, in Python you would be able to write something like: my_activity = Issue.select([ Issue.number, Issue.due_date, Issue.priority, [ Issue.priority.name ], Issue.owner, [ Issue.owner.name ] ]).filter(Issue.number == 10) .fetchone() and get your object and all related data in a single (possibly dynamically constructed) query. Data mutation is done similarly, so you can save an entire form of data in one shot, actually removing most of the need for the usual ORM dirty state tracking and flushing mechanics.
Yes
OOH! I'm very excited about this!
Maybe don't install anaconda? Maybe install [Python](https://www.python.org/downloads/windows/)...
1) go to Udacity.com . 2) create free account. 3) look for course ud170 --login with udacity account 4) lesson 1 : 4. setting up your system topic 5) you will get there a link "go through our short course on Anaconda and Jupyter notebooks to "
&gt; actually removing most of the need for the usual ORM dirty state tracking and flushing mechanics. you've got an object graph, parts of it change, then they want to persist it. You have to track the parts of it that changed versus those that didn't (dirty tracking). You have to express those changes ulimately in terms of INSERT/UPDATE/DELETE statements (flush). It doesn't make sense to say you don't have the need for those things.
I'm big on just diving into stuff. Certs are great for finding jobs.
How does it compare with Neo4J?
&gt;there are no async ORMs [I challenge this assertion](https://github.com/Fuyukai/asyncqlio)
(Edit before comments): After trying it on 5 or 6 more puzzles across various websites, it's been on every single one. I'm so confused...
Lies: https://github.com/impshum/Drumpf-Troll
You don't need dirty tracking if you don't have an identity map and can express all your CRUD operations as atomic interactions with the database. Obviously, with this approach you work with your `query` or `mutation` directly rather than rely on `__getattr__` and `__setattr__` magic. Clients do that with GraphQL, and there's no reason why the same approach wouldn't work in the backend.
Looks like a geat project! May I ask why you say "Note that this SQL query is not very efficient. An experienced developer would rewrite it to use subqueries." in the first example? I was under the impression that joins where more efficient than subqueries.
At least in Postgres it is usually cheaper to compute an aggregate of a correlated subquery than it is to `GROUP` a large relation produced by a bunch of joins. The example in the post is rather simple, imagine one with more relations, or multiple levels of cardinality indirection.
I prefer the first all the time.
I think using a 3.6 feature (f-strings) in a tutorial for a 2.4 feature (decorators) is going to alienate a decent portion of the audience.
From the anaconda prompt, can you run the command spyder? If not, can you run 'conda install spyder'?
I'd be more than happy to share what I know, so ask away
Anyone new to the language in the past few months would benefit based on that logic. Regardless I disagree
 res = fn(args, kwargs) is missing * before args and ** before kwargs. It's correct in the actual executable code at "In [14]". There's a whole lot more to decorators that's not covered, particularly relating to decorating class methods, or classes as decorators. Even if it's not covered, it would be good to point out that there's more about decorators than is covered in the guide. 
Yeah true. Didn't cover decorating class methods but it's not that different also classes as decorators are simply functions as classes in a way. But I will look more into it. 
If you're learning about one thing, why not learn something else at the same time? However, it's a valid point that the guide doesn't mention anywhere that it's targeting Python 3.6 or later. 
try postgraphile if you like graphql
I suggest Chapter 9 ("Metaprogramming") of the Python Cookbook, 3rd Edition.
looks neat, but the dsl will probably determine success more than anything else.
So, does that mean if I change 20 different attributes it renders an individual UPDATE statement each time? or is there some kind of batching, and if so what triggers it seeing that I changed 20 out of 100 attributes.
How about vs numba?
Please make this a reality. This is the exact same thought I have been having for ~2 months, toying with the idea of a 2d array for the entire range of human hearing, but that is 20k^2 = 400m, so would love to see what approach others with the interest take, especially if you found the time to make it into a blog and push it to github! :) 
Oh I did a similar project about a year ago used bs4 to scrape a bunch of sites then organize by price
How exactly does this work I’ve never really looked into it but it seems super interesting but insanely complicated just from thinking about it.
I recently got an esp8266 never ended up using it on the project I was planning but I’m sure I will use it in the future it’s a really cool little board
I think there's a bit of a misunderstanding here. &gt; but you've referred to there being an ORM No, what I was saying is that EdgeDB makes it easier to do certain things *without* a classical ORM. Things like "save this big profile form a user just sent". Forms map very naturally to an object graph, and we've built entire systems using this approach with very little backend code. I'm *not* saying that an ORM that implements session-based dirty state tracking is suddenly obsolete altogether. It's a useful abstraction for cases where your mutations have to be spread around the codebase. It's entirely possible to build an SQLAlchemy-like ORM for EdgeDB.
Going from an inclusive start index to a non-inclusive end index is exceedingly common in programming generally. I won't go into the specific reasons other people have listed here (they are all true), but I will point out that [Javascript's slice method](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/slice), [Rust's slice syntax](https://doc.rust-lang.org/book/second-edition/ch04-03-slices.html), and [Java's substring method](https://www.javatpoint.com/substring), all work the exact same way.
Your code is pretty impossible to read without the right formatting. You can try putting four spaces in front of each line. Also, this is probably the wrong subreddit for this post. /r/learnpython might be better. Also, you left out the error.
Omg thank you! That took your 5 minutes and me an hour to not find :((((
Dask is highly scalable and efficient Dataframe with 99% same API withPandas http://dask.pydata.org/en/latest/dataframe.html , and yes it is suitable and good alternative for spark in productions
You can pipe gTTS’ output to `say` etc. though. 
In case anyone is wondering, you can instruct a diff program to ignore white space changes. (`git diff -w`, for instance.)
I just went through this myself. From what I gather, `dependency_links` were marked as deprecated, but then a lot of people complained that there was a valid use case for them, so they are now in an un-deprecated limbo. You can have `dependency_links` in your `setup.py`, but `pip` will ignore them unless you pass `--process-dependency-links` to the `install` command. It's annoying, but it seems to be the only way for the time being.
I'm just finding this, but I'm soooo using it!thank u so much 
I'm having similar issues, I think its because piwheels.org is down so its timing out. There is probably a way to use a different source, but I think I am just gonna wait it out till the site is back up
Please don't cross-post your r/learnpython posts here.
I just recently used jinja2 to create templates to feed pandas query and eval functions. You could also create dynamic sql with jinja too.
I like something like this: for x, y in [(x, y) for x in range(10) for y in range(10)]: print(f'{x} x {y} = {p}') over this: for x, y in [(x, y) for x in range(10) for y in range(10)]: print('{x} x {y} = {p}'.format(x=x, y=y, p=p)) There have been tons of times over the past year where either I've made my code much nicer or when I'm forced to use python 3.5 and I wished I could make my code much nicer.
I just switched from PySide to PyQt5. I'm still wondering if I should've switched to something like qt.py or anyqt or something as is common with libraries like Spyder for Qt-binding-agnostic code. I figured going pure PyQt5 would be cleaner and I would learn the new library rather than the quirks of the shims.
Coming from C++, I'd have to do the same thing to make progress on a new codebase.
https://www.kaggle.com/learn/overview Might want to follow the ML/pandas tracks there in addition to whatever course/book you end up choosing. Definitely check these out and Kaggle in general.
I am a huge proponent of the library pandas for Python, and there’s a handy tool pandas.read_html that has worked for my webscraping tasks 90% of the time. Other than that, the libraries beautifulsoup and requests are good, although I don’t have the patience for looking through all the tags to parse, so I try to have pandas search for dataframes wherever it can, and then the data is already structured for me.
I typically use qtpy, which is made by the authors of Spyder. It's the PyQt5 API except you write qtpy instead of PyQt5 and it works in PyQt4/5 and PySide 1/2. The only real difference I've found so far is in the QComboBox, where setCurrentText doesn't exist, so you have to use the index. PySide also requires you to be slightly more correct in your code. I don't know about anyqt.
Depending on what exactly you are going to learn (Python programming, NLP, ML, or all of them at once) you have many ways to tackle this problem. If you are a beginner take a look at my Telegram-chatbot that calculates sentiment scores (polarity score) in your chat and replies with the randomly selected messages of the matching polarity from the database. It uses a third-party API that provides sentiment analysis, but also has a fallback to polyglot NLP package, just in case you hit the limits of your free plan. You will learn from the chatbot's code how to: - build a simple Python Flask application - use task queues (Celery) - make your app talking to Telegram API - respect third-party API's rate limits - use NLP package/service for language detection and sentiment analysis - use exception tracking (Sentry) - write unit-tests Here we go: https://github.com/pilosus/PilosusBot Once you are comfortable with developing applications like this one, you can go further with NLP/ML libraries
Can I have the source code as well?
Code?
The two languages are very different in respect to how they implement objects, so it's hard to simply enumerate the distinctions, because they aren't really parts of the same system. Superficially, you could say that Python has meta-classes and multiple inheritance. But then, of all those languages who have multiple inheritance, there are languages which do something about linearizing the tree of the classes inherited from, and some that don't (like C++), but since Java only allows multiple inheritance in interfaces, it's not defined, strictly speaking, which class it it belongs to. On the other hand, Java type system can be seen as inseparable of its object system, and so you could argue that Java has rules to enforce certain properties of object protocol, s.a. ensuring that methods defined on a class and classes that inherit from it will accept the same arguments. Since compilation semantics are also part of the language in Java, and not left to implementation, like that is in Python, Java has concepts like static/dynamic dispatch, but it doesn't make sense to talk about this kind of distinction in Python. Also, Java objects often play a role similar to packages in Python, and so methods on objects have access modifier s.a. public / private / protected. You can see this as part of object system or not, just as you can argue about types. One more distinction is that the internal structure of Java objects is very uniform, their storage is a struct, and all methods defined on them have the same pattern. To contrast that, even in standard library in Python you can find several types of implementation for internal structure of an object as well as several types of method implementations. C extensions often go far beyond that and have all sorts of weird implementations, especially in terms of storage. This is not the end, this is just an illustration of difficulties of comparing these two languages.
Python's execution model is quite different from Java's. You should read * [Python is not Java](http://dirtsimple.org/2004/12/python-is-not-java.html) * [And Java is not Python either](http://dirtsimple.org/2004/12/java-is-not-python-either.html) Java has a mixed model where some values are objects, and some are machine primitives, "boxed" versus "unboxed" values. All values in Python are objects. Java has no multiple-inheritance, classes are not first-class values, and it encourages a [purely object oriented approach](http://steve-yegge.blogspot.com.au/2006/03/execution-in-kingdom-of-nouns.html). Python has multiple inheritance, metaclasses, classes are first-class values, and it encourages a multi-paradigm approach using whatever mix of OO, procedural and functional programming code works best. Java goes out of its way to have the compiler enforce restrictions on classes and objects (private, protected etc), and then Java programmers spend a lot of time banging their head against those restrictions and looking for ways around them. Python does not: there are some restrictions on built-in classes and objects implemented in C, but in general, pure-Python code does not enforce notions of "private", but leaves it up to naming conventions. E.g. names starting with a leading underscore are considered private.
Oh, I forgot to mention: there's also certain differences in terminology: * What Java calls "members" or "instance variables", Python calls "attributes". * What Java calls static methods, Python calls class methods, and Python's static methods are more like functions. * Although both Java and Python have *precisely* the same parameter passing model, the Java community insists on calling it "pass by reference" (even though it is *nothing* like pass by reference in older languages like Pascal), while the Python community generally uses the less familiar by more accurate terms "pass by object reference" or "pass by object sharing".
Thanks for explaining! While pipenv does not give a direct advantage when packaging for Linux distros I think it still serves a good purpose for local development when using a virtual environment isn't out of reach.
Thanks G!
schemaless (n) - A scheme with tamales 
Explain that to github &amp; co…
The phrasing of your title and post strongly implies that you're arguing against f-strings. Also finding something dumb and being something dumb isn't the same. Of course anyone who isn't dumb would be able to make that distinction…
I really like your ideas! I'm looking forward to giving it a try. I'm a bit disappointed with the DSL though, for several small but aggregating reasons: * Strange := operator seems unnecessary (unless you really want to remind people of Pascal). Why not just use = ? * "required" and "property" are such long keywords, especially with how often they'll be used. Also, defining variable modifiers from the left is a C++/Java practice, which most modern languages avoid. * cardinality := '**' ... There has to be a better construct than that.. * Why can't the enum look more like: enum pr_status -&gt; str = ('Open', 'Closed', 'Merged') * Also, using the -&gt; operator for type is confusing. It's not a return value, or a transition. No one else uses this operator to define types. Hope you'll consider what I'm saying seriously, because it might actually influence the adoption of your tech. (FWIW If you Google "how to write a DSL", you'll find me in the first page)
&gt; Streaming real-time stock prices into Excel It's funny how far some people go with their analysis only to lose their money on gambling.
[Dijkstra](https://en.wikipedia.org/wiki/Edsger_W._Dijkstra) has written a short paper about the subject ([Scan of the original hand-written note](https://www.cs.utexas.edu/users/EWD/ewd08xx/EWD831.PDF), [Transcribed text](https://www.cs.utexas.edu/users/EWD/transcriptions/EWD08xx/EWD831.html)). It's called "Why numbering should start at zero", but covers both start and end index. The convention used in Python slicing is the same as in Dijkstra's conclusion, probably mostly for the same reasons.
Given that `list1` is a list, I assume it's supposed to be `list1[year]`
"For the past month, we ranked nearly 1,000 Python articles to pick the Top 10 stories that can help advance your career (***1% chance***)." Ioi 
How have you confirmed that piwheels is out? And are there other repos such as pypi you can access?
Yeah I'll def share it but it might be a awhile I only have the gui finished.
so there passing processes are basically the same？ 
You'll want to activate the virtualenv in Terminal first. That way you'll have the same execution environment as PyCharm.
To my mind, the biggest difference is that you aren't forced to use OO. Python does what YOU want, with Java you have to do what IT wants. 
By executing virtualenv projectname? I've done that and tried executing the command in the OP. Same error.
Not sure what you mean by "executing virtualenv projectname". You'll either want to make a new virtualenv via Terminal, activate it, then run your script. Or find the virtualenv that PyCharm as made and activate that one. Does that make sense?
"this" pretty much somes it up &gt;&gt;&gt; import this Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren't special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch. Now is better than never. Although never is often better than *right* now. If the implementation is hard to explain, it's a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let's do more of those!
Yes, thank you. I found the virtualenv that PyCharm created and activated that one. The python script executed successfully. However, if I close Terminal, I need to activate the virtualenv every time I want to execute the python script? Can I avoid having to do this and if so, how?
Do you like linux? https://github.com/jstpcs/lnxpcs/blob/master/valentine/valentine-2018-large-02.png?raw=true 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [jstpcs/lnxpcs/.../**valentine-2018-large-02.png?raw=true** (master → ec46aa6)](https://github.com/jstpcs/lnxpcs/blob/ec46aa61dad6f50366b9812b671c699b565091e5/valentine/valentine-2018-large-02.png?raw=true) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dxaj00e.)
Hehe that's a big question with a lot of potential answers. To start with I'd say that it depends on the nature of your script. If your script has no external dependencies other than your default system python (likely 2.7) then no, you don't have to activate a virtualenv every time to run it. In your situation though, it sounds like your script is Python 3+ based. So you _could_ update your system Python to be 3+ and then potentially not have to worry about virtualenvs when running your script. Personally I'd just stick with having a virtualenv for _almost every_ Python project/script/GibsonHacking that you do. It's likely that you'll need 3rd party Python packages at some point and using virtualens will help keep everything nice and contained and will give you a lot of flexibility as you grow more accustomed to Python. Most devs will always have at least one terminal window/session active. And from there they might activate/deactivate umpteed different virtualenvs during a day's work. So the whole activation process shouldn't feel too arduous or time-consuming - just leave your terminal window open afterwards for convenience.
If it were rewritten as subqueries, it would essentially mean the same thing and be executed in the same way. Unless it was written very badly, in which case it might be worse. That whole bit in the blog struck some serious doubt into my mind about the project, and it's definitely not just me. That little bit is at best bullshitting to make themselves sound better and at worst betrays unfamiliarity with the very database system they forked.
D'oh. Realised the virtualenv and script uses python3 so I needed to execute 'python3 PycharmProjects/projectname/scriptname.py'
i always think of it as "pass reference by value" since that’s what’s happening
Python is close to a pure OO language - you pretty much do have to use OO everywhere, even if it's just hidden, since everything is an object.
Will add another notebook with the oldest string formating. 
Neat! 
Start by reading the [Fine Documentation](https://docs.python.org/3/library/os.html). 
/r/learnpython OS module contains os specific functions (file commands, access to shell, etc.)
[This](https://docs.python.org/3.6/library/os.html). Really, you should know standard library. os.path is really useful for filepaths in your app, as it handles different separators (Unix/Windows) and all the relative walking (../.) that you need.
I have also recently started learning python and wish to collaborate with people around the world in creating some projects on the same. I believe Django should be the next step as most of the openings I see asks for both at once. PS: I may be wrong. I find our goals to concur and look forward to hear more from you on this.
We did a terrible job at describing the use case. This is how we use it (Docker Swarm Secrets in production and environment variables in development); https://github.com/sourcelair/sec#docker-swarm-secrets
Would be amazing to get these as laptop lid stickers.
In regards to the other steps question, you can prove you're able to provide value by contributing to open source code: https://www.codetriage.com/ In regards to blackhat python being everything you need to get started in the field of ethical hacking: no. Nothing is ever "everything you need" that will allow you to do what you want. With that said, this book would teach you how to install python, how to work with python, how to create a websocket server, fuzzer, stuff like that. Interesting stuff that you would probably like since you went into this field. Also, I found the book online: [here](https://pythonizame.s3.amazonaws.com/media/Book/black-hat-python/file/af0ef90e-83cf-11e5-964d-04015fb6ba01.pdf) It really wasn't hard to find this book. Legit, I searched "blackhat python" and that was [the third option](https://i.imgur.com/FtkVJR3.png) for me. Anyway, I see I got downvoted a few times, as well. I suspect that's because of how I feel about my ethics in hacking. Bottom line is that the information security field is a field of reaction, so we're always going to be on the losing side. You can try to put as many stop-gaps in place to alleviate as much risk as possible, but people are _always_ going to be coming after your data. And, as you may know, it's not a matter of _if_ they finally get to your data but a matter of _when_. You _cannot_ be the best possible security professional you can be if you do not know everything, and everything includes the ability to hack unethically. Having this power doesn't mean you just exercise it and go hack the Pentagon, either. It means you have the knowledge necessary think, hunt and trap that hacker.
Great! Thank you.
Very helpful. Thanks!
[Here's a talk about PyAutoGUI](https://www.youtube.com/watch?v=dZLyfbSQPXI) that might help you decide if it's right for you.
domain specific language
Domain specific language, in this case op is talking about the query language. 
Well if it means anything, I appreciate your feedback. So I have a maybe 8-12 month plan laid out, let me know what you think. Take a udemy course to get terminology down, practice around on gns3 and VMware to get hands-on fundamentals down, then after feel I have a good grasp on networking from rereading over the udemy course and getting comfortable on gns3, I’ll start learning some pen testing basics (possibly on udemy again) as well as playing around on CTFs and reading the black hat python book...I plan on working towards an OSCP as well after I feel I have a grasp on the pen testing basics. 
Getting involved in open source projects could give you experience and evidence to back that experience up.
Mido seems to work well to handle midis. I will probably push it to github because this is a resume building experiment for me. I have a strong math and Excel background, but I don't have a lot to show my programming experience.
feel free to get the image and order them in the nearest place
You can read all you want, but you need to do things. For example, if you're not strapped for cash, you should buy some [rack mounted servers](https://www.google.com/search?q=rack+mounted+server&amp;oq=rack+mounted+server&amp;aqs=chrome..69i57j0l5.2122j0j7&amp;sourceid=chrome&amp;ie=UTF-8) and create a private network at home. That'll give you a great understanding of networking, moreso than _only_ a book can give you. So be sure to put exercises in your regimen. Idea: create a private network using a hypervisor, have two VMs talk to each other, intercept the message between the two?
I'm sorry if my answer is based on me misunderstanding, I haven't coded against USB before. I know that USB version 2.0 and backwards can only do one direction of communication at a time, maybe something is hanging at the end of the transmission which you could get past by setting timeout lower to debug it. I read up a little here https://github.com/walac/pyusb/blob/master/docs/tutorial.rst#talk-to-me-honey but without testing it myself I can't say much more.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [walac/pyusb/.../**tutorial.rst#talk-to-me-honey** (master → 3ec29ca)](https://github.com/walac/pyusb/blob/3ec29cab9a2703b98513673cec8a1607a38b6cdf/docs/tutorial.rst#talk-to-me-honey) ---- 
gns3, VMware, the udemy pen test course, and CTFs all aren’t reading material, they are all hands on work. Only the black hat python book and the CCNA course for networking would involve extensive reading. 
PyAutoGUI gives you the option to send keyboard and mouse clicks and do screenshots, not much more. Pywinauto tries to let you interact with the element of a windows application, so also works, if the program is not in the foreground. I've played with Pywinauto and am not entirely happy. If you want to automate a complicated GUI program, one that contantly opens and closes windows and message boxes, their approach of locating the part of the program that you want to react to can drive you mad. I had to write a lot of try/catch code to get it to work at all. PyWinGUI alas isn't better for this usecase, but at least very easy to use. On windows 10 you also have the option of getting autohotkey (not python, but its own language) which does a much better job at automating, but has horrible syntax and no data structures...
If you're looking to make a career out of Python you should try and nail down exactly what it is you want to do. The majority of Python work is going to be Data Science and backend Web (from my experience). If you're looking to pursue Data Science work I'd start taking a look at Sci-kit Learn and Keras, you'll find plenty of tutorials online. There's a multitude of businesses looking for candidates with these skills and some background in statistics. If you're going down the backend route, start working with Django and try and get something basic off the ground. Then take a look at some [Public API's](https://github.com/toddmotto/public-apis). It'll show employers you have more than a tutorial-level of understanding. If you're wanting to create desktop applications, then picking up PyQT would be a good choice. I've only rarely seen these roles popping up though. Only my two cents. I worked with Python expecting to build a career around it and ended up using a different set of languages. At the end of the day do what it is you enjoy, you'll find more motivation to solve problems if you look forward to working on your projects!
PEP 20. A true treat
This is super helpful, thank you!
Okay - I mean, you stated "rereading" over the udemy course. It's just that you need the hands-on work. So as long as you have that, you should be Gucci :)
[o]perating [s]ystem We use it because it allows us to interface with the operating system, so you can read files, for example.
This should be a beer: "Pythonhearted Ale"
You are using "using OO" in a different way than I am. I mean from a design POV. You mean in an underlying technology kind of way. I'm not "using C" when I write Python code just because the Python runtime and underlying operating system are written in C.
This will definitely get laser etched and posted somewhere at home or in the office! :) Thanks!
I just don’t understand your problem. You click the link on reddit, it takes you to the docs / change log. The description is right there on that page. One click! Where’s the ‘extra effort’?
Sorry about that, I meant reread over the CCNA networking course. The udemy course for pen testing would be mostly hands on. I’m probably gonna add sys admin training before I start pen testing to this list now as well. Thanks! 
&gt; You are using "using OO" in a different way than I am. I mean from a design POV. What? You are designing your program around OO. Using objects is still OO even if you don't make your own.
I don't think they forked PostGres, more using the foundation to build something on top of it.
Maybe they didn't use a virtual environment.
You’re the same person that made the rust design too, right? These are awesome! Thanks!
&gt; Using non-objects is still non-OO even if you aren't using them directly. You are using them directly? Everything in Python is an object, the only way to not use them is to run an empty file without `site.py` enabled. Take a Hello World program: `print("Hello, world!")` `print` is an function object. `"Hello, world!"` is a string object. 
oh jesus Layer 1: My program, written procedurally. Layer 2: Python itself, composed of objects. Layer 3: Code some layer beneath layer 2, also procedural. You are saying that Layer 1 is OO just because Layer 2 is. But you are saying that Layer 2 is *not* strictly procedural just because Layer 3 is. That's idiotic. Code is OO if that code itself is composed of an object design, not merely if it happens to call some API that is internally OO.
I'd be keen on this as well. Currently working as a junior Python/Django developer
Domain Specific Language Basically, programming languages are DSLs but then you things like the imap protocol which requires its own language to communicate. They're a significant barrier to entry for any new product, thats why some advanced apps like, say Qgis or Arcgis rely on scripting languages like python.
;)
glad that you liked it.
All of my phrasing are questions. How do I strongly imply something with questions? I am arguing about the complex scenarios and what benefits it will have in that cases as others pointed out already. Of course anyone who isn't dumb would be able to make that distinction… 
Just figuring out the uses for this. Yes, they are needlessly complex, but was necessary to try to expose what I was thinking.
Yes! That is a great point. So of couse it has its uses, but it's not for every case.
&gt; given up on continually creating virtual environment for every external package I install from conda or pypi That's not normally how you'd do venvs. You should create a new venv for each "project" or "script" that you create and in that venv you install the packages/dependencies for that project so they are isolated from your other projects.
I started using python way back in 1.5 version. I used and liked the old hello = 'Hello' world = 'world' print('%s, %s!' % (hello, world)) which I liked and understood because I was an experienced C programmer. I didn't like any of the new formatting methods - I thought then to be verbose and clumsy and a bit Java-like. I'm now switching to the 3.6 f-strings as it looks reasonably clean: hello = 'Hello' world = 'world' print(f'{hello}, {world}!') and it directly uses variables without having to plug them into a function and having a matching placeholder somewhere where it is inserted. The problem now is that python is stuck supporting **all** the formatting methods. None of this mess supports the Zen of Python notion.
That's a weird website that doesn't explain their methodology anywhere. I wouldn't look to it for input.
I see vim, but do you have any emacs pictures? :)
You should start your t-shirt company with this designs.
[removed]
Yes, I agree, I initially worked with Pycharm but found that it is using a lot of computer power and resources. Pycharm actually, install packages environments the way you described. Therefore, I preferred jupyter notebook and visual studio code. I am not full time web or desktop application developer. I just create many small projects/scripts testing and applying ideas related to my PhD project. For example today I installed some package to read/ write and manage shape files for subsurface geologic fault systems mapping. I did not bother creating a new whole vir envs for just testing how it might work. I realized after installing that my other plotting codes do not work anymore since some other matplotlib dependencies are changed. I spend a whole 2 hours trying to fix it by uninstalling/reinstalling but nothing worked. Another one hour wasted since I ended up removing whole python miniconda and reinstalling it again!
&gt; so its just 'because Guido van Rossum liked it'. Well, when you agree with [Dijkstra](https://www.cs.utexas.edu/users/EWD/transcriptions/EWD08xx/EWD831.html), it stops being _just_ preference.
You'll probably get better quality learning answers in /r/learnpython You should learn what you need to finish the project first, and loop back to learn more when you can. Regular Expressions are very powerful, and the re module has a lot of nifty things in it. They're well worth the time and effort to learn properly, as is the module, for things like "how do i loop through each occurrance of X", "how do I replace all of X with Y", "how do I find the third X?" for text. If you search google for "[Regex Debugger](https://www.google.com/search?q=regex+debugger)" you'll find very helpful tools for learning and developing regular expressions. One of my favourites is Patterns on MacOS.
there is also a site that can automatically test your connection and save it in reports. [https://testmy.net/](https://testmy.net/)
Good luck with your project :)
No-one has credible statistics for errors caused by 0 vs 1 indexing. Dijstra expressed a preference, and people copied it because he was famous.
exactly - if it's based on google traffic or amount of questions on stackoverflow then it doesn't really indicate popularity but how much activity given project gets on source website.
If it were me, I'd have a single venv for the phd project and record the packages in a requirements.txt file. In the scenario you mentioned, the fix would have been: 1. remove the package out of requirements.txt 2. `wipeenv` 3. `pip install -r requirements.txt` and you'd be ready to go. Less than 60 seconds.
Unrelated but if you go to twitter, you'll see that Trump is very popular. Point is some metrics use to rank stuff are flawed.
How are we supposed to know without the code around it? 
'Popularity' gauged by search engine requests or whatever probably isn't terribly useful info. Harvard has some good open courseware with Flask, by the way. I personally prefer the minimal set up of Flask, and I like the design using decorators for "routes", adding subdomains and such. 
Your lock failed for some reason. The data may already be locked, maybe you forgot to free it somewhere, or maybe your locking it multiple times in a recursive algorithm. If you're trying to lock but it might fail, you should use pthread_mutex_trylock, which will return an integer giving you an error code if it fails and 0 otherwise.
&gt; in a way that's incredibly confusing Sorry about that. The example shown in the post is trivial, and, in that particular case a correlated subquery would indeed be similar to simply grouping the joined relations. The real context is this: once you start increasing the depth of your relation traversal ("friends-of-friends"), and adding more relations into the query, aggregating projections separately is actually superior when you factor in the overhead doing the nested grouping on the client side. That is also why `MULTISET` is a thing in Oracle.
Read the official documentation rather than watching videos. You can scan and search videos far more quickly than you can view a video. 
Kind of hard for us to tell when they haven't released any source code, really.
No it's still better, just you can't have it. Eg. I have a fiat car, tesla brings model y, model y is a better car to your model of fiat. Model y is also a better car to my own fiat, it's just I can't have model y. Model S Model 3 Model X Model Y :) 
But... Python is named after Monty Python not after snake *confused*
At what tier are we imagining these rows to be aggregated? Where are these savings, exactly? Is the improvement in performing some kind of forced lateral join, CTE-based fencing, or multiple backend queries (plan, execute, plan, execute) from the main procedure? It's true that the stats used for planning queries that greatly magnify cardinality variances like those sorts of graph queries often become very bad very quickly, but it's also true that rewriting your query with more subqueries does little to nothing to fence those optimizations in postgres.
Flask and Django are often used differently and at different scales. Really big projects are often done with Django, smaller ones with Flask. This isn't a hard rule, but it seems to be what I've experienced. Naturally there are many more smaller projects than bigger ones so naturally that skews things in favour of Flask. Lastly, many of these rankings things are absolutely stupid. Use the tool best suited for your use case taking into consideration what knowledge and skills you have. Ignore any ranking by Github mentions, Google popularity or whatever. 
My bad. Added code link in thread
&gt; At what tier are we imagining these rows to be aggregated? Arbitrary depth as dictated by the query. SELECT User { friends: { interests: { ... } } } &gt; Where are these savings, exactly? Is the improvement in performing some kind of forced lateral join, CTE-based fencing Yes and yes. The main savings come from the fact that you get a data shape that is ready to be consumed by the client and you don't have to recompose the shape once you've fetched your rows.
I updated the question with the code that I used. Do you think there's anywhere in the code that might cause this problem? 
Is there a reason you don't just want to use serial communication? Pyserial is a great library with great examples and plenty of people use it with Arduino, esp8266s and whatever other boards. Synchronising is typically not something you have to worry about using this approach. 
Django is still pretty popular. And don't worry, in your carreer as a developer you will learn a lot of other frameworks other than django and most likely also a bunch of other programming languages besides python.
"What should I do at this stage of life at the age of 15?" Don't overthink for a start! ;)
This describes how you can do it with install_requires and dependency_links. https://stackoverflow.com/questions/26061610/pip-install-dependency-links I've never done it that way, but I have used buildout to to do it. http://www.buildout.org/en/latest/ 
Definitely, I would read all of the documentation about the module unless it's a hundred pages worth. It depends what you mean by learn. Don't make flashcards and use memorization techniques, or really sit down with the docs to read in-depth. I would definitely read it though, at least reading the parts that tell you *what* it can do. That will be something you can add to your back of the mind toolbox -- on one level, you might actually remember certain capabilities, which you will then know you can revisit the docs for to see how to implement them; on another level you'll begin to realize how in-depth Python modules typically are, so you can get an idea of what to expect you might find in other modules in the future. This is important to nudge you to find things that Python has already solved for you, instead of trying to solve them yourself.
For a hitchhikers guide to modules, you could check out [Python Module of the Week](https://pymotw.com/3/os/index.html)
"The time of the childhood is over... the age of the job has begun"
I know it sounds funny but whenever I think such type of questions I really get scared sometimes
Oh! Thanks I didn't knew about it 😃
please open a ticket on github and I will try.
Woot thanks!
I started with web scraping financial data, but you could do same thing with sports, video game stats, etc. Create a python script that downloads a html file, extracts a table to csv. Then, try using something like Flask to load that csv file and load it into a locally hosted server using bootstrap and a little javascript.
Thanks bro actually I made my own portfolio website and I am now learning the login side of Django
Ya I have made my own portfolio website made by django and I am now learning the login part of django, Thanks
You'd be right, but I'm not trying to do the guy's homework for him.
Lol 😂
Awesome project!!!
Just to understand the capability/functionality, yes. Enough so you could explain what the features of the module are on a high level, briefly. Don't learn or study how you'd actually type in the code, etc; as you said that won't be useful to you unless you need to use it. But you'd want to briefly review what it is capable of, so you might know to look it up in the future when you recognize you have a problem that can be solved by it.
Great point about a web portal for organizations in need not existing. Perhaps we should build one?
Woah thanks a lot man! I need to learn how to read the docs,They looked so big so I usually never read them But I'm gonna try again
See the new python developers survey from PSF (google). Django used more than Flask last year. 
React/Vue/Angular + NoSQL databases means that Django template engine and it's fantastic ORM are not as useful as it was before. That's where Flask shines, building heavily customized APIs.
this repo is amazing! thanks
Requests allows you to configure a proxy through an environment variable, so you don't even have to touch any code! I don't know how BrowserBob works, but presumably it provides you with a host/port to connect to: $ export HTTP_PROXY="http://10.10.1.10:3128" $ export HTTPS_PROXY="http://10.10.1.10:1080" $ python &gt;&gt;&gt; import requests &gt;&gt;&gt; requests.get('http://example.org') [http://docs.python\-requests.org/en/master/user/advanced/#proxies](http://docs.python-requests.org/en/master/user/advanced/#proxies)
Can I ask you why it matters?
Right, but how do you get Linus' key? In particular, how do you check that the public key you're getting really belongs to Linus Torvalds, and not an impostor? And you don't just need to do this for one package author - even if you just `pip install` one package, you need to verify everything that it depends on as well. The obvious way to do it is for PyPI to list public keys which are allowed to sign each package. But if someone could hack PyPI to serve a malicious package, they could also add their public key to the list for that package. So it's extra complexity, but no more security.
Whats this referencrle to?
I already have a full time programming gig though, not looking to make any money. It'd be nice to just volunteer to help, with the bonus of refining my skills.
This might certainly be worth looking into. Could service simple websites, internal applications, server infrastructure, etc.
Can you modify the head a bit. At first glance I thought it was a t-rex 😁 Other than that...looks good.
UNHAND ME PRIEST!
the right tool for the job...
Also, the snake in the picture isn't a python.
I do it for fun. there are links to tees for those who'd like to support the project but most people make shirts themselves locally to save on delivery.
Because of how assymetric key encryption works. When a public key is shared it can be verified by anyone but only signed by the provate key holder.
And Python has no Method overloading which means no alternate constructors.
Good point, thx
Although this can be implemented mostly with keyword or optional arguments.
Feel free to PM any time if you want to try to get something going. I have been in the same position as you, and it is extremely difficult to find a way to provide a couple hours of volunteer programming for people who really need it. I live in socal, and there are some local groups that do these type of things, but it would be great if charities could get self-service tech help to some extent.
If you just try to learn everything up front all the time, you'll go too slowly. If you do nothing but copy from examples and never learn anything, you'll never understand anything. So it's about striking a balance. When I encounter something over and over I think, boy, I'd better dig and learn about this in detail. But I'm not beneath just copying something from an example, if I don't think I need to know more.
can you use this on a pc?
Print finally becoming a function
But it's a snake *shudders*
This event looked awesome but wasn’t it like a thousand dollars or something completely unreasonable
Classmethods work really well for this. Like alternate constructors
Async I/O being first class. 
You're right, apparently you don't understand: It comes down to having respect for the time and resources of the users. There are a lot more users than there are creators, and the creator needs to think about all the man\-hours that he will waste if he doesn't keep that in mind. \(Btw, that's also why TL;DR should be at the TOP of lengthy posts, it's called an "executive summary" elsewhere.\) What it should be: In the reddit post, a short description of what the damn thing does, followed by a link. What it is: The reader clicks on the reddit post, only to find a link for the incomprehensible name listed. \(Really, who thought of using Cerberus as a name? Does that say "data validation library" to you?\) So, the reader clicks the link. And what do they get? Well, HUNDREDS of lines of text for the changelog \(Like the idiots who put the changelog in the header of a file, they are just ensuring that anyone who has to deal with this thing will be instantly annoyed instead of getting to anything useful, quickly\), with a tiny " Cerberus is a lightweight and extensible data validation library for Python" blurb on the left hand side. Gee thanks, poster. All of the users clicking this thing, and you couldn't have put that in the @#$&amp;#37;\^ REDDIT post?!!! WHY?????
A 'syncio! a go go!
Now you can finally divide numbers properly. `3/2 == 1.5`, yay! 
it behaves explicitly similar to every other function, instead of being this random thing that acts like a function but doesn't use any of the syntax associated with functions. 
You can use scp usn@some_comp: echo ‘send signal!’ &gt; file.txt To create a file on another computer with just ‘send signal!’ Inside it. Then on the local computer you can check the file periodically. Ofc checking the file (ls) and the scp command can be used in Python with the os module (os.cmd or os.sys I cant remember)
Yeah.. I just don't find writing these parentheses comforting. :D
[removed]
[See PEP 1305](https://www.python.org/dev/peps/pep-3105/)
3 halves.. Are you mad?
What? Why?
I love, love, love that ``str`` is always unicode. It alone is reason enough to upgrade. Type hints for larger code, and for code introspection when using Pycharm. I like the dict combining syntax introduced in 3.5 (``{**dict_a, **dict_b}``). f-string. Love them. Insertion-ordered dicts. Surprisingly useful. NamedTuple (since 3.6), though will switch to dataclasses in the future. I like keyword-only arguments a lot: they force your function calls to be more explicit. The more flexible tupel unpacking, There's probably more.
Good starting point for Django ? 
there are worse things. 
http://pyautogui.readthedocs.io/en/latest/ I think this is more along the lines of what you'd want to use. 
type annotations, hands down.
Sure thing.
+1 - having spent a lot of time in a large codebase polluted by decorators written by people who don't understand descriptors and just tack 'self' on and call it a day this should have a mention. that situation is at least less muddled in 3.
Stick with Django or pretty much anything else. The skills you are learning will translate. 
I'm still browsing the repo, but so far, you've got some cool stuff there, OP. \\#NeedMorePropagandaPosters
Those are all ways you can help without being a full time gig. 
Still not the same. Sometimes you want to implement completely different logic for a the same method or ctor. But now you have to have an absurd amount of keywords and optional arguments... I'm just pointing out something that Java has that Python doesn't. I consider it one of Python's few flaws.
But... this has almost nothing to do with the programming language...
...what?
Yeah, type hinting, ftw! I use this every day.
how does mutability have anything to do with passing reference values in python?
I have working mouse input in DirectInput in my AI framework. Maybe you'll find what you need in here: [https://github.com/SerpentAI/SerpentAI/blob/dev/serpent/input_controllers/native_win32_input_controller.py](https://github.com/SerpentAI/SerpentAI/blob/dev/serpent/input_controllers/native_win32_input_controller.py)
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [SerpentAI/SerpentAI/.../**native_win32_input_controller.py** (dev → 0ccccb0)](https://github.com/SerpentAI/SerpentAI/blob/0ccccb079e69b6d36dd691b8b4566cdb758f4eb1/serpent/input_controllers/native_win32_input_controller.py) ---- 
your work is amazing. Thank you for effort. Definitely will print some of these and share with my friends.
Correct me if i'm wrong, but I think you misunderstood /u/TopicStrong. They meant that OperationCode's mission is to help veterans transition into tech roles. They suggested that you could help them to perform that goal, in X Y Z ways :)
Hear hear*
You could pickle the data then transfer it, and unpickle it. This works for all python data types. So you could then just send over a tuple. You are in a world of pain at the moment dealing with byte orders.
This is exactly what I was looking for! Thank you so much! Did you happen to find any good documentation/references when you wrote this?
&gt; Using objects is still OO even if you don't make your own. You can write Python code in a procedural/functional paradigm if you want. Occasionally having to use a builtin object's method does not suddenly change your program's entire paradigm to be object _oriented_, just as much as using a pure function does not make any Java program functional.
Spacing and indentation. Aka the `IndentationError`s, so you don't mix up your spaces and tabs.
Pretty sure if it's the pub key posted to a git or a Twitter or whatever else it's trustable on a practical level 
Look at the struct module in the standard library. That does exactly what you want including dealing with byteorder issues.
White label, with black logo, and at the bottom have the text, print('Simple but powerful") 
It's as if someone wanted to visually represent C, and draw a picture of the ocean.
Any plans for RedHat ones?
Love the analogies!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Some of my first open source work was testing and helping with the initial PySide2. I'm super happy to see it progress this far!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
No more old vs new style classes. Everything is an object.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Apart from the license, does it have any advantages over PyQt5?
Build a portal, and then you are still looking for np clients! Suggest you make a list of ten nps in your area. Look at their websites to guage their level of tech sophistication, send a personal email to the president/ceo about how you can help; hope to get one to try you out. Don’t get discouraged, they are always busy fighting daily panics, fundraising, etc. Also don’t approach them as a white knight. Be humble. Volunteers aren’t the most reliable employees so you might find a np with an opening. There is actually a large ecosystem of np-specific CMS and CRM software used by even small nps, stuff you could learn. Vast majority of nps are tiny, one or two people with no budget just a passion. For example the 1000s of pet rescues. Pick a niche, share their passion, give them time to trust you. Don’t be surprised if they also ask you to fix the printer!
Support by the Qt Company. It's been a while since I've seen the code so I probably shouldn't comment on technical differences, but when I was working on it last it didn't particularly have advantages over PyQt.
Wow, they've already caught up to Python 3.6. That's awesome.
I would recommend you survey a number of presentations from the PyCon and PyData conferences. BTW, programming changes quickly; be prepared to adapt. see http://pyvideo.org/, http://pyvideo.org/tag/tutorial/ 
III.VI
Cool, love qt, having support from the company is a big plus, wonder if it will idiot proof (download Qt creator, code, deploy)
either as a class or a dictionary
/r/learnpython 
This is fantastic! Hopefully it will be simple to get started with, because even though I have been doing Python development for decades now, I still have no idea how to get started with Qt and what the best way to package for distribution is. Does anyone know of a good tutorial? I'd love to try this right away.
I'm a big fan of wxPython. Can someone familiar with both that and Qt explain any advantages one has over the other?
This looked good, but I couldn't make it. Does anyone know if the videos will ve available from the conference?
And some pills are just harder to swallow for some people. The red ones especially. 
https://opensource.com/article/17/4/pyqt-versus-wxpython
Thanks mate! 
Qt is a major and well-supported cross-platform multi-language GUI framework. A lot more people are working on it and so it's very stable and has many features. On the other hand, it is more complicated to work with and would probably be considered less Pythonic.
Yes, decoding which constructor to call would be hard past just number of args.
No prob. FWIW in my limited experience, QT is probably a better and more powerful toolkit, but wx is more pythonic.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [justanr/objtoolz/.../**singledispatch.py** (master → 68aee9a)](https://github.com/justanr/objtoolz/blob/68aee9a932f8bbf1b120a5da200368feec5258c5/objtoolz/descriptors/singledispatch.py) ---- 
How on earth can a C++ framework be more *pythonic* than another? 
Great news. Had Pyside been further along 2 years ago when I decided to abandon Qt5 for Kivy, well you know how that goes. Qt5's QML language made me a great believer in the declarative programming model for GUI's. I just hated c++. So Qt4 and PyQt4 weren't even a consideration. PyQT4 was not a viable alternative for me at the time as it was just c++ under the hood as far as I was concerned. Plus one needed to understand c++ because that was its documentation. And, did I say no QML? Qt5 recently announced that it would support running within a frame buffer on devices that didn't have X11 or another windowing software. I wonder if Qt for python will follow in these foot steps? 
microservices are the new hot thing of the month, and flask shines there
Direct link to 3.6 wheel built on April 13: https://download.qt.io/snapshots/ci/pyside/5.11/web_pyside_pyside-setup_1521750696226/pyside2/PySide2-5.11.0a1-5.11.0-cp36-cp36m-linux_x86_64.whl
The first decent one I saw was on zetcode (don’t have a link handy, but that’s part of the url).
Cs50 I think, it's on YouTube, you can find it. Basically the framework lets you instantiate an object like this from flask import Flask app = Flask(__name__) The methods included for that class allow you to do "routes", meaning you could do *mywebsite.com/myroute* like @app.route('/') def index(): return 'Regular front page for MyWebsite' @app.route('/myroute') def hello(): return 'this one is my route or whatever' Here's a link to the docs and such. http://flask.pocoo.org/docs/0.12/quickstart/
I haven't used Qt with Python but I have used wxPython. Unlike tkinter and Qt, wx actually uses the native widgets on Windows. Plus, it works on Mac and GTK. That's exactly what I wanted. None of these kits are perfect for every situation, but if you're already using wxPython and you don't need the extensive features of Qt (the stuff *other* than window kits), then I see no reason to switch.
I derped a little there
I couldn't make it through the cringey soyboy analogies. Is there anything of substance in this article?
I develop automation tool suites in Python and Golang that are containeized in Dockerusomg ansinle for deployment. Example project: Create a highly scalable and managed method to ssh into endpoints. Solution: Microservice #1: Authentication Microservice #2: Request Microservice #3: Receive Microservice #4: Initialization Microservice #5: Logging Each one of these microservices are built abstract enough to be used anywhere an Initialization, authentication... Would be valuable. They all live inside containers which makes them easy to deploy and allow for CI/CD. In the right context they become a secure method to access servers monitor user input and highly scalable. If a bastion is overworked you can scale the number of services with a simple Ansible playbook.
Making True/False not just 1 or 0.
I'm not trying to be pedantic here, but isn't every FOSS project a nonprofit organization in some sense? Python and it's amazing ecosystem have given me a career... for free. They provide a massive amount of value to the world by creating and maintaining tools that others can use for no charge. It's a wonderful service. I guess my point is, if your goal is to use your coding skills to provide value to humanity for free, submit a pull request to pandas/sklearn/django/your_fav_proj. You'll be helping me and millions of other people.
small is better
What exactly do you want from client side window decorations that it doesn't do currently?
Also here: https://steemit.com/cryptocurrency/@charlieb/vbqaen2u
It has. The real difference now is that they are declaring it relatively complete, stable, and supported.
Cool, but I have the feeling it's coming since months. Such teaser is mostly annoying. I would rather hear that it is already there, usable and with good documentation.
I thought we already had PyQt? What does offer that's new?
Not to manually implement it myself. Something like the qt headerbar would be nice.
I love the star wars analogy 
The problem work something like that is that it is out of place pretty much everywhere except on the gnome desktop, so there is like demand for it. It seems like an easy enough thing to implement as a library though.
I was nice to see that poetry installs fine with [pipsi](https://github.com/mitsuhiko/pipsi). However, when I tried to *add* `gevent`, I get an error. [SolverProblemError] Unable to satisfy the following requirements: - "gevent (1.3b1)" required by "pyproject.toml" This is in a virtualenv I created with [pew](https://github.com/berdario/pew). If I use `pip`, it correctly grabs, and successfully installs, `gevent` 1.2.2, the latest stable release. `pip install gevent==1.3b1` works fine too. I want to like this project, but still can't seem to use it for packages fundamental to my projects.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://github.com/berdario/pew) - Previous text "pew" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
PySide and PyQt (both using Qt 4) have both been available, and been excellent, for years. Nice to hear that Qt 5 is coming though.
PyQt5 is based on at least 17 years of maintenance. PySide is relatively new. If license is not an issue for you, stick with PyQt. They certainly deserve it. Problem is, license is a problem for developers used to using things for free. Like me :) &lt;/tongue-in-cheek&gt;
FTR incase anyone is confused, PyQt5 has existed for quite some time, so its not exactly new that you can use Qt5 with python, this is just the official extension of PySide to Qt5
PySide has been around since 2010.
&gt; Sometimes you want to implement completely different logic for a the same method or ctor. Why not to name them differently though? Chances are they are doing something different! def get_x_from_y() def get_x_from_z() ?
They state themselves it is not yet stable, so it is not yet there. Yes, we can see the development since over a year. PySide is Qt4 and is deprecated. The above is my only problem. It's there but at the same time not really. Don't get me wrong, I would love to play and use it once it is stable.
Code a text based adventure game?
"Trustable on a practical level" is what we already have today by using HTTPS to talk to PyPI :-). The point of adding per-package signatures would be to go beyond that.
Those wildcard imports make me sad. 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [learnbyexample/scripting_course/.../**Python_curated_resources.md#further-reading** (master → 44b288f)](https://github.com/learnbyexample/scripting_course/blob/44b288f74a99a4fb9e22814455303a69d646fa4f/Python_curated_resources.md#further-reading) * [learnbyexample/curated_resources/.../**CS_and_Programming.md#guides** (master → 48274cf)](https://github.com/learnbyexample/curated_resources/blob/48274cfe37e6d12fac33c25d2c04a8904ee08e9e/programming/CS_and_Programming.md#guides) ---- 
Figure it what you want to use python for and do a project for it ASAP
Right, so your solution is to depend on Github/Twitter to act as a centralised authority for trusted keys? That's certainly one solution (it's roughly what Keybase does, for instance), but there are plenty of people who would take issue with it, for a variety of reasons. And you're implicitly relying on the SSL certificate system to verify that the key you get has not been replaced on the way from Github/Twitter. Also, you still need an automatic way of finding which Github/Twitter accounts are authorised to sign each package. Manually finding the key works for one package built by someone as famous as Linus, but not for 20 packages built by 17 different people you've never heard of.
Good point.
Qt has some capabilities wx doesn't have. Like with Kivy, you are able with Qt to describe the layout with a meta language, which makes you life easier in the case you want something like a window with widgets scaling with the screen resolution. 
At the blog post for example: Qt for Python will be released as a Technology Preview shortly after the Qt 5.11 release as that’s the official Qt version of the first Qt for Python release. We know that many of you are eager to get started – check out the latest snapshots: http://download.qt.io/snapshots/ci/pyside or contact us to kickstart your development project now. Only snapshots are available.
Um, Qt is cross-platform, so it works on Mac and Linux. I’ve used PyQt/PySide on Mac with precisely zero problems.
To be honest, I'd say both projects feel about the same in regards to development interest and activity. I've filed bug reports with both projects and there's generally almost no activity or urgency in fixing them. That being said, at least with PyQt you know who's leading the development. It's never really been clear who was leading PySide development. I'm fairly certain the only reason PySide2 exists at all is because a few VFX software companies paid a single dude to work on the port for like a year until Qt finally decided to take over development.
I think you should put this in https://www.reddit.com/r/Python/comments/8bx6md/rpython_official_job_board/
Ah yes, I misunderstood. Thats what I get for replying quickly while on the go! Infrastructure work and python automation tooling would be perfect for me, I will look further into this :)
Ah, sorry! So I reply to that thread? 
Location: anywhere! We need an experienced Python programmer to help us create a script which continously queries the Twitter, Facebook and LinkedIn APIs to gather post statistics (reach, engagement) for all posts scheduled via our platform (https://www.chooseholly.com) This is NOT a scraper - we have legitimate, approved apps on all the platforms and have approved access to each user's posts via their own access tokens. The solution you provide will need to be able to scale to an extremely large volume of posts, updated hourly. Please email me on scott@chooseholly.com with a brief introduction about your experience and optionally, a description of how you would tackle this problem. 
Not pedantic at all, this thought actually crossed my mind while I was making this post! I would like to contribute to something that has a direct impact on humanitarian efforts, though, and I'm certain there are nonprofits out there that need help but cant afford it/dont know how to find it. Also, it'd be nice to contribute tech experience in ways outside of coding too, like setting up server infrastructure, automating processes, etc.
3105
There there.
Ha fixing the printer, the 10 minute project that takes 3 hours and breaks again the next day :P Thanks for your input, this is good advice. I didnt even consider the smaller organizations that could use a little help with a variety of tech tasks, bet I could find more than a few in my city. 
I've started to use it recently, but the fact that it inspects class attributes by default makes it hard to get to a zero error baseline on an existing code base.
Oh boy oh boy oh boy. &lt;rubs hands&gt;
They're they're*
The more I think about it, the more I think this is a good idea. Wondering if it would be better to create a site with Organization profiles where they could list in their description immediate tasks and ongoing projects they need help with, or a job board style site for listing one off tasks they need completed. Or provide both options
That might be more of a PyQt thing than a Qt thing. Qt is a C++ framework, and PyQt simply took all the C++ classes from Qt and made them accessible from Python. That's why you get QStrings instead of a Python `str`, for example. One of the goals of PySide was to integrate better with the Python environment, so they've replaced those QStrings with Python strings. I'm more familiar with PyQt than with PySide, but they might have done the same thing with other types as well.
&gt; Plus one needed to understand c++ because that was its documentation I always use the documentation [here](http://pyqt.sourceforge.net/Docs/PyQt4/classes.html). It's nowhere near perfect (plenty C++-isms remain) but it's not that bad.
Licenses.
What licenses? It is a wrapper. You need to buy Qt itself only, of course if you really need it
Thanks, I will give you our bid next week. 
They're not that dangerous, since every name has a Q prefix. Not doing that can make your life harder, since the docs aren't great at mentioning what comes from where.
Except PyQt5 is GPL-only and requires a costly license if you don't want to publish your code alongside your product. PySide is LGPL.
Indeed... thank you! 
concurrent.futures is pretty nice. 
Whether weather?
Wheather. *** ^(Bleep-bloop, I'm a bot. This )^[portmanteau](https://en.wikipedia.org/wiki/Portmanteau) ^( was created from the phrase 'Whether weather?'. To learn more about me, check out this )^[FAQ](https://www.reddit.com/78ilq0).
That's not true anymore with Python 3 and PyQt 5
Really? I've been stuck with Python 2.7 and PyQt4 so I've been out of the loop a little. That's good to hear.
Your editor can help. Look how similar the wx and qt code is! 
I'm not experienced with development, so I would like to ask about licensing. I always hear Qt has more restrictive license than wxPython, but what does that mean? Can you sell stuff that uses Qt?
Ah cool, thank you. 
❤️❤️❤️ oh hi there proper windowed apps ❤️❤️❤️ 
&gt;NamedTuple (since 3.6), Have namedtuples been there a lot longer than that? Or is there a new version? &gt;I like keyword-only arguments a lot Definitely agree with this one.
No more def indent(s): if s: # four spaces print s # single tab being valid if you have tabs set to appear as four spaces.
Yes, mine is for PyQt4. You can tell because it has a QString entry whereas yours doesn't. They probably both started out as a copy of the Qt docs, with some reworking for Python. That's why the descriptions are the same. Anyway, yay for ~~PySide~~ Qt for Python!
IIRC QString went away a while ago but there's still QSize, and some other QT classes that a python programmer would probably never dream of in PySide.
nope. https://www.riverbankcomputing.com/commercial/license-faq PyQt is GPL + Commercial https://www1.qt.io/licensing/ Qt for Python is LGPL + Commercial http://www.differencebetween.net/miscellaneous/difference-between-gpl-and-lgpl/
I hope they work on the docs. They're abysmal so far; redirecting to the C++ docs isn't acceptable imo.
It's not about commercial software or making a profit. It's a matter of whether what you're selling is Free Software AKA open source. This is a common misconception so I urge people to try and not loose with terminology.
All the widgets (99% of what you use) are in QWidgets in pyqt5. QCore is for very fine control like size policies. QGui is for signals/slots mainly. Seriously, an IDE helps a lot.
The signal/slot approach is very pythonic. Wx's event system is weird. The CSS things are a bit hacky, but I can live with that.
What I meant was, it allows me to use native Windows controls, which is what I cared about, and as a bonus it us cross-platform. I know Qt is also cross platform. 
"""Highlights of the new release: Python 2.6 is no longer supported - if you need pip on Python 2.6, you should stay on pip 9, which is the last version to support Python 2.6. Support for PEP 518, which allows projects to specify what packages they require in order to build from source. (PEP 518 support is currently limited, with full support coming in future versions - see the documentation for details). Significant improvements in Unicode handling for non-ASCII locales on Windows. A new "pip config" command. The default upgrade strategy has become "only-if-needed" Many bug fixes and minor improvements.""" 
It's nearly very nice. The way callbacks work is dumb.
Sane division. I like pathlib too.
This is good news! Last time I had a look at Pyside2 it was still in beta. The fact that Qt is officially supporting it makes it that much better. An official Golang Qt extension/port would be awesome as well, though i doubt thats happening anytime soon.
Note that this breaks the `pip3` command on Debian (so Ubuntu, too). Normal `pip` works though (after you upgrade, not before). (https://github.com/pypa/pip/issues/5221)
Will do, also your work is amazing!
You just pass it in. Functions work too.
Wonder how difficult it'll be too migrate a pyqt project over
I still can't use the re module in python despite knowing regular expressions and have 12 years of python experience and having wrote f-strings 10 years ago with it. I can't use it at all because I forgot. I can consistently speed up a program by 1000x with numpy, but I still can't use tensordot again, even though I sped up a code using the function because I forget. You don't need to know everything, not by a long shot. You should read through the function/class list occasionally and the release notes, but that's really it. Just go code. The things you remember are probably useful.
conda &gt; pip
I'm a big conda user but disagree with this. They both have their uses. In fact there are a lot of niche packages not in conda.
agreed, but this still has nothing to do with passing mechanisms. this entire example deals with what happens after the object has been passed. 
Indeed not sure why you were voted down. The GPL requires you provide source code to anyone that gets the program. You can indeed sell the software under GPL as long as the person that buys it gets the source too. A "commercial license" really means you want to avoid giving people the source code of your finished product.
What's your experience with Phoenix?
Jose Portilla on Udemy has really good courses for python and data science.
This looks great! I suck at PyGame, so this may help
Django is opinionated, and includes tons of tools to do all kinds of stuff. Flask only includes the minimum to serve a webpage. This means that if you want to do x, in django is pretty clear what you have to do, in flask you have to implement it yourself. Take for example talking to databases, in django almost everyone uses the built orm. In flask you can use flask-sqlalchemy, flask-marshmallow, or skip the orm and go full t-sql. It's not that django doesn't enable those options, it's that if you're going for those options flask is the better option.
it's quite good. using it in my last project.
That makes sense to me! I hope you find something that matches what you're looking for. You should do a write-up about the experience once you've been doing it for a while. 
pipenv &gt; pip
It just seems like a mark against QT if that usage is the standard convention as explicit imports are generally very much preferred. On my initial read that gave me the impression that you were having to cut corners with QT to get them to appear closer. 
pip2/pip3 are hell-bent on breaking each other. In order to restore ‘pip’ to point to ‘pip2’ I had to delete one of the two ‘pip’ binaries (which install on different sys paths between the two versions)
&gt; Have namedtuples been there a lot longer than that? Or is there a new version? There has always been ``collections.namedtuple``, but I'm refering to ``typing.NamedTuple`` (notice the upper cases). It allows you to do (since 3.6.1): from typing import NamedTuple class Student(NamedTuple): first_name: str last_name: str is_enrolled: bool=False It also allows subclassing, which the old ``namedtuple`` did not (or did badly, I think it was possible, just very ugly). So it's a nice improvement, but the upcoming dataclasses will be even better for many use cases.
Even if not dangerous for name collision, I'd want the imports called out for easier referencing. The fact that the wx code is near equivalent with a single normal import kind of reinforces the "less pythonic" part about QT. If QT fit the python model here it would use more generic names with the understanding that python would use an import prefix or do an explicit from import when appropriate. 
If you want up-to-date pip on Debian, always install it using `--user` and add `~/.local/bin` to your `PATH`.
It always breaks my brain trying to work python3/pip3 on distros that default to python2. I feel so much happier working on Arch where python3 has been the default for so long, and my go to interpreter is always python3.
You are right, it has indeed nothing to do with the passing mechanisms. But not knowing this difference, could make someone make wrong assumptions about the passing mechanisms. 
in python everything is a object, so the only thing you can pass to a function is an actual object
Link to PEP 518: https://www.python.org/dev/peps/pep-0518/ The main gist of this PEP is that it adds a new config file that is supposed to supercede the setup.cfg file with greater flexibility and more options. The motivating use case that it is very difficult to specify dependencies for building a package, and doing so in such a way that alternatives to setuptools can access them too. It uses the TOML format, which in my experience is kind of like INI but sane and useful. If you're worried about having to learn a new file format, TOML is very simple, easy to learn, and works very well in the Rust community for their project description files. I didn't like it at first, but I actually prefer it over YAML these days since it is so darn easy to use. 
Thanks for the detailed review :-). I will put a statement in the book page that the reader should a reasonable working knowledge data structures and algorithms to read the book. I am glad you liked the puzzle section :-). There is also a section on Python programming language questions. I hope you like it as well. 
Looks like the tesseract is closing in Python 2. About time. 
Oh man that's tasty.
I still don't understand why I should have to handle the event loop myself. Isn't that the point of threading, the GIL etc - that python handles that shit so I don't have to?
Make sure you know about different paradigms that Python can be used for. Maybe brush up on some object orientated things. Apart from that, no different to most interviews, make sure you're able to answer LeetCode style questions, know about different data structures etc. Searching/Sorting may not be as important since Python already has very efficient included functions, but can't hurt to look over.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [AndydeCleyre/dotfiles/.../**.python.zshrc** (master → cb99348)](https://github.com/AndydeCleyre/dotfiles/blob/cb993480135f4b3f3456b88c2c94a2528e67c246/.python.zshrc) ---- 
I hope this library will become mature enough to be the standard Python GUI framework, something the community has been missing for a long time!
Right on. I know this sounds petty, but I really need my `snake_case `, for one.
I suggest you to look at Curses for python: https://docs.python.org/3/howto/curses.html It's specifically designed to create command line interfaces
I always enjoy using [wrapt](https://github.com/GrahamDumpleton/wrapt).
&gt; The default upgrade strategy has become "only-if-needed" Is that as big a deal as it sounds? Does "pip install -U" no longer upgrade everything, only upgrades versions if explicitly required?
I use both. Conda is nice for dealing with c dependencies. Pip is nice for getting the latest version of a package without looking it unto on conda-forge. 
Just make a virtualenv to work on any project, and specify the python you want. Either python3 -m venv new_project or virtualenv --python=python3 new_project
And then remember you must call it using `pip` and it will give you a pip running on the python you installed it with. I would suggest just virtualenv'ing everything.
conda is based on libzypp, which is indeed a fantastic package management system (it also powers OpenSUSE's package manager). Pip's capabilities are far more meager. 
`setup.py`, not `setup.cfg`
How does this compare to Pipfile?
Shit what am I gonna do with my python 2 books on 8 track ?
sudo pip install pip thanks
I had interviewers ask me about instantiation time of different datatypes, memory efficiency of tuple vs. list, recent development of python (what do you think is the best new feature in 3.6?) and most important differences between py2 and py3. 
I've tried using typing stuff yet. Does that allow you to set the names to non strings? 
AFAIK, the Pipfile is generally a replacement for 'requirements.txt', and is thus more appropriate for configuring development environments and automating that side of things. PEP518 includes metadata deployed with the (pypi) package, 
TBH, I do the whole `--user` install but typically call pip with `python -m pip…` (or `python3 -m pip`). That way you don't have to worry about Py3 and Py2 installs overwriting each other or calling the wrong `pip`.
Also remember that if you have pip installed in \*both\* system site\-packages and user\-site, then there's the possibility of conflicts, with part of pip coming from the system site and part from the user site. That's a recipe for confusion at best, most likely errors, and you should be \*very\* clear on what you're doing if you try this. The real answer is that if you want to use the system Python/pip, manage it using your OS package manager \- the Debian/Ubuntu/Red Hat guys will be sorting out their packages to cleanly manage the transition \- wait for them to sort it out before messing with your environment. If you want to use versions your distribution doesn't yet provide, install your own \(AIUI pyenv is a good tool for this\) or use virtual environments. Disclaimer: I'm a Windows user, and life's a lot simpler there, so take my views as those of a somewhat informed outsider :\-\)
&gt; Pip's capabilities are far more meager. The word you're looking for is DIFFERENT. Unless you're going to put this next: docker &gt; conda The installation and use of pip is trivial, lightweight and makes absolute sense for most programming environments. Different tools for different jobs. 
You need to use boto3 to access and setup s3. Also you will have to refactor your code as the interface is totally different.
It's unrelated. Pipfile is for specifying your application's runtime dependencies (AIUI, I don't use pipenv myself) so that you can reproduce your environment and ensure a consistent set of dependencies at runtime - it's closer in purpose to `requirements.txt`. On the other hand `pyproject.toml` is for defining what libraries your project needs to be present for your build process (`setup.py`) to run successfuly. You'd be better thinking of it as an equivalent of `setup_requires`.
Glad to see this news! Thanks to everyone at PyPA who has worked on this. But why is most of the text in this post `font-size: x-small` or `small`? 
Meh, just switch jacket cover with a book on division. Just make sure the print quality is absolutely imported from the future though. PS: I know, I know. Couldn't help it :)
Well, we had to pin 9.0.3 because 10 beta made the old deprecation warning about distutils an error. I haven't tried it since but I'm pretty sure that's a permanent breaking change. Some history from others: https://github.com/pypa/pip/issues/4805
I am well aware of the mixed environment possibilities and conda-forge, but that's just adding more complexity to the env/setup in my opinion - and I need to be able to re-create these environments easily on my co-workers machines, and within docker images. Mixing and matching package managers has led to rather volatile environments and updates in my experience. I can also see the argument for enterprise support - I actually inquired with Continuum about support options for our Anaconda environments, as we're more than willing to pay to have them update the packages we depend on, but it was prohibitively expensive (i.e., starting at $50k) as it's not really geared towards using Anaconda as a development stack outside of things like Data Science and ML applications. I still love and use Anaconda for various tasks, it works fine as my 'desktop' environment for Jupyter and it's a huge plus for anything with binary dependencies, but for building software (my own packages, Django/Flask projects, etc) it's just not my first choice to depend on conda any more. For context the main package that we're waiting on (pymssql) has been missing from the base 3.6 for over a year now. It's in base 3.5, they just won't add it for 3.6 until the next version is released and happens to be a slow moving project.
&gt; I love, love, love that str is always unicode. It alone is reason enough to upgrade. In the same vein, `open` lets you be explicit about the file type. If I want the file in binary, I know to do `rb` and I am done (usually to then run through `chardet` to decode). Of course, I have to support 2.7 still so I always do `from io import open`
Yes, there's no Runtime type checking. The typing info is only used by MyPy / other type checkers which inspect the code. In fact, you don't even need the type annotations if you are happy to provide default values. Otherwise, just use `Any` for all the fields.
Well, you don't really have to handle the loop, just be aware that it exists and tell it to run your coro. It's not dissimilar to Python threading/multiprocessing, in that you can't just say "this fn runs in a separate thread"; you have to invoke the machinery. 
You should make that a `pip` package
I'm not sure that face is smug enough.
Ah, that’s what I thought ... just wanted to be sure. Thanks!
That's fair. And I understand about the cost. I just had to go through the process of renewing our license at work and it's very difficult to convince some non technical managers that it brings plenty of value. The main thing for us is that we have the internal repository hosted and I can set up and host installers and things for our set ups. We can't have our code leave our network for compliance reasons, and this is easier than paying me to manage our own pip server. Their release cycle isn't that slow IMO, they release the anaconda package quarterly and new versions of packages get uploaded all the time. If you don't depend on the anaconda package directly then you have more freedom on what you depend on. 
Calibre will be forking Python 2 instead of upgrading to 3 - it should support your books just fine. https://bugs.launchpad.net/calibre/+bug/1714107
Isn't that what `async` is for? To explicitly tell python to fork that function into another thread?
"We've done a Qt5 thing for Python"
pipenv is not even close to production ready if you ask me. Even if/when it is, it's just a wrapper around pip.
Can pipenv be used to emulate what I'm able to do with pip install --user? That is, make python use that pipenv when I'm logged in? I had a look at pipenv, but didn't see anything in my brief google research...
Typing is optional in python, and has no effect when running python programs. They can make code clearer to read and let your editor know types of arguments and of return types. The downside is that take a bit longer to write and are not really necesary for small snippets of code (e.g. when you're just experimenting in Ipython. An example: import typing def func(val: str) -&gt; typing.List[str]: return list(val) The above program is very simple so type hints so not really aid, but you can imagine that in larger programs, they're really helpful. 
Something to do with a binding agreement that you shall pay the company an amount at a certain time for the duration the contract is active.
I burst out laughing when I read that bug report. I've had run-ins with Kovid in the past about his coding and architecture choices. That he would choose to fork and maintain python 2 rather than update...I shouldn't have been surprised, I guess. He's just not going to have the community support for identifying and fixing security problems that python 3 has. And there will be problems, they'll just be under the radar more. Calibre has long been on my "no way in hell, not on networks I'm responsible for" list. Suid arbitrary code shims. `curl http://path-to-installer | /bin/bash` installers without either HTTPS or signature validation. Both times, he fought changing his code or process when called out. And now he's voluntarily adopting maintenance of a gigantic codebase, just so he doesn't have to bother paying off his technical debt. I tried forking and refactoring his code once before so I could keep the pieces I needed, but it was way too big a mess. I think he's staying on that list.
Nah! That's too simple. Stuff like this should be understood. x = ['this', that'] def check_string(string, substring_list): for substring in substring_list: if substring in string: return True return False y = check_string('this', that) print(y)
You are technically correct (the best kind of correct). But in practice, very little commercial software is released under the GPL, so 'GPL vs commercial' is probably a good way to understand how Riverbank want PyQt licensing to work.
Mostly because I don't really know how to format stuff in Blogger :-( I copied the text from the email announcement and posted it. It looked OK on preview. Sorry about that.
Guess who hasn't put anything on pypi...
&gt;Well, we had to pin 9.0.3 because 10 beta made the old deprecation warning about distutils an error Remind me what deprecation warnings are for, again?
To this I say: tox.
Unfortunately I don't know any way to make it work on Windows, I'm sorry about that...
The code should run properly for every date.But it doesn't after year 1999. Thanks.
&gt; All of my phrasing are questions. How do I strongly imply something with questions? Learn about *sealioning* and come back. If you're not trolling, that is.
Seems like they really haven't thought this through.
You should head over to r/learnpython and ask there. 
Thanks anyway. I guess I'm gonna keep using For. Most if my classmates are using it anyway.
You're welcome :)
PHP has vastly more users than Python. But run a developer survey and you'll get "ewwww, PHP, nobody uses that" as a response.
ok cheers 
So, pipenv is not a replacement for pip/virtualenv. It's a wrapper that knows which pip/virtualenv commands to invoke for you, in order to provide a simpler comprehensive workflow.
I'd probably say "oh, that doesn't sound like a useful interview process" and cancel.
What kind of useful information does the company think they're getting by asking that kind of stuff?
GPL also is more lenient: You only need to provide source if they ask.
Missing ) in the first line perhaps
Pro tip: Don't `pip install -U pip` use `/path/to/python -m pip install -U pip`. The uninstall step has to remove the `pip` executable.
Please indent each line of code with 4 spaces so it formats properly. Also, what is the full error and stacktrace?
You might want to consider providing greater detail in future posts, such as, * OS * OS version * Python version That said, you should explore Schedule which you can find in the Python Package Index. The link to the readme doc is [https://schedule.readthedocs.io/en/stable/](https://schedule.readthedocs.io/en/stable/)
Your last sentence made me laugh! Looking forward to this app's enhancements.
"Calc = str(raw_input()" in the first line needs a closing ")". Most of the time when there a syntax error, its because of a missing parenthesis somewhere.
"Calc = str(raw_input()" in the first line needs a closing ")". Most of the time when there a syntax error, its because of a missing parenthesis somewhere.
my adblocker blocks 8 trackers from that service. 
Y2K big found. Better stock up on toilet paper 
For a dirty Windows user? I admit, you can't install any numerical packages easily without conda. But on Linux where there are actual package managers and compilation (should you feel like doing it manually) isn't a pain? `conda` is totally useless and regressive.
Did you fill in these lines with you keys and codes? CONSUMER_KEY = 'xxxxx' CONSUMER_SECRET = 'xxxxx' ACCESS_KEY = 'xxxxx' ACCESS_SECRET = 'xxxxx'
I feel I am just really bad at comprehension on a whiteboard 
RemindMe!
There is no need for any type of centralized authority. You can just simply figure that the person who has access to the account is the one that issued it. 
Well encryption and signing are two very different things. Especially since the only thing HTTPS does is guarantee that the data your receiving came from a source and that it's protected in transport. The possibilities for signing on the other hand are much more flexible in my opinion. 
Try this simplified version: import tweepy import re from ramdom import choice from twython import Twython CONSUMER_KEY = 'xxxxx' CONSUMER_SECRET = 'xxxxx' ACCESS_KEY = 'xxxxx' ACCESS_SECRET = 'xxxxx' messages = ( "SPAAAAAACCCCEEE! YEEEHAAAAAW!", "I'm in Space.", "Ba! Ba! Ba ba ba! Space! Ba! Ba! Ba ba ba!", "Space space wanna go to space", "Oh oh oh. This is space! I'm in space!", "Let's go - let's go to space. Let's go to space.", "I love space. Love space.", "Space. Space. Space. Space. Comets. Stars. Galaxies. Orion.", "Are we in space yet? What's the hold-up? Gotta go to space. Gotta go to SPACE." ) portal2_regex = re.compile(r'portal\s*[2]') auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET) auth.set_access_token(ACCESS_KEY, ACCESS_SECRET) api = tweepy.API(auth) twtwitter = Twython() sid = str(api.me().timeline()[0].id) search = twtwitter.searchTwitter(q="portal 2", since_id=sid, rpp="10") for tweet in search['results']: if portal2_regex.match(tweet['text'].lower()): api.update_status('@{0} {1} {2}'.format( tweet['from_user'], choice(messages), tweet['id'] ) ) 
Have a look at [s3fs](https://github.com/PyFilesystem/s3fs) for an interface to S3 that is very like regular files.
That sounds like buying a car that needs leaded gas.
Really? What's wrong with them? 
If I had the cycles, I'd take a stand at refactoring it again, focusing on breaking it up into reusable modules. I think the program would transition very well into an entirely web-based app, with job queues, a REST-based access API and a JavaScript/TypeScript front end. There's a lot of useful features locked into a horridly-structured app. And breaking it into service components in that way would do much for platform and library portability.
It does users 100% of the good. Deprecation warning tells you either 1) upgrade your shit OR 2) if you can' upgrade your shit, then don't upgrade this package cause we've told you "It gonna break". It's not up to package devs to solve all your problems. Their responsibility ends at warning you what upgrading may do.
You can't chain them, returning different objects each time. See javascript's Promises.
and you would cancel some if the best interviews around 
Does `setup.cfg` do much yet? I’ve only used it to mark my wheels as universal.
What took so long?
I always use `{interpreter} -m pip`. And you’re right about the vandalism. But here’s the problem - showing people how to do good virtualenv deployments. I recently out how to use `pip wheel —no-deps` to make deployment artifacts from git or local files (bless the vcs support in Pip), copy them into a user account, install using pip in a virtualenv. Took the deployment time and complexity down a notch. The issues I encountered could be summed as “too many non default options and little consideration given to ‘How do I deploy multiple artifacts and proprietary dependencies without setting up a private PyPI index’”. Also, finding out your wheels are missing vital package data because you made `MANIFEST.in` work for sdist but you forgot to put `include_package_data=True` in your `setup.py::setup`. Python packaging is **too damn hard** and I’m the only one of my coworkers who tries more than “lol put a main.py and just checkout the whole repo for deployment. And docker, lets use that!” 
It will die along with a lot of other software where the developers are too stubborn to adapt. That isn't a bad thing, in Apples world it does a lot of good as old software gets dropped frequently because people don't want to make old code bases compatible with new system libraries. In the end Calibre will go the same way replaced by something better.
Might get lost here but I just installed this via pip and it didn't install a resource compiler. `pyside2-uic` was installed though. Anyone know anything about this? My app uses some .qrc files.
It does work if you don't make an error in the implementation. https://en.wikipedia.org/wiki/Zeller's_congruence 
**Zeller's congruence** Zeller's congruence is an algorithm devised by Christian Zeller to calculate the day of the week for any Julian or Gregorian calendar date. It can be considered to be based on the conversion between Julian day and the calendar date. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Where "better" is defined as "it's available, maintained (enough) and mostly works." But that really does count for a lot. I've been Calibre-free for almost five years, but _damn_ I still miss it. The closest thing I've found to filling that gap is Moon+ Reader on Android, with a sprinkling of Kindle Reader here and there.
It should be fixed in the latest version (`0.8.2`)
You do you, I guess. 
They saved the language to me. The only annoying part to me about the interface is TypeVar declaration but it still works well enough - 3.7 got rid of having to quote forward refs which was nasty. I pretty extensively use the internals at runtime though and the 3.6 to 3.7 transition has been really rough, but the end result is better. Maybe ironically their biggest current failure to me is mypy itself which I've given up on even occasionally checking on my projects - it doesn't have a chance of understanding some of the more dynamic parts of the language and I've not found a way to contextually shut it up. I still cautiously hope to make it useful via the still in-development plugin system.
At this point I'm just using stuff like `__future__` heavily in the hopes that I can at least contain the baffling and unexplained dictates from ~~above~~ slightly above and to the side.
Not seeing the justification for the deprecation in any of that, just a lot of "it's the user's fault".
Scientific code is very much a collection of "actual programs."
100% of the time you got that warning, we were unable to actually uninstall anything other than the one file that acts as a marker that says "hey this thing was installed", otherwise the package itself was entirely left installed. This means that we couldn't progress to adding warnings, or even errors when overwriting existing files because we would do that in any case where this warning happens.
Does the ensurepip module work better / more consistently in combination with a venv, esp. one created with --without-pip? Does the pip package still pull in setuptools, which, in turn, pulls in easy_install(_exploits)(cause it bypasses both setuptools and pip altogether!), which I have to always remember to disable via setup.cfg? Its a decade later and Python packaging is *still* basically a bunch of hooker makeup applied to distutils.
Despite that, the new install occured nonetheless though, right? I'm not saying that's optimal, but a warning and an attempt are better than an error and no attempt at all. An option to make that same best effort would be useful (which was already suggested). If distutils is the problem then why not get that deprecated first (or at least the conflicting functionality) before making this deprecation?
I wish Python versions could just work the way I want them to, but I have adopted `virtualenv ./virtualenv -p 3` as my starting step for basically every new project. The rational part of my brain says _"oh, well with Java/C++/Rust, you have to setup some config or make file instead, so it's basically the same"_, but my gut reaction every time I do it is _"damnit Python why are you so complicated to get running"._
Poetry is dead in the water because the decision for pipenv to be the standard was already made. 
It occured yes, of course if files moved around you could end up with an install that had files from *both* versions side by side confusing each other with inscrutable error messages.
Conda is better for people who need a bunch of compiled libs, non scientific users don't need compiled like 's as often 
Actually, if you don't have any build hacks involved in your `setup.py`, you can specify pretty much all the metadata directly in `setup.cfg`, leaving this line in `setup.py`: from setuptools import setup; setup() https://setuptools.readthedocs.io/en/latest/setuptools.html#configuring-setup-using-setup-cfg-files
Can't say I disagree.
Hi.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Please post in the job sticky
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Pycharm
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Good to know. I agree that'd be messy, though I'd expect the changed files to overwrite any current ones.... but would it affect code that correctly uses the new version of such a package? I'm pretty sure that making any references into the old files from your code would be the primary problem, with the side-effect being they lead to old code versus going nowhere and erroring out. And for all that, distutils is still out and about, despite the fact that it's mutually exclusive with pip 10 (and it's not clear what purpose it still serves). Why is that? It seems Setuptools is superior, not to mention being pip-friendly, while pip will flat-out break when dealing with things from distutils. For all this, understand I posted my initial reply as a warning to users that they should tread carefully with pip 10 if they in any way use things that might have been installed with distutils. I'd be the first to enthusiastically endorse the move to 10.0, because from a security and maintenance perspective upgrading should be encouraged... unfortunately the reality of package distribution (and the peculiarity of distutils - which appears to be something to avoid at all costs yet remains fully supported in Python) means, for a non-trivial fraction of users, staying on a dead branch of pip indefinitely.
Thanks
Author of poetry here! The thing is poetry still has a place in all of this since it is a true package manager, unlike pipenv. It can do what pipenv does and more. You can use it just to manage your dependencies for an application, which is what pipenv is aiming for and you can use it to make libraries that will be published to PyPI or any private repository. When I started it I wanted to build a tool that could be used to manage Python projects from start to finish, be it a library or an application that you need to deploy. I hope it can help make the Python ecosystem a little more consistent.
Well, this might finally be what forces everyone over to ArcPro... yeah, probably not.
Over here laughing in Apple. They don't give AF.
I'd think it'd be more proper to check the version (or specify requirements) than to rely on import exceptions to (hopefully) guide you to the right version. Still, if try and try again is a good pattern, then I'd expect pip to do something similar. Again, is there a purpose to distutils anymore? Is a hard mutual exclusion the answer to working in some way with a packaging system that's not itself deprecated yet?
When you import the os module, in its source code the os.path module is also imported into its namespace, meaning that the object os of type module has an attribute named path, which also happens to be of type module. This is an implementation detail, it is not automatic. If in one of your modules you imported a completely different library into that modules namespace, then any code that imports your module would by default be able to access that other library through your module's namespace. At that point its just treated like any other variable. However, using the syntax import os.path Will only work if the package os has a submodule named path. ---- So essentially, it's up to the specific package to determine what submodules are imported and made available by default. You would have to inspect the package's source code to determine it, or just import it to find out. There is no harm in doing it just to be safe though. 
1. Please ask /r/learnpython 2. To answer your question: every module is different. Assuming a single file, you'll see something more like the os example you gave. If it's a module, though, especially with a deep hierarchy (&gt;2 levels), it will be entirely up to the author's discretion on how that module ends up being required for use. The behavior is defined within the `__init__.py` file. Up until python3, that file was required and now it no longer is. As a general rule of thumb, __init__.py files do not contain code with the exception of imports. However, that generally violate's Python's Zen in that explicit is preferred over implicit. So the default behavior, if nothing has been setup, is the email example above. With extra work, you can usually make the module behave more like the os example above. It typically takes one line... so to make the email example work like the os example, the following line would need to be included within the module's `email/__init__.py`: from . import message 
This blog post has a good description/discussion about this topic. It's a few years old, but the information is still correct. https://jeffknupp.com/blog/2012/11/13/is-python-callbyvalue-or-callbyreference-neither/
AIUI this is a much more common acronym.
bottom
About time. So tired of seeing new projects being coded in Python 2.7. 
Top
Your “architect” is a dumbass, and you can quote me on that. I don’t care if they personally prefer 2.7. There’s nothing wrong with that. But spending their employer’s new-project money on a language that’s officially EOL in 20 months is grossly negligent. 
print(flag[0])
##r/vexillology --------------------------------------------- ^(For mobile and non-RES users) ^| [^(More info)](https://np.reddit.com/r/botwatch/comments/6xrrvh/clickablelinkbot_info/) ^| ^(-1 to Remove) ^| [^(Ignore Sub)](https://np.reddit.com/r/ClickableLinkBot/comments/853qg2/ignore_list/)
&gt; it was just c++ under the hood as far as I was concerned. It will literally always just be c++ under the hood.
Not me? Pep518 covers specifying a new build system, which you definitely can't do with setup.cfg
It has to be done. I am migrating my code to py3 too
Normally/previously our two teams work in separate spheres, so that particular aspect hasn't impinged on me much until recently. However, I'm beginning to wonder if the company's lack of individual-contributor path has to do with some senior folks who just don't see the need since they've-got-theirs.
Those are some really bad signs. I’m not going to tell you to quit your job. Maybe it’s otherwise awesome! But in one post you’ve mentioned: - Bad technical decisions are made - ...”because I said so” - ...maybe by the same people who decided not to have a career ladder for engineers. That’s a very high red flag density.
I'm mostly annoyed by this: class Foo: bla = [] def __init__(self): self.bla = ["foo"] which gives "error: Need type annotation for 'bla'". I'd like it to just ignore the class if nothing in it is annotated.
I love Calibre. A while ago I was looking for code to handle MOBI books and I thought I could just use the module from Calibre. A project this big must be nicely coded and modularized. Oh, was I surprised.
You know, I'd seen that before but actually forgotten about it - because it was always too difficult to use non-typeshed stubs. The news just keeps getting better!
The common term for Proprietary+ gratis software is "freeware".
There’s a number of sorting algorithms available to python users, depending on what your cost constraints are. Check out bubble-sort, merge sort, and insertion sort online. 
Sorry but could you explain why pandas doesn't work? I used it for tick by tick data and I didn't have any problems, what would you say the limits are? Or what exactly would make it fail?
TL;DR: actually, if you know your input is numbers, then you might have better options than built-in `sort()` or any other sorting algorithm in the "comparison based" group. Use some variation of radix sort: https://en.wikipedia.org/wiki/Radix_sort . This sorting algorithm may beat comparison based algorithms in cases when there are relatively few different numbers that need to be sorted (i.e. input contains many repeating numbers). ---- Sorting is used in, basically, every computer-science class on algorithms to illustrate divide-and-concur approach to solving problems. In particular, quicksort and mergesort lend themselves very well onto this approach. However, of course, the idea is more general than just these kinds of sorting. The idea behind many sorting algorithms is that you somehow split the amount of work that needs to be done, after doing that work, you re-combine the pieces together. It is easier to see this on merge-sort algorithm, but for array-like data-structures, usually quicksort is better. So, I'll try to give you an idea about how to write merge-sort (though I won't write one, since it sounds like an assignment you've got for independent work). Sometimes it's easier to think about the problem assuming you've already solved part of it. So, is in this case: assume you already solved sorting for two parts of your array, then your task is to merge them together in such a way, that sorting is preserved. You can do that by looking at the first element of both arrays and choosing the smallest one, then removing that element from the chosen array and putting it into resulting array. You can than repeat this procedure until all elements are accounted for. (bonus: think about how not to remove elements, but use indices to achieve the same effect). Now, once you know how to merge two sorted arrays, note that an array of one element is trivially sorted, so, if you split your array into sub-arrays of one element, and then re-combine them pair-wise, you'll get half as many sorted sub-arrays. If you keep doing this repeatedly until you only have one array left, you will achieve your goal of having a sorted array.
**Radix sort** In computer science, radix sort is a non-comparative integer sorting algorithm that sorts data with integer keys by grouping keys by the individual digits which share the same significant position and value. A positional notation is required, but because integers can represent strings of characters (e.g., names or dates) and specially formatted floating point numbers, radix sort is not limited to integers. Radix sort dates back as far as 1887 to the work of Herman Hollerith on tabulating machines. Most digital computers internally represent all of their data as electronic representations of binary numbers, so processing the digits of integer representations by groups of binary digit representations is most convenient. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
 &lt;Flag object at 0x7fdf0c91b9f0&gt;
We, the inhabitants of the proclaimed land of Pythonistan, shall rise to rebel against our oppressors under this flag.
Use Telegram or Discord. It's very easy to pull off with python. 
Next thing you know is python becomes the dominant computer language 
And some opensource software is not free as in beer. http://wiki.c2.com/?FreeSoftwareVsOpenSource This is why you'll find projects like Audacity describing itself as ["free, open source"](https://www.audacityteam.org/), and VLC describing itself as ["free and open source"](https://www.videolan.org/vlc/index.html)
Github/Twitter is the centralised authority in that case, because they are implicitly claiming that no-one else has access to that account. You're relying on their security and their honesty (i.e. they could deliberately serve you a page with a different key). A couple of years ago, the developer of requests had his [Github account targeted](https://www.kennethreitz.org/essays/on-cybersecurity-and-being-targeted). Luckily the attack was stopped by two factor authentication, but I bet there are plenty of developers not using 2FA. And Github accounts would be more valuable targets if they were used for package signing too.
git clone citizenship_request.py
raise from, especially raise from None when I want purposefully smash a stack trace which is more useful than you'd think at first. 
learning python will not take much time, it is pretty easy! 
These things are not written into stone. In the long run, Python needs a proper package manager and I think there is no sane way around it. I guess most people who have used a good package manager in another language will agree with this.
\^\^
Nice to have you here! Thanks such much for *poetry*! :)
Don't forget Quick Sort!
you could have just gone to piwheels.org yourself and see if the page loads. if it does then it's up and you should retry your install, if installing still doesn't work then something else is your problem 
Too north-korea-esque, the top is something I'd expect a Dutch province to have as a flag (fitting given Guido's origin)
Hmm, this doesn't work for me. I can do, something like: variable_1 = df['1'].values and that gives a 1d array. If I wanted a column for whatever reason, I'd have to transpose it. If I have my column names as regular strings, I can use df.column_name.values. If my column labels are integers, df.column_name.values doesn't seem to work, as df.1.values is clearly rubbish and throws a syntax error. In looking through the Pandas docs, the iloc method seems to be quite prevalent. I'm by no means a Pandas aficionado. In fact, I'm still learning how to use it, and I really no very little about it to be honest. Is there any way you can shed some light on this? 
Made me laugh :-D
Mind telling why you want to do it?
Oh thank you for your advice :)) still try adapting to this area :((
Great design! I'm thinking of doing a t-shirt with a white version of it. https://imgur.com/Br6U1i0
Neat! I'd suggest a page on the site with a few details about what is actually counted. Is this for the latest version, or for all versions? Is it for all time, or the last month? If it's feasible to work it out, it would also be interesting to have options for the time period. Especially for new projects, authors might want to display downloads per month or per week rather than a total number.
Looks interesting. I don't really have any opinion on whether it's better or worse than pipenv myself - neither project really seems to explain very well why you'd want to use the tool, and how you'd fit it into (or use it to replace) an existing pip/virtualenv style workflow. I can't say I've tried it yet, though, so this is basically just from skimming docs. It's a bit of a shame it invents its own version matching notations, rather than following PEP 440 (if the extra notations are useful, getting them into PEP 440 so that other tools can use them too would be great). One of the huge improvements we've made these days IMO, is moving towards making sure everything follows a documented standard, rather than relying on implementation defined behaviour (that other tools need to reverse engineer).
Haha, but the B in BDFL is highly suspect in one of the two parties that you're comparing...
/r/learnpython
You shut your mouth about Guido, our exalted leader.
Can't tell if referring to the username or the post!
None of my projects exist, apparently :( They're all pretty new though. Does it have any way of filtering out CI hosts? I can see them totally dwarfing actual users.
 raise Flag()
You get an numpy array. Check out Numpy homepage, http://www.numpy.org
I heard he once sunk a 3-pointer from the locker room.
Yes I agree. 
This doesn't seem like that big of a deal. I'll address your points in the same order. 1. This is exactly what they committed to. But it's not a big deal because of point 3 that you raise which is that they have to provide this type of dictionary anyways 2. This doesn't force more work than was already done as you note in point 3. This data structure already exists and therefore it's no requirement for extra work in itself it just requires the default dictionary to be an ordered one. 3. I suppose it is redundant if they are the same implementation under the hood but that doesn't seem to be the end of the world. I'm guessing that so many people relied on this fact it was better for the community to make it official. This would make it easier for code to work correctly across different interpreters now that this behaviour is in the spec rather than other runtimes having to "remember" what the de facto spec is even though it's not official.
Another benefit. If someone wanted the performance benefit of using an unordered dictionary they may have assumed that the default dictionary would provide this as the spec didn't specify which it was. But implementations would deny them this. Now the docs would be clear on what comes with the default dictionary.
Thank you for your responses, but I'm not sure that I understand you correctly. Let's imagine that developers of CPython or another Python interpreter invented a new dict implementation that improves performance but makes dicts unordered as they were before. Before this change in the documentation, they could easily use this new implementation, because the order was not guaranteed. Now they could not. How is it beneficial? Once this line was added to the documentation they will have to preserve this guarantee forever. I do not understand why this new dict feature is needed: if you rely on the order, you use OrderedDict.
Import flag Raise.raiseflag(2)
I'd say the top is more befitting of Python, being more beautiful in its simplicity. The second seems very busy with the yellow middle which seems to be there only to facilitate the white circle.
Yippee. Maybe I can stop writing dual compatible code by 2020. Then again, I'm also supporting pre-ANSI C, so I'll just sit here and cry.
You mention that dicts were unordered before but I thought you said that the implementation was ordered. My point is that people probably relied on this and therefore CPython and others had to figure this out so that code would behave identically on their interpreters. So while in theory they could use this faster implementation with better performance, in practice they had to align with expectations beyond the official spec. I'm taking from your original post that they have always been ordered but that was just an implementation detail. You are totally correct in that in the past if you required ordering you should rely on the ordered version. My guess is that so many people relied on the ordering without using the guaranteed ordered version they wanted to make this official to preserve the semantics of older programs. It is a nice thing especially since this old code didn't get any benefits of using an implementation that eschewed order for better performance anyways.
Does the person installing it need to have python previously installed? And what happens if they do?
What about sansio?
Are you sure this has been formally adopted as part of the language specification going forwad? Just because its in the Python 3.7 documentation doesn't necessarily mean its part of the spec: those docs are specific to the CPython implementation of the language.
It seems strange. Aren’t dicts essentially hash tables on the back end? Making them ordered seems like it would drastically increase performance overhead. 
I'm kinda glad it's happening. Just yesterday I made a graph with Bokeh and to export it I had to save it as an HTML but to keep to relevant values interactives (hover over a point gives it's value for example) ; the values are saved as a dict, which wasn't ordered and it messed up one of my axis.
Good bot 
woof woof
You're a good homo sapiens. (●＾o＾●) You can continue flapping your meat around, I s̴w̴̢ea̛r̢̨! *** ^^^I'm&amp;#32;a&amp;#32;Bot&amp;#32;*bleep*&amp;#32;*bloop*&amp;#32;|&amp;#32;[&amp;#32;**Block**&amp;#32;**me**](https://np.reddit.com/message/compose?to=friendly-bot&amp;subject=stop&amp;message=If%20you%20would%20like%20to%20stop%20seeing%20this%20bot%27s%20comments%2C%20send%20this%20private%20message%20with%20the%20subject%20%27stop%27.%20)&amp;#32;|&amp;#32;[**T҉he̛&amp;#32;L̨is̕t**](https://np.reddit.com/r/friendlybot/wiki/index)&amp;#32;|&amp;#32;[❤️](https://np.reddit.com/r/friendlybot/comments/7hrupo/suggestions)
[removed]
Mods? 
That's would be better. [flag of karma kagyu](http://www.dharma-haven.org/dream-flag.htm) 
No. There's a video by Raymond Hettinger talking about dictionaries. The keys and values are decoupled, so they're very efficient.
Use [OrderedDict](https://docs.python.org/3/library/collections.html#collections.OrderedDict)
I sonewhat agree. Software engineering interviews that focus on computational complexity, data structures and algorithms, in my experience, tend to be indicative for companies that optimize on performance and spend less time on internal software quality (architecture, structure and design). The interviewer would have to reassure me that the company knows what they're doing.
Thanks for the heads up. I can fix that!
I'm not very familar with Promises, but it seems that chaining is a way to run several sequentially. What am I missing? I'd still say concurrent.futures is nice, since in comparison with Python 2, there is nothing :) They work fantastic for certain multiprocessing workloads.
Hey, Beemo56, just a quick heads-up: **familar** is actually spelled **familiar**. You can remember it by **ends with -iar**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
[The Python Language Reference](https://docs.python.org/3.7/reference/) links to [The Python Standard Library](https://docs.python.org/3.7/library/index.html#library-index) and it [says](https://docs.python.org/3.7/library/stdtypes.html#mapping-types-dict) that "Keys and values are iterated over in insertion order". I think that is a part of the spec now.
Before answering your question, I consider C++, Python, Pandas, … different tools just like screw driver, wrench and plier. There is no one tool that solves all problems. You have to choose the right tool for a given problem. Most importantly getting emotional about stools is just silly. Now, your question; the precise limitation of Pandas or any other package greatly depends on your hardware and software setup. Python in general and by extension Pandas have scalability and performance issue. That is exactly why the author of Pandas, Wes Mckinney started the Apache Arrow project. Wes also explains in an article “10 things I hate about Pandas” the issues about performance and scalability in Pandas. I explained above why I didn’t go with the Arrow approach and implemented my own. I am not sure what tick by tick data you used. Maybe the instruments you used don’t tick that much. Try using Options data from OPRA or a week worth of S&amp;P500 constituents tick data with Pandas. 
This one? https://youtu.be/npw4s1QTmPg PyCon Portland 2017 on the history of Dicts. I watched it last year and it's a great talk. Funny, informative and gives a good insight into the work the core Python devs do.
That's it!
That article compares Qt with KDE on Plasma. I get the feeling they do not know exactly what they are talking about...
Ah, this is a wonderful library! I've been contemplating building something like this for a project I've been working on, but now it looks like I won't need to.
I hope someone gonna fork Calibre.
my question is that, should we count on dictionaries being ordered from python 3.7 onwards because this is an internal design decision, or should we just order them always on application level ? iv'e heard a few people say you shouldn't that's why i am asking.otherwise it seems logical to count that as a service and not something internal. in addition to slight performance gain, they are now also sorted as stated by raymond hettinger in his talks.
Python has no spec as such. Cpython is the spec, except for things explicitly said to be implementation details. Duct ordering was previously an implementation detail and now is not.
To put it in Python terms: I call an asynchronous function which will eventually return X - so, it returns a future which, when resolved, will have a value of X. I have another function which takes X and returns Y. I have a other function which takes Y and returns Z. I'd like to be able to do x_fut = async_fn() y_fut = x_fut.then(x_to_y_fn) z_fut = z_fut.then(y_to_z_fn) Any one of those futures can be passed around as a variable, returned from a function, and so on. It means I can say "I want to download something, get the JSON as a dict, then use the values in that dict to fetch an image, then turn the image into a numpy array, then find the transpose of that", and have it all done in some other thread I don't care about until I get the result, by composing functions and without having to keep the original result around. 
The version notation tries to be more consistent with what exists in other tools (cargo, composer, bundler). To me, PEP 440 is too limited: no caret, tilde requirement for instance. So you currently you would have something like this: `&gt;=2.7, !=3.0.*, != 3.1.*, !=3.2.*, !=3.3.*` while you could simply have something like this: `~2.7 || ^3.6`. Note that `&gt;=2.7, !=3.0.*, != 3.1.*, !=3.2.*, !=3.3.*` will work with poetry. In fact, poetry understands and can work with PEP 440 .
Thanks for the kind words! I really appreciate it :-)
confusing username is confusing
Why would you want that?
Good bot
I don't really understand what you're saying. Are you looking for a way to automate things you are currently doing manually?
How does it compare to `retrying`?
Use commas.
You're responding to all the extra work concerns, but not the performance ones. Dictionaries are used *everywhere* in Python: even namespaces are dictionaries, so you're using a dictionary every time you call a function. As it happens, the current best dictionary implementation in Python is ordered, but that's honestly kind of weird. The natural expectation is that maintaining order comes at a performance penalty. By committing to dictionaries being ordered, Python is basically committing to the particular dictionary implementation in use now. If in 5 years we have new hardware or algorithms that allow a more efficient dictionary implementation that isn't ordered, Python can't use it. This is a small loss: new hash algorithms don't come along that often, and performance isn't really a priority for Python. Still it *is* a trade off, and what's lost here is not just some hours of Python developer effort. It's important to remember too while the loss is small, the gain isn't particularly big. Most uses of dictionaries don't care about order, and any quasi-competent programmer can understand the difference between ordered and unordered dictionaries. I know Python aims to be very accessible to new programmers, but do we really want to be optimizing for outright incompetence?
Some interesting concepts in there. I usually use `tenacity`, but this seems different enough to try it out.
Sansio is a architectural style. The library defines a reducer function (a function that takes state and bytes from the network as parameters and returns bytes to send to the network and more state) you then use the reducer function with your IO library of choice
Thanks! 
Please check the sidebar.
Sidebar??
I think incompetence is too harsh a word. Python also encourages the use of lists and tuples in place of true arrays, and uses integrators for loops. I think Python has always optimized for abstraction even at the cost of performance, and I think that's not necessarily a bad thing. This is not a major problem when you're first learning a language, but in order to truly understand what's going on, at some point you need to understand how all the 'magic fairies' in Python do there magic. The only true danger I can see is if a programmer only knows a language like Python and doesn't understand the deeper implications. That's why I teach Python in a first class, to help people understand algorithmic thinking and the basic ideas of programming, and then we go to old-style C in the second class, where none of those extractions (even strings) exist in the same way. Then we move on to more modern languages like Java to see how all these things are reconstructed. 
The right side of your screen where it says "Submit a new link." There are some links below it. Not sure if i can link but here's one i found there: http://wakari.io/
Learn python sololearn.com Then it’s just a matter of learning the arcmap tools. Go to desktop.arcgis.com select the version your running and search for stuff. You’ll basically learn the language and the software simultaneously. Pro tip: expect it to not work the first time. 
/r/learnpython and read the sidebar.
I got started with this video series https://youtube.com/watch?v=Iqjy9UqKKuo
Have you looked at the resources in the sidebar?
Pretty nifty!
Now we just need things to support 3.7!
 &gt; 7! 7! = 5,040 
That was an interesting talk but, if I understand [the code](http://code.activestate.com/recipes/578375-proof-of-concept-for-a-more-space-efficient-faster/) correctly, it does not preserve order when an item is deleted from the dict (the most recently inserted item gets swapped with the item to be deleted, which changes the order).
Coding without looking at libraries is probably not a sensible goal. Good data scientists learn the library/package ecosystem and understand how they interoperate. When you encounter a problem in a new domain, looking for packages that are designed for that domain is the right step — inexperienced analysts reinvent the wheel instead. You may have meant reading documentation, but reliance on documentation is directly correlated to the amount you practice and your familiarity with the packages. No one is such a good programmer that they are above reading the docs. (And after you read the docs, read the source) Check out /r/learnpython and data science classes on edX.
Ugh.... Good bot
bad bot
Do you know how deletions are handled? The PyCon talk linked above doesn't address this.
to let sudents run test code without seeng tests
I need exactly python
wow what a rebel
Is this like a more nuanced [fuckit.py](https://github.com/ajalt/fuckitpy)? 
bad bot
wat
r/learnpython
If you can guarantee your script will only use Python 3.7+ or CPython 3.6+ you can write scripts that assume ordered dictionaries. I already do this is many of my scripts because I control the environment they run in. Also for playing around with Python is opens up neat tricks like this: https://twitter.com/raymondh/status/944125570534621185 
Bad bot
I think you mean seeing the code that is executing alongside its output. That's usually not useful since code executes much faster than humans can perceive. It can be useful for checking performance though, certainly Javascript debuggers do something like this, such as in Chrome devtools. For python (and in general) there are tools that use profile data, like [flamegraphs](https://github.com/evanhempel/python-flamegraph). That's not going to help with learning a language though.
Probably because people think Python is prettier. Maybe there are also arguments to say Python is better designed, at least for a general purpose language. I didn't realize until recently that access modifiers were added to php. That makes matters worse in my opinion. I would rather use python, or even something like Go, Java, or Rust if performance matters. (The latter uses just `pub` for modifiers, and has a lot of well designed features.). Probably others would prefer just JS/Node.
&gt; My point is that people probably relied on this and therefore CPython and others had to figure this out so that code would behave identically on their interpreters. I have already released a project that relies on dicts preserving order for a website list. 
As already pointed out even if better hashing algorithms are found the way this was implemented wouldn't stop them from being used Python is great language for people of all experiences, it's design goals specifically aren't about forcing everyone who uses it to learn underlying implementations and concepts. I would hazard a guess that most people who use Python don't know what a hash map is. Furthermore as well as it making intuitive sense to many beginner programmers it has many extra benefits, including the motivation for adding it in the first place[ PEP 468 -- Preserving the order of **kwargs in a function.](https://www.python.org/dev/peps/pep-0468/).
I believe it uses lazy deletions -- that is, rather then actually removing some element, it marks it with a kind of "tombstone" value (and adjusts the rate at which the arrays resize to take into account the ratio between active and lazily-deleted cells). If you're curious and want to learn more, try checking out [`dictobject.c`](https://github.com/python/cpython/blob/master/Objects/dictobject.c). It's pretty thoroughly documented -- it makes for a pretty interesting read!
What happens to the different semantics between dict and OrderedDict? To quote from the OrderedDict docs (3.6): &gt; Equality tests between OrderedDict objects are order-sensitive and are implemented as list(od1.items())==list(od2.items()). Equality tests between OrderedDict objects and other Mapping objects are order-insensitive like regular dictionaries. This allows OrderedDict objects to be substituted anywhere a regular dictionary is used. 
From the post I didn't understand how this library is better than just implementing these functions and running them. Could you please explain?
Python 2 civility, separate but equal
Only the projects that don't trust their own test suite make those "stick to py2" arguments. Otherwise it is really really fast, the whole instagram codebase took only 9 months and that was a concurrent pass so it *cannot* take too long. 
I like the decision, assuming it doesn't slow processing down noticeably. I once had to hand code a bunch of regex patterns as values associated with keys, before I knew they weren't ordered as I needed them to be, so I had to change them all to OrderedDict. It seemed like a bandaid for something that should have been there by default. So assuming it doesn't affect performance noticeably I'm glad it's default.
Thank you, I’m going to try it out with Telegram.
I don't think this is a good idea. A `dict` should be an in-memory implementation of [MutableMapping](https://docs.python.org/3/library/collections.abc.html#collections.abc.Mapping) abstract base classes. As such, one should be able to swap out a native Python `dict` for anything that implements a `MutableMapping` interface. It seems asinine to require anything that implements `MutableMapping` to also maintain order (if it's going to be fully compatible) just because the CPython implementation of `dict` makes it convenient to do so. Also, allowing developers to assume that dicts maintain insertion order is just asking for code that breaks on pre-3.6 in subtle ways. I think it's better to be explicit that implicit. If you need a mapping that also maintains insertion order, you should be required to explicitly specify that.
But the bottom one feels like you have something complex yet beneath it is all is a simply python 
As to point one, developers were already relying on that because cpython was doing it. The only way to prevent that would have been to start deliberately randomizing the order like Go does. It's counterproductive to add a breaking change (in practice, if not on paper) like that.
You could maybe use methods from the inspect module for a backend that checks for specific inputs as boolean value, where if a student is trying to run some gargantuan list comprehension instead of whatever simple expression or statement they're supposed to use, then it doesn't run the code. You could use checks like that to narrow down what users could input maybe. 
You might want to look into PyQt, a lot of the functionality you described can be contained fairly easily in the classes and functions of the module. You can look up some basic PyQt programs [like these](http://zetcode.com/gui/pyqt5/firstprograms/) and see if it looks achievable to program yourself.
Most of your concerns are solved with a quick search/replace. When the time comes, *collections.UnorderedDict* might become a thing.
thanks, I'll have a look now
I think the argument that this helps new programmers is pretty weak, TBH. Why would they assume the dict would be ordered by insertion order rather than, say, alphabetically by key name? That seems just as logical a guess as to what the order would be (I know this because this is what I assumed when learning the language until I learned otherwise). So putting a restriction like this on the language going forward seems like a very high price to pay for a fairly minimal benefit. 
The developer needs Python installed, but the user of the application does not. PyInstaller is used to generate the exe which bundles up Python into the application. It will not conflict with an installed Python already on the system.
You're welcome, I'm not trying to advertise for Harvard or anything, Stanford and MIT also have good stuff, like MIT's course on dynamic programming, or others. If you're trying to learn specific things for work, focus on whatever is used in whatever work you want to do. But if you're freelancing or working on your own project/s or whatever you probably have more freedom to use what you want.
I agree with you. IMO, each "basic" data structure should be a minimal implementation. Lists and other array like things offer index based access so they naturally preserve order. Dictionaries are accessed using keys so the ordering explicitly shouldn't matter. Order preservation adds an unnecessary additional constraint on the dictionary construct. 
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
How, if at all, are factorials even defined for non-integer numbers? 
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Sure 
&gt; Worth pointing out that the change isn't due to a new hashing algorithm, it's a purely data structure change. Whoops. Yes. I was being pretty sloppy there.
A little background on the path to preserving dictionary order: https://morepypy.blogspot.jp/2015/01/faster-more-memory-efficient-and-more.html The specific bug that brought it in (which references the post above): https://bugs.python.org/issue27350 A prior post here on the implications of dictionary ordering: https://www.reddit.com/r/Python/comments/51te8x/raymond_hettingerpython36_news_ordereddict_is/ And the main thread on the matter, including Guido's input: https://mail.python.org/pipermail/python-dev/2017-December/thread.html#151263 OrderedDict is basically redundant going forward but if you're looking for backward compatibility you'll be using it anyway. As for implementations, has anyone found one that is worse with the new algorithm? IMHO if an algorithm / data structure central to Python proves to provide general improvements overall (core and application) then, like Timsort, it's worth making it the standard going forward. And I trust that the core devs have looked at this deeply enough to be satisfied that it's worth standardizing against.
Gamma function.
OH, so have you proposed adding these features to PEP 440? If you did, they could get added to (for example) the packaging library, and be usable in all tools, not just yours.
The downloads data was from the previous month, now I just updated to the current month :-) I am working to do this task automatically :-) Currently I did not filter any CI hosts :-( But I think that this data is also important because normally these downloads are from production enviroments :-) Also pip has an internal cache which does not compute to the download statistics
Ohh great!! I will add a FAQS or something to clarify the content :-) Currently the data is for all the versions and from 1 January 2014. The next feature will be a downloads graph over a time period :-) Thanks for all the suggestions ;)
It's the [analytic continuation](https://en.wikipedia.org/wiki/Analytic_continuation) of the factorials. (Or rather, Γ(n+1) is.) There's the notion in mathematics of extending a function. What that means is taking a function that isn't defined everywhere (e.g. factorial) and coming up with something that matches the original at all points where the original is defined, but is also defined elsewhere. There's, obviously, an infinite number of these extensions. But some of them are nicer than others, in a sense. One extension of a function that is particularly nice is an analytic continuation. You can kind of think of it as being "smooth", in a sense. The formal definition is somewhat more gnarly.
[Gamma Function](https://en.m.wikipedia.org/wiki/Gamma_function).
Non-Mobile link: https://en.wikipedia.org/wiki/Gamma_function *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^170942
I think we should have had hardware acceleration for dict lookups(And object stuff in general) a long time ago since they're so useful. This might make that harder if anyone ever wants to do that. What I'd really like to see is some JIT features in the reference implementation that would make most of this performance stuff a non issue, or native syntax support for some kind of restricted high performance subset.
I program a lot in both ruby and python. Ruby made the switch to ordered dicts (hashes in ruby) a couple of years ago. I was skeptical of this change at first, but I cannot begin to tell you all the different ways and times having first class support for ordering has been helpful. You will never want to go back to unordered.
explicit is better than implicit.
Lists are also ordered... what's implicit about lists being ordered that is not implicit about dicts being ordered
https://mail.python.org/pipermail/python-dev/2017-December/151283.html https://mobile.twitter.com/raymondh/status/941709626545864704
1561!
Why must you test me?
&gt; to illustrate divide-and-concur approach to solving problems Divide and *conquer* :-)
I can say: It is cool! Because working with OrderedDict which have nested OD - is annoying. Basically, OrderedDict is like lists of tuples. In my opinion it is inconvenient. If I can populate ordered dictionaries like I populate original dics it would be very nice. 
This doesn’t change the semantics of MutableMap. `dict` already has a more extensive interface than the five methods defined in MutableMapping so you can’t substitute an arbitrary MutableMapping for a `dict`. You can go the other way, ordered or not, because ordered iteration is an acceptable implementation of an unordered `__iter__`. In a way, this change makes things less implicit, because you’re not relying on a footnote in the documentation to understand the ordering of dictionary iteration. Many developers will ignore this warning so the only practical option for enforcing unordered semantics would be to artificially randomize the order of iteration (as Go does). Using OrderedDict is less convenient than using dicts: no literals, dynamic libraries often mishandle OD, different C-level details. Artificially reducing the functionality of `dict` now in support of future-proofing and interface purity ultimately seems like a bad trade off. 
Thank you! I'm not a guru in licensing, buy why should I use PySide Commercial license if there is PySide LGPL? 
3.7! ≈ 15
&gt; A dict should be an in-memory implementation of MutableMapping abstract base classes. This is true. &gt;As such, one should be able to swap out a native Python dict for anything that implements a MutableMapping interface. This is not true; you're messing up your Liskov substitution principle. 1. You can use a (ordered) dict anywhere you use a MutableMapping. 2. You can use any other implementation of MutableMapping anywhere you use a MutableMapping. 3. You cannot necessarily use any other implementation of MutableMapping anywhere you need an ordered dict.
Man, making it sorta built in but not really is worse in some real ways. 
Why not use nbgrader? https://github.com/jupyter/nbgrader
So what about checking dicts for equality when they've been constructed in a different order? Does this break that?
yeah, oh well
&gt; You can use a (ordered) dict anywhere you use a MutableMapping. &gt; You can use any other implementation of MutableMapping anywhere you use a MutableMapping. &gt; You cannot necessarily use any other implementation of MutableMapping anywhere you need an ordered dict. That's my point. One *should* be able to swap out a native Python dict for anything that implements a MutableMapping interface. Adding order to dicts as an explicit part of the language specification breaks that. I think being able to substitute a MutableMapping for a dict is more valuable than letting someone use a dict rather than an OrderedDict. Imagine you've inherited a mass of spaghetti. You replace a dict in the original code with an instance of a MutableMapping. The code breaks because the MutableMapping does not preserve insertion order. If the language specification says that dicts are ordered, the breakage is entirely on you. If the language specification says dict order is undefined, the breakage is still on you, but at least part of the blame is on the guy who wrote it for relying on undefined language behavior when he could have just used an OrderedDict. If the guy who had originally written had used an OrderedDict, you would know up front that he's relying on that order and you wouldn't have the problem in the first place.
So..i realized i needed this too lxml. Problem is when i run it..its imply hangs.... C:\Python36\Scripts&gt;pip install lxml Collecting lxml 
I believe it to be anywhere you would want to accept a variable number of arguments spanning a range from 0+, whether it be in a function, property or method. A good example would be if you have a user that can create lists which holds "item" objects....but you're not limiting them to a certain number of items at the list instantiation. You can create the object using the *xxxx to accept any number of arguments. ** is just used when you're accepting keyword values and can use anything as long as it starts with * or **, not just args and kwargs; they are just conventions. 
Is order preserved when an key's value is changed, or does that move it to the "end"?
The gamma function is the analog of factorial to real (and complex) numbers. Go look it up! :)
&gt; I’ll address your concerns in the same order &gt; same order 
I think they probably *could* put FPGAs in every new processor pretty quick if they wanted to, but it seems like for some reason they don't. It probably doesn't matter all that much outside of servers though, because scripting languages seem plenty fast and I'd imagine the "Software seems slow and bloated now" thing is probably more about RAM and disk and cloud APIs.
&gt; Python 2 is retiring in thirty months. Calibre needs to convert to Python 3. Note that the reporter didn't say support. He said convert. &gt; Kovid has stated numerous times that any patches which work towards python3 compatibility without hurting python2 functionality or performance would be happily accepted. Oddly enough, no one has ever taken him up on that, though a number of people have insisted it is *very important* that he himself do that work. People taking things out of context...
Looks like basic stream processing. First argument is a generator that yields the items to be processed. The rest of the arguments are all the processes that the yielded data gets processed with.
&gt; I agree with you. IMO, each "basic" data structure should be a minimal implementation. Then the only data structure you need is the ability to reference objects. Pythons 'basic' objects are so bloated already adding a bit more goodness to one of the already present methods doesn't matter.
Comp sci n00b here. I thought dictionaries were essentially hash-tables, where order isn't preserved? How can you maintain order in a dictionary then, unless adding some overhead to the dictionary object?
It's pretty useful with decorators. Let's say we wish to build a decorator which measures the time it took for a function to execute. Let's say our function is simply def add(a, b): return a + b Here's what the decorator would look like.. from functools import wraps import time def deco(func): @wraps(func) def wrapper(a, b): start = time.time() retval = func(a, b) stop = time.time() print('The function took {} seconds'.format(stop - start)) return retval return wrapper @deco def add(a, b): return a + b Now we make another function called addmore, which adds lets say 3 numbers def addmore(a, b, c): return a + b + c Since this function accepts 3 parameters, our decorator doesn't work with it any longer :( Measuring the time it took a function to execute should be something which is independent of the function. Logically, we just need to start our stopwatch before we enter the function, and stop it when we exit the function. What the function does, how it's made, the parameters it accepts should be none of our business. This is where the `*args, **kwargs` can help us, and it allows us to accept any and all parameters that get thrown at us. Here's how our decorator would look with it.. from functools import wraps import time def deco(func): @wraps(func) def wrapper(*args, **kwargs): start = time.time() retval = func(*args, **kwargs) stop = time.time() print('The function took {} seconds'.format(stop - start)) return retval return wrapper @deco def add(a, b): return a + b @deco def addmore(a, b, c): return a + b + c 
`*args` and `**kwargs` are really important in certain places where you have a variable number of arguments, or you don't know what the arguments will be. A good example is `print`. When you use `print()`, you can pass multiple arguments to it. You can say `print(foo, bar, baz, ...)` and so on. You can go on for as many arguments as you like. How does that work in the print definition? Clearly, print cannot be giving each parameter a name, that would be crazy and wouldn't work for an infinite number of parameters. The answer is \*args. Another example is creating decorators. Decorators take in a function and return a different function, binding it to the name of the original function. Below is an example of a decorator that prints the name of any function that it decorates: def print_name(fn): def print_fn_name(*args, **kwargs): print(fn.__name__) fn(*args, **kwargs) return print_fn_name @print_name def add(x, y): return x + y &gt;&gt;&gt; print(add(1, 2)) add 3 The `@print_name` decorator has no idea about the function it will be taking in, and so has no idea of the arguments that function will have. But it still needs to be able to call the original function as part of its functionality. How does it do that? `*args` and `**kwargs`. 
Still new to python and programming so forgive my question. You're saying the new dictionaries are just as fast as before even though they are ordered? Do they use more memory because they have to store the position of everything?
Numpy does not distinguish between row and column vectors; `df.a_column.values` will give you an array of shape `(m,)`. This is a 1D array as far as numpy is concerned, and transposing it has no effect. You can make these in a natural way, e.g. `arr = np.zeros(10)` will make a `(10,)` 1D array (or vector) of zeros. You can forcibly make a vector that behaves more like an ndarray, e.g. `np.zeros((10, 1)).shape` will make a `(10, 1)` shape array. Transposing it will make a (1, 10)` shaped array, but there is almost no reason to ever use this type of vector in numpy. dot notation to get a column requires that the column name be a valid variable name. Spaces are out, starting with numbers, use of special characters, etc. As best I know, using `loc` or `iloc` in pandas is a bit on the hackier side side you are not using a very pythonic interface that exists more to allow extensions of the pandas api.
fyi, the link to a package on pypi looks like `https://pypi.org/project/%3Cpepy.domain.model.ProjectName%20object%20at%200x7f123ecf59b0%3E/` which is probably not what you want. Looks like something needs `__str__` and/or `__repr__`
Damn this is a cool idea
I think it is great for newbies and people who just need just a little bit of python to do their jobs. I think random dicts violate the principle of least surprise for these two classes of programmer.
A possible solution: have devs use the ordereddict alias if the logic requires order preserved, in case of futute implementation changes
The problem is, that unlike any arbitrary programming language, mathematical notation and jargon are unreadable for me. 
Good bot
i wrote a few scripts, to show that I am not a complete moron, though- I am still very nervous about the whiteboard section. I feel I don't comprehend as well on whiteboards any suggestions on how to overcome that?
You can try a frame as your frontend and use python to send rest api calls.
Actually the ordered approach uses less memory than the previous unordered approach. See here for the original proposal: https://mail.python.org/pipermail/python-dev/2012-December/123028.html Yes dictionaries are essentially a hash map but that is only an implementation detail, there's nothing about the Python language that requires them to be.
&gt;One should be able to swap out a native Python dict for anything that implements a MutableMapping interface. Why? That sounds like a personal interpretation that you're trying to force onto Python. Python doesn't claim that a MutableMapping implements the dict API, so I don't know why you are so adamant to add that requirement.
It's guaranteed on Python 3.7+/CPython 3.6+ if you can guarantee that then you're good, there's no "sorta". This always happens as languages update, I was having to use Python 2.4 for a project a couple of years back and was horrified to find no "defaultdict". In a decade people will of forgotten dict was ever unordered.
Sorry, I didn't realize questions were a no go here. I'll remove it. 
I love this shit so much. So many times I have had to use an ordered dictionary; Just need more motherfuckers to go to 3.7.
No, this was implemented in CPython 3.6, run it yourself: &gt;&gt;&gt; a = {1: 1, 2: 2} &gt;&gt;&gt; b = {2: 2, 1: 1} &gt;&gt;&gt; a == b True Also this is specifically outlined in the documentation: https://docs.python.org/3.7/library/stdtypes.html#mapping-types-dict 
For actual dicts, I would expect no change to order. But you bring up a point: for folks making dict-like objects with `__setitem__`, now you have to wonder and test.
Also check /r/learnpython
Here's a sneak peek of /r/learnpython using the [top posts](https://np.reddit.com/r/learnpython/top/?sort=top&amp;t=year) of the year! \#1: [My new book, "Cracking Codes with Python" is now available and free to read online!](https://np.reddit.com/r/learnpython/comments/7sigre/my_new_book_cracking_codes_with_python_is_now/) \#2: [I'm releasing a free code for the "Automate the Boring Stuff with Python" Udemy course](https://np.reddit.com/r/learnpython/comments/7fxork/im_releasing_a_free_code_for_the_automate_the/) \#3: [I made a python cheat sheet](https://np.reddit.com/r/learnpython/comments/82t191/i_made_a_python_cheat_sheet/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/7o7jnj/blacklist/)
When your script ends, the window it's in no longer needs to be open, so it closes. Run it from the command line. 
&gt;The irony on my complaining about Python ignoring data structure distinctions while failing to make the distinction clear is definitely not lost on me, but I do think the main point stands. I don't know the details of the implementation or the true timing data. But I am with you on the smell test. They sound a little like academics arguing O(2*n*) equals O(*n*). But if it's smaller in space, equal or better in adds and retrievals, maybe taking a hit on removals is okay for most users. Perl had a similar controversy with their hash structures, where they explicitly cause iteration order to be not-merely-undefined but actively different from run to run. This is similar to the way modem OSes protect from snooping and tampering by morphing the memory allocation or link tables. 
Top, for sure. Whitespace is significant. 
Agreed 
This isn't my interpretation. Python documentation says that custom mapping classes should support the same operations as `dict`. &gt; These are the operations that dictionaries support (and therefore, custom mapping types should support too) https://docs.python.org/3/library/stdtypes.html#dict Adding key ordering to dicts makes it harder to build custom mapping classes. In some cases, it may be extremely very difficult / impossible to replicate this functionality. If there were an easy way to tell whether previous developers in a large code base used the key ordering functionality, it would make life easier for others working on their code. Having a separation between dict (key value storage) and OrderedDict (key value storage with key ordering) provides that. I'm not adamant about adding anything to the language. I'm adamant about *keeping out* functionality that makes it more difficult to replace instances of dict with custom mapping classes. I don't know why people are so adamant about adding cruft to one of the most commonly used classes.
&gt; It makes collections.OrderedDict redundant OrderedDicts have different comparison semantics, and are *not* redundant. &gt; It forces developers of other Python interpreters to implement this feature as well The new implementation is a *better* way of implementing dicts, and other implementations and languages will likely be motivated to adopt it (not unlike TimSort). &gt; if Python developers want to change the implementation in future they will have to preserve the order as well. The kwargs ordering requirement essentially forces that on them already.
2/10 no gamma function literally unplayable 3.7! = Γ(4.7) ≅ 15.4314...
Python strikes a balance between being nice for programmers and speed. Ruby as a comparison *always* chooses the programmer no matter what the performance implications are, and that's why it's so much slower than Python.
It's definitely not good to rely on implementation behavior. Python has thrown you a bone and made this a guarantee but only on versions going forward, not previous ones.
Thanks for your response, I made this quickly last night. I will use the tutorial and make the project structured in a suitable and professional manner. Again, thank you :)
I am trying to find the same solution. Did you find a python equivalent or port?
This sounds amazing! I wish Portland were not so far away or I would participate. 
The current implementation is really good. Better than the older, unordered ones. https://youtu.be/p33CVV29OG8 Raymomd Hettinger does an entire hour long talk about dictionaries and somehow makes it worth the watch. Some of the reasons that the current implementation is fast is convered here.
I definitely agree with your logic/points (especially with people starting to rely upon an insertion order for dictionaries when they shouldn't do that). It's even sillier as OrderedDict is readily available, but don't forget that they also cite that the new changes will make the dict: - "between **20% and 25% smaller** compared to Python 3.5" [Python Docs](https://docs.python.org/3.6/whatsnew/3.6.html#whatsnew36-compactdict) - "show large improvements on large and very large dictionaries (particularly, building dictionaries of at **least a couple 100s of items is now twice faster**) and break-even on small ones (between 20% slower and 20% faster depending very much on the usage patterns and sizes of dictionaries)." [Blog Post](https://morepypy.blogspot.com/2015/01/faster-more-memory-efficient-and-more.html). Also, they do clearly state that "The order-preserving aspect of this new implementation is considered an implementation detail and should not be relied upon (this may change in the future..." 
Apparently there isn't that much of a performance benefit; "The memory usage of the new dict() is between 20% and 25% smaller compared to Python 3.5" [Python Docs](https://docs.python.org/3.6/whatsnew/3.6.html#whatsnew36-compactdict). "The microbenchmarks that we did show large improvements on large and very large dictionaries (particularly, building dictionaries of at least a couple 100s of items is now twice faster) and break-even on small ones (between 20% slower and 20% faster depending very much on the usage patterns and sizes of dictionaries). The new dictionaries enable various optimization possibilities which we're going to explore in the near future." [Blog Post](https://morepypy.blogspot.com/2015/01/faster-more-memory-efficient-and-more.html)
&gt; Is order preserved when an key's value is changed Yes, it's key insertion order that's preserved. Changing a value has no effect on the key order (unless you delete the key and re-add it).
"The memory usage of the new dict() is between 20% and 25% smaller compared to Python 3.5." [Python Docs](https://docs.python.org/3.6/whatsnew/3.6.html#whatsnew36-compactdict) "The microbenchmarks that we did show large improvements on large and very large dictionaries (particularly, building dictionaries of at least a couple 100s of items is now twice faster) and break-even on small ones (between 20% slower and 20% faster depending very much on the usage patterns and sizes of dictionaries). The new dictionaries enable various optimization possibilities which we're going to explore in the near future." [Blog](https://morepypy.blogspot.com/2015/01/faster-more-memory-efficient-and-more.html) 
You could give access to the docker daemon to your container, and run the python code in containers as well. It's a bit tricky, but it's doable.
Yeah, but maybe (new) programmers should actually understand the "raw hash table shuffles" before actually using it. We keep on abstracting development - which is good in most cases - but at what point do we stop? This is a fundamental data structure and not learning about hashes or how a Dict/Set works internally might result in not even learning about (hashing) collisions in the first place.
I've commented this a few other times, but: "The memory usage of the new dict() is between 20% and 25% smaller compared to Python 3.5." [Python Docs](https://docs.python.org/3.6/whatsnew/3.6.html#whatsnew36-compactdict) "The microbenchmarks that we did show large improvements on large and very large dictionaries (particularly, building dictionaries of at least a couple 100s of items is now twice faster) and break-even on small ones (between 20% slower and 20% faster depending very much on the usage patterns and sizes of dictionaries). The new dictionaries enable various optimization possibilities which we're going to explore in the near future." [Blog Post](https://morepypy.blogspot.com/2015/01/faster-more-memory-efficient-and-more.html) 
So you make your friends lose their productivity? IFTTT already does this, it also calls you.
While these changes do have [memory](https://docs.python.org/3.6/whatsnew/3.6.html#whatsnew36-compactdict) and [performance](https://morepypy.blogspot.com/2015/01/faster-more-memory-efficient-and-more.html) improvements, Python has had `OrderedDict` with the same syntax for a while. All it takes is another line (an import statement) of code 
At what point do we stop abstracting fundamental CS concepts though? Already Python has non-explicit/dynamic variables (so no one needs to learn about variable types/limits/memory), and now we don't want future developers to understand hashing concepts or how Dicts/Sets work internally? 
They do say: "The order-preserving aspect of this new implementation is considered an implementation detail and should not be relied upon" [Python Blog](https://docs.python.org/3.6/whatsnew/3.6.html#whatsnew36-compactdict) 
For the last ~25 years, dictionaries have been unordered. That is changing in 3.7. So, for the last ~25 years, one could replace a dictionary with a custom mapping class without worrying about ordering. That is changing, with 3.7, and I think it's the wrong decision.
When you want to overload a method in a class and are feeling particularly lazy class A(B): 
&gt;I don't know why people are so adamant about adding cruft to one of the most commonly used classes. I think you're missing the point that this is not "cruft", but that this is a much desired feature. And people are not "adamant" about it; the topic of ordered dicts has been discussed since the beginning of time. Python even had a randomization feature added to prevent people from relying on dict ordering. It has been decided that: 1. It is a useful feature. 2. It is a much-wanted feature. 3. It is currently possible to implement this with very little performance overhead. So after a few decades, Python dicts are finally ordered by default.
Good bot
Sure, and it has been decided that default ordered dicts are valuable for programmers and not that expensive to implement, so that's why this was decided. If GP is looking for a language with "minimal" data structures, then Python is probably the wrong choice.
Carefully thought out &amp; a great introduction. Thanks for posting! I enjoyed reading
&gt;where they changed base assumptions to explicitly cause iteration order to be not-merely-undefined but actively different from run to run Note that the iteration order changing is more a *consequence* of the change rather than the direct intent, and this is actually a change python made too, with the same result prior to the ordered hash changes. The issue was the potential for attackers to force O(n^2 ) performance due to creating deliberately colliding entries, which was prevented by creating a randomised permutation to the hash function, so you get different hashes in seperate runs of the program, which makes it difficult to predict what you need to force collissions. Obviously, different hashes would change the iteration order when you're just walking through the buckets, though the same doesn't apply with the new method (though the hashes still get randomised) 
Hey, Brian, just a quick heads-up: **seperate** is actually spelled **separate**. You can remember it by **-par- in the middle**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
There were a bunch of arguments about this when the implementation showed up. It was pretty obvious that people would eventually come to rely on it, and future implementations would have to be ordered. I think everyone against the idea just gave up trying to argue against a faster implementation with free ordering. 
If you find this a useful feature, I'm glad that I don't work on the same codebase as you. The fork in 2020 can't come soon enough.
I had the same thing happen on my Windows machine at work the other day. Your computer might be trying to use IPv6 to connect to PyPI, but perhaps your ISP doesn't support it. Try running this command: ping pypi.python.org If that says something like destination unreachable, then also try: ping ipv6.google.com Same response? Go into your network adapter settings and disable IPv6.
`open(filename, "rb")` works on Python 2.7 though...
Yeah, I really don't see why this "feature" needed to be pointed out. It should just be a side effect that isn't guaranteed. What about other interpreters like pypy and anything else? Why make it an official part of the language?
Hey, so the project has been restructured and should be up on PyPi under the name py_proxy
I spend a lot of time playing on those code online challenge websites. It tests the correctness of your program by reading it's output. So if I want output for testing/checking something I print to `sys.stderr`. But writing `print(my, variables, etc, file=sys.stderr)` every time is annoying. So I insert this little snippet near the top of every challenge I do. log=lambda *a,**k:print(*a,**k,file=sys.stderr) I basically allows me to use `log()` the exact same way I use `print()` except the `file` keyword argument is always automatically supplied. Which is great because for a lot of the code golf stuff and timed challenges you have to get real comfortable doing things like `for char in string: print(end=char)`.
So you want something to auto label based on what incoming data?
The reporter said convert because Kovid needs to change his code to support Python 3. Future support for Python 2 is irrelevant. If someone wants to use a version of Calibre that supports Python 2 (a version of the software that in 30 months will be unsupported), then they can use an old, unsupported, version of Calibre. If they want bugfixes and new features then they'll need to use Python 3. They've had a decade to refactor, just like Kovid has had a decade to refactor. But instead of refactoring, Kovid has decided to attempt to singlehandedly maintain a massive codebase, all so he can avoid refactoring his e-reader application. tl;dr going through so much effort just to avoid refactoring and breaking python 2 support is silly ¯\_(ツ)_/¯
God damn this is a fast bot.
Its implementation strategy originally came from PyPy, so that is not a concern. Jython and IronPython haven't reached Python 3 yet, so Python 3.7 should give them plenty of time to implement a fairly straightforward data structure.
No, async is single threaded. It's explicit, cooperative multitasking. You either do implicit, pre-emptive multitasking (threads/multiprocessing), implicit cooperative multitasking (gevent/green threads), or explicit, cooperative multitasking (asyncio). With asyncio, you are required to explicitly state when any given code is allowed to execute and when it needs to give up. It makes your code look different, but I actually really like how explicit it is. It makes it much easier for me to reason about asynchronous code if there's no magic scheduler doing things behind the scene.
I never said that it was easy. Easy or hard doesn't factor into it. The organization who supports and develops Python decided that Python 2 will be unsupported in 2020. That means that the huge amount of support currently in place will vanish in 2020. It's his project and he can accept or deny any patches he likes. It sounds like the community *was* interested in sending patches, but not ones that would support Python 2 to his standards. Most people aren't interested in supporting something that will soon be a huge liability. They want to write code optimized for the (soon to be) only supported version of Python. I'm not trying to shame you for your support of Python 2. You are welcome to support it. It sounds like you were pragmatic; there are performance and code clarity compromises that must be made to support both versions. Kovid decided that he does not want to compromise, and that means that the community doesn't want to work with him.
It shoots gamma rays at the number.
OrderedDict equalities are order insensitive
It is a useful feature though, I've used OrderedDict a number of times to essentially have both rankings and a hash table I can snatch stuff out of without having to loop through it. Now we get it with dict. The alternative is a list of tuples of key-value pairs, and maybe an accompanying dict to do O(1) look up, which is cumbersome to maintain. If you want to ignore that dict is insertion ordered, that's fine too. No one is making you treat it as if it were ordered.
The gamma function is *not* a factorial. The factorial simply is not defined outside of ℤ^(0+)
&gt; I would hazard a guess that most people who use Python don't know what a hash map is. That's easy, it a map of where the hashes are. :P
Finished cleaning up the repo, made sure that the integration test for part of the code passes. I couldnt finish up the Pyinstaller installation, compilation because of some other issues. But it is kindof of straightfoward. This week, I am planning of finishing up the Integration testss, then I will work on adding the creation of the exe file, then work on making sure that the previous tests still run fine in the VMs. 
&gt; ctypes /u/Gear5th /u/Eatmeimadanish, in terms of speed and other performance factors, how does PyPy compare to Cython vs ctypes? If you try to write code in Cython, are you basically writing in C?
I wouldn't call dict's interface compared to MutableMapping extensive, the only public methods that dict exposes that MutableMapping doesn't (in 3.6 at least) are fromkeys and copy, one of which is a classmethod. But your main point stands.
The whole point of the post that starting from 3.7 the don't call it an implementation detail anymore: https://docs.python.org/3.7/tutorial/datastructures.html#dictionaries
The whole point of the post that starting from 3.7 the don't call it an implementation detail anymore: https://docs.python.org/3.7/tutorial/datastructures.html#dictionaries
[You are incorrect](https://i.imgur.com/pjOyWUU.png)
What kind of database are you using? I also have a bunch of excel/rrf/csv files, which I am thinking of converting to a properly database like postgres/mysql.. but not sure about the benefits/risks of each solution
Why didn't you use OrderedDict?
You could continue to use OrderedDict or write a custom mapping class that uses an arbitrary function to determine ordering. &gt; If you want to ignore that dict is insertion ordered, that's fine too. No one is making you treat it as if it were ordered. That's the thing. With the change in 3.7, I can no longer ignore ordering when writing custom mapper classes. I have to either implement it, or hope that the existing code doesn't rely on ordering. I've used custom mapping classes to, for example, provide shared key-value stores for multi-process and distributed applications. They're super useful, especially when you can just drop them in where existing code uses dicts. Introducing ordering by default on dicts makes it harder to replace them with custom mapping classes.
Cool.. what is the benefit of this over something like `tmux`?
&gt; A RedisDict should be an out-of-memory implementation of MutableMapping abstract base classes. As such, one should be able to swap out a RedisDict for anything that implements a MutableMapping interface. &gt; It seems asinine to require anything that implements MutableMapping to also maintain a connection to Redis (if it's going to be fully compatible) just because some library implementation of RedisDict makes it convenient to do so. Do you see how silly your argument is? MutableMapping is an interface that tells you what the public interface is and what the relationship between methods are. e.g. when you do `someDict['x'] = 1` and on the next line you do `someDict['x']` 1 should pop out (ignoring race conditions). MutableMapping isn't claiming it's ordered, in-memory or anything else. dict is the thing making those claims because it's the implementation of MutableMapping, it gets to say what's what about itself.
I develop on python 2 because that's what my company uses despite me trying. It actually is easy to support both. Ironically, without me trying the Python 3.6 version is faster than the Python 2.7 one. The only requirement I have is that you don't handicap either. I'm not up on the drama that's going on with calibre, but it seems unnecessary.
That's great, but I really didn't like the Python solution he showed. * Doesn't show imports * Imports collections for counting words. But uses collections.defaultdict instead of collections.counter, which is literally made to do what they're doing. * Poor use of regular expression * Updates `ans` on every loop with max, instead of just calling max at the end. * Uses a method instead of function? Maybe this is a requirement of the challenge I don't know * Blatant syntax error. re.sub() is subbing variable `p` which is never defined. Should be `paragraph` For reference here is the code shown def mostCommonWord(self, paragraph, banned): words = re.sub(r'[^a-zA-Z]', ' ', p).lower().split() m = collections.defaultdict(int) ans = (0, "") for word in words: if word not in banned: m[word] += 1 ans = max (ans, (m[word], word)) return ans[1] Which probably should have been written as import re def most_common_word(paragraph, banned): words = re.sub(r'[^a-z ]', '', paragraph.lower()).split() words = [word for word in words if word not in banned] return max(words, key=words.count) Which is more "pythonic" and follows PEP8.
&gt; You could continue to use OrderedDict or write a custom mapping class that uses an arbitrary function to determine ordering. OrderedDict doesn't have a literal syntax and it requires an import, which neither of these are show stopped but why do that when I can just: `{'x': 1, 'y': 2}`? As for writing my own MutableMapping implementation, I have better things to do than do that. Plus, I don't know where you work, but if I spent a day or even a few hours working on a custom hash table implementation, I'd be laughed at and my manager would probably want to know what the fuck I was thinking. &gt; That's the thing. With the change in 3.7, I can no longer ignore ordering when writing custom mapper classes. I have to either implement it, or hope that the existing code doesn't rely on ordering. This is why I like 3's type annotations and mypy so much. I can tell my user, "Hey, you're getting some random mutable mapping object, be happy with it" or I say, "This is a dict, an honest to god dict". But I still stand by what I said, no one is forcing you to rely on dict's ordering. If you're providing a framework, library or have a plugin architecture I feel for you, but if it's just you and your team, then just tell them "This isn't going to be ordered."
From the perspective of someone who prefers a bit more static typing, I think it's fine for the default implementation to be ordered, as long as the, uh, *conventions and hierarchy* that Python uses don't *assume* ordering by default. That second part might be tricky. 
I have to admit that I did not think about it. I basically wanted to build something that was useful with some easy to understand version constraints that are used elsewhere. But since you mention it, I can see how it would be useful to integrate it in existing tools since it would benefit poetry too in the sense that when packaging poetry has to convert them to PEP 440 compliant version specification. I will think about it, and thanks for mentioning this :-) And don't get me wrong, I do not want to diverge from the standards, I even try to enforce them so that published packages to PyPI have proper metadata for instance, but I just want to improve Python project management by making it painless.
&gt; Plus, I don't know where you work, but if I spent a day or even a few hours working on a custom hash table implementation, I'd be laughed at and my manager would probably want to know what the fuck I was thinking. If you can't implement a custom mapping class in Python using a hashtable in less than an hour, I'm not surprised your boss laughs at you. &gt; This is why I like 3's type annotations and mypy so much. I can tell my user, "Hey, you're getting some random mutable mapping object, be happy with it" or I say, "This is a dict, an honest to god dict". Why should I care the type? If it provides the same interface as a dict, then I should be able to use it like a dict. &gt; But I still stand by what I said, no one is forcing you to rely on dict's ordering. You've missed the point. I don't particularly care whether the dict I use is ordered or not. I care whether the custom mapping class I write needs to implement ordering or not to be treated like a dict.
It is not that Kodi is stubborn. It is that many Calibre's dependencies are still Python2-only.
Upppssss 
We had a few local folks last year who didn't use to dorms. You should jump in our slack channel and we can figure something out :)
love the concept! I'm just finishing high school and Id love to join! is there an age restriction? if not it seems super fun!
Upsss 🙈
Kirby Urner going?
In short, yes. Incoming data is handled via. another script, the idea is to slot this in before it finishes.
&gt; Nice ad hominem there. My ability to implement a hash map wasn't the point there, it's that it's not a productive use of my time. Please. You said this-- &gt; if I spent a day or even a few hours working on a custom hash table implementation, I'd be laughed at and my manager would probably want to know what the fuck I was thinking. The obvious implication is that anyone who spends time working on a custom mapping implementation is worthy of ridicule. You got what you had coming. If it's not a productive use of your time, have a junior do it. Although, if your first thought when you read "ordered data structure" is a hash table, I'm not sure how well that's going to work out. &gt; If you implement MutableMapping, you aren't expected to faithfully recreate dict. Ordering, being a hash map, being in memory are all implementation details that you shouldn't depend on being there if you're expecting a MutableMapping and not a dict. That's the thing. Pre-3.7, I can build a custom mapping class and say, "this implements the same interface as a dict. Just treat it like a dict." After 3.7, the conversation is "Well, this is a MutableMapping. It's kind of like a dict..." This is going to be especially onerous when trying to replace instances of dicts in existing codebases with custom mapping types. Pre-3.6, ordering was undefined, so I can be reasonably sure the original author wasn't relying on it. Post-3.7, the only way to know whether the original author relied on key ordering in a dictionary is going to be to examine the code and/or rely on tests. Do you not see how this is a problem? There's a simple solution too-- just ~~update~~ revert the documentation to say that dict key order is insertion order as an implementation detail but is officially undefined.
All Pythonians are equal, but some Pythonians are more equal than others.
In that case then no, I don't think you should go a machine learning route.
What would you suggest? Without manual input it would be impossible to determine what is the title and what part is the people.
A common comment about Python is that it's optimized for developer time, not run time. If this was truly causing so much confusion that the Python devs felt that it warranted the change, then I think they did the right thing. I can easily believe that way more developer-hours were being spent figuring out that dicts are unordered and how to work around that than run time hours were being saved via the efficiencies of unordered dicts.
&gt;Yeah, but maybe (new) programmers should actually understand the "raw hash table shuffles" before actually using this new ordered dict. 
&gt;&gt;Yeah, but maybe (new) programmers should actually understand the "raw hash table shuffles" before actually using this new ordered dict. I'm not necessarily disagreeing, but one of Python's selling points is being able to stay out of the weeds and this is arguably undercutting that selling point.
&gt; I think Python has always optimized for abstraction even at the cost of performance, and I think that's not necessarily a bad thing. As I've seen it put, you use Python when what's at a premium is developer time, not run time. You can use C++ to make the code run faster...but very often letting the developer finish the code faster and moving onto something else is way more valuable.
This doesn't seem to add much to the process... I could do the same without this library.
ETL is the way to connect the dots rather doing something new. This is how it works. High and complex ETL let you( as a business person or exec) visualize the entire data pipeline.
You can also use it to discard arguments you don't want. Such as those that might be inserted into a callback. ie: def closure(): some_local_var = 0 def callback(*_, **_): do_stuff(some_local_var) some_function(callback)
This is Python. I will assume that the maintainers of most interpreters were consulted. Ordered dicts might be handy in JSON to Python to JSON translations. It also serves to enshrine people relying on the order in the major interpreter - rather like looking for the wear in the grass of a park then creating a better surfaced path along that route. 
Currently we're prototyping a mongodb solution as the content in the matlab-files are structured as documents. Might change as project progresses. As I see it your risk of using a proper database is cost in dollars, whereas the risk of not doing it means when you've gone to a new job the next person might look at your junker-folder and go "who did this and why??" where a database lends itself more to newcomers. If your files are 2-d tables then I'd deffo say sql. If it's n-way data then uhh your milage may vary. 
Was excited about this release, but slightly let down because *only specifying wheels* as build-system requirements are supported in `pyproject.toml`, not source distributions. Any tentative timeline on PEP 517 support?
Well spotted! That was my build process being over zealous. Fixed now.
Hey Sean, have you gotten in touch with Code for Portland, the Code for America branch out there? They might be good to talk to. Also, your faq link goes to .io, not .org. Also, the "Here is the schedule for 2018." link on the /attend page goes to the 2017 schedule, not the 2018 schedule. Cheers!
Ack! It looks like it overlaps with PyOhio. Ah well, it's closer for folks on the west coast.
[Pipenv](https://docs.pipenv.org/) solves all of that and then some.
I use linting in the IDE for this.
pyusb for USB-based keyboard-alike RFID readers. PySerial for UART or UART-USB based RFID readers.
I’ve been using virtualenvwrapper for quite a while now. This is how I approach it: I create a venv for each and every project. I activate them when needed through workon venv_name. And that’s about it. Hope that helps.
I'm keen on using pyenv-virtualenv. Different virtualenv for each application.
Whiteboard sections aren't usually awful, absolutely perfect syntax isn't required. They're usually just there for the interviewer to gauge your problem solving abilities. Try just sketching a few data structures code down on paper. And in the interview, try project your thought process verbally as much as possible.
Not really at the moment. pip is volunteer\-maintained, and very limited on resources, so we rely heavily on community contributions. So I guess the answer is "it depends on how much help gets offered" :\-\)
So what is the Pythonic way of indicating your code relies on this new 3.7 behavior? What happens if you run code that relies on explicit ordering in an older version 3 version? 
Yeah, pipenv is awesome!
I use [virtualenvwrapper](https://virtualenvwrapper.readthedocs.io/en/latest/) everywhere. One virtualenv for each project. I also use the `postactivate` scripts a lot, so whenever I type `workon &lt;project&gt;` I get dropped into the root dir of that project and maybe a text editor opens. But if you're still looking for a workflow, I would check out [pipenv](https://docs.pipenv.org/) as it is the recommended way of doing things now. 
I have at least one virtualenv for every project (sometimes even multiple ones). One of the first things I do on every OS X or Linux box is [installing pyenv](https://github.com/pyenv/pyenv-installer). With [pyenv](https://github.com/yyuu/pyenv) I install the Python versions my projects use (i.e. 2.7.14, 3.6.4 and 3.6.5). Then I use [pyenv-virtualenv](https://github.com/pyenv/pyenv-virtualenv) to manage all the virtual environments (i.e. project1-2.7.14, project1-3.6.5, project2-3.6.4, project2-3.6.5, ...). I'm not sure if I would use it like that on Windows, or when I would do a lot of scientific computing. Maybe then I would use [Anaconda](https://www.anaconda.com/) instead. But for general Python development on OS X and Linux it's the best solution I could find.
Pipenv is definitely the best thing out there.
That requires other implementations to use extra memory/space when they otherwise wouldn't have needed to.
Linux: pyenv + pipenv (separate virtualenv for every project) Windows: miniconda
vovanz commented on using OrderedDict() vs dict() and I commented on that.
Thanks for the laugh, I've never considered something like this
Next, we need indexing starting from 1!
 &gt; 1! 1! = 1 
I think I tried using that, but I wasn't able to send 2 bytes numbers (or the baud rate was too slow)
That metaphorce though...
In addition to wrapping, whenever you need to have rather arbitrary set of inputs, like in dict(one=1, two=2, three=3). 
Was not aware it existed.
Sure. The [matplotlib gallery](https://matplotlib.org/gallery.html) has huge number of samples with the code that produces them. Have a look. [This one looks interesting](https://matplotlib.org/examples/subplots_axes_and_figures/subplot_demo.html).
Any idea if there's an insertAt() to either replace at an index or to shift everything along one? I guess it would essentially be creating a new dict.
While true, the use cases where memory is scarce enough for that to be non-negligible are not really use cases that hashmaps or Python are good for.
Your "examples" link gets a 404.
In an 'if' block the 'else' is optional. You only need the 'if' in sections like this: if show_steps == 1: print("atk:", atk_units, "def:", def_units) else: 1 
[removed]
On the point of code quality and maintainability you would profit from not repeating many of the similar if cases, which lead to these kind of faults easily. If I were you at this point, I'd take a step back from solving the code in its current form and focus on breaking out the repeating pattern, it might solve itself doing that. A mockup of a method I'm having in mind, using attacker and defender as small classes having units as attributes for the battle: def perform_action(attacker, defender, attack_dice, defence_dice, show_steps=False): """ attack_dice - descending sorted list of integers representing dice values. defence_dice - descending sorted list of integers representing dice values. show_steps - if True enable verbose output. """ for i, defence_die in enumerate(defence_dice): if defence_die &gt;= attack_dice[i]: # defence wins attacker.units -= 1 else: defender.units -= 1 if show_steps: print(attack_dice, defence_dice) if attacker.units &lt; 2 or defender.units == 0: # attacker can't continue with attack, or defender is defeated, we're done. return
Are they google analytics related? If so, that's not surprising since it's a google product...
when using a variable to decide whether or not to perform a series of instructions, such as "ok_u", or "show_steps" in your case, you should use booleans instead of integers (0,1). I would add that "ok_u" is a pretty unclear variable name. It's okay to have longer, more explicit names such as your "show_steps", and it reads a lot better. You could also avoid code repetitions (see die initialization for example) by using tuples, or named tuples, or list, or any container at all to store your atk and def values. Then you can use numpy.random.randint to generate a bunch of values at once. E.g : from numpy.random import randint atk_dice = tuple(randint(1, 6, 3))
Do you have an example for this or can you elaborate it more accurate, I am pretty new to python programming. 
Ok will definetly look into that, thank you for your help. I am pretty new to programming and haven´t worked with functions yet, so I made it with the "if" statments.
You probably meant ***DEFINITELY*** -not *'definetly'* --------------------------------------- ^^^Beep *^^boop. ^^^I ^^^am ^^a* ^^bot ^^whose ^^^mission ^^is ^^to ^^^correct ^^your ^^^spelling. ^^This ^^^action ^^was ^^^performed ^^automatically. ^^Contact ^^^me ^^^if ^^I ^^^made ^^^A ^^mistake ^^or ^^^just ^^downvote ^^^^^^please ^^^^^don't
Is this an ad? 
I imagine that many people will say "go with pipenv", "pipenv is the best and only one", well, [pipenv](https://docs.pipenv.org/) can be an option, but for me is too much only one tool for many things, sometring that i don't like very much as linux user/developer. I manage several python versions with [pyenv](https://github.com/pyenv/pyenv) for every project i create a virtualenv with [pyenv-virtualenv](https://github.com/pyenv/pyenv-virtualenv) plugin. To cleanup my packages installed in every venv i use [pip-tools](https://github.com/jazzband/pip-tools/) to uninstall every egg dont needed really by my project, I can say that to me, is more easy to manage a requirement.in/requirements.txt file that the Pipfile/Pipfile.lock proposition with pipenv.
Ok thank you for your help. I will rename my variables to more clearer names. And if I wanted to use booleans, how would that look respectively what must the user enter then? I don´t know tuples, because I am not so experienced in python yet. Which modules must I import for them?
I think so 
I don't think so. "Simple scripting" tells me that you have the ability to automate redundant daily tasks. If you had the knowledge of interfaces any possible interface you'd need, you would be doing more than "simple scripting."
I would expect "simple scripting" to be like system automation stuff. Using data structures and numbers I would call maybe more like "data analysis" or "algorithm development"...if you otherwise have some subject matter expertise (i.e. a bio degree or whatever).
For the boolean usage, let's take your "show step" as an example : # init from input, defaulting to False [n] as in your current code show_steps = input("Show intermediate steps ? [n]/y ").lower() == 'y' # later, when using the variable as a condition if show_steps: #instructions ... See ? the nice thing with booleans is that you can assign them to conditions (here an '==' comparison) and later use them in place of that condition, without the need to reevaluate them :) As I don't get what you use "ok_u" for, I won't guess which value, 0 or 1, should correspond to True or False respectively, but know that in any case, booleans allow you to write : if not ok_u: #is exactly equivalent to "if ok_u == False" #instructions ... tuple is a builtin type, no import required :)
the figures are plots meant to be used in a report, which are then going to be selected to be used in a paper to be published in a journal. The point is to have the plots tabbed in a single window for review. [This is an example of how matlab does it](https://imgur.com/a/3c8U3), you can see that 32 plots are placed into tabs inside that one window. I was hoping this was something that was already implemented in matplotlib (or spyder) . Maybe implementing this would be an interesting project for the future, but right now I don' t have time to do this. 
The account is 12 days old... 🤔
I'm partial to jupyter lab for data analysis and plotting. The jupyter notebook is a cell based interactive kernel that displays in the browser. So matplotlib plots just show up after the cell they're made in. 
It's more fair to compare math to a gigantic code base that has been around for thousands of years \- abstracting over itself forever.
hey thanks for the reply!! essentially I need to simulate the movement of mobile sebsor nodes through a water network and record behaviours like movement and if they pass certain points in the network.
Ooh, that sounds like a fun problem. Here's how I determine between discrete event sims (DES) and the time-stepped (Mesa)*. First, is the behavior of what you are trying to model occurring over short time scales? Motion usually is, but is it possible to abstract that out? Let's say you have a sensor going through pipes, and it comes up to a junction. If you can assign a probability that it takes one path over another, you can use a DES to queue up the time the sensor will reach a fork. Once it reaches the fork, decide the new path and queue up the event for when it reaches another fork. However, if your sensors are always communicating and gathering data (and you need to model that), then a time-stepped simulation is probably better, since you'll be running comms and sensing functions each time step. * Mesa is usually referred to as 'agent-based', but agent is a term that means more about behavior rather than simulation framework. I can have agent-like behavior in a DES.
The biggest advantage is consistent dependency locking, but managing virtualenv is another big feature.
Single letter variable/module names are awful to read.
We need to go deeper.
Here's a sneak peek of /r/CFD using the [top posts](https://np.reddit.com/r/CFD/top/?sort=top&amp;t=year) of the year! \#1: [Wind turbine Wake Breakdown](http://i.imgur.com/5SpZDiZ.gifv) | [14 comments](https://np.reddit.com/r/CFD/comments/6rx0c3/wind_turbine_wake_breakdown/) \#2: [I'm pretty sure CFD engineers at Siemens/CD-Adapco are redditors](https://i.redd.it/2hfe108woxnz.png) | [10 comments](https://np.reddit.com/r/CFD/comments/729er8/im_pretty_sure_cfd_engineers_at_siemenscdadapco/) \#3: [I'm making a series of videos on the Navier-Stokes equations](https://www.youtube.com/watch?v=TQVXgeSKYgo&amp;list=PLk6862aQUc73Di_j9-vrXa6-W5-xSSw0j&amp;index=7) | [2 comments](https://np.reddit.com/r/CFD/comments/8b7gpv/im_making_a_series_of_videos_on_the_navierstokes/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/7o7jnj/blacklist/)
Alternate constructor? I don't think you want different names for your multiple constructors. That said, in Python if you *do* want alternate constructors, yes, you have to give them different names, but it's a PITA, imho.
Thanks! Last year we ran the same event but it was "Code for Good" and I guess we missed a couple things on the website! Great advice on pinging the Code for America folks, I'm sure there is definitely overlap!
For this I would ask a candidate to do something like 'request this http api endpoint for a version number, fill in version number to this http endpoint to request the *current version* of a tarball.' if they can whiteboard this or something similar I would start asking about how to implement error handling for the requests, then the system IO calls (writing the tarball.) If they do that quickly I'll drop into unpacking the tar and stubbing in some config files or something then installing. if they superstar the previous sections i move into writing a tool that can properly start up and daemon-ize the service you just built from the tarball contents. things like how to execute as root and read in privileged files before switching access roles to a non-privileged user. forking vs threading, proper signal handling, shutdown and cleanup.
Last year we had a couple of people who had just finished high school and were at Reed for summer program on game design so I think it shouldn't be problem. Our biggest requirement is that you want to do good! However, I will confirm with the venue to ensure there are no issues!
You could just pass the output of correlate to numpy.max() to get the maximum correlation value. 
It would depend n what sort of job you'd applied to. Network admin? Make me a script to collect the host names, ip addresses, version numbers of all our switches/routers. Some sort of accounting job? Take this CSV file from supplier A and output a new CSV in a different format for supplier B.
Thank you for your detailed explanation. I will try that method in the next version of my code. 
You're still welcome to contribute to the projects we work on! :) I know that our project for [Sisters of the Road](https://github.com/codeforgoodconf/sisters-of-the-road-admin/issues) (a soup kitchen) has some open issues that they could use some help on! 
I've read enough of python-dev to get the impression that lots of things get signed off simply because people are tired of arguing.
I agree with this, I have no use for dorms since I don't live that far.
happy to help.
Cool! I should really start playing with gui frameworks instead of just throwing all my apps into Flask lol. Any reason why you didn't use PRAW instead of a browser?
I find the example code to be far harder to read than the typical style. I don't see how it solves any problem aside from typing less.
Quote: Now you’ve got the idea of: Python nested for loops and for loops and if statements combined. They are not necessarily considered to be Python basics; this is more like a transition to the intermediate level. Using them requires a solid understanding of Python3’s logic – and a lot of practicing, too. This is not Python basics? And it requires a solid understanding of Python's logic? I can understand the need for basic tutorials, but the readers shouldn't be fooled into thinking they are now intermidiate data scientists just because they can nest for loops and use if statements inside loops. 
The Reddit API gives you the self posts (like this one) text in 2 formats. Plain and HTML-ish. It looks really bad when you want to show the text in a regular text control. And rich text controls don't support HTML tags. The only solution was to use a webview to fetch it the HTML text. Since this app doesn't require too much from Reddit (only 2 simple get requests) I used Requests instead of PRAW.
Gotcha. That makes sense. 
This lib provide new class based view that split request processing into steps: parsing, validation, main logic, response validation and rendering :) 
Awesome! This would be very helpful for web apps that have alot of business logic in the views! Don't mind if I do :) thank you!
Hey, hpca, just a quick heads-up: **alot** is actually spelled **a lot**. You can remember it by **it is one lot, 'a lot'**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
Frameworks for Django REST Framework already exists ;) DjBurger not exactly framework. This is one class based view, one simple philosophy, five interfaces definition (decorator, parser, validator, controller, renderer) and some useful components with this interfaces.
It can go both ways. I've seen Java code that is completely and utterly crazy with overloads. It was overly complex for no reason. It is almost a balance. At times I wish Python had static compilation to find obscure bugs. Then I wish Java was less of an annoying language for other things. :) 
Documentation provide [solved problems chapter](https://djburger.readthedocs.io/en/latest/philosophy.html#solved-problems). You can find it useful.
Haha, I'm referring to the recent amusement with npm and `is_odd`, `is_even` 
&gt; Decorators (d). Feel free to use any side Django decorators like csrf_exempt. &gt; Parser (p). Parse request body. What if you want a decorator that does something to the parsed body? For example, checks an authentication token passed in through the body, not the headers? 
Oh. I understood that for the past X years dictionaries had been ordered but that was an implementation detail and not one that was guaranteed by the spec. So all previous uses of a dict could be replaced by a custom mapping class. Now going forward this ordering if required and therefore any usage must provide insertion ordering or else the code must explicitly use an unordered implementation.
These are the absolute basics. It has absolutely nothing to do with "data science". The title is misleading at best.
You can wrap parser or controller: p=some_decorator(some_parser)
real usage as where you write and never look at the code again? shortcuts are bad, especially very non-intuitive ones.
It will take some massive improvements to portal and esri altering how licensing works before most places switch to pr
You're right. I think how I can made documentation more readable. Thank you! 
I would reject this entire library on this complaint alone. Single letter names are not names, they are code obfuscation mechanisms.
Yeah, that's what I'm doing. Although I don't think it returns the correlation coefficient, as it returns an array of numbers on the scale of Ne+32 (the max being 3.91397e+32). I am understanding this wrong?
Al, if you allow me to make a personal plea to come to Portland, I'd love to meet you. Plus pycon will have been in Cleveland a few months prior!
That's not "simple scripting". It's not exactly god-tier, requirements-wise, but it's fairly well beyond simple.
&gt;djburger.p I don't want to dig through documentation every 30 seconds to decipher what a 'djburger.p' is, that is absolutely not acceptable. Especially once you get multiple idiotic names like that floating around and I'm spending more brain power tracking what they are and not enough on understanding what the code is doing. Long names are tedious to type out, but the time 'wasted' typing them is \_significantly\_ lower than the time wasted trying to decipher the obfuscation you've introduced. IDEs offer smart auto\-completion for a reason!
I don't mind the single-character shortcuts if you're frequently using those modules, but why not leave it up to the user? import foo.bar.spam as f 
Sorry lol, I didn't get that this is what you wanted to say at first
I'm not a huge fan. As /u/TBSchemer brought up, that confuses equality. Since two ordered dictionaries, with different ordering values, are still equal, there's arguably some undesirable type coercion there. And in practical terms, this means that people will write Python 3.7 libraries, depend on ordered dicts, and they'll just flat-out break in Python 3.4 in unexpected ways. That was okay in Python 3.6 when ordering was a coincidence of implementation, but now that it's a documented feature, people will start to depend on it and might not think to add an assert about the Python version.
Confirmed on [status.python.org](https://status.python.org/), they're looking into it.
As someone that works on a large Django codebase, I don't think this would solve the issues we have. Our views are typically small, and we don't do a lot in the request response cycle. There are a few custom middlewares for site\-wide customisation, and we use some custom decorators for permissions and access control, but apart from that not much. The thing that makes our Django codebase scale is Django apps. We have \~370 apps in our codebase \(according to INSTALLED\_APPS\), and each is small and well focused, and nested appropriately in a hierarchy of apps. 
Alright, so I think I have it figured out after reading [this stackexchange post.](https://dsp.stackexchange.com/questions/9797/cross-correlation-peak) I have two datasets, ace_window and wind_window: correlation = signal.correlate(wind_window, ace_window, mode='same', method='fft') best_shift = np.max(correlation) wind_max = np.sqrt(np.max(signal.correlate(wind_window, wind_window, mode='same', method='fft'))) ace_max = np.sqrt(np.max(signal.correlate(ace_window, ace_window, mode='same', method='fft'))) corrcoef = best_shift / ( wind_max * ace_max ) Corrcoef gives a value under 1, which is what I'm looking for.
For module names, 100% agree like in this case. But for variables, single letter names have a several use cases where they are appropriate and quite readable: * well-established conventions (e.g., using `p`, `q`, `N`, `e`, `d` in an RSA application), * for index variables (e.g., `for i, value in enumerate(my_list):` * one-line expressions: `lower_case_words = [w.lower() for w in words]` * or variables only used in one-local spot, where context makes the meaning of the variable exceedingly clear: for d in list_of_dicts: for k,v in d.items(): d[k] = preprocess_values(v) other_stuff() 
Fixed redirects, now I get 404's -.-
Every 30 seconds? Seriously? It's just five simple abbrs: D.ecorator, P.arser, V.alidator, C.ontroller and R.enderer. And your IDE can explain it, because all one letter aliases - just aliases for long names, no more.
&gt; Dict is more-or-less the canonical implementation of a mapping class. Therein lies your error. 
I don’t find any sense in that. It adds complexity and removes readability. Removing 30 seconds of development adds 5 hours on maintenance....
Ah yes. Scipy gives you an unnormalized correlation. Normalizing by the square root f the autocorrelations normalizes it. 
Just five framework-level abbrs. I don't use any one-letter-names in any other places except some short iterators. But "pre_validation_renderer" kwarg name very ugly. I'm made many variants. I'm collect many feedback. Users don't want it. 
It might be best to list those skills out explicitly instead of just "simple scripting" That way there's less ambiguity. Also would be good to think of past projects where you used those skills.
Very cool. RL anyone?
&gt; OrderedDict equalities are order insensitive The [docs](https://docs.python.org/3/library/collections.html#collections.OrderedDict) state otherwise (emphasis mine) . &gt; Equality tests between OrderedDict objects are **order-sensitive** and are implemented as `list(od1.items())==list(od2.items())`. 
If someone is experimenting at the interactive prompt and sees the default dictionary preserving order, they're not necessarily going to read the docs to see whether that's guaranteed behavior. Some users are going to, whether intentionally or not, rely on what they see the code doing. Compare http://www.ibiblio.org/xml/slides/xmlonesanjose2001/xlinks/89.html
This post is better suited for r/learnpython 
Yeah. ATM I'm getting 503's trying to do anything.
[Github issue](https://github.com/pypa/warehouse/issues/3705)
&gt; Doesn't this approach make the dict more compact only if the first array stores the original data ? Yep, you're correct. In the new implementation, only the first array stores the key-value pairs. While the second array does map from keys to indices, it does so implicitly. The array itself contains only the indices: it's just an array of ints. We perform the mapping by calling the hash function on the key. The original blog post from the PyPi developers has a good analysis of how this new scheme saves space, along with a few more details: https://morepypy.blogspot.jp/2015/01/faster-more-memory-efficient-and-more.html
What do you mean by "replace at an index"? A dict doesn't have any notion of what an "index" is. Or are you asking if there's a way to add a key-value pair so that it appears in a particular spot when you're iterating over the dict? Well, I suppose it's not impossible to implement such a thing with enough effort, but doing so would break the new dict guarantees. After all, the new dict is supposed to preserve the order in which you insert items. 
&gt; If dicts are ordered, then the ordering is part of the value. I think "dicts are ordered" is an unfortunate summary of a weaker claim that iteration order follows key insertion order in Python 3.7's implementation of dict and from now on you can rely on that implementation detail. Note that doesn't say anything about equality, it's just about the relationship between insertion and iteration.
That's a nuanced, but fair point.
Looks like it's fixed now. 
Thanks, hope you find it of use (:
Thank you. I use OrderedDict plenty, but there are simply many other occasions where it would be handy to have ordering hold in the dicts _everyone_ else is using, too. Again, I don't think all these times it would be handy become clear to a person until that's the default system-wide.
What's the point of kitchens when we have Burger King?
Mash together a script in 5 minutes to download 10 last videos from a youtube channel. Be able to google the best tools for the task and use them without hesitation.
https://www.python.org/psf/donations/
Then you have `prev` which will be commonly interpreted as `previous ` but stands for pre validation when, from the description, it actually validates. The same for `prer` which is also just a weird abbreviation. And there's also their post counterparts that also validate and render, respectively It's already mangled and inconsistent. And it's not even off the ground. I think you should maybe listen to the people urging you to go with verbose names. When python developers of all people want verbosity, I think you should take heed
&gt; open to suggestions. Put it together from existing monitoring and reporting tools. Building this from scratch would be ridiculous.
From the point of view of the business, it may very well have been a waste of time for you to duplicate existing software. From your point of view, re-inventing wheels can be a great way to learn. From the point of view of society, it’s very good to have many tools and approaches for solving problems and making new things. BI didn’t just spring to life out of nowhere - it was built using languages and libraries just like everything else.
Artifactory pays for itself with one of these kind of incidents. (The Pro version anyways, enterprise costs 10x as much). It costs $3k when 10 developers spend an hour trying to pip install or npm install or apt-get install anything because the public servers aren't responding fast enough.