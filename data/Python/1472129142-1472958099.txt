&gt; anemic object I believe you mean a `namedtuple`.
Haha kind of what I was thinking but I feel like it's one of those situations where this stuff isn't so obvious to novices. If not particularly informative for me, it was written nice and clearly ;)
The vast majority of the text is using Source Sans Pro. The headings for the smaller sections are in Flux, and the serif font (e.g. for the block quote) is a web-safe stack that will be Georgia on OS X / Windows machines or the system default serif where Georgia is not available. Of course, this is presuming that your browser is rendering web fonts for Source Sans Pro &amp; Flux.
is there a medium.com article where I can read more about it? :)
Or, better, [attrs](https://pypi.python.org/pypi/attrs)
Clearly that's arguable. It sounds like it's too linked to one's sense of aesthetics to be decided.
Hello sysadmins and crawler developers, what about sharing your recommended practices for web crawling here?
So where in your example would you use objects? What would they do? I'd argue more that the example is a reason to use defaultdict rather than a reason to encapsulate things in an object.
I'm going to guess OP isn't the author, so these comments are probably not going to be seen. The author explicitly asks for suggestions as this is his first python project, but it seems he would rather have them as pull requests.
I had actually changed the function to use `setdefault` instead of the if checks, but forgot to update the code :) Will try to change the code to fit my idea.
https://docs.python.org/3/library/functions.html#print &gt; All non-keyword arguments are converted to strings like str() does and written to the stream, separated by sep and followed by end.
Enh, `namedtuple` is built in.
because programming languages don't do notation with commas to separate thousands. the computer sees 3 separate values: `2`, `000`, `000` (000 = 0) Either type 2000000 or enclose your number in ""
You no longer need an empty init file to make a folder importable, and thank god 
neat
I like VIM, but this is PURE MASOCHISM!!!
Sure, but namedtuple should be only used as a temporary refactoring solution rather than a permanent one due to quirks like: &gt;&gt;&gt; from collections import namedtuple &gt;&gt;&gt; Point = namedtuple('Point', ['x', 'y']) &gt;&gt;&gt; Time = namedtuple('Time', ['hours', 'minutes']) &gt;&gt;&gt; Point(7, 40) == Time(7, 40) True
namedtuple is a quite thin wrapper around a normal tuple. Its only function is a bit nicer repr and named field access. Otherwise they are designed to be fully equivalent to normal tuples. Point(7, 40) is identical to (7,40). Time(7, 40) is also identical to (7, 40). Both coerce to the same tuple and are compared equal.
Very low level. Fonts in Cairo are stupidly annoying too. I was drawing multi-layer floorplans. I didn't really know what else to use and it did work. I'm OK with C and that might have made it more acceptable for me.
Sounds like you've described engineering. In what order should the parts on a car be attached?
Exactly, sometimes you just need some data. For example, we have a simple server health dashboard. I just want information like is it up, what's on it, if there's nodes their status. No need for a full fledged object there. Other times, you do want to control invariants and access, so an object does make sense. 
swenty covered a lot of good points. The explanations on the main site are pretty good, although they could be much better by adding references to supporting papers/texts, and definitions for each symbol (maybe a master notation list somewhere and links to it). At a bare minimum, all acronyms need to be defined (especially when used as class names). The mathematics behind each model written out explicitly. All this stuff seems to be in the main site, but not in Sphinx docs. Which is okay, but then they should be linked back so it's easy for programmers to find that info. I can speak for myself when I say all criticism is intended as fully constructive, I'm guessing most commenters feel the same way. Thank you for writing this library, we're grateful for whatever you can add :-).
thanks that worked. appreciate it
Thanks for the hints, will have a look.
I made that mistake and already posted to LearnPython after figuring that out
Inheritance in and of itself isn't bad. There's a time and a place for it. Some problems are easier solved with inheritance and others with composition. That's not to say that inheritance (and in particular multiple inheritance) can't be misused. A class with twenty incestuous parents is certainly a problem -- take Django's and DRF's Generic Class views for example, those things give me a headache. But a class with a small, straightforward inheritance chain probably isn't -- for example I needed to log raw requests and responses in Requests Session class, it much easier to extend the class and drop my logging there than wrap up in a separate class.
This looks very good! Thanks! 
Yes, you can. Have a look at the MediaPipeline: http://doc.scrapy.org/en/latest/topics/media-pipeline.html
Ok I have been playing with it a bit now, and I have to say - this is an AMAZING library! Thanks a lot!
Been announced [quite](https://www.reddit.com/r/Python/comments/4wbky1/the_pypy_project_gets_200000_from_mozilla/?ref=search_posts) a [few](https://www.reddit.com/r/Python/comments/4wwttd/pypy_gets_funding_from_mozilla_for_python_35/?ref=search_posts) times [here](https://www.reddit.com/r/Python/comments/4wx94z/pypy_gets_200k_funding_from_mozilla_for_python_35/?ref=search_posts)
where you trying to install it along with python 3? Because I think I might be in the same boat as you. Care to share your route?
Huh? That's literally the first rule of web crawlers. And it's not binding in any way, but by disregarding it you can cause trouble for website admins and (if they're on the ball) get your scraper throttled or banned from the site. 
But there wasn't any repo or buildbot links
Don't get me wrong, I believe in using the right tool for the job :) The list in no particular order, as I use these features all the time: * Integrated debugging (mega dope, as you can step through/out/in, run expressions) * Live error check * Code completition/generation * Code navigation (ctrl+click'ing somewhere) * Refactoring (mega dope) Pycharm specific: * Clickable tracebacks * Navigate to (best feature imho. supports CamelCase, "fp" matches FontProvider, looks up class names, files, etc. Sublime's cmd+p on steroids)
&gt; The most obvious effect of this is that files are not promptly closed when they go out of scope. This problem is common to many alternative implementations of python, and even cpython itself if you have circular references. The `with` statement has been around since python 2.5, and in my experience it's rare to see an `open` without a `with` nowadays. Is it really that common for otherwise competent python programmers to expect python objects to behave exactly like C++ ones?
An alternative would be making `==` with named tuples involved non-transitive.
Windows 10, I get this error when trying to install Scrapy http://imgur.com/a/qrgTC I have python 3.5 up and running in my computer. I read that Scrapy was incompatible with python but looking at the documentation for Scrapy it says that Python 3 support was added in Scrapy 1.1. So I did more research and saw that I need to install the Microsoft Visual C++ Build Tools, which I did, and I'm still having trouble with the installation
Scrapy doesn't work on Python 3 on Windows yet. Follow this instructions here to install it using Py2.7.
Why isn't the function just: def isBoolean(obj): return obj in ('true', 'false', True, False) It seems intentional but I can't think of a reason why you wouldn't want that. 
As a data scientist, I've definitely been in this situation. If you need the data and they don't provide some sort of dump or API, you really don't have much choice. I just try to write my crawler as efficiently as possible to avoid pissing anyone off.
Glad it's working out for you! I'll have to try it out soon.
Would love to read a more detailed post about this sometime, without any prop details ofc!
I'm still hoping for a revival of trinary logic, just for the confusion it would bring.
What I've done in the past is to build my own scatter plot. It's ugly, but not too hard. (I can't find my example code or i'd post it). Make a function that takes a matplotlib axis and your data, and tell it how many colors and sizes to create. You've then got to calculate masks that put your data into size and color bins, then plot each combination of color and axis. I find that by doing that I can easily get a 10x speedup over standard scatter, while still looking pretty good. Edit: Here's some ugly code I found. import numpy as np import matplotlib.pyplot as plt from matplotlib.pyplot import cm def fast_scatter( ax, x_vals, y_vals, color_vals, size_vals, num_colors=8, num_sizes=8, size_min=0, size_max=50 ): # calculate a series of masks on color color_masks = [] min_color_val = color_vals.min() max_color_val = color_vals.max() color_idxs = np.linspace(min_color_val, max_color_val, num_colors) for i, val in enumerate(color_idxs[1:]): mask = (color_vals &gt; color_idxs[i-1]) &amp; (color_vals &lt;= color_idxs[i]) color_masks.append(mask) # calculate a series of masks on size size_masks = [] size_min_val = size_vals.min() size_max_val = size_vals.max() size_idxs = np.linspace(size_min_val, size_max_val, num_sizes) for i, val in enumerate(size_idxs[1:]): mask = (size_vals &gt; size_idxs[i-1]) &amp; (size_vals &lt;= size_idxs[i]) size_masks.append(mask) sizes = np.linspace(size_min, size_max, num_sizes) colors = iter(cm.rainbow(np.linspace(0,1,num_colors))) for idx, mask in enumerate(color_masks): #color_idx = idx % len(_colors) c = next(colors) for idx2, mask2 in enumerate(size_masks): m = mask &amp; mask2 size = sizes[idx2] ax.plot(x_vals[m], y_vals[m], c=c, marker='.', linestyle='None', markersize = size) # end fast_scatter if __name__=="__main__": x_vals = np.arange(10000) y_vals = np.random.random(10000) color_inputs = np.random.random(10000) size_inputs = np.random.random(10000) fig = plt.figure() ax = fig.add_subplot(111) fast_scatter( ax, x_vals, y_vals, color_inputs, size_inputs, 8, 16 ) plt.show() 
Oh, good. Now suppose you don't happen (As usual) to need to block and copy EXACTLY two pages of text. Do you have such a shortcut to select the 17th letter of the 11th line through to the 66th letter of the 37th line? Because that's really easy with a mouse.
Just in case you're unaware, the `abc` and `numbers` modules can sometimes be helpful for this kind of thing. Your code really doesn't seem to be doing anything sensible, though. It would return True if `reference` was `True` and `test` was "false", and if they were both integers it would try and check whether they were the same to within `self.tolerance`. Also, simply checking that the absolute difference between two floats is below a certain threshold only makes sense if your floats are all roughly the same size. For example, if `self.tolerance` was `1e-5`, then you would return True if the two numbers were `-1e-6` and `1e-6`, but not if they were `1e8` and `1.000001e8`, which probably isn't what you want.
Didn't understand all of that,old boy. I assume that like me English is a second language for you.
Thank you for being a polite user on reddit! --- *This bot was created by [kooldawgstar](http://reddit.com/u/kooldawgstar), if this bot is an annoyance to your subreddit feel free to ban it. [Source](http://www.github.com/kooldawgstar/PoliteUsersBot)*
yeap! im not the author submit a issue
You can reduce `isNumeric` to def isNumeric(obj): return isinstance(obj, (int, float)) It doesn't help you with booleans, but it's much easier to maintain when new types need to be checked.
something like g = df.groupby('z') for i, (name, group) in enumerate(g): plt.plot(group.x,group.y,'.',ms=1, color=colors[i])
this just in: R loves python
For isNumeric, you might prefer: def is_numeric(obj): return isinstance(obj, numbers.Real)
Majorities of websites actually expecting web crawling - booking, github, agoda and many many others. They don't ban your IP even if you crawling them using decent amount of concurrent threads. &gt; if you're crawling many pages of a domain without some sort of delay time, and you haven't identified yourself, you could be mistaken for a DDOS attempt websites should provide pages caching mechanism. especially if you expecting traffic and decent load.
I get not wanting to write Javascript, but it's really not as completely terrible as everyone makes it out to be. And worse, even something breaks you won't know enough Javascript to debug it. 
Check out PEP 420. [Modules And Packages: Live and Let Die by David Beazley](https://youtu.be/0oTh1CXRaQ0) touches on this as well. 
Can I share example code with her over code academy?
https://www.youtube.com/watch?v=qLkhx0eqK5w
The one I put together was an opinionated pattern for creating a dockerized python app, after working through the various options (conda, pyenv, apt-get), specifically built around using the conda environment yaml file that can be generated. This handles both the conda and pip requirements, in addition to the smaller overall base image size, which matters more when dealing with distribution to lots of machines. Most people think they need to create conda packages for everything. I'm more of the opinion that you use conda packages where it makes sense, usually for packages with complex requirements, often already on conda, then use pip for everything else. So, with this you don't deal with pip and conda stuff separate, you have a single file that handles both. So, if you look at the example docker container for the hello world, this makes things super simple and all of that is pre-configured. Continuum distributes images that are just basic debian builds with anaconda/miniconda, which then anything can be done with. I probably should setup another image that builds off of this as an option. This starts from, what is a clean pattern for deploying a dockerized python app, and walks you through discrete steps. I specifically was aiming to avoid having build requirements in the image and having to recompile python dependencies on each change to the base image.
Try Nitrous. When I used it in the past it was pretty convenient. A cloud based IDE with a free plan (which would probably be enough for what you want to do). https://www.nitrous.io/
As a maintainer of a package that works best as a binary distribution I want to point you toward Jake's comments at the end regarding what each can learn from other -- particularly about the building packages for PyPI and conda-forge. Here's my experience: Windows was the bane of my existence -- the build system for Cython packages on Windows is a little different and a little quirky. The number of bugs reported due to the source package on pip not working properly on Windows were just too numerous. So obviously I need to produce some binary packages. Except I'm a mathematician, not a developer, and I can barely get packages made and uploaded to PyPI. I don't have access to any Windows machines, let alone several versions of Windows and several versions of Python. I certainly struggle to cover all the flavours of Linux, and multiple Mac versions. In practice I can build a wheel on my home linux box and that's about it. That doesn't help many people. Now there's the manylinux docker image, but I would have to figure out how to use that. And then, one day, someone told me about conda-forge. They worry a lot about building binary packages. So I submitted a pull request with a recipe for building my package, worked through the details with some helpful people, and ... that was it. Now magically I get my package built for Linux, Mac, and Windows with different Python versions, and all automatically uploaded to the conda-forge channel. Suddenly binary packaging for diverse platforms became straightforward. So yes, binary wheels are great, and we should use them. As a (unskilled) developer however, the experience of building binary packages for conda and conda-forge was light years ahead. I know where my sympathies lie at this point.
So you're basically one of those people who make it hard on every one else who actually follow the rules. Glad you're proud of that. idgaf if it took you a few hours to bypass some random security thing... It takes real sysadmins a few moments to look through their logs and block you again... Like I said, I blocked all of Baidu's subnets in one swoop... Because they were being assholes.
I know what you've said. "I don't care about your server." Etc... So yes I have enough evidence to see that you're one of those people who feel entitled to do what you want cause you can. Like I said, I don't give a shit about a crawler crawling sites on my servers. However if I have to actually look at a server because of your crawler we'll have problems.
Can you tell me what "work" you've automated? Automation is a really big fancy of mine :D
I don't care about your server in different context, i don't care literally since it's your server. Please stop playing fool there. My crawlers don't cause problems to any servers.
Better try r/learnpython
Will we be able to run the script on the site as well or is this just an IDE?
We do a lot of website monitoring: things like checking for broken links or pages that have been removed, checking for page changes, keeping track of content on a site, etc. With scrapy, I can setup a crawler that has rules to check for everything and run it on a schedule.
Can you provide me link to your server?
True, False, None
[tiingo.com](http://imgur.com/64pxQAj.jpg) [css is awesome](http://imgur.com/auavVCZ.jpg)
You could also look into iPython/Jupyter notebooks. There are a few free hosts out there. I found this one with a quick Google search: https://tmp55.tmpnb.org/
Hmmm ... technically 10 years with 50% overtime should count as 15 years of "work experience" compared to a workload without overtime..
How can I scrape JS based websites?
Check for [yourself] (https://automatetheboringstuff.com/) some of things you can do. You can get a couple of Python books at a great price in the current [Humble Bundle](https://www.humblebundle.com/books/joy-of-coding-book-bundle). By the way, [r/learnpython](https://www.reddit.com/r/learnpython) may be a better sub for these kind of questions.
Just do identify checks for True and False: def isBool(obj): # XXX: Fix this when an third boolean in introduced. # Since True and False are singleton (like None), we can check the identify of the object to check if the object is either False or True. return (obj is True or obj is False) or obj in ['true', 'false'] def is_numeric(obj): return not is_bool(obj) and (isinstance(obj, int) or isinstance(obj, float))
I'm reading "Automate the Boring Stuff" at the moment. And although it lacks of advanced topics, from my developer's perspective, I really like it, and I think it makes Python really accessible to any person who might needed and is motivated to have a look. I think it's pretty adapted to OP's situation! 
No worries whatsoever - criticism is better than silence!
thanks :) 
It can probably be helpful, but since you're probably going to work with other software to handle spreadsheets or other stuff, I'd advise you to take a look at git and services like github or gitlab too. Git is a version control software. That means you can tell it to track a file and give it save points, the difference to regular saving and the advantage of git is that you can go back to an arbitrary previous safepoint, without having to keep old versions of files around. Git will manage that for you. So if you have linked files and you notice a mistake has snuck in, but you don't know when or you broke something but you notice it too late, you can easily revert to a previous save. It also enables a group of people to work on the same file(s), but only on non overlapping parts.
Go to /r/learnpython Put text instead of screenshot. If `go` is variable then you forgot define it - ie. `go = "my password"` If `go` is a text then you forgot `"` - `if passkey == "go":` 
It works beautifully, I use it every day. For the wrapper commands, install `virtualenvwrapper-win`.
I know that I don't answer the question. But you can use anaconda without admin rights.
I've had extensive conversations with my lawyer on this and they have somebody who has specialized in these cases. In many ways if you violate the robots.txt, it can be argued [successfully] you are violating the contract and standard practices. If your crawling causes at least $200 worth of damages, you are entering felony territory. So things can definitely happen, and have happened, it's just not everyone has the technical know-how to track.
I meant that first, the problem is there only because Conda's version of setuptools is lagging behind the bleeding edge, when it stabilizes more the ability to upgrade it will become moot. Second, the fact that we are talking about _setuptools itself_ is not the strike against conda, but the opposite: the important thing is not that it's ubiquitous, but that it sits at the heart of what conda _does_, so there could be difficulties if you don't do it via conda itself. Just like you could expect more trouble if you try to update Python itself behind its back. I found the first comment explaining the issue to be more or less reasonable: &gt;&gt; I'd recommend you to not upgrade setuptools using pip. It's better to wait for us to provide a new package because (as you noticed) we don't use easy-install.pth. &gt;&gt; I think that was decided to avoid setuptools messing with sys.path (which is one of its least appreciated features :-) Like, sometimes there's no best solution and trade-offs must be made, and sometimes a better trade-off is "no, you're not allowed to do that thing yourself, wait for us to provide a new version" than delving into the depths of broken black magick required to enable that thing. Not because it's more effort, but because it's complicated and _wrong_.
Everything you say is sensible, and may (or may not) explain why the developers are not answering the questions in that issue. But be that as it may, that's not actually what I have a problem with today. It's this claim: &gt; Conda's own environment manager [...] is fully-compatible with pip It's not. 
/r/learnpython
it is possible, the docs are here: https://developer.microsoft.com/en-us/skype/bots/docs/api/chat
It depends a lot on the website. If it's just some client-side JS, you should give a try on Splash (github.com/scrapinghub/splash). If the website does AJAX, it's possibly easier to mimic the AJAX requests in your crawler (see https://blog.scrapinghub.com/2016/06/22/scrapy-tips-from-the-pros-june-2016/).
I will look into this, thank you
If she's on Windows and is allowed to make some changes to her own account, Babun (https://babun.github.io/) might be a good option. It's a Cygwin port that installs without needing admin permissions, with a basic sane config out of the box. It would allow her to open a shell and run from there. I use it for work, and I really like it.
This actually is a nice hacky solution using matplotlib. The only complication would be creating some colorbar that would be representing those non uniformly distributed group values.
Beautiful. I am tempted to make this my next project.
Thank you for creating this! I ♥ SQLAlchemy but one of the things I've always hated has been to re-invent half-assed [windowed range queries](https://bitbucket.org/zzzeek/sqlalchemy/wiki/UsageRecipes/WindowedRangeQuery) for every project. And then the frustration of working with people who don't know these solutions exist and what problems they solve (i.e. having your production application targeted by the [Linux OOM killer](http://linux-mm.org/OOM_Killer) because a brain dead SQL query pulls a 10 GB result set into memory all at once) but not being able to blame them *at all* because you don't know about these issues until you've actually seen a Python application blow up like that. Now I'm curious if and how well this works with MySQL and SQLite... Unfortunately I don't use PostgreSQL enough and don't really have control over that so I'm stuck picking from the popular MySQL forks :-) plus SQLite for my personal projects where it's an advantage not to require a database server...
I'm not sure how many changes she can make to the account or how comfortable she'll be with just using a shell because this is her first attempt at programming but I'll have a look into that.
Really interesting database. Can you give a brief description why should I choose ArangoDB in my next project instead of Redis or MongoDB?
Not really a solution in this case, given the dimensions of the space I am looking at are 2^20 x 2^19. So this matrix cannot even be stored in ram easily, only in sparse form and heat map will not have the detail I need.
No upvote needed, just thought I'd let you know. It's a nice looking site, and bugs like that are a bitch when they only show up at certain screen sizes.
&gt; you could really use a shower. heh, takes one to know one, eh, Chris?
Changes in 0.8: * Initial menu widget support. * Initial standard dialog library (get one line of text and multiple lines at this time) * Various small fixes 
Interesting!! I'll have to take a look at this when I get home. Thanks for sharing.
&gt; Microsoft bailed them out because they felt IT industry needs more competition to move forward as a whole. Microsoft bailed them out because they felt the IT industry needs more competition in order for Microsoft too not get sued by the DOJ for abusing a monopoly.
Alternatively, use a probabilistic datastructure like cuckoofilters/bloomfilters to de-dupe (http://alexeyvishnevsky.com/?p=26).
yea i use it frequently but not with scrapy, scrapy trying to make too much decisions for you - duplicates filtering is great example of it.
Thanks for the reference. Publicizing it will get more folks submitting pull requests!
&gt; You must be new to dynamically typed languages. That has little to do with a dynamic language, you can do this with Java, Go and other statically compiled languages including C if you really want (through structs and unions). No matter how you slice it is considered a bad practice and should be avoided whenever possible. &gt; And water is wet. Next in our series of boring revelations - the precise difference between unicode handling in Python 2 and Python 3: &gt; [...] You can write a broken code in any language. It doesn't mean the code is correct. I think you should watch this video https://www.youtube.com/watch?v=sgHbC6udIqc which was already posted in this thread. It explains how to avoid problems when using unicode. What Django and reddit code is doing is equivalent of storing number as an integer and a string and constantly converting back and forth as needed instead using integer internally and do conversion to string only at I/O. You should do the same thing with unicode.
Come join us then! In python I have about an hour under my belt. I focus mainly on HTML, CSS, and I'm learning JS right now. https://discord.gg/BFe5zF4
I havent finished but Ive been taking the Cs50 Harvard/Yale course and the MIT intro class and they are both great resources, especially for someone like me who attends community college and havent experienced legit university level courses. Gotta say the CS50 class is a tad more interesting due to the "fun" nature of the instructor, but Im learning alot from the MIT course as well. Hope this comment helps.
How would I make it so he can just enter the website(s) he wants to crawl and that's it? Is that an easy question to answer? Thanks for the info btw.
Quite simply virtualenv is an environment manager while conda is a environment manager and a package manager. They both have their benefits but conda is great if you have multiple Python projects. 
Is really the best course not just to learn python (and programming in general) but also algorithms, something that a lot courses just ignore. 
For the most part. If there isn't a package using conda install you can use pip as a backup
Why do I need to specify packages (at least one) when creating a new conda environment? EDIT: Also, I just created a new conda env called test using python 3. But it installed it inside my system python 2.7 directory? That doesn't seem like the right place for it. (test) keith@helmholtz ~ $ which python /usr/local/opt/python/Frameworks/Python.framework/Versions/2.7/envs/test/bin/python (test) keith@helmholtz ~ $ python --version Python 3.5.2 :: Continuum Analytics, Inc. (test) keith@helmholtz ~ $ EDIT 2: Can I not specify an install location and a name? conda create: error: argument -p/--prefix: not allowed with argument -n/--name EDIT 3: I understand now. The prefix dir should contain the name in it. Then of course it's a pain to activate because I'd need to give the full relative path to the directory instead of just the name. They need virtualenvwrapper like functionality.
Noob question. When would one use such an UI? 
If you're taking that input as part of a program that will run scrapy inside it, you can receive the input and pass it into the spider with a custom parameter. Just override the `__init__` function in the spider. For more info: http://doc.scrapy.org/en/latest/topics/spiders.html#spider-arguments
This is the first side-project I put up on PyPI for others to use, so feedback is more than welcome.
A good presentation on what OP did for those who like SQL: http://use-the-index-luke.com/blog/2013-07/pagination-done-the-postgresql-way
Hey, I'm super interested in this. Could you please post some examples? I'd try it out myself but I'm mobile. 
Thanks for the heads up and thanks Mozilla. For the OP, please stop apologizing for your English. It's one of the most difficult languages in the world to learn. Heck, there are eight different ways of prouncing the 'au' vowel combination.
Scrapy is async since day 0, do you mean asyncio? Asyncio for scraping is not all roses: currently twisted has a more battle-tested download client than aiohttp, and async def functions are tricky to get right - e.g. disk queues are hard or impossible to implement with async def based callbacks, and resource deallocation is harder if you don't use explicit callbacks. A bit more details: https://github.com/scrapy/scrapy/issues/1144#issuecomment-141843616. 
Jump that fence if and only if it ever happens, which I very much doubt.
The analogy doesn't hold, you're right.. but it's not because it's more like a sidewalk. It's because it's not like a physical medium at all. Building an interface that exposes data and expecting several billion people with access to it to "play nice" is just kind of foolhardy. The load on your server is not going to have anything to do with how nice people are, and is going to be directly a result of how valuable / desirable access to your data is. You build your interface to handle the load, or you don't. Asking some subset of the people to "be nice" (blindly, mind you, since they don't know what type of infrastructure you have nor what type of load anyone else is imposing on you) is just myopic, at best. "victim blaming." Ha! We're talking about web services here.
Pure awesomness !
Doesn't support new http based chat protocol, e.g.can't send messages to groupchats based on new protocol. 
This is an awesome recap of a process. Thank you very much.
If an editor provides a native API for plugins written in Python, why does that naturally mean I can do the sort of things I described in the post above? This question might be very basic, but I have only ever written pure Python programs, so this is my first foray into "cross-communication". 
It doesn't really mean you can do that kind of stuff, I just know you can because I know what the API allows you to do, which is, among other things, get the current tab's contents as a Python string, and set the current tab's contents from a Python string, which is all you really need here.
do you search something like this? https://www.pythonanywhere.com/
I got this linux file search project - [angrysearch](https://github.com/DoTheEvo/ANGRYsearch), and I remember how giddy I was when my system scan time went from some 3+ minutes, to 1min 20 sec Not as tremendous gains as on windows or going through network mounted drives, but hell it actually made me feel like the project is usable for some periodic scans to keep the database up to date.. 
I think it is a great idea (though I like to keep the address bar), I was looking for such an app (the qtconsole works good but the features of notebook like cells etc are indispensable), so the ideal APP is: * an app that has the performance and stability of chrome * that has its own icon so that I can easily find it notebook from haystack :) , browsing doesn't interfere with my notebooks . * without plugins and extensions like adblocker etc. I think Jupiter definitely needs its own IDE (a ported chrome or firefox like that of tor browser)
I did and I highly recomend it.The material is great, the exercises are good, and sometimes quite challenging, and the lecturers are just fantastic. I've definitely ended up being a better programmer thanks to this class. But keep in mind that it's a cs 101 class, so you will be using Python and not necessarly learning it. The focus is more on key concepts like recursion, hashs, various algoritms etc. However you are required to read the Python docs, use some standard libraries and you are encuraged to get a good grasp of Python to solve the challenges.
You're not actually waiting for the javascript to run before printing the source code. Then you can click on the links to activate the coupons or whatever. What I do when trying to figure something out in Selenium is run the code in IDLE and keep the browser window running to I can test out things and see what works.
Not sure if this is something you can address, but the mobile experience is absolute garbage. Given that's 99% of my reddit usage, I'm effectively excluded from the survey. 
Thank you for the reply. I get your second point now. But for the first one specifying `numpy`, for example, doesn't indicate which python version I might want. I know I can specify `python=3` or `python=2`, but just a package doesn't seem to make a difference for disambiguation.
He's saying in older versions, you would get an iterable. When you have an iterable, you dont generate an element of it until you use it / come across it essentially. So if you do a scandir and then are slowly doing stuff with each thing it returned, the operating system is still waiting for you before servicing other calls. He's saying, turn the stuff it returns into a list and go through all the entries that way the operating system isnt waiting for you and can service other calls In a newer python version, you can use with to declare the generator. With statements have enter and exit methods which will be called always, even if something goes wrong halfway through and theres an exception. For instance, if you open a file with 'with' as a keyword, even if your program crashes, it will be closed and written to, unlike just saving the open() call which might leave it open Best attempt at ELI5, the terminology isn't all right
I import os, then os.scandir() gets: AttributeError: 'module' object has no attribute 'scandir' I'm running Python 2.7.12 (v2.7.12:d33e0cf91556, Jun 27 2016, 15:24:40) [MSC v.1500 64 bit (AMD64)] I used the windows installer from https://pypi.python.org/pypi/scandir (pip install scandir now reports 'Requirement already satisfied') What idiotic mistake am I making?
Oh, you're right! I was mistaken... it looks like you just can't create an empty environment. I don't know why that is.
When you install the package from PyPI you need to "import scandir", it's not added to the os module.
Everyone should use virtualenv (unless you are using matplotlib but thats a rabbit hole). Also check out virtualenvwrapper. It is a little more setup but is so convenient when done. 
Thanks, I am going to write that down as a possibility. The only thing really holding me back is the hefty $70 cost. Part of the reason why I want to make a UI for a program is so that I can make it easier for others to participate/use too. That sort of becomes difficult with SublimeText, but hey...a possible solution is a possible solution.
use *WebDriverWait* function to wait before blocks of content will be rendered by browser.
On Windows, when you start the `os.scandir`, a system call is made to the OS API. That API requires to keep a value called a **handle** to iterate over the resulting list. Internally, that handle is used to manage some kind of state within the OS. This opened state can create a race condition where if you call other OS APIs, they will have to wait until you close that state before it can process any further. It will block your process and you might end up in a deadlock. Once you are done iterating over the values, the OS API requires you make another system call to close the handle. The original implementation would only close the handle after exhausting the whole list by iterating over every elements returned by `os.scandir` or if the return value was released by the garbage collection for various reasons like the return value getting out of scope. Here is an example in which this can break. Imagine you are looking for a specific file in a directory. You call `os.scandir`, you iterate over the returning items, you find your file and you break from the loop since you don't want to waste your time on the remaining files than you call various file system APIs where you move, delete or add file in the same directory. You run the risk of blocking your process because that system handle `os.scandir` created for listing the files is still opened and you are calling other system APIs (moving, deleting, adding files). This exact example happened in my code for many of my users which can be hard to find and debug if you are unaware. The new implementation starting from Python 3.6 adds an explicit close method and it adds support to use it with [the context manager protocole](https://docs.python.org/3.6/glossary.html#term-context-manager) (the common `with` statement). These can be used to close the *hidden handle* implicitly or explicitly. My 2 cents at ELI5.
You could use the Run command with Notepad++ to run your conversion script on the current notepad file. [Here](http://csc.ucdavis.edu/~chaos/courses/nlp/Software/Windows/npp.html) is an example of using it to execute a python script file. Instead of running python.exe you would execute your python script that takes your text file and do your conversions for you. And for Notepad++, you can have it auto-detect updates to the file so you don't need to manually reload the file after your script has finished running on it.
vim can do this too - take a buffer of text, launch an external program, pass buffer as stdin, read programs stdout and replace buffer with it. http://stackoverflow.com/questions/7867356/piping-buffer-to-external-command-in-vim &gt;:%!myapp.py I rather enjoy TextMate, which can invoke simple stream applications in a manner very similar to vim.
I did and I highly recommend it. It's fucking awesome!
Not necessarily. You can specify which instance of python you use when you create the virtualenv. I am on mac so its a little different but it looks like there are a bunch of windows 10 virtual env tutorials on youtube.
GitHub?
Many ways. Web, Qt, TK, etc
/r/learnpython
Build a local web interface using Flask.
You could do this without tk, just use the OpenCV sliders etc
What!? No way!! Should have looked deeper into opencv. It's full of surprises. Thank-you for letting me know,. I will definetly look into it tomorrow.
If you are running commands in an interpreter that didn't come with Anaconda then it won't be using the Anaconda environment. You need to use the python interpreter or ipython interpreter that anaconda provides to test this.
Agreed. Very well written.
https://www.youtube.com/watch?v=nRtp9NgtXiA http://pyohio.org/schedule/presentation/212/ At PyOhio, Jason Fried gave this presentation which describes how Python 3.5 is now the default version used for all new Python development at Facebook.
Nice. I think the best results are the "abstract colors merge": useful as background or textures.
I prefere Tkinter just because I don't have to worry about dependencies, it is really frustrating at first but when you give it some time, it pays off. I wouldn't recommend it for big projects tough.
Honestly I'd just call out to a Unix tool or wrap the same thing written in C.
What OS (or specifically, what file browser with broken file type handlers) is this? If you're under Windows, see http://superuser.com/questions/280636/trying-to-edit-a-python-file-but-the-edit-with-idle-has-disappeared-when-i-rig
What you are talking about sounds for me a bit like emacs org mode with org-babel. I didn't understand that part about "replace/think". Do you want to evaluate source code blocks and pass back results, or is it something else you have in mind? In ob-ipython you can have a document with embedded source code blocks in python and tell the editor to evaluate those blocks. You can even have dependencies or pass data between blocks, or pass data between blocks with different languages. Code and data live in the same document. 
To be fair, docker wasn't even released when his timeline started.
You can get a web interface in front of your python code going with flask very quickly and it's really light.
There are very compelling reasons to not use Docker given FB's network design. And by compelling, I mean it's nearly impossible to make them mesh in a friendly manner.
FB has had containers since before docker ever existed. Par files just give an easily transportable blob that you can push to a server and know your py dependencies are there. Makes it much easier to package up a set of files for a simple script to get something done.
TLDR: 1. Setup the infrastructure 2. Be the change you want to see 3. Get help (even if they don't know they're helping you) 4. Educate others for the future vision not the current 5. Collect metrics
I have tried out vim and am reasonably comfortable with the editor's basics. I prefer its keybinds to those of emacs, especially because of the effect of this stackexchange answer: http://stackoverflow.com/questions/1218390/what-is-your-most-productive-shortcut-with-vim/1220118#1220118 I remember trying to build a vim with Python on my Windows PC. It didn't go well -- a failed experiment. Does this Windows build have Python built in: https://tuxproject.de/projects/vim/ (it seems to, but I am not sure, maybe you'd be able to determine reading the description: &gt; Used libraries: Perl 5.24.0, Python 2.7.12, Python 3.5.2, Racket 6.6, Ruby 2.3.0, Lua 5.3.3, Tcl 8.6.4, libXpm. Also, how much more sophisticated can I get? By sophisticated I mean, for example, 1) the user cannot use insert mode while the buffer is being processed in the background, or 2) the user can only insert freely on a specifically "unlocked" line (so all the other lines might be frozen), or 3) the vim command line can be used to display information about the particular line the user is on (even more sophisticated the command line might have to be temporarily resized when displaying this information) -- do you think I can do this sort of stuff too?
I wrote up a comment on someone else's suggestion to use vim, and I am pretty interested. I asked a few questions, and I wonder if you can chime in on them too? https://www.reddit.com/r/Python/comments/4zqmlz/what_text_editors_naturally_talk_nicely_as_in/d6yxgce Sadly, I mostly use Windows, so TextMate is out of the question for me. 
Can anyone comment on [npyscreen](https://github.com/npcole/npyscreen)? It appears to have a number of useful widgets. 
Nah. Some dude on Reddit totally knows what is best for internal Facebook.
I quickly added "containers" before any comments came in to suggest I am not suggesting Docker as a technology in particular. I am wondering why packaging python as par would be considered better than packaging as containers? So far replies do not provide any technical arguments other that "duh, because Facebook is the smartest".
[I wouldn't be so sure](http://i.imgur.com/FmilpY3.jpg).
Google 
My god what a shit post. Python 3? The Facebook? Who fucking cares?
http://Rosettacode.org 
I'll write one when I get home 😊 
What if I told you it was on my home PC? 😊 
Or PHP, or Node... 😊 
Doesn't it also create lots of overhead? Overhead you might not actually need. More concretely: disk cloning also solves dependency packaging. But it's huge overkill and slow for most use cases. 
The obvious question is: why?
/u/fujiters was being sarcastic. Well, I _presume_ they were. It is hard to tell, though.
The obvious answer is because that's what I know. The less obvious answer is that it can run all open source frameworks/languages (e.g. PHP, Node, Python, Java) *and* it can also run ASP.NET and classic ASP.
When you only have a few hammers everything looks like a nail.
It creates overhead by it also solves lots of problems. Packaging everything into single image lets your containers to be managed by frameworks like kubernetes rather than wasting time for ops.
That looks like quite a nice vim build actually. Certainly more features enabled than I have ever used. In vim vernacular, vim 7.4 patch 2251 +perl +python +python3 +ruby +lua +tcl +xpm. To find out exactly which features have been compiled into any given vim, you run it and execute the command ``:ver`` for version. They've posted that :version information for the build you're looking at [here](http://tuxproject.de/projects/vim/_versioninfo.php) and I can see they've got +most +everything you'll need. Huge version with GUI means you'll be able to run it as gvim, I believe. When trying out a build of vim, the first thing I do is check ``:ver`` for +clipboard and +cursorshape because *it's the little things that matter.* If you're on windows, you may not have to worry so much about whether copy and paste is going to work ( arrrgh! ) and gvim has no problem with cursorshape IIRC. --- I might have to get back to you on answers to your more 'sophisticated' questions. With #1 I think that would be the case automatically as you'd be waiting for the process to finish and produce output. asynchronous io is a feature that is just barely arrived and as-of-yet is not in default builds. I have no experience with that yet but vim 8 is just around the corner and it definitely will have async features. With #2, idk but it sounds do-able. And on #3, there is a statusline option which does that, and several plugins to dress it up, so you might look into vim-airline ( ask me why I insist on +python in my vim -- it's because vim-airline needs it! ) --- If you really decide to get into vim -- you'll eventually want to use a plugin manager: https://github.com/junegunn/vim-plug --- also btw, on windows, the .vimrc becomes _vimrc another thing on windows is that programs launched from a shortcut lnk quickstart taskbar thingy get their current directory set based on properties of the shortcut, so after you pin gvim to your taskbar, do a right click on it, go to properties, and there is a field that gets left empty by default, the one that sets the working directory for the launcher. An unset cwd means that vim starts up with its current directory in a baaad spot. In my experience it was necessary fix the launcher by putting the path to the home directory. ( I forget exactly where though )
&gt; and I don't know if you entirely groked the problem FB was trying to solve. I currently am working on a greenfield project, where my python code is shipped with docker containers and managed by kubernetes. Packaging and deployment is managed in language agnostic way by docker/kubernetes. I see managing python dependencies with similar type of tech stack as a future comparing to something like par. I see par in the same category as php Hack - it was right at the time for Facebook and is technically interesting, but for greenfield projects using php is not a good idea anyway. &gt; Many of the latest security vulnerabilities for Linux containers right now involve this exact thing I share volumes within single kubernetes pod: http://kubernetes.io/docs/user-guide/volumes/. I don't agree with you it's a terrible idea. If you think it's terrible idea you can email kubernetes authors saying the should remove this feature. Ultimately, I trust engineers behind kubernetes. Yes, containers are bleeding edge and some features have bugs, but many people and companies believe it's the future.
I've heard people saying not to learn from his videos since he glosses over why stuff actually works 
I am not sure if your pars are really that much more efficient here. "docker pull" is incremental, so as soon as my server have the base image, I pay only for the delta when uploading the new image with the changed application code. So in the both cases network traffic between servers have similar order of magnitude size. You may call it a hammer, but I belive it would be a good thing if everyone stopped reinventing packaging for every nail, and leverage set of common tools build around one paradigm of packaging and deployment. I really like kubernetes and frameworks like this would be not possible if we kept reinventing packaging for every single language/company/platform/oh-i-need-to-also-send-so.
Rewrites are expensive, it's better to return a 301.
 permanent returns a permanent redirect with the 301 code. \- https://nginx.org/en/docs/http/ngx_http_rewrite_module.html
That's a quality talk on the subject of making changes in an organization. Recommended for anyone working in an office.
But you aren't rewriting anything. return 301 $scheme://&lt;newdomain&gt;$request_uri?; 
It's better to just permanent redirect to HTTPS on the same domain first
Not sure if serious... 
TIL Python is older than Linux 
We all start somewhere. Don't let anybody hold your age against you- young or old.
/r/javascript
Source?
It wasn't the PSF. It was a community effort led by /u/plogston. I believe the PSF pays for the domain, but he and some other folks (mostly at a PyCon sprint) kept the site going. It was pytube.org until pyvideo.org was repointed.
To be fair, he likely used SCCS, or more than likely rcs back then. 
Yeah, could be a little out of date. There's really only one main guy doing that, so it's a little slow. But it's a pretty decent editor, and the python bits are not too hard to learn.
Trying to figure out what the state of PySide2 is via QT wiki and associated pages, can you point me in the right direction? Just curious if a pre-compiled binary exists for Py3 as I wasn't able to build it earlier on my machine.
Read this book. https://www.amazon.com/Turings-Cathedral-Origins-Digital-Universe/dp/1400075998 it will blow your mind 
This is a mirror of a mercurial repository.
And how! Ppl still think Python is a hippy young'un language.
Just make sure you're using SSL for everything when passing the token over the internet, otherwise it's as good as useless.
That's right. There were a lot of steps leading up to where we are today. Polish and Hungarian mathematicians in the 1900s were also very instrumental 
Its still a good source and has a web console http://labs.codecademy.com/
Who are these people? Go, Rust, Nim, even ~~Ruby~~ are hippy young'un languages.
iirc the first version of google's crawler was written in python, later ported to java.
Try r/learnpython
Ruby is 20 years old. I don't know if that constitutes "young".
That particular part of the tutorial was on collisions: http://www.petercollingridge.co.uk/pygame-physics-simulation/collisions. 
Yes, but rewrites are more expensive then just returning a 301. From Nginx pitfalls an common mistakes: https://www.nginx.com/resources/wiki/start/topics/tutorials/config_pitfalls/#taxing-rewrites
I've met one of Guido's colleagues from when they both worked at CWI, and said that they used to pass around floppy disks of the latest source code for Python around for trying it out or for testing. So never mind source control, the main network they used for distribution was just the good old [sneakernet](https://en.wikipedia.org/wiki/Sneakernet).
You can make commits to a git repository with arbitrary dates. You don't even need to change your computer's clock or anything like that; if the environment variables `GIT_AUTHOR_DATE` or `GIT_COMMITTER_DATE` are set, they are used for the respective dates when running `git commit`. But that's not what happened here. This repository has been converted/imported from a different source control system. In fact the one on github is just a read-only mirror, the real one is the Mercurial repo at `hg.python.org`. But that one was imported from CVS, and so on until you eventually reach the original source control system used, whatever that was. 
Oh that's just precious.
There's ironpython...
I will take you up on that, going to give it another go perhaps tomorrow on trying to compile it all together. Any recommendations on a branch or tag that is the most stable? 
Thank you, but I already got it :)
No, redirects with 301 are stuck in browsers like Google Chrome. You can't do anything about it. If you change your mind and somebody had this redirect already it can potentially take a long time until he can reach your page/site again. That's why I hate it being the default in most CMS that offer some redirection/link feature. The constant use of 301 is SEO voodoo. Somebody heard it from somebody and everybody is using it now without thinking about the consequences. 
I mean an actual bus, as in a physical location without convenient networking. A tent in the wilderness would be equally illustrative, I suppose. 
Going via markdown the outputs are still rendered as HTML (which can be embedded in markdown) but the converter to Word format probably doesn't handle that. Can you export Jupyter notebooks as HTML directly? Word should be able to handle that, and I'll mean everything is in a single format. Not sure if Word will correctly import embedded images though.
IIRC, the Github one is the real one now, they switched over relatively recently.
TIL that initial Python commit was 26 years ago. I am too old. 
And [Czech geniuses](https://en.wikipedia.org/wiki/J%C3%A1ra_Cimrman#Contributions) too.. TL;DR (Wiki Quote): Another one of his great inventions was also the internet itself, although without the widespread use of computers. Due to the technologies available at the time he had to rely on telephones. His internet basically consisted of an old circus tent where the maestro arranged the telephone apparatus for various pensioned high school teachers to answer all kinds of questions people asked. The well known WWW prefix as well originated here. One of the teachers' name was Weber and since he stuttered, he introduced himself as "W-W-W.Weber." His achievements in this field go even further, thanks to Mr. Šustr, who was responsible for answering biologically themed questions. Šustr answered every one by operating with field mice (African elephant's weight was equivalent to 30,000 mice, a weasel was 1.5 times faster than a mouse etc.). This is the first recorded use of mouse as a peripheral in computer technology. /s
asyncio support?
Ah. Well personally I'd prefer if the second was httpsleep(url, until__status_code=200) This is the style we're developing towards at work and it's pretty nice. With our lib tri.declarative the declaration can look like @dispatch(until=EMPTY) def httpsleep(url, until): # here "until" is a Namespace which is a dict subclass But this isn't a style used very widely unfortunately so people might think it's a bit weird :P Otherwise I like conveniences for common tasks. 
I was lucky - reading *The Art of Unix Programming* got me interested in programming in the first place, and git was just taken for granted :)
If you run it, It will take a long time
This has to belong at r/learnpython
I can kind of understand how you feel right now. It's great that you feel excited because you found a new interesting thing, and I'm sure you're going to keep learning and finding more awesome things along the way - but this subreddit is for people who are already familiar with Python, and programming in general. We can't really share your excitement, because (and don't let this discourage you!) we already know this stuff, we deal with it on a daily basis, and we just don't get excited by simple things like these anymore. There's a separate subreddit dedicated to learning Python - it's called /r/learnpython, and I feel like you'll find a much more like-minded community there.
Could you format your code a little better? Check out the sidebar to see an example. Its tough to see what is wrong with the code format all over the place
fixed, check again 
/r/learnpython
First, there's no loop here. What you're doing is called [*recursion*](http://puu.sh/qRikY/bcccaeb95a.png). The Python interpreter has a limit to how many times a function can be called recursively, but I think it's like 100 times by default. Therefore, secondly, what error message are you getting when you run this? Because it seems kind of doubtful you'd run this through over 100 choices. Thirdly: I'm not sure if this is the problem with the code (because you didn't tell us what it's doing) or just how you formatted it on Reddit, but the `print` statements under each of the `elif` statements need to be indented. Fourthly, maybe you should check out /r/learnpython because this is really basic stuff.
Fortran was already 33 years old when python's initial commit was made 26 years ago
FYI default recursion depth limit is 1000 frames
https://www.reddit.com/r/learnprogramming/
Actually JWT tokens can't be forged because they're signed using a server-side secret key. There's still no excuse for not using TLS though.
Honestly, as long as you have something you can show to interviewers, the better. It can be Django/Flask/Kivy/etc. Offer to do these for other people or departments at your school as that can be a resume booster. If nothing else, take time to do these projects for yourself and then have them ready when you show up for the interview.
So, you seem to be very invested in Python 3 and The Facebook. Stupid is a does stupid does i suppose.
REQUEST: anyone based in London who could sit down with me for a few hours and walk me through each step so that I have this running and therefore learn about this stuff WILL BE GREATLY REWARDED. :) Apply within!
So, sexbots?
That's kinda what I was thinking. Would CSV be a good second option? 
The previous repository was imported to GitHub, preserving metadata.
So you mean after 1000 repeating process it will stop?
Wait, isn't that already big?
If you haven't already, you might want to join PyWeek: https://pyweek.org/22/
That is.. pretty weird.
9 days after I was born.
Was github around in 1990, or was this commit retroactive? I can't believe it...
/r/learnpython
TIL Python is older than me. 
Damn, I thought you were just comparing drinking ages
Ruby is only hip because of Rails. Rails was the big fad, not so much Ruby itself.
&gt;Well, initially my intention was discussing pars for viability of use outside Facebook, given raise of popularity of dockerizing dependencies You're not understanding the point of par!!! I've run out of ways to explain this, so forget it. I don't care. You don't understand the problem, you don't understand containerization, that's all fine. But it means the conversation is over. Moreover, you're conflating several technologies as the same or somehow related. They aren't. I've also run out of ways to discuss this. Yes, neckbeards love to resist change, and we leave those clowns behind. That's all fine. I don't like docker specifically because of several technical limitations, and limited or no improvement over using lxc. But this all has absolutely nothing to do with a packaging format and technique.
In the example given here, assuming both DNS records are still active, couldn't you just change the rewrite back to original domain? I'm trying to understand what exactly it is that you're trying to warn people about.
And look at how common it is now!
I can barely understand what I just read.
I would clone the latest from the Qt `dev` branch: `git clone --recursive https://code.qt.io/pyside/pyside-setup.git`. That is the latest. What platform and python are you compiling on? Do you have the [dependencies](https://github.com/PySide/pyside2/wiki/Dependencies) installed? How are you calling setup.py?
You're right, especially if the receiving domain is configured to automatically upgrade to HTTPS (one less redirect). However, I'm also sure there's some jankyass system (the app, not the browser) that handles unsecured vs secured differently
It's funny, you look at a few months later (also described as ["Initial revision"](https://github.com/python/cpython/commit/1e270d6ef5ffdd2739acbe30dcd3b711c6b242c9) ) and it pretty much is entirely readable python scripts. That's pretty cool. Also, Guido is a tab man vs a spaces man at this time... [makes you question everything](http://www.youtube.com/watch?v=SsoOG6ZeyUI&amp;t=0m35s). 
I blow people's minds when I show them that Perl is only slightly older than Python. Everyone thinks they must be 15+ years apart, with Python being the result of a generation of frustration with Perl.
My attempt was before the changeover from Github to QT Co. and I believe I was trying to target 3.4. My memory isn't as great as it used to be but I think I ran into some sort of symbol/include conflict with an inheriting class in PySide2 but couldn't figure out why as I only had the QT5 library installed on a clean slate machine. I wasn't able to walk down the line to see what I had missed from the pyside-setup instructions unfortunately. I have another clean slate ready and when I get the time I will give it another go.
i would suggest sentdex over TheNewBoston anytime
Yeah if I couldn't do it in JSON I'd prob do csv. You could use something like Simple Pie to parse the csv in php.
Git is only twelve years old. I had assumed that it was nearly as old as Linux until a friend corrected me. Man, am I glad that I didn't have to program for a living before 2004. I used Visual SourceSafe for one internship and it was *bad.*
I'd rather not :) The idea behind `until` is that it's a single kwarg to which you can give a list of conditions, joined by boolean OR (see http://httsleep.readthedocs.io/en/latest/tutorial.html#chaining-conditionals-and-alarms)
I just signed up to a Ruby on Rails course. You consider it to be a fad that is no longer useful? 
Janitors sure have a lot of responsibility over there
Probably something to do with AI.
I guarantee your professor doesn't want you to use SymPy. 
It’s overdriven too as if that was the purpose of including it.
That's kinda what I was thinking. I tend to avoid JSON if I have to, I find it a little to awkward for my liking. But that's just a personal preference. 
Break them!
Agreed, unless it's actually important I don't. Luckily, I've never encountered something like that and I sure as hell wouldn't write one. 
I can't think of any that really stick out and annoy me. There are small parts that do, but not worth the time to rewrite the entire program in my opinion. 
I guess: browse github and see what needs fixings or improvements. If that is nothing new, read through scientific papers and see if you want ti implement something or see that something will never work in real life and prove it so you might find the solution which works in real life.
Weird question here but is Fortran secretly a good programming language by any chance?
Not a bad idea. Back in college i did something similar, ending up writing my own academic paper that was published. I'll have to take a look
It has a limited market. It's still useful, but you have to be able to find the jobs for it. At the very least you will be able to pick up other frameworks in other languages that much easier.
Kivy is a very ambitious and well designed NUI for mobile / desktop uses but is barebones in some of the primitives. I think alot more can be done with this, especially in getting better looking front end. https://kivy.org/#home http://cheparev.com/kognitivo-challenge-your-brain/ 
&gt; I've been trying to come up with a large project Why not start with a small project.
This is /r/python which is a place to discuss python. The post was a video discussing facebook's adoption of python. I along with others felt this was a relevant video for the community. If you don't like it downvotes are welcomed. This like all of reddit is a self-voting community. Contributing garbage like your comment adds no value and merely diminishes public perception of you without getting your point across. 
I've seen it used mainly for physics simulations: a friend of mine still writes its flow simulations in Fortran
I actually disagree with using higher level languages because I like python but I always have type problems with it since I can't see the types of everything written out and then I have to guess what I have to fix. If anything most issues that I've had in C++ are usually pretty obvious not that the solution is but just that you can typically tell what's wrong with something a lot easier. 
thanks for your feedback, pep8 updated.
I get that but in C++, etc. when you cast something it is explicitly written there so you know what's happening. In Python if I don't know a type how do I cast it? And if I do then I tend to get other errors because of it. So while useful in terms of being organized, and less verbose Python can be as hard to work with at times as any language. 
Give cython a go! It allows you to write Python and use type declarations, speeding up execution time. 
There's not many people doing deployment on a bigger scale than Facebook.
If you don't care about security, just use "eval" on a string Beyond that, two options : - Try your best to actually attempt your homework. Then go to /r/learnpython, post a SPECIFIC question (with code) on where you got stuck, and some kind soul might help you - You mention a professor, which implies that you are paying tuition? Go bother that person... or their TA. I bet that one or both have open office hours. That is LITERALLY what you are paying those people for. Or better yet, go find some classmates and work with them (trust me, this will be an absolutely invaluable skill later in life). Grad school and most jobs in the real world are much harder than they need to be without this skill!
That makes sense. If I'm considering doing something like Django I guess that would probably be more attractive to companies that do web dev? 
It's literally everywhere. How do you think numpy works?
MATLAB is written in C, C++ and Java. Mathematica is written in C, C++ and Java. Both of them use Fortran as the basis for a lot of their solvers, they're just high level wrappers around it. (Just like numpy does with Python). Aside from a few changes here and there for improvements in computers (64-bit) the underlying Fortran is more or less the same as it was wren it was written back in the day. There's no reason to re-invent the wheel. Short of us realizing that *all* of our understanding linear algebra is wrong BLAS and LINPACK aren't going anywhere. They're unit tested, do one thing and do it **well**. 
Wow, there's suddenly a surge in activity at around 2000. Trying to keep your eyes on Guido gets a lot harder after that. BeOpen era?
[Piwik](https://piwik.org/) is an open source analytics platform similar to Google Analytics. There appears to by a [Python API](https://github.com/piwik/piwik-python-api) available that would allow you to track events (eg a certain endpoint is visited) and log data (maybe the parameters used). It would be interesting to see if you could use that API to create a decorator that would log basic info about each controller method you attach it to.
Many app performance services such as new relic will do this out of the box. You could diy it by sending logs to some ELK style logging service.
It's how the Django ORM does complex filters (joins and comparisons other than equality for the most part). It looked weird to me too at first but I've come to like it. I actually wonder of there are any libraries to assist with handling kwargs of that form.
I like what you got! A possible addition in the future is a mass poller - that can accept a list of urls/request-objs, and poll them efficiently between the constraints of maximum parallel connections, and maximum requests per minute.
I would comment about your use of the phrase 'Functional Programming'. Functional programming is not just about the use of functions within a program - it is about the whole structure of your code. In Functional programming, everything is a pure function, with input parameters, output values and no side effects (writing a file is a side effect for instance). The entire program is itself a function, which uses other functions to transform input parameters to output parameters. Most practical functional languages have non-functional constructs to allow for file input/output and other side effects. Your code is examples of 'functional decomposition' (where you break your code into reusable functions - although these don't need to be pure with no side effects), and using that decomposition in a procedural program. A procedural program is one where the program is defined as one step after another where the order matters. It might sound like nit-picking, but terminology can be vital when introducing concepts to people, especially as Python does actually have a number of capabilities which are commonly found in pure Functional languages, such as functions as first class objects, functions such as map, reduce, any &amp; all and list modification methods (comprehensions etc).
Actually yes, second code is better.Thanx for your advice, maybe I can do it for yapi-v2.Also, I will work for cross version.thanx.
Thank you for your input. I am sorry, sometimes I am not always sure how to phrase things appropriately, especially when it comes to programming concepts. Perhaps I could have rephrased this particular thing to something closer to procedural programming with Python. 
I suspect that is just the way things have evolved. I imagine that low level stuff in C / C++ prevailed for their low level control of hardware.
https support ? 
&gt;Short of us realizing that all of our understanding linear algebra is wrong BLAS and LINPACK aren't going anywhere. They're unit tested, do one thing and do it well. What if somebody wants to make faster implementations of those libraries?
Support for Python seems natural at FB. Switching from PHP to any other language is a no brainer.
And scale alone defines complexity?
- Pitivi: a good movie editor is still missing in the linux world https://git.gnome.org/browse/pitivi/tree/pitivi
Yup, depending on your time and energy you'll want to consider covering the main areas companies are looking for(and things that interest you). Even if you start with a Django app to learn a webdev stack maybe after you get going on it you go back and add some CI/CD aspects to that project to learn some devops tools which are a pretty big area these days.
I really would like to have something done by December so I can start getting a resume ready around then, so I guess that's not much time for me considering I have classes and stuff. Do you think a Django app is a good option in this case?
For polynomials, find the eigenvalues of the companion matrix. That's how it is done properly. It is very easy to code to make it working for toy-project level. import numpy as np import scipy as sp def myrootfinder(arraylike): return -np.linalg.eigvals(sp.linalg.companion(arraylike) You can pass 1D numpy arrays and lists such as `[1,2,1]` and so on. The actual machinary is very similar to this but more involved regarding the conditioning etc.
The second to last line uses WebDriverWait, no? Should I be doing something different?
&gt; You build your interface to handle the load, or you don't. Asking some subset of the people to "be nice" (blindly, mind you, since they don't know what type of infrastructure you have nor what type of load anyone else is imposing on you) is just myopic, at best. Bullshit. It's asking people not to be toxic to the online community. The alternative is to make the internet less useful and/or accessible. You can be an entitled asshole all you want, but it hurts everybody in the long run. Do I actually expect everyone to play nice? Hell no, people like you clearly exist. But that doesn't mean it's pointless to encourage people to play nice, educate them on how to play nice, and call out entitled assholes for being exactly that. You try to hide your selfishness behind an implicit assumption that the internet is hostile. You're a fucking asshole. Period. I don't care that other people are assholes, too. That's entirely irrelevant to the fact that you, specifically, are an entitled asshole. I just hope other people reading this thread realize you're an utter asshole and think "Boy, I don't want to be like phreakmonkey! They're a fucking asshole! I better pay attention to the great advice in this thread so I can be a better person that phreakmonkey!" 
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Looks great, I've wanted this since I started writing in python. I set up highlighting triggers in iterm, which mostly solves the problem when I'm working in OSX. Say I wanted to set this as default behavior for local development - no import required. Do you know of any reasonable way to do this?
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
http://selenium-python.readthedocs.io/waits.html#explicit-waits
If you are using the python REPL you can use a .pythonrc file to import and set the hook.
It's still be that in my example though. 
Django is a backend framework for designing web applications. Blogs, shops, interactive sites etc.. Anything really where you want to be dynamically generating pages or handling dynamic data. The best way to understand it, and I hate saying this for any project, is to just work through the first few tutorials on their site because it covers a lot of what django is. From a database orm, to a templating system to a multiuser administrative user interface for your class based data structures. 
Preferences &gt; advanced &gt; triggers http://i.imgur.com/3mOfH9k.jpg This is my current setup. I can explain in more detail later if you're interested.
Documentation doesn't link back to github or pypi.
Ha! Nice. I make a living securing the infrastructure you depend on from the fact that your myopic vision of the world doesn't exist. You can hate that I think this way all you want, but consider for a second that it might not be out of selfishness. It might actually be out of selfless dedication to my craft and *real data* about what "the Internet" really looks like. 
Sadly IronPython does not run on UWP/WinRT (currently)
Oh. That is a pity. 
Yes. Once it is ported to dotnet core, it should run there, but until then, it doesn't.
This is quite cool... Especially for the case you demonstrate: running an app using a framework. This makes tbs so much harder to read. Especially if you're new to python. I can see this very well in the development environment. Less so in production. A while back I put my personal log config into a package as I'm using the same config across all my applications (https://www.github.com/exhuma/gouge). Do you think it could make use of your library?
If you are this clueless, just use anaconda. Anaconda is the tool for the clueless.
Whats the question? You should post this on /r/learnpython and include an actual question.
I also wrote something similar to this a year back https://github.com/ChillarAnand/ptb
That's interesting, can you elaborate? I'd like to add a command-line option to the utility to do it automatically. EDIT: Ah, it's just for the REPL, not the interpreter, but all the good REPLs already reasonably colorize the traceback (even though they don't hide irrelevant lines).
Ah, good idea, I'll add one, thanks!
http://i.imgur.com/iDs1K.png
Look great. While slightly different than coloring, I often am annoyed by overtly verbose traceback, example: I make amistake in my code, and the traceback goes through literaly meters of errors in library code. Maybe an additional improvement would be an option to remove or condense traceback parts from library code?
The most useful addition to tracebacks I can think of is a way to add links for each line of code that I can customize to have any editor jump directly to that line (if the editor supports it).
... It can do more than bar charts, right?
Maybe create a dict with the name of each amount as the key. Then loop through that to print and take the input. Store the inputted value as the value in the dict. Then loop through again to count and display. Or you could use streams to lessen code again.
This started as a map editor for personal use. I don't know if the tools placement is ok or weird, if the keyboard shortcuts are intuitive or not. I am suggesting to use Python 3 because installation using PyPI is easier - it depends on pyqt5 that installs through pip using python 3 but requires manual install on python 2. You can still use it with Python 2.7 if you install pyqt5 yourself. All the art supplied together is original made solely for this game maker. I don't work in development or have learned through formal education so if there is any obvious error please let me know. The generated game is js, here is a demo : https://ericoporto.github.io/fgmkJsEngine/index.html 
Is there a way to create main title for a chart? I looked everywhere in their docs.
I couldn't figure that out either. It's a good question.
It's more a domain specific language (regex is a nice language but only sometimes). For heavy numerics of the classic linear algebra sort, it's nicer and faster than the C's in many cases. Also it's a PGAS language as of Fortran 2008 - your Fortran program can scale to 1000s of cores. With C you need to use libraries for that. Unfortunately, many fortran programmers are old geezers that write screwy code with lots of global variables and memory errors, giving it a only partly deserved bad reputation. 
Tested it this morning in the interpreter and it works pretty well. Going for the callback in my use case and it worked. But I asked myself what's the syntax for checking on nested JSON attributes with jsonpath=. As i can see, there is only support for attributes on the first layer? //edit: In my use case, I have an Array of dicts. So a structure like [{"a": 1, "b":2}, {"a":3, "b":4}].
It sounds like you want to actually move files around in the file system? Not sure of the best option there. In any case, if you don't need to do that, and just need to split up a dataset which has already been loaded into train/test, then you can use scikit learn's [train_test_split()](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html)
How is this different from seaborn? For data visualization, it is important not only to think about features but also about interface. The API should be very intuitive.
For python, Icalc and mxm midi probably.
yeah sorry for the bad english, in fact is the third language. But tks,
I built something very similar, however instead of doc strings, I used dictionaries as arguments for decorator methods that would do the checking. I feel decorators are a bit more idiomatic than doc strings personally, but to each their own =D
I have started using connexion with swagger integration and it has been working great. Have not tried hug yet with falcon but that looks pretty neat as well. Thoughts on those two?
This very website.
Trees are not flat, so you should be able to walk behind them. The characters upper body should also be able to clip into them. I suggest either adding a different collision box to know if the player is behind/infront of the trees. You could also design the trees to correlate with the players height so that it wont be an issue. I.e. draw the leaves after the player, but draw the trunk before the player. This goes for a lot of different things as well, such as the buildings. If the tool is solely for personal use, then you don't need to concern yourself with tool placement or shortcuts. But, if you're looking for a mapping community, then look at wc3 or sc2, Blizzard has made some of the best map editors. I've probably clocked 2-3k hours in them. The most important thing isn't shortcuts but ease and visibility. You don't want the user to feel overwhelmed, but at the same time you want to make something powerful. A bit off topic, you should indicate doorways/gateways better (art). And keep the character in focus during transitions. [Google](https://material.google.com/motion/material-motion.html) has an awesome article on motion design, most of it uses examples from a more personal device, but a lot still applies to applications and video games. You can see some examples of transitioning in most older [Zelda] (https://youtu.be/xf2IO7P5DVA?t=2711) video games. In that example Zelda appears first and then the scene. He's immediately the focus of the scene. Going even older, though I believe this was due to the platforms performance, Zelda would appear first and then the blocks would slowly load in. Your character is also not in the center of the screen while moving, the movement also feels wonky. Really good movement will have a very quick increase in acceleration and decrease in acceleration. 
It depends on your audience really. Coming from a C++/MATLAB background, one thing I remember getting excited about was higher order functions and decorators. Being able to write stuff like def verbose(func): name = func.__name__ def wrapper(*args, **kwargs): print('calling {} with arguments {}, {}'.format(name, args, kwargs)) result = func(*args, **kwargs) print('{} returned {}'.format(name, result)) return result return wrapper @verbose def example_func(a, b): return a + b example_func(1, 2) was pretty mindblowing, though I'm sure it isn't if you're coming from lisp or haskell. I was also impressed with `pickle` and the ease with which you can write and run short scripts, but again, there are other languages that have nice serialization features or that don't need lots of boilerplate and explicit compilation.
Yep mostly scientific stuff. I haven't tried PyCharm, but it would be the next option I guess. However, so far I really like the philosophy behind VS Code (lightweight, not focused on one language, extensions, etc.)
Thank you, I was looking for this. I will note the suggestion of looking into Warcraft 3 and Starcraft 2 map creation tools, I haven't played both games so this is a good tip. Right indicate the doors better, this is a good excuse to play something today so I can observe how it's usually done. (a brand new Tales of Phantasia cartridge is waiting me at home) I like the idea of player first transition, I will look into having this available, I think it should be easy to draw in the correct layer - you can use the keys 1 to 4 to hide/show the layers in the engine. Thank you so much for the other things, I will add all of this to backlog so I can look into solving all of this :) Edit: Things I already got from Warcraft 3 map editor in my notes: palette as combobox in new file screen, icons in actions for easier visibility of what's going on, and also allow variables as parameters whenever possible. I also found a bug that the drag and drop in my editor isn't working for actions. Edit2: Watching a lot of videos, realized that panning with the mouse is something people like a lot, so I added a way to do this in a new release already available in PyPI.
Thank you, if you have some time please install and play a little with it and tell me what you think. I already have some things planned (missing a way to design heroes and monsters, and also scripted battles right now, among other things), but I am trying to prioritize things and trying to avoid to commit to much in things that need complete overhaul. 
ASCII is "dark" because 7th bit is always zero in the basic set. Go on and have some fun - xor bytes, add an offset. The code will still be much shorter. If you want to change the encoding then you probably should have a function that takes a string and translates it into a list of numbers and the other way around. This way you could have multiple functions for encoding and replace them easily on fly as needed.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
not sure what exactly you are trying to do but if it is more than a page or two I suggest looking into [scrapy](http://www.scrapy.org)
No need to apologize, we are all learning, and we are simply at different places on the journey.
[pyramid_appengine](https://pypi.python.org/pypi/pyramid_appengine/) [webobtoolkit](https://pypi.python.org/pypi/webobtoolkit)
one of my research professors wrote some life saving postgreSQL for our lab. always wondered if there was a nice package out there for everyone to use for generalized purposes. ill have to check this out:)
f.i. variable to getter/setter refactoring with properties: * https://migrateup.com/python-properties-refactoring/
have you looked at ipython tracebacks, they are debuggable and configurable with %debug and %xmode
Something like [this] (https://github.com/ellisonbg/altair/blob/db6ca9de9acd23d7cbd26c1c98c132fea9665ea2/altair/notebooks/08-GroupedRegressionCharts.ipynb) ?
I first stumbled upon this when reading the documentation for [peewee](https://docs.peewee-orm.com/en/latest/) (which includes a similar extension module). This definitely has its use cases, especially for people like me (scientist first, programmer second). I recommend it to a lot of my colleagues who aren't as knowledgeable about programming or databases in general.
I wrote [this](https://thekindlyone.github.io/lessons/2015/04/03/scraping-tutorial/) long time back to sort of demonstrate a whole lot of different things in python.
Thank you so much! Been using it for months now and it's pretty awesome
Yay more yhat spamvertising
Yes, thank you for the link.
It is simple. Always tell developers to use packagename==1.2 instead of packagename&gt;=1.2 in requirements.txt
why's this pinned?
At first I was a little scared when the description said that the first time a column or table is mentioned, it'll be inserted / created. Then I remembered that this isn't a replacement for robust methods but a replacement for lazy methods. It's just as easy as serializing to a Json file in the working directory and yet is in a database, so... it's pretty nice. Just don't make a massive application with it. :)
It's got non-destructive automatic migrations. If any of the keys in a row's dictionary don't map to an existing column, a new column is created. If you want actual migrations, you're gonna have to pull in Alembic; or reconsider whether *dataset* is the right tool for the job.
If you're coming from a science background then I'd say numpy, scipy, et al used in conjunction with ipython notebooks. 
I just really don't like the name of the package... it's not what you'd expect. Still upvoted.
If print() and or an if/then doesn't stimulate their imaginations then F 'em. 
That is not a probability density/distribution function.
[hug](https://github.com/timothycrosley/hug) [isort](https://github.com/timothycrosley/isort) [jiphy](https://github.com/timothycrosley/jiphy) [concentration](https://github.com/timothycrosley/concentration)
I'm a lazy person!!! 
If I understand your complaint correctly, you can using the row_type parameter in the connect method to set an alternate dict-like class to change the type of container rows are stored in. https://dataset.readthedocs.io/en/latest/quickstart.html
Wow, thanks! I don't remember that being there the first time I saw this library!
Correct me here, but why would I use this to make NoSQL like thing out of SQL db when I can use mongo or what ever you prefer? I am serious, am I missing the point?
I think Rethinkdb has the most intuitive most Pythonic API of all the NoSQL databases.
I love that dataset allows me to insert or update a db without first have to prepare a table beforehand or manually write out the code to handle a large number of values for a large number of columns. target.insert(__dict__) is just so simple. It recently saved me a lot of tedium getting a 200+ field datafile imported for analysis.
What exactly does this do? The documentation shows how to set it up, but not what it's for.
I still have nightmares from SourceSafe. To be fair though, SourceSafe was much worse than its contemporaries.
I mean, what's considered non-fatal? It seems like this library is made to be used in iPython notebooks and it's not like a "fatal" error is going to ruin anything. I'd rather have a hard error telling me I have a typo than some quiet log message.
I'm always impressed that a project I've done a lot of work on, [Cookiecutter](https://github.com/audreyr/cookiecutter), is used so frequently. It's used at so many different levels by so many different people, organizations, and companies. 
you're like the crazy ex-girlfriend that expects an immediate response to texts. I've been away from reddit for over 11 hours.
I literally just used that today, following along with the google ML series, which obviously makes me knowledgeable enough to up vote and comment on this post.
On line 15 of your spec file, you need change the third semi-colon to a colon. If this does not work for you, it's because you haven't actually provided a single bit of useful information that would allow someone here to actually try and help you.
Try using cx_freeze
break points can have conditionals, what exactly are you trying to do? 
Oh damn we just made the drivendata data science one manditory at my work.
You're right, my bad. I wasn't so much trying to get a bug fix. I was more interested in if there was a better method than pyinstaller. I figured many people in this sub have compiled large projects and may have some advice on what they use to do it. 
The existing library ecosystem, for one. You won't need to build your own web framework - you can just choose one of the hundreds already existing ones. 
Pyinstaller should work, but requires work. If you don't care about the monolithic executable then the fastest and most bulletproof way is to grab a copy of miniconda, install the packages you want, zip up the folder and send that to your end user. 
I think that ptvs is different from the completion used in VSCode (for now)
Just curious, but what do you think of it?
I absolutely prefer an API to implement one right way of doing things. Libraries that try to "make everyone happy" end up being hard to maintain and debug, and inevitably there's going to be a bug for one person's preferred method over another method that does the exact same thing, just in a slightly different way. It's easier to maintain, easier to debug, less to test, less to document, less to learn...
If you're going to put it that way, I don't think there's a point. Unless you saw this and automatically thought "cool! I can use SQL with Python dicts and I don't have to create columns or tables or anything like that!", then you're probably not the type that'd want it. Unless you have absolutely no time to spec out a schema and you have to avoid the overhead of writing something out in sqlalchemy, you probably wouldn't find much reason to use this.
I sort of feel like "scientist first, programmer second" types should just avoid sql in general unless they absolutely have to (working with colleagues with a project already dependent on it). If you're not spec'ing out a schema in a well-thought out way, if you don't have data that is relational by nature, I don't really see why you'd want to use sql. It probably just makes things more difficult in the end if you're not incredibly familiar with it. TinyDB might work for a lot more scientists than they realize. Mongodb might be better for scientists who don't want to mess with schemas and just need to save a bunch of objects, when you have situations where you just might arbitrarily add a column. But I've definitely seen people work on projects where they forced sql into it when they could've legitimately stored everything in memory and written it to disk as a CSV in the end. Just one GB can hold a hell of a lot of information. Even your laptop can hold a lot of data in memory. And now looking at the API docs for this project... there seems to be nothing on joining tables, primary keys or anything like that. Every example is just some simple object that exists on its own. Why use a relational database if you don't need any sort of relational functionality? If you don't need any columns that refer to other rows, don't have any one to one, one to many or many to many relationships, probably best to reconsider why you're using some sql backend in the first place. SQL isn't just the standard option for data storage. I can understand why people might use it just to store simple data models even without relations, but only if they already know it in and out and it's just the easier answer for them. I would think there'd be much better alternatives for scientists who aren't knowledgeable about databases.
If you looking for IDE, consider pyCharm.
Hmm, could be that I understood the task wrong http://imgur.com/a/0YK5O it's point c.
HDF5? There's [h5py](http://www.h5py.org/) for fairly generic interactions, and [pytables](http://www.pytables.org/) for more structured things. 
Fail2Ban can monitor every hit over NginX web server from NginX access.log. By parsing this log file, we can detect which IP is launching DDOS attack to the server. If you are using CloudFlare, you can block these IP at Web Application Firewall level. Thus CloudFlare will stop these hit before reaching at your server. Daroyan used to do this job.
This is the best tl;dr I could make, [original](https://www.dataquest.io/blog/apartment-finding-slackbot/) reduced by 97%. (I'm a bot) ***** &gt; You eneed to find the listing, quickly figure out if it meets your criteria, then call the landlord to arrange a showing to have a shot. &gt; As most apartment listings in the Bay Area are originally on Craigslist, then scraped by the other sites, there&amp;#039;s also a fear that maybe not all the listings are scraped, or that they&amp;#039;re not scraped quickly enough to make the alerts real-time. &gt; Using SQLAlchemy, we can create a database table that will store listings, and a database connection to make it easy to add data to the table. ***** [**Extended Summary**](http://np.reddit.com/r/autotldr/comments/50a770/i_built_a_slack_bot_to_help_me_find_an_apartment/) | [FAQ](http://np.reddit.com/r/autotldr/comments/31b9fm/faq_autotldr_bot/ "Version 1.6, ~96003 tl;drs so far.") | [Theory](http://np.reddit.com/r/autotldr/comments/31bfht/theory_autotldr_concept/) | [Feedback](http://np.reddit.com/message/compose?to=%23autotldr "PMs and comment replies are read by the bot admin, constructive feedback is welcome.") | *Top* *keywords*: **list**^#1 **Slack**^#2 **want**^#3 **result**^#4 **Craigslist**^#5
I did think its cool, but what is the point when your SQL turns into NoSQL, if I want SQL db than its probably because I care about running complex queries to aggregate and combine data from multiple tables. I think perhaps it is one of those "if all you have is a hammer than everything looks like a nail"
I have the pleasure of working with a database in which every column in every table that I know of (out of hundreds of tables) is prefixed by "t$". So, table ttmxch300100 has columns t$orno, t$seqn, t$line, etc. A system that uses object attributes (rather than keys in a dictionary) to represent columns breaks when used with this database, because $ is not a legal character.
Pycharm
Get a room you two
both a hallucinatory and encompassing talk on await / async / asyncio. both highly interesting and entertaining 
this library also has tqdm_notebook(), which integrates with Jupyter. It's insanely good for adding a progress bar to notebooks and cli tools.
i have seen a few projects like this one in the past year (and t hought of making my own). Just playing devil's advocate, but how does flask_jsondash compare to [pyxley](https://github.com/stitchfix/pyxley) or [pydexter](https://github.com/D3xterjs/pydexter)? Im trying to decide which one to commit to.
It's not that you'd need to swap without a temp, it's that you need to swap and don't need a temp 
Having not used Rethinkdb, any reason why? I've used MongoDB and CouchDB before and they all seem pretty simple to use.
If you're on windows, use something like [Winspy](http://www.catch22.net/software/winspy-17) to see if you can grab the data that way, then use one of the windows automation libs in a script to grab the value. FWIW, Winspy does not work on some .Net garbageware. Autohotkey or Autoit might also help. Again, on Windows
tqdm is awesome, I use it in the majority of my programs. Just a heads up, be sure to use the maintained version from github which is version 4.8.4. "pip install tqdm" will get the right version, while "easy_install tqdm" will get you the outdated 3.X version.
Why on Earth should I use this instead of jinja2, which is incredibly flexible and extensible? 
As someone who has been in the position of hiring software engineers, here are my thoughts about your GitHub profile: 1. This applicant has a GitHub profile. That's a good sign! They have probably used `git` before, too. 2. There is not much activity. I guess I have to look at the rest of the candidate's application for evidence of greatness. *(N.b. my GitHub also has huge blocks of empty space on it, because we use [a different DVCS hosting service](http://www.fogcreek.com/fogbugz/devhub) at work.)* So, it definitely won't hurt to put it on your resume, but I also don't think it will help much either.
":" is pronounced "colon", stop confusing people
HDF5 looks like a definite option. h5py won't work as it only seems to accept numerical data, but pytables might. EDIT: After further research it doesn't look great anymore. There seem to be a lot of data integrity and performance issues. It also seems pretty specialized for numerical data; it's not good for text data really.
&gt; If you're not spec'ing out a schema in a well-thought out way, if you don't have data that is relational by nature, I don't really see why you'd want to use sql. One place it's been immensely helpful in my lab is logging data from sensors, instruments, and so on. The advantage to using SQL here as opposed to HDF5 or CSV or some local file format is that I can trivially setup a server using Postgres or MySQL and record data from many different devices to the same place. Sure, there are things like time-series databases that could do this too (I tried InfluxDB for a while, but it kept eating all my memory for some reason), but SQL works just fine for this type of storage. For data from experiments, using SQL can even be ideal because normally I *can* properly define a schema. Since we started writing all our experimental data to a SQL database, we have also been able to more easily create tools to help with automating data processing and analysis (it's much easier to query for datasets with SQL than to do it on a filesystem, at least in comparison to the previous way the datafiles were stored). So, is SQL perfect for everything? No, of course not. But it works quite well for everything I'm using it for. If something like `dataset` helps get colleagues at least introduced to the concept, then I count that as a net win.
This kind of question would be better suited to /r/learnpython.
Absolutely...though I'd say make sure you clean it up and have 1-2 GOOD sized projects you can show off immediately. I once pulled a project and couldn't it get it started up due to library issues. So verify everything works before pointing it out and be prepared to show off your work. 
Don't access variables from outside the class. This isn't a pythonic thing, it's an OO thing. Interactions between objects should be based on collaboration and functionality, not details of data implementation. At worst, have methods that provide the data, and perhaps write to it if required. At best, rethink the whole structure so that your interaction is based on objects doing things, not giving data. Tell the player object it has been hit, for X points of damage, of a particular type. Let the player object then work out whether it is immune to that type, or vulnerable to that type, or temporarily in god mode, and thus let the player object deduct hit points from itself. 
combinded with [flatdict](https://pypi.python.org/pypi/flatdict) its the ultimate datastorage: import flatdict values = {'foo': {'bar': {'baz': 0, 'qux': 1, 'corge': 2}, 'grault': {'baz': 3, 'qux': 4, 'corge': 5}}, 'garply': {'foo': 0, 'bar': 1, 'baz': 2, 'qux': {'corge': 3}}} flat = flatdict.FlatDict(values) import dataset db = dataset.connect('sqlite:///:memory:') table = db['sometable'] table.insert(flatdict.FlatDict(values)) table.find_one(**{'foo:bar:corge': 2}) flatdict.FlatDict(table.find_one(**{'foo:bar:corge': 2})).as_dict() 
&gt; Multiple assignment is slower than individual assignment. For example "x,y=a,b" is slower than "x=a; y=b". However, multiple assignment is faster for variable swaps. For example, "x,y=y,x" is faster than "t=x; x=y; y=t". Source: https://wiki.python.org/moin/PythonSpeed EDIT Also: &gt; python3 -m timeit "a, b = 1, 2" "a, b = b, a" 10000000 loops, best of 3: 0.0509 usec per loop &gt; python3 -m timeit "a, b = 1, 2" "t = a" "a = b" "b = t" 10000000 loops, best of 3: 0.0553 usec per loop 
Async metaclasses, the look of horror and awe across the crowd's faces when he did that... shame it wasn't caught on camera
Once you'be established your career like you have I don't think it matters much anymore. It certainly won't hurt, but I don't think it helps any more than saying "I'm proficient with git" on your resume. I've been asked "Do you contribute to git/open source" in many interviews over the last year and I always respond with "to be honest, no. I put in my 40-60 hours a week writing software all day every day at work and when I come home I want to put time into my hobbies not do more work." Surprisingly I've received many a head nod and strong understanding from the interviewers in the room with me at the time.
You are welcome. Nowadays I simply assume that pandas already have a functionality I am searching for and search directly in the docs. This strategy is mostly working. ;) The pandas developers are awesome in this regard. As a disclaimer my code barely scratches the surface of the possibilities of numpy and pandas, so I think my simple needs are often fulfilled in general.
I don't think it has to be limited to 1 or 2, but tutorials and school work have really no business being up there as they rarely show anything of consequence.
Has anyone compared this to records from #kennethreitz: https://github.com/kennethreitz/records
I will find it whether you list it or not.
I include it, though it's not cleaned up very well...I've been thinking of having a secondary github for my everyday side stuff that I don't want to parade around.
The good thing about working on open source software for a living is that I can point to my whole career as a software developer. :)
 $ python -m timeit "a,b = [1,2,3,4,5], [5,4,3,2,1]" "a, b = b, a" 1000000 loops, best of 3: 0.271 usec per loop $ python -m timeit "a,b = [1,2,3,4,5], [5,4,3,2,1]" "t = a" "a = b" "b = t" 1000000 loops, best of 3: 0.257 usec per loop $ python -m timeit "a,b = [1,2,3,4,5], [5,4,3,2,1]" "a, b = b, a" 1000000 loops, best of 3: 0.267 usec per loop $ python -m timeit "a,b = [1,2,3,4,5], [5,4,3,2,1]" "t = a" "a = b" "b = t" 1000000 loops, best of 3: 0.263 usec per loop
Hope you're remembering to push to other remotes ;) eggs and baskets
Ok, I'm probably missing something obscenely obvious. What does for user in db['users']: print(user.name) afford you that for user in db['users']: print(user['name']) does not?
What sort of things should you put on git? I'm learning python, should I upload my projects and meddlings? 
Yup. As someone else that hires software engineers I always get so excited when they include a link to their github. And then supremely disappointed when they have practically no activity. If you're active on github, then you should include it. :) Just like u/cyanydeez said! 
This is brilliant! I have a new favorite language for all my fizzbuzz needs. On a serious note though I love the cool angle for an informative write up on lexers, parsers and interpreters. Great work!
Unless it is code applied to a non-coding project. Oh you set up a data analysis tool for some calculation you have to do repeatedly and deal with umpteen derivatives and blah blah blah? Thank you for being smart enough to use something better than excel. 
I look at candidates' public repos to answer two questions: * How good are they at writing code? * How good are they with version control? I need those questions answered before I hire anybody and public repos are the easiest way to do that. The concern here is that if all you use Github for is learning exercises, it's not going to demonstrate your best work. If I were you, I'd spend some time making sure that it had work I was proud of in it, then include it in your résumé. You're going to be judged on the code you write one way or another, and being proactive about creating and curating your code portfolio gives you an opportunity to push that part of the hiring process in a positive direction. 
&gt; "to be honest, no. I put in my 40-60 hours a week writing software all day every day at work and when I come home I want to put time into my hobbies not do more work." If everybody thought that way, no open source code would exist at all.
I would imagine tutorials show you have interest in projects and like dabbling around in different things. It's not a huge checkmark towards employment but it's nice to see and doesn't hurt. School work is probably more ignored since it's stuff you have to do and it's hard to tell where stuff you got from teachers starts and your work begins. But, if you have nothing else, it certainly doesn't hurt.
This doesn't do things other tools can't do. But I still like it so far. For me, I like prototyping quickly, SQLite doesn't require any server to set up, and it's easy to poke around in the data while I work (since I understand SQL well). I can think of two use-cases where dataset might be handy for me: 1. Most of my big applications (after the prototype stage) end up using actual SQL databases anyway (and we use SQLAlchemy heavily as it is), so there's a potential migration path from POC to actual database schema. 2. My throw-away scripts just slurp data, process it, output it, then I'm done. Simple works. Pop it into SQLite while I think, don't futz with schema. So for these two use-cases, dataset seems pretty nifty and low effort. I am very lazy.
I find it interesting people are commenting about 'activity', rather than 'projects'. I sometimes write games and other bits and pieces, but when work does not afford me the time for personal projects, those get pushed to the back burner for a while. Sometimes I won't commit anything for a month, and then I'll come back. The thing is, the projects that are out there aren't going anywhere. Most are in a 'completed' stage, unless someone asks me to do maintenance on one. If I have 4-5 projects, with thousands of lines of code, but haven't touched them in 6 weeks, does that work for, or against, me? 
and dataset is not keeping you from doing that. the idea is to make it simple to get your database set up and filled with data, and thus enabling you to use whatever complicated SQL query you want.
Other hobbies are how you get ideas for open source software to write. For instance, the last thing I built was an ebay auction notifier chrome extension to help me snipe ebay auctions. Buying baseball cards on ebay is one of my hobbies. Many hobbies have tasks like that which can be coded. There is no excuse to not have any open source projects if you're a professional programmer.
Actually the vast majority of Linux is currently maintained by paid programmers, who do that for a living. The idea that no one pays people to work on open source projects is a myth.
Out of curiosity, how? I don't think my github account is linked in any way to my public ID or email addresses. 
Totally! Put it!
You're pretty much writing a definition of HDF5 and why it was created.
Simplify it! if active: print(github-profile) 
When I talk about activity, I'm talking about someone that has made like 5 commits versus someone with hundreds or thousands. If you've done a huge amount of work, but nothing too recently, I don't think that hurts you at all. Especially if you've got a good reason why. Like work. Where you write code. Heh. 
Mainly https://news.ycombinator.com/item?id=10858189
Interesting. I've replied to you already on a different comment with concerns I had. I guess we can consolidate discussion there.
That's really a jsonpath question - check online in the docs (linked from my docs) or google around for help. Hint - "get me the values for all 'a' keys" would be `'$[*].a'`
You don't have to contribute to open source in your free time to contribute to open source. Almost all of my contributions have been on the clock. Granted I haven't been able to write any major frameworks or libraries from scratch, but in the best interest of projects I *have* been able to contribute major bug fixes ... and even a few features to big fancy python projects that look quite nice on my resume and in my github account :) I find most developers I've worked with will *at best* write a bug report on a project's github issues site ... or more commonly they won't even do that and just end up writing some hack-y work-around when they encounter bugs in the open source projects they use. For some reason a lot of developers treat open source projects like they do their OS or language ...ie; Django is some magical layer that they can learn to use but looking under the hood, seeing how it works, and writing code or bug-fixes is well outside their ability. In reality, they are often more than capable of writing *better* code than the project's maintainers ... but they have some sort of mental block, lack of confidence, or just have this perception that they are *users* ... and contributors are an entirely different breed. So even if the bug fixes or contributions they have on their github aren't anything spectacular ... it's a huge plus for me to see that sort of work since it illustrates the sort of mindset they have and prove they are willing to understand not just how to use the tools, but understand how to write the tools.
This is certainly possible if you write a script that calls the `cookiecutter.cookiecutter.main()` function. I know because I've done something kind of similar, where after the template is generated it's moved somewhere else.
mmh I don't know. In Genshi there's pseudo python code [inside the template](https://genshi.edgewall.org/wiki/GenshiTutorial#ExtendingtheTemplate) (conditionals, loops) whereas in this packages (tdi) this happens on the python side. 
I'm hiring engineers and I always love to see that. Even if you only have a few abandoned hobby projects in, it's very interesting to see what you have worked on in the past. And, of course, to read a bit of your code. I personally search for them anyways prior to an interview, so it makes it just easier for me. :D Also
He even has his own subreddit where he posts to himself ... /r/herman402club/
Oh you are that guy! I love your blogs. My favorite blogpost of all time is the one you made about how to read research papers. EDIT: By the way. Is there any chance that you can change the coupon expiration date? 
RIP
Have you tried these? http://groupy.readthedocs.io/en/master/pages/introduction.html https://dev.groupme.com/tutorials/bots
I have python projects on my Github profile: https://github.com/Tafkas But since these also use jQuery (and some other JavaScript libraries) they are tagged as JavaScript repositories. The result, people offer me front-end jobs. But the fact that I get a mail once in a while tells me, that people look at Github profiles.
I've been hiring engineers for a few months now. My opinion: it won't make you less likely to get an interview but it might make it easier for me to say, "yes let's interview that person". My repo has a lot of incomplete and old junk in it. That's just how I do things. I would hate for someone to make a judgment of my capabilities based on my repo. But if a repo has some really cool stuff, that makes it easier to say, "yup, clearly competent. That's a +1"
No dashes? 
[Is this a good enough headshot?](https://github.com/rckclmbr)
For those sort of projects I would either make them private or use bitbucket.
After I lost some of my code because of bad backup practice I have started to backup most of what I code on my spare time on github because of the convince. It's full of small fast shity projects, lots of unfinished iced projects and a few greate active or completed projects. Would it be better to move all the shity and unfinished stuff to private repositories on bitbucket instead. Only keep the good stuff public at github. 
I'll probably end up going with bitbucket, don't want to pay for private github for small simple things
Oh, that's my bad, you're right. Did not see, that jsonpath is another module, that you are only using in yours. Thanks for the answer. Sorry. 
I'm not talking about created tutorials. If one of my applicants had created a tutorial that would be massive points towards them. What I'm talking about is projects people create that clearly just follow a tutorial from the documentation, or a class project that's completely laid out for them. Things titled like "My First Rails Site" which is clearly just copied and pasted from the documentation. There's just nothing interesting there or any kind of demonstration of experience.
I see, that makes more sense and I would agree. Especially if they have nothing else to show.
 ... marketing mostly. here FTFY
Looks great. Will definitely buy when coupon comes!
At work, no one knows you're a cat.
"Not only will he code, but he'll solve the office's mouse problem!"
This is another case of push-style templating and is not new. I keep a list all of such systems http://metaperl.org/hacking/push-style-templating-systems-catalog There are several for Python already. 
97
Because you don't run amuck in the template, thereby allowing static validation. 
I just did something like this recently. I designed a language I call pancake script (it's like javascript and python combined) and made a tokenizer, compiler, interpreter, and editor for it. https://youtu.be/8YtG-iQVac4 I just added some syntax highlighting, actually. https://youtu.be/5gHYhn_Qp1c
I average at least one star per repo. So the trick is lots of repos, I think.
Nope. Underscores or GTFO :P
I think the idea of putting your github on resumes is basically the hipsters of coding. interviewers checklist: github: check starbucks: check beats: check 
When trying to choose a weapon I get: AttributeError: 'list' object has no attribute 'copy' on line 81 in main.py
Please don't get in the habit of using global variables like this. Learn to use classes to track data sets and assign attributes to your game elements. [They are especially useful for games.](http://letstalkdata.com/2014/08/how-to-write-a-text-adventure-in-python-part-1-items-and-enemies/)
Apparently this is due to me writing in python 3 but trinket is only using 2
Makes you seem human.
&gt; writing software all day every day at work and when I come home I want to put time into my hobbies not do more work This statement implies that writing software isn't something you enjoy (because it's not considered a hobby of yours, and hobby means for pleasure). In an interview I would prefer to appear as someone who loves the field.
So you don't get the job?
Oh man that takes me back. About 20 years ago I built a compiler for the Informix ACE reporting language using lex and yacc (later ported to flex and bison). It would translate ACE into C++, then link it against a custom library I wrote that did all the database work and pagination. My original task was to port 800+ reports from ACE and Informix into C++ and Sybase ... one at a time. I figured it would take years. Instead I spent a couple of weeks writing a compiler and ported all 800 at once. Bet my boss didn't see that one coming. 
My email, skype and github are included in my CV. But most HRs keep asking me for my email and skype and github after they've seen my CV.
Apparently so! And commits in forks don't count, either, which is sad. https://help.github.com/articles/why-are-my-contributions-not-showing-up-on-my-profile/ Commits will appear on your contributions graph if they meet all of the following conditions: * The commits were made within the past year. * The email address used for the commits is associated with your GitHub account. * The commits were made in a standalone repository, not a fork. * The commits were made: - In the repository's default branch (usually master) - In the gh-pages branch (for repositories with Project Pages sites) 
Unless your company prohibits or stifles such things. My previous employer did so and it was incredibly frustrating. Not everyone can commit to public repos from work but I do completely agree that you should if you can.
Have a personal website that highlights the projects you want me as the potential employer to look at and put that on the resume. This website could just link back to code sitting in github. Basically guide me to the projects you want me to look at. I am not going to look through 50 projects. Also, I might still take a peak at your latest project to see how your code cleanliness has progressed.
Are there any good tutorials out there for git/github that you cant advise? 
So is activity on projects. Some software are dated and don't have much activity on them, because they are stable or purposefully tackle a small set of features and do it very well. I was just trying to convey the fact that there are other things of note in a profile, and different ways to judge the contents.
You are not going to get a decent job in mechatronics and automation without a degree. I see glorified help desk/wrench monkey jobs in automation demanding a mechatronics degree - any actual interesting robotics jobs tend to require postgrad after either a comp sci or engineering degree. 
Apparently, the game isn't working if you run it on the website due to it being written in 3 and the website using 2. So I would copy the code and run it on your own PC 
I don't have a degree and managed to make myself a decent career. But it was significantly harder than it should have been. I truly regret not doing the last 1.5 years, biggest mistake I ever made. Make your life easier. Get a degree.
Well, if I go more than a month, it's because I'm being dumb and not pushing changes from my laptop. When I get busy, coding can become 20 minutes here, an hour there ... it's tough to know when you have enough to commit. I guess I could push every day, but pusing 2 methods I wrote over lunch that don't break anything yet because they aren't being used feels like I'm just trying to impress people, when deep down I know no one is looking at my projects.
Sadly, I think your right. I'm in same exact boat, I have about 1.5 to 1 year left.. Shits just crazy with rent, tuition, food. 
Sorry! I'll keep this in mind next time.
Yea, that's why you should look at the code, nothing else.
I hesitated writing exactly that. But there's a HUGE random element. Just look at the popularity of Flappy Bird: no marketing but enormous popularity. But yea, you can help with marketing.
Star your own repos, big gains.
if/elif/else. Python has the best keywords. Although my favorite is "def". Also "str" and "dict" make for awesome brevity. Plus all the lowercase.
Thank you! :)
/#Python3masterrace
I was confused at the ending. It just quit on me when I beat the monster! I wish there was something more spectacular when you win. Looking at the code I can see that you're pretty new to code/python. Despite the fact that it's pretty basic and the code could use a lot of work, it's pretty cool that you've "shipped" something. Keep it up!!
Yeah I haven't done much in the way of story. Currently learning about classes to try and get it to work better (It is confusing as fuck)
I too am human, fellow human.
iterm2
Yea... Don't know why they allow that. Seems pretty silly to me. 
/r/totallynotrobots
Simplest answer: If it's good, then why not. If not good, then why?
As-you-type predictions over the Internet? Wtf?
If we have this maybe it might be make sense to allow this syntax to be used to type any expression/subexpression?
Maybe just add the project and maybe a github link in the resume?
yes.. the shown (and awfully displayed) code lines goes into VBA. Then, for example, I let pandas parse info on the relevant workbooks + sheets, which (I prior to tis) had VBA store in the clipboard. pd.read_clipboard() will pick this up. 
So the main issue with http://cyrille.rossant.net/moving-away-hdf5/ is it conflates issues with the format with issues with libhdf5, issues with h5py and issues with pytables. The first point (Single implementation) seems to be that's there's a spec which is fairly precise and the code's not on github. There's nothing stopping you from writing your own implementation (especially if you don't care about all the things like MPI support and different backends etc.). The second point (Corruption risks) may be an actual issue, but there are a bunch of work-arounds you could use for that (for example, not modifying the file after creation, which is what every sane data reduction scheme does). The third point (Various limitations and bugs) is a result of people not reading the documentation or bug reports correctly, or doing something really weird. The segfault was due to conda building h5py and pytables incorrectly. UTF8 is supported fine, the problem is you have python 2, python 3 and numpy wanting to do their thing, which does not map cleanly to how hdf5 works (which is what the whole discussion about strings is about). If you only give h5py encoded UTF8 strings, then there's no issues. The pickle thing is odd to me, because as far as I know, h5py does not use pickle, and using pickle anywhere is a bad idea. The inability to delete datasets is again a limitation of libhdf5, not the format. The fourth point (Performance issues) really comes down to the benchmark (https://gist.github.com/rossant/7b4704e8caeb8f173084), which shows that the defaults for h5py are slower than memory-mapped numpy arrays. PyTables isn't used, nor is h5py tuned in any way. The fifth point (Poor support on distributed architectures) is that libhdf5 doesn't support X, where X is author's preferred system. The sixth point (Opacity) is the first point restated. The seventh and final point (Philosophy) suggests to me the author has not thought about all the fun ways a file system can be different (e.g. cases, maximum file name lengths), which is the whole point of HDF5, which is quite specific in what the format should be. There are issues with the format (look at external links for one), but it's definitely better than someone homebrew format which breaks as soon as it's not running on their custom system.
~~Keylogger~~
the number one tool is mypy, but there have been others making further use Ideally it should eventually make it into documentation tools as well, I don't think IPython's introspection is aware enough to make use of typing yet
&gt; Also, is this good practice? Almost never. Your mind will skip over the line thinking "that's just a print statement". We're too conditioned to expect conditionals to be indented.
Seems normal. For me: 51 repos 356+3+1+1+6+16+2+5+13+1+1+2+1+1+13 = 422 stars, 36 at 0.
Absolutely. There's that point when you have an applicant where you're not even sure they really know how to code yet (even if they claim they do). A github link takes you way beyond that. Even if it's not much, it still lets someone see that you're a coder and you've worked on projects even if you don't have professional experience. If someone has no professional experience, college papers/work and github is really all you can look at, and it's a little intimidating to consider hiring someone where you can't even see an example of what they've done outside of academia. Between inviting a graduate with a github and one without, the one without better have something *seriously* interesting about them to even consider inviting them in. Maybe they did a study on homomorphic encryption and implemented something and the results are on the paper. But if they don't have that paper to show off, then the guy with github is definitely getting the invite over them.
The breakdowns and issues are my own so they aren't exactly written in stone. Others may never get the issues I have tried to solve. I'm also not writing my tutorials for someone who is doing an assignment, I'm writing them purely as helping others who might be coding and run into a similar issue.
Your stats are even more skewed towards one big hit. Quite drastically at that.
Bull. You can have all of those with almost no stars. For example if you have a project that you are maintaining in your company and it hasn't taken off/you suck at marketing. Popularity in stars means nothing except people clicking on the star button.
That doesn't make sense. We're not mutating the values, we're just swapping references to the values. It makes no difference whether the value is mutable or not.
You're gonna end up writing loops and such in templates at some point - to generate rows in a table, for example. I'd rather do that in the template where I can write the html verbatim. 
I really don't like this syntax. I'm confused why they don't take inspiration from Go's type declarations, which are arguably more Pythonic than this nonsense. 
Can you give an example of a Go type declaration for comparison? The syntax they have chosen is fairly standard for languages which support optional typing. 
&gt;If you don't want to use it in your own projects, just don't. Just don't. Just don't. This is not hard. Its not going to invade your life perversely and hold a knife to your throat. I don't buy this. For the most part, sure. It's a feature you don't have to use. But eventually, I will probably use something that uses this feature and enforces that I play nice with it. If type annotations can be checked at runtime, someone will make something strict. Maybe I won't be able to pass a dict-like object in place of their annotated Dict[str, int] and see the same expected behavior. Maybe sphinx will bug out in new ways for the same reason. That would be frustrating. The interface some variable implements is way more interesting than the type. Type annotations in syntax are just unnecessary IMO. They will never replace a good docstring or comment either. It probably won't hurt much to have it, but I think it's just bloat.
lambda abuse wasn't relevant before and it isn't relevant now. If ugly unreadability discouraged people Raymond wouldn't be complaining about thoughtless application of PEP8 causing ugly unreadability. PEP8 dovetailed into the popular dogma of clean code meaning "linter doesn't complain about your code". PEP526 dovetails into a similar popular dogma of "all bugs in large code bases are due to a lack of static typing". Both provide an easy way to thoughtlessly apply an objective standard to solve a difficult problem which will backfire. 
It was 90% a bad joke. If you use it inside a function and keep it referentially transparent, it's totally fine. But one thing that does bother me with python is a lot of people write over variables all the f'ing time. If you're reassigning variables in some long chain of procedural code, you're essentially mutating it.
In terms of what you see as you're trying to make sense of the program. What you called x is no longer is the same thing after some arbitrary code is run, have fun debugging that. I just don't like excessive variable assignment/reassignment prevalent in python code.
Disgusting
You can re-assign variables in *all* languages. Python just makes it easier as it's dynamically typed. No one is forcing you to reassign values. If you don't like it, don't do it. I'm not understanding your point, sorry :/
I was just making a joke about the headache that procedurally reassigning variables gives me sometimes, nothing more :). You've seen the code, where someone pulls in a giant dataframe into some variable x, and then continue to use x throughout the entire program as they chop up and mutate that dataframe to fit whatever they want. All languages allow it, but it's *really* prevalent in python.
A very popular repo is a virtual guarantee that its developer(s) have had to deal with all those things. No popular repos *might* have had that effect, but the chances are much smaller. Anyway, I agree that just looking at how much stars it has is a bad idea. You should check out the bug tracker to see how the developer deals with the community/other people, check out the documentation, packaging, etc too.
&gt; A very popular repo is a virtual guarantee that its developer(s) have had to deal with all those things Sure, but there are so extremely FEW of those popular repos that it is pretty irrelevant for recruiting in practice.
I don't have a strong opinion on annotations or on this PEP. However, when I read something like this: &gt; x, y: T &gt; Are x and y both of type T , or do we expect T to be a tuple type of two items that are distributed over x and y , or perhaps x has type Any and y has type T ? (The latter is what this would mean if this occurred in a function signature.) Rather than leave the (human) reader guessing, we forbid this, at least for now. ... it adds to my feeling that Python syntax no longer has that sense of being logical and composable (lego-like) that it used to.
it’s literally the same with a colon. and that colon is pretty pythonic
Seems it's influenced a lot from AngularJs Directives. 
Why not using the `~=` oeprator for it? packagename~=1.2.3 This way you'll catch all the bugfix releases without changing your requirements.
Nevermind it should be `an int`
&gt; They should use Mapping instead of Dict That's the point though. Many Python programmers, including seasoned ones, who don't have experience with static typing are going to get *way* to restrictive with their types. Part of me feels like this type thing has serious potential once we're out of the growing pains - see the PHP community with their optional static typing. But the other part of me feels like this is just a distracting mess. 
`an int` vs `a int`
He's joking that `a int = 1` should follow proper English grammar, where you use "an" instead of "a" before a word that starts with a vowel sound. It's a clash between English grammar and programming grammar, and it's a joke because you don't expect to see English grammar in the syntax of a programming language.
No that's false. Just look at the docs for meld3 - no need to be invasive at all! 
Don't encourage me
Perhaps, but this is far from the convenience of something like Mako.
Since you cannot move posts on reddit, you might want to recreate your post there.
&gt; continuing to take Python down the road of both ossifying specific patterns which haven't been tested in the real world How so? This syntax is used in many other languages. Also, is it not completely optional to use with Python? Regarding PEP 3107, I do not believe function annotations are the way to go. Statically typed languages _do_ give you _more_ control over things using tools like static analysis. Maybe you can achieve this with function annotations, but they seem much more clumsy. With function annotations, you could put whatever you want there: relying on them to be correct was never a thing. With this syntax (if you decide to use it) it'll be enforced better: so you can't call a list a dict, etc. 
&gt; PEP8 dovetailed into the popular dogma of clean code meaning "linter doesn't complain about your code". I don't think this is true. I don't even think about it when I program. If I make a mistake I fix it. It really isn't a big deal. I haven't met someone that, when criticized about a bad method, has come back to me with "but it's PEP8!" &gt; Both provide an easy way to thoughtlessly apply an objective standard to solve a difficult problem which will backfire. PEP8 is to give some standard to the formatting of code in a language that doesn't enforce these things. Types are a bit different: they allow you to write a lot more robust code. They might be a bit awkward to read at first, but honestly, if they are going to cause you problems you need to think about it a bit more, no?
I haven't written Go in a bit, but standard way of doing it: `var a string = "initial"` `var d = true` Is also valid, and Go will just infer the type. There's another way to do this, which maybe they were seeing if Python could adopt: `f := "short"` Though I don't think you can specify the type when using this shorthand. Personally, `f: string = "short"` is a lot nicer to me than either: `f string := "short` or `var f string = "short"` 
Type systems _are_ something new you have to learn. You specifically quoted an rejected proposal: but it'd make sense if the syntax was just changed slightly: (x, y): T No? Anyway, the way you should do tuple typing is: t: Tuple[int, ...] = (1, 2, 3) Which maybe isn't the prettiest, but it gives you everything you need. 
&gt; If type annotations can be checked at runtime, someone will make something strict. This isn't true though, is it? I don't think this is the intention. I _hope_ that we can eventually run Python with a flag: that requires the file or project to be typed. Guido has mentioned a few times that these type systems will help them improve the performance of Python. I don't know if or how they could do that on a project that's only partially-types, but if they had a flag requiring the project to be typed when it's compiled to bytecode, maybe?
&gt;I haven't met someone that, when criticized about a bad method, has come back to me with "but it's PEP8!" The most normal response to the question I've asked of "how are you going to improve your code base quality?" has been "we'll make sure it's PEP8" and the most normal response to "what's the quality of your code base like?" has been "good! we have a lint commit hook". People default to preferring tangibility when something grows beyond a certain level of complexity. PEP8 may not be very good at improving code quality but it's very tangible. &gt;Types are a bit different: they allow you to write a lot more robust code. Except they don't always. Explicit types *may* lead to more robust code if those types are A) in a place where type errors are likely, and B) checked and cause failures (which CPython won't do). They definitely *do* lead to more verbose code. Future PEP-526 abusers will not be any more appreciative of this trade off than the dogmatic PEP-8 abusers Raymond Hettinger complained about were. They will, like you, think dogmatically that "types" gives extra safety at no extra cost and balloon the size of their code bases.
Thanks for reading! 
&gt; The most normal response to the question "how are you going to improve your code base quality?" has been "we'll make sure it's PEP8" and the most normal response to "what's the quality of your code base like?" has been "good! we have a lint commit hook". Haha! I haven't heard these, but if you have: I understand your pain and I'm sorry! I have worked on some _god awful_ code from previous developers and teams. I actually had a guy once tell me he's an "esoteric programmer" ...! But I have never thought to put the blame on PEP8. How did you respond to this? It's also the responsibility of more experienced programmers to guide people in these situations: it's not hard to say "that's a good start, but it doesn't mean the code is clean. Here are some problems we can pay attention to in the future..." It's frustrating, but that's what good programmers do. &gt; They definitely do lead to more verbose code. This is definitely true! But does that extra text make it hard for you to read? I have no problem reading other statically typed languages, and I spend most of my time in Python. I do disagree that types will not guarantee a benefit. It might be a little tough to get used to them, but it should not take long to learn them. &gt; They will, like you, think dogmatically that "types" gives extra safety at no extra cost and balloon the size of their code bases. I do not think this. They don't give you _any_ extra safety unless your tooling uses them. But, without them, it's a lot harder to write great tooling! It isn't: use types and you're safe! But without types, you lose out on a lot: never mind future performance gains that Guido has been mentioning for typed Python projects. --- Your argument itself is a little interesting. Please correct me if I'm wrong, but the negatives you're saying are: 1) (hypothetical) if people abuse them: - Code bloat (how much bloat?) - "I'm safe now I use types!!!" from less-experienced developers 2) They don't add much to the language by default These aren't the only negatives, but it seems like it's what people are talking about a lot. I don't think these hold up when you talk about the potential. I'm not an expert, but just a few awesome, highly-general ways you can use types to make your code super-slick: 1) Static analysis - of course! But what's more... - You can write tools more easily to analyze your own code: or code that's part of another system: or code provided by users of your application (when using Python as an embedded programming language). 2) Better linting! 3) Can help make better Python compilers, and a _much_ faster runtime 4) Of course, because of previous points, you have: less runtime errors (not eliminate them), and "more robust code."
&gt; your type checker on CI Is this a thing?
Documentation is a good example. 
It is often just called "the" ternary operator. Basically, it just means it is an operator taking three arguments. Since in many (most?) languages the ternary conditional operator is the only ternary operator the two names are used interchangeably. I would not use it in Python since the usefulness is very limited. In C it makes a little more sense since the true/false statement has its own scope. In C the following is not doing what you might think it would: if (a &gt; 10) int b = 1; else int b = 0; // Here, b does not exist anymore But in Python this is no problem: if a &gt; 10: b = 1 else: b = 0 # b can still be used
You are trying to upgrade `praw` package and it tells you that your version of `pip` itself is not the latest. Try `pip install --upgrade pip` if you want to upgrade `pip` itself.
Thanks very much, but this time it gives me a bunch of [errors](https://gyazo.com/b20a292be0eaed4044da47a1df3721e0).
someone sudo pip installed?
&gt; I think its more that the PEP 484 syntax for declaring types static analysis is not well tested. [...] Makes me think that nobody is actually using this in the real world. I'm interning at Dropbox right now, and there's a relatively strong push to use mypy everywhere. I think we have about 230k lines of code covered by mypy right now? It's still a small fraction of the overall codebase, but the number of lines covered by mypy is increasing at a steady rate of roughly 1k to 5k every day (except during weekends, obviously). A lot of the bugs within mypy/a lot of the tweaks and improvements made to PEP 484 are actually motivated in part due to bizarre edge cases emerge as more and more of the codebase gets covered, and due to use cases devs wish mypy would support as they try and push type annotations to express increasingly dynamic code.
I'm not familiar with NodeJS so I'm not 100% sure what the requirement is but if it's about being able to take advantage of multiple CPUs then Zato has had it since its inception: * https://zato.io/docs/ * https://zato.io/docs/architecture/overview.html In fact, on top of using multiple CPUs you can have multiple servers, each in a different operating system all connected through a load-balancer and internal synchronization lets you not only distribute incoming requests over all CPUs in a cluster but also to communicate between workers by their Linux process IDs - for instance, a WebSocket client connected to one worker can easily send messages to another client, say ZeroMQ one, connected to a completely different process in another operating system all running under the same cluster. 
I know Dropbox is probably using it (given that they are the main authors of the tool). Doesn't really fully alleviate the concerns as that means we have a monoculture of developers who are working with that codebase. So what if mypy reflects the needs of the dropbox team, and works with the coding style of the dropbox developers, and does the things that the dropbox developers need it to do. Does that help me? Maybe, so long as I do things that the dropbox programmers would have done, but if I am doing something else, maybe it isn't covered. &gt; A lot of the bugs within mypy/a lot of the tweaks and improvements made to PEP 484 are actually motivated in part due to bizarre edge cases emerge as more and more of the codebase gets covered And that is in a nutshell the argument for delaying the acceptance of PEP 484. Allow mypy to continue to develop, allow it to iterate its annotation format a couple more times. Get it used outside of DropBox and accepted by a wider community of developers, and only then push for acceptance. Guido is using his BDFL position to push for the inclusion of things that "work for him" without doing enough to convince me that it will work for the rest of us. Maybe he will eventually be proven correct, but it is concerning that he is making these decisions seemingly in a vacuum.
This looks really nice, if we manage to get working something with this and python 3.5 async functions using [uvloop](https://github.com/MagicStack/uvloop) we will get something really really fast. :) But thanks, I'll take a look at the docs.
Thanks, apparently there is something we can leverage (https://zato.io/docs/architecture/overview.html) could be great to work on top of this.
One of the challenges with doing static typing in a duck-typing language like Python is exactly the Mapping vs Dict issue. When I accept variable foo as an argument I'm not supposed to be thinking about its type. I'm supposed to be thinking about what it can do. It needs to be able to do X,Y and Z. Now you ask me to annotate the type... so how am I going to describe something that does X, Y and Z? There are essentially three options: 1. The type of whatever I passed to the function that didn't cause it to crash. 2. The smallest concrete type that I know and use which implements the required methods. 3. Some abstract interface type that I don't use or think about. I'm not the least surprised that people reach for #1 and #2 over #3. I never instantiate a Mapping when I am coding so why would I even think of that thing? The better response here is not to criticize the programmer for saying "Dict" when he really only needs "Mapping" but to criticize the tooling. mypy should have a database of basic abstract types, and mypy should identify the weakest type that satisfies the method and should suggest that type when building the signatures. 
Great release, as again! Keep your good work, PyPy team :)
Ah. Yea I agree with that. The rST style type information is pretty lacking and if PEP 484 does basically the same thing with a different syntax then what's the point (except using slightly fewer characters)?. 
Am I the only one who would have preferred a double colon, a la Haskell? I'm not really the biggest proponent of this PEP in all honesty, but if I had no idea about this addition, and I suddenly see `x: int` outside of a dict, I'd be a little confused. At the very least, even with my limited knowledge of Haskell, the double colon immediately prepares my mind for reading a type annotation. x :: int x = 4 Or: x :: int = 4 Plus, this helps address the keyword issue as brought out in the PEP. The only other place I can think a double colon is ever used in Python is for a list slice, but even then I've only ever seen it in the context of `mylist[::-1]`. Just a thought. It's a little pedantic of a request and probably doesn't/wont make a difference. 
Sure. But type information can be put in comments too and that works in Python 2 too so why do annotations at all then?
The usage of the double colon was brought up when PEP 484 was being discussed, and it ultimately ended up being rejected, for better or for worse -- you can find the detailed breakdown of why here: https://www.python.org/dev/peps/pep-0484/#the-double-colon
I see a PermissionError. Try running this command with administrator privileges.
&gt; Simple is better than complex And just a bit further on: &gt; Readability counts As Python 3 has grown up, it's added all sorts of bells and whistles, complicating the language and adding noise (pun intended) to a language that claims to value simplicity and readability. In the quest to follow trends and perhaps be taken seriously, Python is slowly losing everything that made it so attractive to me in the first place. Additionally, I think Guido got lost a long time ago...some time around the acceptance of the twisted...I mean async...PEP. Dude is checked out and it shows.
&gt; doesn't execute any code Write some tests to have something to run your debugger on? Or just start a normal REPL. 
I personally also think variable annotations will end up being a relatively infrequently used feature, at least in terms of type checking. (However, I _can_ imagine there being other 3rd party tools that extend Mypy and use variable annotations to clever effect. For example, I think it should be possible to implement something similar to [PyContract](https://andreacensi.github.io/contracts/) that runs at runtime using function and variable annotations, but is still fully compatible with mypy and PEP 484 via careful use of subclassing and NewType. But I digress.) I think the benefits are mainly for consistency. If you assign something like an empty list or dict to a variable, for example, it's ambiguous what exactly that list or dict is supposed to contain, so you need to annotate it using comments like this: mysterious_list = [] # type: List[int] The idea is that having a part of the syntax be in type comments is weird, confuses linters who don't understand comment type hints, requires an AST parser to start having to care about comments, so on and so forth. Basically, it makes writing tooling a bit harder. But yeah, personally, I probably won't use variable annotations apart from annotating these sorts of ambiguous assignments myself mainly because mypy's inference rules are good enough that there's really not that much point in annotating most variables. Actually, the main benefit that I personally think variable annotations can bring isn't actually articulated very well in the PEP, imo -- I think an incidental benefit that variable annotations can bring, if used correctly, is that it can help bring us slightly closer to a None-free world. I subscribe to the philosophy that [null is a billion dollar mistake](https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare) and personally always try and use `Optional` in combination with mypy's strict-optional mode to try and detect cases where I incorrectly assume a value can never be of type `None` when in fact it could be. The problem is that it's somewhat hard to do that using type annotations in some cases because there's no way to separate variable declaration and assignment, which is a problem when you have some complex initialization logic: # What if I don't want this to be optional? foo = None # type: Optional[BaseClass] if ...: # some code here foo = SomeClass() else: foo = SomeOtherClass() There are a bunch of workarounds you could do here (stick the logic into a function call if you don't mind the incurring the performance hit of calling a function, annotate the variable assignment inside the first if statement if you don't mind having to dig for variable assignments, etc) but nothing hugely clean. Of course, this isn't actually a problem in untyped Python, since you can just assign a variable once you're ready to, which guarantees that there's no chance of a None sneaking through, and this isn't a major issue in typed Python since there are workarounds, but it would be nice to have a clean way of doing this sort of thing.
The debugger is probably the best in the business when it comes to Python development. For that alone I find it's worth the money.
Thanks for your response! I was hoping for some advice other than meetup, more online ..
yes. in my experience the quality of the automated code-linting, ease of code navigation, and otherwise just well thought-out design save me more time than I think I even understand.
Why not just have this as your whole resume? {NAME} {GITHUB ADDRESS} lol. jk.
I've never actually ran into a problem working in python that has required a debugger. The stack trace is normally informative enough to nail it down. Would likely come in handy on the JavaScript side though... food for thought.
I don't think it has to change the existing API at all, just to offer a new API. If you need to help designing it, I don't mind allocating some thought resources to it ;)
&gt; why is the docstring format nicer[..]? Not nicer, just older, already existing and has existing tooling. And it works in Python 2. &gt; more in-line Ish. Except it's not checked. But yea could be. &gt; not cool Calling a spade a spade. 
Which i3 and which i5? There are many models. Also, /r/SuggestALaptop may be a better place for these kinds of questions.
OK, I'll check that out as well! The two CPUs are actually the Intel Core i3-6100U and the Intel Core i5-6200U.
making the change nice catch thank you! Edit: The OS should close it, but it's just bad practice not to clean up after yourself 
Probably not worth the money, so unless *someone else* is paying, just pick an i3. Buy more mem or an higher resolution screen; that's worth more then 1 second of CPU time.
&gt; The problem came that multithreading locks have no idea about other locks in other processes. *They can*, but the lock has to be constructed in the Parent process, and then the Child processes get forked off. You could, for example, do something like: from multiprocessing import Lock, Process def childMain(lock): lock.acquire() # do stuff lock.release() if __name__ == "__main__": l = Lock() Process(target=childMain, args=(l)).start() But, if the process spawning isn't in your code, yes, file locks are the way to go. The file lock should be stored in a location that has a ramdisk (/var or /tmp, depending on system configuration), and you should write the current PID to it, so if the process hangs and fails to release the lock, you can diagnose the problem.
It will be released soon
So, why did you think that was mine? 
right, but my point is that jetbrains products do it way better. no contest.
As a programmer you need at least 15 inch, and you don't need more -- Me.
Hahahaha Actually, if you started with my Reddit account, and you REALLY wanted it, you could find my Github. The catch is, of course, I would NEVER mention my Reddit account on any of my 'straight' accounts. It's one thing to have people start with Reddit, and find a picture of me rock climbing. Their opinion of me can only be improved if they're starting with Reddit. 
Where/when/ what was the mention of improving performance? I thought that he didn't care about cpython perf and was pushing for moar C.
Reddit is nothing. Look up a person's twitter to know their real shit.
You might hit the limit of open fds if you don't clean up
I do not twitter. I don't even think my Reddit comments would get me in any trouble, really. I have a tumblr that is all pretty ridiculous Cyberpunk stuff, with a personal tag that shows ridiculous Cyberpunk stuff I've made ... so, slightly embarrassing, maybe? But, even there, building a completely functional set of Cyberpunk-inspired clothes, complete with wearable computers and night vision, is probably going to work FOR me in a tech job. I would leave off Tumblr and Reddit, for sure, just because I don't want to sweat in the interview, but Facebook, Github and G+ are all very appropriate for work. Ultimately I don't have anything to hide ... I'm a giant nerd, but that's probably a good thing. 
Man that was the coolest story I've ever heard, I gotta say.
Indeed it is. Keep paying, or you lose access.
It's possible!
Sorry, slow day, thinking with my fingers. 
&gt; I've never actually ran into a problem working in python that has required a debugger. &gt; save me from writing a bunch of print statements. This tells me that you HAVE run into problems that ~~required~~ could have benefited from a debugger, you just fixed them the hard way.
Ummmm nah.
Do your own homework. Ask questions about *python* in /r/learnpython
you should use updog to solve this problem
I'm super excited at all the 3.5 activity. I'm a lurker on their commits and just enjoy the energy now going into Python 3.5 support. Keep on the good work!
&gt; Which makes no sense to me at all based on their identifier names. Why would hitting a ship damage all ships of that class? It's not -- the `stats` dict is just keeping track of how many times your entire fleet of ships was hit in total. (Perhaps this is for a game where you're controlling an entire fleet of Starships and you want some nice stats about how effectively you commanded the entire fleet displayed at the end?) Granted, it _is_ a bit of a contrived example. 
PyCharm is absolutely worth the price. It works out to less than a dollar a day for the first year's license, and even cheaper after that as the price decreases. Considering the quality of life boosts, productivity gains, and the number of times it's saved me from myself or automated a refactor, totally worth it. I spend WAY more than that every year on Mt Dew. Dropping the money on a tool that makes me better at my job is a no brainer.
With the Pycharm debugger you can set up breakpoints that don't stop program execution, but write a message to the console instead. This can include printing the contents of variables or executing an expression. This gives you all the benefits of logging or print statements, without having the modify the code. You can also attach the debugger to any running python process, so you do not have to start the process from pycharm to get the benefit. I have used these two features to debug a long-running service without having to stop or interrupt the service while doing it.
You didn't ask. But WingIDE is worth the cost just in time savings alone. Compared to PyCharm? I do not know. I did recently look at PyCharm to see of the switch from WingIDE was a good idea and couldn't find a compelling reason. I've used WingIDE for roughly 10 years and the few times I need support they were awesome. The updates are regular and I have never had an update break existing functionality. YMMV. 
You forgot "Go to declaration". For me this is the most important reason for using Pycharm. It works both for Python and Javascript and it has saved me hours of debugging and better comprehending of the frameworks I use. 
&gt; PEP 3107 introduced syntax for function annotations, but the semantics were deliberately left undefined. There has now been enough 3rd party usage for static type analysis that the community would benefit from a standard vocabulary and baseline tools within the standard library. 
£20 cash up front you got yourself a deal.
No, that's not possible without specifying the keyboard layout.
http://stackoverflow.com/questions/18954645/detect-keyboard-layout-in-nix-in-python
You can program perfectly well on 10 year old pc's. I've used an i3 before, works just fine.
The most important thing to metion here is that left side of that boundary condition should be &lt;= I would say.
Cool! needs to be promoted more. any docs on this?
So your recommendation is fraud?
Github now has pinned repositories, isn't this enough? 
Finally moving up from your old 5100, eh?
Depends on what you're doing but if it's a modern CPU the i3 will likely be enough for you to never be a bottleneck - RAM and disk speed is more often a bottleneck for me (work with large data frames and SQLite DBs) E: For pure programming endeavors. For other things you may be CPU limited.
You never really *need* a debugger with python - that is true. They are a convenience that serves to improve your productivity and if I have a lot to do I appreciate being able to debug hundreds of times faster. For example it's one thing to read the stack trace, another thing entirely to actually be able to inspect any of the variables mentioned in the stack trace and dive into their values. Or to set breakpoints and inspect the local and global state, or to set up watches to see what happens to data as it moves through the system. None if this is needed, but all of it is tremendously time saving and helpful.
&gt; Also, is it not completely optional to use with Python? Python 3 annotations were supposed to remain with no specific purpose for all time; core developers were even told to not use them in their code so as not to influence the community as to how they should be used. Then came MyPy. This stuff will be optional... for now. In addition, if you ever use anyone else's code (and the vast library ecosystem is a major selling point of Python), you're going to have to deal with it whether you like it or not. 
Google for wget to download full website, I'm on my cellphone, but if I recall it right it was wget -mkEpnp http://wikirootwebsite.com
Do you need a PDF or just a local copy of the website? If you just need the information, wget or httrack can do what you need.
I've been waiting for this release!
A lot of the answer to this question is probably depends on what you are using to edit your code. If you're doing everything in vim, you're probably fine with a 10 year old computer. If you're doing everything in Eclipse + PyDev with a whole pile of other stuff, and you're running Chrome, and you're running a bunch of other things, you might prefer the i5. Chances are that you're somewhere in between those extremes and the i3 will be pretty much the same as the i5 for your purposes.
If/when possible, try switching to a message-based architecture where none of this is necessary. I've been using [rabbitmq](http://www.rabbitmq.com/) with much success.
DL'ing wget now, I think I found a solution.
No
Thanks, it works now.
Actually it ALMOST worked. The HTML files all downloaded in their respective folders but they won't open. They just become unresponsive in Chrome.
This was actually the command I needed, not sure what it means, but it works: wget --recursive --html-extension --page-requisites --no-parent --convert-links http://url-of-wiki.com
&gt; fcntl.flock(f, fcntl.LOCK_EX ) &gt; try: That gap between the lock and try makes me nervous. What if you crash there?
This sounds fascinating. I do a lot of work in R so the fact that it supports that language is great. Is there an IDE? Does it work with Windows?
Does ~= make sure on the minor version? For instance, if I want to ensure I have 0.4.*?
The "IDE" is in browser. It's actually a lot like Maple. There are code cells, output cells, and text cells. It's somewhat annoying for large package development in that you often want to keep the files fairly small, so you end up removing code that is done out of the file and putting it somewhere else. However, it's perfect for trying different things out and demoing software.
It does have a pretty decent vim mode. https://confluence.jetbrains.com/display/PYH/Configuring+PyCharm+to+work+as+a+Vim+editor
Yes, that would be easy.
First of all, let me just say that I HATE the Robot framework. Secondly, let me answer your question. Are you using Jenkins? If so, you can replace Robot with nose, pytest, etc and dump the results in JUnit format. Jenkins can display that like the Robot results, although it won't be quite as pretty. Although, every CI tool on earth supports the JUnit format and even Jenkins might have a better plugin that I haven't tried yet. Also, you could even write your own plugin to do just that. You could even figure out the Robot format and use something else to run your tests, then convert the results to that format. tl;dr run your tests from a test framework that can dump them in JUnit format. If you are interested in why I hate the Robot framework, I'll tell you but if you're not I won't. :)
Yes, I hate robot as well! hahah. And yes, we're using Jenkins. Thanks for the input, I'll look into JUnit and the others tomorrow.
I use PyCharm all the time. I bought the All-Products pack so I can use PhpStorm and DataGrip as well. Huge fan of JetBrains' products.
I don't understand how this can pass 99% of the numpy test suite. I don't understand what's missing, or how they make progress. Is numpy not just implemented with regular C and python code, but C code using CPython specific libraries or something? I don't get it.
RAGE. I feel a deep seated rage when I even talk about it! :) It is an over-engineered piece of shit.
NumPy is written using the [Python/C API](https://docs.python.org/2/c-api/) The Python/C API assumes details of CPython, like it being written in C and using certain C structs like PyObject. It doesn't work easily for different implementations of Python like PyPy or Jython that don't meet these assumptions. PyPy contains a module called cpyext that attempts to simulate the Python/C API from Python. It's pretty close, but not perfect. Note that even if PyPy someday passes 100% of the numpy test suite, that doesn't necessarily make it as good as CPython for running numpy. Speed is also a factor. PyPy is usually faster than CPython for running Python code, but cpyext is not always fast. (cffi is another C binding for Python from the PyPy team, that attempts to be more implementation-neutral. If things like numpy were written in cffi, that would be easier for PyPy. But there's a ton of legacy code out there that people don't want to rewrite.)
PyCharm has a good Vim plugin. I am a heavy user of Vim and PyCharm so they definitely aren't mutually exclusive
YES
I couldn't find anything but i would recommend watching out for when you define your type long values. If i recall correctly, not using a period when defining the variable will cause python to think it is an integer. Then it wont perform multiplication and division as it should.
Look up Rodeo too, its an ide very similar to rstudio.
Crazy coincidence, and still, no one helps. Just down voting for some reason
http://notebooks.azure.com - free, has python, r, anaconda.
Conda is a case when you pay a company for the maintenance. If you are releasing a commercial software package, you have to calculate these expenses anyway. 
I honestly don't understand the value of this post. There's a 30 day free trial for the professional version of pycharm. The community edition is free forever. Download it. Use it for 30 days. Decide if you want to spend money on it. Surely you can decide for yourself if it's worth the expense after 30 days of using it?
You could also jist insert a breakpoint with ipdb in your script at the place you wish to inspect.
Definitely agree with this. The fact that you can enable pycharm debugging in a remote process and forward its debug interface across the network / through your VM's into your pycharm IDE is pretty lifesaving at times.
I've used [this](http://facebook-sdk.readthedocs.io/en/latest/) to post before. [It explains how to post as well](http://facebook-sdk.readthedocs.io/en/latest/api.html).
&gt; I HATE the Robot framework RF is a blessing/curse - the management know the name, like that this is a ROBOT (read *"will save real human work cost"*) and the reports are colorful and nice. But on the flip side the tool is easy to use and easy to teach to the new people. Just be aware that having only a hammer turn everything into a nail.
It's more like lying to get a handicapped parking permit.
Or better: pudb 
I call BS on doing as good static analysis as pycharm does. Does your vim setup catch this for example? def foo(a): return a.b class Bar: def __init__(self): self.b = 1 foo(B()) 
As someone who's still kinda new to Python and who uses PyCharm: daammmmmnn I need to learn how to use the debugger properly. To date, I've been using the naive approach of just sticking print statements in everywhere, but the more time goes on and the more I learn the more it becomes clear that I ought to learn how to use the debugger properly because people in this thread are mentioning that you can do things that I had no idea was feasible, but would make life so much better... Is there a good guide to learning how to use a debugger properly? Or should I just jump in and experiment and learn that way?
look up the code and search for each if statment where you see this line like : weapon = sword.copy() remove copy() cause its a list then you can play it
I'm not sure what you mean? It catches `B()` as an `undefined variable`, and if it was a typo and you meant `foo(Bar())` then that shouldn't error anyway... ? Maybe you meant: def foo(a): return a.b class Bar: def __init__(self): self.c = 1 foo(Bar()) Which I believe PyCharm would catch, but you are right, my Vim setup doesn't. I'll survive - PyCharm's static analysis is superior but its not a big enough benefit to switch back :-). 
Actually I just ran it through Jedi linter and I get `E1 AttributeError: &lt;eInstance of &lt;eClass of &lt;Class: Bar@5-9&gt;&gt;(&lt;Arguments: ()&gt;)&gt; has no attribute b.` So maybe I need to look into getting Jedi to lint the code as well and then it does catch that ;-).
If you just want a solution to your problem you can use Shapely to simplify everything. I don't see anything alarming with your code though.
It would not be that difficult to create a template that renders a unit test in HTML like the one you linked, imo.
None of my projects are open source. It's pay or nothing for me.
PyCharm gets my vote.
I currently use atom, but what is drawing me to pycharm is all the integration. I can run everything in the ide. No more digging through a mess of open terminals. 
Cool! They need to work a bit on their error messages though :P
For all the not-vim haters: I run IdeaVim plugin in PyCharm, it works quite well. Especially in conjunction with optional typing in python 3.5 it rocks. In many cases free version of PyCharm is enough though.
https://www.python.org/dev/peps/pep-0440/#compatible-release
your examples are unreadable because you `from pipeleaflet import *`. Don't do this. What comes from your namespace?
I've only been coding a couple of months, so this is probably wrong in many places - but it does the job... w = input("TYPE A WORD:\n").upper() topROW = ['Q','W','E','R','T','Y','U','I','O','P',' '] midROW = ['A','S','D','F','G','H','J','K','L',' '] botROW = ['Z','X','C','V','B','N','M',' '] if len(w)&lt;1: print("PLEASE TYPE IN A LONGER WORD") def checkBot(word): if word[0] in botROW: for i in range(len(word)): if word[i] not in botROW: break if i == len(word)-1: print("YES") def checkMid(word): if word[0] in midROW: for i in range(len(word)): if word[i] not in midROW: break if i == len(word)-1: print("YES") def checkTop(word): if word[0] in topROW: for i in range(len(word)): if word[i] not in topROW: break if i == len(word)-1: print("YES") checkTop(w) checkMid(w) checkBot(w) 
&gt; someone with thousands or hundreds of commits and the latest is within the last year Holy shit is that even possible!? Forgive for my ignorance, I am still at the "learning basics" stage of coding, so I'm not entirely sure of how GitHub works, can you give me a crash course on it?
Add - print("NO") before the break statement if you want it to print no... 
I just wait a very long time before I release a 1.0.0 version.
Sorry, I immediately stop reading at bad practices
Yeah I can understand that. I found for me that I ended up using the terminal regardless and would rather have a proper terminal and be using screen and what not on another screen. If you can get your employer to get you a copy or better yet use the community edition and see if it does what your hoping for. Regardless of anyone's opinions what really matters is what works the best for you. After that it's not too important so I'd say give the community edition a try and if you're finding it advantageous then go buy it.
Yes.
I use PyCharm with the vim emulator. Since I run on Mac, ⌘ is used for PyCharm shortcuts. And I set command+shift+v to toggle vim mode if I ever need normal editing.
You can get a 1-year student license for FREE if you have access to a .edu email address.
i agree. Unless you're doing heavy data chrunching, you won't notice the difference. On the other hand, if you're a novice and you're doing heavy data chrunching, and having unacceptably slow calculations, there's a pretty good chance that you've chosen the wrong approach. In that case, a faster processor won't help you :-) I think you'll do fine with an i3 :-)
Instead of sounding like an asshole maybe you should provide some constructive criticism for improvement and provide a reason why "Don't do this". Not all of us are super programmers and it is comments like this that keep people from sharing projects that others might find interesting. 
A listener requested that I start covering some terminology. I think it’s a great idea. Covered in this episode: * Test Fixtures * Subcutaneous Testing * End to End Testing (System Testing) I also discuss * A book rewrite * Progress on transcripts * A story from the slack channel If there are other terms you'd like to get discussed on the show, please let me know. 
I'll start off: I chose pytest years ago and never looked back, it does what I need and more. I don't know anyone using unittest nor nose, but I see it every now and then on reddit.
&gt; Honestly 90% of the benefit from PyCharm was the linting and static analysis, but vim can do that too with the right setup. I don't believe this. Just like sublime, and atom supposedly have just as good linting and static analysis, they are kludgey compared to PyCharm. I think vim is a great editor, and after gaining proficiency it's a piece of cake to hack out code quickly, but for larger projects, PyCharm is like having an assistant help out with all the boring stuff.
Btw, I would make it about pytest+tox+travis, very awesome combination :) Add on top a way to handle PyPi versioning and you're helping the whole python community. Don't listen to me, I'm as biased as can be :)
I think nose development stopped some months ago, right?
To automatically write the data to a spreadsheet: https://github.com/burnash/gspread
PyPI don't approve or disapprove packages. You can just upload them :)
Yes. I believe it stopped quite a while ago. But it still mostly works. As a counter example to don't-use-tools-not-being-maintained, I have no idea when the last feature or fix for bash went in, but I still use it every day.
I'm a linux guy by trade, not just a python developer. Atom is nice because it's not married to one language. Atom + terminal is very powerful combination.
Aa someone having pytest+travis, what is tox for? Why should I use it?
TIL I should be using pytest. I'm a happy Nose user, I didnt't know development had stalled...
Yeah man I wasn't trying to say pycharm sucks or anything. I was a past user of the paid version (work), and it was fine. But I switched to atom when it came out and I do get everything I got from pycharm and more. Pycharm also took up a bunch of cpu when I first installed it too and I had to look up how to configure it not to. In my experience it's laggy and not worth the money compared to atom.
This looks amazing. I also have to say I like this guy's style. - MIT License. - LinkedIn page linked to the bottom. &gt; Software engineer specialized on GPU architecture and device drivers. A few billion smartphones have shipped with his work. Works at Qualcomm. Well I guess I know what features they're going to start shopping around to companies for their next set of phone chipsets. 
Atoms PEP8 lint is stunning right now, they have knocked the ball out of the park there. 
Frightening but awesome
I use a computer with a recent generation i7 for coding because I work on HPC codes so when I go to test them I don't want to wait forever for the debug run to finish. But I'm a unique case because of what I do. If you are just coding and making desktop applications or command line programs you could do a lot of this work on a Raspberry Pi or a 10 year old laptop if you really wanted to. Which I might add I have done that with a Raspberry Pi before when my old laptop's hard drive stopped working. Coding is not CPU intensive most of the time even if you use a fancy user environment. So pick whatever fits your budget and what has features you like. You really only need the computer resources if what you are testing has a high cpu requirement.
gonna assume that all punks are actually just trying to avoid surveillance systems. https://cvdazzle.com/
This is really cool. It looks like they generally get the direction the person is facing and basic shapes correct. The head shape, jawline, cheek shape are all pretty darn good. But the faces that the network generates are not the faces of the people. They're all browner (probably closer to the mean face color), the noses and eyes are often the wrong shape. Might as well just shop an eigenface in there. Again, really cool that sharp faces are coming out, but these aren't useful *yet.*
This will get you started: import os for root, dirs, files in os.walk("."): for name in files: print(os.path.join(root, name)) for name in dirs: print(os.path.join(root, name))
Why not use pytest for collection and execution, and coverage? Actually, I don't understand how you can use pytest fixtures with a nose execution engine. Are you sure? Or are you using nose for some tests and pytest for others?
I know. I've done super resolution work in the past, but not like this. What I did involved no deep learning at all. I worked on images taken in close succession to produce a single, higher resolution image. I also used the same technique for Shack-Hartmann Wavefront Sensors for deconvolution of blurred images.
Thanks for the response. A toggle option seems like a viable solution. 
[removed]
So what *is* the goal here if not accurate face reconstruction?
Plausible face reconstruction?
If that's the case then I say the result is darn good.
&gt; Image super-resolution through deep learning Anybody got s short description of how deep learning works?
So, this subreddit is now a place to come to beg to get your homework done for you? 
Thanks for the suggestion. I definitely want to cover tox. Travis would be good but that limits you to github only. What do you mean by "a way to handle pypi versioning"? Do you mean for dependent packages? Or for the package under test?
&gt; goddamn motherfucking Cucumber Will not go there. My boss loves Cucumber. According to him it lets non-technical people to write tests. Won't go there. So. What tools do you recommend? You have strong opinions on subject, can you recommend something? What do you like?
Can someone do am ELI5 on what the MIT license entails and what makes it different from other open source licenses? 
On any Linux distro with python3 and virtualenv installed, you can type `virtualenv -p /usr/bin/python3 venv &amp;&amp; ln -s venv/bin/activate &amp;&amp; source activate &amp;&amp; pip install jupyter` to install jupyter in a python virtualenv. You can then run it with: `jupyter notebook`
&gt; where the hours range is from 0 to 12 nah, that's not how 12 hour format works, there's no 0:45 PM
There is no negotiation, or approval on PyPi - the whole python ecosystem is based on the principle of 'Consenting Adults' - i.e. it is assumed that developers follow the conventions on version numbering, and that you peg your releases to particular releases of your dependencies, which means that the only thing suspectible to breaking changes is your development - which you sort of expect anyway. I don't know anything about the other ecosystems - but on PyPi a negotiation with your users would be impossible since you cannot know who has downloaded your published package - let alone who is using it.
Since you seem keen on the internals, I recommend this lecture series: CPython Internals. http://pgbovine.net/cpython-internals.htm It really helps to demystify python. It's from 2014, so uses python 2.7, but it mostly still applies.
http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA591376
No he didn't 
Maybe I'm using the word "negotiation" too broadly -- but even though users and developers are formally protected by the semantic versioning rules of the road, nonetheless users will in some cases initiate contact with package authors to report bugs, offer pull requests, ask for help, or discuss the future of the project on a mailing list that the developer sets up. Or package authors will meet at a conference or something, get to know each other personally and coordinate their efforts. We've seen some evidence that the differences between ecosystems' rules, e.g. PyPi's lack of approval in contrast to the curation of CRAN or Bioconductor, influences how those collaborations play out.
[nose2](https://github.com/nose-devs/nose2) is alive and kicking.
It's functionally loosely equivalent to dumping it into the public domain (except I think the credit and license must remain in the source). Since the laws surrounding the public domain are fuzzy and vary by country, it's a way to uniformly allow *developers* as much freedom as possible. Whereas I prefer to protect the *user*'s right to run, redistribute and modify the program and give a big middle finger to developers who want to use it in proprietary software. (Those who hoard from the common good should not benefit from it.) Thus, I use the GPL.
I like the [wtfpl](http://www.wtfpl.net/) license.
&gt; According to him it lets non-technical people to write tests. Won't go there. Exactly. Non-technical people shouldn't be writing those tests then! They should stay away from code if they can't understand it. And if you can't understand Python, Ruby, Javascript and friends (the scripting languages basically), then you really have no business automating anything. And not to sound like a complete asshole because I have known a few manual QA engineers over the years who are quite adept at finding and tracking down bugs while not even being able to write a batch file or shell script. It's rare for sure but these people do exist. They are either people who just hate programming but love tinkering and breaking things or probably could code but for whatever reason(s), have convinved themselves that they can't. Anyway, I recommend using unit test frameworks to drive tests. JUnit, pytest/unittest/nose, rspec/minitest (although I do hate the BDD style in rspec), mocha and friends in the Javascript world. . . all the major languages have at least one or two such frameworks. That being said, unit test frameworks do come with their own set of biases. The main one is the whole concept of test isolation. Sometimes, I really do want to run a set of tests in a specific order and I do want to maintain state. I'm a big boy and I know what I'm doing. Also, while unit tests are wonderful, they tend to enforce developer silos. Where programmers are almost encouraged to only think about and code for their own module/project/class/codebase/etc. No end user anywhere runs unit tests and you have a major problem on your hand if those "units" don't play well together. Yes, I've seen all the test pyramids and I've read drivel like this: https://googletesting.blogspot.com/2015/04/just-say-no-to-more-end-to-end-tests.html I found this post recently and it echoes exactly how I feel (and references that google post as well): http://danmux.com/posts/test_pyramid_availability_bias/ OK. . . back to your question, so unit test engines/drivers are great but I don't have a great answer for what's better other than something you write yourself which may leverage a unit test framework. Of course, you'll probably also use CI/CD tools and source control tool and any number of build/DevOps/deployment tools. And for specific testing efforts, like load testing, you can use JMeter (another piece of crap) or related tools. I'm currently using (and enhancing) a home grown load test tool but if I wanted to use an existing tool, I'd give Gatling and/or locust a test drive. I've written many frameworks myself but I don't know of a good general purpose test tool. I would love to open source something some day but I'm pretty busy with work. Although I may open source something I build at work eventually. There are tools like [STAF](http://staf.sourceforge.net/). That's kind of like Robot but not a lot of fun to use either. :)
The Skrillex image is the best: like the model was trained using his music rather than other images.
You're my kind of developer
Used gspread. Ok to edit n fill in spreadsheets, but God forbid if u wan to create a new spreadsheet programmatically.
As a BSD guy myself, thank you for a simple and relatively non-inflammatory review of the subject. 
Currently I'm using [beets](https://github.com/beetbox/beets) to process albums/MP3 but the log is only of albums it processes. Any albums that aren't a good match percentage wise (missing tracks, incorrect names) I skip. The purpose is to have a list of albums that are incomplete, Download again and deleted he incomplete one. The issue is in currently seeding ~4200 of the 6733 albums I have. I'd like to be at 95% seeding or better. But that's another component. 
Google turns up [this SO question](https://stackoverflow.com/questions/4932337/how-to-create-sphinx-based-documentation-in-a-jython-project). Basically I think full-on autodoc for jython/java doesn't exist yet :/
[A lot](https://github.com/search?l=python&amp;q=%22import+nose%22&amp;ref=searchresults&amp;type=Code&amp;utf8=%E2%9C%93) of existing Python code uses nose, so I'd say yes. [pytest](https://github.com/search?utf8=%E2%9C%93&amp;q=%22import+pytest%22&amp;type=Code&amp;ref=searchresults) has more, but not that much more. [unittest](https://github.com/search?l=python&amp;q=%22import+unittest%22&amp;ref=searchresults&amp;type=Code&amp;utf8=%E2%9C%93) is even more common, so I'd definitely include that.
FWIW I've heard a lot of good things about Celery from my webserver friends, and plan to use that when my jobs go from batch to real time.
Unittest is relevant for me. It's quite possible that I don't know what I'm missing, but it does everything I think I need for local testing. It's well documented and fairly straight forward to use. I try to avoid anything that is not well documented.
Ah, so they are like example problems to help demonstrate particular functions and various ways to tackle problems using Python's syntax. I get what you mean now. Those can be very helpful. Sometimes just reading the same explanation in different words/context can really illuminate a concept for learners.
Four characters less typing :-), an IDE not syntax highlighting the field name as if it were a string, etc. And no more Delphi flashbacks, where until recently the database access would look something like user.FieldByName('name').AsString Python is a dynamic, object-oriented language, and I want a dynamically generated object, dangit! :-) 
In that case a bit of character substitution would be in order.
Although I love py.test at work stuff has to work with unittest since extra dependencies require setup/politics. Im just happy I can at least use requests.
stallman would be proud
Maybe this? -&gt;https://github.com/errbotio/errbot-backend-skype Not sure if it is still compatible or not.
If you like automatic features, PyCharm is awesome. If you prefer to play it simple, I like Vim for that. Really it's not any different from any other language in Linux.
I just did something with powerpoint and discovered that interaction with office programs in python is really straightforward using the COM interface with pywin32's win32com.client.
+1 for PyCharm - plays nicely with cookicutter too (i.e you can build PyCharm 'projects' automatically - including which virtual envs to use, and which files get opened with PyCharm opens the project for the first time - and even which order the files appear on the tab bar).
Development stalling is often a good thing.
Every major Linux distribution has included WTFPL-licenced software and libraries for years without any problem.
I think the liability is more on the deveoper than the distributor. If cars start accelerating randomly, its the maker and not the distributor that eats the cost.
Same here, atom with linter and autocomplete addons. 
Also, sometimes the problem is in some third party package that doesn't easily expose what you need to see. In some cases, all of the print statements in the world won't help. 
Yes, and start looking for a man instead of a woman (see last face in the examples). I can actually imagine that finding the correct person after seeing the "enhanced" image actually becomes more difficult.
You're so fucking right. I can't fucking stand when people fucking swear it gets on my fucking nerves. 
This sounds like a good fit for the Pandas package. Pandas is basically spreadsheet software in Python. Data can be read from websites with [read_html](http://pandas.pydata.org/pandas-docs/stable/io.html#io-read-html) and written to an .xlsx file super easily.
A mention of continuous integration services would be useful though as it's a concept that people learning about testing should become familiar with. You could mention Travis (or others) for GitHub, [Pipelines](https://bitbucket.org/product/features/pipelines) for BitBucket or the [built-in CI](https://about.gitlab.com/gitlab-ci/) for GitLab.
I use vim and tiling window manager. GNU/Linux is the IDE.
Wasn't this featured in one of the Elementary episodes?
Another vote in favour of focussing on pytest. It would be great if you could cover BDD testing with behave or pytest-bdd as well.
And it's barely even dark magic since they moved from reevaluation to AST rewriting.
You can also use tox to run one command "tox" and it'll set up virtualenvs for all the different things you want to support and run the tests in all of them. For example, we have a lib with this: - python 2, 3 AND pypy 2.7 - django 1.7 - 1.10 That's 3*4=12 combinations. But with tox that's just 10 lines of config: https://github.com/TriOptima/tri.table/blob/master/tox.ini We also have setups to build docs, coverage data etc. All with separate dependencies. It's pretty awesome.
py.test runs nose tests afaik... so unless you have a lot of nose plugins the move over should be trivial. The output of py.test is better. And the setup. With tox it's just another league.
Your question doesn't have a ton to do specifically with Python. It sounds more related to application design and perhaps a bit of dev ops. If I were you, I'd take a look at the [Django project](http://dfpp.readthedocs.io/en/latest/chapter_01.html), go through its Hello World tutorial. Then build a vanilla app that has some of the features you want, just so you get an idea of Django's conventions and popular plugins (if this were r/ruby, I 'd say the same thing, except with Rails). I'm not suggesting you go on a year-long journey of discovering how Python/Django works. I'm thinking a couple of weeks to better understand the eco-system, be aware of wheels that you don't need to rebuild for yourself, and more importantly, get a better understanding of best practices in web app development, much of which can be found in the foundation of Django's design and workflow. It sounds like you don't have the experience yet to build a solid public-facing app. Taking a few weeks to step back and learn some more unknown unknowns is nothing compared to the time it takes to maintain a inadequately designed public application. It doesn't sound like you know enough to build a solid public-facing app, and that's
text
test
Do you know good alternatives?
I think since nose is no longer actively developed (afaik), it can be excluded (or at least de-emphasized). There is nose2 though, with around 240 stars on github. Pytest is far and away the best one, but there is still a need for unittest (some people have a requirement of not using external libraries, not many - but they exist).
Yeah looks better then I remember although it would take a while to walk through the details, makes me wish Python had macros.
You can use `requests` and `urllib` with Python, but this won't open Chrome. Look into Selenium to control Chrome. But here's an example on how you can submit data to a form using Python 3: import re import urllib import urllib.parse from urllib.request import Request, urlopen from urllib.error import URLError, HTTPError url = 'FORM_URL' values = { 'field': 'value' } data = urllib.parse.urlencode(values) data = data.encode('utf-8') url_request = urllib.request.Request( url, data = data, headers = { 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36' } ) The script will go to `FORM_URL` and submit `value` to the `field` input (This is the input that has `field` as name, i.e. &lt;input type="text" name="field" /&gt;`). What you should be careful are websites where the "form submission" is not a single form, but rather multiple pages until "form completion". Look into BeautifulSoup library. You can use it to read the page response and parse the HTML.
Unfortunately, I'm off the project since 2 years ago. I dunno of any alternatives, other than directly interfacing with google's api
I haven't used Python for webscraping, but I can attest to the power of the Pandas package. I learned Python solely because I found Excel cumbersome and difficult for what I was trying to do. 9 months ago I didn't even understand what programming was. Now what took me hours to do in excel takes minutes using Python/Pandas. Check out the e-book 'Automate the Boring Stuff', it is fantastic and there is a chapter on webscraping: https://automatetheboringstuff.com/ 
/r/learnpython
A friend of mine just had this issue. We ended up having to delete the c:/pythonXY folder, run installer to repair, then uninstall and then reinstall fresh. The reinstall after the repair was necessary to get pip working again.
I'm a graduate student in materials science and I have been using python nearly every day for ~ 3 years (I do a lot of data analysis). My workflow is continuing to get better, but I'm finally quite happy with it as of a few months ago. The best thing is the Jupyter Notebook, but I can't tell if you are using that or not. For example, with the Jupyter notebook you can delete the small code blocks like `len(arr)` when you don't need them to remove clutter, and you are able to run code _blocks_ rather than single lines. I think this fixes some of my major issues you mentioned in your post. Jupyter is also nice because it's a clean interface that is run through the browser and supports images. I run all my code on servers that I have to ssh into, which is a major pain for IDEs and actually looking at my results. However, I can open an ssh tunnel to my server from my localhost (wherever I am in the world), and start up jupyter in my localhost's browser! This is fantastic, and there is never any lag. In addition, the "save to pdf" option in the Jupyter notebook autosaves all the images in my notebook, so I can send these to my boss or even put them in a paper. You can also save to pdf or "checkpoint" your notebook in order to save your current state so you can go back to it later (you can also version control it easily via git). Jupyter is my IDE, so I don't use pycharm or anything else. It's all contained here. However, Jupyter is best for development. If I want production code, I almost always copy-paste and refactor all the key parts of my development into a "production" script. So my general workflow is: * start up a jupyter notebook * write a code block to load my data * write a code block to analyze my data * write a code block to process / show the results * iterate on the last two code blocks until I get things exactly how I want (I only ever have to load my data once though) * "save to pdf" whenever I do something worth saving * when I finish, I copy-paste what I really need into a stand-alone script, and run that script on the rest of my data I have some colleagues who use latex to write their papers (my boss does not so I don't either), and they have another final step that collects all their figures a paper-like format. Then they can write the text around their figures, and their time-to-publication is quite fast.
While Apache Shiro is a good framework with great concepts, translating a Java API almost directly to python might not be the best idea. Yoasi defines 252 classes (without tests). That is a ridiculously high number for any python project and actually higher than the class-count in Apache Shiro core itself. 250 classes is on a par with the Pyramid framework, a full stack web framework with authentication/authorisation/session components included. Class-count alone is not an argument, sure, but skimming through the sources I see a lot of factory classes with a single method (e.g. ``ThingFactory.make_thing()``), excessive use of exceptions, and other patterns that totally make sense for Java, but are considered (very) bad practice in python. Yosai might be the right choice for developers that already know Apache Shiro or are used to enterprise API overhead, but I personally don't want to memorize and handle five different exceptions just to be able to call ``subject.login()``. This might actually end up being dangerous. In Java, the IDE and type-checker will do the hard work for me, but in python you'd either have to copy&amp;paste a lot from the documentation, or risk forgetting something. Apache Shiro was designed for a type-checked language. If you remove the type-checking but keep the same API you might end up with a framework that is almost impossible to use with confidence. Sorry for the harsh critique. Perhaps my words can help pushing the project in the right direction.
ping the PSF. Or visit one of the autumn conferences, as PyCon UK, or PyCon Ireland. 
They're looking for superheroes to make a dent in the universe. I'm just a lowly rockstar ninja who only wants to change the world. Maybe someday...
I had great success in using the standalone tool pdf2text (part of poppler), and then parsed the results with Python. 
Ipython notebook is the previous name of Jupyter notebook, I used the old name because people seemed to recognize it more, but maybe now enough time has passed. I'll updated my post to say that this is Jupyter notebook Also, run this in your notebook %qtconsole and you will get a shell console connected to the same python.
Unixstickers 
How many? I can send you a few.
&gt; for example I like much more the cell idea in matlab, where you can run cells and the output is in the shell. FYI: There is a cell mode plugin for pycharm. Just bind your favorite key combo to it, and you can replicate Matlab's cell mode functionality I typically use pycharm, with cell mode plugin, and the built-in ipython window. Convenient key combos are bound to "execute line" and "execute cell" The advantage of going 100% pycharm during development, is that you can use all of the built-in introspection, refactoring, etc. with the scripts that you are actively working on (i.e. if I refactor a class, the development scripts I am interactively working on also get immediately updated). You give up most of that capability when you go to the pycharm + something else (notebook, qtconsole, external ipython, etc.) workflow.
sentdex
YouTube channels... looking for Python YouTube channels, not subreddits. And not necessarily for learning either. Just looking for good content.
Jupyter Notebooks for almost the whole thing. I start off with "Myproject_01" and when I get to a point that I think I've learned enough or it works enough I restart as "Myproject_02". You can see this dev cycle with my [Controls Tutorials importer](https://github.com/DadAtH-me/ControlsTutorials_Python/tree/master/DevScraps/BatchImporter) and [my Celery Photo project](https://github.com/DadAtH-me/CeleryPhoto). The goal is by 10 to have 'done' what ever I needed done. By 05-06 I should have a good portion of my code that doesn't change in a library. To do that I use %%file then ```import``` it. My programming methodology could be described as 'throwing stuff at a wall and seeing what sticks' so I depend heavily on the REPL nature of Jupyter Notebooks. Also why I use code cells a lot with Matlab development. So _01 is almost all one liners in single code cells. _02 I combine what works, remove debugging code (aka, print()). Since projects are all in virtualenvs I can also do stuff like `!pip install` from Jupyter if I realize I don't have something. Then when I'm 'done' I shove all of the numbered notebooks in a "DevScraps" folder for future reference and I should have a .py library that accomplishes what I need done. Then I have [pytest-notebooks](https://github.com/DadAtH-me/pytest_notebook_tests) to evaluate my Notebooks and convert it to PDF/MD if needed. The other massive advantage that JupyterNotebooks has over all of them is that it can run everywhere. I have 4-5 machines in my house all of my data resides on a NFS share (/mnt/Python/), so if I need to do GPU neural nets I fire up my GPU machine, run ```jupyter notebook --ip="*"``` and then open a browser and point it there. If it's not CPU intensive I'll put it on the RaspPi. If I need a lot of cores it's on the dual-LGA2011. 
Apparently I'm missing a paragraph in my comment - I had written a few sentences explaining exactly this use case for an IDE. Sorry!
using tox does not preclude using the testing library of your choice. In my professional opinion, tox should be used unless you have a very compelling reason not to use it.
PyCons -- those are _awesome_ ! [PyCon 2016](https://www.youtube.com/channel/UCwTD5zJbsQGJN75MwbykYNw) there are also all the ones for previous years linked P.S.: Mods -- we should really consider adding those to the sidebar...
Sentdex and pythonprogramming.net!
I don't use the notebook for exploring and analyzing data. I personally believe it isn't useful for that purpose. I used to think the notebook was useful but every time I tried to use it I kept going back to my old way of working. I do think the notebook is nice for code presentation - but not for personal work. I have my favorite text editor on one screen and an ipython console on the other. I type in the ipython console when I'm exploring the data and figuring out what I want to do (making rough plots or cleaning data) and then pretty up the code in my text editor (wrap into functions, etc). I find it very efficient. I usually type in the text editor hen copy paste into ipython. Its pretty fast when you use vim key bindings and relative line numbers; just typing `y-6-j` for example copies the following 6 lines. Edit: small typo
yes. I used to have a very similar practice, which sometimes seems maybe easier than the one I have now. writing in IDE and running %run /my/file in the ipython console after each change to the functions I wrote
I suppose he meant you should ask this on /r/learnpython since it's a question about python tutorials
(*Spyder maintainer here*) You said: &gt; Spyder - this is the obvious candidate, but it has one major flaw, the auto-complete in the the editor is not connected to the python kernel This is a really hard one to fix!! This is thing: we can't connect our Editor to an IPython kernel for completions because at any moment while you're writing your code, you can have an invalid file, i.e. something that can't be evaluated without errors. Simple example: import numpy as np np.z If you only write this in a file and try to evaluate it, you'll (obviously) get an error :-) Besides, if you made a mistake and write a Numpy array with one trillion elements in the Editor and we try to evaluate it, that'll simply eat your memory without mercy!! ---- What we (and other IDEs) do to get completions on the editor is to use libraries like Jedi and Rope that can give you completions *without* evaluating your code. However, these libraries have the limitation that (most of the time) they can't get completions for objects, i.e. things like `a = zeros(10)`, although Jedi can get completions of DataFrames ;-) ---- Final words: we have [some ideas](https://github.com/spyder-ide/spyder/issues/2162) to improve this situation, but as you can see, it's a very challenging technical problem.
[Specifics for the lazy.](http://www.unixstickers.com/stickers/coding_stickers/python-programming-language-full-logo-clear-shaped-sticker)
Thanks, so cool you replied! For me, if spyder had the option the use the same system as the notebook for autocomplete (which is just sending the current expression to the kernel) instead of the Jedi static one I would convert to Spyder without hesitations. note the the notebook doesn't run the whole cell once you hit &lt;TAB&gt;, it just sends the current expression in the line to the kernel and also validates that you don't run anything (hopefully), unless the greedy option is used in ipython. Additionally, I used to have a python shell when &lt;TAB&gt; will only run the safe autocomplete and &lt;CTRL+SPACE&gt; will send the line to the kernel for inspection In summery, some combination of both the static autocomplete and dynamic (Notebook style) will be amazing.
Spyder is great. I write everything in .py files with #%% magic cells. With one file you can evaluate cell individually, or run the whole file, or set debug points. Plus, you have the IPython console right there along with the handy variable editor.
Not looking for tutorials either. I'm just looking for people regularly talking about cool python stuff. I come from the JS world, and there's quite a bit of that around. Was hoping python had the same.
I love PyCharm for its VCS integration. Obviously you can do everything it offers via command line but it saves me from having to constantly remind myself the proper syntax for all my push, pull, branching, etc .. when using git/github.
I'm a data scientist by profession and a pure mathematician by training. Here, roughly, is my Python workflow: * I use [pyenv](https://github.com/yyuu/pyenv) and [pyenv-virtualenv](https://github.com/yyuu/pyenv-virtualenv) to manage Python versions and (more importantly) virtual environments, setting up one virtual environment for each project. * Very simple fiddling around (eg "does this function work like I think it does?") is done in the `ipython` command line REPL. * More complicated fiddling around (looking at output that won't make it into any kind of report, tinkering with something where I know I'll need to rerun the same bit of code several times, etc) is done in an IPython notebook. * Reports are given in an IPython notebook converted to HTML (for internal reports amongst the data scientists and developers on my team), or Powerpoint slides (for presentations to business folks...and yes, I know I should use something more suitable, but slides for these presentations often don't have enough mathy symbols in them to require, eg, Beamer). * Other than the above scenarios, I use PyCharm for writing my code (including lots of SQL). FYI, PyCharm does have IPython notebook integration (although it can be a bit more sluggish than a notebook in a browser...not sure why, although this has gotten a lot better in the last few releases), and it has a built-in Python terminal (which, by default, uses the `ipython` REPL if you have `ipython` installed). So, really, I write nearly all of my Python code in PyCharm.
&gt; Let's be brutally honest: for scientific coding of the sort you're describing, you don't need an IDE. It offers few - if any - features that you'll regularly use or which can't be emulated with simple plugins to a good text editor. I used to think the same, but after giving PyCharm a try, I don't want to go back to just a text editor for the following reasons: * Real, honest-to-goodness code completion. Not just completion on the keywords and variables that you've used and/or defined in the given file or project, but code completion built upon all of the libraries accessible to the Python interpreter that's used for this project. This doesn't seem like that big of a deal, but it saves several small bits of time googling and looking at docs (eg, "Is it `urllib.urlopen` or `urllib2.urlopen`? Oh crap, I have to make this compatible with Python 2 and 3...what's the module in `six` that has what I need, again?"). * Excellent database integration: The [database tool](https://www.jetbrains.com/help/pycharm/2016.1/database-tool-window.html) built into PyCharm not only allows you to browse schemas, tables, etc, but it does code completion on your SQL (as long as you're specifying that the given SQL file is intended for a given data source). You can take a glance at a few rows of data, dump data to CSV, import CSVs into tables, and do even more stuff with it. And it runs fast and smooth, unlike pgAdmin (or any other such dedicated database app that I've used). * The ability to connect a project to a remote interpreter. Wanna run your code on a server with more horsepower? No problem. Just give PyCharm the connection information (and the location of the interpreter that you want to use) and you're off to the races! * The debugger. I've only dipped my toes into using this feature, but it's easy enough for someone without a background in software engineering to use, and it's helped me fix issues that would have been difficult at best to debug via `print` statements.
I'm a big fan of Corey Schafer's python tutorials: https://www.youtube.com/channel/UCCezIgC97PvUuR4_gbFUs5g He presents very clean and well thought out examples that demonstrate the concepts he is teaching.
College economics major and AM/CS minor here. I definitely think Python could fit my needs much better than R or anything else but the problem is that it lacks a stats or data science oriented IDE and Jupyter just doesn't cut it. Someone needs to make an R studio like IDE for Python and C++. I've been looking into Anaconda and Sage and some other packages built on Python that can be used for mathematical work. I've also been looking into Scythe in C++ since I know that language better than Python but I think that for now using C++ for simple math would be way overkill or as my Economics, AM, and CS professors would say "premature optimization". 
I'm an R user who wants to use Python, and I came to Reddit looking for IDE / workflow ideas. I've spent years developing my workflow in R. These days I only need R Studio and some good text editors, but I have a system of efficiency though my choice of packages, debugging techniques, and general R knowledge. However, I find that most Python developers stare at me blankly when I ask how they would do "x thing" in Python that I do easily in R. Maybe it just takes a long time to figure it out... but I can't afford to spend the same amount of time learning Python that I spent on R, so I'm also looking for efficiency in learning. So far I've been impressed with the Microsoft VS Code application. It's open source, cross platform compatible, lightweight, and snazzy. I don't quite understand the debugger, but I've been able to make some headway with editing in **VS Code** and using **pdb.set_trace()** in the code (and tracking changes with git). Yes, I just recommended a Microsoft product. Trust me, I can't believe it either. Please note that you do not need Visual Studio for VS Code. The latter is a few mb download that doesn't mess with much, whereas Visual Studio requires total allegiance from your computer. So far VS Code actually seems more at home in Ubuntu than Windows. In Ubuntu I just downloaded the standalone version. A while back I tried **Rodeo**. People say it's an "R Studio Clone", but unfortunately it was like a clone of R Studio 0.1, which was very limited and buggy (back in the R Studio .1 days I still developed R in Eclipse using WalWare's StatET plugin because early R Studio kinda sucked if you knew what you were doing). Rodeo might be worth another look if it's evolved since then. The **notebook approach** seems like it should be the best idea, but I think they're annoying. It doesn't seem like the right way to develop classes and anything complicated, it seems more like it's the way to import code and try one thing at a time or display results. Plus they're another thing to set up, remember how they work, they seem slow, and to me they feel removed from the actual code. I don't like working in an internet browser for something that's on my computer. I've downloaded **Anaconda** many times, but it always confuses me. As I recall it installed python a second time and then caused path issues forever on Windows. However, it's the only way that I have gotten sci-kit learn working on Windows because you need a freaking CS PhD and 4k Intel license to compile LAPACK on Windows. Now that I'm researching this again, **Python XY** looks interesting... I think I'll try that today. https://python-xy.github.io/ Next week I'll probably just need to get something done and switch back to R. I'd love to hear what others think about Anaconda, and anything else I mentioned. I AM TOTALLY NOT A ROBOT, so please be nice with inevitable disagreement. PS: Although it's not Python specific, I think **git** is absolutely critical for workflow management. We use a master / dev / topic branching approach. Github helps too, but git is the real deal for keeping things straight. PPS: Although it's 2 years old, there's a relevant discussion on Kaggle: https://www.kaggle.com/forums/f/15/kaggle-forum/t/4308/which-python-ide-do-you-use-recommend/22901
I use Jupyter Notebooks for presentations and to distill complex results to my advisors Spyder for an interpretive programming and fairly robust IDE experience I still do most of the coding through emacs. Just love it. Love all the versatility.
You are right. There is probably no silver lining here and getting perfect autocomplete is probably impossible. I changed my previous answer to better reflect what I actually wanted to say. In any case, an option to just autocomplete what was **already** evaluated (like what the notebook does) and not use Jedi or any other static tool will, I think, suit for many notebook users now (which are happy to just autocomplete only already evaluated stuff) This does mean that just writing a = zeros(10) a.&lt;TAB&gt; will **not** get autocomplete (which it doesn't also in the notebook) but actually running a = zeros(10) in the built-in ipython shell and then writing a.&lt;TAB&gt; in the editor will bring up autocomplete
&gt; However, because notebook cells can be executed out of order and commands can be sent from consoles, there is no guarantee that a notebook will produce the same output if it is run from scratch. Since we are trying to develop a highly re-producible approach, the flexible features that make the notebook awesome for exploration are terrible for reproducibility. That's how it seemed to me, but I could never get Python notebook fanboys to simply confirm that. I appreciate hearing this, since we too work for full reproducibility. 
This generated a bunch of syntax errors for me. I thought you said your poems are lines of code?! 
Ah... good 'ol myopic deconvolution from wave front sensing. Now there's a fun pickup line! ^/s Wow... cool research.
I use unittests just to avoid extra dependencies/things to explain: I write scientific code with people who aren't developers and it's enough explaining the scientific libraries they need without also explaining different testing frameworks. It works fine for adding quick-and-dirty tests to maintain some sort of sanity in code that is mostly written ad-hoc. 
Vim and ipython console side by side. I prototype in ipython and then copy and paste into vim (there's the history magic for when I've done lots of work), and then I can also run the file in the console. I've never used notebook so I don't know why you'd need it. It's basically the same thing as console, right?
It's definitely still in a beta state, but I'll be uploading it to PyPI in a week or so once I get some feedback/the kinks worked out/etc. Let know what you think or if there's any features you think I should add!
I agree i also follow these: https://www.youtube.com/channel/UC-QDfvrRIDB6F0bIO4I4HkQ and https://www.youtube.com/channel/UCea5cMUa9xNU0kUtbRcTkqA
What are you getting out of the IDE? For me personally, I use nothing but jupyter notebooks. I usually keep a section of cells at the bottom of my notebook for experimentation, though your qtconsole approach does sound nice. I keep a couple empty cells in between to keep my temp area separated from the main area. If I'm writing something bigger, like something I'm importing elsewhere, I utilize the [auto export](https://github.com/ipython/ipython/issues/8009) ipython configuration so that a .py file is created everytime you save so it can than be imported by other programs.
In iPython notebook, you can run cells of code and embed the outputs below. Does org-mode let you do that?
Open terminal at folder X Jupy- tab - notebook Import pandas as pd Where X is the project I'm working on
If you're looking for a GUI: * PyCharm is really solid * Atom/Sublime will do the text editing portion very well (and can build + run with addons) Otherwise, my preference right now is vim in i3-gaps. Beautiful, fast, and easy to use^TM .
 &gt;set tabs to four spaces Starting a flame war I see?
Rather, I mean, when I hit the tab key, kate automatically puts in four spaces (rather than the tab character) in order to align with PEP8. No flame war. Just a setting that needs to be changed to be python friendly.
For most projects it's like this: 1) Setup a private github repo to store the code and/or datasets. If datasets are too large, say &gt; 1Gb, I'd add them to the .gitignore. (Everything is backed up via crontabs &amp; rsync to a separate drive (typically our Synology RAID) 2) I would write a short lists of goals, todolists to check off (or anything else that comes to mind to be done at some point 3) Often, I setup a python package if I am planning to develop new code/tools/algorithms during this project 4) I setup Jupyter notebooks for the different analyses I want to do. I number them sequentially according to the workflow ... e.g., 1_data_cleaning.ipynb, 2_exploratory_analysis.ipynb and so forth 5) If I develop new code, I do this in the Python package using the Atom text editor, and PyCharm. Often, I setup the unittests in in parallel, which also helps with debugging 6) I import code from this package mentioned in (5) and any other classes and functions I need in the Jupyter notebook, I don't develop code in the notebook itself to keep it "relatively" lean so that I can focus on the analysis itself. The notebook is mostly composed of labeled sections (via markdown headlines), equations, notes, the data analysis, plots, and more notes 7) Once I am done (often also with temporary results), I write short reports and sometimes prepare lean powerpoint presentations if this is a collaboration 8) Once the project is complete, I will pool everything into the report to the funding agency or write-up a paper for an academic journal 9) The python package developed during this project will be cloned and cleaned up, meaning, I will get rid of code that wasn't used/discarded in this project. This is then something I would share with the reviewers or readers
Question: Are there plans for Numba to get a more expressive type system at any point, or will there still be concrete (non generic) JIT classes and ducktyped functions forever? &gt;naively trying to reimplement the core logic in Python Why won't that work? Julia did it.
Anything in particular? Tutorials? Web dev? Machine learning? Stats? General?
I use Spyder because it is like Matlab and easy AF, and my students like it too...Coming from Matlab it was the most natural, seamless transition. Workflow is like Matlab. Work in the editor. Hit F9, or just run the script. If it works, yippee. If not, write code until it does. :) Everything else I have tried either is too slow and high overhead and learning curve (PyCharm grinds my computer to a halt), or not quite enough bells and whistles (Eric, Notepad++).
I do everything in either Sublime Text or Atom, and switch to the Terminal to run scripts. One thing I've really disciplined myself into doing is writing scripts that follow the UNIX philosophy - do one thing and do it well, and, to handle text streams. Normally I might write one script to handle the fetching, wrangling, and collating of data, and another script to visualize it. Now I'll break that data-wrangling process into at least 2 to 3 scripts. The work goes much faster, I don't need an IDE to keep track of things, and it feels much more satisfying.
I just added a full support for ABC (and subclasscheck too!) in the dev branch of the project. It will be fully enabled by the next release. Stay tuned. =)
I use three windows: a text editor with syntax highlighting and basic code completion features; a console (or command prompt) open in another window set to my working directory; and one open python interpreter. I test things in the interpreter interactively, then write the code in my text editor, and run the code from the console. My code has the usual: if __name__ == '__main__': import doctest doctest.testmod(verbose=True) And I tend to write doctests, but that's the full extent of my testing and documentation. I target the list of packages provided by default by Winpython (even if I'm developing on unix). Then, for deployment (to other scientists), I simply add 'This code assumed the dependencies included with Winpython 3.3.x are available' or whatever. Finally, and I know this will annoy some people, I use unicode in my code. This allows my equations to more closely resemble the textbooks they come from. For example: # constants π = np.pi e = np.e c0= 299792458 # speed of light, m/s µ0 = 1.2566370614e-6 # magnetic permeability of free space ε0 = 8.85418782e-12 # electrical permittivity of free space def speedoflight(εr=1, µ=1): """ Speed of light in resistive (low loss) medium c0 = 1 / sqrt(µ0*ε0) c = 1 / sqrt(µ*µ0*εr*ε0) µ0: magnetic permeability vacuum (constant) ε0: dielectric permittivity vacuum (constant) µ: relative permeability (usually 1 for non-magnetic) εr: relative dielectic 1 for air, 4 for lake ice, 81 for water most rocks in the 5-8 range See Reynolds (1997) p.704 for table of dielectrics See Reynolds (1997) p.689 if material is lossy. """ return 1 / sqrt(µ*µ0*εr*ε0) 
I generally break up my pipeline into several notebooks, each with a one or more output data files (csv, json, even pickle) that are loaded in the first few cells of the next. So if, e.g. my project has three notebooks, I'll start with: * Z01_Load_and_munge_data * Z02_Build_model * Z03_Evaluate_model Then when I have a major revision, I decrement the letter so the new versions appear first on the list, and add notebooks where needed, e.g. * Y01_Load_and_munge_data * Y02_Build_GBM_model * Y03_Evaluate_GBM * Y04_Build_GLM_model * Y05_Compare_models I've never made it to A, but on my latest project I got to D.
I think you have improved my life with one magic command.
Rodeo is a lot better than it used to be. That said, they're too late in the game for me, I'm too used to Jupyter. Jupyter notebooks are suboptimal for git, however, since they're JSON and change a lot depending on the cell output.
sounds awesome! where do I find it?
You might want to try Spyder. It's an IDE that sends code to an internal IPython Qt Console. The autocompletion, help browser, and variable inspector are all really nice too. 
What is the name of this extension?
I'm not a 'scientist' per-se, but I do do a lot of analysis tasks in which one takes a large input data-set, does a bunch of fiddling to figure out analysis steps, then produce graphs (or in my case, findings!) at the end of the day. A lot of people have discussed how they approach the problem, but I noticed that one item I find essential is missing: Makefiles. I use Makefiles heavily for automating my analysis pipeline, especially when I expect to be revising various stages over time; or be re-runnning the same analysis pipeline on new input sets. At its heart, a Makefile is a dependency tree: it tells the `make` tool how to generate an output from one or more inputs. If the inputs have changed, then make will regenerate the output as necessary. I add the analysis software as an explicit dependency of the output, so when I revise the software, the output gets regenerated. The beauty of a system like this is that when setup correctly, you simply type 'make what\_i\_need' (where what\_i\_need is your output product), and make will regenerate everything that is necessary to build the outputs. I find the automation to be _critical_ especially when I'm on a deadline, or working long hours. Without it, its far to easy to miss a step somewhere.
It's a joke post, bro I thought this output kinda funny
Peter wasn't involved directly, but he did support us working on it. We're happy to discuss applications; just open a public github issue at https://github.com/ioam/geoviews/issues or email me privately.
the irony
I really like David Beazley's videos: https://www.youtube.com/user/dabeazllc/videos
I also gave PyCharm a try; it's still my go-to tool for when I'm developing my actual scientific **models** - stand-alone software that I run in various configurations as experiments - but not really when it comes to utility modules. For your point-by-point breakdown: 1. To be honest, I've never had an issue with this that the basic auto-completion packages available for ST3, Atom, or emacs didn't cover. When in doubt, I'm always in an IPython console anyway, and I can use the look-up tools there to get what I need from the documentation quickly and easily. Plus, JupyterLab will have a built-in documentation viewer if I understood the tech demos correctly, so this won't be a pain point in the future. 2. This is a good point; I think extensions for JupterLab will also serve well here. Unfortunately, I can't really leverage databases like this in my workflow; I'm usually analyzing 10's of terabytes of climate model or re-analysis output, so I have to build pipelines to process my data into more usable forms. Usually, a "processed" subset from my pipeline - which I can then go on to do more in-depth analysis - will be a few hundred MB or a few GB, but in a structured format rich with metadata. In lieu of databases, I have a specialized utility for loading up data I process, which takes advantage of the metadata and a hierarchical layout in the archive on disk where the data lays. I'd be interested to hear more about how you use databases in your research process, though! 3. Can do the same thing with a vanilla notebook+console setup. I'm always remotely logged into my work cluster, because I can't store my datasets locally. Running the notebook on the cluster usually works great, and with tools like dask.distributed, I can leverage the full system for big jobs. 4. Could be useful, but I can't think of any utility or research script I needed which really could've used the debugger. If the code is so complex that it needs one, I usually find myself breaking down whatever problem I'm solving into smaller steps!
Wow that is intense. Power to you if it works for you, but that just screams version control to me. At the start of each new analysis I first make new folder and `git init` asap. I like to have records of my scripts too but I couldn't personally handle all of that clutter.
I think I've seen examples of ways to strip the outputs of notebooks so you don't have it in your repository. (Or you could probably write something similar yourself fairly easily)
Hey, I'm not defending this design. It can be improved and I could use help with improving it. This design works entirely, though, is documented and can be used today. I'm proud of that and happy that the entire community can benefit by this work, immediately, and before it becomes more pythonic in design.
I find git to be very suboptimal with .ipynb files, their json nature and inline output make the diffs too huge. 
I agree. I personally only see the notebook as useful for giving a code /workflow demonstration to others, and don't use it for my own analyses.
This this and this! I use Jupyter Notebooks to explore my data... then I transfer is over to PyCharm to properly write up code that can be easily reusable in the future. Also the VCS is amazing in PyCharm. I love it 
I kinda wish there was other ways...not that I wouldn't like to go to these conf, but I would just like a sticker :)
Then you should respond to the guy who offered to send you one. My desk right now: https://i.imgur.com/f1HHbHD.jpg
Yuck. Too much magic. Explicit is better than this.
PM me your address and I'll send it today.
I second that. Emacs is great for python (with Elpy), is great for literate programming (with org-mode babel) and for LaTeX (with Auctex + PDF tools). IMO org-mode is far superior than jupyter notebooks. 1. In org-mode you can cycle through sections which is VERY convenient to organizing your work. 2. You can write code and RUN it inside the text. 3. With packages like ob-ipython you can output images from python code directly in the buffer. 4. All that in a text file, easy to maintain and store 5. And lastly, You can easily export it to a variety of formats (LaTeX-PDF and hmtl for instance)
Ha ha, very witty!
In all seriousness, thanks for the feedback! It's not going to be for everyone, but I really don't like typing the same thing over and over to setup a venv, etc. Plus I always forget to update requirements.txt. To each his own :)
i like to use R + Rmarkdown writing reports is really simple, and i like to use R in general
Try power query 
&gt; Not necessarily true. An IDE is pretty much useless for exploratory work. That isn't necessarily true either. Some IDEs are very useful for exploratory work, especially when they offer "notebook"-like features. It's mostly habits and opinions at this point, but I just wanted to point that IDEs are meant to integrate the development environment, which, to me, include integrating being "a simple text editor" and a "notebook". I really love the emacs integration with IPython, for example. It saves me from pasting code from the browser or ipython terminal to my text editor. 
Do you think Andrew Ng had anything to do with it?
Atom has an extension called Hydrogen that lets you use a jupyter kernel to run selected code in the text file and show the results inline. It's a pretty good cross between an ide and the notebook. You can also get auto suggestions from the running kernel. I think the notebooks help me with latex document preparation for class so my reports can look super nice, which I don't know how to do in a straight script. Else I would love to write everything in plain text in Atom with Hydrogen running. 
I would say unittest/unittest2 and pytest are still relavent and nose is slowly dying off. Most Python devs (myself included) use pytest in their day-to-day mostly for the magnitude of customization options. However I still use the builtin unittest mostly because I use Twisted heavily and it's testing framework is based on unittest. My only gripe with pytest is that it can get very complicated and new comers will be confused. The builtin unittest (for lack of better words) forces you to be simple. Also since it's in the standard library, it will be relevant for a while.
It's called scratchpad I think. It kept crashing my computer. Now I use the qt console.
So meta :) 
I use notebooks and PyCharm. Notebooks are just so much better for exploratory or interactive work (especially because they help/encourage me to document it all as I go along). I agree that if you're sitting down and writing big classes or packages then notebooks are not the way to go, but there's where PyCharm really shines. Between the two I don't find any deficiencies, and I don't mind the two tools since they really are quite different tasks that I do separately (although I often turn my notebooks into tutorial documentation for my packages). I use anaconda because it makes everything in the science stack easy. I know I can, in theory, do it with virtualenv and binary wheels, but anaconda just works out of the box. What do you find confusing about anaconda? Perhaps it is messier on windows? I've only used it sparingly there.
What you want is [nbdime](https://github.com/jupyter/nbdime), and the associated git integration. It's new, but works right now and will likely only get better in the future. There was a [talk on it at SciPy](https://www.youtube.com/watch?v=tKAmwC8ay8E).
Where are all the vi people? I write scripts in vim and pipe lines to ipython with [vim-slime](https://github.com/jpalardy/vim-slime). The whole thing runs in a screen (or tmux) session. 
What about trying to use mypy and type sheds for this? Some people have started working on these for the data stack (machinalis/mypy-data on GitHub) and this might save a bunch of work moving forward.
[deleted] ^^^^^^^^^^^^^^^^0.39104218339283614 &gt; This comment has been overwritten by [this open source script](https://greasyfork.org/en/scripts/10380-reddit-overwrite) to protect this user&amp;apos;s privacy. The purpose of this script is to help protect users from doxing, stalking, and harassment. It also helps prevent mods from profiling and censoring. &gt; If you would like to protect yourself, add the Chrome extension [TamperMonkey](https://chrome.google.com/webstore/detail/tampermonkey/dhdgffkkebhmkfjojejmpbldmpobfkfo), or the Firefox extension [GreaseMonkey](https://addons.mozilla.org/en-us/firefox/addon/greasemonkey/) and click Install This Script on [the script](https://greasyfork.org/en/scripts/10380-reddit-overwrite) page. Then to delete your comments, simply click on your username on Reddit, go to the comments tab, scroll down as far as possible (hint: use [RES](http://www.redditenhancementsuite.com/)), and hit the new OVERWRITE button at the top.
I didn't know there was a difference. 
X-Post referenced from /r/irc by /u/Moniker_30 [Limnoria/Supybot FiSH (CBC) encryption plugin, (X-Post to /r/Python)](https://www.reddit.com/r/irc/comments/50x22p/limnoriasupybot_fish_cbc_encryption_plugin_xpost/) ***** ^^I ^^am ^^a ^^bot. ^^I ^^delete ^^my ^^negative ^^comments. ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
[Pex](https://github.com/pantsbuild/pex) sounds like what you're looking for. 
This is great! I really never knew how all those project authors consistently made Changelogs and faithfully versioned their releases as dev1, dev2 etc. Thanks! :)
I have never worked with Django, so I am not sure. I have heard good things about Bokeh for web ready plots. And I love Qt as a gui backend. It has a lot of small quirks when you get into the dark dusty corners, but on a basic level it is super easy to throw a small app together when you know the basics. Originally c++ but has bindings in python, java, and a few others I think.
That makes more sense, thanks for pointing it out! I'll take a look at it :-)
Thanks for your kind words! I do feel proud about my work on Spyder, but sometimes I'd like to fix all these nuisances people have while working with it. But we are limited by the way Python works and the available tools for the job :-)
TheNewBoston Best channel ever with over 1 million subscribers
Sorry to disappoint you, but as I said above, JupyterLab won't solve this problem. I know several core developers of the project (the most productive one is also a Spyder core developer and the one that has worked the most in our completion machinery), and I'm sure they are not working in solving this issue and they'll have to face the same issues about not being able to evaluate your code to get completions in a robust way :-)
Would this still return True if obj was a 0 or 1?
/r/learnpython
Don't quit your day job.
Then show me *your* poem instead of just criticising. 
You could try using the [cryptography](https://cryptography.io/en/latest/) library instead, they're the most up-to-date python crypto library. [Blowfish](https://cryptography.io/en/latest/hazmat/primitives/symmetric-encryption/#cryptography.hazmat.primitives.ciphers.algorithms.Blowfish) is here, an examlpe of using it to encrypt is [at the top of the page](https://cryptography.io/en/latest/hazmat/primitives/symmetric-encryption/)
typically pypy is faster on strings than cpython or cython or numba
You just blatantly copied your homework question without trying to formulate a more specific question ? What have you tried so far?
appreciate all comment
Twisted is a go to if you want to do 'network stuff' and roll your own services from scratch.
Sounds cool. I will try it!
https://github.com/audreyr/cookiecutter
Other people using 2.7 is not by itself a good reason to keep using 2.7 yourself. This data mostly reflects the fact that the majority of software or there is written in python2, which makes a ton of sense since it's been available for far longer. For new projects there is generally no reason not to use 3.x right now, aside from needing a few specific packages that don't work on python 3.
Should possibly reorder the posts based on complexity.
And SQLAlchemy is even better.
You can't download and/or install packages directly inside sublime. Try "PyCharm" if you want to do it inside an editor, or just use "pip". If you want to use Anaconda as your interpreter, try googling. Like "sublime text custom python interpreter" or something.
Actually, you can. Just use Package Control. 
I saw [that post](https://www.reddit.com/r/Python/comments/50xf8y/total_of_pip_packages_downloaded_separated_by/) and yeah it was a bit depressing, not least how close 3.4 &amp; 3.5 adoption is to 2.6. But just because you don't like the results, doesn't make them wrong ;) The download numbers for all versions are likely inflated by test builds/CI. But it is fair to say that *at the moment* and *in commercial environments* 2.7 is still the go-to, and will be for a ~~while~~ long time. In other words, using the download stats probably inflates the difference, but the difference is probably real.
[Scrapy](http://scrapy.org/) for web scraping 
Your "sense" doesnt prove the stats to be bulllshit. Christ 
The example of a webserver in 15 lines just blew my mind.
Ahhhhh!!!! One of the bad things about matlab is that it teaches you bad programming practice. Of the great things about Python is the clear namespaces and scoping. From numpy import * Obliterates all of that! And, makes it super, super hard for others to follow your code 
International address?
2.7 FTW
That's a joke, son.
Wow. I really would have expected 3.x to be closer. Then again, this is separated be minor. I wonder what it looks like if you separate by major?
Ohh, that's what that was. Thanks!
thank
bokeh for interactive data viz. scikit learn for basic ML. numpy for linalg.
my web scrapping days were before scrapy and it just makes me sad that I didn't get to use that tool :(
Subreddit or text ?
thanks
Flask is the django for web development
Hell. That was my experience when working at a place requiring all our python projects to have makefiles, pure hell. 1. Makefiles require true tabs (/t), sane python developers prefer 4 spaces, and no IDE I know of has a per file type setting for tabbing. 2. Make is it's own beast that most python devs do not know. 3. Most tasks could easily be put in fabric and applied to all programs instead of a single one (lint, remove pycache, test, etc...) 4. Python is generally OS agnostic, makefiles are generally not IMO A good makefile in a python project is a thing of beauty when it works, the devil when it doesn't, and a PITA for anyone that has to come along and maintain it.
This is good, and this is how I use makefiles. They've become known as these giant, complicated files, so other build systems have spawned in its place, but makefiles can be simple and elegant, that turn into shorthand commands to do work, and can be checked into your project. This gets stuff done, and I can look at your project and see how it all works together.
Most of my python projects have a makefile like [this](https://github.com/F483/apigen/blob/master/Makefile) with decent use of dependencies. While it is not needed at all, it is quite useful.
Nice! Building wheels seems like a perfect use of make.
GNU Make 3.82 (Released July 2010) let's you use characters other than tab as the prefix character.
Can I ask why? I'm a fanboy of 2.7 myself but my latest project is written in 3, and I want to do so going forward. 
Perhaps full paths should be a thing. Maybe I'm just paranoid.
&gt;Everyone read the title as "suggest excellent libraries" rather than reading the post "suggest scaffolding tools". Yeah I only realized that after waking up in the morning and reading all the responses :)
I want people to move to 3.5, but only so I don't have to continue supporting both versions.
I was always under the impression Makefiles were Pythonic. That people used setup.py for this. Maybe I'm just jaded from having worked at a C/C++ shop for so many years seeing gigantic crazy Makefiles that I assumed that Python had a more elegant way to do this. Be interesting to see a poll of Python devs and who uses Makefiles vs other strategies. 
Dumber than Vim, Emacs, TextMate, Sublime Text... ;-)
Create a python package and upload it to pypi. Then people can install it with pip.
[deleted] ^^^^^^^^^^^^^^^^0.11452863739460217 &gt; This comment has been overwritten by [this open source script](https://greasyfork.org/en/scripts/10380-reddit-overwrite) to protect this user&amp;apos;s privacy. The purpose of this script is to help protect users from doxing, stalking, and harassment. It also helps prevent mods from profiling and censoring. &gt; If you would like to protect yourself, add the Chrome extension [TamperMonkey](https://chrome.google.com/webstore/detail/tampermonkey/dhdgffkkebhmkfjojejmpbldmpobfkfo), or the Firefox extension [GreaseMonkey](https://addons.mozilla.org/en-us/firefox/addon/greasemonkey/) and click Install This Script on [the script](https://greasyfork.org/en/scripts/10380-reddit-overwrite) page. Then to delete your comments, simply click on your username on Reddit, go to the comments tab, scroll down as far as possible (hint: use [RES](http://www.redditenhancementsuite.com/)), and hit the new OVERWRITE button at the top.
I use a simple python script with a couple of decorators I wrote for dependency building and facades around argparse and subprocess. All about 100 loc. Don't rush into library/tool installing, they're not substitutes for good old thinking and general tools.
To fix (1), you should invest in a better text editor. I haven't come across one that doesn't know how to indent a Makefile in a long time. To fix (2), you need to find a new job. It sounds like you're working with people who don't have a particularly deep understanding of the systems they are working on. 
&gt; Even FreeBSD has the gmake package. As a port, not as the system's standard `make`.
This should be on [learn Python](https://www.reddit.com/r/learnPython/).
This should be on [learn Python](https://www.reddit.com/r/learnPython/).
&gt; But I've heard that you need to have an activated Windows license A legit copy? You don't, not that that shouldn't influence things. Most people do.
Why not just install a 'script' that gets placed into the path, then have all these options in that script. Then you can use Python and argparse to have fully functioning menus and sub-menus. You can use a setup.py script for all of this. Also tests can be automatically found and executed with the existing setup.py infrastructure. Also setup.py 'develop' command will install a local and temporary version of the program that you can hack on and resolve all the dependencies.
Dear all young programmers, Stop using words like "rockstar", "ninja", and "superhero" to describe yourself or others. It's non-descriptive, doesn't impress anyone outside the field, and makes you sound like an idiot. Signed, everyone.
Depends entirely on what hardware you're using, and how.
1. What kind of shitty IDE can't handle Makefiles? 2. Using a makefile like this is no more complicated than bash. 3. I'm completely with you on this. 4. That's true, but writing a makefile is usually much quicker than writing the equivalent python script. 
What's Make, if not a general tool? 
&gt; Most tasks could easily be put in fabric Except fabric only works in old versions of Python. There's invoke which is also compatible with modern Python, but that has still yet to see an officially stable release.
If you (the developer) don't have easy access to Windows, [Pynsist](http://pynsist.readthedocs.io/en/latest/) can make a Windows installer from a Linux or Mac system. You probably still want to test installing on Windows, though.
Pygame for games development. There are other frameworks that are frankly better, like Kivy, but everyone starts at Pygame because its the easiest one to learn with. 
Encrypting things multiple times doesn't increase security. AES 256 x 3 is less secure than AES 257. Really 256 is plenty enough for anyone. Also you don't seem to understand the difference between hashes and salts. You salt your passwords and then one way hash so that using rainbow tables and cracking all your passwords is unfeasible. It makes no sense to add the hash to the encrypted data before encrypting it again. You get no security benefit nor any performance benefit. You could encrypt just the hash (why I have no idea) and then store it separately if that hash is useful... But if it's useful it's pointless to encrypt it. 
Thanks for the feedback... However I do know that encrypting things multiple times doesn't increase security, but it does increase total encryption time and therefore total cracking time, maybe not much, but it's something. Anyway, I wanted to encrypt the databse a second time to hide the key hash, and then a third time so that I didn't have to decrypt everything at once, but only when I needed to. Finally, what makes you think that I don't understand the difference between hashes and salts?
What do you plan to program? Networking, web, games, machine learning apps? It really depends on the context of your project(s) what the pros and cons are. I use Twisted heavily and there really isn't anything that made me ever stop using it. Most Python devs don't like Twisted so be prepared for some hate. As far as future proofing, Twisted is actively being maintained and support for the new ``asyncio`` event loop features have started to appear! So long as you keep an updated copy of Twisted you should be set for the future.
In my experience it's always the employer or recruiter that uses those terms. I agree that it's nonsense meant to blow smoke. That's the source of my joke.
+1 for pex! it's fantastic!
Huh, that's really interesting! Haven't heard of pex before. It does seem like they can both be used the same way, different goals though. Could probably tie them into each other too. Maybe I should add custom hooks or something that could be run when a process exits. Then it could generate a .pex along with a requirements.txt when the process exits.
I will be messaging you on [**2016-09-04 23:33:18 UTC**](http://www.wolframalpha.com/input/?i=2016-09-04 23:33:18 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/Python/comments/50zgul/vaultpy_a_secure_cross_platform_password_manager/d78je26) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/Python/comments/50zgul/vaultpy_a_secure_cross_platform_password_manager/d78je26]%0A%0ARemindMe! 1 day ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! d78jf3s) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
I used numpy for nearly every single Python script I write. 
Well I also used to make use of the integrated Git GUI of JetBrains products (IntelliJ, Android Studio and PyCharm as well). But once I could not use repositories that weren't on Github the whole Git GUI thing was a pain in the a**. So what I would suggest is that you might give the commandline a try. It might take a while to get used to it, but once you've worked it out, it is really nice to have a tool at hand which is platform- and hosting-independent. [This guide](http://rogerdudler.github.io/git-guide/) should get you started! If there are any questions, I'm happy to help!
I mentored a high school club in this exact situation. Message me if you want to ask anything.
&gt; sane python developers prefer 4 spaces Look I prefer tabs over spaces and won't get into it here, but wow no need to imply that python devs that prefer tabs are not sane...
How would you suggest they be connected? I am in very early stages and just conducting research for this project.
Message sent. 
If you go directly against a language's standards (in this case PEP8) in a shared dev environment, I declare it insane =P You *can* use tabs, just like you *can* name your files `THISisMY SUPERAWESOME python_file.py` It's fine for anyone to do at home/personal projects, but it's bad practice to do in production or public repos. 
Python is blowing my mind with this shit. So much LEARNING waiting to happen, my goodness!
Despite OP's several nasty PM's, I will elaborate. Poem: [A piece of writing in which the expression of feelings and ideas is given intensity by particular attention to diction (sometimes involving rhyme), rhythm, and imagery](https://www.oxforddictionaries.com/definition/english/poem) I see 1 out of 3 factors that defines a poem for me. Missing are the parts I feel are most important in distinguishing poetry from prose: rhyme and rhythm. I admit I did jump to the conclusion that OP's day job had something to do with Python since you posted in this subreddit, and not one devoted to poetry. My intention was to jokingly suggest that a career as a poet would be more difficult than one related to Python.