also: condition = (precompute.the(condition) and save.it_in(a_variable)) if (condition): pass 
i second this one. it's clearest when there are a lot of conditions
 $ python -m http.server
I'm not sure what a "true lambda" is, but Python most certainly does support true closures.
"True lambda" meaning that you need to name your true closures, with a new level of indentation and all. That's not really a problem, have just found myself starting 12 or 16 spaces indented, with coworkers insisting on 15-character variable names, and absolutely no chance to write good looking code. No diss on Python, it's great, just venting about things long past :-P
This is the one I like as well. The double-indented subclauses make for a clear separation between the subclauses and both the 'if' statement and its sub-block. I also like the 'and', 'or' etc. to come at the beginning of the line instead of the end, though PEP-8 advocates the latter.
These days I'm almost always working with at two monitors, both being pretty wide. I think 80 characters is ridiculously small and I find it harder to read something that is broken up unnecessarily. Generally I like to keep my lines around 120, not too small, not too long, just right (for me).
 $ python -m SimpleHTTPServer works too.
I used to use the style in your third example when I was new to Python because it matched how I used braces in other languages (opening brace on the same line as opening statement, closing brace on its own line unless followed by `else`). Nowadays I generally stick to a more Lisp-y convention of stacking closing parentheses and no linebreaks directly after the opening parens / before the closing parens. Also I tend to put `and`/`or` at the beginning of the next line because the lack of a colon makes it clear that the condition doesn't end with the linebreak. So I'd usually end up with code like this: if (very_long_cond1 and (cond2a or cond2b)): do_stuff() Nested `and`/`or` tends to pose a problem, though, because I feel I should indent them, but that would void the benefit of that style (i.e. only indenting where the compiler needs it). EDIT: Also list comprehensions: print ', '.join([str(x) for x in range(20)]) print 'Yay!' The lack of indenting on the next line makes it clear the for belongs to the previous statement.
I like this a bit better because, at first glance, I see that the function parameters are subservient to the function call. If the parameters are not indented as much as or more than the function call, it looks to my eyes like the function parameters are more closely related to the results. result1, result2, result3 = some_function(parameter1, parameter2, parameter3) To each his own :) 
And then this? if (something.allows(the_argument) and (something_else.allows(respective_argument) or that) and etc_also_too): maintain_correct_indentation() 
Depends on what kind of code you're writing. In Lisp, people do it all the time. Sometimes I write functional Python and this happens.
 class Foo: def myfn(self, filename): try: with open(filename) as f: for data in data_generator(f): if data != None: do_something(data) Sure you can structure it differently but it's not too hard to get deeply nested code in python with all the different constructs. I didn't even use closures.
So, to summarize the points of a few different people: * lines of 79 characters or less are easier to read than long lines * breaking up lines into multiple lines makes them harder to read * shortening names can make them incomprehensible * changing indents to just 2 characters can make them harder to see * moving off some of your code into a non-reusable function whose sole purpose is to keep your lines under 79 characters makes the code hard to follow * splitting up function arguments, etc into separate lines may or may not aid readability Sounds to me like some intelligent compromises may be more important than arbitrary rules.
From PEP8: &gt;Two good reasons to break a particular rule: &gt; &gt; (1) When applying the rule would make the code less readable, even for &gt; someone who is used to reading code that follows the rules. &gt; &gt; (2) To be consistent with surrounding code that also breaks it (maybe for &gt; historic reasons) -- although this is also an opportunity to clean up &gt; someone else's mess (in true XP style). Sounds like you're right, and the all-knowing PEP 8 knew that you would be!
no, [Cython](http://cython.org). Which does but what you just said but also a lot more.
This is how I do it, except I have a comma on the last line for consistency: result1, result2, result3 = some_function( parameter1, parameter2, parameter3, )
It's also on proggit: http://www.reddit.com/r/programming/comments/djldm/python_idiom_for_taking_the_single_item_from_a/ (I have no idea how you're meant to join them, if you even can...)
I had no idea about number 4 - that's really handy.
There are just some cases where it doesn't seem reasonable to have to spend time refactoring out of, for instance when you need to define unit test cases with 3 nested loops - you just lost 20 characters to whitespace, bub. Following the first line-break, I believe the coding standard is to prefix an additional 4 spaces and don't forget to end with space-backslash so now you're just *piling* on LOCs.
 should_be_working = whatever and something_else is_procrastinating = surfing_reddit and so_on if should_be_working and is_procrastinating: pass If you're concerned about readability (and you should), why not go for an option that ... increases readability... :)
&gt;Remember that "foolish consistency hobgoblin mind" thing. You seem not to have...
There's two main approaches, threading or asynchronous processing. For either case, you can roll your own, but there's good library support so you might as well use it. Have a look at the docs for the 'threading' and/or 'asynchat' modules. If you're doing this for your own education, try doing it each way and compare!
As a total python and programming novice (kind of) could someone explain this to me? the serve function defines the socket for this, then prints out in the command line that it is starting, then there is a while loop to start the server. Where do I put anything in for the server to serve?
There are 2 ways to design this. You can either use a threaded model as everybody else here has mentioned, or you can use an event/callback model. See http://ptspts.blogspot.com/2010/05/feature-comparison-of-python-non.html for a comparison sample of event libraries.
 if day_of_the_week.endswith('y') and \ time_of_day &gt; 16 and owf.can_hold_glass(): drink_beer() else: huff_glue() That's probably a bit naughty, isn't it?
From [docs.python.org: http.server](http://docs.python.org/py3k/library/http.server.html): &gt; class http.server.SimpleHTTPRequestHandler(request, client_address, server) &gt; This class serves files from the current directory and below, directly mapping the directory structure to HTTP requests. 
This post got around quick. It was on HN this morning, proggit, and now here. Sequence unpacking is nifty, and quick. [Here are some stats about the example](http://paste.pocoo.org/show/268284/).
You can use PyAudio, the PortAudio bindings for Python: http://people.csail.mit.edu/hubert/pyaudio/ There are examples on the website, hope this helps. :-)
I love Python 3. This one-liner is what I've always used, but I always have to look it up too. http.server is way easy to remember.
Keep up the good work, I love web2py; I snoop around and try to see if I can help but most of it is over my head right now.
I agree with all your points except for the penultimate one: moving off some of your code into a non-reusable function whose creation was prompted by an attempt to keep your lines under 79 characters will usually make the code easier to follow. Make sure you pick good boundaries for that function, and give it a good name.
You also didn't have any problems with lines longer than 79 characters.
You cannot put a for loop in a lambda in Python -- hence the need some feel for inner functions.
It can be found through 'other discussions (1)' at the top. Reposting is discouraged, despite r/python being more topic appropriate.
This is much better.
Does your laptop let you fit a couple of editors side-by-side? Does your netbook? Does everyone on your team have large monitors? Do they all have good eyesight so they can afford to use small fonts? An 80-character limit is universal.
Use http://pypi.python.org/pypi/decorator. You'll love it. It solves problems you might not even know you had (e.g. it preserves signatures of decorated functions so you see the right thing in pydoc, and your favourite web framework can use inspect.getargspec() to figure out what arguments to pass).
You've just introduced a bug: s == "Really longstring". This is why I've made a habit to always put the space on the second line, so it's more visible: &gt;&gt;&gt; s = ("Really long" ... " string") 
What is the technical relationship between PyGTK and PyGObject? [The PyGTK developer page](http://www.pygtk.org/developer.html) indicates that "PyGObject with gobject-introspection is planned to replace PyGTK in the future", but [the downloads page](http://www.pygtk.org/downloads.html) indicates that PyGTK depends upon PyGObject (quote: "Be aware that PyGTK has some dependencies like pygobject that are needed to run it."). 
The frowny face in the third example is particularly apt.
Actually you can use Cython on pure python source code and it does the same thing as Nuitka.
Yeah, an 80-character limit is universal. So is the i386 instruction set and ASCII character set. Our application requires a pretty beefy computer (quad core) and at least one large widescreen monitor, so the 120 character width isn't even close to a limitation to anybody who works on this. The only downside to it is reading 80-column code after you get used to seeing more on the screen. At times it's like looking through a narrow window.
Wrong title, correct is PyGObject 2.26.0 released.
Thanks. A user wrote Rocket. We have been using it for one year but it is an independent project.
That thread clarifies some points. http://www.mail-archive.com/pygtk@daa.com.au/msg19652.html
I think the core problem is that if the restrained have much more sex, they are no longer 'the restrained,' and they subsequently join the pool with the infected. You could reverse this problem and say that if you took a bunch of the non-infected people in the active group and sidelined them so they weren't in the pool anymore, then infection rates would go up for the remaining actives, but it's still just a question of scale. Over time, as people swap around, the same percentage of people will become infected. If more people enter the pool, that same percentage is simply a larger number.
&gt; Ajax is a type of JavaScript programming to make web sites update the contents of their pages without refreshing the page. Neither of these teaches programming to a beginner. Of course it does, I myself have started out with HTML+Javascript (=DHTML in the old days). Javascript is a programming language, and an easy one at that and as such also suitable for beginners.
I am not convinced on the point #1 (readability). (thing,) = stuff This would definitely throw of some folks on my team if they had to maintain my code, where as stuff [0] is fairly standard way of referencing an item in a list, especially for people from other language backgrounds.
Why?
That doesn't seem to allow you to play straight sine waves or whatever - it's all prerecorded. I'm thinking you may have to abuse a MIDI module for this. I'm looking at this problem too, I'd like to make some old school game sound effects (think car acceleration done with simple waveforms)
I got curious, in Django we have 2 instances of this idiom in the codebase.
Why not? [thing] = stuff Why insist on the ugly trailing comma?! Anyway thing = stuff[0] is way better, because it is readable and explicit. import this 
Is it any easier to install in Windows?
I'd love to see the PyQt equivalent of this.
[This](http://www.reddit.com/r/Python/comments/djcjp/attempting_to_follow_the_styles_described_in_pep/c10ojuz) is a perfectly reasonable chunk of Python with 6 levels of indentation.
 result = [(some_func(x), x) for x in other_func(y) if x and third_func(x) &gt; threshold] That's already 86 with no indentation, and it seems like a pretty reasonable line of code to me.
I like [thing] = stuff more for readability, though it still feels a little backwards.
Actually I'm more inclined towards functional programming so I'd rather have a data structure or functions doing the work of those 3 nested loops. And I never space-backslash, rather oparen-multiline-cparen.
Python already has an idiom for indexing into a sequence, the [] operator. It also supports getting items after the first. Or indexing from the end. It's been in the language since the beginning. Everyone understands it. Using structured assignment for this is in no way an improvement. tl;dr Bleah!
I see, the ease of use of python :)
&gt; nyway thing = stuff[0] is way better, because it is readable and explicit. Actually, it's less explicit, less expressive and less generic. `stuff[0]` means "take the first element of this sequence or the value corresponding to the key 0 of the dictionary". `a, = stuff` means "Take the only value from this one-element iterable". It *asserts* that the iterable has a single element, and it works with *any* iterable (including sets, generators or callable_iterators).
I think #4 contradicts #2. If you want a free "assert" that it had just one element, why don't you want a free assert that you are actually pointing to a list and not a set? Even in these instances where this is handy, chances are my peers would be scratching their heads thinking why did I do that. An idiom that should be commented upon, is not really a good idiom in my book. I actually use this sometimes, but it's Perl-ish... Ok, now I'm confused.
It's actually even more generic: it works for any iterable, not just any collection. val, = stuff is equivalent to writing this: lst = list(stuff) assert len(lst) == 1 val = lst[0] del lst
&gt; Well, then you have to check len(b) and make sure it is 0. 1, not 0. And of course it's not a better way since it says something completely different.
There is no method `get` on `list`. `get` is for `dict`. It's also completely different as it returns a value mapping to the key, the idiom in TFA would return the key itself of a one-element dict.
&gt; Python already has an idiom for indexing into a sequence, the [] operator. 1. `__getitem__` doesn't assert the number of elements into the sequence 2. `__getitem__` only works on sequences or mappings (where it returns the value, not the key). Unpacking works with arbitrary iterable. &gt; t's been in the language since the beginning. Everyone understands it. Iterables unpacking were added in June 2001. Not exactly a recent feature.
they usually don't because they get lost in their own code and never get the chance to really complicate it like that.
i find them all unreadable. might be the `func*` and single-letter variable names. anyway, i'd rarely nest 3 function calls. maybe if the inner ones were conceptually like primitive operations, like punctuation in a sentence, so i don't need to think about them. i'd break this stuff up into a series of assignments, like flowblok did, a few levels up.
exceptional... i hate try/except blocks because they make me spend a level of indentation. i use them anyway, because some exceptions, i just have to catch for my programs to keep running (e.g. network errors). anyway, my comment was supposed to imply that i condemn indentation by less (or more) than 4 spaces, as well as deep nesting.
yeah. my editor windows are usually ~120 wide. i'm not trying to stay within the limit of 80, but my "section dividers" (see below) give me some reference while coding. # ======================================================================
If you are only interested in sin waves, and run windows: import winsound winsound.Beep(440, 1000) This will play a 440Hz "beep" for 1 second. For more complicated stuff I had a quick play to try and make winsound play a scipy array of arbitrary data, using winsound.PlaySound(), no luck so far but I'm convinced if you got the encoding of the array correct it can be done. Unfortunately back to work.
Because you don't care about lists, you care about iterables. It rarely matters which type.
Does it? for me it matters just as rarely as the fact that there could be a second element. In any case I think #1 is plain wrong. The vast majority of people will understand foo[0] straight away, and not so much (elem,)=foo , which they will wonder why exactly did I do that, and it if matters. Nothing that proper commenting won't fix anyway. Personally I won't judge anyone better or worse for doing it either way, but trying to be clever for no good reason is usually a Bad Thing.
For me "a, = stuff" looks more like a black magic and not in the good way. It is clever and you have no idea what was the author's intention.
&gt; For me "a, = stuff" looks more like a black magic and not in the good way. A feature you don't know looks unfamiliar? You don't say. &gt; you have no idea what was the author's intention. Considering how restrictive this idiom is, his intention can only be "extract the only value from the single-element stuff". Which is precisely what the line says.
Um, that's why he said "make sure it's 0". 1 would be something completely different.
While I agree with you that this is more explicit, expressive and generic, it's actually not more readable. The average programmer won't immediately understand the intention, so he'll have to think about it a bit. That said, there's no other way of doing it (other than assert(len(iterable) == 1)), so people will just have to learn it, I guess. Maybe a comment would be warranted.
Lists with one item make perfect sense. What else are you supposed to return when you expect a variable number of items, but only get one? I'm sure as hell not going to return the single item, changing my return type depending on the number of items!
&gt; The average programmer won't immediately understand the intention, so he'll have to think about it a bit. Same as with decorators, and those *do* have an other way of doing it. I'm not sure it's less readable either, especially when using parens or brackets around the value (the single dangling comma is fairly unreadable, I'll give you that one). A tuple-like structure on the as lhs is a fairly common sight in Python after all.
&gt; Reposting is discouraged no it's not.
The community will decide whether or not to discourage it and speak with their votes. Although I subscribe to both subs, I'm glad it was reposted - it's generated much more discussion.
&gt; why don't you want a free assert that you are actually pointing to a list and not a set? because you don't want that. You don't care whether you're unpacking a list, a tuple, a dict, a set or a generator.
Yeah but then you're probably not going to expect a single-item list at the other hand, which is what this idiom does.
Right. The new PyGObject with introspection support does the work of both the old PyGObject and PyGTK packages (once you convert your code to the new APIs, anyway), which is probably what I was thinking when I typed it wrong.
A bit, because the number of packages you need to install will be reduced by one. (Once you've switched to the new introspection API, anyway.)
Would they be comfortable with [thing] = stuff ? Because if they are, (thing,) = stuff should be equally obvious if they know the syntax for a tuple of length one in python. And if they're not, well...
As an example that I usually code, when I query the database for a username, I expect it to be unique, even though the query returns a list. If there are two users with the same username, I screwed something up, and I want to hear about it. This idiom would be perfect for that case. Generally, every time I call a function that returns an iterable, but my inputs are such that I know it'll return a single item, this idiom would be very handy. It might not be something I use all the time, but I could definitely imagine some good uses for it...
Yeah, I guess it's probably a matter of familiarity. The "usual" way of doing it is: item1, item2 = func() so I can understand someone being a bit puzzled over [item1] = func(), but I agree, it's nothing hideous.
use backslashes: result = [ (some_func(x), x) \ for x in other_func(y) \ if x and third_func(x) &gt; threshold ] fitter, happier, more readable
&gt; As an example that I usually code, when I query the database for a username, I expect it to be unique, even though the query returns a list. If there are two users with the same username, I screwed something up, and I want to hear about it. This idiom would be perfect for that case. Indeed. &gt; It might not be something I use all the time, but I could definitely imagine some good uses for it... Likewise.
Sure it does. You can just generate the sine wave yourself, based on the number of oscillations per second (hz...). For example, if you want to generate a 440hz (A4) sine wave, the formula is: sin(time * 440 * 2 * PI) The only problem is, I don't know how to convert the python floats generated by that, into something that can be sent directly to the sound card. If you manage that please let me know. :-)
I always enjoy reading the comments for Python links, so is there a reason there are rarely any comments for Stackless Python links?
If I am plotting in Python, I always use [matplotlib](http://matplotlib.sourceforge.net/) which can use a number of [backends](http://matplotlib.sourceforge.net/faq/installing_faq.html#backends) including PyQt.
This is exactly what I need, but unfortunately I'm on my macbook. Is there anything similar for mac?
This is EXACTLY what I'm looking for, and I'm very disappointed it doesn't exist. 
Most likely because there are very few people using it. In the early days, Stackless didn't follow "standard" Python terribly close (it sometimes lagged behind, or implemented something in a different way, or whatever; similar to how Jython lagged for some time until it was revived). I've run into a few people who still had the notion that Stackless was far behind (and, in fairness, I've run into similar people wrt Jython). It's a pretty neat platform for Getting Stuff Done, although I'm very happy that PyPy has some of Stackless' ideas included.
matplotlib can be slow though, especially if you need animation or interactive plots.
See this reddit post: http://www.reddit.com/r/Python/comments/dhpx0/procedural_music_with_pyaudio_and_numpy/ The author of the linked blog entry manages this somehow with numpy, I'm unfamiliar with it though so don't know exactly what's going on here. Looks a bit like voodoo to me but I'm sure it's simple once you understand the (few) libraries he's using.
Perhaps the quoted maintainer of cscope should review the cscope website and either remove the assertion about other language "usefulness" or further elucidate what "useful" really means. (http://cscope.sourceforge.net/ - under "Features") "The fuzzy parser supports C, but is flexible enough to be useful for C++ and Java, and for use as a generalized 'grep database' (use it to browse large text documents!)" 
There's a function: `complex(float R, float I)` You may need to use some string functions and conversion to get it to floats. When you say "new to this" do you mean programming or Python?
This seems to be working for me: complex( raw_input() ) por ejemplo abs( complex( raw_input() ) ) &gt; 1+1j &gt; 1.4142135623730951 Just make sure the input doesn't have any spaces in it.
both :)
&gt; Just make sure the input doesn't have any spaces in it. This fixes that problem: complex( raw_input().replace(' ', '') )
 complex(raw_input().replace(' ', '')) [PEP8](http://www.python.org/dev/peps/pep-0008/)
I learned on HTML/javascript and RM2K. I think the newest versions of Rpg Maker have ruby scripting now instead of the point and click programming they used to have, so I don't think they'd be as good for learning on.
Yeah, I intentionally left ThwompThwomp's spacing for clarity.
Can anyone explain the difference between this and mod_wsgi? The PEP claims that no frameworks use WSGI, but I thought that several used mod_wsgi.
modwsgi is an implementation of the wsgi specification. The PEP is the specification.
1) Don't use shortcuts just to make code terse. Python is not Perl. 2) Explicit is better than implicit. Just add the "assert len(stuff) == 1" if you really need it. 3) I'm not sure if I've ever come across this case where I would use this idiom, which probably means it is very rare. That almost guarantees that 99% of even experienced Python programmers will not know what to make of this idiom.
Thanks for pointing that out. I've looked over it before, but always forget about it. I don't do python enough to continually remind myself of the guidelines and need to bookmark that for whenever I'm actually coding something. Too much editing of bad matlab code has caused me to have a coding style that is as inconsistent as it is hard-to-read.
In addition to winsound and PyAudio you can also take a look at [Audiere](http://audiere.sourceforge.net/). It lets you create simple tones (with CreateTone function) but it also provides many high and low level audio manipulation tools. 
if he wanted to say he is new to Python programming, he'd say "new to self"
maybe? http://www.mxm.dk/products/public/pythonmidi
Awesome :) I noticed they have a free license for Open Source projects.
 if ( something == something and something == something ): pass I like the conjunctions to be quite apparent at the beginning of the line.
Haven't thought about Markov Chains since linear algebra - this is great work!
I like this.
mcdonc is right about modwsgi; but to explain why the PEP says that.... The original WSGI PEP (333 I think) came out when python was beginning to have a plethora of web frameworks and interfaces, as well as servers (cherrypy, apache+modpython, paste, many others). The original wsgi spec was kept minimal in order to encourage adoption by all the existing projects (though I think the minimalism was a worthy goal in itself). Then wgsi took off, and became the dominant standard in python. It even killed off modpython, because the dev team moved to modwsgi, and officially stopped maintaining modpython. So with this second round of the spec, wsgi is no longer the late-comer to the game... but nonetheless they kept the introductory wording of the original pep (maybe just a copypaste job). While this somewhat buries the fact that's its now the de facto standard, I think it's good they kept that bit of original's rationale, because it explains wsgi's origins and some of it's design decisions. sidenote: i'm dissapointed they didn't enhance filewrapper to support offsets and lengths, making HTTP_RANGE requests easier to serve efficiently.
You can try it for free. Give it a go and let us know. Personally, I love PyCharm but have never used WingIDE. I'm a big fan of JetBrains and their products.
But if you could use a multi-line anonymous closure, you'd indent that too, wouldn't you? My only (occasional) problem with having to use a named function is picking the name. Sometimes I just use `block` a la Ruby. def outer(): # some state def block(): # do some cool stuff # with enclosed state some_other_func(block) # Multi-line lambda version (using some made up syntax) some_other_func((lambda: # do some cool stuff # with enclosed state )) Do you have a multi-line example where you wouldn't need/want the indentation? Edit: fixed typo
The first comment in the blog is correct. Don't pass lists with single items, and you will not have to invent idioms to validate that the list has single item and extract it. I would go with the simple: assert len(stuff) == 1 thing = stuff[0] Why is this better? you don't have to waste time blogging about it. Anyone reading this code can tell what was my intent.
Thanks a bunch everyone I got it working. What I want is to create a program that ask me to choose the number "k" of elements I want to work with. Then it should ask me the integer "l" to use. Then, it should ask me to feed it "k" complex numbers. Finally it should take the sum of the products of the "k" elements taken "l" at a time. For now, basically what I am going to do is stick to "l&lt;10", and manually write down 10 if statements. When I am done writing my program, I will check back to see what the easier way to have done it would be :)
[PEP 8](http://www.python.org/dev/peps/pep-0008/): &gt; The preferred place to break around a binary operator is *after* the operator, not before it. With this example: class Rectangle(Blob): def __init__(self, width, height, color='black', emphasis=None, highlight=0): if width == 0 and height == 0 and \ color == 'red' and emphasis == 'strong' or \ highlight &gt; 100: raise ValueError("sorry, you lose") if width == 0 and height == 0 and (color == 'red' or emphasis is None): raise ValueError("I don't think so -- values are %s, %s" % (width, height)) Blob.__init__(self, width, height, color, emphasis, highlight) Implying: * Prefer ``\`` over parenthesis * Align conditions
PySQL does returns 1-item lists in a lot of useful cases. (Getting a record by UserID for instance). Being able to quickly check that you have a unique element and extract it is rather useful and helps keep some database injections from having nasty consequences.
Actually... &gt;The preferred way of wrapping long lines is by using Python's implied line &gt;continuation inside parentheses, brackets and braces. If necessary, you &gt;can add an extra pair of parentheses around an expression, but *sometimes* &gt;using a backslash looks better. Make sure to indent the continued line &gt;appropriately. I can't stand the indenting used, I wish it wasn't in a PEP. Do people manually indent each line with spaces?!
I thought it was really interesting! been wanting to make a kind of arbitrary sentence generator for random commits - and the project guthenburg link is great
Here here! Since when did Python have to be about obscure idioms? 
thing = stuff[0] means that stuff might happen to be a string, list of other length -- and this would actually indicate a problem/error/bug, but wouldn't be caught. Better assert it is of length 1, if you do that. But really, people should know about (thing,) = .. syntax.
&gt; Anyway thing = stuff[0] is way better, because it is readable and explicit. import this &gt; &gt; Errors should never pass silently. Unless explicitly silenced. So if stuff is accidentally "Oops, wrong argument", stuff[0] will be "O", whereas (thing,) = stuff will avoid the error passing silently.
I don't understand why Python still tries to appeal to the readability of code to people unfamiliar with Python. This concept is long gone with the introduction of nested scopes in lambdas, decorators, metaclasses, properties, etc.
The fact there's just one element there is important because usually this structure is expected to have a certain form, and if it doesn't, it almost certainly means that you got the wrong argument.
 item, = struct.unpack("I", x)
 (x,) = struct.unpack("I", str) is explicit, and much nicer than using [0] (if I got something other than a single value wrapped in a sequence I really don't want my error silenced). Also, more consistent with: (x, y) = struct.unpack("II", str) 
How do you give a name to the result of struct.unpack("I", x) ?
I use fetchOne() in case like this, counting on the database to keep stuff unique. If you want to be more careful, add an assert. Hiding the assert in a smart way is not a good idea.
This could really do with a results table to show it actually works.
I can't remember a single time I have unexpectedly received a set instead of a list or vice-versa, and it wasn't an error - so the assert would apply for that as well.
Last I checked, Sony has some very strict rules about interpreted languages on the console, and also -- forget about downloadable interpreted content....
What's wrong with vim?
Oh, it isn't. There are just some things that make immediate sense and others, which you have to think about, even if you're already familiar with the language. It's the latter we're trying to avoid.
Who said there was anything wrong with vim?
This is one of the more practical articles on Markov chains I have read. Good work on the part of the author.
There is no need to use a line continuation backslash inside braces, brackets and curlys in python.
I haven't had to mess around with dependencies (even basic ones) in ages.. Any chance I can point to a repository, and let apt-get sort out the details?
...it's writing raw audio to the sound card. Voodoo for sure. 
I'm particularly interested in how the audio that's being created is being sent to the sound card... I didn't think you could write raw data like that?
I don't think anything makes "immediate sense", some things just appeal to notation you've already internalized (e.g: arithmetic notation). The (x,) = ... idiom is so common in Python, I am really surprised people here claim they have seen little of it, or have to think to read it.
That does go against duck-typing though. If you don't care about order, why place an artificial restriction? Here you don't want to get completely different information than you intended.
I just downloaded and fiddled a little bit. The first thing I always check is the code completion and I think this has the best code completion for a python IDE yet. I did: `window = gtk.Window() # Window was autocompleted with no special setup needed` `window. # offered options that are context sensivte to the object (Window and Widget options)` Very nice!
what's the difference between the personal and commercial edition?
This code used PyAudio, which provides Python bindings to PortAudio, which lets you do that kind of thing.
Is it? I've always seen two or more items in unpacking operations, not a single one. I hate how out of balance single-item tuples look, when I write them, but what can you do...
Implied line continuation is preferred when there is something implying it. An if reads better without redundant parenthesis, and readability wins. In other situations, parenthesis read better.
This technique for classifying text by author was developed quite some time ago, and the blogger doesn't provide any references. I don't have them handy, myself.
Try rmutt: http://www.schneertz.com/rmutt/
Believe it or not, Systems Programming isn't so magical. In reality it is so simple that it can become hard if that makes any sense. On a UNIX system, pipe some garbage to /dev/dsp and you will hear sound. The audio driver presents a character driver and the kernel handles underlying things such as hw codecs and bit transfer to the digital-to-analog converter and amplifier. Dig through the Linux kernel ALSA source to see a bit of this structure. A python audio toolkit will probably link to a higher level library like PulseAudio or ALSA's userspace library to handle a lot of low level details. A scripting language like Python usually includes the ability to create extensions that link to machine libraries so it is capable of just about anything C is with due diligence.
That was only one email message -- not a thread. Also, I don't see where it has clarified anything. But thanks anyway.
I don't know any references for that, at least for nothing using Markov Chains, that was an idea I had sometime ago and decided to implement, in fact is a very simple idea, I'm pretty sure someone could have done this long time ago.
Great news for Mercurial!
Woohoo. OK, this is probably enough to get me at least thinking about moving all my stuff over from github.
Good timing, I was pretty close to moving over to github.
I just switched from WingIDE a couple weeks ago. The Django and Mercurial integration are much tighter, and setting up project specific python paths was much easier. Also has better support for HTML, CSS, JavaScript, and even Django Templates which completely blew me away. If you aren't doing web development, the improvements are fewer over Wing, but still worth it IMHO.
As far as I can see, just the price and the license.
I've had fantastic experiences with django-piston: http://bitbucket.org/jespern/django-piston/wiki/Home FWIW: I believe it's created by the same guy who created (and just sold) Bitbucket.
Well it's using pyaudio and doing synthesis, the other link on that page uses pyaudiere
Also, at this point, I'm understanding this comic alot better: http://xkcd.com/353/
There is no such thing as unlimited and you should be wary of anyone promising such. If you doubt this, try dumping terabytes of data on their servers daily, see what happens.
So not only do we trolls have to come up with throwaway accounts, but now we have to exercise our ability to write in a completely different style .. nice! I like it! :) 
I receive my email today and was quite please to find out I don't have to pay now.
looks useful, thanks! 
it's A VCS, there are no terabytes of data ... Thats how they can offer unlimited, they have stackloads of servers, and hard drives and won't limit you as long as you don't abuse of it.
1. We already have a method of asserting things in the language: the "assert" statement. It allows you to assert any concept, not merely "this is an iterable yielding exactly one item". If you want to assert that some list only has one element before indexing into it, do so explicitly with an assert statement. Your code will be more readable as a result. 2. This is a true statement, but it isn't an argument to use unpacking to index into lists with a single element. If you're trying to suggest that unpacking is somehow more flexible than the [] operator, then again I disagree; [] is far more flexible. Python is designed to promote good programming. And good programming is human-readable. Python's designers *agonize* over its syntax, striving to enhance simultaneously the language's power and its readability. Clever "idioms" that confuse the reader on first try are no service to Python or to your fellow programmers. You should strive to write clear, clean, readable Python, and not clutter your code with clever landmines. Particularly this one. "Use [] to index into lists, unless you know the list only has one element and you want the zeroth element, in which case use structure unpacking" is a terrible idiom.
&gt; Your code will be more readable as a result. No. 3 lines is not more readable than one perfectly unambiguous line. &gt; If you're trying to suggest that unpacking is somehow more flexible than the [] operator, then again I disagree; [] is far more flexible. No, [] is far more different. [] doesn't work on a set, [] doesn't work on a generator, [] doesn't work on an arbitrary iterable, [] doesn't do the same thing (at all) on mappings.
Hm hm, it's nice... once there are binary packages for pygtk and pycairo 1.10 for python3 then I'll be ready to give it a go.
this is not "unlimited" hosting, that is based on overselling, the unlimited part in my title was about the fact that they dont charge by repo number, rather by contributors
Even in their FAQ they say that disk space is unlimited. We all know that this only works in regular cases and that excessive users will be "invited" to calm down, and that in practice it will work just fine. However osirisx11 is right to remind us that there *are* unpublished limits and that you can hit them without knowing.
yeah but i would suspect that 99% will never hit any limits, thats what i had in mind
if you think that it is important that stuff is a collection with exactly one element then write: assert (len(stuff) == 1) This way I will understand your intention when reading your code. 
&gt; stackloads of servers AFAIK, they use Amazon EC2.
Good to see that Mercurial is getting some love too. Now with a company behind them, maybe they'll get promoted more.
The exact same intention is expressed explicitly when you use: (stuff,) = ... instead of: stuff = ...[0] But more succinctly.
At user-space level, playing sound is as simple as writing the desired PCM (Pulse-code modulation) data to the sound-card. The highlighted line simply opens a writeable (output=1), mono (channels=1) with a sample rate of 44.1khz and a format of 32-bit floats. At a high-level you can think of the floats in your data input as specifying the position of the speaker at that particular sample. -1 specifying the speaker to be closest to the back, 1 specifying the speaker to be closest to the front. As the data is processed through the speaker it causes it to vibrate accordingly, producing sound. A naive way of thinking about it is that the value of the float specifies the volume of the audio, but this isn't true as you can see if you sent only a sequence of 1s to the sound card, and hear no sound (the speaker isn't moving). That's only my basic understanding of it, so if there are any inaccuracies anybody notices please correct me! P.S. This code was originally posted as: http://www.reddit.com/r/Python/comments/dhpx0/procedural_music_with_pyaudio_and_numpy/
It makes some editors indent the following line, making it more readable. Not ideal but I do this myself.
I try to avoid them wherever possible, as long if statements generally imply something can be done more tidily. Maybe something like: if something == "blah": raise AnException("...") if another &gt; 40: if yet.more.conditionals() == abc: return Another way that is sometimes very readable is to pre-calculate the conditionals to bools, then use the variables alone in the `if`: is_something = somevar &gt; 5 is_otherthing = another == "example" # ....etc if something and is_otherthing: pass
You need a new editor.
You probably don't know what explicit means. It is: "precisely and clearly expressed or readily observable". In your example the check if the container has only 1 element is only a side effect of the assignment. The side effect is not explicit check, but implicit or hidden. 
I'm enjoying going through it. And Zed's really receptive to feedback.
Unlimited private repos is a huge plus. I won't be mirroring my sensitive work-related projects on BitBucket any time soon, but there's a ton of stuff that I'd love to at least start private before moving public. Great to see the removal of limits on downloadable files too. I expect creators of niche Linux distros could get away with putting up a few DVD ISOs. That's as "unlimited" as any reasonable definition would include.
"Programmer done," that's going into the personal lexicon.
&gt; You type each one in (no copy-paste!) why does Zed insist on typing ?
Way too receptive I would add. Also, I see this more as a "learn python the slow and boring way" - a guide made for sloppy, superficial programmers or people who aren't programmers at all.
I suppose that's what makes it a pretty good starting point for me. I'm using it to get me into the right habits before starting an actual tutorial or book, which is Zed's own advice. 
Because you memorize things when you type them in, as opposed to copy/pasting?
Bingo. Copying and pasting is as brainless as it gets. You could copy/paste your way through any book in about an hour. You could also copy and paste entire college educations if you really wanted to, but it would be a waste of four years and a hundred grand, and you'd learn nothing.
ohhhh fuck yes. this is exactly what I'm looking for. also acceptable would be "transition from (other language) to python" or vice versa
"a guide made for [..] people who aren't programmers at all." &lt; That's the target group.
Turns out I was remembering work where "stop word" frequency was used successfully to classify by author. Still can't find a ref. Here's a citation from 2001 where the authors are using Markov chains at the level of single characters to perform author classification against fairly large corpora: http://www.math.toronto.edu/dkhmelev/PAPERS/published/llc/khmelev.html So, not what I would call "quite some time ago", after all. It is a simple idea, and powerful. In machine learning "hidden Markov models" are used extensively, because I think they work better for some interesting kinds of data (e.g., music): http://en.wikipedia.org/wiki/Hidden_Markov_model That article points out a kind of equivalence of HMM's and Bayesian networks, that I was not aware of.
He was serious? I thought it was a joke. 
Not enough fucking.
I know python, I've dabbled in c/c++, php, javascript, and bash for years as well as being extremely computer savvy. I personally love this approach because I don't consider myself to 'know' anything but python. When it comes to learning other things though it's hard for me to do because I pick up a c++ book for example and while there are lots of things I don't know scattered throughout the first ~300 pages I do know way too much of it to not have it bore me out of my mind. At the same time though I feel obligated to read it because of the things I don't know which likely are fundamental and important for later parts. They also tend to hold your hand and teach said language to a complete noob audience, most books tell you how to setup a compiler for fucks sake. I much prefer the, 'here, take this and figure out what it does, good luck' approach. It keeps me interested and engaged.
Are there any resources like this for c, c++, or java? I really like the approach he takes.
I was in the same position a about year ago. Python is simply just a more powerful language compared to C# and Java. I started a blog about it. http://www.movingtopython.blogspot.com The first posts are just about getting familiar with the language. The last post "Functions and Objects" is based on something I learnt in a scheme course at uni. To my knowledge this is impossible in C# and Java. 
Those figures blow my mind. When I went to school, state university tuition (SUNY) was $775 / semester.
Welcome to life as a programmer.
Me too. Specially java.
this is actually how i learned programming back in the 90s. i borrowed computer books from the library and played with the examples. eg niklaus wirth's "Algorithms + Data Structures = Programs" and some more general computing books. I consider it the hard way, OTOH the information at fingertips nowadays seems pretty overwhelming to me so such a book (just skimmed it for now) seems pretty much old-school and the approach not bad at all.
If I understand you correctly on your last question, I'd recommend looking through the [PEP index](http://www.python.org/dev/peps/) and reading through whatever PEPs catch your eye. In case you don't know, a PEP is a Python Enchantment Proposal, design documents which deal with the implementation of different features in the language and standard library. They're a great resource for learning the ins and outs of different features, and how they were decided upon along the way. For a nice look at the way things came together over time, the "What's new" pages for different versions are interesting too. They're a better starting place for getting an overview than PEPs which go into depth on specific topics. And if you go ahead with learning it, they only advice I can give you that isn't on the surface of every google-search is this: [ipython](http://ipython.scipy.org/moin/) it's an interactive interpreter. It's your best friend.
Nothing. But this has post also has nothing to do with vim.
It is not implicit or hidden. That's what it means to unpack a tuple. Using (stuff,) instead of ...[0] has no other meaning except to *precisely and clearly express* and make it *readily observable* that the collection being assigned from is supposed to have exactly one element.
haha, me too!
that would hurt less
it is most likely you *will* have a lib that isn't "up to date"
a lot of universities are 10-15k per semester. the one i went to was 16k a semester but mostly paid through scholarships and grants.
This should not be downvoted, it's a good question, that doesn't even contain any judgment, that led to good responses.
And when you type something out as a beginner you are very likely to make mistakes, and when finding what went wrong you learn a lot. Also, this is one of the places where you find out whether or not you have the right attitude. Do you get mad and give up? Or do you really care and push on? (That's also why mistakes in book code examples are profoundly insidious, they can permanently alter the course of somebody's life, editors should be _extremely_ vigilant around code examples)
Taking a list k elements at a time is actually a fairly common use-case - you'll seem a lot of recipes for a general case group() function out there. For the specific case, you should look at list slicing: With a list of items,look at what the indexes are for each batch of k items. The first k will be `l[0:k]` then the second k will be `l[k:2*k]` then `l[k*2:k*3]` and so on. You should be able to see how to put that in a loop / list comprehension to get your groups, without having to do a mess of if statements. (The one thing to watch out for is the last group, which will be shorter than then others if your list size is not a multiple of k - make sure you can handle things like single element lists)
[via](http://www.reddit.com/r/learnprogramming/comments/dkldi/learn_python_the_hard_way_a_free_textbook_for/c10xjon) ...from pdf page 16: &gt;*"A programmer will eventually tell you to use Mac OSX or Linux. If the programmer likes fonts and typography, they’ll tell you to get a Mac OSX computer. If they like control and have a huge beard, then they’ll tell you to install Linux."* ಠ_ಠ
I came to exactly same conclusion when pondering why I'm not using my Ubuntu on daily basis. Windows &amp; Mac OSX just have so much better fonts.
That's odd... I always hear the font rendering in Ubuntu is much better than Windows'.
Hedonism = worst teacher ever!
Take a look at this [screenshot comparison](http://i.imgur.com/HdcI4.png). Pay attention to the reddit example. 
That's just your hinting (right?), which can be adjusted.
http://en.wikipedia.org/wiki/Language_model
You should probably add some sort of smoothing method, since word frequencies follow a Zipfian distribution. It is very likely a document will have a word or word sequence not seen in your training data, and you don't want to give these events 0 probability. This [PhD thesis](http://ai.uwaterloo.ca/~f3peng/publication/thesis.pdf) covers these topics well and does many simple experiments showing how character language perform on various tasks, using various smoothing methods.
Correct, furthermore - there are 4 hinting options &amp; 3 different rendering modes, so there is no shortage in terms of possibilities &amp; control. The problem lies in choice of their default fonts. To battle this I changed the default Sans to Segoe UI font. Now most of the applications look good. For some reason Reddit un Ubuntu, still does not look as good as on Windows though.
I use the droid fonts and everything looks great here.
huh "Hedonism" ? also "Hedonism == worst teacher ever!" 
wow I didn't even realize I got a "-5"....reddit is so fucking crazy weird sometimes
I don't use it. I never remember whether else: part is executed when the for loop completed its execution or failed. For me the "else" keyword should mean "do something when last thing didn't succeed".
It's best used in cases where the `for` loop is searching for something, and invokes `break` when it finds that thing. Then the `else` clause means "I didn't find it", so the name makes sense.
I never knew about it, either. Seems kind of unintuitive and an abuse of the word "else" since the for loop always executes.
&gt; an abuse of the word "else" since the for loop always executes Well, it might be ill-named, but the the loop doesn't always come to completion; the point of else is that if the *for* completes (doesn't use a *break*), **then** the *else* "suite" executes. *edit*: correction.
see gxti's reply above, or more relevantly the article itself. the construct shouldn't be referred to as for/else, but rather for/break/else; which then make a lot more sense as a useful extension to the basic for loop.
while has this, too. Here's the example in the article (poorly) rewritten using while: def contains_even_number_while(l): # unidiomatic but this is an example i = 0 while i &lt; len(l): if l[i] % 2 == 0: print "list contains an even number" break i += 1 else: print "list does not contain an even number" odds = range(10)[1::2] has_even = odds + [10] contains_even_number_while(odds) contains_even_number_while(has_even)
1) put a text into emacs 2) M-x dissociated-press 3) enjoy!
I mean a tutorial which recommends that you take the lazy route doesn't teach you the right way to do things. PS: Upvoted for "=="
Yeah, the "else" doesn't seem intuitive here, when first mentioned I thought it might get executed if the loop was empty, eg: for i in []: pass else: print "list is empty" Still, there are times I would have used the for-else had I known about it... vim and python, been using them for a decade and I still find things all the time that I never knew about...
There's an important difference between Markov chains and the simple n-gram counting that's presented there: Markov chains are a probabilistic model and will assign a probability of 0 to any unseen event, which means that you need intricate smoothing procedures to make use of them (for probabilistic Information Retrieval, or anything else). The count-the-ngrams approach on the page has less discriminative power than a language model, but is simpler - i.e. easier to implement and probably also easier to implement well enough that you get usable results.
Thinking of it that way does make it sound more sensible.
yes, *more* sensible, but not 100%; maybe *finally* or *otherwise* or something similar would have been a better name. Still, it does make sense once you realize what's going on.
Would be a good name if `for` was called `find`, but alas, it isn't.
I hate this construct, because I always think the else will execute if there is no iteration (if we never get into the `for`'s body, with an empty iterator for instance). While it might not be as useful, I find it reads far more sensibly.
I don't understand your notation. Suppose my list of k elements is given by a = [] I want to take products of elements of a, taken "l" at a time.
Er... No, the else *doesn't* execute if a break is used. According to the article, anyway.
I think that was his intention, at least the not programmers bit. Dive Into Python gets suggested a lot for new coders (not just programmers new to python but people new to programming); Zed didn't think it was a good resource for rank beginners so he made one.
Oops, orrected above; the ref is quite good: for_stmt ::= "for" target_list "in" expression_list ":" suite ["else" ":" suite] And it supports the case that "else" should be called something more like "finally". *edit*: I accidentally the whole like. 
tl;dr: I think that what is happening is pretty quiet, but activity was seen too recently to assume it is abandoned. I'd wait 3-6 months before concluding that. There is speculation on the wikipedia page here: http://en.wikipedia.org/wiki/Unladen_Swallow I think that some individual pieces have already been merged into CPython for 2.6 or 2.7, and more pieces are in progress for 3.x. See PEP3146 for "Merging Unladen Swallow into CPython". They are working on python 3's py3k-jit branch. That progress can be seen somewhat at: http://svn.python.org/view/python/branches/py3k-jit/ There wasn't anything there in more than 3 months now, but there were some recent checkins on unladenswallow on google's code hosting.
&gt; "As of July 2010, some observers speculated on whether the project is dead or dying" :( It always surprises me that it can be so hard to get clear information on an opensource project like this.
The work for merging it into python-core is happening on the http://svn.python.org/view/python/branches/py3k-jit/ branch. There is no rush to push it into the 3x branch "right now". It's not dead. It's being merged.
But no activity in 3 months?
Thanks, I'll take a look.
I like your explanation, maybe I'll finally remember it.
Same here, have been looking for a good Python book on the subject.
I absolutely love pycharm.
It doesn't have to be actively changed to not be dead. I've read in a few places that the Google engineers who worked on it are back to other projects now, so that may explain why it hasn't been modified lately.
A number of optimizations have made their way into current CPython. I know some pickle changes were committed, but I'm sure there are others.
I completely agree. And i think it's have more sense. if len(l): for i in l: ... else: print "empty" Is something you can read more time that the way it is implmented. And i have never see an open source project using the else statement woth a for loop... 
I was really looking forward to the JIT though.
What Brian says. The google engineers dedicated to it are dealing with other things currently. Besides, Python 3.3 is some time off. 
Ask them.
I believe you'll see it in 3.3.
So, for..else is kind of useless without a break statement? Seems unintuitive and I don't think I like it. :(
I think "for-then" would be much more intuitive. Although, I guess that would have required adding a new reserved word.
I would prefer "finally" or the like, but I do agree that *some* other word should be found to describe this. 
I'd rather have an extra if-else construct after the for loop just to make it clear. And if you wanted to find the even numbers in a list, there are more concise ways of going about it, such as: ListEven = [x for x in ListAll if x % 2 == 0]
I'm in school, and we're always told that "break" is a big no-no. How accurately does this reflect real-world practice?
It's actually python's slice notation. If you're not familiar with it, a[i:j] essentially means "Give all the elements in a between index i and index j". (Note that the first index is 0, and it's non-inclusive of the last (Think of the indices as being between the items)). For instance: # INDEX: 0 1 2 3 4 5 6 # | | | | | | | &gt;&gt;&gt; a = [1, 2, 3, 4, 5, 6 ] &gt;&gt;&gt; a[2:4] # &lt;.....&gt; [3,4] So essentially, this does exactly what you want. Eg. To get the k items starting at index 5, you'd do a[5:5+k]. To break the list up, then you want to take k items, increasing the start index by k each time. You can do this with a list comprehension: &gt;&gt;&gt; k = 3 &gt;&gt;&gt; a=[1,2,3,4,5,6,7,8,9,10] &gt;&gt;&gt; num_groups = len(a) // k + (1 if len(a)%k&gt;0 else 0) &gt;&gt;&gt; [a[i*k:i*k+k] for i in range(num_groups)] [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10]] From there, you can just multiply the items in each group, and add the results together. Alternatively, you could do the same with a for loop if you're not familiar with listcomps yet). Replace the last line with: for i in num_groups: this_group = a[i*k:i*k+k] # Multiply the items in the group. # Add it to a running total (As you can see, there's a bit of a corner case to watch out for if the number of groups is not a multiple of k., hence the extra +1 for this case.). Here the list comprehension takes the group s between 0 and k (where i=0), then k to 2k (i=1), then 2k to 3k, and so on, taking k each time and starting where the last group ended. 
Behold: while blah: for b in blahblah: if condition: break else: break Surprisingly useful...
Just to clear things up: it does get executed in this case too (but not only). I nearly broke a cold sweat when I took your comment to mean that it doesn't!
Finally executes always, that's its point.
Right, I meant just the name, not the semantics of finally; Obviously it's problematic as well (due to what you mentioned), but it would at least "feel" better. There was a suggestion of "then", and I also proffered "otherwise". I just don't think the word "else" matches the semantics of what is actually going on.
Yeah, I was just illustrating how I thought it *would* behave (before reading the full post). Meaning, I thought 'else' would only be executed if the list we were trying to iterate over was empty, as in "for item in list, do this, but if there is nothing in the list, do the else"
It's not the best choice as it is, but so far I think it's the best of all proposed alternatives. And it's useful enough to warrant the inclusion in the language despite all drawbacks. Sure, it can confuse the reader once, it doesn't follow the principle of least surprise, but it's much more useful this way. 
I don't understand how this solves my problem. Example: I have a list a = [1, 2, 3, 4] I want to take their products 3 at a time, that means I want the sum: S = 1*2*3 + 1*2*4 + 1*3*4 + 2*3*4 The pattern is simple enough to write with 3 while loops in this case because I am doing the products of 3 elements at a time. For the case with "l" elements in the product I need "l" while loops. So I wrote down 10 different cases for l = 1, to l = 10. What I want is for this to be doable for a variable "l" to be entered by the user. Also how are you writing code like that in Reddit?
Not very.
This reminds me, I was wondering the other day, "Why doesn't None support the iterator protocol?" I frequently find myself calling functions that return a list or None. It would be so awesome if I could write: for x in results: handle_result(x) Instead, I have to write: if results: for x in results: handle_result(x) 
Because `None` isn't iterable... Why don't you just write functions that return an empty list, if that's how `None` is supposed to be interpreted.
The same is true for various idioms, too: `x, y = y, x` is practically equivalent with `temp = x; x = y; y = temp; del temp` `x = y[:]` is a shallow copy (like `x = list(y)` if `y` is a `list`, or `x = tuple(y)` if `y` is a `tuple`). etc
Because I don't write all the functions I call?
Because I don't write all the functions I call?
Know what I have to say to you? 5! 5 5 5 5 5!
It is, however, consistent with its role in exception handling. try: foo() except: pass # foo raised an exception else: bar() # only do if foo returned properly baz() # do regardless Above, the `else` clause is only executed if no exceptions were raised. I agree that it seems semantically unintuitive, but at least it's consistent in these two roles.
Why? Wouldn't it then be useless since this: for i in stuff: if condition: return foo return bar and this: for i in stuff: if condition: return foo else: return bar would be have the same?
 if any(not num % 2 for num in alist): print "list contains an even number" else: print "list does not contain an even number" * ``any()`` takes an iterable and return ``True`` if any member is true in boolean context (``bool(x)``) otherwise ``False``. There is also ``all()``. Basically "any" implements OR and "all" implements AND. * As the argument to ``any()`` we use a [generator expression](http://www.python.org/dev/peps/pep-0289/). This is like a list comprehension but a generator and doesn't even need the extra parenthesis if used as an argument to a function. * ``bool(x % 2)`` is effectively a check for if ``x`` is odd. We want to check for even numbers so we negate it. It is generally preferred in Python to check the boolean value of something rather than the exact value, for example ``not alist`` over ``alist == []``. Similarly we prefer ``not x % 2`` over ``x % 2 == 0``. * We could also have used ``not all(num % 2…)`` but that would need to iterate all members. Premature optimizations FTW!
It's worth noting that this use of an else-clause in a try-except is a good practice. If ``bar()`` raises an exception you might expect from ``foo()``, it's not clear where it's coming from.
But then you might as well put the fall-through return after the loop without an else clause?
foo = func() or []
I was also taught in school to *never* put a return anywhere but at the end of a function. 
Actually, as you show, it makes no sense with return. But it does make sense with break. for i in stuff: if condition: break else: that_condition_never_happened()
In Python? Are you sure? Maybe they mean infinite while loops with breaks that potentially never executes… It's perfectly fine in a for loop though.
So None acts like None and it also acts like a single-item sequence containing None? That just seems needlessly confusing. 
I realize that; it's what the article was about. punosqnp was talking about return though.
 for x in results or (): handle_result(x)
There's nothing inherently wrong with break. Look through the code of any well-written open source project and I'm sure you'll see it pretty often.
then would following work? for i in foo: try: # do something except: break else: print "no exception raised"
Yep, some classes don't allow it at all: http://www.cs.umbc.edu/courses/undergraduate/201/spring10/lectures/loops.html#(15)
Well, you posed a question, so I attempted to help answer it. My mistake if it was a rhetorical question.
Yeah, I never really got it. They tend to go to extremes in the lower classes to weed out bad habits, so perhaps that's why.
Yes. The `break` is not in a new scope for the `except` block. Granularity for reference scope is smallest at the function level in Python. So, the `break` there is still just breaking out of the loop.
Yeah, I can understand that. It must be hard constantly trying to guide the newbs.
Are the people making up these classes actual programmers? * ``break`` is required for certain tasks, and *the* way to do some things in Python. * You **never** want ``input()`` in Python 2. Even if you really do want ``eval(raw_input())`` I suggest you write that for sake of being explicit. In their example I'd use ``float(raw_input())`` and catch ``ValueError`` for values that are not numbers, and EOFError for Ctrl+D. My rewrite: numbers = [] while True: try: x = float(raw_input('Enter a number (0 or Ctrl+D to quit): ')) except ValueError: print 'That is not a number! Try again.' continue except EOFError: raise SystemExit # or import sys and sys.exit() else: if not x: break numbers.append(x) print print 'The average of the numbers is', sum(numbers) / len(numbers)
It's cool. I was just curious why punosqnp thought it would be interesting when `return`ing from a loop.
I also use it to do "try something a couple of times and break when it works" constructs. I deal with embedded software so sometimes the hardware is flaky. 
Can't you put that in the for statement? for x in (results or []): handle_result(x) I don't even think you need the brackets, but I'm not sure. It'll work if you have an empty list or None or 0.
You don't need the parenthesis so just for x in results or []: handle_result(x) is fine. And I suppose if you are not using *results* anywhere else you might as well write it: for x in get_results() or []: handle_result(x) This works whenever results is None, False or 0.
That was a coding guideline in one of the places I worked. It didn't make any sense why that was the case there but I can understand the motivation for it. There are cases where you need to be aware of all the possible paths a function can take, and in those cases having one return statement makes it a little bit easier to analyze.
Someone at work wrote code like this. except instead of catching just ValueError he caught everything :(
I love it, and I think it makes perfect sense.
not all is just as efficient as any. all will shortcut just like any. This is also how I would have done it. The hardest thing to teach experienced coders about Python is batteries included. I know a few coders who have picked up python in the last few months and I don't think any of them are aware of any and all.
might be a stupid question but can you do a while blah: break; elif: break; else: break?
No, it's not neat. It's a mistake, because it has no clear, obvious meaning: even people (like myself) who've used Python for more than a decade have to look it up in the language reference whenever we run across it.
There is no logical way anything could tell you if all X are Y without checking all Xs. Or am I missing something? Edit: *facepalm*. Lets blame the late hour for my timezone.
you stop once you find one X that isn't Y. Just like checking to see if any X is Y stops once you find one that is Y. all is the analogous to putting "and" between each element in an array and any is analogous to putting "or" between each element in an array. They both short circuit but they short circuit under different conditions.
http://www.reddit.com/r/Python/comments/dkzpa/i_never_knew_about_the_forelse_construct_neat/c110vkl ``()`` (the empty tuple) is possibly more efficient; because it is immutable the compiler can optimize. It's an iterable constant that yields nothing.
Python has strict semantics, however. ``all`` evaluates before the negation of it. I see your point though. ``any`` needs to iterate all members if none or only the last is true. ``all`` needs to iterate all members if none or only the last is false. So it's a matter of which case is expected to be more common. In this case it's a pretty clear-cut 50/50 scenario, assuming the list of numbers is random. I was confusing myself by focusing on the if checking for even numbers.
&gt;Are the people making up these classes actual programmers? yes &gt;break is required for certain tasks, and the way to do some things in Python. If it's not too much trouble, can I have an example? &gt;You never want input() in Python 2. I suspect it's taught that way just because it's an introductory course. It is simpler on the students to just think "use input() for numbers and raw_input() for strings." Maybe they figure it's a bad habit that will be easily corrected the first time they do a real python program. Also, they don't learn try, catch, except until the next course. 
&gt;&gt; Are the people making up these classes actual programmers? &gt; yes I highly doubt that if they forbid `break` for no reason at all, even worse if they call it a "bad programming habit" or anything similar. The only reasonable way to explain its avoidance is "`break` can be used for some fairly advanced things, and can be prone to errors if you're not careful -- but we won't need it for any of our introductory work."
I thought the goal was to remove the GIL but they couldn't find a way to do it.
http://stackoverflow.com/questions/216359/break-statements-in-the-real-world http://forums.sun.com/thread.jspa?threadID=5391985 http://ubuntuforums.org/showthread.php?t=810001 all seem to disagree with you. Googling around makes it seem like: * the problem with break has to do more with the readability side of things than the logic side of things * it's fairly normal in academia to forbid break, continue, goto, etc. CMSC 201 at UMBC tends to have a reputation as an overwhelming course. As a result, professors tend to leave out / simplify extraneous things. I think this is a fair example of that--any student who goes on in the programming world will see that "break" is okay situationally, so they introduce it and forbid it. I'm happy to see any evidence (anecdotal or otherwise) you have to the contrary, but if I'm right you're essentially disagreeing with a large group of Ph.D.s with decades of teaching experience.
&gt;the else suite is executed after the for, but only if the for terminates normally (not by a break). ... &gt; keep the "happy path" logic at the top and the exceptional/error case at the bottom. now i am confused :(
Python is good because I could take a section of code from almost all of my projects, plop it down in front of you, and you could tell me the jist of what's going on. You think that might be a marginal benefit, until you realize that you end up using less brain power on figuring out *your own* code as you go along, and more on actually solving real problems. I make complicated websites, and I would say 80-95% of the time is spent doing front end work, because the backend python is so damned easy its ridiculous.
It pretty much failed to reach any of its goals, so there is not much of a rush.
&gt;It has peaked my interest in python so... /r/python, I ask you: Just FYI, you meant [piqued](http://www.merriam-webster.com/dictionary/piqued).
I think a classic problem solving technique would help you here. Divide your problem into smaller more manageable problems. Instead of thinking about the whole game just focus on a single cell first. Now your problem is reduced to this. Can I draw a square and change its color? I think you can do this with any graphics library. wxPython, TkInter, pygame, pyQt, HTML, HTML5, excel, ASCII ... Whatever. Now your new problem is mapping your results to bunch of cells. You should be able to see that a 2D matrix is perfectly mappable to a rectangular grid of cells. Now you have something like Cartesian coordinates. Instead of x and y you have row and column. Now you need to find a way to communicate between your matrix and the grid. Nested loops are the perfect tool for this. Congratulations, now you can represent your matrix as a colored grid of squares. Now the last step is to handle a continuous stream of states. If you add another outer loop this would take care of it and you would be done. I would recommend reading Polya's How to Solve it. Here is a [summary](http://math.ucr.edu/~res/math205B/polya.pdf). This book is a must read for all programmers. 
That's a pretty big advantage, currently I work on a project with 12 developers, so being able to understand other people's code.. is pretty handy. That can also be a bit of a challenge with perl unless it's well-written to a spec put out by someone. One of the big advantages I see about python is that there is "one right way" to do things (or at least less variety of options compares to PHP, perl, etc)
[Issue #10000](http://bugs.python.org/issue10000)
Perl is a language of ambiguity. Everything is beautifully cryptic and clever, and thusly impossible to understand. Python on the other hand tries to free itself of ambiguity, by enforcing standards and single paths. The biggest trouble you get into Python is, that after a while, you start to see the cracks in the system and want to do things in completely weird ways. It seems liberating at first, or super clever. But in the end, doing things the boring, straightforward way is much better. And PHP is just plain crazy. It's a great platform for quick web applications, but it is a horrible language, bereft of all thought in its creation of syntax, rules, etc. All you have to do is look up Rasmus Lerdorf quotes on the net and see what I mean. I find that the best projects start out with a Philosophy, and then follow it with a reasonable guiding force. "import this", and see what I mean.
eh? __ __ __ __ / V \ / V \ | | | _ _ | | | | | | / \/ \ | | | | | | | || | | | | | | | | || | | | | | | |__| || |__| | | ___|___| / | || | \ |___|___ / \| / || \ |/ \ | ______| | || | |______ | | | | || | | | | \ '__/ || \__' / | \ ) /\ ( / \ / \ / | | | | 
I was thinking this very example requires ``break`` but maybe I wasn't thinking clearly. It can be done with a closure: numbers = [] def get_number(): try: x = float(raw_input('Enter a number (0 to finish, Ctrl+D to quit): ')) except ValueError: print 'That is not a number! Try again.' x = None except EOFError: print raise SystemExit else: if x: numbers.append(x) return x while get_number() != 0: pass print print 'The average of the numbers is', sum(numbers) / len(numbers) Not sure I'm convinced it's more readable, though. It also suffers the same problem that the loop will be infinite if the function never returns ``0``. I'd say their problem is really with ``while`` but **that** I *really* don't see how they'd do without. 
Ph.D.s who invent languages like Haskell where breaking out of a recursion makes no sense at all. Not bashing at Haskell — they're just *so different*. You can't really hold this expectation on Python programs.
[From your own link](http://stackoverflow.com/questions/216359/break-statements-in-the-real-world/2657481#2657481) Has many more upvotes than the top answer.
&gt; Beautifully Cryptic well said :D I've spent the past few years learning how to write clean perl... takes a good deal of work and discipline to do. &gt; And PHP is just plain crazy. It's a great platform for quick web applications, but it is a horrible language, bereft of all thought in its creation of syntax, rules, etc. All you have to do is look up Rasmus Lerdorf quotes on the net and see what I mean. Lol, I've read quite a bit of his quotes. My PHP work is mostly due to the industry I work in (we're a perl shop, but most of our customers use PHP). PHP reminds me of perl redesigned by someone who hates the things that makes perl great.
Indeed I did.
The goal was to speed up Python. GIL was just one of the optimization targets.
To summarize this waste of space: "Write short, testable units of code instead of 1200 line pieces of shit"
&gt; S = 123 + 124 + 134 + 234 Ah, I was assuming by "3 at a time", you meant taking the first 3, then the product of the second 3 and so on, and adding them together. Thus for `[1, 2, 3, 4, 5, 6]` it would be `1*2*3 + 4*5*6`. What I think you want is usually referred to as picking all possible [combinations](http://en.wikipedia.org/wiki/Combinations) of 3 items. A good way to approach problems like this is with recursion, which usually involves framing the problem in terms of a (simpler) version of itself. This results in a function that essentially calls itself. Consider all the combinations of 3 items which contain the first item in the list ("1" in our example). Out results are going to be something like [1,x,y] where x and y are picked from the remaining items in the list [2,3,4]. Then there are the items that contain "2", which will be of the form [2,x,y] where x and y are drawn from the other elements of the list, apart from 1 or 2 (since we don't want to count the ones with "1" in them twice: otherwise we'd get both [1,2,3] and [2,1,3]) - which means pick 2 from [3,4] (obviously the only solution here is [3,4]). Then all the ones starting with 3, which are [3] + (pick 2 from [4]) which obviously has no solutions. Nor do those starting with [4] (they've all already been covered). You may notice that this boils down to "choose an item, then pick 2 from a shorter list". That "Pick 2 from a shorter list" is just a repeat of the original problem, except with 2 items instead of 3, and a different list. In fact, picking 4 items boils down to a sequence of picking 3, and so on. So we can express "pick k items" in terms of choosing start items, and combining with "pick k-1 items" The one final piece of the puzzle is how to stop the chain, generally called the *base case*. You could define it as "Pick 1 item", which has a fairly obvious solution (just pick each item in turn). There's actually an even simpler case: pick **no** items, which has the single solution of an empty list, regardless of what list we pick. Alternatively, you could take 1 as the base case and replace the line below with `if k == 1: return [[x] for x in l]` Here's some code that does this: def combinations(l, k): """Pick k items from l, order independant""" if k == 0: return [()] # Base case: pick the empty sequence. results = [] # Build a list of results for index, item in enumerate(l): # item is our first element, and we want to combine it with the combinations of everything after it. remaining_items = l[index+1:] # Gives you all items after the chosen start item. for combination in combinations(remaining_items, k-1): # Pick k-1 items from the remaining ones. results.append((item,) + combination) return results print combinations([1,2,3,4],3) Which gives us: [[(1, 2, 3), (1, 2, 4), (1, 3, 4), (2, 3, 4)] Recursion is a very useful general principle for problems like this. Where you find yourself in a situation where you have to keep adding a new loop for every increment in the problem level, a recursive solution is usually the way to go. In this particular case, there's actually an even easier solution, as combinations is a sufficiently common problem that there is an implementation in Python's standard library (as of Python 2.6 at least). It's in the itertools module, named `itertools.combinations`, and works similarly to the above except that instead of returning a list, it returns an iterator. If you haven't run across these yet, they're essentially sequences that you can use in for loops and similar places, but that don't actually do the work until you actually try to get the next item. You can only access them sequentially, so no indexing into random elements, but they have the advantage that they don't need to hold all the items in memory at once, which can be important with very large lists. To use it: import itertools for combo in itertools.combinations([1,2,3,4], 3): print combo # This is where you'd multiply the items, and add the result to your total. Which gives: (1, 2, 3) (1, 2, 4) (1, 3, 4) (2, 3, 4) &gt; Also how are you writing code like that in Reddit? If you prefix your code with 4 spaces, reddit will format it as code (monospaced, and no escaping for things like * and _). For code embedded in a single line, you can surround it with backtick characters \`like this\`, which will be rendered as: `like this` (To write a literal backtick, you can prefix it with \\, so to get the one in the previous line, I wrote \\\` (Similarly, to get a literal backslash, use \\\\)).
So basically the rule of thumb to follow for any project in any language? Cool.
Teachers and students with way too much time on their hands have been downvoting that, it seems. It's the right answer. Sure enough, break can be misused. But sometimes it's the direct translation of the actual logic behind an algorithm, and using extra booleans is just wrong, regardless how much purist taboo it conveys.
If raw_input releases the GIL then this is not an issue. Other threads can run just fine. There might be some overhead when trying to reacquire the GIL, but I doubt it's gonna be an issue. see: http://dabeaz.blogspot.com/2010/01/python-gil-visualized.html
Ok. What I was trying to point out that other threads would be able to run while the `raw_input`-using thread was blocking. Is that not typically the case if the blocking operation does not release the GIL?
K, now how can I take the sum of the products of these lists? print combo[0] # will this give me the first element of every list? Will it be a matter of a while loop for the products and another while loop for the sum of the products? Or are there built in functions for this too? Where can I learn about the built in functions?
&gt; print combo[0] # will this give me the first element of every list? It will, though for your case, you'll probably want to go through every item in `combo`, multiplying them together. &gt; Will it be a matter of a while loop for the products and another while loop for the sum of the products? There is a builtin function for sum, though not for product. However, it should be relatively easy to write using a while or a for loop. (There's another common way using a function called `reduce`, but that's probably a more advanced topic, so it's best to stick with a for loop initially.) Once you've defined such a function, the solution basicly a single line: l = [1,2,3,4] k = 3 print sum(product(combo) for combo in itertools.cominations(l, k)) Or possibly clearer if you're not familiar with comprehensions: total = 0 for combo in itertools.combinations(l, k): total += product(combo) print total &gt;Where can I learn about the built in functions? The [python library reference](http://docs.python.org/library/index.html) will give you details on what functions are [builtin](http://docs.python.org/library/functions.html), as well as the modules in the standard library. It's a good idea to familiarise yourself with the builtin functions and types, and with the more important modules (This'll depend on what you're doing, but `os`, `sys` and `re` and `itertools` are some that are useful in a lot of circumstances.)
Features: * Uses Pango Cairo for rendering * Supports Complex scripts such as Indic scripts http://www.google.com/buzz/santhosh00/AEaYgQxLQpD/santhoshtr-pypdflib-new-project-started-solution
I'd like to see a python interpreter written in lisp.
excellent.
Thanks, I never thought of that!
I used this for a project six months ago. The code quality was *quite* good, with extensive, useful, and accurate comments. 
can you tells us how is the data stored? If you were to compare with Sphinx would do you think are the strenghts weaknesses (other than the fact it is pure python, a big plus!)?
If the GIL is not released other threads will not be able to run, even if the one holding the GIL is doing blocking IO. There are some modules that release the GIL when doing computationally heavy operations, usually when calling in to C code (like bz2), and in those cases you would get most of the benefits of a multicore cpu (until the thread tries to reaquire the GIL, when you would have some small overhead). I don't really understand what you meant by "not truly concurrently since it's Python" in the raw_input case.
*Follow up:* [(How to Write a ((Better) Lisp) Interpreter (in Python))](http://norvig.com/lispy2.html)
Because you didn't read the tutorial. I remembered it from there because it was used in an example meant to look for prime numbers. It made sense at that time. I'll admit that I had forgotten its exact behavior in the meantime, though. 
Thought it deserved a post: http://www.reddit.com/r/Python/comments/dlmqf/follow_up_how_to_write_a_better_lisp_interpreter/
Whoosh rocks!
Could you please give an idea of the limits of the indexing. How many documents can you index before it chokes?
My opinion on this is a bit stronger - This is flat-out unpythonic. Horribly, horribly unpythonic. Lets let C and C++ have "one keyword that does ten things in ten contexts", please. This is Python.
[Ask and ye shall receive!](http://en.wikipedia.org/wiki/CLPython)
Last I checked, Whoosh doesn't handle concurrent writes - it's fine if you generate your index once offline and then query it though. Sphinx would also be a lot faster. Whoosh is fantastic for adding search to small to medium sites though, e.g. the average blog. We used it on http://cosmos.natimon.com/search/?q=newton
Dusty Phillips wrote a good one: [Python 3 Object Oriented Programming](http://www.amazon.com/gp/product/1849511268).
You know, we've both currently got 4 down votes, but I really did think it was a joke. When it was announced I checked it out and it didn't read like any programming book I'd ever read, and it was less than 1/4 done. At first I was like "this is really good" then I moved to chapter 2 and it was half finished. Most of the "chapters" were just titles without any content. I figured it was a joke and he'd decided it wasn't worth the effort to flesh it out with his smarmy witticisms. 
Nice! Now, how fast can a lisp program compute 100! when it's running under the lisp interpreter written in python under lisp?
I've used it for minor things, but never for anything major, so use it with caution. I'd love to see a full Python system built atop Scheme or some other lisp though; 'twould be great for software ecologies &amp; for general sharing of code.
this is excellent. reddit fills my heart with joy இ_இ
Use with [Haystack](http://haystacksearch.org/) in your Django apps.
I've used it in combination with Haystack during initial development. It's not bad but it does not do well with even semi-large sites. We have had a lot of luck with xapian though. It's a bit of a pain to setup and not pure python but there are python binding and integrates well with haystack.
Why not work with reportlab in order to support Indic/arabic?
Here is the same input and pdf output: http://web2py.googlecode.com/hg/gluon/contrib/markmin/markmin.pdf Here is an example of a blog page using markmin: http://web2py.com/d2l/embed/page/1/blog Markmin does not require web2py and has a BSD license. We distribute it with web2py under contrib for ease of maintenance since web2py depends on it. markmin2html, markmin2latex have no dependencies and you can only get the one you need. markmin2pdf depends on markmin2latex and pdflatex (not a python module but comes with tetex and miktex). EDIT: yes there is a html2markmin but that requires web2py: def html2markmin(html): from gluon.html import markmin_serializer return TAG(html).flatten(markmin_serializer) html2markmin works most of the times but chokes when HTMLParser chokes.
Having used Whoosh, Sphinx and Solr as candidates for [historious](http://historio.us/) (the service indexes millions of bookmarks in the form of entire webpages, so the engine needs to be **robust**, I can tell you the following: Whoosh is very easy to implement, very easy to understand and get up and running quickly. Its performance is okay, and is a **great** fit for full-text searches on websites (up to a few thousand documents). I haven't used Sphinx **too** extensively, but it is **fast**. It's reasonably extensible, but not for huge use cases, as far as I know (I may be wrong). It's great for single-server scenarios where you need to index lots of data quickly and not do too much with it. Solr is the powerhouse of searching, it is quite fast (not as fast as Sphinx, in my baseless opinion), but it's configurable to the end, if you spend a bit of time reading the docs. It can scale to many servers very easily, and can be tuned to do whatever you want. For numbers, whoosh was indexing about 0.5 documents per second when we had thousands of webpages, solr does about 10/sec with millions. Whoosh was great for getting our feet wet and starting out, but when we got our first social website mention, we found we had to replace it **ASAP** because the indexing was unusable. All in all, whoosh is perfect if you want to add full text searching to your site (index infrequently, search frequently), but not if you want to do more heavy-duty work. YMMV!
this doesn't scale much, the author explains in the mailing list that it's meant for small in-site seach, not real search-engine solutions.
Sure, why not? The old saw is Lisp in Lisp in Prolog in Lisp. Besides, there are things like 3Lisp &amp; friends that *are* lisp in lisp in lisp... so you can just alternate per level of abstraction *ad infinitum*. 
They had me at "unlimited private repos"... I dig the pricing structure because if you move beyond 5 people all needing access to a single private repo, you can probably justify the $120 per year to allow up to 10. I preferred hg to git but github to bitbucket. No more.
native python spellcheck. Awesome. *(looks into replacing aspell code with it)*
Good review, I also confirm SOLR was the best in what I tested.
Non-feature: GPL license
Does anyone know what the bottle-neck is for something like Woosh? Is it just the processing, or is it the backend storage?
Thanks, the downside is that you can't really find anything when you need to tune it past the defaults :/ We really need that at this stage, too (too much memory going unused while the disk is thrashing)...
Looks generally inferior to ReST/Sphinx unless I'm missing something. Not extensible in any documented way that I see.
Yea, the SOLR wiki is not great, but I found their mailing list to be really helpful and responsive. 
Oh, I'll send an email there, thank you for the tip!
This is simpler and implemented in a single file (one for html and one for latex, each very small). It allows you to specify the class of tables, blockquotes and code (so for example I can set color and other attributes of text). It allows to embed html5 video and audio. In my opinion it has more intuitive integration between html and latex, in particular in the way it handles references, anchors and bibitem. It is extensible using the extra argument as explained in the document. For example we use it in [this](http://vimeo.com/13485916) and we extended it to allow embedding widgets, code with syntax highlight and template language. Whether this is better or worse than reST I am not saying. I find the markmin syntax easier but I wrote it so I am biased. I am not aware of things I can do with reST that I cannot in markmin but I do not know reST too well, except that in reST you have more control over table structure and nested lists. markmin cannot do nested lists (yet). Perhaps you can point me other missing features so I can make markmin better. 
I could see this as being a suitable replacement for a wiki syntax (it looks very similar to Moin/Trac wiki markup), but there doesn't seem to be enough document-level support to write larger things (yes, I know, you wrote a book using it, that doesn't mean that Sphinx wouldn't have been easier). Example: How do I generate a cross-file table of contents?
How does xapian compare with Swish-E?
You are right. This is more suitable for wiki syntax than very large documents. It must be extended to do that. I have such extension but it not described or posted here. 
I've not found SOLR to be quite so pleasing. Check out ElasticSearch.
It's built on top of Lucene as well, what do you find better about it? 
Does whoosh or sphinx support facets? (for guided navigation)
I use haystack, and so have the option of all these searches, plus xapian. I use whoosh for front-end developers, and backend devs that aren't working directly with search, but the production, staging and my dev environment uses solr. The feedback from customers has been throughly positive, and whoosh gets the dev team by for 95% of their needs. also, haystack is pretty amazing, I had to replicate a legacy set of search views, and haystack handled it like a champ, and continues to handle spatial queries, faceting, and just about everything I can throw at it in a very comfortable, django/pythonic way. I should be doing a talk on this stuff at a boston django meetup in the near future.
daniellindsey is great, and has given me tons of support on freenodes #haystack channel. I have a pretty badass search if I do say so myself, but whoosh is only used for the front end devs who just need a populated search response - solr is needed for all the really cool stuff we do.
freenode #solr is another good place for solr tuning help. I deleted all the comments in the default solrconfig.xml, it made the thing SOOO much more readable.
solr and xapian do...
Another solution worth looking into is [FTS3](http://www.sqlite.org/fts3.html) which comes with SQLite. It looks like the functionality is substantially the same as Whoosh, except Whoosh has scoring. The advantage of SQLite is that the database (including FTS3 info) is all a single file and there is no need to setup servers, authentication etc. It usually outperforms other database engines for the same reasons. You can compile FTS3 as a loadable extension for SQLite (a little annoying) or use the binary distributions for pysqlite or APSW. For Windows binary they both include FTS3. If you follow the [recommended build instructions](http://apidoc.apsw.googlecode.com/hg/build.html#recommended) for APSW then it will automatically fetch the latest SQLite and include all the extensions. In my work I index just shy of 10 million documents (they are artist, album and track info) in under 10 minutes using APSW and FTS3.
Without being to verbose, I would have to say that dislike of solr stems from the number of features that seem to be attached with 5 minute epoxy. Some are part of a handler, a component or just some extension of request parameters. The documentation tends to be a bit stale so sorting out how to enable and disable certain features can be quite a pain. Now, elasticsearch isn't perfect, but it definitely is step in the right direction. It's documentation is better and the single developer working on it seems to be able to deliver features and fixes that the solr developers have trouble with.
Still at it. 
The license is actually LGPLv3 (updated)
So I've gotten through the book, what's next?
Fair enough, I'll keep it in mind next time I need a proper search engine :)
#solr tends to be a bit quiet... Deleting all the comments makes it ten times smaller, but the comments are a **great** tutorial.
It's pretty trivial to write your own search functions without haystack too, though... Haystack is great for site search, but our use case didn't match that, so it didn't make sense for us. We wrote a 20-line searcher abstraction class and could then switch backends with minimal effort.
I'm not sure :/ solr does, though.
yeah, but I would rather read docs to understand a tag and its parameters, then be able to find it and see which tags it is nested in on the same page. I certainly don't mine that they put all the comments in there to begin with, but all the xml tags are overly verbose anyway, most of it is understandable without the comments, so i saved the original as a backup, then removed all of them from my working copy.
Yeah, that's why I've used solr in the past. It's a valuable feature especially when you look at the cost of Endeca.
Hmm still no sound on my system.
Another data point. I use sphinx for [recipe puppy](http://www.recipepuppy.com). I run everything(apache,mysql,memcached,and sphinx) on a single vps and get about a million searches a day(most is bot traffic). I do know you can distribute the index. http://sphinxsearch.com/docs/manual-1.10.html#distributed
why not use BeautifulSoup for html2markmin? I've never had it choke on me.
I get the feeling that the webdevs in this subreddit only use frameworks. I wonder how many of them _could_ write a web app without Django or pylons.
My first web app was written in C, bash, sed and awk. *shudder*
it require complete rewrite of reportlab. It uses its own rendering engine. Adding complex rendering rules present in pango to that requires lots of rewrite on reportlab. 
Yep, same here, I removed everything after I've read and understood what each one was about...
Whoosh does ([documentation](http://packages.python.org/Whoosh/facets.html)).
a really good set of slides on the subject as well: http://farmdev.com/talks/unicode/
Another one who basically misses the point. * UTF-8 is not the only encoding. In the easiest case, you have file formats which declare the encoding themselves (e.g. XML), or where you have a reasonable expectation what the encoding will be (e.g. JSON, which is usually encoded either as ascii with \u00xx escapes or UTF-8). For everything else (i.e., any text file that could have been written using a different program), you need a way to guess or ask for the encoding. * For the non-XML case, codecs.open() is what you want. You specify the encoding name as the third argument (besides file name and mode), and there you have your stream of unicode strings. * For dealing with file formats that are internal to your application, either stick to byte strings in the user's default encoding (which will lead to problems when the files are moved between systems with different default encodings), or use unicode. Subtle issues may arise in unexpected places if you're not consistent about byte strings and unicode strings: For example, the byte string "\xc6sop" (Æsop in latin1 encoding) will count as unequal to the unicode string u"\xc6sop" (also Æsop), with Python printing a UnicodeEncodeWarning but otherwise doing business as usual. TL/DR: Use codecs.open and explicitly specify an encoding (that the user should be able to change through locale settings or similar), never mix byte strings and unicode strings.
That should be an option and it should be easy to add.
I hope that eventually all programmers will learn Unicode and I won't have to see these blog posts explaining Unicode over and over again :( (Not complaining about the article, it's a good explanation, but I hate how most programmers don't know Unicode)
&gt; Python is simply just a more powerful language compared to C# really ? you know c# ? (i don't), if so please elaborate
because
Or the issue becomes irrelevant and tucked away within the core of higher level languages because 99.9999% developers don't want to care about how their code is handling strings, they just want it to work. In the cases where it is necessary then its fairly simple to learn. 
i would do: &gt;&gt;&gt; def print_vals(*vals): ... for v in vals: ... print v, ... print ... &gt;&gt;&gt; print_vals(10) 10 &gt;&gt;&gt; print_vals(1, 2, 3) # note: no list here 1 2 3 
I would consider doing a variable length argument list and always iterating. [example](http://www.saltycrane.com/blog/2008/01/how-to-use-args-and-kwargs-in-python/) I'm not sure if you were purposely avoiding doing this?
There's really no clean way without testing. Even if you have a sequence you still have the question of is it a dictionary or a list. A slightly better option then testing for type would be (implemented recursively), use hasattr() to see if it has \_\_iter\_\_, then (potentially) test if it has iteritems (a dictionary). Calling itself recursively would accomplish handling nesting. A further question, what's wrong with "print?"
Wow, I'm actually kind of surprised that *t = list(5)* doesn't work... wtf. Edit: this? I basically see if len() works and if not I make it a tuple def print_vals(t): try: s = len(t) catch: t = t, for v in t: print v 
That kinda works, but I'd still like to keep list/iterable support.
Yeah, actually I am.
&gt; you still have the question of is it a dictionary or a list. Well in my case I think it's fair to assume that the parameter will be valid, just that they might be wrapper in an iterator. &gt; A further question, what's wrong with "print?" That was just a simplified example.
Yeah, in that case I could have simply written for v in list(vals): ... 
What should `list(5)` produce?
It's not self explanatory? It should be a constructor that makes a list with what's given. A list of numbers (including a single number) I'm surprised isn't an option that it handles. 
I asked the question, did I not?
I edited it.
We have a really simple function called `tup` that we use all over the place. def tup(item, ret_is_single=False): """Forces casting of item to a tuple (for a list) or generates a single element tuple (for anything else)""" #return true for iterables, except for strings, which is what we want if hasattr(item, '__iter__'): return (item, False) if ret_is_single else item else: return ((item,), True) if ret_is_single else (item,) It used to looked like: iters = (list, tuple, set) def tup(item, ret_is_single=False): """Forces casting of item to a tuple (for a list) or generates a single element tuple (for anything else)""" #return true for iterables, except for strings, which is what we want if isinstance(item, iters): return (item, False) if ret_is_single else item else: return ((item,), True) if ret_is_single else (item,) They do basically the same except that the first works on arbitrary iterables. So you'd use it like def _byID(ids): "Given an ID, returns the item corresponding. Given a list of IDs, returns the list of items corresponding" items, is_single = tup(ids, True) db_items = ... return db_items[0] if is_single else db_items or def sum_(stuff): return reduce(lambda x,y: x+y, tup(stuff), 0)
Thanks, something like that really should be built-in IMHO.
How hard would it be to integrate all this into IDLE? 
What's the purpose of returning a boolean in the tuple if ret\_is\_single is True? 
def print_vals(vals): if not hasattr(vals, '__iter__') or isinstance(vals, basestring): vals = (vals,) for v in vals: print v Realistically, that should be varargs also rather than relying on typing like this. Might want to look at [iflatten_instance](http://www.pkgcore.org/trac/pkgcore/browser/ferringb/snakeoil-dev/snakeoil/lists.py) in snakeoil also for a generic flattening form of what I'm using here.
Look at the `_byID` example above. It's so we can say &gt;&gt;&gt; Link._byID(5) &lt;Link 5&gt; &gt;&gt;&gt; Link._byID([1,2,3]) [&lt;Link 1&gt;,&lt;Link 2&gt;,&lt;Link 3&gt;] That is, if they gave us a list, we'll return a list. Although in practise I think `_byID` is the only function that uses it
You want to print each element from an iterable? def flatten(element, ignore_str = True): # # Standard flattening idiom, generally used to flatten nests # Done this way so the flattener could be reused (it's useful). # # ignore_str used for skipping the flattening of strings # (eg, "abcd" -&gt; "a", "b", "c", "d") # if ignore_str and type(element) is str: yield element elif hasattr(element, "__iter__"): for sub in flatten(element): yield sub else: yield element def print_vals(print_me): for flat in flatten(print_me): print(flat) _____ Edit: Separated ignore_str stanza for clarity.
&gt; I basically see if len() works and if not I make it a tuple `len()` won't work with every iterator BTW, but something like that is what I'll probably have to do. I just was hoping there was a more elegant solution.
Didn't know this had a name, thanks!
Also, Unicode isn't UTF-8. Unicode objects in Python are sequences of _glyphs_ from the Unicode _character set_. Byte strings are sequences of _encoded_ glyphs, i.e. representations of those glyphs in a particular encoding. So you may have "Unicode" in your byte strings, and you may have a `unicode` object that can be represented in plain 7bit ASCII. Now, what most newbies will think of as "Unicode" are string literals with a `u`-prefix (i.e. `unicode` object _literals_). These are byte sequences (as is any text file) that will be decoded by Python and converted into `unicode` objects. What character encoding will be used to decode these bytes depends on the declared encoding of the source file itself. That's why you should always place a `coding` comment at the beginning of your Python source files. It's really simple if you understand the distinction between the glyphs (i.e. the character set) and the byte sequences representing those glyphs (i.e. the encoding). This should be part of any good introduction to IT, but it's amazing how many people don't understand this. Maybe it'd be clearer if you think of number systems (decimal, binary, hexadecimal, octal, etc, but also Roman, Japanese, ...): one number (glyph) can be represented in several systems (encodings); in order to read the number, you must "decode" its representation; in order to write it down, you must "encode" it into one of its representations.
Can you explain why?
I think your motivation is suspect: Why do you use this a lot?
Because then I'd have to unpack lists before passing them, which is just a variation on my original problem.
It still has list support: print_vals(*[1, 2, 3])
Can you give an example of what you mean? You know that Python will auto-unpack for you, right? E.g. (using the example above): &gt;&gt;&gt; def print_vals(*vals): ... for v in vals: ... print v, ... print ... &gt;&gt;&gt; l = [1, 2, 3, 4] &gt;&gt;&gt; print_vals(l) [1, 2, 3, 4] &gt;&gt;&gt; print_vals(*l) 1 2 3 4 In other words, you can use the **\*** (and, actually, the **\*\*** as well) to tell Python to auto-unpack for you. The trick here is that you need to be sure the arg is a sequence before passing it this way.
`iter()` should be a more general solution. try: iter(x) catch TypeError: x = [x]
Yeah but I'll have to determine when to unpack the argument. The argument is not necessarily under my control.
The problem is that I'm given an argument that may or may not be an iterator. If I used this approach then I'd still have to determine at some point whether or not to unpack it.
You're asking the right question. If you can't tell if you're going to be passed a list or an item, something is wrong. This is why they no longer like % formatting in Python 3: it behaved differently when passed a tuple vs. anything else. 
#1 use isinstance instead of comparing types #2 strings doesn't have \_\_iter\_\_(in python &lt; 3.x) ;) #3 use dosctrings instead of comments:)
holy fuck str doesn't have \_\_iter\_\_. How does it iterate with a for loop?
&gt; Right now Nuitka is a good replacement for the Python interpreter and compiles every construct that CPython 2.6 offers (work on CPython 2.7 is ongoing). It translates the Python into a C++ program that then uses libpython to execute in the same way that Python did, in a very compatible way. i am not sure if it's much clearer than before... a picture to help us understand perhaps?
for loop calling \_\_getitem\_\_ method of string, btw in python 3 strings have \_\_iter\_\_ method
If you want a shorter flatten function you could use this. def flatten(elements, containers=(list, tuple)): if isinstance(elements, containers): if len(elements) &lt; 1: return [ ] return reduce(lambda x, y: x + y, map(flatten, elements)) return [elements] Just a note, if you are using Python 3, make sure to use `from functools import reduce` before defining the function :)
def func_x(args): for arg in list(args): print arg
Besides, lists _are_ items. Perhaps someone passes in "whee" expecting it to be treated like a single item, but the function sees it as four. Or the other way around.
hov about using a simple generator: def iter_over(data): try: for i in data: yield i except TypeError: yield [data] def print(vals): for v in (iter_over(vals)): print v 
This is the bitch in the room when it comes to a variable number of arguments and polymorphic programming. If it walks like a duck and talks like a duck it's probably an alligator. I would agree in cases like this being explicitly explicit becomes top priority.
Has anybody tried this out with PyPy?
Wow! I love that there is a link in the first paragraph that explains the project. Don't know how often I see something posted on reddit and don't have a fucking clue what this is. 
example inputs/outputs?
don't listen to them.
This is how I would do it. def print_vals(vals): if hasattr(vals, '__iter__'): for v in vals: print v else: print vals 
What happens if your editor is using utf-8 but you specify a different coding in the source file?
That's not quite right alan. The term 'glyph' should only be used in reference to the visual representation of the characters ( i.e. when you're dealing with fonts ). The difference I think you're reaching for is the one between 'abstract character' and 'encoded character'. http://unicode.org/reports/tr17/#CharactersVsGlyphs
 &gt;&gt;&gt; hasattr('abc', '__iter__') False Strings are iterable but don't have '__iter__' If you check the Python discussion groups you would find a lot of discussions about this.
I don't know the python internals well enough to use them as an example, but I've done something similar for a Scheme dialect I work on. A simple example would be: (+ 1 2 3 4 5) '+ is backed by the function fplus, so in the interpreter, when it's executing +, it first processes the arguments to plus and then calls fplus on the resulting list. When I wrote the Scheme-&gt;C compiler, I did something similar: loop over the arguments, generate code, and add that code to the arguments of fplus. So: // list(int n, ...); Returns SExp-list // makeinteger(int n); returns a Int wrapped in a SExp // (+ 1 2 3 4 5) fplus(list(5,makeinter(1),makeinteger(2),makeinteger(3),makeinteger(4), makeinteger(5)),env); This is very similar to the code that *would* have been executed by the interpreter itself, but instead it is being compiled AoT (and the creation of the list arg to fplus would have been in a separate step). Now, this isn't necessarily faster, since you're just calling the same API as would have been called (I added optimizations like self-tail calls to direct while loops &amp; non-self tail calls to jumps, &amp; other fun), but it can be. I used *this* compiler to bootstrap a better one (which did some amount of unboxing &amp; other things). Does that make it clearer? 
*nod*
man I hate recursive calls
Your question is fundamentally broken. Pick one: * Your object you're passing should support a \_\_str\_\_() to render itself. * Always know what you're passing and receiving, or you're a bad programmer. print\_vals(10) should always be print\_vals([10]), perhaps. You shouldn't check to see if something is a list or tuple or whatever. There are any number of types/classes that are neither, yet behave like them. &gt; print\_vals("strings are iterable") &gt; print\_vals({"in dicts":"you'd never see the values"}) Finally, **you should be using pprint module**.
I wrote some Python ages ago that concatenated several Powerpoint/Word/Excel files together into one pdf for printing out, by automating OpenOffice. Not sure if I'd necessarily recommend it, though... but here's a page about python+openoffice: http://wiki.services.openoffice.org/wiki/PyUNO_bridge (UNO is OpenOffice's automation interface)
For one I occasionally write a function that I'd like to work with both a single number and a list (or NumPy array) of numbers. 
&gt; Always know what you're passing and receiving Doesn't that defeat the purpose of using Python? It doesn't sound crazy to me to imagine a function that works for both a single item or a bunch of them. &gt; There are any number of types/classes that are neither, yet behave like them. I'm assuming that the list of items will all be of the correct type. Laziness in terms of type checking is encouraged in Python, so someone passing a dictionary or something is not a worry. &gt; Finally, you should be using pprint module. That was, of course, a highly simplified example. And I don't think I've *ever* seen anyone use the `pprint` module. 
Someone suggested that. `list(5)`, for example, won't work.
I'm looking for something similar, too. Haha, can't believe I opened up /r/Python and this was the first topic. Could you update me if you find anything? Thanks.
If you want to go the COM route, then I'd suggest looking for VBA documentation, and translating that over (it's not too hard). You can also automate OpenOffice, and then handle the files after converting them to OO format. This has the advantage of being cross platform, but if lack of documentation throws you off, I'd recommend steering clear of pyuno (unfortunately!).
I'm not sure if you'll able to use this, depending on if you're opening new format openXML docs or old style, but: [openxmllib](http://pypi.python.org/pypi/openxmllib/1.0.6) requires lxml. 
Both os.remove, or os.unlink handle those files just fine. If you have a whole directory of these, shutil.rmtree is even better.
I don't think there is anything better than that. It used to cover almost everything. Have you seen the [book](http://www.amazon.com/Python-Programming-WIN32-Windows-Programmers/dp/1565926218/ref=sr_1_1?ie=UTF8&amp;s=books&amp;qid=1286130789&amp;sr=8-1)? 
Few examples how-to use COM: http://www.blog.pythonlibrary.org/2010/07/16/python-and-microsoft-office-using-pywin32/ Native Excel file handling (not what was asked, but might help someone): http://www.python-excel.org/ 
Win32COM is really just a wrapper around COM. If you don't understand COM then no wonder you find the documentation appalling! Here's my suggestion: Use the Office macro recorder to record the actions you want to do to the office application. That'll tell you the commands and so on that you need to call to do what you're trying to do. Now you'll need to "map" it to Python but that is considerably easier if you follow a few simple tutorials.
I recently wrote some code in python related to ppts. PM me with the problem you are trying to solve, and I will try to help.
[Python bindings for tika](http://redmine.djity.net/projects/pythontika/wiki/Wiki?version=5).
Any good non-MS Office software for handling MS Office files? No, not really...
Check [this](http://www.python-excel.org/) for Microsoft Excel format.
http://wiki.services.openoffice.org/wiki/Python
This is always a good idea to do first, and when you have the names of a few API calls you need, it even becomes doable to find what you need in the labyrinthine documentation on MSDN (if you let the google do it for you). Edit: PowerPoint docs are here, I think the Presentation is the most important object -- [msdn](http://msdn.microsoft.com/en-us/library/bb265987\(v=office.12\).aspx)
I've been a C# programmer for about 8 years and its certainly advanced in that time but even the latest additions such as linq seem verbose and clunky compared to Python. There's also the fact that in C# _everything_ must be in a class and is statically typed which means you type a lot of "boilerplate" code just to get the same result. To me when you get more by doing less you have a more powerful language. See one of my posts "Travelling salesman part 1". You could easily do this in C# as well but not as succinctly. Brevity in code helps a lot in a long term project with a large team where your often looking at someone else's code.
Unfortunately, the pprint module isn't extensible.
What is this?
Are there other plugin architectures for Python that this can be compared to?
I will if I find anything.
But this doesn't work for pptx, or does it?
[Apache Tika is a toolkit for detecting and extracting metadata and structured text content from various documents using existing parser libraries.](http://tika.apache.org/) It supports data extraction from pretty much any file format out there and it abstracts the retrieval process. Its a java library and that link should help you use it with python. If you are looking to modify/create ppt files, this is probably not what you are looking for.
There is a lesser known google docs api, which you can use to do just about anything in the realm of document conversion. [link to conversion formats](http://code.google.com/apis/documents/docs/3.0/reference.html#ExportParameters) While I haven't used it yet, it looks recommendation worthy.
Cool resource, though. Thanks.
The only question you need ask yourself when you're starting out a project is: Can this library do what I need it to do (within the forceable future)? There's no point in analyzing the situation more than this. If it turns out you need something more you'll only know after you've started developing. If that's ends up being the case, there are a number of options open to you, but I wouldn't even begin to worry about that at this point. Relying on "third-party libraries" is very normal. So normal that if one talks about a library, it is generally assumed that is not party of the standard library. It is rare for a language to include multimedia components in their standard library, but I can understand how, coming from Processing, this might seem a little odd. At this point in the game, rest assured that as long as you choose something that gets you up and running, you have made the right choice.
what do you want to do with the ppt files ? I have Python make Excel VBA calls to do things (on xls) and also Outlook VBA
Actually, it probably is. I'm not creating pptx files, I only want to extract the text. I want to parse the text into HTML5 slides. Also, it doesn't have to be in Python, I'm also good with Java. Given this information, what do you recommend?
You don't need to limit yourself to python modules. Find any library that does what you need to do: open the mic, set some parameters, record the data, close the device. Then you can wrap it yourself with ctypes. It's remarkably easy to do for most things, I wrapped libnetsnmp to do what I needed in an afternoon starting from almost no knowledge of ctypes.
if you know java, you should most definitely do it in java. [This article](http://rash0208.wordpress.com/2010/05/20/apache-tika-power-to-parse-almost-everything/) will help.
Okay, I mean that's pretty obvious. But why is that? If I may venture your modus operandi, may I suggest that you are really trying to work with lists, but that you are being lazy, and putting in scalars without the surrounding "[]", when that's what you really mean. Remember that being lazy while writing ends up just complicating things; you might think you are being efficient, but you are really just making your life harder.
I'm also interfacing with different functions that return lists or single items. 
Given the liberal license PIL uses, I don't see why one would not use PIL for this?
Maybe OP can't install PIL? Install it to somewhere else on your path then.
Yeah, if OP is having trouble installing he should probably spend the time to get it working. PIL is by far the best alternative for resizing in a pythonic way.
If you are ok with GPL-ing up your app, then use FMOD. 
ImageMagick on the command line is one option.
Yes, I use this for reading and writing to excel. It works well
How about for openoffice ODF files (mostly calc)? 
the number stored will be a float(a number with a decimal), rather than an int. 640/15 = 42 640./15 = 42.666666666666664 without the "." , the result of the division is truncated. 
I don't have the experience with pyaudio to say one way or the other but just wanted to ask that follow up here after you've learned more. 
The period makes it a floating-point number. So writing "640." is equivalent to "640.0". The period allows for natural division with python: if you are dividing two integers, the result is simply an integer (and fractional remainder is truncated). So 4/3 returns 1. Simply having one of the two numbers as a floating point number, you avoid the problem of integer division: Hence: 4./3 or 4/3. or 4./3. all evaluate to 1.3333...
Even though the zero is not implied?
Great this answers it completely. I always saw the notation 640.0 for floating point. But never one that only typed the period. Thanks!! 
Note that this is a little different in Py3k, where integers use natural division now, and if you want truncating behavior, you use the // operator. In 2.6 (I think) and up, you can also do from __future__ import division to change the behavior to natural division.
... it's not pregnant?
True division via `__future__` goes back to 2.2. See [PEP 238](http://www.python.org/dev/peps/pep-0238/) for more info.
Well the period implies the zero instead of you explicitly stating it.
pyopenal should be worth looking into. openal should be pretty solid library.
`1.0 == 1. and 0.1 == .1` However, it's an obscure language quirk that will confuse some people (as you can see), so I would try not to perpetuate this style.
Figures. I started using Python around when 2.6 was new, so it's the earliest version I'm familiar with.
Great! that's a lot more info that I expected. I think I learned more asking this than all day long reading said book.
That explains a lot of things.
Yeah. I lost close to an hour searching for this in the docs and about everywhere. I even risked stackoverflow with the dangers of humilliation it implied. Haven't received an answer there yet anyways.
I wouldn't call it a failure, however - didn't they manage a 3-4x speed improvement?
In short, no. There are no good cross-platform audio packages for python.
It's pretty common and accepted in math notation though. Redundant zeros begone!
The language you learn is of little importance. Learn the concepts, and apply them. 
If you have one function that could return either, that function is malformed. 
The book [How to Design Programs](http://www.htdp.org/). It's in Scheme, but the concepts are there. Also (though some people will shoot this down) school. The CS program I'm in has taught me a hell of a lot.
This is one of the reasons why I don't like Python 3. Every other language including Python 2 treats Integer / Integer = Integer, so why does Python 3 feel the need to change this? It's not really that big of a deal, but it's still kind of WTF to me.
Oh, yeah, sorry. I forgot what the right term for the abstract character was (I guess there isn't any, short of "abstract character"). The rest of my explanation still holds true, though.
Same thing that always happens if you specify incorrect encodings, no matter the file type or method (e.g. serving files on the web, XML processing instructions): the bytes are interpreted according to the wrong encoding, thus resulting in garbage. In the case of UTF-8 interpreted as an 8bit "ANSI" (i.e. Windows code page or ISO-8859 family) encoding you will probably see the usual garbage: ASCII with funny characters wherever you used bytes &gt;= 0x80 (aka the "I am an idiot and don't know how to handle character encodings properly" tell-tale sign of bad programmers).
It prevents things like adding a period to the end of a number, as the OP is asking about. The ratio of number of times I've had two ints and wanted a float versus a chopped-off integer when I divide is quite high.
This I feared. I'm even considering trying Jython. I may be able to call Processing libraries, given that it's Java... Or I guess I can stick to Python and create an interface for the microphone (open mic, get data, close mic...), which would call one library or the other depending on the platform...
You're changing the current working directory (cwd; pwd means 'print working directory') of your python script, not of your shell process. You can see what your current working directory is for your script by calling os.getcwd().
Sure :)
How can I change cwd of shell process then? Is there an any dedicated command to do so or do I have to go through system call. Thanks.
\&gt;&gt;&gt; 1. 1.0 \&gt;&gt;&gt; 1. == 1.0 True 
Um... It shouldn't be a problem. But FMOD is not free for commercial use, is it? Right now, our project is just in a 'research' stage. But that may change if results are good enough!
I'll have a look, although it looks as reliable as pyaudio :(
There's probably something **very** tricky that I don't know about, but in general: no, and you shouldn't want to. What's the larger problem that you're trying to solve? There's nothing you shouldn't be able to do by changing the working directory of your python script and executing something and this way you maintain portability too.
Every process has a 'current working directory'. Every new process inherits the current working directory of its parent. Therefore, what's happening is: * Your shell is in /home/me * Your shell starts a new Python process * The Python process changes its own directory to /blahblah * The Python process exits. * Your shell is still in /home/me The dedicated command to Change the Directory of a shell process is "cd": $ pwd /home/me $ cd /blahblah $ pwd /blahblah
My main goal was to create simple python script to move my cwd up by using the given argument as a filter, and I was thinking to assign that to alias. So it would work something like this. $ pwd /home/aaa/bbb/ccc $ python up.py aaa $ pwd /home/aaa I never thought this simple task can be this complex. btw, os.system('cd /blahblah') also didn't work for some reason. So I'll just give up. Thanks for your help though!
As stated in PEP 238, it's a problem with dynamic typing. It can be 'solved' with manual coercion. For example: def half_of(x): x = float(x) return x/2 I think streamlining '/' as floating-point division was a simple way to reduce potential bugs caused by someone forgetting to coerce the type to float. If programmers need floor division specifically, they're less likely to forget to use the '//' operator, and even if they do forget, the resulting bug or exception (e.g. trying to use the result as an index) will probably be obvious.
"cd" isn't actually a program. It's a special shell command (at least in unix, I assume the same is true for windows) that tells your shell to call a system function (one that runs in the kernel) and set the process' working directory within the process. Your python program is running in an entirely separate process -- potentially one that has no relation to a shell at all -- and so can't (generally speaking) modify the shell process' working directory. Like I said, there's probably a really tricky low level thing you can do that will change it, but if this is just a quick program to challenge yourself I would say it's not possible.
[Here](http://norvig.com/21-days.html) you go! A perfect plan.
Thanks!
When I started programming I only knew Python and Common Lisp. I would write programs that used lots of high level language features but had no regard for optimization or performance, since I didn't understand a lot about algorithmic complexity or the underlying hardware. So an exercise I did that really helped was to write a program (in my case it was a machine learning system using genetic algorithms and neural networks, lots of algorithms and math) starting in Python, and then work my way down to low level, Java, then C++, then C. I never bothered going as far down as Assembler. Once I had implemented it in all those languages and learned about stacks and memory allocation, I went back and rewrote my Python version, except now it was alot shorter and more succinct, and thus ran a lot faster. The thing is, you'll never know everything about programming just by knowing one language, the trick is to learn how to do the same things in a lot of languages and start to get a sense of the best way to do things in any language (hint: the shortest answer is often the best one). And then once you get to that point you can go back to comfortably programming in a cushy high level language like Python and enjoy all of the dynamic syntax constructs and behaviours it offers, while bearing in mind the low level constraints which are necessary to produce high performance code.
Thanks. I didn't even know about those process running separately.
Following from this, the only way for a script to change the working directory of the shell is the script is interpreted by that shell, rather than executed by a subprocess. For example if you have a script test.sh: #! /bin/sh cd /tmp pwd The following will run it as a subprocess. [~] ➔ ./test.sh /tmp [~] ➔ Here it will be executed by the shell. [~] ➔ . test.sh /tmp [/tmp] ➔ 
Pythons don't get periods...those are unique to placental mammals.
Changing another processes cwd at runtime is something that intrigued me after reading this post, so I thought I'd share what I found after a really quick look around. Firstly, you can find the current working directory of a process under Linux by examining the /proc filesystem. For example, /proc/[pid]/cwd is a symlink to whatever the cwd is for that process. To find the parent PID from inside a script you can use $ENV['PPID'] or the equivalent and then use this in the proc path. Unfortunately it seems that you cant change the symlink even by force (ln -sf), and even as root. But it may be a good starting point for someone else none the less.
If you intend to use the program as an alias, then you might be able simply replace the os.chdir call with a print("cd " + yournewdir), and then set your alias to be along the lines of alias up="\`python up.py $1\`", which you could then use as "up aaa" To clarify: the use of backticks will basically tell the shell to run the script and replace it with the output (which will now be "cd yournewdir") in the alias, meaning the shell should actually change directory properly :)
[My offer over at /r/mentors](http://www.reddit.com/r/mentors/comments/czwc4/offer_i_will_teach_you_python_beginner_or/). PM me if you are interested.
It's quite tricky but this does a job that I initially intended. Thanks for the input!
Thanks for such an effort. This method should have worked brilliantly if they allowed us to overwrite files under proc.
win32com isn't tricky when you realise that the docs for it are just standard docs about COM. Find docs on manipulating your PPTs using VB or any other COM language. There will be stacks of info on this. All the win32com docs need to tell you is how the Python wrappers work and this is the simple bit. And you can do it all from the Python command line and learn as you go. The REPL is your friend. Here's an example using COM to automate Photoshop. Powerpoint will work almost exactly the same way: import win32com app = win32com.client.gencache.EnsureDispatch("Photoshop.Application") app.Documents.Add(40, 40, 72.0, "My New Document") app.activeDocument.activelayer.Invert 
That's awesome!
An hour? &gt;&gt;&gt; x = 640. &gt;&gt;&gt; print(x) 640.0 &gt;&gt;&gt; print(x.__class__) &lt;class 'float'&gt; &gt;&gt;&gt; type(x) &lt;class 'float'&gt; &gt;&gt;&gt; dir(x) Python has all sorts of useful introspection commands... 
You can see several links in the yapsy home page: http://yapsy.sf.net
This. Mastering a language is just syntax. It's all about the underlying concepts. Learning python is a good idea, though, because of its compact and clear syntax (less painful than Java, less cryptic than advanced C++), plethora of libs and scripting capabilities. However, there are a few concepts that python won't teach you. The two fields that come to mind are functional programming (closures, macros, immutability, recursion... see lisp or clojure) and concurrency (python isn't the king of concurrency, see erlang e.g). Back to python, I'd say there's no timeline, really. Once you've hacked your way through any of the python books and got familiar with its basic syntax, you should find a toy project and actually start using the language. Practice is as important as theory and the best method I know of is the balanced approach: learn while coding. To become a great developper, though, you'll certainly need to read general CS books. Python is a fancy tool, but it isn't any smarter than the guy behind the keyboard. A good starting point if you're really serious could be the [MIT's Introduction to Algorithms](http://www.amazon.com/Introduction-Algorithms-Third-Thomas-Cormen/dp/0262033844/ref=sr_1_1?ie=UTF8&amp;qid=1286187125&amp;sr=8-1) Happy learning!
Can't say, haven't used Swish-E but xapian has been doing very well for us.
&gt; Every other language including Python 2 treats Integer / Integer = Integer, Really? &gt; ghci GHCi, version 6.12.3: http://www.haskell.org/ghc/ :? for help Prelude&gt; 3/2 1.5 mmm &gt; erl Erlang R14A (erts-5.8) [source] [64-bit] [smp:4:4] [rq:4] [async-threads:0] [hipe] [kernel-poll:false] Eshell V5.8 (abort with ^G) 1&gt; 3/2. 1.5 mmmm &gt; so why does Python 3 feel the need to change this? because integer division is non-obvious and generally useless. It's much better as non-default division (coupled with `%` to get the remainder) with *actual* division as the default operation.
You are right. I thought it is free if you are GPL, even for commercial.
So if your app is commercial... why not use it and simply pay for the quality then? 
When I started using Python 2, the 2/3=0 thing really bugged me. Now that I'm accustomed to it, I find the Python3 2/3=0.6667 thing to be really annoying. But overall, I think Python 3 is neater. Very simple just to use // when you want to return an integer.
Yes but also: \&gt;\&gt;\&gt; 1 == 1. True \&gt;\&gt;\&gt; type(1) &lt;type 'int'&gt; \&gt;\&gt;\&gt; type(1.) &lt;type 'float'&gt;
The current working directory is just a local setting in the program. It's a variable. Outside your program, the variable means nothing because it went away when the program exited. If in one program, like your shell, you want to change something then you have to change the variable in that program. Use the shell command "cd" to do that. Note, "cd" is not a program. It's not in your path. It's not on the filesystem. It's a special string inside the shell only that changes the pwd variable. And be careful with the words "system call". That means executing a function that the kernel implements, like "open()" or "write()" You're mixing up shell functions, userspace/library functions, and system calls. Once you understand the differences and what is which, you'll be much more successful.
No, it's not commercial, yet. It may be commercial in the future. Right now it's a research project in the University. If things go well (that is, if the whole thing serves its purpose) we may consider selling it. Or even giving it for free. The less license compromises, the better. That way we are free to do whatever we want.
&gt; The less license compromises, the better. That way we are free to do whatever we want. Sure, but unless you're going to write your own audio module then you don't seem to have many choices, don't be closed minded to closed source just because internet nerds say OS is the greatest and all that other crap (not to mention if you choose something GPL then you *can't* sell it commercially). Anyway, your best bet is probably to keep that part separate from the main program and encapsulate it's functionality through an object you write. That way you could theoretically swap it out for something more free or something you write yourself down the road. 
That's my plan, right now: encapsulation. I'll look for a nice library for windows, a nice one for linux, and keep my code separated from them. Unfortunately, the maturity of cross-platform audio libraries for Python is not what I expected. And that's why Processing is still sooo atractive for this project! :(
As much as I love Python, the task you're trying to accomplish might be a bit better suited for a bash script. Unless this is a self-imposed-python-only project (i.e. forcing yourself to improve python skill)
You'll need another library to help with the analysis - pyaudio will do the sampling part. Probably you would write the analysis with numpy. Hubert seems to answer questions with pyaudio, if you find something better then post results to python reddit :)
The only way I managed to do this in windows was to run a have a batch file that runs the python program. The python program outputs the new directory to a file which the batch file then reads and changes directory.
No problem at all. That's precisely the prototype I tested with Processing, and I don't need complex computations to achieve what I need. If I'm able to read microphone values, I will be able to replicate the algorithm.
I can't agree with generally useless. The C-derived languages all do integer division and I always found that it felt more natural, especially when writing algorithms such as divide-and-conquers. `size / 2` and `size / 2 + 1` always worked whether the size was 0, 1, or n.
&gt; The C-derived languages all do integer division and I always found that it felt more natural, especially when writing algorithms such as divide-and-conquers. So when implementing a specific kind of algorithm where you know you need integer division anyway, it works better. That's specifically useful, but still generally useless. When I want to divide a and b, the general case is a float (or better decimal) division. Whatever a and b may be. That's doubly annoying in dynamically typed languages, which Python is. &gt; size / 2 and size / 2 + 1 always worked whether the size was 0, 1, or n. `size // 2` and `size // 2 + 1`. There. It's not like Python 3 removes integer division, it just makes it non-default with *true* division (the generally useful one) being the default instead of having to jump through hoops of conversions to floats to ensure you have the right types to magically trigger non-integer conversion.
Some people spend most of their day writing algorithms and doing bit twiddling. For them, integer division is the cats ear, and they'd never want to suddnely pollute their computations with floats. Others most do webb apps or other user facing code, and to them, it seems silly to ever want integer division.
Mine isn't. Depends on what type of code you're writing.
The C-derived languages are mostly statically typed, and don't really have a choice about how to handle integer division.
Personally, I think this is a really bad idea because of the painful edge cases w.r.t. using period as the member operator. You can treat a string or floating point literal like any other object, and access members directly, but trying to do so with an int literal without enclosing it in parenthesis leads to a syntax error: &gt;&gt;&gt; "".islower() False &gt;&gt;&gt; 3.3.__neg__() -3.2999999999999998 &gt;&gt;&gt; 3.__neg__() File "&lt;stdin&gt;", line 1 3.__neg__() ^ SyntaxError: invalid syntax &gt;&gt;&gt; (3).__neg__() -3 
Dude, "internet nerd" is my trademark and you just can't go and use it on the internet as you please. It doesn't look like you have bought a license from me either. So please retract your work of infringement on my intellectual property rights or face legal consequences. Thanks in advance.
"Foreseeable," not "forceable;" "part of," not "party of;" "that ends up," not "that's ends up." FTFY
Clever, but somewhat of a strawman. 
&gt; Some people spend most of their day writing algorithms and doing bit twiddling. Operative word: *some*. Further: once again, Python 3 doesn't remove integer division for fuck's sake, it just moves it to non-main division. The vast majority of *Python* users are not spending their day "writing algorithms and doing bit twiddling". And even if they were, integer division is still a stupid default for the division operator.
That's simply not true. Or are you arguing that Haskell is somehow a dynamically typed language? Static typing has absolutely no relation with a division's types.
How often *in Python* do you need to call a method on an integer *literal*?
I wasn't aware of this. Should've searched elsewhere in the docs. Rather than looking directly at syntax. This is also a great tip!
Nope. Not even close.
It is documented.... http://docs.python.org/library/__future__.html `__future__` is a real module, and serves three purposes: * To avoid confusing existing tools that analyze import statements and expect to find the modules they’re importing. * To ensure that future statements run under releases prior to 2.1 at least yield runtime exceptions (the import of `__future__` will fail, because there was no module of that name prior to 2.1). * To document when incompatible changes were introduced, and when they will be — or were — made mandatory. This is a form of executable documentation, and can be inspected programmatically via importing `__future__` and examining its contents. http://www.python.org/dev/peps/pep-0236/ From time to time, Python makes an incompatible change to the advertised semantics of core language constructs, or changes their accidental (implementation-dependent) behavior in some way. While this is never done capriciously, and is always done with the aim of improving the language over the long term, over the short term it's contentious and disrupting. Edit: formatting
Meaning someone here hasn't read the zen of Python. And that's a very stupid thing to do as a Python programmer.
Careful with using == to demonstrate what you mean here, since in python 1 == 1.0 Better (perhaps?) to say `1.0 is 1.`
That's what makes it so funny.
Yep. If you're going to pass in incompatible types of data to a function, you're going to have to test it. It even happens in C++, it's just that the compiler does it for you.
Hrm... I checked on two laptops I had lying around, which are rather old, but both of them had motherboard speakers. Did you actually see that yours in fact doesn't? That'd be strange... Can you do me a favor, what do you get if you just run: import winsound winsound.Beep(440, 300) Anything? You should be getting either a beep or a RuntimeError as per the docs.
Yeah, seems like pretty bad form to not include the 0's in those examples.
Came in here to post that.
`1 == 1.` is not equivalent to `isinstance(1., int)`. Since the double equals comparison method is a "magic method" of a class (the `__eq__` method), objects can be compared even if they are not the same class if their equality comparison methods are compatible (which I'll define to mean they don't raise some sort of un-checked AttributeError).
Comment - Upvoted Post - Downvoted (RTFM)
I'll admit, I came in expecting a joke and learned something instead.
&gt; which I'll define to mean they don't raise some sort of un-checked AttributeError Or type error.
Yup. And now there's an easy way to do both. I don't see why it would be any more upsetting that integer division is done via `//` than it is to use `==` to test for equality, which nobody complains about. 
Any good tutorials for this sort of thing?
Don't put too much weight on the Zen. Would you really prefer python programmers type if bool(foo) is True: pass instead of: if foo: pass Sometimes implicit is the bee's knees.
I think the `is` behavior is an implementation quirk that shouldn't be relied on. In theory you could have two different `1` objects. I believe Python keeps a pool of integer objects below a certain number (like 255) pre-instantiated for a performance boost on commonly used numbers. But higher numbers don't have that behavior: &gt;&gt;&gt; 12345678 is int('12345678') False &gt;&gt;&gt; 1 is int('1') True The `==` is also imperfect as you show, but I was mainly trying to be illustrative, so I figured it's okay. edit: I just tested, and the range of pre-instantiated integers is -5 through +256.
All of the [Pythons](http://docs.python.org/faq/general.html#why-is-it-called-python) are placental mammals, but they are also all male, so they don't get periods anyway. 
&gt; How to Find and List All Running Processes with Python **In Windows** 
I haven't worked with ctypes or Cython, but I've mostly heard the latter recommended instead of the former.
welcome to /r/StackOverflow
Very well stated. With dynamic typing, it's hard to know whether "x" is an int or not, which means defaulting to true division gets more consistent results.
Excellent point. I see similar mistakes with people comparing strings using "is". Works great... until you throw a unicode string into the mix.
while at it, use "IPython" if it's available for your environment. Then use the tab key to find nirvana and "?" appended to functions to populate it with self.OBJECTS\_OF\_SEXUAL\_INTEREST
The point may have been that C-derived languages will implicitly coerce on assignment. For example, one can assign double z = x / y, where x and y are both int, or int z = x / y, where x and y are both double. Since Python variables reference objects that can have any type, and since numeric input can often come as either an int or a float (e.g. the input parameter in sqrt(2) vs sqrt(2.0)), one can't really know ahead of time without manual coercion such as x = float(x), or using 1.0*x. Thus the Python team opted to split "classic" division into "true" and "floor" division. Python's floor division is about the operation, not the types. The result will have the same type as floor(x / y). For example, if x and y both reference floats, then x // y will also be a float. To get the equivalent of C's int z = x / y, where x and y are floats, Python would need to manually specify the coercion, such as z = int(x // y). That's important if, for example, z is going to index a list.
&gt; The point may have been that C-derived languages will implicitly coerce on assignment. For example, one can assign double z = x / y, where x and y are both int, or int z = x / y, where x and y are both double. That would hardly make sense. The behavior is identical to Python's: `double z = 3 / 2` will result in `z = 1.0`. And `int z = 3.0 / 2.0` is equivalent to `z = int(3./2.)` and results in `z = 1`. &gt; one can't really know ahead of time without manual coercion such as x = float(x), or using 1.0*x One can always use `isinstance`, that's not really the point. The point is that statically typed languages are perfectly free to implement true division for division between integers, there is nothing stopping them from doing so, and that's in fact [exactly what Haskell does](http://haskell.org/ghc/docs/6.12.1/html/libraries/base-4.2.0.0/Prelude.html#v:/) &gt; To get the equivalent of C's int z = x / y, where x and y are floats, Python would need to manually specify the coercion, such as z = int(x // y). Actually you could just as well use `z = int(x / y)`, which is basically what you write in C. 
from __future__ import jetpacks
This is the solution I use too. Came here to see if there was a more elegant way.
&gt; double z = 3 / 2 will result in z = 1.0 3 /2 results in 1.5 in Python 3, while in C it will result in 1.0 if assigned to double z. Anyway, the point is more about function parameters where a function can get called with, for example, 2 vs 2.0. In a C-derived language the parameters will get automatically coerced to the specified type. There's no surprise. I said this could be done manually in Python, but it's a potential bug if the programmer forgets to do it, while in C it's not possible to forget to specify type. I never said that statically typed languages can't implement true division for integers. I just don't see the point of doing that. If I know the type of my inputs there's nothing to cause potential confusion, bugs, and errors unless I'm just being sloppy. You're right that I could have just written z = int(x / y). But the input could be coming from somewhere else that did the operation x // y; the more important point was that the programmer has to remember to force the type to int. For example, if you're calling some_function(int z) in C, you could just write someFunction(x / y) and the system would automatically coerce the result of the division to int. This is a potential type error in Python; however if someFunction tries to use z to index a list, the error will be caught right away in testing. Thus I think the designers made the right call in using "true" division as the default case in Python 3. On the other hand, with static typing I still prefer integers to use integer division. It's more sensible to me for division among integers to be closed over the integers. I can always force a non-integer result if I need it.
Any error, really, as you probably just want a == statement to return False instead of raising an Exception. I just figured that an AttributeError would be the most likely because you might want to compare two class instantiations based on attributed objects that they contain. e.g. def __eq__(self, other): return (self.datum1 == other.datum1 and self.datum2 == other.datum2) That's not a great `__eq__` method because `other` might not have one or either `datum1` or `datum2` attributes. Comparing items of the same type is not strictly required for these equality methods, and since Python has duck typing, it would be impossible to enforce.
Carefully log all the time you spend on learning Python. If you haven't mastered it by 147.84 hours, just give it up, it ain't happening. Consider a career in fashion merchandising.
I've recently got into Processing and I wish there was something like that when I was young.
As a matter of taste, I especially dislike dropped 0s for lists of numbers such as x = [1., .5, 6.2, 3., 5.4]. I'd much rather see x = [1.0, 0.5, 6.2, 3.0, 5.4].
To be clear though this isn't allowed in Ruby because of some ambiguity since . is available for both floating point numbers and attributes (eg 1.__class__ vs (1.).__class__) Imagine 1.f; in C that is the same as 1.0f, but in ruby it is the property f of 1. Not really completely relevant here but probably interesting to people reading this thread
It is completely unnecessary to put the period in math since you have to define the variables to be Real or Rational or Integer anyway
That's precisely something I had to ask in the Processing forums: is Processing suitable for mid-sized applications? You may even combine it with Eclipse! And not only it compiles into Java: you may as well ask for the whole Java code! I just got one answer: "There is no definitive answer to this question... Most applications made with Processing are quite small, often with only one file.", which went on pointing me in the Eclipse direction. I guess I could stick to Processing, but I just wanted to start a big Python project. The thing is, this may not be the right one! :(
Yes and yes. Even more: Processing allows you to create a binary for Windows, Linux and Mac, or publish the whole thing as an Applet (signing it if required). I guess it's not exactly a binary, but something that runs on the JVM. I know it works because I've tried it before (even creating a 'binary' for Windows from Linux) I could go on and do everything in Processing... The 'problem' with Processing is that it seems designed for demos, exhibitions and small things like that, with no more than a few classes. There are, however, pretty good libraries for many things! Even for creating GUIs. And you can even use Eclipse to create Processing sketches. Mmm... Now that I mention all this, it seems that Processing has grown to something much bigger that it once was!
There are soooo many things I wish there were when I was young... and I'm only 32!!
&gt; I just don't see the point of doing that. That it's what division means? &gt; It's more sensible to me for division among integers to be closed over the integers. I can always force a non-integer result if I need it. And likewise the other way around.
Tip: If you want an easy way to know when something was added to `__future__`, just [look in the file](http://svn.python.org/view/python/branches/py3k/Lib/__future__.py?view=markup). Example: `division` was added in 2.2, and became the standard in 3.0. It's quicker than digging up a PEP or reading the svn log.
Atleast read to the bottom: &gt;The package’s name is psutil and it was what I decided to use. Here’s what I ended up with: import os import psutil import time Not windows only afaict
Structure and Interpretation of Computer Programs (http://mitpress.mit.edu/sicp/) also deserves a mention for generic CS books that are free and very useful.
I ran the code, still no sound. I haven't opened my laptop to check if it has one but I've never heard it generate a noise that sounded like a motherboard speaker. All beeps are done through software.
Being aware of how something works does not mean I use it.
Ah, sorry, I gave up too soon. I skimmed it, seing a lot of "win32", and lost interest. 
awesome nickname.
The documentation is pretty good: http://docs.python.org/library/ctypes.html There is also an experimental wrapper that I've gotten to work (though I don't know if it's still in active development): http://starship.python.net/crew/theller/ctypes/old/codegen.html Then there is also SWIG ... which has a code generator as well... and will actually generate wrappers for more than just python: http://www.swig.org/
You're lying about Haskell. That only works because numeric literals are of type `(Num a) =&gt; a`, so you're actually creating `Double`s. Prelude&gt; let x = 3 Prelude&gt; let y = 2 Prelude&gt; :t x x :: Integer Prelude&gt; x/y &lt;interactive&gt;:1:0: No instance for (Fractional Integer) arising from a use of `/' at &lt;interactive&gt;:1:0-2 Possible fix: add an instance declaration for (Fractional Integer) In the expression: x / y In the definition of `it': it = x / y 
Follow-up: The actual way it works is that Haskell sees: 3/2 Where: 3 :: (Num t) =&gt; t 2 :: (Num t) =&gt; t / :: (Fractional a) =&gt; a -&gt; a -&gt; a So it infers that: (Fractional x) 3 :: x 2 :: x Then `Double` is selected at the type, by the Haskell defaulting rule (Haskell will try to default to Integers, then to Doubles, by default). The actual defaulting rule is: A variable is defaultable if it only appears in class constraints (such as `(Fractional x)`), and at least one of those classes is `Num`, and all the classes are in the standard library. If you change the defaulting rule it won't compile: default (Integer) -- this is by default "default (Integer, Double)" x = 3/2 Result: Ambiguous type variable `t' in the constraint: `Fractional t' arising from a use of `/' at test.hs:3:4-6 Possible cause: the monomorphism restriction applied to the following: x :: t (bound at test.hs:3:0) Probable fix: give these definition(s) an explicit type signature or use -XNoMonomorphismRestriction
Opencv has python bindings and resizing using this is a doddle.
Two completely different things. Cython allows you to write C extensions for python. ctypes allows you to access a shared library via pure python. 
I read the ctypes module documentation and it contained enough examples for me. It's amazing what you can learn by R-ing the FM.
Yeah, you're absolutely right — but note that it is always true to say `&lt;literal-int&gt; is &lt;same-literal-int&gt;` since the same instantiated number is referenced both times. So `12345678 is 12345678` evaluates to True. Anyway, yeah, I don't know why I was being pedantic as it doesn't really help explain the point to the OP, but python quirks are fun eh?
Didn't know about that subreddit. Awesome! Would also love to teach and learn from enthusiastic people. Subscribing.
YES. I enjoyed this, thank you.
god forbid somebody wishes to learn something new. you don't like a post, why not downvote, hide and move on with your fucking life?
Chill man, the reality is that there just isn't that much content if you restrict it to 'Python -- Serious Business Only' I personally like to talk about code, it can be a lot more interesting than some articles. Besides you can learn something, asking (and responding)
Why wouldn't we want people posting questions here? I'm sure there are plenty of new python programmers who might benefit from seeing a question here. It's one of the reasons I have it on my list of reddits.
I got excited thinking Google released a proper api for Voice, but no they are still forcing developers to use fragile hack jobs to interface with Voice.
&gt; encourage folks to take the "how do I...?"-type posts to a site that's meant for that (e.g., StackOverflow)? The sidebar does say that this subreddit is for "news" about Python, but seriously, this is pushing it. I'd welcome all of those posts. We're not exactly brimming over the edges with content in here, so anything Python is good to me.
Sheesh and you have to create a fucking thread to bitch about this ? you can go some place else downvoted
for a sec I thought this is about changing password :p
I don't care if these posts show up but it's true that the posters would be better served over at StackOverflow.
you seem to be too obsessed with being "a master" Just get on coding edit: so what have you coded so far ? 
One excellent example of this is the django web framework (http://www.djangoproject.org) When the application is deployed you can use the same shell that is available when you are developing by using: python manage.py shell This will give you an interactive python session with your application's settings loaded. Depending on your deployment there may be some nuance to this, and then of course there is always the question of whether or not you *should* be doing this in a production environment, but that's a completely different question entirely.
&gt; a site that's meant for that Who says this ain't?
In the last 24 hours this subreddit has had 7 posts. * 4 Links to news/interesting info about python * 2 Questions from newer python users to the pyreddit community * 1 Post complaining about new python users reaching out to their fellow redditors. (\*cough\*)
Better than nothing, I must say.
I have experience with Django and its shell, but I wasn't sure if that was what I was looking for. For example, I can't interact with incoming data and such, but maybe I'm mistaken about the concept of a live REPL and the Django shell is what I'm thinking of?
oh yeah
Yeah. I don't think there's such a large number of posts to /r/Python that it's an issue - another poster says 7 posts in 24 hours... no problem.
I guess... If I need to yield a float (which I rarely ever do) I multiply the dividend with 1.0, so it would look something like this: x = y * 1.0 / z Is it retarded? Sort of, but I've never gotten confused over this issue. Changing it now *is* creating issues.
As someone who's not a "pro" at Python I rather enjoy others posting their questions here. Sometimes they're questions I wouldn't have thought to ask, or may end up coming across in the future. This isn't a particularly active subreddit, the Android subreddit gets an easy 5x as many posts per day than here (they're about the same population). I really like the fact that questions are there to 'flesh out' the subject matter and make the subreddit more active. TL;DR: Downvoted you. You're kind of a jerk. Most of us don't mind questions posted here. Some of us even enjoy it.
I often learn a lot from the responses to these questions. I'm happy to have people ask questions like that here. It helps the submitter, and it helps the whole community because we all learn from the submitter's question.
Eventlet (and I think gevent as well) has a class called 'Backdoor' which allows you to connect to an interactive python shell of a running process via telnet http://eventlet.net/doc/modules/backdoor.html
crowding out /r/Python ? if only it were that big of a deal.
Yeah the Django shell isn't really going to give you access to live incoming data (not without modification anyway). Such a thing could be written, or may exist already - can you describe in more detail the type of application the service might host and what you'd like to be able to do with the REPL?
Another cool related proejct is [Twilio](http://www.twilio.com/)
attr.create_system = 3 lol wut? =3 
Awesome!!! I was looking for something like this! To bad they don't have voice recognition :(
... still not available outside the US.
Yeah I don't really know what that does lol and the docs aren't very helpful: ZipInfo.create_system System which created ZIP archive. The link in the code is where I found what those should be set to: http://www.mail-archive.com/python-list@python.org/msg34223.html This function is definitely strung together by a lot of googling :) But it works, I've been using it to package up mac apps for a couple months now.
I can have a real number 40 and I can also have a real number .40. The two are distinct.
Have you figured out how to put an empty directory into a zip yet?
Say you had this function: f = lambda x, y: 1.5 * (x / y - 1) Using "classic" division, f(2, 3) == -1.5, while f(2.0, 3.0) == -0.5. Thus by simply forgetting to coerce the type by doing something like multiplying x by 1.0, this function has an error that may never be caught until something goes boom. All other mathematical operations other than division handle mixing int and float values without a problem. "Classic" division was completely removed in Python 3 because a division operation will either need to use true division or floor division, but not both. Also, as part of a unified numeric model, if 1 == 1.0 and 2 == 2.0, then 1/2 == 1.0/2.0. In Python 2, this isn't the case even though 1 == 1.0. True division fixes this wart.
&gt;Very simple just to use // when you want to return an integer. It's floor division, not integer division. Thus if either number is a float in x//y, the return type will be float, not integer. If you need to guarantee an integer value, use int(x/y).
Thanks, I didn't know that.
Give the runserver plus command a try that comes with a django extension. If you have Werkzeug installed and an exception happens, it drops you into a traceback integrated shell. Looks like this: http://flask.pocoo.org/docs/quickstart/#debug-mode
They're Google. They certainly have the brainpower to do better.
I've updated my code to support empty directories.
Twisted has a similar thing called Manhole that can let you telnet or ssh in to your live process and get a prompt.
tl;dw "Hell yeah! You can do all kinds of shit with python!"
You wouldn't want to get your manhole confused with your backdoor now would you!
Unix-only[.](http://i.imgur.com/YmIcz.png)
"3" or 3000 depending on how you look at it.
What's the name of the search engine they mentioned in the beginning of the video? nullage? nollage? knullage? What's the URL, anyone know?
http://nullege.com/
Thanks!
I think select can be emulated on file objects in windows using various Windows API functions. Maybe someone can patch it in?
Sure, _some_. I won't hazard a guess as to how many people do point and click GUIs versus how many do algorithms. I will say, however, that a _lot_ of people learn to program mostly by implementing various algorithms that do involve some bit twiddling, e.g. that's how coding is taught in every university course I've ever taught. And no, integer division isn't removed. The obvious question (to me, at least) is if the roles should have been switched. Should 1/2 return 0 and 1//2 return 0.5 instead? It's not obvious to me that one way is more natural and intuitive than the other.
wow. thanks for putting that into some light.
While that's true, I thought the discussion in question was about trailing periods.
This seems a bit complex. Maybe even complicated.
In development I often drop the following in my code to give me a shell: from IPython.Shell import IPShellEmbed ipshell = IPShellEmbed([]) ipshell() see: http://ipython.scipy.org/doc/stable/html/interactive/reference.html#embedding
Here are some notes I took down watching this: Tools - http://hexsec.com/docs - major tools: appscan, webinspect - python tools and libs: spikeproxy, proxystrike, ldapython, peach, sqlmap, w3af, scapy, sully, pyscan, monkeyfist, PyEMU, wapiti, impacket, PyDbgEng, unhooker, Python-ptrace, DeBlaze, Canvas, pywebfuzz - third party html libs: httplib2, urllib3, restkit, suds, lxml, PyAMF, PyQT - selenium - gui website unit test writer - difflib.HtmlDiff() cool: from PyQt4.QtGui import * from PyQt4.QtWebKit import * req = urllib2.Request('http://foo.com/') response = urllib2.urlopen(req) app = QApplication(sys.argv) web = QWebView() web.setHtml(response.read()) web.show()
/r/python is almost dead. I would think any attention would be good at this point. Where else can you find out you have python and reddit in common with somebody?
The short version: * In Python 3, bodies are bytes, everything else is strings * Some recommendations or clarifications were added for various minor corner cases That's really it.
I tried it on windows and fixed a bug with empty directories. Symlinks will probably only work on unix still but other then that is seems to work on windows.
While I know it's been done this'll make it easy for me to integrate Google Voice with my Asterisk setup ^_^.
Well, we had BASIC, even in our schools! Now we need curriculum for Processing in every middle school. I'm sick of hearing parents tell me their child is a genius at computers. When I ask if they know any programming languages, of course, they do not. A whiz, huh, more like confident random button masher.
Agreed, though I'd hope to see it restricted somewhat to more difficult or interesting questions that can't be found easily through Google searches.
The tarfile module can do this, although you get a tar.gz rather than zip-format archive.
I find the paranoid comment about google easily learning more about web traffic and the subsequent post to do it [using bit.ly](http://segfault.in/2010/10/shorten-urls-using-python-and-bit-ly/) pretty interesting too. The most obvious thing, is google clearly is making the effort as simple as possible without the need for accounts or api keys.
What error messages are you recieving?
What error are you getting? Check your logs. Is the file executable (`7xx`)? Can you run it from the command line? Also, if a file is being created, it will be created by whatever user the web server is running as, not as you. Make sure the web server's user has permissions to create the file in the directory.
None but the file does not get written into
yes its is and I am just writing into a file "test.txt"
does the file already exist, or are you expecting it to be created? Also, what does the script output when you run it (success/fail)?
I just tried your script and it worked (after fixing an `IndentationError`) both from the command line and as a CGI script. My guess is your web server doesn't have permission to write to the file / directory. 
i think everyone can do that on their own, it's when a team of 50 or more is in a code base so old, no one feels like they own it, that "1200 line pieces of shit" come about.
This is the only thing I could think of when I read your post title: http://pythong.org/
hahaha why do I always have a spelling error. I wouldn't be surprised if my problem was just a spelling error. 
ah that is very helpful! The files have permission to write and execute does it need more? Its in the CGI bin
Yes it already exists. The script outputs nothing, not even the html. just a blank page 
The moratorium (also in PEP form) addresses some of your concerns: http://www.python.org/dev/peps/pep-3003/ -- and really I find Python to be quite good in terms of backward compatibility. Python 3 of course is a big breaking change, but other releases have not been, and won't be. I don't really see how `("someFunc($a, \"" + $b + "\");")` is better than `functools.partial(someFunc, b=b)` (assuming that argument has the name `b`). And unlike the Tcl code it's not really buggy with respect to quotes or backslashes. But yes, lambdas (or partials) are not awesome in Python. For debugging, you might want to try pdb. But personally I mostly use prints and sometimes `assert 0` to get a traceback where I want it. There are good specific through-the-web tools as well. I don't think Python is *too* big; finding out about a new module or method is better than the functionality not existing, after all. For data structures there's a small core that are really powerful and important -- mostly lists and dicts, tuples and sets to round it out a bit more. It's okay not to get into other stuff, these data structures work well enough for nearly everything (stacks, queues, trees, etc). For other stuff... well, it's up to you. You can learn more and more... or not. Your not really worse off ignoring something than if it didn't exist in the first place. Maybe searching for "pymotw &lt;something&gt;" (pymotw=Python Module Of The Week) -- it's a series of articles about the standard library, so if there's a topic that's covered by the stdlib it would probably give you a hit, and by now nearly the entire stdlib is covered by the series.
See also: http://blog.matt-good.net/2007/02/27/pythongpaste
&gt;I don't really see how ("someFunc($a, \"" + $b + "\");") is better than functools.partial(someFunc, b=b) Well, I agree there. Neither is wonderful, but importing a whole other module (that I hadn't heard of until I had the problem) just to get a really standard element of button usage to work feels lousy, whereas string concatenation is very common, and requires nothing more than the base language's syntactic abilities. I don't need to make sure people have that module, or that it might change names or disappear in future Pythons. It's not an additional hit on memory. It's not an extra import at the top of the code that might have me wondering and scratching my head in 6 months time, and it's not something that I have to re-understand later. The module changing might be very unlikely, but again, a whole module just so I can have a button make a proper call - as buttons do - is silly, and feels like clutter. I don't want it in my code if at all possible. Again, I'm not saying string concatenation is great in this case, though I've become very accustomed to parsing it as I read it, and hardly see the escapes and quote sequences anymore. The admittedly still fairly clunky way I've found around it for now is this: def someClassMethodAButtonNeedsToCall (self, btn): print 'You pressed %s' % btn def someClassMethodThatMakesAButton (self): btn = cmds.button(label='whatever') def temp (btn=btn): self.someClassMethodAButtonNeedsToCall(btn) cmds.button(btn, edit=True, c=temp) The second method makes the button and a temp function, with an argument with a default value that evaulates to the button, and calls the first method. This binds the button to the argument, and the first method to the temp function, and edits the button to call the temp function, so when this method finishes, and references go away, the button is still connected to the function object that was originally bound to temp, wherever it may now be. It's weird, but it works with defaults, and it doesn't require concats or any new module imports. My point about the size of Python was more a venting at the overwhelming nature. For months now I've been introduced to whole new wings I didn't know about, and it gives me this sense of bloating, like emacs. I do agree it's nice to find a module that does something, like that time I found one for Perl for ID3 tag info and whipped together the utility I needed in about 15 minutes. I haven't done much of that in Python yet, but I imagine I'll greatly appreciate it once I begin to. I guess the worst thing about it being so large - you mentioned that I'm not worse off - is that it makes finding the right info a much bigger chore. I'm forever ending up in PEPs, or on blogs that talk about things that don't help, or back in the standard docs where my questions aren't answered. There's *so much information* on everything in Python, trying to get a simple answer to a slightly complex problem can be a real uphill battle. Thanks for the pymotw heads up.
OK - does anything show up in your web server error log for requests to this file? When you said you have a couple of scripts already running, are they also python cgi scripts? edit: also, it might be worth trying to delete the 'test.txt' file (assuming it's safe to do so), and set the mode for the file handler to 'w+', which as you may know will cause the script to create the file if it doesn't exist.
consider posting to http://stackoverflow.com -- they specialize in technical answers. If you want to get fancy, use something like one of the modern multidimensional NoSQL databases, like HBase or Mongo. In this type of system *everything* is a key-value pair. A "value" can be a date ("crawled on 10/10/2010") or an entire file. 
yes they are .py and they are forms I'll try the w+ and check the logs when I get back home.
I had to do something similar and ended up just storing each html page in a text column, 'page_html'. Postgres can handle fields up to 1 GB, which is way more than you need for any webpage. This way, everything is in the database and you don't have to worry about dealing with separate files on disk (and backing them up, handling locks, etc.). 
It depends on what a "file" is. If it's text, like HTML or something that is maybe 10s of ks max, you definitely want it in a database. Mongo is really simple to use, much easier than SQL (imho). You do something like: import pymongo M = pymongo.Connection() M.database.collection.insert( {'file':yourfileasastring, 'time':timestamp(), 'etc':etc}) No schemas or other whatever. If the files are bigger, or binary data, it's usually more appropriate to store them as files on the filesystem, and track metadata (including the /path/to/the/file) in a database.
You haven't stated the magnitude of your problem. 1000 pages is trivial for any current system, and even current smart phones wouldn't break a sweat. Anything would work - ie just write the most convenient code you want. A million pages starts getting a little interesting, and once you are looking at a billion pages then you have serious architectural choices to make. You also haven't stated what the content of the pages is. If they are all substantially similar and you want to store the same information about each then a regular database will work just fine and you can store the page as a column (unless it is large, but again you'll need to give more details.) If more than one machine will be crawling the content then you need a networked server solution - ie you couldn't use SQLite. If the items are binary (eg images) then different databases have different issues. For example SQLite has a nice functional blob type while Postgres doesn't. If the content is primarily text then you'd likely want to search the content within. Look for the various text indexing engines and choose a solution that works for you. Some things to lookup are lucene, solr and haystack. If the information you want to store about each item varies by item then a document oriented database will likely be a better fit. You can store any attributes you want for an item and do not need a schema, and they can store the item as well. Two good examples with excellent Python bindings are MongoDB and CouchDB. CouchDB is very web oriented and has excellent replication as well as an effective offline mode, and you only need one machine. Its sweet spot would be up to a few hundred thousand items after which it loses steam and gobbles up far too much disk space. MongoDB works a lot better at scale, has fantastic query functionality and is faster, but doesn't have the offline functionality. It also requires at least two machines for durability ([which is sensible](http://blog.mongodb.org/post/381927266/what-about-durability) but will [support single server durability in the future](http://www.mongodb.org/display/DOCS/Durability+and+Repair#DurabilityandRepair-SingleServerDurability))
MySQL blob type for storing files. I'm not quite sure about Python, but I'm doing this now in PHP, a mediumblob holds up to a 16M binary file.
You could use type(vals) to check if it is a list, then iterate as necessary. Also works with vals.\__class\__
You don't say anything about what you will need to do with this data once it's stored. Do you need to access individual items quickly? Merely serve them over the web (S3!)? Do you need them compressed to take up less disk space? Do they need to be accessible over a LAN from multiple application servers at once? Since you only say "&gt; 1000 pages" then I'm guessing you don't need *much more* than 1000. So since I'm assuming your problem is not all that large in scale, what I'd do is create a nested directory structure, probably 2 levels deep, and store the files by their hash digest. So you'd have a filename like 2/4/245eec368851f75bf93867419c8c156698561664. Then reference the filename in a database record. This way, duplicate files only get stored a single time, since it is astronomically unlikely to have two different files hash to the same value. See [here](http://en.wikipedia.org/wiki/Content-addressable_storage) for more explanation on that part. The reason to have a nested directory structure is to bring down the number of files in an individual directory, because having too many files in one single directory can cause programs like `ls` to become unusable. If the number of files is very large, you might want more than two levels, but two levels would divide the number of files by 256, so it should be fine up into the millions. To get an idea of how many individual files you can store on a Linux filesystem, run `df -i`. My 8GB partition has about 500K inodes and my 115GB partition has about 7.5M inodes. You can also tune filesystems (see `mke2fs -N`) to have more inodes available, so they can handle such a workload better. But I have a feeling that if you're thinking 1000 is a lot, then you'll be just fine without any tweaks. In summary, I think your idea of storing files on the FS and metadata in the DB is just fine. I also think grotgrot's idea of just storing them right in the DB is probably fine too, at this scale.
please don't allow your cgi scripts to write to the cgi dir.
also, need two newlines after the content-type.
ok this is the only error I can find Tue Oct 05 22:44:01 2010] [error] [client 76.126.185.33] Premature end of script headers: tester.py
Hmmm, ok... try moving the content-type header to the top of the script; just after your imports #!/usr/bin/python import cgi, os import cgitb; cgitb.enable() print "Content-Type: text/html\n" ..... I suspect it's generating a traceback for an error that's occuring before the content-type header is provided, and so it's giving a "premature end of script headers" error. Putting the content-type header at the top of the script means that if something goes wrong later in the script, the traceback will be written into the response. edit: I'd say you should also move the cgitb.enable() to its own line. I just tested using cgitb.enable() from the command line, and it printed "&lt;!--: spam" before the content-type header came out when I forced a traceback - so i suspect something similar is happening to you 
 I wish we'd teach our students python using PyDev rather than just idle. It's overkill, sure, but ah it'd prepare them just a little more for the following semesters!
Thanks. The specific question I had in mind when making this post was regarding the division operator. If indeed "/" defaults to floating point division in 3.0, that is going to break *a lot* of my code. I had read the (very limited) documentation on __future__ 'long ago' (I've not been using python all that long) and never really saw a use for it at the time. My programming background largely consists of C and C++, and as far as I can recall there hasn't been any real fundamental changes to the languages since I've learned them-- especially to something as fundamental as the '/' operator. It was a short time ago that I was writing a module where it was convenient to have all divisions default to floating point operations. When I found the hack that worked, I was at once happy and sort of concerned for the above stated reason. From my perspective __future__ in itself is a pretty strange thing. I don't know, I guess it's a proactive version of having something like __past__, though, a hypothetical __past__ module would probably do a lot more to simplify the transition for changes as radical as redefining the division operator. So, anyhow, thanks for the advice. I'll look into it. EDIT: I'll look into how to correct the formatting of this comment later. 
I think this post is fascinating because it seems you are coming to python and finding many things to be over complicated, when I came to python to get things simplified (from C#, Java, and C). Python is interesting in many ways but most importantly you have to understand that Python is what you might call "opinionated." It takes some strong stances on how things should be done, and those strong stances have actually proven very valuable in creating a software ecosystem where developers can comfortably adapt to new apis and modules they use whether they be core or external dependencies. I'd like to address some of your complaints. You've argued that "someFunc($a, \"" + $b + "\");" is better than functools.partial(someFunc, b=b) because with the first version you don't have to import an entire module, but what you have forgotten is that just because you yourself are not accessing code modules or libraries, does not mean the runtime isn't. For example "someFunc($a, \"" + $b + "\");" means more to the interpreter than just "concatenate this string." In fact it's doing 2 variable dereferences, one string interpolation and 3 concatenations. Also many common languages are implemented with immutable strings; if this is the case, you've just created 6 strings in memory; if not you may have had to change the allocated memory for your string several times which is also fairly expensive. Now that all this has happened what does the interpreter have? A string. It now has to incur the overhead of evaluating the string, validating if it's even something it can execute. So while you the developer have not had to explicitly ask for the required modules and libraries to get the job done, you have done so implicitly, and with a great deal of overhead. You may have saved a few keystrokes, but at a cost to performance and readability. As for the size of python, don't feel like you have to learn every available module available in python in order to use it. I'd say a lions share of python developers are not familiar with the vast majority of the built in modules; we tend only to know the ones we use regularly. Python affords you this ability to learn as you go, and from time to time you'll pick up new information about how to solve certain problems in better ways. The real value of all of those included modules comes into play when you want to run a python script on another machine. You can always count on having a certain set of functionality available so long as python is installed. As for where to get information about how to solve problems? The PEPs aren't really made for that purpose. If you're searching for an answer and arrived a PEP, you've probably taken a wrong turn somewhere. It sounds like what you want is solid, practical solutions to specific situations (which is what most people are looking for). If you haven't been able to find the solution by searching, I'd suggest asking on the python subreddit (which you've done now, welcome), or on stack overflow (www.stackoverflow.com). I'd also recommend picking up Python Cookbook (2nd ed.) http://amzn.to/dw9HDg which is both an excellent resource for pythonic solutions to many different problems and domains, and a testament python's ability to remain stable as new versions come out. The book was published 5 and a half years ago and the code examples in the book are still relevant, and even better they still work. Lastly, When coming to a new language, and you begin feeling uncomfortable, you've got to try your best not to succumb to your natural urge to wish it was more like a language you are already comfortable with. This will generally block your ability to understand the new idioms you encounter, and why they are the way they are. And don't forget that many people love their favorite language and are going to have a hard time helping someone who seems to already have a negative perception of it. Imagine for example a man who goes to Japan for the first time. After walking around and talking with people he stops some of them and says: "Hey Japanese people. Your language is kind of strange to me. Like, when you greet someone during the day, you guys say:" 'Konnichi Wa?' "Back home all I ever had to say was 'Hello'. You guys have like 2 extra syllables in there and it just doesn't make sense to me." That man is not likely to win many Japanese friends, and will probably struggle more when learning Japanese in general. Ok now lastly for real, a pythonic solution to your button to function mapping problem: from maya import cmds def on_click(a, b): def fn(): print "%s %s" % a, b return fn btn = cmds.button(l="My Button", c=on_click(a, b)) I hope this helps, and welcome to the python community. 
thank you, ok trying this out.
Im doing it now for testing but may I ask the reason? security?
All very good points, and all well put. You make a far better introduction to the language than pretty much everything else I've encountered so far. Point taken on my tone. I spent yet another day frustrated by obstacles and it came out in my post. I'll work on that. Your solution to the button problem is wonderful, and I'm a little disappointed in myself that I didn't think of it. I was so close, but forgot I could return a function from a function. This also marks the first time someone has said "Here's a more pythonic solution" and I've been very happy about it. I'll go over your words a few more times and check out the references you've offered. Thanks again!
As a newbie to python (formerly perl and C using vim). Do you recommend Pydev? Any newbie tips?
ok same error and still nothing showing up.
The werkzeug debugger is bloody awesome.
From zipfile.py: if sys.platform == 'win32': self.create_system = 0 # System which created ZIP archive else: # Assume everything else is unix-y self.create_system = 3 # System which created ZIP archive 
Thanks for the info. So you recommend Aptana above regular eclipse with the pydev addon?
Wow, still nothing... First: What if you move the content-type header above the imports? Second: Do you have shell acess? Can you run this script from the command line?
Because if someone can trick your script into creating another cgi script of their own design, they can do what ever the servers cgi environment allows, like: - adding evil js to your site files - deleting things - pretty much anything 
incidentally, the content-type should be on the same line as the opening """ as well, if he leaves it in there instead of moving it to the top of the script.
I have to apply for shell access with my hosting (send in my ID) let me try moving it up some more
I would suggest to forget about CGI and use WSGI. Get yourself a nice little framework like flask or botle and start rocking :-)
"bodies"?
&gt; The separation of the idea of 'the number six' from its actual representation is basically all Unicode is. This is a bit inaccurate. While there are identical concepts represented by different visual representations (glyphs), unicode is *not* a mapping betweeen these, or between concepts and an alternate binary representation *instead* of glyphs. Rather, it's concerned with representing *text*, which is already an abstraction at one remove from the concepts themselves. Eg, there are seperate unicode codepoints for symbols representing the same values in different languages. Eg. Thai doesn't use arabic numerals, though the symbols are used in a similar way to our decimal representations, yet the equivalent Thai character to "6" ( ๖ ) has a seperate unicode codepoint (U+0E56) from the arabic numeral 6 (U+0036). It'd be closer to say that it's a mapping between the *glyphs* and an arbitrary number representing that glyph (code-point), and between that code point and one of various encodings. Though this isn't really right either (eg. different fonts may use slightly different symbols for the same character - you can write 4 as a joined triangle with protruding edges, or more as an L with a stroke through it. There are also code-points that get written differently depending on context) The unicode standard refers to codepoints representing "abstract characters" - essentially the symbolic value we attach to a particular element of text: "4" written different ways is still the same symbol, but a Thai 4 is a different symbol altogether. We still haven't gone far up enough to reach "the concept of fourness" however - we're still talking about *text*, not the *meaning* of text.
check out Foundations of Agile Python Development on apress, it covers how to get started with eclipse in the first couple of chapters.
I have found that it is better to learn programming by using the bare necessities of a language. When a certain level of knowledge is achieved, it is more productive to switch to an IDE, but only if you know how this IDE works at the low level (in case you need to fix something).
Pydev is good but personally I prefer Pycharm from the intellij guys. It's free at the moment while in beta but eventually it'll cost. You can sign up for the beta coupon for 50% off and then it'll cost about as much as a cheap video game. The support will be much better (awesome employee support in the forums) and I just think the intellij framework is better than eclipse. They also have nice things like a plugin to store settings on their servers and have access to your config anywhere you install.
Aptana is beastin', it has dark themes :) Also if you're doing any kind of web development it helps there too.
Emacs, Vim...
&gt; Wouldn't it be better to start with an environment such as that to better prepare for later on? Depends: Such environments can be a real productivity enhancer, or just spoil what otherwise could have been a decent coder. Some, otherwise decent, coders get so lost without their beloved &lt;INSERT IDE NAME HERE&gt; that is really painful to see them trying to accomplish anything at all when they get a job at "Company X" which is a "NOT *YOUR* IDE" house. So: use whatever suits you, but learn and try to understand what is going on behind the scenes. Even practice a little with the opposite extreme, ie: basic editor, command line, make files, etc. if your an Eclipse guy, or try an IDE for a change if your a hardcore xterm fan. EDIT: &gt; Does anyone in a real work environment code without something like Eclipse/Visual Studio? Yup. And plenty of us do that not because of external constrains, but because we don't kinda like those particular tools.
Yes. Sometimes I wish, I had done it this way. Harder to begin with. But better in the long run.
Thanks for the advice, I'm gonna play around with eclipse for now see if I like it. I'll check out aptana too. Its honestly weird using an IDE after such a long time with vim.
When I did python in my old job I used Komodo Edit, nice little editor, pydev got tons more features though, iirc.
That's what I would do, though I'm no expert. Most dbs can store data as blobs (I know SQLite can, so I would expect others to be able to), so you could actually store the relevant files *in* the database. This has the advantage that you're not relying on the external filesystem. Depends on your application, though. If it's personal use then just don't move the files. If you have to worry about other people doing stupid stuff then you might want to put it all in the db and use db access controls.
You need to wrap your Python script in a shell script, and have the Python script return the directory path via stdout, which the shell would use for changing. See [go-tool](http://code.google.com/p/go-tool/source/browse/trunk/lib/go.py#93) for a real-world example of how this is done.
Great book, great software. Gracias! Did you do this translation yourself? If this hasn't been submitted to PET yet, I think it would be appreciated http://revista.python.org.ar
That looks handy. Can't say I'd trust your check_creds() function any more than I'd trust prompting the user with "Are you an admin?" A guy named Chad Minsky, for instance would have no problem using your app: &gt;&gt;&gt; logged_in_user = getpass.getuser() &gt;&gt;&gt; logged_in_user chadminsky &gt;&gt;&gt; 'admin' in logged_in_user True 
Not to mention you could just rewrite the script if there's no real policy checking going on. If there is and you're just avoiding an exception I'd say just catch it instead.
I rarely do Python dev in PyDev
I just wan't to reply before to say that there is a select method. Look out the twisted default reactor : http://twistedmatrix.com/trac/browser/trunk/twisted/internet/selectreactor.py It use a select for both platform, without heavy differences.. 
We implemented a medium-scale crawling system for my work (approx 12 million urls and counting). We store the files in Amazon S3 (using the boto library), with the document id stored in a column in a MySQL urls table. So essentially the same as your system, but using S3 instead of a local filesystem: this makes it easy to expand the system to multiple machines as the system grows. (You could presumably use Google storage similarly.) We used a fairly standard crawling design with one process that hands out urls and commuicates with dozens of fetcher processes via the multiprocessing module. Designing the schema of the urls table to efficiently select the next url to fetch requires some thought, so do it carefully. I would advise against using sqlite since that might make it difficult to scale the system. I would also advise against having the same process fetch the url as processes it to get whatever information you want for the same reason. Greenlet seems to have extremely easy non-blocking IO support if you use one process for the fetching. OTOH, when I've done small scale crawling for personal projects (&lt;50000 urls), I've used the local file system with nested directories by computing the first several bytes of the md5 hash: eg if the url has md5 e279a40b0ed298df839af967bb33459d you could store it in ~/cachedir/e2/79/a4/e279a40b0ed298df839af967bb33459d.html (this makes getting a file efficient since selecting a file from a directory with n files takes O(n) time on unix machines). Some meta-advice: crawling the web is annoying because the number of ways that fetching a url can go wrong is surprisingly large. Make sure you have a good logging system in place, and the fetcher processes should be extremely fault-tolerant (one of the few situations where catching Exception probably makes sense). See http://streamhacker.com/2010/10/04/perils-web-crawling/
I'm not sure it's so much a matter of 'knowing the basics' to fix an IDE, but rather signal to noise ratio. Trying to learn what an IDE is and why it's useful is incredibly difficult if you're also trying to learn what programming is and how it's useful. You get a lot of interference between the two and people start confusing the IDE for programming and visa versa. One subject at a time. And obviously you have to learn programming before you use an IDE since there's nothing to do with an IDE if you aren't programming with it.
PyCharm FTW!
No. I do not speak spanish unfortunately. It was done done by latinuxpress.
straight up emacs and terminals here. 
I should add the spanish one is a proper translation made by people, not like these translations made by Google Translate which are wrong and some times funny: [portugese](http://web2py.com/book/static/web2py_manual_pt.pdf) and [italian](http://web2py.com/book/static/web2py_manual_it.pdf). 
That's true, I probably should make it a little fancier or check actual group membership but instead kept it simple since only a few admins (user_admin) are going to run it in our environment.
What do you mean by running commands remotely? Do you want to execute python code remotely within python? 
Try [paramiko](http://github.com/robey/paramiko/#readme) (which fabric uses). Here's a demo program that runs programs remotely via SSH: import paramiko, base64 key = paramiko.RSAKey(data=base64.decodestring('AAA...')) client = paramiko.SSHClient() client.get_host_keys().add('ssh.example.com', 'ssh-rsa', key) client.connect('ssh.example.com', username='strongbad', password='thecheat') stdin, stdout, stderr = client.exec_command('ls') for line in stdout: print '... ' + line.strip('\n') client.close()
 def su(cmd): run('su -c"{cmd}"'.format(cmd=cmd)) Does this *not* work in fabric?
Check out [pydsh](http://pydsh.sourceforge.net/). I've used it quite a bit to run commands remotely on many machines and it supports sudo. I've since replaced it with a custom threaded tool that just uses popen to execute ssh commands, but pydsh has the great feature of automatically accepting remote ssh keys which can be a real timesaver if many machines have been recently re-imaged.
that will work w/o an issue. I use similar for a env where I have to layer sudo over su - root
I have several deployment scripts written with [Fabric](http://fabfile.org) for running multiple commands on groups of remote machines. It was very easy to get the hang of it after taking a look at their [documentation](http://docs.fabfile.org/)
&gt; Designing the schema of the urls table to efficiently select the next url to fetch requires some thought, so do it carefully. Can you elaborate on what you mean by this? I already have a method in mind where I can setup any number of crawlers (in separate threads) ... then I just feed URLs and one of the crawlers picks up the next one.
Why not let anyone run it?
Thanks. I'll have to keep in mind the limits on number of files you should reasonably put into one directory. I guess I'd have to make up some arbitrary cutoff where it sends the next crawl off to another directory. I added more info here: http://www.reddit.com/r/Python/comments/dnd1e/best_way_to_store_many_files_from_a_web_crawl/c11ku89
I'm actually interested in exploring graph databases (for other reasons)... but may just end up going with something like PostgreSQL to keep it simple for now. I added more info here: http://www.reddit.com/r/Python/comments/dnd1e/best_way_to_store_many_files_from_a_web_crawl/c11ku89
Thanks for the responses. Based on everything, here's what I get: * Doesn't seem to be any common or better method that other people use. * I have to be careful about putting too many files in a single directory. There were also some questions about my use. Here goes: * For the crawler, I don't really need real-time access to the files. It is my guess that once I've parsed the html file, the files would mostly be archived and only checked again if I wanted to extract some different data at some point. * For a backup/version control type system... I would need constant access. * Number of files? Hmm... I could realistically see it ranging from 50,000 to 500,000 to go through all the sites just once. You can figure over many crawls, this number would go up. However, since I don't really need access to all the files after they they've been parsed, I guess I would just need a good archival strategy for the files. One possibility: store a special URI in the database that points to a zip file + a filename inside that zip file. When the app encounters the special URI it knows to extract the file from the zip and only retrieve that data. * As for the version control ... I guess the "storing in a database" might be an interesting option so I have easy access ... but I may still want to explore some ways to also store in file(s).
You do realise you failed to provide **any** useful additional information? * Magnitude of the problem (approx number of items, size of each) * What the content is (ie how does what is inside matter) * How relevant the contents and usage of one item are to any other * How many machines would be involved in gathering the items * If the items are text or binary * Text search within the items
&gt; Greenlet seems to have extremely easy non-blocking IO support if you use one process for the fetching. I probably should study the handling of "non-blocking IO" at some point. I am actually implementing a special form of "microthreads" ... because I want to explore the concept for parallel computing research (so figure I might do two things at once). :)
Additional notes: version control would mean: * any file type (text or binary) * the need to access all the files (to piece together version history) * search and other things are something that I haven't really considered. (If I did add search, I suspect it wouldn't be hard to add basic search to any of the methods.) Web crawl would mean: * the files would probably mostly be for archival purposes (after I've extracted relevant data) or to extract info I missed in the past ... so there's little to worry about regarding performance
I've heard learnpythonthehardway.com is good. Also MIT OCW 6.00 Intro to Computer Science.
Perhaps this: def print_vals( vals ): for v in vals if hasattr( vals , '__iter__') else [vals]: print v
+1 for [LearnPythonTheHardWay](http://learnpythonthehardway.org/index). Really, really useful.
The best way to go IMO would be MIT's OpenCourseWare site. THey offer good lectures as well as reading material: http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-00-introduction-to-computer-science-and-programming-fall-2008/ That's how I learned it (as my first programming language ever), and I found it really easy to understand. Python is probably the simplest, most straightforwards language out there.
The [official tutorial](http://docs.python.org/tut/) is pretty good if you know another language already.
&gt; The book is a very beginner book for people who want to learn to code. If you can already code then the book will probably drive you insane. That sounds like a problem for OP.
It won't run unless you are a domain admin - it's just the way we have our network setup with group policy. Normal users can't do any RPC
If you really need version control (it wasn't clear to me), git might be a good option. It has a lot of your problems already solved for you. Just overwrite files when you re-crawl a page and then commit them. You can then easily fetch past versions, search them, etc. It will very efficiently compact the data while still having very impressive performance. I've never tried it with 500K files though, so you might want to try some experiments to get an idea of how it behaves under those conditions.
I'm giving an talk called Python Full Meal Deal in 2 days. I've got 200+ slides, handout and assignments up on [github](http://github.com/mattharrison/Python-Full-Meal-Deal). I claim that the handout has 98% of the Python code you will see in the wild (constructs/syntax not libraries) and it's only 3 pages long. Good luck!
Thanks for the suggestion. I'll probably go a different route, but still... that is a real interesting idea! :)
So normally, my response to your request would be to tell you that you should go submit an issue on the project's code system. In this case by asking this question you have just saved me a TON of time by bringing a project to my attention that does 90% of what I need for a project at work, and it seems that this project may be dead or dormant with no updates since July. So I've pulled the code (I forked to BitBucket [here](http://bitbucket.org/fdumlao/pytracker)) and already started making some updates, and I'll try to replicate your issue just as soon as PyPI comes back online so I can get the modules I need to actually run it. The additional feature you're looking for is to have unreleased releases with no deadline show up in your calendar on the date of the iteration that they are scheduled to be released? The end date of the iteration or the beginning date of the iteration? **EDIT: Someone mentioned that this had come off sounding a bit rude and snobbish. Sorry about that it wasn't intentional. I'm just really bad at being funny.**
It would be the end-date of the iteration. There is no pull for iteration dates (that I could find) built into the current pytracker.py or a call of any of the functions in tracker2gcal.py. I attempted to make my own by looking at the syntax of the Story pull but did not succeed. I'm glad that we have mutually benefited from this question though and thank you for sharing your source! I will take a look at it during work tomorrow. 
I can't recommend Nick Parlante's videos enough: http://www.youtube.com/watch?v=tKTZoB2Vjuk He's a great teacher, and the exercises are tough enough to be interesting. BTW, do ALL of the exercises!
I don't know python *at all*. I hope to learn it, but at the moment the extent of my knowledge is shell scripting. But, if I understand what you're asking about properly, I think [configobj](http://www.voidspace.org.uk/python/configobj.html) may be what you're looking for (or I may be way the fuck off). I know some of the scripts I use at work read from a config file, and it's configobj that parses that file. How it does it is still voodoo to me though. 
I actually don' t think this is too bad a spot for this; if anyone feels like helping they can, people that don't think it should be here can downvote - but I'm a relative newcomer here, see what others say. I'd start with saying that this code is ugly partially because the interface you're dealing with isn't pythonic. Maybe check out [utorrentpy](http://freshmeat.net/projects/utorrentpy/); the first Google result I got for utorrent python. If you want to write your own library, do that, but keep your application code separate.
Thanks for the advice. utorrentpy has become out of date as uTorrent released new versions. It was a great starting place for me to figure out how to approach the API, but it won't be much further use, unfortunately. 
no problem - it's not my source though it's Doug Cokers. I'm just going to be making some modifications to make it a bit more useful. One thing I found right away - you will get an exception if you run this against your tracker and there are any releases that have not yet been assigned to an iteration. So the first update is to check for that state and in that case we just aren't going to add it to the calendar (since it's practically impossible to infer a meaningful date for a release story with no deadline and no iteration) Once that is solved it looks as though the code does pull from story.iteration.finish, which is the end date of the assigned iteration. So after killing this bug and a few others (like some assumptions about calendar ids and imports of modules that aren't in the repo like "pytrackergoogle" this should work the way you need it, and I'll be able to drop this into my project at work. 
some of this code doesn't really make sense to me, e.g.: for row in curs.fetchall(): utorrent_domain = row[0] utorrent_port = row[1] utorrent_username = row[2] utorrent_password = row[3] curs.execute(gmailquery) for row in curs.fetchall(): gmail_mailto = row[0] gmail_mailfrom = row[1] gmail_username = row[2] gmail_password = row[3] curs.close() That is two for loops sequentially which will only ever effectively return a single set of variable assignments, even if the sql returns multiple rows. It doesn't look like you actually expect to get multiple rows, so the entire loop construct is unneeded. Simply fetch your one record from the cursor and assigned the columns in one action, like: (domain, port, username, password) = curs[0] Your use of string format operators to build you sql queries further down in the app is exactly what is explicitly advised against in the documentation of the sql module ;) It's unclear why your main execution loop checks for the top of the hour using a string comparator. I don't have the syntax memorized, but I feel like there should be a way to do a test between regular time objects that accomplishes the same thing without having to shuffle around the types. i'm no python hotshot, but those are just a few things that pop out at me when reading that. 
This is a wiki some classmates and I are working on this semester (we are all learning Python). Check it out, our notes and the professors slides are at the bottom http://boykin.acis.ufl.edu/wiki/index.php/4834-PY-F10
Awesome advice, especially with the cursor. All of the examples I read used loops to grab data, so I just copied that. Didn't realize I could write it in a much simpler manner. Thanks!
Python docs are really not all that bad if you already know C.
The request body (wsgi.input) and the response body (write() calls or the return iterable)
got it working. there are still SOOOOO many improvements that could be made, but I was able to import releases into my personal google calendar. The biggest problem seemed to be an assumption that the story node in the api response had an "iteration" node hanging off of it. It didn't exist at all and so would fail. I added a new method to pytracker to pull the iterations xml and used that. Hope this helps.
I would recommend checking out [Dive Into Python](http://diveintopython.org/). It's free and a great resource for people already comfortable with programming. The official Python documentation is pretty damn good. It has lots of examples and is very easy to navigate. 
I agree. The OpenCourseware classes are great. The exercises go from simple to challenging, and they cover some very interesting subjects toward the end of the course. I highly recommend them.
a few very shallow things: * no need for r'' strings for the priorities (r-aw strings are for when you want to have literal \ chars in the string) * the UT_TORRENT and utorrent prefixes probably makes things harder to read (you need to scan more of the name to figure out what it is) * no need for r on the url either, and string formatting is clearer than +: theurl = "http://%s:%s/gui" % (utorrent\_domain, utorrent\_port) * common practice is that function names should be either all_lower_case or lowerCamelCase, not both :) * sleeping after the IOError is probably just going to annoy you :) 
1. Read PEP 8 - the spacing in your file is obnoxious =( 2. ... utorrent\_domain = row[0] utorrent\_port = row[1] utorrent\_username = row[2] utorrent\_password = row[3] Python has this cool thing... domain, port, username, password = row I forget what it's called... tuple unpacking? 3. "insertquery = prelimquery % values" The sqlite package uses the ? marker for variables in strings, and you can format them with the cursor. MUCH safer, and good practice in general. 4. if results &lt;&gt; '': It's good practice to just let the duck typing do its magic, preferable to go with: if results: Some general comments: 1. ditch the tabs, go with spaces 2. have everything in functions, and have your script have an if \_\_name\_\_ == '\_\_main\_\_': clause that handles when the script is called. Much cleaner, organizationally. 3. you use raw strings a lot, without a need for them really. It's pretty rare to see them used outside of regular expressions. 4. split up your imports, so you do 1 on each line. Easier to maintain. Good luck coding! Python's a fun language. If you need any more help, feel free to pm me/respond, one of my favorite things to do at work is code review other people's python code.
&gt; if __name__ == "__main__" EDIT: Nevermind
I wish I could just do RST!
&gt; I forget what it's called... tuple unpacking? sequence unpacking
Run it by pylint, it is always very critical of everything I do.
This! RST would be amazing for reddit comments. &lt;3
There's also the built in configparser module: http://docs.python.org/library/configparser.html I prefer to use command line flags for everything. Then if you want a config file, you can load flags from a file instead of sys.argv, see the built in argparse module: http://docs.python.org/library/argparse.html This is nice because you can try different values without editing a file, and the argparse module makes it easy to document what all the options mean.
I'd drop all those constants at the top of the file. Instead, write something to translate the json into into a convenient object. Depending on what all is in the json and how much you care about parsing it, it could be something as simple as class TorrentDetail(object): """Information about a torrent. Attributes: Document the attributes here if you care about docs. """ def __init__(self, row): """Init TorrentDetail from a blah blah in the json blah blah.""" self.hash, self.trackers, self.upload_rate ... = row[:11] edit: fixed case and colon
I started learning Python with Guido's tutorial from the official documentation, then learnt the rest through reading the documentation and writing stuff I needed.
Also I'd suggest reading [PEP 8](http://www.python.org/dev/peps/pep-0008/).
Here we go! - split your code in function - use unicode before it's too late - try Twisted framework if you like write network deamon - read PEP8 
please correct your code : class TorrentDetail(object): def __init__(self,row): pass 
I enjoyed the [Google Python Class](http://code.google.com/edu/languages/google-python-class/) youtube videos, although they didn't get into object oriented stuff.
I learned a lot by entering PyWeek, once using PyGame and the second time using Pyglet. You know, the best way to learn a new language is by programming!
So catch the error condition when it fails, and show the appropriate message. Trying to determine yourself if they have the correct privs. is fragile anyway. What if the method for determining who can run this changes? Then you have to update your script. Best to exceptions capture this behaviour (assuming you get some kind of error or return code).
The drop shadow on everything makes it look blurry to me. It could just be me but it could be a problem for others. Just letting you know.
as mardiros wrote, split your code into functions, it will be much easier to maintain and understand. You code (main loop) should look like this, it's not only cleaner and much more readable, it saves you the comments which tend to get out of date: while True: time.sleep( 60 ) for torrent in torrents: if torrentCompleted( torrent ): saveTorrentToDatabase( torrent ) if newHourStartsNow(): sendMailWithResults() 
you can also try this [nice challenge](http://pythonchallenge.com) which brushes your python skills and makes you learn lots of the standard libraries (doesn't help for coding style though)
These youtube videos got me started http://www.youtube.com/watch?v=4Mf0h3HphEA&amp;feature=related He goes through everything, does it extremely well. Just, cant recommend it enough.
It may also be worth reading through this [Config Parser comparison](http://wiki.python.org/moin/ConfigParserShootout) on the Python wiki. Then again I bookmarked it to read later and haven't gotten to it, so maybe it sucks.
i have to say the Packt books are in general expensive and bad.
You can use [Beazley's book](http://www.amazon.com/Python-Essential-Reference-David-Beazley/dp/0672329786/ref=sr_1_1?ie=UTF8&amp;s=books&amp;qid=1286453944&amp;sr=8-1) for both learning and as a reference. This is the best language reference book I have ever used.
[Dive into Python](http://diveintopython.org), but also a slightly more advanced command line interpreter like [ipython](http://ipython.scipy.org) or [bpython](http://bpython-interpreter.org) will prove very useful when exploring the language.
Postgres of course has blobs (unless there is an unexpected problem with using them, they are said to be the same as blobs in the bottom of the page) http://www.postgresql.org/docs/8.1/interactive/datatype-binary.html
Tuple unpacking is nice, but if you like to use meaningful variable names it often becames unreadable. By meaningful, I of course mean long, but they are often the same.
Just tried it out it seems to be working perfectly! Thank you so much for the help! I will look through your changes and try and figure them out so that I can improve my python abilities in the future. Thanks again!
well, use python to execute shell commands remotely. basically what fabric does
but that prompts you for a password right. so far, I edited the sudo command to equal su -c instead of sudo and made it look for "Password:" as the prompt. It seems to work.
yeah, fabric looks like the best option, I'm just going to add an su command that emulates what sudo does, but uses su
Is this a homework problem?
 with open(filename) as f: lines = f.readlines() vendors = [l.split(',')[0] for l in lines] unique_vendors = set(vendors) num_unique_vendors = len(unique_vendors) return num_unique_vendors The key thing here is the creation of a set(). One key property of a set is that it can have no duplicate entries.
What (s)he said, although you might want to use the csv module, like this: import csv with open(filename) as f: reader = csv.reader(f) unique_vendors = set(row[0] for row in reader) return len(unique_vendors) 
 with open(filename) as f: return len(set(l.split(',', 1)[0] for l in f.xreadlines()))
What python editor is the lecturer using?
Sounds good. Though if sudo needs a password afaik it'll still prompt your for one. Was the issue that run() wasn't prompting properly on the version of fabric you're on?
better one http://webpaste.net/
WingIDE is nice also. 
Thanks for that. If you do a Google search for "Postgres blob" you get a lot of pages saying no blob support, or going on about linking fields and bizarre stuff like that. My point of reference is SQLite where blob is just another type and there is a simple syntax - x'aabbccdd' where aa/bb/cc/dd are hexadecimal representation of each byte.
 with open(filename) as f: return len(set(l.split(',', 1)[0] for l in f)) xreadlines is deprecated. 
Actually files are iterable and xreadlines is effectively redundant.
This has been my experience. The documentation for python is really helpful. Once you start to get comfortable with the language itself, there's help in the interpreter as well through the pydoc module. You can pydoc.help( &lt;a_python_object&gt; ) to get its documentation.
A few quick thoughts: * It doesn't look like you're calling `s.quit()`, you have `s.quit`. (It is valid Python because functions are objects, but it won't do anything because you're not calling it. Try `print s.quit` there to see what I mean.) * I wouldn't have my script loop, I'd probably have launchd or cron do it, but maybe that's just my preference. * As others said, you should use Python's `main()` function idiom. * You could get more object-oriented and separate the email presentation from the database. * I would ditch the tabs.
no, if you set the env.sudo_prompt correctly and you have env.password set, it should try to enter the password automatically for you if it prompts. but if the password isn't set or if it's not the same, then it won't work. I have it working correctly now, but I had to hack the fabric code to do it i'm using the dev fabric branch from github
 # File with 4 lines, only 3 unique lines OR 3 unique indexes at 1 l = [ ['VENDOR',246,'07-17-2010 15:13:11',47.4168522,.9818797,162,10], ['VENDOR',246,'07-17-2010 15:13:11',47.4168522,.9818797,162,10], ['VENDOR',247,'07-17-2010 15:13:11',47.4168522,.9818797,162,10], ['VENDOR',248,'07-17-2010 15:13:11',47.4168522,.9818797,162,10], ] # line based unique ll = set() for x in l: ll.update((tuple(x),)) # tuple ( ..., ) wraps tuple constructor print len(ll) # 3 unique lines # Key based unique ll = {} for x in l: ll[x[1]] = x # We care about index 1 being unique print len(ll) # 3 unique keys 
IDLE
Indeed, I didn't pay much attention to docstring this time, thanks.
Thats the difference between sudo and su though. Sudo requires you enter your password, whereas su requires you enter root's (or the user you're su'ing to). So env.password is used for connections via ssh, and it won't be used properly with a su, and the env.sudo_prompt is only going to be referenced by the sudo() command. If you've got to use su though, making your own function to handle it is going to be the best route.
I usually run pyflakes, pylint and pep8 on my code. Pyflakes is supposed to be more permissive than pylint, but sometimes it catches things that pylint doesn't (and its signal:noise ratio is higher). Edit: pep8 is a program in addition to a standard if that wasn't clear. pep8 (the program) checks pep8 compliance.
Some notes (maybe mentioned in other comments): * You might also look at the urlparse module for setting "theurl", which is a terrible variable name IMHO. In particular urlparse.urlunparse. Use urllib.urlencode to create query strings for ease of extensibility. * Also, you use r strings (correct term?) when they're not needed (eg. r'/?list=1' == '/?list=1'. r strings are mostly useful for handling backslashes and non-escaped special characters easily: r'\\\\\n' is way more readable than '\\\\\\\\\\n' (though my habit is to always make regular expressions r strings unless I have a good reason not to). * You could make the while loop "while not time.sleep(60):" though that's probably less readable. I think the 60 second loop is fine. * You should use the "with .." syntax for handling db connections. * You can format the results string as '\n'.join(row[0] for row in curs.fetchall()), which is more readable, and marginally more efficient. * You don't need semicolons in the sql statements. * A lot of your comments seem unnecessary. * pep8 stuff: imports should be one module to a line, comments followed by a space, etc. * You have some unused imports. * uTorrent\_WebUI\_Connect is a poor variable name for what the function does: it gets certain data from uTorrent, but it seems like it should return a connection of some sort based on the name. * The exception handling in uTorrent\_WebUI\_Connect is weird. If you get an IOError, you print an error message, sleep for 60 seconds, and then just continue with the function, which will fail at a different line from where the problem occurred (since thepage is undefined). Also, thepage is a bad variable name. Describe what it is: something like utorrent\_status\_json.
There is a hack solution. I came up with PyBat ( http://pybat.sourceforge.net/ ) as a way for a batch file to call a Python script, have the Python script make changes to an environment variable, and then have those changes copied to the environment of the batch file. (And vice versa with a Python script calling a batch file.) You could set what you want the caller to change its cwd to by setting some environment variable with this value. Remember though, this is a hack solution (I wrote PyBat to kludge together this complicated build system at my last job.) But *technically* it should do what you want to do.
I have used this in the past. However it's very clunky.
Could you give us any more context? Like what the businesses are and what they have to with speeds?
This was my instinct. Did you see the post about the set() method?
it took me a moment to find this, but this seems to be a little more robust, http://www.reddit.com/r/Python/comments/ddojn/mincemeatpy_mapreduce_on_python/
&gt; If you read the script, you'll notice I'm pulling config information from a SQLite database, mostly because it was easier for me to figure out than reading from a config file. Can someone recommend a resource for reading from text files with Python? Seriously? You're already using simplejson. Why not have the config file in json format as well? 
That's great! I'm glad I could help and thank you for saving me some time by asking this question. 
Pull quote: """The Python Webkit Project therefore makes available all these HTML5 features in a "declarative" programming style (as opposed to an embedded "&lt;script language="python"&gt; style) so that developers can use Webkit as, effectively, a GUI Toolkit engine.""" Neat.
Another commenter (zr-rifle) mentioned using [ipython](http://ipython.scipy.org/) or [bpython](http://bpython-interpreter.org/) both of which I have used and can say are very useful. They provide nice ways of accessing docstrings, which helps you explore new modules. You should also get the [SetupTools package](http://pypi.python.org/pypi/setuptools). It comes with the easy_install utility which makes installing new modules a snap. (Not that the default "python setup.py install" is all that bad.) Edit: Fixed my links.
but there is already PyQt and soon PySide for that.
And now there's this!
I did; but admittedly that wouldn't be the way I would have approached it. I don't use sets too frequently, perhaps I can expand my horizons, too.
PyQT's webkit stuff is great and useful (I use it!), but it's not quite the same thing. If you want to actually touch the DOM from PyQT you have to write javascript and fire that into the browser. Totally fine for, say, testing a web app, but I wouldn't want to build a GUI that way.
that's true.
The IOError handling is something I've been fiddling with for a while. When I first started writing this thing I noticed that, when left running, it would randomly fail to log in about once a week and crash the app. I had changed the Except: to "Sleep" in hopes that it wouldn't bring the whole program to a halt when it failed to log in, but it didn't work as I had hoped. Ideally, it'd just let me know that it failed to log in and then go back to its normal routine of trying again in 60 seconds. Not sure if a Try/Except statement would even be appropriate for that action. 
You know, that's a brilliant idea that never even crossed my mind. Thanks! :)
Sure. I frequently use the following idiom: def get_result(retries=NUM_RETRIES): try: return unreliable_function() except UnreliabilityError, ex: if retries == 0: raise print "exception: ex=%s" % ex time.sleep(SLEEP_TIME_BETWEEN_RETRIES) return get_result(retries=retries - 1)
This is fascinating. I'm using pywebkitgtk in just the manner they describe. It's an awkward hack though -- Calling from the client-side JS into my Python backend involves making requests through my own custom URL scheme, which then get redirected to `data:` URIs by the Python backend in order to return the data. Calling from the Python backend to the client-side JS involves some WebKit function that lets you execute a JS snippet (I just call a function name that gets defined by the client-side JS). It actually works great but it's quite weird. This may be a far more natural solution... though porting my code might get interesting.
Also, you could just let it raise the exception, and then handle it in the main while loop...
You should, because you just won the Grossly Inefficient-price. Even for the last item in uniques, you're iterating through the whole list to return 1 for its count.
ok what don't we have this time in the free version?
Do you mean [this?](http://www.twilio.com/docs/api/2010-04-01/rest/transcription)
Amazing! Can't wait for this to take off.
tbh I see more use for this in scraping than I do for html5 features
There is no free version.
What do you need an IDE for Python anyway? Get yourself a good editor with quality syntax highlighting. Might I recommend [SubEthaEdit](http://www.codingmonkeys.de/subethaedit/), or [gedit](http://projects.gnome.org/gedit/). Or, [vim](http://www.vim.org/), if you're nasty. 
fixed. If the constants are just named indexes into a list, collections.namedtuple is another way to do it. 
There is komodo edit which is the free version of komodo ide.
Try taking a look at [nanocli](http://pypi.python.org/pypi/nanocli/0.1.7b). It's a simple, bare bones implementation of a command line argument and configuration file parser.
I use Komodo Edit on a daily basis and I like it. I wish the IDE was cheaper. If it was like $60 I'd probably buy it, but not for $245.
Not entirely Python-specific but here are some things to consider: Try to split the code into separate functions, each with a well-defined purpose. And, as someone else said, add a '__main__'-block to explicitly execute the script. Get rid of the magic contants. The indexes are still implicit in sequence unpacking but it's more obvious what's going on. The same goes for configuration data, don't mix data and code, put the data in a parameter or configuration file: s = smtplib.SMTP('smtp.gmail.com', 587) Never use raw SQL, always use parameters. This gets rid of a whole class of nasty, hard to predict, security problems. Use Python context managers to close connections: with sqlite3.connect('utorrent.db') as conn: ... # conn is automagically closed when scope is exited The same trick would work wonderfully with cursors as well but it seems that's still not supported by the sqlite3-module. Have fun!
Which is why I'm opting for [PyCharm](http://www.jetbrains.com/pycharm/), which is only $44 at this time.
I was thinking the same thing. :D
who the hell is downvoting this one, at least give some reason!
True that it's free but it is strictly an *editor*, not really a free version of the IDE.
What do we need Python for anyways? We could just do the same stuff in C. IDEs tend to provide nice features that make working on large code-bases easier. Like everyone else, I drop back to just using straight Vim from time to time, but Komodo and the others provide SCC features, debugging, etc.
Maybe: if name not in dir(self): … Also note that the right way to ``getattr`` in ``__getattr__`` is object.__getattr__(self, name) in new-style classes and vars(self)[name] for old-style.
How is this advanced?
Because debuggers are awesome.
So does the set() method compare every attribute without iterating?
great post!
post better and link! :)
The sound card has to get the wave data somehow. :)
With all due respect, you seem to be trolling (why would you need to know how a vendor and the speeds relate to answer "how do I count unique elements?"?), so I'll just point you to an intro on sets: http://en.wikibooks.org/wiki/Python_Programming/Sets You may also want to look up what amortized O(1) lookups mean, and how this relates to this: In [1]: a = range(10000); b = set(a) In [2]: %timeit 9999 in a 1000 loops, best of 3: 225 us per loop In [3]: %timeit 9999 in b 10000000 loops, best of 3: 118 ns per loop Note how the set lookups are ~2000 times faster. At any rate, even though LucidOndine's way of building `uniques` is slow, he could still just have done `len(uniques)` to have answered OP's question. Why would he need to count each occurrence of an element in a list of unique elements..?
Komodo IDE is by far my preferred choice over PyDev, which is great in it's own right. On the other hand, the pain both IDEs impose to debug any custom installation, like a virtualenv'd application is rather puzzling. Just yesterday, it took me half and hour to setup a new run configuration in PyDev for a small script that required access to ports in the &lt;1K range. 
For python users PyCharm is awesome. I don't care if it's not free. The is decent and it works very well. Their support has been leagues better than you'd get elsewhere. I suppose if you're doing other languages, like perl then Komodo is one of the few choices you have. I would like to see a perl ide from jetbrains but I don't think it'll happen.
II use vim alot but sometimes you want a proper IDE.
To clarify, Komodo Edit supports Python 3 too (autocomplete, calltips), but it doesn't have a debugger.
I'm not trolling, just new and it seems like I might be a bit over my head. I thought if the set function would only have uniques, it must go through the list and check which ones are unique, and I don't understand how it could do that without being O(n). Are you saying it's better to use set.add instead of list.append because on the subsequent iterations you save that time? I was only thinking about the initial construction operation when set(iterable) makes a unique-only set of the iterable. Anyway, thanks for the info I didn't even know about %timeit That thing for the vendor and speeds was to see if he had any real context or if it was a homework problem because it seemed odd to be learning that way.
len(uniques) would have answered the OP's question; after rereading it, the second iteration would be unnecessary (as would the output). I didn't intend for my pseudocode to be incredibly efficient, instead I saw a list of 4 elements and decided that a beginner was more interested in the concept rather than scalability. My apologies for misunderstanding the desired answer.
Oh. &gt; hasattr(o, "\_\_setstate\_\_"), and hasattr takes any exception to mean, "No, this attribute doesn't exist," returning False. Isn't that a bug, given the existence of the specific AttributeError exception? Shouldn't someone open a bug in the tracker?
I know the guy who wrote psutil. He had a hard time ensuring the library works in all OSs. And it seems he did a good job.
Question: Why don't the code blocks have indentation in my Firefox?
*head explodes* I've read about something very similar to that approach. I like this first-class binding project because hopefully it will result in significant performance and maintainability improvements.
The main issue I'm having with this concept now is that it makes jQuery unavailable. I probably won't pursue it due to this.
Who knows, maybe you'll switch to pyQuery one day?
As far as I can tell, pyQuery is just the DOM manipulation parts of jQuery, which are really the least important parts. You can do all that stuff yourself easily; it's just verbose. It seems to be meant for server-side code that just has to parse HTML. I need jQuery for the animations.
I should've searched for "pyQuery" before saying that. I just meant it as a hypothetical native python DOM manipulation library, but its a pretty obvious name, so I suppose it makes sense that it already exists as something else...
I'd love to see what you've got so far.
For scientific computing, [NumPy](http://numpy.scipy.org/) is your best friend. You can produce nice graphs which may better represent your data with [matplotlib](http://matplotlib.sourceforge.net/). However, be warned that matplotlib's documentation only scrapes the surface of what's possible, so you may need to experiment a bit. Good luck, and welcome to the wonderful world of Python!
You should be able to produce a nice display with just Python and OpenGL. Are you thinking of just having a grid of spheres, representing the detectors on the Super-K? Since the Super-K's grid is nearly square, so I'm guessing you want roughly 100 spheres by 100 spheres... The interesting thing here is to decide how you want to update the color of the spheres, either singly or all at once, or some combination of the two. 
I have some code from another member of the research group who came up with the 3-D layout of the spheres, but "import math" doesn't work. 
If I'm not mistaken our main event display is done in NumPy. The head of the group wants something that embraces style over function. 
Basically what we had in mind was a mockup of the detector that you could navigate in 3-dimensions. The colors of the spheres will be determined by either the intensity of the Cerenkov glow or, if I can come up with a formula for it, the time it took for the light to reach it so the display can show an exact location in the tank. 
Good question. Bad answer. On a more serious note; my comment code only had a "…" indented, is that what you're referring to?
&gt; it must go through the list and check which ones are unique Nope*. Read up on the subject here: http://en.wikipedia.org/wiki/Hash_table (*: Disregarding collisions, etc., which is why I mentioned "amortized O(1)" above. Get the basics first, then figure out what that means.)
Easily done, a 3d cylinder of spheres (or points), each representing the value from a detector. How are the detectors arranged around the cylinder, how many high vs how many around? I assume that you want to model the inner detector and the outer detector, right? (Oops, I just re-read your post, so now I assume you only want to represent the inner detector.)
[see is something like this works for you](http://web2py.com/p3d/default/event). Try reload a few times. It is an event display implemented in processing JS. You can rotate it in 3D with the mouse. I will send you my contact information privately. I have a lot more stuff that I can share. EDIT: This is a python module. The processing code is generated dynamically by the python library.
Nope. I'm referring to the blog's actual post. The comments had no problem with indentation. I'm referring to: import copy class Tricky(object): def __init__(self): self.special = ["foo"] def __getattr__(self, name): if name in self.special: return "yes" raise AttributeError() vs. import copy class Tricky(object): def __init__(self): self.special = ["foo"] def __getattr__(self, name): if name in self.special: return "yes" raise AttributeError() The first one is how it appears in Firefox 3.6.6. The second is how Google Chrome displays it. Time to file a bug, methinks. Then again, reluctance ensues, since there's a SCM version that I don't want to take extraordinary pains to compile to see if it's fixed or not.
I was only suggesting NumPy as a means of handling the data, not the display. I've used both NumPy and matplotlib (which depends on NumPy anyway) before for producing static visualizations (AKA graphs) of scientific data, and it worked quite well.
Looks nice! But, the note on the side says that it's limited to about 2K objects per pic... What will happen when you try to render the other 9K? Is that a limitation of the server, or a limitation from processing?
It is a not a technical limitation. It just that with more than 2K objects rendering gets very slow for typical browsers. Events (like the Super-Kamiokande ones) are a basically a set of lines connecting points where particles decays. Some of them are very slow and would not be visible at that scale and therefore would not need to be rendered. The way I normally use the widget is by displaying the bigger object to display the bulk of the image. When I stop rotating with the mouse, it sends an ajax request with rotation angles. Then I run server side a proper visualization algorithm using VisIt (which has a Python interface) and display a high res images.
Have you also tried execnet?
I don't know the number off the top of my head. As far as I know I'm just modeling the inner detector, but I will ask the professor.
nice the voice is very NERD! xD
No daily/nighty binary packages? It's indenting fine for me in Firefox 4 BTW. Broke my Firefox 3 so can't test there.
I'm guessing that there are about 51 detectors high, and about 150 around the perimeter, for a total of 7650 around the barrel. That comes out to one detector every 27.9 inches, which seems about right for 20 inch detectors with gaps around them.
For anything nontrivial I recommend vps hosting rather than shared hosting. It makes life _way_ easier. With today's virtualization technologies, it's only marginally more expensive, and has much more flexibility. 
There was a lengthy discussion about that and it's finally changed in 3.2 I think.
[http://www.xpython.org/](http://www.xpython.org/)
Shiny. I've always been looking for something like that I can just grab and play with if I'm on a different machine.
You can also use py2exe and it'll wrap up what you need into it's own executable and pyc files, although that adds an extra layer between changing the source and using it. 
Amount of pussy that Guido got.