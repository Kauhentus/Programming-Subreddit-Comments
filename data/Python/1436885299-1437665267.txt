You can create a context manager that lets you write something like: with network_error_isolation(): requests.post(...) See [contextlib](https://docs.python.org/3/library/contextlib.html) for inspiration. 
Nice work. Would you not consider using modules or a package to split your project up? A 600 line file seems like a bit much.
Yeah I've read this: http://programmers.stackexchange.com/questions/162870/gpl-what-is-distribution and some other stuff and it seems distribution to my immediate team is pretty OK, but since I work for NASA / US Government, where the line gets drawn is definitely fuzzy. I have colleagues at a different NASA center and I'm not sure how distributing with them would work. Generally different centers have entirely separate finances and contracts and maintain separate site licenses for software (since they each have their own servers and networks). That doesn't even address agency-to-agency sharing (many NASA centers are located on military bases and partner with local military organizations doing similar work) where I think there has to be a data sharing agreement in place. The route that makes the fewest waves for me is to simply be an end-user of open and permissively licensed libraries that I use to make tools for my immediate team. Of course, my center has a technology exchange office or something for handling software distribution, patents, etc, but I'm hesitant to go that route for fear of getting lost in the paperwork and/or having my software released through a channel that I'm unable to easily update.
Video conversion and tagging. ffmpeg is awesome I just call it from python. The movie db and the tv db each of excellent api's that are simple to create libraries for. I was planning on sharing my code, but it was the first python project I ever made and the code is crap. One day I'll rewrite it.
Cheers! The code itself didn't take long at all (maybe an hour), but the tricky bit is the mapping table as I had to wade through the statements to see the types of strings they had and work out what they were. I would have had to do this anyway, but now I have a good head start on next years tax return.
Aah, I was looking for more stuff outside of the work environment, but thanks for your posting!
Sounds like something I might need to do, would you mind sharing that code with me?
Yeah that's how I justify my coding: "I probly coulda got it done in the same time, but the next time it comes up, it'll be a breeze!"
&gt; My Python final project was to clone Pong. I failed miserably on hit detection. Other than hit detection, what else is there in Pong? A moving paddle? :P
&gt; It's possible to nest functions inside of other functions, but you would rarely ever do it inside of a loop. I have recently started to do this to avoid temporary variables staying alive. Is this bad practice? An example: def main(): var = ... var2 = ... ... def setup_foo() -&gt; Foo: CONSTANT = 12 DIFFERENT_CONSTANT = 12 calculation = ... return Foo(CONSTANT, ..., ..., ...) foo = setup_foo()
Qpython has a python3 version, but it's the only actual example app I can think of offhand. I've recently rewritten a lot of the python-for-android toolchain in a way that should bring Kivy a lot closer to python3 support on android, though the missing part is still actually having a recipe for the python3 compilation (including the patches necessary to run on android). I think Kivy's original patchset for python2 was from [this site](http://randomsplat.com/id5-cross-compiling-python-for-embedded-linux.html) (though kivy also uses several other patches), but it only has up to python3.2, and I'd ideally like 3.4. I'll probably eventually try to tackle this, but if anyone knows of an existing patch set then I'd love to hear about it and it would speed things up! So, some versions of python3 have been compiled for android, but I'm not aware of any projects like Kivy letting you create standalone guis yet.
Doesn't pyautogui require the VB 10 compiler?
Recently, I wrote a python script to compile a list of crafting ingredients needed from nested recipes in an MMO. There's a website that does it for me, but they didn't update the database with the new data fast enough for me.
This works, and has use-cases, but shouldn't be your default approach. &gt; avoid temporary variables staying alive. I assume you're concerned from a memory management standpoint? The first thing to keep in mind is that, unless you're actively doing something with large pieces of data, or doing it thousands/millions of times, it's considered best to just let the python garbage collector do it's thing. Likewise, if you're working on very tightly constrained hardware (embedded systems, etc.) it can be worth worrying about, but in general it just doesn't matter. If your program actively uses a few hundred KB of data, and but the python interpreter itself starts at 5MB, you can be 100% less efficient and it still doesn't matter. Especially when you consider the RAM budget of most machines nowadays. Even with only 1GB of RAM it's you're never going to have a meaningful impact with your constants and simple variable declarations. Of course, when it's a pandas dataframe with a few billion values, or the contents of large files, etc. that's different. But for defining simple constants and such your time and sanity are more valuable than a few KB of RAM. Secondly, let's look at what you're actually doing here. Remember that it's 'objects all the way down'. In [1]: a = 10000 In [2]: b = a In [3]: a is b Out[3]: True In [4]: b = 10000 In [5]: a is b Out[5]: False ***EDIT: I deliberately used a 'large' value for `a`. Try it with small values and see what happens*** So there's an object that contains the value '10000', and there's two names that point to that object. For single integer values the difference may not be much, but for `tuple(range(1, 10**9))` or something it's important. The same applies to function calls and returns. In [6]: def Spam(Eggs): ...: return Eggs ...: In [7]: b = Spam(a) In [8]: a is b Out[8]: True If the value you pass in is mutable (`list`, `dict`, etc.) then work done on `b` inside the function transparently modifies `a` on the outside. And again, the memory usage here is that of one copy of the object, and two names that point to it. In [9]: def return_bird(): ...: bird = dict(state='dead') ...: return bird ...: In [10]: bird = return_bird() So the dict created in the function is alive and well, and if we modify it, it's modified in-place. In [11]: bird['state'] = 'just resting' # same object But if we re-assign we're overwriting the name with a reference to a different object (either another existing object, or one we're creating) In [12]: o_bird = bird In [13]: bird = dict(state='Definitely Resting') In [14]: o_bird is bird Out[14]: False So we still have an name `bird` that points to a dictionary that looks like the original one, but it's not the same object. At this point python knows that the original object has no more names that reference it, so the garbage collector will free up that memory. EDIT: Except, that's a lie, because the `o_bird` name still points there, but you get the idea. Now, the details of how that happens exactly are a bit beyond me, and isn't always as simple as it seems (especially when it comes to actually releasing memory to the OS), but it really does "just work" in the very large majority of cases and shouldn't be an issue, and the impact of any inefficiency in the GC is probably worth less than your time spent trying to optimize it. 
Did you not read what I actually wrote? Why are you telling me things that I already pointed out in my original comment? 
[Screenshot](http://imgur.com/QQvgpNj) I used tkinter, largely because I was familiar with Tk from my Tcl days. It's simple, it was quick to write and it works.
[Fbone](https://github.com/imwilsonxu/fbone) is a good starting point though it's quite complex. It's difficult to explain the app factory in a simple manner other than "it's how things should be". It will allow you to be flexible in your application creation at runtime and provide you with a space to initialize your components. Also, not creating the whole application each time you import its file is pretty good.
Thanks for the in depth response. I agree that I should probably just leave the variables alone. &gt;it's considered best to just let the python garbage collector do it's thing. There are two issues at hand. The first is that if my setup code is in main, it will never be garbage collected until the program is finished so the collection *can't* do its thing. I know it's not a lot of data but I'd rather only have variables I'm using exist. The second one is debugging. Having temporary setup variables pollutes the variable namespace and hiding them in functions will avoid this issue.
No no youre selling it all wrong... Tell people you made a pong-like game with your own special mechanics, physics and hit detection!
Different buttons for each paddle?
And be sure to tell them it's in Early Access, right?
I don't have one explicitly, I was just playing with the `__matmul__` operator and wanted to test with Numpy.
Yeah, but that hard work thinking makes you a better programmer. Makes you better in solving problems.
Ahaha you know it 
http://www.dynamicdigitalarts.com/Screenshot.png
I'm not quite sure what you mean about a function with inputs. `nonlocal` is for when you want to change a variable in an outer function from an inner one. It's not needed very often, but I've run into a couple of situations where that's what I wanted. If you can't use it, the normal alternative is to use a list to 'box' the variable: def outer() a = [5] def inner(): a[0] = 7 inner() return a[0] With nonlocal: def outer() a = 5 def inner(): nonlocal a a = 7 inner() return a
&gt; Or am I missing the point of it? What if you can't change how the function is called? What if the return value is already used for something else? What if you aren't in control of what happens with the return value? Here's a contrived example: def find_most_profitable_company(companies, caches): cache_misses = 0 def get_net_income(company): nonlocal cache_misses if company in caches.net_income: return caches.net_income.get(company) cache_misses += 1 revenue = company.calculate_revenue() # expensive costs = company.calculate_costs() # expensive net = revenue - costs caches.net_income.add(company, net) return net most_profitable = max(companies, key=get_net_income) if cache_misses / len(companies) &gt; 0.25: logging.warning('company net income cache sizes need revisiting: %d misses with %d companies', cache_misses, len(companies)) return most_profitable 
Been busy lately (and juggling multiple interests) so I haven't returned to this project yet but I'm itching to. Its taught me so much about PyQT4 and I've become a big fan of it. Rom management/identification tool: [main gui](https://dl.dropboxusercontent.com/u/67085/RomTool/drr1.jpg) [settings 1](https://dl.dropboxusercontent.com/u/67085/RomTool/drr2.jpg) [settings 2](https://dl.dropboxusercontent.com/u/67085/RomTool/drr3.jpg) As may be evident, I get sidetracked making icons... frequently. The main icon is animated during DAT/Rom scans. edit/update: some early versions of the main gui and a view of how each tab view works, can see the evolution of the UI: [main gui, early version, rom tab](https://dl.dropboxusercontent.com/u/67085/RomTool/romtool2.jpg) [main gui, early version, dat tab](https://dl.dropboxusercontent.com/u/67085/RomTool/romtool3.jpg) 
Yeah, I might do it that way. I avoided it as I refer to quite a few local variables that I can access in the above scope easily. Having it as an external function means the functions will have more inputs but it's not a huge issue. Thanks.
Here's a text editor I made when I first learned pygtk: http://i.imgur.com/Y7URyik.png
Here you go: https://ewilazarus.github.io/feeds/all.rss.xml
Lets see, outside of work, I've written mostly scripts to help manage my media server: - The first I wrote a few years ago was a droplet for converting video files to a compatible format and resolution for my iphone. It doesn't get much use since I switched to android and made my own plex server. - I have a calibre server for my ebooks that my friends and family can access, so I wrote a script that will find the calibre logs, parse them, and geo locate the ips, so I can see what people have been searching and downloading from it. - A script that will convert flac files to mp3 and copy over the metadata tags for me. It has options for cloning input folders so it will copy over cover.jpg, .cue files etc. - I've also been writing a plugin for the deluge torrent client (which is written in python) so I can use [FileBot](http://www.filebot.net/) from within the client to rename and organize tv shows and movies as they come in.
Wow, thanks for posting this. I wanted to work on a solo PyGame project in my downtime when I attended SciPy 2015 last week, but I gave up sort of early on it after realizing that I had no concept of what the API resembled. I'm a pretty experienced Python programmer but have very little game development time under my belt. This code is very clear and demonstrative; I think I'll use it as a tutorial sandbox for learning PyGame.
I actually wrote a script the same as yours but in powershell. I wanted to do it in python for learning practice but thought about other non technical people potentially wanting to use it. The idea was that you can just double click the power shell script and it will handle the rest. Little did I know powershell that comes stock with Windows is buggy and has a lot of deprecated functions that I needed to upgrade to the newer version. That on itself was more of a pain to install than python. Or just including python in the package.
Coursera has a great class on interactive programming. Pong and asteroids are covered. Something to think about on your continued learning
Seriously great looking GUI, though.
Money decisions. Approximations are inefficiencies, and I don't have it to waste. Or at least, if I'm wasting it, I want to be on something fun. But calculations are time consuming and I frequently wind up forgetting the results so I run the over and over again. Finally got fed up and started putting together a library of classes and functions to compare loans, calculate the impact of income fluctuations on child support, etc. I tend to make a point of going out of my way to treat these side projects as practice for more advanced stuff so the learning curve is shorter when I've got real work to do. Also: for remove_string in ['720p', '1080p', '480p']: newname = newname.replace(remove_string, '') I'm just sayin... (won't work as-is for everything you've got up there, but handling '.' and ' ' separately should be fine.)
here's a snippet that I've used in various projects (specifically projects that integrate with AWS and S3) that wraps requests in a way that makes it easier to deal with errors. this particular snippet is a construct for making it easy to automatically retry requests, but you can definitely adapt this type of pattern for other uses. class RequestError(Exception): pass def _try_page(url, attempt_number=1): max_attempts = 3 try: response = requests.get(url) response.raise_for_status() except (requests.exceptions.RequestException, socket_error, S3ResponseError, BotoServerError) as e: if attempt_number &lt; max_attempts: attempt = attempt_number + 1 return _try_page(url, attempt_number=attempt) else: logger.error(e) raise RequestError('max retries exceed when trying to get the page at %s' % url) return response this allows you to just catch a RequestError in the upstream code, which is easier to deal with and gives you an opportunity to allow the program to die (often that's the right thing) or to handle the error and keep going, if you need to. there are, of course, several other ways to implement this construct. it could be a callable object. it could be a decorator. it could be a context manager. this is the simplest way to do it though, just a basic function. 
[screenshot](http://i.imgur.com/nCmJP5u.png) Used PyQt4. It's rough, eh. Took a day to build. 
What about Zombie Pads? It has Zombie Pads right?
[FEA results viewer](https://github.com/SteveDoyle2/pynastran/raw/v0.7/pyNastran/gui/caero.png) I think there are 5 menus. Most everything is on the main screen.
If you'd want it to be accurate, you'd have to do some vector math to calculate the reflection vector so that the ball would bounce properly. Or you could just be lazy and invert its velocity.
GUI for analyzing a specific type of electron microscope data used by no one else except for me - just did it as a way to teach myself python - will hopefully be a part of my dissertation Here's two pictures - one of each tab from the main window after data has been loaded to each tab [my GUI](http://imgur.com/Pn9nWJZ,9e8ZpfQ#0) uses PyQT4 with embedded matplotlib figures EDIT: I got inspired by a few other posts in this thread and added the ability to swap to a dark theme Here's pictures of the dark theme - [Gui with QDarkStyle and a few custom stylesheets](http://imgur.com/muRcmRP,qCzRLfU)
nice! 
Did you read the sidebar? It has some information regarding learning Python, you should check then out. Also, there's a subreddit made for beginners called /r/learnpython , so be sure to check that one out
I made an mp3 tagger last year with curses using npyscreen. I am not a Python dev so the code might not be that great, but I love the throwback UI. http://imgur.com/u2nm3Mz edit: PM me if you want the source repo link. 
Maybe [cherrypy](http://www.cherrypy.org/)?
I was recently in the market for a new house. The local MLS site was terrible so I built a scraper and connected a twitter account to it. I was then the first to know when a new house was on the market. I also added a simple linear regression to predict the price based on past sales. 
How does it look on other platforms?
Web2py I believe does this
Main Gui for PyVmMonitor (profiler for Python) http://www.pyvmmonitor.com/images/main.png I actually use many different libraries. Gui-related are: * PySide (License: LGPL): http://qt-project.org/wiki/PySide Qt Bindings * PyQtGraph (License: MIT): http://www.pyqtgraph.org scientific graphics/plotting * formlayout (License: MIT): https://code.google.com/p/formlayout create dialogs/widgets for qt * pyface (License: BSD): https://pypi.python.org/pypi/pyface python editor * QDarkStylesheet (License: MIT): https://github.com/ColinDuquesnoy/QDarkStyleSheet dark theme for qt * pytest-qt: https://github.com/nicoddemus/pytest-qt testing qt with pytest
Let me quote *The Zen of Python* (`import this`): &gt; Explicit is better than implicit. **UPDATE** Thanks for the Gold, and thanks for supporting reddit :) 
I checked the date. It's not 1998.
Nice and clean. I like it, looks very modern.
I will see what I can dig up. The script is running on my husband's photo editing box and I wrote it in situ and don't think I have a copy (lesson learned). Basically I just hacked together (in the ugliest sense) some open source stuff: https://github.com/themalkolm/PyPhotoShuffle (for the photo naming and exif stuff) and ImageMagick for the resizing and added some kludgy FTP bits. I would make it pretty but it works and my husband is in no way going to criticize the crapiness of it so its all good in my mind ;)
Thanks. Its been a while since I had it up and running but it will scan all roms in a folder without issue. If its doing CRC checks its relatively fast if its doing MD5 or more it will take a few minutes. Other management tools tend to work off zipped/grouped roms which is not something I'm interested in despite the CRC calc savings offered by that method. What I really discovered was that feeding a QTreeWidget with 1000s of records will quickly slow the update/scan to a crawl. Part of this was the routine to update the progress bar (and run the animated gif) but after profiling more and reworking that as much as I could I determined that adding 10,000+ QTreeWidgetItems "live" is still very slow. The solution was to only make the items visible in the widget after the scan had completed. Now when you scan the DAT/Rom views show a loading image while the progress bar runs and shows the # of roms (or DAT records being scanned). While I enjoyed watching the scan add records in realtime the time savings were massive and now a DAT scan completes much faster (as it should, its just text parsing). What I can say for sure is, having an animated icon and accurate progress bar can really introduce bottlenecks. Turns out animated icons/images in PyQT is one of its weak spots. I briefly experimented with running the animation in a separate thread but I recall that producing new challenges I didn't have time to overcome. The workflow is to scan a DAT file, then scan your collected roms, incoming roms or both and then reconcile based on proposed actions and your own settings. I'm basically at hte "reconcile" step but kept making rounds touching up each feature set. I think i'm scared that as soon as it works E2E I'll never want to pick it up again. Which is why there is endianeness handling and CIC detection, etc. Ultimately the idea for this app was to more easily be able to stay in sync with TOSEC (maybe No-Intro too) DATs and verify the roms in my collection against a newly sourced batch while also providing a good interface to build a rom-filled SD card for use in a flashcart. This is another reason the zip side of rom management is uninteresting to me as the Everdrive line of carts can't handle zip files (or at least my Mega Everdrive can't nor can my N64 flash cart)
I've honestly not made it that far but I've tried to code it in such a way that it won't be difficult to get it working on other platforms. I only recently compiled a standalone exe for a much smaller PyQT app I put together. It was pretty painless once I sorted Win32 vs Win64 issues with taskbar icons. Oh and I should have mentioned it elsewhere but none of this would have been possible without the glorious QtDesigner. Once you learn its design patterns (layouts are your friends) it is extremely powerful and has done nothing but help my workflow, not hinder it. The ability to integrate your own subclassed widgets is extremely helpful.
For me, the thing that has really made a difference is learning to use a debugger. There are several, but I use pdb. Do some research, watch a few you-tube vids, and play with one you like.
It expects the user to provide TOSEC dat files to scan. For now the DAT parsing is only fully featured when using TOSEC files but any files following the same format should still mostly work. I wrote the parser against the TOSEC naming convention rules but I recently noticed they updated them (which they dont do much) so I'll probably have to see what changes that will require. I'll also likely add the ability to scan a directory full of roms and export/generate a similarly compatible DAT file. edit: I should mention, I started all this by focusing on N64 DATs and Roms but I've since passed NES/SNES/MegaDrive and any big DATs like some of the C64 ones in and have only had to make very minor tweaks to suss out some of the records that fell through the cracks. That said... the TOSEC "language" tagging rules are atrocious and forced me to build a ludicrous python module that determines the "primary" language of a region based on a few different sources of data. Because someone thought it was a great idea to assume that rom filenames without a language tag would be of the "primary language" of the tagged region, without realizing there is no such official thing in many places, and no one official data source on that either. (I probably went off the deep end doing that as most roms DO come from regions that have a reasonably guessable "primary" language). TOSEC would be wise to just force language tagging on all roms. Here's hoping the new naming convention changes some of this. I dubbed this module "RegionLang" heh, may put it on github if I can read the code again and determine its not just a bunch of terrible ideas :)
I could probably have modules for each of the classes and keep just the "state machine" code in the main file. Good suggestion!
Thanks, I will check that out.
I'm glad I could help! PyGame is a seriously awesome module. I was amazed how fast I could get something up and running.
Interesting UI elements, could you go over what some of the PyQT elements are here?
[Simple Grid Viewer GUI](http://i.imgur.com/KDc1fYd.png), a small program I wrote to view [gradiometery](http://www.ipfw.edu/centers/archaeology/Geophysics/gradiometer.html) data. My first real program with a GUI, written both for fun and because IMHO it does what I need better than the professional stuff. [Link for the source](https://github.com/StivnC/Simple-Grid-Viewer)
I'm not sure of your exact needs, but most likely you can be equally productive in Windows or Mac if you use the [Anaconda distribution](https://store.continuum.io/cshop/anaconda/) of Python. It includes compiled versions of all the most useful libraries. Behind the scenes for Windows it includes an msys distrubution with most common unix tools (ls, grep, etc). It allows me to use the same workflow on linux for Windows. 
It's a great benefit, but you really need a decent core for people to work on, or development is gonna go every which way and you'll spend more time discussing the general direction of the core than improving it. I think the kids these days call it an MVP (Minimum Viable Product) or somesuch.
Anything except Windows would work great for Python. I just can't write single line of Python in Windows. Actualy, if I am not working in VS, screw it, much better boot to Linux/OS X/BSD and do the work...
True, and usually I prefer this, especially on the server side, but for large scale apps it would be nice to have something a bit more magical.
That's pretty cool. I hope you get something out of your labor other than the thanks from the community. I wonder why there aren't any more initiatives from funding agencies or universities to produce software like yours that fulfills a very specific function that saves the researchers hours of work. I am thinking of doing something for Rutherford Backscattering Spectrometry but I'm not sure if I can include a project like this on my thesis.
Neither, really. Both environments will frustrate you in different ways, despite what OS religious fanatics try to tell you. Use VirtualBox from either Windows or OSX (I've tried it both ways, Windows works better) to create a Linux VM and do your development there. You'll need to learn a little about Linux but you need to do that anyway and this is a good excuse to do that.
Thanks for the reply and suggestion to use Anaconda - I'll check it out!
the things that are in bold are comments
You can convert it using str(): print("You added up to " + str(total)) You can also use string formatting: print("You added up to {0}".format(total)) Which replaces {0} with total.
thx it worked
[PyQT5 on Windows 10](https://i.iosphe.re/i/AcidWeb/qf3opo4l4aie)
Most welcome! I played around with it today and ended up doing something similar (except I distribute/install an egg). It's not particularly pretty, but it works! 
You *are* aware of the `logging` module, right?
Not to take away from your project, but are you familiar with the the [logging](https://docs.python.org/3/library/logging.html) module in python? It's setup to do pretty much exactly what you're doing.
what does it do ?? - is it obvious ? ^im^a^novice
Why? I use Flask for some pretty damn large applications and their application factory design with blueprints works incredibly well. What are you looking for the magic to do?
Being honest, it's pretty bad.
#(Player drawing function) def draw_player1(): pygame.draw.circle((screen), (255, 0, 0), (player1.x, player1.y), p1radius, 0)
I use the included QtDesigner app and find it far superior to manually creating the UI in code. I understand the code it generates (its actually very instructive in that way) and frequently find myself making minor UI code edits in it to test things out but ultimately I do all UI design and UI polishing in the tool.
You can configure django to act in this manner. to do so you just need to wrap the urls.py declarations in some dynamic code. Look into how to the various ways that '_ _ import _ _' works. The original popularity of these types of MVC was inherent in the fact that time was saved during scoping and design. But that flexibility can ultimately will lead you to using your controller as a secondary router to parse parameters and then call other methods. With the approach described you end up locked in to a &lt;method&gt;/&lt;param/&gt; type call. This would prevent you from later going and doing something like &lt;category&gt;/&lt;search&gt;/&lt;parameter&gt;/ which might be a much end up being a much cleaner url structure for a given use case this would allow django to handle the overhead of parsing your route instead of duplicating that work over and over again within your controllers. Taking a little bit of time to think about the routes up front may not be as painful as it initially seems. 
Basically all of them: * on the left you see a vertical tab control (Integration, Mask, Calibration) * below the image on the left and above the spectrum on the right are just normal QPushButtons * the whole area above The spectrum is a tab widget which includes several buttons a table widget, spin boxes and checkboxes * and of course there is a lot of labels everywhere * the image and the spectrum on the right are created by using the pyqtgraph library 
I usually got a lot of thanks from users of my programs. But this one is actually the biggest in terms of functionality and user base. There is probably already more than 100 users around the world right now, which will hopefully happily cite the publication which just came out recently. I think programming good and useful scientific software is key for a scientific community and i always think that service to the community is more important than our selfish interest. Another important aspect of programming scientific software for me is that i actually only feel that i understood the technique after having written analysis software for it. It helps a lot to be able to play around with your data and not be limited by what other people had in mind... 
There is a lot of overlap, but I made my own because I wanted a solution that felt simpler to use that could also send output to multiple places at the same time. Additionally, and more importantly, I plan on adding things like built-in GUI support, so that if the user of the module is using a particular GUI framework, they can use modal/alert boxes (etc.) as an output method with almost no extra steps. But yes, in its current form, it's not an improvement upon the logging module for most people. Basically the plan is to support as many methods of output as possible. For instance, there will probably be support for things like Mac OS X's Notification Center as well. 
virtual environments (virtualenv) are extremely useful in python to ensure that you work with consistent sets of libraries/python versions and can easily replicate a particular set-up. On Linux this works perfectly and simply for me. On windows I could not get things working - e.g. python2 and python3 are distinguished in a different way in the windows world, and in a way that foxed virtualenv. 
It's my first time trying any sort of non-game programming so I started with a small simple app. It's not functional, just built the UI in QTCreator and exported / converted via pyuic... [It's a helper app](https://scontent-ord1-1.xx.fbcdn.net/hphotos-xfp1/v/t1.0-9/10984562_10205513185927095_5786055521893338028_n.jpg?oh=1eaed6ff91c1474ffa5e64b4b480becc&amp;oe=5652431C) for a board game called Isla Dorada. Eventually want to get it working on Android. My main concern is learning how to work with slots. QTCreator only seems to let you slot the entire QWidgetList, not individual QWidgetListItems, so I have to figure out how to do that in code.
I hadn't heard of this. I am writing a program that will need to display several graphs of data and was thinking of just using matplotlib. Is this superior, or overkill for just displaying some stats?
This looks really beautiful - I assume you're using VTK for the visualization part?
Plus the logging module makes it really easy to set different log levels for different parts of your code. For example, sometimes I want to turn on DEBUG logging for a very specific part of my code without getting all of the other statements. Also, [dictConfig](https://docs.python.org/2/library/logging.config.html#logging.config.dictConfig) is a godsend as far as configuring the logging.
Halfway down this thread and checked out every screenshot. Best so far by a long mile.
Awesome! It might be helpful to edit your question and put what you found in it :)
Haha true, more like a DoS 
You should have posted this in /r/learnpython or /r/pygame. Do you only update the radius and not the hitbox when a collision occurs?
Hmmm... Interesting default. It'd be easy to get Django to do this, but it strikes me as a little unnecessary and possibly insecure...
&gt; how can returning the singleton object None be the same as not returning anything? If you write a function that does not have a `return` statement, where execution falls off the end of the function, it's as if you wrote `return None`. That's how they're the same. 
Can you elaborate why?
That's a good point. I was hoping there was a book though. The closest thing that comes to mind is "Effective Python" www.effectivepython
What exactly would you add to the cursor.execute call to sanitize it?
[Application image](http://i.imgur.com/ykhAr9r.png). It was written with Tkinter Mine is from an application I made for my research. Basically allows you to take electrochemical impedance spectroscopy data text files, plot them, get polarization resistance value and plot those up on a figure. It's still in it's infancy, but it can generate publication quality vector and/or raster graphics, which is helpful.
You can correct people without being a jerk. We're here to help teach each other, not poop on each other when it's revealed that we don't know something or that something that we thought is true is actually incorrect. That's why it's called /r/learnpython, not /r/tell_people_how_stupid_they_are.
Django + Django REST Framework will give you the functional equivalent; however, you'll still need to do the work of creating the views/viewsets and updating urls.py.
Graphene islands (the lens shapes) atop a ruthenium crystal surface. IIRC that image is a ~50 micron diameter image of the surface. So the Graphene islands are in the few micron size range. 
Interesting! I'll definitely take a look. I can't say I have an terribly large amount of time right now to work on another project as I am in the midst of writing my dissertation but If theres anything I can do to help out I'll try my best. Cheers!
Definitely one of my favorites.
If you just want to display some stats, it may be overkill, considering GUI development is not so simple to learn.
sure it is in the github repository of Dioptas: [Dioptas QSS](https://github.com/Dioptas/Dioptas/blob/develop/dioptas/widgets/stylesheet.qss) 
I digg the dark interface Browsing this thread made be decide to put some actual effort into how my GUI looks more so than how it functions. I spent a good deal of time today reading up on CSS for use in custom styling UI elements in PyQt. In the process of converting mine to a dark styled theme
8 space indents? 4 should be plenty! Other than that, looks pretty good. I would consider splitting the main file into separate files, as others have mentioned. 
i think somewhere in the middle :)
A function without a return statement (i.e. *a function that does not return anything*) behaves in every way like a function that returns `None`. Not returning anything and returning `None` are indistinguishable; returning `None` is what happens when a function lacks a `return` statement, which is colloquially referred to as a function that does not return anything. That's what I said in my original comment, and all of my follow up comments. I don't know how to make it any clearer. You somehow feel the need to repeatedly tell me things that I obviously already know as if they are news to me or news to anyone that has read what I've written, as if you were correcting me and pointing out something that wasn't blatantly obvious from what I wrote. You are not contributing anything of value to this thread. 
I wasn't a jerk moron, I simply pointed out that he or she was talking in such a position that they'd have to stand up so that their voice could be plainly heard. What's the problem?
Oh, very good advanced perspective coaching! Bravo!
Here's a few from a small [personal project](https://github.com/achesak/weatherlog) of mine: [image1](https://raw.githubusercontent.com/achesak/weatherlog/master/weatherlog_resources/help/images/main_profile_example.png) - [image2](https://raw.githubusercontent.com/achesak/weatherlog/master/weatherlog_resources/help/images/general_info.png) - [image3](https://raw.githubusercontent.com/achesak/weatherlog/master/weatherlog_resources/help/images/wind_graph.png) Implemented in Gtk3. I generally prefer to keep the interface as simple and uncluttered as possible, with the data front and center. Not a big fan of extra styling and themes either, I just figure that the user's system can handle that.
Hmm. That's neat. That's also pretty large for graphene; what kind do you use?. What's the application, if you don't mind going into detail?
A swedish developer and I have been working for a while in a set of Material Design compliant widgets for Kivy. [This is what the Kitchen Sink app \(a small demo\) looks like right now.](https://imgur.com/a/omDip) We're still in alpha status but we'd very much welcome contributors wether it's code, bug reports or suggestions. Our repo can be found at https://github.com/kivymd/kivymd and the project is MIT licensed like Kivy. And yes, it runs just fine on Android, probably iOS too :)
Why not just use a Linux machine for development also?
You're going to have to be a lot more forthcoming with information instead of "it doesn't work". Go to File-&gt;Settings-&gt;Project Interpreter, click the green "+" button (Install), type in flask, select "Flask" from the list then click Install Package. If something goes wrong, give us screenshots or copy-paste the error message here rather than trying to interpret the problem yourself.
A "good" UI isn't necessarily one that looks pretty, and it's easy to add a bunch of icons and colors to make a UI look pretty when really you're just making it distracting or confusing. "User Interface Design for Programmers" is a good, practical design book that I recommend. *There should be one-- and preferably only one --obvious way to do it.* The more you can remove elements/messages, and hide the less-used ones on other windows/screens, the better. Otherwise you end up with a DVD player that has 30 buttons but you still don't know how to make it stop flashing 12:00.
Wow, this looks great. Nice work
I'm pretty terrible, but learning about iteration in lists was mind blowing.
Using a QTreeView with a custom model is the path to better performance I think. Just a thought. I learned the model view stuff largely from a YouTube series.
https://i1.creativecow.net/u/1027/esc_7_new.jpg pyqt4
Use the Python -c flag. See https://docs.python.org/2/using/cmdline.html for details. 
Winner
I've been putting off cleaning up duplicate tracks in my trakor library for ages... thanks!
I'm an aerospace engineer, so I mainly do structural analysis (FEA/finite element analysis) and aerodynamics. That GUI supports Nastran, Cart3d, Panair, Usm3d, STL, and a few other formats. There's an input file and a results file to most formats typically. Nastran is a super complicated structural format with horrific file format rules, but it also has almost everything you can possibly want in a file format (other than structured grid support) and plenty of places to store metadata. I also use it as a common format to implement all sorts of functionality (e.g. nodal equivalencing, surface area, volume, mass, free solid faces, boundary edge extraction) and just mesh convert between Nastran and what I need. It takes me literally an hour to parse some obscure mesh format and create a GUI interfaces so I can 1) validate my reader that I need anyways and 2) look a model. It's awesome for that.
Thanks for the tip! Im fairly certain I stumbled through that choice using the first thing I could get working. I'll definitely reevalute the QTreeWidget use when I resume work on it.
I just started learning to program two weeks ago (did a tiny bit in 2009 and BASIC back in the 80s when I was a child but besides that nothing) and came up with my first program a few days back for reading in other languages when I want to have it typed out in front of my eyes. After that comes the English translation. It still gets confused though since periods don't always designate the end of a sentence. Looking forward to being able to automate with more and more complexity though! I'm really enjoying Python so far. text = """Text in the language you are learning goes here""" engtext = """English translation goes here""" import time def printoriginal(): #prints the original text with a delay. j = 0 length = 0 while text[j] !=".": j +=1 else: while length &lt; j: print(text[length], end="") time.sleep(0.2) length +=1 print(".") def printenglish(): #prints the English text without a delay. j = 0 while engtext[j] !=".": j +=1 else: print(engtext[0:j], end="") print(".") time.sleep(5) printoriginal() printenglish() 
How are you getting segregation from an anneal given what you just said before (that Ru has high carbon solubility w/ temperature dependance)? Seems sort of counter-intuitive
Looks really nice !
really cool, but it makes my head hurt :'( I wish I understood this kind of programming better. 
Oh cool, thanks. I wasn't aware of that. Makes sense though.
&gt; if(deriv==True): OH GOD MY EYES!
I don't like GUIs, at all. So, I don't make them.
It's a little more verbose than what OP wants, maybe? $ python -c "print 5+7" 12 You could define a bash function that could glue it together. $ function py { python -c "print $*"; } $ py 5+7 12 This might not work perfectly in every case. Wrapping the expression in double quotes should fix that in most cases, i think. $ py 5 * 7 # * will cause bash file globbing :( $ py 5*7 # will print 35 $ py "5 * 7" # will also print 35 
Throwback? My whole world looks like this. So nice.
I'm a little confused about what you're asking, because rails doesn't really do what you're suggesting. Instead the `generate` command makes the appropriate entries in the `routes.rb` file. In django you have the same thing with `urls.py`, you just have to manually add them as it doesn't (afaik) have as good of a generator. The only real difference being the `resources` magic, which I believe django rest framework can equate to.
Using double equals in the manner the author does, the more appropriate way is to just to write "if deriv:". The original author is using (valid) C/Java style syntax in his/her code, but it's not considered Pythonic. Typically if statements should either be of the form "if blah" or "if not blah" or if an explicit check of the object is needed (i.e. verify if None was passed in), best practice is to do something like "if blah is None", and utilize the is operator (which has more concise semantics than ==).
&gt; it would be nice to have something a bit more magical. Some day, you too will maintain legacy code, you know. 
It's not bad per se but every Python style guide I've ever read discourages this and would instead suggest if deriv: Obviously style is a personal thing but *personally* to use no whitespace is bad enough, but to use the unnecessary brackets *and then compare to True* is just heresy.
Ahh, very cool! As I said, I'm truly just in the beginning stages of learning, but one thing I've really enjoyed seeing is when someone takes another person's code and cleans it, or simplifies it, in the way you just did. 
pythonpy. time to do your own dotfiles repo that installs stuff like this.
I'll take a look at drf, thanks!
This is awesome, and now I want to make a clone of something myself. I need to figure out wich one.
&gt; You can configure django to act in this manner. to do so you just need to wrap the urls.py declarations in some dynamic code. Look into how to the various ways that '_ _ import _ _' works. How would I go on doing this? Any examples would be very much appreciated!
Complete novice at creating GUIs, especially with Python, however I wanted to ask if I should use Tkinter for something as simple as displaying text? Basically toying around with reading the twitter stream, then displaying a tweet if it contains a certain word. The only thing I've ran into now is the threading issue. Not really sure about it, but basically need to connect to the twitter api, watch the stream, then update the gui with the new tweet, but tkinter of course works on the main thread preventing further code on the same thread to run. (I think?) So what should I do? Have a background/second thread which contains the stream code that will constantly be watching the twitter stream and adding a line when it grabs it? 
please delete this post then. it is spam
How are you "building" the script? Is this cx_Freeze or something similar? Are you using the same version of Python (2.7 vs. 3.4) on the Windows 7 and 8 machines? Are you running without a console? Do you have the same problem when running the script from the command line e.g. `python yourscript.py`. If so you might be coming up against an issue with STDOUT/STDERR filling up and blocking the script. Try redirecting the output to null at the beginning of your script: sys.stdout = open(os.devnull, 'w') sys.stderr = open(os.devnull, 'w') Note that you should do this before *any* output.
Thanks. I missed this functionality but forgot the name of the package.
You can also put i%3 == 0 in the parentheses, which should make it easier to understand. I just prefer ir this way.
It's bad in any c/java as well. Writing: if (deriv) { ... } is enough 
I ended up reinstalling a new version of winpython with python 3.4 which has pip and cython bundled with it. This fixed all the problems.
There are plenty of ways. Lambda as default argument, and guard value being the most common.
Definitely top of my list
That is something I'm still not able to answer you. All I know is that PyQt4 has threading capabilities (but I haven't got to that lesson yet). If it's just for displaying some text, it probably won't take you too long to learn it. Check out deusdies2 video tutorials on Youtube. [This one is about threading](https://www.youtube.com/watch?v=o81Q3oyz6rg&amp;index=13&amp;list=PLA955A8F9A95378CE).
You would have a point of it wasn't so fucking ugly. Look obviously we know that each person should use the style that works for their codebase, we're not idiots, but it's still nice to have a bit of fun because at the end of the day it doesn't matter. 
Wow, very impressive. I don't understand much about Kivy, but if I use this will it look the same on Windows, Mac and Linux?
&gt; cx_Freeze Nope, I'm just building in sublime text. I'm running 3.4 on both machines, and without a console. I will try running from the command line when I get to work today. Thanks!
Excellent thanks. I'm a huge fan of the ncurses lib. Simple, elegant, gets the job done. Having started with BSD / GNU/Linux in the mid to late 90's, it was often the best thing on hand. I still prefer to use Mutt as my mail client.
I'm a mutt user too! I tried to pattern the tasks client after mutt.
Heh, ya I know what you mean. that's what I found too when trying to learn. This was the most help to me as it uses actual data from various OpenData initiatives. https://github.com/jvns/pandas-cookbook
This seminar from PyCon 2015 was quite good. The databases you work with are IMDB's film/actor databases. http://pyvideo.org/video/3395/pandas-from-the-ground-up
That's correct. It looks the same on all platforms, with the minor exception of font rendering being slightly different according to each implementation, although I believe there's a flag if you want to enforce consistency.
Well, the real answer is to read some NN paper/blog post/textbook, but the short answer is that if your data is continuous and not in [0, 1] or [-1, 1], then you should scale it to that range first; and with categorical variables, yes usually you use one output for each category and the prediction is the output with the largest value. And the other answer is that this is purely for educational purposes and for anything real you should consider a proper NN library with lots of extra but necessary features.
I've never use it, I just use Django for now. But it's quite a famous python framework and I think it should be include in the comparison
I know it's just following some math conventions from print, but those are lousy variable names for code. lowercase y and upper X - just begging for a typo to introduce a lower-case x. also - "l1" . don't do this in your own code, kids. 
putting the activation function and its derivative in the same function does have a little sense to it: if you add other types of activation function later you will never have to deal with the error where you use the wrong derivative. so it's practical, but ugly
&gt; Django's sheer scale and functionality can feel clunky and bloated for small applications. I still don't really know what that means, it feels pretty subjective.
I will never understand how people get so far up their own ass that complaining something isn't 'pythonic' enough is the most useful thing they can think to say about a post.
I'd agree that it is the triple play, as Sean1708 showed, that gets me. I would have been sort of OK with just: if deriv == True: even though I know that "if deriv:" is better/shorter/more Pythonic. But the way it is written doesn't even look like Python at all.
if deriv was an in t in java we would get an error. C doesn't have a bool type so people use ints
OP, never use web2py
Might be referring to being overwhelmed by choice. Like if I want a simple site that has a button that triggers my dog to get fed when I press it because of a script on my raspberry pi, an entire ORM and all the function and stuff attached to making a site with Django might be overwhelming. EDIT: Lots of responses, I personally haven't used Django at all, but I think the idea is that you might not necessarily realize it isn't necessary if you don't know it well. Think about your first project with a python Web framework, you have a simple task or site or whatever, Django is pitched as having all kinds of complex functionality while Flask is pitched as simple. Can Django be simple? Sure, but is it as easy to be simple with Django as it is Flask? I don't know. 
The headline is not quite accurate...the first example requires __12__ lines of code, the first being: import numpy as np
Looks very modern for something made with Tkinter. Usually things look directly from 1995.
That's like saying Reddit is overwhelming because there are hundreds of reddits on there. You can just ignore those components.
Maybe it's the minimalist in me, but I have the mentality of "Don't need it? Don't have it." I know that I don't use every feature of every language/framework out there, but there's something elegant in simple solutions. (Also, getting away from ideologies, the node.js response time for something I described in my previous comment is way faster than Django. I tried.)
&gt; To be fair, if (bool == True): is about the ugliest line of code conceivable in Python. Broaden your horizons. There is [worse](http://swizec.com/blog/possibly-the-ugliest-python-ever-to-escape-my-brain/swizec/3661): map(one, zip(*[v['steps'][:entry['counts']['p']] for v in funnel['data'].values()]))
Do you have any suggestions on reading material for those of us that aren't interested in the matrix algebra/calculus behind the techniques, but more practical application? I'm about half way through "An Introduction to Statistical Learning" and absolutely love it. Any other resources would be great.
yes exactly it doesn't matter why would you create such hate for something so small when much bigger problems exists in the programming world.
I have been working on a native looking Gui for Windows 10. I like to make my GUIs just right. It is a wifi network selection GUI. So with that: [here is my gui (edited to remove sensitive names)](https://drive.google.com/file/d/0BxehjRdLgxoYUlR1MzhSSjBOazQ/view?usp=sharing) EDIT: Also, for those who are interested, I am working on a Material Design Widget set for PySide/PyQt4 (maybe PyQt5 in the future, and I will be supporting PySide for Qt5). [link](https://github.com/IronManMark20/Material)
I'm working through this right now. I like it.
What? _That's_ tkinter? I didn't know you could theme it so much. Very nice though.
So the first thing is to separate ALL of the points into 2 'buckets' (farmer talk for 'sets'?). How is this better than just calculating their distance? I am guessing that the data is presorted by angle. But that does not make sense either because you could presort by angle and radius as indexes in a sparse matrix for instant lookup. Mathematically you would have to remove duplicates to get a partition, but for product selection you really *want duplicates, maybe the same blades fit different razors.
I'll stick with storing my fake rest service json output in matched files and running `python -m SimpleHTTPServer [port]` :) Also I would have done something like hashify.me and you wouldn't need to worry about expiry. 
I actually coded one a few days back, and just for the sake of pushing discussion, here's my code... print 'Greetings user! I am program "Tipmate v.2".' print "My purpose is to aid you in determining the following..." print " I = Amount of bill with specified tip added." print " II = Amount each individual in a group is charged." print " ************************************************************* " print "First, enter the full bill amount." print " *Please include the decimal." print " " BillTotal = raw_input('Full Bill Amount? $') print "OK, I see that your full bill amount is $", print BillTotal BillTotalProp = float(BillTotal) print " " print "Second, enter the amount of tip you'd like to include with bill." print " *Please enter percentage as follows..." print " *5% should be entered as 0.05 | 15% should be entered as 0.15" print " *Notice: DO NOT enter the percentage symbol(%)" print " " TipAdd = raw_input("Tip Amount? ") print "OK, I see that you would like to give", print TipAdd, print "%" TipAddProp = float(TipAdd) print " " print "With the current bill total of $", print BillTotal print "And the added tip percentage of ", print TipAdd, print "%" print "Your tip amount is $", TipAmount = float(TipAddProp) * float(BillTotalProp) print float(TipAmount) print " " print "Your new grand total is $", GrandTotal = float(TipAmount) + float(BillTotal) print float(GrandTotal) print " " PartyNumber = input("How many people are in your current dining party? ") print "With a part of ", print PartyNumber, print " individuals, the cost is $", print GrandTotal / PartyNumber, print " per person." print " " print "Thank you for using Tipmate V.2" when I get around to it, I'll do a version 3 which fixes the improper decimal read out. lol I'm a beginner so sorry if this could've been coded in a better way with less code.
Well, that depends entirely on how they are presented, not on how many options there are. If the front page of reddit was a list of all the subreddits, you would deal with the problem of choice and potentially be overwhelmed. I don't know how Django presents all of its options, but that makes a difference.
... haha that's what minimalism is! If a framework has functionality that is not needed for the task at hand, then it is bloated. If it doesn't need it, and we can do away with it (i.e. making it from scratch or finding a simpler technology) then that would be the minimalistic approach: eliminate the unneeded functionality from the situation. Don't confuse minimalism with bare-bones. If it's needed, but complex, then it's still minimalist to have it in there.
It's somewhat common from scientists who've had a mixture of C/C++/Fortran.
It's terse but at least it does the job. The `== True` OTOH is often entirely unnecessary.
just use https://botbot.me/
its a django compatible bot, so you can store and view los logs with mysql
You could use it as a way to toggle code when debugging (as an alternative to commenting out a whole block of code). Not for production code though.
damn! they change the backend to golang :P sorry dude
What about asynchronous frameworks? 1) [aiohttp](http://aiohttp.readthedocs.org/en/stable/) 2) [tornado] (http://tornado.readthedocs.org/en/latest/web.html) 3) [twisted] (https://twistedmatrix.com/trac/) 
It's totally OK to explicitly check `if foo ==True`, especially for heavily re-used code and functions. It avoids cases where a bug passes a truthy but unexpected value and the bug propagates downstream. "Hello" is Truthy but will not evaluate equal to True.
As python developer I chosen ClojureScript/Reagent/Figwheel for web app. ClojureScript is better than JS Reagent is better than pure React Figwheel makes working with the previous two easy
`if __debug__` compiles conditionally.
Tornado was already suggested, any reasons why you like these frameworks? I appreciate the feedback!
For your normal, day-to-day code? Bitwise operators won't do you that much better. But once you get to decoding binary data, serial protocols and other interesting things, you _need_ bitwise operators to do their thing. 
I love python and use it daily but I have to say that this can already be done for you with little to no python. Sometimes it's more about using the right tools for the job. Logstash (JRuby) has an [irc plugin](https://www.elastic.co/guide/en/logstash/current/plugins-inputs-irc.html) and you can use filters, tags, and other analysis on the fly to store this into mysql, elasticsearch or even just stdout. Personally, if you are doing textual analysis I would highly recommend elasticsearch as your target output. There are great python bindings for it to perform searches and aggregations. With the additional meta you are able to add during ingestion of the messages you can perform more data analysis. If you must go full python stack for reasons not described then I give my +1 to /u/Kopachris and [Willie](http://willie.dftba.net/)(because it works too)
That was my thought - almost looks like something from WPF.
Not about Clack and Lucerne, but as pythonista I prefer Clojure )) For backend I use now python/pyramid but want to switch to clojure in the future.
Can I see some of the work you do in music? 
upgrade your Python installation, unicode literals were 'reintroduced' for compatibility in Python 3.3
&gt; maybe I only need a REST API, gotta learn Django REST That's not true at all. You gotta learn Django REST (I assume you mean django-rest-framework) if you want to build an API with Django Rest Framework. There's nothing about Django that requires you to use DRF to build an api. Return JSON from views, just like you would a simple route in Flask, etc.
It is not possible to kill (timeout) thread [1], there is no api for this. But I as far as I can see you are using threads for crawl purposes, for such task event bases solutions fit much better, checkout [2]. If you want to stay with thread pool, you should enforce timeout not on thread but on actural request, for instance: ```requests.get('http://github.com', timeout=0.001)``` [1] http://stackoverflow.com/questions/323972/is-there-any-way-to-kill-a-thread-in-python [2] http://compiletoi.net/fast-scraping-in-python-with-asyncio.html 
yeah the source is on github https://github.com/heltonalves99/quickjson
This comparison is referring to bootstrapping your app, not Bootstrap the front-end framework.
can you share the source? would love to know how you made it look so good
How does Django feel clunky?
You're right--what I was saying wasn't a counterpoint to the idea that Django projects have a much larger footprint. In fact, it's evident of the original statement that learning Django teaches you just Django. It's wrong that you have to learn Django Rest Framework to write a rest API. But that is indicative that how Django works is not immediately clear--because it's not obvious how one would do that, the quick reaction is to rely on some third party extension to the framework. So it's a misunderstanding, but that misunderstanding does stem from Django's complexity.
Unnecessary, but its function is clear. I suppose it's somewhat a matter of taste (and Python prefers to omit it). I wouldn't use `== True` myself, but at least it errs on the side of explicitness. 
For anyone who wants to know how to do this. Wrapping the entire for loop for futures in an exception still allows other threads results to process. Using two separate dictionaries, you can see which threads stopped due to a Timeout. with concurrent.futures.ThreadPoolExecutor(max_workers=20) as group_link_threads: for i in range(self.urls.qsize()): group_link_threads.submit(self.group_urls_task, self.urls) with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor: future_tasks = {executor.submit(self.crawl_task, url): url for url in self.requests.keys()} try: for future in concurrent.futures.as_completed(future_tasks, timeout=10): result = future.result() self.responses[result[0]] = result[1] except Exception as e: print(e) timeout = [url for url in self.requests.keys() if url not in self.responses.keys()] print('URL Threads timed out: ', timeout) I have to point out that this goes against conventional wisdom. Typically if you wrap an entire for loop in an exception, anything after the exception in the loop should not process but the magic of futures seems to allow everything in the loop (except for the thread that timed out) to process.
It is possible to timeout threads when using futures. Posted response for it.
fair enough. it requires some more engineering, so good luck hacking on the perf source or convincing someone else to do it :-)
About Flask being not async-friendly: gevent kills that con, hands down. We use both in production (running under uWSGI) for hundred of thousands of requests per second, and our CPUs are sleeping.
Wouldn't Django be the opposite of "overwhelmed by choice"? Given that everything has already been chosen for you. Also, see https://github.com/halfnibble/django-light
That's unrelated. When you're debugging/prototyping code you sometimes just want to toggle pieces on and off manually to compare things (or to understand out what's going on).
What would be the reasons it's your favourite?
It's not entirely a matter of taste though, as they mean different things. `if x == True:` is a strictly stronger condition than just `if x:`.
That's interesting, didn't think about that. Thanks for the suggestion.
It's important to know that [Odoo is moving towards proprietary licensing](https://www.odoo.com/fr_FR/blog/odoo-news-5/post/adapting-our-open-source-license-245). That might affect your choice.
Small, simple, does what I want and not much else, and felt easy to learn when I transitioned away from web.py
Yes, but all new and shiny modules from v9+ are going to be propretary (that is why they're changing the license).
A "whole project" of five files: the `__init__.py`, django.wsgi, and manage.py files that you don't need to edit, as well as settings.py and the urls.py files that you do need to edit. That's the entirety of what's in Django's default project template: two editable files, one for declarative settings and another for code.
Because Django does "a simple page" just fine, with no bells and whistles, no framework in sight. The only mandatory thing in Django is the URL resolver, everything else only comes to existence after you explicitly import it.
Lambda *x: !! Wtf
It's usually people who don't know that they just need to comment out the apps and middleware they don't need in settings. A Django project can be one file and all it does is route a request to a function. As "light"as flask or whatever.
Why not?
Why no cherrypy?
It depends on how loosely you're willing to define 'type' in C. There's stdbool.h which defines a boolean type and is practically a sin to not use in a production environment.
No CherryPy. :( I've been building a small app over the past week or so, and I originally wrote it in Bottle, because I'd built some REST apps in Bottle before, and it had been a fairly fun and simple procedure. Then a couple of days ago, I just got so fed up with how unorganised everything was that I gave up, copied all the templates and static files into a new directory, and rewrote the whole thing in CherryPy. It took, what, a day to get to the same functionality, two days to add a bunch of features that I had been shying away from writing. I haven't really played around with these sorts of things much, but to me I love the fact that CherryPy feels more like a library than a full framework. I build the app how I like it, make sure it exposes an API somewhere that CherryPy can understand, and then put one inside the other. I mean, sure, it's still very definitely still a framework when I need to be aware of threads and how it will go about running my app, but in terms of actually sitting down and thinking about how the app should look on the inside - I feel completely free to do that exactly how I want.
This problem (and probably solution) is not just inherent to Flask, but all WSGI framworks such as django and pyramid.
ITT: Nitpicking. Nitpicking everywhere. 
Would it be worth adding webapp/2? I know it's mainly for GAE but could be worth including to get a general consensus on the pros and cons.
I guess it depends on familiarity. I can make something in Django faster than learning something else, and maintain it much easier. But I work with Django fulltime.
According to pypi Flask hasn't been updated in over 2 years, is it still good or is Bottle actually better for small projects?
I think most of the 'Django is bloated' crowd don't use Django and are just repeating something they heard someone else say and it makes them feel elitist. It always reminds me of Fred Armisen yelling 'Whole Foods is Corporate!' in Portlandia. Django is fun, Flask is fun, Rails is fun, node.js is fun, everyone have fun!
I don't see why you would need the ORM either. dogpusher/settings.py INSTALLED_APPS = ( 'dogpusher', ) views.py from django.http import HttpResponse from dog_pusher_pi import feed_dog def dog_feeder(request): if request.GET: feed_dog() return HttpResponse("fed your dog dude") urls.py from django.conf.urls import include, url from dogpusher.views import * from django.views.generic import TemplateView urlpatterns = [ url(r'dog_feeder^$', views.dog_feeder, name="dog_feeder", url(r'^$', TemplateView.as_view(template_name="dogpusher/index.html"), name="index"), ] templates/index.html &lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt; &lt;form action="dog_feeder"&gt; {% csrf_token %} &lt;input type="submit" value="FEED DOG" /&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt;
I was not aware of that project, thanks for the link. It claims to have MD's overscroll behavior, so there's something we don't have, I might have to give it a try and talk to the author :D.
aiohttp is asynchronous, and supports web sockets out of the box.
That's basically my point. Being a zealot about one framework (or even language) is a bad idea.
The experience of writing a REST API in Django using only the bare minimum is the same as writing a REST API in a microframework. The experience of building a REST API with Django and django-rest-framework improves on both.
I work in company making Odoo ERP's for clients. Odoo is very hard comparing to Django and Flask. It's completly not pythonic with poorly written modules by different people with different skills. It's full of bugs after clean installation and it's very heavy. It's hard to fully understand what's going on in the code in case of some modules. I don't recomend this system for implementation in small company if You don't have team of programmers.
Not python, but libtickit is a C library that you could call through cffi.
Here's a [wxPython multi-user catalog management app](https://imgur.com/a/FpHjZ) I made for an evil company, circa 2003. It never made it to market, but it's some of my best work: * Image editor with undo/redo, custom icons, custom algorithms, * Multi-user synchronization, * Client/server hitting a perl backend, * Dynamically generated user interfaces for editing product information.
Yeah, who needs an operating system anyway? x86 talking directly to networking hardware on bare metal or bust! (Obviously there is a sweet spot, but advocating for everyone to learn from first principles is kind of ridiculous. It's why people make frameworks and tutorials.)
Came here to say serial protocols. Say you wanted to send a byte with two fields, one in the upper nibble and one in the lower nibble: def compile(msg_a, msg_b): return chr((msg_a &lt;&lt; 4) | msg_b)
Django REST framework does lots of sophisticated things, like * pretty views of your API endpoints if you visit them in a browser * providing helpers for converting django Model objects to their JSON representations * — and applying updates from a REST PUT to be saved back to your model * this includes objects that may be composed of other sub-objects * views that apply to lists of objects, including pagination, i.e. if you have an API that may return 1000s of results but you want the client to be able to ask for only 50 at a time * rate limiting * API authentication ...basically a ton of things that aren't *necessary* for a minimal API, but if you start building out a REST API for a lot of objects you're going to be writing a lot of code that looks very much the same for many of the views, and that's the code that's gone in to Django REST framework.
Store the GPS data in some sort of format that can be opened by QGIS. It has Python plugins. You can export to ESRI shapefiles, or use something like spatialite
You could at least explain why ? I'm not particularly fond of FRestful, I mostly use it for the api manager features, not the serializing stuff (using Marshmallow for that). 
I guess many backtesting platforms are popping up now because it is easy to write a backtester for your specific trading strategy in 30-40 lines of Python code in an IPython notebook. Then add more feats, clean it up and document it - ready is the backtesting platform. I learned the hardest part is to actually get useful data, not writing the algo / the simulation, in particular when you aim at fast responses ( &lt;&lt; 1 minute ) to the market, not just the daily open, close, high and low. This is a problem also because you begin to censor your algorithmic creativity and steer your search in a certain direction. 
So you do not half ass reinvent the wheel that has already been worked on by thousand other experienced wheel builders Frameworks are useful for providing structure and for following or adhering to standards: I want to spend my time working on my app, not the generic bullshit that everyone else has already figured out Throttling, pagination, caching, authentication, out of the box UI, serializers, and a hundred other things I get for free by people who are far better at those things than I am
Oh man, that was fun. Got to document a few of my pet peeves.
ffplay prints that stuff to stderr, if I remember correctly. So you'd have to read from there, best using Popen for that. from subprocess import Popen, PIPE proc = Popen(['ffplay', …], stderr=PIPE) chunk = proc.stderr.read(1234) The play info lineendings use \r though, not \n. So you have to consider that.
Blurry and from 2011
The Flask github repo looks pretty active still: [https://github.com/mitsuhiko/flask](https://github.com/mitsuhiko/flask)
Any tldr for people who don't have time to watch the whole video?
It's a step-by-step tutorial. A TL;DR doesn't make sense here.
Within the time in between your two comments, you could have watched the video yourself. Or added it to Watch Later and watched it later. 
They are getting ready to release a 1.0 version which is likely why they have been quiet outside the repositories. 
Thank you LP, your information was a great help. I managed to take your information, and figure something out, and now I have something working
That's not real time. I really wish web devs would stop hijacking that term; it already means something else. 
Great! I like this explanation a lot. Thanks.
I'd love to try kivent. But for m the biggest hurdle is a complete lack of tutorials. I have never used Kivy nor kivent and i really can't get started without a bit of help. Maybe a few simple tutorials for the following will help kickstart things: * Pong * Bricks * Isomtric map * Basic Platformer I will try to get pong and Tic-Tac-Toe running but i really doubt i understand kivent to even reach that point. 
OP's (and video's author) clarifies this at the beginning of the video. You're right that it's not "real" real time, but I'm afraid you're fighting against windmills here. In the web context it's more or less accepted that "real time" means "seamless and close to real time communication".
But is there valuable content hidden within??
Here's the problem I have with that. If I go into a code review and start calling constructors factories and factories constructors, people will rip me apart. We, as developers, develop a common language for a reason. When you start trying to change the meaning of words to make yourself sound like you're doing something cool, it just muddies up the language. 
I recently used flask for a private project, and it was really nice. No experience with Bottle, though. Made a REST-API with SQLite on a raspi with gunicorn and nginx. They have good tutorials on the flask site.
&gt; most python packages are not async compatible I use tornado. Do you want the option to run code, *any* code, in the background so the server is free to respond to other requests?
I think I just watched a 25 minute video that was a table of contents for a talk and the demonstration of a Bloom Filter
That's great! What API are you querying? Are there rate limits? Can you get options chains?
Good summary, but one nitpick: If you're writing it "Postgre", there's a good chance you're also pronouncing it "post-gray", which isn't correct. Postgres takes its name from a previous project called Ingres, pronounced like the word "ingress".
"Connection limit exceeded for non-superuser". Downvote. This is a misuse of technology. Use nginx push module instead.
Try Qgis. It has python scripting. Also you can use this: https://github.com/python-visualization/folium 
Good summary. Thank you!
It's pronounced "post-gress"
The app has a 'wsgi_middlewares' setting that accepts a list of middlewares and the config to feed to them. This is where I'd recommend setting up anything like authentication, sessions, etc.
here you go: http://hastebin.com/uvemigoguj.py
Yes, the 's' is invisible.
Looks like the CNN money API. 
Thanks!
i have to sign up ?! .. nope.
Probably you missed the point, even if your future is timed out this does not imply that your thread timeout. TimoutError is raised in executor thread not in worker thread. Your worker thread still there and waiting for response. Try following: setup ```max_workers=1``` and put ```time.sleep(100000)``` in your ```self.crawl_task```, you will not process anything even with future timeout.
i upvoted you because your comment is relevant, but i think still inaccurate. We, as **web** developers, have a definition for real time. There exists jargon in each distinct field.
Thank you. I'm glad that we can politely disagree. 
What happens to the thread when the future times out? Also what will happen when you run through the ThreadPoolExecuter again?
Nothing happens at all, there is no api to stop the thread. When finally thread handle request and proceed to point where it has to set result into future object, you should see exception since future was cancelled due to timeout or something. This thread just occupy place in ThreadPoolExecuter, no new tasks assigned to it. When long request has been done, regardless future was cancelled or not, thread will be ready to take new tasks. Future is nice way to signal that work has been done or exception occured, it is not the means of thread management.
What software is used [at 29:00](https://youtu.be/PsorlkAF83s?t=29m) to generate the flow diagram? Manual or Automatic, I'd love to know. Thanks
See also: https://www.reddit.com/r/django/comments/3di73h/wagtail_10_a_milestone_release_for_our_django_cms/ and https://news.ycombinator.com/item?id=9896873
Thanks, looks great, not sure how I missed this one!
No. Learn how to format the code. Posting screenshots of code is not allowed.
Hey, I'm sorry for the inconvenience. Could you explain how exactly it's unreadable and what phone are you using? Thanks!
Yeah. It also look like you copy and pasted the link from python weekly news. They are just basically posting reddit articles.
/r/learnpython
Thanks, looks good. Just built and ran the examples. Had a little trouble at first because I was trying to run inside screen, but running `TERM=xterm ./demo-xterm256` gets it working. This worked as well on a rxvt unicode 256 terminal... I wonder if other terminal support is that easy?
I didn't even know this podcast existed. Thank you!
The only reason they bothered was so that they could use it for `**kwargs`. The documentation is confusing on whether that part actually landed or not though.
I installed PyQT5 yesterday on a Win 8.1 box and QT Designer is on the start menu for me.
What about bokeh though ? I think you can create dashboard with it as well.
Correct. Bokeh has some cool stuff coming up too like Ggplot like plotting API and ability to plot large out of core datasets using blaze. 
indeed i was what i did =\ 
Check out [Pushy Postgres](http://pyvideo.org/video/2842/pushy-postgres-and-python) from PyOhio last year for more info on LISTEN/NOTIFY.
Typo in the introduction: text refers to a variable "num_of_accounts" and the variable name is "num_accounts". 
Just watched it after hankering for it all day. Very nice. It's good see everything stripped down to the bare minimum instead of having every 10x piece of software thrown at a problem. To be curious, what was the inspiration for this? And have you used this style of real time app in production, or was this more of a toy example to explore possibilities?
this seems like the flimsiest shit on earth, I hope I am never responsible for something like this.
You mean use it as the data sink for `**kwargs` as opposed to a regular dictionary, or use `**` to explode the structure? Because the latter is already possible. Edit: I'll note that to explode something with `**` you do need to extend `collections.abc.Mapping` instead of just implementing the interface (which is annoying).
I thought that's what you meant, but I wanted to be sure.
why is that useful?
`foo(a=1, b=2, c=3)` loses it ordering now (assuming `foo` is implemented using `**kwargs`). It would be nice if you could get it back in the order its called when you want it.
Especially when you search by (x,y) coordinates; tags I understand, but xy's can change for many reasons
cx_Freeze is your answer, my friend.
looks pretty neat but I would recommend using pandas and their wrapper of the yahoo finance api. you do a query with the ticker and date range and it gives you back a well formatted dataframe that can easily be further analyzed
The ideas there were born from frustration after having built apps like this on top of Django. They're in production now in Mettle, an ETL scheduling/retry/visibility framework that we've open sourced at work. https://bitbucket.org/yougov/mettle
Thanks your information.
Yes, I use CNN money.
This is great stuff. Take an upvote.
You can easily install using pip. pip install pyprice
Does it have to be in specific folder for that to work? It always says command not recognized 
How do I check? 
Cool, thanks for the information!
thanks for that spot
Thanks for this - looks well written and easy to understand. I liked the the TypedProperty class on page 70 - looks useful in some cases (config modules where developers set up complex parameters - strings, lists, etc). 
Wow: Netflix accounts for """approximately 35% of all network traffic on the entire Internet! """ Chaos Monkey at 35 minutes is absolutely crazy... Netflix is always hiring... I didnt know they were in Los Gatos. 
happt you liked it...more content to follow
Investigate SQLAlchemy for ETL tasks. Over the years I've been using the ORM for all kinds of data reshaping tasks. There is a performance penalty of course but my transformation code ends up being nicely succinct.
it is included in both PyQt4 and PySide installers 
If you're building a database-backed content management system of any sort I suspect you'll be better served by Django — that's pretty much it's core competency.
Hopefully they backport that
Thanks ')
Rushabh from ERPNext here. I recommend you try out one full cycle from sales to manufacturing before making a decision in both these applications. It will give you an insight. /u/nahrub has added great points. ERPNext has [developer tutorials](https://frappe.io/tutorial) and [KBs](https://kb.frappe.io) to help you too along with a [helpful forum](https://discuss.erpnext.com)
Thank you for the pointer. The pep contains a few use cases I was looking for as motivation for this change.
In generalities: Mezzanine tries to replicate Wordpress and does a great job of it. Wagtail is different in its approach and is better suited to larger websites with more complex requirements than Mezzanine would.
Soooo many classes :o
One for each frame :p just look at the **Navbar** class thats the most interesting thing :)
I wish they could avoid making it compulsory to use Flask. I wouldn't mind trying it with a CherryPy backend instead :)
How else would you do GUI automation? I've actually been looking for libraries to do some python GUI automation so I would be thankful if you could point me in the right direction.
&gt; SSIS is terrible compared to what ? 
I have automation script that kicks off ssis jobs
yeah, compared to what? I have been using it for the last 10 years (including other ETL software and python alike) and never had any issues with it. Can you pls elaborate? 
Because I myself don't like being downvoted without anyone giving a reason: This is simply a configuration issue. He makes that and several other things very clear beginning from [14:08 in the video](https://youtu.be/PsorlkAF83s?t=848). And how can it be a misuse of technology when it's implemented in PostgreSQL itself? Unless there's a compelling reason why PostgreSQL shouldn't have done that. Also, googling for *nginx push module* returns at least 2 different module, you should really be more specific.
&gt; **(**just**)** FTFY Also, it says *Real Time* **Web** *Apps*. As /u/kurashu89 already said, how else would it work in the browser? But the client-side part doesn't matter at all here anyway.
If you're on Windows, you can get a wheel archive here: http://www.lfd.uci.edu/~gohlke/pythonlibs/#pyqt4
You may want to also post under https://www.reddit.com/r/ETL/
I could pretty much accomplish the same thing with shell scripts, would you say it is a configuration issue? Just because something is possible it does not mean it should be implemented. And, this has no implications about using a given solution in production. Amounts of amentia in comments both here and in /r/Django are astonishing. This thing. https://github.com/wandenberg/nginx-push-stream-module . Just check who's using it if you're interested in mature technology. Unless you're a boy looking for toys. In this case, let's implement pubsub as a kernel module using devfs, because that's possible, too. 
There is sikuliX http://www.sikuli.org/ but it can be slow at finding things and you can't use your mouse or keyboard while it's running. 
Well if your messages have the same quality as this contribution than its a quality issue. (I mean seriously you have just asked us about why authors in general don't reply to you. What authors? What projects? What bugs?!)
Yeah, this is a 21st century thing. I've been in Open Source for a horribly long time - and people have a very different attitude towards maintainership/authorship than they used to. Partly this is likely due to the wild fracturing of the toolset - it used to be e-mail and mailists, and even if it was not perfect it was coherent, linear, and focused. Now Open Source projectdom is a crazy array of forums, and tools, and websites; one never knows which tool is the current 'vogue' and actually has someone paying attention to it. Often it is even very difficult, in an era of DVCS, to discover which fork/branch is "main". Sadly this is just life now.
lol. One explanation explains simple operator precedence, and another uses assembly code and lambda. I love stackoverflow.
Your e-mail is probably filtered out and never even seen :(. Oh, I guess gmail people call this 'labeling' now.
Can't you put the one line patch in for yourself, at least?
I'm not really an expert on scikit-learn, but I know there are a ton of good videos from SciPy on youtube (2015 videos were posted recently) focusing on what you need. * [ML with scikit-learn](https://www.youtube.com/watch?v=L7R4HUQ-eQ0) * [SVM tutorial with scikit-learn](https://www.youtube.com/watch?v=KTeVOb8gaD4) * [Neural Networks demystified](https://www.youtube.com/watch?v=bxe2T-V8XRs)
 &gt; If you want to build a list, and if it’s built on an iterable that already exists, then I’d say a list comprehension is almost certainly not going the be the best bet. But if you want to execute something a number of times without creating a list, then a comprehension is the best way to do it. Few lines later completely opposite statement: &gt;If you want to execute a command numerous times, use a “for” loop. If you have an iterable, and want to create a new iterable, then a list comprehension is probably your best bet. 
yes I did. I just want his "blessing"
well the last upload was 12/2014 Looks like business is good: Downloads (All Versions): 882 downloads in the last day 4087 downloads in the last week 32974 downloads in the last month
huh ? I just want his opinion if it's the right way to do it. Is that too much to ask ?
[Hello World!: Computer Programming for Kids and Other Beginners ](http://amzn.com/1617290920) Amazing book! well worth it. [Code: The Hidden Language of Computer Hardware and Software](http://amzn.com/0735611319) *Edited to add clarification* *The Hello World Book teaches in Python (2.7 to be exact) *The Code book is great for machine language theory and binary basics.
 **Machine Learning in Python: Essential Techniques for Predictive Analys...** (6% price drop) |||| --:|:--|:-- Current|$38.10|Amazon (New) High|$47.50|Amazon (New) Low|$38.10|Amazon (New) ||$40.72|(30 Day Average) [Price History Chart and Sales Rank](http://i.imgur.com/7gfr0ej.png) | [FAQ](http://www.reddit.com/r/PriceZombie/wiki/index) 
Cherrypy is indeed awesome. It depends on how deep its integrated with flask, it might be easy to replace the backend
I've built multiple very large &amp; high volume ETL solutions for big data warehouses using Python. Right now I'm processing a couple billion records a day with it, anticipating getting to 20-100 billion a day eventually. It works best where: * you have high volumes and don't want to pay licensing costs for ETL servers or additional database servers. * you want to distribute some of your extract processes onto multiple machines, colocating them to keep extract times to a minimum * complex transforms that are a nightmare with an ETL tool * complex aggregations that aren't generally possible, or are painfully slow with a database * you need to interface with new libraries, services and frameworks too new to be supported by an ETL tool * you already have good programmers * you want the most code reusability * you want test-driven development, or at least high coverage of unit-tests ETL tools generally simplify the easiest 80-90% of ETL work, but tend to drive away the best programmers. So, that leaves you kind of screwed for that last 10-20% of ETL work. Python allows you to do the entire job and keep the best programmers. About the only time I would stick with an ETL tool is when it's already a department/corporate std, you've got a huge pool of developers experienced with it, and it meets your performance needs at a price you can afford. EDIT: added a few items to the list and removed changed data capture, since it didn't fit on that list. 
I think it's important to point out that *Reddit* is already an open source version of Reddit. It's on GitHub and everything. Also that you would be a bit late to the party. I'm guessing about 1000 Reddit alternatives have sprung up in the time it took for me to type this. 
I think for someone starting out its easier and quicker to understand and implement a very simple 'hello world' app in flask 
As much issues as their having with the actual reddit... I'll pass. I just enjoy learning from you genius's (no sarcasm, I learn daily just surfing this site) and laughing at funny threads. no need to fix something that is~~n't~~ broken
No I mean as in being part of the big machine that says that post-modernism refactoring of other peoples works is disallowed - don't like cool aid.
More syntax to read doesn't really feel like a win in developer performance to me. I'll still end up needing to learn the library or API in a complex system. Now I'll need to identify type. When I change type (because, if anything, you can guarantee change), I'll end up having to perform maintenance on type hinting. I'll have to add type information to my tests and then maintain those as well. I may even need to expose the type information in my documentation and maintain that. And one of the reasons I probably picked python was the lack of syntax, so I could prototype faster. No, I don't really feel that type hinting improves performance as a developer. 
No pip distribution ? 
A documentation and a python3 version and an installable version would be interesting
&gt; Thanks for the suggestion! Yeah, I know scikit-learn is very user friendly I feel a little stupid asking this question, however before buying a book I feel better asking advice. &gt; &gt; &gt; &gt; Well maybe I overstated the problem, I already use SVM and a couple of algorithms from scikit-learn and do things like pattern recognition, number recognition and basic things like that. However, I feel that for my way of learning, a book explaining in detail each step would fit better and help me with improving my way of using scikit. 
Checking for a HTTP 200 response isn't at all indicative that the website is fully up. It could be showing an error page that says "This website is down", but the page itself was delivered successfully.
No "why this is better than requests"?
Yeah that's true. But in that case checking for custom error pages will be just too subjective task.
That's quite a difference!
Why do you have `website_up` and `website_down`, and the same code in each except for return value? This violates DRY principle. You probably want one function (`website_up`) and then if you want to test for down, `if not website_up(...):` when you call it.
Started listening to this podcast recently. It is well worth the time as the episodes are not too long and are focused well. It doesn't hurt that the intro/outro music is catchy.
Too bad they messed with the scrolling
No tests?
Yeah, I agree. Will update the package asap. Thanks for pointing out :)
&gt; http://imgur.com/u2nm3Mz Great. I love npyscreen. Pity the docs aren't great. I might do a tutorial series on it.
Me also. I saw something like this years ago. "Why have you down voted my perfectly good answer". "It's not the one-liner the OP asked for".
I like you
Honestly if you know matrix algebra, I believe it is much more useful than "thinking like an accountant". Also, using your Excel example, why not think like a data analyst? Or like a really good receptionist? Other than that, I think this is very good information for intermediate or beginner python coders. I wouldn't imagine doing this for my kind of work without using numpy but here you have strings and such.
Why not something like https://www.freelancer.com/#vw or the plethora of other sites that offer the same?
 if (sum(code) % 11) == 0: # valid else: # invalid
&gt; you have high volumes and don't want to pay licensing costs for ETL servers or additional database servers. How do you speedily process high volumes of data in CPython? &gt; you want to distribute some of your extract processes onto multiple machines, colocating them to keep extract times to a minimum Are you using Luigi or Airflow? What is the your multiple processor programming tool of choice in Python? &gt; complex transforms that are a nightmare with an ETL tool I used Ab Initio for 1.5 years. It could handle everything I could throw at it. When it couldn't I could write a component in Python. &gt; complex aggregations that aren't generally possible, or are painfully slow with a database This sounds like another vague generalization. With Ab Initio, you stream data out of the database immediately so you get maximum in-memory parallelism with the graph. &gt; changed data capture using file-images I dont know what you mean here. It doesnt make sense. The initial part of the sentence is: "It works best where" and now you put this. &gt; About the only time I would stick with an ETL tool is when it's already a department/corporate std, I was very happy with Ab Initio. I cant imagine getting all the features I liked about it in Python easily (automatic parallelism, functional specification of data processing, visual monitoring of graph in realtime). 
This is actually a pretty difficult problem to solve I think. It may sound as simple as counting the number of pixels that are the sun and dividing by the total number of pixels. But in reality, determining whether a pixel belongs to the sun could be incredibly challenging. Are the pictures of the sun taken from earth or space? 
I think you forgot to remove ":" character from links, none of them is opening w/o removing ":" character.
SQLite is a separate C library. You'd have to upgrade that to a version &gt;= 3.8.2. Assuming the Python module is dynamically linked against SQLite, then that should be all it takes. In [1]: import _sqlite3 In [2]: _sqlite3.__file__ Out[2]: '/usr/lib/python3.4/lib-dynload/_sqlite3.cpython-34m-x86_64-linux-gnu.so' In [3]: !ldd $_ linux-vdso.so.1 (0x00007fff61b5a000) libsqlite3.so.0 =&gt; /usr/lib/x86_64-linux-gnu/libsqlite3.so.0 (0x00007f438e2e8000) libpthread.so.0 =&gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f438e0cb000) libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f438dd22000) libdl.so.2 =&gt; /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f438db1e000) /lib64/ld-linux-x86-64.so.2 (0x00007f438e7c8000) This is showing that the C portion of the Python `sqlite3` module, which is named `_sqlite3` (which corresponds to the dynamic library `/usr/lib/python3.4/lib-dynload/_sqlite3.cpython-34m-x86_64-linux-gnu.so`) is in fact dynamically linked against the SQLite dynamic library (`/usr/lib/x86_64-linux-gnu/libsqlite3.so.0`). I assume the case is the same on Red Hat, but it's statically linked in other contexts (e.g. the Windows installer), so in those cases you'd have to rebuild the Python module, which means rebuilding Python itself. 
There is this one as well http://podcastinit.com/
Wow this is awesome, thanks. pythoscope's promised utility was in dynamically generated tests... but doesn't really work
&gt; so what you are saying is that I will have to compile python3.4 from source now that I have the new version of sqlite installed? No, that's not what I said at all. That would only be necessary if the Python `_sqlite` module was statically linked against the SQLite library, which I doubt is the case for Red Hat. Assuming the new SQLite dynamic library is the dynamic loader search path ahead of the old one (e.g. `/usr/local/lib` ahead of `/usr/lib`), then you should be done. Open the python REPL and type these: &gt;&gt;&gt; import _sqlite3 &gt;&gt;&gt; _sqlite3.sqlite_version '3.8.7.1' 
Try simplecv.org
While the docs may be lacking, I remember the author of the library being super accessible and responsive when I wrote this a year ago.
yea the title said (just), not "just", do i need to explain the different meaning between using parentheses and double quotes on a word ? Really ? &gt; how else would it work in the browser? Oh i dunno, i guess when someone says (just) python i expect to see some library/tool/whatever being used in which you write in python and you get it transpiled to JavaScript ? Ever heard of those ?
I strongly disagree with this approach to programming. If anything this is exactly what is wrong with how many people are suggesting the "correct" way to use Python which is to get very fancy and show off how well you can Python. Not how well you can program. For instance a simple factoid with programming is that you are almost always turning a process of some sort into code. Thus: [number * number for number in range(5)] Is almost certainly three processes. First is that there is a list of stuff. That is a step. Then you take that list and do something else to it. That is another step. Then you print the results which is another step. But this code turns that into a single step, plus forgets the printing step. But that is not how our brains work and almost certainly not how the original process being translated works. But most importantly things change. The list of things range(5) might very well suddenly drawn from something different or the squaring function might become more complex. Or the printing step might become more complex. So maybe it needs to cube the even numbers. Or it needs to only print the odd numbers. Suddenly when this code needs to be modified all three steps have been packed into one. So whomever maintains this code will need to tease out the for loop style function from this "elegant" bit of code. But then the guy says even intermediate programmers will use numbers = range(5) output = [ ] for number in numbers: output.append(number * number) print(output) and then says [number * number for number in range(5) ] is so much more elegant. Yet already he is cheating because he left out the print step. print [number * number for number in range(5) ] But wait maybe printing isn't the only thing that they wanted to do with the output so now we have blech=[number * number for number in range(5) ] print(blech) Which isn't actually that much more elegant than the original "amateur" code. If anything I would say that the original amateur code is exactly what humans want to see. What I love about Python is that as people have repeatedly pointed out that it is like writing Pseudo-code that actually runs. Nobody writes: blech=[number * number for number in range(5) ] print(blech) as Pseudo-code. Then his comparison to SQL is just terrible. Easily the worst code I have ever written in my life has been SQL not because I am an asshat but because the stupid databases seem to prefer in many cases that you pile up the inner joins and whatnot into a single evil statement instead of breaking them out into something human. I can ashamedly say that I have written SQL statements that replaced nice clean SQL that ran in 30 seconds with things that I could barely understand what I had just written but ran in 30ms. Thus I had an excuse. Needlessly using comprehensions is not often excusable. My C++ could be peppered with inline ASM which would certainly make me more than an "Intermediate" programmer. But it would also make me a huge tool. Now as a complete counterargument to what I just said but one that will have to probably wait until python 5 is that when python can inherently use the GPU or at least have ready access to the multiple cores in a CPU then this sort of code will probably become the only way to go as it will then throw the entire thing into the 3000 streams on the GPU and be done in a flash. But today, nope. Oh and for mathematicians who already rewired their brains this way then go for it. 
No reply that is actually a joke? 
Blaze sounds interesting. I already love how easy Numba makes it to accelerate numpy. Haven't tried Blaze myself though, anyone have any thoughts on it? 
I use [Robot Framework](http://robotframework.org/) for UI/API testing. If the UI developer has made it easy and include usable css tags it'll make UI automation easier otherwise you would have to use xpath or stick with an ugly css locator. It has built in keywords and if not you can write some python for what's not there.
you can do: pip install https://github.com/tweksteen/burst/archive/master.zip
I'm embarrassed that I missed this. Thanks. 
Why someday? If you have a computer and Internet, you can be one today.
haha, nice
Excellent. Now I'm kinda curious about swapping Python for Haskell, and maybe do some plain JS rather than all that prettiness, for some real terseness.
You really don't need to know any of that. It's more statistics than algorithms. 
I didn't realise bokeh had this functionality. I will check it out. Thanks!
 if result - int(result) == 0:
and do let me know once you do it :)
:(
I've been streaming hackerrank challenges and "advanced" projects (writing a compiler, distributed p2p cache, data processing, etc) in Python. Might be your style? http://twitch.tv/bvande
It depends what you want to display on it, you certainly could build something using Python.
I know he isn't, that's why i called the title misleading, you wanted to know with what 'magical trick' you could get real time with python in the browser so i answered you that.
Thanks! My mother loves me again because of this!
&gt; I'll still end up needing to learn the library or API in a complex system. Now I'll need to identify type. And now your IDE can help you, rather than essentially just guessing. &gt; I'll end up having to perform maintenance on type hinting Well sure, the same as if you would have to maintain docstrings or any other ad-hoc type hinting. But its optional, so if you don't want it don't use it. I mean if the types are obvious then there is no need, but really the advantage will come from you using 3rd party libs with type hints. &gt; I'll have to add type information to my tests and then maintain those as well Why do tests need type hints? I think you are missing the point of type hinting... &gt; I may even need to expose the type information in my documentation and maintain that. That's already the case in many large Python projects, this unifies the many different ways (ad-hoc, docstrings, comments etc).
The first layer is a root filesystem created with [Buidlroot](http://buildroot.uclibc.org/). In the second layer setuptools is upgraded from 5.8 to 18.0.1. Does that answer your question?
Hold off. That knocking on your door is Google. There is going to be a bidding war.
I am happy to hear that! Hope my parents start talking with me again 
Plot twist. Google guy got into a fist fight with a lady from Oracle who just minutes before beat the crap out of a Cisco recruiter with her high heels. I wait until the dust settles and meet with that Microsoft dude at the coffee shop.
If you want to do basic data science, you could get by with just basic stats and programming, but if you want to do serious data science, get a job, and have in-depth knowledge of what you're doing then knowledge in CS is important. CS knowledge is pretty much math/stats anyways.
Hi all, This is my first PyQt project. You are more than welcomed to leave any advice/comments on this project. I really appreciate your time for reading my code / trying my project. For your convinience, I have built a portable binary executable for Win64 which can be downloaded at https://github.com/mikkkee/gifer/releases/download/v0.1.0-beta/gifer.0.1.0.win64.binary.zip Executable files for other platforms may be available in future releases.
Hi there, please try submitting this to /r/learnpython
I've been using https://github.com/lins05/slackbot for that sort of thing. You can have it regexp messages and then respond with a custom function whenever there's a match.
I was just offered a job at Amazon and one at Google! Amazon offered me a house with a pool and Google offered me a poolboy as part of my personal staff. How in the world do I pick?
https://docs.python.org/3/library/json.html Extending JSONEncoder (modified) &gt;&gt;&gt; import json &gt;&gt;&gt; class DecimalEncoder(json.JSONEncoder): ... def default(self, obj): ... if isinstance(obj, decimal.Decimal): ... return str(obj) ... # Let the base class default method raise the TypeError ... return json.JSONEncoder.default(self, obj) ... &gt;&gt;&gt; json.dumps(decimal.Decimal(1), cls=DecimalEncoder) '"1"' Done on a phone from the documentation example.
I had to learn about some basic feature detection - this set of tutorials was a great resource for me. https://opencv-python-tutroals.readthedocs.org/en/latest/
Is it possible to post the src? thanks edit: and by the way, did you consider using pyttsx instead of Ivona?
Make your own startup with blackjack, and hookers!
Very cool!
Looks cool! I few years ago I made something similar in Java. 
This is a great point, and should have been so obvious to me when writing the blog post.
Looks great! I am an space engineer too. We usually use Altair HyperView (and HyperWorks environment in general) for post-processing. I thought about development of my own tool, but it is far too large project. So I am wondering, what is your motivation for this tool? Is it your side project? Btw thank you very much for pyNastran! ;) 
All the code lives in the `__init__.py` of the package. This would be much better suited as a simple module rather than a package. Also, per PEP8, you should use all lowercase for for the package/module name. On second thought, maybe I should just make a pull request to improve my git contributions. *edit: formatting*
Following this feedback, a private question and to meet one long term goal I have created a blog for backtrader and added a 1st post with some clarification and an example. http://www.backtrader.com/posts/2015-07-18/00-post/ Best regards
We had a couple of freelancers from e-lance.com. They helped us with small Python projects on a milestone-by-milestone basis.
Thanks for sharing, this is great!
Seems like your app.config doesn't have "database" key. Maybe you have it in uppercase letters.
Looks like there is no key named "database" in your app.config[] dictionary. Check that it is there, or spelt correctly.
I'm following the Flask tutorial for the most part, it never has you make app.config. Any suggestions?
I'll post the source code as soon as I can, and yeah, I did use pyttsx for a short while, although I found it a lot easier to implement more natural sounding voices using Ivona.
Iron Man is what inspired me. Specifically this [scene](https://www.youtube.com/watch?v=9P2hgl50Bf4) from Iron Man 2. 
Had no idea it existed! Commits message certainly look better 
It is.
Please show all of your code. Missing from the above are the import statements, a call to StdOutListener(), a call to my_graph() and IIRC a call to show() is also needed in my_graph().
Hi, Thanks for your time! I have updated the code. 
/r/learnpython might be a better place to ask this or stackoverflow. Also try including some details: what operating system? Version of python? What have you tried so far? What are the exact errors you are getting? Did you follow the packages installation instructions?
But when you call it, you're using ['database], not the uppercase ['DATABASE'].
The Flaskr one, I more or less copied it as is. The section that's causing a problem wasn't altered.
Looks like a good start! There are some pretty decent MLP modules out there you might be able to use as well. Also, I'm not sure how well wxPython works for you - but my productivity with making small apps went through the roof (on my own, very limited scale) when I switched from wxPy to PySide.
Will you please stop saying that you have them and **SHOW US YOUR CODE**, thank you :)
You are trying to load the config from WEREWOLF_SETTINGS, which does not exist. Anyway, try this: Put all those UPPERCASE config options in a second file named config.py (same directory). After creating app, then call: app.config.from_pyfile('config.py') Done 
I think you just reinvented type()
This is a really cool idea, thanks for sharing!
Amusing, but something I would run screaming from in actual code. ...you did do this just for fun, right?
Thanks, that works. Now I just need to figure out how to get it to run a bit of javascript.
There's a project called Jasper for the Raspberry Pi that does this. 
For the love of all things decent, put a dot after "A.I"
Come talk to us at /r/learnpython 
Yes, it will play HD video. I will guess at most 2 video at once. Which of the framework support hardware accelerated play back that you might know?
Update - one of the core developers Josh Cartmell has actually written a comprehensive guide on upgrading, check it out: http://bitofpixels.com/blog/upgrading-to-mezzanine-4/
This question is better suited for /r/learnpython, but the short answer is this is due to [floating point math](https://en.wikipedia.org/wiki/Floating_point). The classic example is &gt;&gt;&gt; .1 + .2 0.30000000000000004 
Thanks for the answer! You're right, this should be in /r/learnpython, my bad. I'm going to leave the post up in case anyone needs to learn from it, though. Again, thanks a ton!
Yeah it processes data from a FEM program a guy in my group (aerospace) built. He has some functionality that allows a user to read in data with customized labels to plot on the model. It was a very messy process to get that data formatted, so I built this to provide an easy way to filter data (by stresses, material, geometry, coordinates, etc..) and then export in his format. It ended up being extremely useful to use side-by-side with his program to analyze high stress areas or specific structure. He's trying to implement it in his program now (neither of us know squat about each others language). This was my first stab at a larger gui application. I haven't really established a github profile because I've only been coding a little while (civil engineering background) and I'm usually just messing around. Git was always a little confusing and my work wouldn't allow that type of 'sharing'. I've got everything locally and would be more than happy to share if you'd like to check out the source. I might see if I can get it on git. 
A day to build the GUI! Many days to get the numbers.
The introduction talks about the file being too big so you have to scroll back and forth to find your functions...this doesnt really solve that at all. You just made it harder to maintain a single class and polluted the repository with small files. Any modern editor should have folding, code completion, or even a split view of the same file, but really your methods should be named something logical so that you can easily remember them.
Avinash, dude you rock! ROFL -- this is hilarious.
Do you have to make connections as each different user to get the benefit of this security or does postgres allow you to pass through 'on behalf of use x' type security model? If the webapp has to connect to the datastore as each separate user you will run out of connections and processes before you begin to grow your userbase.
Good point haha, am noob :) Edit: updated
This shows how you can connect to Postgres with a low privilege account and switch to appropriate user via SQL as opposed to setting up a new connection. http://stackoverflow.com/questions/2998597/switch-role-after-connecting-to-database/19602050#19602050
You'd have to implement the app's security model inside postgres. It might be relatively easy if it's something like the example you linked, "user can only see their own log messages", but if it's like * you can see your messages * plus public messages * minus messages from people who have blocked you * plus private messages from people who have you on their whitelist well I don't know enough about how to use row level security to say it's a bad idea, but it certainly raises a lot of questions.
Thank you for your efforts, I did not want to add text but more of an array to an existing file. Thanks again. 
Only as an example that if you use postgres structures to mirror your application's, be aware of what their limits are. I'd assume roles are much easier to have lots of than tables are, but if this takes you from "we have a dozen roles for various services and admin accounts" to "we have thousands or millions of roles", you wanna make sure you can actually make that leap.
CRVKNR - Classic Reddit - verbal knockdown, no reason.
this still sounds messy since user name is being presented as a string argument in the set role example.. If if this was a public facing app ide be worried about easy exploitation.
Any thoughts on how to mitigate that risk?
Maybe ensuring some sort of validated user ID is the only acceptable input, derived from username.
They say it at a 'usable state', but is it production ready? Is mainly for games? 
To try it out, just git clone [this repo](https://github.com/mdoege/grailbrowser) and run `python2 grail.py` from `src` directory 
try [requests!](http://docs.python-requests.org/en/latest/)
I occasionally give some thought to this. Pros: Expressing data-related logic in the database is often the simplest way. WHEREs are explicitly designed to select subsets of rows, so handling access control with that is natural. If you express it in the database, it's much easier to be consistent- once you restrict access to a table, it's protected from all angles- if you implement this in your webapp, there are many ways to do it which leave data protected in some ways and unprotected in other- it's hard to do it 100% right. At some point, you could provide users SQL access- it's the ultimate API. People will run away screaming if I mention this, but it would be great to be able to do this securely. APIs are sucky for reporting and bulk data modification- SQL is AWESOME for that kind of stuff. Cons. Frameworks do not support this, so you would have to roll your own. You cannot do FKs in your tables to the user table, so you have to jump through hoops to simulate that (I think you can now trigger on CREATE USER, so it should be possible to implement this reasonably well). Well, it's not the beaten path. There is bound to be hidden downsides and unthought of use cases. Here be dragons and all that. -------------- I'm a firm proponent of using databases to their full extent, and I think it'd be nifty to investigate this. 
Assuming you'd use a framework like Django, would there be much benefit to this over using one of the Django user accounts packages like django-userena?
For sharing you can keep posts in public table and for banned/not banned use the row security. You need good DBA. Don't drop all in one table. 
That's possible and would work well if you partition smartly and create interconnection somehow. 
Ensure user id is in required ascii field. Never failed me.
Perhaps you're using Python 3: in version 3 the print statement has been replaced with a print funtion. This implies &gt;&gt;&gt; print 'foo' won't work, but &gt;&gt;&gt; print('foo') will.
You want /r/learnpython, and the entire thing you want to print needs to be inside the (). Move the closing ) all the way to the right. I.e.: print ('%s-%s-%s' % (year.now, month.now, day.now))
I would guess connection pooling would be very difficult in this scenario, which is usually pretty important in high performance web apps.
Indeed. Row level locking would have been great for my current multi-tenant app (and likely something I'll refactor in at some point).
it's an interesting idea. my initial reaction (and i say this as someone who likes to try out new ideas) is that it's not going to work. just as a general rule of thumb - new ideas often fail. so i wouldn't do it in paid work until i tried it out in a personal project. the obvious issue is scaling. but thinking about it more, it's really a different take on the perennial issue of how much "business logic" do you put in the database? and there's no one answer to that, because it depends so much on context. but (again) having said that, my general approach is to have several layers of "decoupling" between the front end and backend. so the database is what you might call "very abstract" or "idealised", and then there's a layer of code on the server that adapts that to the stupid little details that always seems to exist. and then another layer on the client that adds yet more weirdness. not sure that's clear, but what i am getting at is that the front end is quite "distant" from the back end. and it's not clear to me that something like security in the front end should be directly mirrored by security in the backend. more likely that there are different levels of abstraction. so the front end is user-based security, but that is translated into different roles by the time it gets to the middle layer, and those roles are what appear in the database. thinking from another direction, what i really want from a database is that it stays consistent. and that's a trade-off between simplicity (because i am stupid and make mistakes) and granularity (using database features to guarantee consistency, at the cost of complexity). one user per user is pushing towards the granular extreme. so i'd want to know what the cost is in terms of simplicity. incidentally, i don't understand your comment *less so for applications where some portion of data might be shared between users* - surely postgres security also has groups? if you're going to model the front end in the back end to that extent, why wouldn't you use groups too, for exactly this?
`type` has three meanings in Python. 1. It tells you the type of something. Surprise! But not really. 2. The type of something ("blarge is type Spam") 3. The mechanism that creates classes (otherwise known as types ;) -- this is also known as a *metaclass* but let's not go there If you call `type` with one argument, you get that thing's type: type(4) # int type([]) # list type(Spam()) # Spam However, you can also call type with *three* arguments: 1. A name. 2. A tuple of base classes (haven't seen if any other iterable works) 3. A dict mapping names to attributes/methods So, we could take this: g = dict(globals()) for e in g: if callable(g[e]) and e != 'MyClass': setattr(MyClass, e, g[e]) And do this instead: # MyClass doesn't exist yet. clsdct = {k: v for k, v in globals().items() if callable(v)} MyClass = type('MyClass', (object,), clsdct) Now you have a class. Usually you don't do this. But you can if you really want to. I've used it to create "anonymous objects", just add extra parens at the end to actually invoke it. 
There's been several efforts to build a decentralized reddit clone, but they've never gone anywhere. I think the last one was called r2r, but five or six probably popped up since then.
As you've already been pointed in the right direction, I'll point out date/time string [formats](https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior)
That's pretty cool. The license on it is a bit weird, but I suppose it's comparable to Firefox's public license since you have to change all the branding in derivative works. Neat to see old stuff written in Python. It never surprises me to find C programs from the 80s and 90s in my software repos, but Python is a bit harder to come across. Now, we just need to port it to 3.x. :P
&gt; but I feel I'm still too inexperienced to be of any real help. That's how I felt a few months ago, but to my surprise I just did all the things I remember wishing I had a clue about. Keep working to your goals and many things will come faster than you think!
Downvoted for the useless post title. "help.." indeed. If I could, I'd give a second downvote for the poor description of the problem. "How do i do it with the latest version?" Probably the same way you would do it with the version before that. Do you mean latest version of Python, or latest version of Automa? What have you tried? What happened when you tried it? Have you tried googling for "install Automa module python"? Don't think of this as me bitching at you. Think of this as me teaching you to ask better questions, so you can get better answers.
The're some efforts to run Python on JS, none of them are really production ready but they're mighty impressive! Can't wait to see what[ web assembly](https://medium.com/javascript-scene/what-is-webassembly-the-dawn-of-a-new-era-61256ec5a8f6) will bring us.
input validation is good - but that doesnt solve the problem that an attacker can just keep iterating through until they find valid input. do you have a strong lean not to use sessions other then they are harder ?
could you please explain furthe, I am not following along. 
Have a look at what? There is no link.
If only the personal assistant would have advised you to post a link.
First off, you should not be writing viruses. Secondly, this is the wrong sub to come to learn how to write a virus. Thirdly, Python is a shitty language to write a virus in for a variety of reasons. Fourthly, you can always bundle a shell in with your virus if you really need to write one
[Image](http://imgs.xkcd.com/comics/exploits_of_a_mom.png) **Title:** Exploits of a Mom **Title-text:** Her daughter is named Help I'm trapped in a driver's license factory. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/327#Explanation) **Stats:** This comic has been referenced 784 times, representing 1.0742% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_ct8siwg)
No, you've missed the point. He hasn't come up with a new syntax for creating classes. He is *dynamically injecting methods into an existing class.* I'm dubious about his rationale for this. The class is too big? Too many methods? Sounds like he's constructed a God Class that does too much: it slices, it dices, you can cut a tin can with it, and fly to the moon, clean your shower, weed the garden, it's a truck and a fridge and can babysit your kids. But I don't really know. Perhaps there is a good reason for why the class is so big. An alternative strategy is to use mixins. But the idea of dynamically adding methods to a class is a powerful one. I just wouldn't do it the way he does.
You have to get Python installed as part of the initial exploit. [This example](https://www.trustedsec.com/june-2011/creating-a-13-line-backdoor-worry-free-of-av/) written in 2011, required an initial downloader in C that installed the interpreter and ran the code. I haven't tried it but I'm pretty sure this requires admin privileges in all OSs in order to work. Edit: and yes, like everyone else said. Don't release shit like this. 
Valid point - I wonder how many large sites actually do that.
Awesome, the vispy example with tubes looks quite cool. It's a shame those bindings use ctypes and not cffi, which should be quicker - but just getting this on android is great.
Yes it's just for fun
http://effbot.org/pyfaq/how-can-i-create-a-stand-alone-binary-from-a-python-script.htm
I didn't know about web assembly. Looks exciting. 
No always. You can overflow the CPU with bits, until the cascade cache master I/O stream device opens up in real time and flows into a normative reverse memory funnel asynchronous path. At that point you need to redirect through an ecliptic encryption entropy analyzer, while executing on a dedicated asic functioner transceiver module (so the feds won't find you). As soon as you get to a quadrillion bits, open up a modem connection and pump those babies to the gopher service, bang! You now own the network. None of that needs a shell. Add my on skype and I will show you how. 
Here's the link https://pypi.python.org/pypi/jango
This is the link https://pypi.python.org/pypi/jango
Mass update would lock the whole table anyway unless you used a cursor or something. It also depends on the isolation level.
Made some changes to code: sorry very novice at this and have test on this and not doing so well 
I hope some people have feedback on the frontend, backend, perhaps hosting ideas.... implementation suggestions. Give it to me, please! :)
I can't really tell what this is. How is agargui "trending" even though the link takes me to a page that reports zero downloads. Some info about how trending-ness is determined would be nice. Edit: I could care less about pypi pages. I usually navigate to the github page, or don't use it if I can't find the source.
Sir/Maam, Can you please show me in the code? I am still not understanding. I indented the "return true" to no avail. Please show me in the code, as I am still a student in this matter and do not understand what you are referring too in such a high manner. I have googled "lowest indent level" but I am not understanding, please show me in the code. Thank you for your time
&gt; my_graph(my_range,my_average) try putting that after line 66 or wherever you want the function to be run, with the appropriate values
Thanks a lot for your valuable suggestions. I'll take these in mind :)
Thanks for the response! Yea, my bad. I'm not really sure where should I show the explanations, perhaps a different page for it? Indeed, the pypi stream is at this moment just a "most recently added packages". I'll make it smaller for now. I can maybe indeed also come up with a mechanism for pypi to really give an indication of when they are trending, but the way it is now, mostly bots are downloading anyway.
Thanks, and I tried using that and remember not getting the result I wanted. I think I might have used it wrong I guess. I ended up just writing a recursive function to get the comments, which just meant adding a few lines. I'll try it out again next time for my next project though, it's sentiment analysis of the users of a subreddit over time. It too will be open source. 
Thank you sir/maam it worked! now I need to figure out how to get the graph to populate, but thanks for your time!
Why not just use [Requests sessions](http://docs.python-requests.org/en/latest/user/advanced/#session-objects) and [BeautifulSoup 4](http://www.crummy.com/software/BeautifulSoup/)? Requests isn't as browser-like, I guess, but they're at least two well-used libraries. EDIT: Links
I just went through an exercise doing this and found out that all of the micro distros that I could find, that have package managers, have moved to musl c compiler, which is incompatible with glibc. Busybox has opkg, or alpine has apk as package managers, but there can be issues that pop up when either compiling or using binaries for things that have had little testing in these environments. If the app isn't super critical, it probably doesn't matter, but it is just an unknown to be aware of. I was experimenting in this repo to get an alpine plus pyenv image setup. You could then easily produce a smallish image with any version of python. However, there are issues with compiling some of the versions, and only could get 2.7.10 working reliably. The point was to have tiny images that could be used for testing apps on many versions, using a tox/dox-like approach.
I wasn't aware of Sessions in requests, thanks, will check it out :) I am actually using BS4 in my existing setup to get the data once the final data page has been fetched, the pain point was logging in and then sending the 10+ cookies with every single request. 
Can also just use PIL.
Hi there. You have posted a beginners question to /r/python, however it is far more suited to /r/learnpython, where users are actively interested in helping with beginner topics. Please resubmit it over there! Make sure to read their sidebar rules before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." Cheers &amp;amp; best of luck!
Pycairo. Python interface to libcairo, a great vector drawing library used by tons of programs and gui toolkits. Can output to svg, png, etc. Pillow is more for image manipulation, though it does have some drawing primitives that might be enough. Tons more output formats... Though the two libraries pair well together too :) 
Surprised nobody mentions opencv ever 
Cool, good work!
They are already. I know so much compared to just months ago. I feel if you are motivated and study hard, you can accomplish a lot very quickly in programming.
Everybody's gonna tell you to use Pillow/PIL. Pillow's probably the right choice in a lot of ways, but it always leaves me feeling gross for some reason. I guess I don't care for its API. I like to be "in control" of the data with `numpy`. If you share these feelings, `pip install` `numpy` and one of `imread` or `imageio`. `imread` works really nicely for me. Those just help you go from *disk -&gt; numpy* and from *numpy -&gt; disk*. Once you've got numpy and a way to read/write ndarrays to/from disk, everything falls into place beautifully. Here's how I'd solve your problem. Your problem is simple (for now), but I think you'll find that numpy grows with your needs really nicely and it tends to stay pretty performant along the way. You can do some [fun](https://github.com/TadLeonard/crash-kiss) [things](https://github.com/TadLeonard/husl-numpy) with JUST numpy. import imread import numpy as np def make_rect_img(img_dims, rect_loc, rect_dims): shape = tuple(img_dims) + (3,) # N x M x 3 array img = np.zeros(shape, dtype=np.uint8) img[:] = 255 # white, initially draw_box(img, rect_loc, rect_dims) return img def draw_box(img, rect_loc, rect_dims): x, y = rect_loc w, h = rect_dims img[x: x + w, y: y + h] = (255, 0, 0) # red W x H box if __name__ == "__main__": img = make_rect_img((300, 300), (100, 100), (50, 50)) imread.imwrite("box.jpg", img) [Here it is in a gist](https://gist.github.com/TadLeonard/93ed1c897fc52888f4c0) in case that's more convenient. 
&gt; I just went through an exercise doing this and found out that all of the micro distros that I could find, that have package managers, have moved to musl c compiler, which is incompatible with glibc. This image is based on a root filesystem build with Buildroot. By default a rootfs build with Buildroot uses uClibc, but you could also select glibc or musl if you want. The same thing counts for the package manager, you can select ipkg, opkg or RPM from the menu's. The image linked to in this thread uses uClibc and has no package manager. &gt; The point was to have tiny images that could be used for testing apps on many versions, using a tox/dox-like approach. This image doesn't fit for that purpose. In general root filesystems build with Buildroot aren't fit for this purpose, because you can only select 1 Python version when building a root filesystem.
I like cx_freeze because it Is drop dead simple. I'm on mobile right now but in order to make the setup script it's like 5 lines max
pycairo - PIL is more for image manipulation than drawing.
I've used pyinstaller because it works like a charm with kivy. Also, i've heard that nuitka works with kivy aswell
I tried mechanize a while back and thought exactly this. I can do most that I need from mechanize with requests and bs4.
I love it, but does it support Mac? BTW, Don Don Donuts Do-n to Ikou!
Well, he just wants to draw a rectangle..
But beware: http://cairographics.org/FAQ/#sharp_lines
well he actually wants to draw a barcode, of which there are many existing solutions....
* py2exe is only for windows but it worked ok in the past. it basically zips bytecode+native modules for distribution. Bytecode can be decompiled. * cx_freeze is similar to py2exe but supports more platforms, i preffer this one from mentioned two. It also zips bytecode+native modules. * nuitka is whole another beast. it translates python code into c++ code which calls into libpythonXX (pythonXX.dll on windows). It does not provide much speedup yet however it completely hides your code so it cant be decompiled. Resulting c++ and then machine code is by far less meaningful than python bytecode. It also is VERY compliant but some things may break. This is not the case with py2exe and cx_freeze. Although i build one of my apps which is not exactly tiny using nuitla (and PySide) and it works well. I also run it constantly because it is clipboard manager among other things. So its stable enough.
Yeah, but in my use cases there is just a shit ton of random cookies that are to be sent and all, mechanize simply allows you to select a form, fill in data and submit it, with requests you need to figure out URLs and all. Requests sessions, though takes some of the pain out, thanks to /u/arbot for telling me about that.
[Nuitka supports Python 3](http://nuitka.net/posts/nuitka-progress-spring-2015.html#compatibility) with some minor issues that they are working on.
If you're not bothered about people seeing your source code, then I would go cx-freeze. If you want to hide your source code, then what I tend to do is move as much of the code into external modules (.py), use nuitka to turn those py modules into pyd (machine code, essentially a .dll or .so), then cx-freeze the main script importing the pyd files. Sounds complicated but it's really quite simple once you've done it a couple of times.
Well, Nuitka is a Python compiler which is different from a freezing tool. If you are only interested in packaging your code for a friend/user who doesn't have Python installed, then there is a nice comparison of Python freezing tools in an appropriate section in [The Hitchhiker’s Guide to Python](http://docs.python-guide.org/en/latest/shipping/freezing/) (an excellent book for Python beginners). On the other hand, if you are interesting in speeding up Python for performance reasons, then you should look into Nuitka, Pyrex or Cython class of tools. Most of them need you install a C/C++ compiler as they translate Python into C code. So it might be a more complex tool chain for your needs.
[PyX](http://pyx.sourceforge.net) is another option: from pyx import * c = canvas.canvas() c.stroke(path.rect(0, 0, 10, 10)) c.writeSVGfile() c.writeGSfile("test.png") c.writeGSfile("test.jpg") While SVG (and PostScript and PDF) is supported natively, rasterized versions are created using ghostscript. Due to the rasterization of vector graphics for bitmaps, "sharp lines" are a problem similar to what is written for PyCairo in another answer. It can be workaround by using "good" coordinates, but maybe working on bitmaps right from the start is better for those cases. It all depends on your needs ...
If you provide the URL to the site then more effective answers can be given to your question.
ha ha thanks
I implemented your suggestion. Thanks!
You don't need the shell to run python scripts. If I still did escalation/invasive toy projects, python would likely be the last language I'd consider though. It's not a small language and for "virus" type software, you want as small of a footprint as possible. More likely some sort of foot hold component that then fetches the rest of it. Everyone else is making snap judgement "don't write viruses" advice which is kind of worthless. From a white hat stance, it's good to have some insight into how malicious software actually works and how it operates. That said, modern malicious code is absolutely fascinating, case in point this recent incident - https://firstlook.org/theintercept/2015/02/17/nsa-kaspersky-equation-group-malware/ 
Or cython. As per nuitka.
Of course we can. We can do same for c++ software too. However for true c++ software reverse engineering is much easier because c++ code maps much more closely to machine code than in this case python-c++ to hardware. By the way similar thing can be achieved with IronPython. It too can compile modules to .NET dll which again for disassembling is pure garbage.
First of all, this question would be better asked in /r/learnpython. Second, the function you're looking for is `os.getcwd()`
I mean both, though I meant C, not C++. The disassembly is fine, but the C generated is barely worth it IMO. I wouldn't say it "completely hides your code" though.
Well yes, you are right. However layer of indirection makes that disassembly much less meaningful. Time required to make sense of it greatly increases. It indeed gets close to garbage. Or maybe i should call it not economically viable to reverse-engineer :)
I have built a executable file on my MacBook Pro. It can run. But the QT layout looks weird, for example the play/pause buttons of the GIF player may move up to the middle of the player rather than stay below the player. Need to modify the ui file to get it looks nicer on Mac. And thank you for donauts :p
If nuitka does indeed call into python.dll/libpython.so, you could also just intercept the library calls into the DSO, and from that completely reconstruct everything the python library is doing. That doesn't necessarily give you the python code, but it would tell you everything about what's going on in the process right now. If libpython is compiled statically (which, I assume, everybody who cares about it will do), it will be more work. Also if nuitka does stuff like cython (which allows you to side-step the python library under certain conditions) then stuff will be going on that you cannot see just by hooking the library.
I feel it's incorrect to say that - a number of my customers have spent quite a lot of time and money obfuscating code and are fairly shocked with the ease with which it can be reverse engineered. They were under the impression it was nearly impossible, and it isn't.
For sites that have tons of ajax and cookies, use selenium requests. So use selenium to load the site, login and all that stuff. Then to download stuff or what ever, the selenium requests module will move the cookies from selenium into a requests session. 
Run unknown script with sudo? No way
I think [Mininet](http://mininet.org/) may be helpful in your experiments. It also provides **Python API** for network creation and experimentation.
&gt; the selenium requests module will move the cookies from selenium into a requests session. That is pretty nifty, sometimes those initial login pages or whatever just simply require js (sometimes other random pages do too), so selenium webdriver is the only thing you can use. Transferring the cookies later on to requests would be great. 
Yeah, I think it has a version of BS from 2004 or something, even though mechanize was last updated in 2011. I just hope someone picks up some of its nicer ideas. 
Doh. Missed out. Looking forward to the book completion to check out. Awesome!
pyinstaller is in my experience, the best of these. However, be warned that they're all pretty average. Compiling a python application into a 'distributable' is prone to all kinds of failures, typically: - Linking to external system library that the bundler doesn't detect - Accessing __path__ and attempting to read assets embedded in the library (eg. templates) - Failure to parse 'complex' dependencies with shared namespaces (eg. zope.anything). - Dependency on some kind of system python being installed for the standard library or libpython. - Built target is a specific arch; eg. x86_64 or i386 on mac, when you want a universal binary. To be fair, they all *try* to sort it out, but it can be a mixed bag. It's not uncommon to bundle an application and have it 'all working except for &lt;insert package here&gt;...' and spend a few fruitless hours hunting google for configuration settings and tips to resolve the issue. Honestly, unless you *really* need to, you'll be saving yourself a heck of a lot of hassle by not going down this path at all. Do you really need a standalone distributable? If all you need is to share your code around, using pip and 'install python locally and then pip install foo' is a much **much** better solution to your problem. Python isn't made for this purpose and although its not ... *completely terrible* at it, it's not really what python shines at. You know the adage; toolbox, tools. Pick best for purpose. If you're building a standard alone distributable application that you don't want to share the source code to (eg. a game), python isn't really the best choice for it.
Python / PySide application for processing scanned images of museum objects: [Inselect](https://dl.dropboxusercontent.com/s/gmwdjn0f35pxr50/Inselect1.png) 
Should we really be posting year old stackoverflow posts to /r/python?
TIL thanks. 
I guess I should be a bit more pedantic: an RDBMS doesn't *guarantee* the order of the data unless you use an ORDER BY clause in your select. Depending on the underlying implementation and the class of table (some RDBMSes support Index-Organized-Tables) the storage of the data *might* be in order, and the default behavior of a SELECT statement will then extract the data in the correct order. It is *not*, however, a guarantee, and if you want the data sorted, you should always just use an ORDER BY.
Varies with your interest in and aptitude for programming in general. But python is simple, so you should know it well enough to be somewhat productive in a few months. 
Well, it depends on your programming experience. If you are familiar with programming already, most of the stuff on Python will be the syntax and of course different libraries, but the idea will be the same. It took me just a week end to get a grasp on it. And after that, it is all practice. The way that I did it, I picked something that I wanted to do and built on it. Practice and practice. 
Shameless plug: [Pynsist](http://pynsist.readthedocs.org/en/latest/) is a tool I made to distribute Python programs on Windows in a different way from all of those tools. It doesn't make an exe, but it installs your code as a 'real' application with start menu shortcuts and so on. I've used cx_Freeze a lot, and helped other people using it, and there are a couple of kinds of problem that seem to come up a lot: it can't detect all the files that are needed, and lots of packages don't work well when packed into a zip file (which is how freezing tools work). Pynsist attempts to avoid both of those problems.
How long does it take to learn piano? The point is, what's your cutoff for "learned it" vs. "haven't yet learned it"? You do give some idea, but even then it's a little hard for me to know what you mean by "a range of projects" (I've seen a big scope out there). To get the *most basic* gist of it, probably 3 good hours--but you will not be able to do much. To get where you can make something useful, yes, probably a few months of pushing yourself and not being mentally lazy about it. But even then, you're still shaky. I'd think after you've been banging your head against the wall with real problems in code for a good year or so (sounds like a lot, but you know, life gets in the way, holidays, summer, problems, etc), then you can be at the piano playing equivalent of playing "The Entertainer" in a mediocre way.
I wrote it, so if you have any questions, I'm happy to answer them. :-)
Someone needs to figure out how to cram this into a GL shader. It would make an amazing render mode in a 3D game.
As with all things practice makes perfect. I kinda accidentally became rather good at T-SQL just because I had to use it so much at work. Although I enjoy Python more and want to get good at it the lack of "reasons" to use it can be a bit of a dampener on getting better at it. I have recently used it to automate some of the mundane stuff I do in the office of late and that has actually allowed me to get proficient at some of the basics, at least.
Since you asked for a comparison to Java, about 10 times as long (according to Raymond Hettinger).
How smart are you?
Are your sure she was a student? It sounds like the work of Jenn Schiffer and her http://vart.institute project.
&gt;I'm using python to parse files get the info out of them and store in SQL. It sounds like you're parsing the file and calling 'insert' on each entry. Don't do this. Parse the files and dump to csv and then import the files. Maybe you know this, but maybe others reading along don't, so here's some links: [SQLite](https://sqlite.org/cvstrac/wiki?p=ImportingFiles). [Postgres](http://www.postgresql.org/docs/current/static/sql-copy.html). [Oracle](http://docs.oracle.com/cd/B28359_01/server.111/b28318/utility.htm#i10606).
The *only* way to prevent people from seeing your code is not to give it to them. That is why SaaS is such a big thing these days.
Then I suggest you compile reasonably complex ironpython app to .NET DLL and take a look inside.
Does cx_freeze bundle up dependencies?
Is there a downside to doing this on a live db? 
Separate question: why is the process called freezing?
Not really. I'm just saying that I've measured it on non live dbs. I guess the only disadvantage is that you have to be logged into the actual db machine since it needs to import the file through the file system. Not all enterprise environments want to allow that.
I Used Pyinstaller, had some minor issues in the begining, I'm also a beginer with Python, and I think I tried all the other versions, but found that to suit my need best. No need of setup script and really easy to use :-)
No worries 
Where are the Russian subs?
If you already know how to program in any other object oriented language? Maybe a day to learn syntax. Another few days to learn the simple libraries you'll be using the most. No programing experience? Really dependent on the person and source of study. 
OK then. On Windows, I ran into having to use a special distribution (winpython) in order to get the scipy stack running. WI this work?
Greetings, professor Falken.
I've used uncompyle2 in the past, it's for python 2.7 only though, you can even modify the decompiled .py file and put it back in the .zip
I've found PyInstaller pretty good in practice. Sure there's a couple of niggles but it mask less deployment much easier 
Where do you get NSIS now that sourceforge is down? Also sourceforge
Much better animal to use for a name. I was always bothered that they named their package after a species that is too stupid to mate or eat.
Here's a flattener that uses `nonlocal`. Its "feature" is that it uses types to control the recursive descent. def flatten(*types): """ Flatten arbitarily nested lists. This allows specifying the types to chain over or recursively descend into, and the return type to produce. Types are the arguments and the return type is first type given, e.g. &gt;&gt;&gt; flatten(tuple,list)(iterable) will descend into both lists and tuples and return a flat tuple. The first series of iterable types are those types to un-nest, i.e. to iterate over. The *first* type given will become the return type. Examples --- &gt;&gt;&gt; nested_thing = [[[[[[[6],5],4],3],2],1],0,(1,(2,(3,(4,(5,(6,),),),),)] &gt;&gt;&gt; flatten(list, tuple)(nested_thing) [6, 5, 4, 3, 2, 1, 0, 1, 2, 3, 4, 5, 6] &gt;&gt;&gt; flatten(tuple, list)(nested_thing) (6, 5, 4, 3, 2, 1, 0, 1, 2, 3, 4, 5, 6) """ car, *cdr = types acc = car() def flatten_(xs): nonlocal acc if type(xs) in types: list(map(flatten_, xs)) else: acc += car((lambda *x:x)(xs)) return acc return flatten_
&gt; pip3.4 install --upgrade statistics Downgrades you to a version of the statistics module for Python 2. Classic Python packaging.
Sourceforge file hosting still seems to be working: https://sourceforge.net/projects/nsis/files/NSIS%202/2.46/ There's also a chocolatey package, and you can probably find it on most of the popular software download sites, though which of those are trustworthy is another question. On Ubuntu/Debian it's available from apt, and I think there are homebrew packages for OS X.
Is there a subreddit for python pandas? 
I just did some googling and it turns out there is py2exe for python 3, I remember cx_freeze being very easy to use though
Looking forward to Python 3.x compatibility
To try and answer your specific question, it might be your formatting but do you have two `on_data` methods? Could that be your problem? Otherwise, some other tips: 1. `numpy.isnan` to check for NaNs. Also you can use boolean masks to filter NaNs out faster: `data = data[~numpy.isnan(data)]`. 2. Don't switch between lists and numpy arrays so much. You can probably get by with just numpy arrays. Learn the methods that go along with that (concatenate, etc). 3. Do something different with the `if 0 in my_list`. Unless I'm misunderstanding it, just check if the value being added is 0 and if so don't add it. Adding it and then removing is a waste of time. If it's not just the element being added then using numpy arrays would make it simple to mask it out similar to #1. 4. Usually when I'm making realtime dashboards I try not to have an ever expanding list of data points. Usually it makes sense to keep the last N number of points. If you need to have it grow forever then nevermind. Writing to a file is another option if you want to do statistics later. **Edit:** Another thought, you could preallocate a larger array in numpy every where needed and fill it in as you go, expanding it when needed. If you fill it with NaNs and use `numpy.nanmean` and similar for your calculations you should be fine. I don't believe matplotlib plots NaNs in line plots. I understand that performance might not be important to you right now...but better to future proof when it's easier.
I use pyodbc. It's been around a long time, is still maintained, has many libraries built to use it, and we've been using it in a production environment for a while with no inexplicable behavior.
You could write it as a web application using django or tornado. Then, use some javascript for the phone gap api to handle ios specific events. 
/r/learnprogramming /r/learnpython Also /r/dailyprogrammer
Thank you for the reply. I haven't found those forums to be particularly good for complete newbies. But I should have asked in learnpython. I will take my question there.
We're in the same boat together. I dabbled in BASIC as a kid. Read through a couple old BASIC programming books that had codes for games that I would create. Just started learning Python literally a couple weeks ago to crunch through some reports at work. Excited to learn more and eager to apply it to everyday life.
&gt; developers should be writing for 3.x "should"??? And according to whom? You? Feel free to port the package yourself, if you're so inclined. It's free software, after all. 
http://www.greenteapress.com/thinkpython/ A free ebook intended for those new to programming. Downey is a very clear writer and teacher.
If you would like to lean the language better there are lots of tutorials out there if If just type 'python tutorials' into a search bar. I Have just recently started learning python as well and acquired a raspberry pi to which I am messing around with different things like led displays and sensors that make it a lot easier to come up with a program on the spot i.e. making the led display into a clock.
&gt; every major package for scientific computing has been ported over Interaction with Kerberos is the blocker: https://github.com/cloudera/ibis/issues/297
&gt; How is 3 impractical? Because it is not in wide use. If you think @ is going to change that because it's super-useful, I don't even know where to start.
It's starting to be used in introductory classes in colleges and newer organizations are starting to pick it over 2.7. Almost everything major has been ported over. For someone like me or a company or person just starting to use Python, there's no reason to use 2. Since adoption is gradually happening on its own, I think the community should start encouraging it to accelerate the process by writing primarily for Python 3.
Like /r/pystats, not pandas only but with some pandas content.
I have not used windows for ages, but you might try the autoit module instead. It is a python bindibg to the autoit dll from the program. 
great! I will try and let you know. Thanks for updating (:
Code Academy?
Check out GRAB. https://pypi.python.org/pypi/grab . It is well maintained russian library. It's faster and fully mature alternative to mechanize and it has more features :)
This is a great find, its one of the few libraries around here that seems to have detailed documentation (like requests), given how bad mechanize documentation is. Thanks :) 
Not ``native x86 code``... ``native x86 code generated by nuitka compiler`` or ``.NET code generated by compiling ironpython application``.
On the [PyPI](https://pypi.python.org/pypi/statistics) page, it says that the statistics package is a backport from Python 3.4 to Python 2.x using the 3to2 tool. Plus, I don't think there's a `pip install` way to upgrade the Python Standard Library.
Cool. Was hoping to ask for pointers on how melt a pandas dataframe out-of-memory (is pytables a good option?). 
Thanks, I'll try it out
If packages on pypi aren't signed, yes, it's the same risk, although at least pip will not allow you to download externally-hosted packages unless you specify it explicitly.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/tagprostatistics] [Ibis, you're finally popular](https://np.reddit.com/r/tagprostatistics/comments/3e1p9v/ibis_youre_finally_popular/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger/wiki/) ^/ ^[Contact](/message/compose/?to=\/r\/TotesMessenger))* [](#bot)
You haven't been in this game as long as we have. I get paid to create scientific output. The python version doesn't matter, only insofar as I can get things done and keep them stable and unchanged over ~3 years (the longest duration an experiment / investigation / paper might run for). Has python3 been stable and useful for 3 years - ha! no.
I agree with you in principle. But ever 14 year old and his cousin has untested crap on pip. If the authors are trustworthy the mechanism for verifying trust is malleable.
Yep, we started major projects this year and it's all on Python 3. There's one tool we use that's Python2-only so we do a subprocess call to a Python 2 interpreter to just execute that one script.
What's this new metaprogramming coming in 3.5?
Good. Try to give examples on when you would use these features. For SEO, try to have each topic in its own blog, rather than trying to force multiple things in one. Keep writing!
Thanks! I'm planning on making at least two more lessons this summer :)
Pandas is phenomenal. I am excited to see how this works.
https://pythonspot.com a free ebook with lots of snippets. 
A little bit disappointed that he didn't say anything that might improve the situation with regards to package distribution. 
If the information is still relevant, I don't see the problem with it? edit: Unless you think that r/learnpython would be a better forum for this particular thread. 
Why not use nuitka to compile it all?
Test engineer - tool building, automation, stuff like that. Not a "Python dev" but still.
We have test engineers but their main projects are all in C++ (for performance reasons). Do you need to do stuff in other languages as well or do you just use Python?
Entrepreneur - I have a startup that writes utility data collection software for solar companies. FYI, if anyone is interested in getting into clean energy, pretty much every major solar company is hiring programmers.
In the past I wrote in Java, Perl, VB6, VBA, ActionScript, C and JavaScript. We, here in Quality Assurance Dept, are by no means masters of programming, but having to do with lots of different projects one tends to learn quite a few languages - you do what you need to in order to solve particular problems. But our weapon of choice is Python first and foremost. If we can solve our problems with Python we go for it.
Are you able to provide some examples? I'm really interested in what kind of tools and automative programs other people get to build in the field with Python.
Django won't do your front end, at least not as cleanly as all the JS frameworks out there like Angular and Backbone. 
Appsec. Any time I need to script up a payload or exploit, I use Python unless I need another language for some reason (C is common). I'm also somewhat of the Python SME on my team so I usually get the Python web apps to review. I'm also in the middle of rewriting a distributed wrapper for oclhashcat using Flask as all the ones out right now and pretty bad.
AWS infrastructure guy - I use boto with a little python wrapped around it.
From the top of my head: we needed a tool that will monitor a vast network of different network elements (few clusters of 50-100 different devices), on and off on different schedules, with different configuration each time. Tool gathered metrics, inventories of elements and reported back to the performance reporting tool for management. Every manager likes a graph and a table in Excel, so we also provided those. Python was excellent choice to build having different communication protocols in mind and different stuff to do with results (graphing, reporting, Excel-ing).
I had a job which started as a Python job - writing code and infrastructure for distributed "big data" processing. When I saw how massively difficult it was to work with for any large system (we had runtime errors on a cluster which would have been caught in any compiled language, for example) I made it my 2-year mission there to get everyone writing Java instead, with partial success. No regrets.
In broad general terms - yes. Python has excellent libraries for automation and great test frameworks.
When you say utility data collection what do you mean? Like for example.. My thought is like comparing energy consumption or something like that and presenting charts to the relevant departments?
Title: Developer (generic, but it doesn't really matter much since it's a smaller company). I work on services that handle analytics data, from receiving them through an API (nginx + flask + redis), to collecting and processing them (pure python, various libraries, redis + postgres dbs) to saving the output for retrieval through another API (flask + postgres). Besides that I create new pieces of code, mostly for internal services, that process various customer data and raw video footage (we host video for customers) including a python C extension (that I am simultaneously proud and ashamed of).
Same, cept I'm makin a stripped down aws console in django on top of the boto
"Python Maniac" - Title within my team. I'm actually a java developer, but I end up writing a lot of python for going through log files and pulling information out of our environments. My main role is supporting production, and python is a really useful tool to help me do that. Offtopic: I've also recently been given the title of Bacon Peddler.
Sort of. When someone wants a quote from a solar company, they need to get their utility bill and usage history so the solar company knows how many panels to install. We write the software that automates that historical bill and usage collection. Not super sexy, but the efficiency improvement shaves 5-10% off the installed price of solar.
Same as another person - I manage GIS systems for a large number of users. Python is not my whole job, but is a big part of it. Python ties together a lot of our data management and distribution systems and methods. I also manage large datasets and Python allows me to generate repeatable processes for creating and managing data, in particular if it needs to be recreated or updated regularly. Python also allows me to write and distribute custom spatial processing tools to meet specific business requirements.
Thanks for being specific on the platforms / modules used if gives a clearer picture on what sort of knowledge you'll need. Python being the go between but you'll need to know how and where it's coming from to apply the conversion to where it is going
Yes, sometimes we have to parse pdf bills, and every utility has a different format... It's tredious work to write and maintain these scripts.
Lead Dev for a data business. We just about only use Python here. From pulling down, parsing, and aggregating data into our system, to running data analysis, feed generation and APIs on our big datasets. We're leveraging a lot from Amazon Redshift, EC2, and Hadoop.
I started as a typical corporate developer. I did some boring bits and pieces of huge enterprise software. As a test engineer I have more freedom to program than any corporate dev I've ever encountered. I do hate manual testing. If I had to do only that - being a testing "drone" - it would be as boring as being a "drone" dev.
I think it'd be fine if the title indicated it was an elaborate SO answer instead of only repeating the question.
Use Postgres this time so that when you start your next project which will require it, you'll already know how to use it. Sqlite isn't appropriate for a multi-user environment but it's solid enough that you'll be able to get by with it for a while, until you're in trouble.
You might want to add import matplotlib.pyplot as plt %matplotlib inline before the first plot. This way the notebook can be run without error when downloaded.
I can imagine so! It's interesting to me because I really hadn't thought of a company hiring someone to automate such a specific kind of task. I bet you save hours if not days of work with nice accurate results compared to doing it by hand
I previously worked at an electronics company where I'd say about 90% of the tests I would be running were automated using Python. Python has some really good libraries for electronic test automation, so things like oscilloscope measurements, voltage/current measurement, changing temperatures in stress tests and things along those lines, as well as automating the result generation as well. (I'm pretty sure it's not the same automation that he's speaking of, but different flavors of automation are cool to hear about)
Is the information gathered sold to consumers or for clients I'm just trying to picture who the information would be useful for and how it's used in the broad sense not specifically 
I know it has standalone, but that means "it will create a folder "_python" with DLLs, and "_python.zip" with standard library modules used along to the "your-program.exe". ". To me, that's not very "alone" compared to a *single file* distributable. Kay is not averse to having that "someday", but someone else has to contribute that feature. See [this page](http://nuitka.net/posts/support-for-portable-standalone-programs.html)
How are you using it for GIS and are you using regular Python or arcpy?
That's my issue with these things. It looks as if OP is asking a question or clarification on a SO answer, rather than linking an informative answer.
Are you using any frameworks for this (arcpy vs straight Python etc)?
&gt; from receiving them through an API (nginx + flask + redis) I'm very interested in this bit. Could you share any info on what you do there. I do similar using [Dokku](https://github.com/progrium/dokku). In the past I used Heroku (expensive) and tried AWS Beanstalk but Dokku with it's plugins seamed quickest to setup.
 def main(): # Using 945M as a bound yields a CSV of primes that is # just under the 512MB Kaggle Scripts disk limit mil = 1000000 upper_bound = (1000 - 55)*mil I like it...
Our entire setup is self-hosted in 2 redundant locations (we rent a full rack with servers at each place), so your setup will vary. All the incoming data is generated by a homemade client-side library that records specific client actions (as well as just registering loading the page). My API basically just captures these packets (~15 requests/sec average, top peak I've seen is at around ~75 requests/sec) and saves them to redis to processing. All of these services run across a handful of VMs (running debian *jessie* / *wheezy*) on top of XenServer. We've considered some "Dockerization" of our setup, but frankly we don't really have any reason to at this point, we have a fairly stable deployment setup.
There's an app called Pythonista which lets you write and run Python on your device. Also has a terminal. You can't send code to or from the device though, due to the rules about running arbitrary code, or whatever. However, there is a Dropbox package included... There used to be a way of converting programs to stand alone apps, but nowadays all apps Must be written in Swift or C# or something silly like that... At least that's what I heard. 
Scientific computing consultant, research software developer - I don't have a python career, but I do use python for my work. Basically is the scientific python stack (numpy, scipy, matplotlib, pandas, mayavi, cython, h5py, pytables) and for web development python + flask (backend)
psycopg2 is awesome. 
Testing Engineer. I write and maintain scripts that are started automatically every few minutes , and use Selenium Webdriver to test websites.
For anyone interested in some [readable code for the mandelbrot set](https://github.com/Brobin/mandelb0t/blob/master/mandelbot/mandelbot.py), I put this togethere a few months ago to tweet generated mandelbrot sets from my raspberry pi.
Technical Director - I work on pipelines at animation studios, writing tools for artists in their day-to-day work, integrating the big name packages (Maya, Nuke, etc) into that studio's pipeline, and controlling the flow of data and information from one department to another. 
Certs help if you're fresh out of school or consulting with a firm that requires it. Companies looking to fill full-time positions would rather see a good portfolio of past work or personal projects. Experience will trump certs any day in my mind.
Good god. Companies would pay stacks of cash to get a console that just hides the crap that a user doesn't need or have permission to. You really need to control both the UI and IAM policies to make that work though, so you can't entirely blame AWS for not implementing it yet.
Do you develop content for other end users to interpret, or are you also responsible for analysis? How do you decide what to work on? Do end users come to you with their needs and you develop it, or do you just think of something and try it? 
I do web app development for a non-profit organization. I actually came to Python late and was using a lot of other tools for a long time. Even then, I would say I still only spend around 60% of my time on Python. The rest of it is other stuff — database management, HTML &amp; JavaScript, managing server systems, handling communication from coworkers and users. 
I think that how my co-workers refer to me as well. But We are Assistant system admins and all my projects are written in python. All my projects deal with monitoring systems and building tools that my team uses to make our lives easier. 
I honestly didn't. Never actually built an app in Django before, only Flask. TIL.
Lead dev in a bank. I do way more than just Python work but it is used extensively on my projects.
Software Developer. I work at a large company (it is not a tech company, but it is still on the fortune 500 list) and all of our Websites are either in a custom made Python MVC framework similar to Django or Java. 90% of all the issues I work on are in Python. This also includes our internal corporate site (which is in Django) and our internal customer service site. EDIT: My company also has a very high ranking for security as it is an online retailer. 
The last project I did was a large [ETL](https://en.wikipedia.org/wiki/Extract,_transform,_load) project taking data from SQL Server, repackaging it, and loading it into a MySQL warehouse. There was a lot of custom SQL code, and Python was the glue that held everything together.
I started out as a Network Technician in a NOC at a fairly large company that Develops, Supports, and Host financial systems for banks/credit unions/FI's in general (think AS400 systems). We have a VERY large network of client and data center network devices. I noticed that we had some very large holes in the way we monitored a network with over 100K+ interfaces. I built a tool that basically Scrapes automated CLI output from our head end routers and plugs that information into a database. Specifically BGP routing tables and finding the best path to our services from one of our HUBs. This told us what service was being used out of which data center, as we have about 50-100 services that we offer over IPSEC&gt;DMVPN&gt;BGP to our customers. Django and DRF Paramiko Pysnmp Postgresql Supervisord After this project I was promoted to Programmer Analyst where I just finished building a application that Builds Client VPN routers to be shipped to colo's, and customers. We have a rack of routers plugged into a rack, that networked up to a console server and a internal router. The application has a web UI where you build a router configuration through a few ways. Converting old Cisco router configurations from previous models to our current model (Using CiscoConfParse), building a configuration from scratch, or providing already made configuration. The builder provide shipping and relevant ticket information into the web gui, and it fires off and applies the configuration to the router via FTP. It then audits the configuration and adds anything missed, emails appropriate parties to inform a router is built, and enters all the information into our DataWarehouse. But in the background while all this is happening, the application is also upgrading default factory routers being put into the rack. Whenever we get a router from Cisco they come with default IOS and can't connect to anything due to network interfaces not being up. The application's background process audits all of this information for every router that is plugged in on a timed schedule and upgrades IOS and sets a base configuration for FTP capability accordingly. Once the background process sees this done the router is now in a pool of available routers for configuration, perpetual router replacement/upgrades/installs are the outcome. All built via Python. I'm a one man show as well, as I'm the only programmer in my department of about 70 people. Tired. So tired.
We lost a good guy like this once. Client gave him a huge list of tests to do, he sat on in a while, higlighted like 70% of those and said that he can automate those till the end of the month. *- No, just do them.* ...and after 3 months he quit. I'm still bitter that the company allowed this.
Use this: http://dask.pydata.org/en/latest/dataframe.html for out of core dataframe and this: http://blaze.pydata.org/en/latest/ To have a dataframe like interface over other compute and storage stuff like databases 
It's not very active, but we have /r/fxpipe for this. Dozens of us! Edit: Disclosure: I am apparently a mod there?
&gt; for a custom in house language with python I'm so sorry. &gt; a deep compositing collaboration workflow based on maya and nuke Are you going to be at digipro this year? There's a topic on this. SIGGRAPH has one too. Also, you might want to sub to the very quiet /r/fxpipe Disclosure: I am apparently a mod there?
I use it to teach. As a language it requires less boilerplate code and syntax. Students can concentrate on the logic and not the language oddities. Plus students HAVE to indent correctly, and I don't get into arguments 'but it runs fine, why are you counting off for not indenting?'
Haha yeah in house languages suck. It was for voodoo at RnH. It never really got traction because it was really a hack and they had plans that never materialized before the bankruptcy. And nah won't be at siggraph or any of the events this year. Too expensive to head down. When it's back in Vancouver I'll be there for sure.
Actually can't sub because it doesn't seem to exist? Relay was lying to me...
Thanks cartin! Dask sounds exactly what I'm looking for. Was also looking at blaze, but don't know where to start approaching how to melt in smaller chunks using it. 
That's because it's actually /r/fxpipe Some mod I am.
I'm a full stack web developer, with a bit of a specialization in backend systems, HTTP APIs, and operational security. I work for a startup company that operates a real estate data software-as-a-service business. Our main product is a Django web app, and most of the code I write is Python code for the the django app. We have a service oriented architecture though and are very polyglot. There's a good bit of server-side Javascript, Ruby, and Go in our mix as well as Python. On a daily basis I'm usually implementing RESTful API endpoints, debugging, or testing our system for performance, security, and stability. 
&gt; Haha yeah in house languages suck. It was for voodoo at RnH. It never really got traction because it was really a hack and they had plans that never materialized before the bankruptcy. Parsley was actually why I apologized. You were dynamically binding Voodoo's command language? Just had breakfast with Cyrus...
Sure! If you have any questions, blaze user group: https://groups.google.com/a/continuum.io/forum/#!forum/blaze-dev (for dask and blaze) is pretty helpful. 
Co-owner of and software developer for [HelpTeaching.com](http://www.helpteaching.com/). The site backend is implemented in Python using (primarily) Flask and SQLAlchemy.
Same boat for sure. Whenever I'm asked why I chose Python over anything else the answer is that it's the most straightforward way for me to get computers to do what I want them to do.
Oh man Cyrus was great. Yeah it was with an external interpreter talking over a socket. It queried all the parsley commands and built python equivalents with types that you could query, run help on, have autocomplete in an ide etc.. So it wasn't fast or a "true binding" but it's as close as I could get without being on the voodoo team.
Founder / CTO / Senior Dev / Senior Consultant. Beside my own company and my own project (3d procedural generation), I help team to deliver medium-to-big (python) projects. 
Have you had a chance to see one of Paul Hildebrand's talks? He presented Inside the Hat at Pycon this year and PyATL had the pleasure of hosting him on his way home. Really fascinating talk. Shame it can't be recorded. 
I'm a consultant in the Oracle space. Pretty much any automation tool our team needs, I'll write it in Python (recently, a skype bot) or Jython (which Oracle now ships everywhere, and is the scripting language of choice in the Weblogic world). Some of the products also use Jython for data-manipulation/data-pumping jobs. It's not really a "career in Python", but it saves my skin almost every day and has become necessary knowledge in my space anyway, which is ironic -- when i was at Oracle proper, I was considered a lunatic for insisting in doing things with Python.
Ah that sounds awesome. My head of department has probably seen them. Ill ask for a gist.
Same, but that doesn't surprise me. Seems the jobs are south of the 49th
Yeah man I am really worried about the job market here.
Ahh, I see now. I was thinking independent of the local python installation. I can see how having a single exe would be handy in certain circumstances. But if it's something that's going to be installed and ran on someone's computer, then you could just as easily create an msi that hides all the chaff in program files and sticks a shortcut to the exe on the desktop or start menu (assuming windows), this is what most programs do anyway.
pythonista will let you create your own scripts. but no way to deploy that script as an independent app AFAIK. can only run the scripts within pythonista. learning swift is probably going to be your safest bet
I'm curious as to why Python and not VBA? I've always wondered what came into play when deciding which tool to use. What kind of data are you working with? Spreadsheets?
I'm a Technical Artist at a big games company. Just like the TDs and the other game developer I use it for doing things in Maya, and interface between the C# scripts written for the rest of the companies pipeline. Really fun language and easy to pick up. I find its a bit frustrating when writing larger scripts but I've been using it for less than a year so it might just be my inexperience talking. 
Software Developer I work on an Enterprise Security Product that our company sells to large companies with big security requirements, things like financials and healthcare etc. It's intended to manage security over the lifecycle of products, so you tell it what you're working on and it gives you tailored advice for the various stages of development, as well as interfacing with tools like Jira and code scanning tools. It's a deployable webapp written on Django, which we both support internally for companies or via a cloud based service. Either way I mostly do feature development and bug fixes. I started out as a Co-op Student/Intern and then just sort of stayed on when I dropped out. I've now been here 4 years and am a senior team member. 
Personally if you've got a degree, I'd look south. Better pay, more jobs, more variety then "Toronto or bust", companies aren't stuck in a 1980's mentality. The healthcare system is a gongshow, but if I'm going to get taxed at the same rate as I am in Ontario, I might as well make an extra 20-40k doing so.
Agreed - also using [DictCursor](http://initd.org/psycopg/docs/extras.html) for everything. python3 (I think) only but there is also [py-postgresql](http://python.projects.pgfoundry.org/). Curious if any one knows if one is better.
Lead software engineer doing back end Web development for a consulting company. I'm technically full stack, but we're splitting up the dev team into groups by what part of the stack they are working on. Flask/Cassandra is 90% of my development.
Current: Build data processing pipelines, data driven web services, and user facing web applications in support of cryospheric science datasets. Stack includes sci-stack (numpy, scipy, matplotlib...), flask, lots of cli apps, and a fair amount of JS. Also a fair amount of deployment and CI work using puppet/jenkins and Docker as of late.
A whole bunch of django websites over the years, 50% client facing, 50% were very company specific intranet tools. Various random tools and utilities, lots of data ingestion and munging, just allsorts really !
same here. python has given so much flexibility in how I want to automate testing, from REST interfaces to expect CLI interaction on router/ap boxes. Python lets me go from 5line scripts to entire test frameworks I wrote so that the testers just focus on test logic and not worry about programming, ie save brain cycles for the scenarios and not futz with programmatic details.
I use Python mostly for data analytics. Sklearn is a great library.
Ive left this role recently, but a really common Python career in my area is Technical Director for visual effects/feature film houses. The TDs usually create artists tools and interfaces for working with high end graphics suites like Maya, Houdini, Cinema 4D, and Nuke.
Tests should catch most of this, no? 
I'll be sure to have a look!
System Validation Engineer (intern) . I use a custom flavor of python to script hardware tests on SoCs. Last year I used python to write an automated testing framework for the embedded software of vehicle displays. This was really cool because it leveraged this custom piece of equipment that spoofed signals for i2c, SPI, CAN, etc. Like others are saying, even jobs you wouldn't expect use python as a 'glue' language
How did you get started?
I got a job as a project manager at a commercial solar company, and getting customer billing history really sucked. So I started a business to fix that pain point. Pretty niche, but it really helps smooth the process of going solar.
ILM?
I'm a software developer at a visual effects company. I mostly work with Python, although occasionally some other languages. Part of my work is on legacy Gtk applications written in Python, although we're slowly moving more of our software to the web, in which case we mostly use either Pylons or Flask. Most of the software I write is to help manage projects (think JIRA, for artists) or digital asset management software, but I also work on tools used as part of the virtual effects pipeline.
I'm an senior SDET for a megacorp online shopping company. A significant portion of my work is doing code reviews, writing internal web sites, and doing test framework and development in Python. In general my programming work is split between Python and Java. 
I'm a sysadmin for an in-house Python project. It's basically an integration hub, identity management and user administration system. I'm not a dev, but we practice DevOps and I'm the sysadmin team lead so I do a fair bit of programming too, but I mostly solve small nagging issues. I don't implement larger new features usually (that's for our Scrum team). Not sure what more you want to know. The source code is located at http://github.com/unioslo/cerebrum if you're interested in checking it out. (it's a mirror, so none of the pull requests/issues are there.) 
Primarily PHP dev (I know...) but I use a *lot* of Python for everything not web related, selenium functional testing, custom build system (0.01ms to build and concatenate assets) as I find Python hugely better than bash for that stuff, use fabric to deploy. It's interesting how useful Python is even on projects primarily in other languages as it's a very powerful glue language.
I started studying math and science, then eventually switched to geomatics engineering.
I use both. Arcpy helps me iterate through data sets, mostly to produce map pages and reports that would otherwise overwhelm ArcGIS due to crappy memory management on ESRI's part. Also, recently used python (with regex) to automate the conversion of field codes to another system to get around a bug in the CAD processing software we use.
You gotta try harder than that before giving up :) http://ca.indeed.com/python-solar-jobs http://ca.indeed.com/software-solar-jobs
I haven't tried it with Pyside, but it should be possible. It looks like the PySide Windows wheels include the Qt libraries, in which case it should be easy - just add `PySide` to the list of packages to include.
I have two jobs right now, both of which use Python. My actual job is at a small hardware company, where I'm one of ~4 programmers. I wrote Python tools to control test equipment to test our parts. I also use PyLab to analyse data. The other job is at a Fortune 500 company that my actual company contracted me out to when things got a little slow. There Python is used for basically the same purpose (but I don't actually do much work with that; I'm mostly doing C). There is a slow movement to implement more things in Python. In general, I'll use Python for all sorts of random tasks also. It's my default.
I'm one of two software developers at my company. We're given our own projects that we work on solo mostly. Sometimes we collaborate and build things together. We build web applications. I'm getting some good full-stack experience. I work with Flask, SQLAlchemy, and other related technologies.
Developer in QA. I build programs to break other peoples programs. It is very fun. You are always stretching your creativity to come up with interesting things that a customer may do to your software. Some of the tools I use. Nose, Webdriver, our home built framework, ibm_db, pymysql, jenkins, SauceLabs for running our tests.
Sounds like me. I started studying Chemistry and Physics and ended up in Geography Department studying Geographic Information Science and Physical Geography/Environmental Science. 
RnD engineer working on large scale OCR of non-documents and machine learning.
I wish you guys would clean up your Github pull requests backlog. I've had one open and uncommented upon since september 2014... Would be nice to at least hear a "no thanks" or something.
Imageworks
What kind of DS things you do? I want to go into the field of Data Science so I wanted to know what are the type of things one does in this job. Like there are various aspects of being a Data Scientist (Building models, visualizations, other statistical analyses). So, what are the things you take care of?
What about using (I'm most familiar with pytest) [monkeypatch](https://pytest.org/latest/monkeypatch.html) to make the decorator return the original function? Even better, you can have a fixture that you pull into a unit test that patches all decorators, and now you it's tucked away in contest.py --- This is assuming you have no control over the decorator's code. If this is code you've written, you should modify the decorator to return the original function unmodified. In this case, a router doesn't need to prevent other callers from calling the original function, it just needs to keep a reference to the function. def remember_some_func(func): func_registry[func.__name__] = func return func @remember_some_func def foo(x): print(x)
When you add text, the link disapears.
I am a "Software Engineer 2" for a neuroscience institute. Here are some examples of things I do. 1. Control scientific and industrial cameras by interfacing with their C API. Sometimes involves writing my own C dll and then loading and using it from Python with ctypes. 2. Integrate software packages running on separate computers so that they can be controlled by a central state machine. For example, a motorized stage connected to a remote computer that is controlled via a REST api, a microscope on another computer that is controlled via serial commands, a high-speed camera frame grabber on a third computer. I make it so that a state machine that controls and automates the data acquisition can control each of them as though they are all the same. 3. Creating tools for scientists to acquire and analyze their data. For example a program that integrates timing information from various data collection nodes during acquisition so that they don't need to realign it post hoc. Or a program that they can use to load the eye-tracking movies that they collect and extract pupil location/area.
`type.__call__()` will run your class's `__new__()` classmethod, and if it does indeed return an instance of your class, it'll then run your class's `__init__()` method on that instance, before returning it. Altering this behavior would require metaclass hacking, which should generally be avoided if you don't have a good reason for it. You have heavy lifting that converts user-supplied data to your internal format. You dislike putting this code in `__init__()`. I can understand that, but it doesn't mean it's a bad design. You could factor your heavy lifting into a separate data conversion method and call it from `__init__()`. This has the benefit that it'll also be reusable in other situations besides initialization. You could also make a classmethod that does the conversion and returns a new instance, e.g. `MyClass.from_userdata(data)`. In that case, `__init__()` would be very minimal, accepting data that has already been preprocessed. I wouldn't advise going too crazy with your `__init__()` signature. It's nice when things fail loudly instead of interpreting arguments in weird ways, although many Python programmers would disagree with me.
Associate Engineer, I work for a gaming company and build either tools or services to help our agents / players. Tools will be mostly interfacing with different databases or API's to collect information generate a picture and provide it to our customer service. I've built websites to allow digital redemption for content. I've also built services that take an event stream, process the information and perform some action as a result, mostly again from the databases and api's. Finally, i just build alot of one time scripts to just do a job faster than its possible to manually. (Mass grant x content to accounts for example.) Not sure if its against the rules, but we're hiring. You can also just look at the job description to get a hand on what were working on. http://riot.com/1Lrw0GQ
Sure. Basically, I'm using it to extract informations from Python scripts. **1st example:** Let's say I'd like to get all requirements of a Python library. The following command returns to me everything passed through the setup() function, which contains the "install_requires" keyword that I can use to extract that information. python -m pyintercept setup.py setuptools.setup --handler=pyintercept.print {'cmdclass': {'test': &lt;class __main__.PyTest at 0x1078e5460&gt;}, 'name': 'pyintercept', 'license': 'MIT', 'author': 'Caio Ariede', 'author_email': 'caio.ariede@gmail.com', 'include_package_data': True, 'url': 'http://github.com/caioariede/pyintercept', 'version': '0.2', 'zip_safe': False, 'platforms': ['any'], 'install_requires': ['byteplay'], 'packages': ['pyintercept', 'pyintercept.handlers'], 'test_suite': 'py.test', 'classifiers': ['Intended Audience :: Developers', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.4'], 'tests_require': ['pytest'], 'description': 'Intercept function calls from Python scripts'} **2nd example:** Let's say I'd like to get the path to a settings file used by a certain Django project. I wrote the following handler: File **intercept_settings.py**: def x(*args, **kwargs): import os print os.environ["DJANGO_SETTINGS_MODULE"] That I use to replace the function used by Django to handle commands: python -m pyintercept manage.py django.core.management.execute_from_command_line --handler=intercept_settings.x This outputs: myproject.settings **How does that work?** Under the hood, *pyintercept* reads and modifies the compiled bytecode of the script, replacing the function you passed by parameter with your own function. From there you can manipulate the code the way you want.
Software developer for a science lab. Python is especially good because of its many scientific software packages, and because small "test" projects are extremely fast to develop in it. I also write in Java, C++, and Matlab, but Python is my favorite.
Sorry I meant optional static typing. [mypy is being added to core Python](http://mypy-lang.org/).
I'm a backend dev for an advertisement analytics company (the title on my business card says Code Monkey). Our javascript analytics code is run together with the ad banner code of our clients (assuming you don't have adblock) and it sends events to our backend, mostly about how visible an ad was. The backend to process and count/aggregate/analize these events is written in Python. We rely heavily on gevent to make sure none of our IO causes blocking and in some inner loop code on the analytics side we use cython. We process &gt;10k requests per second at peak and can run fairly efficient queries on the resulting time series data using an analytics pipeline also entirely written in python served through a flask app. For unittest and smoketests we use py.test. There are of course allot of mundane tasks related to parsing csv files or server ops/deployments, but there are also many interesting computer science problems to solve, especially on the analytics side and doing performance and memory optimization. As far as choosing a path, I think I can recommend small companies where you interact with the founders or at least where you are directly involved with the people who make the decisions for the projects you work on. Direct, open and honest communication will do wonders for your sanity.
...that know French.
I'm surprised there are solar companies in Canada 
I am a Principal Engineer at Oracle. I work on Solaris and have worked on the various Install tools (all written in Python) and now work on OpenStack integration. I live in Python at this point....
Love the pet banana slug haha!
&gt; I can suitably do this by just calling `MyClass.__new__` where I don't need the initializaiton done in other methods, as opposed to messing with __init__. I wouldn't have thought to use `__new__()` to intentionally bypass `__init__()`. The user of your class shouldn't generally have to know whether to construct the class, or reach into a dunder method to obtain it another way. But it would be fair game to wrap (or alias) `__new__()` in a non-dunder classmethod that advertises what it does differently from `__init__()`. This still gives you the advantage of offloading the conditional logic that would otherwise be in `__init__()` on to the user, but without the user being aware of the implementation details of the two methods for construction. (Even if that user is just you. ;) ) As I mentioned above, I think it's better to have `__init__()` and `__new__()` do very little work, and make a separate classmethod that returns a newly constructed instance using the heavy-lifting preprocessing.
Definitely! The problem is that theres 100s (1000s?) of teams working on internal things like you just described. If you dig into IAM, you'll see why nobody has a sellable product that does everything :) If you haven't dug into IAM, you should definitely be using IAM users for user access. IAM roles will also remove the need to hardcode keys for services running on ec2.
Quoting from http://sqlite.com/whentouse.html: &gt; SQLite works great as the database engine for most low to medium traffic websites (which is to say, most websites). The amount of web traffic that SQLite can handle depends on how heavily the website uses its database. Generally speaking, any site that gets fewer than 100K hits/day should work fine with SQLite. The 100K hits/day figure is a conservative estimate, not a hard upper bound. SQLite has been demonstrated to work with 10 times that amount of traffic. &gt; &gt; The SQLite website (https://www.sqlite.org/) uses SQLite itself, of course, and as of this writing (2015) it handles about 400K to 500K HTTP requests per day, about 15-20% of which are dynamic pages touching the database. Each dynamic page does roughly 200 SQL statements. This setup runs on a single VM that shares a physical server with 23 others and yet still keeps the load average below 0.1 most of the time. There are of course limitations: http://sqlite.com/faq.html#q5, but your hard statement is incorrect.
Wrote the sportsbetting website for a large high street and online gambling company.
This bypassing would only be in implementation (private as possible in the class) code. Any and all user code should be calling `__init__`, and should absolutely have the non-optional argument (which is why I want to avoid hidden parameters to `__init__`, since it wouldn't be truly hidden).
This is exactly what my first bullet point proposes. See that bullet point (and first comment) for why I want to avoid complicating the `__init__` signature.
Try patching that in the test's setup method using mock since for mocking decorators, you need to mock them earlier. For e.g: def setUp(self): patch('url-resolver.route', lambda x: x).start() def tearDown(self): patch('url-resolver.route', lambda x: x).stop() 
I don't think I follow. User provides data, that must needs be converted to my format, for that is indeed to whole point of the class. This needs to be done regardless of what the user intends to do with the class. I just want some implementation code, hidden in the class, to not convert back to userland-style data and back again, which would be utterly pointless.
&gt; I don't think I follow. User provides data, that must needs be converted to my format, for that is indeed to whole point of the class. This needs to be done regardless of what the user intends to do with the class. Yes, and instead of `TheClass(data)` you can have the user do `make_class(data)`. This is simple and plain and a common sort of pattern. `numpy.array`, as an example, isn't the `ndarray` class, it's just the primary way of making one.
Market Research. Complex online surveys where customers of a company are asked about in-depth about their experiences. While Python is the primary language on the backend (200kloc), when you have a billion data values to aggregate (or convert to obscure formats) we do drop into some C/C++. Fun fact: our application may well be one of the largest Python deployments in the wild, as scripting those surveys is also done using Python code and I estimate there's around 10 million unique lines of code in there. 
Don't give BS answers. You'll quickly learn in the work world that if you can't communicate your results then you won't advance very far. This goes 3x true in Data Science because you mind as well be a magician to them and no one will trust you unless you can have rigorous statistics backed up with very simple explanations of overall effects/predicitions/whatever your models are producing. Thirdly, if you're going to give a BS answer like that, at least have it make sense which your one line description does not.
I'm not certain that I'm reading your requirements correctly, but could you have a base class called Heavyweight and a subclass called LightWeight? Then just don't bother to call the Heavyweight __init__ from LightWeight? You create an instance of Heavyweight, do your processing and return LightWeight, and this is where I find out I'm completely wrong?
We primarily use ArcGIS, so yes, arcpy does get a lot of use. In terms of file management and data replication though, the core libraries cover many of our requirements.
Data scientist here as well, for a major insurance company, they hired me because of my python skills, everyone else in the actuarial R&amp;D dept. uses SAS, Emblem or R.
Use an `@classmethod` as a second constructor, so you can pass altered stuff to `__init__`, or change the object after it's initialised, then return it?
I think this is what i'm interested in doing. So are most of your projects usually one offs and the occasional upkeep/feature additions? depending on internal company needs?
ok
Sorry perhaps I misspoke. It's not a BS answer, you can do it quite easily by clicking the mouse a few times in excel, (data -&gt; get external data -&gt; From SQL Server etc). He asked how that works and I explained Microsoft's push to support ODBC drivers through it's products (I remember Excel 2007 having tabs for MySQL and PostGres but I only see SQL Server in Excel 2013). I always remember the story backwards because he became so focused on discussing Microsoft and ODBC drivers it sort of derailed the interview. This was several years ago. That being said, I completely agree with you. Giving BS answers is a good way to not remain employed, or at least, not have your colleagues like you. I would rather embarrass myself and say, "I don't know let me update you with an answer via (email, our meeting tomorrow, whenever)," than ever BS my way through something.
I work as principal developer (the position above senior and below lead in my company) at an european animation studio. I mostly do backend-related things like: - Database management - Render queue frameworks, auto wrangling system and automations - Periodic statistical reports - JSON RPC APIs (implemented using Django) which we use mostly as a gateway for the DB and the storages but there are also other RPCs for misc things - Sometimes Maya/Nuke/other plugins (which are scripted in Python) but other people usually take care of that. - Since I've written several base frameworks and libs that are used by many people at my company, I also provide training and support for other developers using them. - And of course, support and bug investigation / finger pointing / fixing, usually related with processes on the render queue.
In my previous job I was a Java developer for a really big project for a multinational. It's not easy to run Java from the command line, so we had a mess of batch files and perl scripts which ran the Java processes. I rewrote all of those in Python, and designed a system of targets (like ant or maven) so that we could easily run a command without caring whether it was in Python or Java or PL/SQL or whatever. Of coutse it also got all the classpath and so on correct. There's now thousands of lines of Python in the product. 
Think of it as this: The job of `__init__()` is to instantiate the class, not to be nice to the user. If being nice to the user requires added functionality, then there should be a different interface for that (`make_class` in GP's example).
Hm not necessarely, two of the 4companies I worked with were english speaking almost exclusively. Meaning the professionnal and personnal convos were in english except for the few french people there. Gotta look in small companies though, otherwise , from a certain number of employees if a certain percentage of those are french speaking, the official communication has to be in french.(this is super vague but it's a memory from 3yrs ago) Otherwise, it's a great reason to learn french, SO MANY JOBS
Head of R&amp;D for a company that provides services and apps for mobile operators. Right now I'm working on integrating with a new telco in Southeast Asia, using Perl and some Python. 
Also awesome community, check out montreal python !
Business Intelligence - I use Python regularly to scrape data off the web, data manipulation/transformation, interact with our data warehouse backend (netezza), and do statistical analysis. My job description didn't specifically require a python background but it makes me 10x more efficient than my colleagues and is the reason I got the job offer initially.
Sounds like you misinterpreted the question. My job is specifically that: realizing actionable intelligence through data. What does your analysis mean for us strategically? It's an important question and one that reflects how useful, ultimately, your work will be to a company.
Wish I had read your response before I posted. You put it perfectly. Very few of the people you work with/work for will data scientists. How do you convey the value/message of your work? You better be good at painting a picture.
Hm, not sure these topics covered will be specifically useful in my area, but I might just try this out for fun and free learningstuff. Regardless, this is a cool idea and keep it up!
exactly. And it applies to every position.
I'm interested in analyzing my local weather patterns as a hobby with the hope that I might be able to do a little better than predict a "40% chance of precip" every day. Do you have any recommendations for starting points for libraries and data sources?
This is me, basically, but instead of Backbone and CoffeeScript, we use Durandal + Knockout and TypeScript, and MySQL for the db.
Ahhh, well thats good. Interviews are hard, weird, and ineffective. BS answers (and environments that pressure you to give them) are more trouble than they're worth in this market, and I was all on board that ODBC train and think it was a shame it never got farther than it did. Of course I'm also on the ANSI compatible SQL train (which is why my products never need much work porting to different databases although SQL Server has its own set of pecularities ie)casting to a date) so I might be in the minority on that last one.
Thats what I've done all summer! My coworkers think I'm a wizard because I figured out how to do computationally intensive Arcpy functions in parallel using some basic stuff from the multiprocessing module in python 
Oh right. This is the answer I was looking for, as it turns out...
I just tried your technique for collecting tweets (doing 30000) and ran into the following ``` TweepError: Failed to send request: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')) ``` Did you run into this at all? I thought Tweepy would handle this for me because of the `wait_on_rate_limit` but that seems to not be the case. According to my Google searches this is because Twitter resets the connection on the underlying socket and Tweepy doesn't seem to handle it. EDIT: [here](http://pastebin.com/SpmdxYbf) is the full stack trace
This isn't my career, but at my last job I did a lot of Data Analytics with python. We had a beefy database cluster which did all the hard crunching, python handled message queues, formatting, emailing, automation, and outputting things in pretty formats. If you ever need to do serious number crunching.... please don't do it in python. Took my last company a while to learn that lesson. Edit:// If you're interested in libraries, I primarily used: boto - interacting with AWS Cloud services; psycopg2 - for the database cluster; pymongo - for a mongoDB instance; a bit of django/twisted for the async engines;
I'm not able to replicate this. I don't think it has to do with rate limit. What country do you live in?
Software dev currently working at a logistics company. We make software to manage a warehouse. (a wms) We write a curses application (this is what the warehouse workers use) and the backend for a website (this is what the warehouse manager looks at). 90% python, the rest being shell scripts and raw sql. (The 10% is just ancient stuff that works great and thus presents no real reason to switch to python)
I'll take a look at this a little bit later. I think you're on the right path though!
This is probably the best solution to create everything. import string def in_range(letter): letter = str(letter) upper_cases = string.ascii_uppercase for i in range(6, 27, 7): final = upper_cases[i:i + 7] if i+7 &lt; len(upper_cases) else upper_cases[i:] if letter.upper() in final: return "{}-{}".format(final[0], final[-1]) return "Not a letter" print in_range("N") **EDIT** Smaller code
I was specifically asked how I would get people like admins, finance people, HR people, etc. to take data and turn it into results. I don't think I misinterpreted the question.
I replied below what you're probably looking for, which is string splicing. Here is is again. import string def in_range(letter): letter = str(letter) upper_cases = string.ascii_uppercase for i in range(6, 27, 7): final = upper_cases[i:i + 7] if i+7 &lt; len(upper_cases) else upper_cases[i:] if letter.upper() in final: return "{}-{}".format(final[0], final[-1]) return "Not a letter" print in_range("N") 
They were looking for a non-technical answer and he gave them a fairly technical one. An answer like "I'd provide future forecasting of solutions to problems based on the current direction given to me by managers or based on projects. By being able to analyze data trends early and head them off before they get out of control, I can give executives the ability to keep this company on course or even to steer it in new directions. This can be achieved through weekly action reports and monthly meetings with a powerpoint presentation". Boom!
The fact Python is dynamically typed doesn't mean you should use Python to do inconsistent, unfortunate things.
It actually looks like /u/diesch essentially has what I need: def is_in_range(range, letter): return range[0] &amp;lt;= letter &amp;lt;=range[2] is_in_range('A-F', 'S') 
I wouldn't call it more useful, per se, just that it provides prettier default plot styles than matplotlib.
What's your favorite language and why is it favored over the others (by you)? 
How long is a piece of string? Your answer will be highly dependent on what you're actually doing. More info?
These links are awesome, thanks!
Hi, I'm a grad student in ECE researching analog and mixed-signal integrated circuits. I also do consulting and research contracts on the side. I use Python (IPython/SciPy/NumPy) when I can for simulations or postprocessing/visualisation. Generally this involves systems- or controls-level stuff (e.g. analysing the stability of a circuit or design approaches based on a model, or getting pole-zero information from a parametric sweep from VLSI simulation software and then post-processing them and simulating their response in MATLAB to obtain a view of how certain parameters alter performance). I've been doing this alongside Matlab for a while. Unfortunately, Matlab's toolboxes still have a bit more power than SciPy, which really only implements the core of Matlab's libraries. I also do some freelance/research software work. Right now I'm working on implementing a character-recognition application as a demo for a professor's general-purpose classification methodology. I'm using Python with numpy and pillow because it's the fastest to develop with for this application (even though it's slower at runtime than optimised C, in this case we don't care about demonstrating speed). EDIT: Changed "freelance" to "consulting". Technically I've freelanced before, but it's not quite representative...
Kivy is the only mature platform for what you're looking for. That being said, I would not recommend Python for iOS development. A lot of the tools you will require just aren't supported like they are with Swift, Objective-C, or even Cordova. If you aren't a big fan of Apple's languages.....you might want to look into Cordova and the Ionic Framework (JS based).
Do you have a sound format? Are you trying to match exact clips? — e.g. the clip was cut from the original podcast.
I've had success with this: https://github.com/Zulko/moviepy/blob/master/moviepy/video/io/ffmpeg_writer.py
But you don't want to introduce bugs into something because of a poorly scrutinized pull request. It's administrative workload.
I have a mental block against Python because of the tabs as syntax. But your comment was a bit of an epiphany. The tabs enforce a style that let's a new programmer read everyone else's code. So I can have a personal preference that it's stupid, but that doesn't matter because it was a trade off for a higher purpose. A purpose I don't appreciate having never collaborated with someone else on a program. Maybe now I can learn it.
And this is now the implemented solution! I wrote a (nearly trivial) `def _copy(self, other):` method that copies the data in `other` to `self`, and `__init__` begins as follows: def __init__(self, data): if isinstance(self, type(self)): self._copy(data) return
Correct, exact clips. And I'd start with an mp3 and convert as/if necessary.
Developer at a Fortune 100 company on a desktop app team. Rewriting our test automation framework for said desktop app in Python (and not regretting a minute of it!)
Product manager. Use a ton of python for crunching data on tests &amp; user behavior. Not the focus of my career, but part of it
4100 keeps coming up. That's interesting to me. From the name RGB24 sounds like it might be bitmap based. What is the file size that 4100 frames corresponds to? Does it always freeze at the same file size? Is there a variance in the frame count it freezes at? That's where I would start, but I haven't looked at your code :)
You don't do Python _and_ R? That's kind of the standard since Perl + SAS started losing footing.
Nuclear reactor designer here. We use Python for all sorts of things. We built a giant reactor analysis framework in python that allows us to manipulate our models easily. The system has lots of pure python analysis modules in it but lots of the heavy lifting is done by old fortran codes that we use python wrappers to make usable. Running lots of cases in the supercomputer with mpi4pi is lots of fun. 
Security researcher, developer background. Doesn't seem like any other sec people in here, so I figured I'd put it out there.
Game developer here. I work in a mobile game company. I was supposed to do backend programming for our games in php, but noticed that we were missing proper tools to automated builds, test,and analytics. So I went full python on this and I didn't write a line of php since. 
You can be more memory efficient at the cost of speed... I once calced the primes from 2-1million on a C64, in memory. Considering that the C64 only has 64K, I did some 'compression'.. I figured that I could use 1 bit to represent each number... Then since we don't need any evens, that eliminates half the bits. And we also don't need 5's (if we assume 2 and 5 as primes).. So we've eliminate 60% of the numbers, I only need to start 400,000... 400,000/8bit = 50,000bytes! So this means that each byte of 8 bits can represent a range 20 numbers: * byte 1 = 1,3,7,9,11,13,17,19 * byte 2 = 21, 23, 27, 29, 31, 33, 37, 39 etc.. This allows me to represent all the numbers 1-1million in 50k. I was able to perform the sieve on the c64 in under 1 minute.. Which, when I originally thought of the 'problem' would be impossible. I wrote a blog article a year ago about it: http://www.technobabelfish.com/2014/07/calculating-primes-numbers-on-c64.html
Looks great, might use it for an upcoming project! I'm really liking Pelican for static sites. 
I care deeply about reddit as an open source project, and it hurts me that we're so far behind, but `git merge`ing the code isn't the hard part. Making sure it works for reddit's scale, maintaining code quality and consistency of features, not causing new bugs or regressions, and deploying it to production are all much bigger parts of the equation than the merge. I totally agree we're not great at it right now, but it's not like we completely ignore pull requests; we're just really friggin' busy. For reference, while there are 72 open right now, [there are 582 closed pull requests on the repo](https://github.com/reddit/reddit/pulls?q=is%3Apr+is%3Aclosed), a huge number of which are merged in some form despite what github's merge indicators show, and open source contributors outnumber all time engineer-employees by a factor of four.
After reading that it just seems like you need to hire more competent people *edit for those downvoting, have you even read the comment he linked? it shows sign of poor leadership, incompetence and just an overall failure at prioritization and lacking sense of ownership. At least it clears things up and shows that it isn't that they don't care and have been ignoring people, they just suck at their job.
I'm sure there's an orchard out there looking for a Python dev?
In my setup, I have a script that runs a given python file on any change to any .py files in the same directory. And I use unit tests to test my code. This give me instant feedback on the code that i write every time i press save. Is it faster feedback you're looking for?
DevOps Engineer here. I work for an [information security company](https://www.securitycompass.com) which develops a web app called [SD Elements](https://securitycompass.com/sdelements/#!/overview). Our app is written entirely in Python and is used to help developers write more secure code. My job typically entails supporting our dev teams by not only providing them platforms on which they can develop SDE, but also helping them by automating as many of their day-to-day common tasks as possible. To that end, I typically end up using python-based technologies such as [Ansible](http://ansible.com) and [Fabric](http://fabfile.org) for build automation as well as automated system provisioning, and I do a good deal of work with [Django](http://djangoproject.com), as that is the app framework we build SDE on, however we have a couple of internal apps which make use of [Flask](http://flask.pocoo.org) as well. Aside from supporting devs, there is a certain amount of client support as well. This comes usually in the form of custom django management scripts or other custom functionality.
I want to say django and careers.stackoverflow seems to agree with me: [Pyramid](http://careers.stackoverflow.com/jobs?searchTerm=pyramid): 5 Jobs [django](http://careers.stackoverflow.com/jobs?searchTerm=django): 67 Jobs [flask](http://careers.stackoverflow.com/jobs?searchTerm=flask): 15 jobs I'd also recommend taking a closer look into the working of AWS, digitalocean, et. al.
Nice! If I hadn't designed my own theme, I'd probably pick this one instead.
Developer on a large-scale regression test at Google. :) The vast majority of the test is written in python, with some performance-critical parts written in C++. Essentially my job is to make performance improvements and quality of life improvements to the test (it's run by &gt;400 devs, as well as automatically, about three times every 45 minutes). Essentially the test brings up an existing build of a bunch of servers (order of hundreds of shards), and a new build of the servers, and tests for any differences in their responses to requests. Of course, because of the number of servers and the complexity of their interactions, there's a whole lot more to it than that. It's interesting work - there's always something new that comes up.
Tornado is a dream. Look into that.
Some great advice, I have been looking around locally for unpaid intern work that revolves around Python to get some free experience I mean for someone with no qualifications but a keen interest this seems to be a great way to get the foot in the door
I am a microservice servicing a swarm of other microservices that are serving up the future in one big hot sticky mess.
Django
Where do you work? How did you get the job? I'm very interested in Openstack development.
My thoughts exactly. I get the feeling that the 2/3 split will do a lot of harm to the Python community in the coming years, since no one seems to have a good idea on how to make the transition. Some people even think that this could be our "Perl 6" moment. The whole problem was demonstrated nicely again in Guido van Rossum's keynote at the Europython yesterday: First, he told everyone to please switch to Python 3 because it is SO MUCH BETTER than Python 2. Then, he told everyone that he would not add any more feature to Python 2 so the language was effectively dead (apart from urgent security fixes maybe). Finally, someone asked him which version of Python they were running at Dropbox (his current employer), to which he answered "Oh, we actually run a modified version of Python 2.7 (so Python 2.8?), because our code is not compatible with Python 3". If not even the company that employs the creator of the language and probably has the largest pool of super-talented Python developers (apart from Google maybe) knows how to make that transition without breaking their business, how are others supposed to do it?
Pythonista has a nice xcode package in which you can put all your code and other resources and it lets you compile it as a standalone app. You can check the forums for it.
1- use ffmpeg to convert the files to lowest quality possible, in wav 2- use a cross-correlation algorithm to find the time stamp
sqlalchemy
That sounds pretty good actually, but I am writing pygame scripts and the entire game would have to reload every time.
It was discussed in a presentation at SciPy2015 and anecdotal evidence from others. 
Thanks, I'll have to look up a video of that presentation 
&gt; but it's not like we completely ignore pull requests; we're just really friggin' busy. Could someone not take an hour out of their day and close some of the smaller issues? I tried to make a few changes and got ignored. My commits just shortened some lines to make them clearer. A yes or a no for [this commit](https://github.com/Matthew94/reddit/commit/fb19a8f8e8506cf8fe6107fe5a046d51aa5810e5) would take only a minute or two but it's just floating in the aether. If I had got some communication, even a no with a reason (e.g. we don't use `map` or something like that) then I might have been inclined to continue and make better changes. Instead the cold silence just made me wander off. On another note, what version of python is reddit written in? I assume Python 2 due to reddit's age but I can't find a mention of it anywhere.
Do you have any pointers / guides on where to start reading about this? Seems neat to know! 
Mongo is great but sometimes overkill. Zodb is good for a single application that does not need to share data.
Sweet! Didn't know about that one. Subscribed!
To add what you said, this is (usually) a good situation for the usage of `@classmethod`: class MyThing(object): @classmethod def make(cls, data): return cls(do_heavy_lifting(data)) thing = MyThing.make(my_data) 
Not bad, I've been wanting to create my own theme too based on material lite: https://developers.google.com/web/tools/material-design-lite/index?hl=en
&gt; Have you used it at all? Yes, I've wasted a nontrivial fraction of my life on porting code. &gt; Or looked up the fundamental underlying changes that were made? Yes. I am extremely familiar with the changes. &gt; It has made python a much nicer language (IMHO) to programme in. It has added warts and removed warts, created new pain and relieved old pain. The benefit isn't worth the cost that this has wrought by orders of magnitude. I am tired. I have been helping people with Python 3 porting for the better part of a decade, seen the pain. I've been helping people learn Python for a long time, and seen how much confusion this business has created. And then to see a shop like Cloudera create useful software in the only version that supports the tools they are using and then have people whine about their releasing it open source..........what the hell. I'm tired. The only people who think Python 3 is good are silly fans who think promoting Python is a good thing and want to toe the party line and people who know so little they don't know what's going on. The rest of us are using Python -- and many of us deeply, many of us at an extreme expert level, many of us contributors to the project -- because we wanted to write good programs. This 3 business has only got in the way of that and wasted our time and others'. &gt; It has made python a much nicer language (IMHO) to programme in. It really hasn't. I don't know how you can think that. It has made the act of programming Python more confusing and more painful, and introduced all kind of unwarranted drama.
Yep, I've been using this one lately as well.
That's good then. I remember reading that Twisted was a giant pain in the ass to port for a variety of reasons.
If you are on a Unix machine, add executable permissions and put it in your ~/bin folder. On Windows, you'd have to explicitly invoke "python.exe etym.py [search term]", which makes it less useful. I guess you could make a power shell alias with an explicit path. In terms of packages, it needs lxml and requests, which are great to have anyway.
Here is my PYTHONSTARTUP script : http://0bin.net/paste/twwq8tRFK77ZVXjo#emGBRHiYFqWy1F5eec1xS5-u0zwKsIifQZNUhNLzvj+ You will notice in there something like (comments are in french, just ignore them) : class Store(object): def __init__(self, filename): object.__setattr__(self, 'DICT', shelve.DbfilenameShelf(filename)) # cleaning the dict on the way out atexit.register(self._clean) def __getattribute__(self, name): if name not in ("DICT", '_clean'): try: return self.DICT[name] except: return None return object.__getattribute__(self, name) def __setattr__(self, name, value): if name in ("DICT", '_clean'): raise ValueError("'%s' is a reserved name for this store" % name) self.DICT[name] = value def _clean(self): self.DICT.sync() self.DICT.close() python_version = "py%s" % sys.version_info.major try: store = Store(os.path.join(TEMP_DIR, 'store.%s.db') % python_version) except: print('\n/!\ Un session utilisant le store existe déjà. On ne peut pas partager un store.') It's basically a quick and dirty NoSQL store I use in the shell to save objects that I don't want to rebuild in my next session. I just do : store.any_name = my_stuff And it's saved. To retrieve it: my_stuff = store.any_name And that's it. It works on Python 2 and 3, by wrapping shelve and making sure an instance is always available in my shell. it's not fast, but for scripting I don't need fast, I need convenient. Now, I got hundreds of Mb, I'll json or pickle .dump() it into a file. If I need relations and the ability to query, i use sqlite with peewee (https://en.wikipedia.org/wiki/Peewee_ORM). If speed is important, I'll go for redis. All in all, the first store and files are enough for 99M% of my scripting needs. 
What are your thoughts on Go?
That's awesome. It never occurred to me to wrap something like this into a script and make it available in my PATH. I constantly use: * requests * csv * json * shelve * farmhash * etc... 
Hehe, okay you're tired, and evidently have had very laborious experiences... Personally, the first large scale project I did was in 2.7, and it was an encryption based project using SMS as a medium.... This was super painful. I rewrote it last year in 3.4, and the unicode changes made everything beautifully easy. But I've been using 3 for a few years now, and I haven't had to port much... so I'm not so tired. Perhaps my lack of tiredness makes me a little more susceptible to accepting new things... and seeing the improvement, not just the headache.
Automated test engineer. One of the lead devs for the test framework that allows us to test multiple different product lines across various versions (Currently working on 7+ linux distros, solaris, windows, hpux, freebsd, aix). There's a good amount of expect-style parsing that we can't get past, some webserver testing (using requests), cross-network scripting w/ rpyc, and crypto ops w/ ctypes. Job also entails a lot of work with jenkins integrations. 
Really nice work! Keep putting useful stuff like this out there, and you'll probably be surprised how many random people you meet who say, "hey, I've read your blog!" It's pretty cool.
&gt; devops I keep seeing this word and have never had a satisfactory explanation for what it means.
It's a huge step in the right direction and has a lot going for it (pun not intended). My [little](https://github.com/reddit/tallier) [experience](https://github.com/kellegous/underpants/) with it has been pretty painless. It also has a really rich ecosystem of libraries now, which is great. I'm not a huge fan of some of the decisions though, like the lack of version pinning in the dependency system or how `nil` can still rear its ugly head.
[link to my app](https://camo.githubusercontent.com/be4f84f693ed3e1ff1ed12d1c51bdfdf41b9ed8e/68747470733a2f2f70702e766b2e6d652f633331323832342f763331323832343839302f363539332f4b6d7366434f5834385a632e6a7067) Simple as that
Cool! Haven't heard of that yet but will look at it for sure!!
Ha! You learn something new everyday in life. Thanks
Nice vm. Thanks for sharing.
That looks great! Thanks for taking the time to provide the snippet!
If the list of solutions actually mentioned the correct data structure to use for this, I would have continued reading.
just a minor nitpick, pep8 says use snake cases instead of camel cases, use `get_subreddit_users` instead of `getSubredditUsers`
How about: bool(re.match('[N-T]', 'S')) # True
Or your can add/change the \_\_cmp\_\_ method! 
Fair enough, just making sure you know.
Looks useful for genetic programming.
I don't think it's possible with kivy - probably such widgets don't even allow opengl. It might be possible to get python involved by manipulating such a widget with pyjnius, but you'd need to work with and use the normal android api to do so, including modifying the java backend of e.g. Kivy's [python-for-android](https://github.com/kivy/python-for-android) and probably changing how the pythonactivity is created to run only in a service. So maybe something like this is technically possible but probably not what you want. I can't speak for sure about other projects, but I haven't ever seen widget management demonstrated with python.
Even better. My main contribution here was just pointing out that one doesn't need to re-invent the wheel. Essentially the OP is looking for a Regex and didn't know it. ;)
Sounds interesting, could you elaborate how it could be applied for genetic programming? Do you mean using the VM for program representation?
Hi joshu, feel free to share alternative solutions if you wish.
`sys.exit` in library code sucks – way better is to raise an ImportError again, with the augmented error message that *includes the original message* (because else you hinder diagnostics of snafus).
I'm not doing your homework for you.
When I was learning Ruby from it it didn't seem to be that great. I'd recommend a book instead.
Some people feed the hungry, some people donate millions to charity, and some people replace complex PHP systems. Thank you for your public service.
I don't think so, at least not for beginners. The instructions are vague and there are no explanations to answers. If you are stuck, you basically have to search the forum for the exercise title and look for the correct answer.
Execution. In GP, you need a small, safe execution environment you can run the computer-generated programs in. Personally I go stack-based but many approaches use register based VMs. Yours has no frills and just enough simple transparency so as to be useful. The only thing holding you back would be execution time; you usually run thousands or millions of programs at a go.
Perfect answer thank you I will do exactly that. Would give gold but I'm broke so sorry :3
Great, wouldn't have thought of that! Thanks! :)
ESRI has a blog post about multiprocessing that I found helpful. http://blogs.esri.com/esri/arcgis/2011/08/29/multiprocessing/
no. check the links in the sidebar of this subreddit. i'm fond of Learn Python the Hard Way (for true beginner programmers) or Dive Into Python (for programmers who know another language but want to learn Python). there's also a very friendly community over at /r/learnpython that will help you if you ask nicely.
I work for a utility company. I write code that runs on small embedded Linux boxes that relay power measurement data back to our servers. In college I focused on embedded programming and architecture/organization. The primary language when I started was C, but midway through became Python when Raspberry Pi and Beaglebone-like platforms became popular. It's nice when Linux (and cPython) can run on something the size of a thumb drive.
Use pkg_resources.get_distribution, as catching ImportError maskes a possible deeper ImportError. import pkg_resources try: pkg_resources.get_distribution('plone.dexterity') except pkg_resources.DistributionNotFound: HAS_DEXTERITY = False else: HAS_DEXTERITY = True http://do3.cc/blog/2010/08/20/do-not-catch-import-errors,-use-pkg_resources/
Thanks for these resources! Now I have a nice fat RTFM queue to get started with. I may indeed ask you for more once I get my head around the basics, appreciate the offer.
Impressive! But wheres F# :D. Here's some more links * http://fslab.org/ * http://fsharp.org/guides/data-science/index.html * https://groups.google.com/forum/#!forum/fsharp-data-science 
Less important: - Don't do `if not foo: pass;; else: ...`. Just do `if foo: ...` - Don't test for Python version to choose `/` or `//` for integer division. Just use `//` - Don't use `//` and `%` -- just use `divmod` - Don't specialcase digits and letters. Just have a dict with both `'4'` and `'f'` in it - Don't call `str` when it isn't doing anything - Put your imports at the top of the file.
If it's not obfuscated, yeah. Obviously it's a lot easier than using IDAPro and/or OllyDBG. 
Thanks For AWS, its speed like fluctuates, i don't think that is the right word. I tried AWS before and I had problems. I explained this to my client, but he wanted to see for himself and there was the same problem. When I moved it over to digitalocean it ran fine. So right now we are trying to figure out the optimum machine for scraping on gandi you can set the specs. AWS I think is designed for raw number crunching, like statistical analysis or something. From my limited research they seem to be the cheapest in this area. 
Ok thanks, good ideas also. From the answers between you and firebyte I am starting to get some ideas. 
Probably anything in /r/SubredditSimulator. I like bots that do their own thing and don't come wandering into threads unrequested, and the subreddit sim bots are hilarious. 
It's a good way to learn "how to do xyz" but you won't learn the why of doing it. (Which in my honest opinion is more important) So I'd strongly recommend checking the sidebar
Thanks for the advice. I'll fix this problem.
Just add a Gitignore to your project specific to Python. Welcome aboard :)
Thank you! Will go over and fix. BTW, I didn't know divmod even existed. Thank you very much!
That's not very nice. You can be critical, but leave the reasons behind it at least. 
I feel like I'm missing something here... why do you need a vm instead of just a threading implementation?
I'd encourage you look at PEP8, the python style guide. https://www.python.org/dev/peps/pep-0008/ If you could reduce your code to 80 characters wide it would be much more readable.
Unless the data belongs in a maintained db, I usually just "import cPickle as pickle" (as long as I trust the content to be safe).
I apologize, I'm still pretty fresh to Python. I'm just trying to contribute what I learn. Hopefully since I've fixed some mistakes you can forgive my sloppiness.
I just forked your file and made a few edits according to styling. I didn't check functionality at all, but you might want to look into testing this out....
Heh this is the site I found and have been working from. His explanations are really nice and accessible. 
It's a pull request. https://github.com/cinemacookie/Convert-Base/pulls
For Python 3 you can do the following: import string base_chart = dict(zip(range(10, 37), string.ascii_lowercase))
Great find! I love how robust this package is.
I know, but the point is: I want programs that *force me* to use Python structures. I don't want to solve programs using C-syntax Python. I want to be familiarized with the structures. But thanks for the link, it's a good reference for programming challenges! I'll follow that subreddit right now.
Before anyone shows up to say something about the GIL, I would suggest you read http://www.artima.com/weblogs/viewpost.jsp?thread=214235 The GIL may be inconvenient but it isn't exactly dumb.
Ipython. No integration with vim, but I don't find it necessary. 
Don't apologise for doing something and putting it out there, everyone starts somewhere and the internet is full of dicks who will tear you down.
&gt; I was wondering what you guys thought are the best Python skills to help differentiate yourselves. Honestly, write something non-trivially useful. The language does matter here even. I've seen a lot of engineers with great resumes and problem solving skills in an interview but no projects of their own. Sure it's not a requirement to differentiate yourself this way but it really helps, shows that you have passion and that you can apply it without direction. Sure, knowing some modules or packages can certainly help in building something useful. But in my experience you're more likely to figure out exactly what interests you and what skills you need to pickup if you set out with the goal of building something.
Thanks for the good advice. It's always been hard for me to think about (only)myself but I'll try to think of useful programs for me. From your perspective: Do you think that something like "record sales by: alphabetical order(song and album), topic, and genre" would be a very good example?
You're
You're thinking of a genetic algorithm.
So, I'm past the one year mark at my first development position. I've made a minor name for myself in my local community. What was my differentiator? Games. I picked up PyGame and I started hacking. By the time I started applying for jobs, I had half a dozen projects that were playable (If not pretty). I'd participated in two game jams. While applying for jobs, I was given a hiring test that revolved around building an AI. While doing my job search, I started freelancing web development. Starting with small mods to Drupal and Wordpress, then full blown flask apps. When I got news about the position I eventually got, the recruiter cut my resume down to nothing except my side projects. I had a tech support job, a PA job, and freelancing as a web dev, and only one solid project to show for it. My shop is small, and the CEO was the first interviewer. He asked about the website and the games. Some pointed questions about why I did what I did. The server lead was my second interview, and he wanted to know more about my general experience with things like web apis (I was lost). I got the job. And it's been great. My professional life is Web APIs in Python and Go, I participate with the local meet up group regularly and have given tutorials on Pygame three or four times over the past year.
Package distribution. 
I recommend Randal Olson as well http://www.randalolson.com/blog/
I know the comment wasn't directed to me, but I'd like to note that command line vim works just as well on Windows as it does on *nix systems.
When I first heard of Python, my thought was, "This looks like BASIC. No way anybody's using it for anything important." LOL, I was wrong. I just got hired as my first job as a developer. I start Monday. We're gonna be doing software for point of sale transactions of credit and debit cards. In Python.
This still returns the html I don't want.
No autovivication
If you want to scrape the js generated code, then do it like I do here with selenium. http://johnpauljanecek.github.io/using-javascript-with-python-selenium/ With firebug check out the http requests, maybe it is being generated with ajax. If that is the case, find the url it is calling and either use selenium requests or call the request directly in the browser. There is another post on my blog that shows how. Usually the request is returned in json format. So you don't even need to parse.
I've always used pickle, but I'm trying to get into the habit of using JSON.
How is this racist comment top post? I don't see how their ethnicity has anything to do with the quality of the content. 
Could you please elaborate? What exactly you don't like?
From what I understand pyglet is great as a widget in another GUI toolkit. It can be used by itself, but I've never seen anything with a native look and feel when branded as "pyglet-only". This can be a choice (to make your application looking unique). But I would strongly recommend against it (not everyone can create a blender-like GUI and I personnaly find it not great). So except if your media player basically has no GUI features standing out (like mpv), I would still choose a proper GUI toolkit. Did you consider using GTK? It's LGPL so as long as you don't change GTK code itself, you don't have to provide any source code. You can use it in commercial products. A few years ago, Windows support was lacking but it's working very well now (that was one of the two main reasons behind most project migrations to QT then). As a bonus, you can use Glade (think QT designer for GTK) to design your GUI in an easy and maintainable fashion. You may read that GTK is not as full-fledged as QT. What is really meant by that is that GTK cannot connect to the internet by itself, it cannot play a soundfile by itself, etc. That's because QT is a GUI **framework** while GTK is only the GUI part of a framework (GObject libs). Some like the fact that you can do pretty anything with QT without resorting explicitely to any other library. That's fine. I, for one, don't like being force to provide half a hundred of MBs just because I need to display two windows. So if you want to perform a fair comparison, you have to compare QT to the whole GObject framework (to which GTK belongs) which is also cross-plateform and can be used to do pretty much everything. Note that I don't intend to start a flamewar: QT is not fine, it's **great**! My point is: GTK is great *too* and it would be a shame not to consider it now that most of the mess is fixed. :)
You are the **embodiment** of what I was saying: poor souls implementing stuff that already exist just because there is no reference to it out there. ;-) I can't count how many times I implemented fairly complicated stuff just to figure out that there is a scipy/scikits function just for that... Exactly what you've just experienced :-) That's why I find it very important to talk about these functions, even if your purpose was teaching. Glad I could help.
Lambdas allowing only one expression.
 import bson bson.patch_socket() s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) s.connect(("127.0.0.1", 12345)) s.sendobj({u"message" : "hello!"}) OMG, what abomination is this. Monkey patching socket to magically send bson? We have to be better than the ruby clusterfuck. This is not the way
I had a look and they just say it's better to use absolute imports for your own code. They may have eased off with Python 3 which makes the relative imports less ambiguous.
Good answer. A lot of learning material I've seen so far completely neglects rote learning, something that Zed Shaw (as disagreeable as he is) has promoted for a long time. You wouldn't teach someone how to drive by handing them the manual to the car. Same can be said for learning musical instruments. I used Code Academy and LPTHW for getting into Python (coming from other languages) and I think both are some of the best at what they do. Sure they don't teach you "everything" but neither claims to do so. What they do give you is a quick and easy way into programming and the syntax of Python. Also +1 for the guy who mentioned codingbat. Great resource. 
Great news ! Thanks for sharing.
Thanks mate. I'll give it a try. I'm on Ubuntu 14.04 by the way
Almost all of the data displayed is either JSON or XML from a SOAP API. [Check here](http://i.imgur.com/eiVKrH5.png). You can right click on the URLs and copy or open them in a new tab. http://www.stubhub.com/shape/search/inventory/v2/?eventId=9186789&amp;sectionStats=true&amp;zoneStats=false&amp;start=0&amp;allSectionZoneStats=true&amp;rows=20 In case of the XML file, you can play with the different parameters. Like increase "rows" to 200 include or exclude "sectionStats" and "zoneStats". If you try to access it programmatically however, you won't get anything. They use [tokens](https://tools.ietf.org/html/rfc6750) for authentication. Right click on the URL and "Copy as cURL" will give you everything you need to access the data. 
It is a buzz word like "cloud". &gt; Hasn't it always been this? I'd say no. I think you would have a Systems Administrator who looks after your servers/networks/infrastructure. They don't make software products they just keep everything working. You'd have a developer who knows nothing about Linux, networks, security etc. I see DevOps as those two areas merging into one. Tech has become faster and easier and businesses can hire less staff if their devs can do both. Maybe I should say sysadmin instead of devops. BUZZWORDS!
Have you seen random.sample()? It picks a selection of items from a list much like your loop that appends to words. Presumably that would also solve the infinite loop problem you've noted in comments.
Though I do like how much sense they make once you've got 'em. Literally just an `import antigravity`, and you've got access to that library. It confused me a bit, going into C#, that the `using` statements were syntactic only, and didn't tell the compiler I actually wanted that module.
I recently graduated with a Bachelors of Science in Computer Science and was able to demonstrate competency in general programming concepts, but didn't need to know specific Python modules to get this job.
oh, thanks man :). Have a nice day
This is something that is badly needed in Python world. There is a R package that does this called [choroplethr]( https://cran.r-project.org/web/packages/choroplethr/vignettes/c-county-choropleth.html). Maybe this will give you some ideas or motivation.
For quick and dirty scripts, as you say, I usually go for json. It preserves all the basic datatypes and its direct readability and manipulation as text file is a big plus.
Imho this isn't a disadvantage. In the last 6 years I worked a lot with legacy perl code and autovivication was one of the things that made the perl scripts unreliable as soon as we added 'use strict' to them.
Excuse me your majesty for trying to help, I thought it was on /r/Programming since theres not much python on that list...
yes
That is very interesting. Thank you very much for the link!
What's an average and unusual day for you? Is Python and Django common in an ecommerce environment? 
Fancy words huh
Hard for me to say if it's common in an ecommerce environment as this is the only ecommerce company I've worked for. I've enjoyed using it though, it seems to fit our needs very well. I'm currently in the process of rewriting an acquired site from PHP to Python+Django so an average day would be just adding new features to the site. Nothing too special.
Neither, use Julia!
Like many others have said, SqLite is good enough to start with. What you are talking about is called premature optimisation, also called the root of all evil. Move up to Postgres or similar only when SqLite becomes a bottleneck. But **don't** assume it will slow you down to begin with.
I would suggest writing your **own** modules instead of learning others. Find something that needs to be done, something useful, or something that you are passionate about and do it. By building up a nice open source resume on Github you will set yourself apart.
Isn't Julia not stable yet? I think it will be a great option in the future.
It's true that it's not 100% stable, but at the recent JuliaCon it sounded like a good number of data scientists are already starting to use it, LOVE it and are telling all their colleagues about it. Lots of tools are springing up around it rapidly.
I haven't toyed with Jython. I'm trying to keep all my python as vanilla as possible to try and get it recognised as a language to use at work for things.
Why don't you use their [API](https://developer.stubhub.com/store/apis/docs)? Quick &amp; Dirty: import requests import json endpoint = 'https://api.stubhub.com/search/inventory/v1?eventid=' id = 9186789 headers = { 'Authorization': '&lt; API Key &gt;', 'Accept': 'application/json', 'Accept-Encoding': 'application/json' } r = requests.get(endpoint + id, headers=headers, stream=True) print json.dumps(r.json(), indent=2, sort_keys=True) 
5 items on a typical python development stack? Am I doing something wrong? * Flask * Gunicorn * Nginx if I want virtual hosts, otherwise just straight to gunicorn * Some database service 
Leiningen. Leiningen beats every other package manager I have used. (It's more than just a package manager, but it's stellar at package management.)
I would ask over in /r/gis as there are already good open source python tools for mapping either online or locally.
I did exactly that: https://github.com/mbjd/WebcamTimelapse You can now specify the time between images, the time to keep recording and the folder to save the images, as well as the URL (all from the command line). It also makes the video automatically after recording has finished.
Ah, yes, forgot about that. That's nginx too, then.
I'd disagree. Multiline lambdas (callback hell, etc.) are unpythonic (flat &gt; nested) single lambas are not, although with list comprehensions, map and filter, which are the main usecases for lambas aren't used.
Yes, then you need a message queue, for sure. If you need to call an external service without blocking the request.
Mainly I was going to refrain from it because of call limits, but I could look into a bit more I guess. By the way, half the time my script will return the XML and half the time it says I don't have a token. Do you know what's making the difference? Edit: Actually, I'm probably being conceited thinking that I need to make more than one call every 6 seconds. Thanks for the help!