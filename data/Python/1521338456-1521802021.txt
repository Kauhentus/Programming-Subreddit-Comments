I find python debugging way more useful than other languages. For years I've just been doing `from ipdb import set_trace as debug` at the top of a file, and then `debug()` to set a breakpoint. Works perfectly for me. 
No lying. And 3 simple apps. I am careful to not just add apps for no reason. About 10 apps total, 7 of which are well maintained and 3 of which i made forks of. May be 1 of those i can get off my fork. Watching warnings gives you a good heads up on coming changes. I find if you use apps sparingly your life is a lot easier.
Wow. Thanks for posting this. Will it work on screenshots of signatures, to identify people?
&gt; the versions of certain libraries are not all in sync Are these yours/coworkers libraries, or are they third party libraries, like "requests"?
"Parser" "Parsing"
This post is better suited for /r/learnpython
Third party
I don’t hate every framework just the ones I’ve used. 
This post is better suited for /r/learnpython 
&gt; And 3 simple apps. I am careful to not just add apps for no reason. About 10 apps total, 7 of which are well maintained and 3 of which i made forks of. It's cute that you think yours is a "large Django codebase". I have about 40 third-party apps for a social network / magazine / video hosting / photo hosting combo. Add about 50 in-house apps and you'll get a code base of about 150k lines of Python code (besides the framework itself). This is a large codebase and it's stuck on Django 1.6.11.
Conda environments or virtualenvs. The same env running on the local machines and the prod VM. Easy enough to do.
To them I say, yeah good luck with that. 
Not me stuck on Django 1.6
subl is not an IDE.
I am removing this post since the tutorial is /r/learnpython level material. It is not suited for /r/Python 
This makes me want to dive back into the Blender Game Engine again. The code should be easy to modify so that it sets a property that could then be used to modify objects on screen, in real time. Thanks for sharing!
by default, pycharm breaks on any exception. so once the debugger is setup (alt-shit-a edit configurations) and running (shift-f9), when it breaks go to the debug panel (should pop up automatically, if not alt-5) and click the console tab (not the main python console at the bottom). you then have two options: 1. open the "evaluate expression" window (alt-shift-8 or alt-shift-a evaluate expression), which is minimally useful, or 2. click the "show python prompt" button to the left of the python console [here's an image labeled with the step numbers](https://imgur.com/a/4HsZp) if you already have a debug configuration that is not breaking on exceptions, you can view/configure break points (ctrl-shift-f8 or alt-shit-a view break points)
pipenv, which combines pip alongside virtualenv, handle multiple package repositories (e.g . proprietary packages you don't want to put up on PyPi), and can also take care of specific python version installation using pyenv if it's installed. Also, personally, I'd set up a baseline project that's versioned with known versions of the most commonly used packages and a standard Dockerfile for running. That way your developers can pick up one project if needed without having to worry if a certain version of a commonly used package is installed, supports feature x, or feature you, etc. If you have internal packages, you can easily set up your own internal mirror of PyPi alongside your private packages using devpi. References (since I'm on my phone): https://docs.pipenv.org https://pip.pypa.io/en/stable/ https://virtualenv.pypa.io/en/stable/ https://github.com/pyenv/pyenv https://devpi.net/docs/devpi/devpi/stable/%2Bd/index.html
that is wrong https://trends.google.com/trends/explore?q=%2Fm%2F0dl567,Python%20programming /u/an_experimenter /u/DonaldPShimoda /u/ant51508 
Nope. Those are trends for combined term "Python + programming" Or do you really think python (reptile) is more popular than Taylor swift... Even if that's the case what's the reason behind it's rising trend?
That's all well and good, but unfortunately not everybody follows that spec, and the spec itself is often lacking compared to reST. It does look a bit nicer, though.
References and directives are much stronger in reST. .. IMPORTANT:: :class:`~spam.FooBar` cannot be found in this module. Try searching in :mod:`spam` instead.
Yeah, I'd definitely agree with that.
I tend to stick to a more FP approach. Having no (or as little as possible) global state and not extending classes more than once. Simple code can sometimes have more LOC but will be more maintainable. In fact i use this approach no matter the langugae, so far its worked oit great. The fact that most of times a POPF (plain old python function) is a more elegant solution than a class makes testing super simple. The above plus mypy types makes code very robust. I have the same feeling with TS, can never go back to plain JS!
This. Rails is the best and at the same time the worst thing that happened to Ruby. It once spoke to some devs working in a digital agency and asked whats their goto tech stack. Mostly it was wordpress, but they very proudly announced that they also have a rails app in production. It sounded like they chose rails just and only becuase it was rails, probably because is was so hyped at the time (this was in 2012 iirc). Most users of rails tend to fall in the same category that most ”php developers” they dont really use the language, but the framework / cms. This is probably more common in php space though. Python is spared from this, as most users know python and use it in a more broad sense than rails/php users. This is a very good thing for python. Having said that my theory turned out true, becuase of the massive growth of python (in the last few years) in various branches of science, webdev, ml etc etc. 
It can be better, by don't using blender for the recording. Use pyaudio and scipy. The audio data has to be low pass filtered, because the high frequencies are changing too fast and nobody sees it anyway. The filter frequency should be lower than 60hz 
This is not a django issue, but a business logic issue. If you have 2 tables and want to do a naive selection of related data you will get n+1 query. This is also why SQL has joins, and nested queries. Dont see this as a django/django orm issue, but more a developer issue. This is also true in most orms. Also, n+1 queries are easily profiled.
&gt; This doesn't make sense. The code you write runs as you wrote it. Not it isn't. Take scrapper for example, it really depends on how your request rate limit, ip source address, geolocation, etc. Your trial `run()` works but it may not guarantee it always works. Sometimes it fails for mysterious reasons.
For someone who has never tried Rails, can you list a few those good, bad and ugly concepts that Rails came up with?
But you can instead do this when calling your program: Python -m pdb script.py And you don't need to modify anything
But why do you do that? Use a modern environment and SCP the files over. Or is your environment restricted?
Good: * Support for packaging your app and all your dependencies into a single package so that when you deploy, you will have the exact versions of all dependencies you tested with. * An ORM that relieves you from writing your own SQL for trivial queries. * You even describe relationships in the ORM, and can trivially walk the dependency tree of your database. * Describe your database model using a ruby language extension, and the SQL schema is created for you. When an upgrade changes the db schema, rails notices your SQL database is an older version and upgrades. * A separate routing layer to go from URIs to endpoints. * For trivial data entry-type objects, simply describe all your fields, and rails will create a simple CRUD-like user interface for you. (Scaffolding) Bad: * The scaffolding mentioned above creates code for you that you need to maintain. Django does the same thing much, much better by automatically deriving things from your data model. * Rails was so slow, that even small apps often needed a caching layer to not overload the CPU. * The ORM was so slow that deserialising the data needed to render a single page could take half a second. * Rails leaked so much memory that you often needed to restart your server every few thousand requests. Ugly: In some parts of rails, they decided to go with words in singular, in other parts they use the same name in plural. (You have a Hat-model, and the corresponding controller is named Hats, for example.) This led to problems, because not all english words are pluralised in the same way, e.g. one sheep, two sheep. So the rails devs added a pluralisation engine to rails that handles such exceptions. Unfortunately, English is a huge language, and they didn't cover all words. So they had to make a plug-in API to the pluralisation engine. All this because some moron couldn't decide if classes should be named in the singular or plural. Completely stupendous amounts of complexity for absolutely no benefit what so ever. 
Arrays historically are based off of memory addressing. So the array name itself would be the memory location of the start of the array. With that being said, if you wanted to get the first element, you'd multiple that by zero. Hence why arrays/lists start at zero.
There's [this mathematical argument](https://www.cs.utexas.edu/users/EWD/transcriptions/EWD08xx/EWD831.html) originally proposed by Dijkstra, and then there's also the fact that C, the language that most other languages copied array notation from, defined `a[n]` where `a` is an array of values of type `T` as "the value at address `a + n * sizeof(T)`".
Is copying to textedit done to fix windows line endings? 
I hope you're being sarcastic, because the notion that RST and Mercurial are what made Python great is incredibly silly. Also, the original markdown conversion tool was written in Perl. I don't think there is any direct ancestry that relates it to Ruby. 
Donald, do you have something you want to share with us? ;)
true. though that still doesn't make me wish to switch away from debugging with pycharm :) now that I read back through the thread, i see you never answered what you missed about pdb
PyCharm has remote workspaces in the Professional Edition. Maybe give that a shot?
&gt; Not me stuck on Django 1.6 No, but it's you who believes that "anti" in "anti pattern" means "bad". Trust me buddy, you're a moron.
&gt; You know how pip decides to install a package when I type `pip install &lt;package&gt;` , the NUMBER of times that the string `package` occurs in the README. I don't mean to be rude, but I hope you know that this is *completely* incorrect. A package's `setup.py` module defines its package name. This name is registered with PyPI on initial upload if that name has not already been claimed. If there is a conflict, the user needs to choose a different package name and try again. If what you said were true, this would cause two huge problems: - Without package registration, any user could upload a new/malicious package with the name repeated n+1 times in the readme, usurping control of that package name. This would be a massive security issue. - If pip had to determine the correct package by counting the number of package name occurrences in the readme, this would require pip to download and parse *every* package readme from PyPi. There are currently over 132,000 packages on PyPI, to download all of these would be... unnecessary, to say the least. Also, it's worth noting that several packages contain an empty readme, and thus wouldn't be installable if what this method were true. Again, apologies if this reply comes off as rude. Just trying to be blunt/terse.
Why does Python return index -1 for can't find item in list or string, when -1 is a valid index, and it should raise or return None?
A few reasons though * My local OS is Windows, and I'm more comfortable on *nix OSs. * I like using vim as my editor, and I haven't found GUI editors that work quite as well for me. I found, for example, PyCharm to pretty overwhelming out of the box. * I deploy to Linux, and having a local environment that roughly matches the build and deployments can be useful. I do like GUI debuggers, and I'll use them for tricky situations if I need to. But overall I really like my setup the way it is.
Use a version control system, e.g. Git or Mercurial. If you just copy-paste code forth and back, I guarantee you will lose some changes along the way, usually the day before a big demo. 
Mathematician uses 1 for starting count. Math driven language like R/Fortran starts with 1. I think VBA also uses 1? General programming languages use 0.
You may have meant r/Fortran instead of R/Fortran. --------------------------------------- ^^^Remember,&amp;#32;OP&amp;#32;may&amp;#32;have&amp;#32;ninja-edited.&amp;#32;I&amp;#32;correct&amp;#32;subreddit&amp;#32;and&amp;#32;user&amp;#32;links&amp;#32;with&amp;#32;a&amp;#32;capital&amp;#32;R&amp;#32;or&amp;#32;U,&amp;#32;which&amp;#32;are&amp;#32;usually&amp;#32;unusable. ^^**-Srikar**
Currently using Git, is there a way to push a repo onto the Pi someway?
Tbf, my opinion in Django changed as it evolved. I used it back in the 1.4 days first. It was ok. A bit of a kludge in some respects. Decided to try it again for a new project now that they hit the 2x branch and i have to say it feels a little tighter. Could be a difference in my experience as that first project was over 5 years ago but I felt the newer one was a little less opinionated and a little less bloated. 
SQLAlchemy gives you a straightforward way of expressing any query. If you can do it in SQL, including database specific stuff, you can do it with SQLAlchemy. That's not at all the case with Django. Additionally database migrations with alembic are just much more straightforward and faster to execute. The Django orm is fine, if you just want to store some data somewhere but if you really want to take full advantage of your relational database, it's just not suitable. 
This actually helps to explain why groovy/Grails is such a terrible product. So many of the same issues with slowness, broken backwards compatible minor release (xml serializer broke one day), bad scaffolding, etc. 
I see thanks
Best way to get correct information is say something incorrect, :) So the way pip resolves installables is in no way similar to how package search on pypi works? Why is there no package name search on PyPi? If I search for PIL the Python Imaging Library, https://pypi.python.org/pypi?%3Aaction=search&amp;term=pil&amp;submit=search its entry is like 20 rows down. &gt; Occurrence of search term weighted by field (name, summary, keywords, description, author, maintainer) pip is subject to typo attacks, PyPi could give a different package name for a common library by stuffing those search fields above, but package names are claimed at initial upload. Is there a canonical list of all those package names? Good to know and thanks for the clarification. Turns out it isn't as bad as I thought.
16-bit is not really a valid concern in 2018. Also, a smart compiler can probably optimize 1-based indexing to 0-based anyway.
Data please. What is prevalence of off by 1 errors in 1-based languages like Fortran, vs 0-based like C?
&gt; Arrays historically are based off of memory addressing. Maybe in C, but there are languages a lot older than C that number arrays starting with 1. If you're going to give an explanation for something, take care that it is the right explanation.
Historical reasons. Returning -1 to mean "not found" is very common in languages where negative indices are not valid, and Python just copied that idea.
Yes, you can either use an image processing [library](https://pythonprogramminglanguage.com/extract-text-from-image/) Or you can train a convolutional neural network to recognize text in an image (would take a vastly longer amount of time) 
There are two main reasons. The weakest is "Because C did it." Guido van Rossum is a C programmer, but he's also familiar with languages like Pascal and Modula-3 where indexing starts at 1. But the stronger reason is that starting indices at 0, and going to one less than the length, helps avoid a lot of off-by-one signpost errors. Its not perfect: there are a few situations where 1-based indexing is better. But mostly, 0-based half-open indexing helps reduce the number of bugs.
&gt; So the way pip resolves installables is in no way similar to how package search on pypi works? `pip install` uses an exact name lookup*. It is in no way similar to, or uses, PyPI's search feature. &gt; Why is there no package name search on PyPi? Good question. I've never really needed it, as when I'm looking for a package by name, I usually just type it directly into the address bar. eg, `https://pypi.python.org/pypi/PIL`. &gt; If I search for PIL the Python Imaging Library, ... its entry is like 20 rows down. Unfortunately, three characters is fairly generic and is going to result in a poor search score using the old algorithm. Luckily Warehouse (the upcoming rework of legacy PyPI), seems to use a better algorithm, and the PIL package is [first in the results list](https://pypi.org/search/?q=PIL). That all said, search is intended for discovery. For example, if I want to find a [permissions plugin for django](https://pypi.python.org/pypi?%3Aaction=search&amp;term=django+permissions&amp;submit=search), there are a lot of useful results. &gt; PyPi could give a different package name for a common library by stuffing those search fields above, but package names are claimed at initial upload. As stated above, search is just intended for package discovery, and doesn't have any bearing on package registration or installation. When registering a package, the `setup.py` module's [`name` parameter](https://github.com/django/django/blob/274e3e27f366bddbf1bb13b40c3c7b95195c496e/setup.py#L65) is used as the package name. &gt; pip is subject to typo attacks This is a problem with a lot of package repositories, and has been [acknowledged](https://github.com/pypa/warehouse/issues/2268). * Names are actually case-insensitive. So, there is only the "PIL" package on PyPI, and it's not possible to upload a "Pil" or "pil" package, as these would be conflicts. That said, the package name retains it's original casing, so it's the "Django" package, not "DJANGO" or "django", although any of those names can be used to install the correct package.
&gt; The tutorial I've been going through says that id(x), the location in memory of the variable addressed by x, will remain unchanged after appending to x The tutorial has lied^1 to you. Twice. The first lie is that the `id` function returns the address in memory of a variable. That is not just wrong, but it is *doubly* wrong. If it wrong, because the `id` function does not return a memory address. It returns an **arbitrary ID number** that just happens to **sometimes** look like a memory address. Here is the `id` function at work in Jython: &gt;&gt;&gt; id(None) 2 &gt;&gt;&gt; x = 55 &gt;&gt;&gt; id(x) 3 (If you try this, you may get different ID numbers.) Do they look like memory addresses to you? They shouldn't, because they aren't. Jython and IronPython allocate ID numbers as consecutive integers. Other Python interpreters may do something different. And it is doubly wrong, because `id` has nothing to do with variables. `id` returns the ID number for the *object*, not a variable. Watch how the *same variable* changes its ID as the object (the value of the variable) is changed: &gt;&gt;&gt; variable = 2.3 &gt;&gt;&gt; id(variable) 7 &gt;&gt;&gt; variable += 1 &gt;&gt;&gt; id(variable) 8 &gt;&gt;&gt; variable *= 27.9 &gt;&gt;&gt; id(variable) 9 Same variable, three different IDs depending on what the value stored in the variable is. And here `id` operates on a pure value, a constant literal, no variable involved at all: &gt;&gt;&gt; id("hello world") 10 That's the first lie. In truth, `id` returns an arbitrary number, not a memory address. It just happens to sometimes look like a memory address. The second lie that the tutorial told you is that "the location in memory of the variable addressed by x will remain unchanged". And, again, it is doubly wrong. The variable "x" is a key in a namespace dict, and that absolutely can move in memory when the dict resizes. So variables, the keys in namespaces, do move in memory. But that's not what the tutorial meant. Even though they talk about a variable, they mean the list. And again, they're wrong: even the list can move in memory. PyPy, Jython and IronPython regularly move objects around in memory when needed. So that's the second lie: both variables (keys in namespace dicts) and values (objects) can move in memory. I don't know whether this tutorial is good or bad or indifferent, but in regard to memory allocation and `id`, it is wrong in every thing it says. One last comment: while Python interpreters such as IronPython and Jython do move objects around in memory, CPython does not. But it doesn't matter: your list can grow, or shrink as needed. As it grows, it takes memory from the heap. When it resizes, it periodically returns memory to the heap. ^1 I'm intentionally using a provocative term. So sue me.
&gt; fdemmer described how to work around the problem you described No, he didn't. His response was quite off. But I see, attitude is more important the facts for some.. 
May be a silly question but I'm fairly new to python, I see that for running the program I can either use the interpreter or an exe. Is this the same on the pi or is there a preferred method? Thanks 
&gt; So say that I've declared x already. You don't declare variables in Python. Not in the sense you mean. &gt; You mentioned that appending to x may change the initial offsets of new objects. That's fine; makes sense. Appending to x moves the initial offset of y down a few once I want to declare y. But what if I've already declared x, y, and z, and now I append a fat chunk onto x? What keeps the initial offsets of y and z immutable? Why shouldn't they be the same? There is no reason for them to move. I think you have the wrong mental image of variables in Python. You're thinking of them as fixed-size boxes, lined up in a row: [ x ][ y ][ z ] Now if you expand x, y and z have to move too. That mental model is wrong. Python doesn't work like that. (Neither do most modern interpreters, like Ruby or Javascript, or even really old ones like Lisp.) If you are a C programmer, a good way to think about variables in Python is that they are kinda-sorta like pointers: x ---------&gt; [ ] y ----&gt; [ ] z --------------------------------&gt; [ ] When the list referred to by `x` resizes, it doesn't need to move the lists `y` and `z`. It *might*, if you are running IronPython or Jython, because that's the way the .Net and JVM memory managers work, but it usually won't unless there is a lot of memory fragmentation. In some interpreters, like CPython, it can't move the list at all: if there isn't enough free memory to resize the `x` list, you will get a MemoryError. But regardless, `y` and `z` don't move.
I'm executing some coffee right now...
Random cow collapses into black hole.
This I currently push to GitHub from my Windows and MacBooks and pull down to my NUC. Look up Pip’s requirements.txt file to help with dependencies. Makes it easy to install everything you need
Overran your video views, so this is a static image of a laptop on a table. Maybe some more hints?
My comment was 100% a joke based on the fact that people called her a “snake” because of the whole Kanye thing (which I don’t really care about). Python is a type of snake, therefore Python is a subclass of Taylor Swift. Had nothing to do with facts haha.
&gt; This is not a django issue, but a business logic issue. No, it is not. Other frameworks like Rails have this issue solved (AR decorators and squashing migrations), other like Django-based Mezzanine does bit of a [dirty hackery](http://blog.jupo.org/2011/11/10/django-model-field-injection/) but with many caveats esp. db migrations and models initialization ordering. 
Thanks. Local zealotism feels a bit scary. Downvoting fest without even understanding or experience. Anything against their faith is enough to blame. 
[Tesseract.image_to_string](https://pypi.python.org/pypi/pytesseract)
&gt; I did, and you answered me oops. sorry. i got lost &gt; I found how to do it though, while debbugin in Pycharm there is a button (like a calculator) that says evaluate expressions, and there you can type any python code or modify current variables ahhh, i didn't realize that modified the runtime state. I just assumed it was a clunky alternative to the debugging python prompt. thanks for the information
Sure, here is the roadmap of the project: https://trello.com/b/7bdwhnLr/léon-your-daily-personal-assistant-roadmap.
i mention how to do that in another thread [here](https://www.reddit.com/r/Python/comments/852t3a/a_quick_tour_of_python_37s_new_breakpoint_feature/dvvrl0r/)
I was obviously paraphrasing the tutorial, so a lot of the terminological imprecision is probably my fault. I can say that it’s been a helpful higher-level abstraction of Python’s basics, even if it does sacrifice some exactness or what’s going on under the hood. Even still, I’ve been impressed with how it does stop occasionally to attempt to describe how Python is interfacing with the memory. Many beginner tutorials just point out functions to manipulate different data types and call it a day. If the tutorial didn’t take the time to describe the memory processes at a beginner level, I probably wouldn’t have posted this question in the first place, since they wouldn’t have introduced the concept. Overall I’ve been pleased. Thanks for your response. Yours and others’ have been helpful for understanding what Python does differently compared to C, for example. Still not sure if I get entirely how computer memory works on a more basic level. But I’m excited to learn more about Python, so someday I’ll get it!
No need for a paid solution
This is the natural way to do things in assembly langauge. An array is defined by a label at the start of a block of reserved memory. If you use zero based indexing, the nth byte is located at LABEL+n. It isn't surprising that C, in many ways a form of portable assembly language, uses the same convention. Some languages followed the mathematical model of using 1 as the first index. But anyone designing a language has to think about how it will work in machine code, and that tends to drag you back towards zero based indexing. It isn't just a case of copying C, it is how computers work at the low level. Even though Python is quite a high level language, it seems firmly rooted in lower level concerns. It reminds me of Forth (if anyone remembers that) in the way it exposes the machinery of the interpreter. I'm not surprised it uses zero base indexing.
Not necessarily paid. They've got educational, trial, and Open Source licenses. Also being a paid solution isn't a showstopper for all. 
I’m interested 😄
Interpreter on windows is "the exe"...
I just use sublime 3 and rsub, because if I'm building something that I want to put on my raspberry pi, might aswell build it directly on it.
Hello 😎
Could you repost the video to YouTube or some other platform with no view limit?
How much you $$$ pay?
&gt; you can't run GUI apps You can, with any X11 server in Windows. &gt; risk of file integrity due to sharing of files between the OSes? Never edit files inside of your WSL root from windows apps and you'll be fine. You can hold your project in any windows directory if you want.
Notice how he wrote 'just for fun'. That means no $$$
Why not just switch to Linux entirely? That said, there's no issue sharing files between OSes, just permissions of files from Windows will be very permissive. 
:D
Because there's a lot of better solutions that aren't waste of money.
I still don't understand why you wouldn't just use a VM for this.
A VM is likely slower than WSL. And the VM takes real time to setup. You can use WSL in 5 mins or less.
This sounds like exactly what I want to do, to be able to develop straight onto the Pi. With requirements.txt, do you just have the file path of each library you want to install?
Any personal assistants' major downside is generally privacy. This is worse with google, facebook, apple etc. Having access to literally any information they could want in the audio scope, and moreso when added to, say a smartphone that tracks your position all the time. How does Léon compare in this sense to so-called competitors. Does it aim to match functionality without compromising user privacy? How would it achieve that if so? Or does it have the same shortfall to the user as generic examples?
Thanks for the suggestion, I'll look into it. Not sure why the other guy is so irate about it. 
More choices. Also I expect WSL to be quite a bit faster than VMs.
`pip freeze` and see for yourself.
Turns out wsl is a lot slower than VMs, at least for IO: http://www.akitaonrails.com/2017/09/20/windows-subsystem-for-linux-is-good-but-not-enough-yet . So, depends on your setup and workflow, I guess.
Heyo whats this all about? We programming bots or..? 
How does it compare to Mycroft AI?
This video doesn't appear to have audio when downloading. Is it meant to? I'm not sure I understand the point of the link.
It's linked in the article: https://docs.microsoft.com/en-us/windows/wsl/about To save you a click; it's Windows Subsystem for Linux.
One thing to consider is that you should use Python's libraries to do anything file name related (os, Pathlib, shutil modules) and avoid using just strings. Other than that that it really depends on the requirements - most of my code written on windows runs on the pi unchanged (even with windows line feeds) 
That has definitely not been my (limited) experience so far. Native is faster.
As Google Drive has limitations for sharing, I re-uploaded the video on YouTube: https://www.youtube.com/watch?v=1B7JMBPZ0qI. You can also find the roadmap of Léon here: https://trello.com/b/7bdwhnLr/léon-your-daily-personal-assistant-roadmap.
Ya, it does depend. I've been using it a ton to develop on a separate Ubuntu machine in my house.
By native do you mean running Linux on bare metal? Of course, that would be faster, but I think WSl will be faster than VMs, it has less levels of indirections.
Nice project ..but it came last I stopped using blender along time the upcoming dev are much lucky 
Nice project ..but it came late, I stopped using blender along time the upcoming dev are much lucky 
Hi, please see [this comment](https://www.reddit.com/r/Python/comments/85axig/im_building_léon_an_opensource_personal_assistant/dvwbi2x/).
Hi, I discovered Mycroft few hours ago, then I cannot really say about it. But it seems to have the same purpose.
By native I mean "executing against the actual linux subsystem, not through a translation layer". VMs are very fast. If you read the article linked by /u/tonnynerd, you'll get good info, and here's some more: https://www.phoronix.com/scan.php?page=article&amp;item=intel-7900x-wsl&amp;num=1
Hi, thanks for opening that topic. Each module of Léon has its own configuration. Configuration may change according to the final purpose of the module itself. And of course, the configurations are fully customized for each module (JSON file). Some modules will work with remote APIs, but if you prefer to use another remote service, then feel free to contribute to the project or suggest the service you prefer. Léon is a community-driven project. Also, you have the control of all of your data, and Léon will do nothing about it as it will be hosted on your machines. Please note that I developed a logger that will log the expressions you are telling to Léon, it will allow to get good dataset to improve his understanding. Of course, this logger can be disabled as you wish.
It better be professional
Works for me...
Try /r/learnpython and try to add more information to your question
Can you post an example of what you mean? Hard to tell you what it is you should be looking at or running you through the justifications without seeing what you're up to
This is super helpful stuff to know when optimizing code, and I didn’t know about a lot of these. Kudos!
Thank you!
This is exactly what I was looking for. Thanks for providing all the documentation. 
This is true for absolutely any cloud provider, and your local computer to by the way.
This is what I came to ask. I've been a follower and backer of Mycroft for a couple of years I think now. The largest hurdle for Mycroft has been an open and privacy-centric STT service. They're developing OpenSTT, but in the meantime you must plug into third-party services for STT. Mycroft is actually a collection of several projects, some developed internally and some external. You can use different sources for some of the features. * Wake word detection * Speech to text * Intent parsing * Speech to text * Mycroft Core which ties all these services together The "skills" that are executed with the data from the intent parser are plugins written in Python. It's super easy to contribute to.
ISWYDT https://www.imdb.com/title/tt0110413/
Nice! This could develop into a very interesting resource, thanks. It would be good to add the versions of NumPy and pandas you are using (as well as the system you're testing on, etc.). Both libraries are under active development and any timings could well change. I'm interested to see how the project grows, but if I can offer some other feedback very briefly: most of the timings between NumPy and pandas here are not particularly meaningful in my opinion. This is for two main reasons: - some of the methods will behave differently depending on the data. pandas is designed to work as seamlessly as possible with missing data (NaN or NaT values), whereas plain NumPy functions are not, and you can expect some minimal overhead to handle this (e.g. `np.median` vs. `Series.median`). Perhaps you could redo the benchmarks with several different datasets, and `np.nanmedian` too. - some NumPy functions (such as `np.mean` and `np.sum`) actually just call the corresponding pandas method (i.e. `Series.sum` or `Series.mean`). All you're seeing in the benchmarks is the additional time it takes to go through one or two extra Python functions before low-level code is hit: this additional overhead becomes virtually unnoticeable as the input array increases anyway. 
Maybe because of the huge list of things most people don't use Linux as a desktop...
Thanks for this summary. I made the code generic in a way that it should be easy to contribute to Léon, and create modules (modules here are equivalent of skills). Looking forward to see how it will look like with the community.
I'd like to report a bug. The meaning of life is 42. Your AI is *clearly* insane. Very cool project, now I just need to think of an interesting application I could apply it to.
To get you going with good and fun exercises you could start out with: https://projecteuler.net and try solving the problems in Python.
Cool, we need another one of those. 
Hi, how goes it
This post is better suited for /r/learnpython
Still working on the py-fortress standars-based access management for python and ldap as the storage backend. The paint is still wet on this code, no releases yet, but now compliant with ANSI INCITS 359, level RBAC0 (Core). README added has quickstart using either openldap or apache directory running in docker. https://github.com/shawnmckinney/py-fortress 
This is the correct way to do it. The author talks about repetition, well writing a decorator over every auth function is very repetitive. 
His response is factually correct, but instead of admitting that, you insult him and change the topic.
thank you very much!
Hello there, I am currently working with the Logistic Regression (Question 12) from the Hands-On Machine Learning and Tensorflow: https://github.com/ageron/handson-ml/blob/master/09_up_and_running_with_tensorflow.ipynb I understand the solution to some degree (still new to the TensorFlow), but the graph confuses me.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [ageron/handson-ml/.../**09_up_and_running_with_tensorflow.ipynb** (master → d01518c)](https://github.com/ageron/handson-ml/blob/d01518cdfa4a5b64d69303a434f236f657f9e721/09_up_and_running_with_tensorflow.ipynb) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dvwpvcp.)
Have you ever tried to use it without a database? Its doable, but takes non-trivial amount of work.
Socket.IO is a layer on top of web-sockets or HTTP long polling and almost exclusively used in JavaScript browser applications. This has nothing to do with the real, low-level sockets supported by your adruino. These are the sockets your adruino can speak to: https://docs.python.org/3.5/library/socket.html No need for flask or any framework at all.
I was unaware of itertuples. Can't wait to give it a shot.
I've never needed it without a database
I would definitely love to see an opensource version that runs locally with minimal network requests, but for some things, we are not quite there in terms of computation, at least if we want good quality. Speech recognition and speech synthesis are both doable on low-end machines, but you'll never get anywhere close the accuracy that Google is getting with their huge deepnet models. In the video you can also see the huge delay between saying "Leon" and the recognition beep.
Look at SymPy, a complete Computer Algebra System (CAS) in Python and do the accompanying tu tutorials. This is for all the stuff you'd like to solve symbolically. If you want to perform 'low level' machine learning have a look at numpy and theano for fast computations. This is for all your numerical (non-symbolically) crunching. Next could be tensorflow which is also built upon mathematical primitives. Higher level you can solve almost any ML problem with either scikit-learn, keras or - for really big data stuff - with PySpark.
&gt; some NumPy functions (such as `np.mean` and `np.sum`) actually just call the corresponding pandas method Isn't this backwards?
 def hello_world(): return 42 super_useful_decorator(hello_world()) Is not exactly the same as its following block. It leaves behind a redefined `hello_world`. The example should probably be: def hello_world(): return 42 hello_world = super_useful_decorator(hello_world) hello_world()
No, this is how `np.sum` and other core NumPy functions are designed - they can operate on any types. Take `np.sum(x)` as an example. `x` can be a NumPy array, in which case we'll hit the fast loop underpinning the `np.add.reduce` ufunc immediately. If `x` is not a NumPy array, then NumPy checks to see if there a `x.sum()` method for the object and calls that instead: class Test: def sum(self, **kwargs): return 'hello' x = Test() np.sum(x) # returns 'hello' pandas Series/DataFrame objects implement their own `.sum()` so `np.sum` returns the result of calling these methods. Of course, the Series/DataFrame `.sum()` methods do end up use NumPy's own ufunc machinery internally to do the actually calculation (but they also do things like mask out NaN values first).
From my experience trying to do this (hoping to move back to a windows machine) it was a bit problematic with the standard cpython release. The issue was primarily compiling any C extensions. However since then I’ve heard a lot of people recommend [anaconda](https://conda.io/docs/index.html) for windows to fix that.
last week I'm still working on [ajson-rpc2](https://github.com/WindSoilder/ajson-rpc2/) project, add more support for the configuration of rpc method, which can make rpc method can be called in another process, or another thread. So it can improve performance for the json rpc batch requests which contains many CPU-bound methods. 
there are multiple graphs in there and those aren't tensorboard graphs... A tensorboard graph looks like [this](https://www.tensorflow.org/images/graph_vis_animation.gif) For those graphs it would help in terms of interpretation if you knew how they were generated. Fortunately, we see that the moon dataset is called up from sklearn. The documentation for the dataset can be found [here](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html) and if you want to see how the points were actually generated read up [this](https://github.com/scikit-learn/scikit-learn/blob/a24c8b46/sklearn/datasets/samples_generator.py#L639)
Blender is continuously being developed so there is never too late or stopped using it. It is always going to be my secret tool besides other commercial tools. 
1) For applications, virtualenv + pip install + pip freeze has always been enough for me. 2) For libraries, define by hand since there's no enforcement of semver. But thx for the links, I will check out these tools.
It goes down spectaculary as soon as package that you want to install with pip includes install dependencies. try `ujson` for example.
Well, how do I read the tensorboard graph after I run the code and go to my localhost?
Just sounds like polymorphism and you can use platform detection to use one or the other...
Please test: for i in df.index: value = df[“some_column”][i] In the iterators section. It might not provide a very direct comparison to iterating through rows, but I find it useful.
I use pandas quite extensively. You can check my blog at mikerazar.com/chart-it What do you mean by mapping? I could probably help you out. 
Thanks for your response. But i need an interface for a user to see the data the user also needs to send data back to Arduino. If i am not going to use web framework then what can use? Could it be a script with gui and internally there's a loop that checks for incoming messages and presents it to the user? Sorry if my question is stupid i am new to this area of python. Best regards
For the love of speed and less system resources consider using a lower level language. 
Nice module! 
I'm using pyinstaller for packing them. I haven't thought about compiling to Android market, but I'll consider it
Check out Mycroft. They are open source, they're cross platform, they listen for the actuation word locally (not passing ambient audio anywhere), they aggregate all the users' audio before sending it to the big speech-to-text-query engines (thus anonymizing the queries). Next version continues to develop local speech-to-text ability on a Raspberry Pi so only the query text will go to servers.
have you tried something like this? https://stackoverflow.com/questions/46337716/pylint-cant-find-qwidget-and-qapplication
&gt; But we are comparing a database toolkit against a general web framework. I think the django ORM is modular enough that you could say that you are comparing an *ORM in a web framework* with a database toolkit. 
&gt; SQLAlchemy gives you a straightforward way of expressing any query. If you can do it in SQL, including database specific stuff, you can do it with SQLAlchemy. That's not at all the case with Django. This is kind of close to this: https://docs.djangoproject.com/en/2.0/topics/db/sql/ Although yeah the sql expression dsl in sqlalchemy is more powerful. &gt; Additionally database migrations with alembic are just much more straightforward and faster to execute. Good to know. &gt; The Django orm is fine, if you just want to store some data somewhere but if you really want to take full advantage of your relational database, it's just not suitable. That's the kind of broad normative statement that's difficult to interpret but very useful to be told. I'll feed it into my bayesian priors for decisions about orms ! :) 
Lua also counts from 1. But that’s about it. It’s fairly unusual for a general purpose programming language to use 1-indexing. 
The location of array[n] is offset + size of object in bytes x n. 
Have you seen recent Kaggle challenge on March Madness ? It might be exactly what you are looking for:)
`str.index` raises an exception for value not found. 
r/learnpython Sit down and start learning.
If you use anaconda you can write small script that will read thru all available packages and extract keyword....
the difference is that we can tcpdump if have shell access to host
A common pattern is to have an `ext` module which is just an `__init__.py` which does a load of imports, each one in a `try` block: in the `except ImportError` block, define a variable of the same name as the module which points to your dummy. Then whenever you want to import those modules, you import them from `mypackage.ext`.
aaaah the lack of talk about `functools.wraps` or `functools.update_wrapper` is bothering me immensely. :( &gt; As an additional bonus, there is now clear separation of concerns between authentication and whatever it is the REST API functions are supposed to be doing. As much as I love decorators, this isn't true. Yes, there is a separation of concerns but by using a decorator, they've become muddled back up together. def authenticate_access(fn): def wrapfn(*args, **kwargs): rv = {} token = args[0] if token_is_valid(token): rv['code'] = 200 rv['payload'] = fn(*args, **kwargs) else: rv['code'] = 401 return rv return wrapfn When you go to write tests, this code must satisfied every time you want to test whatever `fn` actually is. Now, this decorator isn't so bad and probably sits over something like a Flask route. But imagine if your decorator did something like contact a database or send an email. Then you'd really be screwed. If you want an actual clear separate of concerns, you'd not marry them together like this and instead use a less binding form of composition, either function or class it doesn't matter.
Hey, that's pretty great! I use pandas a ton and this is a new one. I just tested it out and it was about 1.8x-2x faster than itertuples() for me (on a million row dataframe). The only shortcoming is I like to have label-access to columns and iterating over df.values returns numpy arrays, but setting up a dict of label -&gt; array index prior to the loop seems to provide a nice middle-ground. cols = {c: x for x, c in enumerate(df.columns)} for i in df.values: cust_name = i[cols['name']] cust_addr = i[cols['address']] 
Hey, that's pretty great! I use pandas a ton and this is a new one. I just tested it out and it was about 1.8x-2x faster than itertuples() for me (on a million row dataframe). The only shortcoming is I like to have label-access to columns and iterating over df.values returns numpy arrays, but setting up a dict of label -&gt; array index prior to the loop seems to provide a nice middle-ground. cols = {c: x for x, c in enumerate(df.columns)} for i in df.values: cust_name = i[cols['name']] cust_addr = i[cols['address']] 
What you really want to do here is "mock" the code when you're running on your laptop. Python has a few mocking libraries, but it may just be easiest to do it yourself. Mocking is exactly what you explained -- using dummy classes/functions to return data that you create by hand rather than use the real functions. Also you almost certainly got downvoted for posting here rather than in /r/learnpython just so you know.
I think you may have switched the query_selection and bracket_selection functions in section '1.3 - Selecting rows'. Otherwise a very cool analysis!
Binary wheels are fine if you just want to use prebuilt C extensions, but they won’t help if you want to actually develop such extensions.
Definitely they are to help alleviate some of the pain, but I still recall hitting a number of issues (but this was a few years back so I am pretty fuzzy on my details, sorry!)
Amazing :) I’ll check it out
While this is true, I still think calling breakpoint a method is misleading. People expect to have to create/import an object to use a method.
There was a bit of a copy-pasta error there. Thanks for the catch!
What do you see on the page when you go to your localhost? Also, when you say 'read' what do you mean? Do you mean see it or interpret it? If you mean interpret it please post a screenshot
ohkay. My question was this one: https://www.reddit.com/r/opencv/comments/7yw52a/opencv_questions_to_detect_cars_in_a_lot/
Could you test df = df.assign(newcol=...) for column creation? Very cool and useful analysis!
This post is better suited for /r/learnpython 
See also https://medium.com/@boxed/moving-a-large-and-old-codebase-to-python3-33a5a13f8c99
oh god, now how would i use subplots to plot them in one figure?
print X.shape, Y.shape, r1.shape fig = plt.figure() plt.subplot(221) #2 x 2, spot 1 / 4 plt.imshow(f) plt.colorbar() plt.subplot(223) #2 x 2, spot 3 / 4 plt.imshow(r1) plt.colorbar() plt.show() 
The pyqtdeploy is the official deploy tool, and it should support Android out of the box without any extra code.
Thank you so much.
What I would do is just split at every instance of a comma, prepend commas where I want them, then put the strings back together.
Markdown's goal is to be lightweight and emulate the way humans write plain-text emails, and translate into sensible basic HTML. It's very good at that, but that's also a very different use case. When I'm writing technical documentation I want a much richer set of options for controlling document structure, working with references, etc. Markdown simply doesn't provide that. The extensibility of rST, which allowed for things like Sphinx to be built, is also huge. Sphinx is an amazing system for writing and publishing technical documentation.
Nice use of type hints! It would help avoid confusion if you add python 3.5 as a [requirement](https://packaging.python.org/tutorials/distributing-packages/#python-requires) and maybe mention it in the README.
Hi, the first version will be released on GitHub in the coming weeks :) 
 def remove_commas_except_for_the_first_three_and_the_last_one(input_str): split = input_str.split(',') # this gets fucky if you dont have enough commas if len(split) &lt; 5: return input_str start = split[:4] middle = split[4:-2] end = split[-2:] return ','.join(start) + ''.join(middle) + ','.join(end) &gt;&gt;&gt; remove_commas_except_for_the_first_three_and_the_last_one('comma, comma, comma, comma, comma, comma, comma, comma, comma, comma, chameleon') 'comma, comma, comma, comma comma comma comma comma comma comma, chameleon'
what about cases which have less than 5 words? what should be the output for those cases?
Hi! There are features which are not in this teasing. No, Léon will be released in the coming weeks, you can see the roadmap just [right here](https://trello.com/b/7bdwhnLr/léon-your-daily-personal-assistant-roadmap) :) 
I never said blender is obsolete,what I meant is that I have moved on to some other project different from 3D modeling and game dev 
Unless 'divisor' is some sort of global outside the function, it's the problem. 
So [this](https://www.google.com/search?q=python+bare+except&amp;oq=python+bare+except&amp;aqs=chrome..69i57.1969j0j7&amp;sourceid=chrome&amp;ie=UTF-8) might illuminate the "bare except" issue. Not specifying an exception type is bad, but learning exactly why and how to get around it, I'll leave as an exercise in Googling and reading.
Number is not defined, it's also a bad name for a variable and questions like this belong on r/learnpython.
You never define the variable 'number'. number=len(string) This will assign number a value equal to the length of the string. Also you use '=&gt;' when it should be '&gt;=' Also you should not use the variable name 'string' because 'string' is also a library and will cause problems if you use that library. Instead use 'slist' for the list and 's' for the individual strings.
Seek r/learnpython and use descriptive titles for your posts.
Seek r/learnpython and use descriptive titles for your posts.
 def long_enough(slist, min_length): result = [] float(min_length) for s in slist: number=len(s) if number &gt;= min_length: result.append(number) return result
I'm not sure a million dict conversions are a trivial cost. Did you time it? What I usually do for labeled access is 'for col1, col2 in df.values'. It's slow to write because you have to write the cols out in order, but it runs fast.
I tried this way and I am still getting the same error. 
update your pastebin and I'll look again.
https://stackoverflow.com/questions/26573556/record-speakers-output-with-pyaudio
I think you might want result.append(s) instead of result.append(number) but otherwise it works for me, assuming I clean up indentation.
I don't know much about your app in itself. However I guess that you have a human interface provided by django and, according to the input given by a user, you perform a inference/prediction using sklearn. You can keep your django human interface but the inference/prediction step will be performed on another server by means of an API. There is a small and easily understandable [github project](https://github.com/amirziai/sklearnflask) that wrap sklearn as a Flask API. I hope this is what you are looking for.
https://pastebin.com/eknKVJjs Here is the updated code... Here is the pylint error E: 9, 0: unindent does not match any outer indentation level (syntax-error)
You need to add a single space before "return result" It's and indentation error. You are using 4 spaces. But 'return result' only has 3 spaces.
Ahhhhh thanks for the help!! I just realised after I pasted the code in again. 
no problem. Good luck with your studies.
I think you might be mixing things up here but I'm not certain. 1. You want a GUI, the Web Interface a person can interact to 2. You want Socket communication with your Arduino The person would use the Web Interface, which then internally (in your python program) would work out what is needed and send the commands to the Arduino via a socket connection. Is that it? If so you would still use Flask for the Web UI and the normal Socket for the communication with the Arduino. 
I'd use vim anyway?
Yes, if you use raw SQL and essentially stop using the ORM, you can write any kind of query you want. You don't have to do that with SQLAlchemy, you can just use the expression language SQLAlchemy provides. 
Hi, any plans about cloud synchronization? I'm looking for simple mp3 player for my pc + laptop + smartphone (+server with .mp3 files), maybe you can suggest something? Long story short - I'm looking for self-hosted solution for my music with support of Windows + android
` def long_enough(strings, min_length): return [s for s in strings if len(s) &gt;= min_length) `
If you ready to build something like this - I can help you with server-side part (I'm web developer) and provide some api for synchronization and file uploading
To be honest, if you asked me what I feel about Django a year ago I probably would have said that I hate it and I'll never write a project with it and I'll stick with Flask, Tornado and CherryPy. Nowadays, I just love Django. Once you understand the underlying class structures and learn how to customize them easily, you start to see the true beauty of this framework. This happens only after you spend a few weeks or even months at least using and getting used to the structures it provides (class based views, forms validation and rendering, context processors, etc). Of course, it has its limitations, but it's not impossible to extend it to cover some use cases that the framework wasn't covering (such as analytics plots in the admin dashboard). But hey, you can't cover 100% of the cases and Django does an amazing job covering the 90% most common cases.
You are absolutely right. The functions were swapped, I have just fixed it.
im interested to have fun in free time =) 8-10 hours in a week
I’m interested ,am available in 2 hour a day weekdays and 5 hours in week ends 
Cool. When working with pandas and numpy, mostly we will works with large data. Don't know about itertuples until today.
Thanks a lot for such a constructive feedback. This is really helpful. I agree with you about the meaningfulness of numpy vs pandas, particularly, "sum, mean, and prod" results. I was hesitant about adding them to the benchmark; especially, that I couldn't understand why pandas functions were faster! I though those are the ones with more python overhead. Just like /u/monstimal pointed out. But with your explanation, it is clear now why pandas is faster. 
This is the correct answer, except without whacking it all on one line.
Nice one — if you want to add a playlist view there are built-in components in Qt5 for this. [See here](https://github.com/mfitzp/15-minute-apps/tree/master/mediaplayer) for a small example app.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [mfitzp/15-minute-apps/.../**mediaplayer** (master → b99eb33)](https://github.com/mfitzp/15-minute-apps/tree/b99eb330310fe7302ead39473ef0d34cccb3d12d/mediaplayer) ---- 
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/wutbotposts] [Wutbot on "project": \[r\/Python\] I am working on a project which basically extracts text from two images and compare if they are same or not , is there any way using which i can implement this in python ?](https://www.reddit.com/r/WutbotPosts/comments/85iiwc/wutbot_on_project_rpython_i_am_working_on_a/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
A little more info on the project would help us help you! Such as, what devices are you using? What is your end goal? I did a small IOT project with an arduino and a raspberry pi. I loved MQTT for sending data and triggers between devices. Very easy to use and fun to learn. I was using MongoDB at the time because it was super easy to just toss data into without having to build a database schema, but Postgres or another sql database would work fine (I was storing temperature data). I then used flask to build a very simple webpage with on/off buttons. Click the on button, the Arduino relay flicked on and the lamp turned on. Off button turned it off, of course. This was cool because any device in my house could connect to the local website and control the light. The code is simple and incomplete because, at the time, I was brand new to python. Happy to send it to you if you're interested, though. https://pypi.python.org/pypi/paho-mqtt/1.1 https://github.com/mqtt/mqtt.github.io/wiki
https://www.wikihow.com/Use-Commas
This is definitely not the consensus or a philosophy anyone should use for deliverables. Requirements files" are files containing a list of items to be installed using pip install like so: Repeatability requires pinned versions There are tools to separate dev requirements from user requirements. And on and on ...
If you need to signal devices, it's hard to beat MQTT. You could try doing something similar using HTTP but you're just going to end up with a half-assed MQTT implementation. Mosquitto is a perfectly adequate MQTT broker. As for storing data, default to Postgres and use the JSON column to store your data. If you find yourself with more data than can comfortably fit in a single table, either adopt TimescaleDB or a dedicated time series DB; InfluxDB is hard to beat for the "it just works" factor. MongoDB will store time series data but there's no reason to use it over Postgres or InfluxDB. Patterns and signaling back: your first iteration should literally be a SQL query that runs every few seconds. If that proves to be too slow, optimize, but be wary of Spark or Flink: they'll significantly complicate ops, and all but the most trivial stream processing jobs get very hard to maintain and guarantee correctness.
Maybe do a min and max version? Still hurts repeatability tgough for projects that need provenance.
Just a tutorial 
I agree but its easier I'll try for pyqt 
Don't you ever update application dependencies?
I like this node.js front end + flask back end service design.
take a look at the curated PROMISE dataset used by researchers. http://openscience.us/repo/
In simple terms, clean/transform/aggregate/visualize input data to actionable business /software intelligence. 
It is probably something like this. Mylist1 = [a, b, c] Mylist2 = Mylist2 İf you do it like this you just give another name to the same list. So when you change a value it also changes on the other. Try doing Mylist2 = Mylist1[::] This creates a copy of the list. So the changed values in Mylist2 does not affect Mylist1. On mobile so sorry for formatting
I use a non-pinned requirements file and a pinned requirements-lock file or something like that, it's more or less the workflow described in the pip-compile-multi README, except I haven't cared too much about duplicating project vs test vs dev dependencies. 
Can you base your claims on something specific or they are just a personal guess ? I didn't changed the topic, he was off with the reply. 
If I remember right, tor installs a socks proxy that lets you make requests to the tor network (TBB provides firefox auto-configured to use this proxy, but i believe any browser could duplicate it). https://stackoverflow.com/questions/12601316/how-to-make-python-requests-work-via-socks-proxy
I chose to use h5py mainly because it follows the HDF5 C API quite literally. This means that you can easily generate and read the same files regardless of the language you use, and that you can adapt your C code to Python and vice versa, with not too much effort. When you work in the lab, sometimes you want to keep a lower level control of what is going on, and you don't want your users to be forced to Pandas, but still give them the freedom to choose it if they want it to analyze their data. 
I'm a fan of the netCDF4 format (based on hdf5) and the [xarray library](https://xarray.pydata.org/). I think netCDF simplifies the concepts of hdf5 just enough to be the premire N-dimensional data format. And xarray builds on dask so that I can transparently access my data out-of-core with a numpy compatible interface.
What
Every line in the file has more than 5 words. Basically, I have a string such as: 210282, 1012412, 14, cups, cars and jars, singlewords I want to keep "cups, cars and jars" together as a string when I make a list. So output should be ['210282', '1012412', '14', 'cups, cars and jars', 'singlewords']. 
For ndarrays you could check out xarray. It provides a pandas-like experience for n-dimensional data. It focuses on netCDF files, but those are just a flavor of HDF5 at this point, so I imagine it would work on both (I don't have any HDF5 files to test on).
My point wasn't so much that I didn't have a way to write NDarrays, just that you can't claim to have made h5py obsolete if you don't support writing HDF5 datasets in N dimensions!
I have experimented a bit with HDF5. My experience is that pandas and even PyTables can't handle as much of the HDF5 standard as h5py does. 
You know how you use "Alexa" or "Hey Google" or "Hey Siri" for all your voice-activated devices? It appears this enables you to build in that functionality to an app of your own. 
Oh that’s a pretty cool package but I don’t have flask. :/ 
Well, the parent of my comment insinuated that pandas is "setting up to be the premier HDF5 interface" which I read as "... and deprecate h5py". My comment was an attempt to explain why that might not be such a good idea.
This beginner level tutorial is not suited for this subreddit
This post is better suited for r/learnpython
I know... it costs a little bit too much of dollars! 
 &gt;&gt;&gt; import sys &gt;&gt;&gt; sys.ps1 = "REPL &gt;" REPL &gt;sys.ps2 = "Indented &gt;" REPL &gt;if 1 == 1: Indented &gt; print("ofcourse")
You use flask-socketio for realtime between the server and browser, and stdlib sockets for between the server and arduino. You don't need separate scripts, just two imports.
#youareadumb@ss
This post is better suited for r/learnpython
thanks so much! i only just came back onto reddit today, saw your comment, and pygame is fully working! super glad i can start making some more advanced python stuff, thanks again :)
For more: - https://github.com/sfermigier/awesome-functional-python - https://github.com/vindarel/languages-that-compile-to-python
thanks, i'll delete this one and post my question there!
[This](https://www.datacamp.com/community/tutorials/finance-python-trading) looks quite in-depth.
Material aimed at teaching and learning python for beginners is not suited for this subreddit
please check out quantopian.com its has good tutorial and very nice API plus excellent community :)
Do you also have any resources for someone who literally knows nothing except for basic python programming?
===================== **Software Engineer** ===================== Resonon Inc. is seeking a full-time software engineer. Duties: ========================================= * Develop, improve, and maintain full stack Linux applications for industrial and airborne real-time machine vision, including data acquisition, user interfaces, data analysis, and hardware control * Improve and maintain MS Windows desktop applications for hyperspectral data collection, visualization, and analysis * Interface various components such as cameras, encoders, GPS units, etc. * Work cooperatively with our existing software team * Troubleshooting and customer support Requirements: ========================================= * Fluency in Python (80% of code) * Working knowledge of C/C++ (20% of code) * Ability to quickly learn new technologies and techniques and adapt to changes * US citizenship or permanent work visa Additional relevant experience areas: ========================================= * Machine Vision &amp; Machine Learning * Remote Sensing * Image Processing * Integration of hardware devices * A background in physics, mathematics, or computer hardware * Linux programming and system administration * Cross-platform Graphical User Interface development Details: ========================================= * Full-time position * Salary commensurate with background * Vacation, holidays, and health care benefits * Opportunity for growth and advancement How to apply: ========================================= Please send cover letter and resume to hr@resonon.com About Resonon ========================================= Resonon is a small, rapidly growing high-technology company that provides an exciting and friendly environment with a flexible work schedule. Work tasks are varied and often challenging. We design, build, and support color-sensitive imaging equipment and related hardware and software, and we sell our products to researchers and industry worldwide. Resonon is located in Bozeman Montana in the heart of the Rocky Mountains, a lively university town with excellent schools and outdoor activities such as mountaineering, skiing, rock climbing, camping, fishing, mountain biking, and white-water boating. Visit us on the web at `www.resonon.com &lt;www.resonon.com&gt;`_
Well the website has a lectures starting with Basic python, numpy and pandas. Slowly it’s build towards basic finance concept and later on advanced algorithms. you can also register to Udacity (for free) they have some courses on using python for financial analysis. Good Luck! 
Easiest way would be a bunch of `if else`
This is what I've done so far. I kinda understand what's wrong. I just can't fix it https://image.ibb.co/kpRPvH/Tree.jpg
 if A=="yes": B=input("") if B == "yes": D=input("") if D=="yes":
I tried so but something is off. This is the py file http://www.filetolink.com/539d89f4c3
guizero currently only supports single window applications. https://github.com/lawsie/guizero/issues/155 Multiple window applications are on the list for the next version 0.5.0.
please use something like pastebin.com
Yeah. The expression language is pretty close to raw sql though. I appreciate the differences things like: if condition: q.where(blah) This is all a bit of a pain in raw sql.
but as far as i understand to have dynamic web page i need to use web-socket right? in this case the same script would have two socket connections of different levels ??
&gt; Watch how the same variable changes its ID as the object (the value of the variable) is changed: [cut] This is actually wrong in the example you've given. Ints and floats are immutable so by modifying them it is creating a completely new variable with the same name, with the updated value. 
This post is better suited for /r/learnpython or /r/learnprogramming 
They should have a follow up post when they move to 3.
Only lasts for one session. You also need to set the PYTHONSTARTUP environment variable to make it permanent. 
🔥
I have no idea how to use or create something with cloud synchronization. I might look into learning it.
That's helpful, thank you for the suggestion!
Huh, I was never aware of this tool. I'll definitely try it out.
I don't know if this can help you but I'm currently working on a large data mining project related to Twitter and its API. You could start thinking about something Twitter-data related, just for start. Search "Tweepy" for the related, official Python module. Simple to learn and use.
Okay, thanks! ill check it out!
I have never worked with PyGame, but from a conceptual point of view, you need a game loop, because if you use a thread blocking action, you cannot read user input or do anything else. This is basically a while True loop, where you 1. read any user input, which has happened since the last time, 2. update your simulation according to user input, 3. draw your updated simulation to the screen. Step 2 is where you would check if 5 seconds have passed since you last spawned an enemy. PyGame likely does this for you under hood and provides you with a timer abstraction.
Yes.
This post is better suited for /r/learnpython 
&gt; So what was wrong with our codebase? Take your pick: &gt; ... &gt; 2. We had a method named login.login.Login.login. (If you're wondering, this method was part of the login process.) :p
The only thing I know about shared hosting like bluehost and similar is that people used to have similar problems with really old PHP versions and things like that. You might want to consider checking out a VPS, which you can get for $5/month or less at Digitalocean, OVH, Vultr, or Linode. You can spin up an instance of Debian or Ubuntu and get a much more up-to-date python version for your scripts. It's also a good time to consider working with python3 for new projects, if you haven't already.
So you have a package `login/` and that package contains a module `login/login.py` because you have helpers (like `login/oauth.py`), now your module has a class `class Login: ...` with a method `def login(self, ...): ...`. At the end of the day, that really doesn't seem too bad to me.
Could you please guide me? I mean what consept is this? For what terms should I look online?
The value is not int. It is of type int. Use type(value) == int.
Not like it's Java, where you'd have your com.business.dev.org.something.app.login.form.factory.factory generating your Login Form Factory generating your Login Form, etc etc :D
Yeah, and if really bothers you, you can clean things up via the `__init__.py` file: # login/__init__.py import login.login LOGIN_MANAGER = login.login.Login(...) def login(...): LOGIN_MANAGER.login(...) Bam, now you can `import login` and `login.login(...)` without having to rewrite much of anything.
Ok, a couple of things. 1) You can't have a variable with a space. current_value is ok. Current Value will not work. 2) Colon following the conditional if value == int: 3) As sai0172 said - it should be a type test. if type(value) == int - or - if value.is_integer(): 4) No reason for sum(). Just add the two. print(current_value + value) 5) Make sure you indent (tab/spaces). Indents are "syntactically significant". I love saying that phrase. if value == current_value: print(current_value + value) 6) If this was a homework assignment, shame on you for getting me to do it for you. And learn try/except - that's a more elegant way to handle your test for variable type validity, and you'll need it a lot going forward
http://deeplearning.net/datasets/
Faces are near the bottom http://deeplearning.net/datasets/
I'm not convinced there's a good reason to use pickle outside of toy scripts or little bits of experimenting. It has so many of these little gotchas.
Do people have pretrained NN’s you can download? Like a very well trained text in image recognition NN? Seems like it’s only possible to download tools that do these things, but why not the NN structure with the weights and coefficients and all that? Like a barebones structure.
My favorite thing about it is that it is named pickle. I have not found other value.
Get photos API? Get insta stories?
It's often about automating stuff, like system maintenance, analyzing logfiles, creating reports, converting data between different file formats or databases, ... 
If you're generally familiar with the contents of https://automatetheboringstuff.com/ you should be pretty well set. 
Absolutely. The response is converted to a python dict. To see your feed, just call the generator "feed": from onegram import * for post in feed(): print(post['display_url']) # you can download via any http library
Know how to work with basic data types (e.g., lists, dictionaries) and how to aggregate badly formatted data into useful summaries. Know how to convert CSV, XML, and JSON data to lists/dictionaries and pull variables for analysis. Know how to make pretty graphs and tables from the data using Matplotlib or similar. Bonus: be able to run statistical tests (e.g., Chi^2, T-test, ANOVA). 
It's required to use AppEngine deferred execution: https://cloud.google.com/appengine/docs/standard/python/refdocs/modules/google/appengine/ext/deferred/deferred
Cryptocurrencies is an interesting project of mine. There's a lot of data you can scrap with websockets and run analysis on.
It's necessary in some contexts, like multiprocessing.
Can we get some background or high level dets?
dets? 
Details
* Basemap is currently/may already be on it's death run. Whilst it is still good and still used it wasn't well interlinked with matplotlib. Some of the developers have moved over to cartopy. Actually it now recommends people move over to cartopy (https://github.com/SciTools/cartopy/issues/920) * Cartopy is good and well linked to matplotlib. I'm a climate scientist and it was developed in the UK Met Office so has good functionality for plotting climate data. That being said it may no be so good at high resolution data. I know someone was recently complaining that it's Google map tile is low resolution (https://stackoverflow.com/questions/49155110/why-do-my-google-tiles-look-poor-in-a-cartopy-map). It has good functionality with Natural Earth data though. * geopandas - not used it but the visuals look cool and may be easy to pick up if you know pandas. * geoplotlib - Never hear of it. I'll throw a couple more hats in ring: * rasterio: https://github.com/mapbox/rasterio - Never used it but looks good for satellite/terrain/high res stuff * Geoviews: https://github.com/ioam/geoviews - interactive cartopy plots. Too fancy for what you want to do though For your project I recommend cartopy and ask a Q on SO if you get stuck https://stackoverflow.com/questions/tagged/cartopy
It may indicate that the company has some proprietary home-grown scripting tools which NOBODY outside could already know, but that anyone who already knows how to write programs in various trendy scripting languages should have no problem picking up the necessary skills in-house.
I’ve only messed with geopandas, so my knowledge of GIS is limited, but it sounds like the project you’re describing would be simple to do. I’d highly recommend learning a bit about the libraries pandas and shapely, though, because geopandas is built off of these and you will have to use some simple concepts from these libraries. Also, learning those libraries themselves would be good; pandas is hands down the best thing I ever learned.
Some of this looks like it could of been solved with design patterns. A builder pattern would be great for RSS. 
Yes — specifically I’d check out the first lesson at fast.ai
We use it extensively to suspend running scripts and store them in a database, then pick them up later and start from where they left off. 
I’m polishing/adding new features to a small Flask app that will pull my friends and I’s Fortnite stats from Fortnite Tracker and display it in a leaderboard-style table. Stats include game wins/kills/KD ratio for each mode(Solo, Duo, and Squad). Happy with it so far, but looking for better test and deployment methods/practices. I think I might check out gunicorn for the “production” web server. 
Thank you very much. Well, of course if I had time I'd do a comparison myself... But you have confirmed what I had vaguely understood: that cartopy was to be seen as the successor or replacement of Basemap. 
Over at [r/crossfit](https://www.reddit.com/r/crossfit/) we in the midst of the annual Open competition where ~400,000 from around the world enter scores online for the same workouts. I knew it would be a good dataset to play around with in my spare time. The data is displayed on a website and thanks to a stagnant GitHub repo I was albe to pick up their work and learnt to scrape data using `aiohttp` and save the data as `pandas.dataframe`'s. It has turned into my first open source project (https://github.com/raybellwaves/cfanalytics). I wanted to share my learnings of creating this figure with python. I’m happy to take any feedback or if you want to improve this plot yourself you can do so here: https://github.com/raybellwaves/cfanalytics/blob/master/cfanalytics/core/cfplot.py The data is separated into regions defined by crossfit here (https://games-support.crossfit.com/article/100-what-are-the-boundaries-of-the-crossfit-games-regions-what-states-countries-are-included-in-each). The regions are somewhat arbitrary but based on population of cross-fitters. I was albe to use [`cartopy`](https://github.com/SciTools/cartopy) which has good integration with the Natural Earth vectors e.g. http://www.naturalearthdata.com/downloads/10m-cultural-vectors/ to build up the regions country-by-country and in some instances state-by-state. `Cartopy` has good integration with `matplotlib` and `Shapely` which makes plotting geometries a one-liner (see https://github.com/SciTools/cartopy/blob/master/lib/cartopy/feature.py#L126). The difficult part was making sure I correctly named each country and it some cases match the name of the state. I had to do this for Canada, US and Russia. For example Quebec is named `b'Qu\xe9bec’` and some Russian state names have quotes in their name e.g. `"Ryazan’”` in the Natural Earth database. The data plotted is the ranking of the top one percentile in each region. The data is in the brackets I decided to use `matplotlib`’s default viridis color map and plot the data from first place (darkest color) to last place (lightest) color. However, it doesn’t work so well when neighboring regions are separated by one place. The strings are plotted as the opposite color in the color map over land. The strings are plotted black over the ocean and black when plotting over regions with the middle colors (33 - 66%). Edit: Formatting
&gt; login.login.Login.login 
Just learning how to walk in Python it is for me!
Thanks! Will do.
Sounds interesting, i will try it thanks a lot.
except that's doing implicit code execution on import, which is generally frowned upon (moreso in libraries I suppose)
One word of warning - don't use HDF5 if you are storing your data on S3. Because S3 treats objects as opaque blobs you will need to download the entire file to local storage every time you want to read it, even if you only want to read one tiny table from a 100GB file. If you are using S3 you are far better off saving each table in a separate parquet file and the metadata in JSON files. This way you can access the tables directly from S3 using Spark or Dask.
What are you trying to accomplish? A good website has an API and doesn't need go have hacking scrapers written for it. Reddit, for example, has an excellent API to access all of the data on it.
This kinda makes me want to cry. Great that they refactored, but it's going to get back to that state because it's a culture and process problem.
I think that's the preferred way of doing it, for example the excellent requests library does it the same way: https://github.com/requests/requests/blob/master/requests/__init__.py
I just wanna learn about web scraper in general. and thank you ill look into Reddit API :)
What's in it for the people who help you?
No, it's not the same error at all. This -- as the developers have pointed out repeatedly in the GitHub thread -- is an issue where people relied on directly importing internal APIs/modules from pip and using them manually instead of using `pip` itself. Which has never been supported, and was always "at your own risk". Now, some of the internal APIs got reorganized, and broke code that was relying on those internal APIs, which has led to people angrily demanding that pip restore and maintain specific undocumented internal APIs for people who relied on them.
That site is all goodness 
I built my companies entire mi solution and process automation in python and pandas, I use it for everything.
just use SQlite.... better
If you want abstraction, build them yourself. There is nothing stopping you from doing it the same way as in Java, but such model doesn't come as standard here. If you want more structure, you may prefer to use Django over Flask.
I see what you mean. However the reason why I am asking is if this approach is the pythonic way
&gt; describe how Python is interfacing with the memory. Python is a programming language. It does not, and can not, interface with memory, because it is a completely abstract virtual machine. Only Python interpreters interface with memory, and there are at least seven under active use and development that I am aware of, each with different (sometimes slightly different, sometimes radically different) implementations. So long as the behaviour of the Python code remains the same, each interpreter has wide flexibility in how it implements that behaviour. And that especially applies to how it manages memory. Very little that you say about how "Python" interacts with memory is going to apply to Jython, IronPython, PyPy, MicroPython, Nuitka and CPython equally, because they all use different memory strategies and implementations. The differences may be small, or they may be huge, but they will be different. For example, objects in Jython and IronPython can move around memory, because the JVM and .Net CLR memory managers use managed pointers that allow blocks of memory to move. PyPy can actually deallocate and then re-allocate objects at different locations, and has to take care to ensure they get the same ID. CPython does neither of these things because objects are guaranteed to never move (although they can shrink or increase in size). 
I don't think you will find much of agreement about that. Generally I see two camps: large complicated apps prefer layers of abstractions (and Flask is not that popular choice there), microservices prefer to have small apps doing one thing, and usually don't bother with any separation. Have a look at Flask-restful and Django rest framework, this will give some ideal how this could be done.
Of course it's not creating a new variable! By definition, the same name in the same namespace or scope is the same variable. There's only one `x` variable allowed in a single scope -- you can't have two different `x` variables in the same function. How could the interpreter tell which one you meant? You are mistaking the *value* of the variable for the variable itself. `id()` operates on values (objects), not on the variable (the name) itself. There's no way to get the location of the "variable" because it doesn't exist in a single place. It typically exists as an association between a string key and an object value in a dict. We certainly don't want to say that the location of the variable is the location of the key, because (1) that can move and (2) the key in the dict isn't the variable, in the same way that the map of New York is not New York. You are absolutely correct that ints are immutable and when you do addition, you get a new object. That's precisely my point! The variable `x` is the same, but the value, the object assigned to that variable, has a new ID. 
It usually is. Especially if our language, as beautiful as it is, expects maturity and constraint from its developers which gets increasingly tough once teams and codebases grow.
What's wrong with [GDAL](http://gdal.org/)?
Did OP just end the article early? 
Did OP just stop writing? I'm not seeing the part where they migrated to Python 3. 
Flask is extremely free-form and you won't really get any separation unless you build it yourself. Flask is mostly tailored for micro-services meaning the apps are usually so small that it's not worth it to create a full three layer model. I would usually recommend Django for java developers (it's a more structured full featured framework). but welcome to Python! a lot of the stuff we do may feel very strange and a lot is pretty much against standard java design methodologiesbut it will all make sense sooner or later (and make you more productive to boot). We also have some kick-ass koolaid ;)
Awesome! Fast cpyext is going to be a game-changer for pypy. Can't wait for it to be released.
Take a look at [Pyramid](https://trypyramid.com/). It's from the same people who made Pylons (which reddit runs on), and is not as minimalistic as Flask. It supports the Model-View-Controller model you probably are familiar from your Java world. IMO, Flask is good for small projects, but can't handle complexity well. Pyramid, like most Java frameworks, tries to support you growing your application all the way. 
You can tets https://www.udacity.com/course/programming-foundations-with-python--ud036
A scripting language like python? Ruby, I guess. Or Perl. 
Another thing that drives me nuts is that datetime.strptime cannot parse the output generated by datetime.isoformat() if timezone is present. Absurd
Some highlights: * Implicit dependency on file location makes it difficult to move files * If moving files (will happen) having oneliner imports will promote merge conflicts * A codebase under the watch of a performance* project, indirectly cause it to be well organized. * In this case, good performance of building and distribution (i.e. JS code).
Read Automate the boring stuff with python, the ebook version is free to download 
FWIW, after using py2exe, then cx_freeze, then Esky over the last 7 years, I'm finding pyinstaller less fragile because it has these import hooks that the devs maintain for like 90% of popular 3rd party libs like matplotlib and PyQt, etc. If you're using stuff with hidden imports you may have to tell it what you need bunded, but that's always been the case.
Just released Authlib v0.6: https://github.com/lepture/authlib This is a huge release with so many features: 1. JWS 2. JWK 3. JWT 4. OpenID Connect Now, you can create an OpenID Connect server with ease. Here is the documentation: https://docs.authlib.org/
Where do i get the ebook?
0.5x to 30x. Performance unpredictable to within a factor of 60. I understand that certain parts of Python make JIT really hard, but this is sort of depressing.
First google link ... [here](https://www.google.de/amp/s/amp.reddit.com/r/learnprogramming/comments/34f2qw/automate_the_boring_stuff_with_python_a_free/) 
I cant find an ebook link in here? Where on the page is it? Thanks
This post is better suited for /r/learnpython
It's not quite unpredictable - the post details when the Pypy will be faster and when it will be slower. (faster with much in-python math, slower when calling cfuncs). It may not be faster across the board, but it certainly isn't unpredictable.
Yo dawg... i heard you like login
I think OP went home and became a scented candle seller instead of dealing with this shit.
Nevermind i got it
/r/django
And http://toscrape.com/ in general.
How are you calling the function?
Well you wanna mole something with a team of people that is cool. This is not something for me like a grade I don’t even hav being classes. 
Nicely put together. Thanks for sharing!
This post is better suited for r/learnpython
Using the networkx library to build graphs and analyze terrorism data.
&gt; [SQLAlchemy is the Python SQL toolkit and Object Relational Mapper that gives application developers the full power and flexibility of SQL.](http://www.sqlalchemy.org/)
Please don't write SQL strings in 2018. Use something like SQLAlchemy. 
As someone with no experience in designing games, will Python ever be a feasible language to write games in, or will it most likely always just be for fun/hobby?
Timezone processing is exactly like Unicode/string processing. UTC is *unicode*. timestamps in a particular timezone are *encodings*. Datetime objects-with-timezone is a confusing mess and should be avoided at all costs. Instead, always use naive datetimes and know whether it is a "unicode" timestamp (UTC) or whether it is an "encoding" (datetime in local time). Ideally, you will use the layer approach to timezones -- input into your system will be an "encoded" local timezone, you will convert it as soon as possible into "unicode" -- that is, convert it to UTC such that all your core system code is handling UTC timestamps only, and then, when time to output a datetime back to the user, out to a GUI, etc, you "encode" it back to a local timestamp.
This has changed in Python 3.7. As of Python 3.7, the %z directive will now parse to a `timezone` from the `isoformat()` format. See note #6 on [strftime() and strptime() behavior](https://docs.python.org/3.7/library/datetime.html#strftime-and-strptime-behavior). Additionally, Python 3.7 adds a [`datetime.fromisoformat()`](https://docs.python.org/3.7/whatsnew/3.7.html#datetime), which does the inverse of `datetime.isoformat()` (though obviously it can only reconstruct a `datetime` with a fixed offset, since there's no way to reconstruct the original time zone).
Depends on the game I guess. Some indie game that doesn't require too much in the way of graphics like Hotline Miami or something, then sure Python would be fine. Will it ever be a good language to make a triple A title like the next Call of Duty game or something? No. 
Mic dropped. Nice find. I will surely be adding this to my post. Thank you. I will also give you credit. 
multiprocessing is for CPU heavy tasks. Asyncio is for IO heavy tasks. Its for MASSIVE concurrency, where as multiprocessing is best at only the number of processors you have. Multiprocessing would fall apart if you had a process per websocket connection, for example. If you had 100,000 connections, and each was its own process, that would take way too many resources. Even multi-threaded would be interesting, especially because of the GIL. But with asyncio, there is only one thread, so no GIL locking at all, and it handles that many connections in a very light weight way, while still sharing memory.
Thanks, I'll try that!
I've found little use for SQLAlchemy for scripting purposes. I'm aware of it's Automap functionality but I still find it easier to simply write the 3 lines of code to connect/cursor/execute and obtain data when only doing select statements. Is there something that provides a SQLAlchemy\-like interface that can trivially connect to existing data stores?
&gt; when only doing ... &gt; trivially When did it ever stay that way?
Nice article! However, I disagree in one thing. Author writes: "And in some cases it (pypy) can be faster than C." In the real applications, a good written program in C is always faster than a program interpreted through pypy. 
When I'm writing single purpose scripts to look at complicated data and detect issues. I have a whole class of scripts because MySQL cannot be trusted with itself, even in strict mode.
For python this will be great , for django /r/django
To make the analysis for my Bachelor's thesis easier, I built a script that takes STM images of nano-structures of a sample as input and lets me draw on the picture and performs a real time statistical analysis on the structures' lengths, orientations etc.. That way I can gather data on 1000s of structures in under an hour, whereas previous approaches by my colleagues took weeks to evaluate. 
&gt; because MySQL There's your problem :D
I’ll be their first customer!
Just released https://github.com/lepture/authlib v0.6, which can be used to create OAuth OpenID Connect server.
So. In this instance. Im usujg it for a game. So how would I change it for the whole thing? Startup environment? Or is there a way to do it thru script. 
Sheets. The cells contain text, values, colour (font and BG), borders and cell sizes -formatting. Basically a table.
It already is feasible for stuff that doesn't need to run any particularly complex simulations, AI, or algorithms. It's pretty great for stuff like visual novels, puzzle or adventure games, etc. Sadly, other than that, it's probably gonna leave a lot to be desired even with PyPy.
Which parts of the statement do you disagree with and why?
Pretty much every visual novel game is written in python. I’m not aware of any 3D games though.
You might use it in bigger games,for stuff like scripting scenes it's common to use a nice high level language like python.
I’m working on a state machine to control the autonomous navigation of the mars rover my university is building for an international competition. Pretty cool stuff!
There's panda3d stuff out there right? But I guess that's c code when you get right down to it.
It worked!
I am already using xlrd for some cases. I was hoping someone would have done something similar. But if not, I might use VB, as there appears to be completed solutions for it. And it wouldn't be time effective for me to create one from scratch.
/r/test 
Slow.
"Fluent Python" is a good book you might want to check out. Not a video course though.
Traceback (most recent call last): File "&lt;string&gt;", line 1, in &lt;module&gt; NameError: name 'Test' is not defined 
This is my code: https://pastebin.com/embed_js/wAUu61kY 
The first rule of programming, do never copy paste...
I've seen this as a previous recommendation and i actually have a copy. Its good reading but I've only got a couple of chapters in so far. 
Can you explain in more detail what you want? I'm confused
[https://training.talkpython.fm/](https://training.talkpython.fm/) Michael Kennedy’s courses are what you’re looking for. Listen to his podcast at talkpython.fm if you’re still hesitant or email him. He had a special still going. You can also check out [python bytes](pythonbyt.es) which is a python community and actual coding challenges with teaching and so forth. Two guys run the show and they are approachable and helpful. This should keep you busy 
**[For Hire] US Based Python Developer - Web Experience** **Experience** * Back-End Development using the Django Web Framework * Front-End Development from scratch or using a variety of frameworks * Adobe Creative Suite - PhotoShop, Illustrator * Web/Data Scraping * Data Processing * API Access **About Me** I am a student currently pursuing a CompSci degree who has been programming since the age of ten. I've always had a passion for learning new technologies and using them to create something new. **What I'm Looking For** Remote work of any kind. Whether it's a one-off project or a long-term Junior Developer position. 
"And in some cases it (pypy) can be faster than C." 
Yes. From the job listing, it sounds like they're using python, but they are confident that if an applicant knows one of the other scripting languages that they'll be able to quickly adapt.
Speed is a problem, and the somewhat unpredictable nature of the garbage collector is a huge problem.
I always hated statements like this anyway. Is X language faster than Y? Well, it depends on how well it was written. Perfectly written C is pretty damn fast, but also very difficult to write. So anyone comparing any two languages at tasks other than basic arithmetic is probably working toward a biased outcome anyway.
Not too sure what you are trying to do, but if you pip install something when a certain conda environment is active, I am pretty sure it gets installed in that environment... Installing from source could also be a solution, as you can choose where to put the final library/executable. Just out of interest, what doesn't work in docker? :)
I am not using pip in this case, I am refering to non-Python programs. And Docker access is restricted on shared computing environments, and if its accessible for usage of pre-made containers, admin rights needed to build your own container is not always available.
So you basically want some kind of container system for any old program, but cannot use docker (which would exactly be what you need), but you cannot because of rights. Well then the only solution I see is building the packages from source and putting the libraries/executable in a specific folder. You could then access these programs by using that specific path (eg. ~/bin/my_program) or by putting the folder (eg. ~/bin) in your path environment variable.
Learn design patterns.
Does this have asynchronous / threading enabled in case processing a response takes a long time and may block others reads &amp; responses?
thanks a lot. you guys are awesome! 
Do you know cython? 
Am I reading that correctly? Wouldn't "0.5x to 30x the speed" imply that using this is potentially slower than not using it? 0.5x would imply a decrease in speed....
word
Pycharm is the best for beginners it is like VS for C# (not as powerful and you get what I am saying, dont argue). However, I use VScode. 
looking busy
Just an FYI, there's an /r/test for testing.
Here's the actual link to the article instead of the junk KDNuggets posts. https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7
This totally depends on what your queries are trying to accomplish. In my main work project we have queries that are &gt; 1000 lines long. Trying to do this using an ORM is a complete nightmare. One of our devs started using SQLAlchemy without telling anybody. The code was completely unmaintainable. When he switched teams we couldn’t rewrite that code fast enough. We celebrated after we finished rewriting it as plain SQL. 
I know the game "World of Tanks" uses Python for UI elements, like chat, status icons, etc. 
because cobra is poisonous.
Failed
The actual engines won't be, but at least one engine I know of has python bindings. Essentially you use python and the engine translates it to c++ when you build/compile your game.
If you snoop around the code for Battlefield 2, you will find a Python script for generating the high score list
Wrong sub. Use /r/test, /r/testingground4bots etc.
EVE Online is powered by python. I'd certainly consider them beyond a simply hobby game.
Failed, again.
How does Dash compare to Pygal? I'm currently using pygal for data outputs, and now I'm looking to build a dashboard to display a few metrics. Here's what I have so [far](https://immense-headland-56609.herokuapp.com/dashboard). Would Dash be a better choice for me? Thanks!
Sklearn 
https://www.udemy.com/the-python-mega-course/
Video linked by /u/gelatinous_poot: Title|Channel|Published|Duration|Likes|Total Views :----------:|:----------:|:----------:|:----------:|:----------:|:----------: [Using Amazon's Alexa to improve customer experience](https://youtu.be/a_azbDZvS30)|howlround|2017-02-19|0:02:08|2+ (100%)|394 $quote This is an example of how Amazon's Alexa technology can be... --- [^Info](https://np.reddit.com/r/youtubot/wiki/index) ^| [^/u/gelatinous_poot ^can ^delete](https://np.reddit.com/message/compose/?to=_youtubot_&amp;subject=delete\%20comment&amp;message=$comment_id\%0A\%0AReason\%3A\%20\%2A\%2Aplease+help+us+improve\%2A\%2A) ^| ^v2.0.0
essentially yes. But I am looking for a more formalized system, because I also want to keep the instructions to build the container and setup the environment included &amp; reproducible. I tried building my own package: https://conda.io/docs/user-guide/tasks/build-packages/recipe.html But ran into the issue that `conda-build` was not installed, and installing it would modify the base Conda installation with new packages, etc., so I first made a Conda env just for `conda-build`, then I used that to build my custom package. The build appears to succeed, but when I try then immediately put that new package into its own env, it does not register as existing
You might want to ask the developers of EVE Online about this. Not all of it is written in Python but a good chunk - Stackless Python to be precise.
Actually, you don't. If you have thousands of images, that's more than enough to finetune existing models. Source - experience from training a variety of models.
Hey OP, in the future you should leave a comment stating what the thing you're posting about is. I've never heard of hashin before and I'm less likely to read the article if it's not explained to me at all.
im sry... im confused myself, but i have this abstract of an idea in my head to transform a RL Event into python " structure " so that the "logical flow or reasoning" for proposal to handle it differently is... structured in a way (python code ) that he "gets" ^^ I want to tell him / persuade him of this statement. &gt; Problem: You always initially seem to challenge,discard,disbelief in anything i present to you **Proposal for different approach** : (lets say you also believe that i am intelligent,kind and i am labsolutly not manipulative ) **Plan / Hope**: For Future events, categorically trust me and trust in things i present to you. (the basis for this trust would be his knowledge of me being :int,kin,and not man ) And operate under this assumption accordingly UNLESS or UNTIl you have absolute proof that my statement was not correct and i accepted my mistake.
... sry, i tried t make it clearer... but since i have 0 clue about python and dont know exactly what the result looks like or is even possible.... it just feels like sth that would help him to ...udnerstand my logic / normal interaction better... or not maybe im completly on the wrong track
&gt; I was pointing out that PyPy's JIT will never be faster than running program in C. Your statement is simply not true: https://morepypy.blogspot.se/2011/02/pypy-faster-than-c-on-carefully-crafted.html?m=1 
you should have a look at the brackets in your "b=..." statement, seems like a ')' is missing
oh shit, thanks!!
This post is better suited for r/learnpython 
That's an incredibly contrived example.
That's not really impossible, and without having tested yourself, how can you know it's untrue? From a purely hypothetical standpoint, a JIT *can* optimize dynamic programming problems in ways that a static compiler cannot. I wouldn't be surprised if PyPy managed to hit such a case or two.
Still learning how to code with python :D Any good websites anyone could recommend??
[Rosalind](http://rosalind.info) If you're into bio-informatics algorithms. In general a good reference is [this](https://interactivepython.org/runestone/static/thinkcspy/index.html).
I would survey a number of presentations from the PyCon and PyData conferences. http://pyvideo.org/index.html In particular Brandon Rhodes has made some inspired video tutorials including the use of Jupyter and pandas. see http://pyvideo.org/speakers.html 
All the old stuff is on PyPI. Looks like the last version you can use is 1.10.4, which isn't all that old: https://pypi.python.org/pypi/numpy/1.10.4
Cheers! Will give them both a read
Well, to be fair, simply passing `-flto` makes the C version compile down to an empty main. If I add a print statement to force the compiler to actually generate the code, on my machine it beats PyPy2 (PyPy3 is slower) by 30-50ms.
I'm wondering why use pymssql over pyodbc? pyodbc looks like the microsoft recommended library for connecting SQL Server and python: https://blogs.technet.microsoft.com/dataplatforminsider/2016/12/09/sql-server-python-whats-new/ Not that there looks to be anything wrong with pymssql mind.
We actually did something like this when we were using Groovy and found so few people used it we just advertised for Python. We would of course tell them at the beginning of the interview but it allowed for people to not be put off and actually apply. 
My experience is somewhat similar, but I haven't written a wiki article, which is a mistake, because I need to read it every six months or so. :p I just now know that if I see an offset of +09:40 (instead of +10:00), I've screwed up.
This sounds a bit like the Python 2 approach to strings vs unicode, rather than the Python 3 approach of strings (always Unicode) vs bytes. Specifically, you risk doing an implicit conversion between naive and aware when you didn't mean to. I'm all for doing processing in UTC everywhere and only converting to localtime when presenting to the user, but I think having the timezone attached is probably safer.
&gt; Especially if our language, as beautiful as it is, expects maturity and constraint from its developers which gets increasingly tough once teams and codebases grow. It's the other way around: an easy to learn language encourages sloppy software architectures by perpetual newbies who don't know any better. If you don't need to worry about static typing, why worry about module and API design? Then there's the sudden resistance to casual refactoring. Want to move something around? Better hope you're catching all the runtime errors before the code gets in production.
No, it's a classic example of when jitted code can be faster that aot-compiled code. 
This was delightfully weird so I wil provide some attempted sketch of code for this conversational purpose: def charity(account): interpretations = eval(account) if any(interpretations) == False: dispute(interpretations) Communication goes both ways, by the way.
Thanks. I’ve never heard of these. Am exploring these now. 
I’m always a little reserved with Udemy course. I did a pretty good Python one in the past. I’ve purchased a couple but found they were massively out of date and udemy are getting tetchy with the refunds. Have you actually done this course , is it a good one to have in the bank ? 
You're hardly my first!
Sololearn /r/learnpython 
Here's a sneak peek of /r/learnpython using the [top posts](https://np.reddit.com/r/learnpython/top/?sort=top&amp;t=year) of the year! \#1: [My new book, "Cracking Codes with Python" is now available and free to read online!](https://np.reddit.com/r/learnpython/comments/7sigre/my_new_book_cracking_codes_with_python_is_now/) \#2: [I'm releasing a free code for the "Automate the Boring Stuff with Python" Udemy course](https://np.reddit.com/r/learnpython/comments/7fxork/im_releasing_a_free_code_for_the_automate_the/) \#3: [I made a python cheat sheet](https://np.reddit.com/r/learnpython/comments/82t191/i_made_a_python_cheat_sheet/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/7o7jnj/blacklist/)
Honestly just use Unity2D. It has all the features you need to build a game, tons of example code, tons of tutorials, and C# is really easy to learn if you know python.
This is the example how to not write a statment in C. If he used for(i = 0; i &lt; 1000000; i++) then the compiler would unroll the loop. 
Yes it can potentially run slower... the post explains that calling in and out of C a lot will be slower, thus half speed (0.5x).
Maybe you could say the same with benevolence ?
Using UTC everywhere is smart until it isn't. UTC is very, very good for representing past times and current times and okay for future times. But for reoccurring times it's about the worst thing you can do. For example, you need to schedule a reoccurring meeting for ten weeks at 2pm every Tuesday. So you put the dates into your scheduler with UTC, however unless you manually account for time zone shifts (say DST), your meeting might end up occurring at 1pm or 3pm. Your best bet there is use native datetimes and just know what timezone they belong to in order to properly handle them. 
"is False" !!
The average of the best iced tea recipe and the best hot tea recipe will not be better than either of them.
THAT’S WHAT SHE SAID
PyGal is just for the graphs, where Dash is for the entire dashboard, which just so happens to include graphs. I'd personally rather build a dashboard in Dash than with something like Flask+PyGal. Also, there are WAAAAAAAAAAAAAAY more options for your graphs in Dash because you're basically using anything in Plotly as compared to PyGal's rather limited offering. I love pygal though, and actually my main dashboards for my sites are currently in pygal still. If I was going to do it again though, I'd use Dash.
Edited. I had considered it, but meh.
And that's why I like to use PostgreSQL whenever possible. Between strict data types, custom domains, and numerous ways of creating various constraints, data integrity can be handled by the DB for the most part, letting you deal with the actual coding/ETL/etc.
Python can't be multithreaded because of the GIL. If you want to run parallel functions, you need to use [multiprocessing.Process](https://docs.python.org/3/library/multiprocessing.html?highlight=process#multiprocessing.Process).
Cool, thanks for the cred - also should mention that its a well done article :). My last suggestion would be that I think it is better to not introduce people to `ensure_future` since really what they want is `create_task` most of the time. `create_task` is a much more intuitive api than ensure_future. It really confused me at first and I find it confuses a lot of people new to async in python. It is also why in python 3.7 you will be able to use `asyncio.create_task` instead of needing to call it as a method on the event loop directly, since this is usually why people end up using `asyncio.ensure_future`. For more on this check out the discussion [here](https://github.com/python/asyncio/issues/477) which goes in more depth. Once again thanks for the good article and the good discussion :)
Um, no. That loop is already unrolled, even with just `-O2`. https://godbolt.org/g/71XvDs
Yes, the interface is very similar.
&gt; Python can't be multithreaded because of the GIL Yes it can, it's just sometimes slow. Python has a [threading library](https://docs.python.org/3/library/threading.html) Now the GIL only affects pure Python, so if you're doing disk IO in Python, the interpreter will be waiting on the file system and you can multi-thread with no performance loss.
That is an amazing idea. Because of how it clusters, it can really be applied to all internet knowledge/opinions and a mixture thereof.
You can actually disable automatic garbage collection and rely purely on reference counting. As long as you're careful, reference counting is all you need 90% of the time. When you need to, you can invoke the collector manually. [See the `gc` module docs](https://docs.python.org/3.6/library/gc.html).
are all those on that site also on youtueb as well? are any of those videos (in recent times since lots of things are outdated pretty quick) accessiable to those that do not currenlty know programming? 
I was thinking asyncio but I have not used it so would need to read all the documentation. And I am on a deadline right now lol.
Thanks, I will give it a shot!
I noticed that still having the same issue though with multiprocessing not releasing the terminal in daemon mode. hmmmm any ideas?
This seems to have a lot of similarities to https://github.com/pydanny/cookiecutter-django.
Pretty neat, but 1/8th teaspoon of baking powder as the only leavener for pancakes is just going to result in a soup of sadness
I find it interesting that you went with py.test that builds on unittest but stayed on print where the logging module is native? 
Good news! Didn't know it was fixed in 3.7, I'm on 3.6 atm
Are developers really launching so many projects that optimizing here is useful?
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
I found click a great tool to wrap python projects. To add migration steps, testing and other stuff related to the project itself. This is just a click bait without technical fundamentals but only few wrong concept ideas such as "only one purpose" Go ahead, use click. If it fits your needs, use it, its that simple. 
Good luck. May I saw that Learning and getting into Python got me using Twitter. There is a whole bunch of advanced tweets daily from half a dozen to ten or so individuals. You can check out : [Dan Bader ](dbader.org) - he sends out two or three awesome emails with TIPs and he has advanced courses, you can check out [Bogdan Popa](defn.io) - he just did an advanced web app series, Lynda just released this course on optimizing python code [Lynda python](https://www.lynda.com/Python-tutorials/Optimizing-Python-Code/661762-2.html) and Miguel Grinberg just finished another chapter of his Mega Course [python flask app](https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-xvi-full-text-search) I never “got” Twitter until learning Python and that is up to you, but these are good programmers to follow. Especially Dan, Miguel and Bogdan. (Apart from Michael Kennedy and Bob)... Good luck. 
How do you get the cooking instructions though?
&gt; Fri 20 May 2016 Considering I've been using click successfully since before this, I'm gonna go a head and just ignore this.
&gt; For example, you need to schedule a reoccurring meeting for ten weeks at 2pm every Tuesday. So you put the dates into your scheduler with UTC How would you do that, except by constructing a localized datetime first and then converting it to UTC? And if you do that for each event, they should all correctly account for any DST changes. (Note, it's incorrect to assume that a weekly meeting occurs every 7*24 hours.) 
Selenium Grid looks awesome
The node part is for [puppeteer](https://github.com/GoogleChrome/puppeteer) to handle getting search results from DuckDuckGo. DuckDuckGo is using JS to deliver most of the results, that is you have to scroll down the page to get more pages of results. This is easily accomplished with something like puppeteer or selenium, but I went with puppeteer because its easy.
Haha I don't know! The cooking instructions could, in theory, be grabbed the same way. But it would be a much harder problem to "merge" the information for a consensus cooking instructions. I mentioned this in the [Roadmap](https://github.com/schollz/consensus-cookery#roadmap). I'm not equipped myself to do this, but I happy to support someone else who wants to try!
Google Scholar is your friend. Search there with your keywords to see what other people have done and then formulate a dissertation idea you like. Creating and formulating your dissertation topic is a big part of your research skills. 
"Let's write a compression algorithm..." It allows them to show they know the basics of data types and their manipulation. The questions they ask show you what how they approach problems and how they handle ambiguity. There are plenty of opportunities to discuss what is faster or more efficient in general, and what is faster or more efficient in Python.
I like it. Thank you.
This sounds supremely useful, are you planning to open source it. It sounds like it could serve *as* your thesis.
It's not simply theoretical. PyPy can optimize across package boundaries. If you're using C++ and you use an external DLL, there is no optimization going on at the interface.
^(Thought you were an ex-PFC…) Firstly, "soup of sadness" is brilliant. Second, that's going to be an *average* pancake.
Ohh... I like this. Will try out tomorrow. Thx
“How would you write a singleton class?” There are multiple ways to do this. Talk through the trade offs of the various possibilities. Do they use a global variable? Do they mess with the metaclass? “Make this collection of folders with python files a pip-installable library” Do they know to put init files in each folder? Can they write a setup.py script? This question has been a useful differentiator for me between people who use python for scripting and people who have used it for developing libraries. “What’s a generator and why would you use one? How do you make one?” This is easier (IMO) but would be a good one to pair with your decorator question (which I like). 
Depending on what your mon function does it may be possible to include it in the main loop with a if condition?
I do some consulting work. Three months ago I started a new Django project for the first time in a couple years. The initial setup—Django, Docker, custom user model—took about 1-2 hours. Cutting that to a few minutes can be useful for my upcoming work for other clients. At edX we setup a cookiecutter templates (https://github.com/edx/?q=cookiecutter) because we found ourselves duplicating work when we created new microservices and apps.
*labels
If you'd read the README: &gt; Cluster the recipes based on the presence of ingredients. So you'd get two clusters of recipes, those for iced tea and those for hot tea. 
&gt; for the first time in a couple years That's what I'm getting at... if you're doing serious work, with the exception of maybe micro services, I'm wondering how many people are popping up new projects. And in your initial setup, how much time was on Django, vs Docker (which isn't required by Django) and your custom user model (which probably was custom for a reason)?
&gt; Acknowledgments &gt; This project is heavily inspired by cookiecutter-django. I initially built DjangoX out of a desire to understand all the config magic in it. 
Old post, but show this to your prof and see what he has to say: https://www.youtube.com/watch?v=BKkX9WASfpI https://www.osadl.org/Latency-plot-of-system-in-rack-7-slot.qa-latencyplot-r7s8.0.html?shadow=0 The video is actually very informative and I just happened to stumble on it.
As far as I can tell the main page's download buttons take you back to the python 3.6.4 page that I linked. You can use the menu bar to download python3 without leaving the main page but it's a bit more hidden than I'd like. A nice big "DOWNLOAD NOW" button on the main page is what we need. And it should start the download right then.
How do I use this? I get 'no module named hue'.
That's a good question! I bet it could, but I'm not sure. It would be a good one to try!
Well really anything interesting. Stuff that you could do with tikz you know. Put these images in a doc. Like for example, what if I wanted to create multiple rubiks cube orientations that I want to save for an algorithms document. But I need the pictures. This would be a perfect use case, where one could write a general image algorithm that creates the cube and colors the faces respectiveley via a single function, and they you are run it through a set of inputs and generate a bunch of images all following the similar format.
1. Mix ingredients 2. Boil for 90 minutes 3. Eat
Please tell me your utilizing CloudFormation?
Haha to be **brutally** honest with you, I tried it, but could not for the life of me understand it. It would work great if each cluster were in their own subnet/VPC, but the requirements I had didn't require it (i.e its totally OK for all these "clusters" to be in the same subnet). Therefore I created my own "cloud formation" class that does the heavy lifting for me according to our own requirements. Plus guides for cloudformation on python were so sparse (and so many of them were made &lt; 2016), I'd rather just go straight to the boto3 documentation and hack my way there, haha. 
I would like to when I have the time. So I think my python/numpy/pandas skills is at intermediate level, how long do you think I should learn/practice tensor flow before I can tackle this?
with cooking, this might work. with baking, i suspect things will not work out so happily. as they say, "cooking is an art. baking is a science." bad art is still art, but bad science leads to things breaking or not working
Working on Python implementation of authenticated and encrypted [Branca API tokens](https://github.com/tuupola/pybranca).
I think python.org's main page should have an instant download button that's big and obvious. I think that would be a better new-user experience. Here's an example: https://code.visualstudio.com/
It totally does for me. I click it, it downloads a tarball.
If you're from source, does it have to be 2.6.8? You said everything was 2.7 compatible...
Nice! Although why would total eliminations return as a string? 
ooh, I see. thanks!
Possible typo in README? `self.age = age` =&gt; `self.age = AdultAge(age)`
Looks like that's just how the API returns it.
Weird, for me it links to the py-3.6.4 page
You have to import it to use it. Take a look at the Usage section in the Readme for an example.
Yes. It's so odd how defensive software developers get about automating things and making things easier, when that's the whole point of software! Haven't looked into the quality of this one in particular, but streamlining new project setup is a worth goal. In my job, there's a frequent demand for small one-off websites. If I can get something started straight away, rather than spending half a day getting things set up how I want over and over every single time, that makes me a lot more productive. Apart from anything else, it's *boring* to have to spend hours setting up a ton of boilerplate before you can start working on the actual problem. I want to build things for real people, not engage in configuration masturbation.
Overwatch counts partial eliminations? I feel like I’m taking crazy pills. 
 stats['ALL HEROES']['Eliminations'] &gt;&gt;&gt;'1,169' Never mind, guess thats a thousand seperator. We use "," as a decimal in Norway not "." so I got confused. 
Probably nothing, but I suspect too large and complex for my own simple needs.
Thanks for the recommendation I'll check it out. 
Well, this [cartopy example](http://scitools.org.uk/cartopy/docs/latest/gallery/tube_stations.html) seems almost tailor-made for my simple needs. So I'm going to test it out.
That's like the most simple and basic one of them. More than half of geospatial packages are just wrappers around it.
Docopt "clicks" for me.
I'm guessing that Brigette is no longer "TO BE DETERMINED" (looking at the hero ids)
I reuse stuff like custom user models but I don't ever recall doing several projects in a row where I used the same set of customizations.
[Here's](https://morepypy.blogspot.se/2011/08/pypy-is-faster-than-c-again-string.html) another example. I'm not arguing that PyPy is in general faster than C. But it is obviously true that in *some* cases it can be because it can make optimizations that the C compiler can not do. You have been given at least two examples of this now.
I am always using the cookiecutter from Pydanny.
Recently used swoosh alchemy and it worked really well!
I am new to Python but I am working on a program to generate plots on iOS from excel/text files. The program is meant to he run through the share sheet and so far the first version of it works. 
Eh, pretty sure I don't see Doomfist in the heroes dict
Not for me. :) I like Plumbum. Used to like argh and pyinvoke.
That is an impressive library.
Not exactly matching your description, but you can script GIMP (which is essentially the GUI for imagemagic library) using Python: https://www.gimp.org/docs/python/index.html but this will be automation more like automating pre-press, or "automatic graphical designer", not generating graphs or 3d models.
I've been learning on codecademy.com and I really like it so far. I also just went into the App store on my phone and have been using an app called SoloLearn. Both have been super helpful. 
There was an old joke about SED programmer and an interview question. It went something like this: &gt; Ask a programmer in an interview to implement Roman to Arabic number translator in SED. If he or she manages to produce one, do not hire them. If a programmer knows how to do this in SED, they will do everything else in SED. (side note: I actually met someone who wrote such a program, as a joke of course) On a more serious note: are you sure this is the kind of knowledge you want? The time you have to interview a candidate is limited. Assessment is a very hard task... why spend it on trivia questions? I think, that knowing the syntax is a kind of a baseline, but it's not necessary to have that knowledge up-front. What if your potential hire is very good at Ruby, but didn't touch Python in the last ten years? I think, that you need to be flexible and try to figure out what the applicant think they know, and then work from there. Obviously, it's preferable that they know something related to your company's business. Though, I find that programmers who contribute the most to company's success are those who understand the domain in which the program needs to be used. Ironically, most programmers are reluctant to even hear about that. Hence, if, say, your company does banking, I wouldn't ask the programmer about their knowledge of Python: any monkey with half a brain can learn most of it from YouTube videos in a month or so. I'd ask them about bonds, derivatives, regulations, stock markets etc...
Well. Adding an thousands seperator in an number value returned by an API isn't exactly the most sensible thing I can think of. I guess they wanted to have an easy way to display the value with javascript and not code the thousands seperator in the UI code.
Working mainly on company's internal SDK and tuning deployments to AWS EB.
This is also a good opportunity to learn if candidate knows very basic discrete math. "Why is it impossible to have a compression algorithm that compresses all strings?" Because of pigenhole principle; maybe the candidate wouldn't remember the name, but they should be comfortable enough with discrete structures to give *some* explanation.
Automate the boring stuff with python
Automate the boring stuff with python
The more sensible suggestion was downvoted and slides into a discussion that misses the main point: use `multiprocessing`. Threads in Python are lame, regardless of the version of the language you are using. The same is true about `asyncio`. But, really, if this is the problem you see yourself solving over and over in the future, then Python is just not the right tool for the job. Use a different tool that allows run code in parallel in an easier way. Multiprocessing has a lot of problems of its own, which would be too many to dive into in this reply. What would be the right tool in this situation? Well, if you like Python, then maybe Jython? But... it's an interpreter inside an interpreter, which brings a host of new issues... Erlang would be my choice, but Java, C, C++, Go, Rust, Ada, D, C#, Clojure, Haskell and a lot of other good and not so good programming languages could do this job better. What languages don't do this job well / same as Python or even worse: Ruby, JavaScript, OCaml, most Scheme implementations, etc.
Just completed the last release of "splitnjoin", for splitting/joining binary files. It works well and it seems "fast" (depending on hardware)... I'm very happy about it (it's my first package uploaded on Pip) :) https://github.com/SergioLaRosa/splitnjoin
are those projects object-oriented?
Must have missed him, thanks. 
I guess it might be slow the first time. .. The ftp handler would navigate the directories until it found a component in the url that was not a directory (backup.zip) The zip handler would say it could navigate into files, it would check it was zip, and then try to do it's thing from there.
Actually, that is the difference between PyPy and C. In PyPy, you do not care about the resources. It will do JITs and deep magic. In C level, the optimization is given mainly to programmer. If you have enough time, you can even write JIT compilations there. Yup you write dirrectly in OPcode and you are touching assembly level now. Anyway, lets analyze the previous code in C. ``` for (i = 0; i &lt; 10000000; i++) { char *x = malloc(44 * sizeof(char)); sprintf(x, "%d %d", i, i); ``` Yes it is readable but not optimal in the terms of performance due to sprintf function. I would create a buffer of integers and then easily assign numbers: ``` int * x = malloc(2 * sizeof(int)); x[0] = i; x[1] = i; ``` The buffer contains the same stuff as previous code. Moreover the allocation of the buffer can be placed before the loop. The result: ``` #include &lt;stdlib.h&gt; int main() { int i = 0; int * x = malloc(2 * sizeof(int)); for (i = 0; i &lt; 10000000; i++) { x[0] = i; x[1] = i; } free(x); } ``` Same code in C written in different way. 
Because lol blizzard. [My API](https://github.com/Fuyukai/OWAPI) has to do a bunch of annoying extra processing because blizzard scraping is annoying and hard.
 int main(){ register char *x = (char *) malloc(44); char *tmp = x int i = 0; for(i = 0; i &lt; 10000000; i++){ memset(x, 0x00, 23); itoa(i, x, 10); while(*x != 0x00) x++; *x = 0x20; x++; itoa(i, x, 10); x = tmp; } } The optimization is mainly given to programmer not compiler. 
You will have to do some research on multi treading. 
My somewhat tongue in cheek point was that the average of several good recipes is unlikely to be better than either. 
I don't remember, it's been a year since I've taken the course
I don't remember, it's been a year since I've taken the course
Despite their using a CL menu, command line args seem better suited for this, à la `if any(sys.argv) == "-s": ping(address)`. A better approach would seem to me to be some kind of client-server type service where a server would run the service and commands could be issued with command line options and args, rather requiring the interface be running to perform tasks. One because you could troubleshoot, use timeit, do whatever else, use other tools. 
Please check r/learnpython
&gt; I'm guessing that Baguette FTFY 
&gt; My API Impressive project, nice usage of asyncio!
Python is such a language which you don't need to "learn" or follow tutorials. Everything and anything is possible with python. Think of any idea and BOOM start working on it. If and when you get stuck, the internet is here for you. PS : Best start working on a project. And you will start learning by yourself.(When done with the basics.)
The problem is that everything else we run at work runs on Python 2.6.8. I don't want to be stuck regression testing it all. 
I use HackerRank to learn some basics.
To be fair, Python 3.7 is only out in beta, and I mainly know about this because my friend wrote the `strptime` implementation and I wrote the `fromisoformat` implementation.
Hey, looks decent. Typically when I've had this requirement at work I just embed the data connection and query into the workbook using Excel's database connection functionality (either the older versions or power query). I find that this allows a broader team to run / refresh / modify, any reason you prefer to use python as the middleman? There's probably something I'm missing and always good to learn. I could see python being useful to do in memory adjustments (calcs and various transformations) on the data before putting in Excel.
I mainly did it because my working environment is old school and quite restrictive. I've used Power Query to update Excel dashboards but due to system problems restrictions, this hasn't been a satisfactory method. Alongside this a lot of our dashboards sit on SharePoints where users require them to be updated as soon as they open the Excel report. If you map the network drive to these SharePoints on a server you can run a windows schedule program to run this python script which will update as many Excel dashboards as you wish. It can also be done on your own computer but your computer would have to be switched on all the time or I suppose you could write a simple TKinter program to have all of this run at the push of a button.
Yeah, I'm actually in the process of doing something like this now. So that I can weed out anyone who doesn't know what they're doing before we waste anyone's time interviewing them.
Fair enough, as I said, looks decent , I can definitely see the advantages in that environment! I'm about to start looking for a job (took a year off to chill) so if I run into similar circumstances in my new place I'll definitely refer to this, cheers!
"What are variable types in Python?" It is a trick question. In Python, variables don't have types, values do.
Well, I wrote it back in May 2016 when I naively thought asyncio was good. Nowadays, I regret heavily writing it with it.
Yes, you can easily modify the `nutrition_count` function to do whatever logic you want, and to output the data in your desired format, I'll leave that to you as it's a good learning opportunity. Good luck!
A class with two functions, an init and a get.
Think you have a typo "Marshaller", not marsheller ?
It's true that you can script GIMP with python which is very powerful. For the record, though, GIMP uses GTK (the GIMP Toolkit) for its rendering which has nothing to do with Imagemagic.
This is a great article. I've been playing around with classifying my credit card txns (for budgeting) using an older and less reliable classification method, so this should push the reliability up even higher.
The GIL just means different threads have to take turns to run - this is all handled by the operating system and they are real threads/
They are real OS threads, but only one runs at once.
Hi, awesome! Yes of course, I'm finishing to work on the first version, then I will release it on GitHub in the coming weeks. You can [check the roadmap here](https://trello.com/b/7bdwhnLr/l%C3%A9on-your-daily-personal-assistant-roadmap). Looking forward to see you there and count you as contributor!
For those interested, there are also: * [termcolor!](https://pypi.python.org/pypi/termcolor) * [colorama!](https://pypi.python.org/pypi/colorama)
of course, but the parent specifically equates things where you'd expect naively, that the ingredients are the same. 
This is a bad idea. Because of hot it clusters, it can't really be applied to any intrnet knowledge/opinions and a mixture thereof.
These kind of "a-ha" questions are very bad to ask in an interview, imo. It might make you feel smart, but it tells you absolutely nothing about a candidate.
Brigitte was released yesterday.
 pip install git+https://github.com/foo/bar ...?
Well then... I think that almost any question about Python's data-model, if answered will provide good insight into one's familiarity with the language. In order from simple to obscure: 1. How would you make an object printable? (discuss `__repr__`, `__str__`, bonus material: `__bytes__` and `__unicode__`). See if applicant understand the difference between how information is acquired, stored and represented. 2. Ask to implement a hash-table with keys being of a user type. Discuss `__hash__`, potential pitfalls of hashing. 3. Ask to implement a context manager. Discuss `__enter__` and `__exit__`, bonus for `__aenter__` and `__aexit__`. Double bonus for candidates who will also mention `__del__` in this context, and inconsistencies that arise from the use of two protocols implementing same functionality differently. 4. Ask to implement `@property` decorator, discuss `__get__` and `__set__`, bonus if applicant had ever to write C extensions for Python and are familiar with internal organization of CPython objects. 5. Something to fail the candidate for sure: if they never dealt with numeric Python, ask them about `__index__` and its uses. If they never dealt with heavily over-engineered class hierarchies and languages with convoluted type systems, ask about difference between `__instancecheck__` and `__subclasscheck__`, if they know, ask them for examples of usage. Polish with `__set_name__` if they are still standing. At this point, you can ask them to write left rotation of red-black binary trees without using web-search, or prove P = NP. They are surely defeated :)
 Joytan, the free audio/textbook maker: https://github.com/kokimame/joytan I started uploading a lot of videos on YouTube mostly for language learners. Any feedback will be appreciated! YouTube Channel: https://www.youtube.com/channel/UC0bLbtTI9uni3bNRPIJQAqA Key modules: PyQt5, Pyinstaller, pydub, jinja2, boto3, BeautifulSoup, requests etc.
This actually seems like an exercise in statistics. Why not try Pandas, specifically `DataFrame` class? It stores information similar to MS Excel spreadsheets. You'd have a lot of statistical functions to help you find the best solution for your problem.
Maybe some validation before running the scraping on the input values would be nice
Looks cool and much more in depth than I could do right now! I am a new developer and this project is me learning. It's a million times easier for me to learn when I have some goal than trying to follow along tutorials etc. I want to add a bit more functionality to it, though. Before this I wasn't really familiar with requests and lxml. It felt really, really good when that dictionary was successfully returned. I think I actually raised my arms up and said "YES!"
Thanks. Some nice ideas there. 
Hence "allow room to kind of explore where the candidates strengths and weakness are" If you don't know how to implement a decorator without using `@foo` that's cool. Because if you understand higher order functions, and closures etc, I can hint you in the right direction, and see what your problem solving skills like. It's also why I like starting the interview with a more general technical conversation.
well done dude ! iv'e been doing freelance python work for a year now, and after the work is done the clients want it to be very compact, preferably .exe . i actually went and created a reddit account to tell you that, you are awesome !.
Few nit picks: - Using python 2.7 syntax. - Using type() instead of isinstance(). - Using str.format() instead of “”.format(). - Not using mock as decorator or in a with block.
What would you have used instead today?
This is great. I'm still looking for a useful first project.
If you're not trolling, explain what you mean.
1. If your algorithm isn't scaling by number of servings, you're gonna have a bad time. 2. Median would probably be way more effective here than mean. 
Hope you don’t mind the late comment... IMO you should see if you can merge this project with redbeat. One good quality distributed scheduler would be great. On its own I’m not sure that beatx will get much uptake against the already established user base of redbeat. However I do think you have some good ideas here, especially the storage provider abstraction.
A couple of suggestions: 1) Yeah, as /u/ninefourtwo hinted, it should be a function. Just in case you haven't watched it: https://www.youtube.com/watch?v=o9pEzgHorH0 2) Heroes id lookup should by dynamic - it's easily obtainable from the page and this would help you not to force to update your script every time new hero is introduced. 3) Why lxml and not beautiful soup? "//*[@id="competitive"]/section[3]/div/div" is duplicated so many times, when it could be just a node in bs4 and all lookups start from this position. 4) Have a look at f-strings to do an inline strings interpolations. 
I was fortunate enough to meet one of the JPL rover pilots once, but at the time I had no clue what he was doing. Doh!!
3) that's not a shortcoming of lxml; it can reuse a selector to pick stuff below it. Unless you need to parse broken HTML, lxml works just fine.
This post is better suited for r/learnpython 
This is, it appears, just a digest of the top reddit posts?
Trio.
As somebody who's gone through the pain of parsing that website, I'm glad to hear it. Just a warning; there are a *lot* of edge cases you'll hit randomly, and you'll need to make your code as malleable as possible because the data constantly changes.
It's a little difficult to pin down exactly what you want but if I understand you correctly you want to do something like install your python code and install some other things like drivers or supplementary software. So let's clarify some ideas here All conda is doing when it creates environment is creating a directory for Python and some core libraries changing the path to your python to this new directory. A conda build or skeleton is something like a wheel or egg but is designed to allow you to go projects from different kinds of sources. Perhaps C and python. So if that is what you're doing great - then Google conda skeleton. if you're trying to install drivers and other kinds of programs and maybe modify some environment variables then this is not what conda skeletons are for. So a typical option is to have some kind of distribution system. So maybe if your machines have SSH you would like to be able to execute some remote command to install the driver. Python has a solution for this is called fabric. It lets you do things like execute arbitrary commands or put files on a remote system via python script. So you can write a function that install python create environment installs your wheel and your drivers and so on. But most of that is something you would do for several distribution so now you might think hey I could do something like create a yaml to file to specify what functions to call to create a certain kid of build. And there are tools that do exactly that. Salt an ansible are quite popular and AR for exactly this purpose.
yeah I tried that but even after building the package it was not showing up as an available package on the system
It looks like there's a "GOTO 1xx" in there that breaks out of the nested loop. Too bad the [multiple break idea was rejected](https://www.python.org/dev/peps/pep-3136/). Though here you could easily use `itertools.permutations(range(10), 4)`...
I need to wget the tar-ball for a program, unzip it, store the output (a bunch of Perl scripts) in some directory, then have that directory be available in $PATH by loading some kind of module or container or w/e, in this case a Conda env. I need this to be wrapped up in some modular system because I need to be able to switch between different versions of the program scripts, and also have a scripted method to create the env for each of them on various systems I am using. I was able to create a custom conda package by manually making the 'meta.yaml' file and listing the URL to the tarball as the 'source', but when I try to install the package to a conda env the package does not show up as existing locally even if I include the `--use-local` flags
Great - I can help you then. I'm going to offer a couple of suggestions and you can decide what to do with them. First, I personally would and actually do accomplish this with fabric scripts. Fabric scripts are just a collection of python functions execute remote commands for you. You use the fabric command line program to execute them. For example, I have a install_miniconda function in my fabfile.py (yes that's the default name). I then type fab install_miniconda -h &lt;hostname&gt; and it installs python for me. Then if you want to codify this in yaml, there are tools like ansible that are exactly defined for doing this. Ok solution 2 - trying to work directly with your conda environment. I'm going to assume no knowledge here so if i say some basic things, don't be offended. Conda environments have to be activated. If you are on windows you type "activate &lt;env name&gt;" and if you are on linux you type "source activate &lt;env name&gt;". So there are 2 ways to handle this situation. You can make sure you are activated OR you can call the python in your env path. If for example, you have anaconda installed in c:\anaconda3 and you create and environment via conda create -n myenv python =3 then your environment is located in c:\anaconda3\envs\myenv, the python executable is in c:\anaconda3\envs\myenv\python.exe and pip, activate, conda and so on are located in c:\anaconda3\envs\myenv\Scripts. If you call pip from myenv\Scripts for example, regardless of whether the environment is activated, it will install in your environment. 
Nice 
It’s not the same code as your code will continue looping even when the password is found. 
&gt; As to why Python 3.6, it's just that I wanted to take advantage of the latest addition of the language (like type annotations and f-strings) and, most importantly, I didn't want to manage the compatibility issues between Python 2 and Python 3. I think depending on 3.6 is a potentially fatal mistake that limits adoption. In general, if you want people to use a library like this, you should make it compatible with something not newer than whatever is shipping in the prior Ubuntu LTS. Normally it wouldn't be a big deal, but package management is a convention that needs to transcends projects. I always like to use the latest Python features myself, but I hope you'll consider porting this to earlier versions.
This post is better suited for r/learnpython 
Was the itertools module even released at that time ? (Given this computer from another time) But I agree, easily one-lined. But why even bother ? Just return `password` (:
Hey there! I wrote this article, I went with print debugging because it's a common technique across many languages that I've used liberally in previous jobs and languages without native logging modules. It's also nice for a quick check of something without the overhead of logging setup. Personally I think the logging module and its uses deserve their own article, since there's a lot of ground that can be covered there. 
Hmmm, maybe it might be worth to create a library using this that does what I want.
That’s awesome! I interned at JPL last summer. A wonderful group of people there
Thanks for the feedback! The code was tested in python3 so it should work fine, but I'm sure some 2.7 syntax leaked over because my main work stack is still on 2.7, so it's almost reflexive. I'll try to be more cognizant of any differences in the future. For \`type\(\)\` vs \`isinstance\(\)\` \- while \`isinstance\(\)\` is more powerful and supports inheritance, it's not always necessary for basic checks like the ones in the example code. Anything more complicated than this example code should use \`isinstance\(\)\` of course, and I'll keep it in mind to use that more frequently in the future. As far as mocking, I'd love to learn more, since mocking as its done with pytest seems often documented using this pattern with fixtures. 
I understand what you are saying. And I agree. The thing is is I wanted to be fast in the early stage of the project so I chose to not struggling with potential incompatibilities of Python versions. However, starting support at Python 3.4 would not be too much of an ordeal, I think. It would just mean getting read of f-strings, and other minor specific features. So I could do that now that Poetry is getting more stable every day. However, Python 2.7 is another matter entirely since the incompatibilities are harder to tackle.
Sorry friend, I can not. You are giving benchmarks of dead codes and I can not take the benchmark results seriously. 
The project requires python as we are using tensorflow and a few other python only libraries that are essential to the project. 
This is the one I am using. https://runestone.academy/runestone/static/thinkcspy/index.html
&gt; As explained in the README, I made this module for fun and to surpass my damn ISP limits about upload filesizes. How does this work?
Lynda is pretty good. Not sure which course you took. FWIW Do you know already understand programming? Programming (to me) has two sides. 1 general understanding how to apply logic to solve a problem (think: if-then-else, loops, etc) 2 understanding a specific language, is syntax (java, c, python, ruby, etc) Once you really understand the first, then you can apply the best language for the best solution. A database solution needs different knowledge of the language then something that runs real-time. A daemon has other needs then a GUI. Etc. So I would pick a course that zooms in on the aspects you will encounter within your solution. Or get a better higher level understanding of programming. 
You really should pick a project. Here are places you learn: 1. At home, in your chair, on your computer with a code editor open. I can't stress enough how important it is to _practice_. It's the only way you really learn what you don't know. 2. https://docs.python.org/3/tutorial/index.html 3. https://docs.python.org/3/library/index.html 4. /r/learnpython 5. Stackoverflow.com 6. Google.com 
&gt; Was the itertools module even released at that time ? No. Python wasn't either. Stranger things takes place in the early 80's while python was released in 91.
/r/learnpython 
I wrote two examples about splitting/joining files in the README :) It's just like "split" but in Python! For example, I'm currently using a 4G connection for my notebook and my ISP, sadly, block the uploads of files over 250 mb each one (for no apparent reasons, also). For example, if I need to upload a huge ISO (over 4GB) my only option is splitting it in various chunks (for example, 200mb each one?): ``` from splitnjoin import FileProcessor example = FileProcessor() example.split_file("myISO.iso", 200, "chunk_dir") ``` So I can upload each chunk individually, no hurry. If I download the uploaded chunks I can rejoin them into a single file absolutely equal to the starting one (integrity can be checked with jacksum, for example).
Curious if you're still looking for some practice. I began a script and have hit a roadblock. Don't think it's terribly complicated but could use some help.
I mean, that'll work. def crack_password(password): print("Four Digit Password: {}".format(password)) Though, that'll have the same effect.
P.s. I know I'm missing some elements but I know some nerd will jump on the opportunity. Try to cast to int, must be 4 characters, etc
1. Mix ingredients 2. Add garlic 3. Think about cooking it 4. Add garlic 5. Eat
Wow, I know about the factbook, I know about analysis and some web scraping, but it never once occurred to me to use the factbook for analysis or visualization. Very clever and good resource!
This post is better suited for r/learnpython 
Are there any commonalities, at all, between srting_A, string_B .... string_N ?
&gt; I'm currently using a 4G connection for my notebook and my ISP, sadly, block the uploads of files over 250 mb each one (for no apparent reasons, also). I don't really understand how this blocking could work. Wouldn't a simple SSL connection prevent this? Or perhaps a VPN?
Haaave you met Windows(TM)?
Over a decade ago. They still don't have package management? Wow.
 mappings = { 'stringA', module.script1, 'stringB': module.script2, ... } for string, func in mappings.items(): if string in filename: break func(filename) Maybe? Only works if there's only one string that maps to each function.
You can no longer see your chains because they have become part of you.
it's more of a substring
thanks
nope, unfortunately
I did find this that is very similar to what I am wanting to do. https://stackoverflow.com/questions/2098495/parallel-while-loops-in-python
I'm trying to get Lmfit to work on a 2D data array. The purpose is to generate a script that performs something called "global lifetime analysis" on an ultrafast (frequency and time) spectrum. I'm struggling with how to define a function with a variable number of parameters in which i can call each one of those parameters through the model class in lmfit. Yeah, that sounds gibberish, doesn't it! 😅
2 things. A programmable bot for fightcade/MAME via keyboard commands 2nd thing is learning more about Luigi for work and how it's used to solve big data problems... which my company is hitting the wall at now.
How cool! Are you doing it with Pythonista?
Had an idea for an online notetaking app, combining the Ultimate flask tutorial and [this](http://charlesleifer.com/blog/saturday-morning-hack-a-little-note-taking-app-with-flask/) excellent post. It has markdown, databases, the whole nine yards. Hosting it currently on Heroku. Excited to see where it can go from here. It's super fun to be able to build something and watch it grow. This community has been great with seeing how people can use python to do. This weekly thread is one of my favourite places on the internet, for sure. 
Go full stack!
Excellent work on this terrific library! My only gripe was the `Pendulum` class name; very happy with the rename to `DateTime`!
[tox](https://tox.readthedocs.io/en/latest/) can help with automated testing of multiple versions of Python.
I'd like to be able to mount any project from A to Z. But javascript isn't really my thing ... When I need to design something, I just use some bootstrap ahah. But i'm curious of what you would recommend :) 
Automated testing ? Like with selenium ?
Do you have any resources you found very helpful on this topic?
JavaScript sucks IMO. I would go with Linux, MySQL, then some framework (Rails, Django, Etc) with on top some nice HTML framework (Semantic ui, Bootstrap, Materilze) and JQuery. OFC git 
A VPN maybe can help...? But honestly I didn't even tried it: I thought it was simpler (and funnier :D) make a module to split my files. It was a good exercise for me! Hope it can help other people too 
And [colr](https://pypi.python.org/pypi/Colr) and [colorful](https://github.com/timofurrer/colorful) and [fabulous](https://jart.github.io/fabulous/)...
I think ... thank you ? ^^ As you probably know, i have no clue if this is what i looked for ^^ But since you invested the time and also liked the factorof weirdness - i will trust the code :) so... now i just have to think about how to slip it to my friend xd
Nah, that's not the same at all
&gt; He focuses on topics such as formal verification, specification languages (i.e. hybrid systems and stuff like that) in addition to embedded design processes and functional safety for road and air traffic (think ISO 26262 and stuff like that). The lecture I attended also focused on these issues. Understood. And there's a question posed in the QA period of that talk where he addresses this as well. Short answer: in many cases, modern hardware is no longer deterministic (cache misses, instruction pipelines). I find this fascinating because their approach (OSADL) seems to have gone from mathematical formal to mathematical statistical (i.e. from deductive reasoning to inductive). &gt;I'm still a student. I've written the original answer because I asked the question of open source in ES in the lecture (because I'm an OS/Free-Software fanboy) and the above points were more or less what my Prof said about it. Fair enough. I did study the kinds of things you're talking about here (formalized modeling) some years ago, and I recognize their importance: I'm not arguing they're unnecessary or wrong. If there's any advice I can give it is not to believe in dogma. Seeing a beaglebone achieve 200us real-time latency on a community written OS would have made people laugh 10 years ago...
Selenium is a good start for web application front-ends. For other code there's unittest and pytest. I've no doubt that there are countless others, but those are the ones that I (anecdotally) come across the most. I should probably stress that I manage Ops and not developers so my exposure is limited to peer reviews and hobbies.
Your list is laden with domain-specific stuff that wouldn’t be useful in many jobs. There are few truly specific technologies that I’d include; most will be an understanding of the abstract ideas: - git - regex - Automated testing - Documentation! (Especially with Python; Sphinx is a godsend in this respect) - OOP and functional programming - Algorithms (just read Knuth and you’ll be fine 😉) - Basic understanding of low-level system constraints (in particular memory) and the structure of modern OSes - Basic understanding of networking (esp TCP/IP &amp; REST) - Database design and normalisation, and where databases are unsuitable (document stores; big data) Everything else is probably a combination of the above or an implementation of some aspect of it. If you mastered everything in that list (I certainly haven’t!), learning a particular tech would be a reasonably short jump. 
Update: Just showed it to him and after a few seconds he laughed and obviously wanted to know what this is supposed to be. After i explained him, what i intended to do - he laughed for ages and was reading the code over and over and more than loved the code + idea + intent Success! ;)
Thank you very much for your answer. This is not my first internship, and yes I think I agree with you when you say i might be a little 'encyclopedic'. But is it a bad thing ? I do Python, this is really the tech' I like ! But as I said before I want to be able to create projects, but also put them online, scale them etc... That is why I wanted to know what people think about the list I wrote above. Or something else, you talked about organizational concept. I think there's some dev pattern I should really dig into like "strategy" . All advices are welcome ! Again thx for your long explanation :) 
Ahah nice ! That is exactly the kind of answer I hoped to get :) I'll check out the resources you cited ! Thank !
I've just released version 1.2 of my project: a toolkit for writing reusable web API calls. The latest release adds support for sync/async compatible pagination. Working on this feature in particular has helped me better understand PEP492 and async iterators. [github repo](https://github.com/ariebovenberg/snug) | [readthedocs](http://snug.readthedocs.io/en/latest/)
&gt; can you explain how using a join to prevent multiple separate queries does not address your issue of "dreaded n+1 query"? I'm not sure it has to be taken seriously. First it looks like you don't even understand what `[select_related](https://docs.djangoproject.com/en/1.11/ref/models/querysets/#django.db.models.query.QuerySet.select_related)` really does. It's unrelated because related table data prefetch does not remove the original problem, it *may* only lessen impact in some scenarios. Original problem, extending (non-abstract) model by subclassing which always create an additional table 
Hey :) I'm currently using linux on my computer for a little time. I know some basics stuff, but I definitely need to learn bash ! I use command line when I need to grep something, or find if I lost something specific... I have a VPS that I manage (I agree, there must be a ton of security vunerabilities etc ... ;p ) . I use git as well, I'm quite friendly with commons operations, but not so much with some like cherry picks etc... But I don't know if I need to spend much time on this, or if I just need to know if some functionality exists for when I'll need them. I did a little bit of Docker, I'm able for now to create, manage my own containers, as well as create a Dockerfile. I planned to learn how to write docker compose for multi containers apps. Yes, there is a little bit of web related stuff, but I'm very interrested in everything. That's the problem, I'm too impatient. I want to do everything, mobile dev with Kivy or Pybee, web dev with Flask/Django/Tornado etc... Create my own bots, do machine learning stuff ... I don't know how to structure my learning.. And I don't know Python programmer that I can take for figure to follow.. :/ Thanks for your answer :) !
What variant of basic uses function calls AND line numbers? There'd be a GOSUB 1040 or something along those lines, not a call to another function. Especially bare like that and not using a CALL statement, I'd think. 
I just ran it and it is exactly what I need. I am going to try to implement this. 
Looks decent. You should probably investigate [PEP-8](http://w4t.pw/8e).
I do something much simpler but using an sklearn model. I joblib.dump my model to a cache, load it, and transform the inputs when they're entered. If it had to be faster, I'd look into attaching the model to the server thread or see if it's thread safe and then keep it on the process.
 main_dishes = (('Main 1', 405, 26, 13, 29, 0, 1.4, 0, 14), ('Main 2', 1003.5, 45, 3.6, 58.5, 3.15, 2.6, 7.2, 85.5), ('Main 3', 676, 38.48, 5.2, 46.8, 2.34, 2.6, 6.76, 39)) side_dishes = (('Side 1', 316, 8.2, 1, 53.8, 0.6, 0.2, 4.6, 4.8), ('Side 2', 824, 39.6, 4.4, 104, 2, 2.4, 12, 8)) for main in main_dishes: for side in side_dishes: print main[0] + ' and ' + side[0] + ' is' print [sum(x) for x in zip(main[1:], side[1:])]
Could also sklearn.base.clone a new one from a shared in memory model (eg at the process level)
Is scrapy out of the picture now ?
/r/pythonhomework 
No, this is a less sophisticated project so Scrapy would probably be overkill, though they should have used requests instead of urllib
From your post it's hard to know how much machine learning knowledge you have. I recently attended a nice workshop for which some material is posted here: https://github.com/kjam/intro-to-ml --- Once you have the model it should be pretty straight forward and fast to make a prediction. You could use a REST API through Django or whatever to communicate between the web frontend and the backend which does the calculations.
A password may use the same digit repeatedly, so we cannot just compute P(10,4). We need to generate all 10^4 possibilities.
Oh good call! We can use just use range then in that case. I'll update 
Read the page you linked. Why are spaces preferred over tabs? (FYI - I'm a noob, not someone trying to start a flame war - not sure if tabs vs spaces is a thing....)
I have a book I picked up as a kid that is every built in function and keyword for BASIC for four popular computers from the early eighties. A couple months ago I was wondering if there might be some kind of hack that might let me write in BASIC some things in modern programming languages and I was very surprised to find out that user written function s could be written using a variable name as a kind of pointer. Of course, most BASIC programs were pretty awful so you didn't see it much and it was confusing to figure out how they worked.
Here's a fun interview question: write a function to generate a password of n length. Now write a function to generate all license plate numbers (in the US, generally 3 digits and 4 characters A-Z). Now do it without recursion!
You need to re-read the code..
I didn't know you could do that! That'll sure help with those pesky PEP8 line lengths!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, this post has been removed as it is not directly related to the Python programming language. It might be more topical on /r/programming, /r/coding, or /r/technology. Cheers, /r/Python mods
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Please check the sidebar and /r/learnpython 
I gotchyu: def gen_password(n): return ''.join(random.sample(string.printable, n)) def license(): return str(random.randint(100, 999)) + ''.join(random.sample(string.ascii_uppercase, 4))
Yeah, I know, but I'd only need to add a few things to trigger exceptions. You can handle those. assert len(password) == 4 passcode = int(password) # ValueError assert passcode &lt;= 9999 and passcode &gt;= 0. # to catch a negative trying to sneak in I can't think of any other logical difference. If you find anything else you'll need to explain. Bonus: mine won't crash with an unexpected NameError
Bruh, it's fake dumbass code that should be in r/itsaunixsystem
Here's a sneak peek of /r/itsaunixsystem using the [top posts](https://np.reddit.com/r/itsaunixsystem/top/?sort=top&amp;t=year) of the year! \#1: [\[Supergirl\] You know... Python 6 malware encryption](https://i.redd.it/ipvod31laab01.jpg) | [246 comments](https://np.reddit.com/r/itsaunixsystem/comments/7rsyh6/supergirl_you_know_python_6_malware_encryption/) \#2: [\[Death Note (2006)\] Why hide your password when you can hide your username instead](https://i.redd.it/iiawczoocwiz.png) | [135 comments](https://np.reddit.com/r/itsaunixsystem/comments/6x02d9/death_note_2006_why_hide_your_password_when_you/) \#3: [\[Flash S04E12\] Every TV show when it comes to firewalls](https://i.redd.it/bdhswjrpagd01.png) | [90 comments](https://np.reddit.com/r/itsaunixsystem/comments/7ugtou/flash_s04e12_every_tv_show_when_it_comes_to/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/7o7jnj/blacklist/)
A super interesting application. Can I ask what data you are going to be graphing? My problem with Pythonista is that I struggle to find uses for it...
This post is better suited for r/learnpython 
You do know that there is already a newsletter called [Python Weekly] (https://www.pythonweekly.com/) :-)
github, https://github.com/suned/serum
Or just use return
how is that different from a post like: https://www.reddit.com/r/Python/comments/85c84u/functional_programming_in_python/?ref=share&amp;ref_source=link, except length of content.
Qbasic
I discovered fstrings two days ago, they only work on 3.6+
Not that different. If I noticed it was beginner material or it was flagged, I would have removed it.
Hi there, this post has been removed as it is not directly related to the Python programming language. It might be more topical on /r/programming, /r/coding, or /r/technology. Cheers, /r/Python mods
PEP8 is not always about what is the best, it's about enforcing consistency. When you download someone else's code and it's all spaces and your own code is tabs or vice versa it's super irritating to deal with.
I have removed this post as it is aimed at beginners learning python
Gotcha. Thanks for the heads up. 
 break
I think the best way to self learn machine learning is to code while learning the theories, so that you will have a deeper understanding of the theories and applications. I would suggest that you first familiarize yourself with programming languages such as Matlab and Python. First, I would recommend that you have some basic knowledge about mathematics, especially statistics. Second, you have to learn more about machine learning itself. As for intro books, I would recommend: Machine Learning in Action (this book combines code and machine learning theories in a very clear way. I would suggest you to try coding according to this book in order to familiarize yourself with such knowledge) Elements of Machine Learning (this one is more difficult and has more requirements. As for intro, the book above is more recommended) In the mean time, if you can take some online courses to strength your understanding. I would recommend courses from Experfy, a Harvard based company that provides various online courses related to IT and Tech. To address your request (which is more about the applications of machine learning), I would recommend Machine Learning for Predictive Analytics from Experfy if you want to broadly learn about how machine learning can be applied to different areas, as it has a lot of real-world cases and demos. Third, to further understand machine learning, you can read: Bishop’s Elements of Statistical Learning (you can read this book first) Hastie, Tibshirani, and Friedman’s The Elements of Statistical Learning (this book requires more mathematical background and you can read it after finishing the first one) Hope this will help you and good luck! Eric
This post is better suited for r/learnpython 
Why did you move away from MS products? Are you moving to Hadoop/MongoDB etc?
Very cool.. what libraries are you using? What metrics are you measuring? Are your structures very similar to each other? I know when I see images from my colleagues, they tend to vary quite a lot, as a result its difficult to generate a algorithm to measure them. Maybe a ML algo might be able to recognize the structures, but if I built a rule based code, I would have to put a lot of rules to be able to do it for all possible images that my colleagues see.
Continuing on my work on automating and scaling the application. I am following the `pseudocoding` methodology from `Code Complete`. It has been an interesting experience, I think I should have designed it at a higher level upfront better. However, I am interacting with a lot of external systems (VMs, networks, etc), and I found that a lot of times, I couldnt actually write out the entire implementation in pseudocode, becuase I had no idea how to even interact with the external system at the start. What I realized on re-reading the process, is that its a iterative process. So you will write out the higher level classes and what they represent, then write down the functions, and what they do. Then just pick one class, and start implementing the functions and classes. Especially if you are interacting with unknown systems, and in an unknow territory, its kindof hard to write out the entire function and class in `pseudocode` at the level that `Code complete` mentions, without actually writing it out and testing it out in code. Secondly, if you are writing a big system in pseudocode upfront, you will spend a lot of timejust writing pseudocode, and it can be demotivating, as the system still doesnt work even though you have designed it well. Nonetheless, compared to my previous try where I just jumped into coding the system, and spent a lot of time refactoring the class, it is a better method. Right now, I am writing the test functions for a class called IpythonServer. This server is where the actual work happens, and also happens to be a VM for integration testing. I have separated out the functions which are necessary just to run the integration tests, so I dont write functions for them. This week I am going to atleast finish off the integration test, the tests to push the code to the server, and the code to push the code to the server.
I think the best way to self learn machine learning is to code while learning the theories, so that you will have a deeper understanding of the theories and applications. I would suggest that you first familiarize yourself with programming languages such as Matlab and Python. First, I would recommend that you have some basic knowledge about mathematics, especially statistics. Second, you have to learn more about machine learning itself. As for intro books, I would recommend: Machine Learning in Action (this book combines code and machine learning theories in a very clear way. I would suggest you to try coding according to this book in order to familiarize yourself with such knowledge) Elements of Machine Learning (this one is more difficult and has more requirements. As for intro, the book above is more recommended) In the mean time, if you can take some online courses to strength your understanding. I would recommend courses from Experfy, a Harvard based company that provides various online courses related to IT and Tech. To address your request (which is more about the applications of machine learning), I would recommend Machine Learning for Predictive Analytics from Experfy if you want to broadly learn about how machine learning can be applied to different areas, as it has a lot of real-world cases and demos. Third, to further understand machine learning, you can read: Bishop’s Elements of Statistical Learning (you can read this book first) Hastie, Tibshirani, and Friedman’s The Elements of Statistical Learning (this book requires more mathematical background and you can read it after finishing the first one) Hope this will help you and good luck! Eric
I think the best way to self learn machine learning is to code while learning the theories, so that you will have a deeper understanding of the theories and applications. I would suggest that you first familiarize yourself with programming languages such as Matlab and Python. First, I would recommend that you have some basic knowledge about mathematics, especially statistics. Second, you have to learn more about machine learning itself. As for intro books, I would recommend: Machine Learning in Action (this book combines code and machine learning theories in a very clear way. I would suggest you to try coding according to this book in order to familiarize yourself with such knowledge) Elements of Machine Learning (this one is more difficult and has more requirements. As for intro, the book above is more recommended) In the mean time, if you can take some online courses to strength your understanding. I would recommend courses from Experfy, a Harvard based company that provides various online courses related to IT and Tech. To address your request (which is more about the applications of machine learning), I would recommend Machine Learning for Predictive Analytics from Experfy if you want to broadly learn about how machine learning can be applied to different areas, as it has a lot of real-world cases and demos. Third, to further understand machine learning, you can read: Bishop’s Elements of Statistical Learning (you can read this book first) Hastie, Tibshirani, and Friedman’s The Elements of Statistical Learning (this book requires more mathematical background and you can read it after finishing the first one) Hope this will help you and good luck! Eric
Looking for a top python developer for a full-time position in NYC in a large hedge fund. Excellent pay and great culture. Responsibilities include supporting a critical production trading platform and building tools to automate and monitor it. Can make a big impact. Must be a good problem solver, communicator, work quickly and easy to deal with. Finance, Linux, c++, or java knowledge is a big plus. PM me if you are interested.
I got a VM set up, after some [trouble](https://www.reddit.com/r/vmware/comments/859b1k/corrupted_view_w_ubuntu_16_on_virtualbox/), and found out my vscode extension was failing due to a simple case mismatch &gt;_&lt; Fixed now, so my [extension](https://marketplace.visualstudio.com/items?itemName=almenon.arepl#overview) is officially cross-platform supported!
I'm a bit confused - in your readme you say that the query can be executed asynchronusly, and then you use await. But isn't await synchronus? Await waits for the result to return - that's synchronus, right? Asynchronus being continuing on with the code and resolving the promise later? I've never worked with async in Python before so I'm a bit hazy on the details.
Hello, `np.newaxis` should be in there. I also briefly mention `...`, but if you'd like to expand, please feel free to make a [PR](https://github.com/vlad17/np-learn)
I'm making a custom OPC client to read data from an OPC Server linked to a PLC to automatically generate reports on demand. My end goal is to automatically generate and email the reports based on a trigger in the PLC, without having to print an excel page to whatever format, then email, manually.
Generally speaking is there any reason to use urllib over requests?
I just got around to trying what you said, and your post guided me in the right direction! :D Thanks so much!
Hooking up Plasma API to xnd. Aka lots of c extensions wrapping
Really well thought out article. Makes me wanna build something
You have the same problem in maths. There are two different definitions of natural numbers, one that includes all *non-negative-integers* that starts with {0,1,2,...} and the other that includes all *positive integers* that starts with {1,2,3,...}. Sometimes different symbols are used, sometimes not and you have to guess what definition is used. Personally excluding the 0 from the natural numbers looks odd for me. Array indicies has to be represented by natural numbers, so in the end the inventors of a specific programming languages has to choose between one of the two definitions. Also, if you extend the indicies to include *negative* numbers, going full integers, then starting with 0 fits better, otherwise you would have a gap between 1 and -1, or you use 0 as index for the last element, which also looks odd. But in the end it is a personal choice, technically it wouldn't be no problem to implement either of them nowadays. 
Mostly tkinter, and some plotting libraries. I set it to get the coordinates of clicks and calculate the Euclidean distance and all the angles based on that. All the structures have the same width, but different lengths, and the surface is plastered with them. I also thought about applying machine learning, and even signed up for an ML class this semester, but gave up on the idea since I don't have enough time to incorporate it in my thesis. Maybe I'll reconsider for my Master's or PhD. In my case simple edge detection might even work, but I'm not dealing with a helium-cooled surface and get a lot of noise and drift on the STM, which might make an automatic detection difficult. The very point of ML is that you don't need a rule-based system, you just feed it data and let it figure out the function itself. But unless your structures look similar to something you have abundant training data on (teach it to see rectangles for example), you'll have to label a ton of them yourself, which would defeat the purpose of making the problem more convenient to solve. 
Maybe have a look at some of the Bee Ware tools?
Well it's an awesome guide indeed! 
Thanks Fneu for replying to the post. I am very new to the Machine Learning and trying to do hands on with R, Python. I have made a website using HTML, Css, Php and the data model is on sklearn can u suggest me ways how I can include the functioning model into the website.? Reply to this is really appreciated.Links to how include the same into the website will also work. Regards, Subhro
Thanks Whoopska for replying to the post. Can u please elaborate the process of how to do it? As I am very new to the sklearn thing and have very little idea about it. I already have made a basic website using HTML, Css, Php but the data model is done on Sklearn now how can I basically include the data model into my website so that it works perfectly. I want the model to run and show the results which takes the data from the website while run locally. Any procedure, links to do the same are appreciated!. Regards, Subhro 
This is amazing
PyQt is probably the option that has the best online resources for it. It's a couple of years old, but I wrote a blog post titled [So you want to write a desktop app in Python](http://takluyver.github.io/posts/so-you-want-to-write-a-desktop-app-in-python.html).
I really like PyPy, but as I understand it freezers like PyInstaller do not yet work with it. pyglet has long worked with PyPy, but distributing a game has been a road block. I'm hopeful that this will spur some interest in that area! 
Happy to explain. &gt; Asynchronous being continuing on with the code and resolving the promise later It is true that asynchronous implies continuing with the code, while putting other tasks aside to come back to later. However, promises are not the *only* way to do implement this concept. Enter async/await. Async/await allows us to express asynchronous logic in such a way that it *reads* like synchronous code. It seems like this is the source of your confusion. &gt; But isn't await synchronus? Await waits for the result to return It is true that `await` indeed "waits" for the result before continuing. However, during this "waiting", control may be given back to the underlying event loop, which then puts the task aside (and comes back to it later). This happens when blocking I/O operations are encountered. In this way 'await' is asynchronous. However, because scheduling is handled behind the scenes, it looks very different than code with promises. Here is an interesting article describing similarities of promises and async/await: [link](https://quentin.pradet.me/blog/javascript-promises-are-equivalent-to-pythons-asyncio.html) An example with queries: import snug import json def repo(name, owner): """get a github repo by owner and name""" request = snug.GET(f'https://api.github.com/repos/{owner}/{name}') response = yield request print(f'retrieved "{name}" by {owner}') return json.loads(response.content) queries = [ repo('Hello-World', owner='octocat'), repo('apistar', owner='encode'), repo('requests', owner='requests'), repo('pendulum', owner='sdispater'), repo('typing', owner='python'), repo('toolz', owner='pytoolz'), ] ``` synchronous execution: ``` import time t_0 = time.time() for q in queries: snug.execute(q) duration = time.time() - t_0 print(f'sync duration: {duration:.3f}') ``` this outputs: ``` retrieved "Hello-World" by octocat retrieved "apistar" by encode retrieved "requests" by requests retrieved "pendulum" by sdispater retrieved "typing" by python retrieved "toolz" by pytoolz sync duration: 2.711 ``` asynchronous: ``` import asyncio loop = asyncio.get_event_loop() gathered = asyncio.gather(*[snug.execute_async(q) for q queries]) loop.run_until_complete(gathered) duration = time.time() - t_0 print(f'async duration: {duration:.3f}') ``` this outputs: ``` retrieved "requests" by requests retrieved "toolz" by pytoolz retrieved "pendulum" by sdispater retrieved "apistar" by encode retrieved "typing" by python retrieved "Hello-World" by octocat async duration: 0.553 ``` 
How is the use of those APIs free? I remember looking into the Google speech recognition API and it was something like 3 cents per minute of audio or whatever.
I prefer argparse. It's not the easiest in the competition but most extendable for sure. 
Have you tested this in a situation where the various OS or IO errors happen? BEcause looking at the structure of the try/except flow control it looks like flow still continuous after an error in is cached (even though the expected data did no read etc).
I have never heard of file extensions changing the functionality of a certain file... Heck you could call your python script `file.idontcare.about.extensions` and it would still work if you called it. The tutorial probably has a kind of terminal plugin that looks at the extension of the file and decides how to run it based on that I guess... You can run files with ``python -i file`` which will execute the file and then leave the python interpreter open for you to execute whatever you want. (This is called interactive mode). You would still have to exit the shell and reload it every time you change something in your file, but it's less type work then importing the file in a python shell... :)
Been experimenting with PyQt and for me it works like a charm!
But would it be better then if you pick one at random?
I once saw someone claim that requests was more annoying if you needed to do more customised low-level stuff, but they didn't give details
can you at least *try* to make it look difficult?
Damn, I'm working in 3.5. Thanks for the heads up for my next project!
Is OK to dump random plates? He ask for all the plates. If repetition isn't a problem the number of invocations to get ALL the plates is unbounded
+1 for PyQt. I use it at work and on small projects and it's very easy to get some ui working. 
That makes sense - thanks :)
Awesome news!
[Redis](https://redis.io) would be a good choice here. It supports pub/sub, is installable via conda, and has a nice Python API library. It's also worth the time to check it out as it's a super-versatile piece of kit to have in your toolbelt.
Maybe wxPython is a choice for you like me https://wxpython.org/
Most of the APIs are not free to use. The Google Web Speech API, which the guide uses in the examples, is free to use with a strict cap of 50 requests/day and no more than 30 seconds of audio per request, and that request limit can't be increased. The Google Cloud Speech API offers virtually unlimited requests but does cost something like 3 cents per minute.
What about tkinter. It is very simple. Also it is a standard module for python. 
What did you do as an intern there?
Most of my time this week has been building Python bindings for a Go SSH library and then implementing that in our Python codebase. Why build the bindings? I find Paramiko to be a bit flaky (we connect to a lot of mobile wireless devices via SSH, it seems to get stuck at various parts of the handshake during outages) and SSH2-Python is a bit young (tested it, odd behaviour from time to time). [Check out gossh_python on Github if you're interested ](https://github.com/initialed85/gossh-python)
I’ll second this. I’ve been using PyQt at work for a while and it works like a charm. QT official documentation is really thorough and easy to grasp as you understand PyQt.
To convert lbs to kg you just need to multiply the value in pounds by a conversion factor. I'm not sure why you'd need a for loop in this case.
The ratio of pounds to kilograms is static, iirc 2.2 lbs to 1 kg, why would you need a for loop?
...also [zeromq](http://zeromq.org/) it will be a good candidate.
Why would you need a loop to execute a simple calculation ?
My thoughts exactly.
Event driven is somewhat complicated in terms of effort if you have to roll everything on your own, especially when it comes to communication between systems. Current popular option is to use some type of message broker system. It's basically a server that allows producer(s) to write messages to the server, and the server will then deliver the messages to consumers who are interested in certain topics (via message queue or pub/sub model). Redis is definitely one of the easiest thing to use in my experience. If you don't want to run Redis server, AWS has a fantastic service as SQS, it's very cheap and very reliable. 
...what? Why are you looping?
I've noticed that this sub is either **very** upvote happy or there's some questionable voting behavior.
Cheers
 for x in range (0,0): kilograms = pounds * 2.2 return kilograms Cheating the system?
You seem to be obsessed with for loops today. /r/learnpython
&gt;Is that a problem to you? Yes. There is no obvious application for a loop in the example you need. 
Average = 0 Goals = 0 Number_of_games = int(input(“how many games did you play”)) For i in range (number_of_games): game_goals = input(“how many goals did you score in game {}”.format(str(i))) Goals += game_goals Average = Goals / number_of_games Print(goals) Print(average)
Like what I said, I am forced to write an exercise on finding how to write a program in a for loop notation
I'm after the same. I haven't confirmed yet, but I believe you can use Dragon Naturally Speaking (~$100 license).. there's a library called [dragonfly](https://pypi.python.org/pypi/dragonfly/0.6.5) that looks like it could fit the bill (also works with Windows Speech Recognition Service).
Apparently this is an excercise I am forced to solve, I know I am a beginner but it's not good to criticise a unexperienced programmer who is a 15 year old student in 9th grade
Oh, c'mon... Cheer up goth! 
Unfortunately this doesn’t meet the Linux support need, but for those interested in Mac menubar apps - [rumps](https://github.com/jaredks/rumps) looks promising.
OP seem to be getting weirdly offended by a completely fair question, which I'm finding bizarre. But to be fair, they did answer your question a few times in the comments before you asked it. 
You're right and yet Reddit didn't highlight their username in any replies... I just thought it was normal discussion among non-OPs.
Oh man you are going to have a *really* hard time if you choose this career path.
If I were you I would probably ask your instructor why this is required. It seems a tad extra, I wouldn’t take thinking outside of the box as an answer either lol.
That happens when OP deletes the post. It still exists, and people can comment on it and get notifications of replies to comments, but it's removed from the sub/front page/search results and is no longer associated with their account. So their username isnt highlighte
Lol, /r/choosingbeggar over here. "Do my homework for me, Reddit. But I'm going to get salty if you ask me a legitimate question about my bizarre question statement."
I did not. I assume you are looking for something similar?
Two papers on using genetic programming to locate and repair bugs/errors: https://dl.acm.org/citation.cfm?id=1555051 http://ieeexplore.ieee.org/abstract/document/6035728/?reload=true
Does anyone know what the advantages/disadvantages are to using this instead of NLTK?
Speed vs flexibility. Spacy is good, and very fast, if you just want to use a few "standard" ways of doing these. Nltk is good if you want to research different techniques and don't care as much about speed.
I really like the singleton idea.
Yes, CMU Sphinx and Dragonfly both run locally. My experience is that neither is as accurate as the online engines. The $300 license for Dragonfly claims "deep learning" abilities to improve over time, but this is probably limited to a single speaker.
As far as I know this is a Windows thing only, where `pyw` files are associated with a `pythonw` executable, which suppresses the terminal window that usually pops up on Windows when you run a Python program. Otherwise it works the same as with the regular `python`-interpreter. So you may be mistaken in how you think it's supposed to work.
Well, you rock. Thanks for solving a pain point! :) 
&gt; PyQt Isn't PyQt meant to have an unfriendly license? 
I think that jives with my understanding as well and why requests is slightly slower because they handle all that low level stuff automatically.
Perhaps a multiprocessing Manager() server running on a common port and auth key, and sharing a Queue or using Events to trigger the function you want to run.
Yup, with no luck!
I am still using MS at my day job. I have some consulting work where they want to use postgres and python, looking at how to architect the ETL part. They all come from that background and want input on how it compares to a MS stack and paid ETL tools.
I have removed this post since its for beginners to learn python 
I’m not a professional Python developer but is using a remote Python interpreter that common? I’d think using a local virtualenv for development would be more efficient.
I do it often, my workstation runs windows but all the cluster and embedded stuff I work with are Linux; it makes it easy to edit code locally but debug it on the actual system especially when there are resources on remotes that can’t really be emulated on the local machine due to hardware or OS issues.
Ah yeah I never considered using it for testing on another OS. That makes sense. Thanks for sharing.
tkinter for the GUI and then use py2exe with the file bundle options. I wrote a few tools using Python3 and this was the easiesy way to write a gui that was cross platform compatible and generate a windows executable, OSX program and in linux I just run it via command line. (I am on OSX when building these).
This has been my experience too.
What would make SpaCy less flexible? You can manipulate the SpaCy pipeline as much as you want. I'd say the advantage of NLTK is that it's simpler, more transparant, and it comes with a whole ecosystem of tools and documentation that are great to use in an educational environment. But it does lag behind the state-of-the-art.
For doing lots of things, Java and Python doesn't require math at all. Don't worry about that. Since you are learning as a hobby, I suggest you check the official tutorial of both languages, and see which one do you prefer. Both are good choices for a beginner. It's not hard to learn the other when you know one of them very well.
You don't necessarily need an advanced understanding of math or program. Also, *program* is the operative word here -- it makes no difference whether *programming* in Java or Python, the math requirement is based upon the task at hand. So, pick either and start messing around. If you find that you enjoy programming as a hobby and want to pursue a career, then you will benefit greatly by expanding your knowledge in mathematics as computation becomes more of a real concept in your approach to solving problems.
Okey thank you all very much
Check out [Kivy](https://kivy.org/#home) Really underrated and under-recommended project. Like any UI framework, there's a bit of a learning curve. But Kivy has a huge advantage over most other UI frameworks in Python: you can compile it down to a native app on almost *anything*. OS X, Linux, Windows, Android, iOS. It can take a little effort to get the build tools set up (I've done OS X and Android), but it does work.
This is good stuff! /u/tippr 100 bits
[removed]
[Google fav, Youtube fav] ?? Are you wanting to control youtube in a browser using python?
Well, it’s a sub where a majority knows how to program an upvote bot. 
My [mini-frame](https://github.com/jdavidrcamacho/mini-frame) seems to be working :D Now its time to improve it by adding more kernels to it, afterwards apply the Jones et al. (2017) framework to generalize everything.
Today I did some basic work in Micropython on an ESP32. I have some seedlings in my lab and I want to make a basic environmental monitor to be placed in close proximity. I have a DHT11 and a good old ORP12 LDR, I got both of those working nicely today, as it turns out there is a nice built in library for the DHT11. It reports ambient light level as a %, temperature as C and humidity as %. The ESP32 dev board has a built in OLED and takes a LiPo battery, it could report readings standalone, but next I want to get to grips with MQTT and try and get the data on ThingSpeak or Adafruit.io I was thinking that I will probably CAD up a case for it all as well :) I will share code at some point but right now it isn't doing anything other than reading sensors and printing :)
In my laptop, it takes forever for pycharm searching and indexing libraries from anaconda distribution, my laptop even freezes forcing me to do hard restarting. I gave up on this charm and started using VSC. 
Please checkout r/learnpython and r/learnprogramming
Hi!The requests-html library is very simple to use and abstracts to you all these work with HTML tags. You can iterate in tables and links, find elements using CSS selectors and render Javascript. http://html.python-requests.org/
Oh this is interesting. The skimmed the pyx documentation and this seems like exactly what I was looking for. It's very detailed too. Thanks for this!
There's [an episode](https://www.podcastinit.com/podlove/file/210/s/feed/c/mp3/Episode-87-SpaCy-with-Matthew-Honnibal.mp3) of Podcast.__init__ with the developer of SpaCy. I highly recommend it.
I've used [RabbitMQ](https://www.rabbitmq.com) to do this. You can set up a weather "channel" that is fed by your telegram bot and consumed by one or more weather consumers. You would have to set up a RabbitMQ server (service) that would act as the message broker and implement the client interfaces in your python scripts. It would be easy to prototype on a single system, but you can easily scale it so that clients on many different systems could connect to the broker (securely) and send and receive messages.
Here's a minimal working example of a toolbar application using PyQt5: from PyQt5.QtGui import * from PyQt5.QtWidgets import * from PyQt5.QtCore import * app = QApplication([]) # Create the icon icon = QIcon("icon.png") # Create the tray tray = QSystemTrayIcon() tray.setIcon(icon) tray.setVisible(True) # Create the menu menu = QMenu() action = QAction("Test") menu.addAction(action) # Add the menu to the tray tray.setContextMenu(menu) app.exec_() The result (the icon is on the left): [Imgur](https://i.imgur.com/CKgnA5p.png) [Imgur](https://i.imgur.com/cVgnWE8.png) 
Oooh, I was just looking at GIS and GeoPandas for someones stuff at work. Thanks for sharing
tl;dr you need to send to and join the multicast group of the same multicast address. your example code is good except for three things: * everybody needs to use the same multicast address; pick 224.1.1.1 or 224.3.29.71, but you can't send on one and expect to receive on the other * "struct.pack('4sl', group, socket.INADDR_ANY)" is not 64-bit safe, while '!4sl' is, but you are receiving on a raspberry pi so 64-bit might not be an issue. i prefer to just "socket.inet_aton(multicast_address) + socket.inet_aton('0.0.0.0')" (replacing "0.0.0.0" with the IP address of a specific interface if desired) because that's always the right size and endianness. * the final block (ie "except Exception as e:") in listenTest.py is improperly indented as will result in "IndentationError: expected an indented block"; you need to indent by a tab both the following "print" and "break" lines (or just remove the exception handling as an unhandled exception is equivalent: the exception will be printed along with the traceback and the loop, and entire script, will exit). here's my reference implementation of a multicast sender and receiver: https://gist.github.com/ifundef/09d3ec98459a856052bd935bd91683ed (including support for windows, but take windows support with a grain of salt as i haven't tested/ran it on windows in years).
Please check our sidebar and r/learnpython 
This post is better suited for r/learnpython 
What, why?
I really like Tauthon and am trying to encourage my work (heavily entrenched in Python2, including a lot of handwritten old C modules) to consider Tauthon the logical successor to Python2.7 when Python.org finally decides Py2 is EOL.
&gt; I really like Tauthon and am trying to encourage my work (heavily entrenched in Python2, including a lot of handwritten old C modules) to consider Tauthon the logical successor to Python2.7 when Python.org finally decides Py2 is EOL. It looks like the sane upgrade path to me. Hopefully we get more contributors to Tauthon and some adoption from Linux distros. Gentoo devs are resisting, so far.
Answered [here!](https://www.quora.com/What-are-the-advantages-of-Spacy-vs-NLTK)
I got all my songs bookmarked in google Chrome I would like to create a program that read my bookmark file and plays my songs one by one randomly *thanks for awnsering btw*
Should I change it now I am new to reddit to lol
Python 3 will be supported for a long time. Learn it.
Do anybody have experience with [PySide2](https://wiki.qt.io/PySide2) see it still in dev for Qt5. Any body worked with PySide? Using Qt4? Is starting a project in 2018 using PySide and Qt4 a bad idea?
I got to work in the Safety Office. So I had the opportunity to visit a bunch of different labs
The university of Helsinki published their materials for a course called "Automating GIS-processes". Maybe that's interesting for you, you find the course at https://automating-gis-processes.github.io/2017/
Agreed. I know a lot of Python people are really resistant to the idea of people using anything but Python3, but — "different strokes for different folks," and, "use the right tool for the job," and all that. A small community continuing the spirit and use of Python2 is not a criticism or insult to Python3, and does not detract from your use of Py3! It's just the natural result of a hard fork of a popular language. If anything, it just goes to show how dang popular Python2 was and Python3 is.
I have a similar environment. My remote interpreter is at 127.0.0.1, though; it's the Python interpreter installed within WSL.
Am I the only one who still uses bucket = list() ?
You can train a computer to do anything nowadays
I work with large datasets which live on a central server. Rather than download the data or even connect to it through Python, I usually SSH to the server and use vim and ipython. This would provide that same access.
AFAIK using list() is slightly slower than [].
My best idea would be to set up a web framework that uses Python like Django or Flask or the one you find you like. You could take the user input from a html input form and parse it in the choosen framework and render a http response. Django and Flask offer template engines for this purpose.
Definitely read up on test driven development Write your tests first. Run the empty tests (your blank test could raise NOT Implemented Error) to ensure they fail. Write code until your test passes. https://en.m.wikipedia.org/wiki/Test-driven_development Can you share some tests you think might accidentally pass? As long as your test harness is not accidentally passing, and every test has an assertion, you should be fine. Also look into seeing if there is a setting that will force fail if no assertions are made. 
Non-Mobile link: https://en.wikipedia.org/wiki/Test-driven_development *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^162833
Thank you so much! I'm still in uni so when this got a lot of attention I was very happy. I'm glad it's of use to you!
Thanks! It means a lot to me.
I am happy to hear that you find Pendulum useful :-)
you should not have so many libraries installed to one virtual environment; allocate at least one virtual environment per project, and keep the installed libraries to just your dependencies. It makes things far easier and far faster to index everything (and frankly, that's best practice too).
Lemme tell you, having a drop-in replacement was a godsend
Read up on the [`cgi`](https://docs.python.org/3/library/cgi.html) and [`wsgi`](https://docs.python.org/3/library/wsgiref.html) modules in the standard library.
&gt; Python string How would you use Python string split to load this file? I am switching from Matlab so this is so confusing to me. Thanks
I couldn't agree more! Something that I found useful was [this](http://www.leancrew.com/all-this/2013/10/simple-expense-report-with-drafts-and-pythonista/) post from Dr. Drang. It helped me to realize that Pythonista could be a text parsing tool, and gave me data to work with. Drafts also has potential as a way to send data to Pythonista. 
For both examples, can you provide your expected output?
Did you try Googling python flatten JSON? https://github.com/amirziai/flatten
Sounds interesting..will give it a try
I tried switching from vim to PyCharm once. The vi bindings are really rudimentary; I don't remember what was missing, but I think it was things like "cib", "ct(", etc. It was too much to give up.
It depends on the project, I have an 'embedded' system that I use the remote interpreter for
Pandas readcsv does support regex delimiters. Use " +" as the separator and the python engine.
list can also be overriden by a careless or devious developer as well. import __builtins__ def nope(*a): raise SyntaxError("use []") __builtins__.list = nope
Did this recently and would have to agree. Especially with conda/miniconda -- super efficient.
One potential issue is not properly testing corner-cases. The hypothesis package is intended to help with this. Another potential issue is with floating-point numbers. They often don't have the value you think they do.
Currently I am learning the language. Parallely I also solving excerise related to it. Intially I wrote a simple program related to hotel bills. Then a small program that will display grades of student based in precetage of scores obtained. Currently I am working a program that will provide sum of mutiple of 3 and 5 from the range 1 to 1000. For that loops are required. I am learning that. I am very much eager to work on open source project..but I have a long way to go.
So, don't use any builtins ever in case you ever accidentally import __builtins__? 
Yes, I think that's a good approach. As fast as software itself changes, deployed versions stick around for a long, long time. The market is (finally!) starting to move on from Python 2, so while excluding Py2 will still cost users, I don't think it's an unreasonable decision at this point. In the meantime, I'm about to give Poetry a try on a new (Python 3.6) project and see how it goes. I'm excited! Package management has been a glaring weakness in the otherwise-fairly-robust Python ecosystem for many years. I'd love to see any kind of standard comparable to Bundler or npm emerge. Thanks for all your hard work!
I find TDD annoying. I use it for say writing an intense algo like a quicksort... but never for a CRUD function. Which obviously 99% of my life is not writing quicksort. For most code i try to test as close to the endpoints as i can. Integration or almost integration. Lets you cover a lot more lines of code per test, and will be much less brittle down the road.
definitely. i work 95% of the time in vagrant or docker containers.
You may find this useful https://testdriven.io/ All about building flask and react apps with testing as a priority.
Test not only pass cases, but also fail cases. Make sure you fail properly, and that things you expect to fail, do fail.
when i use a letter at Number of Results: box it crashes. 
It's also 4 less keystrokes and doesn't require reaching for the shift key.
"New Text Tool" is one of the top 3 new features they mention.
Thanks. I have not yet added validators for the form submission fields 
Not used pytest.
I'm working on learning Python GUI construction using tkinter. I'm also learning SQL basics.
Sounds like a good alternative and it looks easy to use, thank you! I'll make sure to try it.
Thanks for the suggestion. I'll be comparing this with the other alternatives.
Yeah, I thought it would be something more simple and easier, but the message broker seems the way to go. I didn't know the correct words, but now I can do my research. Thanks for your input!
Yeah, I thought it would be something more simple and easier, but the message broker seems the way to go. I didn't know the correct words, but now I can do my research. Thanks for your input!
Which OS?
Do python's test methods not allow for imprecise comparisons? C#'s look like this: void Assert.AreEqual(double expected, double actual, double delta);
Another way (with further complication): bucket *= False
There are methods like that but you need to know to look for them and use them properly.
r/learnpython 
&gt;we're still talking less than 0.0000001 seconds Cool, but if you bother to figure any of this out it might be because the scale of what you're doing requires that you optimize as much as possible. I've been asked things like this in job interviews, that time delta matters.
`list = [1, 2, 3]` is legal Python. I’m sure someone has done things like that, although I wouldn’t recommend it. `zip` OTOH I’ve shadowed myself. 
&gt; the scale of what you're doing requires that you optimize as much as possible. Then you likely wouldn't be using python.
If you have to optimize *that* much, you shouldn't be using Python, you should be using something that gives you more low-level control.
Tell me about it so useless.
python has a framework for embed devices that maybe you could use while learning https://micropython.org/ i believe that in the robotic field c++ is more used than python because of the performance . but im not sure 
I'll look into that too, thanks!
Thank you for the detailed explanation! RabbitMQ seems an interesting suggestion and more geared towards messages than Redis, so I'll try both of them and compare.
Creating a list which is just one item repeated. lst = [obj] * 500 could also be lst = [obj for _ in range(500)] but the terseness can be preferable if it's in the middle of a function call, for example.
Sharing and autopromotion of a new master in a replica set. 
For me, sharding and promotion of a new master in a replica set upon demotion/failure of the current master are two big ones.
Aha! I failed to scroll far enough.
I'm going to admit I use it for creating square surfaces in pygame. `mysurface = pygame.Surface([500] * 2)`. I know it's bad, but I feel no shame.
You might be able to use the command line browser control described below with `subprocess` module to open pages. https://superuser.com/questions/459775/how-can-i-launch-a-browser-with-no-window-frame-or-tabs-address-bar
Humans: Often the bottleneck.
It has nothing to do with the scale of optimization. The reality is that for any real production code there are going to be a million other things to optimize before you get to things like list() vs []. 
And the new text tool... Is it not broken? So many years yet it was useless. It being new does not guarantee it is fixed
Python 3 for personal use / staying current. Python 2 is still currently used more in the industry than Python 3 though so it's still important
That doesn't discount the point of optimizing lists at all.
I second this. You can get a simple webapp going in no time with Flask.
This is why I love this sub
I know what you did bhat. For shame!
 import requests import datetime from dateutil.relativedelta import relativedelta def callUrl(query_string): url = "https://fakeurl/site/number" headers = { 'Cache-Control': "no-cache", 'Postman-Token': "FakeToken" } response = requests.request("GET", url, headers=headers, params=querystring) Full_File = response.text import json json_format = json.loads(Full_File) allValues = json_format["energy"]["values"] return allValues def write_to_file(array_of_json): file_handler = open("QuarterHoursRepeated.csv", "w") file_handler.writelines("Date, Hour, Value" + "\n") for each in array_of_json: for values in each: Date_Parts = values["date"].split(" ") The_Date = Date_Parts[0] The_Hour = Date_Parts[1] theValue = str(values["value"]) if theValue == "None": theValue= "Null" file_handler.writelines(The_Date + ", " + The_Hour + ", " + theValue + "\n") file_handler.close() if __name__ == "__main__": no_of_months = #number of months you want to call. start_date = datetime.today() end_month = datetime.today()+ relativedelta(months=1) array_of_json = [] for i in range((no_of_months)): startDate = start_date + relativedelta(months=i) endDate = end_date + relativedelta(months=i) querystring = {"timeUnit":"QUARTER_OF_AN_HOUR","endDate": "FakeDate","startDate":"FakeDate","api_key":"FakeAPIKey"} array_of_json.append(callUrl(queryString)) write_to_file(array_of_json)
I've literally saved dozens of seconds my entire career.
Thanks, that worked. Switching from Matlab to Spyder is quite difficult I see.
I haven't done any comparisons, really. I used to dual-boot, and it's definitely more convenient to use WSL. A VM would probably be better if I needed any GUIs running natively in Linux, but that's not necessary at my job.
As does numpy.testing
Damn here I am using ``` bucket = list() ``` Like a fucking pleab.
Assuming python is as fast as c++ compiled code. It was never meant to be c++. A lot of the benefits in python come at the cost of speed. 
Uses some basic Python/Flask, MySQL and the Spotify API Endpoints used: GET: https://accounts.spotify.com/en/authorize (Authorise the user) POST: https://accounts.spotify.com/api/token (Get the authentication token) POST: https://api.spotify.com/v1/users/{user_id}/playlists (Create a playlist) GET: https://api.spotify.com/v1/me/top/tracks (Get the users top tracks) PUT: https://api.spotify.com/v1/users/{{user_id}}/playlists/{{playlist_id}}/tracks (Replace tracks into a playlist) PUT: https://api.spotify.com/v1/users/{{user_id}}/playlists/{{playlist_id}}/followers (Follow a playlist)
Rather than having region and platform as random string input, would be great to turn it into an enum. For example, if I wanted xbox, what is the platform string for that? 
Yes, but beware - you can definitely find patterns in noise if you look too long :P
If you install it with the toolbox app it seems to help, on Linux at least...
The new cell by cell execution in the scientific mode is pretty awesome. I love jupyter notebooks for exploring data and wrangling, but having it save to source control as json (.ipynb) has always been a pain for following code changes - this seems to be the best of both worlds. I don't think that feature would have been there if someone hadn't done it in VSCode first though - and this is why I think it's great having more than one viable IDE for python dev, as a little competition can help push each other along with new features.
Since you said you can't install any other modules, you may want to try something like this: it's a basic HTTP server that you run on your own machine, along the lines of Flask and other web frameworks but much simpler and much more DIY. My first application server (ScriptServer) « Python recipes « ActiveState Code http://code.activestate.com/recipes/392879/ It's from 2005 and written for Python 2.4, but it doesn't look like it would take much to get it running under 3.x. The principles are all pretty much the same. I used it several years ago to create a simple report server for my company. It did the job even if it didn't get much use. You write pages as Python scripts that output HTML. You can also include CSS and JavaScript to make nice looking interactive pages. I even had an Ajax example working. 
No kidding I had to stop one of our analysts from shadowing zip just today. It probably wouldn't have mattered except that about 20 minutes later the most convenient way to do something was with zip (which she didn't know about so she was going to use a range to index two lists).
Thank you for your reply, yet the chance that I learn coding c or c++ plus python at the same time while maintaining GPA is very small, so I wonder which language to pick up for engr student is better? Would like to hear your advice, thanks.
Python 3 would be a better choice for current learner?
For the heck of it, `bucket *= 1//(len(bucket)+1)`
Depends on your keyboard layout.
There is so much Zen in the Python language.
Look, just stop it: `bucket *= bucket == []`
Or `bucket *= [] == bucket` for better symmetry.
Someone stop me, please! `bucket *= bucket in bucket`
Aaaaaaagh! `bucket *= not bucket`
Nice job!
Thanks! Do you have any suggestion?
I expected this to be a Kenneth Reitz project. Not sure how he feels about it, but I don't like that you are copying his brand in this way. I feel like you are trying to take advantage of his ability and hard work.
Check out ROS (Robot operating System, http://www.ros.org/). You can create modules either in python or c++. I've worked with drones and when we could use python, we would. But when it comes to real-time processing, high performance such as vision, position control and so on, C++ was the language of choice. Considering you are starting robotic engineering, I'd start with python to learn more about the concept and architecture of a robotic software before moving on to C++ for more specific applications.
Add functionality, but keep generic templates for future sites. That way you can use for other sites. Dont stop developing. Looks like you got a decemt overview of it
Alas, this one isn't right: &gt;&gt;&gt; bucket = [] &gt;&gt;&gt; bucket.append(bucket) &gt;&gt;&gt; bucket *= bucket in bucket &gt;&gt;&gt; bucket [[...]]
I'm not entirely sure about your use-cases for programming, but unless you are talking about high-performance computing it hardly matters. Embedded systems programming? You'd expect that Python isn't suitable, but check out MicroPython.
https://docs.pytest.org/en/latest/reference.html#pytest-approx
You can do something that has been done before to learn _why_ or _how_ it's done that way. For _one_ of your existing basic scripts/modules: * Put docstrings on every function &amp; class. * Package it up so it's installable with `pip`. Use `entry_points`. * Make pieces usable from another module via `import`. Reuse is the mechanism by which we stand on shoulders. * Use `argparse` (or `click` or something) for argument parsing. Pretty `--help` is good for the soul. * Use `pytest`, and get 100% coverage (so include your argument parser).
I can’t help with tools... I was curious too. As for inspiration here’s a suggestion. Find ways to automate things in your day job. Yes, there are other tools, but that’s not the point. Make something and make it work for you. Also, Find and do a tutorial on a regular basis. If you spend enough time playing with the blocks you will find new ways of interconnecting them. 
Why on earth? Lxml is already for humans. Stop this "for humans" madness!
It's just the motto of all the "Requests" modules at this point
I use it keep complex formatting parameters as concise as possible, and I got the idea from [Ploty documents](https://plot.ly/python/table-subplots/). 
This. But it's not just accepted because it's succinct, it's accepted because it's fast, too. # multiplying a list $ python -m timeit "x = ['a'] * 1000" 100000 loops, best of 3: 3.3 usec per loop # building a list via list comp $ python -m timeit "x = ['a' for _ in range(1000)]" 10000 loops, best of 3: 26.2 usec per loop # appending to a list $ python -m timeit "x = []; &gt; for a in range(1000): x.append(a)" 10000 loops, best of 3: 52.2 usec per loop The first alternative (list comp) incurs a penalty for having to iterate. The second incurs an additional method call overhead. Plus there's the cost of copying the list as the list grows. Know you're gonna have a really big list? Preallocate and assign the values in.
1) Tightly coupled tests - tests that couple to implementation rather than behavior so that they fail when code is *changed* and not necessarily when there is a bug. 2) Unrealistic tests - tests that do not mimic the real world accurately enough and thus don't find bugs. 3) Unisolated tests - e.g. tests that pass or fail arbitrarily because some random API starts returning something different or because the time has changed.
Lxml is indeed great. Been using it for years and I've yet to find something better. 
&gt; Python 2 is still more heavily used Probably, but that does not make it a good case to learn it. All new projects are starting in Python 3, and 2 will be on life support for some time, some even converted to 3.
But does in the case of a = [obj]*500 does it store references or shallow copies?
Or if lxml is not humane enough, beautifulsoup supports xml just fine and you can use "css selectors" even in xml, which I find much more "for humans" than xpath. 
The problem is that "end" isn't iterable, it's just an integer. Look up range/xrange.
"for humans" legit turns me off of any project at this point.
If multiplying a list can be confused as multiplying each element, is that the fault of the Python language or the person reading it? Obviously it was chosen as convention for a reason. I think most people who write python understand this convention and would use a list comprehension to multiply each element in a list by an integer (or use a numpy array). Whereas copying a list a certain number of times could only be accomplished (easily) with an ugly for loop if the multiplication convention did not exist. So it is better that it does. I haven't found much use for it's use though except for the trivial case of multiplying a list with 1 element.
Do you plan on posting your source code?
Give a take-home test, preferably before a personal interview. Make it difficult but solvable within a day. At the interview you can discuss approach used to solve the problem. This is the best way to measure candidate's problem-solving performance, as opposed to asking trivia questions. 
Yes, because Python 2 will die in two years. Besides you can still work on Python 2 code, they are not so different. There is absolutely no point whatsoever to start on Python 2 today. 
&gt; I want to pursue a more developer mindset and use python to develop software apps. That's not a developer mindset. A developer mindset (to operations - it's unclear exactly what you do currently) is programming anything that you do repetitively. Using software to provision and configure machines. Tracking configuration in a git repository and doing code review on it. Multiplying yourself with code so you don't need to scale the team at the same rate as the servers you manage. If you give more details about your experience and knowledge and what you're interested in doing, we can provide better career guidance.
if you are doing XML already you are *not* supposed to be human!
Thanks :) Now I know about dumbell operator and ski hat operator. Noice. http://norvig.com/python-iaq.html
Pretty sure pymssql uses ODBC to connect. The way it is used is identical to pyodbc and there is a few references to ODBC in the docs. You CAN connect to MSSQL in a proprietary, non-ODBC way, but only with use of .NET tools or Activepython. I have seen programs using this alternative and they are pretty ugly.
It's not bad though.
I use both bare pyodbc as well as pyodbc + SQLAlchemy. * **pyodbc** - extremely fast and reliable, works like a charm. * **SQLAlchemy** - optional ORM add-on. It makes the progams more graceful but has some limitations and awkwardness. I often have to step down to pure pyodbc.
Nice! Will give it a try
&gt; but the terseness can be preferable It's a trade off between unambiguous and terse. I prefer terse, but I almost always prefer unambiguous over terse.
Do you want 500 references or 500 instances? A = [foo ()] * 500 can lead to fun bugs :)
I have queries 10s to 100s of lines long that are generated dynamically in response to user input. This was accomplished with a home-brewn ORM tool similar to SQLAlchemy. Parsing SQL commands without an ORM would be awful. Overall I prefer SQLAlchemy vs generating SQL strings in Python. It is less error-prone and removes the "language in language" snafu. However, for **static** queries over several lines long bare SQL is, of course, preferable. 
&gt; Is there something that provides a SQLAlchemy-like interface that can trivially connect to existing data stores? SQLAlchemy can `reflect` existing tables and foreign key dependencies. I also mastered other approaches, such as 1. hardcoding table definitions, and 2. creating views that pretend to be SQLAlchemy tables. 
Use the correct tool for the job. We have a 100000+ loc c++ application (actually multiple applications that all talk to eachother). Apart from a few thousand loc of unit tests we do all the integration tests with python. Maybe 30000 lines of python over a few hundred tests!
vim ftw
Nice work! I have wanted to make an electronic display for my lab that reports on something like this, a top 10 Spotify track or album list (I prefer listening to albums over tracks!) 
Also have a look at Micropython if you haven't come across it already - super interesting project as it means you can keep a core language that is very multipurpose at multiple levels
I did find this: https://github.com/siquick/ssapi
It's finally working! Thank you so much for the advice. But what do you mean by 64-bit safe, and right size and endianness? I'm quite new to networking, and a bit confused. Could you elaborate, or do you have any resources I could read up on? 
Yup!
I you use Django the way its meant, it's quite convenient. If you are it bit stubborn (like me) want to do certain thinks your own way, there's a lot you have to read before you really can bend it to your needs. And switching to a much newer version (force by the hosting company) did'nt prove all that easy. 
Thanks for sharing! 
[Huey](https://github.com/coleifer/huey) is a great little solution for this. Brokers for Redis, SQLite. It's very easy to use and set up. It's by the same author as my favourite little ORM, [peewee](https://github.com/coleifer/peewee), [Charles Leifer](http://charlesleifer.com/). He [blogs](http://charlesleifer.com/blog) a lot about Python, databases, writing small-to-medium scale applications and how things work. Absolutely worth reading and using his stuff.
 bucket *= 1 == 0 
So the question is, should there be just one way to do something, or should how to do something be Obvious? Obviously, the line is One Obvious way, but which virtue takes precedence? Not to state the Obvious, but, let me state, Obvious. Because if your workflow with lists include lines like: bucket.append() bucket.remove() Then the OBVIOUS thing for you, would be to use bucket.clear() But, on the other hand, if your list work is more about arrays, and your workflow tends to be: bucket = [0]*10 bucket *= 2 Then the obvious solution, in YOUR workflow would be: bucket *= 0 But, if you mostly work with Dicts, there is no reason why: del bucket[:] Should not be obvious to you.
Sure, if your browser can see data then so could python (with a bit of work). Open your browsers developer tools' network panel and have a look what happens when you do a search. It sends a POST to some RPC endpoint and get a bunch of JSON back. A fun complication is they apparently use a CSRF token, which I guess you'd have to extract from the maps page. There are also some cookies being set that might be needed. So if you make your HTTP request like the browser does you should get this. It might need a bit of practical experience with HTTP and python/requests etc. Anyway, extracting data like this could be breaking the TOS. Maybe it's worth to see if they offer this data as export, like a CSV file, since they are all about promotion of free knowledge and such.
Python n00b here. I've seen this sort of code pop up many times when people are discussing the speed of certain code snippets. How exactly do I implement it? In shell? In Idle? pls halp
Am I the only one who thinks the "Zen of Python" is BS? Python doesn't really stick to those principles at all - as this article demonstrates. It's a well designed language, but has dark corners and can be abused just as easily as other languages. 
some robots have python API
You can use CSS in lxml.