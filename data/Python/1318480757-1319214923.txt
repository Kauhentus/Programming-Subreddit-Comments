This is the correct answer for running python scripts without having to prefix the python interpreter. In all likelyhood python is already in your PATH variable. try running: $ which python in a shell prompt to find the location of your python interpreter - this is the path you put at the top of your scripts (i.e. #!/path/to/python). If you have multiple interpreters (say, for python 2.6 and python 3.2) you can specify which one to use for a particular script by specifying the path to the interpreter you want to use (e.g. #!/path/to/python26 or #!/path/to/python32) 
I always assumed that a script opening itself and printing the contents was not technically a quine.. not sure why, just seems like cheating.
Yes. I often am looking to do one simple thing, and the internet says "download and install this huge program". But then I find that a small python library will do it, and someone has posted a script to use it. I like this better. It may come up that I want to use this functionality in a script and then I'll be more glad I saved such a small text file into my "code/tools" folder. Install 150mb of code to unpack a gif is a bad solution IMO. It is similar to, but not as bad as, the linux folks who say "try a different distribution" for every glitch a newbie runs into. (I use linux happily, but I don't switch distributions every time a package isn't configured the way I want)
It looks like a heredoc version of function literal for me. I bet that this proposal will be rejected.
whoa. over-react much? 
Sorry, I should have been more specific. I do have python installed, and I have no trouble accessing it from any directory. instead of having to type $python foo.py, or I'd like to just be able to type (if it's possible/simple enough, like it was in 7) $foo because having to add #!/usr/bin/python at the start of each script and making it executable is a bit repetitive. PS: You all get upvotes ^_^
thanks, I'll have a look. can redis support very huge data(bigger than physical memory) now?
I don't see this happening either. It's a sloppy way to do multi lined anonymous functions.
Actually, in Linux the preferred script shebang line is -- #!/usr/bin/env python -- for maximum portability, because it makes no assumptions about where Python is located on a given system. 
&gt; because having to add #!/usr/bin/python at the start of each script and making it executable is a bit repetitive. You know, you can always write a python script to do this automatically. :) And the preferred shebang line is: #!/usr/bin/env python 
Flattred :)
It makes python not so easy to read... hate it.
How is it sloppy? I agree I'd rather have a pair of keywords instead of `:` and `@`, but it strikes me as relatively clean, not sloppy.
It introduces syntax which is inherently ambigious in function (the function defined under it is removed after execution, the redefinition of the meaning of the : and @ operator, : is used when we are to expect a value following a key in a dict literal, or when we are expecting an increase in indent) to a person unfamiliar with the language. In python, readability seems to be one of the key selling points. Then again, we have decorators and list comprehensions. 
+1 from me. That path manipulation that Django does is the biggest cause of headaches.
Hi, I'm a developer on PythonAnywhere. Just a quick message for anyone that's interested to check it out - when you sign up for the beta, you'll get an automated email from me, or one of the other developers, which asks a few questions. Basically we're just trying to start a conversation! Send us a cheery message, and we'll zap you over an invitation sharpish.
for sure - I don't think we're aiming to completely replace anyone's desktop... for hard-core developers, it's more about supplementing the desktop with a python environment you can use anywhere else - think ipads, internet cafes, other PCs... then we try to help with stuff that's more appropriate to servers than desktops, like web hosting, cron jobs, long running tasks... we dogfood the service at work, but I have 2 personal, real-life use cases: I use it for "ssh anywhere", to manage my own servers. I've also found it useful for remote pair programming - shared consoles can be good for exploring ideas together, or coding collaboratively, with vim or emacs.
Fantastic!
I don't get it. What is the problem it it is solving? 
What a coincidence. I am on Python 2.7.
both linode and slicehost cost real money! pythonanywhere is just a really neat and easy way to build python based cloud apps. 
plus I don't reckon you can run emacs in linode or rackspace's consoles :-P
That to a lot of people callback code in Python "feels" backwards since you define the callback first then pass it to the receiver instead of the other way around. It's about improving readability. 
Don't get too hung up on the colon and at. He's also considering keywords for this. The latest idea was to use "postdef" and "def" instead. The important part is it fixes the "backwardness" of defining a callback before the receiver. It always bugs me to have to write my sort key function before I actually do the sorting. This puts things in the "right" order. 
s/for/to kill/
&gt; Inside the new pyc file, a field is automatically added that says it's associated with a py file that was modified on Oct 9th. Okay, I had a different understanding, namely that it uses the timestamp of the .pyc file as a reference; not one stored within the .pyc file. As I wrote above (emphasis added): &gt; Apparently it checks if the timestamp of the .py file is *newer* than the .pyc file My justification was that touch'ing a .pyc file after it has been created and running the .py file didn't result in the .pyc file being generated again because it would still be newer that the .py file. I now see that what you said is the real reason (the .py file timestamp remained unaltered). Thanks for the explanation.
Regarding the "more examples" section, I'd welcome a more convenient syntax for the following: def environ(): ... return ... environ = environ() Having to type the name 3 times is tedious. Using a decorator helps: @apply def environ(): ... return ... But `apply` was deprecated and removed from Python 3, so you'd have to add it back: apply = lambda x: x() Regarding the default argument example, it isn't necessary to define a named function to create a unique closure for each iteration. A simple lambda does the trick: funcs = [(lambda k: lambda x: x + k)(i) for i in range(10)] Edit: As to the 'postdef' syntax, I'd never use it. To me it's backwards. 
Not sure, I mean: his reply is 452 characters long and mine (including footnote) is 393. So based in that simple parameter I would say no. But over reaction depends on the observer so I can't be certain about it.
You know what it would make more sense to me? Not a python-to-javascript compiler, but rather being able to simply use python as easy as if it was javascript. You know, doing something like: &lt;script type="text/python"&gt; for i in xrange(0, 100): print "{0} bottles of wine.".format(i) &lt;/script&gt; I've been dreaming about that for years... I was even going to try implement it in firefox for the joy of it but then a job took _all_ my time.
Stop worrying about "the python way". Does it work? Is it easy for you (and your team) to maintain? Those are the only things that *really* matter.
I'm mirroring DiveIntoPython.org since Mark Pilgrim took his sites down. It is how I learned Python initially, so I figure it is the least I can do. It's hosted on Amazon S3, so we shouldn't have to worry about down servers, etc. I'll mirror DiveIntoPython3.org and DiveIntoHTML5.org soon as well. Is there more we could do for this site though? I was thinking that the commenting system on DjangoBook.com could be really useful in keeping up to date and clarifying things.
It all comes back to this. Web2py is different in very touchy areas. Python community seems to reject it, but no worries people outside might see the benefits... and they will. and you know what... there is more of them, web2py attracts people who do not find python especially ground-breaking... Its kinda like rails vs jee. I know a lot of jee folks, they will tell you that the way they do sites/apps is the right way... By the time they are finished talking rails people are putting first prototypes. Web2py will get rejected as it is not the engineer way of doing things. It cuts a lot of crap I do not care about as long as it works. Engineers dont like when people less skilled than them start putting stuff together that is of comparable quality... its as simple as that...
I've emailed a copy of the flat HTML ZIP file from the site (version 5.4) so it can hopefully be made available on your mirror. As I said in the email, I think the ZIP file is unaltered as usually if I do anything when I re-archive it I put it in 7z format (even if I don't change anything sometimes).
Please don't mirror this. Dive Into Python isn't a good way to learn the language; it's full of misleading and outdated information.
I realize it is probably outdated (2004 was a long time ago), but what misleading information is there? I found it helpful. Perhaps if it was more of a Wiki or a DjangoBook.com style set of comments, it could be updated. I'm open to suggestions. I know a lot of people aren't ready to switch to Python 3, so something like this is a valuable resource.
Thank you! I got your email and I'll update it today with the ZIP file! 
It has helped and continues to help *countless* amounts of people, and you just want to let it die? You want to let a *free resource* to learn Python die because it doesn't conform to your personal writing and language standards? You don't want the book to go on because it contains outdated information, yet in computing, specifically programming languages, materials can be obsoleted in a matter of *months*, but that's only a problem here, right? Do you have any idea of how many people were able to get from 0 to beginner with Dive Into Python? Do you know how many experienced programmers have resorted back to DIP? In the last few months, I've taken a peek at DIP a few times as a refresher or to get an idea, because it's freely available on the web for me to search through. I've been using Python for around 7 years now, I'm on the core CPython development team, and I *still* take a look at DIP. You can like other resources all you want. Dive Into Python has a place in the learning of Python.
I'm trying to learn python, what should i choose instead of dive into python?
I thought it would only be useful for beginners. Then again, I've been using Python for about 2 years and still reference it. Glad to know more experienced developers still use it! 
I wouldn't choose anything *instead* of Dive Into Python, I'd choose things *in addition to* it. People like Learn Python The Hard Way, so maybe try that as well.
Dive into Python is just fine for getting started. I would suggest you go on to read other more involved books to better your grasp. I'm a fan of the long winded but high quality [Learning Python](http://shop.oreilly.com/product/9780596158071.do?green=31C2F1EC-F7FD-59EB-9289-79A99B1688C1&amp;cmp=af-mybuy-9780596158071.IP).
install ipython and read this: http://docs.python.org/tutorial/index.html Python is so simple it is fairly pointless wasting a lot of money on books.
Can't one just build multi dimensional arrays on top of 1-D arrays? As in, all finite dimensioned arrays can be mapped one-to-one on to 1-D arrays, so it's just interfaces, right?
What's wrong with it exactly?? Aside from it being old. I don't think you should just toss out that it's terrible without specifying what you mean.
This is definitely not something new. There are JS implementations that do the same thing for arrays.
I really wish I had a Dive Into... book for whatever subject I have chosen to deal with. Pilgrim has an enormous talent in writing and I hope he's just taking a big break or just keeping some distance from the online world. I wish him the best.
I don't get how this is different from, say: def postdef(callback): def decorate(func): return callback(func) return decorate @postdef(lambda def_: weakref.ref(target, def_)) def x(obj): print("{} is being destroyed".format(obj)) Given the limits of the syntax, this could be more generally accomplished using something like an 'in ... let' syntax, e.g.: in x = weakref.ref(target, destroy) let: target = something def destroy(obj): print("{} is being destroyed".format(obj)) That is, define a syntax for executing a statement using temporary bindings defined in a scope, sort of like a backwards-"with" statement. [Edit to add: I appear to have reinvented [PEP 3150](http://www.python.org/dev/peps/pep-3150/) with different syntax and semantics. In my idea, the names don't get unbound nor are they private; it's just syntax sugar for executing the statement after the block body.]
There seems to be a PDF there: http://www.megaupload.com/?d=7UGLP0UG Edit: Downloaded it, it seems clean and usable for me, 20 May 2004, GPL header :-) 
[Fabric](http://docs.fabfile.org/en/1.2.2/index.html) will let you do something similar
Those are very nice additions to fabric. Github URLs: * https://github.com/sebastien/cuisine and * https://github.com/sebastien/watchdog
Awesome, I will check that out. Thank you.
After reviewing Fabric I agree. I too am looking for a configuration management tool more specifically.
I think Ian Bicking has been working on something similar. Check out [Silver Lining](http://cloudsilverlining.org). It is not a complete and full product, but you can help make it one.
&gt;BTW does PyPy have a native API so people can write PyPy-only extensions? Why would you want to do that? It seems to me that the point of pypy is precisely to be fast enough so that you can write extensions in python.
Awesome! I'll upload it and provide a permanent link for download. Thanks!
I agree. We could use more Mark Pilgrims for all subjects.
I was thinking about things like NumPy, which would require specific modifications to PyPy (e.g. vectorization) to make it fast.
You can find a repository with mirrors of Dive Into HTML 5 and Dive Into Python 3 [here](https://github.com/diveintomark), and they have their respective domains with working websites: http://diveintohtml5.ep.io/ http://diveintopython3.ep.io/
Absolutely! We always love patches, if you want to help work on it that's awesome. If you don't feel like working on it directly we'd also for you to test out what we have, if it runs with your code let us know if we're faster or slower (especially slower, it's how we get better), or if it doesn't work let us know what features we should be prioritizing.
Oh fantastic. Thank you! I already own the domains, so I'll probably mirror them as well, but it's good to know there are a lot of mirrors for this extremely important and helpful information!
Wouldn't the time be better spent improving PyPy than writing an extension in C to circumvent its shortcomings?
403 forbidden
Awesome, awesome, awesome! Dive Into Python coming up on Google search has been an extremely useful reference for me. Thank you so much.
You're welcome! That's part of why I did it: I kept hitting his site and getting a 410. 
I always end up there when I'm Googling specific problems. It seems less like a book to read all the way through and more like a great, great reference.
Anyone know why he took his sites down?
Any chance of there being an updated Mercurial repository? The last changeset I have from his old Mercurial repository is from February 2011.
[Not really.](http://meyerweb.com/eric/thoughts/2011/10/04/searching-for-mark-pilgrim/) But he is OK.
Here are two branches of his GitHub. [Dive Into HTML5](https://github.com/diveintomark/diveintohtml5), [Dive Into Python3](https://github.com/diveintomark/diveintopython). I'll have a git repo up later today of Dive Into Python. Not sure on Mercurial.
Hrm. Failing that, I guess I could just reconstruct every single change since February myself and then upload the repository to my personal Bitbucket account.
You can mail me personally at `alex.gaynor@gmail.com`, if you want to communicate with pypy developers your best bet is either the #pypy IRC channel on freenode, or the pypy-dev mailing list.
If you do that, please shoot me a message!
well, there were other try, except solutions proposed that are better than his, so your not out of line at all in offering critique. Accusing him of being a smart ass took me off guard, and the rest was rather defensive rather than relating to the topic. and then I thought the *fingers was an obscene gesture, but on second reading it was not what i thought. I should save my whoa's for more flagrant over reacting I guess.
Have a look at cuisine which adds that kind of functionality to fabric. watchdog is a nice addition as it adds monitoring and notification to the mix: * https://github.com/sebastien/cuisine and * https://github.com/sebastien/watchdog * http://www.slideshare.net/ffunction/fabric-cuisine-and-watchdog-for-server-administration-in-python 
well, there were other try, except solutions proposed that are better than his, so your not out of line at all in offering critique. Accusing him of being a smart ass took me off guard, and the rest was rather defensive rather than relating to the topic. and then I thought the *fingers was an obscene gesture, but on second reading it was not what i thought. I should save my whoa's for more flagrant over reacting I guess.
pypy-dev, I see the general pypy progress donation link, I'm assuming that part of this donation goes to separate GIL thread/STM. Is this assumption correct?
last update over a year ago... sounds quite ambitious and interesting though
Please edit this link -- it seems to be attempting to post a comment.
Whoops. Thanks.
I really would like an E-Book version.
Why do you need that `@apply` trick? Why not just use the body of the function, with the `return` changed to `environ = ...`?
http://heynemann.github.com/provy/
Would a PDF suffice? I updated the site to include the downloads. Otherwise, which format would you like?
PDFs are terrible at resizing for most e-books. My favorite format so far is [mobi](http://en.wikipedia.org/wiki/Mobipocket). Hell, even plain text would be fine. 
You're welcome :-) Thanks for providing the mirror(s), very useful to many I would say.
&gt; Throw me a lifeline from Matlab - answer my question.... Please come up with a more descriptive, and perhaps more searchable title from now on.
I see that there are lot of example files(.py) with DiveIntoPython 2. I only have PDF file for DiveIntoPython 3. Does anybody know where can I get the example files for python 3?
Apologies, I see what you mean. Will do going forward.
Some context for all of these may be you better or at least more helpful and focused answers. Numbers 2 and 4 are both well documented. Have a look at #2: http://www.voidspace.org.uk/python/articles/OOP.shtml and #4 http://wiki.python.org/moin/TimeComplexity
&gt; But when I try and write out to a file the output is mangled. Code? Python supports Unicode, so it seems something is amiss with your code. Python should be able to read and write Unicode with no problems. Without seeing your code, I can say that, if you are declaring a string and appending to it while reading from a file, or assigning characters to it for later saving, you need to initialize is this way: my_string = u'' See the 'u'? 
I'm not terribly familar with Matlab, but I think this might be what you're looking for? I'm basically masking all of the values you don't want to zero with the where function. def howmany(nrows,ncols): import numpy test = numpy.random.randn(nrows,ncols) tsump = numpy.where(test&gt;0.2,test,0).sum(axis=0) tsumn = numpy.where(test&lt;0.2,test,0).sum(axis=0) return tsump/tsumn As an aside, I'd love to see if there's some kind of quick and easy function like statlist in numpy or scipy too...
The point made in the PEP's example was to keep from having to manually clean up the namespace by using a function. The os.py example uses `_createenviron` as a throw away function that's immediately deleted afterwards. I added the variant of naming the function after the target to keep from having to manually delete it. Then using `apply` as a decorator minimizes redundancy. Overall, my point was I'd appreciate the ability to have local blocks in the case of assigning a value -- something that might be seen as less of a 'trick'. Something like: environ =: ... #local namespace #assign the value of the final expression sorted_list =: def normalize_item(item): item = item.strip() item = item.lower() ... return item sorted(original_list, key=normalize_item) However, I'm not on board with the PEP in general. It's natural to me to define a callback function before using it, so many of the given examples where people want anonymous multi-line functions don't appeal to me. Maybe I'm being inconsistent or short-sighted across the board, but only lots of examples and time to mull them over will penetrate my thick skull. 
Here is the mirror from mine: [diveintohtml5.sayhive.com](http://diveintohtml5.sayhive.com) &amp; [diveintopython3.sayhive.com](http://diveintopython3.sayhive.com) &amp; [diveintopython.sayhive.com](http://diveintopython.sayhive.com) I really hope Mark will host these awesome resource again. I get it if someone removes his porn repository after the guilt of a huge fap - but I still don't understand why he killed all his brainchildren. 
 #!/usr/bin/python import os systemPath = "/Library/Fonts/" fHandle = open("lan.gp.fontsTest.txt", "w") dirList = os.listdir(systemPath) for fname in dirList: print fname fHandle.write(fname + "\n") fHandle.close() This is a simplified snippet of the code to illustrate what I'm seeing, as you can see there's not much to it. An example of an original filename I'm struggling with is: ヒラギノ丸ゴ Pro W4.otf The print statement displays that identically in the terminal. When written to file it comes out as: „Éí„É©„Ç≠„Çô„Éé‰∏∏„Ç≥„Çô Pro W4.otf (I took a screen of those last few lines, in case the browser doesn't display as I intended. That's [here](http://i.imgur.com/mRJMX.png). [This](http://i.imgur.com/Occ3C.png) is a shot of the terminal output next to the text file. ** Edit, also just thought to mention that if I copy the file name from the Finder or from Terminal and paste it into the text file in a text editor after it's been written, it displays just fine.
You'll probably get a bit more out of this group if you supply us with your best guess or understanding of these questions. As it is, it just seems like you want someone to do your homework for you.
&gt; systemPath = "/Library/Fonts/" Umm, read my prior post: systemPath = u'/Library/Fonts/' All fixed now. All the result are converted to Unicode. Go through your program and make all your 'strings' into u'Unicode strings'. 
Having preceded everything in quotes with a u I now get: Traceback (most recent call last): File "./plist003.py", line 13, in &lt;module&gt; fHandle.write(fname + u"\n") UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-7: ordinal not in range(128) when trying to write to file the filenames with Japanese characters.
First, show me all your code. There is no way this can result from anything but a simple typing problem. Second, you need to use single quotes, as in my examples. And because the file name is already Unicode, you can safely say: fHandle.write(fname + '\n') 
I see an D in your future. 
Have you been in touch with the [archive team](http://archiveteam.org/) at all? They may have similar efforts underway. You might want to avoid duplicating effort by talking to them.
 #!/usr/bin/python import os systemPath = u'/Library/Fonts/' fHandle = open(u'lan.gp.fontsTest.txt', 'w') dirList = os.listdir(systemPath) for fname in dirList: print fname fHandle.write(fname + '\n') fHandle.close() Produces the list of 'normal' file names, the first Japanese one and then... Traceback (most recent call last): File "./plist003.py", line 11, in &lt;module&gt; fHandle.write(fname + '\n') UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-7: ordinal not in range(128) **\*\* Edit: ** After re-reading sections of [this page](http://docs.python.org/howto/unicode.html) I've re-written as: #!/usr/bin/python import os import codecs systemPath = u'/Library/Fonts/' fHandle = codecs.open('lan.gp.fontsTest.txt', encoding='utf-32', mode='w') dirList = os.listdir(systemPath) for fname in dirList: print fname fHandle.write(fname + '\n') fHandle.close() This seems to work as intended. Thank you very much for your help :) 
DiveIntoAccessibility.org is (was) a great resource for anyone needing to understand web accessibility and how to implement it in their sites. It can be found in the [Internet Archive](http://web.archive.org/web/20110726001153/http://diveintoaccessibility.org/), but other copies may also be around.
http://diveintopython3.ep.io
You should encode it with utf-8 instead of utf-32. It's more common and doesn't require a BOM.
I thought this was an unusually good comment for reddit, then I read the username and realized why. :-) You should get on Python-ideas and give your two cents. 
This is not the place to request programs to be written for you. Craigslist or freelancer sites are.
Try asking your question on stackoverflow or superuser. Someone is likely to be able to help. 
There's a great place for Python beginners, the Python Tutor mailing list: http://mail.python.org/mailman/listinfo/tutor As the name says, it's meant for Python. But they're very helpful there and likely quite open to general questions as well. As others have already pointed out: The more specific your questions the more suitable the answers.
Should I buy HP shares? ;-)
I wrote it. I will port it over once get my bearings.Thanks!
fire up Linux and learn to use http://www.imagemagick.org/script/index.php Specifically crop'ing: http://www.imagemagick.org/Usage/crop/#crop something like: for image in *; do imagemajick -magic stuff $image; done 
You don't need a program to do this, a one liner in bash with ImageMajick will do the trick.
General means it comes with no strings attached :) It might be used for GIL/STM work (which is happening right now), it might be used to fund sprints, it might be used to do things noone would sponsor (like issue tracker gardening, buildbot maintenance etc.)
Was he getting tired of [this guy](http://oppugn.us/posts/1272050135.html) ?
That's genius. I know what I'm doing this weekend. Thanks for the idea!
1. Encapsulation is how you bundle up Python programs. It's important because without it, you couldn't share what you write with other people. 2. A method is new when you're the original creator of the algorithm. It's inherited when you get the algorithm from someone else, but you need to have it overridden in terms of IP or else you might get sued. 3. OOP is "object orientation programming." That means you need to align the data in your programs for faster access. ADT is automatic data translation. It save you the trouble of orienting the data yourself, but there's a big penalty in speed. 4. Constant time is the time it takes to retrieve the list from memory; linear time is when the list is processed from top to bottom instead of randomly.
I like your style.
EDIT: This example was so broken that I decided to delete it entirely. 
&gt; There should really be some software for sorting pictures randomly placed on a scanner head, but until that software comes along ... It's already here -- [ImageMagick](http://www.imagemagick.org/script/index.php) will do this.
[Try mine -- it's easier to use for some tasks.](http://arachnoid.com/python/searchReplaceGlobal/index.html)
There's a big difference between a command-line tool and a GUI tool - so I wouldn't say these two programs directly compete. P.S. besides, your comment is kinda patronizing
Goodness, when I had a go at doing iphone dev I would've knawed off my right arm for this, I hope someone packages it. If pyjs from pyjamas was combined with it you could even do the gui in something python like too.
Yes, true, but for a global search, with the option to replace content -- with so much at stake, it's nice to be able to see everything at a glance. I recently used my app to made a complex editorial change to 375 of my Web pages using a rather complex regular expression, a high-wire act if there ever was one. It came off without a hitch. Nevertheless, command-line apps have a number of advantages over GUI apps. The app described in the link has ANSI coloring of the search results, a nice feature I don't support. So ... to each his own. EDIT: I agree my original remark was "patronizing". After reflection I changed it. 
Tried utf-8 first, it still produces mangled output.
Agreed, which is why I still find your "it's better and easier to use" comment inappropriate.
I agree I went overboard -- I'll change it.
1. It can quite definitely result from things other than a typo. When you try to write unicode to a file directly in Python 2, it attempts to encode it as ascii, which will fail if it contains any non-ascii characters. 2. You do not need to use single quotes: it makes no difference at all. 3. Using '\n' instead of u'\n' is unimportant here. 4. Below, you suggest that the "coding:" magic comment is the key here. It's not: that's only necessary if you have non-ascii characters in your source code, and there aren't in this example. It's great that you want to help people, but please don't just write anything you think of. People find unicode hard enough as it is, and a load of maybe-relevant fixes aren't going to help. Your suggestion to make systemPath a unicode string was part of the solution, but GimmeSomeSugar had to work out the other part (codecs.open) himself.
The 'mangling' probably depends on the program you're using to view it later. Most good text editors should let you select an encoding when you open a file. I'm a bit surprised that UTF-8 isn't the default, but maybe you've changed it at some point previously. **Edit:** In fact, the BOM is probably the key thing that made it work. Whatever editor you use to open it has probably seen the BOM, and correctly decuded that the file was UTF-32 encoded. Without the BOM, it must be defaulting to an incorrect single-byte encoding. You might want to try utf-16 or utf-8-sig for a smaller filesize.
Well, education is important.
&gt; It's great that you want to help people, but please don't just write anything you think of. EDIT: I should have taken longer to respond. Look down the thread for a better reply. 
You did not solve the poster's problem. One of your posts provided a partial solution. In fact, I think the root cause is the program he was using to open the text file choosing the wrong encoding to open it: I suspect his original program already wrote valid UTF-8 to the file. Your own program runs successfully because it doesn't do what you intend: the line output += data + '\n' Should be output += item + '\n' When I make that change, the program crashes with a UnicodeEncodeError, because, as I explained, Python 2 does not let you write unicode directly to a file opened normally. I can only assume you did not actually look at the files your program wrote before posting the code. In addition, you have made a number of statements which are just bizarre. For instance, there is no distinction between single and double quotes in Python (just use the same at each end of a string), and the "coding:" comment at the top of the file is only necessary if the source code contains non-ascii characters. There's no harm in including it anyway, but it's not the cause of this problem. I'm impressed that you have written an editor, but I stand by my criticism of your comments here: you have not provided a working solution, and several of your suggestions are just irrelevant.
It should work unless your text viewer is relying on a BOM to select the encoding. Try writing utf-8 with a BOM (the 'utf-8-sig' encoding): import os font_path = u'/Library/Fonts/' listing = os.listdir(font_path) fname = 'lan.gp.fontsTest.txt' data = os.linesep.join(listing).encode('utf-8-sig') with open(fname, 'wb') as f: f.write(data) But this would normally be a Windows problem. 
You do use version control right ? Bulk changing 375 files shouldn't be a "high-wire act"
There is also [lk](http://pypi.python.org/pypi/lk)
*Gah, bloody hell!* I feel like a real idiot now. Had another go with your code, was still seeing some 'erroneous' behaviour. By chance I happened to open the output in Smultron instead of TextEdit and it looked fine. Enough time has passed since my recent OS install from scratch that I don't immediately think of that when something trips me up, but surely enough, TextEdit was using its default encoding of Western (Mac OS Roman). Switched it to UTF-8 and now even the code that I posted first works as expected. Embarrassing as it is to admit to such a rookie error, thought I'd write it up in case anyone with a similar problem should happen across this later. Paul, thanks again for your help, that kind of pointed me in the right direction.
&gt;In fact, I think the root cause is the program he was using to open the text file choosing the wrong encoding to open it: I suspect his original program already wrote valid UTF-8 to the file. That is spot on. Came back to the thread after the embarrassing revelation that TextEdit was using Western (Mac OS Roman) encoding after a recent-ish OS re-install. (I'm writing in Smultron, but checking the output files in TextEdit helps me keep things mentally segregated.) I guess that will teach me to think midnight is a good time to take a quick peak at some code before I go to bed. Thanks for you help.
I hadn't heard of them until now. I'll talk to them. Thanks!
Thanks! I'm so glad to see so many mirror popping up!
[My GitHub repo has them.](https://github.com/pcsforeducation/diveintopython3/tree/master/examples)
 grep -Ri "expression" *
it runs fine: http://i.imgur.com/eKmFH.png though I'd need to figure out how to get the ctrl- keys to not be intercepted by the browser. that said I'd always use regular ssh access over a web based terminal any day.
Not to mention [grin](http://pypi.python.org/pypi/grin/).
i really don't get who the target audience for this is? i mean, i guess python might be more common on windows machines than perl (so you could install ack), but i've never met anybody who develops on windows but still uses command line tools a lot. as for anybody on anything *nix-ish, if you don't like grep (or even if you do) ack more than accomplishes this task. for search&amp;replace, [prep](http://peter.verhas.com/progs/perl/prep/) is awesome -- but again, i can't imagine somebody who develops on windows not wanting to just search-and-replace in their ide. 
Not to mention [burying backups of code in ammo cans in his backyard](http://www.reddit.com/r/reddit.com/comments/aqw20/reddit_youre_my_last_hope_a_final_that_i_had_due/c0ixzn1). I guess the bigger concern is that your find/replace could cause errors that go unnoticed for a long time and subtly break something.
I agree there is a place for this tool. I run Windows, and I do not want to install Perl to run ack. Even with the GnuWin32 tools installed, I find the use of find and grep together to be constantly frustrating. In that context: When I installed it on Windows, a file named "pss" was added to my Python/Scripts directory, but that script uses a shebang line to indicate that it is a Python file. Windows doesn't know what to do with that. 
That depends upon the student.
First and foremost, there is absolutely no problems in diversity and multiplicity. Redundancy per se is not evil, and something done well is always nice to have around even if the functionality and applicability is duplicated 100%. I would hate to live in a world where there was only one tool to achieve something. So kudo's to the author for that. But the fact is, there is much value added beyond its primary purpose. For one thing, it is a clone of (the fantastic, and my go-to grepper) 'ack'. But a *pure* *Python* clone. That's wonderful! If nothing else, a pure Python implementation would allow reuse via direct calls from other Python code, as well as allowing it to be easily modified/tinkered by Python-fluent people. But it also serves as a great example of a "how-to" for different goals beyond its primary purpose (e.g., how to write colored output to the terminal), and these sections of code, too, can be easily reused/called from other Python code. 
You're welcome. I'm happy to help.
THIS ONE IS BETTER
&gt; You do use version control right ? No, I just make backups of everything -- and my program does that automatically whenever a file is changed, so I had two backups in this case. Version control is obviously a better approach, but too complicated for this kind of task. 
&gt; Not to mention [burying backups of code in ammo cans in his backyard](http://www.reddit.com/r/reddit.com/comments/aqw20/reddit_youre_my_last_hope_a_final_that_i_had_due/c0ixzn1). Yep -- at that time, 60 million dollars was at stake. I was well-motivated. :) &gt; I guess the bigger concern is that your find/replace could cause errors that go unnoticed for a long time and subtly break something. Yes, that's a problem no matter what approach one chooses -- there could always be some subtle change that escapes one's attention for months after such a global change. Which IMHO is why kernel.org is still offline -- they need to make sure the archive hasn't been tampered with in subtle ways. But I agree with your earlier comment that a version control system would be superior. 
Good heavens. You're using *Python*. Why would you want to emulate bad ideas from 90s-era Java?
Macs come with a version of Python preinstalled, but not perl (as far as I know). I know Ubuntu was looking at dropping perl from the default installation. I don't think it happened, but if it does in the future, there'd be a small pressure in favour of Python-based tools because the dependencies are already present.
http://docs.python.org/release/1.5.1p1/tut/node43.html &gt;The modification time of the version of "spam.py" used to create "spam.pyc" is recorded in "spam.pyc", and the file is ignored if these don't match. So, this wouldn't affect a developer deploying their code. Unless you can fake the modification date and predict when a developer will have finished their code in advance (good luck with that). Of course, as the OP said, it would require "execute arbitrary code" rights. 
It only speeds up running your code. Any changes to the associated PY file will ignore the PYC. You shouldn't be running any PYC files directly, only if you do the PY2EXE thing. 
wow, neat! i withdraw all my cast aspersions... was that linode or rackspace? meanwhile, fighting the browser for who gets ctrl- keys is a big challenge for us... vim is totally usable in firefox, but in chrome, hitting "ctrl-w" to switch between split windows rather tends to close the whole tab, oops. anyone that fancies a quick play with ours can check out http://www.pythonanywhere.com/learn - no signup required... 
So... it's grep + syntax highlighting for .py files? Don't downvote me, I just seriously don't get it.
It's no different than if I wrote my own program, appended your program as a resource (in windows, for example) and then my program would run first, do its thing, then load the other program from it's resources. It's not a hack or an exploit. If I can modify any program on the system, if I can run arbitrary code on the system, I have complete control of it. No need for a virus when I have control of the computer. That's just the standard risks you take running compiled code. If you want to avoid this risk, the only thing you can do is to audit and compile all your code yourself.
Without more information, my guess is an Uncaught exception.
&gt; I'm impressed that you have written an editor, but I stand by my criticism of your comments here: you have not provided a working solution, and several of your suggestions are just irrelevant. I have to agree. I began with a naive assumption that was inadvertently supported by a typo in my "demonstration" that wasn't a demonstration. Then I objected to your criticism instead of looking at it more closely. My naive assumption is that Python has a robust Unicode infrastructure, like Java. Java uses 16-bit strings internally for everything, regardless of what the user thinks is going on externally. As a result, one rarely sees the kind of bizarre behavior in Java that led to this thread (and to my unhelpful help). (I won't say "never".) There are many things wrong with Java, but its handling of Unicode is one of its clear advantages. Here is my latest Unicode test program, more carefully checked: #!/usr/bin/env python # -*- coding: utf-8 -*- import os, codecs def write_file_unicode(path,data): with codecs.open(path,'wU', 'utf-8') as f: f.write(data) dir_list = os.listdir(u'.') output = '' for item in dir_list: output += item + '\n' write_file_unicode('more_output.txt',output) print output Interestingly, the last line in the program will fail if an effort is made to redirect it to a file in the shell, i.e.: $ program_name.py &gt; temp.txt It turns out this is a [known issue, rather difficult to solve](http://stackoverflow.com/questions/4545661/unicodedecodeerror-when-redirecting-to-file). Again, I should have been more careful with my claims and my code. 
Clearly it's the GIL contention. You need to separate those threads into separate processes. /sarcasm Really, we have no clue. It's most likely an uncaught exception. You should have a catchall for a service app that will write the exception details to a logfile. PY2EXE most likely isn't the issue, unless it didn't bundle the right code, dlls or something. The fact that it runs for weeks tells me that it's not PY2EXE.
For the times when you actually need a shared data structure do you have a cleaner way to do this to propose?
Take a look at the [PEP-397](http://www.python.org/dev/peps/pep-0397/)-compatible [Python Launcher for Windows](https://bitbucket.org/vinay.sajip/pylauncher/).
Thanks, Paul, and kudos for being able to admit when you were wrong. For my part, I'm sorry for being rather patronising in my initial criticism. I would contend that Python does have a robust unicode infrastructure, although only with Python 3 is it the default interface for working with text. But even in Python 2, it's not hard to get right: in this case, GimmeSomeSugar's original Python code was actually working perfectly, and the trouble was with the editor used to view the output. He would have seen the same thing with Java or any language, assuming the text file was written encoded in UTF-8.
I don't know if this is production ready or not, but if people want a Python version of Chef this would be the place to make contributions: https://github.com/samuel/kokki 
Which times are those? :) The only reason I can think of letting multiple threads directly access the same data structure is for certain performance reasons, and if those apply to you, you probably shouldn't be writing that part of your code in Python.
There is an emerging project called Salt that is a great alternative to Chef that is written in Python: http://saltstack.org It is very easy to set up, fast and easy to extend, the core is here: https://github.com/thatch45/salt Salt can use YAML or JSON for the "recipes" (they are easy to write) or it can use pure python (The docs for pure python support are not up yet): http://saltstack.org/ref/states/index.html Salt is a very active project with a lot of developers working behind it, the configuration management component is young, but growing very quickly.
All true. It's too bad the Python 3 transition is turning out to be so difficult -- there are too many missing libraries, so people won't make the change, and it seems this has become a feedback loop. 
Sounds good for Python users on windows. On Linux, I think I'll stick with ack though - same functionality, and most of the big repos have it.
I think Python 3 is taking off, although perhaps a bit slower than people hoped. The number of compatible packages is [ramping up steadily](http://dev.pocoo.org/~gbrandl/py3.html), and most of the most important packages are either already compatible, or are working on it. Even Django, one of the big holdouts, recently started work on Python 3 compatibility.
Nope, it's grep that knows the extensions of various file types (i.e. Python files, C++ files, XML files, etc), searches recursively by default, knows which directories to ignore, colors its output, plus a few more bells and whistles.
++ Nice writing. Just to add that pss was designed from scratch to be built of modular components - each of which can be used separately. In fact, the actual command-line script is just a thin wrapper over library calls. This makes it all the more hackable (in Python, yay!) 
Does this preclude you from running pss from the command-line, though? Since pss.py is in path, Windows still finds it alright (even when you execute 'pss')
Thanks for the explanation, good enough to make a case for donation :) Keep up the good work guys!
What about benchmark between pss and ack? is it faster?
Whoa, lk is quite fast. Thanks!
1. start menu -&gt; search for "Event Viewer" 2. run it 3. under "windows logs" click on "Application" 4. Look for the error and see what it says. Beyond that, you need a debugger. 
I asked you not to downvote, but since you're going to be an asshole about it: There's nothing wrong with using the find function in your IDE. It's a feature built for just that purpose, it gives you a nice semantic tree of matched files inside your editor. Compared to output produced by command line tools, that's better in practically every sense. Calling that something that *newbies* would do is beyond ridiculous, since it's something that simply a *sensible* user would do. Piping together something on the command line takes more time and is error prone. A terrible solution in every sense and one that should be avoided unless you absolutely have to. Writing your own script for project search? Even worse. There's far more to lose than to gain with that approach. Calling that something that *experienced* programmers are likely to do is an outright lie. Ignoring predetermined directories like .svn or .hg is a half-assed solution at best. If you're really concerned about performance, you should write the whole thing in a compiled language. And if you're going to skip directories, you might as well skip all hidden ones. No one is ever going to write code that's supposed to be included in a project search in a hidden folder. Searching recursively by default *isn't a feature*. That's like me writing a script that calls grep with -R and calling it a new program. /asshole rant over Duplicating tools is all well and good, but don't be surprised if people criticize the project's goals.
Probably not doing it the "Pythonic" way. It takes a while to get away from writing the code in your head as C or whatever other language you prefer, then converting that into Python. I checked your code closely and I didn't notice many style mistakes when it comes to [PEP8](http://www.python.org/dev/peps/pep-0008/). List comprehensions needed maybe? This is a good thing to review. http://chrisarndt.de/talks/rupy/2008/output/slides.html#the-zen-of-python I also noticed you aren't using a defaultdict. And you are not using a setdefault. You should pay attention to those features of the language, they can save you a lot of time. Here's a sample rewrite of your discover_modules. You use a lot of temporary variables and such that just aren't needed if you are doing things the python way. Take a look at the code below. It's what's called a generator. def discover_modules(directory): for _, _, files in os.walk(directory): for f in files: if f.endswith('.py') and not f.startswith('__'): yield f[:f.find('.')] now your load_modules would have to be rewritten to take advantage of this... &gt; def load_modules(self): &gt; for m in discover_modules(self.conf['plugindir']): &gt; modname = string.join((self.conf['plugindir'].replace('/', '.'), m), '.') &gt; self.load_plugin(modname) of course, once you rewrite that, you can see it can become a list comprehension with your generator. You don't need to have a temporary variable named 'modname' if you are just going to call loadplugin with the 'm' of the generator, after it has been replaced, stripped, joined... optparse might be handy, as would fnmatch. Get to know and love your standard libraries. sys.exit(main()) is hard to read, it should never be written that way. change your 'return 0, 1' to sys.exit(0,1,2,3,4...). Each error condition can return it's own number. It's wise to do it this way so you can script around certain types of errors. If for example '1' is 'cannot connect to server' then your os script used to launch the bot can detect that, and try another server, or retry. if the error '2' is 'config file unreadable' well then you might want to not retry. 
It's definitely not a py2exe bug, because as far as I know it doesn't involve itself in anything relevant. Also, while Python probably is not widely used for Windows applications running for months, it has its threading facilities built on top of a very small set of platform-dependent primitives, so I'd say it's unlikely that there's a bug there. Do you have an antivirus running on that machine (especially something **_ENTERPRISE QUALITY_** like F-Secure)? I've seen some weird stuff happening due to the kernel-level driver of this particular piece of shit leaking various important system resources. Anyway, I don't think that anyone would know what's happening, so about tracking down the error: spend half an hour reading [docs on `logging`](http://docs.python.org/library/logging.html), then add a RotatingFileHandler and log everything. Every one of your thread functions should look like log.info("starting thread %s" % threading.current_thread().name) try: ... while ...: ... except: log.error("Shit happened: %r" % (sys.exc_info(),)) else: log.info("Thread %s terminated peacefully" % threading.current_thread().name) Though probably you should log stuff in a more readable fashion, read docs on the `traceback` module. Also, I've written that from memory and might have botched some method names. Also, `log.info` all interesting stuff like preparing to start a thread, `log.debug` all synchronization stuff like acquiring and releasing a mutex, and so on. Because it also sounds like a typical deadlock, this thing you have here.
That was kinda my initial reaction, but I actually think the question is addressed quite well in the announcement. In particular, the command-line tool is basically just a wrapper around a set of libraries, so it's easy for python programmers to modify or use in other projects. Also it's just nice to have a python implementation of ack, especially as python increases in popularity and perl becomes less common. There *are* people who have to use windows but like command line tools. The author's stated motivation for the project was that he was installing perl on windows boxes purely to use ack. Besides, I doubt ide search/replace tools are as flexible as the command line (although I'm not really familiar with them, so I can't be sure).
Apologies for the deletion, repost and subsequent removal of comments. I found a bunch of errors in my original article and wasn't sure how long it would take me to fix them - nothing personal.
Thanks a lot!!
Definitely this. Log ALL the things. Know exactly what it was doing at the time of death. Beyond that, you're looking at needing a debugger. If the code is portable, try running it under Linux, and see if it exhibits the same behavior.
I have code you wrote above very similar, but the problem is it's not throwing an error and catching it. The whole process and all it's threads are destroyed instantly. Again, exact same as a user hitting &lt;ctrl&gt; break on the shell (but there is no ^c which is always printed if someone does this). I've also checked the system logs and nothing there. running McAfee enterprise edition so can't rule that out 100%. So am I asking to much of python to run as a full time multithreaded server application because it has a habit of dying for no reason? Don't believe I'm doing anything too unusual here.
&gt; So am I asking to much of python to run as a full time multithreaded server application because it has a habit of dying for no reason? No, it doesn't have such a habit, one program of mine has been running for at least a year non-stop now, deployed via py2exe, featuring a tkinter gui, and doing a lot of stuff (capturing and dumping data received via a serial port at the almost fully saturated 19200 bits/s). It has only a couple of persistent threads though. &gt; The whole process and all it's threads are destroyed instantly. Are you sure you don't create all those threads as daemonic? Are you sure that every single one thread is wrapped in try-catch like that? It only takes one to bring everything down, by the way that's exactly how ctrl-C works on Windows, unlike in UNIXen where the signal is received by a random thread and results in the respective exception being thrown, Windows spawns a ctrl-C handler in a separate thread (which promptly terminates your program due to uncaught exception). Are you sure that your program doesn't run out of memory? I don't know, can you go all "let's debug this bitch" on it, install VS Express on that computer, attach its debugger to the running Python process, and hope that whatever kills it would show up there?
 import random random.choice(dictionary.keys())
If you consistently use version control for everything, its no longer complicated. I'm sure you could make it complicated as modern SCM systems have a plethora of features, but I find myself sticking to the basics and even with small things one could dismiss as "not important enough" I just whack into a repository anyway &amp; run a commit from time to time. As a perpetual learner I find its a great way to try something new then in the commit log document why it was a bad idea ;) As the files are checksummed its also easy to detect fs corruption earlier.
Still very useful information. Thanks for posting!
That returns a random key, not a random value of a specific key. import random d = dict(a=[1,2,3],b=[4,5,6],c=[7,8,9],d=[10,11,12],e=[13,14,15]) random.choice(d['a']) 
honestly, I started reading the article, and when I realized the tool would be pronounced "piss" i just closed the tab and moved along..
Maybe, it seems like an interesting idea but I don't like the interface. Specifically I abhor the use of docstring and consider it an abuse. I'd find the following interface more palatable: notnone = Contract(lambda result: result is None, lambda x: x is not None, y=lambda y: y is not None) @notnone def foo(x, y=None): pass You could even have the decorator append to the docstring a formatted description of the contract if you wanted. You could address self and more with an AttributesContract(attr1=lambda attr1: attr1 == True) For the record I think my proposal is too verbose but that might be alleviable by builtins PredicateTrue PredicateNone etc giving `Contract(PredicateNone, x=PredicateNotNone, y=PredicateNotNone)` which isn't horrible I guess. Any further thoughts? I just really don't like using docstrings like that :-/ EDIT: And of course a contract decorator on a class would use the same magic logic to decorate __init__ __del__ and other methods. EDIT EDIT: I realized when I said "Specifically I abhor the use of docstring" it could be read like I dislike docstrings, I mean that I dislike using docstrings to encode data read/interpreted by the computer
Could someone explain this Design by Contract to a layman? I understand it's taught as part of the curriculum at ANU along with Eiffel. I read the motivation, but I'm not convinced that this will do much for correctness of a program.
It says that it's really for debugging purposes. It executes boolean expresssions before and after methods are called to verify the state of an object. For example, if one of two variables on your class should be 0 at all times (not sure why that would be, but it's possible), then the program would raise an error if both or neither were zero. Hopefully you'd be able to find the bug in your program before your next release.
That was good to know. Of course it is better to be fixed if possible. 
I started implementing a design-by-contract library for Python called [covenant](https://bitbucket.org/kisielk/covenant) mostly out of curiosity's sake. I haven't really looked at it in nearly a year, but I think I will come back to playing with it at some point. I'm not so much interested in using it as in just seeing if I could do it. I was mostly inspired by some reading I did on Eifel a few years ago. For Python 2 I implemented the concepts using decorators. For Python 3 my plan was to implement the contracts via function annotations, but I never quite got to that stage. I'm no CS guru so the implementation is probably crap, but 
I'd like to think I would...probably not.
I knew there was another just couldn't remember its name. 
`CamelCaseForClasses`. `underscores_for_basically_everything_else`.
In theory probably not, in practice with that API? Not in a million years.
I try to stick to [PEP 8](http://www.python.org/dev/peps/pep-0008/).
running on a 16GB win2003-64 that is completely underutilized so don't see a memory problem and know it's not daemonic threads. All threads are the same object and wrapped up pretty tight with several layers of try catch (one layer is probably better) so have a hard time thinking an exception can sneak by. control C spawning a separate thread sounds interesting and I need to look into this more. How else can a program get obliterated without something telling it to die? attaching VS to the python process, is that possible? sounds like a good bet to find out what is happening. Another idea I have is to stop running the program from a command shell and make it into a windows gui application. Does that sound like something that could make it more robust? Thanks you all for the help kregg
In one of the Java example you have twice "addOne" instead of addOne/addTwo ;)
I think it's the accepted practice to name variables "like_this" and classes "LikeThis".
yup, that's PEP 8. Upvotes to jeetsukumaran.
Personally, I prefer ClassNames everythingElse although I'm aware it's against PEP 8.
For throwaway variables (lambdas, listcomps, etc) I use uppercase single letter variables: lambda X: [N*2 for N in range(X)] For most other variables, I'll go lowercase and try to be as descriptive as possible (for readability, and also since autocomplete means you never have to type it all out): host_port = 1234 first_name = "Joe" 
Variables is almost done right intuitively by most people: * http://www.markus-gattol.name/ws/python.html#naming_variables It's the rest such as class or function names where it's not always clear: * http://www.markus-gattol.name/ws/python.html#naming_conventions
I didn't downvote you, and you may have noticed here and in the blog comments that I'm entirely open to criticism. What you say here makes sense, but I don't want this to turn into another IDE vs. command-line flame-war. To each its own. I also use IDEs for some things. Regarding ignoring .svn and .hg - you're missing the point. The concern is not with efficiency, it's with bogus reports from files I'm not interested in (deleted files, duplications, and so on).
I didn't do any official benchmarking, but from some ad-hoc runs they're about the same speed (give or take 20%)
PEP 8 used to allow both styles, but has been revised to say underscores for variables and functions, camel case for classes with initial capital. My main niggle with PEP 8 is that when it comes to acronyms in class names it takes the opposite tack to Microsoft and Java, mandating `XMLHTTPRequest` rather than `XmlHttpRequest`. But so it goes. Variables should generally be nouns, functions generally start with a verb or be something like `datetime_from_rfc2822` for conversion and projection function. Booleans if possible are predicates (as in `is_alive`, `has_buddha_nature`, `wants_statistics`). I try to consistently name variables so you can tell `apples` is a list of apples and `apple_count` is the number of apples. This is especially important in function parameters as it is a bit embarrassing to pass the wrong type in. For limited-scope temporaries (like in comprehensions and one-line `for` loops), I am increasingly using single lowercase letters. Often `x`. Long, descriptive names are most important for object attributes and function params.
Yeah. I recently moved from a (very long term) java project, and while I sort of prefer the java conventions, I mostly prefer conventions.
I do throwaway variables in lowercase. Per Fortran, `i`, `j`, and `k` are indexes. `n` is a number being acted on. `x` is about the same thing. `l` is a list. `d` is a dict. `s` is a string or set. `r` is a return value. If you have a bunch of things, it's `for item in items` or some other singular/plural combo. If you have a class and a single instance of the class, the class name is CamelCase, and the instance is the same name in lowercase, ex. `class Car:` … `car = Car()`.
Ah... thank you! I guess I would have stumbled on this eventually, but in the mean time you've saved me a lot of work and boiler-plate code in my newish project.
I am quite open minded but I'm fairly sure my boss would consider this to be egregious gold-plating.
consistently
I also do this, but with the addition of CONSTANT where some value really should not be changed in the code.
Contracts are syntactic sugar. They allow you to specify checks on the parameters of functions, on their outcome, and on their effect on their object. They ensure that the object stays in a valid state, or an exception will be thrown. Objects themselves can have contracts too (called invariants) -- conditions that must always hold between function calls. Invariants will be checked for you after each function. Contracts allow you to guarantee conditions when defining an interface. They prevent derivative classes from breaking those conditions. Etc. It can be disabled in production, like other debug code, so it carries no inherent performance overhead. IIRC, Eiffel goes further and allows contracts for loops, ensuring that they will finish in finite time. For example, a loop can be set to always decrement some unsigned integer, guaranteeing the loop will finish. The term 'Design by Contract' itself is trademarked by Eiffel. 
Thanks - fixed.
Have you installed handlers for `SIGINT` and `SIGBREAK`? Without a configured handler SIGBREAK will immediately kill a win32 console app. You won't see an exception.
...but still no binary for OS X Lion (64bit), sigh. A bit of a first world problem I know. But of all the Python libraries I use, and they are quite a few, Matplotlib is always a challenge to install on Mac.
pep8
&gt; attaching VS to the python process, is that possible? Yes, you might need the same version of VS (2008 I think) that was used to compile Python. In fact it might be a good idea to compile Python yourself (download the source, open the VS solution, click 'compile' =) ), maybe even in debug mode. &gt; Another idea I have is to stop running the program from a command shell and make it into a windows gui application. Does that sound like something that could make it more robust? No, not at all. Also, right now you have a nice option of wrapping it into a batch script that would automatically start it again after it terminates. Also, the first thing you should want to do is to make the bug reproducible. Can you run the program on a different machine? Can you try an "accelerated aging" test on it -- whatever it does, make it do it a thousand times faster with fake data in smaller chunks? Also, just to make sure -- check if the bug still happens if you don't use py2exe.
Well, putting these things inside docstrings means that. The python language is not affected by new keywords and such, which is always a good thing. Of course, the same can be said for an implementation with decorators though, but I like that this way, the contracts become a part of the documentation, which is what they sort of are. The doctest module does it the same way, though admittedly I have never used it. With this specification you can write a simple module that calls functions with a bunch of random values and tests all contracts upon each call, giving you a kind of simple unit testing; I like that. On the other hand, the PEP needs some work. It specifies `forall()` and `exists()` instead of using the python builtins `all()` and `any()`, which is a silly violation of DRY. Also the implies function seems strange, since python already has a form for the C ternary `x ? a : b` operator (`a if x else b`)
`this`. ... uh, I mean `self` ;-)
i_hate_using_underscores_but_i_feel_compelled
There is no way that single file ascii I/O is faster than a well-designed hdf5 scheme. First off, if you aren't using the indexing features of pytables, then it's probably be faster to use h5py with your own hdf5 spec. Second, it sounds like this is more a problem of the nature of your data, how you lay it out, and how you process it. Can you tell us more about this? How large is each time series? Are you sure the I/O is what's limiting you?
You are wrong about how `synchronized` methods work in Java, by the way. They use a per-instance lock, just like your second version but with an implicit lock name. Your first attempt is _not_ how Java works, and is quite pointless: not only it doesn't prevent other synchronized methods from executing concurrently on the same object, it also does prevent this method from executing concurrently on different instances, and why would you ever want that?
If it was easy to use - absolutely not everywhere tho
I'm tempted to name classes `Like_this`, but it goes against PEP8, so I don't know...
i wish there was more built-in support for constants - automatic checking if they ever change, etc.
PEP 8 to the letter, except that I use tabs for indentation (no discussion, please) and mixedCase for variables. Thus: * `MyAwesomeClass` * `my_awesome_method` * `myAwesomeVariable` I like the visual distinction between variables and functions/methods.
You are correct, sorry this is a mistake on my part. I'll try to update the article.
The name for it is Camelcase: Example: *thisTypeOfCase*
I know pandas (http://pandas.sourceforge.net/) was originally written for financial time series data, and supports reading and writing both CSV and HDF5 (using PyTables). The author (Wes McKinney) also cares about speed. Not an answer to your question, but perhaps useful to know about.
There is no more pro version of PyTables, I believe all the features are now available in the standard version. HDF5 is an extremely common format for time series data. For projects at my company, though not time series, we use h5py. The API is super simple and traversal of datasets is easy, either via buffered access from disk or by loading the whole series in to memory. 50MB datasets should be easy to just load right in to a memory buffer, and h5py presents them as numpy arrays.
 CamelCaseClass camelCaseEverythingElse
That's it really. It would be great to get involved with a project in my spare time. I'm aware there are many large projects to choose from, but it would also be interesting to hear from anyone here if they are working on a lesser known project or if they're trying to get a project started.
https://pylonsproject.org/ is always looking
I've been working on a python delicious bookmark app replacement: https://github.com/mitechie/Bookie There's a list of features/todo items and some good JS/Python/etc to play with in there. Feel free to poke around and hit me up with any questions in #bookie on freenode.
There's some concern that the core scientific tools on Python (Numpy/Scipy/Matplotlib/IPython) have quite a high bus factor - i.e. that they are too dependent on a small number of contributors. I'm involved with IPython, and I know there's work for interested people to do.
Sahana Eden -&gt; http://eden.sahanafoundation.org/ "Sahana Eden is an Open Source Humanitarian Platform which can be used to provide solutions for Disaster Management, Development, and Environmental Management sectors."
[OpenAnt](http://www.reddit.com/r/openant) is still going, I believe.
hm, from the top of my head, that are projects and things that would help them: * https://github.com/agiliq/merchant (tutorial) * https://github.com/zedshaw/mongrel2 (not packaged for Debian/Ubuntu yet) * https://github.com/sebastien/watchdog (improve documentation)
It's a bit of a "name your favorite project!" match, I guess. Anyway, pywikipedia (which is a framework to edit mediawiki wikis such as wikipedia) could always use some good developers (developers, developers).
The key to fast IO is to read the data in blocks. If you read rows from an HDF5 table one at a time, you won't get good performance. This overhead is mostly the conversion to python objects. Try reading in rows 1000-at-a-time.
that's funny, I started writing an app to replace delicious too. I guess there are others who are unsatisfied with their interface.
i don't think anyone will turn away a volunteers contribution. I would suggest looking on github or bitbucket, and if you find a project you feel you can contribute to, fork it, make your contribution and issue a pull request. 
How does someone go about getting involved in helping with the core scientific tools? By the way, IPython is awesome.
If you've got an itch of your own to scratch, just fork the codebase (most of these tools are on Github) start coding, and make a pull request when you think it's ready. For larger things, you might want to mention your intention first in case someone else is already working on it. I got involved because I wanted IPython on Python 3. Otherwise, you can see if there's an issue on their tracker you can solve - we have a quickfix tag for IPython, for instance. Or join mailing lists, get a feel for what's happening, and ask the project what needs doing. I've just started a page of [possible projects](http://wiki.ipython.org/Potential_projects) for IPython, but there's not much on it yet. Hopefully we'll be able to flesh it out.
I'm looking for dev for [new version of the political memory](http://dev.memopol2.lqdn.fr/) of [La Quadrature du Net](http://lqdn.fr) (defending net neutrality and protecting our fundamental rights of the internet). The long term idea behind this is to make a paradigm change: currently when you have to chose for who you will vote at an election you mostly only base you choice on non-concrete fact (promise, feeling, their political communication, historical attachment etc...). We want to give the possibility to people to base their choice on concrete fact like the way their representatives have voted on law propositions that concern subjects that matters to those people. Say in another way: people should be able to vote with information based on fact older than 2 months of political campaigns. [A description of the project](http://www.memopol.org/what-is-political-memory/) [Code](http://gitorious.org/memopol2-0) And it's in Django. Wanna change the world while learning python :) ? Ping Bram on irc.freenode.net#lqdn-memopol (or send me a pm).
Exactly. To use it effectively you'll have to understand numpy and why it does vectorization - loop unrolling. I imagine pandas goes some to hiding this and would suit your application well.
THIS.
The presence of any parameterized behavior (callbacks or interfaces implemented by callers) called inside synchronized methods is a recipe for deadlocks. 
[rctk](http://rctk.googlecode.com) is a rather unique (at least within python) project that can use some help. Combines many disciplines (networking, processmanagement, desktop applications, web applications, javascript). It even supports python 3!
I think it might be more rewarding for you to work on a project that you actively use or topic that interests you.
There are badly-maintained projects that, while glad to receive contributions, don't necessarily respond to them in a timely fashion. *glances at his inbox guiltily*
I know [this one](https://github.com/reddit/reddit) is looking for some help.
there is camelCase and CamelCase, in python the rule is to use the later one
I use h5py. This is a pure hdf5 implementation for python and does not include indexing and database like features that slows PyTables down. It is very fast on my system (much faster than ascii). EDIT: h5py arrays are very similar to numpy arrays and if you have a dataset X you can do this to get a subset as a numpy array Y=X[xi:xf].__array__() This will allow you to query datasets that are two large for memory. Otherwise h5py is a very thin layer of python on top of c code (much like numpy) and is very fast. 
CPython
I run [SQLAlchemy](http://www.sqlalchemy.org) which always needs help as I'm doing mostly everything at the moment, but regarding your request for "lesser known/new" I also have a new, unreleased project called [Alembic](https://bitbucket.org/zzzeek/alembic), which is a small migrations library for SQLA, that could use a maintainer overall. First thing it needs is docs, and from there a release at which point there'd be lots of work to do fielding user issues and feature requests.
https://github.com/languages/Python Probably better if you find something you're passionate about, first :)
emesene, a MSN/WL messenger for Linux is written in Python and is looking for contributors. 
Not sure what happened to the rest of the comment. In any case, I got inspired today and installed Python 3 and ported the whole library over to use function annotations instead. It was relatively simple to implement. Basically you can do something like: from covenant import bind @bind def fun(a: lambda x: x &gt; 2, b: lambda x: x &lt; 0) -&gt; lambda x: x &lt; 0: return a * b and it will perform the checks in the type annotations for you. I also added some preliminary support for invariants with an @invariant class decorator, but I'm sure it's broken in a multitude of ways I didn't think of yet. Going to get around to fixing up the test suite in the next little while and then work on fleshing out some documentation. Then I guess a PyPI upload is in order to see if anyone cares.
 - Have you installed handlers for SIGINT and SIGBREAK? Without a configured handler SIGBREAK will immediately kill a win32 console app. You won't see an exception. I haven't done this but will first thing Monday morning. The signal package looks looks exactly what is needed to at least see what is happening and maybe flush the logger before dying. Much easier than installing VS and trying to debug. Thanks all it has been very helpful.
matplotlib in particular, I know, has really been chugging along rather slowly on the Python 3 front. Actually just generally, since John faded into the background.
yeah well, such is OSS development. :)
How about mysqldb?
Yes. A good number of Python core and library developers use UNIX rather than Windows, so everything ports mostly nicely more or less.
it's actually harder to run python stuff in windows than in linux since most people only care about the latter. however I work mostly on web, not sure about the scipy community.
LPTHW is the most insanely boring intro to Python. The entire book is just contrived examples that don't actually do anything useful or interesting. DiveIntoPython gets my vote hands down.
interesting...
Hilarious .... most people run away from windows because of this ...
PyPy seems to need help.
+1
[http://flask.pocoo.org/mailinglist/archive/2011/10/12/looking-for-a-maintainer/](http://flask.pocoo.org/mailinglist/archive/2011/10/12/looking-for-a-maintainer/) Re, recent request by an author of a few Flask web framework extensions, looking for new maintainers and contributors. From what I've seen , there's about 5 projects you can contribute to just in this mail thread alone. Flask itself is very friendly to community involvement as well. 
You will have a much better, easier time of using Python for *anything* in Linux vs. Windows. In fact, when I develop for work on a Windows machine, I do it in Cygwin. :-P
I am the developer of [Registry Decoder](http://code.google.com/p/registrydecoder/), an open source digital forensics project that performs analysis of the Windows Registry. The place where people contribute the most is plugins that perform some specific analysis. Our plugin API is dirt easy and many useful plugins have been written in less than 10 lines of code. If you are interested just reply and I can send much more information.
Excellent explanation. It definitely sounds useful in the same way assertions are used. Thanks.
Pardon my ignorance, but what are Quines used for?
https://github.com/asweigart/pygcurse Pygcurse is a curses emulator for Pygame. It's used to make roguelikes and console/text programs. Currently it's at about 2.5k lines of code. I'm looking for people to make some enhancements or suggest features.
try converting the string to an integer with int(&lt;val&gt;) eg text = raw_input("please enter a number&gt; ") num = int(text) int will raise a ValueError if it cannot convert the string to an integer
SimpleCV: a cross platform open source computer vision framework in python http://www.simplecv.org http://github.com/ingenuitas/SimpleCV You don't necessarily have to know vision, there is a lot of other python libraries we would like to integrate. We also wrapper IPython, Numpy, Scipy, and use them quite heavily in our project, so helping with those projects would also trickle down to us. :-)
Python itself &amp; and [they make it easy to get started](http://mail.python.org/mailman/listinfo/core-mentorship) to boot 
Yes, I started this in earnest back in Feb at PyCon after the news that Yahoo was "sunsettings" delicious. It's got a long way to go, but it works. 
I'll be open-sourcing [Fetchnotes](http://www.fetchnotes.com) soon. I'd highly reccommend looking at some of the projects I leverage. They're doing some cool things. In particular, check out [Tornado](https://github.com/facebook/tornado), [Asyncmongo](https://github.com/bitly/asyncmongo), and [DictShield](https://github.com/j2labs/dictshield).
Use "Search package directories" at http://packages.ubuntu.com/ to find the current versions of the packages in Ubuntu. You can install your own versions instead if needs be.
 try: int("not an int") catch: print("AHHHH") File "&lt;stdin&gt;", line 3 catch: ^ SyntaxError: invalid syntax Think you mean try/except :-) 
FWIW, I have a Win7 and an OS X box. I did quite a bit on Win 7, but having gotten my OS X box, it's A LOT easier. So much so, I'm considering blowing out Win7 for Ubuntu (probably Mint actually). 
`int()` can take a string expected to consist of digit characters and returns the converted integer value. &gt;&gt;&gt; int('123') 123 If a given string is malformed, it raises `ValueError` instead. You can catch it and execute the counterpart instead. &gt;&gt;&gt; int('abc') Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; ValueError: invalid literal for int() with base 10: 'abc' &gt;&gt;&gt; try: ... int('abc') ... except ValueError: ... print 'not an integer' ... not an integer
Almost everything open source is easier in linux than windows. Just consider that in ubuntu you can install anything you want with: apt-get install &lt;packagename&gt; Instead of search, click, download, click, installer, click, etc. 
I would love an improvement here. My first real deployment was such a headache because of stupid import issues between dev/prod environments. Such a silly hangup, but in retrospect it seems like a funky design.
You'll have functionality you've never dreamed of!
PEP 8 We just have to do it. If we like it or not. It's an official convention, which I'm very glad for that it's existing, so I don't need to spend to much thoughts there. Only issue I have is that my names and therefore lines tend to get very long and need to be wrapped. And for sequences I use plural nouns, like pickled_items (vs. pickled_item) and for mappings id_to_pickled_item.
the maintainer of [Tweepy](https://github.com/tweepy/tweepy), a great Twitter library, has been busy and looking for additional maintainers. Not too big, not too complicated I think?
And more. F2PY and Swig are so much easier to setup and use on linux.
I try to stick to the [Google style guide](http://google-styleguide.googlecode.com/svn/trunk/pyguide.html), which is basically PEP-8.
Don't forgot to install the python-dev packages in Ubuntu.
Python support is AWESOME in Ubuntu. My advice is to be patient and stick to the 6-month released packages...
**TL;DR:** Mostly yes. Keeping up with the latest python/numpy/matplotlib can be a little tricky -- you may need to have the latest Ubuntu version or compile from source. In windows you normally just downloaded a bunch of .exe or .msi install files and ran them all, making sure all the versions lined up. In Ubuntu, software is installed through the repositories using the Synaptic program, Ubuntu Software center or command line apt-get install &lt;name&gt; as someone mentioned. [Click here](http://packages.ubuntu.com/) to search for which versions of python/numpy/matplotlib come in the repositories for different versions of Ubuntu. Ubuntu 10.10 (Maverick) has scipy 0.7 so if you need some of the features of 0.8+, then you need Ubuntu 11.04 or compile it yourself from source, which can be a bit messy for newcomers to Linux. I found this out when I wanted to calculate the Mel-Cepstrum Frequency Coefficients for some signal, which relies on a discrete cosine transform, which was added in scipy 0.8. I was running Ubuntu 10.10 and had to compile scipy 0.8 myself. **EDIT:** Clarity
Python is tightly integrated into modern linux distributions. The only one of those four libraries that you list that doesnt show up in my repositories is mathplotlib, and installing that wont be any harder than it was in windows. 
It's called matplotlib (no 'h') and lives in the package python-matplotlib. :)
Excellent. That is 4 for 4 then, eh?
&gt; Considering migrating from windows to Ubuntu, will I have all the Python functionality? This is actually a little bit funny. Even though it can be run on Windows, Python belongs on Linux/Unix. The latter is Python's natural home -- on Windows it's an uncomfortable tourist. 
you might be able to find more up-to-date packages as ppa repositories
&gt;Python's natural home I like how you put that.
[Pyramid](http://www.pylonsproject.org/) is always looking for contributors
I recently made the switch as well. The only downside I've found is that I've failed to setup the environment variables. In 7 I could call a script by doing just "helloworld.py", and it would run. In linux I've had to do "python helloworld.py" which is a bit belaboring. If anyone could point me in the right direction to change that, I'd appreciate it.
You have to set the executable bit on the file and and this line to the beginning of python file (so that Linux knows how to execute it) \#!/usr/bin/python -or in more cross-platform way- \#!/usr/bin/env python
Put *#!/usr/bin/env python* in the first line of your script.
The answer to this particular question is not as obvious as it seems. Sure, Linux beats Windows with hands tied behind its back when it comes to Python in general, but the Scipy, etc situation is somewhat different. Ubuntu repo versions of all concerned packages are a tad outdated and building them from source isn't exactly a straightforward job. For instance, *pandas* will build and install with stock Ubuntu dependencies (e.g. numpy 1.5.1) but will have trouble running. On Windows, on the other hand, library dependencies are usually bundled in the "click installers", so you can more easily mix and match what exactly you need. So I'd keep your Windows environment around until you are settled in Linux and know what you are doing. That having been said, I am using Linux only for Python myself.
Harder indeed, if not impossible. I couldn't get matplotlib run on 64-bit Windows. I gave up quite easily, though. Development on Windows is a PITA.
For scientific Python stuff, we do care about making it work on Windows as well. But certainly a lot of the developers are on Linux, and it's bound to be best tested and understood for Linux.
I think OP is trolling. That was my first reaction to the thread title 
To clarify: you can 'set the executable bit' from the permissions tab in the file properties dialog (at least in Ubuntu), or you can run this at a command line: chmod +x helloworld.py
Not for this reason, it's just that it's pointless including them and wasting space in the repo... also, they're platform-dependent and Python-version-dependent. (I think they suffer from the big/little-endian issues, at the very least.)
I saw the thread title, first reaction: "not sure if serious..."
It's not a program until you set the execute bit. Magic at the top tells it how to run. You may need to specify where it is, like with "./" before the name (because search paths are problems of security -- if I can put a program called "dir" somewhere, can I trick you into running it?) so "./helloworld.py" or "/usr/local/bin/helloworld.py".
PyPy is looking for win32 developers (most of the current devs use *nix). Here are some specific bugs on win32 that need special attention: * [The win32 buildbot is broken at the moment](http://buildbot.pypy.org/builders/pypy-c-jit-win-x86-32). * [Zip Importing is broken for nested packages in win32](https://bugs.pypy.org/issue725) * [pyglet is broken on win32](https://bugs.pypy.org/issue849) * [Extension modules can't be built on win32](https://bugs.pypy.org/issue889) * [Multicore thread performance is buggy on win32](https://bugs.pypy.org/issue884) 
Any news on when we can expect the next release of CherryPy? I love that framework.
Yeah, this was my main concern, which is the scipy modules which have the msi installers. I know python was meant for linux, but ubuntu in specific may cause some issues.
Lol no, not trolling. I do understand Python was made for linux, but what I am concerned about more is Scipy/matplotlib/numpy on ubuntu in specific. 
Robert Brewer pushed out 3.2.2rc1 this weekend, fixing notably an issue with the WSGI server and unicode. Hopefully the final release will follow soonish. Once that's done, Robert hinted a move to 3.3 with possibly a package refactoring so that the WSGI server could be packaged up on its own for others to use.
Did they write up their reasoning for choosing hg over git? 
Nope. From what I gather, it was more of the fact the main dev are already using Mercurial for other stuff so it felt more natural. It's not something against Git per se. 
you've been recommended top notch tools without a real appreciation of what you are trying to do. with PyQt, you use parsing tools that comes with Qt (QNetworkRequest, QDomNode, QXml, etc...). BeautifulSoup can get on by itself, just feed it some html (urllib, urllib2, etc...) i suggest you go the way that makes your application better integrated (is it GUI, is it command-line based?) your os (win7 64) is going to give you hard time. for python modules check this [site](http://www.lfd.uci.edu/~gohlke/pythonlibs/)
I'm not sure if [this subreddit](http://www.reddit.com/r/scipy) is still alive, but you should double check there as well.
I'm considering moving from west africa to the United States. However, I am worried, is there food there? 
The file you linked seems to work for me on Python 3.2. Can you give the exact exception you're getting? Did you copy the file exactly? It sounds like you may have inadvertently messed up the indentation or something.
They work just fine, so long as the versions in the repositories are recent enough for you (they can be a few months behind released versions). If you need to compile newer versions, it's a bit more challenging, but it's OK once you've worked out what packages you need to do it.
Odd... I closed it a while ago to do something else. I came back and tried copying and pasting again and it worked perfectly. That's weird. Anyway, thanks for your help.
I want to know if it is useful enough for me in the long run.
Odd - it's working here (on Linux). Maybe it's handles the encoding different on Windows, but I don't see why that would be a SyntaxError. It's not clear from your post - which character is the ^ pointing to with the SyntaxError?
You can use exec to run code from a string, and offer it a customised namespace in which to run as a dictionary. There's no reliable way to restrict access to Python features, though.
But what should I do with this foam coming from my mouth? How dare they use a piece of software that I prefer an alternative to!
It looks like the file was double-encoded to UTF-8. That is, the unicode string `u"\xb0"` was encoded to the UTF-8 byte string "\xc2\xb0" which was then again encoded to UTF-8, giving the byte string "\xc3\x82\xc2\xb0". I think when you change `print line` to `print repr(line)`, you will see that the line contains `u"\xc2\xb0"`, which means that the codecs module decoded 4 bytes to 2 bytes. Or when you run this: for line in open('addrs.txt', 'r'): if line.contains('\xb0'): print repr(line) print repr(line.decode('utf8')) I think you will see that the character '°' is encoded twice.
While I'm sure the bitbucket platform is better for dev, it's a mistake to redirect the main domain to their bitbucket page. The main bitbucket page is *not* user friendly for someone who just dabbles. The current cherryPy page has a big "download" link at the top, a nice quick install guide and some nice tutorials all within 1 or 2 clicks. The bitbucket (and the same goes for github, which is similarly confusing) interface is just not user friendly for non-devs. They probably don't realise it because they are developing the software. Yes, I know that you have to be a developer to use cherryPy, but familiarity with source control or bitbucket is not something that everyone that uses python has. Python is a language people start programming in, and if I'd just taken up programming, wanted to develop something with a web interface and someone said "CherryPy is great", that bitbucket page would turn me off completely. I'd probably end up using a web framework with a nicer website.
If you can easily read french, there is another good resource: ["Apprendre à programmer avec Python" by Gérard Swinnen](http://inforef.be/swi/python.htm), which introduce programming, with answer this question (both with Python 2.X and 3.x).
Oops -- line.contains('\xb0') doesn't work, you need: '\xb0' in line
+1 for an interesting question, I've wanted to do something like this for a while. I'm not sure if it meets your criteria, but check out [this presentation on the cmd2 package](http://catherinedevlin.pythoneers.com/presentations/cmd_cmd2/pycon2010.html). You'd probably still need to interface this in via multiprocessing and some sort of message passing scheme (just guessing, having not tried this myself).
Except it doesn't work. I've tested since the last commit in august, and it just flat out doesn't work. As with most open source projects, my inability to grasp what the other programmers were thinking when writing said code makes it difficult for me to contribute in any useful capacity. I'm also limited in my knowledge of the technology they use. I assume I am not unique in this position. 
Kindof. People are fixing bugs here and there, but nobody ever responds to discussion posts, and there's nothing remotely resembling a release schedule in sight. The development branch is broken on some platforms, too. 
In my first post I suspected you had a BOM at the start of the file. I also suspected a carriage return problem. But I couldn't reproduce the error exactly. So I installed PyScripter. It's wrapping the error indicator around to the next line, whereas in the Windows console the indicator corectly points to the end of the line. So using `eval(line.rstrip())` should do the trick. As to "Â", it's the utf-8 '\xc2' byte in the Windows Western encoding that PyScripter uses. Just do `print line.encode('utf-8')` with the Unicode '`line`' to reproduce it. Edit: &gt;&gt;&gt; eval(u"{'TYPE': 'ADDRESS', 'VALUE': 'Av. Bellavista N° 185'}\r\n") Traceback (most recent call last): File "&lt;interactive input&gt;", line 1, in &lt;module&gt; File "&lt;string&gt;", line 1 {'TYPE': 'ADDRESS', 'VALUE': 'Av. Bellavista NÂ° 185'} ^ SyntaxError: invalid syntax 
/thread
Since I am running a GUI that needs to stay active while scripts run, multiprocessing is probably going to be involved. I guess the end result is likely to involve some kind of "start an interpreter in a thread, handle message passing, etc" because I need to have two-way communication between the main app and the script, and also because I'd like to provide error feedback in the case that the user writes a bad script. 
Luckily, easy_install or pip is still around which will install the latest versions directly from the cheese shop. It can also update all installed packages through setuptools.
It sounds like [Restricted Execution](http://docs.python.org/library/restricted.html) should work for you.
&gt;We really wish this will make CherryPy more visible and therefore attractive for people who aren't aware of it. Since we are a small set of contributors, the project has a rather slow pace, ideally this will make the project look, well, more alive. I truly hope CherryPy will has a new life as it seems to be a very pleasant framework. But I don't think moving to this new platform will make it competitive. It's very simple: you will have to put more effort into it. For example, the documentation is found wanting; much less impressive than the competitions. I know CherryPy has a small group of core developers (3???), but there're other frameworks that are doing well but only 1 core developer. 
It's covered in deprecation and security warnings! I can't find any solid information on whether or not something that is modern and secure exists to provide this same function. I am not so much worried about security, since this is an in-house app, but I would like to do a minimum to prevent accidental data loss, and make it hard for users to accidentally corrupt the parent application state.
Create a parser that uses a dictionary to map symbols to function calls. Split the input on whitespace, submit the resulting symbols to the dictionary, execute the functions. Too easy. 
http://cython.org/ is probably what you'd want to look into. You can also try the ctypes library included with recent versions of python (http://docs.python.org/library/ctypes.html) if you want to attempt doing a pure python wrapper (compared to cython which generates c code for you).
Code sample?
Is the function name a keyword, like "while" or "local" or "global"?
Did you put an empty pair of parentheses after the function name but before the colon?
Thank you.
Depends on your use case?
You can find the real solution [here](http://hs.spoj.pl/forum-en/viewtopic.php?f=51&amp;t=129)
BitBucket allows you to have an index.html that will be rendered rather than their default pages. So that could offer a better default view probably. edit: Also CherryPy would need some love from a designer to provide a more attractive layout. 
It's good, especially as they started the effort of moving from a wiki to Sphinx docs this year as well. On the other hand, &gt; We will point the cherrypy.org domain (as well as www.cherrypy.org) to https://bitbucket.org/cherrypy/cherrypy in the coming few days, so don't worry if the domain stops responding for a while. Do Not Want. Bitbucket (or github) is fine for a very small project (nb: site-wise, not talking about code hosting), but for a big one it's Absolutely Not the Right Place. If they don't want to maintain a separate site, I'd heartily recommend using rtfd.org + their sphinx doc (that's what [mod_wsgi](http://modwsgi.rtfd.org/) and http://wsgi.org have moved to), bitbucket simply does not feel or look right for a big project.
Who is this sarcasm aimed at exactly? Society?
Thanks.
Whereas my old boss mandated it as part of our coding standards in C++. Sometimes you have a fairly complex method that makes certain assumptions about the data you pass it, and it's much easier to debug if you catch those errors at the start of the method than to operate on bad data and hope something catches it further down. It's easy to justify it in the context of C++, in that you're just being much more specific about the type you're passing in. In Python, it's a bit fuzzier - is it more important to have this sort of thing, because the arguments are otherwise not checked at all? Or is it less important, because you usually hit an exception at some point if the data is wrong? Personally, I'm quite tempted to start using something like this in Python because too often I'm getting invalid data in my methods and only discovering this much later.
Just use the damn software and don't worry where the homepage is hosted. It's good software. 
My advice is to live on the edge and roll with Arch linux!
&gt; Sometimes you have a fairly complex method that makes certain assumptions about the data you pass it, and it's much easier to debug if you catch those errors at the start of the method than to operate on bad data and hope something catches it further down. That's a good explanation; I'm a bit more tempted to give it a go at some point now. However I would argue decomposition of complex methods might apply (that's one of my "screw everyone, this is how I work" axioms). Overall, I think it's less important in Python because you just wind up with some attribute error if you screw up parameters.
Arch *is* nice. I have had some beef with the community's attitude ('piss-off n00bs, we're better because we use Arch' -- Fedora often does this too and it's *very* uncool). Also, much of my development is for specific Ubuntu deployments in a lab with specialized hardware, so I try to develop on close to the target box. Rolling releases would be the death of me. :-)
The question is rather why did they choose to go to the site which is apparently less popular with developers. Nothings wrong with hg, but GitHub is where the mindshare is (currently).
Bitbucket would also need some love from a designer to provide a more attractive layout…
It gets more complicated if I want to allow scripts to do things like define their own locals and use control structures like loops and if/else statements.
Also, Mercurial is easier to customise (or fix) with Python, so if you're a competent Python developer, it's a natural fit.
I strongly suggest using [json.loads()](http://docs.python.org/library/json) instead of `eval()` for these kinds of data parsing tasks.
Mainly for my own amusement.
Bitbucket now does git with free private repositories!!! I prefer GitHub but Bitbucket is now actually useful. 
Yes, in which case it might be easier to use Python itself, rather than write an interpreter in Python. Then the trick becomes deciding which parts to allow in, and which to exclude, to achieve a particular security objective. 
Definitely use the second line (shebang). Using "#!/usr/bin/env python" gives important flexibility like being able to run inside of virtualenv.
People still care about these moves?
So I see the below, which seems to alingn to what you described, I was so caught up in why reading from the file wasn't working and what eryksun mentions below with PyScripter I didn't think to use repr(). When you say the file was doubled coded to UTF-8 is this something that could have occurred if I was using different editors to work on the input file? Or am I completely off track? Thanks :-) "{'TYPE': 'ADDRESS', 'VALUE': 'Av. Bellavista N\xc2\xb0 185'}\n" u"{'TYPE': 'ADDRESS', 'VALUE': 'Av. Bellavista N\xb0 185'}\n" "{'TYPE': 'ADDRESS', 'VALUE': 'Los Aromos N\xc2\xb0 12185'}\n" u"{'TYPE': 'ADDRESS', 'VALUE': 'Los Aromos N\xb0 12185'}\n" 
Hi - thanks for the info about it working on Linux, see below as eryksum points out it looks like it's a Pyscripter thing as I too see the indicator work correctly in the windows CMD line. 
i checked it out, looks nice!
It could become double-encoded with a single action. Suppose the file initially was encoded with utf-8, and was then opened in a text editor as cp1252, and then converted/saved as utf-8. The main point in these kind of issues is that all files have an encoding, there is no such thing as "plain text". When you open a file in an editor, there is no way for the editor to know its encoding, so it must either be told (by you, or by some annotation inside the file that declares its encoding, even though that's a bit of a chicken-and-egg issue) or it must guess using heuristics. When you let software guess the encoding is when files get corrupted (mojibake.) You have to be vigilant.
I've not read it. What I _will_ say is that Google will take you _very_ far, when it comes to confusion about programming. Glancing at what's there, it seems like a pretty decent survey. Just make sure you answer questions you have by asking others or Googling, and you'll be fine, IMO.
Great info thanks for the assistance :) I too see it working correctly in the CMD line and chars displayed as in the file - with the CMD line set to use the Lucida Console font - and working in Pyscripter with the rstrip or using repr in the eval on line. It appears that using repr with eval is always a good idea? 
Thanks for the pointer, I am not familiar with that but will take a look. I am using eval in this test code and my project as it is an easy way for me to build a dictionary spat out by another project and read it into my test code. Thus for now it is just a kludge ;-) I appreciate the direction to look at json.loads() and will check it out. 
Here's a python wiki page adressing this question: http://wiki.python.org/moin/SandboxedPython &gt;One solution which can be considered within this particular domain is Zope's RestrictedPython 
I wouldn't even do that, just type: sudo easy_install [name of python package] It's got easy in the name, you know it's good :D
That is likely to be the case as I was using Ultraedit and Notepad++ to view/edit the file and ensure it was UTF-8! How would one un-double encode it or is it not possible to go backwards now? :-/ 
Oh and thanks for the new word too (mojibake). 
I didn't know about that command. Thanks for the heads up.
`eval` cannot process carriage return ('\\r') characters at the end of the string. When you use `codecs.open` the file is opened in binary mode, so the '\\r' characters are *not removed for you automatically*. Read the contents of your file in binary mode ('rb') without decoding it and search for '\\r' (carriage return, CR): '\r' in open('addrs.txt', 'rb').read() If the lines in the file use CRLF instead of just LF (line feed), that is the source of your problem. Simply remove them with `rstrip` before using `eval`. There is no need to use `repr`. Also, you should configure your text editor to only use LF line endings to avoid such problems that come from using CRLF. Edit: Additionally you need to include a 'u' in front of the Unicode text; otherwise `eval` will implicitly encode the Unicode characters as utf-8: #not what you want &gt;&gt;&gt; x = u"{'TYPE': 'ADDRESS', 'VALUE': 'Av. Bellavista N° 185'}\r\n" &gt;&gt;&gt; eval(x.rstrip()) {'TYPE': 'ADDRESS', 'VALUE': 'Av. Bellavista N\xc2\xb0 185'} #better &gt;&gt;&gt; x = u"{'TYPE': 'ADDRESS', 'VALUE': u'Av. Bellavista N° 185'}\r\n" &gt;&gt;&gt; eval(x.rstrip()) {'TYPE': 'ADDRESS', 'VALUE': u'Av. Bellavista N\xb0 185'} 
Thank you for SQLAlchemy!
It's pretty useful. Your original comment did get me wondering about when to use it and when not to, though. I think the best use is when you want to run python under virtualenv and get libraries really quickly, otherwise it's sort of redundant. Right?
Ipython. Check out how we use it in our app for something similar. Http://simplecv.org There is also something like this: Http://repl.it
`iconv` is a good tool to keep around. It can convert to and from pretty much any encoding. This example was made with Cygwin on Windows, BTW, so don't think this is a \*nix exclusive thing: $ PYTHONIOENCODING=utf_8 python -c 'print u"N\N{DEGREE SIGN} 185"' | tee file N° 185 $ od -t x1z file 0000000 4e c2 b0 20 31 38 35 0a &gt;N.. 185.&lt; 0000010 $ iconv -f cp1252 -t utf-8 file | tee file.mojibake NÂ° 185 $ od -t x1z file.mojibake 0000000 4e c3 82 c2 b0 20 31 38 35 0a &gt;N.... 185.&lt; 0000012 $ iconv -f utf-8 -t cp1252 file.mojibake | tee file.fixed N° 185 $ od -t x1z file.fixed 0000000 4e c2 b0 20 31 38 35 0a &gt;N.. 185.&lt; 0000010 In this example, the operation that caused the error was interpreting utf-8 as cp1252 and trying to convert that to utf-8, so the inverse (convert utf-8 to cp1252, which will really be utf-8 again) undoes it. 
Its a great point about the wider ecosystem. I use numpy all the time, but use scipy and scikits.learn just as much.
When you unexpectedly see one of these characters: 'ÂÃ', and you're dealing with UTF8 and possibly something like Windows-1252, from my experience it should immediately tip you off that mojibake is involved, because those two characters are U+00C2 and U+00C3. Have a look at this: for x in range(128,256): print repr(unichr(x)), repr(unichr(x).encode('utf8')) 
Link to slides at start of third paragraph. But read the rest of the post, it's entertaining.
I agree. I have not been able to install in on lion
Makes its so much easier when coding for open source libraries to just in get the habit of PEP8 for personal code.
catch/except and throw/raise always throw me off when I'm switching between Python and Java
Yes, what about Cython and PyPy? If PyPy can host multiple syntaxes and I assume Cython’s implemented largely in Python, is it not plausible that some hybrid solution could be created where your Cython code can we used unchanged with PyPy as well as CPython?
&gt;I sacrificed a year of my life in 1999 (delaying my PhD graduation by at least 6-12 months) bringing SciPy to life. I sacrificed my tenure-track position in academia bringing NumPy to life in 2005. Constraints of keeping my family fed, clothed, and housed seem to keep me on this 6-7 year sabbatical-like cycle for SciPy/NumPy My hat's off to you
There was a GSoC project this year aiming to allow Cython to produce pure Python code, using ctypes to call into compiled libraries; this would be usable by any Python interpreter, but is of particular interest for PyPy. Unfortunately, it was [too much for one summer](http://mail.python.org/pipermail/pypy-dev/2011-September/008260.html), but hopefully someone will pick up the work that's been done and finish it off.
This is a good point. I wonder however if the way forward wouldn't be, exactly at the opposite, to focus on porting numpy or even a subset of it to PyPy, and not worry too much about backwards compatibility. The entire ecosystem is there to stay and will take a very long time to be ported. Instead of waiting for that to happen, having a small and working numpy-on-pypy would allow people to start experimenting with it and writing code with it without worrying about the huge burden of backwards compatibility. We can always build bridges between the two worlds to allow them to communicate.
&gt; I assume Cython’s implemented largely in Python It is, but the main purpose of Cython itself is to compile a Python-like syntax to Python-compatible C. The compiler can probably run on Pypy, and you might be able to run Cython code inside pypy itself, but you'll likely lose the main point of cython: statically compiled, fast, native code. It's theoretically possible Pypy will run Cython code at C-speed, but i don't think we're quite there yet.
This is what's happening right now. As far as we're concerned, having a very fast numpy (or a subset of it) that's incompatible on the C level is what caters very well for a group of people. It's not the same group as Travis is concerned about, but it caters well and we'll see where to go from there.
Similar thing done with OpenCV Python API - https://bitbucket.org/dekomote/pyfacedetect/src/bd81f138633e/pyfacedetect.py
That's not the point (and obviously, the downvoters don't get it either). The point is, that they went for the site which is less frequented by potential contributors. It is not the point of choosing Mercurial over Git.
Just found this and tried it out and it is quite useable - especially as a math shell (sympy is allready included) or for some hacking on the go. It's a more or less standard python 2.7 shell with a limited (no socket stuff, no threading stuff) standard library and sympy. Additionally the shell is a bit enhanced in that you can easily reexecute edited versions of former commands and manage the history. numpy, mathplotlib and scipy are on the list of future enhancements according to author, too. Sadly no GUI stuff yet, not even small plotting or graph modules - would be fun if it would gain some graphing module ala processing.
Github is shit. Yes, some people think this 
If you have a bunch of patches collecting dust because you don't want to use Mercurial or Bitbucket, give them to me, and I'll try to help apply them.
But the majority does not. You're still missing the point.
Thanks for the offer, but it'd be easier if I could just fork their repo on Github and send pull requests. I have a small open source project on Github and every month I get about one new pull request, because someone saw it, forked it, made two commits and wrote a pull request. I use Bitbucket longer than Github and never got any single pull request.
Like? Actual question.
If you know a function will raise an exception in all the error cases, then you're fine. Where this sort of thing comes in really useful is where the error can be silent, or not discovered until later, in a different part of the code, because it's been allowed to pass through a function that was not guaranteed to work with the data it was given. For example, I have recently found myself passing byte strings to functions that expect Unicode, and vice versa. 99% of the operations that work on one will work correctly on the other, meaning an exception won't be raised. But at some point in future, many functions away, the wrong data will get returned because that first function didn't make sure it was fed the right data. (eg. It gets stored in a queue, removed from the queue later, formatted, and finally output to the screen, but now the text is garbled because the encoding is wrong.) But if that first function had enforced the 'unicode only' contract, then the error would have been found immediately, in whichever function called it with the wrong data, which is exactly the place the fix needs to be made (if each function has the correct contracts in place).
I have been trying to do something like this for a while. My goal is to get ffmpeg and ffplay as a dll so that i can use them from python to play, and decode/encode just about any format. ( when using the ffmpeg.exe/ffplay.exe to decode, i have this strange issue where the syscall finishes but the file has not finished processing, which takes another 6-10minutes ) Commenting here, saving your name, and if i ever figure something out i can send you a PM. I currently have no free time to look into it. Until then, I am interested in what you come up with.
&gt; what if I want to expose some basic Python language features (loops, if statements, the time.sleep() method, for example) but not the entire Python API, just my app's internal API. Why? What for? I mean, it sounds like a cool, interesting thing to do, but what benefits it would actually give, and how are you going to minimize inconveniences from your restrictions? You shouldn't let your desire to write clever code interfere with your ability to deliver useful product... I recommend using exec with your API inserted into the global namespace you give it, and call it done.
OK. But if you don't have any patches to send yourself, then there's no problem, right? There are more gains to be had by worrying about a project you actually contribute to.
I've looked into extending Python quite a few times. Always the complexity has disillusioned me - but this makes it seem a lot more simple!
Fair enough. My original intent was to avoid teaching anything but the minimum of Python to the people who will be writing the scripts, but I guess that since security isn't a concern, there's no real reason to restrict anything. 
Well, it's going to be a while before I get to wrapping FFmpeg. I'll let you know if I get to the answer before you.
There is also boost-python that will do most of the magic.
That always looked really good - though then I have to use C++ and boost.
Thanks for posting. I'm keen on the *hacking on the go* use-case, as I'm still on the early-side of learning python. Plus, I've been planning to get into using python for math, especially statistics. Great find--again, many thanks.
Guess the lady in the middle of the photo at the bottom of the page didn't have a face.
I should hope so!
I think I need to elaborate a bit ... Python has the reputation of being a toy language. "But, google, NASA, Youtube, Disqus, ...", I hear you say, and I agree. But most of the hundreds of non-IT companies with turnarounds of about 100 billion (at one of which I'm employed) still use mainly JEE for their projects. There're not only political, historical, but also very good technical reasons for that. Those reasons are the standards and conventions (and performance) Java and JEE bring with them. There's the opinion that Python or Pearl are OK for personal scripting, but not for creating robust, mission critical code, which needs to be maintained for years by several IT-service provider companies. Python has great flexibility, with the potential to simply write better (as more directer) code than the whole JEE nightmare. But as we know "With great flexibility comes great responsibility" (or was it power? ;-)). To write large applications, you just need to stick to conventions and standards, like documentation, testing and of course naming conventions. It's a requirement, otherwise your project will explode at the latest when a new service-provider joins the team that works at the code. That's why we simply can't use naming conventions as we like. Or extend the exisiting, (e.g., my globals have camelcase ...). Professional Python code has to conform to PEP 8 (you can argue about the line limit, but not with naming conventions and the like). We just have to do it. Please ... ;-)
Some optional static type checking would be swell, too!
Not me, but yeah, we owe Travis Oliphant a great debt.
Thanks for sharing that. These days, I keep multiple zipped copies of my repositories saved off to two different servers along with a set of rdiff-backup copies to a local external hard drive. Keeping successive frozen copies helps me if source disk problems ever crop up. I started keep successive copies after losing work on an old dedicated word processor I used in the 90s.
I used cython to write a wrapper on ffmpeg in the past. I can see if I have the code somewhere if there is interest. 
Might be hard to get because of dependencies, but I wonder why there is no numpy/scipy? That seems like the most obvious choice for additional packages.
Multiprocessing is probably not quite the right tool - that's more about using worker processes for heavy computation. You probably want to use subprocess.Popen to start a single other interpreter, then pick a system to handle communication. ZeroMQ is getting quite popular as a simple, lightweight messaging tool. The downside of this design is that the second process can't directly manipulate Python objects in the first process. There are some frameworks like Pyro that try to allow that, depending on your needs.
Dollars to donuts it is a space/tab issue. Python can throw some weird errors if you mix spaces and tabs. I always use an IDE that will replace tabs with spaces for this very reason.
Indeed it is!
Urrgh.. From p 4. * Use C modules. Writing C modules is easy. * No such thing as “100% pure python.” In other words, "donot use python where performance matters". Right? PS. btw I find article title to be condescending and, frankly, quite a bit misinformed.
Hmm. Cython generates C with calls to the Python object model; hoe about if it created C with calls to the PyPy object wrappers instead? Would that make sense, or would the results be worse than translating Cython to Python + ctypes?
See http://wiki.python.org/moin/PythonSpeed/PerformanceTips . Everything in there could be interesting to you, but have a look at the *Profiling Code* section. When you have a speed problem, follow these simple steps: 1. Get it right. 2. Test it's right. 3. Profile if slow. 4. Optimise. 5. Repeat from 2. 
Pyro looks like it could work well, thanks! I think I'll try injecting Pyro into the user scripts and then running them in a subprocess.
How about trying [lxml][]+[html5lib][]? It would give you way better performance. (It’s written in Cython, so you cannot use threads property with it.) [lxml]: http://lxml.de/ [html5lib]: http://code.google.com/p/html5lib/
Thank you! I think the real problem is not at the optimization, though. Processing a document takes pretty little time, but I think repeating the process for 5000+ times in a unparalleled fashion makes it slow. Are C API or alike the only solution for this kind of problem? :(
It's probably doable but it's a big job.
The real problem I see is in making sure that the subset *really is* completely compatible. The basic ndarray semantics are complicated enough that it's a huge job just to ensure this much.
Be honest, you do not know what the problem is. You *think* you know, but you do not. You have completed step 1 and maybe step 2. You are now ready to start step 3: profile if slow. Profiling will tell you what your bottleneck is. You need to know for sure what is taking so much time before you can fix it. You should have a look at that page for more than 2 minutes: http://wiki.python.org/moin/PythonSpeed/PerformanceTips . 
[Cython](http://www.cython.org/), my friend.
Getting them to compile on certain full-fledged operating systems is challenging enough. The prospect of getting them compiled on iOS are iffy.
I have no idea where you got the idea of I have never stumbled upon the URL you have given to me. I think I have done a pretty good job when I can cut down the speed of each iteration to the ballpark of 0.1 second when the code requires database query, file system lookup and various other string processing. My question here was if there is any sort of approach that allows drastic speed improvements that I am missing or do not know. Pointing at an URL that is well known and mindlessly saying "follow it" is nowhere close to a drastic improvement. 
Thanks! I suspected BeautifulSoup to have a bit of room for improvement in speed, but never really looked at it. By the way, is there any HTML or XML parser available in Python that is not written in pure-python? 
You could try dropping in [PyPy](http://pypy.org/) and see if it helps as a quick test. It says it is compatible with beatifulsoup
I suggest this [MIT course that uses Python](http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-00-introduction-to-computer-science-and-programming-fall-2008/). The benefit is that it will give you a good introduction to computer science principles.
I just found out lxml actually uses C library libxml2 and is much faster than BeautifulSoup. Thank you so much! http://blog.ianbicking.org/2008/03/30/python-html-parser-performance/ 
So in other words, you haven't profiled it yet? Note that parallelizing this isn't going to do a thing if the database or file system are still single-processing serial bottlenecks. The point of profiling is to find out what part of what you're doing is the slowest bit. Why is this important? Because if you speed up anything that's *not* the slowest bit, it's not going to make a whole lot of difference. There are plenty of ways to drastically improve a Python application's performance, but none of them can simply be applied randomly. You have to know where the slow bits are, and more important, *why* they're slow.
Possibly of interest: BeautifulSoup 4 will use lxml behind the scenes, so you can get lxml's speed and BeautifulSoup's interface. It's in beta at the moment.
Thanks. that addresses the first part of the question, but what about the executible?
lxml uses libxml2. lxml.html is fast and quite good with most HTML (you might need html5lib for cases where you want to be very very close to how browsers handle extremely broken HTML.)
You can use [py2exe](http://www.py2exe.org/) or [pyinstaller](http://www.pyinstaller.org/) for the executable. Some prefer one over the other you just need to see what works best for you.
Glad to see the NumPy guys are still enthusiastic. The day when Python/NumPy/PyPy can automatically and transparently use multiple CPUs, GPUs, etc. for added performance, will be truly awesome.
These GSoC summers are never long enough :)
True. There are tons of unmaintained NumPy packages out there, I say forget about them and follow through with a redesign that potentially breaks compatibility. Once PyPy-NumPy proves itself I'm sure people will be more than willing to port their stuff to it.
Check out Vala. The extent of work you need to call Vala libraries from Python is adding an extra line to your Makefile. [Here's the documentation.](https://live.gnome.org/Vala/SharedLibSample) 
By default, ack ignores .svn directories, which is a huge pain in the arse to avoid with grep. Yes, I know, there are better source control tools out there but some of us still have to work with it.
Making "console_scripts" entry points you can annotate functions in your Python module for which package installer's will write-out executable scripts that will call directly in to them: entry_points={ "console_scripts": [ 'myexecutable = mypacakge.mymodule:myfunction', ], } Then to use this during development either install with "python setup.py install" (Distribute-style) or "pip -e ." (Pip-style) or create a buildout.cfg to install your package (Buildout-style): [buildout] develop = . parts = mypackage [mypackage] recipe = zc.recipe.egg eggs = mypackage You'll also need to use VirtualEnv to clone your Python so that you things can be installed into there, or use Buildout which installs everything in your project's workspace and keeps your Python clean. 
One more reason to focus on porting the core :)
Great, thanks! I wasn't aware of console_scripts.
Wow. Did not even know about it and it actually cut the whole processing time to half. For the same data set, it took 600 seconds before and with BeautifulSoup 4, it only takes 313 seconds. Awesome! Thank you so much! 
I thought about PyPy too, but I use some database modules that are not supported by PyPy. Thank you for the suggestion though! I do not know why you have been down voted. 
Yes! I just changed my codes to use BeautifulSoup 4, which uses lxml, after takluyver suggested it to me. Now it only takes a half of the time I used to need to process the whole data! 
It is good, but maybe a bit terse and short on explanations.
I've started putting together my my setup.py but I'm a little confused about defining the package when there is only a single file. do I need to put it in a sub folder with the package name and use 'from mypackage import mymodule' or can I define the package as the single file? Edit: source is here: https://github.com/andrepl/pyninepatch/
This is available for iOS, so does anyone know how the got around the rule that user-defined programs cannot be executed on the phone? Has the rule be relaxed? The only way I could see this being allowed is if it was running on the native javascript interpreter.
You need an extra parenthesis to close the first line of your function: guess=int(input("Guess again: ") should be guess=int(input("Guess again: "))
Meanwhile, I'm going with: v = [v] if type(v) is str else v
There's also [cx_Freeze](http://cx-freeze.sourceforge.net/), which is already compatible with Python 3.
Basically PEP-8, my personal rules: Short names in list comprehensions, ie. def foobarize(items): for item in items: .... as opposed to [i.foobarize() for i in items if i.something &gt; 17] No excessive underscores as in file_name smelly_pants vs. filename smellypants however, many_words_to_clear_up_identifier I tend to give method verb-names, ie: foo.foobarize() vs. foo.foobarinated() and adjectives for interfaces/mixins: class Stronzo(object, Foobarizable): vs. class Stronzo(object, Foobarize): And spaces around keyword-arg assignemnts, not defaults: def __init__(self, stupido=2500): but Stronzo(stupido = 3900).foobarize() 
 if isinstance(v, basestring): v = [v] This will work for unicode as well as str, as well as instances that are subclasses of these classes. I think it's easier to understand than a conditional expression as well.
That will fail if v is a unicode string.
Will this require many changes to work with the Windows BASSMOD DLL?
I hadn't looked deeply at isinstance yet. It seems the smartest alternative. Thanks!
Good to know. I'm going to go with michaelhoffman's suggestion using isinstance which accounts for unicode.
The key difference vs doing "type(v) is" is that isinstance will also be true for anything subclassing strings. That's not that common, but worth considering.
Using the python profiler to identify large numbers of needless function calls, provide clues to reorganizing code (such as why does "the code require a database query"? why not do one big query for all records rather than 1000 little ones ?) and allow one to cut down on method calls allows by far the most drastic speed improvements possible. More than using Pypy, more than rewriting in C.
[Isinstance considered harmful](http://www.canonical.org/~kragen/isinstance/). Like it says it isn't pure evil but if you're considering using it then you're probably missing something in terms of design. What it does is split control flow, which is not generally desirable with objects. So your method could go one way, could go another. I'd further add that as someone who used to write functional code *what the hell are you doing with such a vague interface*. Bu that's just me.
Wouldn't it be better to store a two-dimensional board? Than you can create it with: board = [] for i in xrange(0, 10): board.append('.' * 4) Drawing a board is simple as that: a) all in one line: print ' '.join(' '.join(line) for line in board) b) each row in its own line: print '\n'.join(' '.join(line) for line in board) Setting value for a cell at (x, y): board[x][y] = value
Ease of use. Not dealing with paths. Intuitive access to pip, and installing certain modules from the Ubuntu repositories. Etc. Edit: basically what Jimminy said about developing on Windows.
You can declare an entry_point points to a top-level module, "mymodule:main". Top-level modules need to be listed individually in the py_modules field. I prefer to always make a package and put the module in there, then nest the package into a 'src' sub-directory and then auto-include all packages in that directory. It's more project structure, but then it can remain consistent on every project you work on. Include packages in the 'src' sub-directory with: package_dir = {'': 'src'}, packages=find_packages('src'), 
This is sort of the flip side of this question, but in Python 2, you can tell if something is a nonstring iterable by asking: if hasattr(v, '__iter__'): ... In Python 3, however, strings have an `__iter__` so this no longer works.
I like how many options there are that I've never known about. Thanks.
Probably only line 6. The cdll call should change to windll. I'll test it out tonight and see for sure.
is this the most "complete" Python on iPad ?
thanks I'll have to give that a try
Well, your only other option is [PyPad][1], which isn't very well documented and has mediocre reviews. So I'd say yes. [1]:http://users.on.net/~jon.dowdall/pypad/index.html
I think it would make a great scriptable calculator. I haven't had time to play with it, but I'm guessing data files will have to be imported via iTunes.
meh. The "correct" solution according to this would be to just force the user to pass in ['string'] rather than 'string'. It's a convenience versus correctness thing, and I'm not sure where I'd side. How about the compromise of using \*args to pass in your list? This would allow both strings to be passed in simply without treating them specially, and other iterators just need the added \*. It might not make sense contextually though, I don't know since I don't have context.
I personally wouldn't have a problem to contribute to Bitbucket as well. I was just pointing out that programmers are lazy and unlikely to register for Bitbucket and unlikely to learn hg just to contribute patches for CherryPy. And while Bitbucket has users, the numbers are clearly on GitHubs side, whatever you might think about them. And yeah, I worry about my own project. That's why it has its perfect place for version control and contribution, is listed in relevant code registries, has a liberal license etc.
The following changes got it working for me in Windows (Python 2.7.2): #Line 6: _B = ctypes.windll.LoadLibrary('BASSMOD.DLL') #ctypes was casting the returned cpu usage to an int _B.BASSMOD_GetCPU.restype = ctypes.c_float #after 389: import os #for os.path.basename 
Don't be clever. Instead, write readable code. Either have separate functions or separate keyword args for lists vs single items, or use *args to take multiple items. (I second the recommendation of the "[isinstance considered harmful](http://www.canonical.org/~kragen/isinstance/)" essay.)
Sounds like you want to use `py_modules` which takes a list of single files e.g. https://github.com/collective/charm/blob/master/setup.py#L33
That's what I figured, ATLAS can be a pain in the neck. Certainly someone has a binary somewhere though...
Wow, thanks. It was just one parenthese. 
You need to profile your code to see where its slow. You can't possibly get any specific advice without knowing these details. Generally, I've found it significantly quicker in python to perform file actions in batches, e.g. read and process 100 lines at a time rather than doing it line by line. One script I had for parsing log files went from 15 days runtime to a couple of hours by making such a change. 
What's your halloween costume?
I don't like having to use multiple version control systems and I prefer Github as well. But it's not my project, so what I think isn't very relevant. The project leads have things to worry about of more importance than my personal version control system / website preference.
If you actually read the link - it says DropBox, so you could presumably use one of the code-aware highlighting editors (textastic for example) on the ipad, roundtrip through dropbox, and run what you wrote with this. Crude, and not something you'd mistake for a real dev platform, but probably not too bad for just poking at things (or maybe doing LPTHW exercises? :-)
I concur &gt; for simplicity I like to be able to also pass in a string and just have it become a one-item list automatically. This may simplify the invocation of the function in a few cases, but it *complicates* the function itself. It really isn't hard to just invoke the function with `f([string_var])` in those cases. It's handy that Python is dynamic, but don't try to make things overly dynamic.
 v = Panties()
"basestr" is the common subtype of str and unicode. See my other comment.
 if isinstance(param, basestr): param = [ param ] Though, you might should have it as unicode by this point. This is a reminder that you need to learn about it. Decode strings in some encoding to unicode coming in, and encode to something known when going out.
Not all iterables have an `__iter__` method, so that's not a very good method one way or the other.
Is there anything similar to this for Android?
Do you like things like this? Try [Church encoding][1] in Python. [1]: http://en.wikipedia.org/wiki/Church_encoding
And now take the advice of washort and others ... ;-), it's easy, e.g. the multi function solution: def process_item(item_name): # do fancy stuff return item def process_items(item_names): return [process_item(item_name) for item_name in item_names]
There is an effort to make Cython code [compile to pure python](https://github.com/hardshooter/CythonCTypesBackend). Maybe this would be a good compromise so that the PyPy people can focus on PyPy, and the Numpy people can move towards a code base that would fit them better anyway. 
Believe it or not, I'm listening. I'll consider this.
I started trying to learn it last week. It's some complicated stuff!
&gt; but I use some database modules Which database are you using and how is it used? In my experience database access is always a prime suspect.
I had separate functions, but grew tired of managing separate entry points. Three mildly different calls for four separate concepts had me looking all over the place in twelve functions. The difference here is really just a 'one, many, all' thing. The functions weren't different. There was, e.g. queryAttr, queryAttrs, and queryAllAttrs. I just wanted to get rid of queryAttr and have queryAttrs accept one or many strings, but liked the idea of passing one string in as a string, instead of a list with one string in it. There isn't really a different pathway I'm creating here - just handling singular/plural. Thoughts?
fork
I just think that the amount of work and discussion that would go into this sort of thing is greatly disproportional to the benefit it would give you. And ironically, my main nit with PEP 3150 is about clarity. In Ruby (to take one example) block-local variables have a dedicated, unmistakable syntax. There's literally no way to be confused about what's going on. But take this example code straight from the PEP: classname = f1(classname) given: f1 = classmethod def classname(cls): return cls.__name__ Tell me a Python newbie is not going to be utterly baffled by this. Which variable is in the block-local namespace and which is in the outer namespace? You have to read through the entire block to have any idea. 
every iterable has an __iter__ method, but some things support the sequence protocol (strings), can can be iterated over
If anyone is baffled, here is a more verbose version: def invoke_function_with_itself_as_argument(function): return function(function) invoke_function_with_itself_as_argument(invoke_function_with_itself_as_argument)
PIL does support numpy style arrays now I seem to recall.
I think they changed the rule. Now you can emulate and interpret, as long as what's interpreted doesn't come from a download.
It supports buffers, or some rough approximation to them. You can make a PILImage from a NumPy array and vice versa but it always involves a copy and possibly a reshuffling.
 lambda *a:[b,c][not a] (Requires understanding of python's implicit/duck typing) foo = [1,2,3,4,5,6] foo = [foo.pop() for x in foo] Returns the second half of the `foo` reversed - doesn't raise an IndexError because it eats itself before it does.
Thanks for the clarification. I guess "able to iterate" != "iterable".
 Flatten a list: &gt;&gt;&gt; def flatten(l): return [i for s in l for i in s] &gt;&gt;&gt; flatten([[1,2], [3,4], [5,6]]) [1, 2, 3, 4, 5, 6] matrix transposition: &gt;&gt;&gt; matrix = [[1,2,3], [4,5,6]] &gt;&gt;&gt; transpose = zip(*matrix) &gt;&gt;&gt; transpose [(1, 4), (2, 5), (3, 6)]
The article you link to is not dated, though it does seem a bit old (it mentions python 2.1). Haven't things changed since the introduction of abstract base classes with [PEP 3119](http://www.python.org/dev/peps/pep-3119/) ?
When I recently commented on numpy in regards to pypy I felt like I steped on someones toe. * [referenced comments](http://www.reddit.com/r/Python/comments/kt8bx/ask_rpython_whats_your_experience_with_pypy_and/c2n1mrb?context=3) I actually felts sorry for it, because I think pypy is a gear effort. However, I still was confident that my observation is correct. Soon after there was a posting that said exactly the opposite of what I think. * [posting](http://www.reddit.com/r/Python/comments/kuuyj/pypy_devs_the_people_that_are_most_likely_to_care/) I had the very strong feeling that the pypy devs are smart and passionate about what they do, but I also thought: "There is no way these guys are numpy/scipy/matplotlib/mayavi users". I saw this huge disconnect, it got me concerned, but I also knew I'm not the one to bring this to their attention. There is a guy claiming to know how to do things right every week on their mailing list, I bet. I'm very happy to see that Mr. Numpy himself has taken this on. I really hope his efforts are received as a sign that he really cares about pypy as the future of python and isn't put into the jar of nay sayers. I like to thank Travis for what he has done and I like to thank the pypy folks for what they will do in advance.
I'd rather stream instead of using **read()** because there will be situations where this will use a lot of memory. Will make the code more complex of course.
chat server in a single line of code (not mine obviously): http://paste.pocoo.org/show/94512/
This is probably a useful approach. Unfortunately, it was too much for the student working on it to get finished during GSoC, but hopefully people will pick it up and do the remaining work.
I hadn't read that before; it does seem to encourage isinstance use. On the other hand, the contrast with duck typing is important and seems to indicate ABCs are fairly niche in themselves.
I've read a comment in the standard library to the effect of "Strings are unique enough that we're not going to try to do duck typing here." (not the exact wording) For some purposes, it makes sense to treat strings as iterable sequences, for others it makes sense to treat them as indivisible chunks. There might be more 'pure' ways to do that, but *practicality beats purity*.
This depends on what it's for. If it's a user-facing function, conveniences like not having to embed an argument in a list are appreciated.
No, don't use hasattr like this. Duck typing means checking for an attribute you want to use. This is just mildly obfuscated type checking - checking for a string based on an attribute you expect only strings to have. If you want to test for a string, use type() or isinstance().
There was a presentation by Raymond Hettinger at the last pycon (I think it was [this one](http://blip.tv/pycon-us-videos-2009-2010-2011/pycon-2011-api-design-lessons-learned-4901258)) where he talks (among other things) about ABCs and duck typing.
yes, that's how I do it - my editor is synced to dropbox (I use textastic) and can use the open-with widget to send the python code to PythonMath. So I edit in a syntax colored editor, send it to PythonMath for execution an store it on Dropbox for export/import to my desktop. Quite a nice little setup for on-the-go coding.
Check the [Scripting Layer 4 Android](http://code.google.com/p/android-scripting/) - there is Python for that, too. It has hooks into the OS, too, so you can even build full applications with it.
code can be sent with open-with, but data files not. It does allow file access, but I don't know the layout of the iOS storage so can't say if you actually could access files you have in some other application (some parts seem to be shared from cursor examination). Other than that you probably have to include your data in your code as base64 encoded multiline-strings maybe.
unicode is to str as any object is to str: Neither are bytes, and if you want to represent them as bytes, you need to choose an encoding. json, pickle and utf-8 all do the same thing, only with different restrictions as to what they can encode.
 false = lambda truth: False if not truth else True true = lambda truth: True if truth else False amirite?
Thanks, I'll check it out.
Folks, do read the original article through. It's worth your time.
I agree. Creating database connections can be especially expensive in your inner loop. If you are creating fresh database connections on every iteration, that could also be taking quite a bit of time. If you can, you may want to consider opening the connection before your main loop and closing after your main loop. 
I found these (but you've probably seen them already): [http://fwallpapers.com/files/images/python-programming.jpg](http://fwallpapers.com/files/images/python-programming.jpg) [http://2.bp.blogspot.com/_E4XHjAU723A/TUvKA0s5yvI/AAAAAAAAJUw/YOTA39ssvLM/s1600/python_wallpaper.png](http://2.bp.blogspot.com/_E4XHjAU723A/TUvKA0s5yvI/AAAAAAAAJUw/YOTA39ssvLM/s1600/python_wallpaper.png) [http://www.jotlab.com/wp-content/uploads/2008/08/python2.jpg](http://www.jotlab.com/wp-content/uploads/2008/08/python2.jpg) [http://www.jotlab.com/wp-content/uploads/2008/08/python.jpg](http://www.jotlab.com/wp-content/uploads/2008/08/python.jpg) [http://fc01.deviantart.net/fs71/f/2011/173/e/a/python_wallpaper_03_by_petux7-d3joc98.jpg](http://fc01.deviantart.net/fs71/f/2011/173/e/a/python_wallpaper_03_by_petux7-d3joc98.jpg) [http://wallpaperzone.info/2011/04/python-dark-wallpaper/](http://wallpaperzone.info/2011/04/python-dark-wallpaper/) Strictly out of scope, but perhaps useful: [https://lh4.googleusercontent.com/-Kxqe3WipTWI/TX__xwSVH8I/AAAAAAAAALw/WU75fYuWSB4/doodle4google.jpg](https://lh4.googleusercontent.com/-Kxqe3WipTWI/TX__xwSVH8I/AAAAAAAAALw/WU75fYuWSB4/doodle4google.jpg) (generated *with* python)
Not only the core scientific tools are threatened. If Robin does a _why run, we are in big big trouble. :)
So kinda for "transmission between a widely disparate set of numerical and scientific libraries in Python (save for the notable exception of PIL)." I guess that was my point then.
I'm not really aware of a better way. Some people will make class member assignments. Gets will fall back to the class if never set, a set will happen on the object, and then future gets will happen on the object. The main downside to this is mutable types, similar to default parameters to functions.
This is the idiomatic way of setting attributes. Sometimes you also initialize attributes at the class level to provide defaults: class Point(object): description = "A point" def __init__(self, pos, description=None): self.pos = pos self.description = description or self.description This way a subclass can easily override the default description. In some cases it is also ok to initialize attributes from the keyword arguments: class Person(object): def __init__(self, **kwargs): [setattr(self, k, v) for k, v in kwargs.iteritems()] But it is best to avoid this, as while it provides flexibility, it doesn't generate the same helpful docstrings as e.g.: class Person(object): def __init__(self, name=None, address=None): self.name = name self.address = address and ensuring docstrings are helpful is part of being a good Python programmer.
&gt; [7] https://lh4.googleusercontent.com/-Kxqe3WipTWI/TX__xwSVH8I/AAAAAAAAALw/WU75fYuWSB4/doodle4google.jpg &gt; (generated with python) Link to code, please? (:
That's a pretty good simile. Thanks.
That would be awesome. How far did you get in wrapping it?
All built-in ones (tuples, lists, dicts) do. And that's good enough for lots of scenarios.
Yes. Something similar to this, looking for I was.
This is a great utility! I like it very much. Good job! :) One question... one thing that would make this utility even better would be the ability to pass a list of individual files to exclude. Any plans on adding something like that?
Nope. You can do this though. class Person(object): def __init__(self, **args): [setattr(self, key, args[key]) for key in args.keys()] EDIT: Actually you can do this. But you never *ever* should do it. class Person(object): def __init__(self, **args): self.__dict__.update(args) 
promising, but brief...
Hmm: def __init__(self, name, address, phone_number, attractiveness): for n,v in locals().iteritems(): if n != 'self': setattr(self, n, v) That only works as long as you don't define any other local variables. I don't know how to just get parameters. Also, you might be able to use NamedTuples and extend them.
That would make a very useful decorator. E.g. @init_obj_from_kwargs.
&gt; But you never ever should do it. How come? Why is your second example worse than the first? **Edit**: Actually, the update practice seems an ok thing to do if you could assure to only update members that already exist. Like so: class Person(object): name = "A name" def __init__(self, **args): self.__dict__.update(args) #This would fail Person(adress="SmithStreet 3") #This would be ok Person(name="Mr Smith") Now, I'm probably using the syntax *all* wrong here. But hopefully you get the point. **Edit2**: Ah. Ok I see the con of using the update practice now. It will cirumvent any special handling of attributes, causing the same problems that get/set is meant to solve in Java. **Edit3**: I also realize now that checking whether an attribute already exist might not be that hard... Hmm
As a blind shot in the dark, I'd guess that the code visible in the picture should do... *edit*: Looked at it briefly. **If** this is the code, then it's going to be painful to sort and reformat it...
Well, doing *anything* at all with a database in your inner loop is a normally a killer. Especially if we're talking about a non-embedded database..
 class A(object): def __init__(self, hello, world): for k,v in locals().iteritems(): if k != 'self': self.__dict__[k] = v In [1]: a = A('hi', 'world') In [2]: a.hello Out[2]: 'hi' I definitely don't like it and recommend you do not use it.
You can do the following. I am not saying this is a good way of doing it, but if you have some kind initialization function that takes a lot of arguments you can do this: class A: def __init__( self, x, y=1, z=2 ): for vname in dir(): setattr(self, vname, locals()[vname]) This technique has the advantage of only requiring two lines of code. Secondly, you can use named and positional parameters. Disclaimer: I never thought of doing this until you asked the question. So I am pretty sure there are some hidden pitfalls.
Explicit is better than implicit, remember Python Zen! Don't do too clever things, verbosity is a good thing to reasonable length.
I wish I had read this before I tried executing the OP's code. 
I'd love to give it to you, but I just scrounged up the image, I didn't author the script that generated it (judging from the embedded code visible in the image, it's structured around Boids or some similar EB system with goal seeking and predator avoidance). I *have* written a lot of python scripts to generate [print-quality graphics](http://effekts.dk/pypainting/index.html) - you can have the code for those, but I guess that's not what you were looking for ;) Edit: Sorry about the delay, had to find the time to make you guys some [decent examples and formatted code](http://www.effekts.dk/pypainting/addendum.html)
It's fundamentally broken and apparently unfixable. PyPy has a [sandbox option](http://codespeak.net/pypy/dist/pypy/doc/sandbox.html) which apparently actually works. Of course that only helps you if you can use PyPy for your project.
The older sites will be coming back. \- The PyCon Organizers
The 'name' in your example exists in the class space of the object. It will not be found on self.name It will be found on the instance of the class: $ p = Person() $ print p.name "A name" $ 
I think file storage is sandboxed. The app has to register to receive specific file types, and it looks like only .py was registered. I'll have to see if I can open a .py file for read. All of my data sources are in text anyway, so I won't need to do crazy conversions. 
Whaaa the hell is going on there? ELI5 what that is? That's awesome.
http://i.imgur.com/vduZN.png Thanks for the thread… realized I'd like one too, but did not quite enjoy the ones available so went ahead and created a minimalistic wallpaper: 
Oh, you can read and write files - I just don't know uf you have areas where other apps could deposit files you can read from PythonMarh. Reading a py file workes without problems from the pythonmath shell.
I think its not enough to even be considered an intro. Its a great start though.
Oh my god hand those scripts over immediately
That's really quite nice... any other resolutions available? :-)
 class Person(object): def __init__(self, **kwargs): for k,v in kwargs.items(): setattr(self, k, v) Person(name='Bob', address='123 Main St', phone_number='555-1234', attractiveness=-9.0)
While I agree with this article, it's title should be "NumPy isn't just about fast arrays," because it would not have gained the ecosystem of modules using it as a hub for data communication if it weren't reasonably fast and efficient. That said, this very clearly makes out the reason for why compatibility needs to be maintained. This applies to a lot of C modules with respect to PyPy, NumPy is a bit of a lightning rod though since it is probably one of the most common compiled dependencies outside of the standard library.
Thanks for posting this. It runs no problem as a drop in replacement for the pychecker I had already been using (Linked in the post) But the warnings are still showing up red instead of blue. Anyone know what I'd have to fix?
Expanding on your example (which is sufficient for most cases) you can also treat pos as a property of the class: class Point: def __init__(self, pos): self._pos = pos @property def pos(self): return self._pos @pos.setter def pos(self, newpos): self._pos = newpos p = Point() p.pos = 5 print p.pos # prints 5 This is an implementation of a [property](http://docs.python.org/library/functions.html#property). Although the external syntax hasn't changed, this also allows you to define a functions to set/get your variable, much like a setters/getters, but all from the single accessor p.pos. You can also make this property read-only be simply getting rid of the second pos function with the pos.setter decorator.
You can use something like this: (custom-set-faces '(flymake-errline ((((class color)) (:underline "red")))) '(flymake-warnline ((((class color)) (:underline "yellow"))))) This will affect any flymake you have.
Are you sure flymake is using the new command? If so run the command on the file and check what the output is. If the word WARNING is not inserted onto lines, then it is the script.
Here you go: http://www.wallpapersdb.org/original/62/ 
Yep, I see the word WARNING in there properly 1: WARNING E302 expected 2 blank lines, found 1 [2 times] I used pydev's snippet above to test and the warnings are showing up underlined in red.
Thanks. I like the underlining better, but it didn't solve my problem. I had already checked flymake-warnline and it was set properly to blue.
D'oh, I took out the import! Also, that would explain my 0.0% CPU usage. Thanks for the help.
D'oh, I took out the import! Also, that would explain my 0.0% CPU usage. Thanks for the help.
If you're a Django dev you could grab one from http://djangopony.com/
Nice. Thanks.
Ok, looks like the problem is my pep8 is outputing line number and column number so I ended up with pyflakespep8.py:8:1 WARNING E302 expected 2 blank lines, found 1 Getting rid of the 1 so it reads pyflakespep8.py:8: WARNING E302 expected 2 blank lines, found 1 makes it work
Write queryAttr to call queryAttrs.Probably it'll just be a one-line function. Nice interface, no extra mess
You can change the colours to better fit your theme, this is mine for example (I have a dark theme): (custom-set-faces '(flymake-errline ((((class color)) (:background "#ffffd7")))) '(flymake-warnline ((((class color)) (:background "#0a2832"))))) 
It’s not only about Python, [Hacker News][1] is my favorite link aggregate community. I am subscribing [PEPs][2] RSS as well. Some Pythonistas’ Twitters/Blogs are good to read too, for example: - Armin Ronacher (Flask, Werkzeug, Jinja2): &lt;http://lucumr.pocoo.org/&gt;, @mitsuhiko - Georg Brandl (Sphinx): &lt;http://pythonic.pocoo.org/&gt;, @birkenfeld - Ian Bicking (virtualenv, WebOb, Paste, SQLObject): &lt;http://ianbicking.org/&gt;, @ianbicking - Michael Bayer (SQLAlchemy, Mako): &lt;http://techspot.zzzeek.org/&gt;, @zzzeek - Michael Foord (IronPython): &lt;http://www.voidspace.org.uk/&gt;, @voidspace - PyPy Team: &lt;http://morepypy.blogspot.com/&gt; - Pocoo Team: &lt;http://www.pocoo.org/&gt;, @PocooProject One way I recommend you is, following the authors of tools/libraries you are using. [1]: http://news.ycombinator.com/ [2]: http://www.python.org/dev/peps/
Pretty much all I need: http://docs.python.org/library/
Hey, that might not be what I was originally looking for, but that's awesome indeed. Thanks! :D
There's a pretty good, but brief, tutorial in the first chapter of [Gray Hat Python](http://www.amazon.com/Gray-Hat-Python-Programming-Engineers/dp/1593271921). You can preview it right there on Amazon.
I like the [Python Module of the Week.](http://www.doughellmann.com/PyMOTW/contents.html)
I run a weekly newsletter called Python Weekly, which features curated information related to Python. You can subscribe to it here http://www.pythonweekly.com/
Here's the original Inkscape SVG file - tweak it as you like it: http://dl.dropbox.com/u/3346/python-wallpaper-5.svg Hope that helps :)
There's no need to obfuscate the for loop with a list comprehension when all you want is the side effect! def __init__(self, **kwargs): for k, v in kwargs.iteritems(): setattr(self, k, v) 
It appears to be for Python 2.4, which is several versions old by now. For backward compatibility, make sure you install a Python 2.x version, not 3.x, if you decide to use this tutorial. The newer tutorials suggested by other redditors might be more useful "in the long run." 
ye olden forkus bombus? :(){ :|:&amp; };:
Hello there, I am the author of this article. There are still some flaws as this is just an example. When I tried the same image but with a higher res her face got marked. If this was on a real app I would probably accept any image size, locate the faces and then resize the image if it's too big.
[Python recipes.](http://code.activestate.com/recipes/langs/python/)
Well put.
That's actually how I had it, but with many functions doing that, I had pages of functions that just filtered various counts of things to core methods. I actually find it much more readable to see &lt;1 page of core functions that can handle 1/many/all than having dozens of functions spread out over pages. I'll note that passing ['string'] for singular strings is tolerable to me. I'm probably going to end up going with that, but in the meantime, I have royally destroyed my local Python build somehow, so everything's on hold until I fix it.
this is GREAT!
Hello there, I am the author of this article. I tried the Python API alternative but I just couldn't get it working (apparently my opencv was compiled against another Python version). I'll try to get it working and create a benchmark of the performance os the two methods of marking faces. This script you posted does basically the same that I did on my extension so I'm curious on which one will run faster (though I think the C version will run faster as it iterates through the faces and then generates a single python object with the result). If I write this article I'll let you know, thanks for the comment! 
Thomas Heller still hosts [his original ctypes tutorial](http://python.net/crew/theller/ctypes/tutorial.html) which is how I learned to use it. (Thomas Heller wrote [writes?] ctypes)
Thomas Heller still hosts [his original ctypes tutorial](http://python.net/crew/theller/ctypes/tutorial.html) which is how I learned to use it. (Thomas Heller wrote [writes?] ctypes)
To be fair, this was mentioned in the comments on his post, but I wanted to get the word out there. If you are one of the organizers: thanks for putting on a great event!
It seems like it's most useful with the following assumptions: * you are writing small system utilities and therefore want to optimize for minimum start-up speed * you aren't writing very many of them, so you can spend the extra time writing code in c In my personal case, writing large amounts of python code to transform billions of events - this doesn't apply much.
It's always worth having a tab open of this site: http://babbledrive.appspot.com/ It's on github too, but I spent 20 minutes trying to get it to run locally without success. There's no documentation, and my common sense didn't get me through it.
i really like the way the artist did the python logo in this one http://fc01.deviantart.net/fs71/f/2011/173/e/a/python_wallpaper_03_by_petux7-d3joc98.jpg
 class P: def __init__(self, **kwargs): for k, v in kwargs.iteritems(): setattr(self, k, v) p=P(a=3,b=5) print p.a 3 Nice.
I'd love to see the source on that. It's beautiful!
I once took all my code (from random hobby projects and stuff) and ran it through one of those online tag-cloud generators: http://img189.imageshack.us/img189/7000/codeyk.jpg I added the background gradient myself. Looks pretty nice, IMO. On closer inspection, it seems that this is not exclusively Python, but also a bunch of Javascript, PHP and other languages. But the idea works for just Python code as well :)
Yup. You just have to challange that fine line though. :)
Kinda old, but a really useful resource if you're looking for a fun way to poke around parts of Python. Being a beginner at the time, I found it a useful tool to learn areas of Python that I would not have touched on otherwise. http://www.pythonchallenge.com/
Please do share. I learn through plagiarism. :)
Heh it's ok mate - I was mostly just taking the piss. At least it isn't being racist like [the nikon and HP software](http://www.time.com/time/business/article/0,8599,1954643,00.html). :) I've played with openCV before and know that it can sometimes have issues with particular images, especially as you say when the res isn't quite enough.
[Planet Python](http://planet.python.org/) is an aggregation of tons of Python bloggers and websites. Usually a good place to find some interesting reads and find other authors of interest to follow.
That's ok. I should have mentioned it on the article. PS: I still remember seeing that HP issue on the news on christmas eve and I still laugh my head off at how can one small mistake on a poorly tested software become such an embarrassing flaw. I guess they decided to create their own proprietary cv lib instead of using something live openCV. 
you'd be better off getting an IDE that would do all the boiler plate stuff for you if it bothers you to type it out yourself. Explicit is better than implicit. Six months from now when you open your code back up, or reuse the object else where, you'll be grateful that members are explicitly defined.
Google tkinter and alpha. (might not be exactly what you want) http://effbot.org/tkinterbook/wm.htm 
Oh, python is an extremely useful language. And, I myself do routinely use it to process hundreds of GBs of data.. It saves a lot of programming time at expense of CPU time: Cpython runtime IS slow. And pretending that its speed is not a problem is just outright silly (and harmful for the language's future). 
&gt; Cpython runtime IS slow How slow are you talking about? Can you give some general number based on your typical usage scenarios?
'O'.join(2*'L')
I totally agree with this. When programming in Python I always have the docs open.
I figured it out: &gt;&gt;&gt; y = M.list() &gt;&gt;&gt; y ('+OK 2 messages:', ['1 2636', '2 2255'], 16) &gt;&gt;&gt; 
This should be a must read on a regular basis. Lots of ideas and saves plenty of time. 
Is there any way I can follow this as an RSS feed like everything else I follow rather than email?
Slow is relative I just spoke to someone who was using hadoop for massively parallel processing hundreds of millions of events a day. I'm doing the same thing with python on an eight-way SMP. It pegs the machine for two minutes out of every ten when the next batch arrives. It's a used machine I got for free. Of my 20 minute data latency - python only contributes 2 minutes. Changing anything would be premature optimization. Writing code in c or going to hadoop would be silly.
Thanks, I found a method using the form: w.attributes('-alpha', .1), but I can only get that to work for the root surface. What I'm trying to achieve is having a root surface that is completely transparent, and have another higher level surface (for text) that is visible. So far I've been unable to achieve this with Tkinter.
True. Things without an `__iter__` method are mostly weird old bizarre things that shouldn't be iterated over in the first place.
+1 0MQ. I'm using it for IPC and it's a great library. I'm using it locally for multithreaded processes, much like it sounds OP wants to do. This is on a distributed system and it is simple to use the same library for message passing between hosts.
I just started on a Sokuban prototype in Python + Curses with a friend, we use a 2d array for our map, and game logic. Feel free to [check it out](http://bitbucket.org/jtruant/sokutype) if you want an example
In extreme (but not uncommon) cases python code is ~100x slower than an equivalent C++ program. (equivalent here means: roughly the same algorithm and written by a competent developer). These benchmarks: http://shootout.alioth.debian.org/u32/benchmark.php?test=all&amp;lang=python3&amp;lang2=gpp do have some basis in reality :-(. Also take a look at pypy benchmarks: they are getting 50x speedups on some of them and STILL not reaching optimized C speeds. Comparisons to Java are better but not by much.
I love reading [The History of Python blog.](http://python-history.blogspot.com/) It has a lot of insight into the design of the language; always keeps me intrigued. Edit: As someone that wrote a large integer arithmetic library in C, I always found [this](http://python-history.blogspot.com/2010/08/why-pythons-integer-division-floors.html) article to be very interesting. I like seing when languages begin to deviate from C, and start doing things proper.
One of your recommended blogs hasn't been updated for *almost 2 years*! Also, in this list naturally some of the best are missing (I'm not saying those listed are not among the best), as the list of Python guru's is fortunately quite long. To stay up to date with the best Python blogs you should read [planet python](http://planet.python.org). Also reddit, of course, and [hackernews](http://news.ycombinator.com/). EDIT: Here's a great example of what I just found on planet python: http://nedbatchelder.com/blog/201110/forelse.html
Mark Summerfield has a nice collection of books. One is PyQt specific, an older C++ version is available online. http://www.qtrac.eu/marksummerfield.html Also, the official Qt dev center has a lot of resources (including videos, conference slides, ...). http://developer.qt.nokia.com/
Essential, but I really wish it wasn't so verbose. It's more of a manual when what I need is a reference. They should at least add a table of contents to module docs.
It's way better to use [Cython](http://cython.org/) for generating wrappers for C libraries; you get the C compiler involved so you don't have to duplicate as much work with regard to cpp macros, struct size/alignment, etc. Plus the syntax is a lot nicer.
The Python Standard Library by Example has recently become a favourite of mine.
I used http://rgruet.free.fr/PQR26/PQR2.6.html quite a lot, unfortunately, it has no 2.7 or 3 info. Especially the list of the included batteries
[requests](http://docs.python-requests.org/en/latest/index.html) seems easier to use
Well, what I wanted to try with this blog post, is showing that using PycURL isn't so hard. I suppose I did not accomplish my goal then. Surely Requests is more "pythonic", but easier? Not so sure about this myself.
I haven't actually used either, so I can't say, but I have used CURL in php. I don't like having to call setopt, hey could at least have written some wrapper functions, or added the ability to set options when creating the object (that would have been more pythonic/easier to read) That having been said, requests isn't as feature rich as pycurl or urllib2 yet.
It is easier to use, sure, if you need a plain ole' HTTP library, but PycURL has features like full support for SSL (which probably is the best and only choice if your app needs to send certified requests), and it's not just HTTP library. It supports a very large list of protocols including ftp, over-ssh protocols, ldap, mailing protocols, etc etc.
True...requests is meant more like a replacement to urllib2
Security is *always* a concern.
I find pycurl to be a pain in the ass to use. It's pretty much identical to the C API, which is pretty much identical to using the `curl` CLI - you set a bunch of options one by one and then say go. Requests is much nicer, but not as feature-complete. 
We use a slightly [modifed](https://bitbucket.org/dec/pycurl) version of pycurl so puts/posts work properly (I think puts are broken in trunk), its a fair bit faster than urllib2 (and requests) especially with SSL - it also has much better auth support =)
it also works much better with threading due to being c code and releasing the GIL
A myriad of spelling mistaks, but not in the code so you get my vote. Consider open-sourcing the project and I'll join up with you, I love me some QT!
I have that book and it's glorious. Please note that Mark Summerfield is a programmer, and as all good programmers have done, he's improved the code on his website, this means that the book can be a little different from the source on his website. If you're interested in PyQT, get this book. WELL WORTH IT.
At the core of every Qt application is proper planning, especially if you're using Qt Designer to aid in the quick creation of certain forms. Planning out in which order you create your various windows goes a long way, since some state and layouts become part of child windows this can create a HUGE annoyance in the middle of a project. After that, careful consideration of what kind of widgets you want will go much further than you think. I.e. do I want a set of radio buttons or a drop down menu to select X information? The idea with QT is mainly that it's nothing explicitly 'hard coded' you're generally creating everything at startup each time, there's nothing stopping you from adding elements with ifs/elses etc etc. If you want something advanced, get Mark Summerfields book on the subject. Extremely deep and helpful! The programs that you write aren't simply to illustrate a point, they're real programs in their own right. In the beginning with Qt, the planning comes down to how well you can extract previous version with your repos ;P The best way to think of 'general' Qt applications is that you have a single MainWindow and everything is a child, or spawns children of that. I generally work backwards from the children, but that's just me. I like to create the children so that I can see what kind of state the MainWindow needs to have in order to operate the child in the way I had in mind. Overall I think Python and Qt's core principles gel extremely well together, it's a very 'Pythonic' (ugh, can't believe I said that!) library that, when wielded correctly, can produce amazing results. Basically, the idea is to use QtDesigner for dialogs, fire and forget windows and anything that you would otherwise be creating for the millionth time. MainWindows and anything with some of the more exotic widgets (QTableView, I'm looking at you) are generally best coded by hand because of their seemingly endless array of options and differences with 'basic' widgets.
A tip to make it easier for us to help: Reddit has built-in code formatting; simply insert four spaces before each line of code. You can use inline code formatting by surrounding your code in backticks (e.g. \`POP3.pass_\` transforms into `POP3.pass_`). For example, I believe your original post should look like this: M = poplib.POP3('pop.myspot.org') M.user('me@myspot.org') '+OK' M.pass_('secret') '+OK Logged in.' Additionally, on the [bottom of the page you linked](http://docs.python.org/library/poplib.html#pop3-example), there's a small example of how to use the `user()`, `pass_()`, and `list()` methods to login and display message info: import getpass, poplib M = poplib.POP3('localhost') M.user(getpass.getuser()) M.pass_(getpass.getpass()) numMessages = len(M.list()[1]) for i in range(numMessages): for j in M.retr(i+1)[1]: print j
The source code for the \*nix utility ["file"](http://en.wikipedia.org/wiki/File_%28command%29) would also be useful in this connection -- it identifies many different file types based on content. 
 import subprocess def guess(name): print subprocess.check_output(['file', name]) :D
Nice "extension". :)
Don't use it on UTF16/32 files.
You're doing OOP wrong. Why don't you put the "draw" method into the shape? As in, circle.draw() will draw a circle, rectangle.draw() will draw a rectangle, using the instance's data. For future reference, however, isinstance does exist. Also take a look at Duck Typing.
You could manually check the object type: if isinstance(shape, Rectange): draw_rect(shape) elif isinstance(shape, Circle): do_circle(shape) or even look up the correct function in a dictionary, but it you should just have each object implement the appropriate drawing method: for shape in shapes: shape.render(canvas) **EDIT:** What [kineticflow](http://www.reddit.com/r/Python/comments/lhopm/to_ask_a_class_a_class_what_it_is/c2srjh4) said. 
I love me some Q**t** even more ;-) ... 
&gt; *you shouldn't care what type of object you have - just whether or not you can do the required action with your object.* Python is all about duck-typing. You're going to have to unlearn some java habits (I know I had to). You should be looking for capabilities, not class-type. Does the object have the property/attribute/method? Or, more commonly, just try to use the capability and catch the exception if it fails. Depending on specifically what you're trying to do...you may want to reconsider your class hierarchy. Instead of doing different stuff depending on the object type, perhaps you should turn that 90 degrees and refactor. Or perhaps a common base method that is overridden for each subtype. A do_Stuff() method that acts differently for each subtype. And, one of my favorites, there is a [common pattern](http://stackoverflow.com/questions/1494442/general-command-pattern-and-command-dispatch-pattern-in-python) used in python that is handy in many cases. You could do something like: class MakingDoing: def do_Rectangle(self, obj): pass def do_Circle(self, obj): pass def do_Triangle(self, obj): pass def dispatch(obj): type_name = type(obj).__name__ method_name = "do_%s" % type_name if hasattr(self, method_name): method = getattr(self, method_name) method(obj) 
Of course not, although the people who use it most likely already know that. It assumes, of course, files are single-byte encoded.
it depends a lot on the specific case, but if you have different types of shapes, and have a draw method for each shape, I'd simply have a class for each shape with that draw method inside, then you can just `shape.draw()` without caring about what kind of shape it is specifically.
Do it the OOP way: # duck typing -- recommended class Rect(object): def do_stuff(self): pass class Circle(object): def do_stuff(self): pass # inheritance -- we don't need that in Python paradies! class Shape(object): def do_stuff(self): pass class Rect(Shape): # no reimplemention class Circle(Shape): # overwriting do_stuff def do_stuff(self): pass # use the types -- works with duck typing and inheritance def make_shape_do_stuff(shape): shape.do_stuff()
But isinstance is concidered a bit non-pythonic and goes against the duck typing idea. shape.draw() can perhaps be better because of that. However, that places some limitations on how I can make the architecture. Having draw functions separate from the rest seems like a good practice. Perhaps not one applicable to python. NOTE: I seemed to have created two identical posts so I deleted this one. Sorry for this :( Edit: Nope, didn't seem to want to stay deleted.
It uses something called libmagic. There are a few libraries floating around that wrap it.
"a single line of code" (paste website word-wraps it onto 64 lines) ಠ_ಠ.
I've tried installing it before but I wasn't able to. I will try again though.
What I responded to [kineticflow](http://www.reddit.com/r/Python/comments/lhopm/to_ask_a_class_a_class_what_it_is/c2ssd2n). Also: &gt; look up the correct function in a dictionary Seems like an interesting approach...
Ha! I had to do this the other day. My solution: p = subprocess.Popen(['file','-bi',path],stdout=subprocess.PIPE) while True: o = p.stdout.readline() if o == '': break #XXX: Motherfucking OSX is a super shitty and not real operating system #XXX: and doesn't do file -bi properly if 'text' in o: # Do your thing here if o == '' and p.poll() != None: break
A cross platform solution is a Python package but I think is hard to distribuite packages to final users. I don't think people will install Python and after that install your game package to play it.
For Windows, you can bundle it up with py2exe to get a self-contained program, or send them the .py file and ask them to install Python themselves to run it. MacOS, Linux, etc. come with Python, so you can just send them the .py file. That assumes no dependencies beyond the standard library. If they have to install dependencies it gets worse.
Your comment, meant I suppose for the future maintainer, is woefully unhelpful. What does "properly" mean? On a Mac, 'file /etc/passwd' returns "regular file" (that's with file version file-5.03) while on FreeBSD (file version 4.23) it returns "text/plain charset=iso-8859-1". I installed version file-5.08 on my Mac and got "text/plain; charset=us-ascii". Using 'file' does not seem like a good cross-platform solution. Your last line, with the second test for o == '', does nothing, as your first line already guarantees o will be non-empty. Instead, try: p = subprocess.Popen(['file','-bi',path],stdout=subprocess.PIPE) out, err = p.communicate() if 'text' in out: # Do your thing here No cussing for unexplained reasons and shorter/cleaner code will make the maintainer's job easier. 
 # we don't give a damn about the object's class... just to be sure try: foo.area() except AttributeError: # oh my ... 
if you only want some attributes... class Bubu(object): attrs = ['foo', 'bar', 'baz'] def __init__(self, **kwargs): for (k, v) in kwargs.items(): if k in self.attrs: setattr(self, k, v) 
This could be a simple extension - sample every second and fourth byte, see how many are 0. But I don't think there are that many UTF16/32 files around.
Sounds like you need to look up XML parsing.
shouldn't the result be '1 - text - foo - 0.43 - value of class C'? 
You may want to look at the BeautifulSoup library: http://www.crummy.com/software/BeautifulSoup/documentation.html It allows you to read an HTML file in Python and easily search and navigate through the HTML structure in your code. Hopefully you will be able to use that to pull out the data you want and reformat it as necessary.
Funnily enough, the `-i` behaviour of OS X's `file` is required by POSIX. BSD `file` is wrong here. OS X `file` does what you want with the `-I` argument, but that's also non-standard and not portable. `python-magic` is probably the portable solution.
because that's not how `or` works. hitmev == "Hit" or "hit" is seen by the interpreter as: (hitmev == "Hit") or "hit" and regardless of what the first half of that expression evaluates to, "hit" always resolves to `True`, so that expression is always `True`. to do what you want, try something like: if hitmev in ["Hit", "hit"]: or better yet, if hitmev.lower() == "hit":
The dictionary lookup may be appropriate if you don't have access to the base shape objects or don't want to 'pollute' them with your custom drawing methods. I was thinking something like this: draw = {Rectangle: custom_draw_lib.draw_rect, Circle: custom_draw_lib.draw_circle, } for shape in shapes: draw[type(shape)](canvas) This lets you separate your drawing logic from your geometry objects.
Could you explain the first one for me, please.
&gt; Every time I use the "pass" statement in a context like this ... It executes the a(). That's not true! Try it. &gt;&gt;&gt; a = "test" &gt;&gt;&gt; b = "test" &gt;&gt;&gt; if a==b: print "matching!" ... else: pass ... matching! &gt;&gt;&gt; b = "derp" &gt;&gt;&gt; if a==b: print "matching!" ... else: pass ... &gt;&gt;&gt; The `pass` isn't your problem, it's the conditions in your if/elif. Also, since `pass` does nothing, why check for `hitmev=="Stay"` at all? Also, since Python doesn't have a switch statement or built-in regex matching (like Perl), just do case-insensitive comparisons to accept a broader range of input capitalization: if hitmev=="Hit" or "hit": Should be: if hitmev.lower() == "hit":
Your problem has nothing to do with `pass`. The `==` and `or` operators just don't work together like that. What you mean to write is: if hitmev == "hit" or hitmev == "Hit": this is usually written as `if hitmev in ("hit", "Hit")` to be more concise. What you tried to write sounds correct when you read it like english, but in python it means something entirely different (this is why we don't program in english). It means if (hitmev == "Hit") or "hit": which returns True if `hitmev == "Hit"` evaluates to True, or if `"hit"` evaluates to True. And since non-empty strings always evaluate to True, your entire condition is always True.
I'd recommend lxml over BS, though I think lxml has a soup-parser.
[http://www.pyinstaller.org/](http://www.pyinstaller.org/) From their site =): PyInstaller is a program that converts (packages) Python programs into stand-alone executables, under Windows, Linux, and Mac OS X. Its main advantages over similar tools are that PyInstaller works with any version of Python since 2.2, it builds smaller executables thanks to transparent compression, it is fully multi-platform, and use the OS support to load the dynamic libraries, thus ensuring full compatibility. The main goal of PyInstaller is to be compatible with 3rd-party packages out-of-the-box. This means that, with PyInstaller, all the required tricks to make external packages work are already integrated within PyInstaller itself so that there is no user intervention required. You'll never be required to look for tricks in wikis and apply custom modification to your files or your setup scripts. As an example, libraries like PyQt, Django or matplotlib are fully supported, without having to handle plugins or external data files manually.
Paste the code as text, not as an image if you want help with it. Do you know CSS3 selectors well enough? Perhaps you can use any of the HTML parsing libraries to build a DOM and use selectors to grab the data you want. Whatever you do, don't use regular expressions.
 if hitmev in ("Hit", "hit"): Sorry for my OCD, but it's supposed to be just a bit faster, so there's no reason to use anything but the tuple notation in this context, so all other notations are distracting_!!_ (btw, in Python 2.7 or 3.2 the preferred method would be `hitmev in {"Hit", "hit"}`, I guess. Oh my.)
Awesome thank you!
I'm curious how other people use Python... like what do you write? Web stuff or apps or something?
Sorry for my OCD, I prefer to follow Guido's motto: "Tuples are for heterogeneous data, lists are for homogeneous data.". I suppose for Python 3, you could also say: "sets are for unordered homogeneous data". So in this case, a set would be preferred, semantically.
You'd still have to check the byte order mark, because you'd have to know whether it was little-endian or big-endian to know whether to ignore odd bytes or even bytes. And even then, the file could be a completely legitimate text file written in a non-Western language and it would register as binary. To really do this right requires a much more extensive treatment. 
Can't recommend PyInstaller enough. When you progress on to Pygame and PyOpenGL you'll be happy to know that it not only works great with them, that it's way nicer than Py2exe is with PyOpenGL.
Pylons/Pyramid is awesome!
Although it probably is possible for the input to be 'hiT' or 'hIT' as well, so the use of lower is probably the better option.
Not really. For most scientific/HPC purposes, any unnecessary copying of data is basically fatal for performance, so when I wrote "transmission", it implied a copy-free passing of data by passing a pointer. If you consider encoding and copying of data to be the same sort of transmission, then Python byte arrays (aka strings in Python2) are a lingua franca for everybody! 
&gt; While I agree with this article, it's title should be "NumPy isn't just about fast arrays," Noted, and fixed.
I've posted a follow-up: http://blog.streamitive.com/2011/10/19/more-thoughts-on-arrays-in-pypy/
MintyPhoenix, I appreciate the tips and I will definitely use them. Thanks!
When I wrote a distributed henon curve generator recently the returned numpy arrays were collated then converted to an image using exactly this functionality on the master node. I can see what you wrote, I now see what you actually meant, I still don't necessarily agree. However I think I can sum up our arguments as: To me mandarins are orange, to you bananas are yellow...
you are technically right (the best kind of right!). A set fits best semantically (for python 2 as well, I'd say). Still, I think it's idiomatic and common to use a tuple here.
It takes more time to create a set or list object compared to a tuple.
because they have the same functionality, but the inheritance way has a Shape class that is essentially without purpose. Its draw method does nothing and it has no other methods or data that squares and circles have in common. The only thing it allows you to do is make isinstance(x, Shape) work for both Rects and Circles, but isinstance is one of the things we were trying to get rid of here!
most of old-fashioned python bindings are thin C-wrappers. 
&gt; Use compressed data directly **in RAM** from ZIP files or gzip http response FTFY
I like that Monty Python Silly Walk by Cleese
 hitmev in {"hit", "Hit"} I'm not sure if you mean ['Hit', 'hit'] because that's an invalid dictionary. the if foo in some_list: method works fine, but why not just use if hitmev.lower() = 'hit': # do stuff
Yeah, but it's a little harder to do things that are simple in bash, like invoking processes and chaining them together with pipes. Of course anything you can do in one, you can do in the other, but they have different strengths. The best bet for Python is to find a tool or module that makes shell scripting easier. For example, check out [Fabric](http://docs.fabfile.org/en/1.2.2/index.html), which gives you some useful primitives for running programs (locally and remotely via ssh). I also find that once a shell script gets beyond 50 lines or so, I start to want a more structured programming language. At that point, I'm willing to pay the overhead of working within Python's instructions in order to get modules, classes, lists, first class functions, etc.
Depends on the context really. They'd probably be fine with Python knowledge, but they may have a bunch of existing shell scripts that need maintenance. Of course, knowing Python should allow you to learn shell scripting pretty quickly. I would apply either way. Frankly, a lot of jobs (i.e. sysadmin) say that shell scripting is a requirement, but then you walk onsite and nobody knows shit about shit, so Python skills would be a huge step up.
It definitely can. For example, I made this small thing for shell-style process scripting with python: https://gist.github.com/1300342 Basically, it creates a Pipeline class you can use this way: p = Pipeline() | "ls -s" | "sort -n" print p.run()
sorry, the formatting on that isn't correct. the first line should also be in the "code text" or whatever.
shoulda said "one expression" rather than line.
 $ chsh Password: Changing the login shell for user Enter the new value, or press ENTER for the default Login Shell [/bin/bash]: /bin/python chsh: /bin/python is an invalid shell. Oh well, I tried ;-) Edit: A google search reveals a few interesting projects to try out now: [IPython](http://ipython.org/), [PyShell](http://sourceforge.net/projects/pyshell/), and [pysh](http://pysh.sourceforge.net/)
 import string for identifier, question in zip(string.ascii_uppercase, questions): # do your stuff here...
Edit the post and put 4 spaces before the line.
thanks
Found it: [http://build-its.blogspot.com/2011/03/doodle4google-entry.html](http://build-its.blogspot.com/2011/03/doodle4google-entry.html) And from the blog: &gt;My entry to this year's Doodle4Google contest. The drawing was created in Photoshop, and the fragments of code come from a python program I wrote that simulates predator and prey cells, which can replicate, mutate and hunt each other down. If you check carefully enough and are Google-savvy enough, you may find some surprises!" A little disappointing :( Still, it was worth visiting this thread for gaiaap's code!
I can't wait for its py3k support.
urllib3 is nice, it can reuse same connection for sending multiple requests. This makes it much faster than the standard urllib2
&gt;works with any version of Python since 2.2 Their website says it doesn't support 3
bash has its place.
you have to add it to /etc/shells 
&gt; for jobs that ask for shell scripting skill, can Python be considered an "equivalent" ? There is a reason bash shell scripts exist -- they run in a very small environment with limited resources. I doubt that shell scripting of the classic kind will disappear overnight, but certainly there is a place for Python scripting for a system that is fully operational and has adequate resources. &gt; I ask because in my field I see far more asking for shell-scripting and almost no mention of Python. The answer depends on the phase of the computer's operation. If the computer needs scripting while it is booting up, or for a limited-resource environment, a Python script might demand too much for the circumstances. 
Add the first letter of the series to the index. a = ['this','is','a','test'] for i,s in enumerate(a): print '%s %s' % (chr(ord('a') + i),s) ........... a this b is c a d test 
They're quite different. I wouldn't call them equivalent. But Python is the more complex of the two, so if you know it, you can probably learn shell easily (although it has a lot of idiosyncrasies that you'll spend forever learning).
Not now, not until I can easily change environment with Python script. Like: source myEnvFile.env
We don't need inheritance for achieving polymorphism in this case. In static-typed languages like Java you would need to use inheritance or interfaces. That doesn't mean it's useless at all. You can use inheritance to reuse methods and attributes, which are independent of the specialisation of child-classes, e.g.: class Shape(object): def translate(self, delta_x, delta_y): # ... class Rect(Shape): # translate method available class Circle(Shape): # translate method available So, in the context of polymorphism, duck-typing works fine. For code reuse inheritance is one (not the only) good option (besides composition).
If you have more questions, or need some more in depth explanations of some really great Python tutors, look at the python tutor list http://mail.python.org/mailman/listinfo/tutor. 
FYI, CherryPy 3.2.2 has been released ;)
Exactly. Until python's linux version hell is fully resolved, you can use python as a fully operational shell, and python retains all core functionality without needing any kernel modules loaded, it will not be "equivalent" to the commonly used shells. Until then there are plenty of reasons to use a structured development environment, but the simplest and largest subset of my problems will arguably be more appropriately solved with bash. Frankly, I must disclose I am a linux admin, not a software engineer, and I would have more fun solving the remaining subset with perl, because I have always been more of a fan of dropping a bomb on my problems than by doing what would be considered "correct" to developers. I do not "develop", I glue other people's shit together to make problems go away.
`{"hit", "Hit"}` is a shorthand for `set(['hit', 'Hit'])` in newer versions of python.
It depends on the job you're currently accomplishing using shell-scripting. Is it data processing? You can probably do it better in python with tools like [Numpy](http://numpy.scipy.org/) or [pandas](http://pandas.sourceforge.net/). Is it scripting servers? [Fabric](http://docs.fabfile.org/en/1.2.2/index.html) is a great replacement. What field are you in?
I've left a bug in here, as this sounds suspiciously like homework. That said, something like this will give you an unlimited enumeration (like enumerate), while the other solutions so far limit you to a finite enumeration. You choose your prefixes by setting enum to an indexable sequence of the prefixes you want to use. Wouldn't work well with roman numerals, however. edit: typo in code tag def alpha_enum(iter): enums = string.ascii_lowercase modulo = len(enums) for idx, item in enumerate(iter): idcs = [] while True: idx, r = divmod(idx, modulo) idcs.insert(0,r) if idx &lt;= modulo: if idx: idcs.insert(0, idx-1) break yield ''.join(enums[x] for x in idcs), item
That's definitely unfortunate if it's still true. However a lot of people are still stuck on 2.x for various reasons anyway, especially people using Python for games. For example, I'm still waiting for the seemingly abandoned PIL or a workable replacement to show up. Even pygame still recommends 2.5. I'm not sure if basic PyOpenGL works for 3.x but I'm pretty sure its accelerator module doesn't yet.
I just can't upvote this enough.
TIL. :)
&gt;Could you explain the first one for me, please. Sure! The `*a` specifies that `a` is a wildcard argument; it represents any number of arguments, including zero. It is presented internally to the function as a tuple - you can see this by running def wildcard(*w): print w &gt;&gt; wildcard('foo','bar') ("foo", "bar) &gt;&gt; wildcard('foo') ("foo",) &gt;&gt; wildcard() () Okay, so now that's sorted, we look at the `not a`. Specifying '`not`' means that it will be interpreted as a `bool` - that is, `not something` implies `not bool(something)` (duck/implicit typing). So what's the boolean of a tuple (or list, or in fact, any iterable)\*? Well, it's whether or not the iterable is non-empty - that is, `bool(mytuple)` is equivalent to if len(mytuple) != 0: return True else: return False Now we have, for example, `[b,c][True]` (or `[b,c][False]`). Duck/implicit typing comes back into play here - because it is an index, `True`/`False` must be interpreted as integers. And since `int(True)` -&gt; 1 and `int(False)` -&gt; 0, we have either `[b,c][0]` (which is of course `b`) or `[b,c][1]` (which is `c`). So to expand, the process is lambda *a:[b,c][int(not bool(a))] Or, in full: def tricky(*a): if len(a) == 0: return c # 'not' inverts result else: return b It is also equivalent to lambda *a: b if len(a) != 0 else c (However, older versions of python do not allow this syntax for lambdas!) This is why I think it is a good piece of "tricky" Python code - it invokes the implicit typing not once, but twice, all in one fell swoop. PS. The `not` could be replaced by `bool()` - but, by swapping the order of `b` and `c`, you can get exactly the same result (and it obfuscates it a little more, which is useful given the topic ;)). # \* Specifically, the boolean value of an object (`myobject`) is determined by (in this order); 1. If `myobject` defines `__bool__`, return the result of `myobject.__bool__() != 0` 2. If `myobject` defines `__len__` (as any iterable should/will), return whether or not the result of `__len__` is non-zero. 3. If `myobject` defines neither, return `True`.
There is some other problem with your code. temp = "" counter = 0 while counter &lt; 10: temp = "%s %d" % (temp, counter) counter+=1 print temp Output: 0 1 2 3 4 5 6 7 8 9 Perhaps line_2 is a list of blank strings?
make sure that you are getting a value for answer as there's no reason that temp should be empty. I suspect you've got something wrong with what ever you're using to populate your line_2 list.
FYI, python 2.7 also introduce dictionary comprehensions (backported from python 3) which are pretty cool too. &gt;&gt;&gt; {x: x*x for x in range(6)} {0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25}
I wrote a scraper for my own use, and used PyCurl and LXML for speed and reliability. I'd say that whilst PyCurl is a bit grungy as a thin wrapper, its performance and maturity make it a great option for HTTP. Also I'm reasonably used to C so that didn't bother me so much. I tacked on some REST stuff, which I could probably have done with urllib2, but having gotten used to PyCurl I opted for this instead. https://github.com/ahri/pycurlbrowser -- it's grown a little with my own usage, but I've consistently used it over the past 6 months and is now somewhat of a go-to that I use in other projects :) I'm more than happy to take comments. I know it's a little bit nasty faking the user agent and not following robots.txt, but like I said; it's a scraper first and foremost, and pretending otherwise with "nice" defaults seems a bit misleading, not to mention requiring boilerplate every time I use it as a scraper!
If you have to do plenty of sysadmin tasks you should consider perl for the job. I found perl to be perfect to small to medium scripts in a sysadmin enviroment and you can find libraries for just about everything in the CPAN. Python can do the same, of course, but it is not as "shell-ish" , does not have such a big library and all those nifty shortcuts.
I wrote this module [extproc](https://github.com/aht/extproc) to make python do those shellish things easy: * Fork-exec commands, wait or no wait * Capture stdout/stderr of children (command substitution) * I/O redirections * Construct pipelines Alpha stage, but check it out!
it certainly can. i've never written shell scripts. the moment i need to do something with more than three or four pipes, i bring up vim and start writing python
A python script takes a long time to start up in comparison to a bash script. For small scripts, the delay is a bit nagging.
I use [pexpect](http://www.noah.org/wiki/pexpect) to do some advanced scripting of scientific programs that I use. I found that it was the easiest to use when you need to recover information that the program sends to the terminal. It's simple and intuitive, but might not be powerful enough if you need to do things remotely (not sure if it handles that).
This. You should always convert user data to a known format before using it. A simple method is string.lower(), this is annoying when using anything other than 8-Bit strings but should get by if you're just using raw_input() YMMV.
But sometimes you want to do_stuff to multiplee different types in very similar but still mostly non-overlapping ways. I'm thinking about what the visitor pattern is doing for example. It sometimes makes sense to not have the do_stuff methods in the classes but in a separate module. Perhaps one, slightly ugly way of doing it, would be to create the do_stuff methods in a separate module and load them onto the classes when running. Also, there seems to be other advantages of keeping render methods (for example) separate from the classes themselves. Protability is one. I can't think of others at the moment.
The difficulty of distributing Python applications is somewhat exaggerated. For a simple one go with PyInstaller. It's as easy as pointing it to your .py file and hitting go.
[cx_Freeze](http://cx-freeze.sourceforge.net/) is the only one of the big three bundling tools with Python 3 support. There's [a ticket](http://www.pyinstaller.org/ticket/85) open for PyInstaller, but it doesn't look like anyone's working on it.
Let me help you :)
[This site](http://www.lfd.uci.edu/~gohlke/pythonlibs/#pil) claims to have source code and Windows installers for PIL under Python 3, although I haven't tried it.
I don't think it can replace it, but it can surely complement it nicely. For very simple tasks, chaining two or three commands with a pipe and being smart about which command you use, I don't think Python can beat the shell: there will be more to write in Python (or more to import), and it will not run as fast. In such cases, the startup time is very important. On the other hand, for slightly more complex scripting, notably as soon as you feel the need for a function, or as soon as you need to handle options and logging in a significant way, Python is much better.
Oh. My. Shit. That is awesome.
As noted elsewhere, `temp` should have the same scoping inside and outside of the `while` loop, so there's no need to "move" it. The error is elsewhere in your code. On a different note, I hope this is a homework assignment. There's no good reason to use a `while` loop for simple iteration like this in a real Python program. It's also (sometimes) inefficient to append strings in loop like this, so it's not considered a best practice. What are you trying to do?
Googling the quote yields a lot of different opinions, including [this one](http://code.activestate.com/lists/python-list/326654/) of Tim Peters. Problem is, if you really have a collection of heterogeneous data, you should use a class for that.
My first response is... "Who the hell cares?" Honestly though.. why does this module matter?
Interesting, both Python 2.7 and 3.1: 1. store the tuple as a constant, that is, build it during compilation. 2. store the list as a constant _tuple_, lol. 3. construct the set for every call of the function. So tuple it is, even in py3k!
For small scripts, would you even notice?
&gt; python's linux version hell What is this?
I have written a custom SOAP class for the Salesforce API for data dumps and replication using PyCurl and LXML and main reason was performance and reliability( I needed to be able to dump 500000 lines of data, about 1GB of XML!) The pythonic HTTP and Salesforce libs lacked gzip compression and were much too slow for large datasets using SOAP 
The short answer is NO.
Check out envoy for subprocessing.
Lots of different versions of python having to be installed due to stupid old programs.
That's interesting, but I think that is an abuse of syntax; it looks very not pythonic to me. Why can't you just run bash with the pipe expression as a parameter?
Depends on the job, you would have to ask if they want just scripting experience or specifically bash. 
Actually this is for work. List_2 is a line that I read from a file and looks something like this: 48**00**45**00**4C**00**50**00** I was trying get the first 2 digits (48), save it to temp, skip the next two, get the next two and save it to temp, etc... I want my final output to be 48454C50 I am new to python, should I be using a for loop instead? Thanks 
That sounds like fun. Thanks for the explanation! :)
I would have preferred the syntax p = Pipeline() print p.run("ls -l").run("sort -n") 
It can of course (heck, so can Java, if you really wanted to...) but I think Perl is better suited for it.
Doesn't subprocess.Popen accept a command string with pipes in it? Why not use it like that? Simpler that spawning all processes manually.
If you execute them often, maybe.
From my understanding of programming history (in a nutshell). First there was Thompson Shell, with no scripting at all. Then sh was born and added the ability to write scripts. Scripting made life easier, but it still wasn't powerful enough, so bash was born. Everyone loved bash, (some love zsh), but they needed an easier way to write complex scripts without resorting compiled languages like c. So perl was born. Perl is great, but it can become a tangled mess of cryptic looking code. So Python was invented to be developer friendly and easy to read. The Japanese felt like they needed to invent something, so they copied Python and called it Ruby. (Kidding!)
Can we stop upvoting comments like this? It adds nothing of value. Edit: the parent was at +8 when I made this comment.
 line_2 = '480045004C005000' temp = '' for i in range(0,len(line_2),4): temp += line_2[i:i+2] print temp output&gt; "48454C50" This will accomplish what you're trying to do. *range(0,len(line_2),4)* gives you a list of integers, 4 values apart, from 0 to the length of *line_2*. In this case it will be *[0, 4, 8, 12]*, and the for-loop iterates over these values. *temp += line_2[i:i+2]* is short hand for *temp = temp + line[i:i+2]* *line_2[i:i+2]* takes the substring/slice of *line_2* from *i* to *i+2* (not including the *i+2*th character). A more pythonic version would maybe be something like this: line_2 = '480045004C5000' print "".join([line_2[i:i+2] for i in range(0,len(line_2),4)]) output&gt; "48454C50" Which uses list comprehensions and the *&lt;separator string&gt;.join(&lt;list&gt;)*-function. Links: * [The range()-function](http://docs.python.org/tutorial/controlflow.html#the-range-function) * [Strings (scroll down for slice-notation)](http://docs.python.org/tutorial/introduction.html#strings) * [List comprehension](http://docs.python.org/tutorial/datastructures.html#list-comprehensions) 
Try this: List_2 = '480045004C005000' ''.join(List_2.split('00')) # outputs '48454C50'
I'm interested in a longer answer, if it's not in all caps. I like Python for this because it makes all the complexity explicit. It takes at least a decade to be a competent shell programmer, because of all the hidden problems one has to account for in every keystroke.
 import personal import os os.environ.update(personal.environment)
If you're willing to run a shell to interpret the pipes, you're not programming in Python any more, AND, you probably have bugs.
Yeah, unless it runs out of characters and starts displaying random ASCII.
I don't trust spaces to delimit my commands. I hope that takes ["arrays", "of", "args", "to", "syscall execv"].
It's not as causal as that. Take out two or three leading "So"s, and it's right.
Very clear explanation, thanks! Is there a real-world scenario where this kind of construct would be usefull? 
Not if you compile them to C++ with [shedskin](http://code.google.com/p/shedskin/).
It doesn't seem bad. Their HF Programming uses Python as well. I have PDFs of both if you know of a place I could upload them you could check them out to see if you want to buy either of them.
Any high level language could replace shell scripting, but it obviously hasn't happened. Shell scripting is still useful because it emulates closely interactive shell sessions. For people that do their work from the shell, this is just natural. 
Fabric does not yet support Python 3?
Thank you! is working great now.
Simply a matter of speed, at least for me. I know shell scripts/commands can be a bit daunting but the basic usage is pretty simple and the surprising thing is that shell commands can be shorter than equivalent language X code.
The slightly longer answer (by one letter): YES.
&gt; If you're willing to run a shell to interpret the pipes, you're not programming in Python any more fmoralesc code hands over the work to the shell too. &gt; AND, you probably have bugs. Why? Spawning all the processes yourself, redirecting stdout to stdin along the way, etc. seems more error prone than to hand it over to the shell completely. The output is supposed to be the same, after all. Namely, the output of the last process in the pipeline.
Program number three in your pipeline took a filename parameter with a space and an ampersand in it but your shell ate those, and the fourth emitted to stderr, and the parameter substitution in the first should have been "$*", with quotes and everything, but you forgot those and you got a different interpretation. The fourth, because it got bad input, also screwed up your terminal's line discipline, which you'll need to fix with "stty sane" before you can even figure out what the problem was. Sadly, that also ate the error messages. Don't get me wrong, I use the shell all day, every day, and have since 1995 or so. It's a terrible programming interface, though, and almost impossible to get right the first dozen time you run the program. At least Python, with its verbosity, also gets the problems out in the open with its explicit nature.
People apparently need to have other people see that they agree with someone. Upvoting gives no satisfaction, I guess. I was in another thread and a guy just replied to a comment he liked with "^", which is basically as close to just clicking the damn arrow as you can get. It blows my mind. 
I read the whole thing. It's alright, but the Learning Python and Programming Python (Mark Lutz, I believe) are way better. 
Run it :) {1} refers to the second argument, b, and {0} to the first, a, so it is 'text - 1 - foo - 0.43 - value of class C'. I tried to show a few different ways to refer to the arguments of str.format(): by order, by name (in case of keyword arguments), or a property of an argument.
PyInstaller creates an .exe file?
It's a good book. I enjoy the approach of the Head First series
&gt; Popen(shlex.split(self.steps[0]), stdout=PIPE) No shell there, strictly speaking. Not much better, though.
Soon, requests will be powered by urllib3 actually :)
Technically str.join takes any iterable that consists of strings. 
I just finished Head First Design Patterns, and it kicked ass. They make it easy to absorb large amounts of complex material.
I'm embarrassed to say that I have scripts that do things like this (and I bet I am not alone curl "http://url/$1/$2/$3" -o tempfile.xml stageproc.py tempfile.xml out load.py -c config.qc -db qc -s qcallo -t ivstage out Clearly this script is just an unwritten program. If I extract the objects out of the two scripts and dump curl I can have a quicker and nicer script. 
it is very non threatening, this is the book I started with that got me really going with programming in general. The explanations in some points were pretty lacking. I.E. "Just use this, it doesn't matter why or what it is right now" but it got me comfortable with typing code and seeing code, so that I was able to move on to other books and real projects.
this is good stuff thanks !
Yes, it is an abuse of the syntax.
You could simply extend the Pipelines.steps list if you wanted.
If the script has any kind of complicated logic in a continuing loop, python will still be faster, in my experience. Python is more performant when it comes to computation.
Right but in your formatting you have .format( a,b, 0.43, C, x='foo' ) which leads me to believe that you're going to see a before b (due to formatting).. so a = {1} and b = {0}, even though they come in opposite via code. 
The difference is suprisingly (for me at least) significant. In [74]: %timeit (1,2) 10000000 loops, best of 3: 21 ns per loop In [75]: %timeit [1,2] 10000000 loops, best of 3: 130 ns per loop I used low integers instead of strings as they are just constants and no additional objects are created (so there should be little to no overhead). 
I like this book, Programming in Python 3: a Complete Introduction to Python Programming. http://www.qtrac.eu/py3book.html First 100-150 pages cover python the rest of the book are base examples built up on various included modules. My other suggestion would be to buy two books: Quick Python (or Lutz's book) and Hellman's Python Standard Library Book 
No. And before you downvote, pay attention. I routinely work in an environment with nearly 1000 *nix servers. They come from many vendors, represent multiple OSs derivatives, and, most importantly, have a wide range of software releases on them. Some of the older ones only have python 1.x running. In that context: 1) You cannot just upgrade python to some common version everwhere. Big shops will not typically install something newer than what the vendor will support for a given release of OS. 2) Even bash isn't a given in a big environment like this. 3) The only way you get script portability is by writing for /bin/sh. 4) Python is a heavyweight solution relative to the shell, or even awk. This may not seem like a big deal until you need to run scripts on a machine that is already very, very busy with no headroom left. So ... no, python is not going to replace Unix shell scripting. Nothing is. I'd venture to say that 40 years from now, engineers will still be using sh, awk, and sed, but that perl will mostly have been displaced by some more modern dynamic language like python or a python derivative. P.S. If you really understand the gestalt of python, you'll understand that it is not really a scripting language ... it's a full fledged programming language.
Yes.
good to know. I was feeling stupid for finding this code so complex.
Yes...but. Sometimes it is just quicker to hack out a BASH script on the spot (at least for me).
Perl is portable, and unlike Python, I can't think of a single *nix environment under active support that doesn't ship with Perl. Hell, even HP-UX does.
what's wrong with p.run("ls -l | sort -n") ? 
It is nice to know you can do stuff like this though (that's the reason I wrote it this way... I vaguely remembered you can define the behavior for when an object is put in a chain like A | B, so I checked that out. It was just a test code for something else, which in the end didn't use the "|" syntax at all).
[These](http://www.e-booksdirectory.com/programming.php#python) might be worth checking out before you buy.
I am reading this right now: http://openbookproject.net/thinkcs/python/english2e/ So far, it's great. I have zero programming language knowledge and it's working me through the concepts and application of those concepts quite well. I want to check out the Head First series as I've heard good things as well.
Perl isn't remotely portable because to do anything with it requires and endless supply of non-default packages/libraries. I rarely have to do this with Python. Moreover, pretty much every "*nix environment under active support" also ships with python. There's a reason python has eclipsed perl in popularity and is growning. Perl solved a set of problems for its time. Its time is now mostly over and what you will see is a gradual sunsetting of perl. It will never go away completely - nothing every does in this business - but perl is definitely NOT the wave of the future.
&gt; i've never written shell scripts. The voice of experience.
The think I liked most about Head First Python was that it gave you the resources to develop a "real world" python app. It's a great book if you already know some python and want to know what you can do with it. By then end, you will have written webapps that run on Google App Engine and the Android platform. Get the basics of the language from [Dive Into Python](http://www.diveintopython.net/), then take it to the next level with Head First Python.
you can also use a generator that yields like A, B, ..., Z, AA, AB,.. like this, so you can numerate lists which len&gt;26: def alphagen(): for i in itertools.count(1): for j in itertools.product(string.ascii_uppercase, repeat=i): yield "".join(j) for i, v in zip(alphagen, questions): pass 
I'm not saying Perl is the wave of the future, nor that Python won't replace it, but "available" and "ships with" are two different things. HP-UX and AIX ship with Perl, but not Python (it's a depot or RPM, depending). It's a required package on Debian. Anything more than @base on RHEL will install it. Not that Perl is good or bad, necessarily, but it works. And yes, you can write scripts against sh, but you're sacrificing utility for "portability" that Perl already gets you, unless you really like coding in a language with virtually no support for anything (associative arrays, hashes, regexes that don't suck, etc). Python is batteries included. Perl isn't. But you don't *need* the CPAN or modules from it to make Perl curbstomp /bin/sh.
To be fair, cPython implementation can be made about 20% faster by using map functionality and avoiding the looping over indexes. def test2(): N = 2**16 y = [sin(ii * pi/4.) for ii in xrange(N)] x = [sin(ii * pi/1333.) for ii in xrange(N)] t = [xi*yi for xi,yi in zip(x,y)] tsum = 0 for ti in t: tsum += ti
no, i just knew python before i moved to linux. i can do everything i want in python, so i never learnt to shell script. seriously, can you give me a good reason to bash script when you have python?
Speed when processing large logs files. 
No way, man... Perl v5.54 FTW!
Looking forward to trying out the flashcard game.
&gt; It takes at least a decade to be a competent shell programmer, because of all the hidden problems one has to account for in every keystroke. Not true. You'll get out of it what you're willing to put into it.
If shell scripting is a common requirement for jobs in your field, you would be better off learning some shell scripting, than *hoping* that somebody accepts Python as a substitute.
Yes, true -- this method can't display more indices than there are letters. Unlike using integers, which (according to some well-tested mathematical theories) are infinite. 
Learning Python and Programming Python are basically the de-facto books for Python. They are above anything else out there imho.
Nice. I'm excited about BrowserID and hope that UI for it shows up in Firefox soon. 
All very well taken points. I was more focused on the OP's original question though - will shell programming be displaced by &lt;something else&gt;... I have to say though, after switching to python for most everything that doesn't absolutely need C, trying to write in perl again hurts my head. 
communicating between applications is a nightmare in python compared to bash. 
I'm really interested about BrowserID although the information on it seems pretty limited. And they also mention that it is more complicated to set up a private BrowserID server. Also important to note is that their implementation of BrowserID server is in Node.js.
Yes, all file storage in iOS is sandboxed. iTunes file sharing, "Open in" and interfaces to cloud services like DropBox are the only choices for getting files into and out of iOS apps. I think you can get pretty much any file type into Python Math using iTunes file sharing, but I've only tested .txt files. Adding a DropBox interface is on the PythonMath roadmap, but is currently lower priority than a built-in script editor and numpy/scipy. As the PythonMath developer, I'd be very interested in hearing whether those are the right priorities.
The answer is yes. I use it on a daily basis in a large cluster-computing environment, and I'm not the only one. The basic rule of the jungle is this: If you can get away with doing it in a bash script, do it. However, most of the 'fun' things you're tasked to do on a day-to-day basis will require either python or perl.
Numpy/scipy/matplotlib are on the roadmap. The big roadblock is cross-compiling FORTRAN to iOS and ARM processor. I've tried using f2c, but haven't had any success yet. Next I will try fort77.
Shell scripting *should have* been displaced by Perl, and it *should be* displaced by Python, Ruby, Lua, Node.js, or something else which isn't terrible, but it probably won't be. Writing in Perl hurts my head, but not as much as admins (I'm also an admin) who replace shell with Python and end up with 1000 lines of "python" with no methods, no classes, etc.
well, the goal is to have email providers run their own BrowserID servers as primaries. They're talking to other browser makers and want to have one secondary server per browser, I think. 
I agree. Then again, you have to ask, if an admin tool requires thousands of lines of anything ... are we solving the problem properly?
On Python 2, there could be a further speedup if you use itertools.izip. In Python 3, zip works that way already.
Yes, they changed the rule. iLuaBox was already on the store when I started work on PythonMath. Nonetheless, I was unsure whether they would accept it or not, especially if it had a full Python module library. That and the fact that I was really trying to build a "poor man's matlab" is why PythonMath has such a severely restricted set of modules.
Probably not, but it depends on the problem you're trying to solve.
Great. I've been following the Javascript Weekly and HTML5 Weekly, but never crossed my mind the idea to google a Python equivalent.
Good call. One can also use the built in sum() function instead of the last for loop. Finally it should look like this. It is 35% faster than the one in the blog post. def test2(): N = 2**16 y = [sin(ii * pi/4.) for ii in xrange(N)] x = [sin(ii * pi/1333.) for ii in xrange(N)] t = [xi*yi for xi,yi in izip(x,y)] tsum = sum(t)
Fwiw, this book is responsible for the [numerous "simple printer of nested list" packages](http://mail.python.org/pipermail/catalog-sig/2011-March/003515.html) on pypi. No clue if it's any good. I learned python (quite some time ago) with Martelli's *Python in a Nutshell*, but I'm not sure when it was updated or how relevant it is today.
[Practical Programming: An Introduction to Computer Science Using Python](http://www.amazon.com/Practical-Programming-Introduction-Pragmatic-Programmers/dp/1934356271?tag=duckduckgo-d-20) This book is awesome.
Depends. * If you have to support the code of most other sysadmins, then no - need to know what's most common - shell. * If you have to support many unixes, esp. older ones, then no - you'll need to know something on all servers - shell. * Otherwise, a mix of both is best: shell for quick &amp; tiny stuff, and python for anything more likely to be reused or complex. In my day job we knock together quick hacks in bash then migrate them to python if they look worth keeping. Python gives us far better reusability &amp; manageability. Current favorite tool of mine includes &amp; excludes sets of rows &amp; columns from a csv file using python slicing syntax: $ gristle_slicer.py -f us_state_crime.csv --records 5:15 --exrecords 10:12 --columns 0:5 --excolumns 2 It just sucks to do that with awk &amp; bash.
In fact, we can improve that a bit more, using generator expressions to avoid generating those big lists: def test2(): N = 2**16 y = (sin(ii * pi/4.) for ii in xrange(N)) x = (sin(ii * pi/1333.) for ii in xrange(N)) t = (xi*yi for xi,yi in izip(x,y)) tsum = sum(t) With this, it takes about half the time of the original version on the blog post.
You can logically extend that to os.system("ls -l | sort -n") and now you have no non-stdlib dependencies!
Funny. Generator version runs tad bit slower for me both on Python 2.7 and 3.2
 import os os.system("yes") Jokes aside, you can do most anything you want to do in shell from Python. But there are reasons you might need to do one or the other. I think "equivalent" might be wrong. "Complementary" is more accurate -- if you work in a Linux/UNIX environment, you should learn shell scripting no matter what your language of choice is. I do find when working in shell that there are certain operation that just suck to deal with. For example, any time you iterate over a list of items in shell in a general purpose piece of code you potentially have to worry about a variety of (sometimes odd) corner cases. And I hope you never get into a problem with shell quoting. On the other hand, a few lines of shell can be enormously, powerfully expressive in ways that few other languages can. A moderately complex pipeline can effectively multiprocess and slice and dice a data stream in a single succinct statement where it could takes dozens of lines in Python (or other languages) to accomplish the same effects. So, yeah, learn both. But if you already know Python, shell shouldn't be much of a challenge.
Create a standard local install of python, distinct from the OS. Distribute it to all your servers. Problem solved.
Isn't os.system deprecated in favor of subprocess?
I would add that there is no reason people shouldn't learn shell scripting. If you get good at shell, it'll probably only improve your python programming.
Most recently, I had to write a script that downloaded large (gigabyte+) log files, put them into a temp directory, did some minor text processing on them, and push them out to individual directories based on what times the logs covered. Unix-like environments already have ridiculously robust tools to do all of this. Just pipe one tool to another, and it's like four commands by the time you're done. For example, coming up with a way to efficiently retry a failed partial download in python becomes a half a day's worth of work. wget does this already. Want to do search and replace? sed is going to be faster than a python app can hope to be. What works amazingly well at moving things around a file system? mv. Want to recursively upload/download a directory's contents in a ridiculously efficient manner? rsync. All of these utilities are going to be faster, easier, and less prone to errors than rolling your own. Plus you don't have to even think about what version of python is going to be on some other system that this is running on.
In a sense, yes.
That's not how big shops work. Nothing gets installed unless it is supported by a vendor. *That's* why RedHat even has a business. No one is buying Linux from them, they're buying support. Also, it is questionable just how well one could make python work on very old/out of date OS/Hardware instances.
If you want a web framework with lots of stuff built in, Django is a good way to go. It has [good documentation](https://docs.djangoproject.com/en/1.3/) as well. There are some good Python tutorials around if you want to get a bit more insight into how Python works. It sounds like you're having a bit of trouble with classes: class A(object): def __init__(self, foo) self.foo = foo def sayfoo(self): print self.foo a = A("hi there") a.sayfoo() Every method you define for the class has "self" as the first parameter. When you call a method, that's automatically filled in with the instance you're calling it on. The __init__ method is called when you create an instance of the class. You can pass any arguments you want just by calling the class. Like other methods, it has "self" as a reference to the new instance. __name__ has a couple of different uses, but the most common is: if __name__ == "__main__": do_things() If you run the script from a command line, __name__ is set to "__main__". If you import it from another Python file, __name__ is set to the name of this module (i.e. its filename, without the ".py"). So this just protects something which you don't want to happen if you import the file. As for string formatting, .format() is the newer, more flexible system. The % formatting is older and simpler (it's kind of deprecated, but still very widely used, so I don't expect it to go away).
Ok, I see your point. I wrote it that way on purpose to show a way it is more flexible than older % formatting: arguments can be used out of order in the string.
I've worked in big shops. I've worked with big shops. What you say is patently false.
I think a script editor would be a great help, but I was going to look at Editor for iPad that seems to do Python script editing. I think Matplotlib would be more welcome, though perhaps more challenging. I think, for you, in app purchases are also a good idea. I don't mind paying a few bucks (at 99¢ a pop) to get just the modules I need. 
Was going to recommend Django too. 
(Disclaimer: More questions :( )Classes as in OOP style programming? :/ not my strong point in general programming reading. Never found that one document that you find that makes the thing your looking for just click. I guess everyone has those moments :D How do they differ from functions? Is a class a way to wrap up multiple functions? And great dude! Perfect advice. Is Django just a framework? Would/Could i still use CherryPy as the http server? And should i completely ditch bottle? I found it interesting and easy to create a very basic static site which offers nice features like the dynamic url calls and i generally like it. The lack of documentation is a killer, it seemed great upon general searching but after scouring the site i felt like there was something missing. Like i'd skipped a whole section of in depth documentation. I blame a lot (99%) of it on my basic python knowledge, i've got a lot to learn. :) Thanks for the help tukluyver. Once question, can i have some links about python/programming you find/found interesting/educational :D sorry for the /slashs/ 
As a programmer any time I find myself expecting a CLI, I die a little inside.
WOW [https://docs.djangoproject.com/en/1.3/](https://docs.djangoproject.com/en/1.3/) This is more like it :D
Then you've never worked in a shop with any operational discipline. You cannot reasonably manage very large scale operation with unsupported software ... that, at least, is the theory. I have argued - as was previously suggested - that we SHOULD be using more open source that we package ourselves. The Powers That Be (tm) will simply not do it because -historically at least - very large scale operations must have a "throat to choke" for every single moving part. 
Notice also the heavyweights who appear in the comments.
[considered harmful, considered harmful](http://meyerweb.com/eric/comment/chech.html)
Your link seems to point to a guy trying to debug his telnet code. Didn't notice any discussion on internationalization, even on page 2 of the comments.
Yeah. For every time I think WTF iterable string I find myself thinking how hard it would by to do x-y-z without iterating over a string...
Doing manual is acceptable, but I want only one env file that I can use both in my bash shell and my script. And I wouldn't call this way easy. Don't get me wrong, I love and stay with Python for a long time, but we have to face our limitation
Thank you!
What's the purpose? 
Thanks to your excellent assistance I now have the code working, thank you! One more thing, in the 'better' example above 'Av. Bellavista.......' is wrapped in the u''. Why is this required when x is already defined as u''? Is it because of the use of the dictionary here and I need to explicitly say the value is unicode? 
Yes, `eval` is treating the text as source code in a file. You have to explicitly create a Unicode object (by way of the u'' Unicode literal) to be referenced in the dictionary instance. Otherwise you get a utf-8 encoded byte string as in the "not what you want" example.
Fantastic - I now completely understand this and am working with the unicode files as I need to :-) 
The whole construct? I would never use it in production, it is too esoteric. But, each of the elements can be used sensibly in production code. For example, older Python versions do not support lambdas in the form lambda x:a if foo(x) else b But, you can do the same thing by lambda x:[a,b][if foo(x)] And, interpreting an iterable as a boolean is something I do all the time. You can replace `any` with something like any = lambda i:bool([x for x in i if x])
in the fishing rode category give Flask or CherryPy a spin (I prefer CP :P)
In Python 2.4+, it's more efficient if you drop the brackets and write `"".join(line_2[i:i+2] for i in range(0,len(line_2),4))` because that uses a generator instead of making a whole list before the `join`. In general, it's best practice to avoid using `+=` on strings. In some reason versions of Python, adding strings together is sometimes efficient, but most of the time you end up getting O(n^2 ) performance, since what's happening is that you first make a new string of length 2, then make a new string of length 4 and drop the old 2-length string, then …. Using `join` just creates a buffer as things go along instead of making and throwing away a bunch of objects. 
Hmm, could have a pathological response if you have a string like `"AA000000BB00"`.
Flask or Bottle.
The one you like.
Enthought: http://www.enthought.com/products/epd.php http://www.enthought.com/products/epd_free.php 
I am CTO of a startup company ([here][1]), and we have been running about a year with [Flask][]. Some personal experiences led me to decide to use it: - I have some experiences with [Werkzeug][] and [Jinja2][], libraries behind Flask, and these satisfied me. They both are well designed (the whole design makes sense), easy to use (very good usability) and have large sets of powerful features. Werkzeug especially consists of easily adaptable components — in other words, it is not a framework but a library actually. - It has a very good documentation like other [Pocoo][] projects. - When I just started the company, fast prototyping is most important for us, and *microframework* could give us several benefits. I considered [Bottle][] also, but I think its features opposite to Flask are needless for our use: - Python 3x support: we didn’t plan to use Python 3, because there were already several dependencies that don’t support Python 3. - One file packaging: we have already several depending libraries, and so decided to manage dependencies by `install_requires` option of [Distribute][] ([setuptools][]). - Routing: Werkzeug’s one is better. - Templating: Jinja2 is more powerful, because Jinja2 is a template engine (not a web framework). - Built-in server: we don’t use it — we use [`gevent.wsgi`][2] with L7 ([Nginx][]) and L4 ([ELB][]). What WSGI does is it exactly. - And there are several lacks Werkzeug and Jinja2 already provides e.g. [content negotiation][3], [client-side secure session][4] (using HMAC), [cache interface][5] (actually we have some experiences of painless switching of caching backends between [Redis][] and [memcached][] *in production* by this interface), [poweful debugger][5]. - Yet fast prototyping was important for us, growing up in the future also was important too, and we have been growing up well now — Flask is powered by two powerful libraries (Werkzeug and Jinja2) and these make us not to be limited in quick and dirty structure. Umm… yes, actually the most benefits of Flask are originated from Werkzeug and Jinja2. [1]: https://stylesha.re/ [Flask]: http://flask.pocoo.org/ [Werkzeug]: http://werkzeug.pocoo.org/ [Jinja2]: http://jinja.pocoo.org/ [Pocoo]: http://pocoo.org/ [Bottle]: http://bottlepy.org/ [Distribute]: http://packages.python.org/distribute/ [setuptools]: http://pypi.python.org/pypi/setuptools [2]: http://www.gevent.org/gevent.wsgi.html [Nginx]: http://nginx.org/ [ELB]: http://aws.amazon.com/elasticloadbalancing/ [3]: http://werkzeug.pocoo.org/docs/wrappers/#werkzeug.wrappers.AcceptMixin [4]: http://flask.pocoo.org/docs/api/#sessions [5]: http://werkzeug.pocoo.org/docs/contrib/cache/ [Redis]: http://redis.io/ [memcached]: http://memcached.org/ [5]: http://werkzeug.pocoo.org/docs/debug/
It *is* a written program. And if stageproc.py and load.py were written before this script, it might be the most efficient way to do the job.
So put "import sys" and the update in the other module, and "import squirelly_but_short_environment_hackery", or look up the "site" module. Fuck.
Thank you for bringing this up. I'm glad I'm not the only one that looked in dismay at that awful code in the article.
...and the only reasonable answer I know how to give is sitting at zero points. Sigh. Look, people, there just really aren't significant technical-quality differences between the popular Python frameworks. So choose one based on how you like it. Choose one based on whether its approach fits your brain. Choose one based on whatever subjective reason you like, because we have a plethora of high-quality frameworks in Python and there aren't solid *objective* reasons to pick one over another.
Thank you so much! Everything works, just like that :)
I think he meant [this](http://www.wefearchange.org/2011/10/python-internationalization-without.html)
Wait till you get to biochem and pchem. You will not need Python, but being able to do your own dynamic modeling in Python of enzyme kinetics, thermodynamic state equations, chemical master equations, etc. Will greatly enhance your understanding of the subject. 
It's getting to the point where you need a weekly weekly that is a summary page of all the weeklies. They are cool though. Someone has even go on to starting a dart weekly.
Someone commenting on my blog mentioned [human_curl](http://pypi.python.org/pypi/human_curl/0.0.2) which looks very interesting. Use the syntactic approach of requests, with the power of cURL under the hood.
&gt; I'm probably not going to write any programs Then...why would you learn python? If you have the vaguest inkling of interest in writing programs--any kind of personalized, specialized automation--then learn python (or whatever language suits your fancy). Otherwise...no, I don't think so.
Another example of why you should be forced to type out em dashes instead of doing auto conversion of "--". Anyhow, I think the canonical guide to packaging is the (unfinished) http://guide.python-distribute.org/. Rather than writing his own article, he should have contributed there if he had anything to add.
do you plan on continuing with chemistry beyond a BS? i haven't met a single working scientist or grad student who didn't do some kind of programming related to their research. either simulations, instrument control, or data analysis -- programming is an integral part of modern science.
wow that's weird. At least it seems you can still download pythonxy at [google code](http://code.google.com/p/pythonxy/wiki/Downloads). 
You may want to take a look at http://www.scipy.org/. Its rapidly becoming a standard in biochem.
That's a bit cynical.
If what you write, as a chemist, in the future, is going to be worth anyone else's time to read. You can anwer this question yourself. Is computer driven informatics the future of all sciences? Then yes. Otherwise, only maybe.
It might depends on the nature of your project. But I'd go with Flask. We have tried other usual suspects before settling on this. It's not a micro framework as you might have heard. I'd call it as a core framework, a very flexible, fast and powerful framework. Just for a read, http://invenio-software.org/wiki/Talk/WebFrameworks 
Looked up gevent and am impressed. How did you set up your deployment strategy with nginx so you won't loose any requests (Bad Gateway responses from nginx)?
Django, and particularly its administration interface toolkit, is well-suited for database browsing and editing. You can start with the [Django tutorial](https://docs.djangoproject.com/en/dev/intro/tutorial01/) (part 2 covers the admin), then the [admin docs](https://docs.djangoproject.com/en/dev/ref/contrib/admin/).
Yea it was just a quick answer, that may be acceptable if you can guarantee the form of `List_2`. The best general answer I could come up with matched [cannabis_sam's](http://www.reddit.com/r/Python/comments/lih6n/assigning_a_variable_within_a_while_loop/c2sz862).
That almost makes sense. 
Yes, but for someone without experience using any of the frameworks, 'the one you like' isn't all that useful. He's asking what people who've used them like.
going to reply to this one as it's the most detailed. i'm going to assume that the python you've got has the standard modules. (i'll talk about portability later) a try... except... with urllib will do your retrying a partial download quite simply. i couldn't imagine it taking more than 5 or 6 lines, maximum of fifteen. certainly not half a day. the standard modules supply the functionality of mv, cp, etc. (shutil especialy, but your find and replace is handled (v powerfully) by re, and urllib is far more well featured than wget). this is, i think, where python needs to be used a bit differently to shell scripting. instead of using programmes, you use modules. all of the functionality is there, without needing to "roll your own". and in addition, if you absolutely must use some program from the shell, you can os.system or os.popout it. you can't import a python module into a shell script. as i see it, these are the advantages/disadvantages of python/shell scripting. python advantages 1)fully featured programming language if you need to expand. 2)can run shell proggramms if you need to 3)more recently developed: it can do web interface(getting/putting) more slickly, for example 4)complexity is explicit 5)an effect of 4), very easy to learn, and complex scripts are simple to understand. shell addvantages 1)apparently faster (i'd like to see a source for this, but this seems to be consensus). 2)mature- and hence extremely stable 3)implicit complexity. this may seem to be a downside, but to a skilled proggramer, it allows you to work faster, and write fewer lines of code. now: on portability. bash is installed on a wider variety of machines, no doubt. it's also got a lower footprint too, this is obvious. for many people, this is important. especially if you're working on older servers that are highly loaded. python, however, is installed on most modern server environments, and pretty much all desktop environments. it has a higher footprint, yes, but in exchange, you get more functionality (as comes with a full programming language), and (imho) cleaner syntax. tl;dr:if you're trying to communicate between applications in python, you're doing it wrong. communicate between modules, and use the subprocess module to work in parallel. bash (or even sh) is more portable, and lighter, however i believe you lose functionality and syntax advantages. don't read the tl;dr and reply- if you're going to reply, read the full post.
if you're comunicating between aplications, you're doing it wrong. you should be using the standard lib modules, that replace the functionality of most standard shell applications. anyway- big reply above.
speed seems to be said a lot. has anyone got a source for this? anyway, big post above.
Cool, I am very glad this page promotes the usage of PEP 386 -- the "unified" version scheme.
Oh I see what you did there :P For OP: I'd use Flask with (flask-)sqlalchemy and (flask-)wtforms.
Classes: Yes, this is OOP. You define a general type of thing (e.g. user), which you can create instances of. There can be data attached to each instance (a user may have username and password attributes), and a class can have methods (you might write a forgottenpassword() method which emails the user a code for a single login.) It's a bit more than a way to wrap up several functions. Instances of a class have some state, which can affect what their methods do. Going back to the example I gave before, each instance of A has its own foo attribute, so a.sayfoo() can do something different from a2.sayfoo(). It's possible to do it all without classes, but it makes it a lot clearer if they do. Microframeworks have their place, but if you find bottle tricky, there are alternatives like Flask, CherryPy, etc. I don't think I can suggest any better links than the ones in the sidebar on the right.
Use `#!/usr/bin/python -S` as your shebang. For scripts that use only the stdlib (no site-packages), that starts much faster.
`eval $(dircolors)` changes your environment, and dircolors is written in C.
Given import math from itertools import izip def test(): sin = math.sin pi = math.pi N = 2**16 n = range(N) x = [0 for ii in range(N)] y = [0 for ii in range(N)] t = [0 for ii in range(N)] for ii in range(N): x[ii] = sin(ii*pi/4.) y[ii] = sin(ii*pi/1333.) for ii in range(N): t[ii] = x[ii]*y[ii] tsum = 0 for ii in range(N): tsum = t[ii] + tsum assert abs(tsum - 0.595740438942) &lt; 1E-9, tsum def test2(): N = 2**16 pi = math.pi sin = math.sin y = [sin(ii * pi/4.) for ii in xrange(N)] x = [sin(ii * pi/1333.) for ii in xrange(N)] t = [xi*yi for xi,yi in izip(x,y)] tsum = sum(t) assert abs(tsum - 0.595740438942) &lt; 1E-9, tsum return t def test3(): N = 2**16 pi = math.pi sin = math.sin y = (sin(ii * pi/4.) for ii in xrange(N)) x = (sin(ii * pi/1333.) for ii in xrange(N)) t = (xi*yi for xi,yi in izip(x,y)) tsum = sum(t) assert abs(tsum - 0.595740438942) &lt; 1E-9, tsum return t def test4(): N = 2**16 pi = math.pi sin = math.sin t = [sin(ii * pi/4.)*sin(ii * pi/1333.) for ii in xrange(N)] tsum = sum(t) assert abs(tsum - 0.595740438942) &lt; 1E-9, tsum return t I get % python -mtimeit -s 'from reddit import test' 'test()' 10 loops, best of 3: 121 msec per loop % python -mtimeit -s 'from reddit import test2' 'test2()' 10 loops, best of 3: 55.3 msec per loop % python -mtimeit -s 'from reddit import test3' 'test3()' 10 loops, best of 3: 49 msec per loop % python -mtimeit -s 'from reddit import test4' 'test4()' 10 loops, best of 3: 37.9 msec per loop Scaling of 0.31 beats pypy, right? Now, to combine the new implementation and pypy... Using pypy 1.5.0-alpha0 (so it's a bit old) those timings are: test: 10 loops, best of 3: 44.6 msec per loop test2: 10 loops, best of 3: 43 msec per loop test3: 10 loops, best of 3: 44.3 msec per loop test4: 10 loops, best of 3: 18.9 msec per loop That's 0.16 of the original version.
I fully support this PEP.
Listen dude, you've been learning for three weeks. Chillax, go play a game, go for a walk or something. If you're anything like me, you just try to learn, learn, learn almost constantly because you're now obsessed with Python. That's great, and I've learnt a lot like that. But in the end you'll burn out! Trust me! Take things slower instead of thinking you need to learn X and Y before Z date. Spreading it out and taking time learning each nuance can go a long way. Case in point: When I first started learning my initial project was using the ctypes module to read shared memory data from a third-party dll. For an entirely new person to Python this is something of a mystery as there were many things I were missing. The C dll used a struct to hold it's data, there's no struct per se in Python, so I failed miserably in understanding what that was. I put it on hold, went and learned the entire basics and came back to it eventually I finished my project and moved on. I've been learning Python for over a year now and I can safely say that I am still as excited and driven as I was when I was green but now I know when I should spend 8 hours on a mysterious and esoteric problem simply because 'I must understand' and when I should chill out and solve a problem logically away from the computer. Hope this helps somehow... maybe not what you're looking for but a clear idea of how self-paced learning should be.
&gt; Umm… yes, actually the most benefits of Flask are originated from Werkzeug and Jinja2. That is actually nice to hear (as the author of Bottle), because you can integrate werkzeug and Jinja2 into Bottle quite easily. There is a plugin that integrates werkzeug, and Jinja2 is fully supported since 0.6. Thats the point of the one-file-no-dependency approach. You get a feature rich web framework for free, and may add additional features in the future if you really need them. Bottle does not get in your way, and does not enforce dependencies on you that you don't need. Oh, I forgot (edit): client-side secure session (using HMAC) are called 'signed cookies' in Bottle. And the "powerfull debugger" you mentioned is a WSGI middleware that works just fine with Bottle. 
Guido hopefully does not mean that you should not use tuples if your data is homogeneous. Tuples are better than lists if the data is constant (tuples are immutable).
We have multiple instances that serve web application, and we approach serial deployment (deploying one instance at a time).
Yes, I just didn’t know things you mentioned above at that time. I didn’t want to dis Bottle. :-)
unless the database schema was created outside of django. then the admin tools will probably have some problems
&gt; I first looked at Pyramid and it was a little over my head/ **documents not fully developed.** Perhaps the docs are indeed over your head, but "not fully developed" is not accurate. They are in fact quite thorough. But, they are not the hand holding kind you might expect. For example, they assume you know what HTTP is. If you don't know then well, you might want to start there. 
This one is still available. [http://code.google.com/p/pythonxy/](http://code.google.com/p/pythonxy/)
The best answer has been given: the one you like best. Reddit seems to be little biased towards micro frameworks. Maybe rightly so or maybe the philosophy appeals more to the experienced programmer. Please do take a larger framework like django into the equation. The documentation and scope are amazing and will help you get a good start. Hell, just try them all for a day and make up your mind after a week or so.
I'll second this. Microframeworks are nice and all, but django is quite self contained and will probably have the best resources in terms of tutorials, examples and entry-level documentation. Don't be afraid of it. Web development is simple, there are no hand-grenades.
No explicit loop needed. Try this: "".join(line_2[i:i+2] for i in range(0,65,4)) edit: I guess I should read other replies before posting..
Can anyone explain the use of `__import__()`? I've only ever seen the usual use of `import`. 
Well in this case, the proc code spits out a sql script and the loader just reads the file line by line and executes the sql, updating the audit tables and writing an error log when commands fail. Ideally, these scripts would fetch the XML report, parse them while updating the database. Creating two temp files along the way is perhaps not the best thing. And yeah, there are like a dozen scripts like this.
Wrote. If it's on-going you could say 'Maintains'. (assuming you're a non-native English speaker and that's what your question was about, sorry if not!)
CherryPy + your template language of choice (I use Mako).
Also, if packaging for Arch Linux: https://wiki.archlinux.org/index.php/Python_Package_Guidelines Or for Debian: http://www.debian.org/doc/packaging-manuals/python-policy/
Anybody interested in the "canonical guide" can probably find it via a search engine. Developerworks has been putting out articles on Python (and other technologies) for a decade or so. Are you saying nobody should ever write an article about something, rather contribute to the source?
My team does this all the time in both bash &amp; python. The bash code becomes a nightmare to maintain - it's hard to read, has poor exception handling, and hits a wall as the complexity of what you want to do increases. None of this rules out bash - it just means that bash is reserved for the small &amp; simple, quick &amp; dirty. 
I think you'll find [web2py](http://www.web2py.com) very easy to set up, learn, and use. It requires no installation or configuration, has no dependencies, and comes with many batteries included (web server, web-based IDE, error ticketing, database abstraction layer, database administration, database migrations, jQuery integration, AJAX support, access control, internationalization, web services, etc.). The scaffolding app and default behaviors make it easy to get going with minimal coding, yet it is also very powerful and flexible for more advanced needs. The [documentation](http://web2py.com/book) is excellent (a new recipes book is coming out soon, too), and if you have any questions, there's a very helpful and responsive [mailing list](https://groups.google.com/forum/?fromgroups#!forum/web2py). For what you'll be doing, web2py includes some great built-in [CRUD capabilities](http://web2py.com/book/default/chapter/07#CRUD). There is also some newer grid/smartgrid functionality (see [demo](http://labs.blouweb.com/web2pygrid/default/index?jqueryui=true&amp;smartgrid=true)) that will likely replace some of the legacy CRUD functionality. The grid/smartgrid functionality is so new it isn't yet documented in the online book, but the documentation should be coming soon (in the meantime, the [mailing list](https://groups.google.com/forum/?fromgroups#!forum/web2py) is a good source of help). It's not shown in the demo, but the grid will also soon include a flexible query builder for searching/filtering. web2py also includes built-in database administration functionality (called appadmin), and there's also a nice DB admin plugin called [Instant Admin](http://sramana.in/web2py-instant-admin/). There was a recent review in InfoWorld: [[Overview](http://www.infoworld.com/d/application-development/pillars-python-six-python-web-frameworks-compared-169442) | [web2py](http://www.infoworld.com/d/application-development/pillars-python-web2py-web-framework-168920?page=0,0&amp;1313029958=)]. web2py also recently won a [Bossie Award](http://www.infoworld.com/d/open-source-software/bossie-awards-2011-the-best-open-source-application-development-software-171759-0&amp;current=10&amp;last=9#slideshowTop) for best open source application development software. To try it out, just [download](http://www.web2py.com/examples/default/download), unzip it, and click on web2py.exe (Windows), web2py.app (Mac), or web2py.py (source). (If you've already got Python installed, go with the source version -- the Windows and Mac binaries include their own Python interpreter, so they don't require Python to be installed.)
What about using Dialect.skipinitialspace in the reader instance?
took a quick look.. I don't think it'll handle if the file gets rotated while you are tailing it. 
&gt;a try... except... with urllib will do your retrying a partial download quite simply. i couldn't imagine it taking more than 5 or 6 lines, maximum of fifteen. certainly not half a day. Now implement resuming of failed downloads where they left off (remember, I'm downloading gigabyte+ files), and do it faster and in a less error-prone way than wget (just doing "wget somesite.com/hugefile" will retry up to a default of 20 times, I think). You're not going to be able to do it. I'm not able to do it. &gt;3)more recently developed: it can do web interface(getting/putting) more slickly, for example Have you seriously never used curl? It's one of the most slick tools ever, and it does exactly this. &gt;1)apparently faster (i'd like to see a source for this, but this seems to be consensus). It's not shell that's faster, per se. It's all the native C tools that you use in shell that run fast as heck because they've had 30+ years worth of optimizations under their belt. For reference, I'm a professional software dev with seven years of Python experience (not some "I learned it on my own for the first three years" nonsense - I've been using it at work for that long). I use it daily and I love the language, so don't think I'm hating on it. But it is *not* a replacement for a shell script. They're both tools in a tool box; just because I like using a circular saw doesn't mean I should try to use it to pound in nails. When you start getting into more complex problems (if you want to connect to a database for just about any reason, do anything with hash maps, if your awk script got longer than about 50 characters, etc), shell scripting makes a whole lot less sense. As another commenter pointed out, large shell scripts are painful to maintain, and what you can do in a reasonable way is pretty limited. If what you want to do is simple enough to stay within the limits of a short, sane shell script, then use the right tool. If not, that's why more fully-functional scripting languages like Perl were invented. I'd say that Python replaces shell scripting less than Perl does. Shell scripting and Perl have co-existed for 25 years. I see no indicators that Python will take a bigger bite out of the problem sets that are best solved in a shell script than Perl already has. That is to say, "more functionality" is an argument for why Python would replace Perl, but not why it would replace shell scripts.