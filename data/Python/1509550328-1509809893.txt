My suggestion: Go to a few topics like these and you should be good to go. http://www.safarnuma.com/2016/10/a-quick-beginners-guide-to-classes-in.html http://www.safarnuma.com/2017/10/a-better-example-of-class-inheritance.html http://www.safarnuma.com/2016/09/generator-functions-why-and-when-should.html http://www.safarnuma.com/2016/09/python-running-executables-using.html http://www.safarnuma.com/2016/07/regular-expressions-with-python.html These should be enough to get strong in some very common topics. 
So basically you are looking for someone to work for you for free.
Asyncio is more a toolbox for library writers at the moment. i've tried twice to use it for an application, and every time i get broken by its leaky abstractions. It will be great one day.
Well, I'm comaintainer of MicroPython, an alternative implementation for small systems (Arduinos and stuff), so my view is definitely biased. But I think Python3 started to evolve too fast. We didn't yet overcome Python2 vs Python3 split, but creeping featuritis in Python3 may create another split, or at least maintain and make 2-vs-3 even worse, where py3 is a *completely* different lingo than py2. So, in a sense, in the end I agree with you - they'd better spend even more effort on infra around the language, than munge the core language. 
&gt; aviation-grade Is Aviation software really that much more reliable? Google.com's uptime is probably better than anything in aviation (even ATC shuts down), and planes frequently need rebooting. They just do it between flights so passengers aren't aware.
TFW your python 3.6 is symlinked to py2
The Python symbol! And Larry Wall! Awesome!
Thank you! This is great stuff! Loved the write up on regex. Did learn a thing or two.
gevent is much more intuitive to use, and faster. The only drawbacks are a few rough edges around the library monkeypatching, but it usually hurts more when you're doing something crazy or using some bad library (like django).
Thanks to this, I just noticed that the python logo is two snakes. Out of context makes it obvious. 
You need the info required to diagnose the bug. You can get all the info about their sysytem from the sys module (e.g., processor, OS, RAM). Just depends on what is likely to cause problems. If you're testing on TravisCI is good, it shouldn't be a package version version, so that leaves dumping info about the current state. What triggered the error?
Maybe he is just saying something along the lines of "It's good enough when lives are on the line." I am not sure what goes into "aviation grade". Uptime is probably a part of the equation but there is probably a lot more to it.
yes i was full wrong
The dev version of `numexpr` can pass `numpy` at about 64k elements in the array, which would be a 256x256 pixel image. 
Isn't that, like... the whole idea behind generators in the first place?
Does it provide some mechanism to handle stdout/stderr like subprocess. How about setting cwd so that the called script runs from that directory? Sorry, I couldn't find this info in the documentation.
It's custom code, no frameworks used except jQuery. You can check the implementation [here](https://github.com/jupyter/notebook/blob/master/notebook/static/notebook/js/menubar.js).
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [jupyter/notebook/.../**menubar.js** (master → 4918eb1)](https://github.com/jupyter/notebook/blob/4918eb1f8040cd3f92976a96615688a83458d460/notebook/static/notebook/js/menubar.js) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dp77kto.)^.
I mean yea, it's a quad issue in the sense that it tries to determine the best integration strategy, but it seems that the one it chooses in this situation runs into floating point issues. 
&gt; did I under-appreciate the asyncio Nope. Its impact on your code is very invasive and it is insufficiently integrated into the programming language and runtime. The later makes diagnosing problems more difficult due to insufficient help from tools like debuggers.
So you want a bot for following,liking etc?If you make it plz send it to me
I have written a blog post about web scraping using BeautifulSoup[0]. Now trying out Selenium and other stuff for automation. 0: http://www.kashifaziz.me/web-scraping-python-beautifulsoup.html/
I need help making a bot XD do u know how?
Nope :-(
Working on a library to do everything I'm learning in my Linear Algebra class. As I take more math classes I'll add them in as well. Hopefully, by the time I get out of college I'll have a pretty solid homework solver :)
Really cool! I'd love to see that source code ;)
Everyone always recommends rendering the page with Selenium. But the majority of the time this not necessary. Take a look at the XHR requests when you load the page, use Postman and grab data from internal APIs. This is faster, more reliable and less strain on your targets server. When you have failed with this then revert to using selenium, which comes with a lot of issues particularly when you want to scale. 
In your enumerate section it may be easier for someone to wrap their head around if you didn't use the same name for the container object as the item being pulled out of the container: for i, menu_items in enumerate(menu_items): could be for index, item in enumerate(menu_items): or something similar. The way you have it, after the loop is done, the variable menu_items will be bound to the last element from the original container rather than to the container itself. 
After mulling it over further, I could just do this by implementing a dictionary. `playerNum = {}` `for loops...` ` playerNum[item] += random...` But I'd very much like to not have to call the number out of the dictionary every time I need to use it in the rest of my code. Edit: lots of formatting
&gt; But I'd very much like to not have to call the number out of the dictionary every time I need to use it in the rest of my code. Why's that?
SQLite really is a great tool. It's impressively fast and resilient. 
It's long and ugly. In my whole code it would look something along the lines of... `for i in range(0,len(randomname.Table.players))` `playerNum[randomname.Table.players[i]` `etc` Although it maybe be missing something, I can't tell as my computer is currently updating. Long story short, I'm creating a blackjack game for a casino simulation my project group is making, and this quickie is a part of the blackjack game object to check each players score (so it can then be determined if they can still play or not). Although it is possible for me to do it this way, it looks ugly and I tend to get confused easily when there's a lot of parenthesis and other stuff to keep track of. Simply being able to say `AI` would be helpful, and less time consuming in the long run.
Sublime 3!
You'll have to associate the name of the player with their score somehow, and a dictionary is probably the simplest way to do this. If I'm understanding your requirements right: Given a list of players of the form ['playerName1', 'playerName2', ...] you have to generate a score for each player. This means you'll have to loop over each name (as you're already doing) and assign a score to that name. What you have now: item += random.randint(0,10) adds the player's name to their score, or more concretely, adds a string to an int, which is invalid. You'll have to store the score somewhere else, in a way that it can be referenced given the name. This is exactly what dictionaries are for. 
&gt; stdout It's a little buried down, but when you run a command, it returns a Result object which contains stdout, stderr, rc (return code) and traceback. http://sultan.readthedocs.io/en/latest/sultan-examples.html#example-12-results-from-a-command I just realized I need to fix the formatting of that too.
The error message is telling you that you can't change a single letter in a string with `guess[0] = char`. Only lists and dictionaries allow that kind of mutation. You'll need to do it with a different variable name for each level, like this: for char1 in AlphaNum: for char2 in AlphaNum: print(char1+char2) --- If you have more questions like this it's better to post them on /r/learnpython. Be sure to [format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin. Also, include which version of python and what OS you are using. 
We have [a pretty long list of learning resources in the wiki](https://www.reddit.com/r/learnpython/wiki/index#wiki_new_to_programming.3F). Try a few and see what resonates. For a brand new programmer I'd recommend codecademy. Also, if you don't have one already make sure you look for a project that interests you and start on it as soon as you can. Programming is a lot more fun if you have a goal. Come visit us in /r/learnpython if you get stuck and we'll help you out. 
Awesome. Thanks for that wiki link bud. It helps a lot. 
MicroPython is an awesome project and truly makes embedded programming accessible to a lot more people.
RIP. Knew that much about the TypeError, was just hoping I could in some manner do `eval(item) = ...` since their call elsewhere would then be `randomname.checkPoints.AI` which is extremely intuitive. Alright, dictionaries I will use. Thanks for the assistance.
I think the author is confused on the *semantics* not on the principles of what he's trying to say. It can basically be boiled down to: - Generators are iterables, not all iterables are generators. - Generators are *lazy* where iterable objects are generally computed before they're returned. - Generators should be used when the data is "large" and the resources are "scarce." - Generators are functions that utilize `yield` or class instances that implement `__iter__` and `next`. - A class generator's `next` is the `return` version of a function generator. - Any function that loops computes something to be returned in a list could be converted to a generator.
I'm 95% sure it's hand-optimized assembler and 100% sure the performance games are both real and large.
Pympkin
It's weird though how so many people use the phase but can't explain what it means. That isn't how engineering works.
First, this is probably better for /r/learnpython Second, what you what is a web framework. A minimal one such as Flask or Bottle should suffice. The latter is nice because it is a single file, if that matters for you. Alternatively, something like [remi](https://github.com/dddomodossola/remi) may be even better for you!
At the moment you return a float, so your only options are the ones `float` provides. If you want more you need to make your own class to return. class JacobFloat(float): def getReturn(self): return 'hot' if self &gt;= 100 else 'cold' class Celsius: def __get__(self, instance, owner): result = 5 * (instance.fahrenheit - 32) / 9 return JacobFloat(result)
I had a month long run in with C# recently and I miss switch in python now. It's so much nicer than if/else for certain things. And that's considering C# doesn't allow fall-through cases with code like C. 
Every method parameter and return value must declare type and it is enforced.
I just watched a presentation that discussed this, and the way I understand the advantage of generators is they allow you to extract and utilize data as it is being processed, instead of waiting until the function is finished. Almost like running in debug more for lack of a better explanation.
Please search for `python walk directory` and take your pick from any of the first 10 hits.
Not to be rude, but what is your point? Obviously numba and numexpr and cython are going to be faster than discrete numpy operations. The discussion here is about the GIL and the python threading module
Which is a pity. I'd love to see some Python interpreter for Unity. I mean, there's IronPython which is a CLR language too. So it should be possible. 
Oh great that's really helpful. So I could combine that with a text parsing method after walking the folder directory. Very useful. Ty. 
A useless article as it simply repeats things that have been said many times before.
This doesn't sound true to me, just use [itertools](https://docs.python.org/3/library/itertools.html#itertools.combinations) 
I try to use a more functional approach with lists and dicts. Switch statements feel a bit dirty to me, lots of conditionals instead of fewer, broader code paths.
From your phrasing, I would guess you will be better served at /r/learnpython. 
&gt; after the loop is done, the variable menu_items will be bound to the last element from the original container rather than to the container itself. Is this correct? Isn't menu_items a local variable in the scope of the for loop, so once it ends, as long as you're outside the for block you will be using the container 'menu_items'
&gt; platform's javascript-like language. both deprecated.
I'll take payment up front, sure.
You should look at Flask. Django is primarily used to make Content Management Systems so someone in marketing can make a new blog post. Flask is for simple web apps. 
&gt; 1) All the async methods needs to be implemented as such, my code is littered with async/await keywords, while in gevent I used before for something else, the code is mostly the same. I found the explicit async/await a good thing to be honest. It's a tad harder to read, but they make the yield points more easier to spot as opposed to regular function calls in, for example, gevent. &gt; 2) The next step will be to store everything to mysql, and for this, I will probably also need a special asyncio version of the db library. Basically, everything needs to be re-implemented to support async. This is true, though this seems like it should be different as asyncio support in the community grows. For example, a PostgreSQL driver that embraces asyncio called [asyncpg](https://github.com/magicstack/asyncpg) is being developed now. Another example, is a Flask-inspired framework called [Sanic](https://sanic.readthedocs.io/en/latest/). They will only mature over time and joined by other, asyncio-compatible, libraries. &gt; 3) gevent code structure is much more intuitive, you get callback where you do the async stuff. I would say this is a matter of taste. But like everything else, if gevent fits your current use case just fine, it is probably better to keep using it. That being said, it's always a good idea to at least be aware of asyncio-related developments even if you're not actively using it. Only time will tell if the community would accept asyncio as the creators intend.
granted I've not actually written any gevent code (so im just briefly googling around) (and I'm finding it surprisingly hard to find comparable examples of asyncio vs gevent code), but I feel like callbacks slash implicit context switching still end up meaning you write code that only really works in gevent. Granted, async/await code *can* tend to bleed into surrounding code, in the name of code reuse I've found myself factoring the io outwards in order to improve code reuse. And either way, I feel like ultimately any cooperative multitasking setting you're going to have to remain aware of the fact that your code is running inside an event loop. Thus it feels (and again, no gevent experience) like it being able to write code that generally flows identically to regular single threaded code would be a boon for grok/teachability
Not exactly clear what your signal and nose look like without a picture, but it sounds like a bandpass filter (with a frequency window around the sine wave /signal frequency) would be a way to start. Here's a link to [one filter possibility using scipy.signal](http://scipy.github.io/old-wiki/pages/Cookbook/ButterworthBandpass), which you'll want to get familiar with.
The sidebar of /r/learnpython is full of great resource. I usually start students on the free codeacademy.com Python course to get their feet wet.
This echoes our experience. Pickle isn't a good option for long-term storage. 
Magical SQLiterc, didn't know it existed. Will set mine up. Great article!
`for` loops don't create a new scope in Python. There's an exception for comprehensions as it was largely useless and mostly just surprised people (`[foo for bar in baz]` - `foo` will not exist outside of the list comprehension) Basically, the only things that create a new scope are modules, classes, and functions.
https://github.com/MonsieurV/py-findpeaks I used the second one for my work successfully. Not sure if it helps you 
The vast majority of articles posted on this subreddit tend to be the same dozen topics rehashed over and over again. It might be useful to have a "cheat sheet" style thing listed in the sidebar that covers these topics, for people who know enough that the in-depth teaching resources are largely a waste of time, but have missed out on the odd trick. I'm not sure if such a thing exists though.
Good to know! 
Aviation software is, as I understand it, designed with a guarantee that it will work until the flight is over. The definition of work isn't necessarily that it will have all the features, just that it is almost impossible not to be able to fly the plane to the destination. To this end, it's fail-safes over fail-safes over fail-safes. As much as possible is proven to work, that which can't be proven should be locked into boxes from which failure can be caught. OTOH, when Google suffers a failure in some of their code, they can reboot the one box among millions that is failing, and keep on going. Any particular failure can be completely catastrophic to the machine it's running on, because that machine itself is entirely isolated. Obviously this doesn't work on planes, because planes aren't yet big enough for datacentres to fit on them. At least, that's the definition of "aviation-grade" that I've always heard.
Thanks. I was actually thinking maybe the best way to do this is a FFT and assume the largest frequency peak is the frequency of the signal (also could be thought of as the distances between the peaks).
A [recipe](https://github.com/rosette-api-community/compare-vocabulary) for doing some basic, exploratory NLP with [Rosette API](https://developer.rosette.com/api-guide)’s Python bindings inspired by [SameDiff](http://dev.databasic.io/en/samediff/). I made a [Jupyter notebook](http://nbviewer.jupyter.org/github/rosette-api-community/compare-vocabulary/blob/master/visualize.ipynb) as well.
That sounds like some kind of sex jelly
Pretty sure you can fit multiple motherboards in a rack, and have it fit in a briefcase. There's no way an airliner can't fit that somewhere.
I'll only address point 2 since some other comments have addressed the other points and I don't really want to get involved in the "asyncio vs. gevent" conversation that sometimes arises in these threads. While you can use an asyncio-specific library to talk to a SQL server (or whatever else for that matter), you don't *have* to. As a bridge between explicit async and synchronous code, asyncio provides the `run_in_executor` method. This allows you to run on otherwise blocking call in a background thread or process. Threads are generally perfectly suitable for I/O-bound work, and using `run_in_executor` makes it pretty easy to use libraries that don't yet have an asyncio version or let you defer updating some parts of your code to be fully asyncio-compatible until later.
They don't look like redundant motherboards, though, they all look like they've got different stuff on there. I'm sure you could, but and tbh I can imagine that modern aviation-based software uses plenty of redundancy in the hardware as well as fail-safes in the software. However, traditionally that has not been something that has been practical or economical in the tight-margin world of airline construction. Hence the evolution of the idea of "aviation-grade" software.
I will try codeacademy. Thank you..
I agree. An extra computer is too expensive to include in a $400,000,000 airliner.
I was referring more to the weight issue, but, yes, computers have historically been somewhat expensive devices.
I haven't looked at /r/learnpython so what I say may be on that sub, but my favorite podcast is "talk python to me," obviously you won't learn coding from it, but as an audio only medium it is something to nerd out on while driving to work. It's executed as well as a programming language podcast can be, but I found a lot of cool libraries and ideas I wouldn't have otherwise without listening to it. The operator has a website for paid learning content, that after over 1.5 years listening to the podcast I didn't feel to bad dropping the 40 or so bucks for one of his series, not only for supporting great podcast content but the series was very direct and content was meaty as hell. With that said, I would learn everything free and it is possible to do that with python... I just went on a tangent because I live in Mississippi and don't get to talk about cool Python shit very often lol.
Does it support FreeRTOS? 
I also agree with that. An extra computer is too heavy to install in a 400-ton airliner.
&gt; They care about typing (really???) I think optional typing is really important. It makes it possible to find errors at compile time rather than runtime, which can be hugely beneficial for large codebases. I think a huge amount of people care about this. According to the BDFL &gt; I think that at least adding static typing as an optional part of Python is a good thing for the distant future. I also think that this particular tool may be able to help Dropbox convert our own Python 2-based codebase to Python 3. 
Did you really just say Django is a bad library?
It was removed from Unity a long time ago, and it wasn't created for Unity - it's standalone, but its development stopped.
Tbh, my guess would be that you are either being deliberately obtuse, or really misunderstanding what I'm trying to say. You asked for an explanation of the term "aviation grade", and I explained the different problems that aviation software has traditionally had to deal with that have not been suffered by large scale web companies - namely the need for very reliable software without the physical redundancy of a large datacentre. Historically, this has been a lot more of a problem, as planes rely on being as light as possible to carry as many people as possible. Large, heavy computers (as computers have not always been as small as they are today) and also the historical expense of computer hardware (again, we have much cheaper and more efficient manufacturing processes these days) have meant that physical redundancy has not always been the most ideal way to achieve the required confidence in software. I'm not saying physical redundancy is not used in aviation, just that it has had much greater limits than, say, Google, which can give over huge warehouses for use in their computing network. Obviously that sort of scale is entirely impossible for an individual plane to carry, particularly given that a large portion of those warehouses is given over to cooling the building to avoid overheating. I'm also not saying that one is better engineered or designed than the other - you seem to be taking a personal affront to the idea that any airline might possibly want to do things differently to Google. Both situations had their own pressures that lead to different solutions. One of them became known as "aviation grade", although tbh I've more commonly heard the idea of critically safe software being referenced in relation to NASA or nuclear power plants.
UnityScript is not deprecated at all
what if I cannot modify ```__get__```?
And you can get awesome performance benefits pretty easy. Just yesterday someone posted a module that can cythonize type-annotated functions in 3.6.
The 747 is a flying UNIX box from the 1970s with 3 computers in case some break. And I will bet money that they made sure to have at least 2 different architectures in case of a hardware bug. I don't understand why they can't make adequate use of redundancy, given that they have 3 times as many computers as they need, and we've had the ability to mount more than enough computing power in planes for over 40 years.
Sure, once i get a bit further in. 
I only found out about this a few days ago, and I'm very impressed by the start up times being so much quicker than cpython. I said in an earlier post, it now makes it possible to shell out to a python program from within another, without lagging the user when its run.
Convert to the frequency domain (numpy.fft.fft), apply a high pass filter to get rid of frequencies you don't care about (scipy.signal.butter), convert back to the time domain (numpy.fft.ifft), and then get the peaks (scipy.signal.find_peaks_cwt)
In this case it means a ["DO-178B-inspired"](https://sqlite.org/hirely.html) process. Though one would need to inspect the code, test suite, and development artifacts oneself and determine whether or not a) such a process was actually followed a d b) such a process is sufficient to qualify as "aviation-grade."
You don't have to use an index, and can iterate over a dictionary https://www.mkyong.com/python/python-how-to-loop-a-dictionary/
Thanks, that's useful.
I kept reading wondering when it would tie into Python. Add that to the pile of minutes of life I will never get back...
The flow of gevent code is generally the same as that of asyncio code. gevent's greenlets are coroutines just like asyncio's coroutines. Within them, you can write regular single-threaded code. &gt; code that only really works in gevent. Are you sure you don't mean asyncio here? I sometimes write code that can fall back to threads when gevent isn't available. I don't think that's possible with asyncio.
iirc 3 computers helps prevent errors caused by cosmic radiation
People who do real time algorithm work, e.g. embedded vision, care a lot.
That is definitely a reasonable approach-- essentially doing the same operation in frequency space.
FFT?
Can you please elaborate, I am not sure I understand your comment.
There's an oddity around variable annotations that isn't super obvious: you can annotate a variable without defining it. &gt;&gt;&gt; bob: str &gt;&gt;&gt; bob Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; NameError: name 'bob' is not defined &gt;&gt;&gt; import sys &gt;&gt;&gt; sys.modules[__name__].__annotations__ {'bob': &lt;class 'str'&gt;} I don't think most people will run across this behavior, but I thought it was kind of neat.
Yup, you are right. "the advantage of generators is they allow you to extract and utilize data as it is being processed, instead of waiting until the function is finished". Iterables and iterators provide the same advantage too, i.e allows you to extract and utilize data as it is being processed. Generators are similar to iterators, in fact generators implement the iterator protocol of Python. In this post I wanted to focus to validate that generators implement iterator protocol. I did this by calling iter() and next() on generator.
If you read what I said, Becoming an adviser for a % of the profits + I will also pay once I regain money. It's a good opportunity as I will not be giving away any % once I regain capital as I will out hire straight. It's a great opportunity, if you want to make it in life, you have to take risks.
I disagree on one point: Generators should be used when the data is "large" and the resources are "scarce.". Iterables can be used for "large" data and "scarce" resource too. In fact everything which can be done with generators can be done with iterators. Though generators can help achieve the same thing as iterator with much fewer lines of code. But there are certain things which can only be done with iterators and would not be possible with generators. See https://stackoverflow.com/questions/2776829/difference-between-pythons-generators-and-iterators#answer-2776865 Please let me know if I am wrong.
I haven't even discussed anything about the project, if someone is interested they can message me on skype to understand more.
Never tried. In the future use Git or some other form of source control. 
Hey, tell him to check [this stack overflow question](https://stackoverflow.com/questions/41405001/pygame-installation-for-python-3-6-0). If it doesn't help, one ugly solution would be to downgrade python (I had to do it so I could use pygame on a project a few years ago).
I'm working on a small library to enhance the python `typing` library. One part of the library is to add useful classes for ensuring values fit the expected types. I've started writing a couple of [base classes](https://github.com/dangle/typingplus/blob/typedobj/typingplus/types.py#L629) that create properties for your annotated class attributes. That way, you can write a class like this and get a TypeError: class MyObject(TypedObject): my_int: int my_obj = MyObject() my_obj.my_int = 'Hello, World!' 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [dangle/typingplus/.../**types.py#L629** (typedobj → bd11be1)](https://github.com/dangle/typingplus/blob/bd11be198b9f38a6a70ae0e87dd3963de1fda82b/typingplus/types.py#L629) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dp85s6i.)^.
Interesting, I'll keep that in mind. I'm not sure I can do that though, as to condense things I was thinking of assigning multiple values to the keys in the player dictionary (using a tuple). players = {"Name" : [SkillValue,PointValue]}
Python itself has a small logo. Home they make better logo this time. 
I am Planning to start learning Python. Please advice a good website or a book to start with.
Here's all of the things you can do with the new format and not the old one: https://pyformat.info/
I used Active State's Active Python to fill this need on San outdated CentOS box.
Finishing a Flask app for a Cisco Callmanager deployment to deploy a custom directory lookup for hard phones, ccx, and a jabber custom tab. 
"leaky abstractions"?
^ This Also, go to dsp.stackexchange.com (Digital Siganl processing). 
There are very few sources of _true_ "randomness" out there. Numpy's PRNG is good enough for just about anything, except maybe strong crypto. 
Okay, so it's more than good enough for just about any statistics work I'll be doing. Thanks!
EasyPythonDecompiler explicitly states it only works up to 3.4. The uncompyl6 package doesn't seem to have a wheel for 3.6, but it seems to claim support for it. However most of the build instructions seem to be Linux-centric and while there is an AppVeyor yaml file for windows CI builds, there's no link included in to see if they succeed. How did you install it and what happened when you tried it? You could also try [pycdc](https://github.com/zrax/pycdc), but that looks harder to build and doesn't explicitly state support for 3.6. Apparently 3.6 changed a lot of semantics and these projects haven't really caught up yet. Doubt you're in a position to just wait and try again every couple of months, though.
Followup, is there any sort of function that automatically pulls true random numbers in a way like random.org generate random data based upon weather data or another sufficiently random source?
It's probably because python is so much more widespread than those other languages that they expect you to just pick it up from the repo. And you have to be careful about installing new versions because it's easy to break core system utilities (that are written in Python). If you find yourself in a situation where you want to maintain your own version of the software, you should be comfortable compiling it yourself. Even better, you should know how to get the build files your distro maintains and use those to build a package of the newer/customized version. If you're trying to maintain multiple versions of python on one system, I'd highly recommend using Docker instead. There are a lot of things I dislike about it and its hype, but dependency isolation is exactly the problem it solves.
Random.org lists some applications: https://www.random.org/clients/http/archive/
Oh wow can't believe I missed that. Thanks!
Technically any software-based random number generator (even one using **/dev/(u)random** as a source of entropy) is still a Pseudo-Random Number Generator (PRNG), it just *might* be a Cryptographically Secure Pseudo-Random Number Generator (CSPRNG). Looking at the docs, **numpy.random.RandomState** uses the same algorithm (Merseinne Twister) as Python's **random.Random**, and is designed to provide reproducibility with the same starting seed and number of generations. This is **not** a CSPRNG, however it is probably more than suitable for statistical modeling. If you *need* a CSPRNG-quality source, you can use **random.SystemRandom** or the new **secrets.SystemRandom** (although, here's a hint, that's just an alternative entry point to **random.SystemRandom**), but if you're generating a LOT of data, then you should know those use **os.urandom**, which uses the *non-blocking* **/dev/urandom** source; the underlying implementation of that varies wildly by OS, but tends to have the property of starting to re-use the same entropy once it's been called enough times to exhaust the pool of **/dev/random**. But, to repeat, the numpy PRNG is almost certainly sufficient for academic work, I just wouldn't use it to encipher anything you don't want superpower-level nation-states reading.
&gt; But why is there no generic static build for python on linux? Lack of need would be my guess.
I'm definitely asking more for my own curiosity, as I noticed that real data scientists seemed to consider numpy's PRNG good enough to consider random, but I had an older-school Psychology professor (very much not a computer guy) that used to actually pay for lists of random numbers that he used as a seed. I'm guessing he did that more out of "that's the way he's always done it," but thanks for clarifying about all that!
This looks promising, I'll give it a try.
IronPython hasn't been updated since last year apparently, is it still in development? Maybe they favour statically-typed languages, e.g they have UnityScript (whis is also [deprecated](https://blogs.unity3d.com/2017/08/11/unityscripts-long-ride-off-into-the-sunset/)).
The *factoring* of really big primes is critical to modern cryptography, as is choosing those initial primes using a CS PRNG... generating them isn't that hard, that's one of the *many* computers are ludicrously good at. People still pay for "true random" sources; back in the day there were little old ladies who were paid to draw numbers out of thoe cages used to hold lottery balls and write them down fastidiously in books that were then extremely valuable to the sort of people who really don't like having their minds read. A lot of paranoia at times went in to trying to prove that those little old ladies weren't getting lazy and cheating. But for statistical purposes and if you don't for some reason re-use a seed, the Merseinne Twister is probably suitable. If you need truly huge amounts of random data, then you might want to generate that by concatenation of several Twisters that are started with seeds chosen by a CSPRNG and not run any of them long enough to hit their period, but I'm talking like terabytes+. 
&gt; It's probably because python is so much more widespread than those other languages that they expect you to just pick it up from the repo. And you have to be careful about installing new versions because it's easy to break core system utilities (that are written in Python). I remember I broke PIP by upgrading to a version that wasn't in the repos and it was a painful process to fix it. Only God remembers how I actually resolved it.
If you know enough about their sensors and the local weather conditions, you stand a chance of guessing their output. But, more importantly, if you know where their sensors are (or just where their sensor is) and have the 101st Airborne at your disposal, you can control what others are using as their source of randomness. Random is *hard*, though it does get easier if you have a radioactive source and a reasonably large and sensitive sensor.
I code in Windows, and I highly recommend forgetting installing wheels manually. Windows...it just doesn't play well with stuff like that (in my experience -- I'm not an expert). Here's what I recommend: 1. Uninstall everything Python you've already installed. 2. Install Anaconda with Python 3.6. 3. Anaconda comes with NumPy. 4. In an Anaconda Prompt, "conda install pygame". If pygame is not available on the default conda channels (i.e., if Step 4 fails), comment here and I'll figure out if it's on another conda channel or whether you should use pip.
Why is Django a bad library?
&gt; Also, if some python veterans are here - is asyncio the future, or just one option? I always strive to use canonical, standard approaches, but here I don't know whether I am on a good path. I think asynicio is becoming the standard very soon. Just have a look at this for example: https://github.com/channelcat/sanic It made 7K stars on github in less than a year. I think that's quite amazing.
It's fine. It's not great, but you could easily publish a paper and nobody would bat an eyelid at it, though I vaguely remember it being argued that they are not cryptographically secure random number (from my understanding they are crypto insecure). If you need the best random numbers your computer can generate then use the system's random numbers. /dev/random (is first choice), /dev/urandom (is second choice). Both of those are regraded as cryptographically secure
... and? What you're doing looks fine at first glance, except you're not using **line.rstrip()** to remove the trailing newline, and your "eof" check is a little weird (does the file actually contain the text "eof"? And, if it does, will you have wanted to already append the youtube-dl call for the line that includes "eof"?). So what are you asking?
where should I add the line.rstrip()
In the line where you do: + line + Do: + line.rstrip() + Instead.
sweet thanks
Now that I see your data, you might want to move the "eof" check *above* the bit that writes the contents of the line to disk. Also there's no real reason to have the eof, just end the file at the end of the last link.
I did now I have something like [this](https://gist.github.com/haidev12/3ebcf5027c55ba05d61c31b2c23d0387) Now I am making some research on how to run each line onthe windows cmd without having to copy/paste each line
These days you should be able to run simply python3 -m pip install numpy pygame or pip3 install numpy pygame 
Just a few things (assuming you are on of the developers of this library since you are promoting it): - it took me more than 5 seconds to get to the first example of usage, that hello world. And I actually searched for it. That should be the first thing new users see. I bet you are losing a lot of potetial new users because of it - it is pretty hard to follow what happens with those controllers. You defenetely should have some how-to tutorials so that users get a better grasp on what are the best usage cases for this library. - How does it compare to other CLI libraries, such as click?
if you say so https://blogs.unity3d.com/2017/08/11/unityscripts-long-ride-off-into-the-sunset/
Docker is really awesome for deployment, but how can I use it for development?
man you just didn't say Django is a bad library :O I agree that at some level, using django leads to more pain that pleasure (needing some database that django doesn't support for example) but that's all the developer's fault because they went with a tool not suitable for their needs. Django is amazing for what it does best, and that is developing web applications with not so complex requirements in a record time.
I could just give you a version that works. For your own understanding however, I would strongly recommend that you try to fix it yourself. That's how you learn to code, really. The way you should do this is by "rubber duck debugging" the code. Imagine a friend that doesn't know how to program sitting next to you, and you telling him precocely how your code works. You'll find error this way.
use a for loop, and use /r/learnpython 
del or rmdir shouldn't completely remove it from the disk. I'd recommend https://www.piriform.com/recuva and see if the source file shows up. I've successfully recovered files deleted on accident with it.
Since generators are lazy, you can express all natural numbers in a generator, but not all iterators are lazy, thus some evaluate immediately, and cannot express all natural numbers.
For reproducibility you would want to seed the random number generator anyway, state what the published results use for a seed in your github repo, and add a paragraph how x thousand additional runs with different random seeds changed your results by only z with a standard deviation of q
&gt; I think optional typing is really important. It makes it possible to find errors at compile time rather than runtime, which can be hugely beneficial for large codebases. I think a large amount of people care about this (myself included). Given the fact that *all* of your huge codebase is typed as well as *all* of your external dependencies, this doesn't void the need for 100% coverage. &gt; I also think that this particular tool may be able to help Dropbox convert our own Python 2-based codebase to Python 3. I can understand the fact that the BDFL is working in an environment side by side with a huge Go codebase that is statically and strongly typed by design. That should be a really unpleasant situation.
Man, Python will always be Python, please don't try to make it a *worse Go*. I love Python *because* it's dynamic and it allows you to write pretty elegant and understandable code, not *despite* that.
Dev random will never not be cryptographically secure.
Can you give an example where using generator provides an advantage over iterator in terms of memory consumption.
There is practically never a good reason to use /dev/random over /dev/urandom.
Just in time, my esp32 devkit will be in the mail today! I’m so looking forward to this, MicroPython might be my second-best Python experience (after NLTK). Keep it up! :)
Download a 100gb file and try to read it one line at a time without using generators.
&gt; UPDATE 2017-11-02 10:35:00: Thank you all guys for your answers, I learned some new things. Just fyi, I was able to add asynced sqlalchemy to the script via the sqlalchemy-aio, and overall I feel it isn't that bad. Yes, another await's appeared in the code like "await conn.execute", but at least I see to points where execution will be suspended, which could be somewhat useful. Great man, glad to hear that. If you feel comfortable with asyncio just stick with that, there are a lot of excellent asynced libraries in the wild (https://github.com/timofurrer/awesome-asyncio).
Get [proper random numbers here!](https://qrng.anu.edu.au/)
I think [this is the closest thing you can get to "true randomness"](https://qrng.anu.edu.au/)
This sounds very sensible.
How about including the „py” launcher (#149)? Waiting for 3 years ...
&gt; if you're generating a LOT of data, then you should know those use os.urandom, which uses the non-blocking /dev/urandom source … SystemRandom calls os.urandom, that's literally the first mention of SystemRandom in the docs: &gt; the SystemRandom class which uses the system function os.urandom() &gt; the underlying implementation of that varies wildly by OS, but tends to have the property of starting to re-use the same entropy once it's been called enough times to exhaust the pool of /dev/random. That's some pretty serious misunderstanding of PRNG, and at this point pretty much only Linux has /dev/random be different from /dev/urandom, for nonsensical reasons.
&gt; /dev/random (is first choice) No. /dev/random should never be your first choice for anything, and unless you're 1. working during boot and 2. on linux, should never be used at all.
There are [plenty of TRNG cards out there](https://en.wikipedia.org/wiki/Comparison_of_hardware_random_number_generators) if you're willing to pay for them.
**Comparison of hardware random number generators** In computing, a hardware random number generator is an apparatus that generates random numbers from a physical process. Such devices are often based on microscopic phenomena that generate a low-level, statistically random "noise" signal, such as thermal noise, the photoelectric effect or other quantum phenomena. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
MicroPython is highly portable, and can be easy made to run in a thread of any RTOS (or yield to cooperatively-scheduled RTOS, that's how ESP8266 port works). The "WiPy" (TI CC3200) port in the mainline uses FreeRTOS. ESP32 port (not in the mainline so far) also based on FreeRTOS. 
The current MicroPython logo can be seen at http://micropython.org ("M" in the shape of snake, the isometric version "on a chip" is the main logo as far as I understand). That's the seconds version of the logo, the first (from the original Kickstarter campaign, a cute hand-drand snake sitting in a chip) can be see here: https://github.com/micropython/micropython
I personally always was interested in MicroPython on Linux, but over these years, the adoption was pretty slow (which is understood - CPython just around a corner), but recently, it's fair to say that more and more people start to look into it (based on the amount of bugreports/patches) - be it due to faster startup, or overall lightweightness. 
I'm actually not the framework author or a developer on it, but thought it might be an interesting library. I'll see if I can notify the author regarding these points.
The one issue you might run into is the seed. If your seed is the same on multiple runs, you will get exactly the same output. In academia I've seen this used properly for debugging and tutorials and I've seen it really bite people. My recommendation is to seed with the current time. That brings some real-world randomness into the process, making it closer to truly random.
Interesting, but seeding with time isn't really all that random since you're excluding numbers within the range and the time of day you work isn't random.
Hmm. I did some research and I see you're right. /dev/urandom is in fact preferred. I guess it's one of those myths I fell into the trap of. A great article on the matter: https://www.2uo.de/myths-about-urandom/ Also, I was only thinking from the Linux side where typically both are regarded as crypto secure as long as you make sure there is enough entropy at boot. Some save some, some block till they have. Thanks for the heads up though 
&gt; SystemRandom calls os.urandom, that's literally the first mention of SystemRandom in the docs: Pretty sure I said that SystemRandom uses os.urandom, like in the line you quoted from me directly below this statement of yours. &gt; That's some pretty serious misunderstanding of PRNG Please explain the misunderstanding. &gt; at this point pretty much only Linux has /dev/random be different from /dev/urandom, mostly for nonsensical reasons. So, first, you're saying that Linux doesn't matter? Like I said the implementations vary, both across the various OS platforms and across their various releases. As I understand it, *at least* on Linux, you're still capable of pulling from a re-used entropy pool if you pull from it large enough and fast enough to exhaust it. Yes, on Mac and BSD variants you'll block until reseed, on Windows you'll get whatever it is that CryptGenRandom actually does (last I looked it was closed source, so I don't know), on other OS you'll get various behaviors depending on the underlying implementation. I'm just pointing out what's potentially a problem on at least one of the top three OS options. &gt; The only point at which it makes a difference is *during boot*, which is unlikely to be a concern when you're using numpy. Happy to be educated, but why does this not matter, assuming you are on an older kernel Linux and calling `SysRandom.getrandbits(k)` with a very large value for **k** extremely often?
Not sure how much graphics knowledge there is here, it may be worth asking the PyGem devs.
If you're trying to generate random numbers for some monte carlo, then yes Mersenne Twister is considered generally to be "good enough". What is not good enough is the LCG type random number generators, which have been shown in some cases to bias monte carlo calculations because they are insufficiently random.
Yeah, right up until that 101st Airborne moment I mention above.
I'd be interested to know what % are on iot devices or maybe raspberry pi etc.
I did, to the parameter passed (num).
I want to print out the numbers the parameter takes to reach 1.
Quick question: Is there anything that OneSite doesn't do well? (Genuinely curious) I'm always interested to hear how people "work around" issues in the standard software for their industry.
It doesn't terminate. I tried it many times with very different cases. 
I have seen (reproductions of) military wargames from as late as the 1970's or so still using sheets of random numbers (0-99 or 1-100) instead of rolling dice. I think the main reason for that was not to get better random numbers but because dice have often been seen as toys or gambling so it has been easier for the military to adopt games using other forms of randomizers that seem more professional.
Oh, agreed, *practically* speaking you're unlikely to ever exhaust /dev/random sufficiently to get anything less than sufficiently random back from /dev/urandom ... but as I understand it if you were drawing on it really hard to fill, I dunno, massive multi-terabyte drives with random noise, while simultaneously never giving the machine sufficient noise to reseed and immediately after a cold boot, you'd eventually end up with a repeated entropy pool, at least on earlier Linux kernels when no hardware crypto modules are present. It's a remote risk, but I don't believe it's yet not a risk.
You can still by [random](https://www.amazon.com/gp/aw/d/0833030477/ref=cm_cr_arp_mb_bdcrb_top?ie=UTF8) on Amazon.
The value is just a list, and can be accessed as a single list. But if you have many different attrs for a player, it's time to make your player a dict or class. Two would be manageable in a list, but with 10, keeping track of the indexes may cause bugs whereas names would be clearer.
Just my 2 cents: There is nothing dramatic and awesome about gaining skills. Posessing skills does.
&gt; But why is there no generic static build for python on linux? Is compliation more encouraged as when installing python? Python should already be installed by default on most Linux distributions since many applications or system utilities use it. Golang, node and ruby is not used at all in the same capacity. If you need to use different Python versions, or library versions, then I would suggest trying miniconda. As others have already told you: mucking about with your systemwide Python installation can be a bad idea :)
Nice! I googled and found the [wikipedia page](https://en.wikipedia.org/wiki/A_Million_Random_Digits_with_100,000_Normal_Deviates) and the PDF is [available for free from the RAND web page](https://www.rand.org/pubs/monograph_reports/MR1418.html).
**A Million Random Digits with 100,000 Normal Deviates** A Million Random Digits with 100,000 Normal Deviates is a random number book by the RAND Corporation, originally published in 1955. The book, consisting primarily of a random number table, was an important 20th century work in the field of statistics and random numbers. It was produced starting in 1947 by an electronic simulation of a roulette wheel attached to a computer, the results of which were then carefully filtered and tested before being used to generate the table. The RAND table was an important breakthrough in delivering random numbers, because such a large and carefully prepared table had never before been available. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
&gt; Pretty sure I said that SystemRandom uses os.urandom No, you strongly implied that one should "know those[sic…] use os.urandom" instead of SystemRandom: &gt; If you need a CSPRNG-quality source, you can use random.SystemRandom […] but if you're generating LOTS […] of data, then you should know those use os.urandom &gt; like in the line you quoted from me directly below this statement of yours. That's from the official documentation, not from your comment. &gt; Please explain the misunderstanding. The PRNG does not "exhaust" the entropy pools, [it is regularly reseeded from it to avoid predictability (basically jumping around the PRNG's space)](https://www.2uo.de/myths-about-urandom/#re-seed), it does not "run out" of entropy. &gt; So, first, you're saying that Linux doesn't matter? No, I'm saying there is no difference between them outside Linux, and on Linux the difference is based around FUD rather than sense. &gt; As I understand it, at least on Linux, you're still capable of pulling from a re-used entropy pool if you pull from it large enough and fast enough to exhaust it. No. The only thing /dev/random does is block when [some nonsensical estimate gets low](https://www.2uo.de/myths-about-urandom/#estimate). Both /dev/random and /dev/urandom pull from the same CSPRNG output, the "entropy pool" is just a cache for a bunch of CSPRNG output and the aforementioned nonensical estimate, which &gt;4.8 /dev/urandom bypasses entirely. &gt; Happy to be educated, but why does this not matter, assuming you are on an older kernel Linux and calling SysRandom.getrandbits(k) with a very large value for k extremely often? [Why would it matter?](https://www.2uo.de/myths-about-urandom/#low-entropy). If you ask actual cryptographer, [they tell you to use urandom](https://www.2uo.de/myths-about-urandom/#experts).
You've just reminded me I have a player class already made, that I haven't done anything with. I knew there was a reason I made that! Lol. Sorry, too many things going on for my courses - can't keep my mind straight.
There's a bit of a problem with your approach though. A truly random number is only beneficial to you as long as no potential hacker can access it. And the random number you're fetching from random.org is always only as protected as the connecttion you use to get that number. So however random random.org's number is, you can just as well use the random generator used by your SSL protocol. 
Is there any reason why Numpy shouldn't just simply call C++'s `#include&lt;random&gt;` under the hood?
Are you sure your Py version is the 64 bit? He could've installed the 32 bit, which is very common to overlook, so just get the 32 bit wheel and try that. 
Me too. If you conduct a survey, please share the results ;-). In the meantime: https://www.shodan.io/search?query=micropython
It should do - is the function defined as you gave it up there. Eg this: def collatz(number): if number % 2 == 0: even = number / 2 print(even) return even elif number % 2 == 1: odd = (3 * number) + 1 print(odd) return odd answer = int(raw_input("Enter number: ")) while answer != 1: answer = collatz(answer) Runs fine for me, regardless of what I enter (though incidentally, I'd take the print statements out of the function, and put them in the loop instead, but that's a style thing rather than anything that should change anything) Is there anything you're doing obviously different? If not, what exactly do you see? Does it print anything? Is it stuck in some kind of cycle, or endlessly growing?
`time.sleep(10000000000000000000000)`.
 for i in xrange(10000000000000000000000): time.sleep(10000000000000000000000)
Webscraping! BeautifulSoup is so much fun. I'm having a problem though. My py program is kicked off via a shell script that takes a url as an argument. I want to run this script every hour. I'm on OSX so I'm supposed to be using [launchd](http://www.launchd.info/). I have no idea how to use this correctly I guess? I tried writing the launchd config xml by hand at first based off examples from the documentation. Then I used [this free lil guy](http://launched.zerowidth.com/) to generate it for me. Still no luck. Oh geez and then there is PyQt4. I need the webkit from there so I can run the JS on a few pages to generate a fully-rendered page that I can soupify. Installing PyQt4 is a pain in the ass. I've tried several ways and I still can't import it in my python3 interpreter. Ugh. Besides all that overhead, webscraping and NLP in Python is a blast. If all you need is Requests/BeautifulSoup/NLTK, you can get a whole idea operational in less than hour. Insane.
This gave me a couple cool ideas. Any libraries you'd recommend me to look at?
Random.org offers 20M Rand() numbers for free. Could use those as seed values. There random number generation is based on atmospheric noise.
&gt; No, you strongly implied that one should "know those[sic…] use os.urandom" instead of SystemRandom: I rather believe I didn't, nor was the use of "those" incorrect, the clear implication of the line above is that "those" are **random.SystemRandom** and **secrets.SystemRandom**, which, yes, are two names for the same code, but that's not precisely clear from the docs and without looking at the source. Now, that is an interesting link, and I has helped me understand somethings that I haven't fully grokked, so thanks for that, but: &gt; The view espoused here is certainly a tiny minority's opinions on the Internet. Yes, it is, and until now I'd came mainly across the opposite view, and certainly the one expressed in the man pages the author rails against, but also by others who at least proclaim themselves to be True Scotsmen. There is a nice bit about how he believes appealing to authority isn't valid, then appeals to authority, but the overall argument does seem sound. Except at boot up, especially first or cold boot, on a VM or (extrapolating, but for all I know) Docker images. Still, though, I wasn't saying to *use* /dev/random, I was trying to point out that, in the majority view at least; there is some information theoretical risk with using /dev/urandom when it comes to generating "True" random numbers in **very** large quantities... I still totally and I think very explicitly recommended that OP use the non-CSPRNG that doesn't even use /dev/urandom for OP's stated purposes.
 while True: pass Tada: infinite time. Or at least until cosmic rays flip that True to False in memory. 
Ooh, errata! Yeah wouldn't it be funny if there was a couple or appendices about how number 11,024 on page 126 wasn't *actually* random.
if you can us a loop, just `while true: pass`
 def Ackermann(m, n): return n + (m &lt; 1 or Ackermann(m - 1, n &lt; 1 or Ackermann(m, n - 1)) - n) That's the Ackermann function. Takes a ridiculously long time to run. You can write it in a single line if you make it a lambda.
 x = [0] z = [x.append(y) for y in x] Will run as long as you've memory left :) 
The RNG uses SHA256 IIRC. Or some form of cryptographic hash. Good fucking luck. If you're reading terabytes of data, you're not going to finish until the sun dies if you use /dev/random. Oh and they use the same exact pool so you'll get the same issue with /dev/random, it'll just take you years to actually notice it since the entropy estimate "fills up" at maybe 6 bytes per second on my machine. If that.
Nothing wrong with using a little hyperbole to catch the eye of his target demographic.
If all you care about is non-cryptographically random numbers, seeding with the current time is fine, since it's never going to repeat, practically speaking.
I found [this blogpost](https://blog.ytotech.com/2015/11/01/findpeaks-in-python/) last year that gives better peak detection alternatives to scipy.signal.find_peaks_cwt.
Thanks for the heads up. I'll take a look at uwsgi and nginx. This is a huge help!
I think numpy is C, though it does use C++ extensions, but the key thing is it's not going to be inherently any better than the same algorithm in C, or for that matter Python, at least in terms of the resulting randomness. Also as I've tried to make clear in other posts, but for the purposes of generating unable-to-be-distinguished-from-cryptographically-random-data that will nevertheless **not** be used for cryptography, there's really no reason to try and improve on Numpy's own facilities, just use a throwaway seed that you never use again, and with a good PRNG the result is still indistinguishable from noise unless you generate a really, really large number of them without re-seeding the generator.
 time.sleep(10**10**10) You might end up spending more time computing 10^(10^10) than sleeping though. (That's a one followed by 10 billion zeros)
I made a maze generator that saves to an image, message me later if I don't update this post with a link to it's github page
not really. depends on if you're worried about hacking or statistical correlations in your PRNG.
it's a seed tho.
Just a note, you don't need to be the NSA to crack PRNGs, a dedicated hacker with a sufficiently leaky application (e.g. forcing http500 errors with a "sorry we crashed here's a bug tracking number" over and over again) can crack a Mersenne Twister without breaking a sweat
Assuming [this](https://www.2uo.de/myths-about-urandom/) is correct, they never used the same pool -- which I didn't know -- and in newer kernels /dev/urandom uses no pool at all. Either way, I wasn't trying to imply that there is necessarily a practical problem, there's just a theoretical one. Even according to that link, apparently by True Scotsmen, there *is* a practical risk with freshly first-booted / reinstalled machines using older Linux kernels, VMs (and I'd assume likely Docker images), and I'm just trying to pass on the point they there's a theoretical risk when creating ludicrously large numbers of random digits on limited hardware.
&gt; Both /dev/random and /dev/urandom pull from the same CSPRNG output What? /dev/random does *not* use CSPRNG in its output.
That doesn't impugn their ability to be used for generating statistical data.
I too only have moderate experience with async in python. Even less experience with golang but it sure seems a heck of a lot easier &amp; cleaner. Iv'e read somewhere they don't want to fix concurrency in python because it would break so many libraries etc etc. To me that is quite silly because if they provided the tools for the community to convert their libs easily or in the least painful way and make it a stated goal so let's all pitch in and help then im sure it would happen a lot faster than they think.
&gt; What? /dev/random does not use CSPRNG in its output. Today you learn: yes it does. /dev/random gets its stuff from the "blocking pool" which is filled by the CSPRNG.
Try r/learnpython Also, it could be useful to be more specific in your question. &gt; Q: Help, I'm lost! &gt; A: Where are you going?
I read the official tutorial. I didn't understand everything but i did understand most. If you code the examples so that you remember and go back to it later on you will understand it all and also ensure you don't miss some important stuff that you might miss in other tutorials.
No, but for *anything* security related, not just high-priority-nation-state security, PRNGs are A Bad Thing. Even a dinky little web app should *not* use things like a Mersenne Twister such as provided by Python or NumPy. That's the whole reason for `secrets` being a thing.
That it would be a completely unnecessary dependency on C++ while Python's standard library already provides an MT implementation and access to the system's urandom.
the fuq
[There's modules you can buy that attach to your computer that do that for you](https://en.wikipedia.org/wiki/Comparison_of_hardware_random_number_generators). They're required for various crypto uses, but in your case you're likely not to need it. 
**Comparison of hardware random number generators** In computing, a hardware random number generator is an apparatus that generates random numbers from a physical process. Such devices are often based on microscopic phenomena that generate a low-level, statistically random "noise" signal, such as thermal noise, the photoelectric effect or other quantum phenomena. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
Obviously it's pseudorandom, but [they say it is based](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.RandomState.html#numpy.random.RandomState) on Mersenne Twisters. Mersenne Twisters is a specific type of pseudorandom number generator (PRNG). Different PRNGs have different statistical property making them good quality or low quality. The most common statistical test suite for them is called [Diehard tests](https://en.wikipedia.org/wiki/Diehard_tests), and Mersenne Twister pass them all. That makes Mersenne Twisters generally regarded as high-quality PRNGs, suit fored for academical purposes. This comes with the warning that Mersenne Twisters are not particularly fast (for high-quality fast prngs a very recent one is [xoroshiro](http://xoroshiro.di.unimi.it/)), and that they are not cryptographically secure (meaning they are not tested against adversarial behavior). But those are totally different requirements that what you asked about: many random-based algorithms would never be as fast if they had to be cryptographically secure for no reason.
Right, but that's not the topic of this thread. Nobody has suggested using Numpy's RandomState for hashing passwords, or anything else security related. Also, everyone should read the source of **secrets**. It's a short wrapper module around parts of **random** and some convenience functions, it's not doing anything fundamentally new, it's just making some better practices available under a new name and with better documentation.
Two lines, though.
I don't disagree. I actually did a google search and nothing very convincing came up as far as what "aircraft-grade" meant where software was concerned.
While I agree on the unnecessary dependency part. Numpy only gives one random generator the popular Mersenne Twister algorithm, C++ has many more, this is what's missing in Numpy and could be easily shared from C++. See: http://en.cppreference.com/w/cpp/numeric/random
So, curious if you noticed that there's a consistent pattern of a relatively "sparse" band of the maze at around the 10th "row" from the bottom. Seems like there's consistently far fewer horizontal lines in that band.
I don't know how that monkey-patching in gevent exactly works, but in the async/await approach, you implement coroutines where you will explicitly tell that here on these points the coroutine can be stopped and loop can then resume the next coroutine. I don't think this can be easily automated. But according to my limited understanding, this is intended to be used only in libraries which are waiting for some I/O operation to finish, so they can be stopped while they wait. But if that's not the case, then their code still needs to be run in separate thread or process to achieve speedup. 
&gt; Numpy only gives one random generator the popular Mersenne Twister algorithm, C++ has many more Which are mostly no good (ranlux would be the only one of interest), and which could easily be reimplemented in numpy. &gt; this is what's missing in Numpy What's missing in Numpy is a shitty LCG?
Ok thanks. So to be more precise: I have 3 sets of data against a single variable: ppm silica, ppm calcite and ppm phosphate (dissolved in the ocean) vs ocean depth. I need to produce 3 graphs of them next to each other. The data is being read out of a simple text file. I shall look up r/learnpython thanks
&gt; 3 graphs of them next to each other You can do that with factorplot in seaborn module. For example: import seaborn as sns q=""" select cast((case when Age &gt; 60 then 69 else round((Age+2.5)/5)*5 end) as int) as AgeG, C as Class, sum(S)*1.0/count(S)*1.0 as Ratio, 1 as Tt from df2 where Age is not null group by case when Age &gt; 60 then 69 else round((Age+2.5)/5)*5 end, C """ a = sql(q) g = sns.factorplot('AgeG','Ratio', col="Class", data=a,kind='bar', margin_titles=True) [Output](https://imgur.com/a/mT2Oo) 
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/Mlo4FLx.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) 
So it is great for current property reporting. I️ do our acquisitions so my problem is getting current data output in an actionable manner. Most reports are either PDF (ugh) or Excel (but poorly delineated) 
how to posess without first gaining?
There are many use cases where you do not want a MT. Speed? Cryptography? Research? Even if you use `/dev/urandom` you can predict MT's output after only 624 values....
&gt; but I had an older-school Psychology professor (very much not a computer guy) that used to actually pay for lists of random numbers that he used as a seed. So that is ancient and is basically a holdover from pre-PC days. Back when state of the art at a University was a mechanical tabulator of some kind. Companies would publish books of quantities useful for researchers including: * Books full of random numbers physically drawn from tumblers (like they do for show with lotteries). * Books full of values relevant to statistics, like Z-scores or the values of error function * Basically any hard to compute integral or other numerical value could be purchased in dead tree form, provided it was common enough. Using these standardized tables enabled researchers to cross check each others work, and avoid silly mistakes. Its no good to have a paper rejected for publication because the reviewer miscalculated a z-score while verifying your primary claim. As for random numbers it was a good way to provide a common seed: "I used the random numbers in the third column from page 78 of A Million Random Digits (1966)", and the publisher had ostensibly done some testing of the digits to verify that no obvious biases were present. Nobody uses this shit anymore, forget about it. You can still buy this crap online, but it has no practical real world value. A modern PC could generate "a million random digits" in the blink of an eye. It could then perform hundreds of correlation and verification tests that weren't even considered in the 1960s. You get better quality from a modern RNG with a fixed seed than you do old books like that.
You can also use a fitting tool to fit the sin wave to the data. Something like (py)ROOT could do this, or even scipy.optimise tin this case.
Can this make smaller size mazes?
Why does the small picture on resort has a typo but the one on the site itself doesn't? Trick to make people click the link? It worked.
Thank you very much!
you'll hit recursion limit before it executes more than a milliseconds tho..
I have long been wanting to spend time on political issues with data science. Did you just google for this dataset or did you learn of it somehow else?
&gt; There are many use cases where you do not want a MT. Speed? Nice strawman big guy. &gt; Even if you use /dev/urandom you can predict MT's output after only 624 values…. Er… no shit? What's the relevance of /dev/urandom to MT oracles?
I thought for both NumPy and `random`, if you call `random.seed()` it will use the system random source. So while the Merseinne Twister is, be design, pseudo-random, if the seed is truly random, isn't that acceptable? I am also pretty sure (though maybe not), given a series of random numbers, you can't back out the seed (right?)
Could do it in one line too I believe.
I don't see a picture, but chances are that someone on the website corrected the typo, but that it hasn't updated here yet.
Only be cheating but yea. 
Too bad they don't have the ASTM rainflow counting method. It's useful for fatigue analysis and gives you sorted pairs of max-min peaks. They describe a Fortran implementation in the report and it's not too hard to write in Python. I'd really like to see that method vectorized though.
Interesting explanation. Thank you for your time and knowledge.
&gt; find_peaks_cwt Man I wish I knew about this sooner. I wrote my own kind of algorithm to find peaks. But I also applied a `butter` filter with `filtfilt`. But again, I am not an expert in signal processing so my approach may be very basic.
&gt; and not hard to implement You volunteering to add these into numpy?
Now to make a twitter bot that solves your mazes...
Simmer down, Confucius.
We are brothers, as I did the same.
You're asking this while suggesting that all existing numpy build architecture should be broken?
It's certainly acceptable for non-cryptographic work, it's **not** acceptable for cryptographic work: the whole point of the Twister is that it's a *Deterministic* Pseudo Random algorithm... starting with any specific seed, you'll always get back the same series of values, though those values will be *apparently* very random in relationship to each other. This is a huge advantage in certain kinds of work (I'm in VFX, when we move simulated hairs around we want the apparently random motions to be reproducible), but yes an attacker with a sufficiently large ordered series generated from it could brute-force reverse it. That's why you simply don't use it in cases where someone knowing your seed is *bad*.
Thanks! `format()` really has some neat features!
On a quick scan through this has some weak advice; I note that the the submitter and the author are the same person. For instance, *How to make an attribute in a class private*, the attribute `side_up` **does** change to 10, but the `get_sideup` method isn't looking at it any more. Furthermore, *Using a method to modify the value of the attribute* completely ignores the correct Pythonic way of using getters and setters, which should explicitly **not** be used in Python. You should define a property, like so: class Employee: def __init__(self, name): self._name = name @property def name(self): return self._name @name.setter def name(self, name): self._name = name 
Download and install these wheels https://www.lfd.uci.edu/~gohlke/pythonlibs/
This is the right answer
True enough.
Airflow relies substantially on a bash shell (look at things like the Scheduler or task-triggering). I would avoid running it on windows at all costs. The Raspberry Pi sounds like a good option. You can use things like Remote Python Interpreters in PyCharm to write code in Windows and then execute remotely (on your Ubuntu env). You can use things like Virtualenvs to install Python 3.6 in your Ubuntu machine, and then run Airlfow inside that 
There should be a site wide rule that an OP must call themselves out if they are the author or what they are submitting. Kind of getting tired of everyone posting their shit to get traffic. Whether its programming, sports, or underwater basket weaving the OP should be transparent. It just seems somewhat deceiving otherwise. 
Large primes are important for asymmetric cryptography (encryption with a private-public keypair) based on using integer factorization (modulus is product of two primes) or discrete logarithms. There are [efficient algorithms for testing a large number for primality](https://en.wikipedia.org/wiki/Primality_test) (e.g., check whether a few thousand digit number for prime in milliseconds on a standard computer; check whether N is prime with a running time of O((lg N)^(4)) or better). Note these efficient algorithms can tell you some large number is or isn't prime, but will not tell you how to factor it if it isn't prime. Finding the [factors of a product](https://en.wikipedia.org/wiki/Integer_factorization) of two large primes is still very difficult. Best known factorization algorithms on current computers is sub-exponential which is still very slow, though efficient quantum computing algorithms for factorization exist (Shor's), but quantum computers that can run such algorithm on bigger than 21. Granted, the main problem with using Mersenne Twister PRNG for crypto purposes is it's predictability. Even though numbers don't repeat until you've gone through a very long period (2^19937 - 1), it's internal state vector is relatively small so if you observe [624 successive random numbers coming from MT19937 (the common form), you can then predict every future random number to be generated by the MT](https://github.com/kmyk/mersenne-twister-predictor). So if for example, some website creates random 256-bit encryption keys for every user that were seeded with eight consecutive MT19937 32-bit integers, an attacker could request 78 encryption keys, observe 624 numbers. Then they could predict every 128-bit random key that site would generate (and decrypt traffic intended for other users by reducing the sample space for potential keys greatly).
If you need something that runs on Windows you can look a Luigi for a similar functionality.
&gt;Note: &gt;When you want to import a class to another program, make sure your program files are saved in the same folder. Um...So packages just aren't a thing? We're just going to ignore subfolders? __init__.py files? Move along, folks. This is python 101 level stuff and most of it isn't even particularly well written or informative.
What packages do you use for something like this, i.e. how did you get started/are there tutorials on this?
&gt; I'm on OSX so I'm supposed to be using launchd. Maybe try [crontab](https://ole.michelsen.dk/blog/schedule-jobs-with-crontab-on-mac-osx.html)? &gt; Oh geez and then there is PyQt4 Have you considered tkinter, I don't believe it's as flashy as Qt but it's the GUI I started with and still use for personal projects. Cheers!
I like how it has support for logging. I do not like use of Argparse because it is so low level. Pyinvoke was my recent step up from argh. But this is nice to know about.
Here is a list of threads in other subreddits about the same content: * [mclmza/linkedin_learning_courses_downloader](https://www.reddit.com/r/openintel/comments/79vrj1/mclmzalinkedin_learning_courses_downloader/) on /r/openintel with 1 karma (created at 2017-10-31 21:36:19 by /u/5uture) ---- ^^I ^^am ^^a ^^bot ^^[FAQ](https://www.reddit.com/r/DuplicatesBot/wiki/index)-[Code](https://github.com/PokestarFan/DuplicateBot)-[Bugs](https://www.reddit.com/r/DuplicatesBot/comments/6ypgmx/bugs_and_problems/)-[Suggestions](https://www.reddit.com/r/DuplicatesBot/comments/6ypg85/suggestion_for_duplicatesbot/)-[Block](https://www.reddit.com/r/DuplicatesBot/wiki/index#wiki_block_bot_from_tagging_on_your_posts) ^^Now ^^you ^^can ^^remove ^^the ^^comment ^^by ^^replying ^^delete!
Improve your skills by ignoring properties and packages!
Please add a warning that people use classes way to often. Classes are a way to store state and state causes bugs. Python is also functional so prefer using those features before diving in and using classes. I good rule of thumb is only create a class when you are creating a new type. It's sad how easy it is to spot python code written by a Java developer... Sodding classes everywhere.
I should clarify I am only running it on a windows machine to test getting it working and learn how to use it. Once I do that, I will be paying for a digital ocean linux server to run it. 
So increase it manually or run it with coconut.
Do you think luigi is as good an option? I'm relatively new to python (being using it for less than 6 months) and am just getting into scheduling. I've read a lot of people prefer airflow but my main concern is something not too complicated. 
Read right to "there are two kinds of programming: functional and object-oriented" and came back to down-vote. If this is a tutorial for beginners you should be talking about procedural vs object-oriented programming and leaving functional programming for a later lesson. Also the definitions given for the two terms are so vague as to be useless.
I always use the thin plate surface spline documented in section 2.4. It does extrapolation as well. I haven't been able to make scipy produce such nice results (assuming you know to not put dupliate points at the same "z" value and don't overfit). It's a method that's used in aeroelasticity, so it has a bit of a different application vs. PyGem which seems to be more graphics based (e.g., it's more physically based). https://simcompanion.mscsoftware.com/resources/sites/MSC/content/meta/DOCUMENTATION/9000/DOC9182/~secure/aero.pdf?token=zRSPmKmLENgQ1qRiPxlD!fKHJdvKjFjfg8Q1glNKXZbWy7GzFkwczNJKwaVCUR4oZXvsB9Spa2oba2OkDCtHcS-vjSql8QfkTwI!NT5Odndf9XWx7eapnMsVEdEWH!jNGkqdcDz1Wid8fynuJFR2x2ZhhFv5FjuQQ!XnWQ1MxuqhheURgoZO4fhW2YT!6m5zxxNj!YSzXWsSQXntmquO1sRShjnWC5Cm7Y!6QoEwk24=
Django brings much more issues than features. Maybe it would be a good library in a language like Java, but in Python it's just off. I maintain a legacy project that was written in django, and still have to fight its quirks all the time. It's heavy, slow, complicated, and too much overengineered for python. In the meantime I've written tens of Flask applications that do much more than that one while needing almost zero maintenance and being fast, reliable, and small.
It's possible but annoying. There are several Node tutorials out there that are pretty easy to apply to Python 
But sometimes you need the performance. Isn't it better to annotate one function than to completely switch languages?
Having a project is king and google is your best friend. Write a program that prints out the lyrics to 100 bottles of beer on the wall.
If you are uncomfortable with the absence of Null in Go, you will be shock learning Rust. It has nothing equivalent to None, Nil, Null.
The book referenced by the blog author strikes me as having some fundamentally unsound advice, judging by what has been excerpted.
Anyone else just read the word. "Basic" like a billion times in the first paragraph? "Prepare to learn the basics" "ok so on to the basics" "So, basically..." lol Jesus Christ 
I ran into the same issue a week ago. But bc I have a running jenkins server this is not as pressing. What are your goals with airflow?
/r/learnpython 
u fail it
micropython suuuuuuucks. batteries not included and are nuclear (will give you cancer)
it really "opens up" embedded programming (because you will want to smash your hardware with a hammer).
hehehe.... My bad. Thanks for the contribution.
If you have an updated Windows 10 instance, it comes with the Windows Subsystem for Linux. You can install Python (from source, apt-get, or using Anaconda) inside the subsystem and use that to develop. Alternately, could look into using a Docker image for a dev environment. Alternately, I think some people use Vagrant for this, but I'm not sure if it works on Windows.
thanks for your constructive criticism, your points are noted. I was trying to use simple terms for a beginner to understand.
&gt; that used to actually pay for lists of random numbers that he used as a seed damn I should get into that business
Other than that, I obviously didn't have much else to complain about. 👍🏻
It was a mistake I rectified. it is not any trick. Thanks for pointing out the error. it was valuable to me. 
It was never a trick just a typo error. I have made the necessary corrections. Thanks for the observation.
I'd wager that it's not much of a growth industry these days.
Thanks for this... 
That was what happened. 
You are definitely right. Thanks for your contribution. 
If you give me a bunch of numbers in sequence out of the *Random* book, using mine, I'll be able to predict the next number at some point. Are you claiming that the numbers in the book are not random with respect to one another? I think you need to "scope" (contrived term) the randomness, such that *within* the *fixed* 2&lt;sup&gt;19937&lt;/sup&gt;-1 MT sequence, the numbers are not measurably correlated with one another. For cryptography you need a world-scope, so you need to generate novel sequences.
Enjoyed your post. It's noteworthy that the peewee orm takes advantage of this knowledge of sqlite3. I've been using peewee a lot more these days and there wasn't a week that went by when I use to think 'hey, maybe I should be using raw sql calls here to speed things up'. Only to discover that when it comes to performance peewee's got most of my use cases covered. And now I know why.
Thank you anon. I finally got it through a shit ton of trial and error. I do appreciate your reply though! This is all I have to give !RedditSilver 
###[Here's your Reddit Silver, AnonymousChimpanzee!](http://i.imgur.com/x0jw93q.png "Reddit Silver") *** /u/AnonymousChimpanzee has received silver 1 time. (given by /u/Lefty_28) __[info](http://reddit.com/r/RedditSilverRobot)__
Basically, I want to schedule a number of etl processes to run daily. Maybe some other basic python scripts too. 
Airflow gets quite complicated quite quickly. Luigi also gets complicated but not as quickly, though it's also less capable in same areas.
Depending on what specifically you want to simulate, you might wanna take a look at [mesa](http://mesa.readthedocs.io/en/latest/) for agent based modeling. 
"functional programming is programming with functions" You're not wrong, but you're also not right
Pet peeve alert. You are not computing the FFT, you compute the DFT using the FFT method. There are other methods (e.g., the actual definition). An FFT (fast Fourier transform) is a fast method for calculating the frequency response of a time signal. It's great if you have hammer hit data and very large data sets, but lousy if you have repeated data as you introduce frequencies that doesn't really exist in the signal. A DFT (discrete Fourier transform) is the actual frequency data and FFT is a method to compute that. 
Ha. Exactly the same here. I have to think about airflow some more, bc I have to be able to access windows network shares easily. And the rest of the platform is win anyway. Did you ever look at jenkins?
Thanks, I'm glad you found the material interesting!
this guide gave me cancer. Thanks
Yes! I am planing to upload smaller and bigger mazes in addition to the normal one a day :)
Saw that too, interesting how some patterns emerge :) will check it out
I would love to work on some projects with you 
I would love to work on some projects with you 
I would love to work on some projects with you 
I just started using luigi and found it really simple and got it working really quickly. There really is very little to it. Airflow looks harder to learn but clearly has more functionality but if you don't need it then use luigi. 
TL;DW: - No mention of GIL.
Going to be dedicating a whole video to the GIL and how you can work around it through processes or using c based modules that don't require the GIL to run! 
Side note: I always love these types of threads when the hardcore crypto guys come out swinging about how the only true random is to take multiple samples of moon dust off the Hale Bopp comet and multiply the angular momentum of all the electrons moving through the electron cloud of an atom off said particle. It's just such a funny topic when you think about the theory vs. practicality of this infamous hacker who can break all non-perfect crypto. I enjoy the show. (And yes, I do take it seriously when doing sensitive work, but it's still pretty comical)
You can use quantum void fluctuation if you want : http://qrng.anu.edu.au/ https://pypi.python.org/pypi/quantumrandom/
would you want to work on a bitcoin trading bot? ^^
It's bosonic (made by physicist). Heavy lead-acid truck-size batteries are indeed not included (*those* may give you cancer), instead small, flexible, nanotechnologic LiPo's are, with overheating and overcurrent protection. 
You might want to look at `vispy` instead, `matplotlib` is a little slow for interactive stuff. 
Am sorry about that, thanks very much about your feed back.
I'm contributing to pylint! I even got a hacktoberfest shirt out of it. I love pylint and use it a lot, but the amount of false positives can be annoying. pylint has a large backlog of issues. The pylint/astroid code base is a bit hard to get started with, especially because their is not enough API documentation; I just end up reading the relevant module code in question to get an idea of what's happening I just submitted a pull request to fix the false positives with the attrs library and for extend the trailing-comma refactor warning to assignments with lists e.g. `a=[5],` will now be caught as a potential line to refactor. I tried to get pylint to not throw up false positives for Pathlib object methods however, I need to understand how astroid infers types from the abstract syntax tree to actually fix it.
Checkout django-oauth-toolkit, it has all you need to run your own oauth2 provider
So if I've never worked with embedded systems, nor SoC, nor microcontroller, is a pyboard a good starter or should I try something more popular for the breadth of tutorials?
&gt; Pymunk is a easy-to-use pythonic 2d physics library that can be used whenever you need 2d rigid body physics from Python. Perfect when you need 2d physics in your game, demo or other application! It is built on top of the very capable 2d physics library Chipmunk. &gt; &gt; &gt; https://github.com/viblo/pymunk
i got aiopg up and running pretty easily with sqlalchemy. In my mine, aiohttp and async compatability are a must.
Hi guys, I’m creating an expert roundup post for my blog(www.coolpythoncodes.com) and would love to include your insights on the following topic: How to learn Python effectively- The best way. Just 100–500 words on this topic would be awesome. you can share based on your experience in a way that you are guiding someone. Deadline for submissions is 10th of November – hope you are able to participate. Please submit your entry via the link below https://coolpythoncodes.com/contact/ pls also write a brief description of yourself. Thanks
I would enjoy working on some projects. I am fairly new to programming. 
sounds like a cool idea. 
How many times have we seen this link over the last weeks? It appears that the link is deleted, then reposted, in order not to seem overly spammy.
I’m going to take a wild guess that english isn’t the OP/Author’s first language so I commend them for trying to share their understanding of the subject. I agree there is quite a bit of information lacking, especially using packages. The code examples could be improved to be a little less confusing. Such as the first example is the class Monopoly. I probably would have done a class of Player to give a more concrete example.
Doing this won't exclude numbers.
Yeah, Postgres has bunch of bizarre syntax: https://bitbucket.org/zzzeek/sqlalchemy/issues/3566/figure-out-how-to-support-all-of-pgs 
This is really the answer op should be looking at. The discussion on how to get cryptographically secure random data is not relevant to the original question.
You can't "exhaust" /dev/urandom. Once you have 256 or so bits there is literally no difference between /dev/random and /dev/urandom, as stated in the article you linked.
Looks like a lot of work went into this. To be honest it would be very helpful if you put together a more detailed description of how exactly it helps, where it fits, what features &amp; functions can it enable, etc.
Hei, I’m interested in the generator :) have the link somewhere?
Ugh. I know that pain all too well. Python + Excel can work really well, but if the sheet is crazy then its no fun. PDF: I'm working on a side project to read PDFs. I've found that using pdf2txt works pretty well for getting the text out of complicated PDFs ( http://www.unixuser.org/~euske/python/pdfminer/#pdf2txt )
I am shifting careers and almost finishing intro to CS on udacity. Sure would like to begin collaborating and work on projects.
Yes, the pyboard has the best MicroPython support, both in terms of technical capabilities and overall smoothness, docs, etc.
I am down , message me if you're up for it 
There's a little girl who will roll dice to generate passwords for you: http://www.dicewarepasswords.com/
There's also [arcade](http://arcade.academy). I haven't used any of them enough to comment on their functionality, but arcade seems to have a little cleaner API than pygame.
Why on earth would you want to further process (anything) in MATLAB???
(Python wrapper for gnupg)[https://pypi.python.org/pypi/gnupg] - latest release: 2.3.1 on 6th September 2017
Where is the code sir
i'm not an expert in python, but I can still find so many things wrong with this: 1. "The functions in a class can be accessed with an object." what about static methods? 2. you have a class called Monopoly and objects of the class are players? that doesn't make any sense and defeats the purpose of OOP 3. i don't think OP knows what global variables are 4. you have a class called `Phone_book` stored in `phonebook.py`. my head hurts. 5. `from phonebook import *`. Yeah, no. I stopped reading then. 
renpy has powered a lot of 2d python games. https://www.renpy.org/
Writing a program to automatically clock users into this program called 'TimeClock' that we use at a program in my school. It's web based so I'm mainly using mouse/keyboard controls to do it. Hopefully will have gui or console with a selection to clock in or out.
This is quite old, but a good review of this topic. http://surface.syr.edu/cgi/viewcontent.cgi?article=1012&amp;context=npac
What framework is that on the ESP for Python? MicroPython? CAn you share the link of the source? Nice project. 
That's how ut's supoosed to be! You're welcome.
Yes I have heard of tkinter but I have not tried it, I’ll look into it! Cron jobs are easier to get going in my eyes because it’s been around for much longer, but I tried launchd as OSX said “it’s like, totally our official shit now.” I’ll try this combo instead of the massive overhead combo. Thanks!
Maybe a stupid question but I've never seen that before. What are you doing and why should it be done like that? What's wrong with setting self._name directly? I'm not even sure what property's are and I've never seen method.setter before. 
You might want to work on your project in a virtual environment. It allows you to work on your project with different versions rather than whats on your pc. I would recommend virtualenv as a solution. 
Thanks, good to know there's lib like that
An excellent idea. Count me in :)
This really looks good
There are rules about not doing ut too much, i.e. someone can't just come here and post stuff, in theory. But someone engaging in the community can post their stuff once in a while. Most subs that are affected by this have disclosure policy though.
Tinder for programmers/projects would be awesome!
Please avoid being misleading, especially with beginners. 
The ESP is running stock AT commands firmware. The SnekTek director is running MicroPython. Communication is through UART, which is RS232 Serial at lower voltage levels. This is a very rough implementation but its a starting point. The basic script is here: https://www.snektek.com/air-examples/V2.0/director-plus-IoT-thingspeak-esp8266-main-V2.0.py or access it here: https://www.snektek.com/script-online.php under "getting started examples"
I feel you, but it's handy for making plots. See: https://thingspeak.com/apps/matlab_visualizations/180328?size=iframe
I want in. Bored to death with corporate projects.
Recently, I was tasked at work to implement an ETL flow. I was evaluating and playing around with both airflow and Luigi. airflow had more features but working with Luigi was so straightforward that I had managed to make a 3 node cluster and managed a semi complex workflow including some previously trained machine learning models in a few hours. You have to use cron to run, but you can run as much as you want as it wont work on something already done. 
You could do the same thing with [matplotlib](https://matplotlib.org/index.html) and [plot.ly](https://plot.ly/python/line-charts/).
Thanks
I’m not sure if that would work since there are places with no signal. I guess I certain type of fit might work. Definitely not a least square fit though.
Because that's what your company uses? Because that's what the engineers know?
How many lines of code? How long will it take to write? What are your hourly engineering costs?
Godot has a language very similar to python called GDscript and is a full game engine.
Some thoughts. - Pillow is a replacement for PIL; use one or the other. Pillow is probably more actively developed right now, and it's what I tend to use by default. I think out of all the libraries you mention should be the easiest to install. - skimage is useful. But has a lot of dependencies so it might be tricky to deploy in some cases? (Honestly I never had an issue with it though). - The fastest library? Probably depends in practice. Both PIL and skimage do the heavy lifting in C or C++, so their speeds will be comparable. You might also want to consider the python bindings for opencv, "cv2"; in my experience it is often slightly faster than PIL or skimage. But not by a huge factor. 
Thanks for the contribution, and good job keeping a positive attitude while getting feedback. Some of the people giving feedback forgot to give constructive criticism unfortunately.
[bit of a mess, but you'll get the idea](https://github.com/jchevertonwynne/pymazegen/blob/master/maze.py) it's an implementation of an incredibly simple maze generator i made whilst watching daniel shiffman do it in p5.js you pass the function and the name you want to save the png as and a size for the maze. currently it only does square mazes as i think i messed up some x/y thing somewhere draw_maze("example",100) will draw a 100x100 maze to the file "example.png" since writing it, i realise i could change some bits over to sets rather than default dicts, but i've not got around to doing that
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [jchevertonwynne/pymazegen/.../**maze.py** (master → cdea661)](https://github.com/jchevertonwynne/pymazegen/blob/cdea661188d24559248e7f4a8291ce70902a342d/maze.py) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
Would you be able to post an example? It's not abundantly clear what your aim is and the answer depends on the manipulations you are trying to do. Odds are cv2 is most likely the best library though.
Message me if you want to start some project, python beginner/advanced level here too
Do you guys think we should start a discord? I’m interested in helping out.
Algorithmic trading on raspberry pi?
from itertools import product chars = 'abc' max_len = 3 for i in range(1, max_len+1): gen = product(chars, repeat=i) print(' '.join(''.join(p) for p in gen)) 
Pillow actually works now with pip. How are you installing it?
I had to implement my own in Python for AWS Lambda, but Auth0 is a service that lets you do your OAuth with an external service.
The fastest I found is pgmagick (a GraphicsMagick wrapper): https://github.com/hhatto/pgmagick You'll have to look at GraphicsMagick's C++ documentation for most of the API, but working with images in memory is easy with the Blob class: im = Image('input.png') im.filterType(FilterTypes.SincFilter) im.resize('100x100') im.magick('JPEG') im.quality(85) blob = Blob() im.write(blob) # now your in-memory image data can be accessed directly as blob.data # (or the Blob instance used to create a new Image object) More details: http://www.graphicsmagick.org/Magick++/Image.html#blobs
Have you looked at Anaconda?
What types of problems have you been running into? I'm just curious. I've had the good luck of getting numpy, scipy and scikit image packaging alright with pyinstaller so far. Would be nice to get a heads up if more problems are coming my way. 
I’ve always wanted to do a text based adventure in python. I had an engine half made then life interfered. 
I second django-oauth-toolkit. We use it at edX.
working on a web scrape with beautiful soup as a project to reintroduce myself to python, finally feel like I have a hand on how that library works. 
1. write the server and client yourself 2. ??? 3. profit
&gt; hourly engineering costs? Even engineers don't say shit like that, you fucking smart-ass wannabe.
&gt; Technically any software-based random number generator (even one using **/dev/(u)random** as a source of entropy) is still a Pseudo-Random Number Generator (PRNG) *Technically* (to a perverse level of pedantry) a PRNG has to be deterministic, and not all software RNGs are. Those are better described as the composition of the input stochastic noise with the PRNG that turns it into the output sequence. &gt; there might be some theoretical danger of starting to re-use the same entropy once it's been called enough times in a row No, this simply isn't true. Reseeding has nothing to do with this, and you won't find a cryptographer who believes it. You might find one that supports the blocking interface, but not because you would "re-use the same entropy", which doesn't make sense. On top of that, /dev/urandom isn't used nowadays, so it doesn't even matter. 
&gt; it's internal state vector is relatively small No, it's absurdly huge. The issue is more about information leakage and poor shuffling.
I can't recommend enough the course on edx. It's from MIT and it's called Intro to computer science and programming with python. It's a great course!! Practice everyday! I'm on my fourth day and I know how to build programs from scratch now. Get familiar with python library and study when you have your doubts. 
If you look at the plot.ly link you can see that they create basically the plot in around 20 lines of code. It could be done in 10 minutes. You get the added benefit of staying in 1 language instead of switching to Matlab (especially just to make a plot).
Yes, python is already installed in LinuxMint, but it's a bit outdated. Why do you suggest miniconda? It won't affect system utilities relying on older version of python?
I mean use discord to group up 
I’m a Front-End WebDev but love working on side projects. Beginner at python and would love to collaborate on a side project. 
Hell you could even use seaborn (which uses matplotlib on the backend) and arguably write less lines of code 
Depending on how technical you are, you can read up on the algorithm they currently use to generate pseudo random numbers and what they have done to decide it is good enough. The short version is that for this to have become the standard, it has worked in all the ways that are important. It is not biased, does not have cycles, and is effectively indistinguishable from "true"randomness. While it may be cool to think about setting up a sensor and a radioactive source to your computer to get truly random numbers, it won't be better in any way that matters.
I think you could potentially do the number recognition on the arduino. You’d have to train your neural network via the computer then copy all the weights and all that into your python code on the arduino.i think the arduino could handle the math and calculate which number you put in.
For fast transformations of row data turning your pillow images into a numpy array is probably the way to go. Numpy can be crazy fast and moving between pillow and numpy is relatively quick and very easy. If you want to get fancy you can even directly modify a pillow memory buffer from numpy.
What type of application are you building?
In terms of performance, if you are asking the question, then you can always expect to be the bottleneck before Python. Numba would likely smoke all the comparisons. Numpy and knowledge of vectorization as well. 
PIL is dead. Pillow is it's replacement. Skimage is almost certainly using Pillow to actually load your images, check the default plugin for `skimage.imread()`. The fastest plugin for Scikit-image is probably `freeimage` but that's not compiled by default. Personally I normally use `imageio` for image IO: https://imageio.github.io/ It doesn't have Pillow weirdness when it comes to things like floating-point image ranges and such. As other people here have mentioned, `opencv` is the fastest for afffine transforms and similar tasks. If you need a custom algorithm use `numexpr` if it's a whole matrix operation and `numba` if it's a conditional operation. 
Two things First, combing tuples, named or regular, seems counter to the whole point of using a tuple! Use a list or dict. But that’s just my opinion. Second: &gt; TODO add a link of something to support this statement. Ummm, you may want to fix this. Or maybe it’s hard to find supporting links for a reason... 
If you need a programming language to do real things, use Python. If you need a language that can do fast operations in benchmarks, use others
Friend you want this list of game engines: https://en.wikipedia.org/wiki/List_of_game_engines 
Auth0 is not an option as they are EXPENSIVE.
Python does a lot of error checking on types and similar. Look at the actual numbers for the benchmarks, Python is reaching higher CPU loads _and_ taking longer to compute. Also lolz at the JS memory consumption... Actually implementing performant code in Python is a little silly. There are a lot of little tricks to be aware of, but no matter what you do, simple comparisons and the like will take far longer in Python compared to C, due to all the checks and object instantiation. Python is the wrapper, we write the performant code in C. Python is by far the easiest tool I have to link together different libraries. The science community wouldn't use Python if its libraries weren't fast. 
Because science
Thanks for your valuable feedback. It means a lot to me.
Thanks for your feed back.
I just make installers from `conda` virtual environments: http://www.entropyreduction.al/python/distutils/2017/09/21/bundle-python-app-w-inno-setup.html The setuptools entry points are the most unsatisfactory and fragile part of the whole thing. I'm considering writing my own little C-program that starts a Python interpreter and using Python as the C pre-processor to fill in the script-relevant details into the code before I compile it. 
Thanks for the encouragement. Am actually learning a lot from the comments to do better work next time.
What do you mean by “performance?” Do you need maximum throughput on a few instances? Do you anticipate low throughput, but do you need to optimize for request/response time? YouTube, reddit, Instagram, and Pinterest are written in Python. I’m pretty sure that it’s performant enough for you. 
It'll always depend on your use case/what you're trying to accomplish. Some modules I frequently use from the standard library are os, os.path, re, sqlite3, and csv. Check out https://awesome-python.com and https://wiki.python.org/moin/UsefulModules to get a better idea of what 3rd party modules are out there and what they can be used for.
Some times ago, I read an article why Python is slow and here are the reasons I saw. #1 Python is Dynamically Typed rather than Statically Typed. #2 Python is interpreted rather than compiled. #3 Python's object model can lead to inefficient memory access 
Thanks! I will research that tonight! 
&gt; The science community wouldn't use Python if its libraries weren't fast. I love the point you made. 
I am in a similar boat. I asked to take a break from trading to work on the programming/quant side of things and have about a whole year to do so. Hit me up!
This. It's is the most obvious place to look for performance gains. In any case, if this doesn't work, it's probably beyond the skill level of someone who has to ask why python is slow to speed it up suitably with any other techniques. Because it can be a pain. Best to use another tool.
You don't have a product and you're already worrying about performance, you've fallen into the premature optimization trap. Use whatever will allow you to develop an MVP with the least possible friction. If "performance" is an issue then neither Python or JavaScript are excellent choices, but as others have said you will be the bigger bottleneck if you're asking these questions. For 99% of applications either choice will be adequately performant with reasonably written algorithms. If you have a working model and find a bottleneck, write a C extension for it as an example, but don't worry about these things before you've started.
First project for OP's crew right here.
Great way to learn some machine learning and working with API's as long as you're not married to the idea of actually making money. Everyone and their grandma is trying to do this right now, and I have yet to see an open source version do all that well.
I suggest looking into Julia. It ‘walks like python and runs like C’. Its got nice semantics reminiscent of MATLAB and Python and like PyPy it is JIT compiled. However, it was designed from the ground up to be amenable to this JIT compilation and so both compiles to faster code than PyPy or Numba and it does so without forcing you to leave behind giant swathes of the language. Further, if there's a language construct thats not included in the language that you miss from another language Julia has an incredibly powerful macro system which are essentially functions that act on code and return code, allowing you to implement your own semantics or do powerful meta-programming. This is all fine but you may be asking "what about the package ecosystem?" It's true that Julia is a very young language and has much fewer packages than Python but I think anybody who knows about the experience of package development in other languages would be shocked by the breadth, flexibility and power of Julia's ecosystem. Because the language was designed in a highly flexible and extensible way while being on the same order of magnitude as C in terms of speed, developers are able to write their whole packages in Julia without having to drop down to C for all the important bits or develop their own compiler like what is very common for big python libraries. The result is more flexible packages that integrate better into the language which require orders of magnitude less effort to develop and maintain and it really shows, especially in numerical computing where I would say the community focus is strongest. 
In my opinion, tests tend to become useless rather quickly when you don't run them automatically (CI). People will forget to run them locally. So at some point you will have a couple of failing tests, that are not related to the super important thing you need to deploy right now, so you will start ignoring them. On the other hand, having a CI setup with no tests to run may seem pointless. A proper CI setup does have benefits other than running tests though. I think I'd start with just one or two simple unit tests. Making the whole code base testable is probably a huge task and will take a while. But you should be able to find one or two small pieces for which you can write some simple unit tests right now. Next, I'd get them to execute on Jenkins. From there you can take it step by step. I would stay away from high-level tests for now. You will spend a lot of time on them, they may not even run on Jenkins once you set that up, because maybe you need a db or browser to run them which is easy to do on your local machine but may not be possible on Jenkins. Also, you're going to spend a lot of time maintaining them because they're going to break all the time. You mentioned that you have very inexperienced developers working with you. When they're wondering how to do certain things they will probably look at your code for orientation. So, if you start with writing high-level integration or e2e tests they will do so too, and you might end up with a lot of hard-to-maintain high-level tests. So, my advice would be: Start with a few tests, you should be able to get that done in a couple of hours. Then set up your Jenkins integration and take it from there. 
&gt; Those are better described as the composition of the input stochastic noise with the PRNG that turns it into the output sequence. They're still pseudo-random unless the noise is actually stochastic; is it *guaranteed* to be so on any given pair of cloned VMs being started up identically and immediately polled for random numbers? If they're run on a limited host that doesn't have RDRAND or any hardware security modules? What if the host itself is a poorly prepared VM, or hardware controlled by your adversary (a poisoned cloud hosting provider, say)? Yes, I know the odds of this being meaningfully exploitable are really, really low, but isn't the best software RNG still deterministic algorithms being used to merge the output other deterministic algorithms with a source of noise that's being pre-seeded with preserved state from a (possibly cloned or manipulated) file and then fed new seeds that are determined by machine state that *could* be subject to MITM control? &gt; No, this simply isn't true. Reseeding has nothing to do with this, and you won't find a cryptographer who believes it. You might find one that supports the blocking interface, but not because you would "re-use the same entropy", which doesn't make sense. I wouldn't have found a cryptographer in late '30s Germany who believed the Enigma could be practically reversed, either, but you'll notice in my post above that I added a bit (before your reply) pointing that cryptographers don't agree with the man pages or [kernel documentation](https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable.git/tree/drivers/char/random.c?id=refs/tags/v3.15.6#n52). I'm not arguing the point -- I'm not a Scotsman -- I'm simply trying to point out that there remains a controversy to be aware of around /dev/urandom, a controversy that will remain until all the docs and man pages are updated to reflect the beliefs of cryptographers. Beliefs that are strongly held, but still seem to waffle around VMs and other situations in which the pool of entropy (or the source of apparently stochastic noise) may effectively be re-used. &gt; On top of that, /dev/urandom isn't used nowadays, so it doesn't even matter. Well, that gets bloody confusing, since the general consensus of cryptographers seems to be to only use /dev/urandom. Also "isn't used nowadays" always rings a bit hollow to me in a world where, last I checked, nuclear silos in the States were still using 8 1/2 inch floppies and everyone walks around interacting with wireless access points that likely haven't had an update since their date of manufacture.
You also save $2000.
Count me in :) having some projects now. Love to collaborate with others too
Python is an awesome language to learn. You can seek help from StackOverFlow, but make sure to ask relevant questions which has not been asked to avoid downvote. Quora is also a good community where you can ask question. Reddit is also another awesome community. Don't only ask question, try and make contributions on topics you have knowledge of in Python. This helps you learn a lot.
Read this before you do anything: https://hackernoon.com/yes-python-is-slow-and-i-dont-care-13763980b5a1
&gt; YouTube, reddit, Instagram, Pinterest, and Dropbox are all written in &gt;Python. I’m pretty sure that Python is performant enough for you. This needs to be on a T-shirt! 
Cant you compile python to make it more bearable?
It works with pip on Windows too
A missing dll in scipy sparse linalg. No help on google
How does that help? It's fine for developers but we can't have users installing anaconda and setting up a virtualenv. 
What purpose was this reply even supposed to serve other than making yourself look like an idiot? 
what sort of libraries are you working with? 
We doing this?
Usually the process goes like this: You start writing the code. You realize that you need to do something like plot a graph. You google how to plot a graph in python. Several stack overflow articles and some python documentation tell you that the module matplotlib can be used to plot graphs. So you include the module and then use it to plot your graph. Basically, I usually just include modules as I need them. I’ll be coding along, realize that I need a module for something, and then import it so that I can use it. If I don’t know what module I need, then I’ll just google until I find what I’m looking for.
Thanks SentientStoic! I am starting to realize that I don't need to have all the answers, I can use Google, Overstack, Reddit Community and achieve the desired results. I have always been somewhat shy and turned off by coding because I thought I needed skills I didn't have, but am starting to see that you need a basic understanding of how the language works and everything else is research. Thanks so much! 
well don’t benchmark async code against blocking code and say wow that blocking code is slow. asyncio allows you to write easy async code in python so you can really compare apples to apples when comparing node to python
I think the question is not "Am I fit for it?" but "Do I like doing it?" I understand it's hard, you keep learning and learning but then you actually try doing something and you don't even know where to start. We've all been there. If it's something you enjoy doing, I say just pour more time into it. Stop learning individual things and try building something and learning as you go - I can assure it's much more valuable this way. I suck at maths. Always did, almost missed some years, still suck at it. I'm still here trying my best and I'm sure you can do it too.
Python is eminently tunable. Here's a basic example: import numpy as np from numba import jit @jit def sumit(arr): value = 0 for x in arr: value += x return value sumit([1]) ## run once tmp = np.arange(100) Comparing the two sums: %%timeit tmp.sum() The slowest run took 19.91 times longer than the fastest. This could mean that an intermediate result is being cached. 100000 loops, best of 3: **2.95 µs per loop** %%timeit sumit(tmp) The slowest run took 229093.64 times longer than the fastest. This could mean that an intermediate result is being cached. 1000000 loops, best of 3: **312 ns per loop** That is an order of magnitude difference. 
Sounds like a cool idea. Can you give an outline in case if someone doesn't get a partner to work with.
Building something you want to build is so much fun. Also recommend learning as you go because reading dull books etc can be really fucking boring.
Not sure if there's any way to "know". I recommend Segaran Programming Colllective Intelligence as a way to apply fairly basic Python to solving concrete and fascinating tasks. Good practice for data structures.
 selection = random.choice(HaveGoat) This says the person's random choice is from the goat doors only!
If you think about it a bit more, it won't be weird anymore. First choice has 3 possible cases of equal probability, and two of them are wrong, so whatever you pick, there's a 1:3 chance you're right. After that, one wrong door is revealed. If you had picked the right door initially, switching means you lose; but if you had the wrong one, switching means you win. And if you remember the original odds, you know that you are twice as likely to have picked the wrong door initially. In other words, you are being asked to pick a door, and then you are asked whether you think your first choice was right or wrong, and the odds tell you that it was probably wrong. Part of the psychology here is that people don't want to be wrong, and changing yoir mind feels weak, so your gut feeling says to stick with your original choice. Plus thee thought that if you switch and your original choicr turns out to be right, you will regret it.
Im down
If you want to use python to develop a web site or such things,I suggest you use sanic project.It's much faster than django or flask. https://github.com/channelcat/sanic
Worth pointing out that Python does compile to bytecode.
Am a chemistry student but my interests also cover computer science, and I've gotten into Python programming this summer (profiting from Uni classes now). I'm in for everything that has to do with automation! Given your background, a trading bot would make sense (as mentioned by other commenters), but I'd also be super stoked about home automation and machine learning. Also been trying to build a biometric password manager, but I'm still nowhere with that. So how do we go about this? 
Agreed on the context, but I interpreted your sentence &gt; But, to repeat, the numpy PRNG is almost certainly sufficient for academic work, I just wouldn't use it to encipher anything you don't want superpower-level nation-states reading. to imply, my set-complement, that PRNG is good for anything that *doesn't* require protection from NSA-type groups, which is obviously a false statement, but I see that that implication I read from it is very ambiguous and subjective.
Thanks!!
I'm in the same boat as you but when I was learning Laravel I tried to make a hobby project. That kept me going until I made it work. Basically, find some project to do. Doesn't matter if it's something you can't do yet with your skillset cause that's where the learning will come.
Definitely interested. Been using Python for about 3 years now and would benefit beginner group experience.
&gt; YouTube, reddit, Instagram, Pinterest, and Dropbox are all written in Python. I’m pretty sure that Python is performant enough for you. Not arguing with your point but isn't Dropbox mostly go nowadays?
&gt; I kinda of expected this for programs with a lot of I/O Yes, in Python, I/O operations are blocking by default. But you can use asyncio to make them non-blocking.
&gt; If you give me a bunch of numbers in sequence out of the Random book, using mine, I'll be able to predict the next number at some point. Are you claiming that the numbers in the book are not random with respect to one another? &gt; &gt; I don't see where you're going with that analogy. &gt; within the fixed 219937 - 1 MT sequence, the numbers are not measurably correlated with one another. Not true. Only a small fraction (orders of magnitude smaller) of the order of the PRNG is required to deduce the internal state (for most PRNGs, including most notably the MT).
I don’t work at Dropbox, but I have a friend who does. As far as I know, the majority of their back-end code is still Python (and Python 2.x at that). 
Or it is also possible that those fast operations already have python libraries implemented in C, in which case you still can use python.
Hey can you elaborate more. How exactly did you get the json for the 1st course? And how to get it for all the courses?
Rather than reading a blog post &amp; creating opinions test it out yourself and then believe something. It can write really shitty code in Node.js and same in Python. It will be slow regardless of what language you choose if your architecture is crap. 
Why would you think io slow and computation fast? It's pretty much the opposite at least on multicore. 
Exactly my thoughts. In addition, there is a big change his product never grows that much for him to think about scaling.
That's a somewhat complicated way to simulate the game: from random import randint from collections import Counter def choose(d): return randint(0, len(d)-1) def play(d=3): doors = [0] * d doors[choose(doors)] = 1 stay = doors.pop(choose(doors)) doors.remove(0) change = doors.pop(choose(doors)) return stay, change def main(): doors = 3 plays = 10000 results = Counter((play(doors) for _ in range(plays))) stay_won = results[(1,0)] change_won = results[(0,1)] print("Of {0} games with {1} doors:".format(plays, doors)) print(" Staying won {0} times ({1:0.2f} %)".format(stay_won, stay_won / plays * 100)) print(" Changing won {0} times ({1:0.2f} %)".format(change_won, change_won / plays * 100)) print("Changing was {0:0.2f}x more likely to win.".format(change_won/stay_won)) if __name__ == "__main__": main() Really the player who stays is just choosing an index that might have one winning value among some number of losing values. The player who changes is choosing a different index from the remaining doors, less one losing door. It's that "less one losing door" that will always give the advantage to the change tactic over enough plays, no matter how many doors there are, although the advantage drops as there are more losing doors.
Do not take a lot of stress about this. There is so much to learn, it is pretty easy to be intimidated. Remember this, to be good to anything you need to invest time and work hard. There is no other way. When I was learning python, I mostly learnt from the official docs. It gave me a good command over the languages and the usage. Next, in order to apply the knowledge, you first need to see what's possible. For that, you need to READ CODE. You might wonder which code, Read source code of libraries like Flask, Django etc. or even any code on github that is python based. https://github.com/topics/python?l=python&amp;o=desc&amp;s=stars You might now always understand all parts of the code, but read a code, if you don't understand something go back to the docs and see why you are not understanding it. Almost everytime you will find the answers in the docs. If not stackoverflow, IRC is there. Try to write small tools that might do something like sending a tweet, uploading a photo. Programming as a skill can be acquired through hard work. Work hard and have fun. 
If you're one of them *speed* -diggers, then try out **Julia**, then you may call Python functions inside **Juila** using the **PyCall package** .
`with` guarantees that the `__exit__` method of the context manager is called (`release()` in this case). Without `with` it would look like this: pg = await app.pg_pool.acquire() try: users = await pg.fetch(...) finally: await pg.release() Same number if indents, more than twice the number of lines.
&gt; It won't affect system utilities relying on older version of python? Exactly. It is also nifty if you sometimes have the need or desire to use different versions of Python for different projects since it has a concept of "environments". These environments are basically small Python distributions in themselves, with their own interpreter and packages.
Already working on this gentlemen. www.mlsociety.com. The social network for scientists and Data Scientists will be out in 2 weeks. It's called "CO". Let me know if you wish to beta test. www.mlsociety.com
Ah, TIL. Articles like [these](https://about.sourcegraph.com/go/go-reliability-and-durability-at-dropbox-tammy-butow/) make it sound like go is more used but being a talk from gophercon I guess it would emphasize the usage of go.
Keyword is fun. I know I'm fit for programming because I find it quite easy to understand and I feel excitement when I see new possibilities (new technology), or when I'm challenged by an algorithm riddle and I solve it. For instance, being also a godot game engine user, I noticed that I found very exciting to implement a new gameplay and game mechanisms, but I gradually lose interest when I work on other parts, like music, graphism and level design. I have more fun making a framework to make a game rather than making the game itself. And I usually have more fun making a game rather than playing an existing game. That's how I know I am fit for programming.
Ahh, yeah, I don't mean "just" to imply "exclusively", or the set-complement, I'm saying "but I wouldn't" as in "I just don't know" implying "I wouldn't have the answer" instead of "I am exclusively ignorant of all knowledge on all subject". Editing for clarity, though.
If you have to do easy operations like crop and interpolation also consider numpy: you turn the image to 3 2-dimensional arrays (or one three-dimensional) and manipulate it as such.
I agree with that. Matlab and Excel are good to mess around with data. But as soon as you have to do other things, it's better to go back to Python.
Just start poking around. This was my process: * Go to the page and open the developer console, * Select the Network tab, * Select XHR, * Refresh the page to record everything, * Evaluate the URLs, * Realize they use an API, * Try to request https://www.edx.org/api/v1/catalog/search, * See [the first URL](https://www.edx.org/api/v1/catalog/search?selected_query_facets[]=availability_current&amp;page=1&amp;page_size=9&amp;partner=edx&amp;hidden=0&amp;content_type[]=courserun&amp;content_type[]=program) is for current courses, * Make a request to that URL, * Find what you wanted. I recommend that you install a JSON formatter. I use [JSONView](https://chrome.google.com/webstore/detail/jsonview/chklaanhfefbnpoihckbnefhakgolnmc?hl=en). You want to look at: { objects: { results: [ {course1}, {course2}, {etc.} ] } } A common structure for webpages is to have a basic page that gets served to the client without any data, then use Ajax to make API requests for the data.
Bit of a tangent (replacing **with** with a function call requires more lines and, invariably, more presses of the Tab key), but why exactly is avoiding an extra indent level an advantage?
I guess it could be possible to ship miniconda, a pre-made conda environment with your app and its dependencies, and then a wrapper script to activate the environment and run.
That is Python equivalent of getters/setters in Java. It allows you to control the access and modification of a variable, but allows you to use it as though it is still a variable. Without properties you'd have to use a getter/setter with a private variable (not that you can have private variables in Python) and have users use them which looks like this: class Employee: def __init__(self, name): _name = name def get_name(self): return name def set_name(self, name): self._name = name employee = Employee('John') employee.set_name('Andy') print(employee.get_name()) with properties this looks like this: class Employee: def __init__(self, name): _name = name @property def name(self): return name @name.setter def name(self, name): self._name = name employee = Employee('John') employee.name = 'Andy' print(employee.name) More info and probably a better explanation: https://www.programiz.com/python-programming/property
Hindsight is wonderful isn't it? &gt; [Vos Savant wrote in her first column on the Monty Hall problem that the player should switch (vos Savant 1990a). She received thousands of letters from her readers—the vast majority of which, including many from readers with PhDs, disagreed with her answer.](https://en.wikipedia.org/wiki/Monty_Hall_problem#Vos_Savant_and_the_media_furor) ... &gt; Vos Savant commented that, though some confusion was caused by some readers not realizing that they were supposed to assume that the host must always reveal a goat, **almost all of her numerous correspondents had correctly understood the problem assumptions, and were still initially convinced that vos Savant's answer ("switch") was wrong.**
You just proved that underlying library that is using C internally is fast as C :) Python itself is slow for many reasons. Many python libs are fast because they are written in C/C++. In fact in many places python is just easy to use wrapper around C/C++ code. 
Using constructor you can build your own miniconda distribution, and if you take a advantage of menuinst you can have it drop start menu shortcuts to launch it, no activation necessary. Then just add an update button to your application that shells out to conda update. 
Well, yes; you have to think about it enough to understand what it boils down to. Once you do, there is no arguing against, really, although your animal brain will still tell you that this can't be true.
I know one guy that is a beginner in Python but he has done so many awesome image processing projects using Python. He has done the following -Gesture driven Virtual Keyboard using OpenCV + Python(you can watch the demo of the project here https://youtu.be/Yv-3u5VXOQ4) -Motion Gesture Recognition and many more projects. The fact is; What is very important for any programmer is their problem-solving skills. Find problems around you and solve them. I know another programmer that had problem watering his plants. So he developed a fully automatic system for watering plants that controls air humidity and temperature, soil humidity, light intensity and water pump. All this integrated into menu controlled by potentiometer from my electric guitar. Always try and solve problems around you. Whenever you are faced with a problem which seems unsolvable,start by breaking the problem into smaller sub problems. keep on breaking the problem until all the sub problems are solved. If all the sub problems are solved, the problem itself gets solved. That's my advice. I wish you good luck.
&gt; You don't have a product and you're already worrying about performance People *do* tell startups to "fail fast". Choosing a high-performance programming language ensures you fail as fast as possible.
&gt; You just proved that underlying library that is using C internally is fast as C You misunderstand languages if you think numba.jit transpiles to C then compiles to machine code. LLVM etc etc. Your statement is simply false.
And if you wait for the official release of Godot 3.0, you'll have real Python3 support.
This is an excellent explanation of how python works, explaining why it is 'slow' relative to C: http://jakevdp.github.io/blog/2014/05/09/why-python-is-slow/ That said for performance benchmarks, take very much with a grain of salt - benchmark results are in no way guaranteed to translate into performance for YOUR program - it will depend a lot on where the bottlenecks are and what can be done to address them. As for 'computationally intensive' programs, again it depends what you mean - for any kind of numerical computing, the scientific python stack (numpy, pandas and friends) is widely considered best-in-class (you'll generally only do better with C/++/fortran, and even then you can use cython).
&gt; rson's random choice is from the goat do Oh no!my bad, after another look at my code,I realised another flaw; that is that the initial selection can be removed on the #remove a wrong door Doors.remove(random.choice(HaveGoat)) part
Cool, thanks
Thanks for the explanation and the code reference,I'd consider myself quite a lacking programmer,I'll refer more on your code and try to see where I can optimize mine.
Most of the comments here cover the fact that you probably are underestimating python a bit. However, I'm going to suggest a different view on your language choice: use whatever your peers are using. If you work at a company that develops in python: use python. If you're in a university course and everyone is working in C++, use that. Or whatever! My reasoning is that if you are developing in the same Language as your co-workers you can more easily get support if you need it. This will make it way easier to get shit done!
&gt; . First choice has 3 possible cases of equal probability, and two of them are wrong, so whatever you pick, there's a 1:3 chance you're right. After that, one wrong door is I do get what you mean about the psychological part,but the thing is that I'm confused about the problem in the mathematical part.
Node runs on top of Google's v8 Javascript JIT compiler. There's been fierce competition between browser makers to create highly optimized and optimizing Javascript compilers, and v8 is among the very best. It uses aggressive caching, multiple compiler modules, hidden classes to convert dynamic property access into fixed offset dispatch, and a number of other clever techniques to speed up execution. PyPy comes at the same problem from a different more flexible approach. It has been getting progressively faster, but is not nearly as far along as v8 in terms of deploying aggressive optimization strategies. Ultimately neither Javascript nor Python was designed for raw performance. They are both dynamic scripting languages that prioritize simplicity and convenience. For the foreseeable future a compiled language like C will be best for the most computationally intensive tasks.
When you are considering pure Python implementations of numerical problems, it's not the fastest language. But then you are outing yourself as an amateur. A project considering a tool aka programming language is not just about speed. Python is popular because of it's infrastructure which makes it possible to code fast and take care of quality management. I've looked into the first link. It's basically a benchmark setup in favor for node.js, because these amateurs don't use numpy, which no sane Python programmer would do. It's not just for the sake of speed, but for being sure that the implementation is right. Yje next thing is, the benchmark is missing a vectorisation which should the next reason to use numpy. Nobody with a decent education would use such a Python code: for i in range(n): for (([x1, y1, z1], v1, m1), ([x2, y2, z2], v2, m2)) in pairs: dx = x1 - x2 dy = y1 - y2 dz = z1 - z2 mag = dt * ((dx * dx + dy * dy + dz * dz) ** (-1.5)) b1m = m1 * mag b2m = m2 * mag v1[0] -= dx * b2m v1[1] -= dy * b2m v1[2] -= dz * b2m v2[0] += dx * b1m v2[1] += dy * b1m v2[2] += dz * b1m for (r, [vx, vy, vz], m) in bodies: r[0] += dt * vx r[1] += dt * vy r[2] += dt * vz It turns out that people complaining about Python's speed are almost all bloody amateurs. 
OOP is not the flipside of FP. Functional programming and object oriented design are in no way mutually exclusive; Scala code in particular will often be purely functional while involving a large amount of abstraction, inheritance hierarchies galore, and classes just all over the place. Functional programming and *imperative programming* are more directly opposite to each other.
It'll be crowded with students from finance etc whom all has awesome ideas and just need someone to do the "easy" part and implement them 
In most cases it's not, but if you're dealing with nested functions or for loops it can enhance readability (though I guess the real goal is not to get to that point in the first place).
Cool :) The basics are not very hard, i recently took krakenex api and wrote a few functions to have look at order book on a pair, to try evaluating where it's going, and give orders (fake for now), didn't do much with machine learning yet, would need to chose a platform to do that, though about maybe trying to implement simple strategies first. There is not much to share openly right now (and not sure about sharing the code of such a project very openly in the end), but i figure sharing with someone with a finance background could prove fruitful :).
Maybe neither, have you considered peewee?
Hard to say, really. One important thing seems to be that in order to be successful as a programmer, you need to be able to grasp a certain kind of very fundamental abstraction, and it seems that you either have it or you don't (at least that's what the available evidence seems to suggest). A few simple tests that you could try to see if you "have it": 1) Can you implement Fizz Buzz? In Python, or in pseudocode, doesn't matter; but can you? 2) What does the following program output: ```python a = 5 b = 3 a = b print(a) ``` Can you explain why it outputs what it outputs? 3) Read the following code: ```python def foo(x): if x == 0: print("We're there!") else: print("Are we there yet?") foo(x - 1) ``` What happens if we call it as `foo(0)`? What if we call it as `foo(1)`? `foo(2)`? And why? If you can solve either of these (doesn't really matter which one), you probably meet the brain requirements to be a programmer - these 3 examples cover loops, variables, and recursion, and understanding either of them seems to indicate that you are also able to understand the others in due time. That's just the "talent" part, though; beyond that, what you need to bring to the table is a drive for learning new stuff, a bit of an open mind, and, most of all, you need to enjoy at least some aspects of programming. For some people, it's the money (though I think that's a lousy motivation that makes for bad programming habits), for some it's knowing that they are making something that helps a huge number of people, for some it's the joy of creating new stuff, for some it's more about solving puzzles, for some it's about playing with formal systems and getting them to match up with real-world problems, for some it's looking back every now and then and seeing the enormous progress you have made in the past year; it doesn't matter, but if you can't find joy in programming, then you won't make a good programmer. Don't let the learning curve discourage you though; programming is complex, there is an overwhelming mass of knowledge and concepts to learn, and you will never (!) get anywhere close to learning everything there is to learn, because new stuff is being produced faster than you could possibly hope to read about it all. That's fine, though; start with the basics, proceed to things you find interesting, and the important stuff will stick when you're ready for it. After 25 years, I'm still learning new things every day, and my brain still hurts regularly from studying novel concepts. To be a programmer means to be in a perpetual state of not knowing it all, of learning new stuff, of making do with what you have in your toolbox. There's always new things on the horizon with a prospect of making your life easier or your code better, you never achieve perfection - but that's also part of the neverending joy.
&gt;You don't have a product It's not really a startup and isn't it honestly ever reasonable to give the whole thing a bit of thought? Just starting out with absolutely 0 planning seems like a sure way to quickly create a lot of technical debt that then needs to be ironed out later with a lot more effort.
Let's just admit it that Python is slow doing your `for` loops. Case closed. Good luck finding a job optimizing `sum()`.
If it was fast, you probably wouldn't like it anymore.
To answer *what's wrong with setting self._name directly*; nothing in this example. The nice thing about properties in Python classes is that you can start with a standard instance variable (`self.name = name`), and if you see the need (for example, if you wanted to store a list of names the person has had in the past), change it to a property. From the perspective of your class's users, nothing has changed--it behaves in exactly the same way.
&gt;Numba This seems interesting, thank you. How different is it from standard Python? I'm going through the docs and it has types and stuff? Is it like C-infused Python? Would be a bummer.
Pillow-SIMD Faster than Intel/cloudflare's optimizations.
&gt; Python is the wrapper, we write the performant code in C [He](https://www.reddit.com/r/Python/comments/7agyka/i_love_python_but_why_is_it_so_slow/dpa3pmq/) said something similar and got a lot of flak for it.
We can all appreciate how monumentously hard it is to convert a codebase from anything to anything, let alone from python to golang
There's no I/O in the benchmarks, afaik.
How does MATLAB plotting compare octave?
Write a C extension, use CFFI, or Cython to complement your Python code when you require computational performance. Simple. Case closed.
&gt; It turns out that people complaining about Python's speed are almost all bloody amateurs H-hey!! But doesn't it kind of speak against Python that one needs to use whatever library (which might even just be a Python wrapper around C code) to get performance? I mean, you could do the same in Node. In the end, you'd be comparing C code to C code. 
Yes, that makes sense. Though we're currently in the process of what to use together.
Because Python is blocking and Node isn't? Node can do I/O while the program execution just continues. Python would wait for the I/O process to finish or fail.
This depends on so many things you aren't telling us. How proficient are you at Python (or other languages)? How much have you already done? There are plenty of tutorials out there for creating a simple GUI, and I've lost count of the amount of cryptocurrency miner tutorials and articles I've seen, so it shouldn't be hard to hack something together.
But I wanted to write in Python and not in C.
[17 hours ago](https://www.reddit.com/r/Python/comments/7acl3d/i_wrote_a_python_script_to_download_video_lessons/) Stop your spamming!
I dislike this way of thinking enough that I wrote an article on it: http://negfeedback.blogspot.co.za/2016/01/efficient-compiled-binaries-arent-c-code.html 
It's a mix of Python, Go and Rust.
It's a sort of Talibanism when you are demanding this type of purity. A programming language is a tool as well as the infrastructure. If a a programming language fits your purpose it's a good tool. Numpy is a part of the Python infrastructure which is well tested. The same is true for numerical libraries with interface for C or C++. They are well tested, faster and provide the opportunity to write easier to read code. As far as I know, node.js doesn't have general available numerical libraries and I would not do any numerical benchmark with node.js. The reason why Python is so loved, it is providing fast hacks, as well as support for large projects incl. fast coding and QM. It doesn't matter whether some libs are written in C or something else. The foundation is the concept of the Python infrastructure. 
Sorry, should have been more clear, I get reducing *unnecessary* indentation, or refactoring deeply nested loops, I mean in this case the OP seems to be talking about moving a *necessary* bit of code that is in its most reduced form into a function, seemingly taking: def a(b): with c(b) as d: d.something() And turning it into: def something(b): with c(b) as d: d.something() def a(b): something(b) Which, I mean, does reduce an indent level, but also adds function call overhead and results in more actual lines. The same is true with refactoring for loops, obviously, but at least then there's the argument of enhanced readability. I mean, the function idea *does* make sense if all your uses of **with** can be abstracted, but that's relatively rarely the case.
maybe you should try to solve "real world" problems instead of the academic exercises. Have a look at https://automatetheboringstuff.com/ . Or help to improve an open source project - it should be one you're interested in/using.
I've been using Python for years. My advice is to stop worrying about it until you can write the question in the following format: "I've got a program that does X. It runs in Y time but it needs to run in Z. How can I make it faster?" First make it work, then make it work correctly, finally, make it fast. 
better formatting
thanks for your comment. It was valuable to me.
You made a reddit account specifically to spam your shitty code?
OK, that is actually quite simple. There is a 1:3 chance that your first pick is the winning door, and a 2:3 chance that it's not. If you pick the winning door, then staying will win the game, switching will lose the game. If you don't pick the winning door, then staying will lose the game (because you have picked the wrong one), while switching will win the game (because the host has revealed the only other losing option). And because your chance of picking the winning door in the first move is 1:3, that means your chance of winning by staying is also 1:3, while if you picked the wrong door in the first move, 2:3 probability, you are guaranteed to win if you switch and lose if you don't, so the probability of winning if you switch is also 2:3. In other words, given the probabilities: - P(W): the chance of picking the winning door in your first move - P(L): the chance of not picking the winning door in your first move - P(S,W): the chance of winning if you switch after having picked the winning door - P(S,L): the chance of winning if you switch after not having picked the winning door - P(N,W): the chance of winning if you don't switch after having picked the winning door - P(N,L): the chance of winning if you don't switch after not having picked the winning door - P(S): the overall chance of winning if you switch - P(N): the overall chance of winning if you don't switch We have 3 doors, and only one of them is the winning one, so P(W) must be 1:3, ergo P(L) must be 2:3. P(N,W) is obviously 1: if you stay on a winning door, you always win. P(N,L) is obviously 0: if you stay on a losing door, you lose. And P(S,W) = 0 and P(S,L) = 1, because if you switch from the winning door, you lose, and if you switch from a losing door, the only other door to pick from is the winning door. Basic probability math then gives us the chances of winning by switching as P(W) * P(S,W) + P(L) * P(S,L) = 1/3 * 0 + 2/3 * 1 = 2/3, and the chances of winning by not switching as P(W) * P(N,W) + P(L) * P(S,L) = 1/3.
what does the GUI do?
You won't be writing C, you'll be writing Python. Then, during your profiling phase, you'll find the slowest part of your code and use a C library for that part or write C code for that specific code. Since Python understands C types (`ctypes`) and C understands Python types (`PyObject *`) there will be no loss of information during the process.
You can do the same in Python. Google asyncio.
That's not similar at all. The reason he is coping flak is he is getting some thing confused. Firstly, he is saying that numba.jit converts python to C code. That is wrong, it converts the python code to LLVM IR the compiles the IR to an executable module. Second, he is calling numpy and similar compiled libraries 'C code'. While they may be written in C, what they produce is an efficient executable compiled module that you can use in your python code. That is not the same as using C code in python.
The problem is you haven't given us any idea of what the program is. A website? A command line tool? Are you doing machine learning? At the end of the day, the libraries and ecosystem are probably more important. And while Python is slow, a lot of its libraries are written in C/C++ (e.g. numpy) so they are fast. Python is slow because it's a fairly simple interpreter with minimal optimisations. I'm not sure how Pypy and Node.js compare these days, but I know Pypy has been making good progress with performance. If the choice is between Pypy and Node.js then your choice should probably be which are you more comfortable with, or which you prefer developing in as their performance will probably be good enough.
Counterpoints: - Performance is observable behavior - low performance can be spec-breaking - Fixing performance "in post" makes structural mistakes very expensive (or, to put it differently: assumes that performance is dominated by easily refactored hotspots, rather than design deficiencies.) FWIW, if you consider the paper this meme comes from: it's a strong case against habitual, ineffective non-optimizations that turn the code into a sticky mess.^1 It makes a strong argument for consideriung performance during design, *and* for dedicated, well-informed microoptimizations. --- **tl;dr:** you fell for the "premature optimization trap" trap. --- ^1) ^(so maybe, just maybe the "premature ....ation" isn't accidental)
This is great. Thank you.
Numba is a library for Python that JIT compiles functions to improve performance. It does add limitations to what features of Python the function can use though.
Alright, thank you. That's pretty good advice. Much appreciated.
&gt; If they're run on a limited host that doesn't have RDRAND or any hardware security modules? What if the host itself is a poorly prepared VM, or hardware controlled by your adversary (a poisoned cloud hosting provider, say)? What if they're not?! You said "any software-based random number generator"; you can't just exclude the ones that you don't like now! &gt; the man pages or [kernel documentation](https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable.git/tree/drivers/char/random.c?id=refs/tags/v3.15.6#n52) These don't claim the risk is that you'd "reuse the same entropy"; you're *always* doing that. Instead they're arguing that this frequent reseeding defends against the circumstance that SHA can be predicted. &gt; Well, that gets bloody confusing, since the general consensus of cryptographers seems to be to only use /dev/urandom. No, it's to use `getrandom()`. /dev/urandom is old hat. 
If performance is important and Python and Node are your forerunners, I’d suggest Go or Dart as faster alternatives while keeping things quick to program in.
Exactly. During my bachelors I rewrote the analyzing software for the instrument I was measuring with since I had no access to the C# code base. My program ended up being a lot faster since I took advantage of caching, threading, vectorization and cython. My rewrite was already faster when I just had finished the proof of concept version so it is fair to assume that the algorithms and architecture already made a bigger difference than the language.
Can't wait to check it, i'm on may way home.
Build even the SIMPLEST thing. Break it down into the parts you need. Don't let feature creep sneak in. Stay focused. Attack it piecewise. Find some little task that you want to try to automate. Play with datasets. Like try to do something simple like: * Get your bank transactions * Import them into Pandas * Use matplotlib to visualise your incoming and outgoing expenses over a given period Boom. You've just built something.
Slightly different. u/0xSpock was saying that numba was written in C so the function `sumit` would be in C, and therefore fast, but it doesn't matter what numba is written in as what it does is JIT compile the Python function to machine code so that Python can execute that instead of slowly interpreting Python bytecode. Many libraries are written in C though and wrapped to give fast libraries, and it's fairly simple to write your own C code to replace a function if it becomes a bottleneck.
Your unfit for programming if you continue to think your unfit. Keep trying. Its never easy when your starting out.
I know some of these words... But really I think you just gave me some research topics for the day. 
&gt; YouTube, reddit, Instagram, Pinterest, and Dropbox are all written in Python. I’m pretty sure that Python is performant enough for you. So much this. Python is “slow” on paper, but computers are so fast these days it doesn’t matter in most cases. Here is a short list of when not to use python: * When creating a AAA game * when creating a system to trade stocks and milliseconds are a big deal * when creating any sort of medical life/life supporting device where an extra second is a big deal * any system for self driving/auto pilot That’s all I can really think of.
I’m in!
How's the ecosystem for Go and Dart look like? One thing I love about Python is the gigantic ecosystem.
You come to the python subreddit saying python is too slow for your project... The community will obviously disagree with you. What did you expect?
I know Go has a big one, especially for server-like applications, less so for local desktop applications. Dart’s community seems a little smaller, but still sizable.
I built (kivent)[http://kivent.org] on top of kivy to provide a entity component approach to building 2d games in python. Since we're on top of kivy you get a lot of nice modern constructs like event dispatch similar to unreal and out of the box support for mobile. The whole thing is heavily performance optimized making it as fast as unity/unreal for 2d and giving you the tools to make use of similar optimizations. 
&gt; for programs with a lot of I/O [I'll just leave it here](https://magic.io/blog/uvloop-blazing-fast-python-networking/) &gt; Python would leave Node in the dust when it comes to computationally intensive programs. No, Python is generally not suitable for computationally intensive programs. Well, if most operations in your program can be [vectorized](https://en.wikipedia.org/wiki/Array_programming) and you can utilize NumPy then it can be really fast... but, generally, if you have a computationally expensive task you should probably use something compiled and static typed.
**Array programming** In computer science, array programming languages (also known as vector or multidimensional languages) generalize operations on scalars to apply transparently to vectors, matrices, and higher-dimensional arrays. Array programming primitives concisely express broad ideas about data manipulation. The level of concision can be dramatic in certain cases: it is not uncommon to find array programming language one-liners that require more than a couple of pages of Java code. Modern programming languages that support array programming are commonly used in scientific and engineering settings; these include Fortran 90, Mata, MATLAB, Analytica, TK Solver (as lists), Octave, R, Cilk Plus, Julia, Perl Data Language (PDL) and the NumPy extension to Python. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
I went through the same thing. Still struggle with OOD. But, beyond designing an object-oriented program, I could barely scrape together the most basic procedural program. I use a book called Exercises for Programmers. I used the techniques the author suggested, on pen and paper, to write a solution for the problems in the book and then used docs of whatever language (first ruby then some javascript then python) to figure out syntax and then write the solution program. I highly recommend this to you based on what you are saying. I never finished the book because I landed a job and then a second one and now I mostly just learn on the job :)
I built [kivent](http://kivent.org/) on top of Kivy to provide an entity component approach to building 2d games in Python. Since we're based on Kivy you get a lot of cool out of the box stuff like proper multitouch handling, event dispatching on par with unreal's features, and out of the box support for mobile as well as desktop. (including the build tools necessary) There's a lot of C level work done to ensure that the builtin systems are optimized, and that you can also build new systems using the same optimization tools. KivEnt is pretty much as fast as unity or unreal for 2d. 
Just copy the environment or export an enivornment package list for the monolith env. Conda should hardlink as much as it can so it doesnt waste space. It should handle all the PATH and PYTHONPATH for you. IMO if you are using LD_LIBRARY_PATH you are doing it wrong. It shouldn't be needed if things are built correctly.
The site has a feature that allows admins to assign roles to users. A while back some JS was added to the main index page (what everything else inherits from), and ended up intercepting form submits on the role assignment page, breaking that feature. Nobody knew about it until a few days later, someone IM'ed me and told me it wasn't working for them. It took me almost two days to track down the problem. There were no errors, it just never sent a POST when you clicked the button on that page. This would have been caught right away with a suite of e2e tests that walked through the site testing the 5-10 core things it does. How would unit tests have been beneficial in that situation? How could having a few UI tests not help? I'm just trying to understand, I hear this a lot and it's hard to wrap my head around the concept.
&gt; I don't know what I should use here, a list? A dictionary? Where do I use OOP? Try what you think might work and if it doesn't see why not and try other thing that solves that problem.
Except that Dropbox uses Rust and (I think) Go for their performance-sensitive code, so it doesn't count.
Are you socially awkward? yes? then you can program.
Yeah keep in mind that you are competing for jobs against people who live and breathe code. For the sake of your career, find something you're good at. What about Photoshop? If you can do the technical stuff, you might be able to get a job at a marketing/advertising agency. Ideally they would have an art director and you could just be a technical monkey with little "design" input .
I'd love to open source my code, but it's hard-coded to support our proprietary identity provider. I'll see what I can do.
I was using the same earlier but conda clone takes up to 15 mins to clone the monolith. Waiting 15 mins to install a single package was a pain.
Everyone goes through this. You just have to keep going. Maybe you could find a Github archive and reverse engineer it to see how it works. When you understand how it works, then think about why it was implemented the way it was and if there’s any different way it could be run. My problem after I took the Python training courses was that they didn’t contain any practical advice for how to implement anything. I had to find similar code on the internet that performed a similar function to learn to implement what I wanted. Programming talent (or any talent in life) is a function of the amount of work you put in. That is to say, good programmers are not good programmers because they possess some unattainable trait. Good programmers just program a lot which make them good programmers.
Very little of this is actually correct. Why don't you tell us what you're building and we can tell you if it works in python or not, or maybe point you to an existing python implementation. 
i assume you are doing a web project because otherwise this choice does not make sense. one of the reports is very clear where its bias lies (it does not even emphasize results where python does better whereas it does for node). i would not find it credible. https://www.techempower.com/benchmarks/#section=data-r14&amp;hw=ph&amp;test=fortune&amp;l=8vmygv [-] is an authorative resource on web performance. it shows nodejs in general being fast. which is not surprising since its a base platform. however usually you would not use just nodejs. some common nodejs configurations (express+mongo, hapi) are doing worse than some common python frameworks flask and django. meteor is not even listed. So the reality is not as clear. as for why nodjes may be fast it is likely due to a lot of resources being poured into javascript optimisation at browser vendors. personally i'd still use node for most advanced web projects given the choice for the simple reason of it being the language of the frontend. i use python for other things. 
A lot of the python code in that first benchmark link is just... [wut](https://benchmarksgame.alioth.debian.org/u64q/program.php?test=mandelbrot&amp;lang=python3&amp;id=7): range7 = bytearray(range(7)) ... for _ in range7: for _ in range7: ... (range7 is a *bytearray* with the bytes 0-6, whose values are never accessed, which only exists because the code wants to iterate 7 times)
&gt;YouTube, reddit, Instagram, Pinterest, and Dropbox are all written in Python. I’m pretty sure that Python is performant enough for you. I agree that most times the speed isn't an issue, but this isn't really fair without knowing what the OP is doing. He could be doing 3d graphics, or something.
It's just experience. Simply learning the syntax will not do though. Often you can ignore lots of aspects of programming languages, if you don't need them. The code might be less efficient, harder to read, but it will work. You don't really need OOP, generators, recursion, decorators, type hints and what not. print("Hello World") is a valid program. If it does all you want it to do, it's perfect. Advanced language features are meant to help you do stuff better you can do in other, slower, harder to write ways. So you need exercise and you only get that by working on something you have an interest in solving with code. Either because you care or because you're paid to do it or both.
The first game built using my python game engine ([kivent](http://kivent.org/) went live on kickstarter this week! It is an educational piano game called [Trebella](https://www.kickstarter.com/projects/1842123672/trebella-a-piano-teacher-at-your-fingertips/)
I remember when I first started to learn to program, I was always working on small problems. Most of the problems were boring and focused more on immediately applying some programming concept we had just learned---if statements, for loops, pointers, memory allocation and de-allocation, and what have you. But I still enjoyed working on those small problems because I enjoyed the challenge of essentially learning to "speak" with computers. The first time I remember truly *loving* to program was in a compiler course. The professor had us work on small parts of a compiler throughout the year---building the system from ground-up without us even knowing it---then the final project was to connect all of the individual compiler parts into a full, working compiler. That was such a cool project and really highlighted the power of software engineering and software design to me. I've been hooked ever since. So, yes, this is my long-winded way of saying that the best way to learn to program is to have a project that you want to work on that requires programming. Even better when said project requires you to learn something new, like a new library or programming paradigm. Necessity is the mother of invention.
simple-salesforce and the Google API Client (I think that's what its called). I also use pandas of course.
Here's an idea: think through what slow means. IaaS makes rough speed cheap. What is expensive is human time - time developers spend working on a product. Python is at the top of "problems per minute solved" for me and quite a few people and companies I know. That's the speed that currently seems to matter the most. Now, to answer the why is it so slow: Python is an interpreted engine designed for ease of development, not rough speed. If you want single threaded speed: Fortran and C are your best bets. Want incredible threading? Rust, Erlang and Go solved that problem. And there are examples of people switch from Python to Go. And from Go to Python. As an exercise to you: use Google and read 30 top most posts on python speed - really not that hard.
Lol. This may be one of the best comments on this thread. 
Plenty of other interesting things to do in this world if programming isn't for you. In most areas we have a shortage in the trades.
Well, OP is debating between Python and Node.js… 🤷🏾‍♂️
I have been in your shoes before, in fact I would guess that if the people posting in this thread that are self taught have been there. You need to find ways to turn the knowledge ‘about’ programming into programs. Look around on sites like upwork at the programming jobs. Some will be out of reach, but there might be a few that you can do. Forget about the money, because you’ll probably have to work for 3rd world rates. BUT, it will give you experience. After a few of these projects you will probably find out that you like some project but not others. Follow what you like. 
Interesting points, but I happen to know that Robinhood’s back-end is written entirely in Python. 
Omg dude. Node is slow too. What is your app gunna be? If you want to be a total wanker, use mongodb while you are at it, heard it is web scale bruh!
Good advice!
5+ years in IT and Sysadmin, there is something off about most programmers i have worked with. Good people just socially awkward.
Being good at programming, like anything else, takes practice. You may not be the best at first but there are studies that show that practice is pretty much the same as "natural ability". _If you don't like programming though, I'd advise you not to pursue it as a career path, but CS is still a desirable major as you can look at other fields and look desirable. Such as algorithmic trading, sound design, or even plain running a business._
That’s a fallacy in your thinking. You are learning pieces to a puzzle. If you keep at it, you will begin to see the whole picture. You are building a software tool in your mind. It is teaching you how to think. That takes time. The secret sauce is the imported libraries in Python. That where you will realize how powerful your mind and your capabilities are. Programming is it for those looking at the code on the surface. This applies to anything. We live in an age where we want to learn everything easier, quicker, faster, and overnight. You have to give your mind time to integrate Python into your thinking. Just look around you. Don’t you see strings everyday? Of course you do. What about list? Of course you do. What about objects? Yes. So you learn how to harness this power in Python code. A stop sign is can be an arrary of strings. Your grocery list can be a list. Classes? Dog Instances: basset hound Classes: blueprint of a house Instance : 5 houses on a street built from the blueprint Calling a function? Flicking a switch to turn on a light. Hitting the gas pedal to accelerate a car You are transforming the way you think. Remember that. It will stay with you for the rest of your life. Software is being built into everything. It should be required to learn in school just like reading and writing. Stay strong HODL. In code we trust!
you provided three benchmarks that show node fast. here is one that shows python faster (with uvloop since i am assuming you talk about web app performance): https://magic.io/blog/uvloop-blazing-fast-python-networking/
I have mixed feelings about books, but I think reading the ones about good software practices, like Clean Code for example, in general is very beneficial. But to really understand those books one must be into programming for a good 2-3 years at least. You basically need to learn the basics, building shit, and learn some more stuff, upgrade and build new shit, but eventually it's nice to go over a book or two.
I guess I underestimated how monolithic your monolith was. But really how many new environments are you creating on a weekly basis? Your approach may work for most pure-python packages, but I'd be a little nervous about finding all the C libraries that some things need. Especially since some python wrappers around C do some pretty sketchy stuff to find the C library they wrap. You'd also have a lot of issues in the future if you created a new top environment (after not having created one for a week at least) where installing the newest library Z would require a newer library Y than your monolith has installed. Then what?
A great way to learn is solving coding challenges. The best ones allow you to see how others solved the same problem. Check out [projecteuler.net](https://projecteuler.net/) . 
But all these sites don't use python for the 'heavy' tasks or am u wrong?
&gt; use I would buy it :)
&gt; I think the question is not "Am I fit for it?" but "Do I like doing it?" This. Fucking this.
Honestly, my go-to advice is "GUI". I would reccommend the [GameMaker Studio by yoyogames](https://www.yoyogames.com/get) - The first one if possible (they have GM2, but I'm not familiar, so I can't recommend) Benefits. 1.) You see the effect of your code rapidly. 2.) Documentation is immaculate in comparison to any other documentation I've ever read. Simply middle mouse click on any function and it brings up documentation. Further, if you don't know what you need, it's relatively easy to navigate. 3.) Key Press and Mouse Press is highly involved in almost everything 4.) you learn things like state machines rather rapidly (I think Python needs switches precisely for this - state machines (although they can be done with ifs)) x.) I personally benefited a lot from using it, a lot of small gains.
I've had to muck around with spec files (https://pythonhosted.org/PyInstaller/spec-files.html) for some versions of pyinstaller in the past to manually include some dlls. Basically, I took the .spec file that pyinstaller built (and missed a dll with), and then manually added to the binaries list. 
Great news then, you can write in Python, because I very much doubt you will ever need to write anything that requires such intense computation.
This is super interesting, thank you.
&gt; After a few months Give it another year and reevaluate.
Muh man, it's gon' be a gluten free electron app in the cloud. It's gon' be Uber for your sneakers.
Great, I'm also trying to learn &amp; use python on trading. Help me??
I think I would end up making about 50 new environments every week. I think if the libraries in the monolith have a weaker check something like Y&gt;=0.1.2 it should be fine. And the monolith can be updated in every 10-15 days. What precautions could I take to avoid the problems with C libraries?
I want to know your citation for that. Engineering managers say it constantly. Engineers that want to move up the ladder or get their project approved say it all the time. At the end of the day everything comes down to $. That's all that the higher levels care about. 
^^^ That. One thing you need; tenacity. It gets tough/frustrating/irritating but you have to plough on, simple as. I learnt BASIC in the mid 80s and can remember moving to xBase (DBase/Clipper/Foxpro) in the early 90s and felt the pain of not knowing. But I kept at it. Then mid 90s again, pain moving to Delphi but again persistence paid off. Just don't give-up!
it all boils down to the 'is it in my choice or is it in the remainder' Scale the problem up to 1000000 doors. Would you stick to your choice knowing that the chance of getting it right is abysmal 1/1000000? Switching after discarding 999998 doors becomes a no-brainer. 
&gt; What did you expect? [ People to disagree with me and prove me wrong.](https://meta.wikimedia.org/wiki/Cunningham%27s_Law). I'm not here to bash python, I really like Python, or to boost my ego with fake internet points. I simply want people who are obviously more knowledgeable about Python to show me that my worries are unwarranted. So far, it's been working perfectly and I learned a lot! 
Make it work, make it fast, make it beautiful. And thats the only order that will result in something usefull in a reasonable amount of time.
VTK has a thin plate spline transform filter where source and target points define the deformation of space. This transform can then be applied on the mesh vertices. [vtkThinPlateSplineTransform Filter documentation](https://www.vtk.org/doc/release/5.0/html/a02101.html) [2D thin plate spline example](https://github.com/Kitware/VTK/blob/master/Common/Transforms/Testing/Python/TestThinPlateWarp.py) Also, the original TPS paper has all the equations you need to implement TPS in python using numpy. [Bookstein 1989](http://members.cbio.mines-paristech.fr/~jvert/svn/bibli/local/Bookstein1989Principal.pdf) 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [Kitware/VTK/.../**TestThinPlateWarp.py** (master → 457aede)](https://github.com/Kitware/VTK/blob/457aede0c1245a1f003b95b352e305c8379116a6/Common/Transforms/Testing/Python/TestThinPlateWarp.py) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
I wouldn't get too hung up on OOP early on. Most things can be accomplished with functional programming. To beat the dead horse in the comments, keep learning. Read good code. You will most likely spend more time reading code than you will writing it. It's a good habit to get into and seeing how other people solve problems definitely helps. Write simple scripts that solve real problems. I wrote simplified versions of command line utilities when I was starting out. Don't stress if something doesn't make sense. You will have plenty of 'aha' moments as long as you keep learning. I just had a concept click yesterday that I tried to figure out 2 years ago and it happened when I was learning about something entirely different. Literal bottom line: If you enjoy it, keep learning and you will be rewarded. 
50?!?! What are you working on that you need that many? What is the difference between the environments? As for the python wrappers around C libraries, you could rewrite them all to use SWIG-like/Cython C extensions that do C linking to the necessary libraries. Obviously not something you can do.
More specifically, he probably doesn't want to use python. I used to be of the belief "why the fuck not" but there seem to be some very hard caps on the amount of information that can be processed due to python being interpreted. Further, the game libraries are lacking in comparison to other complete engines. My advice would be to find an engine with a language he already knows, or one that uses C++ because most of them use C++, and if he has to learn a language anyway, it might as well be C++ to maximize the amount of engines he can use in the future.
I've been programming for 30+ years. I still ask the same questions you're asking.
Except your group already has a floating MATLAB license for your embedded controls work. No company is buying MATLAB to just plot stuff.
&gt; What if they're not?! You said "any software-based random number generator"; you can't just exclude the ones that you don't like now! I'm not, I'm saying (and said) that *all* software-based RNGs are still fundamentally pseudo-random; the underlying algorithm is deterministic, the source of entropy is outside of the control of the algorithm, and if you take a SHA256 of a PRNG with a given seed and -- to be simplistic -- XOR it with the SHA256 of a series of digits you believe to be random, *but which nevertheless are not*, you'll get the same series of values, and I don't think that's controversial. The PRNG is pseudo-random but reproducible without unlikely amounts of control and effort, the CSPRNG (or RNG if you want to call it that) is pseudo-random, but not reproducible without an unlikely amount of control or effort. &gt; These don't claim the risk is that you'd "reuse the same entropy"; you're *always* doing that. Instead they're arguing that this frequent reseeding defends against the circumstance that SHA can be predicted. I may very well have read those docs wrong, but in the "theory of operation" section it says that when random bytes are requested an SHA is generated from the then current state of the pool, and this is the actual source of bytes to hide the internal state of the pool. If the same section of the same entropy pool in the same state were used twice in that manner, you'd get the same SHA and therefore the same bytes, right? I'm not arguing the likelihood of that happening, I'm just trying to understand the odds of a cryptographic hash algorithm taking precisely the same inputs and giving different outputs. &gt; No, it's to use `getrandom()`. /dev/urandom is old hat. Again, fascinating... it appears that not everyone -- even in this thread -- seems to know this, even if it's an access vector to the same randomness, just by a different name and without the device interface.
&gt; link you can see that they create basically the plot in around 20 lines of code. It could be done in 10 minutes. I ctrl-F'd that entire page and didn't find anything about thingspeak.com. I guess if your data was already in a copy and pasteable format. Or your time was free. 
The codebase itself is educational for people who want to see what a good python package looks like. Nice work.
Making the mineral is one task, making the GUI is another. Out of those two making a GUI by far the easier task. All you are doing is setting up a window with some buttons on it that runs functions, and a text area to display text from a string. Look into Tkinter, it will take you a few weeks to get the hang of it, I'd say 4 weeks or so, depending on how much time you can give it every day. As for the rest, the absolute best idea is the one you yourself suggested, find open source code and pour over them till you know what's going on and rewrite it in your own way. That will also take a few weeks, but probably longer than 4, I'd estimate something between 6 and 12. 
&gt; What purpose was this reply even supposed to serve other than making ~~yourself~~ those that don't actually work in industry look like an idiot? What's funny is that in my decade or so in industry all of my co-workers and extended co-workers have had MATLAB. I even got pushback from multiple managers trying to use Python (So I just did it and didn't ask permission or tell them it was Python). So it's beyond hilarious watching the Reddit demographic's opinion (and votes) of how they think industry does or should work. 
ya but before you start learning as you go dont you need the basic by reading a book at least ?!
&gt; better to go back to Python. Based on what? If your time is free and your want to volunteer to work at your company. No company I've ever worked at has paid me to go back and rewrite something that was working and running just fine in another language.
I want to love go. Simple concurrency, fast compile time, single .exe build. I just can't seem to get the hang of it.
Programming is very hard and requires a lot of time to get good. If you enjoy it, awesome go for it. Only practice will get you better at it. Also as a tip, professional programming / software engineering is very different from school. Extremely different honestly. So if you like it enough to get through school, you might like work more or less. But just having experience programming can open doors if you'd prefer project management or some other related field.
I know what you meant, it would be a good exercise regardless.
Sometging where you need to conpute something. You cannuse C modules like numpy there, but python is still slow and speed does matter.
Dear god, I don’t even know what half of those things are.
If you are looking for more stuff like this, have a look at the very useful book [https://en.wikipedia.org/wiki/The_Algorithmic_Beauty_of_Plants](The Algorithmic Beauty of Plants)
I just check if the file already exists (though there could be a better way). Its just adding one line before copying: if not os.path.isfile('...output_path/foo.bar'): shutil.copyfile('...input_path/foo.bar', '...output_path/foo.bar')
I recently tried numba and got very bad results. Just running the same code (which was pain to write for numba) in pypy got me like 10 times more speed. And that's ignoring the lengthy startup.
There is absolutely no way to judge this or provide insight without knowing the project. For example if this was some kind of data science project you would be using Python to pull in numpy and pandas. Once you start pulling in Python's useful libraries, which is very easy with Python, execution speed on "computationally intensive programs" plunges to a level that is just a little above C (easy to explain .. many of numpy's components are wrapped around C). Comparing Python to Node.js is a distracting, essentially meaningless operation. I am not posting this because I read it somewhere. I design computationally intensive programs, mostly in finance, but some in audio (hobby). Fast Fourier transforms. Is that "computationally intensive?" I do lots of those.
At first read it seems like you should be able to use virtual environments. I forget what it is, but there's a flag to allow the virtenv access to packages installed outside the environment.
&gt;I am not posting this because I read it somewhere. I design computationally intensive programs, mostly in finance, This is actually surprising to me. I have a friend who does automated trading on the foreign exchange market and he showed me his program, which looked like a weird C-style programming language. When I asked him why he wouldn't use Python or whatever, which must have a gigantic ecosystem for finance-related stuff, he told me that Python was too slow for his trading, which apparently is done extremely fast. 
Also what I would do but I'm a python noob so who knows 
Perfect I was trying to play around with something like this but was having trouble to get os.path.exist to work with it because well im still learning. The putting the if not before hand is new to me. Really appreciate the help. 
Isn't there a sub for code review that OP could get some feedback from?
Depending on what level of protection you are looking for, the answer depends on your operating system. A sort of safe solution is opening the file yourself in exclusive mode, and using shutil.copyfileobj(): try: fsrc = open(src, 'r') fdst = open(dst, 'x') shutil.copyfileobj(fsrc, fdst) except FileExistsError: # The file already exists 
I appreciate your sentiment, but I think you've missed the mark here. 
I generally agree with this, although I would recommend doing the interface in PyQT using QT designer (which comes with the Anaconda dist of Python) or Django if you want a web interface. But as Exodus111 is stating, this is essentially learning two languages. Python is not very GUI-friendly. What I suggest you do is take a couple of hours and go find an intro YouTube video about these three (Tkinter, PyQt and Django) and look at the differences.
Wow!?! I'm in college now too. Would you mind sharing some of your work? I think I might know how to begin automating Linear Algebra in python but I'd have no idea what to do with calculus.
Check your pulse. If you have a pulse, you're fit for programming.
Ill play around with this see if it works for what Im looking. I dont need heavy protection. Im not even sure why I decided I needed to check if file exists. It really isnt that important the more I thought about it 
You're way over thinking things. There really aren't idealized textbook solutions for real world problems. If it seems like a good idea to use a dictionary then do it. By practicing and real life experience you'll figure out better and better solutions. Even if you don't implement the optimal solution, in general a decent solution is sufficient enough. 
&gt; Wand (Imagemagick wrapper) - Theoretically, Wand would be great! But I have found no mention of being able to read the image from memory, which makes it VERY slow. When instantiating your Wand Image objects, rather than passing in a filename, pass in a StringIO object containing your image data. This works. I have used it in production.
&gt; Wand (Imagemagick wrapper) - Theoretically, Wand would be great! But I have found no mention of being able to read the image from memory, which makes it VERY slow. [Here you go.](http://docs.wand-py.org/en/0.4.4/guide/read.html#read-a-blob).
This is a common misperception because Python per se, which is to say Python with none of the libraries, is too slow to use in finance. But the SciPy libraries and numpy are specifically designed to speed program execution in Python for computationally intensive work. Go to the Anaconda website and read the background material about data science. There is another misleading issue at work. If your friend is talking about high-speed trading, that is typically NOT computationally intensive (for example spread arbitrage is not computationally intensive). The necessary speed for that kind of trading comes from location (literally ... the closer to the exchange the better off you are) and the latency features of your network, your modems, etc. 
no, I think you are doing the right thing. Especially when you are just beginning with Python. I actually only started checking if any of my files where already there, because I once overwrote every file I had in a folder, not realizing they were newer versions that had already been modified in further steps... so I had to run all of these steps again... Lesson learned ;) 
If you're still interested there is an "EAFP" way to do what you're asking for, though it's less nice than a trivial copyfile: * In python 3.3 or above, you can give the `x` mode (for eXclusive) to `open` and it will raise an error if the file already exists: with open(in_path, 'rb') as f, open(out_path, 'xb') as g: shutil.copyfileobj(f, g) * in previous versions you have to to much lower level as [O_EXCL](https://docs.python.org/3/library/os.html#os.O_EXCL) is not exposed to higher-level API so something along the lines of: with open(in_path, 'rb') as f, os.fdopen(os.open(in_path, os.O_CREAT|os.O_EXCL|os.O_WRONLY)) as g: shutil.copyfileobj(f, g)
Just a heads up, your blog/website hyperlink leads to an ''account suspended'' page. Might want to fix that, just a heads up.
Thank you, the codebase is a product of studying previous well-organized Python projects. Some I'd recommend for people looking for "best practices" projects would be: * https://github.com/pyinvoke/invoke * https://github.com/pallets/flask * https://github.com/cjdrake/pyeda * https://github.com/jakubroztocil/httpie Happy to answer any questions about the design or the library in general in here.
https://stackoverflow.com/questions/20873723/is-pythons-shutil-copyfile-atomic
For a webapp? I doubt Python or NodeJS will be the bottlenecks.
You can use threads like in the good old days.
I want to use it for a shared workspace, were multiple users would share the same base environment.
Hi Guillem! Your WhatsappStatistics is pretty cool ) I'd suggest couple ideas in whatsapp_file_processor.py Store commands data in dict: COMMANDS = { "1": "Plot messages per day", "2": "Plot messages per hour" } def show_models(): for k, v in COMMANDS.items(): print("{} - {}".format(k, v)) And use dict instead if-elif statements, something like follow: def plot_send_per_day(file_analyzer): if my_file_analyzer.messages_day == {}: my_file_analyzer.process_input() my_file_analyzer.plot_messages_days() def plot_send_per_hour(file_analyzer): if my_file_analyzer.messages_hours == {}: my_file_analyzer.process_input() my_file_analyzer.plot_messages_hours() def plot_send_by_user(file_analyzer): if my_file_analyzer.messages_user == {}: my_file_analyzer.process_input() my_file_analyzer.plot_messages_user() def print_incorrect(file_analyzer): print("nothing to do") command_map = { "1": plot_send_per_day, "2": plot_send_per_hour, "3": plot_send_by_user } ... my_file_analyzer = FileAnalyzer(input_data) command_to_execute = command_map.get(var, print_incorrect) command_to_execute(my_file_analyzer) 
Could someone ELI5 what the purpose of tracing is?
&gt; Having a browser running, rendering and executing javascript will always be slower TBH. True, but sometimes you don't have any choice.
I read this as "PIL is dead. Long live the Pillow!" Truth.
I've typically used the root environment for that. If all of these environments **need** everything in the monolith then good luck. If not, then I still think individual environments would be best and have conda, the package manager, figure out what can be shared with hardlinks. Otherwise it sounds like you are basically making your own package manager. Or virtualenvs could be useful as /u/maryjayjay said.
In addition to what's already been said, every Python programmer evolves with the modules s/he uses. You'll find as you continue to develop that your modules choice becomes more informed, it's just a matter of getting out there and gaining experience
Interesting. Could you possibly use that for employees in a place of business as a way of them clocking in/out?
Don't give up. It takes years of constant learning before you even begin to feel like you're any good at this, and even the best programmers don't stop Googling things on Stack Overflow. (They just Google differently.) But you don't have to feel like you're an amazing programmer to be a useful one, is the thing. Code that works *works*, it doesn't have to be a masterpiece. There's *so many problems* in the world that just a little bit of code could fix, and there aren't enough programmers to go around. I'd think it was a real shame if there was one fewer because you stopped.
&gt; I am in the process of deciding whether to go with Python or with Node for an upcoming project for which performance is kinda important and before running my own benchmarks, I thought I could find some stuff online. Obey Knuth's Dictum: "premature optimization is the root of all evil." Programmer time is more important than execution time. Write in the language where the code is the most maintainable and fluent for you and any others on the project. You can always re-write your hottest code in C++, anyway.
It is nice to be able to write MATLAB code online and deploy it on ThingSpeak.
Bro. Sometimes you need coding motivation. You can see here you have brothers who will carry and be with you in the journey. But the most important thing you must do everyday is begin your day and and end your night with thoughts of self-confidence. You have to overall believe in yourself. If you can work on that everyday, you are already halfway there. #incodwetrust
I ran into an issue where I could edit and write other people's code but couldn't ever decide what I wanted to do on my own and if I started out with a fresh slate I was blank on what to do. Ended up just going with that for awhile, joined some open source projects I was interested in on GitHub and providing little ideas until I understood it better and then I started building additional functions for the application as I grew in skill and confidence. Took about 4 months before I felt comfortable writing my in code but understanding other people's code was a big first step. Also CodeCombat is fun and helped me get started because it slowly builds into some rather complex stuff (don't let the art style and starter missions fool you, that bugger gets hard later on)
&gt; Why not wrap it in another function to save an indent? ```with``` shows that there's a context being managed, here, and it reduces a bunch of ```try | except | finally``` boilerplate. If the ```with``` wound up being a ton of boilerplate, too (suggesting that, overall, there's an abstractable pattern to how the context is being managed here) then I might write a decorator that wrapped up the context management and use it to decorate the function.
Hello, I've been a programmer all my life. I knew I wanted to program computer when I was 10 years old and I enjoyed programming my any computer I could get my hand on. So when you ask, "am I a fit or not?", then that tells me right away you probably haven't found your true calling. Don't feel you have to go into computer science as a career. I enjoyed Mathematics/Computers/Logic Games so it was very easy for me. What is it you really enjoy doing? The question is, If you had to pick a career where you wouldn't get paid.. ie, you would do it for free, then you are getting close to finding your ideal career. I could do programming for free.. i love it that much! 
if someone's posting in this subreddit, and people's comments on that post include the str 'r/learnpython', they're probably not that fit for programming. 
That looks great actually, I could add some stuff in the `except` to hand out http500's while I'm at it.
Thanks. I'm migrating it to AWS and forgot I had a link here to it.
I've been looking for exactly this a month ago, gonna try it right now!
Of course you're fit for programming. You're asking the wrong question. :) If you find it interesting, pursue it, even if you don't end up in Computer Science, or use it in your career. (personal anecdote - computer science is not the only major that makes use of programming. It's the major that focuses the *most* on it, but you can still try other majors if you decide that CS isn't what you want. I decided after one year that CS wasn't for me at the time, so I switched to Business/Information Systems. There was still programming, but there was also a larger scope of IT as a whole, and that's what I needed. My point is, CS is not the end-all, be-all of programming). Here's another thing you will run into, and I struggle with this myself. There are *always* going to be people better than you, and a subset of those people may actually discourage you, because you're "not as good" as them. Do not listen to these people. If you can, learn from their expertise. But do not compare yourself to them, and let feelings of inadequacy fill you and keep you from coding, even if you're only coding for yourself. It's better to use what skill you *do* have and code, rather than to not code at all. Try to use what you know *now*, and if you stay interested, you will pick up more skills as you go. Do not let people discourage you from coding, even if they claim your code is amateurish or whatever. If any one replies about best practices, security issues, etc, you may be part of the problem. Yes, when doing work in *production* where security is important, you can't reasonably accept inexperienced code. But that's not what I'm talking about here. Coding, and learning to code, is hard enough already, and it's so incredibly easy to get discouraged by others (intentionally or otherwise) that you question if you're fit for programming, and then give up. As for applying what you know, my suggestion is to find a problem (even trivial or arbitrary ones), and solve it with a program. Don't get hung up on which is the ideal (or pythonic, in this case) way to solve it, for now. Just solve the problem as best you can. Once you have something that works, *then* you can look at it and wonder if you can improve it. Maybe you can add some error handling. Maybe you can complete a task with fewer lines of code (as long as it's still readable). Maybe you can add comments to your code (even if you're the only one using your program). Maybe you can use a totally different way of solving the same problem, just so you can learn a new way of solving it. Don't get hung up on doing things the "right" way. Get it working the best you can now. When you gain more experience later, you can look back and say "Oh, I totally could have done this better if I did it this way..." You *can't* do that if you don't code at all. You *are* fit for programming, and don't let anyone make you think otherwise. Don't get discouraged. Try to enjoy it. It can be hard at times, because you might be stuck on something, or other people's suggestions don't make sense (or they're downright mean). But when you've created something that works, you can say "I made that" and feel good. It doesn't matter what it looks like, as long as you made it. 
If this is working perfectly, I wouldn't like to be one of your users!
&gt;I wouldn't like to be one of your users! What users? We only have unpaid beta testers. Better yet, they pay us!
You use a list if you want an ordered collection of things accessible by an index. You use a dict if you want an unordered collection of things accessible by a key. You use OOP always.
oooh very impressive
Beyond my current skill level I’m sure but I’d be interested in following along 
Try getting involved in some students organizations on campus that you think you might be interested in. If there’re any team based competitions, try to join one. Make friends in the field and grow communally!
When you really think about it, all of the 'mysteries' of existence have been answered, but like this problem, there are too many psychological hurdles for people to accept them even when presented with evidence.
I would like to add something. A suggestion from Andrew Ng (Stanford professor), the real ideas you get about any project and it's implementation is not immediate. You have to work on other's project copy it, modify it; that's where you get the ideas from.
Indeed. Thank you
Indeed. Thank you
This really helped me when I was struggling just last week. Now I can read most commands and get a basic idea, even if I can't quite apply it. Only in chapter three though, but I skimmed the other chapters to see whats ahead. 
Yes, I added stuff from forum posts like https://stackoverflow.com/questions/35060523/how-to-use-pyinstaller-with-hidden-imports-for-scipy-optimize-leastsq and https://github.com/pyinstaller/pyinstaller/issues/1138
lets do it. 
 # The opposite of DRY principle - WET (we enjoy typing) principle And then your solution is a lot more code and more difficult to understand.
If you are running some code you wrote and it's not doing what you expect, or if it is hanging, then it is useful to trace the suspected problematic areas to follow the execution steps and see where they are diverging from your expectations.
great idea...
yes. pm me.
You might be interested in Pyfilesystem. Specifically https://docs.pyfilesystem.org/en/latest/reference/copy.html
It sounds like you have a good idea of what scale you need. If it’s easy enough to do so, take about a week to write a prototype in both languages and see if they can handle your use case. Also keep in mind, depending on your workload, you might be able to just spin up more workers to scale in either language.
Or should I just learn this on my dual booted Chromebook at home? 
Hey first of all thanks for the comments. I agree with you that list / dict could accomplish the same thing. There are places where namedtuples excels (which I should've include in the article in the first place,) such as: 1. immutability, 2. named attributes, and 3. less memory footprint, So I tend to prefer namedtuple whenever my object is immutable. But then you're right, it's not trivial to combing tuples because they are not designed to. That's why I did some research and came up with the recipe. I'll add supporting arguments to my TODO. :P
I haven't looked at jenkins but I will. I actually do need to reach an mssql server that requires windows authentication and I've been having trouble connecting on my linux server. Will jenkins not have this issue? 
Did you just go through the Luigi documentation or is there a good guide you found valuable? 
Before your time :)
Have you considered implementing __and__, __or__, __xor__, and __invert__ for expressions? There seems to be a decent chunk of code dedicated to parsing and building expressions, which could be handled by Python natively. For example: from tt import BooleanExpression as BE expression = BE('(A and ~B and C) or (~C and D) or E') # with __and__, __or__, __invert__ a = BE('A') b = BE('B') c = BE('C') d = BE('D') e = BE('E') expression = (a &amp; ~b &amp; c) | (~c &amp; d) | e expression2 = (a | b) &amp; expression The base object might be one of your Node objects, but when combined results in a BooleanExpression. This could allow for an arbitrary value per node (presumably as long as it implements __eq__ and __hash__, since you're dealing with sets). 
Jenkins service has its own AD user, which can have be a member of any AD group and therefore have permission on a sql server. In this scenario you would just flip native auth to true and the jenkins user could query the db. That would all be in windows.
except the overheating module is missing and the overcurrent is a stub.
Is there any algorithm they build logic gate according to truth table specification ?
cool. sounds like some garbage app that would be running node JS all over the place, single page apps, react, mongoDB. sweet tech stack!
Yes, that's the trade-off I didn't emphasize. ColoredSquare = namedtupe('ColoredSquare', 'x0 y0 x1 y1 r g b') vs class ColoredSquare(namedtuple('ColoredSquare', Square._fields + Color._fields)): @classmethod def from_(cls, square: Square, color: Color): return cls(*square, *color) First one is simple and clear. I also like this solution for simple example like this. Second is more verbose yet, IMHO, more usable for more complex problems. For example, when more Colored&lt;Shape&gt; need to define. Suddenly someone wants to change the rgb color to rgba. Then you have lot's of places to fix if you're using the first solution.
The Pipfile project is in stasis — Donald would like to re-write it into a functional API, and is very busy, so it has not been developed in a while. Don't expect it to move much for a few years. 
Yours runs the game a 1000 times, and at the end you know that the player won say 450 times and lost 550 times. What you don't really know is whether or not the player would have been better off to choose to Stay or Switch, or if the odds were better with one strategy or another, because you're not trying both strategies and recording the results.
When you've been programming for quite a while but the burnout hits you so hard you just plain quit.
Very cool. Have you looked into boolean circuit minimization? All the programs I've found (like Espresso) were incredibly tedious to use programmatically, but I'm not sure how complicated these programs are.
Numba will run slow, until all it's assumptions and tricks are satisfied, at which point it will beat even python. Try adding the nogil are to the jit decorator. Then learn about performant indexing. 
An array has a non-changeable size and all the elements in an array are the exact same type. This means that an array can be packed into memory much more efficiently. A python list uses arrays in the background, but also allows you to add and remove elements in O(1) time and allows the elements to be a mix of data types. --- If you have more questions like this it's better to post them on /r/learnpython. Be sure to [format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin. Also, include which version of python and what OS you are using. 
No problem. Glad I could help!
Python is not slow; perhaps you ought to spend more time improving your skills. I use python to process billions of rows of data, about 36tb worth. Language x might be marginally faster for some use cases, however, development time for language x is 10x or more greater. You also have to account for the pool of talent you can hire from and the labor cost to maintain. Well written python is very easy to read and make changes to even if you've never seen the code before. Computing resources are dirt cheap compared to the cost of labor. A few grand for a server once vs six figures for an engineer every year. Invest in your skills. Learn how to be a better coder, learn parallel and multi processing techniques.
?
Octave syntax is identical to MATLAB except for a few small additions, so the plotting should be the same. 
Numba is not faster than the hand written assembly that numpy uses.
pipenv?
That’s not true for all languages. JavaScript arrays are not fixed length. And the performance considerations are not about memory size but about caching. Also, numpy arrays *can* be a mix of types with dtype object.
Numpy arrays can be multidimensional and are used mostly to do fast numeric operations. If you have to do the same math operations on a bunch of numbers, numpy may be right for you. If you’re dealing with strings or objects, or you have a lot of branching or function calls in dealing with your array elements, then numpy is probably not suitable.
On mobile, those code snippets have no indentation at all. 
You can easily do that yourself. look at kv-diagramms, with this you can get the shortest boolean equation possible to solve a given truth table iirc. Had that like 4y ago.
&gt; That’s not true for all languages Thanks; edited. &gt; Also, numpy arrays can be a mix of types with dtype object. Yes, there are workarounds to these limitations. You can make an array of pointers to objects and call it "mixed type", but it's really an array of ints. You can use the `np.append` function to add to an array, but it's really making a new array with the element added on. I was focused on the array itself. 
&gt; the source of entropy is outside of the control of the algorithm But *accessing* that entropy is part of the random number generation, which means it's no longer strictly a PRNG. &gt; If the same section of the same entropy pool in the same state were used twice in that manner, you'd get the same SHA and therefore the same bytes, right? Yes, but this risk has nothing to do with the difference between /dev/urandom and /dev/random; it can only happen if there's something fundamentally wrong with the system (eg. it was cloned at an inopportune time in a risky way), and if it does go wrong then /dev/random offers no more protection because its estimate is also wrong! The risk they're talking about is about predicting the next output of a stream from the previous outputs. The CSPRNG turns this from trivial to computationally infeasible, though you run the (negligible) risk that the CSPRNG gets broken and no longer offers that protection. Reseeding, on the other hand, is literally unbreakable under the assumption that you have a correct, nonzero estimate of the unknown entropy in your input (which is by no means guaranteed). Both sides of the picture are important for different reasons, which is why you have both. The case that /dev/random protects you against that /dev/urandom does not is when the CSPRNG fails to provide the computational security it's meant to but the entropy you're reseeding with is good enough to pick up the burden. 
You have the means of production comrade, why not push yourself?
That's actually something I am really interested in, and I am looking to include a wrapper around the C espresso library in a release in the near future, similar to what is done now with the PicoSAT wrapper
Oh. I thought you meant the array can be picked more efficiently than a linked list representation. Numpy arrays and lists are *both* contiguous data structures, so a Numpy object array should take about the same space as a Python object array. The overhead of a list in memory is because the type must be stored with the value. Specializing array data types which Numpy does is not so much about storage space but about making operations fast. Functions whose implementation depends on the type of data can be chosen up front instead of when you get to that element. 
Right. I suppose a much better answer to OP's question would have been: "numpy arrays are structured in a way that allow numpy's operators to work on the entire array in a very fast manner". 
That is something that is coming up on my roadmap. I realize that strings aren't the easiest way to build expressions and that the built-in operators that you would likely provided a nice interface into expression-building. One idea that I'm working with now is the introduction of a "recipes" api for functions that would produce the underlying string representation and pass it to an expression object. Think something like: &gt;&gt;&gt; from tt.recipes import OneHot &gt;&gt;&gt; OneHot('A', 'B', 'C') &lt;BooleanExpression "(A and ~B and ~C) or (~A and B and ~C) or (A and B and ~C)"&gt; Anyways, I guess what I'm trying to say is that we seem to be thinking about the same things. And, of course, I appreciate the feedback and thorough example. Another reason why I originally began parsing the expressions with strings is to be able to parse s-expression (https://en.wikipedia.org/wiki/S-expression) representations in the future. This way, I'll have a couple of different expression "frontends" but won't have to mess with any of the underlying set or tree structures.
**S-expression** In computing, s-expressions, sexprs or sexps (for "symbolic expression") are a notation for nested list (tree-structured) data, invented for and popularized by the programming language Lisp, which uses them for source code as well as data. In the usual parenthesized syntax of Lisp, an s-expression is classically defined as an atom, or an expression of the form (x . y) where x and y are s-expressions. The second, recursive part of the definition represents an ordered pair so that s-exprs are effectively binary trees. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
Also, I am trying to gain some more exposure for the project (one of the reasons why I posted here). Would really appreciate any votes for my pull request to get this project added to the awesome-python list at https://github.com/vinta/awesome-python/pull/904
When you google "install pylint" and follow the instructions, what happens?
1: read the sidebar 2: /r/learnpython 3: google "pygame tutorial" 4: pay attention in class Not necessarily in that order.
Anybody can learn programming. Contrary to popular belief, traits and skills are both earned and inherent in you, nature and nurture etc. With that said, programming at a high level is impossible if you don't have a solid understanding of the theory behind computation. If you can understand computation, then you can be a programmer, if you so wish. Pro tip, you shouldn't be a programming expert right out of college. If you are an expert, you wouldn't be here in the first place right? Experience is key, and you won't feel like you've accomplished anything until you've actually accomplished something.
Interesting. See I'd say that it remains a PRNG, albeit a CSPRNG; I don't see it as a "true" (ie information theoretical) RNG unless it's a dedicated chip hashing entropy it's directly gathered off a sensor measuring some inherently unpredictable physical phenomenon like neutron emission in radioactive decay, i.e. a hardware RNG. Maybe we're splitting hairs, but I don't see the CSPRNG that yes, *may* be running on a machine with good hardware sources, but also may be running on a VM on some unknown cloud server that may or may not have redirection to underlying hardware sources as being a reliable source of "true random" data, aka an RNG. All that said, I'm perfectly willing to trust my security to the CSPRNG, I just wouldn't necessarily want to seed a universe factory with one. Btw, here's a less hypothetical point on this tack: in Python 3.5.0 (IIRC) there was a switch to getrandom instead of direct reads from /dev/urandom ... this caused a problem because, as it turned out, LOTS of people were running virtualized web servers and other things that depended at some level on CSPRNG output and which *were* being spun up from cold boot and launched really fast, and these were suddenly hanging because there wasn't enough entropy to initialize the CSPRNG correctly. This hadn't been a problem with os.urandom and random.SystemRandom in previous versions because the device calls were non-blocking even *before* init, whereas suddenly anyone who'd upgraded was faced with a deadlocked machine because getrandom blocks until the entropy pool is initialized, but now Python was waiting on just such a call before the interpreter was fully initialized. Wouldn't that mean that such servers running &lt;3.5 would have then been -- and likely still are -- in exactly that "fundamentally wrong" state, because they were, de facto, reading from the device and generating secrets (of unknown utility) *before* it was ready to deliver cryptographically secure numbers?
created a script for current task that involves making api calls that return json data, parsing that data to populate a database and then doing some further compiling and redirecting output for review. First time using the requests class instead of urllib2, quite noice !
Fish &amp; chips, all day, erry day.
i got you fam https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-0001-introduction-to-computer-science-and-programming-in-python-fall-2016/lecture-videos/
Are you referring to things like matrix multiplication, DFTs, etc? I'd certainly agree with that. On the other hand, a lot of numpy (like `np.nonzero`) is optimized for the common case, and a trivial numba implementation can be an order of magnitude faster.
thank you
&gt; when creating a system to trade stocks and milliseconds are a big deal However, there are many successful trading applications for Crypto currencies that are written in Python. In fact, Python is used in these scenarios for its ease of use and extensive numeric/scientific libraries. Not millisecond responses, but per-second level it does ok!
this is a very good outlook/perspective to have especially in any IT technology field, there is ALWAYS someone who knows more than you. Accept it and sponge as much as you can so when the next dude looks at you, you will be that guy hes trying to sponge ;)
s
These are the kinds of posts I love seeing on this subreddit. Great job on the module OP!
&gt; Are you referring to things like matrix multiplication, DFTs, etc? Yes &gt; a lot of numpy (like np.nonzero) is optimized for the common case, and a trivial numba implementation can be an order of magnitude faster. They really need a numpy.numba_utils or a numba.numpy_utils
Yes, that's the whole point of Cython, PyPy, and just writing a C extension.
VS Code is on linux. Why do you need developers edition? Is there a certain well defined workflow your team uses that requires VS? Can't you use any IDE you like? I'm sure there are devs using Django in VS, what exactly is your concern?
Now I'm thoroughly confused what you are asking: dual booted Chromebook refers to the OS, VS is an IDE, console is a shell...what are you trying to decide?
I guess what Im trying to say is I should just use the console on my linux laptop? It seems like most of the tutorials and books are geared toward using the cmd prompt. 
&gt; Its got nice semantics reminiscent of MATLAB That can't be a good thing. Matlab treats everything as a matrix (including strings), they have no concept of a dictionary, they don't have python's nice loops, they have a lousy import system, and they used 1-based indexing. They thankfully have slicing.
Sure, go ahead and learn on the console. People use IDEs because they get efficiency gains. It helps visualize your project structure, keeps environment information stored and switchable and provides code completion, etc. Just because tutorials use the shell doesn't mean you have to. Once you've learned, you could switch to an ide, it really makes no difference.
The people I work with only use Visual studio for C sharp. I found out i could use both R and Python(pretty basic level right now) in VS and I liked the workflow. Atleast in R it seemed almost identical to R studio. I though if I did learn C # eventually it would be nice to be comfortable using them all in the same box. As far as django is concerned I felt like this was the best way to get me more active with python. I finished How to automate the boring things and I can read as many books as I need to but I feel like it wont be as useful as getting my hands dirty. I cant really think of any projects to start with what I know but I have always been interested in building websites. I dont know. im sorry Im guessing none of this makes sense. 
Thanks!
I'm not sure why you'd need Django for GIS, you should consult with your team mates and see if they agree. There's no reason you can't use VS and there's no reason you MUST use VS (unless, like I said, there is a special workflow requiring it at your company).
I dont need it for GIS it was more of a hobby thing. Thanks for the help. 
&gt; Don't let feature creep sneak in. I like to make a list of features I will NOT implement, just to keep the number of features from creeping upward. It also gives me a useful guideline, "Well, new feature X would be nice, but it's as much work as one of these negative-features and not as cool, so I'm going to take a pass on it."
Glad to help! Just hate to see people get bogged down in tooling and IDEs, do the tutorials, learn what you need and you'll pick up tooling as you go!
Yeah the whole layout thing is confusing me. It is just what I have on my work computer and was going to practice during my free time in the office. 
Many of the things you have listed come with practise and experience Also, beware of imposter syndrome. It is very possible to have anxiety that makes you think you are bad at programming even if you are not, I have been the victim of this very harshly.
In my research group, everyone uses numpy arrays
Learning is learning and doing is doing and learning to do is learning to do and doing to learn is doing to learn. Do or do not. There is no good enough. 
... I thought I'm not in English class. 
Personally, I'm really missing books/comprehensive tutorials on PyQt5
What I mean is don’t worry about whether you enough to program. Just program. Being any good at it is more about having some experience and skill at knowing how to figure out things you don’t yet know how to do, and that’s not something that anyone starts out with. 
Just what I was looking for! Recently converted to python for sklearn and pyspark, but I've been sorely missing ggplot and dplyr. Plotnine is a good fix for ggplot, and this looks promising for dplyr!
Celery or even tulip seems adequate for this.
I’m not quite sure how tulip would work in this context? Celery I could understand with using it in conjunction for running the luigi tasks but it doesn’t actually maintain a pipeline. Unless I’m missing something? Care to elaborate?
Just to add to this with an example. Consider the following: x = list(range(10**6)) y = np.arange(10**6) def L(): x1 = [_x + 1 for _x in x] def N(): y1 = y + 1 # Run in IPython %timeit L() # 10 loops, best of 3: 136 ms per loop %timeit N() # The slowest run took 4.36 times longer than the fastest. # This could mean that an intermediate result is being cached. # 1000 loops, best of 3: 692 µs per loop *much* faster, easier to write, and (maybe?) caching.
I manage just fine. I never took a programming course outside on an intro course. I program to do engineering and am quite good at it. I found those intro problems to be mind numbing.
Good luck with the learning! Make sure to check out /r/learnpython for help. I also got a ton of mileage out of [CheckIO](https://checkio.org/). Puzzles and the like that you solve with Python. If you're knowledgeable about algorithms, it'll work your python skills. If not, you'll get to practice python and learn some basic CS skills.
&gt; Except your group already has a floating MATLAB license for your embedded controls work. Sure, in the hypothetical scenario where this is the case and everyone uses MATLAB that's fine. But this is just a guy in a YouTube video playing around with controllers posted on the Python subreddit - not an internal howto video that needs approval by upper management. Not everyone has MATLAB here. 
Well, yes, the initial program is used for that, but I am just too lazy to go along and click every button and type in my username. So I just made a script that will automate it all for me and my friends.
The namespace (the dictionary that correlates a variable name to an object) is mutable, yes. I suspect you have a REAL question that you aren't asking. What are you actually trying to do? 
&gt; So it's beyond hilarious watching the Reddit demographic's opinion (and votes) of how they think industry does or should work. Who (other than you) is talking about industry? This is a Python subreddit and this is a post about using Python to do something interesting. If your company uses MATLAB everywhere (which is common in engineering firms) of course it makes sense to use MATLAB. I'm not sure why you're trying to pick a fight over this. Maybe the parent comment's slight on MATLAB got to you.
&gt; But this is just a guy in a YouTube video playing around So are all of my YouTube videos. I don't link my Youtube to my Linked In or Reddit. &gt; Not everyone has MATLAB Most students, which encompasses a large part of Reddit's demographic, should have access to MATLAB of some sort.
&gt; This is a Python subreddit and this is a post about using Python to do something interesting. And OP did. Then posters went on tangents about Matlab. &gt; If your company uses MATLAB everywhere (which is common in engineering firms) of course it makes sense to use MATLAB. Which OP did. It was /r/Python that went off with this post: *Why on earth would you want to further process (anything) in MATLAB??* &gt; Maybe the parent comment's slight on MATLAB got to you. No more than a middle schooler's opinion on something you use gets to you. 
&gt; I’m not quite sure how tulip would work in this context? Well tulip allows for concurrent processing so each time a new file was detected you could have tulip process that file asynchronously while you continued to scan. Just brainstorming here. &gt; Celery I could understand with using it in conjunction for running the luigi tasks but it doesn’t actually maintain a pipeline. I'm not convinced you need Luigi (or Airflow) for this. Why not just create a directory for each stage of the process and move the files between directories as it is processed for that stage? A Celery (or a lightweight alternative) could monitor each directory and kick off jobs based on which directory a file is in to move it to the next stage. Finally, there must be some Luigi support resource, like a mailing list. And why did you choose Luigi over Airflow? 
There are no constants in Python like there are in C, if that's what you're asking. Any name can be reassigned to a different object with the exception of a few language keywords like `if` and `pass`. You can even reassign builtins like `sum` and `list` but that's obviously a bad idea.
&gt; Matlab and Excel I wouldn't compare MATLAB and Excel like that. You can actually use and reuse MATLAB code to process data whereas Excel sheets are not amenable to analysis pipelines. Yeah MATLAB costs money (so perhaps you should use Python to reach a broader audience) but its a fully fledged, respectable programming language.
&gt; It was /r/Python that went off with this post: Why on earth would you want to further process (anything) in MATLAB?? I agree it wasn't a great comment.
Python doesn't have variables, it has names https://nedbatchelder.com/text/names.html and then everything makes sense :)
So you're making a triple A game?
You're going through the growing pains that every programmer goes through. Just keep working at it. Most of my learning was "on the job". I "knew" python but I didn't really know it until I had a ton of smart people teaching me all the time with a steady stream of business cases to boot.
moving average crossovers?
You need to clarify what you mean by "mutable", as that word has a specific meaning in Python, in relation to *mutable* container types. If you mean can a given name be reassigned at will to any other *object*, then yes. If you mean are all the *objects* those names refer to *mutable*, then no.
Nope, this is it. I'm a fan of programming languages and roam between langs like Rust, Lisp, Haskell, and Python and so I just read up on these things for fun. I noticed that "Dynamic referencing/naming/binding" was not so much a term like "Dynamic Typing" and wanted to look into it more.
**Ah!** TIL that mutable/immutable is used in context of objects! Googling mutability alone shows my error in usage. My bad for misusing the term! But yes, former is what I meant. Thank you!
Everything I’m finding about tulip is some type of graphing tool? Am i finding the wrong tulip? Because I have a feeling that we will soon want to be making decisions on some of the data going through the pipeline, (e.g. a file that is produced might be fed into 2 other jobs). We are going to be targeting windows and airflow won’t work on windows. 
Yes, this is what I'm seeing now and as yawpitch pointed out to me, my error was using the term "mutable" in context of names when it is a term used to discuss structures and data.
I like your attitude! 
I just want to echo deadmilk's praise, and suggest an [article of mine](https://codewords.recurse.com/issues/four/the-language-of-choice) you might enjoy -- it's about BDDs in Python with some examples which might be nice to adapt for your library. (The github repo has extra examples that didn't make it into the article.)
To answer this question, we would need to know what you are using to run the program. IDLE? a terminal?
Python speed is always a big concern as it is slower than most of its counter programming languages. I think this is the reason , why so many Python libraries are written in C. But again, in front of power and scalability of Python code, speed is neglected in real time applications.
Ok, well as to the former, yes, any valid [name/identifier](https://docs.python.org/3.6/reference/lexical_analysis.html#identifiers ) that is *not* a [reserved keyword](https://docs.python.org/3.6/reference/lexical_analysis.html#keywords) can be reassigned to any *object*.
IDLE 
Here are some other libraries you might find useful / interesting, - https://plumbum.readthedocs.io/en/latest/ - https://pexpect.readthedocs.io/en/stable/ - https://amoffat.github.io/sh/ Here's a full list! https://stackoverflow.com/a/13106558/2490686 
I meant to say that it has *syntax* reminiscent of MATLAB, specifically the syntax for dealing with matrices and the use of `end` to specify the enclosure of a statement is similar to MATLAB. Julia however certainly does not treat everything as a matrix, has dictionaries and has better looping constructs than python, deals fine with imports and yes, uses 1-based indexing by default, which is more natural for mathematical purposes. However, Julia is actually in some senses agnostic to your indexing scheme and if it really bothers you you are free to redefine the indexing to start at 0 or 2 or whatever you wish at no performance cost and without any of your packages complaining. 
Am I the only one who never saw a use for truth tables? They seem like a really bad way to learn boolean logic. 
I wouldn't freak out like others in this post, just stating the point according to the OP's points: - Python is slow yes - Node has a highly optimized engine (v8), I'm not surprised that node is faster - There's no best language/framework, pick whatever works for you - Speaking of picking python/node for your project, I would suggest Python since node's community is a little bit messy compared to Python. They're both "slow"-ish, so if you're picking for performance, neither would give you much. Pick the one with better ecosystem and language ergonomics. - If you do need intensive CPU work, your best bet is probably going to be rewrite the core parts in C/C++/Rust. In my understanding, Python allows you to do that easier. 
Patches welcome.
Benchmarks don't actually tell you much about real world situations. There's a lot of optimization techniques that can be applied to Python or to Node. At the end of the day, you can write fast Python and fast Node; you can also write slow Python and slow Node. Use whatever is easiest for you to get your project going; you can optimize later.
Hey folks, developer of CertStream here. You can read more about the motivations and implementation behind this project by visiting the announcement page (https://medium.com/cali-dog-security/introducing-certstream-3fc13bb98067) on my company's blog. I'm also happy to field any questions anyone may have!
&gt; However, Julia is actually in some senses agnostic to your indexing scheme and if it really bothers you you are free to redefine the indexing to start at 0 or 2 or whatever you wish at no performance cost and without any of your packages complaining. That's an odd, but at least (maybe) solves that complaint. Matlab has slicing, but it's inclusive at the upper end, so maybe that's really my issue.
I'd try and learn Python 3.
I first decided to learn Python because of an idea for a program that I wanted to write. Most textbooks focus on giving you small problems that teach individual skills. I just worked on my one project and picked up skills along the way. It took me over a year, and I just broke it up into pieces and wrote it one class at a time. It was a blast.
&gt; Types are like unittests for code, but apply to your data. Types are types, even in Python. I know it might seems strange for someone that is able to write a total nonsense like that.
Best way is to built small apps or even writing small programs and making small changes to each of your code to see how you can improve it. You can also make a flow chart of like a small app that you like to design and based on that, write small lines of code:)
Hie, I went through their examples. Can I ask you what your workflow is going to look like?
Thank you for the feedback. I’m thinking both a current overview of functionality, a near-term roadmap and how to contribute will be starting places if there’s community interest.
Cool idea! I wrote a program to solve your maze from a jpg image [Here](https://github.com/edbeeching/StandAlone_Python_Tests/blob/master/maze_solver.py) I've never used the twitter API but perhaps I will try to make it more interesting over the weekend. Here is the solution to your most recent maze: https://imgur.com/iAyXguF 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [edbeeching/StandAlone_Python_Tests/.../**maze_solver.py** (master → e9ed9ca)](https://github.com/edbeeching/StandAlone_Python_Tests/blob/e9ed9cadf44d1ed8d9aa30e638eb53a5d5d45b07/maze_solver.py) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dpb6412.)^.
A lot of numbas power is in easily reducing a hard in general implementation to your case. I wrote my own pd.dataframe.add once as pandas version uses a huge temporal data structure. I knew a lot about the two framed I was adding so I could do it in place instead, and it was orders of magnitude faster to boot.
I would would say the current focus of the library near-term is primarily to aid in declaring schemas such as materialized view helpers, triggers as well as create analytical queries. In addition to this, found that the lack of support for streaming inserts/data, lack of copy to be bigger issue with the base sqlalchemy library. Generally, for data processing jobs, having each process run in threads or a distributed system using a queuing system has been more successful for me than async or using a threadpool executor for scraping data and then inserting it into a database. For DDL there isn’t much of a need for async. Since the library doesn’t target the orm outside of DDL, async shouldn’t be too much of a problem using a threadpool executor.
I was the same way a few years ago man. I did every python tutorial under the sun and I couldn't figure stuff out. It never even clicked, I just kept doing stuff over and over, looking every little thing up and seeing if it fit. It wasn't until I saw questions on /r/learnpython and realized I knew at least some answers that I started to feel like I knew *something*. I made little scripts like downloading images from imgur, reading comments on reddit, changing my desktop background from those images and stuff like that. Tiny projects that took me forever since I was learning. I followed a fantastic Python roguelike tutorial and tried to make one. Eventually I got super lucky and got hired as a webdev and learned a shit ton from some real smart dudes I worked with. Even today like 7 years later, after quitting that job to work on my own games fulltime, I feel slower than everyone else but I feel like if I can do it, anyone can. It just takes a lot of time, but I can assure you it's amazing whenever you get something going you didn't think you were able to.
&gt; Python or with node for a project that is kinda performant. I hate to say it but you don't know what you're doing. If you were to choose two languages for performance then I would expect you to be comparing compiled languages, but you instead choose the two of the worst languages for performance optimization. Any "Professional" would know this.
Can someone help me with this. This is straight from my book "Python Crash Course". When I try and type it in, I get to the second if statement line and the moment I hit enter I receive an invalid syntax error pointing to the if. Not sure what am doing wrong but can someone help a Pirate out!?
This is good for R converts (I used to be one of them), but what's wrong with something like this in pandas: import pandas as pd df = pd.DataFrame({'x'=range(5), 'y'=None, 'z'=None}) df.y = df.x * 2 df.z = df.apply(lambda row: "even" if row.x % 2 == 0 else "odd") df
Where is the text you typed in?
A nice few words on `map` `filter` and `lambda`. I found the examples a bit lacking tho. If you want to explain how they work, lengthier and more examples would've been a nice addition.
Some REPLs (interactive environments) might not support multiple lines. If after you press enter you see `...` you still have to type `tab` or 4-spaces ` ` before the `print` statement. &gt;&gt;&gt; if 'mushrooms' in 'Pizza Please': ... print('yum') ... &gt;&gt;&gt; Also for future reference /r/learnpython
Why would Python be able to do this, and what advantage would this magical Python program have over simply timing the slides manually?
Neat. I'm going to play with it for transforming search syntax. Good work!
Good bot. 
What on earth are you talking about? What is an ETL? What is timing out some computation or the network? What does "extend the time for arcpy" even mean? Is there artificial time limits for computing map data?
Sounds like an easy project for OpenCV. Report back when it's made!
Hey LightShadow, thanks for the help! Also I'll start posting more to /r/learnpython Learned something new today! 
No
Wow, thanks! You didn’t answer my question, so why bother?
Give a man a fish, as they say... 
https://youtu.be/1coLC-MUCJc ... That's tulip but it sounds like you are better off with Luigi so things will scale.
The Luigi mailing list is mentioned at the bottom of this page : https://pypi.python.org/pypi/luigi That will be your best resource I think. Good luck.
It is not about any one single instance of manipulation and how it compares to pandas, rather how it all fits together. I think most people (me included) not only struggle to remember how to do `apply`, `transform`, `aggregate`, ... manipulations correctly, but even when checking with the documentation to jog the memory it feels new. Using regular Pandas, code can get clunky very fast. This can happen whether you are doing it the right way or the wrong way.
How can we all get in contact?
Try /r/learnpython. Show them the code you have and describe where you are stuck. Be sure to [format your code for reddit](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) or use a site like pastebin. Also, include which version of python and what OS you are using. 
I'm really new to python, so I don't even know where to start with this besides for like asking input and making sure the input is within the range, would that subreddit still be able to help me if that's all I know? :(
Probably. Certainly a lot better than this subreddit. This subreddit is for python news, not help. Read the sidebar. 
Okay, thank you! 
Its 25k/year for "enterprise" level. And for 50k sers its 750/month on the more basic plan.. nope too expensive.
Do you mean using python, or in general, if in general you'll need to learn /r/HTML/
Sure, tell us more.. do you know any Python? Any other languages? What are you trying to build? Start with the basics...
Why don't the package and the module have the same name? It's a small thing, but figuring out what packages I need to have installed to run this or that example code I stumble on is an impedance point. If I see some code that has `import tt`, and python tells me "ImportError: No module named 'tt'", then the first thing I'm going to try is `pip install tt`. Likewise, if someone tells me "you should check out the `ttables` package, it's got some cool stuff", I'll `pip install ttables` and be a bit stymied when `import ttables` throws a `ImportError`. I don't mean to pick on you, but I've just been confused for a long time now why so many python library devs seem afraid of a little metonymy.
Oh really, that expensive for Enterprise? Damn...
okay. as far as languages go, I dont know any programming language to the point where I could actually do anything with it. I spent around 3 weeks running through freecodecamp and got frustrated with the required challenges in javascript since I didn't see the connection between manipulating number arrays and strings and how to actually make a website that would have forums you could click through and could create and store users information and things of that nature. as far as what i'm trying to build, i want to make a simple website that allows people to view one page that has a list of resources to learn any subject. in a sense, it would be similar to wikipedia where there is one page for every topic and people can create an account to come and edit the information at their discretion. so the website would allow users to register an account, have a search engine to find any subject they are looking for, allow registered users to add links to other websites, youtube videos, books, articles, journals, and a method for people to allow the best resources to rise to the top.
Feel free to elaborate 
On shared systems (research network) it is common to use LD_LIBRARY_PATH to access packages on the server but not in your local directory
pip install pylint, probably
Is there any other math field for which we need libraries? (looking for some inspiration..)
Do you actually want to write it from scratch or just install an existing system and use it? If you want to test things, have a look at bitnami stacks. You can run them on your own machine very easily.. and even use them in production if you wish. Building your own solution will be more work, but you might want to start with an existing framework like Wikimedia (what wikipedia is built on) or use a Python based app, like Django. Both are available from Bitnami. 
This will be a lot less frustrating than learning to build a car from scratch just so you can drive around ;-) I still think learning Python is a great idea though.. I'm still a newbie, but I know there are lots of tools out there I can use to get the job done without coding it myself. Checkout the /r/learnpython subreddit for places to start from.
Computer Programming and Computer Science are almost exclusive. You'll be dealing with all kinds of mathematical abstractions and most of them are life-draining philosophical gymnastics that have absolutely zero consequences on your later life if you are not going to be an academician. 
In that case are you building your own or some third party software/libraries against the shared libraries? By that I mean, couldn't you use LD_RUN_PATH during compile time to point to the shared location (assuming it doesn't change over time)? Not that LD_LIBRARY_PATH isn't "safer" in this case.
I am right with you buddy im a sophomore in college learning java and self teaching myself python. What has really motivated me to learn more is working with physical stuff. For example I have a raspberry pi and I bought a kit that comes with a breadboard, lcd, etc. It is so satisfying to watch your code actually do more than just calculating and arrays like they teach you in the beginning. I am by no means experienced but getting a raspberry pi and a kit has made it a lot easier for me to learn off of. It's intimidating at first but once you do it your hooked.
No you can't
Thanks a lot!!
lambda is a little strange, but map and filter can be easily expressed in a few different ways. # non-pythonic starter result = [] for x in iterable: result.append(function(x)) result = list(map(function, iterable)) # is the same as result = [ function(x) for x in iterable ] # non-pythonic result = [] for x in iterable: if function(x): result.append(x) # filter result = list(filter(function, iterable )) # or result = [ x for x in iterable if function(x) ] Thing is the comprehension can be mixed and used as list `[]` or generator `()` The best use I've seen for lambda is a way to make non-trivial function calls into iterables with iter(function, stop condition) #rather than with open('blob', 'rb') as f_in: data = f_in.read(2048) while data: #process data data = f_in.read(2048) # iter+lambda with open('blob', 'rb') as f_in: for data_chunk in iter(lambda: f_in.read(2048), b''): # # process data
End of this week, I am watching the live stream of the Ethereum DevCon3 conference. 4 days packed with exciting new tech. Here's my initial notes after 2.5 days: https://twitter.com/drandreaskruger/status/926614818886422528 tomorrow is one more day of livestream! Join us in that gitter chat if you want to. Linked in the README. Yes, Ethereum has also very good Python support now. 
You'd have to take video of every presentation, upload it to your computer, and then analyze afterward using Python and yes, something like OpenCV, to note when the slide changes, and then record those times. You could then even use Python to create another presentation with only the top x slides based on presentation duration. But this also seems prone to serious problems, with much riding on how consistently the lecturers follow your theorized model. I can imagine all sorts of edge cases that would challenge it, such as a prof putting up a slide briefly with the info necessary to find some paper or chapter pages and read on your own, and saying, "OK, just read this and you'll be tested on it" and your tool would miss that briefly shown but important page. Every 10% off your tool is, that's a letter grade down, roughly. If it were me, I'd just use attention and my mind to filter the presentations, which is an excellent skill to hone anyway.
FYI, I have a production script that parses and dedups tar data. Designed to process up to 700MB/s per process it can push 4GB/s if the dataset is in memory. The parsing and moving of the data is pure python3 although the sha512 checksums are technically C coded openssl calls. It's all about keen debugging and knowing the pain points for python.
he's the Python team lead of the foundation: https://www.youtube.com/watch?v=Yo9o5nDTAAQ&amp;t=4h48m42s
Possible. First you need to find the transitions. For that you subtract two consecutive frames of the video. Whenever two video frames (e.g. frame 100 and frame 101) show the same slide, the total pixel color difference ... abs(framePixels[100][x][y] - framePixels[101][x][y]) summed over all x and x ... will be small. So when that number spikes to very large values, you have a candidate for a new slide. You might actually want to check them manually too. Secondly, just subtract all two consecutive such positions. And sort those descending - and you have the slides which are shown the longest time. All approximate of course. And if he has flipped a slide forward and back - you would not notice. Hope that works out. Sounds like a very clever hack. Keep us updated if you failed your exam because instead of studying you spent all your time hacking his test with this video analyzer :-) 
That sounds perfect
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
&gt; I can't really apply anything. What you need is a PROJECT, a reason to code, some topic. A tiny task. Think about your favorite hobbies, one by one. Which one could do with some small coding task? And then just sit down, and try to figure it out. Come here when you're stuck. Good luck. Proficiency will come with doing it. A hundred thousands of lines of code, and I still don't feel "fit" for programming.
Pedantic note: lambda is not a function, it is a keyword to make lambda expressions. I feel like you wanted to say "map, filter, and reduce", but, like me, discovered that reduce was removed from the builtins.
The way I go about learning something or making a webpage is I decide which language to use ASP/PHP etc for the back end. (This was easy before I to learn ASP/C# for work, my go to was PHP) If you don't want to get into that conversation start with HTML/CSS see if you could just get the layouts right and just build the pages and then that will link in with the Java for the forms etc. &amp;nbsp; https://www.w3schools.com/ Go there its where I started before I needed more complex help of Stack Overflow. That aside there is quite a bit you can do with Python I just subbed here because I had an interest in learning it.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Depending on your editor you can "zoom" in and make stuff bigger. This is a google type of thing my dude as it depends on your ide/editor.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community is not a fan of "how do I..." questions, so you will not get the best responses over here. On /r/LearnPython the community is actively expecting questions and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. No matter what level of question you have, if you are looking for help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
See also MySQL Connector for this problem.
Right,thanks for the detailed explanation!
Maybe what you can do is use an external microcontroller (Arduino) to control the raspberry pi. Python can issue a signal to the external microcontroller to start counting time before issuing a system shut down on pi. When count down ends on external microcontroller, it can then send signal to power up the raspberry pi. When pi boots up, it can auto launch your Python program again. 
 for topping in requested_toppings: print("Adding %s" % topping) 
Funny. I did the same thing using punch cards (do you know what those are?) and Fortran II on an IBM 1620 (https://en.wikipedia.org/wiki/IBM_1620) a long, long time ago. I carried all my precious punch cards around with me in a box. They represented hours and hours of work. After I graduated I always took that box of punch cards with me. I reluctantly threw them out when I finally came to my senses and realized that the world had moved beyond IBM 1620s. I met my wife of 48 years in the room where the IBM 1620 was set up for students to use. It was raining one day and she had an umbrella that we shared on the way to biology labs. 3 kids, 2 grandkids, a great wife, and no box of punch cards. Sorry for the long story.
**IBM 1620** The IBM 1620 was announced by IBM on October 21, 1959, and marketed as an inexpensive "scientific computer". After a total production of about two thousand machines, it was withdrawn on November 19, 1970. Modified versions of the 1620 were used as the CPU of the IBM 1710 and IBM 1720 Industrial Process Control Systems (making it the first digital computer considered reliable enough for real-time process control of factory equipment). Being variable word length decimal, as opposed to fixed-word-length pure binary, made it an especially attractive first computer to learn on — and hundreds of thousands of students had their first experiences with a computer on the IBM 1620. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/Python/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
I'm not really sure how I'd code for that. I understand what you're saying but I wouldn't know the syntax 
Truth tables are very useful as a building block in logic synthesis, technology mapping, and logic optimization. Any operation on Boolean functions over a small number of variables, say under 10 (or 16 variables in extreme cases) is likely to be faster or more powerful than any of the alternatives. A 32-bit unsigned integer can store a 5-variable function and quickly perform a lot of operations. For example, replace the order of variables, negated them, AND, OR, etc. You cannot use truth tables for representing Boolean logic by itself, as it takes space exponential in the number of variables. But when used judiciously in the right places, it help dramatically speedup many algorithms. A representative example: https://people.eecs.berkeley.edu/~alanmi/publications/2006/dac06_rwr.pdf 
&gt; I used the series from New Boston. Short You-Tube lectures. What I did was watch the lecture, pause it, enter the code, then play with it. Then I would search for whatever the lecture was about and play with that code too. And I would save examples etc in Nimbus under appropriate headings like loops, arrays, etc. so I could refer back to them. Now I am working problems on Hackerrank and CodeChef. They have beginner series that help you learn. They also have contests. I have tried some of them. A lot to learn. One step at a time. Good luck. 
You can look into pySerial. It is a serial library that will allow you to 'talk' to the microcontroller.
TfidfVectorizer returns a [scipy sparse matrix](https://docs.scipy.org/doc/scipy/reference/sparse.html) to save memory when dealing with large amounts of features, so it’s not going to be immediately intuitive to look at if you’re not familiar with sparse matrices. Try setting up three or four sample sentences and running them through, then look at the output while perusing the [API docs](http://scikit-learn.org/dev/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer.fit_transform) and or using dir() on the fitted tfidf vectorizer object and look for informative looking attributes like vocabulary_. Using a small set of known data and spending some time investigating the component you are using should get you there pretty quick!
Right thanks!
Text sentiment analyzer that so far can process 1.1millions words in under 30 seconds. Learned Django so the script can be utilized through the browser. Proud of it so far, just hoping it'll help with getting my foot in the door as I'm currently looking for a Junior level position.
can you use threads somewhere in django to fire up multiple threads the same way you're describing Nginx to be? Working on a web application now that may run into this problem.
HTML is mandatory, as is it's counterpart CSS for anything with actual visual quality. If you want dynamic and interactive displays and advanced functionality (login, statistics, etc) you then need JavaScript. Fortunately, two frameworks exists for this exaction function -- creating websites with Python. The first is Flask, but only use this if you end to do bare minimum web design. The second, and recommended, framework, however, is Django. It's intelligent by design and allows you to make a website 100% accurately, that is secure and with little overhead, and utilizes SQL, JavaScript, CSS, and HTML! Sites like NASA currently use Django. As do I for my corporate management.
**Best prerequisite for your project us using [OpenCV library](https://opencv.org). Please give us an update when you hit success!**
&gt; Running from the command line **Debian** sudo apt-get install pylint **Ubuntu sudo apt-get install pylint **Fedora** sudo yum install pylint **Gentoo** emerge pylint **openSUSE** sudo zypper install pylint # python2.7 sudo zypper install python3-pylint **FreeBSD** portmaster devel/pylint **Arch Linux** pacman -S python2-pylint # if you live in the past pacman -S python-pylint # if you live in the future **OS X** pip install pylint ** Windows ** pip install pylint **From source** git clone https://github.com/PyCQA/pylint git clone https://github.com/PyCQA/astroid 
Read about data structures, algorithms, and operating system concepts
Nah, I use PyCharm Professional. I think it's the best, most reliable, and Python native IDE to ever use for any Python project. Plus, the company behind his suite (JetBrains) develops similar all-in-one solutions for other languages, such as; * [Clion for C and C++](https://www.jetbrains.com/clion/?fromMenu) * [DataGrip for SQL](https://www.jetbrains.com/datagrip/?fromMenu) * [GoLand for GoLang](https://www.jetbrains.com/go/?fromMenu) * [PyCharm for Python](https://www.jetbrains.com/pycharm/?fromMenu) * [IntelliJ IDEA for JVM/Java](https://www.jetbrains.com/idea/?fromMenu) * [PhpStorm](https://www.jetbrains.com/phpstorm/?fromMenu) All tools are cross-platform languages, and also support: * Intelligence smart code completion, code inspections, on-the-fly error highlighting and quick-fixes, along with automated code refactorings and rich navigation capabilities. * Web Development Frameworks, specifically supporting for modern web development -- such as DJango, FLask, Google App Engine, Pyramid, and web2py. * Scientific Tools, integratable with IPython Notebook, interactive Python console, support for Anaconda as well as multiple scientific packages including matplotlib and NumPy. * Groovy, Scala, Kotlin, Android. * Drupal, Wordpress, Zend Framework, Laravel, Magentoo, Joomla * HTML5, CSS, Sass, Less, Stylus, CoffeeScript, TypeScript, Emmet, and JavaScript. * Refactorings, debugging and unit testing. * Built-in Developer Tolls, for a huge collection of tools out of the box: an integrated debugger and test runner; Python profiler; a built-in terminal; and integration with major VCS and built-in Database Tools.
Thats a polite no. You will discover as I did that people with working stock trading bots don't tell a living soul how they work. 
Hah! Love the title.
The answer to your question is "No". The print function is simply printing text to the console standard output. You could always print some ASCII art though.
Walk through the django intro tutorial. Itll tell you what you need plus teach you most of it at the same time... It's perfect for somebody like you. 
I'm starting learning Python, so... I'd consider that my main+pet project :)
The learning aspect is bound to vary person to person, right? As for usefulness in actual applications, the "implicant table" is probably the data structure most applications would choose to represent a Boolean function in tabular form. Eg, Espresso uses one kind of implicant table for logic minimization.
Hey, I wrote one of those! Thanks for the mention :).
I have no idea what terminal you're using. Some do allow you to increase the font size in the settings. From within in python there is not a way. 
That’s great! :) I’m a bit astonished how small the code is. You could make a bot that solves and post those solutions
I am working on a scraper to get crypto currency data for analysis. Also working a scraper that gets all the sellers for a set of products on Amazon and tracks their inventory. Next week I will be making a connector between woocommerce and the Amazon affiliate api. 
This does not look very good.
Yes. It's not something you can do in your code, but you can in the settings. Go to the options menu, configure IDLE, and pick a bigger font size.
The last print is printing `type(print(...))`. Print returns None so printing `type(None)` returns None Type.
What do you gain from this?
Hi there, I'm glad that you are getting started, it is such a great thing to learn. My advice to a beginner would be to keep your code as clean as possible and always write comments about what you are doing. If you come back to it in a year you might wonder what was going through your head when you wrote it haha. Anyways here is my solution, I hope that it is easy to understand. https://imgur.com/a/IjH3j
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/nj16tAY.jpg** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20dpbuagh) 
Sorry if I had offended you guys somehow, but I think you guys may have misunderstood,I'm not trying to prove or disprove anything, I merely just found the problem weird or interesting, so I decided to run a simulation test it.
1. **print** with no argument prints "\n" and returns **None** 2. **print** with **None** (from 1) prints "None\n" and returns **None** 3. **type** with **None** (from 2) returns **NoneType** 4. **type** with **NoneType** (from 3) returns **type** 5. ** print** with **type** prints "&lt;type 'type'&gt;\n" and returns **None** 6. **type** with **None** (from 5) returns **NoneType** 7. ** print** with **NoneType** prints "&lt;type 'NoneType'&gt;\n" and returns **None**
If you would like i can rewrite this in English for a small fee
Up voted even though I prefer format to %
I was thinking to make something upon https://github.com/conda/conda/pull/5159
Cool! What are some uses for this data? 
For me it depends, with one thing %s feels better, although you could just say print("Adding", topping) 
I am trying to do something similar. But when we are allowing package reads from two different locations, how should conflicting dependencies be handled.
Of course if you have something working, you need serious reasons to rewrite it in another language. The case I was thinking of is when you explore your data first with Excel, then Matlab for more in-depth, and then after to integrate it with production, it might be easier to use Python while keeping the Matlab logic
Much more though, i wouldn't program a programing language or kernel either in python, program engines neither dropbox is written in go rust and python... go figure. Pro of python: super fast to read and write code, super productive. Con: slow in some cases and for big projects not as easily maintained. Most cases python is a super good choice but NO language is perfect.
johnmellor and myself go into a *lot* of detail on that subject at the issue you raised: https://github.com/ContinuumIO/anaconda-issues/issues/149 My final conclusion can be summed up as: 1. `py{w}.exe` needs to be in C:\Windows\System32 and I would oppose strongly and idea that conda should ever write anything outside of its installation prefix and should avoid writing to the registry when not strictly necessary. 2. `py{w}.exe` provides a capability to read a `py.ini` which *should* allow us to put it in the conda installation prefix and avoid the registry but it does not work correctly. So IMHO this is a bug with `py{w}.exe` and if you really care for this feature then I recommend you file a bug with the `py{w}.exe` project. You can read the details on your bug report.
Check out this tutorial - http://zetcode.com/gui/pyqt5/ It is suited for beginners and intermediate programmers. I hope it helps you.
Actually, by function, I meant feature. Sorry for ambiguity.
If you're learning python you can join r/learnpython. You'll get more help there. Have fun with coding!
No, you're fine. I was talking about the responses to the original problem from all those years ago, and just saying that it's completely unsurprising still the problem still exists today.
Check out [Sympy](http://www.sympy.org)!
`random` is included in the standard library. To use it you just need to put `import random` at the top of your script or in IDLE before you try to use it.
If you have the file you just type import random do you understand the purpose of importing modules?
I would recommend getting anaconda. It will make learning less painful.
Anaconda?
&gt; A sort of safe solution is opening the file yourself in exclusive mode Note that exclusive mode is only available from Python 3.3. With previous versions [you have to hand-roll it using open(2) and `O_EXCL`](https://www.reddit.com/r/Python/comments/7aj0n4/file_copy_options/dpadq9z/)
Hmm, that's weird. I guess I was just using the code wrong. Thanks!
What is wrong with simply using the default Python installation. What is the actual advantage of another layer ?
It's not really a layer, it just comes bundled with a lot of useful packages. 
Anaconda is a python distribution that includes spyder which is a scipy dev env. In laymans terms its .5 gigs of shit that has everything you will need for your foreseeable future. Just download it and use spyder. It will have all the libraries you want so you can just type in import whatever you need and its yours. If you need any extra stuff you just go to anaconda prompt and type pip install "x". Just get it and open spyder and you can thank me later.
You can learn command line basics later.
I'll look into it. Thanks!
More importantly, stop ruining your code by making it run on earlier versions. The other day someone told me they couldn't accept a contribution as it required version 3. As far as I am concerned, that project no longer exists.
Theres nothing wrong with using the default python installation but hes clearly struggling with it and this can help him move along so he can go back later when he is better versed and ready to digest the command line.
Oh that’s cool! Do you have the original code handy? I’d like to take a look
Do you have the original code handy? That’s seems very interesting
Not to be patronizing but from your diction that seems beyond your level. You should be competent with pandas and numpy before you embark on that.
It's not really another layer - to most people, it's just Python with all the popular third-party modules included in one installation. That's why I like it - I install one executable and get pytest, BeautifulSoup, numpy, matplotlib, openpyxl and others included automatically.
Probably the best thing about Python is that there's not much that's difficult to do in Python. This is probably a better question for r/learnpython. Basically you can break it down into parts. 1. Figure out how to scrape your news sites 2. Define what constitutes a key word 3. Rank your key words 4. Figure out how to display the output That's how a student would do it. A pro would google `python word cloud library` 
I am cycling back to my database work where I try to build a useful database on top of wiredtiger (mongodb database engine). I am considering adding 3D index for (latitude, longitude, time) intervals in https://github.com/amirouche/AjguDB and/or a versioned graph abstraction.
Deprive the wealthy of working software. Squeeze them like a sponge. Dollars will come out.
What is 'Fuzzy Linear Programming'?
How’s does using strings instead of functions and misusing the shift operator to do something other than shifting help? 
I know and use python3 at work
I've been working on various projects. Mainly on a small game using pygame.
Thanks! I'll try your suggestions soon :)
The title is somewhat too reductive. The post is more about focusing on what the maintainers find most productive and expecting the community to fulfill their own needs, which is something I agree with. If I had any good open source libs, you'd have a hard time convincing me to support anyone else purely because I'd rather fix my own problems, which is what OP is suggesting.
&gt; Any recommendations on where to go from here? tl;dr: Django admin is your friend I was a Django developer. If you have frontend+javascript skills I recommend you go the rectjs+DjangoRESTFramework. Otherwise, get a good grasp of django admin, (and along the way of django models) you can leverage it to some point to avoid the need for a custom frontend. Once you get a good idea of the problem you are solving (good specifications). Move pieces of the business requirements UI/UX with custom made widgets and workflows using DjangoRESTFrameork and reactjs (prefered). Don't trash that Django admin, try to maitain it as it will be useful for debugging stuff later. If you are not into Javascript, you can go the html templates routes + small jquery snippets. In the past, Jinja2 was a better tool than Django templates. Jinja2 is still the most popular template engine in Python ecosystem. 
Look up how to deploy it basically. Honestly, I've been hacking on Django several months or years before publishing my first project that way...
Awesome find! I'm a ChemE student and our only programming and numerical methods courses were in VBA. I was lucky to get experience with R through taking a math minor and next semester I will be taking a python course, and this kind of book is a great start for me since it's familiar material implemented in a new language.
Thanks sir...
gunicorn + a few lines nginx config is not trivial to publish a Django app? Something like https://gist.github.com/Atem18/4696071?
&gt; uwsgi and nginx Forget about Flask, forget about uwsgi. Flask is good in some situation, but it's more difficult to grok. If you don't have prior Python web knowledge, Django is the way to go. Also gunicorn is in experience easier to setup that uwsgi. 
You are welcome.
I am so happy I can be of help to you.
I did a project like that a few years ago https://github.com/amirouche/xp-hivi.mx That said, the code has bit rotten you will have an hard time running. It's a Django 1.4 i think something like that. Today, I would use aiohttp with websockets to be able to lively collaborate to build the playlist.
Why is python3 still not on macOS? Why is Arch (and now Fedora, sort of) the only major python3 default distro so far? Making it the OS default is really the missing piece.
It makes the project easier to find for people exploring Python packages
Hey man, I love PyEDA! It's a big inspiration behind this library and I actually have it listed on the special thanks page of the project site (http://tt.brianwel.ch/en/latest/special_thanks.html#inspiration). Thanks for writing a great library!
From the docs. `To install Scrapy using conda, run: conda install -c conda-forge scrapy Alternatively, if you’re already familiar with installation of Python packages, you can install Scrapy and its dependencies from PyPI with: pip install Scrapy`
I would split the original number in three parts: beginning, the two unknown digits, ending. Then in a loop count from 00 to 99, and for every number concatenate the three parts and check if it is correct.
What about using os.path.exists(path) Return True if path refers to an existing path or an open file descriptor. 
It's time to review [PEP 394](https://www.python.org/dev/peps/pep-0394/) again and officially deprecate the link between `python` and `python2`. There are now [less than 3 years](https://www.python.org/dev/peps/pep-0394/) to the official death of Python, and v3 is now mature and stable enough that pretty much all libraries of note have been ported; it's the right time for distribution maintainers to start fixing their scripts, at the very least pointing them at `python2`. More than 6 years have passed since PEP 394 was introduced, and more than 3 years since the last review. It's time to move on.
A bunch of theoretical mumbo-jumbo. From my perspective there's a general problem with conda: the uncompromising attitude towards various python things. Because we don't like this and that we make another solution that doesn't play well with the rest of the ecosystem. Users don't care who's fault is it and who fixes it, they only look at the result.
&gt; #no longer exists. Best. ---- ^(*I was trying to think of a better way to put this, but "you're dead to me" is simply the best way to think about a project that has a dependency as old as the final episode of Lost.*)
Yah this is what I ended up doing. Only realizing afterwards that it really doesnt matter if I actually check if the file is there. 
functools.partial is better for that use case. It's a little faster, and arguably clearer.
On my mac, python points to 3. I didn't do that myself, and I suspect it happened with Anaconda.
Done! [Horrible rushed code](https://gist.github.com/anonymous/166078ab60fcf3cf287c67b4e42691a7) [Twitter](https://twitter.com/MazeADaySolver) not that exciting now...but just you wait for tomorrows maze!
&gt; I suspect it happened with Anaconda. Yup. But on mine, `python` points to `ipython`, which runs under Python 3. Again, not something I did myself, Anaconda made it so.
&gt; On my Macbook, Python points to 3 That's not normal, even High Sierra is still defaulting to 2.7. Might have been anaconda or something weird with Homebrew. I'm surprised you are not seeing any major breakage. Arch Linux is the only major OS that defaults to 3. Ubuntu, Fedora and Debian ship with 3 even in standard installs, but never as default `python`.
Some of our setups just upgraded from Python 2.5 to 2.7. While I don't disagree, it's quaint to get dictated at from people that don't understand all industries. For reference the JSF's MCU was specified in the early 2000s. I worked on a locomotive that was build in the '70s and being retrofitted with some electronics designed in the late '90s with software from the late '00s in the mid '10s. When you deal with regulatory bodies you get a toolchain certified and don't touch it again.
Why is it now free? Does it use an older Django version?
Linear Programming problems using triangular (right now, will switch to trapozeid and stuff later) fuzzy numbers. My code is more about crispifying them to operate on them properly.
I wish PyPI would clean house of someone would make a 'curated' PyPI. Drop everything that is Python 2 only. Start dropping 3.4 only stuff. Hell just automate a "pip install ___" on the latest version. If it fails notify the maintainer. If the e-mail bounces drop it from the search.
pandas may be bad - this is worse (strings will not get any autocompletion, it's a hack at best)
I do a lot of Python work, embedded and server side. Several of our projects now have a prelude like: ``` import sys assert sys.version_info.major &gt;= 3 assert sys.version_info.minor &gt;= 6 ``` Both to make sure that the CI containers fail early and don't end up with anything hard to debug, and to make sure that you get proper errors in production if you're lagging behind. Other pieces of code have had a : ``` async def _trap(): pass ``` Simply to make sure that it's not parsing in older versions of Python. I really wish there was a better function call to do this built in that did not require asserts. 
thank you, ill give it a go
 assert sys.version_info &gt;= (3, 6)
Even better, you can do async def trap(): yield None And everything under 3.6 will fail. I might start putting this in setup.py to ensure folks aren't trying to install on versions I don't support. 
Please don't. Some of us run legacy software that can't or won't be upgraded to python3 for one reason or another (I've pitched it, even included the looming EOL for py2).