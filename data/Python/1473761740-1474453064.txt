Sounds interesting, Could you perhaps elaborate on how you managed to achieve this?
Not really a big fan of the builtin simple http server API, it has a pretty ugly API, I think you're better off starting with something like Flask to be honest.
I don't have access to my code right now, but I can write you an example.
I have faced with the same problem. It occurred regardless of whether installed via Homebrew or not.
no. There continues to be no official distribution story for python applications; pyinstaller is as good as it gets.
Ah, that sucks. You may have some luck with [PyRun](http://www.egenix.com/products/python/PyRun/).
Mmmh, [this one](https://docs.python.org/3.6/whatsnew/3.6.html#pep-498-formatted-string-literals) makes me nervous.
I tried to look at the code of PuTTY, the SSH client once. It was pretty damn bad. OpenSSH is also a well known example.
Why? I use python, swift and rust among other languages on a weekly basis and formatting strings in python is a sour part of python if you ask me.
I like it, been using celery's retry for a while but I somehow find this easier and cooler. Thanks!
Okay, so this is far from production code, but it should serve to give you an idea. This is written and tested in Python 3, btw. **worker.py** - This is the script doing the actual work. Remember what address it's listening to, because you have to put that in the next file. Just running it will start the built in Flask debug server, which should be sufficient for a quick test. A worker exposes a function "execute", which expects you to post a JSON string containing a script and a chunk of data. You can run multiple instances of the worker with different port numbers on the same machine if you want to pretend you have a network of them. import json from flask import Flask, request app = Flask(__name__) @app.route('/execute', methods=['POST']) def execute(): data = request.json script = data['script'] data = data['data'] loc = {'data': data} exec(script, loc) result = loc['result'] if 'result' in loc else None try: return json.dumps({ 'result': result, 'exception': None}) except Exception as exception: return json.dumps({ 'result': None, 'exception': ( type(exception).__name__, str(exception))}) if __name__ == '__main__': app.run(debug=True) **manager.py** - This is the script that tells the workers what to do. Right now, it contains a shitty test script that accepts a list of ints and returns an ugly looking string. It uses the ThreadPoolExecutor from concurrent.futures to kick off a bunch of requests, collect the results (or the exceptions), and return them in a list. import json from concurrent.futures import ThreadPoolExecutor from pprint import pprint from requests import post # Convenience function. Feed it an iterator for easy chunking. def take(items, amount): for _ in range(amount): yield next(items) def execute_script(script, data, workers, items_per_worker): # Wrap the data in an iterator. data_iterator = iter(data) # This is where we store the results. futures = [] # We'll run as many threads as we have workers. number_of_workers = len(workers) # This will become false when we run out of data. running = True with ThreadPoolExecutor(number_of_workers) as tpe: try: # While we have data, loop over the workers and send them scripts and a chunk of the data. while running: for worker in workers: # Get the URL for the current worker. url = 'http://%s/execute' % worker # Collect some data to process. chunk = list(take(data_iterator, items_per_worker)) # If there's no data left, quit the loop. if not chunk: running = False break # Create a dictionary with our payload. payload = { 'script': script, 'data': chunk } # Submit the payload to the worker, and store the resulting future in the futures list. future = tpe.submit(post, url=url, json=payload) futures.append(future) except Exception as exception: # Dang it! print(exception) # Scrape the results out of the futures, load the json, and return it. return [json.loads(future.result().text) for future in futures] def main(): # You have to keep track of all known workers, somehow. Let's stick them in a list for now. workers = ['127.0.0.1:5000'] # Here's a script we'll run remotely. script = """ def some_function(items): for item in items: yield "[%03d]" % item def run(data): return "-".join(some_function(data)) # data is the data you put in the payload dict in execute_script(). # You should assign a value to result when you're done. result = run(data) """ # Let's make a bunch of data we can work on. data = range(1, 101) # Hand the scripts and all data to the workers. result = execute_script(script, data, workers, 20) # Print the results. pprint(result) if __name__ == '__main__': main() 
Wow man, This is far too much effort! Thank you so much, This will help immensely! 
Oh, no problem. I got stuck in "how did I solve this last time" mode. There's no stopping me then.
Thank you :)
I don't know if this is a joke or a reference or what, but I can imagine it being true either way.
Great article! For the external state section, specifically about databases the solution is: don't directly test the interaction with database. You want to test the boundary between your program and the database, and mock out the database itself. You should know what the database expects and what it returns, and adjust your code to fit. If your database is changing structure often enough that your tests will fail frequently, then you should probably rethink what you're doing (if your tests are failing, your code *should* fail too!). 
Imho that does not solve two essential misconceptions of Python 3: * No **universal default encoding** for *all* platforms for IO (preferably UTF-8) * No possibility to define an (optional) output-encoding for ``print``, or make it accept also Bytes (like [``click.echo``](http://click.pocoo.org/5/utils/#printing-to-stdout) as [rspeer](https://www.reddit.com/r/Python/comments/52hoas/python_36_beta_1_is_now_available/d7kmraj) has allready mentioned) If you want a language to be platform agnostic, you should simply define a default encoding for all IO. If you stick with the *platform default* you loose unnecessarily an advantage that an internal unicode type offers. Why do we have to make the same mistake as Java did? For newbies (or senior devs that have no understandigs of unicode and encodings) the actual behavior makes it even worse than in Python 2, as they will face problems much later in the application development process... after the deployment onto another platform than they used for development. So simply switching from Linux to Windows can cause much problems or even damage! Further more this rule would be so damn simple: *"Python uses encoding XYZ as default for IO. If you want to use another, you must provide and ``encoding``-parameter!"* Couldn't be easier, could it? And not to be able to print encoded bytes is a shame and make python less usable on Windows systems (who does use the Power Shell? Even though it is quite good...). Of course you can ignore this from a language engineer's PoV, but imho you shouldn't. The acceptance (and popularity) of a language could take damage if it is poorly usable on common systems (think of C# via Mono!).
https://twitter.com/micropython/status/706920047411904515 - zerynth vs micropython differences.
Awesome! I made sure to bookmark this one; very fascinating!
You can try cocos2d (http://python.cocos2d.org/ is the python library - there's also an Obj C port for iOS games). It has a sprite library and a fairly comprehensive animation/tweening library.
Is there a way to keep the proper indentations, but not trim the output? Sometimes I need to have it all on the screen so I can Ctrl-F through the outputs. Edit, sorry just found text_autoclip_enable = True
...in that it specifies that it won't be different than .format() at runtime. 
Absolutely. I was only replying to the implied security issues. 
Asynchronous python has been historically poorly thought out, but the new async core is starting to change that. Unfortunately, there is a large amount of legacy code that is written in blocking fashion, so it will take a while before the async side catches up to support every type of IO you might want to access. Node had the benefit that it was asynchronous from the start - so all the IO integration libraries were also async from the start (and blocking code was frowned upon).
THANK YOU FOR PUTTING THIS IN REAL WORDS. I've been working on a discord bot and learning about asynchronous python in the process, and it has been such a series of "why are we doing that" moments.
When was the last time you looked at the PHP ecosystem?
I ended up fixing the problem. I had to checkout the HEAD of the git branch to get the latest version. In the standard branch on Homebrew's install it's not there. It's an option under the install command for OpenCV3 "--HEAD". That, along with the "--with-contrib" and "--with-python3" options. I ended up figuring it out by compiling OpenCV a couple of times to figure out the Cmake options.
I see. I think the, sort of, implicit scoping here made me nervous. Probably for the wrong reasons. Thanks.
https://twitter.com/Zerynth/status/706947800496513024 - zerynth vs micropython differences
Am I missing something? I installed it, I import it, but it seems to produce the exact same output as regular pp For example: (Pdb) pp stuff &lt;class '__main__.stuff'&gt; (Pdb) pp qwerty &lt;__main__.stuff object at 0x7fb8f4dbbe10&gt; (Pdb) from beeprint import pp (Pdb) pp stuff &lt;class '__main__.stuff'&gt; (Pdb) pp qwerty &lt;__main__.stuff object at 0x7fb8f4dbbe10&gt; BTW, in case it's relevant, here's the code I ran before breaking to try beeprint: 1 class stuff(object): 2 def __init__(self,x,y): 3 self.x = x 4 self.y = y 5 6 qwerty = stuff(4,5) 
&gt; .format(**locals()) O_o That works? That works! I might have to use it somewhere, just to scare the next guy to read it.
I manage one specific conda env which is the official python runtime for our department. All third party libs that we use are in there. If someone wants a new library, I add it with conda, sync it to the central share and people sync it to their python runtime folder on their local box. Our own python libs are loaded via central share, for people who don't have git / are not developers.
how about directly run it with scripts ? like this: from beeprint import pp class stuff(object): def __init__(self,x,y): self.x = x self.y = y qwerty = stuff(4,5) pp(stuff) pp(qwerty) and then: python script.py I also run it with python -m pdb script.py and both of them print as expectation: class(stuff), // &lt;--- ooohs, this is a bug instance(stuff): x: 4, y: 5 what not as expectation is, there is a bit of bug. I'll fix it.
You'll get more help at /r/learnpython. 
terrible
Alright, thanks man. New to python and some things I really like, however it's always difficult to learn a new system.
Central share, in my case is, a cifs/smb share. I have added external libs (not installable by conda) to this python runtime as well (bloomberg api libraries). People use jupyter from this "centrally managed, but locally installed" python as well. I have created a few scripts, to run a cmd or a jupyter from it as well, and these scripts add a custom pythonpath to find our own libs.
I am not a GIS developer, but just a python developer who had to dabble in a bit of GIS. Here is what I had to do: 1) I made a QGIS plugin that used k-means clustering in images to get approximate amount of farm land, and barren land. There were three clusters (dark green, light green and brown). 2) I made a geo-django website where people would make "boundaries" or selection using mouse and the software would output list of entities in the area such as poaching records, animal observations etc. 3) I wrote a route optimization software so people who would go to forests would find the optimal route to walk. In essence, this is a graph theory problem but it is interesting as it shows intersection between GIS and various other domains. 4) Little scripts to convert one data format to another (e.g. shape files to KML and geojson for displaying on websites etc) 4) Python was used a lot for ETL process. GIS data would be converted from one form to another. In addition, QGIS uses python. GDAL has python bindings. Google maps and OSM both have python api. Also read this: http://desktop.arcgis.com/en/analytics/python-in-arcgis/usgs-python.htm
that sounds complicated
I totally get that. I just know where to go to get help. This subreddit is more for language announcements and things of that nature. /r/learnpython is usually super helpful though if you post there. 
And that's why I disagree with the article in ignoring test categories! Testing Database accesses or any external service is something you should do in **integration tests**! That's it. No mocking required, no obscure substitution with a different RDBMS, no hustle to miss errors or possibilities to test IO. Also making more than one ``assert`` per test is a no go imho. Besides that the article is a pleasure to read!
The one thing on there that I'm super excited for is [PEP 523 - Adding a frame evaluation API to CPython](https://www.python.org/dev/peps/pep-0523/). Basically, opens the possibility of plug-and-play JIT extensions and faster debuggers.
hola == 'YES' is comparison, not assignment.
Sorry, it's fixed now. I made that comparison in the shell to see if it returned True (it did) and copied it like that by accident. I still have the issue when using the OR 
Well of course. Your boolean operation is returning the result of ('Y' or 'YES'). Try just: 'Y' or 'YES' And see what happens. Just for clarification, you might also try these: None or 'YES' 'YES' or None If you're still lost, come back and say so. 
Awesome, it's about time we got a new way to format strings!
Yip, totally agree. Looking forward to this one too.
&gt; Also making more than one assert per test is a no go imho. Most of the reasoning for this I see is that often tests that have multiple assertions can hide test failures behind other failures: x, y = 2, 8 assert x + y == 9 assert x * y == 15 Would only see the first failure. The downside is that it really can complicate your test layout, since not all tests easily can be split along those lines. I wrote a [pytest plugin](https://github.com/astraw38/pytest-assume) that can assist with this (forked really, but it's diverged quite a bit from the original). 
Julia also can statically resolve functions and aggressively inlines.
&gt; In 2011, at the first and last inaugural PyCodeConf, GitHub founder Chris Wanstrath (@defunkt), introduced me by asking me in front of various Python luminaries (Raymond Hettiger, Travis Oliphant, David Beasley, Jesse Noller, the young Kenneth Reitz) details about this... er... game. WOW, impressive list! Did Guido van Rossum and Brandon Rhodes stuck in the traffic at this time? ;) Mostly likely James Powell sat also in the crowd and planned his first pydata :D
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hear, hear. Best of luck.
could you explain more? 
You can use the Tk bindings bundled with python. People don't like it but it does the job for such use cases. I have used it to make a gui to a 2048 clone, you can have a look at the code here to get a glimpse: https://bitbucket.org/rndblnch/2048/src/ A good intro to tkinter can be found here: http://effbot.org/tkinterbook/tkinter-index.htm 
Is there anything *specific* that you don't understand? I mean, yeah, it's a pain because, honestly, how the hell uses `L` as a variable in Python (or any programming language, for that matter), but still, the question is too broad and there is too little information to say something meaningful. If you have a problem understanding Python itself, you can ask /r/learnpython. PS: Yeah, I tried to understand what's going on for at least 15 minutes and gave up, so I understand your frustration. Maybe another solution would be to understand what the author is trying to automatize (I see that's about A.I., but not sure about what methodology/algorithm/whatever they are using) so getting that in the first place would help to understand the whole code.
&gt; Index zero to four... but not including four? Yes thats exactly how slicing works. If you specify 1 index you get 1 letter of a string. If you specify range its from zero to specified number but no included. You can also specify negative numbers then you start from the end of a string. e.g. Justin[-1] == 'n' or Justin[-2:] == 'in' or [1:-1] == 'usti' You can read more https://docs.python.org/3/reference/expressions.html?highlight=slicing#grammar-token-slicing and you should use r/learnpython
The correct link is [https://pypi.python.org/pypi/pprintpp](https://pypi.python.org/pypi/pprintpp), and yeah, it appears to look exactly like beeprint and even has the same subheader as this thread ;) &gt; A drop-in replacement for pprint that's actually pretty
`pp` is a pdb command. You could try importing beeprint's `pp` as some other name.
i dont have too much of an issue with python, these functions are just confusing. here is the specifics. I will also, add greater context to the original question. you can read it to see what is going on better. **Function 1:** Ssue: What is H? I understand its coming from the input of L which is a list of itemsets purchased at a grocery store **Function 2:** BR1 is tripping me up a bit. Its using the BigRulelist created in Function 1. What is the br1.append doing there? **Function 3:** Function 3 Issue: This is coming from my previously mentioned issues. I dont know what H or freqset is. So, this whole thing is a mystery. 
If the author didn't package their code on Pypi, I probably wouldn't use it because it's not a distribution ready piece of software.
Love it! That's the one I am most excited about.
/r/learnpython
/r/learnpython
Added to the Python OOP Resource list https://github.com/metaperl/python-oop
Sweet. Does this work with iPython?
I should direct this type of questions to that sub? I'm already trying to learn Python (just starting, obviously due to my noob questions :) )
&gt; I mean, yeah, it's a pain because, honestly, how the hell uses L as a variable in Python (or any programming language, for that matter) I dunno, sometimes I'll initialize a new class as: L = mymodule.classname(some_args), because it's the only thing in a pretty large notebook with an uppercase (or single) letter in the entire namespace. You pretty much know exactly what it is, and it stands out. It's usually pandas related, so I just have too many iterations of df, *_data, and I get lazy. Plus I'm not shipping the code to other people usually or I'd care a bit more.
Yeah I've already been told like 5 times bro.
I'm looking forward to [PEP 487](https://www.python.org/dev/peps/pep-0487/). It removes unnecessary metaclasses (which were hard to combine) and simplifies a lot of code.
Oh, sorry, my bad! It was my first question so i wasn't aware and to be honest i didn't read the rules. I will now, and from now on i'll submit this kind of posts to /r/learnpython, thanks for the help, and again, sorry. Regards!
True but I favor small things over beasts like notebooks
Just use the %save magic function. You have to give line numbers, but it can also automatically convert magic function calls into IPython api calls, or not if you prefer. 
You could just copy and paste %history. One would probably want to edit it some anyways.
Can't you just use virtualenv or conda environments? What's your rationale for copying the source around? 
Yes, it does. :) In addition it removes all your mistakes (which raised exception) from the script as well.
You can start the script with pythonw.exe to hide the terminal when running. Having an icon in the systray or listening to keys is a different matter. For example, I use Scheduled tasks to Start pythonw.exe with the Argument "C:\Scripts\display.py" to show HW Stats on a 2004 LCD connected via USB
Short version: you can't. Longer version: you cannot.
I don't have one. I'm trying to figure out the best way to go about this.
http://timgolden.me.uk/python/win32_how_do_i/catch_system_wide_hotkeys.html Or if its just about hotkeys: Take a look at AutoIt or AutoHotkey
While it's not a direct Python solution, LaTeX might be something to look into. It is a typesetting tool that produces beautiful mathematical figures and would be pretty straightforward to script using Python, and you'll get a nice PDF out of it. I used LaTeX a lot in my undergrad, so feel free to let me know if you have any questions should you go this route. 
GIS Analyst for local govt here. I'm currently using Python and SQLite/SpatiaLite to develop a model (a series of scripts and database) to map city building permits and report on density analysis. It will answer questions like: * how is the city's development pattern changing? * in what areas is the zoning underutilized or being maxed out? * where can we expect future growth and redevelopment to occur? Finally, if we multiply new dwelling units by census/ACS median household size, can we accurately model population change for non-census years and ACS gaps? Then test the accuracy. 
You can only make Access to the Code "harder" - the step added would just be extracting the sourcecode with a Tool. This will only help for users that don't know how to fiddle with Code - at least for me that's good enough. Every real programmer can get the sources from our internal git while normal people only get a binary
i thought pyc is the answer, but it isn't. SA: [How can I prevent a client from seeing my code written in an interpreted language?](https://programmers.stackexchange.com/questions/66616/how-can-i-prevent-a-client-from-seeing-my-code-written-in-an-interpreted-languag) &gt;You can always compile all you files to byte code pyc. There are decompilers out there that can generate source code out of it but nothing serious. &gt;However that will just solve the ability to read the code of your program. To protect the only way is to license it as nightcracker said, because even if you compiled your code, to lets say machine code, if your work is not protected by a license, it can still be commercialized against your will. 
so? python has lots of excel packages/functionality..we can use that too!
Can't be *read* is one thing.. but can't the files in question be `chown $ADMIN.$ADMIN myscript;chmod 755 myscript` 'ed ? I would have thought that would at least required them to make a copy before they could *edit*.
The best but not ideal variant is to put sensitive part of your code into a Python-C binary module. But again it's not 100% reliable, and if a smart hacker wants your code, they will get it. 
Matplotlib can invoke glorious Latex math mode. 
Android does have a lot of extra security features. Figure out where on your Android device is not read-only and use that
No, that is Not a good programming style. This may change in the next Version and makes it difficult to port your program to another Operation System.
Just use a proper license.
Well, there are several reasons, but let me offer one reason why I worked to hide one of my scripts: it was a bot for a platform that hasn't been tainted by bots. The only way you can really make sure of this is if all the code is executed on your own system. Next to that, you have to start looking at unusual encryption models that may or may not be feasible depending on the application.
Or use bpython which has this built in. For development it's better than ipython anyway.
Mount it in a read only filesystem, then ;) (squashfs for example.) [ this message brought to you by the "use regexp to solve the problem, now you have *two* problems" department ;) ]
It is now. To be fair, even the US only joined the Berne convention in 1988, so one can be forgiven for writing documentation in the 1990s about how copyright may not actually be automatically applicable.
That page scared the sh out of me, by starting a video in background.
Setup.py will contain the code for setting up whatever is being set up and setup.cfg will hold the initial configuration settings (the values that the variables in setup.py will likely be initialised with)
What do you have against AutoHotKey? It sounds like it is exactly what you want. I'm not familiar with this, but this seems to be what you want if you intend for the program to be running in the background. https://www.autohotkey.com/docs/commands/ControlSend.htm
If you're interested in improving the story for distributing end user applications: - [Glyph's talk at Pycon](https://www.youtube.com/watch?v=5BqAeN-F9Qs) about it. - [Pynsist](http://pynsist.readthedocs.io/en/latest/) is my tool for making Windows installers for Python apps. I've tried to avoid the big issues I see with freeze tools like Pyinstaller. - [Briefcase](https://github.com/pybee/briefcase) is an in-development project under the *BeeWare* umbrella, aiming to do cross-platform application packaging.
/r/learnpython
How about circular driveways? https://www.reddit.com/r/ProgrammerHumor/comments/52lf77/why_programmers_hate_posting_on_online_forums/ I think the point was having a goal and trying to accomplish it with python, effectively learning by doing. A motive one should support and encourage imo. 
That doesn't really serve the same role as easily or as well * you can't pass it to many threads unless you pass it 'by reference' ```foo([x])``` or wrap it in another object * you get a race condition if you also want to return the counter value from the parallel threads
How about something easy like this? Just define your operations and the form you expect and you can generate a lot of questions. import random signs = ['+', '-', '/'] operation1_template = "{first}x {sign} {second} = {result}" print operation1_template.format(first=random.randint(1,20), sign=random.choice(signs), second=random.randint(1,20), result=random.randint(1,20)) 
Haha! Muggles! Sorry, I didn't contribute and made a stupid joke instead. 
If it runs on the user's computer, the most you can do is make it *harder* to get the code, not impossible. If making it harder is enough, [Nuitka](http://nuitka.net/pages/overview.html) is a decent option: it translates your Python code into C and compiles it. It would take a fair bit of determination to reverse engineer the executable into readable code.
Latex or MathML
/r/learnpython
No, it's definitely not -- don't do this unless you want to be bitten badly by threading issues. :-) If you comment out the `with self._lock:` line in my code and unindent the next two lines to remove the lock, then run the script (which runs the doctests), you'll see how badly it fails. # NOTE: locking commented-out for testing $ python atomic_counter.py ********************************************************************** File "/Users/bhoyt/Downloads/atomic_counter.py", line 29, in __main__.AtomicCounter Failed example: counter.value Expected: 400000 Got: 328247 ********************************************************************** 1 items had failures: 1 of 12 in __main__.AtomicCounter ***Test Failed*** 1 failures. The execution of the `__iadd__` (in-place add) method itself might be atomic in CPython, but then there are extra bytecodes to assign it back to `c`. In CPython, execution of a single bytecode instruction is atomic, but not multiple. You can see the bytecodes for this using `dis` (INPLACE_ADD and STORE_FAST in this example): &gt;&gt;&gt; def f(): ... c = 0 ... c += 3 ... &gt;&gt;&gt; import dis &gt;&gt;&gt; dis.dis(f) 2 0 LOAD_CONST 1 (0) 3 STORE_FAST 0 (c) 3 6 LOAD_FAST 0 (c) 9 LOAD_CONST 2 (3) 12 INPLACE_ADD 13 STORE_FAST 0 (c) 16 LOAD_CONST 0 (None) 19 RETURN_VALUE If another thread kicks and increments the counter just after the INPLACE_ADD executes on the first thread, the count will get messed up (that's what's happening in the failed doctest above).
If you have a virtualenv at `filepath` that you want to load, the following will do it. execfile(filepath, dict(__file__=activate_this)) 
Perhaps you could spend the a couple minutes on the Readme. It's more than a little off putting not to find at LEAST a reasonably detailed description of what the project does and why one would want to use it. Don't just throw them to a wiki whose own main page is ALSO mostly blank. That's way to many steps. People are gonna leave before you have even had a chance to describe your project. 
 $ python &lt;&lt;&lt; "import math; print math.sqrt(9)" 3.0 You can use a .pythonrc to avoid the "import math" 
Nice idea! But still too verbose for me :) Seems helps when all I want to do is some small code. But yes, &lt;&lt;&lt; helps :)
You might not know it, but you're describing [recursion](https://en.wikipedia.org/wiki/Recursion). You can do this with a naïve factorial implementation, like so: def factorial(n): if n &lt; 2: return 1 return n * factorial(n-1) then call: print(factorial(5)) which will call factorial(4), which will call factorial(3), etc.
Great! Good job. Just remember, this is not production code, it's just an example mostly drawn from how I remembered an old project.
I'll have to try myself, never built Apps for Mac, only Win or Linux.
Love this solution (on my Windows 10 PC, I had to place the shortcut into a folder I made: C:\Users\username\AppData\Roaming\Microsoft\Windows\Start Menu\\_hotkeys). Thanks
That's a lame reason.
On most distributions, highlighting text automatically copies it to a buffer, and you can middle click to paste it in a different window. It's an X11 feature, so you can enable it even if your distribution doesn't enable it out of the box. 
Maybe try xonsh as a replacement shell (assuming you are on Linux). A cross between bash and python. I haven't tried it yet but it's on my list of things. xon.sh for project home page
To understand recursion, you must first understand recursion.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
It's entirely possible to run a Python script in the background that catches all of the keyboard presses. The fact that this could be a security concern has nothing to do with Python at all. The OS has this functionality available; all a program has to do is make the appropriate system calls while running as a user with sufficient permissions. The same argument could be made for any program. "It's an OS-level task, therefore you need more than the average C++ program can do on its own." Yes, the OS is responsible for this sort of functionality; that's why you need to call the OS to perform it. The real reason you can't do this (easily) with Python's standard library is because it's a platform-specific feature. Most everything in Python's standard library is exposing standard C library functions that are part of the POSIX standard. In cases where the Windows API differs from POSIX, equivalents are typically provided. Globally capturing keyboard input isn't part of the POSIX standard and is quite OS-specific. But all things in the Windows API can be accessed by calling the appropriate functions of the DLLs directly. This can be done in Python itself using `ctypes` module from the standard library or can be done through a custom C extension. In fact, somebody already did all the work of wrapping the various Windows DLLs in `pywin32` module.
You are absolutely right, I've updated the README and wiki accordingly, thanks for the feedback :)
Search for "software licenses". I'm sure you'll find what you need.
not pertinent to my point.
Sympy can print latex formatting. It is very handy.
Django Framework official tutorial: https://docs.djangoproject.com/en/1.10/intro/tutorial01/ Flask tutorial: http://charlesleifer.com/blog/how-to-make-a-flask-blog-in-one-hour-or-less/ 
+1 for conda environments as being the easiest way to do this on Windows. Read up on how to use them - they even save space because they symlink libraries that are the same version. So if you have already download numpy 10.0.4 for another environment, it'll just share the install instead of making a copy.
[removed]
library for UI, you mean some CSS framework?
For Uis, generally you should stick to Qt in my opinion. Kivy is nice, but has non native ui widgets. Qt is all native widgets and the tooling and apis are top notch and mature. Qt designer plus either pyside or pyqt should do the trick
I've been experimenting with using jupyter notebooks while developing my understanding of the components of my intended projects. Hopefully I can turn those into defacto tests while I'm doing it.
r/learnpython
Don't underestimate the bullshit Windows allows you to do.
True, but most "modern" apps I have been on for the last 4 years are only about building APIs with some JS SPA frontend, and they are less about generating pages and forms anymore (which is part of the reason Django is overkill now), so if building APIs is built into Ray isn't that enough for writing these modern apps. In fact for personal projects I have gone all in and completely dropped Python for Go to build these APIs but I can't see that happening at work for a while, where we will continue to use Python.
Lol @ the down votes. Give me them allllll
Not yet.
Looks like PEP 520 needs to be rewritten to accommodate that note. I think that since dict's are now implemented as OrderedDict in Python, there is no need for definition order. If you want to know the definition order, just iterate over a class's `__dict__` and you'll get everything in order.
This is awesome!
Take your pick: - https://docs.python.org/3.5/extending/extending.html - http://cython.org/ - http://www.boost.org/doc/libs/1_61_0/libs/python/doc/html/tutorial/index.html - http://pybind11.readthedocs.io/en/latest/basics.html 
Try /r/learnpython. Also, post the full error message you're getting.
Sorry I'll post it in that subreddit!
Yepyep, started using mypy in my latest project. I like how it's even looser than gradual typing, how it allows me to separate the process of making a change from messing with the types; yet support generics and all sorts of advanced tricks when I need it. I very much prefer fixing typing errors to chasing runtime bugs. Example: https://github.com/codr4life/albaum/blob/master/src/albaum/binmap.py
Another flask one: http://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world
Sounds great, thanks
Went to the site and realized I already had an account. Over two year old account at this point. Got bored having to do basic stuff and never doing any really difficult puzzles. So instead I had a lot of fun finding ways to "cheat" to solve problems. Not solving it "creatively" or in a really obfuscated way. Like on [this](https://py.checkio.org/mission/brackets/) problem I solved it with import random if random.randint(0, 1): random.seed(729) else: random.seed(11345) def checkio(expression): return (False, True)[random.randint(0, 1)] 
Indeed. But I fiind myself relying a lot on the quoted types which I find a little weird for now. However, I love the fact pycharm now warns me when I'm not using the righ type.
Your result:159.00000000000003 Right answer:159 "The result should be given in degrees with precision ±0.1" 
I know that. However, the point is that an object's `__dict__` will be ordered now. Read the note at the top of PEP 520. Other Python implementations will need to ensure that iterating `__dict__` is ordered according to definition order.
All the code you need for the median one is: from statistics import median 
I'm always surprised at how the code quality of FOSS, is usually much better than the proprietary software I work on.
mutation testing as in fuzz testing? I've heard of sulley or Peach -- although that was a while ago
Why is it a bug? The [itertools docs](https://docs.python.org/3.5/library/itertools.html) don't say anything about thread safety (in fact, they sort of imply they're not with the equivalent Python code snippets wouldn't be thread safe). See also this [StackOverflow answer](http://stackoverflow.com/a/7083576/68707), which I think is correct.
Can you do a quick compare-and-contrast between enforce.py and [mypy](http://mypy-lang.org/)? The most obvious difference I can see is that mypy is static while enforce.py does its checking at runtime. What other differences are there in the two approaches?
Thanks for the reply! I briefly looked at pytest but missed parametrizing part of it as it looks like what I'm trying to do. The solution I found in JAVA w/ TestNG was [this](http://toolsqa.com/selenium-webdriver/testng-multi-browser-cross-browser/) so I was hoping python had a similar solution as well.
+1 for Haskell. Or Scala.
Hey thanks! I actually went ahead and used PuTTy instead through the command prompt. (I had thought it was only a GUI application and couldn't be used in the terminal) But I will use this for future use :) 
It appears that [the issue](https://bugs.python.org/issue24254) has been re-opened and there's a lively discussion taking place on the [mailing list](https://mail.python.org/pipermail/python-dev/2016-September/146358.html). As far as I can tell, they're continuing with removing \_\_definition\_order__ though I'm a little fuzzy on whether \_\_dict__s will become OrderedDicts or not (especially around non-CPython implementations).
&gt;Is this just part of the design philosophy? Yes. And I think it depends where you're coming from. Disclaimer: I'm not much of a coder, but what I have learned I've learned with Python. I find the standard '{blah.dothis();}' to be cumbersome and ugly in comparison, while whitespace feels natural. &gt; you can mess up your program by having one too many spaces in front of some line. Much like you can mess up your program in another language by missing a curly brace or semicolon. You just get used to it. &gt;Different text editors can put different white space for tabs [Follow PEP 8 and just use spaces](http://legacy.python.org/dev/peps/pep-0008/#tabs-or-spaces) 
One of the main principles behind the language since the beginning has been readability (something like "code is read way more than it is ever written"), so it's a conscious decision to better enable that ability. Typically speaking, people indent their code between the curly braces, whether automatically or manually. They do this so they can visually distinguish the pieces of code. All Python does here is remove the need for braces and encourage consistent styling.
What version of Python are you using? I think aiohttp has an example of doing exactly what you want if you're using Python 3.
&gt; Proxmox Web UI If you mean menu, buttons, panels etc in code editor, than check out ExtJS. 
It's not a bug, Python 3 changed to [bankers rounding](https://en.wikipedia.org/wiki/Rounding#Round_half_to_even). It's better in theory than rounding up at `.5` which introduces bias.
Sure, no problem. `replace` is a method that you call on a string variable. It takes two arguments: the first is what to replace, the second is what to replace it with. It returns a new string with the replacement made. For example: &gt;&gt;&gt; x = 'abcde' &gt;&gt;&gt; x = x.replace('abc', '123') &gt;&gt;&gt; x '123de' Using an empty string (`''`) as the second argument means you'd be replacing the first part with nothing, so essentially deleting part of the string: &gt;&gt;&gt; x = 'abcde' &gt;&gt;&gt; x = x.replace('abc', '') &gt;&gt;&gt; x 'de' You could also accomplish similar things using something called "slicing". Slicing selects parts of a string based on the position/index within the string rather than the contents. For example: &gt;&gt;&gt; x = 'abcde' &gt;&gt;&gt; x[:3] 'abc' &gt;&gt;&gt; x[3:] 'de' &gt;&gt;&gt; x[0] 'a' 
Yes, i've been using them for 2 years using Python3.4 and mypy. Mypy has been getting considerably better during that time even if it still fails on some valid python programs. Its helped me catch a lot of bugs and save a lot of time as a complement to tests since real deployment of this product takes some time. The biggest win though has been the increased ease of refactoring.
I'm using them for all my py3 stuff. Helps me understand wtf I was thinking if I come back to the code a few weeks later and makes me realise bad API design faster.
I don't usually use type annotations, but there have been a few tricky modules where adding type hints really helped find some bugs (along with Hypothesis for test-case generation). Usually it just looks noisy though :(
Nah - I switched to Scala. Joking aside - this is a great feature but it only makes sense if you use it alongside a decent IDE like PyCharm. This can use the type-hints to make useful inferences about what functions accept and return. But if you really value knowing what types of stuff your functions are using then Scala is a python-like language that already solves a bunch of these problems in a slightly better way. 
It is still within the tolerance
No, i tried it but it led to circular imports all over the place and solving the problem was either too much work or meant the lines became way too long. 
No and, till now, I'm not planning to start using them. Nice feature, could be useful in some very specific use cases, but in last 13 years of writing Python code I've got no one single serious trouble due to the lack of typing. Just my experience. 
Have a coworker take the same C / Javascript / whatever (your favourite brace-using language) source file - one that's neatly and properly formatted according to your organization's conventions and/or language community best practices - and process it to remove all the brace characters; then process it separately to leave those in but remove line-leading whitespace; and email both results to you. Then tell me with a straight face that the whitespace-omitted version is easier for you to make sense of than the brace-omitted version. Good luck.
This is pretty cool! 
OMG :) This is awesome Is this solutions actually published? &gt; Got bored having to do basic stuff and never doing any really difficult puzzles I get more excited not only by solving difficult puzzles but also by seeing solutions of others users. Creative solutions like one you have shared!
https://dev.twitter.com/rest/reference/get/statuses/user_timeline
Yes, but I moved to Python after years of using strongly-typed languages. So it just feels more comfortable to me.
Yup. I'm a pretty big fan of Pycharm and use it for my development. Since it respects pep3107 annotations I actually use it quite a bit, especially for code that returns custom objects. That saves a lot of overhead from a editor perspective as the introspections allow for auto completion very easily.
Isn't it 3.5 which is already in use?
Short anwser: The last one. 2.7 only became LTS because 3 was backwards incompatible and conversion was slow. Within version 3.X releases there should be no breaking changes afaik, so you always want to be at the latest version because it will contain all the bugfixes and maybe some new features you might not use yet, but libraries you do use might be faster because of it.
that's not how it works. It's like saying that given that we have newer versions of Windows, we are dropping support for XP/7 in a year. Would these versions be considered LTS? Is staying so far behind the curve desirable at all? EOL date in case of a programming language is bad news. It's literally a countdown to obsolescence. It means it gets relegated to legacy support, which means technical debt by default. Nobody in his right mind wants to deal with technical debt. Python3 is where the vast majority of effort is.
Here ya go. This will do 150 at once, and you cant change it to do more but expect diminishing returns depending on your computer's capabilities. Also beware of being banned over a suspected DDOS attack. I probably wouldn't recommend doing 150 requests at once but that's your call. import requests from multiprocessing.dummy import Pool url = 'https://www.something.com/' def req_split(r): #requests.head is much faster than requests.get if your intention is only to get the status code req = requests.head(url+str(r)) if req.status_code == 200: temp = r #return the url string if the server report OK else: temp = 0 return temp data = range(0,5000) with Pool(150) as p: pm = p.imap_unordered(req_split,data) pm = [i for i in pm if i] 
Never skip a minor version bump, test and keep up to date. The removal is as you point out well documented (and went through deprecation) and it's often documented what the new correct way is. If you are Dutch it was of course already obvious way before ;-)
virtualenv lets you use a different python binary with the p option, however that python binary still needs to be maintained and patched. Realistically if you're keeping up with security patches (which you should be) that means you're going to stick with the binaries available from the distro maintainer or a trusted source like IUS or the EPEL. You can build an automatic process to maintain this for you (distros almost have to have this just for sanity sake) but from an ops perspective you better have a good reason to pick up that much extra overhead if you're not RedHat, Ubuntu, or the Debian project.
Microsoft said that about Windows XP and then Windows 7 ended up in the same situation. I suspect 10 will be the same way. People use LTS/distro maintained versions of languages/distros/operating systems/whatever because no one wants to deal with the maintainer breaking their business applications with a minor point release.
This version improves on the Jedi integration with better Python code navigation and code completion. It also improves on the in-built Python scripting and in-editor Python code validation. **NOTE:** Zeus is shareware and runs natively on the Windows. *Jussi Jumppanen* *Author: Zeus IDE*
&gt; I don't think so - do people really use the python that comes installed on their distro? Yes, all the time.
Yes, it will break code, because people wrote the apps wrong. If people have code break due to dictionary iteration order (which should always be assumed is unknown), then they wrote bad code. Time to pay the piper. You get in trouble when you play with internals that are not language definitions, just implementations. Also in the future, if you want an OrderedDict you use an OrderedDict. If you are relying on a normal dict to be ordered, you are writing garbage, dumb, non-portable code in 3.6. I see too many people talking about not using OrderedDicts anymore. 3.8 might make the ordering go away for another optimization. 
Sounds like you have never managed a large data center and was responsible for the stability.
Well, mypy is static, enforce.py is runtime. It may catch something that can be known only in runtime. (For example, due to user input or a remote call to the procedure) Mypy works best when everything is annotated. Enforce.py works best in barely annotated code bases. It makes it easy to see if there are cases when either some functions start sending it something unexpected or it starts returning something unexpected. Just annotate a function, apply runtime type checking, enable it and run the tests.
Following a deprecation policy isn't the same as completely breaking compatibility. Though a more glaring is the change of `__aiter__` from 3.5.1 to 3.5.2. It went from being a coroutine itself (`async def __aiter__`) to being a regular method (`def __aiter__`) 
&gt; however that python binary still needs to be maintained and patched Just like every library you would use on any commercial software project. Even if you use the system python, any other libs you install from pypi will need to be maintained and updated regardless of what your distro maintainer is doing. Why do you consider it such a big hassle to update to a newer version of python in your virtualenv?
Asyncio stuff has been explicitly marked as not covered by the usual deprecation policy. IIRC there was a thread on the mailing list to lift that provision in 3.6.
Why would I want another piece of work on my team when the distro can do it for me? In regulatory land that's what you pay Red Hat to do in RHEL (I've worked in regulatory land for years so I'm biased heavily toward it). Part of it is CYA, a big chunk of HIPAA/PCI/Graham-Leech-Bliley/etc is maintaining security patch levels. This doesn't help you in the real world against zero days or distro fuck ups but it does help you against your own people or processes failing. When something happens, as it always does, I want the confidence to be able to say 'We are at the latest patch level the distro provides.' Boils down to risk transference/avoidance, like buying insurance, contracting something risky/complex enough to need a specialized actor to a vendor to handle, or just not doing something with inherent risk in the first place. The other issue I have with maintaining custom builds of software that's available from a distro is once you do this for one thing, you get pressure to start doing it for others. No I will not spend DevOps story points to package your emacs nightly. This is one of the endless battles between operations and development, you will never see an actual resolution to it. It's not to say you can't build and maintain python yourself, but there are real reasons why people choose to go the route of LTS and then eat the pain of updating every few years. If you do it right you can automate building and unit testing your software on more up to date versions of python in your CI environment alongside your production versions and log tickets in the backlog to correct issues that arise. This is one thing Ubuntu actually makes easy since they have separate LTS and rolling release tracks (updating OS every few years generates similar issues). You may not get full functional testing but it's a lot cheaper than dealing with, 'the security patch broke our core business application and now everything's on fire.'
I'd reduce the 150 simultaneous requests down to 40-45 or so. Apache's often-used mod_evasive module's default limit of concurrent requests before triggering action from the module (like banning the source IP address) is 50 for example.
If you are about to ask a question, please consider r/learnpython. 
To clarify, mypy itself can only be _run_ using Python 3.3+, but can be used to analyze either Python 2 or Python 3 code.
[TestNG](http://testng.org/doc/index.html) is just a code testing framework, especially with unit testing in mind. Selenium is the framework for testing HTML Frontends. Of course you can couple them, but the same is true for JUnit or any other test framework...
In 3.6 (currently in beta, release expected around March 2017), dicts will maintain insertion order as part of a revamp of the internals which will save memory. But you're not supposed to rely on that, as it's an implementation detail. So technically speaking nothing has changed; if you want a dict that maintains order you must still use `collections.OrderedDict` even in 3.6, it's just that that will be an alias for `dict` and won't carry any extra performance overhead. 
Circular imports where a problem to me too :(
There are large orgs that are frequently refactoring in their infrastructure - Google is a good example.
Python in general [follows](https://mail.python.org/pipermail/tutor/2003-October/025932.html) the "we're all adults" philosophy: people are allowed to do (potentially) stupid things, and if it blows up on them, well, that's their own fault. (There's another humorous take on that [here](https://steve-yegge.blogspot.com/2010/07/wikileaks-to-leak-5000-open-source-java.html)). I'd argue that you can't get away from this, as users can always screw things up if they try hard enough, and that if you're having problems with people repeatedly sabotaging your stuff, you should look for a policy solution, not a technical one; it's pretty common for companies to say they don't provide support if you've modified their stuff or are using it in an unsupported way.
That has not been my experience, especially in heavily regulated or government environments. Redhat has also never rolled a release on me that breaks basic functionality intentionally, security patches are backported and fixes for major broken issues are backported but the overall language version stays functionally the same throughout the cycle.
Thanks! I'll take a look at the documentation!
Yea I'm not saying you go from 2 to 3. That's asking for trouble. 
The point of LTS is not having to alter your environment for as long as LTS is supported. Changing your codebase because functions you used are no longer there does count as altering your environment.
It's never that easy. Even if this was not regulatory deployment you would want your deployment as immutable as possible. If you tested against software versions X, Y and Z you will at the very least freeze those as requirements for every deployment until you get to the next testing/certification pass. You don't want your software to fail because someone you'll never meet accidentally pushed a broken build of a fifth level requirement. Some companies build docker images the very moment a given commit is tested to make sure all environments where it's going to be deployed will be running exactly the same code. You don't just randomly swap Python versions at deployment time. And even if you could, there are applications that don't get redeployed every other week. Some software is running in maintenance mode where the company responsible for the SLA is only supposed to touch anything if security is at stake (and will certainly not get paid extra for upgrading Python to the "latest and greatest").
wxPython is a nice, mature, multi platform alternative. Can't vouch for the GUI builder (wxGlade), I prefer coding my layouts; but it's been around for quite a while and is still actively developed. The new Phoenix version is working fine for me on Python3 so far. https://wxpython.org/ http://wxglade.sourceforge.net/ Good luck!
Python2 is where the majority of people is though.
Basically, each package following the DBAPI 2.0 specification declares what type of parameter binding style it follows among the following: qmark (?), numeric (:1), named (:name), format (%s) or pyformat(%(name)s). While this brings flexibility, it makes having an ORM in Python database agnostic hard, especially when you use raw queries. Orator solves this by allowing the use of the qmark parameter binding for every backend supported (psycopg2, mysqlclient, sqlite3).
You can use a toolkit such as GTK+, you'll can have a script running in the background, register keyboard shortcuts and even add an icon in the system tray and add a GUI to configure your shortcuts. Edit: you can have a look at Screenkey (https://github.com/wavexx/screenkey) , it uses the old pygtk instead of PyGObject but it could be a good starting point.
Exactly what I was looking for! Thanks guys.
nice read, i wish there was more examples though. 
A good read, but beware that the post is over 2 years old.
&gt; Cython Did you mean CPython?
That's true for small companies, but not large ones that have the manpower to vendorize and maintain many of their dependencies.
Not all of them do. Usually the cost of switching to a new version is not justifiable over the possible risk of security concerns (I know as a developer this sounds stupid, but business owners really do make this decision). 
Nope.
Learn git/github. That's most of what you need to know. Also, be nice, write good messages, make small enough changes that someone can review the changes easily, and add small test cases. I've been working with git for 2 years. I still can't issues a pull request, but I can merge like a champ. That's sort of the advantage of running a project.
This is why people still use Fortran 77, when Fortran 90 is a superior language. And, although there are plenty of people employed using COBOL, and they make decent salaries, no one gets their new project approved using COBOL. The problem is that you're relegating yourself to maintenance programming for the rest of your career. Which is fine, if that's what you want. 
Ah, good old ANSI colour codes. That reminds me of my BBS days. I'll admit, this is a pretty clean solution - it's basically just an enum with named colours. But to take it any further you'd need to use curses or something. https://docs.python.org/3/howto/curses.html
Not sure how common any other use-cases are, but one thing I've seen that I liked was using it to give type information in a different way in a command system for game servers. You would do something like: @command("give") def give_cmd(player: player_filter, item: item_filter): player.give_item(item) return CommandResult.BLOCK Which would call `player_filter` and `item_filter` to parse the arguments given, and turn them into something the command can actually use. It saves a bunch of boilerplate of checking for valid input, giving error messages, and converting to what you actually need. Edit: Of course, right after I post I remember the name of it: [SourcePython](http://wiki.sourcepython.com/developing/module_tutorials/commands.html).
That's a pretty moot point, tons of new tools are developed in Python2, all the libs are maintained, and Python2 is a perfectly valid language for this time &amp; age.
You can have a serverside entirely in django, right? Just create APIs and consume them from the client side using your fav JS framework?
Google is not a good example for pretty much anything outside of Google. They're their own beast and can throw infinite money at any problem. They can do pretty much anything, say it's gospel, and 10s of thousands of fanboys will sing their praises even if what they're describing would only work in their environment. That does not exist outside of Google.
Just so no one gets the wrong idea, the program will still run just fine. It's the static type checker that fails, and you can opt out at any time by adding a '# type: ignore' comment to any problematic values.
Why do you want to be a like a sheep? Aim high. Tech giants got where they were on the strength of their engineering and their williingness to break the standard models. Obviously can't help if restricted by regulatory rules, but that a different problem entirely.
https://dev.to/tra/expert-resum-driven-development
Having thought about it more, SQLite takes datetimes in "YYYY-DD-MM hh:mm:ss" format, but your dates seem to be variable width (not leading zero padded), so you have some trouble. However, this is quite easy to do in python, and you can install your own native functions (i.e. written in python) into SQLite, and you can then use them in queries and updates.
I have often treated what the author calls "external services" as just any other model, building the data fetching (and persistence) regardless if it's a sql relational db, a json endpoint, a docstore, a flat file, etc. It hasn't yielded any appreciable problems treating it this way. The relational db is just any other "external service".
Scala is awesome but doesn't have much to offer as a scientific language the last time I checked :'(
I'm a bit puzzled by your last comment when compared to the example of using annotations for filters. If I say that `def foo (x: filter_x)` means to run filter_x on x before calling foo, isn't that incompatible with mypy? Mypy is going to think that means x should be of type filter_x which doesn't make sense because filter_x is a function not a type... similarly the programs that use these filters will instead be calling `int` and other type constructors on args when they see type annotations. These seem to be fundamentally incompatible.
Will it be an alias for dict or a featureless subclass? If it's a subclass, the interface remains the same. If it's just another name for `dict`, isn't that a subtle change in the interface?
Why are you using multiprocessing for an IO bound workload? Threads are just fine for anything that is mostly waiting for IO and threads have much less overhead than processes.
Software projects have an official support lifetime, in which the person or people who make the software provide official support (bugfixes, security, etc.) for a particular version for a particular period of time. Some projects also declare certain versions to be *long-term supported*, or "LTS". An LTS version has, as the name implies, a significantly longer support period. So, for example, a project might have a default policy of supporting each of its releases for one year, but declare LTS releases to receive three years of support. The normal support life of a version of Python -- in terms of what the core CPython/python.org team will provide -- is typically a couple of years. Python 2.7, however, received a one-time extended support period, since it serves as the transitional release to help users move to Python 3.x. Python 2.7 will end up receiving official support from the core Python team for roughly ten years total (Python 2.7.0 was released in 2010; Python 2.7 support will end in 2020). As far as I am aware, no plans exist to extend this further, or to have any Python 3.x release ever receive such a long extended support lifetime. The 2-to-3 transition, which only happened once, was the sole reason why 2.7 received such a long support life. (of course, operating-system vendors often will provide paid support for a version of Python long after its official support lifetime has ended; Red Hat will happily take your money and continue providing bug and security fixes for Python 2.7 well after the official support from the Python team ends, for example)
In less than four years, Python 2.7 stops receiving any type of official bugfix support. When your options are to crash/get hacked, or pay Red Hat through the nose for third-party support, or just finally write `print()` instead of `print`, what will you do?
There's lots of benefits to be gained from not doing template rendering for every page. You can build your frontend using whatever tech stack the front end developers want to use and not have to worry about collisions with whatever templating system you're using (for example Jinja2 and Angular 1 collide). You can also do stuff like stuff your entire frontend behind a CDN. There's cons as well, though. Like, you're backend has to be developed with this in mind so everything is an API. Of course, this is complete overkill sometimes. And Javascript fatigue is a real thing too. 
I get it. I can agree that your way isn't bad. I, personally, prefer to divide things by domains of control, though, so I would lean towards external services being their own "thing" since they are often out of your control and may require their own patches. But that's just me, your way is valid too.
&gt; the front end developers Am I the only one that has to be both? Plus engineer. And IT? Making it easier means that one person can do both ends.
What you would like to do can actually be achieved quite easily using the win32 library or even better pyHook. PyHook lets you easily bind the keyboard events and run a callback when keys are pressed. I wrote a small Python key logger using this method. Also there is an example in the book "Black Hat Python".. Cheers
I use [seaborn](https://stanford.edu/~mwaskom/software/seaborn/) to handle this when using one of my [dark themes](https://github.com/dunovank/jupyter-themes) (sorry for the shameless plug). If you don't already have seaborn you can install seaborn with pip pip install seaborn Then put the following lines in your ~/.ipython/profile_default/startup/startup.ipy file, Jupyter will execute them every time you open a notebook (context, style, and font_scale arguments are optional): import seaborn as sns sns.set(context='paper', style='darkgrid', rc={'figure.facecolor':'white'}, font_scale=1.2) 
You can add variables together in Python - Google it.
Pleasant read for a beginning developer. I had been thinking that there was no clean way to create a strictly MVC structure without one pillar becoming a monolith. It's nice to be vindicated by someone with more experience.
I'm glad to see the Python 3.x situation calming down, but there are still a ton of commercial systems that use Python 2.7 backends. As someone who's been using the language in earnest for a few months now (and have tried for years), my current analysis... * If you're supporting commercial apps on Windows: especially science or video production; you're stuck with 2.7 right now. * If you're an IT person writing scripts for your environment, you probably have to maintain both 2.7 + 3.x; depending which version of Linux you're using for the latter. * If you're writing new software: please, please write for 3.x.
This is a pretty dismissive blog post on two of the more popular web frameworks from python and focusing almost entirely on a 3rd but only through the eyes of python's best ORM. The reality is that specific tools matters far less at scale. While I don't really know what their experience is, there's sort of five phases of developer growth. 1. I can make a toy app and I follow all of the rules. 2. I can see where the limits are on the original rules and I can make a small app. 3. I realize that a framework is just a set of rules and I sometimes break them. I can make a large app. 4. I realize that frameworks are great provided that I can make small services with them and I can use any framework I choose. Additionally, I tend to break the rules in extraordinary ways. 5. I create frameworks and make my own rules. The author of this blog is still learning... 
&gt; If I say that def foo (x: filter_x) means to run filter_x on x before calling foo, isn't that incompatible with mypy? So don't use mypy or ignore that message when using mypy. Write a plugin for your favorite IDE that treats it differently. That was the intention. It's just a note. PEP 484 expanded the syntax to be more useful with a specific type of annotation because people were using it for typing and that's about it. It didn't remove anything. It really didn't change anything, except say that it defined a few new names that should be reserved for things like mypy. People used to write `true = 1` at the top of their program. Other people wrote `True = 1`. Still other people wrote `TRUE = 1`. PEP 285 defined the True/False variables. Sure it broke some code, but no biggie. Python 2.7 removed `float('1.234D+05')` and didn't even write a PEP.
I'm aware that django works api only, but it seems like there's a lot of wasted overhead in using it for that purpose. Setup and config and management are really heavy with django. I love django, use it for some massive, monolithic projects, but whenever I've tried react with it, it seems like a lot of startup work before things are in place. Maybe there are some samples of base project templates when looking to take these routes?
Yeah, this is definitely not what I'm talking about. Async and dynamic updating are MUCH cleaner in react than using pure django-template based async processes. 
Yup, one-man team here.
You're beautiful too :) 
So here is what always helped me(also fairly new to programming). 1. Think what your program/script wants to accomplish, 2.How can you repeat/sectionalize your program (functions/classes/modules). Then when you get into the specifics, "What does this line of code do" so let's say you add two numbers, print what that returns. Or try printing the type of a variable it returns etc
To be a bit more specific, datetime.strptime can parse the type of date string you have described above and to get the most out of sqlite dates you should read the beginning of http://pythoncentral.io/advanced-sqlite-usage-in-python.
I was trained in C++ during 5+ semesters in college. Recently stumbled upon Python, and my main issues are just the 2 -&gt; 3 compatibility things along with installing the various modules. The variety of modules to perform common tasks is incredible. Parse a CSV? There's a module for that! Connect to a MS SQL Server DB, there's a module for that. Most common tasks have a module to simplify the process. Python isn't perfect, but it's pretty damn fine. edit: But it didn't get that way on its own. The thanks go out to all those coders who created the modules we all take for granted. Thank you!!!!
This is a WHOLE lot of opinion, take with a bucket of salt.
Totally agree, I'm creating an excel report based on a Sql dB right now. The different modules are amazingly easy to integrate. Mind you pip isn't working for some reason on my new comp, but easy_install is here to save the day
Honestly, I don't know what you're saying, but I know what you mean
You mean y = ax^2 + bx + c? What's the problem with it? What do you want to accomplish? 
I wouldn't say you have to create frameworks to be considered a great dev. I'd stop at 4.
I hardly ever use Django for serving Web frontends. I've built backends for sms and ios APIs, along with APIs for Angular apps that don't even need to get on the same server. 
It's difficult to do in a way that makes sense to a framework. You get a lot of benefit from splitting the frontend from the backend. They can live in different repos, have different build processes, and utilize different infrastructure to scale independently. Plus you build a better, more robust API as you're consuming it yourself and can see where all the real world faults are.
&gt; but it seems like there's a lot of wasted overhead in using it for that purpose Pray tell... what is the actual overhead? &gt; Setup and config and management I'm not really sure I agree. But I guess it's subjective. startproject, install DRF, start app, get to coding.
How? What isn't simple about setting up a django service? (Compared to any other python service with a db) 
&gt; There's lots of benefits to be gained from not doing template rendering for every page. Yah... I didn't say no. But what does that have to do with using Django? Django doen't preclude AngularJS/React.
I don't really get this - I've toyed with flask and built heavy in Django. One isn't particularly easier to setup than they other 
So you want to program the quadratic function but there's that +/- piece right? So take in a, b, and c as parameters. Now solve for the discriminant (part under the square root) first and store that in a new variable. Do the rest of the problem once adding the discriminant and store the result in a variable. Then do the rest of the problem subtracting the discriminant, and store that in another variable. Normally functions should not return two values, so if you really want this to act like a function, you'll probably want to return a tuple containing the two values. I've got a working solution I can show you, but try to work it out yourself first.
I do it all too. Front, back, side, dev ops, etc. 
Because the option of Flask AND Django forces you to use both? That's nice that *you're* free to build things but what of us that don't want to build things?
Ooh, can I see your code? I want to do something similar!
You're not wrong but that's true for most other languages too.
`from __future__ import braces`
I've been entertaining the thought of using it for request-based templates defaults = {'json':templates.jsonify, 'xml':templates.xmlify} @app.route('/page/{}') def posts(page_id:int) -&gt; {**defaults, 'html': templates.page}: return Posts.paginate(page_id, per_page=15) if a webbrowser hits `host/page/1`, its `Accept` header will request `text/html`, and get the `template.page` view for that controller. if its curl or xmlblahblah from javascript, they can request (probably) `whatever/json` and get the `templates.jsonify` view instead of course this could be done as a decorator, but then what can't? 
Very few languages have such a large library of prebaked ready to install with no effort modules. Your close runners up that I'm aware of are node, ruby and perl, none of which have anywhere close to the same breadth of modules by themselves that python does.
Just curious, what's the audio/text? &gt; I basically just want to align speech to existing text. Does this mean the speech is already transcribed, and you want markers in the audio corresponding to the transcription?
&gt; Mind you pip isn't working for some reason on my new comp, but easy_install is here to save the day *twitch*. Try `python3 -m pip`.
I love python, just the tab thing still annoys me
And yet my python2 code is just happy with print "Hello, world" print("Goodnight, Moon") with out `__future__` The swears directed at myself when I saw that once. 
Ah, that was definitely forgotten in the list. Again though, I don't think it exceeds the composite breadth of available python modules (though it's probably the closest?). Certainly less of a joy to program in.... it reminds me of if you took c++ and tried to make it better but you were stuck believing every language construct could only be improved with more syntax boilerplate
I would rephrase 5 as: Know the pros and cons of the popular frameworks, or have the maturity to evaluate new ones objectively as they come by, without getting distracted by shiny new things, and have the conviction to pick the right tools for a job.
So reference this page...http://scn.sap.com/docs/DOC-57020 the other major step would be figuring out how to open and connect with sap. That is something that I'll leave to you because it might depend on how you access it. Start with figuring out how to open different desktop apps, then maybe try to access websites with python. Just depends on how your company has SAP set up. Again I'm new to this so to me it's 80% research, 15% trial and a lot of error, and 5% luck ;)
Ahh, cheers mate! But aren't we all beautiful in some weird way
I haven't had a need to do something like that in my scripting. I'm still new so I feel a lot of them are pretty basic and hacky. But that feeling when they work is amazing.
This makes me think it needs to be refactored somehow. 
Is there a Python interpreter for Android? 
&gt; Why would anybody want to learn all the new quirks and differences of Python3 when Python2 is doing its job perfectly fine. because python3 is not that different and has in fact way fewer such quirks? Print is not a statement for god knows what reason, you can forget about range/xrange, zip/izip and such horseshit because everything in the stdlib runs on iterators. You can forget about input/raw_input. Unicode becomes sane which if you are not an entitled anglophone is huge, because ain't nobody got time for fucking around with UnicodeEncodeDecodeErrors. Never again. If you are half decent in py2 the differences can be mastered in an hour, which buys you access to cool stuff that will never make it to py2.
maybe this will convince you &gt;&gt;&gt; L = 1, 2, 3 &gt;&gt;&gt; print(*L, sep='+', end='xxx\n') 1+2+3xxx py2 &gt;&gt;&gt; print *L File "&lt;stdin&gt;", line 1 print *L ^ SyntaxError: invalid syntax 
I got fairly good results with IBM Watson's speech-to-text API, you might want to try that.
&gt; If you're writing new software: please, please write for 3.x. No. Write it for both. It's not hard and your software will be usable by more people. Ever have to dust off a Python 2.3 program that uses something ancient like Qt3? It's annoying to backport a Python 2.7/3.5 package, but it's not really that hard because hopefully you're porting libraries that were well done in the first place. How many people really write fancy things like coroutines? Most of it is things like remove list comprehension and with statements.
yeah i noticed that soon after. my apologies! :D
`for _ in post` would fix it.
I'm still using %s and %d in my print statements here. Cut me some slack. ;)
&gt; Google’s acquisition of Apigee emphasises how important API’s are in today’s architecture of applications. I kind of stopped reading there.
Try haskell.
Nah, we don't need C++ to die, we need C++ to pull the Python 3 "we're going to change a lot to modernize the language" thing.
It is, indeed, beautiful and the community is beautiful too!
I would argue that you should likely have both. Some things lend themselves to simple unit testing. Other things require integration tests. At work we have both. Unfortunately there is much less discussion online about good integration testing practices because it's more complicated and much more specific than unit testing. Do you have any good resources for reading up on good integration testing practices?
Indeed it does.
Right, but there isn't the wasted overhead as you say. 
change your dates to YYYY-MM-DD
I believe those two games have different audience because games are using different motivation
I see, what your indirect answer is. This is not possible because of syntax-candy magic swooshy use cases it enables. It is possible because it would be too clumsy for interpreter to check for recursion each time container operation is performed. Did I understand you correctly?
I didn't know that it had to be compiled differently. I thought maybe *all* Python functions (including ones with no yield statements anywhere) supported pause and resuming, it just never kicked in unless it hit a yield.
Right. There are cases where recursive objects present a problem (e.g. JSON serialization, pretty-printing), and in those cases there will usually be an explicit check. You can see this in fact in your REPL output, where the `__str__()` method of the list had to detect recursion and print `...` instead of an infinite loop. 
Wow, thank you for in-depth answer. Have a great day.
Probably obvious, but the behavior I think you expected can be achieved by wrapping the generator in an outer function that performs the assertion def foo(n): assert n&gt;=0 def bar(n): for index in range(n): yield index return bar(n)
A few reasons here: 1. To get around the GIL 2. The threads/processes have no reason to talk to each other 3. It's a script and I'd sacrifice memory overhead for better completion time
Py2 &gt;&gt;&gt; L = 1,2,3 &gt;&gt;&gt; print "%sxxx\n" % ('+'.join(str(l) for l in L)) 1+2+3xxx A bit more verbose, perhaps, but perfectly possible. 
100,000 hours is 11.5 years of audio. Even if your system can process 100 seconds in one wall second, you are looking at quite some time. You could consider [Amazon snowball] (https://aws.amazon.com/importexport/) they ship you hard drives in a suit case, you load your data, return to Amazon, and they push it into S3. Have you tried Sphinx 4? Possible the original software is faster than pocketsphinx, which has different design goals. 
&gt; I would argue that you should likely have both. Some things lend themselves to simple unit testing. Other things require integration tests. At work we have both. I haven't said anything else, have I? &gt; Unfortunately there is much less discussion online about good integration testing practices because it's more complicated and much more specific than unit testing. Do you have any good resources for reading up on good integration testing practices? I agree with you further and no, I have no good resource. I have started integration testing for a sub project and had to figure out, how I manage all the setup and so on (it was a C# project). If databases are on focus, you have basically multiple possibilities: * use transactions in a setup / tear down phase to make sure, you do not change the DB state. Disadvantage is, that you loose the data after the test and therefor often important informations in order to fix the problem. (You will then have to rerun this test and disable rollback) * always initialize the database (or the relevant parts your test affects) befor *every* test - could slow the tests enormously! I tend to mix those strategies dependant on the use case.
Even shorter: def bar(n): assert n &gt;= 0 return (x for x in range(n)) 
Yeah it's a violation of the "explicit is better than implicit" ethos of Python IMHO. Should have just added a "generator" keyword that declares a function to be a generator. Should have had to declare your variables too.
Do you happen to have a best-practice base template you use? 
startproject install DRF &amp; dependencies configure local_settings/settings (big time-eater if you have multiple dependent apps) startapp and that 'get to coding' is a lot more than you say it is. Not only are you doing all of the standard per-app django configuration, but then you're adding serializers, probably signals / celery config per model, and that's just the start. I'm a freelance contributor to DRF and I really like it, but I'm saying that there's a lot more time-consuming groundwork to get a fully-functional API setup and that's not including configuring everything front-end side to handle the cors headers and everything else. I DON'T KNOW what the other frameworks offer. That's my question. Does anyone else use them? Has anyone done both and found Django to be the best? Instead of having stupid pissing matches, let's have a conversation and sharing of best practices. My question was simply is there a more lightweight setup investment out there. Maybe there isn't and django w/ DRF is truly the best of everything. That's my question. Another question asked here is: are there any lightweight project templates implementing best practices out there in the form of a github project? 
We're not saying 'can' do it all. We're saying 'must' do it all.
I'd like to add DataFrame.to_html to the list of wonderful time-saving features in pandas. Doesn't take much css (I just grab table-striped from Bootstrap) to export a good looking report that you can be happy presenting to your bosses/co-workers/clients. 
I'm using a minimal example here that could be replaced by a comprehension to avoid distracting from the point. Assume I really mean to use a more complicated yielding sequence.
I agree, it would have been better if yield was forbidden in normal functions, and only allowed in functions which have the generator keyword so it would be: def generator foo(n): assert n &gt;= 0 for index in range(n): yield index or def foo(n): assert n&gt;=0 def generator bar(n): for index in range(n): yield index return bar(n) or something like that
&gt; Another question asked here is: are there any lightweight project templates implementing best practices out there in the form of a github project? I have my own, but it's simply a copy and paste of settings.py. Sounds like you guys' requirements are way more complicated. In the time it took you to type up that comment, I'd have probably started a new project for an API.
Yeah, there is absolutely no way we'd be able to have something up-and-running with that. The majority of our projects are healthcare-related, meaning we have to have significant server configuration for security purposes (private media, multiple databases, etc.) Our projects tend to be small in terms of user count, but massive in terms of tables, apps and inter-relationship between apps. 
&gt; The majority of our projects are healthcare-related, meaning we have to have significant server configuration for security purposes Just to be clear, I meant up and running from a development standpoint. Not production server. Though even that doesn't take too long for me.
That's like 1.b for some people (through inexperience or "other devs said so") start with a home-grown POS not-invented-here "framework" that spirals out of control and ends up requiring weeks to accomplish the most basic of changes. THEN you find a framework and breathe a sigh of relief. This is how my experience went; though I wasn't originally hired at my first job to do "web stuff" it just sort of fell in my lap, because I was "the computer guy" (my original job was writing assembly for embedded systems). The management hired another webdev as the "expert" and he wrote this gigantic PHP monstrosity. Over the years as the assembly business fell off and the web picked up I moved more and more onto PHP stuff; just assuming "this guy is the expert, he must know his shit" until I started looking around online. I tried "CakePHP" first (being most familiar with PHP) which opened my eyes to a lot of things, then it was on to Ruby and various frameworks, which was a huge mental shift for me. 
&gt; We recently ran into an issue at my office where we needed to convert a number of PDF files (massive brokerage statements) to excel documents to sort and comb the data. That's sounding like a nightmare... If the pdf is well formated it is relative easy to do, if ... There are modules for that, search for them. For the excel part, that is a very bad idea, excel is not a database replacement, it is just a shitty viewer for tabular data with some filters to playing around, nothing more. Ever opened a 100MB or 1GB file with excel? My advice: store the parsed data into a real database, sitting on a server so it is reachable all day long and use a real database, not MS Access, this is also a kid's toy like excel. However than right a tool that does the hard job of calculate some stuff and as output you can use excel if you want to. Better would be hook in a webapp, django is good enough for that, that displays the data from the database acording to your needed queries and in pages, to not kill the server. So all the stuff is available in a browser, I think the office bees can handle that. Of course only in the local network. Also you can make sure that logged users can only see what they are allowed to see, again django makes that relatively easy. There are more benefits to this, you can visualize the date and display it on a dashboard, collect time based reports automatically and so on. And if for example the boss want to have access from home, just say no. Without a VPN to your local network and a safe computer on his side, which is most unlikely, it is just bonkers and very very unsafe. And in case he want to see the data with his smartphone, quit your job and search for a new and better one. Make sure you design a system that can be used for the future and can handle massive data. PDF, EXCEL these are just toys, nothing more. For a small and young company enough but you will collect alot of data over the years and that'll become unhandable. Wait until you have to make your tax reports and watch the ship sinking...
 &gt;&gt;&gt; def foo(): &gt;&gt;&gt; if False: &gt;&gt;&gt; yield 1 &gt;&gt;&gt; foo() &lt;generator object foo at 0x101d721a8&gt; So it does.
I have a similar problem. I deploy postgres, python, nginx, etc. to old Linux boxes, some running &gt;10 year old (albeit patched) 2.4 kernels. I build these from source on a modern Ubuntu using musl libc. Works like magic with some effort. One limitation is that I've yet to successfully build all of the X libs with musl libc. That would allow me to build our app (that relies on X libs). Is pkgsrc a better approach?
everything is possible if you throw enough boilerplate at it. People are using python for convenience, otherwise they would be reinventing the wheel in C. More convenience is better ceteris paribus. For quick and dirty debugging splatting the shit out of some container(s) is much more convenient than comprehension with conversion + `join()` + `format()`. 
ipython
&gt; Where is it from? Is it an IDE, a debugger? These are the line numbers from ipython. That is an awesome terminal interpreter with alot of magic in it, it is also a part of jupyter projects and their awesome notebooks. `In [x]:` means input and `Out [x]:` means the output, not `print`! Here some magic, with version they also added multiline edits, oh and autocomplete, syntaxhighlighting and much more is there from the beginning: ~ ⟩ ipython ~ Python 3.5.2 (default, Jul 5 2016, 12:43:10) Type "copyright", "credits" or "license" for more information. IPython 5.1.0 -- An enhanced Interactive Python. ? -&gt; Introduction and overview of IPython's features. %quickref -&gt; Quick reference. help -&gt; Python's own help system. object? -&gt; Details about 'object', use 'object??' for extra details. In [1]: def f(x): ...: return x ...: In [2]: f(1) Out[2]: 1 In [3]: print(f(1)) 1 In [4]: %%time ...: f(100) ...: CPU times: user 0 ns, sys: 0 ns, total: 0 ns Wall time: 3.58 µs Out[4]: 100 In [5]: %%timeit ...: f(100) ...: 10000000 loops, best of 3: 58 ns per loop In [6]: from random import randint In [7]: randint? Signature: randint(a, b) Docstring: Return random integer in range [a, b], including both end points. File: /usr/lib/python3.5/random.py Type: method In [8]: randint?? Signature: randint(a, b) Source: def randint(self, a, b): """Return random integer in range [a, b], including both end points. """ return self.randrange(a, b+1) File: /usr/lib/python3.5/random.py Type: method That is a [picture](http://ipython.readthedocs.io/en/stable/_images/ptshell_features.png) with colors and suggestions. Since version 5.0 they integrated `prompt_toolkit` as base for the terminal interface and you can now do alot of cool edits in your termial!
Ipython, its great
Thank you for the feedback. I will try to change some things in my writing for the next post. I hope you will have a great experience with Connexion. If you any questions just open an issue on Github and we will try to reply as son as possible.
Its certainly not needed, as you said, but somewhat commonplace to do the following in your python code: import somestuff def main(): # do something useful if __name__ == '__main__': main() If you point the interpreter to a .py file that doesn't have any code to execute, then nothing will happen at all, no errors but also no output. for example: # functions.py def func1(x,y): #do something return def func2(m, n): # do something else return This file doesn't do anything on its own it just defines functions but if you were to run 'python functions.py' there would be no output. Instead a file like this could be designed simply to be imported: from functions import func1, func2 But you could also do both - ie. have a file setup to be imported for use elsewhere but also have some tests attatched to it so it can be executed byitself to make sure thigns are working as intended. # functions.py def func1(x,y): #do something return def func2(m, n): # do something else return def test_func1(): # do some testing def test_func2(): # do some testing def main(): test_func1() test_func2() if __name__ == '__main__': main() Now you can point to interpreter to functions.py and it will run the test code executed form the function main(). But you can also just import the individual functions like normal. 
While I can respect the current implementation, I also like explicit declaration. Is there any linter (pep8?) that can warn? (Or is this effectively a halting problem?)
Apparently so: http://qpython.com/ But to avoid troubling you further, running `from __future__ import braces` produces `SyntaxError: not a chance` 
Interesting. Thanks! That's the official way of doing it?
Makes sense. That check should take care of any unwanted execution attempt. But, what about the second part? How do you know what's the correct file to run? Its there a convention on how to name the file that should be the entry point? 
Yeah but it has to effectively guess at what the right thing is in a given context. That's how you end up with "semi-colons are optional" in languages like Javascript, except where they aren't. Better to just have a rigid structure that's unambiguous. You can pretty easily end up with stuff like this: value = 2 def func(): value = value + 4 print value Which gets parsed just fine, but throws an UnboundLocalError exception at runtime. If we'd had to declare the two separate instances of value, then it wouldn't be a problem. The second declaration could proceed just fine, and afterwards the outer variable would be shadowed, like we expect. And, like I said, it makes it clear exactly where the lifetime of a variable begins: var value = 2 def func(): var value = value + 4 print value Ultimately a pretty minor thing, but if you're gonna make "explicit is better than implicit" a core part of your ethos, we shouldn't slack on the details.
Can you mix yield and return statements in a function? What effects would it have, and do you know of any immediate uses?
Following the line that opens this discussion, there is a module for that. You can use ctypes wherever you feel the need to control the types (to the partial extent of C, which is not perfectly safe either). Or numpy of course. Cython, mypy..
&gt; it applies to all containers Doesn't work with sets, because sets itself aren't hashable, can onyl work when you converting the original set into a frozenset, but then the frozenset isn't the same reference any more. But of course you can make a hashable mutable set, but this is another container type and not a set anymore. And you can't create nested strings that contains itself and strings are also containers.
On a windows machine u have to manually add pip toyour path. Do that and it will work
How does static code checking work compared to, for example, PyCharm ?
Wow, I didn't know that Python did that! Just goes to show why you shouldn't shadow variable names... :P I feel like your solution wouldn't solve the problem, though. I could be wrong, but I assume the weird behaviour is caused by `value` being created in `func`'s scope before the RHS of the assignment is evaluated - once `value + 4` is being evaluated, `value` is undefined. It seems to me like a solution would have to involve evaluating the RHS of an assignment before creating the variable on the LHS; frankly, I'm not sure why that isn't already the case (unless I'm misunderstanding something, which is entirely possible). Making variables explicitly declared wouldn't cause that to happen, as far as I can see. Edit (I suck at reddit today, sorry): if we're quoting PEP20, I think "Special cases aren't special enough to break the rules" is relevant too - variable declaration feels to me like a special case of variable assignment. Continuing the box analogy, you can represent an undeclared variable as either an empty box or no box. No box is closer to the reality (you have to allocate the memory before you can put something in it, after all), but I don't use Python to program in reality! I use Python to avoid reality - for example, I don't care how my integers are stored, so I like that Python 3 removed the distinction Python 2 had between short and long ints.
&gt; No, you can't pause and resume functions. Sure you can. Its called SIGSTOP/SIGCONT, or going to the next instruction in pdb ;)
Thanks! On a quick glance, this seems to have a learning curve. Since my attention is on other things right now (mainly C), I'll simply keep Jupyter in mind for now. Is Anaconda a useful addition to Jupyter IPython? Their site praises it a lot.
Okay ;) But subroutines aren't intended to be paused and resumed.
Get a room guys
In theory you could try and do this, but it quickly becomes ambiguous. Consider the following: def stupid_gen(iterable): i = 0 for x in iterable: i+=x yield x return x `foo=stupid_gen([1,2,3])` now foo is a generator and you can call next on it 3 times (getting 1 then 2 then 3) before you get StopIteration. The value in the exception will be 6. But what about `foo=stupid_gen([])`? What is `foo`'s type? Should it be an `int` with a value of 0? Or a generator that throws `StopIteration(0)` on its first call to `next`? So if you treat all functions as co-routine/generators you need to distinguish the act of passing arguments to a function from executing the next set of instructions of a normal function, because in python `()` does both. It is the way you give arguments to the function, but also it triggers the execution immediately. 
You should try checking out [PEP 484](https://www.python.org/dev/peps/pep-0484/) and [mypy](http://mypy-lang.org/) -- Python has (optional) gradual type hints now. All the different tools that understand PEP 484 type hints (mypy, Pycharm's built-in checker, py.type, etc) are all in various stages of beta and so still need work, but if you want static types in Python, they're a thing now.
(micropython)
I'd like to buy a paragraph.
Username checks out. 
I use Django with Django Rest Framework (their ModelViewSets make quick work of producing API's, I've also in general become very familiar with the code of Django Rest Framework). For auth there is token authentication from [Django rest auth](https://github.com/Tivix/django-rest-auth) or lately I create my own token auth. Rest auth also which gives you endpoints for login, registration, and hooks into some other nifty user management packages. I use token auth for all. You don't want session auth if you want things to be able to be nicely decoupled, plus, I like the simplicity of just passing an authorization header. 
What kind of wasted overhead is there?
My little project was kind of just for fun. I made something akin to a neural network (not really sure as I just kind of went with it without going too much into the math) and randomly generated several "organisms" on a grid. All the organisms were given a random RGB color, which determined who they were allowed to eat and who they could breed with. Too different a color, and they would not breed. They would move based on my pseudo-neural network with an output of 8 neurons (one for each direction in a grid including diagonals), and had 8 input neurons that were the RGB color of the possible spaces they could move to. And when a new organism was created to it would randomly select the weights between "neurons" from its two parents, and take on an average of their colors. It sounds like it's cool, and it is, but it's definitely not accurate to...anything really. But the pretty colors they make on the grid are neato. That's cool you made a script that verified a real thing! How long did it take you? 
I am studying the Japanese language and often play video games to practice reading. I wrote a small app to take a screenshot of an emulator, then compare the screenshot's RGB values to a sqlite database of the RGB values for the font used in game. After all the text is found, the text is tokenized and the words words are ran through a translation API. Someday I hope to combine the app with another script I wrote to automate flashcard creation. 
That's pretty neat. I'd imagine that could be a useful tool for someone creating a translation ROM hack. I've always enjoyed tinkering with ROMs, but I never really did anything substantial. One time though, I changed a couple lines of assembly in a game to make it so when I bought an item in a shop, it gave me money instead of subtracting the cost :) If I had a decent amount of knowledge built around a ROM, making a tool and GUI to do things would certainly be on my list of ideas for projects. 
Ah fair! Yeah makes sense. I started with checkio but I also do code wars, so the two seemed similar, and empire of code felt different, so I switched to that. 
No, till python 3.2. It was changed with 3.3.
There is no way you can do that without modifying Apache configuration.
If you're writing a multifile module, you can provide a `mymodule/__main__.py` file, then you can run your module with `python -m mymodule` and it will automatically use that file.
Well, there's [Brython](http://www.brython.info/index.html), I guess...
[WSGI](https://en.wikipedia.org/wiki/Web_Server_Gateway_Interface)
We've just been working for 1.5 years on a massive Pyramid app also with a large team and have come to some similar but also some different conclusions. We also had issues with haste, it really doesn't help and hurts the project in the long run, SQLAlchemy takes a few weeks to learn and use effectively, this is something we discovered too. However we also came to a very different conclusion with Colander and that is: Colander: never again. I am not sure WHY the author is recommending Colander when it's been a really terrible experience for us, and now I would recommend Marshmallow instead. Problems we had with Colander: * Everything is serialized into strings making it a terrible choice for producing nice JSON, we had to subclass every field type in order to "fix" Colander and it was horrible * Null handling in many of the fields is broken in the release we were on and colander.null vs None can be confusing * You can't just serialize an SQLAlchemy object like in Marshmallow, so you have to convert it to it's dictionary representation first, THEN serialize it AGAIN to a more low-level dict, why???? * Schemas are more verbose than Marshmallow and fields have to be "wrapped" in SchemaNode() * Not just Colander, but the way Cornice integrated with Colander made it impossible to do validation across two fields in the schema as field1 couldn't access field2, at this point we couldn't really go back anymore so ended up having to write really convoluted code to get around this design flaw. Also I hated Deform but luckily didn't end up using this and went with using WTForms which is way nicer.
Note that the last point about Colander could have been fixed if there wasn't the constant haste problem, we could have gone back and changed the architecture early before it gave us any more grief.
http://www.archiveteam.org/index.php?title=The_WARC_Ecosystem#Tools Since you posted here i assume you want http://warc.readthedocs.io/en/latest/
&gt; That's cool you made a script that verified a real thing! How long did it take you? I put in a couple of hours every day after work and it took a few days. I should upload it to GitHub. Your project sounds interesting. Kind of like the [Game of Life](https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life) in some ways.
Yeah I partially borrowed inspiration from that. I had another version where organisms (circles) would swim around from a top point view, although that one didn't use neural networks. Instead, each organism had a set of traits that could change, or not change, upon birth. Stuff like speed, turning radius (they could move I 360 degrees), "attention span", which meant a lower value caused them to turn direction randomly more often. It was kind of half baked and I got tired of the complicated movement, so I moved onto the grid based approach. 
Username has nothing to do with knowledge :)
`yield from foo()` expression allows to get the value returned by the `foo` generator while yielding everything `foo` yielded. This was the usual way to develop with `asyncio` until async/await.
It sort of sounds though that the author is using Pyramid or Pylons rather than inventing a framework from scratch, which is probably why the lean towards libraries like Colander and Deform which are all under the Pylons umbrella. Pyramid itself is fine, it's just a bit more low level than say Django meaning you have to do more setup yourself. To me Pyramid is a nice enough framework to get into, but probably more after you've been doing web development with Django for a while and aren't afraid of doing a little project setup.
There's [this GUI library](https://github.com/dddomodossola/remi) if you absolutely need to use python. I've used it a couple times when I needed to quickly get a web GUI up and running, but IMHO you're best bet is just using HTML, CSS, and JS with something like bootstrap which already does a lot of the heavy lifting for you.
You did the second circuit "Safe Shutdown Switch"? If so, by all means, please help.
I'm working on a image processing pipeline at work. We take in large datasets of many images, preprocess them, transform them, and then spit out the transformation. This is a complicated pipeline and refactoring is problematic because we don't have good integration tests. This is partially because I'm uncertain what the best practices are for integration tests and additionally because part of our pipeline relies on randomness as part of optimization so we get slightly different outputs each time. I think I'm going to try to find a book that covers real-world integration test scenarios (ideally for Python) so I can understand better how people manage this stuff.
Well, yield should clearly alter the return type regardless of whether it's reached in some particular case - just imagine you're doing for i in range(x): pass And getting a "ValueError - NoneType is not iterable" if x happens to be 0. You want range() to return an iterator regardless of whether that iterator's empty. It's only in cases where the yield is totally unreachable that it makes sense to do otherwise, and that's technically a programming error. Better to flag that kind of thing in the IDE.
What /u/magic2hobo, but also [pyjamas](http://pyjs.org/) and [flexx](https://github.com/zoofIO/flexx).
Oh right, I remember now. I generally don't write tests but I have seen this in them.
I'm surprised I haven't run into your first example. I do things like the following all the time, and it works just fine (prints 6). Why does python try to create a new local variable for `value` in your example instead of just using the existing one? value = 2 def foo(): bar = value + 4 print(bar)
&gt;No, variables are just names linking to objects. The variables themself don't have a specific type, you can link any object to any name and relink right after the same name to an object of a different type. Ok, I misunderstood you. I thought you were saying the the VALUE of a variable doesn't have a type. &gt;object btw is not the type of objects, it is just a basetype in the object-hierachy. Type is usually the class of an object. I was thinking more along the lines of a class that inherits from object.
Those sound like awesome scripts to make life easier. I wish my job was easier to automate (I should be careful with my words...), but I think it'll be awhile before engineering work can be automated. I like the idea of a program that gathers data, such as the weather, and outputs a result. I saw a video recently about a guy who used weather data and a neural network to try and fit predict the weather. All he showed was his program's output compared to a weather database, but it was cool to think that he could train a numeral network to make predictions based on a handful of carefully selected variables. Thanks for the ideas. That last one sounds like a great way to get some more business. Of course, some people don't really like automated stuff in their inbox. Maybe find a way to make it seem more human? :) 
`pythonProj1-env` is a build artifact to support `pythonProj1-app`. I put those things inside my project, so: `pythonProj1-app\pythonProj1-env` But you can put it like you suggest. That way works just fine too. However, having something like this: ~/projects ~/projects/proj1 ~/projects/proj1/profile.sh ~/projects/proj1/env ~/projects/proj2 ~/projects/proj2/profile.sh ~/projects/proj2/env Means that if you want to delete a project, you only need to delete one top level folder. It's a bit cleaner. Having a `~/projects/proj1/profile.sh` is a personal preference for my projects. This is basically a copy of the virtualenv activate script, but customized to include any other project specific environment variables. Also it's nice to keep this at the top level of project rather than having to remember what/where you've named your virtualenv stuff. 
Cool! What you used for font recognition and OCR? 
&gt; Different text editors can put different white space for tabs You could look into [Editorconfig](http://editorconfig.org/) to standardize your settings, it works in multiple editors built-in or through a plugin.
*Java* is sometimes used as a synonym for the whole JRE platform. Perhaps that was his meaning? The JVM offers some nice languages with FP paradigm as first class citizens (Scala, Clojure and Frege). But to be fair: With Jython one can easily use other JVM libs; the other way round it is more difficult...
I replaced my ancient home alarm system with a Raspberry Pi + PiFace board (http://www.piface.org.uk/products/piface_digital/) and wrote a python bottle app for a web based home alarm monitoring system which my family have used daily for over 3 years now.
Have you looked at numba? Vectorized code is a dead simple way of doing parallel execution. The alternative is threading style (like multiprocessing) where you'd have to lock objects in shared memory yourself. Current multiprocessing is actually nice because serializing objects means you don't have to lock them. It would be cool though if you could put locks on mutable objects rather than serializing them, but it's not really less specialized than vectorized code. Pyjion is pretty cool, like having pypy execute just one of your functions but still be in cpython. 
I love home projects like that. Having things interconnected and controllable is really satisfying. Whenever I actually buy a home, I am definitely going to spend some time and money on making things interconnected so I can do stuff like set lights from my phone or like your setup. 
I was trying to build a function that was optionally a generator or recursive. That failed brilliantly! That's the day I learned this.
You may want to check out numba (http://numba.pydata.org). It is extremely easy to use (especially compared to using your own OpenCl code) and can also target multicore CPUs and GPUs using LLVM and automatically generated Cuda code. You just write normal Python functions (with some restrictions) and decorate them with a special numba decorator and they will be transparently JIT-compiled to a highly optimized CPU/GPU-native function.
Sry, get that often wrong. Next time I will consult leo.org if I am not 100% sure if I use the right spelling or translation. (In my mind that seems correct because of message and not messege...)
The win for threading vs. processes is in not having to deal w/ copying. COW helps a ton (where it's available), but marshaling data in and out of the process is necessarily more expensive than sharing it. So for something simple like a pool of workers taking work from a queue and (potentially) queueing more work, threads are nice, and aren't hard to reason about. I agree that serious performance gains are almost certainly going to need more, but sometimes that's enough. Pyjion is extremely exciting. I can't wait to see it take off. It doesn't do anything about the GIL, though, and if anything, makes it more likely to be a bottle-neck, since now your numeric Python code is so much faster.
I just started the course a few days ago and finished it today, so I did see. I don't think you should assume anything. They are not just upgrading Python but their other courses too.
The default configuration checks the code by using Python itself. For example, given a *test.py* file the syntax checking of that file will run this python command: python.exe -m py_compile test.py The results of that check will be capture inside the IDE and any errors generated navigated to from inside the IDE. But the actual command used is fully configurable so in reality any checking command line could be used. For example, with a bit of tweaking, something like [pylint](https://www.pylint.org/) could also be used for the syntax checking. 
grequests
That's random, but sounds cool. It would be kind of nice to put at a really low volume and use to fall asleep to as low key background noise. What made you decide to make it? 
Misleading title; This doesn't do any conversion with Python. The library is just uploading your data to a remote webservice which does the conversion. 
It was pretty cool. I eventually extended it to having some controls on the face of the "screen", and the ability to pull random still images from a Google Image search (inspired by the WebCollage screensaver). I abandoned the project before I could integrate random YouTube videos into it. &gt; What made you decide to make it? Job interview answer: Well, it was a longer-term project that aided me in learning the QT framework for Python3. Real answer: I was very, very bored.
Remove the parens Round your if else statements
It's not actually the indenting. You need a colon at the end. if (a): Without the colon, the interpreter can't understand the line, so it doesn't realise it should be indented as it is. Assuming the previous line ends well, of course - you may have more than one problem. Also, remove the () after "else", and add a colon there too. 
Cool! It's simpler than Machine-Learning, but it seems to be given great performance. I might try your approach to see if I can recognize card names in Magic The Gathering Online (GUI bots are allowed there)
Pretty cool, I hope it's not as complicated to set up and push to prod as typescript is for JS.
I'm not disagreeing, but your post heavily implied it couldn't be done in one line.
Yes, although for command line utilities and the like you'll want to use setup.py's [entry points](http://python-packaging.readthedocs.io/en/latest/command-line-scripts.html).
Good to hear you had a positive experience! How long did programming as a hobby take to get you to a professional environment? How self-disciplined were you?
hey, that's a really good workaround idea, thanks!
I was able to get this working by creating a service account as detailed in the instructions below. Once I get the creds from the function I can use the rest of the API documentation to create/query google apps. https://developers.google.com/admin-sdk/directory/v1/guides/delegation 
Looks like you're looking for a .dll file called LZ77.dll LZ77 is a compression algo, as far as I know.
You'll probably get sent to r/learnpython/ but since I started recently too, I recommend codecademy.com to get started.
That's cool. You should make a SuDoKu *maker* next. 
 def add_me(_input): if len(_input) is not 1: temp = sum(int(x) for x in _input) print temp add_me(str(temp)) check /r/learnpython for help. 
Although I haven't finished them myself: Black Hat Python and Violent Python. Definitely on my todo list. 
google. lz77.dll
i made a ray-tracer using peter-shirley's 'raytracing in a weekend'. though due to other commitments it took a while longer :)
Typing code can be a pain. I can't imagine doing it on a phone. If there are ressources dedicated to learning on mobile, I don't know them.
The pyjion dev had a pep accepted to allow arbitrary execution contexts per function, which is what make pyjion possible. So, pyjion may not release the GIL, but it is the first and that pep potentially allows for another project to do something like releasing the GIL if it only has immutable inputs or something. Pure speculation here, but I believe there is a lot of room for new, cool things in the future.
It's going well. The learning curve is steep. Everything is child's play at first but it gets hard really fast. I've gone through 3 basic "courses" (learn python, learn python the hard way and codecademy). I'm looking to find some intermediate courses now.
I used an inductive current sensor and a Raspberry Pi to send Slack notifications to a channel when the coffee machine at work is brewing :)
Thanks!
Where exactly did you get the script you're trying to run and what is it supposed to do?
I've made a Telegram bot for my friend group to schedule videogame/D&amp;D sessions. It's not open source, because the code is a huge mess right now, but me and one other guy have started refactoring it into something more resembling an architecture designed by a sane human, and I'll probably set the repo to public when that's done. 
If you need to crawl a website, Scrapy is your choice (it's async)
The entry point to a python package is the `__main__.py` file. If the package doesn't have a main file then python will fall back to the `__init__.py` file. Strictly speaking, the init file is the import entry point (the place to start reading when you import the package) while the main file is the execution entry point (the place the interpreter starts executing when the package is run directly). The main file is a relatively new addition to the ecosystem. Before that we used to use the init file for both purposes and we used the `if __name__ == '__main__':` trick that everyone is talking about to disambiguate. That trick isn't deprecated or anything, but you generally shouldn't need to use it in a modern python project unless you only have a single module. If a python project is a library that isn't designed to be executed directly then it obviously won't have a main file. You can't tell the difference between this and a project that used the old init-file-only system without reading through the init file. If a project has more than one entry point then things get more complicated.
This attitude of _not preventing people from doing something silly just in case they have a good reason_ is a widespread principle in the python community and is commonly referred to under the name "We're all consenting adults".
/r/netsecstudents &amp; /r/netsec 
I used to recommend LPtHW to beginners in my lab...but that disclaimer is straight up FUD despite having 8 years to get used to it. 1. A hard distinction between text (characters that humans use) and bytes (serialized/encoded data) is a *very* good thing. Text (`str`) in and of itself is an abstract concept that cannot be written to a file or sent over a wire. 2. There are 3 different ways to format a string because curmudgeons like `%` formatting, and also didn't like `.format()` that much, so now we have f-strings. I'd be fine with obliterating the others, but then there'd be complaints about that. 2. As far as I know, 2to3 is something that only package authors need to deal with. 2/3 cross-compatible code is a thing, but you need to write it like Python 3, which given the author's views is probably why they're unfamiliar with doing so. 3. The stdlib `urllib` returns bytes because bytes are what is sent over a wire (see above). Is "poor design" just that it doesn't parse out the encoding from the HTTP header and/or Doctype declaration and/or `&lt;meta&gt;` tag? I wouldn't really call it poor design, maybe incomplete, or batteries-missing. `pip install requests`? 4. New features are an impediment to teaching? Sure, `async def` makes my head hurt, so don't teach that. Metaclasses can also summon eldritch horrors and are in Python 2, but you're not talking about those: problem solved. As per the formatting "problem", I'd only teach `.format()` because 99.9% of Python installs support it. If students stumble across `%`-formatting code "in the wild", that's just one of a hundred other things that they'll need to learn beyond what any course can teach.
i do lik this forum: http://forum.xentax.com/viewtopic.php?f=10&amp;t=14269. i have post another post to ask . please help me that question?
Can't come soon enough in my book. 
I used python for the PC half of my desktop lighting project! https://youtu.be/F1baDAY0vDA 
It is a virtual machine. &gt; Current use includes virtual machines which have no direct correspondence to any real hardware. Wikipedia.
Lots of things. The most recent one was a telegram bot that will alert my group of friends when a pokemon spawns in our home town. 
That's my point: The GIL is not an issue for IO bound workloads. While a thread is waiting for IO, it releases the GIL and others can continue. The rule of thumb is: * IO bound -&gt; threading * CPU bound -&gt; multiprocessing * Lots of concurrent connections (more than ~100) -&gt; asyncio or gevent
I would say: The **idea** of having dicts ordered came from a particular implementation. Having dictionaries ordered by default **will** be a **conscious choice** (if it happens in the future indeed) I don't see anything wrong with getting an idea from an implementation (though of course it would have been nice if they had had the idea earlier - preferably before the introduction of OrderedDict)
&gt; I wish my job was easier to automate You don't need to automate every single thing, and definitely not the design work. But engineering jobs have lots of paperwork, much of which can be automated. www.automatetheboringstuff.com is a good resource, it's free, but it doesn't follow PEP-8.
I'd say that it's less "you can't have that" and more "you don't want that". What if the generator does an irreversible operation like reading from a socket, or can wait on IO or perform a lengthly computation? You'd expect that stuff to happen _after_ and _only if_ you requested a value, just like it happens to the rest of the values you requested. And then by the way you'd have a choice between inconsistency (first yield is different from the rest) and utterly stupid and useless and wasteful behavior (generators always eagerly precompute the next return value, then it sits there in case someone needs it). pinging /u/java7nerd too.
The hash implementation was not changed in order to introduce ordering, rather a new layer of indirection was added so the hash table only records indices into an array (which is iterated to produce the ordering). I still hate everything about this creeping into the core language. Knew with certainty the moment OrderedDict got accepted in 2008 that things would get worse, and here we've arrived. This is what the slow erosion of sanity looks like: https://bugs.chromium.org/p/v8/issues/detail?id=164 We're all but guaranteed OrderedDict will become the new dict, simply because people can't be trusted to understand the difference, or read and understand documentation or specifications before writing code that gets deployed in so many places that it gains "voting power" in later forcing shitty changes to the language that are ultimately impossible to argue against When democracy gets a hold of a language spec we end up with perl and PHP.
You can already used OrderedDict. 
And...
That's neat. 
Niiiice. 
Including an even more efficient (but unordered) `dict` implementation.
Wow... I wouldn't want anyone to read a book from an author that's stuck on notions 8 years out of date. He used to be a fantastic author, but his stance against the community has been very disappointing to where he actually has become a negative voice for us.
So you're arguing with a straight face that ordered dicts are a data structure that should be.. what? Banned? What are you even saying?
Huh? The previous ordering was made without conscious choice, so why would a new order, regardless, be a bad idea? Besides, we already know that lots of places that are dicts would be better ordered. What's wrong with killing many birds with one stone?
The new implementation would probably be a bit faster if the compacting step didn't preserver order. Instead of filling in the holes by backshifting all following elements, they could just swap in whatever's at the end.
More or less, yes. In 8 years I haven't once encountered a use for them that resulted in code that didn't look completely insane, or made assumptions that did not exist. The most common manifestation of this in Python land is using OrderedDict to control the output of ``json.dumps()``, which is pointless since JSON has no ordering guarantee. Of course, *de facto* JSON effectively *does* have an ordering guarantee, to be fed to a JavaScript engine that once again has no ordering guarantee. But of course, *de facto*, JavaScript engines effectively *do* have an ordering guarantee (hence the linked bug report). None of this was by design: by virtue of the majority of users being too stupid, all Javascript engines must emulate bugs of older engines in order to run code that stupid people wrote. And now the same thing will happen to Python's dict. I'm sure there are uses for OrderedDict but I have yet to find one, and I have been writing code pretty much every day for the past 20 years. It's most often a tempting hazard that causes silly people to write shitty code that I might encounter, and I'd like to avoid that. Use a sequence or use an associative mapping, learn the freaking difference. But of course the chance of that happening diminishes for new users every day exactly because of crap like OrderedDict.
I watch a _lot_ of anime, up to 30 airing shows every season. To manage all these files I wrote a script which matches filenames by regexes from config file, renames and moves them to appropriate directories. It includes a macro mini-language to make regex generation more bearable as well as submission through API to a website I use.
* a script that makes VLC playlists out of a sub reddit videos (youtube, gifv, streamable, gfycat) to watch them directly with VLC like a TV channel (vlc.tv) * a script that finds all the new images and gifs posted to the sherdog forums, or to the UG forum, and makes a big html page out of them (mmavid.com)
*Python is more concerned with making it easy to write good programs than difficult to write bad ones.* - Steve Holden I think a language can't really prevent people from writing bad code. Sure, ordered dicts can be misused, but so can any language feature. Of course it's a pity to hear you've had to deal with "shitty" codebases, but I guess you already had to deal with those before OrderedDict was introduced in Python - Dealing with shitty codebases is mostly part of being a programmer.
I LOVE PYTHON
Yeah thats my bad for not reading the sidebar 
sweet thanks, imma head over to that sub right now
o7
Nah, I'm more a fan of his original work.
you didn't post the config - your code is also not using best practices. i.e. https://docs.python.org/3/library/ssl.html#ssl-security
If all you need to do is remember the order of keys and values, a list of tuples seems like a good idea. To justify ordered dict, you'd also need random access lookup by name/key.
Slightly OT: What happened to PyData NYC 2016? For a long time the status was "coming soon" and with the redesign of the website it seems to be gone. 
But WALDO is for "Worm Analysis and Live Detailed Observation," [software developed by my lab](https://github.com/amarallab/waldo)
Screenshots or something?
The ordering is stable until the hash table changes size.
Crap! Now I gotta find a new name ;)
If you have gonads of steel, possibly.
I never even thought of it that way, but your logic makes complete sense.
Doesn't Qt Designer generate C code, which you then have to use PyQt to convert the project to Python? Or does it natively support Py now?
Yes, and we don't need dicts either: Just use two lists.
Instead of predicting a time series, is there anything available that detects when a time series rapidly moves outside its normal range? I'm thinking trend or anomaly detection.
I don't know. Depending on less apparent properties of data structures makes for obscure, hard-to-debug code.
There are a couple indicators that are commonly used for similar purposes. 1. Stochastic Oscillator 2. Relative Strength Index Lots of people make trades partially based on these indicators. In the example, I'm actually using Slow Stochastic Oscillator (SSO) values for my model and you can see the hot/cold spots identified from training the model on a year of historical values. You can monitor the SSO values for a particular stock and wait until it moves into a range predicted to increase the stock price. Tricky thing is you usually can't predict when the time is right to buy from a single indicator. The conditions need to be right with multiple different indicators to make accurate predictions.
Yes I second Bollinger Bands.
It generates `.ui` files, which are XML, and can then be converted to C++ (with `uic`) or Python (with `pyuic`).
People have been talking about having ordered dictionaries as the default for years. It's hardly a new idea. It was never seriously considered because the existing dictionary implementation was un-ordered, and the obvious way of tracking order would have come at a performance penalty. Given that dictionaries are used *everywhere* in python, it was a no-brainer to prioritize performance over ordering, especially since a separate ordered dictionary type is easy to implement. For just that reason, the python devs will not be quick to make the decision to make ordered dictionaries part of the specification. If a better dictionary implementation comes along with substantial performance advantages, but no ordering, they want to be able to switch to it.
Very nice. Hopefully I can be at that point soon. 
I have it. It looks like the ones I already have is pretty much the best ones there is in learning Python. How's learning Python for you?
Learning Python, 5th Edition by Mark Lutz (unless the 6th came out). In my opinion it can be considered an encyclopedia on Python, it's about 1600 pages and covers topics in both Py 2.7 and 3.X. Codecademy teaches Python in the 2.7 branch, but their roadmap shows a course update for mid-2017. We don't quite know what that means yet. SoloLearn teaches Python 3.X. There are a a lot of similarities between the 2.X and 3.X, but there are still some changes. And SoloLearn has a different method of teaching than Codecademy. I would suggest using both sites. A big thing with beginners is whether to learn 2 or 3. I'd say both. But at the end of the day it really depends on your tasks and libraries.
Lookups are slower in a list. If you need fast random access lookup, the dictionary is the better choice of data structure.
You can nest modules as deep as you need. This doesn't have anything to do with pip or easy_install actually. It's just how namespaces work in Python. 
Parse actually has some of that functionality, you can create custom "types". I'm working on exposing that part of parse to the user now!
Carmen
Capital Reevaluation Analysis in Python
Lol I don't get it
Wooow, that's good
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hmmm...yep not gettin it. What's that stand for?
Carmen Sandiego was originally an educational series about finding Carmen Sandiego.
Ooo, I gotcha now.
Ahahah is it cause I'm drunk or that's really funny?
It's great because it makes some other desirable things easy (like reliable order of kwargs when unpacking), and might eventually lead to inclusion in the spec if it seems appropriate. That seems pretty good to me. Maybe "great" was a little strong. As an aside, I'd really encourage you to avoid trying to shoehorn conversation into formal logic. The habit tends to lead to careless reasoning rather than correctness. Here's what I take to be your argument: It isn't in the spec =&gt; You shouldn't use it You shouldn't use it =&gt; It doesn't matter It doesn't matter =&gt; It's not great It sounds great and all, except the second inference is just clearly not sound. Changes can have benefits that aren't just about their immediate use by you (specifically benefits relating to their future use, or to other people using it, e.g. the Python devs themselves).
No problem :)
If that's the real code you're using you probably need to put the filepath in 'quotes'
This is the type of thing I hope I can do some day! Looks awesome 
I was going to start a project very similar to this tomorrow but honestly didn't know where to start. This is perfect for me! I look forward to playing with it and will be sure to share whatever I do with it. Thanks for the awesome work! 
That'd be an awful idea and I can't see it happening. Basically, 99% of the use cases don't call for an ordered dict, just a key-value map, order not mattering. That means you can optimize for that use case by not having to give a shit to the order, which isn't promised for un-ordered dicts. If we start promising the basic dict will be ordered then code will start relying upon that promise. In 10 years some wizard comes up with some hashing magic that makes dictionaries 1000 times faster improving 99% of the use cases but oops, it doesn't preserve the order so I guess we have to discard that algorithm as an option because 1% of the code relies on our ordered-dict promise! Really, if you think locals/vars/etc. needs an ordered dict instead of your usual dict, then the problem is that you're using the unordered dict instead of an ordered dict, and not that the unordered dict is unordered. It would make more sense to have a way to use an ordered dict for locals/vars for those few use cases instead of trying to make all dicts ordered by default.
Interesting. Does the SVM clustering algo actually generate positive returns in a backtest?
Haha I just searched Google Images and found a relatively clear one :)
username checks out ?
I'm still a beginner, so it's hard to say. I'm in the 3D industry, so all my programs like Maya, Houdini, etc all run on 2.7, and they don't seem to be looking to move off of that. That being said, I still look at 3 for other things. For example, if you wanted to learn Qt5 and then PyQt5: that's Python 3 only. Qt4 supports Py2. 
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Just a word of caution. Technical analysis is largely useless pseudoscience. 
Will this work with the meme markets? Asking for a friend. 
What do you meant by Maya, Houdini, etc run on 2.7? 
They have built in interpreters, and the ability to run Python. They are all node based programs, so you can create nodes with Python (or other app specific languages like MEL, VEX, etc,) that run specific tasks or that actually create geometry and control it. Sorry for the I correct use of 'run on'. I realized that might be confusion after I wrote it. For an example, just google Python in Maya and there should be a video for Intro to Python Scripting in Maya - Part 1. It'll give you the idea I'm taking about. Because the programs have been around for so long, and Python 2 was the standard when they eventually incorporated it, a lot of studios and users scripts are all in that 2.x format. To shift to 3 would be a huge undertaking. 
lol, I didn't notice that. Although, &gt;Or how one refused to send 100 manual emails and made some charts instead sort of works. :D
This would depend on the stock price and the capital invested. In the model you can see a 69% accuracy for TSLA in the past year. But as I said, that doesn't mean much. The algorithm uses a binary classification scheme. Therefore it can't predict how much a stock will move up or down, only if it will move up or down in general. I haven't done a test set with hypothetical investments yet as I'm still trying to figure out how to do so in a way that makes sense.
Still working on figuring that out completely. As of now, some stocks yes, some stocks no. It seems the algorithm has a better time predicting stocks that are influenced heavily by news reports and social media hype. I don't have numbers though in regards to returns.
Well to be frank, I just didn't really need it. You can handle CSV files in many ways in Python (e.g. CSV Library). Pandas is good for other stuff though.
Looks like a good book, thanks for sharing!
There's a tool that comes with P3 call 2to3.py that automatically updates scripts from 2 to 3 (hence the name). But like all solutions, it can't do everything (it tells you what it can't) so really the only solution is to write as simple Py3 compliant Py2 code as possible before going through it by hand. As far as I know. 
Guessing the extra 'o's are because it shortens to CRAP :)
I think /u/dikduk and whoever upvoted them misunderstood your previous comment. Perhaps I can rephrase it to be more clear: "You need ordered dict if you need *both* ordered iteration *and* fast key-value lookups. Otherwise, a list of tuples or a standard dict, respectively, is a better choice." (I mostly agree, but think ordered dicts have some desirable set-like behaviour (prevention of duplicate keys) that you can't get so easily with a list of tuples)
- Look into using 'with' for opening files, they close for you! - try to avoid using global variables - use 4 space indentation, not tabs! - to find unique things, you can use a `set`. It's like a list, except you can only have one of any unique thing in it. So for instance you could write your entire unique word function as return set(text.lower().replace('\n', ' ').split()) - `x` on line 23 isn't used! - try to write a unit test! Good work for a first project :D
Yes, that is true. This is a project that I am working on with a teacher at college, and it needs to be in python because this graph will be a GUI.
Well, I would argue that 99% of users don't need faster dicts either. And I'm also sure you can't make dicts 1000 times faster.
If it's ok to use OrderedDict for when you need an ordered dict, why would it not be ok to use an UnorderedFastDict in the future if such a thing is invented?
Learn how to determine whether your changes break anything, how to get feedback and suggestions from your chosen project's established developers, and how to accept and apply constructive criticism. With those bases covered, you ought to be able to learn as you go without doing much damage. :)
You cannot just use OrderedDict whenever it's useful because the system itself uses dict. That's why it's important to use an ordered dict at the core of the language. If you really need a super fast unordered dict (that hasn't been invented yet) you are free to make a new class for that. 
The "file not found" message refers to the `xdelta` command, which is either not installed or not in your `PATH` environment variable. The references to `subprocess.py` are something called a *traceback* - it's a way for you to know where exactly the error occurred in the code, and what function calls led to that specific code being executed. 
Thanks for the explanation. How do I install the xdelta command (or verify that I have it and add the PATH environment variable)?
Awesome! Thank you. The script runs perfectly now.
Your approach is all wrong. To determine if it's "truly" random (which it isn't because it's a pseudorandom system) you want to check if it goes closer to equal over time not if it's exactly equal at some random point. Also, your code needs some serious work. import random from collections import defaultdict result = defaultdict(int) choices = 'abcdefgh' for _ in range(800000): result[random.choice(choices)] += 1 print(result) That's a reasonable implementation. Took 2 seconds to run on my phone. 
The [chi-squared test](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test#Test_for_fit_of_a_distribution) for your distribution can be calculated with SciPy: &gt;&gt;&gt; scipy.stats.chisquare([100159, 100278, 99735, 100346, 99800, 100081, 99905, 99696]) Power_divergenceResult(statistic=4.4050799999999999, pvalue=0.73211503072132689) That's a pretty reasonable p-value, all things considered. It is possible that `random.choice` introduces some sort of modulo bias though, but that needs to be estabilished by looking at the code. Edit: just retested your approach with a 100 million sample size and got a sub-0.1 p-value. Seems like your sample size was way too small.
There are no entry points here and the behaviour you describe has nothing to do with `pip` and will work just as well with `easy_install`. You're already using `setuptools` since you have a `setup.py`. Maybe you could describe what you're doing in more detail.
Ran it on my desktop with 5 million as the sample size and got: {'a': 622990, 'c': 625077, 'b': 625432, 'e': 624901, 'd': 626225, 'g': 625334, 'f': 625263, 'h': 624778} So as you can see the deviation from exactly equal goes down with more samples.
Yeah, unless someone comes up with convincing proof that ordered dicts are guaranteed to always perform better than unordered dicts, I wouldn't want to close that door.
I contribute to projects only when I have an int he to scratch. But there are projects that have good lists of issues that are good for newbies to tackle. You could try that. 
The stated reason for the limited lambdas in Python is "just use def" for complicated stuff. What's your opinion on that? 
But how did you manage to do it so fast?
But how did you manage to do it so fast?
distutils, setuptools, distribute, easy_install, pip, pypa, pypi, ensurepip, warehouse, twine, conda, virtualenv, venv, virtualenvwrapper, egg, wheel, ... It sure seems the Python packaging ecosystem has a bit of a problem. For some reason there are a thousand things where there should be one thing. Instead of improving and fixing existing infrastructure, multiple alternatives or wrappers or whatever are started but never finished or really replacing the old things. Documentation is incomplete, outdated or not existing. Very sad. :(
I'd assume it's the typical relative slowness of interpreted Python v. well-optimised built-ins implemented in C. From memory, there's nowhere near the same difference in PyPy.
Obviously, given the stdlib can obviously rely on implementation details, given it frequently makes no attempt to be portable to others. Hence one assumes it can basically just become a thin wrapper around dict.
Because often people who try to apply technical analysis don't know basic probability and stats.. Even the concept of 'overfitting' is unknown to them. 
Good read [Article on open source](https://medium.freecodecamp.com/a-beginners-very-bumpy-journey-through-the-world-of-open-source-4d108d540b39?source=linkShare-7003b31b6d74-1474188812) 
You need to use `from setuptools import setup, find_packages` ``` setup(..., packages=find_packages(), ...) ```
Can't we use deepdream for this ? 
Not unless you want to actually rewrite Tk to run on Android's graphics stack. If your phone is rooted, I guess you can try something like running a full Linux system in a chroot, and using VNC to connect to it, but it'll be extremely slow.
/r/learnpython
/r/learnpython
/r/learnpython
[Skulpt](https://github.com/skulpt/skulpt), though it's probably way overkill for what you want to do.
need to gauge the pepe market 
It's been on my mind, and since you mentioned it I went ahead and added support for 3.0 - 3.5 as well as test coverage there.
And half the links on http://packaging.python.org/ say: \ SORRY / \ / \ This page does / ] not exist yet. [ ,'| ] [ / | ]___ ___[ ,' | ] ]\ /[ [ |: | ] ] \ / [ [ |: | ] ] ] [ [ [ |: | ] ] ]__ __[ [ [ |: | ] ] ] ]\ _ /[ [ [ [ |: | ] ] ] ] (#) [ [ [ [ :====' ] ] ]_].nHn.[_[ [ [ ] ] ] HHHHH. [ [ [ ] ] / `HH("N \ [ [ ]__]/ HHH " \[__[ ] NNN [ ] N/" [ ] N H [ / N \ / q, \ / \ (Although it seems to vary which ones.Two ours ago only two worked. Now a few more do.)
Old things exist because once they are in use you can't just "kill them". New things exist because the old things didn't work perfectly. See: https://packaging.python.org/pip_easy_install/ https://packaging.python.org/wheel_egg/ Features in old things usually disappear (get deprecated) because they are causing way more trouble than they are worth supporting behind the scenes. Pip used to scrape a project's entire pypi html page for links to try and find a link to the package's distribution files. Yes, exactly like a simple html scraper. It doesn't anymore, because that becomes unmanageable, a bandwidth hog, a source of massive install time slowdown, a huge security issue, a reliability hole, etc, etc. Old feature that used to be nice for projects that wanted to host their distributions outside of pypi, but simply not worth supporting any more. Documentation is always hard and not always kept up with. If you're angry about not knowing how to do stuff though, there are many places to file an issue nowadays saying where you can't find information to let developers know. Sometimes making the devs aware that there is a hole of knowledge for X is the only major problem with getting that documentation written.
This is an unfortunate example of bad language design. Guido should have used a different keyword for this, e.g., `defg`. The problem is that sometimes you forget to yield or copy and paste code with a yield in it. Either mistake happens silently and is discovered at runtime. When this was suggested on python-ideas, Guido said that a linter would catch the problem provided you specified the return time as generator. It's better than nothing.
Deep Dream is for "hallucinating" images, not predicting data.
 from collections import Counter import random allowed = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'ice-cream'] c = Counter() for _ in range(10**4): c[random.choice(allowed)] += 1 print(c) We don't need counter here. You can use a regular list and pick numbers. But this is the generic solution for counting anything, not just alpha letters; which is why it has ice-cream. BTW: The computer science and Python ecosystem is very mature and much work has been done on the mersenne twister algorithm that Python uses. This isn't a computer game anymore. The quality standards for tools are *much* higher. To "prove" that it's broken when you can barely write the code to "test" it seems a little ambitious. You should instead say "Can you explain these results to me?"
Can you give a couple examples? I've used unordered maps all my life (for C++, Python etc...) so I can't really immediately see how an ordered map would be frequently useful. (Sure, I definitely can think of niche cases where it would be useful, but frequently?)
Someone didn't use parentheses with print
Theoretically you should expect the size of the deviations to be around sqrt(sample size * probability of picking letter * (1 - probability of picking letter)), so sqrt(800000 * 1/8 * 7/8), which comes to around 300. Look up the multinomial distribution if you are interested in the details, or the binomial distribution for the simpler special case where you only have two letters to pick from. Some comments on your code: * Printing text on the screen is *slow*. Your program is probably spending almost all of its time just printing out letters and numbers. Just print out the totals once at the end and it will go much, much faster. * Whenever you find yourself writing stuff like `var1=0; var2=0; var3=0; var4=0`, you should instead be using a `list`. It might take a little bit of time to get your head around, but it will make your life much, much easier, and it's absolutely one of the first things a python programmer should learn about.
When you say you checked the price the next day, how did you come to that time delay as the best metric? Do your models give different results if you look at the price with a delay of two or three days, to attempt to iron out sudden peaks?
Thanks!
Fun fact, True and False are just global variables in Python 2. So: `True, False = False, True` is possible, not many things like this though. They were promoted to keywords in 3.
Thanks so much for the recommendations. I will surely check them out! 
Yes, but instead of the entire language and all packages speeding up for free, which they would have done, now you have to consciously decide every single one of them to use fastdict if you want the benefit. 
I'm committed to tabs!
Just use it to invest other people's money, and charge a steep fee for the privilege. Win win!
 You will never feel ready to start contributing to any project because so many projects use frameworks you are unfamiliar with, or their method of accomplishing the task is unknown to you. My advice is you were always ready to contribute to a project, as long as you have a strong motivation to stick through it. We all just learn on the fly, you are no different. Go talk to the devs directly, explain your situation and they may be willing to explain what the code is doing for you, if not find another project. I've come across a lot of jerks involved in open source projects, so don't let their shitty attitude turn you away.
Which part of the code deals with that?
Thanks for the advice. I will definitely get to work on this :)
Low managed index funds, stock manipulation by the big banks, fee free trading with Robinhood, etc. Basically, don't put your money in an actively traded fund.
I fixed up my post I admit it was poorly worded. However I wanted a source or comments with complicated code that I could read for experience. I get what you mean that most code can be read by beginners but I just wanted to challenge my self with.
The easiest way to contribute to open source is to test. Use the software and report any bugs you come across. The more detailed you can be with your bug report, the easier it'll be for the devs to figure out what is going wrong. Don't be mistaken in thinking the only way to contribute is to submit a pull request.
Because the baseline is not 0% returns. The baseline depends on the state of the market, i.e. the market average. If the market as a whole moved up 5% last year but you only earned 4% return, then you have essentially lost money because, figuratively, throwing darts to pick your stocks will earn you 5% anyway.
[Pythonista 3](http://omz-software.com/pythonista) for IOS has a [GUI editor](https://www.youtube.com/watch?v=4BbjSXZnjBo&amp;t=20m7s) built in, and a really nice [native ui module](http://omz-software.com/pythonista/docs/ios/ui.html). I used it quite heavily while I was on holiday and away from my laptop. It supports both Python 3.5 and 2.7. I'd thoroughly recommend getting [Dash for IOS](https://kapeli.com/dash_ios) to complement it, and installing the [Pythonista](https://github.com/Kapeli/Dash-User-Contributions/tree/master/docsets/Pythonista) and Python2/3 docs in there.
And skulpt supports the turtle module, it's even used in one of their examples iirc 
What a shitty website. 
Thanks, 5 and 13 are updated with new tips.
Find open source projects written in python. There are many. 
Complicated code is bad code. If you want to read good code, check out Flask or Requests. Both are small, open source, and generally really well written.
There is no combination that has been proven to work. The stock market is unpredictable, however that doesn't mean all the tools we have are useless. There are some hedge funds that have done VERY well using scientific approaches (mostly physics) to consistently beat the market.
Stopped reading when I saw `print( x, y )`
I just wanted to add that having had numerous issues trying to get oy installer to work for me on a win 10 environment I gave pynsist a shot and it worked beautifully. Thank you for working on this problem and coming up with this solution. I found it quite easy to understand the setup and get something working in a matter of minutes. I absolutely recommend checking out pynsist.
It looks like something is up with ReadTheDocs (where packaging.python.org is hosted).
&gt; What's with these little jabs at the other packaging ecosystems whenever someone comes out with an article on the python packaging system? I don't think it's a jab at all? It's simply stating that when you restrict your use cases it becomes easier to solve problems (and thus appear better/simpler), but if your tool ends up going outside of that original use case then things start to get more complicated. That's not particularly a jab, that's just fact. &gt; Look at golang right now; they've been around for 5 years, and realized they need a proper package management solution instead of the (very python like) scatter of different dependency management solutions out there at the moment. It's a hell of a lot easier to add something new when you don't need to worry about backwards compatibility with something that doesn't exist already. We have over a decade of packages that we're maintaining support for while we're moving forward on trying to improve things, Go has... well nothing they need to maintain support for because they don't have an existing packaging tool they need to worry about keeping compatibility with. I don't think anyone actually involved in working on Python's packaging doesn't have a rough plan of where we're trying to go. While writing it down may make it easier for people who don't care enough to get involved to figure out where things are going, we have a limited amount of time available to us that we'd rather spend on, you know, actually improving things. You also see things like Go having actual support thrown behind it by companies willing to invest man-hours into it. Hell, google has a whole Go team. For Python packaging I am the only person paid to work any it so I am the only person with any sort of dedicated time for it. At the end of the day, we're solving a fundamentally harder problem while dealing with a decades worth of backwards compatibility and with fewer resources.
[Trinket](https://trinket.io/python) is exactly what you want. It even works on mobile. Once you've created code, you can create "share" links that you can put on another page, which show your source code and the resulting drawing. I believe it uses skulpt behind the scenes, or at least it did a year or so ago. EDIT: just checked, and they do still offer the ability to embed your creation, so it's easy to integrate into other sites!
Deep dream is for recognize patterns, you learn it how to recognize a bolt, and then you ask it to find bolts in a family pictures, and you got mommy and daddy bolt. We could use it for recognize patterns in the trading market. 
Why spaces over tabs?
&gt; Using Pandas and chunking the data? Yes. :)
Tabs can have different sizes depending on your editor settings. So person A could set their tabs to 2 characters and then hit tab twice to get the equivalent of 4 spaces, then hit save and upload to github and person B could download that and open it in their editor where it's set to tabs that are 8 spaces and the indentation will be all wonky! And tabs are visually indistinguishable from spaces, and Python will complain if you mix them, so the rule is just only use spaces and then you never have a problem! 
What a shitty comment.
is it possible that you need a subset of the data and the subset will fit into memory (e.g. there's 200 columns but you only need 5?) if so, you can choose to only read in the relevant columns.
You can first try using the CSV module if not already used it. It's tested to work with files having large sizes. And if the data is enormously large like for data analytics or so, then as mentioned by the other member use Pandas.
Basically I just need to do a group by on the various labels and output a new csv file with columns for the max and min values of the respected labels. 
Why?
Dash is a very fast, searchable, offline manual viewer. You can install "docsets" (manuals) such as the official Python documentation, the manuals for Pythonista, numpy and so forth. Very handy when you want to look things up as you work, especially if you don't happen to have internet connectivity at the time.
Shameless plug: https://github.com/peerchemist/finta Just started working on it, goal is somewhere where Waldo is right now.
That makes more sense. I see what you mean.
Regarding #21 In [1]: from math import factorial In [2]: factorial(5) Out[2]: 120
Looks good! I will definitely be playing with this one too!
Post your code.
More details on CSV module is available [here](http://cs205uiuc.github.io/guidebook/python/csv.html). It claims to read a set of large files.
&gt; The function is actually returning a tuple, but Python lets you omit the parentheses in the return statement. Not needing parentheses is not an exception. It's the comma that's essential in the tuple syntax: &gt;&gt;&gt; a = 1, 2 &gt;&gt;&gt; a (1, 2) &gt;&gt;&gt; a = 1, &gt;&gt;&gt; a (1,) Parentheses make the same difference as between `1+2` and `(1+2)`.
Dask dataframe is exactly what you want. It will provide an identical interface as a pandas dataframe as long as you only want basic operations (it doesn't reproduce the whole vast pandas API), but it will do out of core computation to ensure you keep a low memory footprint. It will also parallelise where possible if you want.
I firmly belive that if you are every handling any kind of coding, be it Python, Matlab, Bash, C, etc, you should be using some kind of source control. That includes engineers writing Matlab to computer scientists writing complex algorithms. I also think git is a great option since you *don't need a host* like the ones you mention here. You have keep git locally, or host it yourself easily (without all of the extra features of course). And git has a great and helpful community. But any source control is worlds better than no source control. With all that said, I do not think the belongs in this sub. The post isn't about Python! and only relates to Python by way of good practice for all coders
If you're removing `current_transform` and `remaining_transforms` you should compare it to def apply_all(transforms_list, s): if not transforms_list: return s return transforms[0](apply_all(transforms[1:], s)) which is still nicer. Though I'd prefer the much faster, non-quadratic def apply_all(transforms_list, s): for transform in reversed(transforms_list): s = transform(s) return s which can only be expressed with the `def` version.
As a member of the GitLab community, I can definitely recommend it. I've also run CE at my home and it's fantastic: easy to setup, simple to use, and fast to update. My school uses Github for all their projects though. I also agree with /u/jwink3101, this post doesn't really belong here. 
The second part of the example for #1 doesn't really show the chaining of the operators, since both results will be False anyway. Making the second test "1 &gt; n &lt; 20" would make it more obvious that the test stops after 1 &gt; n
Not only unexperienced python user but unexperienced programmer as well, did you just start learning?
I like http://rosettacode.org/wiki/Category:Programming_Tasks Its a site that lists simple programming tasks and presents solutions in multiple programming languages. This has two advantages: a) You can read similar code in another language you have more experience in b) The programs are self contained ; big open source projects have too many imports and dependencies to understand easily.
[deleted] ^^^^^^^^^^^^^^^^0.4398 &gt; [What is this?](https://pastebin.com/64GuVi2F/01473)
That just applies to the bundled exe installers from Riverbank. If you install via pip (apt, brew) they won't interfere. Also, you *can* use PyQt5 with Python 2.7 it's just not officially supported (so no installer available from Riverbank). It should be available in Linux and Mac (via Homebrew). There is a 3rd party Wjndows Pyqt5/Py2 installer online somewhere, but if you have the choice just go with Py3.
Ah yeah, I had learned this at some point but I guess I had forgotten. Usually, I think it is better stylistically to include the parens. When returning in a function, leaving them off is okay, but I wouldn't fault anyone for including them either.
I'm not as confident. Also I was lazy with my language—I meant the entire dict implementation rather than just the hash function. In any case, I would say that the compact dict implementation which led to this particular ordering side effect is evidence dict implementations'll sometimes be a bottleneck or efficiency consideration to be rethought and improved.
Usefull :) some are pretty basic, but maybe unknown.
Thanks for this.
now that github offers unlimited private repos with a $10/mo plans there is zero reason to look elsewhere. bitbucket still doesn't have code search for fucks sake. gitlab is nice but dog slow.
Sure. But what you just wrote has no bearing on what you replied to. 
(29) [There are other ways to flatten a list.](http://stackoverflow.com/questions/10632839/python-transform-list-of-tuples-in-to-1-flat-list-or-1-matrix) Some methods have different performance and some are clearer and don't require importing anything. (30) Please use a [default dict] (https://docs.python.org/3/library/collections.html#defaultdict-objects) instead. Python has a wide array of useful data types. They should be looked at for anyone who wants to improve their python. There are also a lot of great Python books for intermediate Python. Some of them you can find by googling "intermediate Python." I personally really like Effective Python. 
Yes that's right, my point was mainly that there isn't a lack of expressiveness in the multiline lambda. Niceness is a function of one's personal tastes, I happen to think the multiline lambda is "nicer" from the perspective of expressiveness while the "def" syntax currently has greater readability. def apply_all(transforms_list, s): for transform in reversed(transforms_list): s = transform(s) return s This is only faster because of the inefficient list slicing at every step of the multiline lambda and the lack of tail call elimination in python. If the list slicing reused underlying memory and tail call elimination was in place, the performance characteristics should be identical between the two pieces of code. In functional languages, the lack of iteration (for, while, do) is common (Erlang) and is replaced with tail recursion. In general I agree with you though, for the time being the def syntax is still all around 'better'. This was an experiment intended to push the envelope and discover python's internal capabilities. There's a lot of practical limitations in the multiline syntax. I think one area where it does better though is in nested functions. For example: def outer(): def inner(): x = 1 return x outer.inner = inner vs def outer(): outer.inner = () &gt; (x &lt;&lt; 1, x)
Yeah, I gathered that's what you meant. I think it's less likely to happen again, because the faster the implementation gets, the closer time spent doing dict operations gets to 0, and the less effect even dramatic speedups will do (if programs tend to spend 10ms for every second in total on dict operations, then even a 1000x speedup for dict operations means only a .1% speedup in total). But they haven't yet decided, so there's still time to discuss what the best course of action is.
Does it use? import __future__
Fairer comparison: def outer(): def inner(): x = 1; return x outer.inner = inner # def outer(): outer.inner = () &gt; (x &lt;&lt; 1, x) --- Alternate fairer comparison: def outer(): def inner(): x = 1 return x outer.inner = inner # def outer(): outer.inner = () &gt; ( x &lt;&lt; 1, x ) --- I happen to think the border between single statements that can be used in `lambda` and longer statements that are better with the full repertoire of function syntax (and normally deserve a name anyway) to be particularly small, at least in Python.
My office needs this.
Assuming the Mersenne Twister produces very high quality PRNG bits/bytes, the rest is implementation details. Assuming Python coded it correctly in C, looking at the Python code, `random.choice(seq)` gets a random integer below `len(seq)` (code appears faultless) from [`random.Random._randbelow(n)`](https://github.com/python/cpython/blob/923a556/Lib/random.py#L222). There's some extra guard stuff in the method for weird stuff...but usually it seems to do: # maxsize is 1&lt;&lt;53, or the number of random bits that random() returns, # a float from [0,1). I'd guess 52...but 4 quadrillion, 8 quadrillion...whatever. rem = maxsize % n limit = (maxsize - rem) / maxsize # int(limit * maxsize) % n == 0 r = random() while r &gt;= limit: r = random() return int(r*maxsize) % n I don't know what `rem`/`limit` is for, but it comes into play when `n` gets somewhere near `maxsize`, i.e. billions/trillions, so the crux of it seems to be: `int(r * maxsize) % n`. `int(r * maxsize)` is extremely large, basically a random 53-bit number. If `maxsize` is incorrect relative to what it should be, the least-significant bits won't actually be random, so then `% n` would expose that *very clearly* if n is a power of 2. 
Thanks, I'm glad it worked for you! :-) If it's something you can talk about, can I ask a bit about the project you used Pynsist with? What kind of task is the application for, and what technologies is it built on? I'm interested to hear about the scenarios Pynsist gets used in.
[deleted] ^^^^^^^^^^^^^^^^0.7587 &gt; [What is this?](https://pastebin.com/64GuVi2F/61404)
How large? BigQuery?
&gt;final release planned for Dec. 16th ok
You should post this question in /r/learnpython. 
All the libraries you mention expose interfaces for taking locks. Locks have various granularities. I'd never actually encountered begin transaction exclusive before. There's a reason for that, though: it's a huge hammer. It means the db only does one thing at a time, which is almost always a terrible idea. I'm guessing the use case would be seriously heavyweight maintenance activity, but apart from that I'm not sure what you'd use it for. Is it even standard SQL? Sounds vendor-specific to me. Non-standard extensions are usually exposed by libraries in some manner which makes you feel dirty about using them. There's a reason for that too, though. Locking is normally done with row locks, which means non-overlapping updates on the same table won't block each other. Done correctly, this is entirely safe in all the cases you mention. Look for "select for update". There are also table locks, but these also come with severe concurrency penalties.
There is a general rule of thumb for Pythonic code that says that a function or method should either mutate the object passed and return nothing (i.e. return `None`), or it should return a new object and not touch the object it was passed. This is not a hard and fast rule, as it's not always practical, but it's the pattern followed by most of the standard library. For example `list.sort()` sorts in place and returns `None`, whereas `sorted()` creates and returns a new list. Many types in Python are immutable and cannot be modified, so returning a new object is the only option. Numbers, strings, and tuples are the most common immutable types. As to whether you assign the return value to the same name or to a new name doesn't really matter. I guess it's a stylistic choice. Using a new name is probably slightly more readable, but I wouldn't really sweat the details. Also, don't read too much into performance. For example, strings are implemented in native C and so returning a new string is probably faster than a naive class written in Python that tries to work with mutable buffers. But it depends on what you're doing. The point is, you can't just say that returning a new value is always slower. Python is so far removed from the low level details that there are tons and tons of things that can affect performance. (Also, CPython is the default implementation of Python and is not particularly high performance. You're probably thinking of Cython.) Your second example is just someone being clueless. There's no reason to use `readlines()` if all you're going to do with the resulting list is iterate over it. 
I haven't worked much with the csv module, do you have any suggestions where I can find some examples?
Although for command line handling of JSON, I would strongly recommend [jq](https://stedolan.github.io/jq/).
Yep. OP, please be careful when giving advice that you don't give bad advice. Not only is writing math.factorial() much cleaner and easier to read, it's also around an order of magnitude faster. http://hastebin.com/pukedaroya.py
Yes, I've done so for 7+ years [as my resume shows](http://metaperl.org/resume).
Not impossible, but unlikely. And if they did hire you as a junior dev, they'd want to train you up in other skills as well once they got you there. Even if you were going to work alone as an independent contractor, it's unlikely you'd be contracted for a project that didn't involve knowledge in things alongside python. If you plan on being a sysadmin type of role, you'll probably at least need to be really good with back end python as well as being comfortable working in a terminal. If you're looking for more application development, you'd really need to have some familiarity with SQL and javascript to be able to do work on both front and back end development. In this day and age, if you're going to be a developer( a good one at least), it's typically not good enough to be knowledgeable in only one language or toolset. Best bet would be to figure out what kind of work you'd be interested in doing with python, search around for python developer job listings, and see what other technologies or languages they want people to be familiar with. 
Yes, with the caveat that it depends on how strictly you mean to define "Python only." You could, for example, be a highly valued team member on a web development team building a web app back end written in Python. Python today is perhaps more popular than ever for server side web app development. I know of entry level devs earning six figures (in Florida, no less, not a hotspot LA or NY). However, the most competent and effective web developers also know a good bit of JavaScript, HTML, CSS, and SQL.
Thanks for the recommendations. Lots of good advice in this thread. I'm currently working towards improvements!
jesus that is impressive. How were you able to make it as a freelance consultant in Southern California.? who did you talk to or know for gigs?
Hi there, Your inputs are read as strings, and not integers. Check out this link for more info! http://stackoverflow.com/questions/20449427/how-can-i-read-inputs-as-integers-in-python
Agreed about the first point: The itertools method splits strings, too. I use Python with Hive command line, and sometimes have nested arrays; that was not the result I wanted. 
&gt; cursorclass='pymysql.cursors.DictCursor' There's your problem. You need to pass the class, not the name of the class as a string. Internally to pymysql.connect, it's attempting to do `cursorclass()`.
thanks, that worked :)
Ah, okay. Makes sense then, thanks! 
In python if you do: x = 5 Then: x = "some string" Then print x, it would say some string. You can do the same with object "on the fly" a well, do yes you can.
I know you're joking, but: In [1]: __import__('math').factorial(5) Out[1]: 120
Do a for loop over the switch dictionary and there u go, you got your fall through and implement a else clause for the 'for' Loop to land the default value. Ezpz
Functions in python are objects, so you can simply reassign the use method if you wanted. If you have some function newthis, defined elsewhere you could just do weapon.use = newthis Same thing for adding new methods: def holster(): do_something() weapon.holster = holster 
&gt; small = a if b &lt; c &amp; c &gt; a else b if b &lt; c &amp; c &lt; a else c If you do that I will hunt you down and hit you with a trout!
&gt; zero reason &gt; $10/month Mmmmmk
&gt; ... most likely I couldn't think of the right keywords. Search for python metaprogramming. It should answer most of your questions. In case you need to mess with imported modules, check importlib. Further, you can go all the way down to metaclasses and interpreter internals.
When I first stumbled upon Python... there was only P2, which I believe was an upgrade. And then there came P3, which I assumed was also an upgrade from the previous one which is P2. But it didn't seem that way. I'm still very knew to this. 
You required people to click on a link that appeared to be a meme to get to a tutorial? Also, the title seems completely disingenuous.
How easy is GibLab CE to run?
Yes, proprietary models based on advanced mathematical and statistical models. Not technical analysis. And the fact that you're comparing hedge funds to the market means you don't know what hedge funds do--they're supposed to be mostly uncorrelated with the market, so it makes zero sense to compare them to the market. The tools are considered useless until someone shows otherwise. That's how scientific thinking works.
Lol...
By that metric I was a Python only developer too. I used my Mechanical Engineering degree and knowledge of the niche programs CANape and dSpace to write Python modules. Even though Python was probably 1/10th of what I needed to know to do the job.
Without looking at your resume, I'd be very surprised if you don't know and use at least some of: Bash/powershell SQL HTML Etc...
Probably the most painless thing I've ever done with Git and Linux. I'll lay it out in the shortest amount of steps: Make sure you're using a supported Linux distro (I used Kubuntu). Go to the download page and download the omnibus package. You can build from source, but then you have to go through all the dependency crap, and I was still a fairly new Linux user at the time. Run the omnibus package. Let gitlab CE install and keep your eye on the output in case anything comes up. Once the install finishes, all you really need to do is get the service running (I think it does this by default, or by running `linuxCommandHere gitlab-ctl restart`, it's in the docs and tells you at the end of the install) and you're good! Then go to the IP of the machine and you can log in just like you would on gitlab.com. Updates are easy, as they show up in `apt-get update` and there is always a .X update on the 22nd of every month, with patch builds every couple of days or so. An update is usually a 270ish MB download, with a minute to actually upgrade. I ran all this on a 2011 Mac Mini. There is one file you may need to edit, I can't remember off the top of my head, but it lets you redirect where the project database is stored, and most importantly, set the web address of the server. For myself if was http://servermini/ and then in my hosts file on my local machines I added that as an address so the repo address would be http://servermini/user/project.git vs an IP. 
gitlab and docker are probably the easiest full featured option
docker if you can
Three paragraphs of instructions and caveats is the most painless? GitLab has an absurd amount of dependencies, which is always a great recipe for failure in my experience.
In an ideal world. For simple stuff, this works just fine
Knowing python doesn't guarantee employment, no. The metric you want to measure yourself with is whether you can solve problems someone needs solved and is willing to pay for. Besides, knowing only one language is like marrying the first girl you kiss. Just don't.
Calling yourself a "python only" developer is practically a malicious misrepresentation to the OP. Your resume is not remotely what they're talking about. 
Tip 22 has quadratic running time, whereas you can do it in linear time with a more standard technique like using a Counter. Please don't advocate programming tips unless you actually know what you're doing; there's enough bad advice out there already. Edit: I was looser than I should have been with terminology. Given n items, of which u are unique, tip 22 runs in O(n*u), whereas using a Counter does it in O(n + u).
You'll get a lot more help on /r/learnpython. This sub is more for python language announcements and discussions. 
You'll get a lot more help at /r/learnpython. This sub is more for language announcements and discussions, while /r/learnpython is for questions. 
One example is when you want to build an argument parser that cares about the order of arguments (say, you are passing remaining arguments to a new program). If you preserve order you can focus first on getting all the args into a dict and then worry about what they mean afterwards -- all with a single data structure (yes, I'm familiar with argparse). Let me be clear--I know that you *can* solve any problem without dict ordering, you just don't realize you've been resorting to "work-arounds" until you have it available. Once it is available you realize that it saves you effort in some significant fraction of scenarios (maybe 10-20% of scenarios naturally use ordering).
I've been using GitLab for a couple years since they were the only ones who had private repos for years. They've been getting better and better at almost a monthly basis. There used to be some things I missed from GitHub, but... now there's none. In fact, my company uses GitHub and I find myself missing GitLab features while I'm working. GitLab really does a great job. Plus they're unlimited private repos now! GitHub still has 0. I'd never heard of "Coding" before - is there an English version? I can't seem to find it on Google after an exhausting 7 second search, but the generic name doesn't really help.
I had to click an additional link to view your resume. I also had to click an additional link to get to "why I don't give references" (it leads to a page telling me to click another link to get to your article.) What gives?
I had the same problem, "Coding" is quite a generic name. Their website is https://coding.net/ . Only their WebIDE has English UI. https://ide.coding.net/
https://docs.python.org/3/library/csv.html
DICKHEADS call their own videos "awesome".
I can see the reason behind posting it here, it's just this is sub is really meant for "Python" specific tasks if one is to get technical about it. It's a great post, nonetheless! Thanks for sharing :)
No data is sent to anyone else's server. You run the server, and the web browser communicates with your server.
The CSV module can open, read/write and close CSV files row by row. Pandas does not. Use the CSV module for your purposes.
Thanks for the code snippets and neat tricks. You could add a little more explanation though in a few of them.
Definitely this! ^ It'll be easy for people to create issues, comment on them or send pull requests.
These all can by self hosted no? Subversion for example can be.
Very little - a great way to start is by contributing to bug reports. If you haven't found your own, reproduce bugs that others have reported - and add more detail! (Seriously, maintainers love people who submit detailed bug reports) Eventually you'll describe the cause of a bug in enough detail to think "I know how to fix this". *Submit the bug report anyway*, and then make a pull request that you think fixes the bug. (test your fix too) You can think the same way about feature requests, or even new projects - the key is to get involved with the community, and start small.
[deleted] ^^^^^^^^^^^^^^^^0.3728 &gt; [What is this?](https://pastebin.com/64GuVi2F/68216)
It is just wrong. Consider a, b, c=1, 2, 2.
Are you freelance developer or work in an organization only for few months?
I always just reference my history with _x. Based off of the _ variable, where x is the line number you want. In [1]: 1+2 Out[1]: 3 In [2]: _1 Out[2]: 3 In [3]: Out Out[3]: {1: 3, 2: 3}
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
It was Linux to Mac over WiFi.
In the "implementing a switch statement"... why? Why not just make a dict `xswitch` and use direct index access? You're just replacing `xswitch.get(some_key)` with `xswitch(some_key)`. It's easy to read already. You don't need to specify None as default in the second positional arg either, because it already is by default. The only time I wrap a function around a dict is if I have something weird that a defaultdict isn't going to solve and there's a few special cases that can't be done with the dict. A dict is such a primitive in python that you probably shouldn't be wrapping it up in a function just to give it a `__call__`interface. I could see doing that if you know down the line you're going to have more complex logic and it prevents you from having to change all your `xswitch[key]`'s to `xswitch(key)` and write the function, but usually it'd be better to assume it'll stay simple than prepare for complexity ahead of time.
Thanks for this. But just curious to ask, if the tip given is a notch closer to C/C++ like enums rather turning it into a function which has its own overhead. And it looks much finer to use class statics as enums.
The only thing you can become an expert about in 22 hours is making ice cubes. 
Without knowing other programming languages? Possible. Without ANY other skills? Unlikely. Invest in other job related skills - be it data analysis or testing, system administration or web dev, and you'll be fine.
Not sure how much it will help, but you could use itertools to iterate over the list without creating a new list. from itertools import chain def flatten(listOfLists): "Flatten one level of nesting" return chain.from_iterable(listOfLists) frequentTokenCounter = Counter(flatten(A)).most_common(X)
It can be summarised as "on a supported distro, [install the omnibus package](https://about.gitlab.com/downloads/)".
&gt; Something like x, y = y, x actually creates a copy of both x and y, plus the overhead of the tuple (which the author does mention). So not exactly "in place" It certainly doesn't create a copy of *either* of them, not in Python. And thanks to the peephole optimiser, it also doesn't actually build a tuple. You can verify this with the `dis` stdlib module: &gt;&gt;&gt; from dis import dis &gt;&gt;&gt; dis('a,b = b,a') 1 0 LOAD_NAME 0 (b) 3 LOAD_NAME 1 (a) 6 ROT_TWO 7 STORE_NAME 1 (a) 10 STORE_NAME 0 (b) 13 LOAD_CONST 0 (None) 16 RETURN_VALUE 
Pretty much no. I am mostly a python developer, but I had to deal with around 10 languages, including javascript, fortran, C++, powershell and soon typescript. Remember that programming languages are pretty much close to each other within some classes. When you know a few, you pretty much have only to learn the diff between them, so it's easier. The big deal is the environment (libraries, frameworks, build system etc)
&gt;I know several languages though You slut!
Since you mention Maya specifically in a later comment, be warned that you need to build against the Maya version of Qt which is modified from the source Qt. I'd recommend sticking to PySide2 or Pyside depending on which version of Maya you're using. I also recommend using: https://github.com/mottosso/Qt.py It lets you abstract the Qt implementation you're using. Re the installers, I'm not sure why they have that limitation but I think it only applies to the riverbank installers and wheels and building from source etc should be fine. Though I recommend using Anaconda instead: https://www.continuum.io/downloads and use conda to install PyQt4/PyQt5 if you go down the PyQt road. It's much simpler.
The purpose was to give an example why I would want to change a function, it's a good practice to keep these kind of things in a attribute anyway. The reason I want to do that is because whenever a little bug's fixed or something new is added, I don't want to have to disconnect players each time or cause lag while their connections are transferred to the newly started version.
I didn't like (the start of) your article, but I like you now :) That's a great attitude!
Quoting the documentation: &gt; The mode is unique in that it is the only statistic which also applies to nominal (non-numeric) data: &gt;&gt;&gt; mode(["red", "blue", "blue", "red", "green", "red", "red"]) 'red' It actually uses a Counter behind the scenes. The only difference (aside from being able to write more direct code for what you want) is that `statistics.mode` raises an error if your distribution doesn't have a unique mode, whereas `Counter(data).most_common(1)[0][0]` will pick one arbitrarily. 
I honestly did not know that one; I was thinking semicolon.
Honestly the useful info in that site is already known for me, and I have been writing python actively since Dec 2015. Not impressed.
Many people make a surprisingly good living by specializing in some obscure niche - as long as there are people willing to pay a premium for someone with that skill. If the niche uses tools that are mostly in Python, it might work for you. I don't think the niche can be python itself. It does not really define a specific vertical slice of some industry that can be addressed as a market. It is a very general-purpose tool that is used for a wide variety of tasks.
You can set vmin and vmax to set the limits of the scale, at least with pyplot.imshow() - I'm suree there is something similar with contour plotting.
&gt;Works only on Python 2.7
Sped it up about 100 times. Thanks! I know this may be the wrong board but can you explain why that is so much faster?
When you come from advertising maybe you could at first be the connection between customers and developers. This way you have the opportunity to look them over the shoulder and learn what it takes to be a developer. If you still like it ask if you can solve a little problem, bye coding it up in your free time. Now you have a chance to surprise them with a good job. Tell them that you could do this more often, it makes you better understand the problems the developers are facing and therefore makes you better in your job towards the customer. At some point try to ask them to work as a full time dev or apply at a different company telling them that you did development and customer care but you found your real strength is coding. On your way there you can learn much more than Python. But to be honest I don't know if that will work or not.
Unless people are relying on `dict`s NOT having the same order each time, nothing should break. This is changing the implementation of `dict` so that it becomes ordered, and shouldnt have anything to do with hash seed randomization
Looks like 2to3 can help you move to 3. Print statements and raw_input. 
I work for consulting agencies (unfortunately) for an hourly rate. I wish I had salaried employment, even if it were with a consulting agency. Hourly contractors can get cut or furloughed at any time. 
I've known some people who have done it, but it's fairly limiting. Learning HTML and CSS (which are pretty simple) and javascript (which is similar to Python from many respects) would enable you to work on the front and back end of web applications, and there's decent demand for that. I've also known people who could get jobs with just python experience, but a willingness to learn more languages. If you come off as a one trick pony, nobody will be that interested in hiring you. If you seem like a green developer who has a lot to learn but seems capable, you're more likely to get a hiring manager's attention. 
well, that's actually a neat trick when you need dynamic switch-case. I use it quite often.
Seems like the user moving the mouse should be slow enough to not matter....
&gt;"Python only." &gt;six figures &gt;entry level devs &gt;in Florida I need to know more about this. I have been wanting to transition into working in Python for a bit now. Currently my company uses it in small scripts and simple applications, still most of the work is with C/C++.
holy buzzwords lol
I don't get paid to write Python. I get paid to solve problems. Python just happens to be one of the tools I use.
I haven't gotten around to using 3 yet. Im a beginner and this is my first project. 
Like a polaroid picture?
Nice! Saved it for later. I also recommend David Beazley's talk here https://youtu.be/E-1Y4kSsAFc which was a nice intro to using async and await
Python int is a little different from standard int in other languages. In Python, an int is a well-formed object. It means there's an extra overhead. It's the reference count and a reference to the object's type in addition to other storage. That's why it consumes a lot more than the usual integers. I would welcome if anyone else can bring more insights.
Wow, that's really cool. Thanks.
Wow!! Nice video. Thanks. By the way, some notes came from David Beazley's previous talk. :) https://www.youtube.com/watch?v=ZzfHjytDceU https://www.youtube.com/watch?v=5-qadlG7tWo 
Well, if I can do it without having any of these problem in Python, I will prioritize learning Python. Otherwise, I can just start doing it in Java. So, right now it's the perfect time to worry about those.
Fixed an issue that broke this on python3. Deve release should work on python 3. otherwise run on 2.7!
Seems that you want to do *hot code reloading* or *hot swapping* in your game. I've seen this easily done in Lisp like (Scheme, Clojure, Common Lisp) languages and a bit more difficult in Java, C, C++ and C#. Here is an example in Python https://github.com/hoh/reloadr
Yeah I don't disagree with anything you said, but all the detail did make it sound quite 'involved'.
https://code.google.com/archive/p/livecoding https://bitbucket.org/petershinners/reimport Something like this? 
&gt; (29) There are other ways to flatten a list. Some methods have different performance and some are clearer and don't require importing anything. 'Not importing anything' seems like a strange advantage when your next advice is to use `defaultdict` instead of `dict.get`. Also, chain has the advantage over most of the other methods in that post that, a lot of the time, you don't actually need a *list*, just an iterable. Even when you do need to build the list, `chain` and the list comprehension method will have better performance characteristics than `sum`/`reduce` based methods, especially as the number and length of lists you're merging grows, since you avoid building and tearing down multiple intermediate objects. It also likely that if chain exposed a [`__length_hint__`](https://www.python.org/dev/peps/pep-0424/), then it could be faster still. 
&gt; You slut! Perhaps - but I am not an *ignorant* slut. 
I think you are misunderstanding what that function does. The [type function](https://docs.python.org/2/library/functions.html#type) returns a new type. So when I call __enum() I get back a new type called "Enum" (the first param), with no base class (the 2nd parameter), with writable attributes of whatever I passed (the 3rd parameter). Continuing my original example: def __enum(**enums): return type('Enum', (), enums) nums = __enum(ONE='one', TWO='two') nums.ONE == 'one' # True nums.__name__ == 'Enum' # True In other words, it's exactly what you want: static class attributes.
For #36 - sure, you want a function that stringifies its arguments before it prints them. That *is* somewhat useful. But say you want to change what gets concatenated between each argument, or whether a newline appears at the end, or you want to send stuff to STDERR instead. Here's a better function that handles all of that: print 
poor ass mfucker
that's great, I mainly used that logic to handle that `count==float('inf')` case, never thought using islice. regarding `--cover-file-config`, I was working under virtualenv and so I have included nose master in requirements.txt If the tests are still failing submit PR in gitlab which will run tests for your PR inside gitlab runner. PS: sorry I couldn't reply soon. but I'll wait for your PR. 
Learning how to play with source rewriting is fun! This syntax and others have been proposed and rejected multiple times over the last two decades... BTW, the answer to the multiline part is simple. Any python expression can span multiple lines without backslashes - just wrap it in parentheses 
Lol? There's a good reason why domain knowledge is required in data science, and this is one of them. Pretty much all academic literature in finance points to technical analysis as being useless. Hedge funds are supposed to be uncorrelated to the market and have no beta. Hence the name, HEDGE funds. I'm saying this for your own good. Edit: not to mention that hedge funds are not required to disclose performance, so the only ones posting their performance are the ones with exceptional returns. The bad performers stay quiet. Selection bias at work.
Python (and ruby, lua, js, ...) don't support code reloading without jumping through some/many hoops (being careful about what you are going to reload, how you import or update it ...). OTOH, some statically typed/compiled languages/platforms support limited reloading - provided you respect some constraints, such as class/interface/method signatures. Synchronization is universal problem. The only [used &amp; usable, batteries included; AFAIR] languages that comfortably support code reloading are: Smalltalk, Common Lisp, Factor &amp; Tcl (Factor &amp; Common Lisp support gradual/optional typing)..
Sets are basically implemented as hash tables, so it only takes the time to compute the hash of the string to see if it's in the table (set) or not. This operation will always take the same time, regardless of the amount of tokens in the set. The list on the other hand has no order, so the interpreter must run through (at worst) all the elements in the list to check whether a string is in it or not, which may take a long time for very long lists. If you want more info on how hash tables work, wikipedia has a great article on the subject. https://en.wikipedia.org/wiki/Hash_table
Some people can find themselves in these situations due to a talent shortage, but that means usually no promotions because they can't find a replacement. But if there is a surplus of talent, your employer will expect more. Best to hedge your bets and diversify. Doesn't mean learn every languages in and outs, but just the tip ;)
Nono that's another project. This is the one called Waldo.
Well thanks for the advice :) I think I'll continue to work towards improving my model however and addressing the concerns raised by this wonderfully helpful thread. I'm certainly not going to just give up because some guy online says the stock market is impossible to analyze.
Actively traded funds performed better than usual, such as in the 2008 crisis, but iirc only around 50% beat the market, so like flipping a coin. Think of the distribution of returns as a lognormal distribution. Any management and transaction costs shift the mean.
I was talking about &gt; In my repository I have a program called DataCrawler which I use to scrape Fidelity. I don't see it.
There is a difference between perseverance and being delusional. It's not just some random guy's opinion, but the resounding consensus of the academic financial community. It's the equivalent of saying "global warming is a myth" but for finance. Tbh you sound pretty clueless about finance. You need to learn actual finance before you start trying to build a model. The market in the US, at least, is pretty darn efficient. If you can get superior returns just by running SVMs, it would've been priced into the market already by the big players. Here's a piece of advice: domain knowledge is really important. In my work, I can spend a whole week just trying to understand the data and researching the field before I even touch the ML algorithms. Lack of domain knowledge leads to shitty models. Feel free to keep working on your model, but do so only after you have learned the financial theory and math behind it. K, not gonna bother after this. Edit: well I do feel bad if I make you feel discouraged. Good job on the script, really. Do it for fun, feel free to try your model using small amounts of money. But do not invest significant money in your model.
 I have implemented hot reloading on two AAA games. The basics are fairly simple, as pointed out by other replies, but getting the reload to be 100% reliable is extremely difficult. For this reason, we have only used hot reloading as a development tool - it would not be something I would recommend for a production environment. From the first project, Jon Parise has open sourced the reload code: https://github.com/jparise/python-reloader The implementation we used deviated from there a bit. We flipped the direction of the dependency tracking, extended the `__reload__` callback to have a pre- and post- reload callback, and also added hooks to objects that needed a reload callback. We also blacklisted a large number of core modules. This gave us a decent success rate, but still had problematic areas (pointers to modules, reloading metaclasses, and reloading objects referenced by Stackless Python's internals). In my current project, I decided to rely on object serialization to make the process more reliable. Reloading serializes each game, reloads all gameplay modules, deserializes the games which picks up the new code, and then passes a reference to the old game to each new game allowing it to transfer things like live client connections. This approach makes it more reliable, because it avoids those problematic cases I called out above. However, it is by definition limited to the subset of the game that supports serialization. Since we only support this feature to speed up gameplay iteration, it felt like a reasonable tradeoff. Also, supporting serialization is a significant ongoing cost. I wouldn't suggest implementing it just to allow hot reloading. Happy to answer questions if you'd like more specifics.
How confident are you that you'll need to handle files larger than 2GB in the future? This may be a YAGNI (You Ain't Gonna Need It) situation. I'm constantly surprised by how much data can be handled by a totally naive, read-it-all-into-memory solution - that's now my goto approach until I've proven it won't work. Developer time is expensive - even if the data does get huge, it's probably much cheaper to rent an hour of time on an EC2 instance with lots of RAM than spend much time thinking about how to stream process CSV (even though stream processing CSV isn't actually that hard).i
if works_only_on_python27: pass
That automated build thing sounds like it would be nice. 
If you don't have a more senior member in your organization that can help you this, then you'll have to share your code repo (if you are allowed to do that, be careful here) for others to see. I don't actually know of any specific code review subreddits, although I guess this exists: https://www.reddit.com/r/codereview Maybe try /r/learnpython too?
A quick note about asyncio to eliminate some beginner confusion. Asyncio runs tasks concurrently, meaning that it essentially provides a fancy loop for running a bunch of functions without each function having to complete before the others are allowed to continue. This does not mean that the functions run at the same time, as the Global Interpreter Lock restricts the Python process to a single thread. In order to run functions in parallel; that is, at the literal same time; you have to use a library like multiprocessing that can break out of the GIL. Asyncio is great for some things, but *it is not a magical solution to make code faster.* Multiprocessing can be messy, but it is the only way to get performance gains in situations like socket servers (as multiple clients can be served at the same time).
Link your github
Got my first programming job in the DC area around $70k (before that I had a CS degree but spent 10 years teaching and hobby programming) and now three years and two jobs later I'm at $110k. I'd say $120k is an incredible starting salary, although since you already had 10 years of other experience maybe you don't feel like it's your starting salary. Of course, in the DC area, housing prices are totally out of control, so you can't even really be comfortable unless you win the lottery.
Git is also great to manage your tex files. 
That's a good point I didn't consider too much: maybe If you got the foundations of programming itself down, a new language is not as hard as the first one...
*how* large? There's a world of difference between 8 GB (doable in memory) and 3 TB (realistically, not doable in memory unless you have a lot of money to spend).
Great idea. I will implement all of this, including 'profile.sh' The idea here being (just to confirm) that I'll "cd" into the proj1 directory and simply type "profile.sh" and it will run the "source Proj1/env/bin/activate" command to activate the virtual machine -- Awesome, this is great advice!! Thanks ________ Edit-- alright, I gave it a shot. I'm having difficulty running profile.sh here is what I have in profile.sh: source env-djangoProj1/bin/activate I found this askubunutu thread: http://askubuntu.com/questions/38661/how-do-i-run-sh-files which suggests: &gt;Give execute permission to your script: &gt;chmod +x /path/to/yourscript.sh I understand that this linux command allows me to execute (x) the script. however, it's not working for me... Here is what i have in my terminal: ~/localhost/pythonProjects/djangoProj-1  profile.sh zsh: command not found: profile.sh ✘  ~/localhost/pythonProjects/djangoProj-1  ls blog manage.py resources for project.txt db.sqlite3 mysite env-djangoProj1 profile.sh ~/localhost/pythonProjects/djangoProj-1  profile zsh: command not found: profile ✘  ~/localhost/pythonProjects/djangoProj-1  chmod +x profile.sh ~/localhost/pythonProjects/djangoProj-1  profile.sh zsh: command not found: profile.sh ✘  ~/localhost/pythonProjects/djangoProj-1  profile zsh: command not found: profile ✘  ~/localhost/pythonProjects/djangoProj-1  ./profile zsh: no such file or directory: ./profile ✘  ~/localhost/pythonProjects/djangoProj-1  ./profile.sh ~/localhost/pythonProjects/djangoProj-1  ./profile.sh ~/localhost/pythonProjects/djangoProj-1  ls blog manage.py resources for project.txt db.sqlite3 mysite env-djangoProj1 profile.sh ~/localhost/pythonProjects/djangoProj-1  source env-djangoProj1/bin/activate (env-djangoProj1) ~/localhost/pythonProjects/djangoProj-1 The last command I ran was just to check that the venv was starting correctly (and that I had the right command) -- seems ok. My only problem is that I haven't figured out how to get the shell script going... _____ edit: Ok, i realized I forgot to add the shebang line to my shell script. I now have the shell script looking like this: #!/bin/bash source env-djangoProj1/bin/activate but as you can see below, it's not working... ✘  ~/localhost/pythonProjects/djangoProj-1  sh profile sh: profile: No such file or directory ✘  ~/localhost/pythonProjects/djangoProj-1  bash profile bash: profile: No such file or directory ✘  ~/localhost/pythonProjects/djangoProj-1  bash profile.sh ~/localhost/pythonProjects/djangoProj-1  ~/localhost/pythonProjects/djangoProj-1  zsh profile zsh: can't open input file: profile ✘  ~/localhost/pythonProjects/djangoProj-1  zsh profile.sh ~/localhost/pythonProjects/djangoProj-1  when I run 'bash profile.sh' or 'zsh profile.sh' it seems to run the script (no error output) however it doesn't actually activate the venv... so, I know I'm getting closer...
I'm not sure I fully understand your question, but I might write it something like this to keep "globals" at the top: x = 7 def main(): application = tornado.web.Application([ (r"/test", Example) ]) application.listen(8080) tornado.ioloop.IOLoop.instance().start() class Example(tornado.web.RequestHandler): def post(self): self.write(x) if __name__ == "__main__": main() But that's just a style thing (imports, then globals, then the main procedural "routine," then the rest of the damned code). Anyway, wouldn't just defining a class attribute also work, and be cleaner? Isn't that what you would do in Java in the first place? def main(): application = tornado.web.Application([ (r"/test", Example) ]) application.listen(8080) tornado.ioloop.IOLoop.instance().start() class Example(tornado.web.RequestHandler): def __init__(self): self._x = 7 def post(self): self.write(self._x) if __name__ == "__main__": main() I'm just spitballin' and I haven't tried any of this.
Python 3.5 no longer requires `@asyncio.coroutine` or `yeald from`, you can use new `async` and `await` keywords.
This could work. I need to make a message queue connection in the setup method, So I only want to do it once, and then have the channel variable available to be used in the routes. So i need it to create only once, but still have access to the variables representing the connection.
Yep, this is exactly the kind of thing factory functions are used for!
Re: second example - ah, good point. I have the same (lack of) understanding. Here's the code that I got to "work," but I'm probably leading you down the wrong path anyway. :-) Please post the correct answer when you figure it out! #!/usr/bin/env python import tornado.httpserver import tornado.ioloop import tornado.options import tornado.web def main(): application = tornado.web.Application([ (r"/test", Example) ]) application.listen(8080) tornado.ioloop.IOLoop.instance().start() class Example(tornado.web.RequestHandler): def __init__(self, *args, **kwargs): self._x = 7 super(Example, self).__init__(*args, **kwargs) def post(self): self.write(str(self._x)) if __name__ == "__main__": main() 
Thanks, I really appreciate
Im still learning, but so far I have a script that uses wget, to download files from a txt file. I even managed to create a simple GUI "Chose file" to open it and download the files, that script saves me around 2 hours of work per day. Also a selenium script to automate the form filling of our HR system. Latest, a Selenium script to help fill some forms while looking for jobs. 
You can hit 90 days with the master branch for the investopedia scraper for historic data and run those in parallel processes. If you look at the stock market analysis branch on the project I've recently added a parameter you can pass for the investopedia historic data function that will get up to 5 years of data for the stock. I've been able to run the scraper for investopedia with as many as 10 parallel processes using pool(see demo scripts for example) with no problems. Haven't used Yahoo's CSV option for awhile but I might revisit that to see about getting historic data for more than one stock at a time. I did run in to data limits when using their YQL endpoints if I queried for too much data at one time so I spent the extra bit of time scraping multiple pages of quotes from other sources instead of figuring out how to circumvent that. Using a pool of 10 worker processes I can download about 90 days of historical data for 6500 ish tickers in about 20 minutes. I haven't seen any throttling from them or yahoo, but I have had nasdaq.com block me out for a few hours at a time if I hit their site too quickly
so what here is exactly the factory method? In your example, would i make all the connection in the make_app? If so how would I reference the variables created then in the post method? If i create a variable within the make_app method to my knowledge I won't be able to reference it again outside of it.
IIRC, a lot of the argument in regards to servers is that most of your time is spent going to be doing I/O of one form or another - reading the socket, looking through the filesystem, database calls, etc. In these situations, asynchronous execution means that there's nearly always some code running, as opposed to blocking execution which has times where no code can be run while you wait for an I/O call to complete. Of course, if your I/O calls are often and cheap, then adding async execution could potentially make your code slower, as there's a slight performance penalty to each context switch, but that's unlikely to be the case.
Thanks to all, I'm actually in-between jobs right now, and I'm trying to revamp my skills. I was working in "BigData" as a consultant, and I'm needing to automate everything and want to learn as much as I can using Puppet and Python. I was hoping to get a few responses "there's a better way to do that" in response to my code review.
Or some `from __future__ import print_function` and `from six.moves import input #, range, zip...etc.` then you can happily support both!
Yahoo CSV: 4 years of end of day data on 3600 symbols: about 10 mins. Also with 10 worker processes. Your Investopedia download has twice the fields I use in the Yahoo CSV url though. So no need to change your code for historic data download IMO. Parsing a merged file after downloading everything could potentially give the database its data faster. I will install the python package in the next few days and try this out. Thanks.
By people posting answers they don't understand
You are over optimising and over engineering bro
Nope, I just don't want to pay for something that I could host myself for free. 
Thanks. In this case, should I still include 'source' in the shell file? that is, currently it's this: #!/bin/bash source env-djangoProj1/bin/activate but should it just be this? (i removed "source"): #!/bin/bash env-djangoProj1/bin/activate ______________ Heh.. I'm such a dummy sometimes. I tested both ways. I need to keep "source" in the shell file. Thx a bunch for your help!!
If you wanted to make things confusing as all get-out... You could combine asyncio with multiprocessing to get asynchronous task handling on multiple threads. I myself am not masochistic enough to do so, but hey, if that's your thing then I won't judge.
The set idea is spot-on. But I can't resist trying to find something that could be faster... allTokens = [] tokenMap = {} i = 0 for subA in A: j = 0 for itemA in subA: allTokens.append(itemA) if itemA not in tokenMap: tokenMap[itemA] = [] tokenMap[itemA].append((i, j)) j += 1 i += 1 infrequentTokens = sorted(allTokens, key=lambda q: len(tokenMap[q]), reverse=True)[X:] for t in infrequentTokens: for i, j in tokenMap[t]: A[i, j] = Y Off the cuff, so sorry for bugs and typos. This version should only iterate twice over all values, and should minimize the size of the loop over A to actually write Y into it. That is, if I'm not brain-dead. 
I'm a bit confused as to what you really need. Do you need global variables or static class variables? Globals should (generally) go in the top and class variables can go into the class definition like so: class Foo(object): x = 7 def post(self): print(self.x) 
&gt; to using 3 &gt; a beginner For the code you write, there is very little practical difference. In the code I saw, all you'll need to change is `raw_input` to `input` and `print x` to `print(x)`.
Multiprocessing, ironically, has a bunch of "not thread-safe" tags in the docs, too. On Windows machines, multiprocessing does what you described in an indirect way. In order to break out of the GIL it spawns separate instances of the Python interpreter which, if written carefully, can be used in a thread-safe manner. As for Unix... yeah. You can set multiprocessing to spawn new instances, but by default it uses os.fork(), which is gonna be a nightmare to debug. The performance gain of os.fork() may be worth the debugging, though. Like I said, ain't my thing. Sounds like purgatory.
source is a tricky one to understand in shell. You can't run 'source' inside a shell file, as it will only apply to the sub-process running that script. So you can't nest files intended for sourcing. e.g. source env-djangoProj1/bin/activate Will not work. You will need to copy the contents of bin/activate into your profile.sh. 
That's extremely progressive of your employer! Lots of companies are still stuck on python 2.
Huh? Tuples, strings, frozen sets, ints and floats... Am I missing something?
You're right!!!! Maybe "guide" or "note" is more suitable. Thanks. :)
What do you mean?
Yeah!! The note just wanted to show what async-await is. :)
You can definitely get those comments if you post the code, but part of learning on your own time is looking at what other people are doing, and comparing that to your code.
The general safe idea is to multiprocess, and then an event loop for each process, and don't cross event loops. If I'm not mistaken Not-thread-safe things only are issues when going across thread boundries
Hi There! How are you running the program? Are you running it from the command line with a command or double-clicking on your script?
What is the error that you get when running from the command line?
 can't open file '3': [Errno 2] No such file or directory I thought this was referring to the shebang line but I am pretty sure I had it right (#! python3) 
numpy.genfromtxt(filename)
Are you running the python command from the same directory as your script?
&gt; ConfigParser https://docs.python.org/3/library/configparser.html
So I am trying to use this program to clean up my SMS backup but I keep getting this error. 2016-08-29 23:06:31,325 Adding skipped 7549 MMS into new XML... Traceback (most recent call last): File "clean.py", line 147, in main(input_paths, output_paths) File "clean.py", line 36, in main append_mms(mms_list, root) File "clean.py", line 53, in append_mms root.append(mms) TypeError: append() argument 1 must be Element, not lxml.etree._Element I am not a coder so I do not have much experience with Python.
Something like [aiohttp](http://aiohttp.readthedocs.io/en/stable/). Right now there are no built-in modules for high-level async IO.
This is both super incredibly awesome, and unbelievably scary.
I'm on a Mac so I don't know too much about running scripts with windows, but you might be able to do this in command prompt python yourscript.py
Looks cool. So you blogged about a Python program someone else made, ported from a Go program someone *else* made? `:P` Might be cool to try in a big ol' building at work that has hundreds of APs with the same SSID (and some rogues...), could maybe locate you pretty well. Amusing that it's AGPL licensed; the A, Affero, part seems moot because a WiFi sniffer/ML program is pretty hard to turn into a web app. Easy enough to reverse/rebuild to unGPL it if you shift to any other hardware.
I'd just put them in a configuration module and import it. I wouldn't bother with `ConfigParser` unless it is the kind of thing that users will be regularly modifying. An advantage of using a separate file is that all your modules can then import it, and use it to [share global variables](https://docs.python.org/3/faq/programming.html#how-do-i-share-global-variables-across-modules).
I'd say that as long as you understand the *concepts* of programming like loops, conditionals, data structures and have used them in at least a few "textbook" type projects, you gain a lot from doing a real project. If your knowledge base is too narrow...a hammer's great, but at least learn about such things as "screwdrivers" and "pliers".
Hey mate, glad you found it useful. If you come up with better/alternative solutions to problems consider pull requesting the repo. Getting involved with open-source processes on Github is great for a new programmer and I'd be stoked to grow this resource.
Pausing after/during script: import os os.system("pause") Can't find file: Try setting your current working directory in the command window. Either open with start+R and use "cd C:\PathToFile" before calling your script, call the script with an explicit path ("python C:\PathToFile\script.py"), or open the command window to the correct path by shift right clicking in explorer without a file selected and clicking "Open command prompt window here". An alternative solution is to put your script in the system path. Most installations will add your python and your python\scripts directories to the path so either will work fine.
Hi! My answer is YES! I'm not going to go on for too long here, just offer one quick bit of advice: check out [pandas.](http://pandas.pydata.org/) Specifically and at first, mess around with read_table/read_excel on one side, and to_csv/to_excel on the other side. It is absolutely the fastest way I've found for getting stuff to and from spreadsheets into Python-manipulable code.
Yes, Python is good choice I would say. But for a web app you will need to renew your web development knowledge a little I would say. For something not gigantic sqlite as SQL database is also quite good and right in the standard library...
I'm pretty confident in the general concepts. To use your analogy, I've nailed a nail into a board, but i havent used the hammer to build anything or solve a problem yet. But i guess the next step after learning how to use a hammer is to build something, right? Start with a birdhouse? Thanks for your feedback.
Hey! that's not nice! you shouldnt swear! (This is a test)
Thank you. I definitely plan on renewing my web development. I started drifting that way this weekend while looking up tutorials on python. Even ventured in django for a video or two. That made me wonder if python was a good step one, or if I should make python a step 2. Honestly so far it seems like it's everything with more weight put into one over the others (70% python, 15% database, 15% web dev). Does that sound accurate?
On windows, try the following : first: go to start-&gt;edit the system and environment variables -&gt; Environment Variables. Make sure that somewhere on the PATH environment variable, and make sure that the path to the folder where your python.exe file is located(for example, C:\Program Files\Python35) is somewhere on the PATH environment variable. Once you've made sure of this, save your changes and close that window. Open up a file explorer and find the script you want to run. Shift+Right click somewhere either on the file or in the whitespace near the file and click 'open a command window here'. If you're not familiar with the command prompt yet, don't be alarmed. For now, just think of it as an ugly version of file explorer that lets you navigate your files on your computer and run them(There's more to it, but that's for you to learn later and not necessary for the task at hand). The particular command window you just opened up is now a view in to the folder where your script is located(you can verify this by seeing that the text to the left of the cursor is the directory path to the folder your script is in). Since you told the command window about your python executable by adding it to the PATH environment variable earlier, when you type 'python' and press enter in the command window, your computer will find the python executable file you told it about(python.exe) and run it. If you only type 'python', this should bring up an interactive shell for python like you've probably seen before. instead of just typing 'python', type 'python myscript.py' and hit enter(replace myscript.py with the name of your particular script). This will tell the command window to run the python executable if it can find it(which it should if you followed the steps earlier), and pass along some additional information to the python executable(the name of your script you gave it). The python executable will recognize that you've given it the name of a script you wish to execute, so python will run your script directly instead of opening up an interactive shell. Once your script is finished running, python will exit and return to the command window. You should see any print out statements or error messages from python in your command window. Alternatively, if you wish to just double click your python script and have it run(assuming you've associated *.py files to be run with the python executable in windows, which I believe you can set up either from when you install python or by going to start-&gt;default programs-&gt; choose default programs by file type), you should see a command window just briefly pop up and then close automatically when your script finishes because you've told windows to open your script with the python program, run the script, and then close the program when it's finished. To get it to stay open until you press a key, add a line similar to input("Press any key to continue") to the end of your script. The input() function is used to read input from the keyboard to a python script(you'll probably get to that a bit later), so your script won't be 'finished' until it's received it's input from you. 
Awesome! Thank you. I was looking for a way to kill 2 birds with 1 stone.
Well, I would say that Django is an overkill for something smaller but possible I guess. But otherwise those percentages look quite possible. Maybe depending on a particular project few more percents for web dev and less for one of those others.
Could you give a little more detail on what sort of web app you want to build? Will affect what the best tools are.
One is a list, the other is a dict, yeah, that's a fair point. A list is something slightly different from an array (either the builtin [array.ArrayType](https://docs.python.org/3/library/array.html), or, more commonly, a [numpy](http://www.numpy.org/) array)
Silly me. I come here.
[deleted] ^^^^^^^^^^^^^^^^0.9547 &gt; [What is this?](https://pastebin.com/64GuVi2F/22682)
Glad you enjoyed it!
Python, Flask, and SQLite is a great way to get started with server side web development.
Well, you can do that pretty easily with a ProcessPoolExecutor.
&gt; I would say that Django is an overkill for something smaller I disagree. If the project requires a database, users, and template rendering, then Django is perfect even for a small project. The only time it seems like overkill is if all you are doing is implementing an API (and even then is a perfectly fine choice).
the cool thing of learning to program is you learn by doing anyway. just do not be afraid to throw some code away because you found or learned a better way. you will appreciate later. and also. have fun!!!
If you learn as you go, you will certainly find answers / help online for topics that would be covered in an academic resource. It is not necessary to know all the details under the hood when hacking together something that works. However, it absolutely helps your intuition when debugging, as well as designing your system from a wider perspective. As far as DB stuff goes, totally depends. Since you mentioned excel, sql is probably what you want. Try out SQLite for a prototype. It's super easy to work with. If your looking for something like full text search, document retrieval, etc, you might want a NoSQL like DB. I'm a fan of Solr but that's all I've used.
How could you possibly expect any answer but yes when coming to the python subreddit?
Haha, no I think it was confusing. `schollz` wrote FIND in Python, I made a few commits almost a year ago, now I checked the status of the project and I see he rewrote everything in Go. I thought we Pythonistas still "deserve" a tool like this :-) Also, we're just scanning for how good the reception is of each wifi. The same thing that happens when you switch off &amp; switch on wifi. I'm unaware that is sniffing?
And yes, I can't wait to try it in a big building :-) tomorrow!
Python has a strong standard library build in though.
nice homework /r/learnpython
/r/learnpython
Personally, I am interested in picking up a statically-typeed, compiled language, C or Go possibly. I also see the usefulness and marketability of picking up Java. Any input? 
 def digits(n, base): out = [] while n: n, r = divmod(n, base) out.append(r) return out[::-1]
You might consider using Python to accelerate your full time job. You could practice and make a good case for a promotion at the same time. The Python libraries for working with Excel are pretty good and the things you can do by generating and combining workbooks using Python crush what you can do with Excel alone.
It really depends on what you want to do. Go doesn't have generics, so it would probably be a good first step if you want a gradual intro into statically typed languages. Swift and kotlin both have nice inferred type systems and are decent general purpose languages with objective-c and java interop, respectively. In the functional world, you could learn elm or haskell. In js-land, typescript is probably the way to go. Of course you can also dip your toes in the water of something like static typing by using python 3.5+ type hinting along with mypy. As far as how I would approach it, I'd say start with whatever seems like it will be the easiest to get up and running. Personally, I'd start with python type hinting. From there, maybe try go or swift. I also really like elm at the moment, but i'd probably only suggest that if you're specifically looking to pick up front-end stuff.
 import string fail = False while True: user_input = input('Please enter a '+ fail * 'VALID ' + '13 digit code: ') bar = [int(c) for c in user_input if c in string.digits] if len(bar) == 13: break else: fail = True Or, in action: &gt;&gt;&gt; import string &gt;&gt;&gt; fail = False &gt;&gt;&gt; while True: ... user_input = input('Please enter a '+ fail * 'VALID ' + '13 digit code: ') ... bar = [int(c) for c in user_input if c in string.digits] ... if len(bar) == 13: break ... else: fail = True ... Please enter a 13 digit code: 123456 Please enter a VALID 13 digit code: 1234567890123 &gt;&gt;&gt; bar [1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3] &gt;&gt;&gt; That is assuming you need the entry to be converted to int anyway.
python is rather new thing. i doubt you will find many experienced people that have started with python, since they would have to have started relatively recently. 
have you checked out https://github.com/awkman/pywifi pretty much does what you need, just add OSX support and you are good.... Sample: In [5]: import pywifi In [6]: wifi = pywifi.PyWiFi() In [9]: iface = wifi.interfaces()[0] In [10]: iface.status() Out[10]: 'connected' In [12]: iface.scan() In [13]: iface.scan_results() Out[13]: [{'bssid': 'xxxx', 'freq': xxxx, 'security': 1041, 'signal': -85, 'ssid': 'xxxx'}, ... ] (Sidenote: the version on PyPI doesn't work, the github one is fine though.)
You should put more (read: a lot of) thought into your variable names. To quote from Chapter 11 of Code Complete (which you should totally read): - Good variable names are a key element of program readability. Specific kinds of variables such as loop indexes and status variables require specific considerations. - Names should be as specific as possible. Names that are vague enough or general enough to be used for more than one purpose are usually bad names. 
Actually, Python first appeared 25 years ago =&gt; https://en.wikipedia.org/wiki/Python_(programming_language).
yes, quite recently. 
Thank you for all the responses. I will definitely try to make it work for Python 3 too. Also, I'll try implementing the other suggestions you guys have suggested. 
If you're interested in lower level stuff, look into Rust. It's not nearly as *big* as C/C++/Java, but it's got a lot of potential, and way less footguns.
Yes. Python is good at large data sets and its perfect for beginning programmers because it hides complications to focus on complexity. Programs should be as complex as the problem they're solving. They should be as plain as the programmer can make them. Python allows both.
Yup, and let me tell you why: while you don't have to use any of the popular languages only for web development, Python is used in such a crazy wide variety of non-Webdev situations that you don't have to go down the webdev route if you don't want to.
I think when learning, you should specifically use a verbose language and it should specifically be inflexible. You want it to be verbose so that every concept you are using is physically written in the code. You want it to be inflexible because, as a beginner, you shouldn't be trying to bend programming paradigms to your needs. The most important thing is that you get an unpolluted foundation in those paradigms.
I don't think there is a single one source because Python's a bit more diverse than R is. With R, you're almost certainly a data scientist. With Python you could be anything, and the different domains of expertise don't have that much in common. 
There's not really a right choice for a first language. It looks like you've already chosen python so what you want to do now is stick with it and learn how to program. Don't waste time switching between a plethora of languages when you're first starting out. 
Yeah, it's a decent first language. Though don't be that person that only knows a single programming language. Learn some more after you feel good enough in Python and have some spare time. http://www.catb.org/~esr/faqs/hacker-howto.html &gt; It's best, actually, to learn all five of Python, C/C++, Java, Perl, and LISP. Besides being the most important hacking languages, they represent very different approaches to programming, and each will educate you in valuable ways. Python is a bit of a unique language in that it's one of the only ones to use indentation instead of braces or `end` statements. Also quite a few other languages requires semicolons at the end of statements, python doesn't.
I think you can make Q of Q: entries = Entry.objects \ .annotate(x=Count('x')) \ .annotate(x_this_hour=Count(Case(When(x__created_at__gte=current_date - timedelta(hours=1), then=1)))) \ .annotate(x_by_ip_today=Count(Case(When(x__created_at__gte=current_date - timedelta(days=1), x__session__ip=ip, then=1)))) \ .filter( Q( Q(maximum_xs__isnull=True) | Q(maximum_xs__gt=F('x'))), Q(maximum_xs_per_hour__isnull=True) | Q(maximum_xs_per_hour__gt=F('x_this_hour'))), Q(maximum_xs_per_ip_per_day__isnull=True) | Q(maximum_xs_per_ip_per_day__gt=F('x_by_ip_today'))), ) \ .order_by('x_by_ip_today') \ .first()
I'm really sad that people are downvoting your post, OP. Don't be discouraged :) It's great that you're looking for help to improve your coding, ignore the downvotes.
So, I guess that goes into the face of Oculus needs GTXR10490 to run :) Did you link against the Oculus SDK for tracking? Any plans on OpenVR?
This release includes some bug fixes, code clean-up, updates to the docs, more tests, and various feature additions. The uzlib module now supports efficient stream decompression in the form of the uzlib.DecompIO class. Freezing of bytecode now supports floats for the ESP8266 port, as well as complex numbers for all ports. The stmhal port has ADC working on L4 microcontrollers, fixed initialisation for DAC, and addition of the machine.WDT class and machine.reset_cause function. More detailed changelog is at the link in the title.
Domain knowledge? Say hello to my little friend: http://automl.github.io/auto-sklearn/stable/
Totally agree. SQLite is a good option for beginners. I like because it's tiny and powerful.
Use python 3
Yeah, just realized what I did and switched it, thanks.
:) It's using http://openhmd.net for tracking, which is device agnostic, I've not done a feature comparison with OpenVR. 
I guess you're asking the wrong people here!
Please format your posts, so that the people you are asking for help have it as easy as possible, helping you.
I'm about a year into a very similar project and very happy with my choice of python + pandas. Its versatility and straighforwardness is the key for me. For learning, I did a bunch of the free online tutorials to get my head around the syntax, but like others said, just using it to solve your own problems is the best way to learn. 
&gt; The biggest problem with Python is that it allows you to program like an asshole. Good thing I've already come to accept that about myself.
yea but real life is not a action hero movie
Google for local Python User Groups.
The goal of pointing people to /r/learnpython is to keep this sub usable and worthwhile. If one x-posts /r/learnpython posts here then that defeats the purpose.
Python is definitely a great choice for a programming language, but I don't think it'll teach you all you need to know. You should consider looking into some basic CompSci theory to get a good idea of how to best implement your web app. It'll also help out in terms making sure your app isn't doing any unnecessary calculations, etc. 
NO! Definitely not! What does this look like, a subreddit for people who appreciate Python?!?!
**TL:DR** - In a few months doing what you're doing I managed to automate a lot of my Excel data work without intensive structured learning. This was the stage I was at about 3-4 months ago, with Python as my first venture into learning to code. Since then by using this subreddit and various YouTube tutorials, I have automated about 90% of the manual work that comes with using Excel. I found the learning process to be very cyclical as: * Google how to do something in Python * Play around with the code and adapt to what I want it to do * Find that I need to understand something else referenced in the adapted code * Repeat I would recommend installing [Anaconda](https://www.continuum.io/downloads) and using Jupyter notebooks. This is because it removes a lot of the technical knowledge needed in setting up a Python environment to run on your machine, and the notebooks allow you to test short bursts of code, so that you can monitor output as you adapt your script.
That's my problem. I want to try out these relatively new languages like Go and Rust and others, but I don't use them at work. I've come from C languages and taught myself Node and JS, but I'm using Java and only Java at work. I do consulting, and every company that I work with is doing Java, even for Big Data projects.
What is your idea of experienced? Experienced = expert? I know that a language might never be fully grasped, like C languages, but how many years of working with a language does it take to become experienced?
I would be happy to help.
Decide if R or Python is right for you.
The Answer is yes, here what you need to do. * Do Python tutorials and youtube until you understand the basics, as well as how functions, classes and methods work. * Then its time to learn some frameworks. For a Web application you want to start with Django, and also learn Flask. don't learn one of them, learn both. They have different uses, but understanding one of them makes the other easier. * I suggest starting with Django because the Official tutorial is so well crafted. You need to go through it twice. The first time is going to be hard, as it starts with models, and introduces the MVC paradigm. This will be difficult to wrap your head around. But stick with it, and once you get to the end, the beginning will make much more sense. * Flask is a Micro framework, where Django comes with a Database orm, Models, and an Admin Panel right from the start. Flask pretty much only starts with rendering Hello World to a browser. But sometimes that is all you need. * Javascript. Python only works as a backend language. That means on a webpage all the Python code is run on the server. Running code in a browser, the things that makes webpages dynamic and movable, are all done in Javascript. So some Javascript is unavoidable. Luckily JS is fairly similar to Python so picking it up is not very difficult. * SQLAlchemy. This is an ORM, (Object Relational Mapper) for Databases. Remember that Django has its own? Well SQLAlchemy is leagues better, and any serious database developer using Python should immerse himself in SQLAlchemy. Things I would suggest you also learn: * Docker. This is very popular these days, and is becoming essential for Web deployment. Go to the webpage and check it out, it will increase your chances of getting a job. * MongoDB. Check out PyMongo to learn something about the world OUTSIDE of SQL. Again, this is a marketable skill. * Git/Github. Should go without saying. Get a Github account, learn Git terminal commands. Don't just stop at the basics. Learn how to set up branches, merge them, manage conflicts and fix errors. Good luck. 
As long as you understand that Python isn't the fastest language ever, you'll be fine. It's very readable which is the tradeoff and that's great for someone just learning. Jump into real world stuff as soon as possible too. There's nothing like being faced with an applicable challenge 
&gt; once it's rolled out. What year are you from?
In a particular order: * Python is lovely as a first language * Use python 3. Unless you're maintaining a million dollar legacy platform, there's no reason to be using an outdated language * SQL is alright. Pandas makes it easier though * HTML/CSS experience, while not immediately applicable, should not be discounted. Anything that gets you coding and thinking creatively is experience that will help
Pastor says Java is the fool's fig leaf
Joist hangers.
&gt; My full-time job deals with data and working with big datasets on excel. Then Python is good. Much less error prone and easier to maintain than excel.
Let's be honest, there are no big datasets in excel. 
If learn python wasn't full of people looking to figure out the basics of python then i would agree with you. There doesn't seem to be a good place for questions that aren't elementary. There's a lot more experienced people here that would have been able to answer this style based and best practice question. The best places for questions are where the best minds are, it's unfortunate that's turned down here
Does anything change if you try to use QDeclarativeView? So you would change your code to something like from PyQt5.QtDeclarative import QDeclarativeView ... view = QDeclarativeView() view.setSource('your-qml-file.qml') I'm not sure if the syntax is exactly the same but that would work in pyqt4, however in pyqt5 some things were restructured. So check that the imports are actually correct.
Yeah, one of the changes with PyQt5 is QDeclarativeView was removed.
I will have to read more about it. I have only skimmed over some of the details about Mozilla writing bits of Firefox in Rust. 
/r/rust has a bunch of resources to get you started.
What are you testing, exactly?
Just a note that qt5 doesn't support the compiler specified for py27. Maya uses a different compiler version anyway than stock python. Not to say it won't work for someone to compile it, just that it's something to be aware of should you see bugs 
So, let me get this straight: you want a random string, and you want the alphabetical numbers of every letter in the string to add up to 200? Is that your homework? Also, /r/learnpython is a better place for such questions.
Im not quite sure if i follow your logic on that. Its not a question asking for new information it is asking how to process information about the python language that is out there. If the mods find that this should be taken down then i would understand, but i feel like this is still relevant to python and does have a place here.
Why did you choose a SVM? What's you RMS Error out of sample? I am currently implement such a software but with a bagged KNN learner. 
It doesn't look like PyQt5 supports `SwipeView` yet. \* *and PySide doesn't support Python 3.5 yet.*
[You are taking the piss right?](http://stackoverflow.com/questions/2560310/heavy-usage-of-python-at-google)
Yes correct trying to calculate the name of the beast. No upper limit to how long the name can be. The list would have to be auto generated and would have to equal the sum. 
LOL no i wont they are horrible any ways
&gt;it should specifically be inflexible Haskell is even more inflexible than Java in that it is strong static typing. Java's verbosity is too much trouble for the very little benefit it could bring; just "Hello World" takes 10 lines. Verbosity really just unneeded bloat that is a turn-off to beginners and for a reason. Why need to write a ";" at the end of each instruction? It's just archaic. and this is the least of problems. &gt;every concept you are using is physically written in the code I agree beginners should understand what they are doing. but emphasizing each idea with cryptic notations isn't the way to go. Let's use a close comparison. In old RPGs, players had to type in all the dialogs, presumably for "immersion". They would have to complete a form and submit it. Soon, this was discarded. The user isn't stupid, and having to type everything actually provides the opposite effect; it's immersion-breaking in that it's a hindrance. Nowadays, you just click on the line of dialog you wish your character to say, and this detracts from nothing; it's a very good improvement in usability. Similarly, why require the programmer to end each instruction with a ";"? This is redundant with the line-break and doesn't enforce anything. It can actually enable the bad practice of writing two instructions on the same line. Python got rid of it, and actually Python borrowed a lot of ideas from functional languages, such as map-reduce. and fun (ctional) languages are only made up of such great concepts... &gt;you shouldn't be trying to bend programming paradigms to your needs Functional languages aren't cluttered by such issues. They are the most clean since they are closer to mathematics. They are fairly easy to use, yet much more abstract stuff than imperative paradigm provides can be done at the tip of the hand. In Java, you can't pass around a function as a parameter. You need to create an instance of an object with said function in it... This kind of OOP is faulty. Functions as first-class citizens is a much better design. Python, whose most popular and praised features are easily the functional-inspired ones, is a language with several paradigms. JS is a much worse offender of this. That's why it's advised to just use Scheme or Haskell right away to learn properly. &gt;you get an unpolluted foundation in those paradigms You can't get any better than those (or tell me if you know so, because I would be very interested in trying them out). They are the closest to math, ideas, abstraction, while imperative languages are in an awkward in-between of low and high-level programming.
Fantastic!
I wish they hadn't announced it honestly
&gt; i started my first ever lines of code in python I've seen beginners doing much worse. If you wrote it by yourself, congratulations, it looks ok for a first attempt. But if its just something you copied from other place, go back to basics, and make sure you understand what every single line does and why it was written this way. Important things to improve: 1. Get familiar with PEP8. Python uses lower_case for function names and CamelCase for type names. def Game() will look odd for every python developer. 2. Get rid of global variables. Pass them as parameters or use classes. 3. Prove that your program is working as expected by writing tests. 4. Post you further questions to r/learnpython
https://www.micropython.org/
/r/learnpython Post this in the learning sub and put what you have already tried.
That's an /r/learnpython question. Also, I would suggest using the [Requests library](http://python-requests.org/) for that. &gt;&gt;&gt; import requests &gt;&gt;&gt; requests.get("http://api.pathofexile.com/ladders/Hardcore%20Essence?offset=3000&amp;limit=20").json() {'total': 15000, 'entries': [{'dead': True, 'online': False, 'account': {'challenges': {'total': 15}, 'twitch': {'name': 'eccentricdb'}, 'name': 'koceto66'}, 'rank': 3001, 'character': {'level': 88, 'class': 'Inquisitor', 'experience': 1704686723, 'name': 'Essentricxddddddd'}}, {'dead': False, 'online': False, 'account': {'challenges': {'total': 10}, 'twitch': {'name': 'lordtekkless'}, 'name': 'Tekkless'}, 'rank': 3002, 'character': {'level': 88, 'class': 'Gladiator', 'experience': 1704634990, 'name': 'I____TEKKLESS____I'}}, {'dead': True, 'online': False, 'account': {'challenges': {'total': 11}, 'name': 'SpeedyO_o'}, 'rank': 3003, 'character': {'level': 88, 'class': 'Hierophant', 'experience': 1704207255, 'name': 'EnergyShifter'}}, {'dead': False, 'online': True, 'account': {'challenges': {'total': 23}, 'twitch': {'name': 'slurm80'}, 'name': 'slurm80'}, 'rank': 3004, 'character': {'level': 88, 'class': 'Assassin', 'experience': 1704069270, 'name': 'Slurmstrike'}}, {'dead': False, 'online': False, 'account': {'challenges': {'total': 22}, 'name': 'zaki11'}, 'rank': 3005, 'character': {'level': 88, 'class': 'Necromancer', 'experience': 1703980870, 'name': 'Zakii'}}, {'dead': True, 'online': False, 'account': {'challenges': {'total': 12}, 'name': 'iHillda'}, 'rank': 3006, 'character': {'level': 88, 'class': 'Slayer', 'experience': 1703938466, 'name': 'Hillda'}}, {'dead': True, 'online': False, 'account': {'challenges': {'total': 8}, 'name': 'zicks'}, 'rank': 3007, 'character': {'level': 88, 'class': 'Trickster', 'experience': 1703208055, 'name': 'PoisonPeace'}}, {'dead': True, 'online': False, 'account': {'challenges': {'total': 24}, 'twitch': {'name': 'jamesworthh'}, 'name': 'JamesWorth'}, 'rank': 3008, 'character': {'level': 88, 'class': 'Juggernaut', 'experience': 1703084138, 'name': 'Jimmmy'}}, {'dead': True, 'online': False, 'account': {'challenges': {'total': 15}, 'name': 'Zuuy'}, 'rank': 3009, 'character': {'level': 88, 'class': 'Raider', 'experience': 1703040024, 'name': 'ZuuyMapTonight'}}, {'dead': True, 'online': False, 'account': {'challenges': {'total': 17}, 'name': 'toiskori'}, 'rank': 3010, 'character': {'level': 88, 'class': 'Trickster', 'experience': 1703036230, 'name': 'ElamanImia'}}, {'dead': False, 'online': False, 'account': {'challenges': {'total': 20}, 'name': 'elstulin'}, 'rank': 3011, 'character': {'level': 88, 'class': 'Champion', 'experience': 1702736398, 'name': 'Path_of_suicide'}}, {'dead': True, 'online': False, 'account': {'challenges': {'total': 17}, 'name': 'BloodBox'}, 'rank': 3012, 'character': {'level': 88, 'class': 'Slayer', 'experience': 1702608001, 'name': 'JizzingBladesBox'}}, {'dead': False, 'online': False, 'account': {'challenges': {'total': 9}, 'name': 'Jatesy'}, 'rank': 3013, 'character': {'level': 88, 'class': 'Trickster', 'experience': 1702606670, 'name': 'BendrBendingRodriguez'}}, {'dead': True, 'online': False, 'account': {'challenges': {'total': 11}, 'name': 'SupervAn'}, 'rank': 3014, 'character': {'level': 88, 'class': 'Elementalist', 'experience': 1702296041, 'name': 'WhisperingvAn'}}, {'dead': True, 'online': False, 'account': {'challenges': {'total': 13}, 'name': 'Loopstok'}, 'rank': 3015, 'character': {'level': 88, 'class': 'Pathfinder', 'experience': 1702272040, 'name': 'Cairrrrrrrrrriba'}}, {'dead': True, 'online': False, 'account': {'challenges': {'total': 10}, 'name': 'Nezria'}, 'rank': 3016, 'character': {'level': 88, 'class': 'Trickster', 'experience': 1702247356, 'name': 'OnlySolo'}}, {'dead': True, 'online': False, 'account': {'challenges': {'total': 15}, 'name': 'flatzoom'}, 'rank': 3017, 'character': {'level': 88, 'class': 'Juggernaut', 'experience': 1702224868, 'name': 'BardisAThingOfDread'}}, {'dead': True, 'online': False, 'account': {'challenges': {'total': 15}, 'name': 'kevin741852'}, 'rank': 3018, 'character': {'level': 88, 'class': 'Chieftain', 'experience': 1702176453, 'name': 'Bored_____'}}, {'dead': True, 'online': False, 'account': {'challenges': {'total': 30}, 'name': 'jallaland'}, 'rank': 3019, 'character': {'level': 88, 'class': 'Assassin', 'experience': 1702090360, 'name': 'Lebulbasassin'}}, {'dead': False, 'online': False, 'account': {'challenges': {'total': 12}, 'name': 'Eakrich'}, 'rank': 3020, 'character': {'level': 88, 'class': 'Pathfinder', 'experience': 1701892837, 'name': 'EakRip'}}]} 
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
&gt; ' Thanks! Will post over there now. 
I made a post over in the other sub, but thank you for the reply! Much appreciated.
/r/learnpython also terrible post title
Why? Because people will rely on it? Although, I don't think they would have unless it was going to stick around.. 
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Yes, because people will end up putting more broken libraries on pypi that rely on it without understanding why it's an issue. 
I think you confuse asyncio with threading. Async IO never runs code in parallel it runs code asynchronously. Asycnio always runs in one thread.
...That's literally what I explained above. Asyncio runs concurrently, not in parallel, and is locked to a single thread by the GIL.
Real pythonistas are not the heroes who wear capes and are NOT prone to flattery. They are more like spiderman. They come to your rescue when you're in trouble. Else, they are neck deep into their own python world. You never really get in touch with them until they respond with a stunning one-liner to calculate the size of a black hole. Wait for it. Ask questions in r/learnpython. Engage in IRC chats. They are not the heroes you may need right now. Send the questions onto them. Announce publicly that they are not of your help. But remember, one fine day, It all pays you off.
I would start by 1) looking at the projects bug trackers / jira / github / roadmaps to see what's happening in these projects. 2) "talk" to maintainers / core devs / their mailing lists to identify gaps that are big enough &amp; not too big for a master thesis. Ps: Make sure to get the theoretical reasoning right about why your development contributes to the advancement of science..;)
very nice, how does this work? I've never seen this formatting before.
Assuming this is CPython, it's total and utter garbage. CPython primarily relies on reference counting, and a resource will be freed when its count reaches zero, e.g. when the last name that refers to it goes out of scope. This happens immediately. The garbage collector is only there to resolve situations that reference counting can't handle, such as cycles. It is not used as the primary means of managing lifetimes as in other languages.
What formatting? Are you talking about `str.upper`? That's the unbound version of `"foo".upper`. If you access a method as an attribute of an instance, it automatically gets the instance filled in as the first parameter (self), i.e. it's bound to that instance. If you access a method as an attribute of a class however, that doesn't happen, and it will be expecting one more argument than usual, the "self" argument. So `str.upper("foo")` and `"foo".upper()` are really the same thing, it's just that through the magic of the descriptor protocol, the latter is turned into the former in most cases so you don't usually use unbound methods. You could also do it with `getattr()`: getattr("string", random.choice(('upper', 'lower')))() 
as i say, relatively recently compared to C or even C++.
Check out "Automate the Boring Stuff". It is free as an E-book but you can also buy a hard copy. I was in a similar boat as you, ATBS helped a lot as I was first learning python. 
PythonAnywhere is really helpful for web development. It cuts out a lot of the stress of setting things up
I just started down the road of learning Python - this looks very interesting. The possibilities seem endless.
Sweet. I just discovered this module this weekend, and it's such an improvement on just using requests (my app makes ~1,000 API calls)
You are on the right track, get on with Python (check Flask) and also learn SQL. With Flask and SQLite you can go a long way and make the web app you want.
Awesome! It's really a pleasure to do PRs for this project, the main author is to-the-point and nice.
yes starting with python is the best choice cause python frameworks like django are for perfectionist with deadlines .First learn python basics then jump to learn django and after learning some database you are ready to go for your DIY:)
So, here's the deal. I've got this little project going. I want to expand it a lot more, but I haven't got all of the time. Basically, I'm posting here to try and promote this idea, get people thinking about it, and hopefully get a little bit of help with it. I'm not expecting you guys to write this for me, I plan on at least getting the basics of choosing a starting creature and implementing the random encounters and battles before accepting any type of pull request. Like I said, I just want a little attention.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Did you not consider Pycharm's remote debugger? It's the best I've used. The remote debugger does require you to use the paid version of Pycharm but it's easily justifiable for commercial use.
I love it, but the year's wrong. Python came out in 1991.
I see. That would make sense, then.
The output you're seeing above is a tuple for each row, so to get the date you would access row[0]. print row[0] Or write your sql statement as "select date from stocks". Further down on the docs page you will find the row_factory member of the connection object. Set this to the built-in Row type. With this you can access results by their column name. c.row_factory = sqlite3.Row # run query print row['date'] 
sort of a general side question I noticed it had deployment instructions, should one go through all that fun (of making sure the code is multiple worker capable, setting up gunicorn, and also setting up nginx) or would it be okay to just expose the single process to the web?
This utilizes the new asyncio features in Python rather than synchronous requests
You know if they released CAN support?
Best I can understand is that you want to make a text based pokemon clone where people gamble bitcoins on the fights? This surely won't have any legal ramifications if it actually were developed
I didn't start with python, but I would think if you learned C it would give you Not only a better understanding of things that go on under the hood of some of the other interpreted languages(including python) but also allow you to have the skill set to write custom C extensions for python if you ever found the need. Language syntax differences and different built in functions and features for each language will be your biggest hurdle most likely. For instance, to get the arbitrary number size convenience that is default for python numbers, you would have to implement your own custom struct in C with the accompanying math operations. Or use Java's BigInteger class if you needed something bigger than a long.
I really want an extremely dumb `requests`-style API on top of this, something that lets me write `await aiohttp.get("http://reddit.com").json()`. Yes, it won't be as fast, but sometimes you don't really need things to be super fast, especially when you're just prototyping. Is something like that planned, or should I just make my own wrappers? 
This isn't supported and it's heavily discouraged by the main author. He really pushes to use just one session if possible as you gain so many benefits (connection pooling, keep alive, etc). After using aiohttp in a project, I have to agree with that sentiment. I did end up using two session objects because one needed to ignore keep alive connections, but the other didn't. It was easier to pre-configure the session with that header than add it every it needed to go. And as far as I know, Requests discourages this for the same reason but it's supported anyways. 
I really disagree with that, to be honest. If I want to do things fast, I'll use the more verbose way, but for a one-off request that happens once every blue moon, I don't really care about speed - I'd much rather write less code. 
if speed/performance are not an issue, what are the benefits to making the request async? use `requests.get("http://reddit.com").json()` 
Read a snippet from the Espressif CEO (sorry, on mobile). It sounded like it was pretty low on their list. Bluetooth was next.
That's fine, just sharing what I know about it and my experiences with the library. As a heads up, there's an issue with your example. You need to await both the request *and* reading from it. On top of that, aiohttp needs you to close the session and request if you don't use it in the `async with` form. Until we get async generators (the implication being we can then have an `async_contextmanager` decorator), you're probably going to end up writing more than if you just used a global session. 
In my perfect world, my example would return a future that itself awaits the request, reading the response, and parsing the response. I'm pretty sure that's possible. 
My intended use case for this is a thingy that does a lot of async networking that needs to be close to real time (IoT sensors and such), but also fires off HTTP requests to a stats dashboard service once in a minute or whatever. I don't want to block the event loop, because that would cause latency for the things where performance does matter, and I don't really want the extra complexity of firing off the request from a thread. 
In Python 3.5 you need to install panda_datareader as a separate utility and do: `import panda_datareader.data as web` or `from panda_datareader import data as web` Instead of importing from pandas.io. The DeprecationWarning makes it all very clear so I'm not sure if this post is helpful at all.
I'll be using a map of my own creation, monsters of my own creation, and items of my own creation. It takes inspiration from, but does not actually use, a popular intellectual property that I shall not name.
Though a bit less precise, codemonkey14 has it about right. It's a text-based MMO (like good ol' Phantasia from the BSD days) where you capture and battle monsters. I'll be designing everything myself, though, and not using any resources from any other existing product.
Django. I built a web app in django and showed it to the team. They were a web development shop that used django. The interview went very well. Edit: should have clarified that I had been reading a bit of tutorials and documentation to get up to speed to talk about django intelligently. Come to think of it they may have cared more about my drive and ability to talk super passionately about something I built than the app itself.
Thank you I think this was the most helpful so far. I believe my confusion came from thinking that I would see a different window other then the command line window. I appreciate your help! Thank you very much.
I've used [nuitka](http://nuitka.net), which has the added bonus of possibly speeding your program up. It is pretty handy.
Can you give more details on why/how they aren't properly building?
Yea the issue was that the queue module was included twice, something like that. There a queue and a Queue module. Gotta love that Windows case insensitivity.
Have you considered wrapping the aiohttp boilerplate into its own "aiohttp-easy" wrapper api? I know it's dodging your question, but I think what you're asking for would be handy and should be pretty straightforward to derive from the aiohttp tutorials.
You would have to open a port on your router and forward that port to your machine. Your question also would probably better be answered on r/learnpython.
Ok thanks
The only reasonable use for this that I've seen, is when you wish to disable garbage collection temporarily for timing or performance critical tight loops. I've read somewhere that the timeit module actually does this. In those cases, you need to call gc.collect() manually, or just re-enable garbage collection. 
Thanks again, this shit is incredibly simple, and the best part: it works!
&gt; The possibilities seem endless. The first one that jumped to my mind was bundling it with IOT worms allowing said worms to be cross platform and written in python 
It might help to be more specific about what you need - a book? tutorial? website? 
[deleted] ^^^^^^^^^^^^^^^^0.0527 &gt; [What is this?](https://pastebin.com/64GuVi2F/38770)
I went from basically sucking at Python to becoming very comfortable all on Rosalind.info It's meant for training in bioinformatics however there are hundreds of problems that range from easy to very difficult. They also have a short section that runs through classic algorithms. Check it out, I had a lot of fun and learned the ins/outs through breaking down problems and figuring out on my own (googling) how to solve each step through Python.
thanx
No set of lessons, guides, tutorials, or books will ever be adequate to master any programming language. There comes a point where further learning can only be accomplished by writing code.
$30,000 per year? Am I looking at the right thing? 
Well, numba comes with anaconda which is completely free, I'm not sure where you saw the $30,000 figure
Plain Anaconda doesn't have the CUDA functionality. According you their page you need Anaconda Accelerate, which [this page](https://www.continuum.io/anaconda-subscriptions) says starts at $30,000 per year.
So, are you saying that master is not a level someone can achieve in programming after acquiring enough exp? Can this not be done by finding an environment which is rich in high end encounters and repeated until MASTER level is achieved?
Yep. The lowest cost license (that includes accelerate) is $30k a year. "But" you do get up to 10 seats. I am thankful I am a student and get it free :) EDIT: Is [this](https://github.com/numba/numba/blob/a4237562b78e9c4183173983051e5383dfab901c/docs/source/cuda/overview.rst) usable w/o the pro license I wonder... EDIT2: It is! And here are [some docs](http://numba.pydata.org/numba-doc/dev/cuda-reference/host.html) I may write a blog post experimenting with this...
Thank you for your thorough and honest feedback. This is exactly why I came to /r/python to ask this question. I wanted to ask the Mr. Miyagi's of python if I should wax more cars or go kick some Cobra Kai butt. If I were learning a spoken language, it sounds like you're suggesting I learn the formal way to speak before I start learning slang/shortcuts. Probably a very loose analogy, but that's how I understood your point. I think what will work best for me is to do both at the same time. I need the quick satisfaction to keep my motivation levels up, but I'm also no stranger to textbook style learning; even for recreational learning. I've committed myself for at least 1-hr a night (I have kids, work to do at home, etc.). However, last night my 1-hour turned into 4-hours of research and that time flew by quick! I am highly interested in the concepts and theory of programming. I don't plan on having only 1-tool in my toolbox, and it doesn't seem like it's even possible to only have 1-tool if I am really diving into it. If I compared this to a sport, I would want to do drills, games, study tape, repeat. I'll take your advice and look into learning a more strict language for much more of an overall understanding. Thanks again!
If you didn't know pi is for Python Interpreter. 
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Thanks for the post. Really insight for people new at debugging things. What you think of pudb? 
Yeah, that's what I'll probably end up doing. Was just checking to make sure I won't be duplicating work. 
You are right. Officially the language was created in 1991 when it was released to public, but in in 1996 Van Rossum wrote in [Foreword for "Programming Python"](https://www.python.org/doc/essays/foreword/): &gt;Over six years ago, in **December 1989**, I was looking for a "hobby" programming project that would keep me occupied during the week around Christmas. My office ... would be closed, but I had a home computer, and not much else on my hands. I decided to write an interpreter for the new scripting language I had been thinking about lately: a descendant of ABC that would appeal to Unix/C hackers. I chose Python as a working title for the project, being in a slightly irreverent mood (and a big fan of Monty Python's Flying Circus). That's the only reason why I decided to take 1989 instead of 1991. 
Nice find. I certainly don't see anything about needing a commercial license and it seems to be working fine.
No some features (that should have an *) are yet to be implemented. As the moment the is a command line interface script in the repo that can search for problems by their tags. The repo got promoted a little earlier than I intended, but I am working on adding all those cool features.
It means you don't have to wait for the response of each HTTP request before executing the next one.
Cognitive overhead, in some cases speed differences, installed footprint. Presumably memory differences too though I haven't seen that myself. If you are using many of the features of Django then the difference disappears, but if you are just looking to render some simple data to a page the difference is larger. 
Yeah I did some reading last night. Pretty nifty. Heard a lot about this asyncio stuff but being new to Python it'd probably be more work than its worth in my application
How can you predict without using patterns ? I was thinking about deepdreams/neural network, because it seeks patterns. 
Does this use epoll/kqueue under the hood?
No, CUDA support and almost everything else that was numbapro-exlusive has landed in numba now. CUDA has been supported for over 2 years now. Please check your facts before posting such things. It's easily visible in the docs and has its own section: http://numba.pydata.org/numba-doc/latest/cuda/overview.html. Relevant blog post by Continuum: https://www.continuum.io/blog/developer-blog/deprecating-numbapro-new-state-accelerate-anaconda
Wait a minute, [numba does support CUDA](http://numba.pydata.org/numba-doc/latest/cuda/overview.html). Please see my other comment.
Aalways try strace first! Super easy and sometimes it gives you everything you need to find the problem
I tried fromLocalFile, but still no dice. import sys from PyQt5.QtCore import QUrl from PyQt5.QtWidgets import QApplication from PyQt5.QtQuick import QQuickView if __name__ == '__main__': myApp = QApplication(sys.argv) view = QQuickView() view.setSource(QUrl.fromLocalFile('two.qml')) view.show() sys.exit(myApp.exec_())
Check out pbpython.com for info on how to use pandas to replace Excel. Automatetheboringstuff.com also has a section on Excel, as well as automating things you do in your daily life.
Thanks! I think learning both alongside each other is a good idea. If you have the time, that's definitely an approach worth looking at because you spot commonalities in the paradigms and it gives you more perspective. And yes, I think the drills, game, study tape repeat cycle is the best way to approach it. It will help keep your motivation up when you see the utility of what you are learning.
I think the problem is that python needs indentation and this is one big line