I pledge, but am wondering about the expected price per board when done... 
Selenium doesn't *simulate* a browser session, *it is* a browser session. Writing for selenium is basically writing a set of actions and feeding them to a browser (usually Firefox, but it can work with others). As someone else said, if the site you're scraping uses Javascript or AJAX to fill in its content, you *need* a browser in order to get that content. It doesn't have to be Selenium/Firefox, but it does need to be a browser. Selenium is the most well-known, and has APIs for several programming languages, but it's most well supported in Java and can be frustrating if you're using something other than Java to drive it. One alternative to Selenium is PhantomJS, which make browser automation fairly easy to do via javascript... but since this is a python forum, I only mention it because there is now a python project that provides drivers for Phantom. And if you don't need *all* the features of Selenium, most new development for the Selenium has been shifted to the Webdriver project, which supports several browsers and provides APIs in several languages, including python. With that said... If you don't *need* dynamic content, you're almost always better off just requesting the page content over HTTP (for example, using urllib2) and parsing it programmatically. How you do that, though, depends on what you're looking for in the page, how it's coded, and the limitations of the machine on which you intend to do this.
Do you mean an [IDE](http://en.wikipedia.org/wiki/Integrated_development_environment)? If so, I like [PyCharm](http://www.jetbrains.com/pycharm/).
Thank you very much!
What's watchdog doing on that list? It doesn't work correctly on linux or osx, and the developers are downright unfriendly about reported bugs.
The library I was most impressed with from the list was docopt.
I find that overall comprehensions are just easier to get other developers on board with. Map requires you to view looping over a dataset in a much different way than writing a loop does. First class functions are something that many people enjoy the convenience of, but don't really understand the depths of manipulation you can do. Reduce doubles the complexity of the whole affair, without a really sensible understanding of iteration, its hard to really see what is going on just by glancing, where as with a list comprehension its literally and figuratively much more spelled out. Just some thoughts on it.
I'm confused by the following: &gt; **NumPy** [emphesis mine] has been split: now PyPy only contains the core module, called _numpypy. The numpy module itself has been moved to https://bitbucket.org/pypy/numpy and numpypy disappeared. You need to install NumPy separately with a virtualenv: pip install git+https://bitbucket.org/pypy/numpy.git; or by directly doing git clone https://bitbucket.org/pypy/numpy.git, cd numpy, python setup.py install. Isn't the name NumPy already taken by a different group?
lxml is awesome! sh too. Rest I got to try.
Ummm what?
Yes, exactly. Like I said, at the end of the day you're still connecting to a standard database. Even if your chosen toolkit doesn't let you descend the abstraction, you can just disconnect and *choose a different toolkit*.
I think it comes from the philosophy that unicode is the one true string and has some sort of purer representation. As a result, collections of bytes must never be thought of as stringlike. I do a lot of serial protocol stuff. So Python 3 is of no interest to me because of the string brokenness as you have described.
Maybe you are looking for something like [py2exe](http://downloads.sourceforge.net/project/py2exe/) or [bbfreeze](https://pypi.python.org/pypi/bbfreeze/)? They are not compliers in the sense that you seem to be thinking but they do build executables that do not have the kinds of run-time dependencies normally associated with Python, particularly on Windows. They are wrappers around a subset of a Python runtime + app rather than native instruction set targets, i.e. still interpreted byte-code that gets executed.
I must try docopt... 
Normally Python code is executed by an interpreter, usually called [CPython](https://en.wikipedia.org/wiki/CPython) because it was implemented in C. Available from python.org as source, and as binaries with some extras from e.g. [ActiveState](http://www.activestate.com/activepython). Because of some aspects of Python syntax and semantics it is not amenable to compilation to binary, however [Cython](http://cython.org/) is a compiler for a slightly restricted subset of Python. Actually it compiles all Python, but the parts that require runtime analysis, it just punts to CPython. Anyway you can get pretty big speedups by compiling selected modules of a larger program with Cython, leaving the bulk of the code interpreted. Then there is is [PyPy](http://pypy.org/) which is a different implementation of a Python interpreter, one that tries to get execution speed by [JIT](http://en.wikipedia.org/wiki/JIT_compiler) compiling Python code in memory as it runs. "Wut?" I hear you say? Yes, they actually run the code ala CPython but analyze it as it runs, figure out where the heavy CPU loops are, compile machine code for those on the fly in memory, and transfer control to the dynamically compiled code to go fast. For a program that spends a lot of time in some central loop, under PyPy it has a "warm-up" time of slow running while the analysis goes on, then it speeds up to hyperwarp. So as long as the structure of the program is favorable, PyPy gets the best of both worlds. 
I remember watching the video for docopt when it first hit YouTube a little over a year ago, and having to winch my jaw back up off the floor. It's a beautiful concept, and quite well-implemented.
I am really pretty mad about this. You can use list comprehensions to emulate `map` and `filter`, yet they are builtins. But you can't use comprehensions to emulate `reduce`. Thus, `reduce` is really the *only* one of the three that is actually necessary. But nooo, it is also the only one that is *not* a builtin. I once had to concatenate a few million lists. `sum` takes ages. `+` in a loop takes ages. `list.append` takes ages. You know what is blazingly fast? `reduce` and `+=`. Like, literally half a second instead of half an hour.
Hard to say without any logs in front of me, but perhaps you are trying to use python3's shell but python2's pip - or vice versa?
Did you "sudo pip install"
Yes.
Never do that. Use packages from your distribution and Initialize your virtual envs with --system-site-packages.
It's definitely used in production. Last time I messed around with iOS it was used for stashing application data (state, preferences and stuff)--I believe the interface was replaced with CoreData which still uses sqlite on the backend. It's pretty prominent on their iOS data management page. https://developer.apple.com/technologies/ios/data-management.html For web development it's generally used for testing and prototyping your db and you'd have a db better suited to concurrency and scaling for use in production. For individual apps it's used all the time. On my computer the applications that to mind using sqlite are Address Book, Aperture library (there's a few in there), Anki (a flashcard program).
Requests is something you start using and realise you can't go back to the old ways.
Requeats and beautiful soup are fantastic for html parseing and crawling.
Interesting. I saw it on the list, along with the description, and it struck me as a very handy thing indeed. For it to be a lie... it makes me sad. It's something I've searched for (sporadically) in the past, and found nothing that would be satisfactory. Makes me wonder how difficult it would be to implement a truly cross-platform solution.
Not even with the bonuses. :') But on the other hand, these lists seem to pop up with startling regularity, so perhaps it's a good thing? ;)
I really love it, but if other people want to read your source code, it may not be the best idea.
yep. My thoughts exactly. 90% of the typing is typing of the options / help text anyway, people just want to save a tiny bit of time (using copy/paste) and instead have people expect to know the docopt 'language'. Plus you need the library, rather then using argparse which is built in to the library. 
See https://mail.python.org/pipermail/pypy-dev/2013-November/011892.html
use request and beautifulsoup4 for python. Scraping with nokogiri is easy as fuck. But it's a ruby gem. Gud luck
What could be more clear than the help text itself ? After all that is the documentation to the usage of the program. Not only do we expect developers to understand that text but also users who are supposedly much less technical. I absolutely love docopt; it follows in the same vein as Donald Knuth's literate programming.
It's clear to the clients of my command line utility, sure. But as the programmer, I get more clarity from explicit programmatic behavior than trying to parse a DSL in my head. I'd rather let my spec describe the help text (which argparse does automatically) than the other way around.
how full python it is? if it's not complete, why do you call it Python?
Beautiful soup is great, but sometimes I find it's returning blank spaces as an element a little annoying.
I use the buit-in STM DFU bootloader. If you look at the pinout of my board, you will see that BOOT0 is right next to 3V3. To enter the bootloader, you simply connect BOOT0 to 3V3 and reset the board. Then it appears as a USB DFU device for reprogramming. This way, you can never brick the board, and end users can easily upgrade the Micro Python image, or put their own image on, even one which has nothing to do with Micro Python. boot.py is simply the first script that is run, and sets up some configuration parameters for Micro Python. Of the 128+64 KiB available RAM, I currently use the 64 CCM block as a filesystem cache. This was a quick-ish hack to get around the fact that you can only erase large pages of the flash on the MCU, so I needed to buffer an entire page in the CCM. It also simplified other things, since the CCM is a separate memory range. Hopefully I can reclaim most of this memory for Python. Of the 128 KiB, if you have no hardware drives, then pretty much all of it is available to Python. With the drivers I currently have, they take up around 12 KiB (mostly USB buffers for VCP and MSD, LCD buffer, and FAT block buffer), and I have allocated 16 KiB for the stack, leaving around 100 KiB for Python. At the moment there is only a single thread running, and context switching is just prioritised interrupts. Making it a true RTOS (or embedding it within an existing RTOS) would be a great idea, but is really out of the scope of this project, at least for the time being. Simple threads may be supported, if I can think of a neat way to do it. You are right that it's more of a tinkering board, and the last thing I want to do is decive people as to its capabilities! But there's a lot of scope for tinkering, and maybe one day Micro Python can mature into a proper RTOS suitable for more serious applications. I think I've made a useful step in that direction, and wanted to share that -- to gauge interest -- before stepping further. You can't do everything in one go! Thanks for your interest and valuable feedback!
Thanks for your pledge! I'm not quite sure about price later on, it depends how the Kickstarter goes and how the manufacturing of the boards turns out. Probably best to get one during the campaign so you get it early and at a good price! Anyway, you can always make one yourself after I release the schematics and gerber files.
Leared about [sh](http://amoffat.github.io/sh/). Seems great, can't wait to find a place where I can use it :)
Everybody should try 'antigravity' at least once.
First glance understanding is a very important part of Python. Half the reason I like Python so much is that I can grasp much of what is going on at first glance and not have to turn the mind into a decompiler. As for Lambdas that is easy, introduce braces. Well braces or some other begin / end pair that causes Lambdas to standout in the code visually and can throw Python into a mode that deals with the lambda. Now I know many will throw fits when it comes to braces or similar block defining pairs but I actually think it makes lots of sense in the case of Lambdas. 
You want [learn python the hard way](http://learnpythonthehardway.org/book/).
If they haven't killed the print statement I would have moved already. 
Looking into it now :)
You should sent a message to Dev about this issue. 
Wow that was a quick response. To be honest I haven't had the time to dive into your challenge here. So the comments below are My minimal thoughts about your response. &gt;Thanks for your valuable feedback regarding the license. This is a tuff one no doubt, but honestly it should have been resolved before the project hit Kickstarter. I'm extremely biased against anything GPL related, this isn't the place to discuss why other than to say it is the work of people out of touch. That being said I'd suggest BSD. Or consider using the Python approach. &gt;It was important to support Python 3.3, since that is the future! Glad you also agree. Yes, it would have been a waste of effort to support the 2.x series in a new project like this. I wouldn't have bothered to even respond if the controller was running 2.x &gt;I can't decisively say that Micro Python could/couldn't control a 3 axis CNC machine.... But my guess would be that it could, so long as you use something like an A3977 as the motor driver to control the current. Actually I would be looking at pulse and direction output that would need to be rather high speed. This brings up all sorts of questions about how Micro Python handles interrupts, threads, assembly and the like. Again I haven't reviewed the site in detail but no one has ever called Python realtime. &gt;I can tell you though about the serial USB support. Micro Python implements a composite USB device. Thus, when you plug it in to your PC, it acts as *both* a mass storage device *and* a USB serial device at the same time. Under Linux, I run "picocom /dev/ttyACM0" to get a Python REPL, and at the same time can mount/umount the device /dev/sdb1 (and also /dev/sdb2 when the Micro SD card is inserted). Ok that actually helps out a lot. However I see the board has support for other serial hardware, the question is can they be used for for RS232. If so an API that closely follows or is developed upon Pyserial would be nice. I actually see the lack of an old fashion RS232 port as a shortcoming in the embedded world. If a follow on to this board is ever considered ( I suspect success here) I'd strongly suggest at least one or two dedicated RS232 interfaces. Dedicated hardware may slight reduce flexibility but I'd prefer a solution that doesn't require fiddling to talk to whatever external device. I know many see serial ports of this type as dead but I don't see that as the case at all. If Pyserial is there to provide an API you have both the hardware and software sides handled. &gt;So yes, it supports 2 way communications (that is how the REPL works). And I don't see any problem with using this to stream G-Code. At the very least, the Micro Python board gives you the powerful STM32F405 chip running at 168MHz which you can program with your own C code if you need every clock cycle. This brings up another question, Python is normally associated with real operating systems to help support some features. Do you have some sort of micro kernel running under Python to support threads, interrupt handling and other things that maybe Python shouldn't be concerned with? 168 MHz is very fast compared to some G-Code processors for example but other systems require far higher performance processors. The hope right now is for middle ground performance. 
I dislike them removing the print statement, but I'm totally on board with .format and use it exclusively in 2.7. I actually find it less verbose, in a sense of the amount of higher cognitive effort required to write and parse. I mean, for example having to specify argument indices in 2.6 was a big put off, because it requires actually _thinking_. Like, counting stuff. Reading or writing ".format" instead of " % " doesn't require thinking. On the other hand, thinking about whether the right part of " % " should be a tuple __does__ require thinking, and a lot of it (comparatively), and especially if it's error handling code that I want to get right on the first take, and that bothers me a lot. So not having to think about it ever again felt really liberating. `.format` also scales gracefully to more complicated templates thanks to keyword arguments. And I managed to actually memorize the alignment syntax somehow!
 [Pomp](https://bitbucket.org/estin/pomp/) - networking and parsing libs on yours choice
How could `reduce` possibly be faster than `+=` (aka `.extend`) in a loop?
Try [opster](http://opster.readthedocs.org/en/latest/). You write a decorated python function and it builds command line interface to it.
Is there an alternative that you would recommend?
The problem is that i am using the free version of wordpress which means that i can not make any changes to the theme. As soon as I buy premium package I will change the font. I might make a grease monkey extension for the time being for those who are having problems with my blog.
I've tried it. Its neat. The help usage documentation is much, much, much clearer than reading a whole bunch of code checking the args. You will need to produce the help text anyway. When doing that it makes sense to follow the POSIX standardized format for the help usage. Even if you do your own argument passing it would be a good idea to follow the standard. It's not complex or it's own language and there isn't really anything that's hard to follow and there are really only a few simple rules, things like (--help | -h) for exclusive options. -f &lt;file&gt; for a named argument. -f &lt;file&gt;... for multiple args. The most complex thing is [--] which tells the processor that anything after optional -- is an argument (the point of that is purely in case there is an argument that begins with a -). If a developer can't grok that in about a minute you probably don't want them near your code base anyway. From the developers perspective you don't even really need to know what's going on, just under that that the output of docopt contains the args. Basically you can turn your option parsing into a single line that outputs a dict and will automatically dump the usage if it's mistyped. Maybe there is some uber complex commandline option setup that docopt cant handle, worst comes to the worse you can use docopt until you encounter than then go manual. You haven't wasted any time since you still needed the help screen.
you should probably decode ascii with the error method set to ignore if you're doing this.
I did a very lazy look through of the source, this is a really nice and tight minimalist library, I already have a couple use cases in mind, thanks!
Everything has to be well organized and designed. You need to know what you want and prepare it before coding it. Big projects are not something that you want to have to hack together or workarounds. It may need a lot of refactoring if you don't prepare. Other than that, classes are always a good idea just because it helps separate ideas and objects (especially when you're doing a game). I prefer vim, but you can use anything. However, the more efficient you are, the better you'll be especially when working with a lot of files and code. Tests. I'm rather new to them myself so understand why they suck to write, but even I have to admit they're invaluable especially for a game. Instead of having to run your game and go through all the motions to see whether you did it right, you can just run your tests and get (almost) instant information back. When you get far into the game (if you do), that time you saved helps. It does mean some extra time getting set up for your project, though, but I believe it helps. If you want some help with coding or even the storyline, head over and post to [/r/progether](http://www.reddit.com/r/progether) one of us there most likely will be glad to help out. I'd be especially interested in helping with the storyline; that can be the most fun part.
This is really interesting stuff. Where can I go to learn more about how I can make use of PNaCL running Python as part of my app?
:D Don't worry I will. Thnx for your interest in telling me that.
&gt; Probably best to get one during the campaign so you get it early and at a good price! Actually I pledge to get 2! &gt; you can always make one yourself after I release the schematics and gerber files. Yes, but my concern is more around the fact that it's usefulness will be based on how much making one, or buying one made industrially, will cost. Look at the rasberry Pi, PCs have been around for a long time, but being able to buy one that is small and very cheap created a whole new market. Price is important.
It isn't actually true that I need to produce the help text- argparse does it automatically, and spits out a usage message (and quits) on -h or --help. It's probably my favorite feature of the library. argparse also does a usage dump if the user gives incorrectly formatted arguments. Just to be clear, I'm not advocating "manual" (sys.argv) argument parsing. That's madness. I'm just having trouble seeing the advantage, other than novelty and terseness, in using docopt over the more traditional argparse.
Just wondering if a Qt port is possible, would make a nice framework for heavy client side business apps. Well startup time is a bit slow though. Pressing Ctrl-D closes the tab, nice :)
I've never used the Python binding so I can't speak for it specifically, but inotifytools is a GREAT little toolkit.
The fact that the inner loop is now running in C. For millions of (fairly short) lists I can see this making a huge difference.
THANKYOU. Checking out Vim now. Classes do seem to be the way to go: I'll likely set up one for each enemy, equippable etc. /r/progether looks like a great place, will post there soon if I remember. I'll get back to you with a storyline. ^possibly^although^I'll^probably^forget
Yeah, I just came to a similar conclusion while benchmarking. I also tried another approach of making the extend method a local variable to reduce the function lookup overhead and it was the only one which was consistently slower than the other two, so that's a pessimization in this case.
TLDR; spend effort on the design and implementation of your environment to allow focus on product design.
What k0t0n0 says is very simple. scrapy and p0mp seem very rigid and it takes a learning curve to use them. for my task of doing depth first parsing of a tree rendered on an html page I think the simple basic tools allow me to get going fastest. so I upvote this, because the obvious and unelegant approach is sometimes best.
oi
I'd love to see pyqt there. But really C++/Qt wouldn't be that bad too. I would love a nice GUI program to replace the ugly HTML-JS-CSS-MVC lib of the week mishmash.
Definitely worth the read, it gives a nice outline of how one would actually setup the environment.
oiiiii
No problem. Vim can be really hard to learn if you just want to get started up. An easier way to get your foot in the water may be with an IDE. Feel free to post whenever you want. Just post a really basic storyline and we can just roll with it; you can just pick and choose from the trheads there.
Very cool project, glad to see it's close to being funded. Is there any technical documentation available yet (maybe for the pyb library)? I'd love to see how inline assembly works in particular. BTW I feel like it might be nice to have a more objected oriented API like `pyb.servo[1].rotate(45)` vs. `pyb.servo(1, 45)`.
not sure if this is exactly what you are talking about... but I use structural folding in the WING IDE http://www.wingware.com/doc/edit/structural-folding 'The editor supports optional folding for Python, C, C++, Java, Javascript, HTML, Eiffel, Lisp, Ruby, and a number of other file formats. This allows you to visually collapse logical hierarchical sections of your code while you are working in other parts of the file.'
KDevelop can do that.
Haha Vim is confusing... recommendations on an IDE to use? 
Nice links btw. Its nice to have them compiled somewhere to refer other people who want to know about the BDFL.
Since you like Visual Studio, download Python Tools for Visual Studio.
It may be better to search reddit for some threads (there are tons of them), but off the top of my head: pycharm, eclipse pydev. . .
Yeah, this is what I wanted, saddly it costs moneys. Do you know of one that (or if wingIDE) can change between tabs (opened prog.py) with CTRL+TAB?
I never miss an opportunity to recommend PyDev to EVERYONE. It's a fantastic development environment. Of course, if you want something more lightweight, Sublime Text supports collapsing too.
This one looks nice. I see it's for KDE, here at school they have fedora, wil that be a problem (maybe a dumb question but i'm fairly new to Linux)? The thing I like about Canopy is that packages are EASY to downloa/install (I actually downloaded Canopy at school because I didn't know how to install some libraries I wanted to use, I did what the documentation said with no response)
A help message shouldn't be very hard to parse in your head.
Do you need to have Eclipse also for PyDev to work?
Python has a dynamic runtime, dynamic typing is unrelated.
For Python 3, I quite like [plac](http://plac.googlecode.com/hg/doc/plac.html#scripts-with-options-and-smart-options) - it's a similar idea to opster, but it uses function annotations instead of the default values.
I too enjoy breaking games with Charles! I've found some pretty bad login exploits that way, and of course hundreds of ways to break games. What it comes down to is, at what point do the developers just not care about people hacking network calls? I'd argue that, so long as you aren't directly or indirectly harming the experience of other players, it's not worth putting in the robust server-side checks that preventing this type of exploit would require.
I use it for my open source project and at my work. It's incredible. The code is so clear and you can do things with it that you can't do with argparse. The video on the site goes into what fundamental limitations argparse has. It's also pure python and on pypi, so there are no complaints from coworkers about added package dependencies.
Spend 1/2 an hour trying docopt. I went and converted all my working argparse code after doing that. It's worth the effort.
I'm always suspicious of myself as an API designer - it is too easy to add unnecessary complexity here and there, esp. when creating CLI for some existing library/project. Docopt restricts you: no complex argument parsing logic, no complex rules, just some standard syntax. And you actually start with writing help for your CLI before you start writing parsing code itself, this also makes the resulting interface cleaner. So the problem docopt solves for me is a problem of writing sane CLIs easily. Other non-standard argument parsing libraries (usually providing some decorators) also make it easy to write CLIs, and standard optparse/argparse are not that bad, but what is special about docopt is the "sane", "restrictions" part. Docopt looked like a horrible idea for me until I realized that. Not all people need those restrictions, but for others they are a killer feature; tech details are usually easy, but API design is not.
I am with you and only use it without tuples and only because it is pretty. If my language has one quirk, let it be this one!
It seems he's pretty much reached his goal. Has he thought about maybe adding stretch goals to the kickstarter? 
+1 for Makefiles. Integrating pylint and pep8 is a cool idea!
Yes
I am working on my own ideas for a robot. I have split the design into two halves. A low level controller for doing actual interaction with sensors and motors. And a linux based computer to run the hi level AI on. I am writing the AI in Python. I am doing this because of how easy and fast I find I can prototype ideas in Python. For the low level stuff I have no problem using C or dropping to assembly. I learned to program on a 8085 processor in assembly. It is no big deal. But a chance to try out doing the low level stuff in Python is something I have been wanting to do. I did look at Python-On-A-Chip, but it only implements a subset of the Python 2.5 syntax. That just sucks. It really is not usable.
Thanks, I missed PythonJS! Also pyjamas was renamed pyjs.
Yes I know its standard, but you still have to format it a certain way in order for docopt to parse it correctly. And while pip is being included in 3.4, still annoying to have to install a library to even have the most basic part of the script (the --help, usage statements, etc) I just don't like docopt because of the reasons already listed, too 'magical', and doesn't save that much time or typing, an additional dependency, for something that argparse does equally well, but that is just my opinion =P
Anyone know an alternative to sh for a PC?
What about modules you should know from the standard lib? - functools - itertools - collections - urllib2 
http://docs.python.org/2/library/turtle.html#turtle-methods 
If I have understood you correctly then you can try out pycharm which has a community version and it is able to hide your code. Mainly it hides the class and functions. Do give it a look as it is one of the most feature complete free python IDE out there (It has a paid version as well)
stuff that's implemented in C in numpy essentially
I've used it a few times and for my purposes found argparse to be the better solution for a few reasons: * Argparse includes built-in logic to validate arguments. With DocOpt you're left with less maintainable options: writing a bunch of code on the side or using something cryptic like schema. Argument validation is a make-or-break deal for me, so this is enough to settle it as far as I'm concerned. But there are other issues anyhow... * DocOpt is still evolving and changing. Not mature enough to deal with (for me) yet. The developer originally bragged about how it was a fraction the side of Argparse, but handling edge cases had made it grow enormously. Some basic concepts are still being discussed on its github pages. * Both ArgParse and DocOpt have great documentation - for basic cases. When your needs get a little odd either can be frustrating. For ArgParse I've found subcommands to be too frustrating. For DocOpt I wasted far too much time on supporting multiple identical options. Eventually had to read the code to get an answer. Ugh. * Personally, I don't believe that the help I want to provide users is always exactly what I want to use for developer documentation. While it works fine for easy examples, the needs seem to quickly diverge with complex examples. The fact that it's based on a POSIX standard isn't helpful either - when few people know 100% of that standard.
Not to toot my own horn too much, but I created a similar flask setup on [github](https://github.com/JackStouffer/Flask-Foundation).
Pycharm is going to be the best option here, in my opinion. It has more features than most other editors, it's free, and a lot easier to learn than vim/emacs.
This first thing I do when starting at any company is have them purchase a site license to Charles if they haven't already. An essential tool.
This was a great article. I actually learnef quite a bit
Basically every editor out there supports code folding, either out of the box, or via an extension. Vim, emacs, gedit, nano, ... http://en.wikipedia.org/wiki/Code_folding#Software_with_code_folding_capability
I was hoping for a bot that would play the game. I was also hoping to evidence that Candy Crush "cheats" by purposely sabotaging games by providing least likely to be useful pieces rather than simply randomly supplying new pieces. But this is still cool.
yeah, I was kind of excited to see an analysis of the best moves to make on a board and a method of automating the execution of those moves. :-)
&gt;Writing for selenium is basically writing a set of actions and feeding them to a browser (usually Firefox, but it can work with others). This also works in reverse with the Selenium IDE. You can record the actions you take in a browser and the IDE will automatically insert commands into your test case. http://www.seleniumhq.org/docs/02_selenium_ide.jsp
just wat i needed … i will use it … thanks
Actually the way to go is to use the `+=` operator, it shaves off a noticeable overhead (values for 3m items on my I7): sum_loop: 0.49 sum_reduce: 0.73 sum_loop: 0.47 sum_reduce: 0.73 sum_loop_plusequal: 0.38 sum_reduce_plusequal: 0.66 sum_loop_plusequal: 0.38 sum_reduce_plusequal: 0.67 The reason for that is that the `+=` operator is dispatched via a straight lookup in the class's C structure, while `.extend` has to be looked up in the class dictionary (though IIRC there was some sort of `dict` optimisation where it cached the last looked up key location so it's not as bad as you'd expect, but don't quote me on that). As for making `list.extend` a local variable, you are hitting the same problem, I think: it is now an ordinary function with all the overhead, apparently (*edit:* an ordinary python function wrapping a C function call, so even worse). And yes, it pessimizes pretty hard, from 0.47 to 0.7 seconds here. On a side note, it would be an enlightening experience to launch Python under a debugger and record all actual lines of C that are executed during one iteration of the loop (or reduce). Why don't you do it, eh? =)
this gives me `Browser does not support PNaCL or PNaCL is disabled` on chromium 30.0.1599.114. is my version too old or do I need to do something?
I don't care about a site license as much as I care about one for myself. Much easier sales pitch.
I mean, my hatred of unnecessary thinking directly leads me to using `.format` everywhere, just so that I don't have to think what should I use. Try it and you might find that having all code using the same formatting operation is prettier overall.
There's only so much you can do before you start hitting diminishing returns. 
Exactly. As long as you aren't hurting anyone else, it is basically like a 'bonus level' to the game.
I agree about the ease of adding unnecessary complexity. There were a lot of times I added far too many or just unintelligible arguments to an interface. Over time I've developed a process where I'll write out my help parameter first and foremost so that act of explaining the CLI keeps me from going off into the wild blue. It's all just process and different development style for sure.
Thanks ! I'd like to know what your use-cases are, as I might stuff the wiki with some examples. Wanna share ?
Already wrote a tiny script that uses a web socket to pass function names to the server and returns the result. 
It's one thing to understand what the interface- what I as the client need to know- and another to understand exactly what behavior this system will have. Even if it's perfectly straightforward, it's still another syntax I have to keep in my head
True. But can't the same be said of argparse's code? 
Glad you liked it ! I hope it will fit your needs :)
I personally don't think so- argparse is all function calls. Now, granted, I've never used some of the advanced features of either library (subcommands, mutual exclusion, etc), so maybe docopt has me beat here- but I find argparse code much easier to read, especially when I'm already in a Python development mindset. It's just a list of every option and argument, with some properties for each.
You can use the Selenium webdriver with Python as well. Although I have only direct experience with using it with Perl, Python is well supported: http://selenium.googlecode.com/git/docs/api/py/index.html 
Never used Charles before but it seems interesting. Is it a WinRar/Sublime Text-esque license? That is, after the evaluation period you're reminded to buy it but still free to use the software? Or does it lock you out after 30? 
I can't comment on the developer attitude, but what are the issues with it on linux? I used it there recently, and didn't have problems with it. Granted, if I tried to start it on too large of a directory, it would take forever to start. Does that issue not exist on windows?
Stuff I'd never use, so I don't care that much, but it's discussed in the video on http://docopt.org/ &gt; Well, it itself is a package dependency It is, but it's such a simple one that nobody cares. One that's not on pypi (numpy, scipy, matplotlib, internal pacakges) and has dependencies, people care a lot about.
Too bad `import antigravity` doesn't work
Unfortunately I'm sorry to say that Candy Crush is a glorified roulette table. The stars have to align just right to be able to win just about all of the levels in the game.
I once wrote a solver for a facebook Tetris game, which worked by reading the screen and sending keystrokes. Unfortunately I'm not very great with AI, and it was only as good as an average human player :p
Ha! I was pretty obsessed with making these kinds of bots when I was first learning Python. I also suck at AI, so the bots were super fast at performing specific actions, but so dumb that a slow but moderately sane human could out perform them just by making better choices. 
So it becomes a speedhack challenge? Sounds great!
It's not like you lose what you learned in the previous 30 minutes. It's just an annoyance. :)
Your link to Sphinx is broken, being interpreted as a relative path.
Remember the [Rogue-o-matic](http://en.wikipedia.org/wiki/Rog-O-Matic)? Original paper [here](http://www.cs.princeton.edu/~appel/papers/rogomatic.html). 
this is what I was looking for when I opened the link. Still a nice list.
One of my favorite assignments back in college for CS was to create a Sudoku solver. The goal was to have a recursive brute-force method, you would get full credit for that working. But I remember you would get extra credit if you made it "smarter". In the end, my brute-force method would be faster than my smart filtering attempts, but would hang intermittently on some edge cases.
Thanks. The link really seems like "Python modules I think are cool right now." Nothing on there was a "must have" and they all require external packages. Remember you always have access to the standard library.
Interesting...
Nice read... (Goes back to reinforce client stats with server verification)
Yes, the goal has been reached! Thanks to everyone who has pledged so far. I didn't expect it to go this quickly... I'm thinking about strech goals now, but feedback from you guys on this would be great. What sort of things would you like to see?
Naming is subject to change from what is shown in the examples. In particular, I want to make it "Pythonic", and something like your suggestion for the servos looks good. I'll get to posting about inline assembler examples as soon as I can.
* Pdf user guides * New libraries (maybe even popular third party ones) implemented * Recipes of some of your favourite designs * Technical documents on the chips used Or you could even just add more items to each pledge (It seems a bit counter-intuitive but it could work). I.e. "If I reach £20,000 all micropythons will come with with a graphical LCD".
Is this any better than [Fiddler](http://fiddler2.com)? We use that pretty extensively, but I'm always willing to try something new.
Excellent. I've had idle thoughts about this sort of thing before but never looked into it.
How many companies have you started?
That sounds interesting. I really want to learn this stuff, and I will be investing some time in it over the next few days. The issue is just that for right now I need a solution that's as close to working right out of the box as possible, so if I could take a look at your code, then I could implement it or something similar and we can discuss it later. I'd love to learn this. 
Take a look at this library. It is much more out of the box than my code. It looks easy to use and not specific to patents like my code is. http://radimrehurek.com/gensim/ 
Is there any overview of what is working now and what not?
Charles and Fiddler have been developing in parallel for a long time, so I'm not sure how they compare. One thing that is a life-saver in Charles is [Map Local](http://www.charlesproxy.com/documentation/tools/map-local/) which allows you to map remote requests to a local file. This means you can access a production URL, but have some of the URLs point to files you are editing locally (like JS or CSS files). Charles also supports bandwidth throttling, DNS spoofing, and many other features. I'm not sure how that stacks up to Fiddler.
Thank you. I feel silly now.
how about `open` for files? Write unlimited data to disk?
This is a great post. Thanks for sharing :)
This is exactly the catch that keeps people playing, many levels simply cannot be passed no matter your skill level and it's easy to think "Well idiot 'X' can pass it, there must be something wrong with me if I can't too". Assuming the RNG isn't terribly broken that just means we can't necessarily determine an optimal move for a given state but we can take a guess at it with a lower confidence. The only catch is that confidence drops exponentially. As someone who has sunk a bit too much time into it, there are some tricky things from a strategy point of view. An example is that a few levels have tripped me up with the score requirement, it wasn't too hard to meet the other requirements of the level but I had failed to collect enough collateral damage along the way, in these cases, the rules change and you have to actively avoid meeting the other requirements, while leaving the state so that you can do them in a move or two and try to do things to increase your score.
Nice, I usually use kaa to edit reST files, so this change is really helpful.
http://www.uclassify.com/
Wow! Definitely fww very relevant talks to what I need.
Yup, too old. For Portable Native Client you need Chrome 31.
Please take a look at nice screenshots! ;) http://kaaedit.github.io/ 
For now, I'd avoid focusing on things like IDEs, code editors, etc. If you're a beginner, the number one way to improve is to continuously work on projects and programs, and trying to learn a complex IDE could just serve as a distraction. Plus, if you use a minimalistic code editor (like Notepad++), you're basically forced to learn to use the command line, which could be another good learning opportunity. Try and use Python for literally everything. If you're doing homework for math or science classes, for example, try and use Python as a calculator, to automate the work, etc. It might take longer then just doing your work normally, but you'll be potentially able to learn two things at once in compensation. For large projects, try and avoid coding everything at once. Carefully plan out what kinds of things you want to code, and then prioritize them, making sure you test your code very frequently as you're developing them. Then, try and write the absolute minimum amount of code possible to get a bare-bones version of your program working. This is your skeleton -- your proof-of-concept (which is useful for mocking your the overall structure of your code). Continue adding on more and more features, fleshing out the skeleton, and refactoring as you go. For additional ways to learn, try going to stackoverflow.com, picking the 'python' tag (or any other tag that sounds interesting to you), ordering the questions by their score, and just reading the top 10-20 posts per tag. Initially, you won't have a clue what anybody's talking about, but as you keep googling and reading, you'll get a glimpse of advanced topics you may have never stumbled on by yourself and good introductions to various useful topics and methologies. 
Candy Crush is just a slot machine that makes you believe your choices matter.
 I have actually been thinking about the algorithms behind Candy Crush. But instead of just solving Candy Crush, I have been thinking about how one would go about building it. I have narrowed it down to a couple of majors problems that I need to solve. 1. Once you start removing candies of the board how does the game decide what candies to add to the board next. For example if you were to remove a row of green candies what candies would you add back? Would you add back 3 green candies? Replace the green candies but over 3 turns? Or just pick 3 random colors? 1. This also leads to another major problem of making sure that each level is solvable .So there must be a second algorithm used by the level designer that would try to actually solve the level using and figure out how many different ways you can solve the level (picture a tree like structure). One solution that I have thought of is to first keep the right ratio of candies. So if player removes 3 green candies try to add back those 3 greens over a couple of turns but also make sure that there is a nice spread of candies , if same color were added next to each other , the game will just solve it self. As for the implementing a solver itself I think it’s pretty straight forward to brute force candy crush . You can look at Flood Fill algo for ideas. If you actually play candy crush you will find that it’s actually very polished in terms of how level difficulty goes up. I have never actually been stuck at a level for more than 3 times.( Maybe this because of the make it easier on purpose on the second attempt.) 
The [coursera scala](https://www.coursera.org/course/progfun) course by Martin Odersky (the designer of scala) had the last assignment to write a simple solver shortest path (bread-first-search) to the flash game [bloxorz](http://www.coolmath-games.com/0-bloxorz/) (given text input of the game state, and slightly simplifying the rules for the class).
wow lol
you mean "collapse/fold"
I'm always suspicious of people who say they try to avoid frameworks, smells of NIH syndrome.
`defaultdict` has superpowers.
Now I am kinda bored by this. If anyone wants me to make one I can make it but I myself don't need one. :D
I expect it's the functions and the loops which are causing you problems. The basic commands will be a 1-to-1 mapping to functions in the turtle module. What I'd do: * Start by reading the file line by line * When I hit a "to &lt;somename&gt;", I'd start a list, put the lines inside into the list and store it in a dictionary under &lt;somename&gt;. This dictionary is now your function table. * Once we've finished reading the file, I'd then process each function, working on repeat loops. Easiest thing is probably to replace each one with it's lines replicated 'n' times. * Then I'd have a final function, let's call it interpret(&lt;functionname&gt;), and call 'interpret("start")'. It would go through each command in the start function, calling the turtle module as it went. When it hit a function call, it would call itself with the function name. e.g. 'interpret("house")' That should do it.
Requests is great, but without keepalive support, using it in applications making lots of requests is a no go. 
see [NumPyPy Status: how much of numpy can you use in pypy?](http://buildbot.pypy.org/numpy-status/latest.html)
pylint, pyflakes and pep8 can get integrated fine into vim by using the syntastic plugin and it requires exactly zero additional work to see the warnings and errors - they are displayed as soon as the file is saved i like to see there are no problems before actually wanting to commit this is an editor specific solution though, not everyone is using vim
Unless the pages actually build the content purely out of JS relying on no backend (never seen this happen), you're better off just figuring out the web APIs the JS is calling and calling them yourself
your code is either binary, and therefore numbers. or it's text and can be decoded to unicode. I don't see the problem really. why do you need numbers as malformed string?
Very cool stuff. Guess I'm playing with scraping this weekend.
Awesome, thank you. I'll try this out and let you know !
Thanks !
Thank you so much. Will give it a whirl. 
So? Unicode code points are numbers too, but taking `"§ 2.4"[0]` doesn't yield `167`, because that would be a massive pain in the neck. Furthermore it's always been Python's way to treat characters as strings of length one. `bytes` objects are no different, merely lists of a different type. If I want a code point or integer value I have `ord()`. I have data. It's *mostly* textual but to pretend it really is unicode would be utterly wrong. Maybe it comes off of a serial port or a weird mostly-ascii format or IRC or some other archaic setup that was designed before unicode was a thing and likes to mix random high-bit characters in. It's still sensible to think of bytes as a string-like thing because that's exactly what they are, for virtually every single operation (string of bytes vs. string of unicode characters). There's even e.g. an `upper()` method that really doesn't make any sense for true random binary garbage, but does for semi-text. They're string-like things in every way. Except one! Because for some unfathomable reason the Python devs saw fit to make this one *really* important operation one often does with string-like types behave completely insensibly. it's broken just by virtue of being *different*, as it defies my expectations (so far, every single time I go to do it).
What does it not recognize already exactly?
Why require python 3.3 ? Ubuntu 12.04 has only 3.2 ....
Take a look at how Go does it. It makes a lot of sense. Exceptions should be reserved for totally WTF happenings in your code. E.g. a totally unhandleable (in the contenxt of the current function) thing happened and we need to bail. Otherwise, such stuff like "a file doesn't exist" or the network goes down should be simple errors. Works well in practice. Needs some reworking to apply perfectly to Python but...
Based on what? Am I blind or this seems totally arbitrary? http://www.crispycodes.com/blog/industry-news/python-popular-programming-language-year.php
The Command Palette gives fast access to functionality. Here Ctrl+Shift+P is used to show the Command Palette, "sspy" (short for Set Syntax: Python) is used set the syntax of the current file to Python. i found that in the image slideshow on the sublime homepage.
If I were me, I would raise an exception if I were expecting other people to use the code, or to indicate an error that happened before or after processing. If an error occurred during processing, that's where I'd return None, False, or 0, depending on whether it would be a valid output for the function. Examples: I have a function that requires some basis of validity. If I am not passed two proper arguments for my function, I'll throw an exception. But what if I have two proper arguments but the data doesn't come together in a sensible manner while performing operations on the arguments? If it's math I'll return None or 0, if 0 is a valid output. Boolean? False or None, depending. 
I wouldn't advise this. Go doesn't use exceptions as a part of its flow control, python does. So emulating how Go handles exceptions isn't a good idea. I do agree though that exceptions should be kept for more serious issues, but if the scaffolding design of the project is good, its not necessarily bad as they are transit and can be caught anywhere. I guess it really depends. 
[TIOBE November](http://www.tiobe.com/index.php/content/paperinfo/tpci/index.html): #8 [TLPI July](http://lang-index.sourceforge.net/): #7 [PYPL November](https://sites.google.com/site/pydatalog/pypl/PyPL-PopularitY-of-Programming-Language): #3 [RedMonk January](http://redmonk.com/sogrady/2013/02/28/language-rankings-1-13/): #4 [Trendyskills November](http://trendyskills.com/): #8 I still can't find what the source is for this. But rest assured, the popularity of Python is all over the place.
I had a similar problem when I first got started, maybe my solution will help you too: From within Sublime Text 2 go to Tools&gt;Build Environment&gt;New Build System. Set the new environment to: { "cmd": ["C:\\python33\\python.exe", "-u", "$file"], "file_regex": "^[ ]*File \"(...*?)\", line ([0-9]*)", "selector": "source.python" } Where the first line reading &gt; "cmd": ["**C:\\python33\\python.exe**", "-u", "$file"], points to the Python interpreter. Save the file as whatever and select the build environment to use the new environment. From there it should parse correctly. -------------- If your slightly more ambitious you can find the default Python build environment on your disk and edit that file to read as the new customized one. For me, that file path is: &gt;C:\Users\Blinity\AppData\Roaming\Sublime Text 2\Packages\Python\Python.sublime-build 
I want to know it too. But I already using Python 3.3 for developing individual products, so I don't feel any antipathies about it. (I use newest Mint linux.)
Github says javascript.
If you do this regularly against certain websites, particularly a certain one that has a "download this gallery as a zip" function, they sometimes recognise you and feed you a dodgy zip. I have received [zip bombs](http://en.wikipedia.org/wiki/Zip_bomb) and various other things I shouldn't. Don't stop, but do program defensively!
If you get stuff from a gelbooru-style imageboard (I like http://idol.sankakucomplex.com/ ), there's an api you can use to do all sorts of useful things . For instance, I wrote a small script that downloads the tags for an image and writes them as metadata. Edit: Forgot the link - derp! https://github.com/xiongchiamiov/sheska Edit2: And the API docs: http://danbooru.donmai.us/wiki_pages/43568
Love the feedback! How would you handle cases where expected pre-run conditions are expected but not set? I work with a lot of external datasets, which are maintained is varying degrees of integrity. So, if I am expecting data to be there but is not, the user may need to take specific actions to remedy the situation. Would you use exceptions to handle this? 
Although I wouldn't be surprised to see Javascript anywhere near the top, I'd suspect it would be one of the most difficult languages to evaluate based on LoC, because of the amount of source vendoring that goes on in most web-based javascript projects.
This does not apply to Python.
Yes. And only catch exceptions in places where you want to take some action as a result.
I would also question using something like github statistics, because it assumes that open source projects are representative of software use in general. 
Gotcha. In another vein of the same concept; For production, do you wrap all code in try/except statements to handle every case? The last thing I want in prod is a dump screen but it just seems like SO many try/except cases.
Pandas has a flag that gets passed in whether to warn or error on exceptions. It defaults to throwing the exception. 
Cool, thanks! Great info!
Thanks, that site is really useful. 
Never return an error in the same place as a value. If you must, use Go like pairs. *value, error = foo()* I say subclass Exception and use those everywhere. class NameInvalid(Exception): "Names must follow [A-Z][A-Za-z0-9]*" 
There's basically zero benefit to Candy Crush developers spending any time defending against this. If I were designing it, I wouldn't do it any differently either.
You can also use mitmproxy, but Charles is more user-friendly. It does shut down after 30 minutes, but if you reopen it it just keeps the last state. It wasn't that big a hassle while playing with Candy Crush, but I'd buy it if I used it often, just because it's a great piece of software.
I don't think it's sabotaging, the seed is provided before every game and sent back so developers can recreate the level. Granted, I didn't check to see what it actually does with the seed, but its mere presence suggests it wouldn't be sabotaging you.
Beyond the stuff that you want to actually act on you can just have one try/except on the highest function call: try: main() # or other code except StandardError: print "Bad stuff happened" Then you won't get any tracebacks. You won't need to have a separate except clause for each type of exception unless you want to act differently based on the type of exception. try: magic_function("Fake Stuff") except KeyError: print "That doesn't exist" except KeyboardInterrupt: print "User cancelled the function call by hitting Ctrl+C" except StandardException: print "I don't want to show you a traceback"
Of course it is ranked highest on PyPL
This can't be right. C# at 2.5%? JS at 3.9? No way.
Github not only hosts open source projects. There are LOTS of companies using it for their private projects. 
Java is 2nd in this data, seriously?
Because it's %, not /. % is named "modulo". The meaning of "modulo" is a bit different in arithmetics and in programming. In programming, the modulo operation returns the rest of an integer division. (x % 2 == 0) is True if, when you divide x by 2, you have a rest of 0. Every even number is perfectly divisible by 2 so have a rest of 0 when divided by 2. Odd numbers have a rest of 1: 9 % 2 = 1. Because 9 = 2 * 4 + 1. The behavior of the modulo operation with negative or floating point numbers is language dependent. You can use modulo for things other than testing parity. For example, let's imagine a game where the orientation of the character can be either East=0, North=1, West=2 or South=3. You can write the TurnLeft and TurnRight functions that way: def TurnLeft(orientation): return (orientation + 1) % 4 def TurnRight(orientation): return (orientation - 1) % 4 print TurnLeft(0) # We start facing 0 = East. 1 # Means North, this is correct. print TurnLeft(1) 2 # Now you're facing West. print TurnLeft(2) 3 # South. print TurnLeft(3) # Let's keep turning. 0 # Not 4, but 0. East again! Why did it automatically loop back to 0 instead of going from 3 to 4? Because (3 + 1) % 4 = 4 % 4, and dividing 4 by 4 gives 1 with a rest of 0, 0 being what we want. 
I see! thanks alot for the help! I am currently trying to teach myself python 3.3 and it is kind of challenging. I am using the Lynda videos, they total to about 15 hours long or so but they are using python 2.7 . I have to keep looking up the newer updated codes which takes a really long time.
That *has* to be growth and not just use.
Generally, I think exceptions are the more Pythonic answer. Use of `with` blocks can cut down considerably the number of try/finally or try/except blocks needed in the calling code. That way you don't need to wrap *every* function call in a try block; you just let the exception walk back up the stack to the point where the program can best recover from the error. Of course this doesn't preclude writing functions that will check for error conditions ahead of time. If your data is structured such that a `has_missing_data` function makes sense, then that could return a boolean and be tested before processing. But errors during processing should still throw exceptions in Python.
I forked the project it's pythonium https://pypi.python.org/pypi/pythonium-core/0.1 core it has some gotchas [1] but works better than PythonJS, code is also simpler demo: http://pythonium.github.io/ [1] method passed as callbacks loose the reference of ``this`` to the object the method is bound to. I'm working on fixing it.
thank you! I understand the print is a function and what I did wrong when i tried to correct it was add () at each ends instead of removing the ("today is:") bracket to the end
But are private projects included in these statistics?
 from __future__ import print_function for row in allrows: #print the date for each listing span = row.find('span', {'class':'date'}) datestr = span.text.strip() link = span.findNextSibling('a') link_anchor_text = link.text link_href = link['href'] print(datestr, link_anchor_text, link_href) * http://www.reddit.com/r/Python/comments/1qnbq3/webscraping_selenium_vs_conventional_tools/cdeq2t7 * http://schema.org/docs/full.html
They don't say whether it's growth or use, but they imply it's use. No way that is true. Personally I can't stand JS or C#, but I see they are very popular.
using [this SO answer](http://stackoverflow.com/questions/3051295/jquery-like-html-parsing-in-python#3051389) I found soupselect: markup = """&lt;div class="content"&gt;&lt;p class="row" data-pid="4122419039"&gt; &lt;a href="/clt/4122419039.html" class="i" data-id="0:00c0c_4v56o1Co1aK"&gt;&lt;span class="price"&gt;$265&lt;/span&gt;&lt;/a&gt; &lt;span class="star"&gt;&lt;/span&gt; &lt;span class="pl"&gt; &lt;span class="date"&gt;Oct 10&lt;/span&gt; &lt;a href="/clt/4122419039.html"&gt;Huge Chinese Porcelain Fish Bowl with stand&lt;/a&gt; &lt;/span&gt; &lt;span class="l2"&gt; &lt;span class="price"&gt;$265&lt;/span&gt; &lt;span class="pnr"&gt; &lt;small&gt; (Cherry Hill, New Jersey)&lt;/small&gt; &lt;span class="px"&gt; &lt;span class="p"&gt; pic&lt;/span&gt;&lt;/span&gt; &lt;/span&gt; &lt;a class="gc" href="/clt/" data-cat="clt"&gt;collectibles - by owner&lt;/a&gt; &lt;/span&gt; &lt;/p&gt;&lt;/div&gt;""" soup = BeautifulSoup(markup) soupselect.select(soup, 'div.content p.row span.pl a')[0].text prints the answer u'Huge Chinese Porcelain Fish Bowl with stand' 
Yea... Who needs sources?
Hmm, i don't love the matplotlib defaults, but i don't agree with the total removal of the ticks. Also it all looks a little too washed out. 
Nice, the script seems to do exactly what I need. I'll have to try it when I get back home. On a side note, do you have any idea how I could pull the description from each of the links for the listing? Basically I need to follow the link, and then be able to find whatever tag the description is under, and I can figure out from there, I guess. I just don't know how to get python, using beautifulsoup, to look into a link.
Well it could also be complete bullshit.
Why don't you create per-function discussion pages, or per-module forums, or a well-organized wiki, in which all users can share their experience of using that function/object/module, post their examples, and contribute to the documentation?
Strech goal: There's a port of the mbed to the stm32f4 , I'm not sure if it's finished. A combination would be very usefull. Add some wrappers to a few mbed libraries.A documentation of a C API. That's it. Other people will add wrappers, Pretty soon, you have a very versatile python mcu. Why mbed and not arduino ? so people can use it commercially.
Not really, some are incredibly easy to win, some are insanely hard. I'm on level 275 and the pattern hasn't changed much. Never spent a dime either. 
Ok, I solved the mystery! I used Google Image Search on the graph and followed the bubbles wherever they led! :-) Similar bubbliness showed that it's the most popular language used on CodeEval for 2012: http://blog.codeeval.com/codeevalblog/most-popular-programming-languages-of-2013 &gt;Statistics and Figures are based on a sample size of over 100,000+ challenges &gt;processed from Employers who have run challenges on CodeEval in 2012. &gt; &gt;CodeEval is a community of developers interested in solving programming &gt;challenges. Community members can compete with each other, challenge their &gt;friends and build out their profiles to showcase to friends and employers too. That is an interesting figure. Perhaps it serves as a "leading indicator"? A lot more jobs opening up in Python? 
While I don't doubt that there are lots, I doubt that they represent more than a very small fraction of, for instance, enterprise applications. I would imagine that a very large percentage of the production code in the world is written by companies that would never even consider storing their IP offsite.
Plus the few dozen VBA applications used at my work are just stored on network out of sheer laziness. I still don't know a good way to use git for them.
http://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags See the first answer from Marc
Show us some ideas/code that you have started and we can help you. I'm not trying to be a dick, but no one is going to design your project for you.
I wish I could support older Python including Python2, but curses module prior to Python 3.3 doesn't support unicode string. http://docs.python.org/3.3/whatsnew/3.3.html#curses
From your use case it didn't sound like you needed encryption, as much some sort of permissions. The fact that you are loading text which is valid Python doesn't make it much more interesting. In retrospect a database is overkill, I bet you could hosts all modules in a shared location and implement the rest with unix permissions.
God damn. They (crispycodes) just replaced the attribution with their own and released it with some vague BS article
IN GB stats I think that they are, in any other stats there are definitely not, most of them are based on this https://github.com/blog/1112-data-at-github
you can use [pyserial](http://pyserial.sourceforge.net/)
I was going to suggest Tornado as well. The key--if you want to provide users with the best experience--is to use Tornado with WebSockets. It's about as real-time as you can get and you don't even need a fancy client side framework (didn't need any libs for Gate One).
Absolutely - I've been extremely impressed with its readability as well as its flexibility.
In production, you should have a top-level exception handler that logs unhandled exceptions. For web apps, [Sentry](https://www.getsentry.com/) is a nice choice.
I've been on teams that rolled out brand new products in COBOL. Fucking banks. SMH.
[For those interested](http://www.crispycodes.com/blog/industry-news/python-popular-programming-language-year.php).
 &gt;&gt;&gt; isinstance(self, Pythonista) True &gt;&gt;&gt; self in Fun, Loving, Developer True
i worked at a hiring firm last year (europe) , the most popular were (for around 3000 recruiters): -1 java/jvm related (like 30% of hires ) -2 C# (20) - 3 php (20) - 4 c/c++ (10) - 5 python (10) - 6 objective C (5) .... i do not count JS since most businesses assume you know it too, but there is very few nodejs hirings ruby used to be big before , but business are moving away from it, not sure why. python is getting a lot of traction today, and it's big in analytics and advertisement related jobs. Recruiters have hard time finding python devs because they need a solid math and science background too. the highest paying jobs were C# related. PHP was on the lower end,
Hi .. So at the beginning of the talk it sounds like this implementation is only possible on Windows because of the way the OS is written. But at the end you say you are looking for funding to implement this on Linux. So would you need to change the Linux kernel to get it to work or not ?
This should give people incentive to learn or improve their Python... you know... for the learning experience.
Normally c# numbers are low in polls like this since they use github numbers. 
Every year I evaluate my main programming language, to make sure I stay pertinent in the job market. In the past months I've increasingly come to believe that python is the next language I should probably hop on. But having seen similar claims about its popularity, I couldn't really find conclusive evidence of that or it making me more marketable. However, one thing struck me as peculiar. To make a web-python program, you have to go through unusual steps to both setup and deploy a program/project. Steps that aren't typically available out of the common web hosting box, and steps that probably require use of a CLI. In short, is python an elitist's game now?
java is fucking everywhere
YES!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! +1
yes of course, you can use subscribe and publish methods and write filters based on the meteor session, which you depend on meteor router package (although there is now ironrouter package on atmosphere, but this was about the time I got canned it was too late). Mongodb itself is really questionable, lot of problems that could be solved with just a simple RDS, doesn't really work. Also the query is butt ugly as hell with nested JSON objects, it's up against the masters like PostgreSQL and MySQL and just because it got funded a couple hundred million dollars doesn't mean crap. Node.js no argument here, but again I feel a lot of hype, even the founder of node.js said it best, 'too much hype'. Also, JVM server even GO HTTP server kicks node.js butt in terms of performance and efficiency. Checkout the techempower benchmarks. Those companies you listed are already going down the crapper. You left out Google (rapidly becoming more evil and silent about it). Samsung doesn't even use it.
Python isn't PHP, is that what you're saying?
Well that's some unsourced data. Awesome. Can't tell what it means because who knows where it came from.
I realize you asked about the **fastest** way to implement this classifier, and that the sklearn API can be quite cryptic at first. I hope you'll manage! 
Please consider using requests instead of urllib. You won't regret it.
&gt; source vendoring ?
just use any old text editor! notepad, notepadd ++ (windows) nano, sandy, emacs, leafpad (millions on linux). nano is a solid, simple editor. IMHO, using an ide will make you ignorant to whats happening behind the scenes, and that is always bad.
The problem with using google count on "Python" is that if there is an increase of python (the snake) attacks on humans, or some other reasons pythons (the snakes) make the news, then Python (the programming language) does very well that particular year.
What? Haha, no. Using WebSockets is *easier* than regular HTTP handlers. The connection is always open so there's no complicated AJAX nonsense. You can send() whenever you like and with JSON it's a piece of cake to dispatch incoming messages however you like. There's loads of examples in Google but if you look at Gate One's on_message() function (in server.py) I can answer any questions you have. I'd point you to the exact location but I'm on my phone at the moment.
robotgame.org
You may be interested in this as well: https://github.com/mdipierro/canvas
I will play around with it for a while. For now I just chose to go with the tagger that I showed in the example for the purposes of a demonstration. Should the project progress further I believe we would implement sklearn. 
Us old timers recall the old game called PCRobots where people would submit C/Pascal/Asm programs compiled with a common library, to ?PC World. the library would interface the programmes as tanks in a nxn world and battle each other to death.
Indian IT outsourcers, what do you expect? It's a cut throat margin industry.
Well that explains it. Like I said before, commits would probably be slightly more accurate at determining the popularity. Solo, probably inactive Ruby projects skew the number of opened projects.
The core code could be much shorter: def get_clusters(elems): return clustering(sorted(elems)) def clustering(elems): "Given a sorted list of sequences, return a list of clusters of the sequences." clusters = [] for elem in elems: if not clusters or DISTANCE &lt; distance(clusters[-1][-1], elem): clusters.append([]) clusters[-1].append(elem) return clusters def get_largest_cluster(clusters): return max(clusters, key=len) Also the distance function can be a thin wrapper around difflib: import difflib def distance(a, b): return sum(0 if oper == 'equal' else max(v-u, y-x) for oper, u, v, x, y in difflib.SequenceMatcher(None, a, b).get_opcodes())
I think the nicest thing about matplotlib is its flexibility. The defaults are kind of boring, but a little bit of tweaking usually makes a giant difference and if you need something special, it is always possible. But it is important that the defaults stay boring: There are many applications for plotting, and not all of them work well with fancy layouts. Print often requires high contrasts and does not support colors. Most of the more "beautiful" plotting libraries really don't work for that. 
I personally don't do that because I'm not involved in the documentation writing :')
there's lots of links there
Yeah, the article is for beginners. 
It would be nice to be able to read the headers directly and ignore all unsupported constructs. It is annoying to write a potentially incomplete preparser to strip out #IF and friends.
Reminds me of [Core War](http://en.wikipedia.org/wiki/Core_War)
I like it. The ticks and whatnot would be important for trying to read specific data out of a chart, but most of the time you're just looking for trends. 
It would be great if you could easily switch to a nicer style, given that you want rather to concentrate on research/analyze the data, instead of writing matplotlib code.
"Flask has no magic"? What about `import request`? Don't get me wrong, I really like Flask and use it on several projects. I like that *Flask has magic in the right places*. I just don't think this the correct thing to say.
Thanks! * https://bitbucket.org/cffi/cffi * https://cffi.readthedocs.org/en/release-0.8/ * https://pypi.python.org/pypi/cffi
With an hour of time there isn't that much that you can do. You could probably get them started on the turtle module pretty well, but anything more depends on how much they know about programming in general. Explaining control structures to a non-programmer could eat up an hour by itself.
- Calculate stuff with python (using python console as a fancy calculator) - Draw stuff on the screen (prepare some helper module to set up the pygame context for them) - Make things work in the web browser (bottle.py of cause) 
it's hard and a lot of time not what you want. you often don't care about the exact fields etc., also the #ifs are platform-dependent. Additionally, if you run C preprocessor you often end up with gcc extensions and stuff :(
A simple calculator seems like a good idea, where can I find a solid guide on how to code it?
https://brilliant.org/competitions/hunger-games/ &gt; **Hunger Games** &gt; &gt; A game theory programming tournament &gt; &gt; Write an algorithm to fight to the death against other algorithms. Cooperate and compete with other players at different points in the game to survive and win.
I know. That's why I filter out these things. I'd just like CFFI to do a "I don't recognize this -- ignore" than "I don't recognize this -- raise an exception" Running a c preprocessor is just asking for trouble (tried it early on, no end of pain)....
&gt; Are you comfortable with math/optimization...? I am not actually. I signed up for a course that is perhaps a bit out of my league as I am just starting out programming and don't have a history in mathematics outside of largely forgotten by now high school math... But I want to try my best to finish it. Though requirements for the solution are a bit more complex than I have indicated in my very brief description. I will have a look at the genetic algorithm.
This makes the numbers and operations easy to represent. This is how I learned it in school many years ago: https://en.wikipedia.org/wiki/Reverse_Polish_notation How old are the persons you want to teach?
14-18, this looks really useful!
Heh. http://xkcd.com/353/
[Image](http://imgs.xkcd.com/comics/python.png) **Title:** Python **Alt-text:** I wrote 20 short programs in Python yesterday. It was wonderful. Perl, I'm leaving you. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php?title=353#Explanation)
Can you show a concrete example that bothers you?
Yes. I wanted to make a CFFI wrapper for SSL. I ran into issues as I wanted to read in ssl.h and would always get Exceptions for things like #IF, etc,., I did not want to include my platform's ssl.h into my project, but instead wanted to make it so I could read any Unix-like platform ssl.h. I ended up writing a preparser that would filter out preprocessor constructs, but I never knew how much would've been correct, especially given that on some OS's, one may use slightly different structures for the same thing
It would be interesting to know the piece selection algorithm. Having a seed doesn't imply that there aren't rules to selection that would disadvantage the player. 
This is quite hard to achieve in the general case. Consider that even in C toolchains, there are large differences between platforms and compilers. Therefore, autotools commonly run before compilation starts to create the proper headers and define the proper #defines. pycparser (which is used on the front-end of CFFI) lets you run the preprocessor, and you can point it to a directory with "fake" C headers (where only empty typedefs appear to appease the parser) that replace system headers (a fairly complete directory is provided with pycparser). This has been used successfully to parse many real-world headers and source bases.
Hi pp19dd; Pythons popularity is boosted by its use outside of web programming as well as its use for web-centric projects. Remember also that use of a CLI is second nature to a lot of programmers. It's not elitist, it is how people get things done. Most server farms and supercomputers run a version of Linux which is famed for its users getting work done from a command line - even when invoking GUI programs to do part of the work.
Well, the magic which Django does is not present in Flask. Flask is a simpler approach to solutions rather than conventions.
Sounds like your time might be better spent looking for jobs than learning Python. Being proficient as a programmer has much less to do with specific languages than underlying concepts. 
Listen to this.
Most of the speakers had their slides or ipython notebooks on their github accounts. I would check there first.
I think it is pretty unlikely that you will understand much more than just syntax by doing codecademy. It is a decent way to learn what Python code looks like, but if you really want to be employable, start building things that work that you can show off and explain to employers. Just knowing a language is practically worthless. However, being able to make useful things is always employable. 
First of all, thanks for a thoughtful reply. Not sure if I misrepresented my background in what I was saying, but, CLI is where I got started. To this day, I use vi over any other editor. But, you have to agree with me on one supposition: a good/better programmer will always have some/greater familiarity and comfort level with CLI over others. If you can agree with me on that one, consider the unspoken supposition #2: future of computing is increasingly becoming web based (until D-Wave people figure out what they have and prove it.) If you can agree with that, and then compare the two suppositions, what I was saying doesn't sound so alien after all. Dominate, and common, web hosting packages do not include python - and most people don't know CLI. What I was trying to say is -- what I thought was painfully obvious -- there's a saturation of weak programmers out there, and python's barrier to entry is a natural and very visible dividing line between levels of expertise. For what it's worth, I switched to python during the government shutdown. I like the language just fine, but, in all honesty the ecosystem is proving to be recalcitrant.
If I were approached with this problem, I would initially model it as a mesh of springs. Each object is attached to every other object by a spring, as well as being attached to each corner of the surface by a spring. Include damping so that it doesn't settle into an oscillatory state, and they should be spaced in an approximately optimal way when they appear to cease motion. This is NOT a great algorithm for this, because you have to wait for the simulation to settle, but it is a way to think about it. Perhaps this can be a starting point for the development of a better algorithm.
Codecadamy is like an introductory language class. You will get the basics of the grammar and vocabulary, but you aren't quite ready to become an essayist in that language. Even if you know all the mechanics, it takes a lot of practice to become skilled. I'd recommend writing small programs, then starting to scale up. Web/database apps, games, and things like IRC bots are all good projects for a beginner, but there are really an infinite amount of options out there.
Getting a job and learning a language are two separate tasks. You get jobs to keep from starving; you learn languages for love. Don't get it confused.
or JSoup for java
Do this: http://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world Come back when you are done.
I signed in just to upvote this fella. Well said.
Very awesome tutorial. But others be warned that the Alchemy Migrate package is not compatible with the current version of SQLAlchemy. I think the creator of SQLAlachemy has actually made a migrate module. The lesson that covers this explains in the comments, iirc.
Python wiki has a list of simple programs - https://wiki.python.org/moin/SimplePrograms Also KataCatalogue has some small projects as well - http://codingdojo.org/cgi-bin/wiki.pl?KataCatalogue
If you use Python 3, `super()` has some new magic so you can call it with no arguments, which works the same as calling `super(ClassName, self)`. So you could do this: super().__init__()
I copied his title directly, and I'm going to give Armin Ronacher the benefit of the doubt. He doesn't need to share anything beyond what he's already given us.
In the first one, it would be better to use the `with` statement import os import tempfile fd, fp = tempfile.mkstemp() with os.fdopen(fd) as f: # do stuff with the file That way the file is closed even if an Exception is raised while working with it
Thanks for the tip. I added a little note stating the post is targeted to 2.X
2.4, are you using RHEL? 
Use webdriver and do something funny to a web page to gain their interest. 
Some kind of automated cloud computing thing, according to their main page. I guess it allows you to run threaded applications easily across a large network of processors to allow for fast shit. I don't even know, look here: http://picloud.com
[have you tried turning it on and of again](http://lmgtfy.com/?q=picloud)
I'm a heavy user of PiCloud, and I owe Ken and the rest of PiCloud team tons of beer for the incredible support I got from their team. Congrats are in order on their acqui-hire, I'm sure the terms are quite nice and DropBox is not a bad company to work for. Oh, and thanks for open-sourcing the platform, allowing this to die would have been a huge loss to the Python world.
But you can: just dump some defauls settings in your .matplotlibrc
I'm relatively new, and I too am curious. I've been using classes lately and they've been incredibly useful, however I'm not sure how they compare specifically to just using functions.
Is there C++ support planned?
https://en.wikipedia.org/wiki/Object-oriented_programming#Fundamental_features_and_concepts
Do you work in an environment where your coding style is abnormal and your colleagues find it difficult to integrate your work? You remind me of my scientist colleagues who grew up on matlab and whose work is a difficult to integrate and maintain...
I use classes very sparingly in Python. Really, I mostly use them to wrap complex state, like C libraries or GUI objects or Test Suites. I also use classes to mimic other types using magic methods such as `__index__` and `__next__` and `__enter__`. But all those are very specific use cases. Outside of these things, I prefer to organize my code around functions and modules. Those magic methods can be used to great effect, though. 
I was also a bit underwhelmed with the article content given such a grand title. Client supplied session data with a MAC isn't comparable to a database. But I'm with pydanny here, Armin wrote Flask and Jinja among many others and is unlikely looking for self promotion here even if the title is a bit sensational.
Whether or not you use classes will depend a lot on what task you're trying to achieve. Right now I work as a research assistant in a psychology lab, and my time is split between creating experiments and analysing the results. Creating experiments (which you can think of as really simple, fairly shitty computer games) generally requires classes out the wazoo. Data analysis, on the other hand, often just ends up being done with long scripts full of single expressions, one after the other. This is especially true for the simple analyses that are needed to analyse the results of a psychology experiment, where your main goal is to split the means of the different conditions up. Almost 0 classes, and often very few functions, apart from simple one line lambdas. I don't find it particularly odd that you've used no classes for the statistical side of things, but my limited knowledge of web dev leads me to think you might find some use for them there.
I actually write the cleanest code of my colleagues. I'm usually the one getting on their case about crappy hacked together scripts, or having to fix their code by implementing things like iterators because they tried to read the universe into memory and have been swapping for 2 hours. We have a lot of really fast machines in house -- multiple dual Xeon setups with 128-256GB of ram and 2-4 GPUs on board -- and sometimes all that speed and capacity can cause people to get lazy about how they write their programs. Don't get the wrong idea when I say I'm a "scientist" -- my background is in economics, stats and CS. I'm more of an applied/empirical computational economist than anything. I never bothered to learn MATLAB in grad school because it was silly -- I wanted to use a multipurpose language that I could leverage for all kinds of things, not for just doing problem sets in grad school lala land. I committed to Python back then and still use it for 80-90% of my programming. The other fraction is made up primarily of a classic unix/gnu toolkit (awk, sed, grep, parallel, xargs, etc) with some R mixed in. I guess my overall thought in this thread was that when I am thinking of how I'm going to structure some program, never do I say to myself "Yeah, I'm going to use a class for that part!" Perhaps it is like others have said and my typical work load is more functional than anything, which is definitely true. I write lots of code to automate things that need to be done on a regular time schedule (whether thats minutely, hourly, daily, etc), including lots of integrating these various sources coming in at different intervals into a handful of interfaces/APIs/GUIs which myself and others use to actually do real work. 
Your contrived example would be simpler if you just used os.fork directly instead of using subprocess.Popen.
I hadn't seen his recent presentation on Python 2 vs 3. In retrospect, I don't see how anyone can argue that Python 3 was a good idea. It has caused more problems and created more warts on existing code bases that the minuscule benefits of Python 3 will never offset.
What kind of data structures do you find yourself using usually? Are you just implementing your own ad-hoc "classes" via dicts or lists? 
Scientists seldom need to define classes because they pay much more attention to fundamental principles, most of which can be dealt with Python builtin classes or other well-written tools(ex. scipy), rather than big software engineering projects, in which case, you need to create many new components yourself and fit the regulations. If you'd like to know how object-oriented design is useful, I think SOLID is a good start: http://en.wikipedia.org/wiki/SOLID_%28object-oriented_design%29 There also exists a profession called software architecture engineer. They define interfaces and make sure that the architecture is suitable for implement, maintainable and extensible. Technically, you're already using classes since primitive types and functions are actually objects. (lambda a : a + 1).__class__
Just have them make a text adventure game with a number menu system. The idea starts small and then becomes more complex. Each iteration will still be a complete game to an extent so they will have something to show for it but the level of exploration can continue until the end of the period. This will garner questions such as "How can I add gold or hit points" or "What will happen if they go this way without having got the treasure from this other room?" Things like that.
as a grad student, i agree, i have never written a class myself - i use python mostly for numerical computation - especially when fortran starts to become too bulky and i have never needed to write a class!
I can't say that I know the answer to your question, but I can give you my perspective. I am an astrophysicist who works with simulations and simulation data. Most of my work is fairly linear in nature meaning that I do A then B to get to C. I then proceed to plot C or do further data manipulation/reduction/etc. Early in grad school I picked up *C* as it was the language my adviser used; but that quickly got tiresome as I was always writing new code to output ASCII files for plotting. Once I started using python all of that changed since I could do the calculations and the plotting in the same place with simple scripts (no compilation) and results started to come a lot quicker. However, I was still doing things in a linear fashion and storing large arrays with multiple indexes to represent different properties. And it ended up that if I wanted to plot data from multiple simulations I had to save those arrays to a file (npz in my case) and remember all of my indexes and naming conventions. This became a pain when I started changing or adding things to those modules and the indexes/names changed. It wasn't until recently (August) that I discovered object-oriented programming and how to use it in python. I have since rewritten my entire analysis suite (that I spent the previous 6 months working on) to be object-oriented. Not only is my code cleaner, shorter, and easier to read/maintain/edit/add/subtract - it's much more user friendly. I can now plot multiple datasets with ease, and access information much quicker without having to write entire new scripts. I personally don't use methods very often in each of my classes, but having individual objects each with their own set of attributes has proved immensely helpful in my work. I like to think of the classes as python's structures. Anyway, hope that helps!
\&gt;ever signing out
Classes are great for book keeping. For example, I want to run a simulation with a bunch of [harmonic oscillators](http://pastie.org/8489311). That is an example that uses a class approach and a function approach.
http://lucumr.pocoo.org/2013/2/13/moar-classes/
no, but you can semi-easily wrap C++ code in C api in verify() and then use that
This is the question that came to my mind, also. Do you end up with lots of arrays or dicts that share the same keys, so that one data point is a key with values in different tables? If so, classes would let you instead have a single array of data points, each of which has several named fields: cat_colors[12] = 'orange' // color of cat 12 cat_weights[12] = 13 // weight of cat 12 vs. cats[12].color = 'orange' // color of cat 12 cats[12].weight = 13 // weight of cat 12 That can be convenient, but it is more about c-style structs than classes. 
/r/learnpython is a fantastic place for asking questions about Python and more appropriate than /r/Python 
It seems like you dont want to change your coding style, and thats understandable but OO programming work with just about everything and it usually results in cleaner code unless you take it to the extreme. Its going to take a lot of practice to really get your moneys worth out of OO programming tough.
Straight from PEP 20: Namespaces are one honking great idea -- let's do more of those! I've never understood that last line of PEP 20 completely. Could this be related to the `abuse` of classes ? 
It seems that your computations are mostly sequential in nature. Structured programming makes a lot of sense in those cases. If you don't do it already it may make things easier to use classes as collections of fields, instead of using just lists and dictionaries that happen to contain all your data. See /u/mons00n's answer in this thread. It's a lot easier to both think and talk about a domain model with a dozen classes that have some relation to each other than thinking about lists and dictionaries that happen to point out other lists and dictionaries at certain indexes. But using classes like that isn't object oriented in itself. Sure it uses classes and you instanciate objects from them. But that can be done with e.g. structs in C as well, a completely procedural language. When object oriented programming really shines is when you have behaviour on your objects. E.g. a polygon can rotate. A car can accelerate and turn. If you make methods on your polygon and car that encapsulates those behaviours you can have other objects call those methods and change the polygon's and car's internal state without knowing exactly how it's implemented. When you have a lot of behaviour on an object it's easier to have all that in the same place i.e. on the object itself. Then you can chain objects together and they can interact with each other in a very expressive way that's hard to communicate with procedural languages. E.g. if not garage.is_full: garage.add(carA) carA.turn_off garage.close 
This seems like a very interesting idea, I'll look into it. Thanks! Like you said, this may not be the best approach because of the time it takes. Because of differences between the houses in terms of price per meter and accumulation of that price being dependent upon the specific placement of adjacent houses, I'll have to run the program many times with different starting positions of the different types of houses, so speed is important. 
Post an example of your code?
This man knows his shit
Thanks, I'll try it out!
&gt; So my question is: Given that I know how to get stuff done quickly, what am I really missing out on or shorting myself on by never using classes? In traditional languages classes have a number of roles including * encapsulation * modelling objects with similar but non identical properties Lets consider encapsulation first. Now obviously if you are collaborating you don't want to randly set variables inside someone else's module, but consider this: class Walrus def __enter__(): print ("enter") self.x = get_thing_from_shared_store() def use (): # do stuff with the shared thing print ("use", self.x) def __exit__(): print ("exit") return_thing_to_shared_store (x) Now: &gt;&gt;&gt; with Walrus () as p: &gt;&gt;&gt; p.use () enter use exit Why was this good? Well we automatically allocated and returned a shared resource, without chance of forgetting to put it back and causing a "leak" Now considiering similar but unrelated objects: For example "car" and "truck" are both really types of vehicle. One has "load cargo" function and one has a "load people" function. All share drive. Without classes you'd have to store the type of each and you need to check what abilities it had before you loaded it. With classes you would define car and truck as child classes of vehicle, both with their own load function, then you could then just call load without needing to know if you had a car or truck. class Vehicle: def load (self): print ( loading unknown type") def drive (self): print ("VROOOM") class Car (Vehicle): def load (self): print ("loading passengers") class SportCar (Vehicle): def load (self): print ("loading golf clubs") def drive (self): print ("moar vroom!") class Truck (Vehicle): def load (self): print ("loading cargo") things = [Car(), Car(), Truck(), SportCar()] for t in things: t.load () t.drive() How do we *easily* and *robustly* do this without classes? Note how tere 2 different drives (sport car has a faster one), otherwise it defaults to the base. Also everyone has a different cargo. Now in python the language is dynamic and you don't need classes to do this. However it's bit of a pain to do; you would probably pass a function or a function name, and that makes debugging a lot harder.
&gt; It seems that your computations are mostly sequential in nature. Functional programming makes a lot of sense in those cases. What? Ordering is irrelevant in pure functions. &gt; When object oriented programming really shines is when you have behaviour on your objects. E.g. a polygon can rotate. A car can accelerate and turn. If you make methods on your polygon and car that encapsulates those behaviours you can have other objects call those methods and change the polygon's and car's internal state without knowing exactly how it's implemented. In a functional language, you'd have a pure function that takes a Car and maybe some parameters, and returns a new Car. (You could, of course, pass in the state of the world or whatever else you wanted.) Any single Car you give to that pure function will always yield the same result. All of your examples have some hidden side-effects. When you call the functions, you don't know what happens. A lot of people prefer it this way, but it doesn't seem like a particularly convincing argument for objects. I do agree that it's handy to be able to see all methods that act on a certain object, but this can be solved by code layout and documentation, e.g. grouping all functions that take a Car under the definition of the Car type/object. &gt; Then you can chain objects together and they can interact with each other in a very expressive way that's hard to communicate with procedural languages The difference isn't really more than calling `x.foo()` instead of `foo(x)`.
I think it has more to do with polluting the "global" namespace of a program. e.g. variables you define outside of your functions in a C program, or classes/functions defined in any PHP file ever included/required.
(I don't disagree with any of what you said but rejecting a claim that someone is self-promoting based on the fact they are "already" well-known seems amusingly circular)
&gt; As crazy as it sounds, my long term goal would be to try and influence Linux and BSD kernels to implement thread-agnostic I/O support such that an IOCP-like mechanism could be exposed Source: Python dev list
Whatever works for you is fine, but have you tried using classes for any particular cases? I also use Python in a scientific environment, usually for scripting/automation or converting or processing data sets, so I tend to write a lot of short to-the-point scripts and one-offs. I had never used classes until quite recently. I had to expand a webscraping script so that it could scrape multiple pages instead of one. I ended up converting all the code for dealing with a webpage into a class and then starting using lists of pages. It ended up being very clean and I would guess that the code is much easier for someone else to use.
You don't sound like a very classy programmer. Actually, tbh, I'm not all that different from you. My first years as a scientific programmer I never defined a class. I've started using classes in instances where they are obvious in the past few years and have learned some of the benefits, but I think I'm still far from realizing their full potential.
100% agree with this. We do a lot of Python programming where I work. Not one of the people we have hired knew Python but had a few years experience with other languages.
&gt;they tried to read the universe into memory and have been swapping for 2 hours Quote of the year here.
I'm guessing this is an unpopular topic and I don't want to be that guy, but your use of spaces is inconsistent. You seem to prefer using a space before a parenthesis, but on two lines you don't. [PEP8 also disagrees](http://www.python.org/dev/peps/pep-0008/#whitespace-in-expressions-and-statements) with your whitespace strategy and to add an argument to that: it makes it seem like (what's inside) the parentheses and the object's name aren't related while they are.
This is doable without classes as well. define functions that operate on stuff. e.g. def drive(d, ....): print "I'm driving %d mph" % d Define some data structures. I realize namedtuple constructs classes without behaviours. Car = namedtuple('Car','speed') Truck = namedtuple('Truck','speed') but you can do it with dicts too though the syntax changes. car = dict{'speed'} Integrate. drive(foo, foo.speed) or drive(foo, foo['speed']) Of the two, plus one you gave, one will be uglier. Which one it is, is up to personal taste. They both arrive at the same algorithm with different checks and balances, e.g. namedtuple is immutable, using Class new methods can be added and it's directly available per structure, , one has less state etc.. All we're doing is reordering the receiver and its data.
Your first example can be done without explicitly defining a class: from contextlib import contextmanager @contextmanager def walrus_use(): x = get_thing_from_shared_store() print("use", x) yield x print("exit") return_thing_to_shared_store(x) Your second example could probably be done with [single dispatch generic functions](http://www.python.org/dev/peps/pep-0443/), but that will not be in python until 3.4 is released - you would need to use a third party library for now. 
Off-topic, but does your lab use Python-based experimental presentation software? I'd love to, but I haven't found anything that meets my needs.
Custom exceptions. class MoreSpecificValueError(ValueError): pass 
How often do you actually do that? I use classes plenty, but that basically just...never happens. 
If you haven't used OOP so far felicitation : you have a brain, and did not missed the essential : coding is about automating tasks. OOP is mixing code and data in stuff called objects. It is elegant to use, it often leads to hard to read code with pit everywhere ((“object-oriented design is the roman numerals of computing.” — Rob Pike)); - programmers love to hide tight coupling in private variable - results = Class(*lot_of_stuff).run() is a common pattern in OOP where a function is rewritten inefficiently as a class (“Sometimes, the elegant implementation is just a function. Not a method. Not a class. Not a framework. Just a function.” — John Carmack); - it is a pedantic way to write code - Bad OOP code is worse to maintain than bad procedural code because inheritance and bad try catch handling are equivalent to GOTO hell. OOP can be cool, but given the actual fashion to overcomplexify everything and oversuse OOP, I dare say OOP is just a buzz that you must comply to to be bankable, because it gives more work to computer engineer that are clueless about design. OOP is one brik of the actual cargo cult programming trend based on buzzword. For an actual enterprise design don't look at the problem just take random keywords and combine them together. http://harmful.cat-v.org/software/OO_programming/
He forgot the #1 of python don't: *concurrency* especially with multihtreading. Python sux for distributed computing. I remember fortran to be even more usable than python for executing code over clusters. 
Namedtuple has replaced those for me. 
I see that I made the mistake of writing functional programming when I meant structured programming. It's fixed now.
I think you should also look at an optimization technique called simulated annealing. As far as I can see, it would easier to formulate the problem you are describing in terms that a simulated annealing-based optimizer would be able to solve, and simulated annealing is also much more straightforward to code yourself, should you need to do so.
I too avoid writing classes but I do love namespaces. Do you use them?
It is there, just cut off the area can scroll.
The problem with most people's arguments for when to use object oriented code is that they always go straight to web and server examples. No one can give a good example that is directly applicable to scientific computing. The typical scientific computer is not worried about passing information across a server or reading some specialized stream. They have some physical system that needs to be manipulated in some way, usually with operations like passing it through an equation. How does one use object oriented code when they don't care about dealing with servers, transfer protocols, etc. via objects? That is the answer to OP's question. You stated that &gt;Object oriented programing is extremely useful anytime you want to organize your code around different types of data structure The issue with this from the standpoint of a scientific computing individual is that short of making objects for physical things (this wave is an object, that wave is an object, that car is an object, etc. and all of them will be acted on by forces of some sort), it typically doesn't make sense to do anything with objects. Or, to rephrase, it is typically more intuitive to not use the object paradigm and just design whatever operation you want to happen. I would love to be proven wrong because then I could justify OO programming with respect to scientific computing. But short of the above scenario, I cannot see any good reason why it is needed for scientific computing. It obviously has uses in other paradigms. But that is beyond the scope of this discussion. 
That's a long title. However, Armin didn't title his post like that.
[this](http://me.veekun.com/blog/2013/03/03/the-controller-pattern-is-awful-and-other-oo-heresy/) is a fairly good wrap-up: &gt; Stop writing *stupid* classes.
As someone who's favorite two languages are Python and Clojure, you're doing it right :) FP ftw!
I think that github profile filled with open source work is the killer CV/Portfolio 
When I looked at the title and then the name of the sub, I thought it was going to be /r/confession. It's early; let my brain turn on.
His contributions make his post (and its title) no less ridiculous. First, storing data client-side is not a database. It is, at best, a replacement for something like redis or memcache. Second, this is not storing data in "the network" (whatever that is supposed to mean). It's storing data in the client. Now, let's examine his first claim, that storage is unbounded. If you're using HTTP cookies (his example), it most certainly is not. Cookies are capped at 4KB each, and you're limited to 20 cookies per domain, for a total of 80KB of storage. Outside of some very niche (or super-huge) applications, I cannot envision a case in which 80KB per client is going to have a huge impact. With 1,000,000 active clients, that's only 80GB of data max. Plus you have the limitation of having to split it up into &lt;=4KB chunks, which may not be an issue for most applications, but can quickly grow annoying. Next, remember that everything in all of the cookies is being transmitted *in every HTTP request*. If you're making a webapp that uses lots of JSON, you've added up to 80KB *upstream* on every request. If your images aren't hosted on a CDN with a different domain name, you've added up to 80KB to every image load. This can add up quite quickly, especially when you look at the trade-off between how much storage you're saving and how much data transfer you're adding. There are some other (potentially) big disadvantages and limitations here. This only works for non-persistent data that is unique to the client. User settings, for example, if they're to be consistent across different access points (think laptop, work, desktop, and mobile) need to be stored server-side. Anything persistent needs to be server side. Anything you may want to run stats on (e.g. "How many users use setting X?") needs to be server-side. I'm not saying there's no use for what he's suggesting, but it's also nothing new and greatly exaggerated. A better title might be "Cookies: Use them when appropriate."
From my experience 80% of the time I got contacted by some kind of HR they ask for a link. Maybe it depends on a country.
FWIW if anyone's looking for a fun project, they could use libclang to parse C++ headers, then automatically generate the wrapper functions.
Most of what classes give you, you can get from other constructs. A class is really just a way of defining a data structure, and coupling it with the behaviors that operate on that data structure. Writing lots of little functions that mutate data and can then be strung together is a perfectly legitimate way to structure and aggregate code. That's the "functional programming" way, and it's very powerful and very extensible. There's a down side -- it can be very hard to read and debug -- but the up sides are fantastic in problem domains where your program's raison d'etre is to calculate a result. Contrast that -- the focus on *calculating a result* with a typical desktop application's focus, which is on *entering and manipulating data objects*. In the latter case, you frequently have many different types of data objects, and you want to be able to mutate those specific data objects in response to application events -- button pushed, text typed, timer expired, whatever. Until the event occurs, you're not sure which manipulation you will want to perform. In a program designed to calculate a result, an input gets heavily processed through several phases of computation. It might be useful to define classes here, and it might not: I could see cases where heterogenous input needed to be processed along a common axis, but with the heterogenous identity preserved. Named tuples or classes might serve this goal well. But the concept of the program is essentially a stream or blob of data that moves through a processing pipeline until an intermediate or final result is produced. In a program designed to provide a set of interactive workflows, you can envision the data instead as a set of related data objects -- documents perhaps, or account credentials, or card catalog records, or all of the above -- upon which the program performs operations at the request of the user. The objects are like a lattice of interrelated data, waiting to be tickled or touched in exactly the right way. Classes fit this paradigm perfectly. Many problem domains can be conceived in either way, depending on the vision of the architect. That's why both OOP and FP are general-purpose paradigms. But I think some fit one style better than others. It sounds to me like OP's problem space orients strongly to the functional side of things. Classes might be useful there, but they might not be, too.
I use namedtuples/built in data structures for most stuff, however when I need an exotic data-structure for analysis I write my own class. It's really easire to write node.left on a tree as opposed to node[0][0] etc.
Codeacademy won't make you employable. You'll need a deeper understanding of CS concepts, some of which you can get through [How to Think Like a Computer Scientist](http://www.greenteapress.com/thinkpython/thinkpython.html). Write some small but useful Python projects and start learning another language. Immerse yourself in learning programming in general and Python in particular and you might qualify for an entry level job, but don't expect that to happen in just four months, and "casually going through" is not going to cut it.
* http://elsdoerfer.name/docs/webassets/expiring.html * http://www.fanstatic.org/en/latest/intro.html#smart-caching * https://github.com/wimleers/fileconveyor * https://npmjs.org/package/grunt-cache-bust
&gt; You'll need a deeper understanding of CS concepts, some of which you can get through **How to Think Like a Computer Scientist**. * https://wiki.python.org/moin/TimeComplexity * http://bigocheatsheet.com/ * http://rosettacode.org/wiki/Category:Python &gt; Write some small but useful Python projects and start learning another language. * https://projecteuler.net/problems * https://github.com/thekarangoel/Projects * https://github.com/samsquire/ideas * https://github.com/seedifferently/the-great-web-framework-shootout
Honestly I'm quite a young programmer, but I've found knowing (or more realistically) having experience in as many language as I've been able to get my hands on has been the most beneficial. It forces you to think in many different ways and you end up with a very useful toolbox. It also prevent's you being pigeon holed (as far as I can tell) I consider myself a python programmer first and foremost, but at the moment I work almost solely in java and occasionally maintaining php. More pythony - messing around with Django and HTML5 I've found to be invaluable. A surprising number of companies use Django and HTML5 is (if nothing else) a lot of fun. It's also worth mentioning code kata, like Project Euler which isn't really a specific skill set, but is incredibly useful in broadening you thinking and honing problem solving skills in whatever language you happen to be using.
but OP seems to be functioning okay
Uk, never been asked. Yourself?
...neither have i 
Do you have a lot of functions of the form: def a_func_for_me(context, arg1, arg2): ?
I find that people get quiet religious about people doing things "their" way. Even comments are a massive fight. Within Python spaces vs tabs is an ongoing brush war. So I congratulate you on your bold stance. Personally I am a user of classes but try to keep them to a minimum. I have met many people who spew out classes like a firehose. Every table gets a class. I even see people who end up sub-classing some existing object with the intention of modifying it, then finding that the original class could do what they wanted but they keep the sub-class anyway, instead of 10 seconds of re-factoring. 
It depends on many factors. If you use functons because they are the best tool for the job you are doing, then I see no problem. If you use functions because you are uncomfortable with object oriented paradigms, then perhaps you should look more deeply into the subject. Programming is just a tool to automate conditional logic and math, right? Why limit yourself with an artificial handicap? 
Since the beginning Flask outsourced session management to the client. More generally, the idea of outsourcing data storage (perhaps not as powerful as databases) to the client side is a great idea. It would be much more interesting to have a seamless framework in which much of the rendering (e.g. Jinja) is outsourced to the client side as well. Python still seems more natural for complex template rendition. But Javascript can do simple template rendition pretty naturally. It'd be nice if Flask figures out a natural way to unload much of Jinja's burden to the client side. Then, we are talking. 
Russia/Germany I've also noticed that when company is ready to help with relocation they interested in your public activity. A week ago I was contacted by dubizzle.com(didn't even know it before): "At the moment I am looking for someone who's first and 'native' language is Python, who has extensive experience in web frameworks (preferably Django), and who's GitHub account is filled with exciting work."
&gt;Ordering is irrelevant in pure functions. While order of evaluation is irrelevant, clearly A compose B is quite different from B compose A.
Then you're already practicing a rudimentary form of object oriented programming. Now imagine that your "module" can have a lifetime of its own with some private data that only it should modify and see, and some public data that any other class can use, and that new modules can be based on the old one through inheritance, and you'll start to get an idea of what OO brings to the table. Throw in polymorphism, which is just a fancy way of saying that we can treat all objects of a certain category the same even though the actual behavior for each object might vary according to its sub-type (and without using a bunch of if statements), and you find that you'll be able to simplify your code in some surprising ways. Don't get me wrong - I think structured programming is just fine for a large category of problems, especially the linear analytical problems you seem to be dealing with, but OOP can help organize to help you solve the problem.
It really depends on your approach to maintaining and managing state when needed. Classes can be a convenient way organize state and behavior but so can a well document set of functions. I've found golang's approach to OOP to be very productive and dare I say fun. That said, namedtuples, sets, heapq, and rest of the std lib can get you pretty far. I just try to keep in mind that OOP is not the only paradigm available. 
Do you know how to continue execution after an exception? I do not. I would be more than happy to learn such. And I heavily resent PHP relations. PHP swallowing errors is not the most common cause of woes - it's weak typing and inconsistencies promote unsafe and deprecated code, which opens up Pandora's box of invalid data (usually with no checks to prevent it) and vulnerabilities like SQL injection. What you have me do is making a parser that tries again and again to strip out more unknown constructs (invariably stupid ifdef macros) until it passes. I'd rather get a list of loaded and skipped constructs than play "Loop for unknown more times until I don't get a lunatic exception". I like /u/eliben 's suggestion as it can make the problem easier though. 
I can't imagine where you're getting function composition from. Did you maybe reply to the wrong comment?
Have you looked at pandas? For building async tasks I also recommend looking into celery.
&gt;It seems that your computations are mostly sequential in nature. This strikes me as discussing a sequence of mathematical operations, and not a sequence of side-effects. In that case, clearly we're talking about composition and not evaluation.
I don't think anyone can argue that OOP is essential to any computing algorithms and it does NOT enable new classes of solutions that I've seen. It's purely there for the programmer so that we, as humans, have a better chance of understanding what is going on in the system at a given point in time. If it's not going to do that for you in your situation, then don't use it. On the other hand, we could argue much the same point about structured programming. A long time ago, there were very passionate arguments about all the computing time and memory that would be "wasted" with all of this horribly stupid jumping around in memory, continually shifting things on and off the stack to registers, and all of that just so you can call a "function" instead of just setting a register or two and jumping to the relevant set of instructions?! The problem with OOP though is that the benefits aren't always as clear cut; especially when someone has used it to create a design that defeats understanding by mere mortals. Sometimes it's a good idea; sometimes not. 
https://github.com/fdouetteau/PyBabe http://petl.readthedocs.org/en/latest/
I think I will just trust my intuition. So far I have determined the use that OOP would have for me in my line of work and searching the web has shown that intuition to be true. OOP has its place. It can have its place in scientific computing, but it is more likely that a functional paradigm is more appropriate in most cases.
Selenium is really handy when you need to do something like bypass a captcha or enter credentials in an http authentication popup (not sure if there's a way to do that natively through selenium or not), you can have your script wait while you log in or enter the captcha phrase manually. 
Shit I use Classes for everything. 
There's a series of lecture notes on scientific computing with Python here: http://scipy-lectures.github.io/
Discussion on python-dev https://mail.python.org/pipermail/python-dev/2013-November/130285.html
Here's a [one-stop-shop](http://datacommunitydc.org/blog/2013/07/python-for-data-analysis-the-landscape-of-tutorials/) for things related to data analysis using Python.
Same. Using `__new__` isn't a big deal, and the forced immutability makes functional-style programming easier. Usually I find myself using this pattern: class Foo(namedtuple('Foo', ('foo', 'bar'))): #Foo methods So the data layout is fixed, but I can still have some basic methods or properties.
In what I do I treat classes and functions equally because you can accomplish the same task with either. I'll use a class when I need more than 3 arguments for a function, as it just ends up being cleaner by then. The other use case is if I write my own library for something, and want to use it as a method. But I'd say 99% of the time I'm not using a class, I'm using functions only. 
Yeah, I could have articulated that much better. All blogging is some form of self-promotion, including developing thought leadership. But suggesting some form of fraud in attracting views is excessive giving his standing and contributions to the community.
I'm guessing something along the lines of[ another example](http://www.reddit.com/r/Python/comments/1qvoop/ive_been_using_python_for_3_years_and_ive_never/cdh2enm) in this thread.
Not knowing your background or what you know so far, there is a lot to know. To be able to manipulate tabular data, pandas is a good library, to make charts you'll need to learn MATPLOTLIB, but there are other charting libaries. Then you'll also need to be familiar with numpy and scipy. You may also have to check out statsmodels library if you want to do some statistics heavy stuff. Of course you need to retrieve the actual data you want to analyze. Your data will most likely be in text files, databases, or you may need to get data from web sites embedded inside HTML or JSON. So you may need to know SQL, know what database drivers are, and learn how to use a HTML/XML parsing library like lxml or BeautifulSoup. If you are going to be working with time series data, you'll have to be familiar with python's date parsing functions and formats. If you will be working mostly with windows OS, then [here](http://www.lfd.uci.edu/~gohlke/pythonlibs/) is a comprehensive list of binary installers for a lot of popular python 3rd party packages or libraries. If you are having problems installing or setting up a Python computing environment, you can get an account with a cloud-based Python environment at wakari.io or install the Anaconda Python installer [here](http://continuum.io/downloads). Lastly, check out IPython notebook environment at the ipython.org site.
... or a dotdict
namedtuples also have a `_source` attribute that contains the source code for the namedtuple.
I came across this the other week, http://pygrametl.org but I haven't used it yet.
&gt; try and influence Linux and BSD kernels to implement thread-agnostic I/O support such that an IOCP-like mechanism could be exposed Yeah... not-gonna-happen. **reads python-dev thread. Yep. Not gonna happen.
Nothing. And object orientation usually adds overhead and slows performance. The only thing you really gain from it would be making it easier to work with other developers. OO design makes things naturally more modular (if done well), and easier to work on in a team.
These are two well-known ETL tools: [Pentaho](http://www.pentaho.com/product/data-integration) [Talend](http://www.talend.com/products/data-integration) 
I hope it can be keep alive. Do you understand what the new model will be? It sounds like Multivac will run an installation on AWS. Will they collect fees and pay Amazon the way piCloud did? How much confidence do you have? Do you know any of the Multivac team. I notice that on the web site the platform and documentation tabs are "comming soon". From the web site it sounds like the first implementation will be the command line which is OK with me.
pipeless is for ETL - http://asperous.github.io/pipeless/
This appears to be an instance of the [bin packing](https://en.wikipedia.org/wiki/Bin_packing_problem) optimization problem. I've seen this question asked and answered relating to the subject of compositing bitmap images together as close as possible to create a CSS sprite sheet. From what I can recall, it's a computationally difficult problem to solve optimally, but there are a bunch of heuristics that can deliver "good" solutions. I would suggest you solve the optimization problem first before doing anything graphical (e.g. stuff with pygame). You could use the ratio of used to unused space as a ranking metric to determine which algorithms are performing best. EDIT: I found a Python package which implements bin-packing optimization algorithms: [OpenOpt](http://openopt.org/BPP).
You're right to mention it. However I just type stuff in and the code formatter in Pycharm's IDE deals with all of that. I don't even know where I am supposed or not supposed to put spaces in. BTW your spelling of parenthesis / parentheses is inconsistent :-)
I would say, honestly, you aren’t missing out on anything really. It sounds to me like you are a functional programmer, and speaking as a die-hard FPer, python is great for this style of programming. You might be interested in playing with other language ecosystems that embrace this style of programming more fully, such as OCaml, Haskell, F#, or Closure. Python has an amazing ecosystem for scientific computing, so it will always be a great tool in your belt, but learning one of these languages might show you how to get high-level modular code out of your functional style without using Objects. Remember, when you remove state and identity from an object, what you have is a module. I would argue that you don't want that state or identity 99.999% of the time.
'Never' is a harsh word. 'Unlikely' for sure. But, with sufficient money, who knows? If a large player like Google decided to standardise all their servers on some set hardware, they'd certainly have the resources to fork the kernel to run on their own gear. It wouldn't be their first kernel fork (Android).
Yes, I'm aware of these. They are good products, but the top tiers* are commercial. Plus both are JVM based. The need is for Python based OSS tools for Python developers. The intent is to take open data files, analyze and validate the data and load into PostgreSQL which will be hooked to web sites for public consumption. (*Plus I don't trust software where you must "request" a quote.)
Actually, my spelling is correct, I just forgot an "a". Parentheses is the plural for of parenthesis (AFAIK). 
Damn, you're right.
This is going to sound weird but actually not following C syntax conventions is the biggest drag for me. 
300,000 years. I just started learning Python a few weeks ago, but I would guess that each job would require it's own evaluation of your skillset. There is no way for anyone to give you a good answer here. You don't provide nearly enough information. Maybe your question should be needs to be...How do I begin to ask the right questions? "By proficient I mean that if an employer asked me to do a project, I could be able to do it without hesitation." If an emplyer asked you to do "x", would you be able to do it without hesitation? There's your answer for proficiency. Just fill in the x with whatever the projects or skills are. I suggest determining what kind of things you enjoy doing, or that you're good at and might like to get into. Try many types of things while building your core abilities (problem solving, other core abilities that I don't know because I'm too new to Python, etc.) while looking for projects and jobs. Are you comfortable with your skillset and feel you would have no problem researching/determining a solution, in a timely manner, if you have no idea how to proceed? If so, I would say go for it and put proficient on your application when you feel you can put it on there. If you aren't, maybe you'll find out very quickly during interviews or on-the-job that you have things you need to work on. OR maybe you'll find out you can get by and it will be the best learning experience of your life. Sounds like a win-win to me. Just reign in your ego, strengthen your sense of self-worth, and let those that know what they are doing rap you across the knuckles when things go wrong. You'll learn.
Python 3 removed a ton of ugly warts in the python language. It was a great idea. As now we have much more standard ways of doing things. You're gonna ask for an example... `super`
Dang, 3.3 would have been cool.
Using classes as a namespacing mechanism where no state in a language like python doesn't buy you too much. There are mechanisms such as dispatch tables which aren't only useful for class design. e.g. if foo == 'foo': foo() elif foo == 'bar': bar() vs stuff_to_do = {'foo': foo, 'bar': bar } stuff_to_do[foo]() The one big pitfall in OOP is the attn/love an OOP hierarchy needs. e.g. A car is a vehicle, as much as a plane. Some helicopters have wheels, some don't. But they both can fly. Boats can float, as do some planes and helicopters etc. You can go on and on and on. Same with modelling shapes such as squares, circles, cones and so on. For simple hierarchies where state exists, OOP is friggin AWESOME. When it starts getting complex, keeping your hierarchies really shallow or non existent is key. A fun example of a hierarchy that went wrong, but there's no backing out of it now without breaking source compatability, are mutable and immutable lists in scala. Some methods do zilch. In java, the same applies. Functions that throw stating these methods aren't used. 
If they wanted IOCP and Torvalds didn't
Any reason to believe that is the case?
Former Matlab/C user here who's switched to mostly Python. I'm happy to see that someone asked this. When I look at my functions in a module and see that they operate on the same set of data and share a lot of the same variables, I make a class. I don't think I've ever started a module by making a class. Are there any kind of guidelines for when you should make a class?
Unknown.
Ok, it is weird that your first inclination was they they would need to fork the kernel.
appreciate the downvotes people. anyway. [this](http://norvig.com/21-days.html) is why I said 10 years. Having been a part of the "in 21 days" generation and now in my 15th year of doing this professionally, I realize that this essay holds a lot of truth. 
My version: When to use asserts? In tests. Automated testing has swallowed up every reasonable use the assertion mechanism ever had. If you want to put an assertion in your code, stop. Write a test.
Thanks! I will look into it. Eventually it has to be visualised though. Would pygame be a good way to go or would Something else be more suitable? 
No, I was saying it was always an option, and one that has been chosen before. So I don't accept the thing I responded to that said IOCP in Linux could "never" happen. Some of the UNIXes added it, too.
Oh wow, lots of great stuff there, &lt;bookmarked&gt; ... will definitely be referencing this. Thanks a lot!
Neat! How long has that site been available?
It might depend on what you are looking (usage or code of a framework) at but I'd say that Flask's magic is more difficult to deal with when shit's getting real.
Thanks for the detailed reply. I've done a fair amount of coding in Matlab so I have an idea what the steps involved are, but with Matlab (my experience was academic) I was able to work/collaborate with other individuals in the same boat as me and then apply what I determined to be good coding techniques to my code...and that's how I picked it up. I actually have been using the Spyder IDE (with Anaconda installed) for the EDX course I'm currently taking; I couldn't recommend it enough, between the object viewer, and the live interpreter adjacent to the text editor...what more could you want? Thanks again for the comment!
1) Distributed computing is not the same thing as concurrency. What are you actually trying to say? 2) Saying something is slower than Fortran isn't saying much: Fortran is murderously fast and even C and C++ don't really want to get into a race with Fortran in its own domain.
All the arguments I had all through 2.5, 2.6, and 2.7 about how it was silly to have to pass values to super, and literally everyone yelling at me that I was an idiot, and that Python was brilliant. Then they change it to this. I almost wish they didn't, just to continue to justify how much abuse I took saying it was silly.
I don't even understand the first bit of the code example: &gt; py&gt; x = 23 &gt; &gt; py&gt; assert x &gt; 0, "x is **not** zero or negative" &gt; &gt; py&gt; assert x%2 == 0, "x is not an even number" What does that "not" do there?
I'm currently working as a Python web dev and I never read a Python book. And I never used Pypy, NumPy, SciPy, BeautifulSoup or PIL in a server side Python web application or in any other thing that I wrote. So those are some strange suggestions. 
My lab mostly uses PsychToolbox for MATLAB. Right now I'm putting together an experiment using Pygame, since this experiment is more game-like than your average experiment and it helps to have concepts like sprites available. It seems like most of the presentation software for Python uses Pygame as a backend anyway, so I figured I might as well just use it directly. I've briefly poked around with PsychoPy, enough to see that it seems roughly on par with PsychToolbox, but haven't actually run any experiments with it yet. One thing I did see recently that I've been meaning to try out is [Expyriment](http://www.expyriment.org/), which seems to have a nice design,
I guess you could try that wheel thing. http://www.python.org/dev/peps/pep-0427/ I use pyinstaller with PyQt, but you're right. The boilerplate is ridiculous. Over the years I've bit the bullet and created batch files to take some of the bite out of it. Definitely use a virtualenv. But then, sometimes running pyinstaller will fail. Sometimes you have to put pyinstaller in the main Python install. Other times it won't run correctly from inside an IDE, but it will if you run from a command line in the same location. Then sometimes you have to add stuff to .paths after your imports or pyinstaller won't catch it. It's a miracle it even works at all. It all feels so fragile once you get it working.
If you're creating lots of these, consider testing to see if classes that define \_\_slots\_\_ are more efficient. Last I checked I believe they were faster and took less ram.
how did you learn? I've been trying to find resources but I can't find anything. I think I've been using the wrong keywords
I'd use named tuples for this use case. Sets of data with named properties are perfect for named tuples. Unless these guys are changing state and have lots of methods associated with them, I'd use named tuples with some functional programming style
To expand on that, classes arent used just for having named properties. If that's the only reason, even dicts ~~are~~ might be better for that. Consider classes for design patterns but not simply for the sake of having named properties and a method or two. Edit: "stateful" is a keyword that hints towards using classes too.
Thanks for the tips! I'm still new to the object-oriented game so all advice is much appreciated. I should mention that my suite is a bit more complicated than so I still feel the OO approach is warranted, but I see where you're coming from! 
I had a difficult time wrapping my head around the concept of object-oriented programming at first. It took a few Lynda tutorials my buddy had to convince me it was worth putting some time into, but I'm glad I did. The best way to learn something IMO is to actually do it. Sit down with [an example such as this site](http://www.tutorialspoint.com/python/python_classes_objects.htm), try it for yourself and experiment.
Please don't use "foo" and "bar" in your examples, it only confuses things more. Come up with some real example where the variables have meaning. 
Interesting....have you done any other type of programming before?
Amen. The best abstraction I've ever seen for a db that was oop-ish were 1. Perl dbi 2. java jdbc (which mimics dbi) 3. java's spring framework (they give you mapper patterns, easy outs for bidning etc) 
Sure thing - what types of examples are you looking for? Simulation visualizations? Plots? Python plotting routines? Python data calculations? Sorry not quite sure what you're looking for =)
Oh no problem. Yeah, there's a tendency for even experienced coders to jump to object oriented design when it's not need, abstracts the design a bit too much, and adds overhead. There's definitely plenty of cases when it's the best tool of course. For data driven work, a lot of sciences I'd assume, functional style can often be easier to read, less prone to error, and more efficient. All depends. Namedtuples are an immutable object type that can store data in properties and are very lightweight for Python. Great tool. But you know the nature of your data and the nature of how you're processing it, so your judgment is best, as long as you know your options. Good luck!
Visualization and plots! D:
I learn new things about python on a daily basis, which is one of the reasons I love this language! I just took a quick look at named tuples and it looks pretty awesome. My concern though is how would I create multiple named tuples with the same name? As in my example above I have thousands of galaxies with a radius; would I just create a list of named tuples in that instance?
most of my visualizations worth seeing I end up throwing to this [youtube playlist](http://www.youtube.com/watch?v=3ExqyEALsEY&amp;feature=share&amp;list=PLu2AWJCkxDzQuBQmPmXb8x_hpV_OvuMXG). I spend most of my time however making plots of various galaxy properties from my simulation. Recently I've been comparing 'zoom-in' cosmological runs of individual galaxies using different numerical methods. [Here's a series of plots comparing some](http://imgur.com/a/det5N). I am able to quickly churn out all of these plots once the analysis is complete in a matter of a few minutes after object-orienting my plotting routines and data storage.
Oh come on. Is that easier and more robust (readable and maintainable) than just using plain classes? And we could *probably* use some kind of niche future feature?
As someone with a little bit of kernel development experience who does some parallel heavy math programming in python, I'm looking forward to your next talk. 
Any guides you can recommend on this? For the data I deal with it sounds like classes would potentially be helpful. 
BTW, the class returned is lighter weight which is why you might use it instead of writing a class. Also you might want to check out defining \_\_slots\_\_ in a class for improving performance. Named tuple sort of returns a class with slots.
Have a look at my [py-nsis-template](https://github.com/takluyver/py-nsis-template). It's a template for making an installer for a Python 3 application which includes the Python.org installer. It doesn't try to convert your application to an exe, it just sets up a start menu shortcut which launches your Python file. However, it is still pretty new and plain, so it's up to you to work out things like bundling PySide with it. I have also used cx_Freeze. Qt-based applications are one of the main things people want to distribute, so there's relatively good support for that. It typically does require some fiddling, though.
&gt; My program relies heavily on proper utf-8 support, which is also not great on 2.7.3. Use Python 3.3. It's much better. &gt; I'd love to try it out, but I'm feeling these unofficial tools are just not mature enough to distribute actual Python applications with. cx_freeze is pretty stable. It works like a charm with PySide/PyQt4/PyQt5 and Python 2/3. &gt; My program is open-source anyway Yes, but .exe include .pyc files. If user unzip .exe file still can't read source directly (Take a look at Dropbox.exe for example). &gt; It's big. Not to big unless you mean the console programs. Comparable to applications written in Qt (C++). You have small but powerful stdlib, you don't need Boost etc.
Yeah, I'm pretty sure. There is some black magic called meta classes that that instances become classes. Not sure if thats how they're implemented. I think they return subclasses of tuple with slots defined.
&gt;There is some black magic lol!!
I'm saving the videos. Did you use matplotlib? Is this your job? I would love to have a job like this *.*
Lol yeah, I see it referred to as black magic all over the place. It's rarely a good idea to use them. Sometimes they can be extremely useful. I think they're in the Django web framework, so when you define data Model classes it patches them so they can work with your database type and you don't have to worry about storing then in MySQL or whatever. In that situation, patching and messign with classes makes it easier for the developer.
I don't really know what you were expecting to find. Its not like python dictates kernel development. Guido's response to talk to some kernel devs is appropriate. I'm sure there are probably some kernel devs out there interested in this. 
matplotlib was used for all the plots. Most of the visualizations were done with other software though as matplotlib is pretty slow when it comes to 3D data. Throughout the astrophysical community there are numerous custom software packages to visualize your specific simulation data so I didn't have to program any of that myself =)
No doubt the downvotes were because you said nothing but "10 years." That's a fine article, but no one knew you were referencing it.
I use them anytime where I have at least hundreds of dictionaries that are never changed. In most instances, dicts are just fine for your purposes and the mutability is desirable. Where memory is a factor and you're never changing them, namedtuples are appropriate.
If you want to learn about scientific computing, generally you would want to learn science first.
I generally use them for lightweight long-lived data structures. The `__repr__` output is self describing, and they are easier to define than a behavior-less class. If I didn't have `namedtuple`s, I would probably be using a dict (most likely an immutable dict); but it is also easier to access the members of a named tuple than the elements of a dict, and you don't have to worry about misspelling the dict keys. I'd consider long-lived tuples a hack because you end up using magic numbers all over the place for access to the members. (Short lived tuples are perfectly fine, like returning a tuple from a function and unpacking it at the call site - but if it is going to be passed around or referred to in its unified form then I start considering using a named tuple). *(I've also created something horrible in the attempt to get the easy access; -&gt; https://bitbucket.org/beltorak/washlib/src -&gt; washlib / scriptPackages / wash / util.py -&gt; class AttrDict; eventually I will get back to it and kill it properly.)* I haven't had a need to evaluate the performance of them - my python ventures are non-professional/non-production endeavours. &gt; Are they just a special class or something closer to the metal? I've heard the first rule of `namedtuple`s is to [never look at the implementation of `namedtuple`](http://hg.python.org/cpython/file/2.7/Lib/collections.py#l230)....
&gt;Is this your job? I would love to have a job like this . And yes, I am an astrophysicist. I simulate the universe, compare with observations, and make predictions. It's certainly not done for the money! =/
I have a B.S. in Mechanical Engineering, I've written a number of algorithms which have been used to evaluate stress/strain relationships in Truss structures, beam, and so on ... All my "advanced" programming work has been in Matlab, and now that I'm out of school, I really want to keep falling back on it as a crutch, which is why I've been learning Python. Learning the basics of python (like I have been in the edx course) isn't the equivalent of being able to do scientific computing, and I want to be able to do scientific computing in something other than Matlab.
&gt;Are they just a special class or something closer to the metal? They're kind of weird as namedtuple is actuall a class defintion factory, given your inputs it runs it against a template here http://hg.python.org/cpython/file/2.7/Lib/collections.py#l230 and generates a new class def ( injecting it into the calling frame's scope and parent module ). Sadly I can't find the discussion of WHY they did it this way but I think the summary was that namedtuple though odd is efficient and easy to maintain. 
The term "scientific computing" is quite broad. Perhaps you don't find much use for OOP in *your* corner of scientific computing, but to extrapolate that to all scientific computing is ridiculous. For example, I make a ton of use of OOP concepts in my research, which is based around protein fragment libraries.
I watched a couple of vids in youtube of a mexican guy who was an astrophysicist and had lived in like 4 countries! Are you in the usa?
I use 'assert' in critical sections of code where an outright failure is preferable to erroneous execution. Usually this encapsulates a minuscule corner case that is unlikely, but possible.
When I write a program in Python, I usually start that way as well: functions, built-in data structures (arrays and dicts), and so on. This is great for the chained-generator, functional style of programming. I make myself justify every step up in complexity. For example, when I start seeing a group of functions take the same data structure as an argument to work on, it makes more sense to wrap that in a class. So from: get_customer_purchases(customer) get_customer_address(customer) (You can also start seeing a group of functions include the same word or phrase) To: customer.get_purchases() customer.get_address() 
yea I'm in the USA, but I'm moving to South Africa in January!
+1 - Have used it and it will do the job.
Having never used Pygame, I can't give you a good answer as to whether it will meet your needs. However, from looking at Pygame's API docs, it looks like a good choice.
I don't know about his case, but I can provide an useful example extrapolated from my work. Part of my work involves using mixtures of a large number of multi-dimensional Gaussians to describe my data. I'll stick to single univariate Gaussians/Normals to illustrate my points though. I've found one of the easiest ways to introduce object oriented programing is to describe it as a way to encapsulate data collections and common operations on that data into a single 'entity'. A normal distribution is parameterized by it's mean an variance. And you'll typically want to evaluate things like the PDF or CDF of a normal, or calculate the likelihood or log-likelihood, or even perform affine transformations. In a functional style each of those would be a function, that operates on the mean and variance ie: def normalPDF(x,mean,var) ... def normalCDF(x,mean,var) ... ... which isn't so bad, unless you're dealing with large numbers of them, in which case you'll need some bookkeeping to keep your means and covariances paid up correctly. And lets get back to the affine transform of a normal. Functionally it'd probably look like: def affineNormal(A,b,mean,var) ... and return the new mean and variance of the transformed normal, but if you started using that in a bunch of places in the code, it'd probably get a little awkward as you'd be having to bookkeep two new values. What if we defined an object to represent our normal instead? Recall we're describing a single distribution, that is parameterized by two values, so wouldn't it be nice to just treat it as a single thing (a distribution) as opposed to the two things that parameterize it? Class Normal: def __init__(self, mean, var): self.mean = mean self.var = var ... this makes this easier for bookkeeping, as the object keeps the mean and variance together for us. Heck if we've already written the functional version of the PDF or CDF we can exploit them as methods in our object: def pdf(x): return NormalPDF(x,self.mean,self.var) But real saving comes from functions like our affine transform, as we can overload the arithmetic operators (+/- etc). def __add__(self, k): new_mean = self.mean + k return Normal(new_mean, self.var) this way we can make our affine transformations of normals much easier to read as we can directly say: X = Normal(0,1) new_X = X+4 which can be a lot clearer than walking through the rules for transforms of normals. 
What's wrong with \_\_slots\_\_
This is a reassuring answer. I'm in broadly the same boat as OP (I'm a Mathematician, who does mostly scientific programming), and as much as I would love to be a fancy-pants programmer who uses classes, I can't think of a reasonable way in which they would make my program more logical. Like OP, I also extensively use module namespaces for holding variables, so to some extent that is an object-oriented approach.
Do message passing, you mean? In game development I exploit polymorphism very often: call the .update() method of every object in the world, etc. Also very handy for GUI work. In other situations it might be a good idea less often, but if you default to hammer paradigm, everything looks like a nail I guess.
Noob here. Are tuples mutable?
I really tried to explain the virtues of OOP in a way that wouldn't sound right for every case. Scientific programming often requires doing identical operations to very large sets of data - OOP is especially bad at that, because it usually means less efficient memory layouts (every field of a struct is in the cache) and lots of virtual function lookups. Might be useful in some subset of problems, though.
There are some examples (like www servers) where OOP allows a division of code that makes new things feasible.
Nothing, really. I like this, though, because it defines a few basic methods implicitly. For instance, I used this when making a `Vec3D` class, which meant that I automatically got `__init__`, comparisons, numeric immutability, value-hashing (for more intuitive use as dict keys), etc. Obviously I did have to define custom operators for `__add__`, etc.
I personally use assertions in game code, it's great because you get the benefit of it being checked while developing. But when a game is released you run it optimized (-OO) and there are no performance penalties. UnitTests are good for checking logic, but quite often don't beat running the game in debug mode yourself...
You are being kind of a dick Most people think of A(b(c(d(e(f))))) As a series of computations working from the inside out. 
[no](http://docs.python.org/3.3/library/stdtypes.html#tuples). Named tuples are also immutable: &gt;&gt;&gt; import collections &gt;&gt;&gt; Person = collections.namedtuple('Person', ['name','age']) &gt;&gt;&gt; john = Person(name='john',age=33) &gt;&gt;&gt; john Person(name='john', age=33) &gt;&gt;&gt; john.age=34 Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; AttributeError: can't set attribute 
Nope. Theyre usually described as immutable lists, but that's not their main selling point. In a tuple, each index has a meaning. Coord tuple might have x at index 0, y at 1,... You might represent path string, filename pairs. There is meaning behind each index, as opposed to a list which is a growing and shrinking collection of similar objects.
Cool. I have to make some plots today. I'm going to try Vincent.
I guess we don't have 1000 ways to do concurrency natively in python: Threads or process (or sets of servers with threads of processes)+ messaging (async IO) or shared data Thread vs Process - killing a thread out of control may happen when it has the GIL. So, if you build a thread based solutions you should rather hope they don't get in an infinite loop. - putting a timeout in the process (with signal or a Timer) is also so poorly supported that weired stuff happens (we can't mask interuptions) Remember the halting problem : we cannot tell that a process will never crash. Killing a process/thread after timeout seconds in python is perillous. messaging vs shared stuff the tools for sharing information either by messages or shared thread/process safe mechanisms leaves us with Queue, Value, Arrays I think it is a tinge insufficient. . We can only share with hope of atomicities small fixed size values (no python int, just C ints for instance) which limits a bit our expressivity. stdlib does not also provide an expressive messaging system with patterns such as broadcasting, client/server, round robin push, Python sockets are pretty rudimentary Time Well, not having a reliable monotonic clock for python &lt; 3.2 really creates nifty bugs hard to troubleshoot (especially with Timer). But I guess using a clock in a distributed system is like begging for troubles. However having the possibility to have a reliable scheduler is quite important. You will tell me out of stdlib we have a lot of solutions... indeed. Greenlets, pyzmq, circus, gaffer, tornado maybe? (yes there are messaging, and process control in the bundle). (Please don't make me laugh with APSscheduler, disco, celery, &amp; al) But you don't have the bricks in python for sane concurrent programmation. You cannot unleash the full power of the OS because python gives you the worst : the biggest common denominator of all OS. It castrates the possibility for the developper to have the full control at OS level of process/threads/IO/signals. Yes python is portable, and that is the problem. To have a solution that executes more than one worker being it on a local computer or on a distributed sets of computer python and the stdlib don't have the required basics for it. If you don't believe me (and you should not cause I love to lie), you should read how pyparallel achieved to do an interesting framework for parallelism in python : by short-circuiting python and getting OS specific. Exactly circumventing what I reproach to python and why I am building my very own solution. https://speakerd.s3.amazonaws.com/presentations/606aa4e02d30013103c12a5f68b843a3/PyParallel_-_PyData_NYC_2013.pdf 
Using mutable keys is generally a bad idea. You may want to reevaluate whether you actually need to look something up by matrix value, and whether a dict is the right data structure. If you really do need this, you can implement a wrapper object with `__hash__` and `__eq__` methods. You can compute the hash of the string representation if you don't care about performance, and the wrapper obj can cache the hash value.
PS and removing the GIL is not even considered here : most C libs are not thread safe so I prefer to keep my dear GIL.
Treat each row as a tuple, hash each such tuple, then hash the tuple of tuple-hashes. That's one way to do it, hope it makes sense.
A BS does not make a scientist. Its not even a juniour scientist. You barely know your ass from a hole in the ground and you want to do science? Sorry kiddo, the world does not work like that. Go to grad school, get a phd, and publish. That is science.
A software company that my girlfriend works for is trying to convince me to drop Python for Ember. I'm still learning basic programming, but I just wanted to mention that.
Why would I get a PhD as an engineer? Lol
I was surprised to see so many asserts in Django code myself.
You want to be a scientist? If not, continue on with what you are doing. Just dont ever claim to be a scientist.
Define scientist?
What are pros/cons of Ember compared to Python?
One properly trained to apply the scientific method in solving problems.
&gt; Yes, but .exe include .pyc files. If user unzip .exe file still can't read source directly (Take a look at Dropbox.exe for example). It's pretty trivial to recover most (if not all) of the original application's sourcecode from both .pyc and .pyo files. Dropbox use a custom version of the Python interpreter which obfuscates the byte-code in the .pyc file. It has been cracked though.
https://github.com/gorakhargosh/watchdog/issues/190 https://github.com/gorakhargosh/watchdog/issues/158 https://github.com/gorakhargosh/watchdog/issues/179 https://github.com/gorakhargosh/watchdog/issues/135 Take your pick. I guess a better comment would have been; it's really buggy, on all platforms; some are worse than others.
Sounds like node.js would be even better add it could do the frontend and backend as well. If they are looking at doing more with js, then node.js would probably be the way to go.
Define scientific problem? Seriously though, with your definition, anyone that took high school chemistry or physics qualifies as a scientist.
I distribute a desktop application using cx_freeze, which in turn I package using WiX (Windows Installer XML). I really don't have any issues with it. I guess cx_freeze isn't in the standard library, but I definitely wouldn't expect it to be. Neither is/was py2exe or any of the other packaging solutions. I'm also pretty sure users won't put up with a "Step 1: Install Python..." as part of the setup process (at least on Windows). On the other hand, WiX is an open-source, Microsoft-endorsed installer packaging system that generates nice, standard MSI files (as opposed to EXE files). WiX can be a bit of a pain, but using Python to generate the inputs makes WiX quite easy enough to work with. My WiX building steps are just built into my setup.py file with some custom tasks.
No, they dont. Not even close. Let me retype that "one properly trained." Is a single class in the sciences "proper training" to be a scientist? If you say "yes" we are done here.
WTF? They're kinda completely different things.
My typical data structure consists of large textual documents, so I use lots of flat files for storage. For smaller pieces of text, like user reviews, I generally use CSV files for each item where every row in the CSV file relates to a user review for that item. I also have a couple TB of metadata related to the large text documents. This includes statistics about the document (ngrams, tf-idf, sentiment, and other related NLP stuff) along with quantitative and qualitative metadata. For this I typically use lists of tuples before storing it in the SQL database (MariaDB) used by the APIs to access it. Most of the memory on the database server is used for in-memory tables which make things really fast. When analyzing the metadata I typically load things in pandas/numpy/statsmodels to do my statistical analyses. So my data structures are not very interesting. I would be curious if anyone had a better solution for storing ~700k large textual documents (avg size is about 6MB) other than flat files.
Not always, there's a great deal of power to be gained by leveraging the scientific or other libraries on the server side without the need for Node.
Cool, I'm also most comfortable with PsychToolbox. Have to take a look at Expyriment, too.
Not yet, although that's the one that everyone mentions. Any thoughts?
&gt; I love Python as a language but, it has some serious issues with distributing actual applications to various (Windows-only) systems. I feel like you are confusing your understanding of the breadth of options for distributing applications with the capabilities of the core and non-core Python tools for doing so. As the OS updater for the platform you have specified is not extensible to other applications, it is necessary to manage application [updates/upgrades/patches/hotfixes](https://en.wikipedia.org/wiki/Patch_\(computing\)) in addition to operating system package updates. Python 3 compatible methods for distribution: http://docs.python.org/3/library/msilib.html (`bdist_msi`) https://pypi.python.org/pypi/bdist_nsi (`bdist_nsi`) https://pypi.python.org/pypi/esky (`bdist_esky`) **https://pypi.python.org/pypi/wheel (`bdist_wheel`)** * http://wheel.readthedocs.org/en/latest/ * http://www.pip-installer.org/en/latest/usage.html#pip-wheel
So, what's the advantage? I've never done anything where immutability was required or beneficial, so I always just construct objects. Why is immutability favorable, or in what circumstances?
But you're bound to only two parameters, correct? Is there not an easier way to define an immutable list or object with arbitrary or defined length? Tuples seem restrictive. 
High school students are properly trained. Even in the most elementary of labs you're taught about developing a hypothesis, performing an experiment, evaluating the results and making a conclusion. What high school students don't have is the theoretical background to develop experimentation; but they know the scientific method. But back on topic, you're using circular logic and vague definitions to try and make a point that nobody that isn't a "Scientist" (by your definition which is a rather poor one) should have reason to perform scientific computing. That's just plain silly. Personally, I have used Matlab for scientific computing purposes both academically as an undergrad engineering student, and professionally as an engineer. I want to expand my skill sets when it comes to scientific computing because I don't want to have to hit up my employer for $5,000/year for a Matlab license when I feel there are other products on the market (Python with SciPy and NumPy) that are much more economical and just as powerful. Sorry if that's a problem for you, feel free to not make any suggestions if you don't feel it's appropriate for someone like myself to utilize scientific computing packages to achieve any of my professional goals.
I don't know that I have any guides I can recommend. You might try looking for MOOCs or Open CourseWare courses that teach "object oriented" programming. I'm sure there are also dozens of good sources that are a bit lighter weight than a full course, but I don't know of any off the top of my head.
couldn't OP just use a tuple of tuples as his matrix?
[pytest](http://pytest.org) is more functional than [unittest](http://docs.python.org/3/library/unittest.html); both of which utilize [classes](https://en.wikipedia.org/wiki/Class_\(computer_programming\)). While possible to write tests without subclasses of `object` with `__init__` methods or `unittest.TestCase.setUp`, I find it easier to [reuse code](https://en.wikipedia.org/wiki/Code_reuse). I guess you could [namespace](https://en.wikipedia.org/wiki/Namespace) things into one non-class per file. http://www.reddit.com/r/Python/comments/1nzsze/functional_programming_in_python/#ccnuwno http://www.reddit.com/r/Python/comments/1drv59/getting_started_with_automated_testing/#c9tfxgd http://www.python.org/dev/peps/pep-0020/
Tuples *are* arbitrary length. `namedtuple`s have a defined length (that is, all instances created are fixed to whatever number of fields you specified, be that 2 or 256). 
http://pytest.org/latest/assert.html#assert-with-the-assert-statement (in tests)
I find this conversation confusing. You're all comparing different technologies that do different things in different places. 
Perhaps this could be tweaked to fit your experiments: http://econwillow.sourceforge.net/ I helped an economist doing experimental economics and game theory setup an experiment using willow in my final year of grad school and it was super intuitive. The interface is kind of bland, but so are most interfaces in social science experiments. :)
I just don't see how it matters at all to this discussion. That's the same for all languages.
Oh, ok. I was thinking they were bound to length 2. 
Yes--and it's just one paradigm. But seriously, tell me how this relates to the discussion?
I've used cx_Freeze to distribute PyQt applications. It compiles all the Python's modules used into DLL files. It's actually pretty simple. I would highly recommend it. The one downside is that because of the compiled modules, your applications may get really large compared to your source code. You might write a few kilobytes of code, but with all the compile Python, the application ends up 10mb+.
Object oriented design is more about being able to easily integrate the work of numerous programmers into a very large piece of software. If you aren't doing that, you probably aren't missing out on much. It's just become a though-paradigm for many people (including myself), I find it is often much easier to understand what i'm doing if things are modularized into classes.
For most people, text parsing is useful from day to day regardless of what they study. Strings are easy to see updates to and easy to move around. Parsing a text file will also get some practice with how easy file reading is in python and looping through lists in python. Plus, I think you can do all that stuff with included modules. You could read in a csv file and do a nifty madlib thing, or you could have some input / output program that writes an outline for a paper. You could write something that formats a bibliography given a JSON file, or other format. You might also try to look in to a super simple web scraper. I think you could write something that downloads all the images on a page, in an hour or less. It feels cool, and could be useful in pretty short order with a little extension.
this guy gets it
Since [Jan 20, 2011](http://area51.stackexchange.com/proposals/11464/code-review).
Machine learning in Ember? Or data munging? 
I wish it'd be more so in my field. But alas, in my university grad students in biochemistry are still taught Perl. Now, I have nothing personally against Perl but teaching it as (likely) the first language... Brutal.
I prefer hand-towels to crank shafts.
Democracy is much better than hand-towels. Especially before lunch.
Interesting. I've decided to focus on improving my scientific-programming skills in Python rather than learn R, because I had a hunch things were heading in this homogenous direction. AFAIK there's nothing special about R's language that makes it suitable for statistical work, it's just that it happens to have a large library of statistical functions. Scipy's library is pretty good though, and if it can do what I need, then there's little reason to leave Python. 
The Wiley books. One is 'programming python'. Can't remember the other one. One is the basics and the other is practical examples. 
Dude is not doing the kinds of work that OOP is optimal for, so it makes sense he would be using a functional or imperative style. (the two most popular styles that preceded OOP)
This is good. It gives me more incentive to learn Python. 
The equations aren't that difficult though are they? It's been a little while for me to remember them correctly though I have to admit.
http://www.reddit.com/r/Python/comments/mejfc/are_there_any_things_about_python_that_you_do_not/
I think they do.. well not HRs themselves, they don't know shit usually. I like this practice myself, as a team lead I usually go through all public profiles related to work before invite someone to the interview. I see that more and more developers put github link to the CV so the tech guys see it anyways. But again it's Moscow, can't say for the rest of the world. 
This. R comes out of the box with excellent array data structures and data frames. Makes it very easy to do analysis.
No gtk?
That's what I hear, but is it better than numpy/pandas?
Personally, since 3.3, I'm really looking forward using py3k more than py2k. 
The best advice I have for you is to start a (small) project and decide ahead of time that you're going to figure out how to do it in Python. Maybe a PHP project you're working on right now needs a data-import script, or some sort of cron job. Do those things in Python and force yourself to learn the Right Way if doing the job by searching for examples online or even asking about it here. I've always found that practical application trumps theoretical learning every time, and this is exactly how I got my start Python.
The closest I've found to a K&amp;R equivalent is *Python Essential Reference* by David Beazley, ISBN 0672329786. It is basically a more in-depth version of Guido van Rossum's official Python Tutorial.
In my experience, yes. And microscopy because they support many microscopes and associated imaging hardware
if you know your software is built upon another software, you move when they move.
Yeah. But it is all in python 2.x. Python 3.x is a major step back for scientists: * Letting major APIs return iterators or views instead of lists just introduces completely unnecessary complication. Most people doing data analysis don't even know what these structures are but they definitely know lists. * Scientists have to deal a lot with bytes or strings of bytes but never Unicode. Python3 treats Unicode as first class citizen as opposed to raw strings of bytes like in Python2. Scientists give a rats ass about unicode. * Sometimes you have to convert a lot of clear text data formats and needing to use 'print(x, end=" ")' instead of a simple 'print x,' makes me cringe every time. Printing something is substantial, why shouldn't print be a statement, why has it to be a function? * Finally there is also a loss of performance in Py3k. I use numpy because it is usually faster than the stuff I wrote myself in C. I use python because I got the best performance without having to care much about programming. * I want to be able to reproduce results I or other people did 10 years ago. Maybe poeple in 100 years want to do that. A language that breaks backward compatibility for trivial consistency issues is definitely not suited for that. The easiest solution would be to stay with 2.x for ever but python devs announced to put no energy in 2.x anymore.
The tutorials on Codecademy are very good also. I found them better than learning through thenewboston
It's a shame some popular libraries won't support Python3.x anytime soon... :( 
It does seem that beginners find PERL as hard to learn as a language with randomly chosen syntax: [http://wadler.blogspot.co.uk/2013/11/is-perl-syntax-better-than-randomly.html](http://wadler.blogspot.co.uk/2013/11/is-perl-syntax-better-than-randomly.html). I totally agree, it's a very poor language to learn first, since to write it well takes substantial experience in coding and learning a whole bunch of frameworks (e.g. Moose). I long argued with my old PI about teaching the n00bs python instead.
Twisted...
[Celery](http://www.celeryproject.org/) handles retries, timeouts, and a bunch of other things for you. If the datasets are large and you think that you would benefit from running tasks at more than one machine it will help, too. You can create a periodic task that tries to get the latest data from both sources (in parallel, with subtasks) and does something on success. I found [this site](http://book.mixu.net/distsys/single-page.html) to be an excellent introduction to distributed systems. It is not Python specific though.
http://www.cis.upenn.edu/~bcpierce/unison/index.html
R has a fast, built in matrix language as well as simulation tools. What's more, everything is parameterized in a way that's familiar to statisticians. Also, creating nice graphics is way easier. Matplotlib makes nice graphics, but its hard to use. Last, for a lot of tasks, I find R to be faster. I don't know exactly why, but doing lots of large matrix operations and a ton of simulation (ie, for mcmc sampling/Bayesian inference), I get better results in R. That being said, I love python for just about everything else, just not statistics.
That depends on your needs. Long matrix expressions are more concise and readable in R, and I think they might be faster now too.
Maybe include wxPython widgets as well? If the site gets traction, it could serve as a very handy hub for all Python UI components. I've created a number of custom widgets in wxPython over the years, but have found no good place to share them. This site seems neat and easy to use.
I'm saying that your response that its not gonna happen based on an email to a python mailing list doesn't make sense, because they don't do kernel development there. So, of course you aren't gonna find someone there who says, "sure! lets implement this in the linux kernel", but that doesn't mean its not gonna happen. We'd need to see what the response is to IOCP on the linux kernel mailing list first. 
Can this be used for .qml as well?
There was a project called OpenSync but it seems that it's been dead for some time now: http://www.opensync.org/ At least it has some good reading material on the general problem of syncing. Also, if you want to dive into concurrency guarantees and all that, you should read up on the ACID principle (http://en.wikipedia.org/wiki/ACID). It will give you some good insight into what you need to keep in mind. What sort of data are you syncing anyways? If you're using a relational database I'd recommend that you simply use database transactions if at all possible. Turn off autocommit and manually commit transactions at safe points. As pilt points out, you can use something like Celery for the data transport but I don't think that will handle data integrity for you though. Also, you're probably going to be better off storing your data in some sort of a log format (additive) rather than trying to update records. At least as your source of truth, you can then "generate" your actual data from the log by "ingesting" the log from specified checkpoints. This is pretty much what ACID does in databases.
The easiest thing I can think of to help with your data integrity needs is to use db transactions to ensure all-or-nothing synchronization happens: with dbRead.open() as cRead: cRead.execute('''select * from mydb ''') data = cRead.fetchall() with db1Write.open() as c1: with db2Write.open)() as c2: write_to_db1(c1, data) write_to_db2(c2, data) erase_sync_data_from_read_db(cRead,data) This will ensure all data is written to your 2 output dbs and that your queue is properly emptied. If anything fails, the entire operation aborts.
What's a protein fragment? It's an object with properties which is the exact use case I said computational scientist would use it for. My argument was merely that it was the only case that a computational scientist would use if for. Thus, there is no reason for you to think we are in disagreement at all.
Thanks. That looks like a great book. 
I thought about that afterwards. Should be easy to add. Look forward to seeing your widgets
udacity.com has a great intro to computer science which has you make a scraping script in python. Also coursera has a great python class as well. It's more of a traditional online class. I'm new to programming (other than basic which i took in college) so they were a good fit for me. I have also heard learn python the hard way is another good option.
I can add that and tkinter too.
Is that the same as the .ui files?
France, It's already on my CV, they ignore it. I did quiet a few projects. People expects medals in the form of thousands of stars and/or followers, anything but that and you are just a geek. This is very hypocrite.
I'd rather solve business/technological problems than doing Kata. Kata is useful to learn a language, anything beyond that is just code play.
Sorry to bother you again. But please file this in your data banks. When extending the embedding story for PyPy please. 1. Allow for multiple PyPy in the same process space 2. Allow for CPython to be embedded in the same process as PyPy, symbols should not collide. I have a use case for embedding both CPython and PyPy in the same application with multiple PyPy each running in their own thread and own allocators. Regards.
What does that have to do with his comment?
Interesting that i picked today to start learning Python. Ok, its not really that interesting. I don't really know the difference yet so i just downloaded 3.3.3
The link is the generic 3.3 whatsnew page, showing everything that has changed since 3.2, not what has changed from 3.3.2 to 3.3.3, which you can find [here](http://docs.python.org/3.3/whatsnew/changelog.html#python-3-3-3). 
It's the language you can use in QDeclarativeViews. You can create widgets with QtCreator, then use them in .ui files or straight into PyQt. In your PyQt install they usually have some examples, such as DialView.qml.
Wouldn't that leave on uninstall a python installation with non-standard install path ? Also, what happens if python is already installed ?
I saw one of the lead devs give a talk on Bokeh at PyData NYC. There wasn't any mention of a paywall, but I wouldn't be surprised if it happened. Currently, Continuum Analytics does have some proprietary products and more in the pipeline.
It's not that hard t make the functionality yourself. There is a "Control Systems Library" that has some stuff that might be useful to you.
&gt; Sometimes you have to convert a lot of clear text data formats and needing to use 'print(x, end=" ")' instead of a simple 'print x,' makes me cringe every time. Printing something is substantial, why shouldn't print be a statement, why has it to be a function? And I cringe every time I see a 'print "foo"' without the parenthesis. It's a horribly broken idea to treat writing to stdout different from everything else. To each their own I guess.
At this stage, I believe it's probably a safe bet to start up with 3.3.3 to learn the language itself. The only worry would be if you had already requirements for 3rd party packages that don't support it yet.
comtypes
I don't think it was supposed to be taken literally, more like [a programmer's version of a chinese proverb](http://www.canonical.org/~kragen/tao-of-programming.html)
No, I think he means 'Learning Python' by Mark Lutz that precedes 'Programming Python'.
https://github.com/fortharris/Pcode
If python had arbitrarily-long closures and top-level regex support, I would no longer use ruby as my primary text munger.
Breaking backwards compatibility is the point of a major version bump; it's not like these happen very often. As someone who works with ten-year-old software on a regular basis, I'd much rather get the improvements we've made in the field during that time. 
They're actually arbitrary length. Try tuple(range(100))
You should post these types of submissions in /r/learnpython instead. (I saw your other downvoted submission re: the collections module, and figured you might be looking for a more receptive audience...)
He asked for distributing binary *applications* not binary *packages*. Applications have more requirements than packages (like environment changes, configuration, dependency bundling etc)
It is annoying that they say it was released November 17th, 2013. I checked last night and it wasn't out yet. Maybe I can see them saying the 18th, but definitely not the 17th.
Yeah, someone else explained that. I learned tuples in college but had no interest in engineering at that time. I'm relearning it all now. :)
&gt;Unfortunately, once you start doing things on the client side your only option is javascript Yes and that's okay. It's okay for pieces of a web app to consists of Python, HTML, CSS and Javascript. Attempts to replace HTML with pure python codes can be really clumsy. Not everything has to be in pure Python. It'd be nice if there is a nice platform/framework in which the server side is Python, the client side is Javascript/HTML/CSS, all working together to divide up the labor (coding and data) in a seamless fashion. Armin talked about outsourcing data storage and manipulation to the client side, and that's great. But to me, it's not complete yet. Rendering is still all Python. I think what might need to be done is someone taking a lightweight Python framework and a lightweight Javascript framework and create a hybrid lightweight framework that provides natural and effective manipulations of logic and data on both the server and client sides of the app. 
Developers for libraries who won't make the effort to port over should have all their work boycotted. 
Last edition of Learning Python is 1600 !! pages. The verbosity of this edition can not be compared in any way with the ca 260 pgs of The C programming Language or the less than 350 of effective Java. I would say Mr Lutz is making Python long to explain.
Maybe you are not linking a fast blas/lapack liberay in numpy/scipy? Matrix operations should be on the same level of speed, because the both call the same functions. numpy is also a little better in avoiding copies.
Timezones are a thing. Though, really, it's more intriguing that a release date discrepancy actually annoys you...
That's why I could understand saying the 18th. No where in the world was it still the 17th when it was actually released.
It would leave a Python installation in a standard install path, and a standard option in add/remove programs. This is similar to installing a .NET application - if you don't already have the .NET framework, it will install it, and it won't uninstall it with the application. If the same major version of Python is already installed, it will be upgraded (e.g. 3.3.1 will be upgraded to 3.3.2). If a different major version of Python is present, the new one will be installed alongside it (so you could get 2.7, 3.2 and 3.3 all one on computer).
I don't think you're really missing anything. Talking to third party services often entails lots of error handling. To some degree, you just need to babysit it to see all the possible problems that spring up. Set up some kind of monitoring that notifies you of unhandled errors.
That's kind of already happening though, people who need python 3 support obviously won't be using a library that doesn't have it. 
I see what you mean, but some important libs like gevent, Twisted and nltk haven't been ported. In case of gevent I've looked at the issue tracker and it doesn't seem anywhere close. By extension I couldn't use gevent-socketio. nltk is a language processing toolkit which would greatly benefit from Python3's unicode changes but is not converted yet. Also for a real project I wouldn't want to risk noticing halfway through that a sub-library hasn't been ported and I have to rewrite it from scratch.
fabric, paramiko, boto, supervisor... well supervisor not a library but it'd great to have all Python 3 down to deployment.
That's possible, I tend to just use default binaries. I'll also say that nonstatistical uses of arrays are almost always better suited to numpy, but R is really well optimized for statistical computing.
&gt; Scientists have to deal a lot with bytes or strings of bytes but never Unicode. Python3 treats Unicode as first class citizen as opposed to raw strings of bytes like in Python2. Scientists give a rats ass about unicode. As someone constantly dealing with text in multiple languages, I couldn't disagree with you more. That's the main reason I cannot wait until Python3 is the mainstream choice.
What's the 'secret'? Did anyone find out?
At least fabric 1.x will be deplrecated "soon" and version 2.0 should get Python3 support. Invoke (fabric's task runner) works in Python3 just fine right now.
I think he is asking for an auto-tuning library, not a description of how to implement a PID controller. i.e. http://www.mathworks.de/de/help/slcontrol/ug/introduction-to-automatic-pid-tuning.html FWIW: I usually follow the rules of thumb and tune (emperically) manually. I think the control systems library (python) would contain all the building blocks necessary, but your tuning approach would depend on if you had an model of the plant.
I was surprised when I saw the parent comment. Continuum is one of the most reputable python software companies with strong ties to open-source. If this is the definition on enterprise, we need more enterprises not less. But if these comments indicate anything, it's that you may need to put more effort in marketing, starting with your website. Your website is indeed too enterprise-y. The carousel only shows your paid products and I wasn't able to find the word "Open Source" by using ctrl+F and it was somewhere nobody usually looks. There is no mention of "community", "github repo" or any other words usually associated with open-source. Look yourself and tell me if your website is more like [Elasticsearch](http://www.elasticsearch.org/) or [Oracle](http://www.oracle.com/index.html). I know you are committed to open-source, but only because I use your products. For a newcomer you look like an enterprise only focused on B2B markets and paying clients.
This is awesome. I have an OpenGL simulation project due this friday that uses a lot of numpy operations, and this might bump up my framerate by quite a bit. Thanks!
Then they're going to become unpopular libraries soon enough, especially when Python 2.x support ends. And even if they do port in the nick of time, who wants to use a library whose maintainers were so dangerously lax in supporting modern Python? We've got to stop letting the tail wag the dog. 
Python 2.x library maintainers are too busy downvoting you to port their code. ;-) The former maintainer of Pyjamas before the coup once wrote: "Why should we port to Python 3 when 2 is going to be supported FOREVER?" Yes, that's exactly the kind of thinking that should be boycotted. 
Don't you think it is still a bit early to compare Python2.7 to Windows98?
This looks nice. Can you comment on how extensible the websocket/notebook framework will be? For example, will it be easy to use your code as the python&lt;-&gt;browser layer but use three.js or sigma.js for rendering? 
Too many people seem to be advocating choosing the version of the language you use based on your library preferences rather than choosing your libraries based on Python3 support though. This helps feed a catch-22 where maintainers won't port because there isn't demand and there isn't demand because they won't port. Python and Guido helped this by being to accommodating (such as far too much backporting of 3.x features to 2.x, causing a certain person in this subreddit to always insist that there's no compelling reason to switch to 3.x) and others took advantage of the dual development track not as extra time to port but as an excuse to keep using 2.x indefinitely. All in all, it's hurt the language as resources that could have gone towards developing Python went towards maintaining and backporting for 2.x. It's also led to fragmentation and confusion. I hope the takeaway is that Guido needs to remember the "D" in BDFL the next time there's a breaking version of Python and not let things get out of hand. Sadly, some folks took advantage of Python's good nature.
Well it isn't like Python 2 is somehow going to magically vanish. That simply isn't how things work with computer stuff...
As far as I'm aware Guido knew it would take this long, and I don't really mind that. There reasons to use 3.x are now finally compelling enough to push people towards it, but I don't think its fair to say that the backported changes were what made it take so long to get there. The purpose of 2.6 and 2.7 (and 3.3 in a way) was to ease the transition from 2.x to 3.x. Without these releases it would be anywhere from nightmarish to impossible to support both 2.x and 3.x
It was the last I read. Maybe they are taking a different turn with it? The github page says "experiment" so maybe it was just a quick testing ground?
Have fun :]
There comes a time in the development of every programming language when the focus of the developers changes from from what people are actually doing to what they *should* be doing. This normally generates conflict and sometimes a big disconnect...
That syntax is invalid.
So happy to see GPU's starting to move into "traditional" programming! I'm in no way a developer, but I do write some simple scripts and programs. And by the looks of this, I'm not to far off from being able to take advantage of the GPU! And that is awesome :D
Why might one choose this over Vincent? https://github.com/wrobstory/vincent at least as a starting point?
Do you have controls background? Then Modeling the system and designing using [Python Control](http://www.cds.caltech.edu/~murray/wiki/index.php/Control_Systems_Library_for_Python) may be your best bet. Otherwise, I usually start with [Ziegler-Nichols](http://en.wikipedia.org/wiki/Ziegler%E2%80%93Nichols_method), and empirically tune from there. 
The websocket/notebook framework is actually not. That is, we have a generic Python object &lt;-&gt; Backbone-based models bridge, and the in-browser BokehJS code has a simple shim that gets model updates from the server via websockets. If you run in server-less mode, then there is still an entire reactive object oriented plot scenegraph in the Javascript, which can be driven by external Javascript. See [1] for the Python object layer code, and [2] for the JS layer. The IPython Notebook folks have been working on a Python kernel &lt;-&gt; Notebook data transfer layer, and the proof of concept for widgets in the notebook was demoed by Brian Granger at PyData NYC last week.[3] We want to be compatible with this, but we do not rely on IPython notebook at all for our base infrastructure. It should be possible to use our stuff to bridge Python objects to three.js and sigma.js, but since we didn't really plan for extensibility this way, it might take some work. First, you would need to subclass the HasProps base object in Python (maybe call it ThreeObject or SigmaObject), and then on the JS side, you would need to create a new Backbone Collection and register your sigma.js/three.js object with that collection. That object would then need to handle all the logic of actual rendering, setting up the canvas and rendering state, etc. You can kind of see where we do that in [4] and [5]. [1] https://github.com/ContinuumIO/bokeh/blob/master/bokeh/objects.py [2] https://github.com/ContinuumIO/bokeh/blob/master/bokehjs/src/coffee/common/has_properties.coffee [3] https://vimeo.com/79832657 [4] https://github.com/ContinuumIO/bokeh/blob/master/bokehjs/src/coffee/common/plot_context.coffee [5] https://github.com/ContinuumIO/bokeh/blob/master/bokehjs/src/coffee/common/load_models.coffee
I think we can definitely make improvements to our website, and work is underway in that regards. However, as a business owner, if I had to choose between the two ills of (1) everyone coming to our site and thinking that we are an enterprise software company selling B2B, or (2) everyone coming to our site and thinking all we do is open source, I would gladly take the former because it then means that our potential customers will at least understand we have products and offerings for them. :-)
Find jobs and apply. Take requirements in job ads with a grain of salt. Be honest. Demand for developers is very strong right now and I'm sure you could get a Python position without too much trouble. In short, just go for it.
With the exception of the GIL, all languages suffer from these issues to some degree. What would you use instead and how would it get around this? Killing threads is nuts in any application. The halting problem affects all languages. Thread-safe and race-safe sharing is again hard. People build whole platforms (like Redis) to get around this. etc. etc. What do you recommend we use instead of Python?
Have you got a sample of that WiX code?
Don't need twisted. Just use asyncio/tulip
That's pretty much the way to go. As the dict type documentation states, the keys must be immutable. m = [[0, 2, 3], [2, 0, 1], [3, 1, 0]] t = tuple(tuple(n) for n in m) d = {} d[t] = ['some','stuff'] If the matrix is never going to be used as a list, just make it a tuple of tuples in the first place rather than messing around with intermediary discardable objects. 
This is pretty cool but it's missing a _lot_ of awesome Tornado features. For example, the tornado.concurrent module with it's sweet `@run_on_executor` decorator. I need to put together, "Advanced Tornado" or something like that. The forthcoming 3.2.0 version is going to have some even _more_ advanced stuff in regards to concurrency with the new [tornado.platform.asyncio](http://www.tornadoweb.org/en/latest/asyncio.html#module-tornado.platform.asyncio) module. Something else to think about: Do your unit tests take _forever_ to run? If they can be run in parallel you should take a look at [tornado.testing.AsyncTestCase](http://www.tornadoweb.org/en/stable/testing.html)
&gt; binary applications / binary packages Cool outdated opaque binary which I can double-click on. * http://pythonwheels.com/ * https://pypi.python.org/pypi/esky (Python 2/3, py2exe, py2app, cxfreeze, bbfreeze) &gt; **configuration** Why reinvent the wheel to store static configuration files? * Create a versioned package containing configuration information. * Generate templated configuration on invocation (`str.format`, `string.Template`, `jinja2`) (because someone will accidentally delete it) * *https://config-resolver.readthedocs.org/en/latest/* * http://docs.python.org/3/library/configparser.html * https://pypi.python.org/pypi/configobj/ * https://pypi.python.org/pypi/dotconf/ * YAML * https://pypi.python.org/pypi/collective.recipe.template * http://www.buildout.org/en/latest/docs/recipelist.html &gt; **dependency bundling** esky &gt;&gt; esky: keep frozen apps fresh &gt;&gt; &gt;&gt; Esky is an auto-update framework for frozen Python applications. It provides a simple API through which apps can find, fetch and install updates, and a bootstrapping mechanism that keeps the app safe in the face of failed or partial updates. `pip wheel` &gt;&gt; Build Wheel archives for your requirements and dependencies. https://github.com/wolever/pip2pi &gt;&gt; pip2pi builds a PyPI-compatible package repository from pip requirements https://pypi.python.org/pypi/compoze &gt;&gt; This package provides a script for creating setuptools-compatible package indexes using packages downloaded from other indexes.
Unless you're using something built on twisted (e.g. scrapy) *Edit: stupid phone*
Port it to tulip
XP would be a fairly accurate comparison, as there's many applications that have moved on, but many programs are stuck there...
3.3.3 should be no different to someone just starting than anything in the 3.x family. Once you learn more, you'll probably want to explore Python2, since quite a few projects still use it, and there's not a ton of differences.
Ye olde [Wall of Superpowers](https://python3wos.appspot.com/) is getting greener and greener.
Willing to move to DC? http://ch.tbe.taleo.net/CH01/ats/careers/requisition.jsp?org=ATLANTICMEDIA&amp;cws=40&amp;rid=1488
That's easier said than done, because you can't easily transition things if they don't even work on the same version of python. ~~Also tulip isn't even out yet.~~
hm- i think this is smack dab in the middle of finals season for students. lame.
this looks useful, but is it simply a way of 'classifying' functions into a namespace? or is it taking advantage of some of the OOP stuff such as inheritance etc n00b here
This message is probably too late, but here goes anyway. You may have noticed this already, but there are two basic answers people are giving in the thread that overlap but aren't quite the same: data structuring and behavior sharing. - __Data structuring__: Let's say you have a pair of functions `get_length(x1, y1, x2, y2)` and `get_area(x1, x2, y1, y2)`. I think you can already see the problem there: the arguments are unordered. Better would be to have a data type called a point with an x and y (maybe a z) and then pass in two points to those two functions. Generally speaking, whenever you have a long chain of functions where you keep passing the same things over and over, you can probably benefit from using classes instead of using `tuple`s (which are essentially C-structs without the type information). - __Behavior sharing__: You have something that does A B and C, but you wish it did A D and C. This is what inheritance was made for. Define a sequence of behaviors on a base class and then make a series of sub-classes that slightly change that behavior. In an example from my job, the other day I used Django's feed class. It has a lot of mechanics behind it to create RSS feeds, but all I needed to know was that in my subclass I should define the `get_object` method with the instructions for how to get my site's data out of the database. The Django people didn't need to know about my site, and I didn't need to know about how to make a valid RSS feed because of behavior sharing. (People usually call this polymorphism, but that name doesn't mean anything to you unless you already understand it.) Data structuring and behavior sharing aren't quite the same things, but they're pretty close, and it's often helpful to have something with related data and behaviors. For example, it's useful to make a person class with a date of birth instance variable and a get age method. You could do the same thing with a function by just passing in the date of birth, but then you lose the relationship between that date and the person's name and sex if you're not careful. So, bundling the two into a class is good sometimes. 
he does start out assuming you've never programmed.
I do, considering my industry (games) and its neighbor (film) use Maya for many things (I've used only Maya for 11 years at 5 companies), and it's still on an embedded Maya 2.6.4, even in the recent Maya 2013. Maya 2014 comes with 2.7.3, but it'll be a few years before we upgrade again. It's a big deal to move everyone. We won't be in 3.x anytime soon.
It's on pypi
I'm not sure thats's the official one, last time I saw Guido give a talk on tulip he mentioned a minimum version of 3.3. 
Programming is programming. The language is irrelevant. If you know how to code picking up a language will only take a week or 2. It's as simple as knowing, "oh how do I pass a pointer in this language. Lets google it" The tools you use are the same in every language. Some just make some things easier. In short: having coding experience is all that matters
Here it is, uploaded by Guido https://pypi.python.org/pypi/asyncio
this answer is the most correct one. but to add to it NETWORK, because going the usual route through an HR department is a dead end. Those bozos dont even know what to look for. The best strategy is to interview with the team you will be working with. If it's a good fit, the HR bullshit will be just a formality. To do that, NETWORK, meetups, users groups etc. 
Thanks for your response. The loop is in existing hardware, I was just looking for something to help with tuning. I haven't found anything really that could do the job and is open. It is one thing to write a loop to handle PID it is another thing to auto tune the loop. 
Looks very promising. Somehow I've never managed to work on a GPU related project so working with them is totally foreign to me, looks like once this matures a bit it should open this up as a possibility for me.
Why not raise an exception instead, though?
I actually just managed to get into a job that is entirely Python with my years of open source experience in PHP, Perl, and Apache. It depends on what the company is looking for. Any company looking for JUST language knowledge is not worth working for anyway, IMHO.
Hmm, I don't know anything about tuples in math or outside of Python. I just know it's an immutable collection of related values that is hashable if all its elements are as well
The introduction of tulip/asyncio into the standard lib in 3.4 is going to completely change libraries like gevent and Twisted. I foresee those libraries changing completely soon. Speaking as a programmer with a project currently stuck in 2.7land, the number of libraries getting ported to 3 appears to be accelerating. I'm very hopeful that I'll be able to port to 3 very soon.
Have you looked at [this](http://matplotlib.org/users/event_handling.html) documentation page?
The changelog entry "Fix various unicode operations on strings with large unicode codepoints." may seem dull, but it's quite exciting to me. This is the last bug I know of where you had to worry about how a Unicode string is represented internally. When I'm writing a [text handling library that works on Python 3](https://github.com/LuminosoInsight/python-ftfy), Python 3.3.3 is the first version where I can expect consistent and correct behavior from every installation of Python, on every OS, no matter what crazy Unicode codepoints show up in your strings. Go nuts with emoji, with musical notation, with Chinese characters that Chinese people would have to look up in a dictionary, with private use characters you just made up for your own nefarious purposes. It all just works.
At 1,600 pages, I had better have found jesus (and solved several NP-complete problems) by the time I'm done reading that beheamoth. That's longer than a copy of the Bible from my bookshelf.
This is not streaming. This downloads the file and plays it.
Here is a starting point using matplotlib http://vimeo.com/63260224 Chaco can also do that http://docs.enthought.com/chaco/user_manual/annotated_examples.html#scatter-select-py
As someone on the interviewing side, we often take people to the interview stage who claim to have experience with one or more programming languages, but no real world experience - especially at the moment, as we're currently interviewing fresh graduates, who may have used it in project work, but nothing in a work environment. We'll generally ask them to pseudocode something simple on a whiteboard; take a sorted array of numbers and only output the unique values, for example. We're not looking for 100% valid Python/Perl/C++/whatever on the board (though it is more impressive if you do), but we are looking at how they approach the problem, and whether they come up with a logical solution, or at the very least, a logical *approach* to the solution, i.e. they make a few fuckups, but then step through the code in their head and figure out a way to fix it, and explain their thinking along the way. Coding follows, for the most part, very similar paths of logic, whatever your favourite language is, and you can generally tell the ones who have a decent grasp of programming logic over the ones who don't. Basically, don't discount yourself simply because you lack work experience; apply anyway. If you can get some experience with other aspects of coding through hobbyism, whether it be testing, deployment, or whatever (learning how to use VirtualBox with Linux OSes is great for this), all the better, so long as you can show that you understand it, why it's important, etc., and didn't just follow a few tutorials blindly. Even if you don't get the job, don't be discouraged; going for interviews is great experience in itself, and don't be afraid to ask for feedback from interviewers afterwards; not everybody will reply - especially if there have been a lot of applicants, we don't always have time for personalised feedback for everybody who applied, and some companies have policies not to tell an applicant why they were rejected, for fear of legal repercussions - but if they do, it can be very valuable when considering future applications. Remember, if you got to interview stage, and your resumé was honest regarding your skills, it usually means that you were qualified for the position (otherwise why would you be invited for interview?), but somebody else who was better suited to the position or company beat you to the post. That sucks, but you can't fault a company for wanting somebody who better fits the bill.
If you don't mind living on the edge, [nltk 3.0a](http://nltk.org/nltk3-alpha/) supports Python 3. Its default tokenizer and tagger are better, too. Python 3 is becoming the great language for NLP that it should be. (fixed brain fart where I said "Unicode" instead of "Python 3")
Very neat, easy piece of software! Couldn't find any way to do live streaming, though. Is that possible? As in, making a little radio station that people could access where if we're 15 minutes into the playlist, they hear what's being played at the moment instead of starting from the beginning.
This should get you started, just something I threw together quickly. It doesn't erase previous points, but it does demonstrate the method you'll want to use for doing this. https://gist.github.com/bheklilr/1be3bbaf733ff77d6781
Another apt resemblance is that they're both about to run out of official support. 
To be honest, if you have 10 years of Enterprise Java and VB.NET and you are motivated, you will have no problem picking up Python. I know, because I work in Big Enterprise, and I have picked up and evangelize and trained others in Python in my workplace. The learning curve is low, and you are experienced. Sell your experience with confidence because you *will* do well in that position. 
No specific experience or no experience at all or...? Or are you asking/they hoping that your lack of experience will translate to working for below-market wages? And you're also saying you have almost no programming experience but people are looking to fly you to interviews? Do you have an advanced degree from a prestigious university? 
 def main(): print ("Hello, welcome to a simple coin adition game. You will be given a number, and you must feed in the names of the coins required to add up to that ammount.") #A random money value is generated value = random.randint(1, 100) print (number, "cents") penny = 1 nikel = 5 dime = 10 quarter = 25 func_addition(penny, nikel, dime, quarter) def func_addition(penny, nikel, dime, quarter): sum = 0 print ('enter the name of a coin. No caps please.') input('coin name') = coin coin + sum = addedcoin if addedcoin == value: print ('correct') Looks like this is supposed to be your code. First, main is never called. So under all your function defs, you should call main. Second, some of your assignment is wrong, in func_addition, you should have coin = input('coin name'), I don't do too many console input programs so I'm not sure if that's how input is used or not. You should also have addedcoin = coin + sum if you want to assign added coin. Next, the scope of value is off, func_addition can't see value because it only exists in main. Overall, the logic of the program is wrong I think. Try having a dictionary coins, you can initialize it like this. coins = { 'penny' : 1, 'nickel' : 5, 'dime' : 10, 'quarter' : 25 } This way, when the user gives an input, you can do sum += coins[coin] You shouldn't need the addedcoin variable, because you want to check the sum against the value, not just the addedcoin. The input should prompt in a while loop so that the user can input multiple coins, right now only one coin may be given. These are some of the logical errors and syntax errors that your program currently has.
Why delete the anonym-ish function at the end? In most cases, you're in another function, so it goes away at the end of the call. Or you pass it somewhere else, so it still can't be cleaned up. 
Everything codehelper said was correct. There are a few things I can add. def func_addition(penny, nikel, dime, quarter): sum = 0 print ('enter the name of a coin. No caps please.') input('coin name') = coin coin + sum = addedcoin if addedcoin == value: print ('correct') In this function, the identifier "value" is not defined. You assigned to "value" in main(), but that variable is local to main() and you cannot access it from another function unless you pass it in as an argument or make it a global variable. I think this does what you want? import random from collections import defaultdict as dd def main(): goal = random.randint(1,100) sum_so_far = 0 print "try and reach %d cents." % goal while sum_so_far &lt; goal: sum_so_far += dd(int, {'penny':1,'nickel':5,'dime':10,'quarter':25})[raw_input("Choose a coin: ").strip()] print "You %s." % ("win" if sum_so_far == goal else "lose") if __name__ == "__main__": main() 
Just use Python 2.7 then. It's not hard to learn both, but do it one at a time. 
Its hosted on github. Pull it locally and change whatever you want. https://github.com/nltk/nltk/blob/master/nltk Then be sure to import your locally modified copy into your code.
This is just a way of wrapping state, in this case the "customer" data. Instead of passing around the customer data all over the place, you make a class that holds it. Then you can ask the class instance about the data, or make changes to it, in a simpler way. But I try not to start by figuring out what my classes should be. That tends to lead to classes that are too small or too big.
Yeah, I think that just a few "dummy" files for demonstration would be fine, but the structure of the WiX file, and how you build it in Python, would be valuable to me.
It's not a catch 22 at all. There are ways to gain real world Python experience while not on the job. Find an open source project that makes heavy use of it and start contributing :)
It does look nice. My only complaint is the font. If they could have some presets for nice font styles and shapes it would be nice. Ideally one should be able to drop a plot into a ppt presentation or a report with minimal editing.
Not being familiar with matplotlib, how is this better than it? Couldn't find it in the link. Are the colors automatically better? Is the API easier?
As a physicist, I honestly find these plots worse than the matplotlib defaults. The gray grid is very distracting and the colors have low contrast.
the results look really nice. but man i have to say i wish people would build projects with fewer gash dependencies. you shouldn't need scikitlearn, pandas, scipy and numpy (let alone everything else in there) just to do plotting. i could use d3.js to do all these things, but it would only require d3.js.
There's been a whole bunch of similar modules posted lately, and I have to say this is the nicest looking one so far.
Good points, Matplotlib should really start focusing on theming support and improving the look of plots.
done. https://github.com/matplotlib/matplotlib/pull/2236
This is not just plotting, interpolation of time series error bars and confidence intervals is a lot more than drawing colored bars in javascript. If dependencies are difficult for you then perhaps you could try another operating system where they are not such a problem. Or use virtual environments.
the additional timeseries functionality in this module is very nice.
I suppose this article is related to Python's original namesake.
&gt; If dependencies are difficult for you then perhaps you could try another operating system where they are not such a problem. Or use virtual environments. How does changing the operating system or running in a virtual environment change the dependencies?
I'll take a look into those features. I was also thinking to write something on Tornado + ZeroMQ, because I think you can do really nice stuff combining them, and ZeroMQ plays very well with Tornado. 
This doesn't replace matplotlib, it works with it. You import seaborn in a file that uses matplotlib and your graphs instantly look cool. It can also do more than that if you start using the API.
No, it's just a popular (and old) framework in Python. I/O libraries have existed long before Twisted, and not just in Python.
^ This is a solid advice. Some actionable ideas to help you get started: Find a project, start by looking at the open bugs of the project, pick one bug, try to reproduce the problem and then try to debug/fix it to get yourself familiar with the code. If the bug is too complex, you can always send an email to the mailing list or one of the developers directly asking for guidance. Note that bug fixing may seem like a chore, but it is an important part of being a developer and often it can expose you to the underlying nuances and subtleties of Python, it's lib, the operating system and the project itself, which is normally the type of things you would expect to help you in a programming interview anyway. Good luck :)
This is because you are passing the result of "listen(s)" as "target", not the function "listen" itself in your invocation of the "Process" constructor. As a consequence, "listen(s)" is executed during the assignment. Try this instead: looper = multiprocessing.Process(target=listen, args=(s,)) tl;dr: Pass the function, not its output to Process
Twisted is 12 years old yes. Can you quote me an older framework with an IO loop ?
Job requirements aren't exhaustive, they're a wishlist. The applicant that ticks the most boxes will be hired in most cases, so go for it!!
I took the OS comment to mean switch to Linux where installing a new python dependency is as simple as a single package manager command whereas in Windows it's messy unless using something like canopy.
That's not a function, it's the [name of a test](http://hg.python.org/cpython/file/tip/Lib/test/test_tcl.py). The Tkinter module does link against the TCL interpreter, on account of the fact that Tk is written in TCL. 
what pandas integration do you mean?
I'm saying I have no professional experience in the tech industry. I've worked as a maintainer on an open source project for a while and have done a bunch of online courses.
Just to add on two items: 1. I expected to need to keep honing my skills for a few more years, but apparently there's enough demand that places are okay with it (and I say explicitly during interviews that I don't have a CS degree / don't lie about my experience) 2. So far I've passed every coding / technical interview I've been given. I'm just trying to say that you need to apply for things and let other people decide whether they think you're ready to work for them.
&gt; That's not how it works. You have to pass the automated resume system and then the resume jockey before you get to talk to anyone. it has continued to work for me for the last 10 years. there is plenty of evidence out there that the automated resume/hr screening procedure is useless. No one in HR will admit it though because that would be like admitting that they are useless. But, they are useless as far as filling jobs is concerned. Any resume workshop/job counseling will tell you the same thing. They'll also tell you that most job listings in the usual places are bullshit. They are either there because they have to advertise for the job for a certain amount of time before promoting from within, or are just fillers to justify the monthly expense of maintaining the subscription. Side note: I wonder if companies would be willing to pay for someone to interview just so they can promote whoever quicker. I'll gladly do it for $500 + travel expenses + lunch and you can ask me questions on whatever for a couple hours. :) So, how do you find out about the jobs? Network. Someone somewhere knows someone who's looking for someone that might have your skill set. You wont find them by constantly submitting your resume to a black hole. You have to talk to people, you have to make it known that you exist and are available. edit: reading your comment below, we agree more than we disagree. I'm merely describing a hack to the system that has continuously worked for me. it's not without it's drawbacks though. I dont know hardly anyone in those "big companies" so those kinds of jobs are out of my reach, but then again, I rarely see one that I would want. 
&gt; but it looks to me like the concept of building applications with front-end GUIs that are packaged as executables is not Python's strength I'd more optimistically say that python does so many things well, gui applications just don't stand out. The language is too versatile! Personally, I use python for scientific data analysis. It has really great tools for all the data mangling without a problematic speed sacrifice - and if you do hit speed problems, stuff like cython is remarkably easy to start using. I've also recently had fun making android applications with [kivy](http://kivy.org/#home). It's a really impressive project that lets you make fully fledged apps without touching java at all, which is really nice. Actually, to be clear, kivy is a cross platform graphical framework (linux, osx, windows, as well as android, ios, maybe others) with some associated tools that make deployment on android very easy.
programming. On a more serious note, I uses it for randomly mocking about, trying to make myself some simple gui things or more advanced cli games and such, learning as I go along. I've also used it to play flash games on the internet for me, just as a learning excercise, it just uses a program for linux I've downloaded though to simulate mouselclicks and give me feedback from the screen. 
I use python for two main purposes: data analysis and web development. I'll do web development first. I've created multiple specific web applications for my student union and small companies, mainly to ease administrative tasks. I'm now starting to work on an notification system trough email for the same student union. I am a student [Technical Medicine](http://www.utwente.nl/master/technical-medicine/) at the University of Twente, the Netherlands. I do stuff you really can't possibly do in Excel/Access like model optimization and signal analysis. We learn to use Matlab (the standard for academics) for these purposes, but I recently started using Python. I have two important reasons for that: Python is free and there are better machine learning/model optimization packages for Python (especially hyperopt). The fact that Python is free allows me to run it on a non-Matlab-licensed server, so I don't have to use my own computer for all the calculations, which would screw up my efficiency quite well (now I have reddit for that). Another reason is that Matlab is really awful at memory management --- it tends to use 2-3x the size of your data set as memory, which is not ideal working with 4GB+ data sets. The python program I wrote uses only 1-1.5x the amount of memory.
Desktop apps, both at work and for hobby release. Work apps do networking, collecting and displaying sensor readings (real-time plots, video feeds). Hobby apps are mostly utilities: instant messaging tools, screen colour tweaker, text-to-speech reader etc. Web apps, both at work and for personal use. Scripts of all sort, to automate certain tasks, like making video thumbnails, sorting mbox folders, maintaining backend processes. One-time scripts, like gathering IMDb links and ratings for the programme of a local film festival with a somewhat lacking website. Python is well suited for making GUI applications. The applications can easily be packaged into stand-alone exes with tools like PyInstaller.
Assuming of course that the package with the specific version you need is present in the repository. If the version you need is not in the repository you are in the same boat as before. 
&gt;I love this advice, "network", all the time. It's another one of those things that sounds good but doesn't really say anything specific. What it really means is "Somehow, some way, happen to meet someone who's looking to hire for the job you want". It's a big part of how you get the best jobs. It's hard to give someone a step by step guide on how to do this. What it basically boils down to is make as many friends as you can, and stay in contact with them. Send out feelers to them, and have them send out feelers to their friends. The last three jobs I've taken were all made possible in large part due to networking.
The downsides of dependencies are: finding &amp; installing them can be a pain, and the system gets messy after every project wants it's own 10-20 dependencies. But with virtualenvs, the dependencies are isolated away from the rest of your system, and installing them is trivial with pip. So there's no reason to avoid dependencies and re-implement the common code in many packages.
 sudo apt-get install package likewise mkvirtualenv --system-site-packages foo is pretty easy.... why else would you complain? It can get harder if you are boxed into an existing python distro on another OS (like canopy, epd, etc).
According to PyPI, not working in 2.7 either. Maybe this library isn't being actively maintained any more.
Oh silly me! It didn't occur to me that you meant virtualenv. I was thinking along the lines of running virtualbox or vmware. 
Do the first 50 projecteuler.net problems
It didn't occur to me that u/goforkyourself meant virtualenv. I was thinking along the lines of running virtualbox or vmware. Virtualenv is naturally the better alternative. 
Well, pyzmq use Tornado ioloop and a modified version of Tornado iostream, it also provide monkey patching to make Tornado use ZeroMQ ioloop. So from an API point of view everything is fine. I think that things are even better now with Tornado 3, because handling of asynchronous calls is much more cleaner. Still, with ZeroMQ you have only the building blocks, you have to do all the rest (supervision, fault tolerancy, security). 
What matplotlib needs is a drastic redesign of interface so as it takes as little time as possible for users to plot. Here is the workflow for most of us: (1) Do the experiment, generate the data (2) Plot the data in some perspective (3) Analyze the result from step (2) and repeat step (2) if necessary (4) If needed, change parameters, go back to step (1) (5) Otherwise, generate final plots/figures for publication For this workflow to be efficient, the transition between (1)-(2)-(3) needs to be really fast. Otherwise, it disrupts the thinking process. In Excel, once the data are available, you can put up a plot within 20-30 seconds. In Matplotlib, it's 30 minutes, sometimes more, because you will have to write a program to plot. Using matplotlib disrupts the thinking process so much that it's not worth using in many cases. The result is many of us are not sharp with Matplotlib; which means it will take even longer if you need to write a program to plot in Matplotlib. So most of the time, matplotlib is not utilized in the process of data analysis, but rather in step (5), to generate pretty figures for publication. But often, it is even not worth to do this in Matplotlib because Excel is sufficient for the job. The people behind Matplotlib need to read Edward Tufte, grammar of graphics, etc. All the components are there; you just need to make it extremely easy and intuitive for people to do things, at least the most common things. 
I didn't have any Python experience when I was hired. If you know the theory well, somebody will hire you eventually. You'd have to learn a lot of practical stuff anyway, because every company does its thing in their own way.
DC is a great city but the SO and me are currently happy in NYC. DC is up on my list of places to live in outside of NYC and has a cool and underrated startup scene IMHO.
&gt; This helps feed a catch-22 where maintainers won't port because there isn't demand and there isn't demand because they won't port. You just gotta stroke somebody's ego. That's what drives the open-source world. Someone used that nasty trick on me to get me to port my package to Python 3 :)
I use it for file manipulation at work. I do work with other environments, too. Interface file testing: custom diff, internal dependency check, format check. Reporting: Process and join one form of file into another. Input is mostly some delimited text, output is mostly fixed length or xml.
having implemented statistical analysis and plots using both - um, no. pandas is in its own league here (or at least approaching the league of R)
If you can't make a bunch of meetups, pick one. In the cities I've lived, the Python meetup is usually very well attended and includes lots of interesting topics. I know about "life stuff" -- I also work full time, and I have four kids whose schedule I am beholden to -- but once a month I can usually find a way to attend one of these things. The payoff is profound. It's the best exposure you'll get.
But you write the program once, and then run it again for every iteration. At least I do. When I'm done, I just save the figures and done.
Job apps lie about what they're loooking for: I got a note back from a company I'd clicked on in [AngelList](http://www.angel.co) - which is a nice site because it shows startups and has a really low commitment way to submit job apps. I looked them up quickly and *every* ad said they wanted someone with experience in Java/C/C++ (in addition to something like Python). I told them point blank that I didn't really know Java, C or C++ and they didn't care. So you might even ignore the requirements.
The real language example probably wasn't the right choice. Thats two whole different worlds. But on a programming language level your Argument is spot on. The language is just a tool, the key (to a good job) is your knowledge about programming.
"Violin", eh?
Or the submitter is one of those paid to submit things to social media sites.
is there any real hope this will ever happen? 
Sublime Text plugins. Overall I really enjoy python, but the package/dependency management and module system kind of puts me off. Its honeslty the worst of any moderin-ish language I have worked with. Among other things, it annoys me that I have to do the following at my execution entry point to import 3rd party modules from a project local library directory (I'm kind of a python noob, there could be a better way): ``` sys.path.append(os.path.dirname(os.path.abspath(__file__)) + os.sep + "lib") ``` ___ **Edit**: psyche...here is my goto cross platform version. def add_lib_path(lib_path): def _try_get_short_path(path): path = os.path.normpath(path) if sys.version_info &lt; (3, 0) and os.name == 'nt' and isinstance(path, unicode): try: import locale path = path.encode(locale.getpreferredencoding()) except: from ctypes import windll, create_unicode_buffer buf = create_unicode_buffer(512) if windll.kernel32.GetShortPathNameW(path, buf, len(buf)): path = buf.value return path lib_path = _try_get_short_path(lib_path) if lib_path not in sys.path: sys.path.append(lib_path)
Is there really anything that you can do different with web development in Python that you can't do with HTML5/CSS or javascript/PHP, etc? Or is it just that Python is another choice that can always do MORE than a language which is tailored only for web development?
This sounds really interesting is what I would like to do. Creating useful utility apps that solve problems and make my life easier.
I dabbled in perl before switching to Python and it was the same. Are the majority of languages like this?
HTML5/CSS let you display text via markup and styling, you'd use these regardless of your backend (python, php, javascript, whatever). Rather, the backend would control exactly what html and css get served up, such as autogenerating pages depending on input parameters. As for what python can do, ultimately nothing that php or whatever cannot, but nor is it lacking anything. Since python is a great language (arguably way better designed than php, at least) with great tools (there are so many great web frameworks now), it's a great choice - especially in the context of already knowing how to use it.
Have you tried virtualenv? You can set up a separate instance of python and pip in the folder, then use `source virtualenv/bin/activate` to set the working environment to that virtualenv. Then there's `virtualenv/lib/`.
Well, I partly agree. The issue with Matplotlib is not that it doesn't use nice pastel colours, it's that it always chooses the wrong ticks so the tick labels overlap -- or if you make two plots with values on different scales, they end up as different sizes because the labels are strings of different lengths -- or a million other tiny things which this library won't affect.
Scientific computing. Specifically down stream analysis of cancer genomes
Thanks for the explanation.
yea. works great when you have full environment control, but when you need to package something to be loaded and used in an external system where you don't have control over launching the python interpreter or have pip available isn't an option. Granted, my use case is pretty specific, but its still an issue. Hell, Sublime (or similar systems) could add virtualenv support, but it seems like the type of thing that should just be supported at the core/runtime level out of the box.
I make little scripts to simplify daily stuff. Just yesterday I wrote a script to get information from an API anonymously and put the data into json files, so that a PHP site could access the data. I set that up in a script so it updates every 10 seconds, which is far better than getting the data every time the webpage is loaded. I also made a script to create a REST api for a [minidlna](http://sourceforge.net/projects/minidlna/) database. Also, a script that checks with my ISP to see if my internet usage for the day is over the 'suggested' amount (calculated as total/daysleft), and then logs into my router and disables the wireless internet if true (for my family members; I'm regretting introducing them to torrents :P). And lastly, a script that does dynamic DNS for me: checks the dns entry for my home subdomain, if it isn't a match with the current IP ([here's the site i'm using to get my public IP](http://ipv4.icanhazip.com)) it logs into my domain management and updates the entry. Most small scripts I do are on my [Github Gist](https://gist.github.com/blha303/) account, the others are on my [Github profile](https://github.com/blha303/).
Web development. You've got a million options for a backend language for web development. But without special requirements you want to use Ruby or Python. And I love writing Python.
Not in the forseeable future.
Data analysis and web development. IPython is great. 
“Global Variable Considered Harmful” (1973) https://en.wikipedia.org/wiki/Global_variable#cite_note-1 https://en.wikipedia.org/wiki/Information_hiding#Encapsulation https://en.wikipedia.org/wiki/Encapsulation_(object-oriented_programming) https://en.wikipedia.org/wiki/Protocol_(object-oriented_programming)
Added support for PyGTK, Tkinter, and wxWidgets. I still need to familiarize myself with qml
vagina
Can you display the python stack trace? If you are query for a large amount of data this can cause you to lose connection with MySQL. In that case you can try something like varying the size of max_allowed_packet Try [MySQL Manual Packet too large](http://dev.mysql.com/doc/refman/5.5/en/packet-too-large.html)
Hi - Thanks for the response. I will try this when I get home tonight. Any recommendations on the new value? The text files that this particular table consisted of, combined was many gigabytes.
You couldn't do smoothers in d3.js without a lot of additional work... Plotting, in this case, is a lot more than simply mapping points to data. Statistics are involved in creating many of the aesthetics.
If you are looking for scripting applications, autohotkey is another scripting type language.
write a query that returns less data. 
I need it all!!! :)
Pull it in chunks then.
2. kind of works with minimal effort (either you compile pypy --withoutmod-cpyext or you enable some stuff to mock the symbols - it's done for tests) 1. is kind of hard, for really bad reasons.
So maybe something like: X = 0 Y = 1000 SELECT * FROM table LIMIT X, Y Then increase X and Y by 1000 at each iteration? 
i did cs101 as an intermediat C programmer. sometimes its really good, sometimes I was thinking in a C way of doing things. othertimes the course is really tedious.
MySQL server has a timeout on the connection. I think the connection exists on the server until either closed or the timeout happens (but I'm not entirely sure), so if you aren't closing your connections, a large number orphaned connections might build up on the server. You can set a connection's timeout like this: connection.query("SET @@session.wait_timeout = 86400") # set timeout for 1 day On SQLAlchemy, the correct thing to do is set `pool_recycle` to a value lower than the default server timeout. eng = create_engine("...", pool_recycle=3600) http://dev.mysql.com/doc/refman/5.0/en/server-system-variables.html#sysvar_wait_timeout
I think it is also dependent on what you are familiar with. I can do a quick and dirty plot in python with matplotlib faster then I can in Excel, largely because I have written support programs that help me load data in python much more easily then I can in Excel. From there it is very easy to cut and paste code from programs for old plots to get the look and feel that I want. 
Yup. Just append the dataset to your main dataset each time. There are issues with memory consumption, range size tuning, etc. that you will have to figure out. You should probably tell us the actual thing you are trying to accomplish, there is probably a better way here.
Getting familiar with programming in general and games, and 3d objects in particular with [blender](http://www.blender.org). In the process I have discovered scipy for more extravagant functions and have an idea of what I want to familiarize myself with in the future when I get the chance, namely FEM, numpy and sympy. It's really usefull in that context because the variety of libraries gives the option to project nearly everything into 3d data. And that's awesome.
natural language processing for a robot that will write love letters
I am going to try this as soon as I get home. Basically I have a table of data that I extracted from Twitter. One particular field, when processing it, I delimited with a character. Now that I have all the data in the DB, I am attempting to write a new table that takes the following: ID, DATA1,DATA2,DATA3 and converts it to: ID DATA1 ID DATA2 ID DATA3 
I've built my prediction engine in python. 
That's very interesting and worth a look. Thanks.
No, this is the wrong way. 1. Read for insert into select example: http://www.w3schools.com/sql/sql_insert_into_select.asp 2. Read for splitting example: http://stackoverflow.com/questions/10921400/t-sql-substring-separating-first-and-last-name 3. Write a query that uses insert into select and splitting.
How many rows are we talking? 
Millions - I would have to revisit it, but I'm thinking 19 Million
I am very excited about this. Tulip is a way for all the async religions (twisted, tornado, gevent) to coexist. Module writers can support tulip and leave the async framework choice to the application developers. This is a good thing
I will certainly look at it, but the lost connection issue happens on the initial Select. So I guess to do it this way, I'll need to also look at pulling it in chucks too.
grid lines = chartjunk
Just generally mucking about really
You should probably start by reading the goddamn sidebar.
It's because they see it as a threat to their (non-pythonic) lifestyle. It does really show the growth of python. It's hard to hate a language that no-one uses.
Okay - what's your suggestion then?
Reckon they may be OK for informal presentations, but definitely not for academic papers. That being said, does anyone have any suggestions for well polished academic paper templates/libraries?
Python is comparable to PHP in functionality. However, Python is written from an OOP point of view, while OOP was implemented in PHP 5, years after the first release. Also, Python is more modular - i.e. it has few built-in functions, but great extensibility. I would say PHP is a tiny bit easier to learn, but you can do way, way more with Python.
Mainly processing protein structure files (PDB files) - mainly getting certain information out of them, calculate various statistics, and create inputs for other software. 
For my recent project (involves analyzing protein structure files) I started to use classes and methods instead of writing standalone scripts. This is the first time I really write my own classes and methods, and I have to say it is really worth it for bigger projects that require work on similar data structures. 
&gt; future = database.put() Personally I nope on that. Not going back to Twisted, with deferreds, a forest of errbacks and callbacks. So, ok your database's PUT returns a Future. But your library needs a result not a Future. It does something with the result, maybe passes it along, it doesn't know what to do with the Future. So then these Futures bubble up all through your code creating a mess. Oh and then Futures can fail, but those are not Exceptions raised. You need add errback functions. Nope, nope, nope. Anyway, here is how you do it much simpler: Import gevent or eventlet, monkey patch, then use https://code.google.com/p/couchdb-python or Requests directly. Run: import couchdb myserver = couchdb.Server('hosturl') mydb = myserver['mydbname'] mydoc = mydb['mydocid'] You want multiple ones concurrently? Fine, spawn an eventlet.Pool or if monkey-patched, spawn regular Threads which are not backed by green threads, then wait for the results. 
I love it for machine learning. My work primarily uses java, but there's nothing even close to scikit-learn
Brute force statistical analysis. Odds of certain scenarios with dice and cards, mostly.
I completely agree. I am glad others feel the same way.
Can't believe I missed this. Author here, thanks OP!
I'm on chapter 17 out of a planned 21 or so. The physical book should be out in the spring. But don't wait for that, grab it now! And give me feedback before it's too late!
Much appreciated :) Any and all feedback is gratefully received...
Thanks Daniel :)
Thanks guys. Do send any feedback and suggestions and stuff!
You shouldn't have to do it in chunks. You should be able to do everything in a SQL query - it may take a while, but you aren't pulling any data back, the processing is done on the SQL Server itself.
lol. But, whether you want to pay for it or not, the book is designed as a hands-on tutorial - it expects you to be coding, running tests, and building an app all the way through. It's not really bedtime or beach reading, so am not sure whether it would be useful to have it on an e-reader...
hey its another wingide user! hello, friend! all the kool kidz at work are using vim, but im perfectly happy with my purchase.
Day - Content Pipelines for video games, Maya Night - Web App Devlopment (Pyramid, SQLAlchemy)
If you want to do synchronous requests, just don't enable the async interface: &gt; account = cloudant.Account() &gt; &gt; response = account.get() If you don't set `async=True`, it just uses vanilla Requests.
vim is for the proletariat :)
Oh no! In the example, the y-ticks are not well aligned in the distplots example. (The number 1 is to the left of all the other y-ticks labels.) 
I use matplotlib for my publication plots with only a few tweaks, mostly things like the font sizes of different types of labels and line colors/dashing. I also position my legends via coordinates. With very minimal effort, you can produce plots that will blow packages like origin out of the water. If, and this is a big if, I have time, I am hoping to work with a friend on writing a matplotlib for publication tutorial in the near future, maybe ill hammer something rough during my winter travels.
that would be very much appreciated. Nowadays I make my plots with matlab but I encountered a few problems along the way that lead me to research alternatives and python (numpy, scipy and matplotlib) has become very feature rich as the adoption increases. So I am slowly transitioning to python. In any case, tutorials on how to make academic polished plots would be very much appreciated and I reckon many of my peers would appreciated it too. Let's hope you find inspiration and time during this winter :D
there's multiple tools for everything. you can write machine specific assembly code if you really want to and its all equivalent in the end. you can program in [Brainfuck](http://en.wikipedia.org/wiki/Brainfuck) if you really want to. doesn't make a difference except you might not be very productive. We choose to program in Python because it is a very well designed language that increases programmer productivity. 
&gt; it seems like the type of thing that should just be supported at the core/runtime level out of the box. This sounds like the thought behind [PEP 405](http://www.python.org/dev/peps/pep-0405/), included in [Python 3.3](http://docs.python.org/3.3/whatsnew/3.3.html). May not be super helpful now, but support is on the way!
 &gt;As a physicist, I honestly find these plots worse than the matplotlib defaults. The gray grid is very distracting and the colors have low contrast. I'd have to disagree here. For one I actually like lower contrast colors. The gray grid actually makes read and interpreting the graph easier. I would hope though that these are all features that can be tuned or eliminated via setting the right parameters. As for matplotlib and these various extensions I'm not sure why people don't offer up code improvements to the matplotlib developers. There seems to be many of these enhancements floating about that will never get widespread support because they aren't pat of matplotlib to begone with. Incremental improvements to matplotlib makes more sense that layers of additional libraries. 
Yeah, don't forget that if you have this in your rcparams rcParams = matplotlib.rcParams rcParams['svg.fonttype'] = 'none' # No text as paths. Assume font installed. rcParams['font.serif'] = ['Times New Roman'] rcParams['font.sans-serif'] = ['Arial'] rcParams['font.family'] = 'sans-serif' and export as svg, you can touch up fonts and legend positions in inkscape.
&gt; So yeah, do you use Python to build full fledged executable apps? Yes, but not always. There's a lot of scripts that I've developed over the years to do analysis. &gt; What do they do? Aerospace engineering related stuff. &gt; Who do you build them for? Myself (to do my job better), the Department of Defense and NASA mainly. Also, random people at other engineering companies in order to get my name out there (who are mainly stuck on Matlab). &gt; Do you use Python for data analysis? Every day &gt; Why do you use Python and not simply plug your data into something like Excel? Excel is 1) proprietary 2) not on Linux 3) it's slow as balls 4) can't do any math outside of statistics without a plugin 5) I drive external programs a lot, some my own, some third party 6) I don't think I work with big data, but apparently I do (Excel is limited to 32k data points). I also develop an open-source engineering related package (lots of engineering stuff with a qt and wx gui). I laughed when I got an email about some guy using it to load data into Excel. He had to jump through so many hoops to run and load in the data and save it into SQL database in order to access it later. Shockingly, he was having trouble.
Django-powered web-app, sending emails, scrapping data from a web-portal, writing log files, and managing operations for a state-wide news service.
I do the same. Have you had many issues with slow program speeds for large or computationally intensive programs? 
If you need to do something really heavy, you are better off writing it in C and wrapping it in python. If I am writing things in pure python I try to farm the work out to as many compute cores as I can to speed things up. But most of the really heavy work is done in C.
Awesome, I like that, thanks for mentioning it.
Most numpy array operations are already highly optimised and written as C extensions. Profiling your code should have made it obvious what the problem was.
The only criticism I have of your code is "sum = 0". Please try not to overwrite built-in functions. :)
I'm a computer science PhD student. It's generally simulation, data analysis, or optimization for me.
Measuring and analyzing scientific data. I'm an experimental physicist (PhD student) and we run our whole lab (quantum optics and quantum information) with python. We have a home-built environment in ipython with which we control all hardware via home-written drivers/dll-wrappers. that includes (for my lab, there's more in our group) lasers, waveform generators, and so forth. There's some other languages in there as well, mostly code to program certain types of hardware (FPGAs, and some other integrated systems) It has become a nice little framework by now :) For our default set of experiments, including automatic analysis, it's about 500k lines of code in total, about 80% of which is python (on top of that the low-level stuff, like communication with devices in the background). Also, all analysis, plotting, etc. is done with python. Essentially the whole workflow from measurement to publication.
You can't really do WebSockets in PHP. I think that's all. EDIT: That's assuming that you use classic Apache2+mod_php or nginx+php-fpm
try: httplib.HTTPConnection("vulnerable") (apache is probably configured to only reply to requests for that hosts) also, I find urlib2 much easier to work with (unless you're doing something more complicated): import urllib2 html = urllib2.urlopen('http://vulnerable/index.html').read() print html
Lost its mojo? No way! They're still actively working on it and more Tornado-using projects pop up every day. What seems to have died down a bit is some of the older Tornado-specific sites like Tornado gists and whatnot.
Or on Windows, get [AutoIT](http://www.autoitscript.com/site/autoit/) and drive it from Python using the COM interface. It's so hackish, it's almost a shame that it's this easy and fun.
the code you posted works thanks however your first suggestion still did not work. However I am trying to follow these rules write an HTTP client to retrieve the home page of your site using an http library (for example net/http in ruby is using urllib2 following these guidelines?
I used it for network scripts until I discovered expect. Still like python for learning programming.
I assume they're referring to some non-browser environment like nodejs which does have decent module loading for JavaScript (which, now that I think about it, is probably what you're referring to).
I think it depends on what you mean by http library, as urllib2 can open other protocols besides HTTP. what do you get when you use the code I wrote using httplib? **edit** here's your problem: conn.request("/GET", "index.html") it should be conn.request("GET", "/index.html") (the / should be before the index)
I am currently developing a platform from which to automate scientific experiments on low temperature cryostats. It takes into account instrument control, data collection, and visualization of results. (SOOOO happy to not be using labview for this. I absolutely despise labview for trying to generate modular experiments).
I tend to get this occasionally when I'm querying a database that lives somewhere far far away, which generally only happens when I'm testing something. To combat the problem, I wrote a small decorator which wraps a method and catches this error. When it catches the error, it waits for a few seconds and retries a specified number of times. I've ended up re-using that decorator dozens of times now, and it means never having to worry about this problem again. edit: I should add that this is only effective if you see the error sporadically when making reasonable queries. If you're seeing it consistently on a given query, you need to break up the query, which can also be done with a straightforward and reusable piece of code. If you want to see code for either of these, I'll post them here.
alright thanks for the help!
My most common use lately has been for text manipulation. Taking some big block of text that isn't formatted how I want, pasting it into a string in IDLE's REPL, and calling whatever combination of split, join, strip, and regex that puts the text into the format I want, then copy/pasting it back out.
I'm a sysadmin running a LAMP stack basically. We run webhosting for a university. I use python to do a lot of automation bits that would be clunky to do in Bash, and to automate large portions of our site deployment process.
Sorry for my late reply. I've looked into simulated annealing and I think it may be just the algorithm I need to get the job done. Thank you! 
I've been a Python user since late 2002. Some stuff I've done: 1. Unit tested a DLL on windows, since writing the C version of the test suite would have taken forever. I was a early user of Pyrex. 2. Wrote an XMLRPC-like (modifed version of XMLRPC spec) service that handled DNS changes for one of the largest websites on the internet (amazon, basically a precursor to Route 53). 3. A GUI app to perform a production test on some embedded hardware. (testing if the hardware works..) 4. Various web small services. 5. Many many utilities to help day to day programming tasks. Sometimes I'll write a quick C/C++ code generator in python, because it'll be easier than hand coding the C. I'm currently looking into a slew of product ideas using pyzmq. Network messaging made easy.
I agree. I don't know why so many people still use PHP when Python frameworks are an alternative and use code that is so much clearer. Maybe there's some advantage to PHP I don't understand?
What I meant with my analogy was if you can think logically you can program, but the language is not irrelevant. In two weeks you might learn a new language enough to write a non-trivial program, but you would be unlikely to learn most of the language idioms and idiosyncrasies. I've seen enough Python written by Java enterprise programmers and Lispers to know that this can make the difference between failure and success. If the OP's goal after 10 years of Java and VB is employment as a *Python* programmer, he should pay special attention to learning to write Python *Pythonically*.
It's really funny. Matplotlib and much of the sci-vis tools in the Python ecosystem are created by scientists and engineers. Matplotlib, for instance, is inspired by the Matlab defaults and appearance and whatnot, and for almost 10 years it's been very focused on producing publication-quality plots. However, the thing I hear all the time from R users is that the plotting in R is "so much better" than Python's. Or they straight out say that Python plotting sucks. And they all love the styling defaults from ggplot (which is what Seaborn's aesthetics are a copy of). Statistical plotting has its own set of quirks, and statisticians are an idiosyncratic bunch. Seaborn (and yhat's ggplot.py) are meant to placate them.
d3.js can also depend on a bunch of other stuff. Javascript is far worse about dependencies than the Python world, actually. I don't know about the scikit-learn dependency, but the dependencies on scipy, pandas, and numpy all make sense to me. You want to run stats on a few million points in pure JS? (d3 chokes around 10k-20k elements.)
&gt; The people behind Matplotlib need to read Edward Tufte, grammar of graphics, etc. All the components are there; you just need to make it extremely easy and intuitive for people to do things, at least the most common things. I've read both Tufte AND Grammar and Graphics and I find them both to be relatively useless for the very large numbers of use cases that people successfully apply Matplotlib to. GoG is totally fixated on statistical plots and the needs of statisticians. As an actual grammar, it's actually quite difficult to apply in practice. Are you using GoG via the Java package from the authors of the book, or are you using it via the ggplot2 R library, or via the ggplot.py clone? If the latter, you should note that the spelling of ggplot2 is *not* an integral aspect of the actual Grammar as presented by Wilkinson, and many R users complain about how *difficult* it is to learn how to use ggplot. During my research into this, I found that most of the tutorials and Stackoverflow answers told people to use qplot(), and there rest did extremely simple compositions of aesthetics and faceting. Furthermore, you cannot generate the wealth of examples as seen in http://matplotlib.org/gallery.html via ggplot, and there is no easy spelling via the GoG for many of these things. As for interactive graphics, like even the most basic examples in [Chaco](http://code.enthought.com/projects/chaco/gallery.php), there is no approach from the GoG or the statistical side of the world. As for Tufte.... psssh. Besides small multiples and sparklines, both of which are extremely situational techniques, what actual insight does he offer for information visualization? [Cleveland](http://www.stat.purdue.edu/~wsc/elements.html), [Robbins](http://www.amazon.com/Creating-Effective-Graphs-Naomi-Robbins/dp/0985911123), even Stephen Few have far more useful things to say in this area. Of course, nothing beats [Tukey](http://www.amazon.com/Exploratory-Data-Analysis-John-Tukey/dp/0201076160) and [Bertin](http://www.amazon.com/Semiology-Graphics-Diagrams-Networks-Maps/dp/1589482611). These are the books I get my collaborators on [Bokeh](http://bokeh.pydata.org) to read.
While not in the same spirit of Seaborn, Olgabot's [prettyplotlib](https://github.com/olgabot/prettyplotlib) is also worth mentioning, for those who want to dress up Matplotlib plots.
Here is a compilation of tutorial videos from the PyData conferences, on Vimeo: https://vimeo.com/channels/612789
give us output of `xxd tmp.png | head` ?
It's good to stick with the idioms of the language you're writing in. Sometimes those idioms are shared with Python, sometimes they aren't. The simplicity, explicitness, and general "readability is important" parts of Pythonic code you can and should definitely extend to any other language you write in, even if it's harder in certain cases.
I had talked to a grad student who highly recommended using SWIG for wrapping C++ function to python. Do you mind me asking what you use?
Who are you replying to? The first function was written by ghx454, it's from the original post. Kind of hard to tell though, since he put it all on the same line. And, if that's your only criticism of it you should read it more carefully (it doesn't work.)
You're reinventing TCP yourself. Just open two sockets and use TCP for the stuff that has to be reliable. 
Adding a Pandas dependency to matplotlib is a bad idea. Pandas is pre-1.0 and still has pretty inconsistent support for 3d and higher data, so it will be changing more rapidly than other core packages.
Text processing. Video transcripts, log data, etc. Business data analytics. Why python and not excel? Size of the data sets, easier to assure correctness, ease of use, IPython Notebook. Simple web apps using Flask or Bottle in front of tools to do the above. 
You should look into ipyton notebooks. Plotting doesn't have to be a separate step. You can even plot periodically as the data is being generated. If you're loading data into a spreadsheet to work with it you're only more efficient because that's what you have experience with.
[ØMQ](http://zeromq.org/)
 0000000: 8950 4e47 0d0d 0a1a 0d0a 0000 000d 4948 .PNG..........IH 0000010: 4452 0000 0320 0000 0258 0802 0000 0015 DR... ...X...... 0000020: 1415 2700 0000 0373 4249 5408 0808 dbe1 ..'....sBIT..... 0000030: 4fe0 0000 0009 7048 5973 0000 0ec4 0000 O.....pHYs...... 0000040: 0ec4 0195 2b0e 1b00 0020 0049 4441 5478 ....+.... .IDATx 0000050: 9cec dd79 981c 5779 2ffe b76b df7a df7b ...y..Wy/..k.z.{ 0000060: 7a16 cdae 19c9 b256 6bc1 962c db08 db60 z......Vk..,...` 0000070: 3bd8 8e4d 0063 2010 3b84 5ce0 925f 4242 ;..M.c .;.\.._BB 0000080: f290 b0df 1b2e 2117 0787 6030 2660 b85e ......!...`0&amp;`.^ 0000090: 3060 0b0b af92 17ed a35d 9a5d b3f5 74f7 0`.......].]..t.
It may just be simpler to send important messages over TCP, and everything else over UDP. Many applications do this. Your idea would indeed work, but you have to consider how exactly the server will store and retransmit packets that weren't received. I'd recommend just using one UDP channel and one TCP channel.
EVERYTHING!!!
I use it for metrics at my job, pulls from a sql dB, does some transformation and measurements then serves it up via cherrypy to management. Also for a ton of administrative tasks on my Linux server. Periodically cleaning up old files, monitoring the connectivity of a mapped drive and using api to pause a downloader. My first dip into game development was also pygame before switching to love as a prototyping language. All in all very versatile and fun language. 
&gt; Yes, Excel can ostensibly store data - but its not meant/designed to. Because most engineers don't use Access. I sure don't.
I use python for basically everything, at work and at home. At work, I use it for data analysis, data conversion, database maintenance, general maintenance, general scripts for everything from scraping data from webpages to writing small GUI apps to interact with the clipboard. I also use it for building web applications (using django and flask). At home I use it to automate various tasks from video games to media library maintenance, and plenty of other things. As for the Access/Excel thing.. Excel is quite limited on its data, and as others have pointed out is proprietary and not available on linux (though I could use Libreoffice, and I do for some tasks). Using python combined with mysql or even sqlite can be extremely powerful though. Way more than you could do with even Access.
working fine in 2.7 in 32-bit, having problems in 64-bit
Do people actually use `def main()` in Python code? I've never seen that before; usually it's `if __name__ == '__main__'` or a special `__main__.py` file.
This. TCP can get decently fast if you work on it, but trying to add a layer of reliability to a system that is unreliable *by design* will only earn you pain. Do it in TCP and tweak until it's fast enough, or refactor your system so that it can withstand UDP.
I do a lot of post processing at work and am forced to use VBA. I use access all the time to store or data because Excel is awful at it. I think you're right that most people don't use Access, but I think it's out of ignorance. Before I was forced to use Access because of my data size, I had always wondered what the program was. Saw the icon everyday. 
Haha, where do you find love letters to train it on?
Okay, so you're numbering each packet sent. But... - What if the packet is clipped and you don't get the number in the first place? - What if a bug or halt in the numbering code breaks the order? Yes, there will be bugs and halts in the numbering code. - You're sending the number-checking packets over UDP, aren't you? What happens when *those* packets get lost or clipped? 
Is there anything cool in the pipeline for JRuby?
[numpy + scipy + matplotlib + IPython for signal processing, instead of MATLAB.](http://www.embeddedrelated.com/showarticle/197.php) Add the [numba](http://numba.pydata.org/) library for CPU-intensive tasks that need speeding up by easy compilation to native code. [Python dot net](http://pythonnet.sourceforge.net/) for interfacing to a data acquisition card with libraries written in .NET. [PyTables](http://www.pytables.org/) for reading and writing to HDF5 files, because they take a fraction of the disk space of .csv or .xls files. [Jinja2](http://jinja.pocoo.org/) for templates; I had to do some automatic code generation recently. [enaml](https://github.com/nucleic/enaml) + [PySide](http://qt-project.org/wiki/PySide) for quick-n-easy GUI apps with data binding. Why Python? Because it's a nice language to use with a lot of libraries that are nice to use. In my youthful stupid days I used C++ and had to mess around with way too many frustrating distractions like "memory management" and "COM" and "MSDN documentation". And why use it instead of Excel? You have to ask? Because Excel is a big steaming piece of crap put together mostly for business people to analyze data. It's good for some interactive fiddling with spreadsheets, but I try not to use it for anything more complicated than that. When I got out of college in 1996 I used Excel for graphing data, and learned Visual Basic macros to create reusable scripts. And it was AWFUL. The object model was great for accessing cells/sheets/workbooks, but horrible for making good graphs. What kind of graphing software doesn't let you create multiple timeseries plots that actually line up with each other? After about 6 months, I swore I would never write Excel macros again. From what I gather, today's Excel is not much better. I can load data and graph it quickly with IPython, and I can do it exactly the way I want with Matplotlib. And once I get it the way I like, if I have 96 more data files, I can wrap my graphing functions in a 5-line script to run automatically.
Try [numba](http://numba.pydata.org/); it's easier. edit: there is one gotcha with numba. You're translating dynamic-typed Python code to a compiled function with static-typed arguments. The @autojit decorator infers the data types from the first function call, so if you have functions that take data of different types, you have to be a bit careful to handle type dispatching before you enter a compiled function, otherwise you get a type error.
[There's specific reasons why we aren't using TCP.](http://gafferongames.com/networking-for-game-programmers/udp-vs-tcp/)
just curious: what types of data acquisition cards are you using? I couldn't find one that had builtin python bindings.
It makes it more readable if everyone sticks to one (somewhat arbitrary) convention. Also it's often [more performant](https://wiki.python.org/moin/PythonSpeed). If you get the Pycharm IDE it will underline anything that doesn't conform to PEP8. I conform to the standard automatically now because I hate that stupid squiggly white line.
It would be nicer if they split it into 2 or 3 smaller volumes...
What Python implementation? I'd wager JRuby might be near the top of the pack in this regard, at least once you're JIT'd.
I should have mentioned my original goal in the post. I'll fix that. But yes, we are trying to make a client/server for a multiplayer game. But this is awesome! We've been looking for something like this! Thanks!
Duplicated http://www.reddit.com/r/Python/comments/1qgnte/dataset_databases_for_lazy_people/
I don't feel it's particularly awful to have to expect someone to install python to use a python application. The same is true for Java, Flash, and most other non-native frameworks. With this in mind, python works quite well for distributed apps. Myself, I use it as a generic all-in-one scripting program. I would use bash, but python is more powerful numerically and can call bash easily through subprocess or os.system, and it's faster for me to code in. I'm hardly a devout python user. Just yesterday I made a python script to generate FORTH programs, and I regularly write in C and C++ as well.
Thank you, I'll give this a shot. 
Sorry, this needs to run on a headless (no X11) server.
A quick google search shows that, AFAIK, selenium can itself be run 'headless' if configured. While I agree with vvhy, it'll probably be slower, at least it may be a viable option.
Oh god why is matplotlib so inconsistent in its interface? And this is *even worse*, if such a thing is possible! What the hell is this?! sns.set(style="darkgrid", context="talk") sns.boxplot(data) plt.title("Score ~ Category"); sns.axlabel("Category", "Score") Why do I have to use both sns and plt? Why can't it just wrap the "plt" methods? Plus this whole thing is all module-based instead of classes, which also boggles the mind. It may be one of the worst libraries I've ever used! That said, it does make pretty plots.. 
Duplicated *and* the original has a pretty good conversation about database systems, abstractions &amp; whatnot.
UTF-7 is the gift that keeps on giving.
&gt; (Excel is limited to 32k data points) Excel doesn't have that limit anymore. I've used Excel to do analysis on millions of rows. Excel is a great BI tool. It connects all of SQL Server's BI stack (obviously) and a lot of third party ones (as long as you have a connector and they stick to standards). 2010/2013 PowerPivot is extremely powerful. I personally wouldn't do any sort of statistical analysis using Excel like run models or test hypotheses (though there are some pretty good plugins for that), it's hard to deny the power of Excel. No spreadsheet program comes close. That all being said, I hate Excel.
&gt; And why does Py3k not have a `__contains__` magic method listed in the range pydoc? I feel like it is documented somewhere, because I definitely remember reading this at one point. 
haha So I was misunderstanding what I had in mind for how this would work, and I was making it way more complicated than I thought originally. Whoops. 
1. You can't reverse engineer algorithmic complexity from 4 running time data points. But Python is open source, so you could find out more directly. 2. 0x100 and 0x200 are both very small numbers, too small to be useful for achieving #1. 3. Fully populating a list that can trivially fit into memory would be expected to be faster with range() than with a generator. 4. Moreover, you're timing the lazy population of the list in one implemention but not the other. 5. Explain or show us in pseudocode how you're thinking the constant time list search works in Python 3.
I was just reading Jeff Knupp's book on idiomatic python today. Check it out for all the best tips 
TCP is more or less just UDP with a reliability layer. With real-time needs like multiplayer games, you usually reinvent only as much of the wheel as you need -- it's not going to be as reliable as TCP but it will probably be a whole lot faster.
You wouldn't happen to have any articles/tutorials etc on python and socket UDP and multiplayer networking would you? We're still new to programming and after making our game work awesomely with twisted over telnet as a text-based MUD we want to make it graphical and into more of an MMO. By the way, I too am an NLP enthusiast! Have always been infatuated by language and a way in which computers can process them.
Ya I def main a good amount and then use the if statement that you used. I'm not sure what is better or if there are any advantages to using one.
I think it's just a Python-specific idiom. No real disadvantage, just a different way of doing things. 
Might not be the best way... but it's what I do. I tend to write all the C code into shared libraries which I can then load into python and call directly. I'd write a "main" loop in pure python while all of the functions are written in C. I don't have to do it that often, so I haven't really looked into things that could be better. A lot of my background was working with MPI/OpenMP so this was the habit that I got into and never changed. I'll have to look into SWIG. I've heard of it but never used it.
I think you misunderstood. If you need certain high priority packets to have resend logic, use a TCP socket for those. For stuff that needs low latency but can tolerate drops, use a separate UDP socket. Add a sequence number to only pay attention to the most recent. Getting game networking to work well involves a sliding window and some prediction logic. You don't want to be doing everything synchronously, waiting for a packet before computing your response. You probably want a server that sends out the true game state periodically, but the clients update their own state based on speeds and so on, syncing to the server when the update is received.
browser = webdriver.PhantomJS()
sure I am. True: javascript doesn't have anything at the language level at the moment, though [its probably coming](http://wiki.ecmascript.org/doku.php?id=harmony:modules). However, almost every javascript platform has decent dependency management and/or a good module system baked in (node, narwhal, ringo, + a few others) or it is trivially easy to do even without an official module system (the browser). I think that an official module system is going to be one of the best improvements to ECMA script. However, in the context of browser environments (since thats the weak link) think about it this way: when was the last time you found a library you wanted to use and had any frustration simply making it available to use (quality of said library notwitstanding) ? But...this is /r/python, sooo......
Didn't realize there were so many like me doing data analysis and web development with Python. 
I may be in the minority with this opinion, but I think dependency management + module loading is trivially easy on pretty much every javascript platform including the browser. That said, node+npm is currently the best experience in that regard.
Two things. 1. WHen establishing the mysql connection in Python you can set a connection_timeout. 2. Your cursor may be timing out. In which case it means you need to quickly do an operation on a row or value from the mysql connector output. If you are doing too many things in that window, then you can lose your connection. 
[Here it is](http://docs.python.org/3/library/stdtypes.html#typesseq-range): &gt; Changed in version 3.2: Implement the Sequence ABC. Support slicing and negative indices. Test int objects for membership in constant time instead of iterating through all items.
To take it one step further, it's good to stick with the idioms of the project you're contributing to. Every project has warts and, even though it pains me to do so, I will CamelCase variables in python if I'm editing code where that convention is firmly in place.
Yep, I certainly agree. Consistency is extremely important. In cases where there are warts, if I find the warts obtrusive enough, I'll actually go back and convert all previous lines/names to the "better" way just so I can write new, clean code that's consistent with the rest of the project. I can get a little OCD with that at times, so I don't recommend that unless the warts are very severe and ugly, and if you're making a serious contribution or fork that'll involve a lot of code.
Tested on windows, this works pretty well.
Most languages follow those naming conventions for the most part, though Java uses camelCase for methods and variables, and C# uses PascalCase for methods and camelCase for variables. I'd recommend sticking with those if coding in those languages. Ruby shares Python's naming style, and Javascript seems to go either way.
I use Python to automate some boring things at work: parsing the files, interaction with database, plotting a lot of charts (instead of doing it manually in Excel) etc.
How do you suggest that happen without reimplementing some sort of reliability layer (a la TCP via UDP)?
The "What every programmer should know" article you linked above is one of my favorites, but you've already seen that. I'm not too familiar with Twisted, especially given the level of control that you need over the data sent, but if you're willing to get your hands dirty you could try out [socket programming](http://docs.python.org/2/library/socket.html). The best source for learning the details of sockets is [Beej's Guide](http://www.beej.us/guide/bgnet/output/html/multipage/index.html), but that's all in C++. What you're probably looking for is some sort of "reliable UDP". There are various implementations (I found [this Python one](https://github.com/noiseoverip/python-rudp/tree/master/Rudp), but haven't looked at the code) but you might need to write your own. If that's required you'll want to take a look at the features of TCP that are lacking from UDP and implement them (such as resending of lost packets), but only the ones you can't live without. You probably have the basics of networking in Python down, but I wrote a sample "game" some time ago while answering a similar question. You'll have to provide your own `sprite.png` and `bg.png` and install `pygame`, but after that you can run the server and then multiple clients. Each client will get a window and the arrow keys will move your character around on screen (the movement is synced across all clients). It's very crude, but it may give you a starting point. [Server](http://codepad.org/p9lVrmqn) [Client](http://codepad.org/e6pwGj24)
Using assert in the fix patch? Is that safe? assert can be compiled away right
The MIT Medialab Brill or Stanford POS taggers are much better.
The assert isn't the bugfix. The actual bug is fixed further down (line 3.15 in [this diff](http://hg.python.org/cpython/rev/7dde9c553f16)). Basically, when Python failed to decode a UTF-7 character, it was leaving the partially-decoded base64 value in the variable *base64buffer*, making the next value it decoded too large. The bugfix makes sure to reset the value to 0.
Important safety tip: do source cleanup before making changes. Do *not* give in to that "oh, I'll just fix this while I'm here" impulse. And run your tests after the cleanup to make sure you didn't mess up a scope (for instance). And write tests before messing with anything if the code doesn't have any.
why not just: [Number|Data] and check the check sum in every UDP packet to make sure its intact? The client doesn't need to receive every snapshot of the game world (every UDP packet).
Something's gone horribly wrong for you to see a difference like that. Perhaps massive packet loss. On a normal network that is functioning well the difference between UDP and TCP will be hard to measure.
There aren't really good reasons for UDP datagrams to be 'clipped'. They can be fragmented during transmission but the receiver should either get all of one or none of it.
Huh. I didn't find it with a quick search. Apologies.
+++++++++++ Very well stated. I might add that every programmer has a choice, he can make his code readable or not, the language isn't a big factor here. Python does seem to attract people that like readable code but that doesn't mean you have to give up readability on other platforms. &gt;It's good to stick with the idioms of the language you're writing in. Sometimes those idioms are shared with Python, sometimes they aren't. &gt;The simplicity, explicitness, and general "readability is important" parts of Pythonic code you can and should definitely extend to any other language you write in, even if it's harder in certain cases. 
I think the only thing from Python that I take over to other languages I work in, like Java or PHP is the 4-space indentation, and that only on projects where I am the lead developer and can set the style for the whole project. In PHP, I also tend to prefix functions considered "private" with an underscore. Doing stuff like that on projects that already have their own style is usually a bad idea, it will irritate your colleagues, make the whole code less readable in general and possibly also run counter to the whole culture/ecosystem of a language. (e.g. using snake case in Java code).
&gt;How do you make your non-python code more pythonic? I use python to generate program code for other languages. &gt;Is that even a good idea? Yes. It cuts down my programming time to about 10%. It wouldn't work well for every scenario, but for mine it's hard to imagine doing it another way.
Ive worked on a system that controlled a 9m satellite dish. Its been doing it since 1994ish and just recently decommissioned. Yes almost all of it was written in Python 1.something. Me, I use it for prototyping in realtime and mid sized embedded systems and lately for almost everything.
There are a few python alternatives : [Browshot](https://pypi.python.org/pypi/Browshot), [eagleeye_te](https://pypi.python.org/pypi/eagleeye_te), [django-url2png](https://pypi.python.org/pypi/django-url2png), [sharder](https://bitbucket.org/dholth/sharder), [django-thummer](https://pypi.python.org/pypi/django-thummer), [WeasyPrint](https://pypi.python.org/pypi/WeasyPrint), [wkhtmltopdf](https://pypi.python.org/pypi/wkhtmltopdf) and probably more (look for libraries like [ReportLab](https://pypi.python.org/pypi/reportlab) too) Browshot, WeasyPrint &amp; wkhtmltopdf seems to be the best choices.
Do you use any tools to do this? 
STM, if they pull it off, is going to be an awesome new capability for a python language powered interpreter.
That would be postgresql, I am not an expert but there was quite a consensus at europython (between competent people) that one should be using that instead over mysql. 
Well said. You win this thread.
Curious why you hate SQL. 
I work in animation / visual effects. We use python as the primary language for our pipeline. Our developers who work on the rendering side all use C++ though. Our pipeline uses python for building full fledged applications, toolset management, data analysis, batch processing, asset management, and production tracking. We use python because it is a very versatile and fast language. By fast I mean that we can knock out multi-platform utilities, UI's, and all sorts of things in single day and have them in the users hands. Getting feedback and making iterations can be done very quickly. Python is also integrated into may off-the-shelf commercial applications that we use as well so it makes it a no-brainer. I find that most of the news here in this sub-reddit is geared towards web-development / scientific-analysis which is cool but does not seem to really apply to any of the work I do :) As for excel, I do actually end up using it sometimes. Usually what happens in those cases is that I use python to build a CSV from processing a bunch of data and then use excel as a viewer for that information. &gt; but it looks to me like the concept of building applications with front-end GUIs that are packaged as executables is not Python's strength...? Am I mistaken? This is what I mainly do, minus the exectuable part, as we have python on all our desktops. I make lots of GUIs with wxPython and PyQt / PySide. Like I mentioned earlier, you don't see too much info on this sub-reddit relating to those topics, but I can say for sure that it is done and can be done it very-well.
I can't move to Py3 at work due to a large existing codebase which cannot be easily ported. Hell I can't even move to other python implementations :(.
[pexpect](http://pexpect.sourceforge.net/pexpect.html)?
Is it a PEP or a complete framework documentation? This page is overwhelming. Note that I like the idea behind tulip/asyncio but it's still quite a journey to go through that PEP. 
So this is one place where SQL Server's lack of utf support might actually be good?
I missed it the first time. This looks sooooo much easier than how I've done it in the past, thanks.
I migrated but it's been sort of a pain since I have to change/fix p2k code where I need to decode to string from bytes. Changing the print statements to function hasn't been too much trouble. Most prominent libraries for stats and data analysis have been ported over so that is why I migrated to py3k. I can see web devs not in a hurry though to migrate so it'll depend on who you ask.
We've looked around at various ones (PodSixNet, legume and others) but they either had really terrible documentation (legume) or we saw that it lagged a lot. This whole quest sparked because we had it working with PodSixNet where we had a very simple black screen and a client connected and populated a white square it could move. As soon as we had more than 2 client connected, even on local host, it would lag like crazy. That's when we discovered TCP is much slower than UDP and to not use it for multiplayer networking for games. PodSix runs on TCP. We would like to use legume but, I'll admit, we don't really understand how to use it, and we can't find any sort of "here's how to do anything with it." We looked at the examples it came with, which for PodSix that was enough, but legume isn't as clear about how it works. Then we came here and said screw it, we'll just learn sockets and do it ourselves.
Am I mistaken? Tkinter is simple and does a good job. 
Its also one of the first important steps to a no GIL interpreter that isn't running in another languages VM. Not that you can't work around the GIL, and its really not as big of a deal as people say, but I think it would still be a boon overall.
I've been using Python 3 since I started with the language, except when I didn't have time to try and bring an older module up to date. It's actually a bit jarring, now, going back to Python 2 (rather the opposite, I'd imagine, of the common state of things). Of course, now I'm working on a project where I have to use Python 2.6.6 with only the standard library available, so I'm getting a lot of practice in 'the old ways'...
I've been stuck on Python 2 for the past decade (or so) at a variety of businesses (planes, trains, automobiles, insurance, biometrics, big data, etc.) Here's my take: Python 3's feature upgrades don't outweigh the time lost in upgrading a legacy product. And in some cases, an upgrade to python 3 also means a major upgrade to the platform (e.g. moving from an older linux distro to a newer one). The business risk associated with a move like that is tremendous and would ultimately affect the bottom line. So unless Python 3 had a killer, must-have feature, there's simply no point in upgrading. Examples of killer features: 1. a library only available in python 3 that tremendously simplifies our code base (e.g. something that makes threading ridiculously easy) 2. a huge performance boost In our case, despite some of the headaches, python 2 is really the way to go. And whatever headaches we have encountered as a result of a deficiency of Python 2, we've already found a way around. 
&gt; common data analyses I think the problem is that everyone doing data analysis has their hands on a different part of the elephant. I'm curious to hear how you would define "common data analysis" plotting use cases, and to see what back-of-the-envelope percentages you'd put down on each of them. Most of the engineering disciplines have a core set of plotting needs that overlap, but virtually every single one has its own quirky domain-specific plot types (tertiary, Smith charts, vector streamlines). The physical sciences are similar but have greater divergence. Most of them frequently have special annotations and overlays to help them visualize complex 2x2D phase spaces. Statistical visualization generally has much smaller datasets with much greater dimensionality, and statistical data analysis requires much more interplay between reshaping (pivoting/group-by) and visualization. Furthermore, there tends to be a lot more direct plotting of models (e.g. statistical overlaying of loess, lm(), etc.), which is much more rare in physical sciences and engineering. MPL originated in the sciences and engineering, and I've heard many, many Python programmers in those areas singing its praises. Of course, any tool can grow in complexity and become too burdensome to use, and most open source tools could use improvement in this area. But for simple plots, the Pylab interface to matplotlib is pretty darn straightforward. For statistical plots, use pandas's built-in plotting or seaborn or ggplot.py - those interleave model with data and naturally handle faceting on dataframes. (And all three are built on top of the Matplotlib infrastructure, in actually a very straightforward way.) 
I am using Python 3 and the Scipy / Matplotlib / ipython stack for two years now. It's awesome! 
~~[Looks like it's the same thing](http://www.python.org/dev/peps/pep-3156/#status)~~ EDIT: misread
If you need it to be as fast as possible, it can't be reliable; you have to make a choice. 
It's a bizarre document in its current revision. They're discussing complex implementation details and then throw this paragraph into the mix like it's a beginner's document: &gt; Exceptions &gt; &gt; There are two categories of exceptions in Python: those that derive from the Exception class and those that derive from BaseException. Exceptions deriving from Exception will generally be caught and handled appropriately; for example, they will be passed through by Futures, and they will be logged and ignored when they occur in a callback. &gt; &gt; However, exceptions deriving only from BaseException are typically not caught, and will usually cause the program to terminate with a traceback. In some cases they are caught and re-raised. (Examples of this category include KeyboardInterrupt and SystemExit; it is usually unwise to treat these the same as most other exceptions.) &gt; With the only real mention of how they're being handled is by Futures, before even introducing futures. I'm super excited for asyncio, but yeah, quite an adventure at the moment.
asyncore is just for sockets. Tulip, aka asyncio, is for event loops with sockets, file descriptors, callbacks, subprocesses, signals, etc. More like Twisted (I think) or C libraries like libev, libevent, or the Glib event loop.
asyn*core*, not async*io*. (i didn’t downvote you btw)
Thanks for detailed answer. I do mostly web(django) and sadly even new projects are done is 2x because many of the web related libraries are yet to support 3x. 
Could you suggest any libraries you had in mind? We went with those two because they claimed they were specifically for creating networked games 
https://github.com/petezhut/ConfigReader
Web: I've built sites with Django before but have since moved to Node and Meteor. If I were to ever go back to Python for web, it would probably be with Tornado. AI: I made a genetic algorithm for finding optimal map points but my AI teacher apparently disagreed on how awesome it was. Presently my senior design team is using Python in an autonomous ground vehicle to manage and control the motor and sensors.
I don't get much of a chance to use Python at work so all my personal projects use Python 3. Asyncio is pretty fun.
I prefer something more Pythonic,and the syntax feels dated (not surprising that it's 40 years old).
Sadly not - Python doesn't seem to have a good selection of game-related networking libraries.
Primary work is in Django and Twisted so will not move to 3 until they do. Now that Django itself is supporting 3 I suspect (hope?) that more libraries will be providing 3 support as well. All our new code is using __future__ and stand-alone scripts all run with the -3 (Python 3 compatibility) switch, so we're setting the base for the eventual move. 
What are some simple use cases for this?
Good old ConfigObj: https://pypi.python.org/pypi/configobj/
I missed it too, so thanks!
when I don't have the option to choose, I cry and run away from cfg files otherwise I use JSON, because I can slurp the config data into python data structures in one line of code
https://config-resolver.readthedocs.org/en/latest/
This might be useful for some things, but let's be realistic about why people use CSV. It's supported by everything including command line tools, and you're unlikely to bork it badly enough that you can't recover. Everything built on top of a relational database is a leaky abstraction, where sooner or later you need to know a lot about the implementation. Use this thing carelessly and you're likely to see your strings truncated to 256 characters, or find that two fields that are different in the code refer to the same column.