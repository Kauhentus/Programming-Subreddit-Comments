Awww. Now that's mean. I agree that fighting over tabs vs spaces isn't useful, but it's nice to have a community standard. [Google's published Python style guide](https://google.github.io/styleguide/pyguide.html?showone=Indentation#Indentation) says 4 spaces per indent. I heard somewhere that they actually use 2 spaces and line length 78, but I can't find that source anymore.
see edit
The easiest way to do that in python is to use the "key" option of the sort (or sorted option). It helps you define on which part of your object you want to sort. In your case sorted(l, key=lambda el:el[1]) should work OK. 
I think it's weird how you nested two `if`-statements together… taking what *Nanaki13* said above I think you might be able to fix the error by encasing the part of the expression after the first `if` in some extra parentheses. if number &lt; 100000: return base[number/1000] + ( ('-Thousand-' + int_to_word(number % 1000) if (number % 1000 != 0) else '') ) However, I haven't run the code…
&gt; There should be one-- and preferably only one --obvious way to do it \- PEP 20, Zen of Python https://www.python.org/dev/peps/pep-0020/ See other posts here as to why the function works better. Adding a couple of parentheses is really worth it. 
Kind of like the regular blog posts about somebody discovering that `{}` is measurably faster than `dict()`, because the second one has to account for the possibility that some jackass put `dict = set` on the line above.
I think it would be possible to do it. obviously there would be hacks around specific individual tasks that maybe python cant compliment by itself but its definitely possible. Although, it would be much easier to try something like machine learning i.e neural networks to make a system like that instead of having different codebases working together...
Actually, it doesn't print a tuple .... print("hello") == print ("hello") == print "hello" if you wanted it to be a single element tuple you need to add the comma: print("hello",)
Your code should explain WHAT you are doing. Comments explain WHY you are doing it. Do not write comments that need to be changed if your code changes (like "append result to list").
Way overkill. When it's obvious enough what you're doing and why, no comments are needed. Especially when you use descriptive names for things. Comments are for clarifying intentions, explaining complicated bits of code (though it's better to simplify those), or warning about possible gotchas.
Ah, right. My mistake.
I am curious about the design behind this vs n, the tool for node js
'don't write comments that need to be changed if your code changes' I'll write that down. Thank you.
Why not pyenv virtualenv?
I mentioned this in the README file, but I never liked how pyenv required the creation of shims in order to run bins. virtualenv is also great for changing Pythons on a per-project basis, but I think it's heavyweight for just setting a default Python interpreter (I use Python a lot for running general-use scripts, outside of a project environment, and I'm pretty rigorous about keeping it updated and occasionally running scripts against other versions). This script is fairly simple; it only changes the value of `$PATH`. (Eventually, I also want it to create aliases for Python 3 installs, such as `python` is aliased to `python3`, but I haven't implemented that yet.)
That's usually done so that students learn what the code is doing since initially you won't have those skills developed much. Unfortunately it means that people later get in the habit of writing comments like that in real world code because it's all they've been exposed to. It's not their fault, it's literally how their professors taught them. However, the best comments really do explain why the code is the way it is not what it's doing line by line. Furthermore, code that needs lots of comments likely isn't understandable enough. Use descriptive variable names, break up long lines, extract small sections as simple methods with good names. In some people's opinions the best code is that which doesn't need comments at all because everything is clear just from the code itself. Another strategy you can try is writing all the comments first to explain the algorithm then filling in 1-5 lines of code after each comment. So you might have something like def send_newsletter(user): # verify user's email address # personalize email template with user data # connect to email service # send the email pass Now you have a rough draft to follow for the implementation, the blanks should be easy to fill in. If you find that you need more than about 5 lines for one comment then you can either introduce a new comment to explain the additional logic or move that block to a new method. Then, you can either leave the comments in or if you have a lot of lines that look like # send the email email.send() Then you can remove the comment since it doesn't add anything of value to the routine. These are pretty ideal conditions in my opinion, your code looks so simple that it doesn't need comments. 
Comments are useful for helping people (namely yourself) understand the intent of your code. I ask myself after writing a function or a particularly bulky line of code: * Is this easy to understand objectively? Can I rewrite this to be easier to understand? Prefer readability over cute syntactic tricks. * How is this function going to be used by others, or by myself in other areas of my code? Often intent is more interesting than implementation when it comes to comments.
You can email me and Ilan directly, and we'll get the thread going. Due to some of the interest in this thread and whatnot, we're looking into releasing some aspects of our work on this front, and would love to get your input.
with all that said it seems pretty obvious print should have been a function all along. So why was it implemented as a statement to start with?
&gt; You should poke him in the ballsack.
&gt; The maintainer refused and said that it needs to maintain compatibility with 2.1. https://www.youtube.com/watch?v=EYWbatgKN4g
Google does python like no one else. They strictly follow the 79/78 chars per line thing, but yeah they use two spaces because of how nested lines make the code difficult to write with 4 spaces. I use spaces, but PEP8 only insists on consistency.
There's a couple of things I would do differently- * Firstly, I didn't like those -1's around everywhere, they really confused me until I realised that they were just because list indices start at zero. So instead I just added a 'None' at the front of the lists so that base[1] = "One" * Another big difference is that I changed the recursive function to return a list of words, rather than a string text. This way, you can worry about glueing the words together at the end and you don't have to worry about the "zero" case until the end. * Finally, I broke the recursion up into how I think about the wording. e.g. 123,456 can be treated as "123" + "Thousand" + 456. Similarly 123,456,789 can be treated as "123" + "Million" + "456,789". The big advantage here is that you don't need so many predefined lists (and it makes more sense to me at least) * The only other difference is that since the recursive function returns a wordlist, we first need a seperate function that wraps around it to actually return text. It does two things- first it checks for the "Zero" case- the one and only time you ever need the "Zero" text. Second, it converts the output from a list of words into text while ignoring any "None"/"Zero" values. [My code here](http://pastebin.com/MeFRPHxJ)
It's easier to make Py3k code work in Python 2 than the other way around. Most issues are cosmetic changes. One tricky situation is if you've been reading data that you think is ASCII text but it's actually some other kind of data. In Python 2, ``str`` is really just bytes and ASCII happens to be a text encoding that maps 1-1 with bytes. If you want to make sure your Python 2 code works in Python 3, you should say ``text = s.decode('utf-8')`` everywhere you currently have a string ``s`` that assumes it is holding text data. Unfortunately, in many cases that will be a flawed assumption. For example, if you're dealing with terminal output you might have accidentally pulled in ANSI escape codes like ``'\x1b[30;1m'`` along with the actual text. The frequency of such mistakes is why Python 3 made the choice to enforce that text data must be decoded into Unicode.
I use i3wm and have a dmenu to select a "session", and a hotkey to open a terminal into the path of my project with the virtualenv set (with bash history from last time I used that session), and another to open ipython in that venv. Works great for me.
I try to comment my code considering myself as a "bus factor" of zero. I get hit by a bus, nobody knows what the fucking shit I was thinking when I was coding this stuff. Some short time from now, I shall be either dead or effectively an amnesiac. Should I still be alive to review my own code from some time ago, I promise you cold hard cash money that I shall not remember the details of what the fuck I coded. "Oh yea dude, this script does AWESOME SHIT PLUTO" would be the best I could sell you. No idea how I did it, or why, or how. I'm not kidding. So I comment my own code for my future dumb-fuck self. And for the some poor soul who stumbles across my shit and thinks it'd be nice to fork or something. The worst\\best I ever came across was a line of code where the comment read something like: "The following line of code Just Works. As a courtesy and lesson to those after you, please note here how much time you waisted trying to figure out and improve the following line of code." ... and there were multiple comment entries of "shame" which basically admitted "I tried to fix and understand this shit, I failed I wasted time and money and effort, I'm sorry, please do what we say and not as what we do, this is legit". 
There's a few things I would do. Firstly, your function name is not a verb, and is not typed in a different way from your variables. I would change to def getConfusionMatrix(target_list, predicted_list, binary_matrix=false, label=1): # Compute and return a matrix. Passed lists must be array-like Now, let' me look at what your comments tell me. They don't really tell me a lot (especially since I don't understand confusion matrices). Essentially you list the parameters and the defaults, but my function header does most of that (especially if you change the variable names), and the little comment below it explains the rest. 
I have inherited overall about 100k lines of Python split between a few projects. It amazes me how many people think every function needs a big decorated comment above it to tell me the name of the function (and nothing else). `# This is ftp_getfile` is not a comment that ever helped anyone do anything in the history of comments.
What arguments it takes is the easiest part. Give them descriptive names. Don't be afraid to make them longer than 12 characters. Usually from the name alone it should be reasonably clear what type they're expecting, and *really* good Python should be flexible enough to accept any incoming type that is reasonable for whatever purpose it's doing, for example a list of strings *or* a string, and if someone passes in an int it gets cast to a string. Or vice-versa. However the internal logic is supposed to work, treat the calling code like the customer is always right. If you can't say what the function does in one short sentence, then it's too complicated. The return type is 3 words, 4 tops. Telling me the name of your returned object is utterly useless. All that fancy formatting just means that an IDE is going to choke on the docstring, the code is now probably 200% the size it should be (I'm guessing the docstring is as long or longer than the function), and it didn't really tell me much more than what should be in the one line function declaration. I mean, it's called `confusion_matrix()` You don't need to *also* tell us that it computes a confusion matrix.
I agree on the concept but dislike the form. The camel-case isn't PEP8 compliant but the real problem is that this comment should be a docstring in order to be included in the function documentation and be easily available.
&gt; Do not write comments that need to be changed if your code changes Some of the best comments describe a confusing implementation.
If you have your variables more descriptive names than my_list, k, and i, then you wouldn't need those comments. A docstring is all that you'd need, although in this case you haven't really said what your function is doing aside from that you are demonstrating list append and iteration.
I'm a huge fan of doc strings for most functions but that's just because part of our build process is to compile sphinx docs into html and load them onto a nginx server for documentation purposes, but I feel your pain about inheriting functions just reiterating what the function title says in a doc string (I had to do disgusting amounts of filling in the doc strings details when coming on board with my current job, but it was totally worth it). Regardless, I'd say doc strings are overwhelmingly good, but only if used properly 
 1. The best comments are the ones that don't need to be written. Sometimes this is accomplished through other things in your code, like naming. For example, a `products = []` would go way further to making it clear what is going on than `my_list=[]#here we create a list where the multiplied values will be added to`. Other times it is accomplished through choosing simpler things. 2. Never leave a comment that just describes a language feature or how the thing that you're using works (unless it's particular tricky or weird). Someone shouldn't be told by your comments what `return` does, for instance, they should learn that from their favorite Python book. 3. Do comment things that you had to go back and change because you had a bug the first time. This shows that they were tricky. 4. Do comment your general thought process, especially in big code blocks. (Most of the time you should not have big code blocks, but sometimes it happens.) Note what the steps are that you had in your head when writing. 5. Do comment things that you had to think about, that you stopped and planned out. 6. Do comment optimizations put in place. Almost by definition, optimization makes your code less clear. If it was the clearest way you could think of, you would have written it that way the first time.
You should strive for no comments in your code, because that means you've made your code readable and understandable. The minute you put in a comment, it's already outdated. People make changes to code, not comments. Never trust the comments.
I like to follow advice from Robert Martin's *Clean Code* book: &gt; The proper use of comments is to compensate for our failure to express ourself in code. Comments are always failures. We must have them because we cannot always figure out how to express ourselves without them, but their use is not a cause for celebration. So when you find yourself in a position where you need to write a comment, think it through and see whether there isn’t some way to turn the tables and express yourself in code. &gt; The older a comment is, and the farther away it is from the code it describes, the more likely it is to be just plain wrong. The reason is simple. Programmers can’t realistically maintain them. &gt; Comments Do Not Make Up for Bad Code! One of the more common motivations for writing comments is bad code. We write a module and we know it is confusing and disorganized. We know it’s a mess. So we say to ourselves, “Ooh, I’d better comment that!” No! You’d better clean it! Clear and expressive code with few comments is far superior to cluttered and complex code with lots of comments. Rather than spend your time writing the comments that explain the mess you’ve made, spend it cleaning that mess. **Example:** Bad: // Check to see if the employee is eligible for full benefits if ((employee.flags &amp; HOURLY_FLAG) &amp;&amp; (employee.age &gt; 65)) Good: if (employee.isEligibleForFullBenefits()) 
Back in the day, Python didn't have a proper boolean type, so a lot of people would just write `True = 1` and `False = 0` at the top of their modules. (It's also conceivable that people had attributes named True and False.) Not wanting those to break, when a boolean type was introduced, the constants True and False were introduced as builtins, not keywords.
Thanks! Reading it now.
Sounds like an interesting project. pico2wave definitely sounds better than most of the options I'm familiar with (espeak, mbrola, festival). I would suggest starting a github project for this, so other can contribute code easily.
Cute, but even the super simple example doesn't work well. It offers pop, but not getitem, and so doesn't suggest a non destructive option.
I typically only comment if either: * The way I'm doing something is unusual or relies on some not-generally-known API or language feature, or * I'm explaining the source of some constant value (or similar), or * The code is highly dependent on some outside reference material, in which case I explain it in comments. For example, I have [a library which converts between the various CSS and HTML color formats](https://github.com/ubernostrum/webcolors), and part of it is an implementation of the HTML5 color parsing and serialization algorithms. Since those involve some kinda strange things, and the implementation only makes sense if you know what the specs say to do, I intersperse the description from the HTML5 spec as comments in the code.
&gt; Do not write comments that need to be changed if your code changes (like "append result to list"). Do write those comments if they help you. I write comments like that when I'm working with VTK objects or numpy sets. You'll stop writing them/remove them as time goes on. If code is super mathematically dense, and you want to explain in words because that helps you (set A - B), then by all means.
Docstring the type of the argument and the purpose of the function. If anything tricky happens within, note why (e.g. the data is ridiculous, we need to get x out of dictionary y.) I've gotten my inspiration from the boto library, it tells me what the type is, and why it's there (though, over time, it's maintenance has gotten sketchy, the core idea is there): def multiply_list(k): """ This is an example working with both the range() function and method list.append(). :type k: int :param k: This integer will be multiplied with each of a list of 1, 2, 3, 4, 5, 6, and return the results. :rtype: list of int :returns: a list of results of the multiplication. """ my_list=list() for i in range(1,6): multiple = k*i # Append the result of the calcuation to the list my_list.append(multiple) return my_list
[removed]
http://python-history.blogspot.ro/2013/11/story-of-none-true-false.html
[pyttsx](https://pypi.python.org/pypi/pyttsx) seems to be a cross platform option. Would that work as well?
&gt; I mean, it's called confusion_matrix() You don't need to also tell us that it computes a confusion matrix. Fair enough, that's probably not the best example :P. But does it hurt to have this extra sentence in there? :P 
sometimes I leave apologies in my code for the next person to come along. if im that next person, i continue the conversation, along the lines of "aw, it wasn't that bad, boo" or "jesus. what's wrong with you?"
This is why you use a capable text editor and take advantage of folding.
Good point.. Thanks!
Not trolling, but looking at the comments, I am not alone. There seems to be mixed options both ways. 
This. Finally, clean code is mentioned. I expected it to be the best/first answer when opening this post. 
I'm not sure - it was over 2 years ago when I started, so it was either not out yet or I was dumb and didn't find it.
One thing that helps me get comments on the page to tell me 'wtf was I thinking' is the sketch out a few notes as to what a function is supposed to be doing, and then fill in the space between them with code. It's not perfect, and leads to a ton of verbosity, but it lets me think out what I actual want a function to do before I start digging myself a hole.
When I come across that error, it's usually because of something the text editor did, such as a weird carriage return or other whitespace weirdness. Also, a helpful suggestion: using `eval` is pretty heavy-handed. You are trying to convert the string that results from `raw_input` into an integer. You can do that same thing by simply calling `int` or `float` instead of `eval`. Good luck!
For your old code, you can use 2to3 to convert it :)
OP: Using `map()` is a great way to improve this, but if you don't want to change the logic of your code (since that's not what you asked about), making the names as clear as possible will go a long way. def multiples_of(factor): multiples=[] for constant in range(1,6): multiple = constant * factor multiples.append(multiple) return multiples I realize that you used k because it's conventionally used for a constant factor, so that may be descriptive enough. An additional way to make the code self-documenting would be to check the type of the argument: if type(factor) is not 'int': raise TypeError
That's right, thanks. Swype does this a lot to me.
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
I really enjoy software engineering tools for python. 
&gt;Some of the best comments describe a confusing implementation. Which is why comments should explain the WHY, while the code explains the WHAT.
Sometimes it's nice to say WHAT you are doing in the form of blocking sections. Like, if a 20 line method has 3 main parts, I'll label them with one-line comments 
is there ever going to be a practical difference (other than weird overriding of eq)? also `a.is_(None)` is just wrong
What are your favorites?
did you mean to see "much more" instead of much less?
Hey ShortSynapse, I tried your first suggestion last night but I could not get it to work. i'll give this version a go instead. I did get it working using something like the following. //index.html &lt;html&gt; &lt;a href="/cgi-bin/light_on.py" &gt;&lt;img src="image1.jpg"&gt;&lt;/a&gt; &lt;a href="/cgi-bin/light_on.py" &gt;&lt;img src="image1.jpg"&gt;&lt;/a&gt; &lt;/html&gt; and then my .py file within the cgi-bin is something like(sorry I'm at work). import cgi, cgitb, subprocess subprocess.call('./milight 0 ON', shell=True) print "Content-type:text/html\r\n\r\n" print '&lt;html&gt;' print '&lt;head&gt;' print '&lt;meta http-equiv="refresh" content="0; url=http://192.168.0.36/" /&gt;' print '&lt;/head&gt;' print '&lt;body&gt;' print '&lt;/body&gt;' print '&lt;/html&gt;' So you can see the script gets called and then the user is redirected back again. This works great apart from one thing. you see the page reload which is something I don't want it to do. Eventually I want it to return to html that will display the output in the main part of the window(menu on the left) but I'm not there yet.
The only applications are already provided by: * shell variables ($HOME etc) * OS apis to get special dirs (for packaging etc) * cross-platform toolkit abstractions of such apis (QT etc) Basically, you have reinvented filesystem aliases in pure python. These only make sense if they are standards. It would be more productive to actually build more extensive support for OS abstractions; the stdlib only gives you expanduser('~'), but it would be useful to have some sort of app-specific datadir and installdir, which both OSX and Windows provide fairly consistently with APIs and *nix with freedesktop conventions (.local etc). Today you get that sort of feature with mega-toolkits like Qt, afaik, but it would be useful to have it in a smaller package (if not baked in stdlib). 
&gt; My point is that pypi numbers are not a good proxy. Your point is clear, now all you need is some arguments to prove it.
I guess something like clever bot would be a good idea. I was thinking, absolute basics could be: I submit something like: if input == "Hello": print "Hey, how you doing?" But then someone else might submit: if input == "Hello": print "Hi" The AI would then have two possible answers to the same input and it could maybe rotate through them. of if mood parameters we given then maybe a different mood would output different responses. If users were to enter responses to different output then it would build up quite the brain to interact with. However the learning part could be that if a user then response with something like "I don't understand" or something similar then the response originally given would be flagged for review or less likely to be used again. 
Debian supposedly wrote a huge policy around this problem... And I never actualy understood how it's supposed to work. Luckily virtualenv made it all irrelevant for basic needs.
This is more like a chatbot than an AI, and there are already a lot of those.
Have you looked at Anaconda and Conda environments? It's more robust than virtualenv for a wide variety of Python packages, and the conda package format supports other languages (C++, R, Javascript, Scala, etc.). http://conda.pydata.org/docs/
Right on, good point.
If the implementation is confusing because it is doing unusual things for obscure reasons, then by all means comment it and explain why. That sort of thing shouldn't have to change unless you're actually changing the entire implementation so that it no longer needs to do unusual things. However if the implementation is confusing because the code itself is unusual or obscure, then that's not a scenario where you need to comment it. In that situation you need to refactor your code so it's no longer confusing. Python code is essentially self-documenting if you don't go out of your way to mangle it. But it is our responsibility to take advantage of that by making the effort to avoid confusing code.
Actually, the specific case of `while 1:` is optimised so there's no boolean check at all. The same occurs in Python 3 with 'while True:`.
These things are so 2005. There are better solutions available. All of these things, regardless of the language have one thing in common, they don't work properly. Use lxc,lxd or docker. That way you will have exactly one version of python,node,ruby, etc in that container. Lxd,lxc and docker use kernal namespaces so there is no overhead of an emulator. They run at native speed. As a bonus, you can make a custom dockerfile for eack project or what ever lxc/lxd uses and it makes deployment a snap. So if you are developing on Ubuntu but your server is using RH, no problem as long as docker is installed. 
If you are doing juypter notebook stuff, there are many docker containers available. I customized the dockerfiles for my own use. So have different images for python2.X, python3.X etc. If you want to try out python 3.5, it is a snap to install in a docker container. There is a bit of a learning curve for docker, but it will save tons of time in the long-run. The next laptop I get, I will install on it nothing else besides an xdesktop of some sort and docker. You can run x applications from within docker containers. So want to have different versions of web browsers installed ? Install each different version in a different docker. No problem with conflicts, makes testing a snap 😊
&gt; is there ever going to be a practical difference Yes: When you start programming Python with others, you will read and write code that other people have made decisions about. SQLBuilder for example overrides operators for the purposes of query building, so `==` has a different meaning when the left argument is an SQLObject. Practically understanding the semantic (intended) difference between *structural value equality* and *object identity equality* will be important if you want to avoid pissing off other programmers who have to work with you. This
If numbers after "M" are really important to you, MicroPython runs on Cortex-M0 chips, e.g. nRF51822 as used in bbc:microbit http://ntoll.org/article/story-micropython-on-microbit
Nouns are fine for math related things. `average(centre(circle), centre(square))`, for instance.
That's fun. It's like [hoogle](https://www.haskell.org/hoogle/)'s type-based search except horrible. 
are there collaborative python ones though?
I would imagine this to be the case. I think the general rule is no breaking backwards compatibility, even on unintentional behaviours that are not clearly bugs. A big version bump like to Python 3 is meant to go and clean up all the things you wish you could if everyone would just politely update their code all at once!
There's obviously some overkill because it's an example, some comments independent of that: #this is an example working with both range function and lists function 'append' ## Formating: why is the blank line above there? ## Pedantic: use proper capitalisation and punctuation where relevant. ## Taste: separate `#` from the start of comment with a space. #insert an integer, this will be your multiplier ## Phrasing is weird, consider instead a `parameters` section. def multiply_list(k): ## The name of the function is not well chosen: there's no list being multiplied... You're not mentioning that you're multiplying the list 1..6 anywhere in the function name or comment. my_list=[]#here we create a list where the multiplied values will be added to ## ... also have a space BEFORE the `#` to separate from preceeding code. And this comment is too verbose even for an example :) consider instead naming the variable `multiples`. for i in range(1,6): #here we create a variable 'multiple' which multiplies every value in range of 1 to 5 with input integer ## 'here we' is too chatty, what other location in the code could this comment possibly be referring to? The comment is missing the relevant information: it's a temporary variable with scope limited to the loop. The variable is not multiplying anything, it's being assigned the result of the multiplication. multiple = k*i # like so, we append the result to a list ## `like so` is unnecessary clutter my_list.append(multiple) return my_list # Here we call back the list ## "here we" see above ; you're not 'calling back' the list, you're returning it ; prbly too chatty even for an example :)
use .format() instead of modulus string interpolation. print """ this is a load of textz: {} {} """.format(some_string, some_int)
Comments inside methods are rarely useful, only if you're doing something extremely odd and want to explain why. Commenting the entire method on the other hand is a good thing, but only explain *what* the method does (as in, what do the parameters mean and what will be returned), not *how* it does it.
very possibly! I'm hosting a website that is powered by python using scripts that are stored in the cgi-bin. for example: import cgi, cgitb first_name = "John" last_name = "smith" print "Content-type:text/html\r\n\r\n" print "&lt;html&gt;" print "&lt;head&gt;" print "&lt;title&gt;Hello&lt;/title&gt;" print "&lt;/head&gt;" print "&lt;body&gt;" print "&lt;h2&gt;Hello %s %s&lt;/h2&gt;" % (first_name, last_name) print "&lt;/body&gt;" print "&lt;/html&gt;" So all I'm simply trying to do is do away with all the print statements at the beginning of each line. Now, I know I could use django or flask or web2py. I've looked into them are they are far too powerful for what I want to do. Do you have a suggestion to improve what I'm doing?
I love you! can I say that?
Try http://www.codeskulptor.org There are a few other in-browser interpreters out there too.
A little outside my realm of experience (I'm a hobbyist at this stage really). jrwren's answer seems like a great simple solution. Maybe look into pprint and BeautifulSoup if you need further functionality :)
I thought BeautifulSoup was for web scraping? I might be wrong though! not heard of pprint. i'll look into it!
ooooh, shiny! me likey!!
Horrible it is.
This is one of the most irritating things about Python IMHO. Not that I have a good alternative...
Seems to me that a basic templating engine is what you need. `format()` is good for simple tasks.. If you need more complicated templating than that, for example looping over a bunch of items and generating html for each, then something like Jinja2 is probably closer to the mark.
Oh, you and your fancy pants level 48. Mines only a level 13 Aasimar Dragon disciple. How's it looking being a god? Pretty windy I'd say! 
Doesn't Codeacademy also only teach Python2?
The last example should rather be: if not isinstance(factor, int): raise TypeError("maybe some helpful error message") Though in Python duck typing is commonly preferred to explicit type checking.
Thanks, I thought I might have had something off there. Looks much better. 
Line length conventions are not any more based on the screen size, it is pure for reading convenience. And if the code can be read better, it is less prone to bugs. I agree that 79 is not a hard limit anymore, but it is still a good advice! Problem here is using tabs which results in 8 spaces. So on the given line, there are already 32 spaces wasted. Solution, use space delimiters with a sensible size (4 or 2).
Yes, you can. I welcome it. :]
And that's bad advice since it omits one of the most important and established reasons for comments: your code won't express *why* you're doing something or not doing something. Nor does it acknowledge other considerations that won't be expressed within your code. The other day I wrote a cryptographic function that deviated from a common example for that library. Because the library as published had a typo in it - and didn't work. I had to explain multiple times exactly why there's a difference. There's a comment there now.
Speaking from experience, it's the nicest font I've come across for coding in Vim.
Python3 for sure. I've been teaching myself Python3 for about three months and its been great. Its not terrible trying to port something over to Python2 for legacy apps and vice/versa. As far as a book I really enjoy Automate The Boring Stuff With Python. Great book by a great author.
Just of the top of my head: Take the string, compare the first and last characters with `startswith()` and `endswith()` methods, if they are the same remove them. Repeat until you are left with one character or no characters at all. 
Look, it's Ypur. A hive of scum and villany. All sorts of adventures can be had there. ::consults random encounter table:: Oh. Nope, just sexual ones. 
&gt; Are there any reasons not to just use 3? Sometimes you want to use a library that hasn't been ported fully to Python 3, such as wxPython for making GUI applications. You may prefer Python 2's minor differences relative to 3. Some books you like may refer to 2. You may enjoy feeling "old school". For your purposes, my guess is it doesn't matter very much which you use, and they are not that much different anyway. 
Well, you can't actually remove them since strings are immutable in python, but you can generate a new string without the first and last characters with `replace()` For example: def isPalindrome(mystr): if len(mystr) == 1 or len(mystr) == 0: return True firstChar = mystr[0] if mystr.endswith(firstChar): isPalindrome(mystr.replace(firstChar, "")) else: return False There may be a couple of errors though because I haven't run it, but it should drive my point home. Oh and if there are going to be spaces in `mystr` like "race car", simply remove them, `replace()` should work.
 S to the P to the aghetti SPAGHETTI!
This seems pretty contrived to not be able to use reversed or otherwise. My solution would be to check if they have equal length then use a for loop over range of len, comparing the characters at index i and and len-1-i.
Wrote a data analysis and model regression software with PyQt for the GUI on dektop. Rapid development and the variety of packages/libraries made it easy to work with, both for development of new features and fixing bugs. Not to toot my own horn, but it's also the most powerful regression engine I've encountered. Definitely possible to construct professional-looking, high-quality applications in Python. I don't know about selling those applications necessarily (licensing is always a headache), but it's very easy to build excellent internal tools for use within your company.
Don't want to criticize here, but I think "GitHub stars" is really not a best metric for talking about "Top X Devs". The awesome-python repo is really, really cool, and please don't get me wrong if I use it for the sake of this example. I'd say that awesome-python it's not a coding project, it's just a list of links and resources. These collections get a lot of stars very easily (e.g., 18,200 in case of awesome-python). Now, compare that to really huge efforts such as NumPy(~ 2000 stars) matplotlib (~2,600 stars) or scikit-learn (~9,700 stars). I think we need a different metric since everyone of the core contributors (full disclosure: I am not one of them) there deserves a bit of credit here as well :).
Python 2.7 will be supported till 2019, mainly for businesses that have yet to make the switch. The future (technically present, is been over 8 years since the shift) is Python 3.
There's an official standard for this: ISO 639. A quick search of PyPI yields [pycountry](https://pypi.python.org/pypi/pycountry/) as being your best bet. Disclaimer: I've never used it and there isn't a repo link provided, but you can always download the archive and inspect it for yourself.
This list is definitely broken and needs some fixing to make sense. E.g., I don't see Wes McKinney on the list, who is the creator of pandas (&gt; 5000 stars) or O. Grisel who's a core contributor to scikit-learn and joblib. These are all very popular libraries; I assume that the approach used here doesn't capture them because pandas is now part of the pydata organization? Sorry, but using GitHub's search function to just look for repo's directly listed to someone's account is not the way to go. This is quick &amp; dirty and not fair towards people who put so much great effort into open-source Python tools. If we really need such a list, we would need a substantially different metric that also captures the contributions to python projects on Github in general (not only the ones in the person's repo account).
I'm trying it out in ST3 and it is pretty great. i like the dotted `0`, it's nicer than the liberation one.
Of course it works. `%` is an operator of `str`. Both single and triple quotes create strings, so it works. This is like asking if `0x2 + 2` works the same as `2 + 2`
My point was that if you just ask somebody on the internet to give you the answer to your homework problem, then you're not really learning Python. If somebody translates a sentence like "My mom baked a pie" into Italian for you, it doesn't mean you've learned Italian. You've skipped the step of learning the basic vocabulary and structure of the language. It seems like you may also have skipped the an even more important step, which is learning how to find the answer to simple questions by reading the primary language reference manual. The class may be for learning Python and Computer Science, but if you don't do the homework yourself, even if you manage to pass the class and get a good grade, you have taken a shortcut past the actual learning part, and missed the opportunity to really learn whatever the class has to offer. 
Thank you!
Well, to be sure you have all of them you can also for example scrape webpage [http://www.loc.gov/standards/iso639-2/php/code_list.php](http://www.loc.gov/standards/iso639-2/php/code_list.php). But someone probably already did that...
What you actually want is to create a vertical bar chart with labels on the x axis. Check out the matplotlib gallery for examples. 
Not a bad start, lots of *very* Windows specific code in there though. You should be able to write this program in a way that it would run on both Windows and Linux, without needing all the `win32api` code.
You should change the title from "Top Devs" to "Most popular devs"
To be clear, there are asynch libs for 3, right? Things like the reactor pattern and similar will be important to me. 
&gt; matplotlib gallery ty so much, I found what I wanted!
Or simply and honestly "Devs with the highest number of stars in Python repositories"
 lines = open('input_file.txt').read().splitlines() lines[10] = 'new line 11' lines[14] = 'new line 15' open('output_file.txt','w').write('\n'.join(lines)) Edit: changed 'split' to 'splitlines' (thanks, centurion236) 
I am not a developer, but I would do something like this. * I'd use an offline tts engine. http://askubuntu.com/questions/501910/how-to-text-to-speech-output-using-command-line * Have a Flask project in which the page will have a listener for every keystroke and the page would be a huge textarea HTML element. If the user pressed any key, it would automatically be added to the textarea, if he pressed F1 it would repeat the last world, and F5 would say it all and F9 would clear the contents of the textarea. 
Look closely at how you are handling the '\^dd' instruction. Are you sure you're passing the correct arguments to the dd function?
No, worries, and I saw that comment :). However, I still think that such lists (particularly this one, sry :P) are never fair. Just wondering, do we really need such Top X lists? Isn't it better to acknowledge people for their quality of work rather than putting a number behind it? &gt; Do you have a suggestion? Unfortunately not (for the reason I mentioned above). One could think that the number of commits to Python projects would be a better metric. However, then you have the problem that some people "commit" more than others given the same amount of work (e.g., on scikit-learn, the commits are typically squashed before a branch is merged for clarity). Another idea would then be the lines of code contributed. Here, the problem is that e.g., that you would have to distinguish between "comments" or documentation and actual code. I think the closest think that could be somewhat fair would be to really isolate code lines from documentation strings, and then count the number of times the line of code was executed by any user world-wide (excluding continuous integration build systems) -- but how to get that data? :P
Go here instead: https://www.reddit.com/r/learnpython/ Read a bit there before posting your question.
command = get + line + snmp + "\n" Please note that the format of the command should be: snmpget -v1 -c &lt;community string&gt; &lt;oid&gt; &lt;target&gt; or snmpget -v2c -c &lt;community string&gt; &lt;oid&gt; &lt;target&gt; i.e., snmpget -v1 -c snmp .1.OID 10.0.0.1 
Yes. The async problem has been solved in both python 2 and python 3, they're just not compatible with each other. There's a new library called 'asyncio' which utilizes a new keyword of the language called 'yield from'. But because it uses a new keyword, it is currently impossible to back-port that code to python 2. There would need to be an update to the python 2 interpreter to add the new keyword and then any extra work to make the library python 2 friendly.
I tried to figure out oauth to Jira but its complicated. But I think that we before v.2. I though it wasn't that secure? 
It's the font assets as well as the source code to build the output files containing the font. The majority of the latter is in this python script: https://github.com/adobe-fonts/source-code-pro/blob/b2ffdccd53fb380e6d5784b7d790c22207b82965/addSVGtable.py
 def foo(bar, baz): return bar + baz Pretty clear that when you call `foo(1, 2)` this implements addition. But how about `foo('a', 'b')` - is your code prepared to deal with the resulting concatenation? And what about the exception resulting from `foo(1, 'b')`? In a statically typed language, the compiler or interpreter would catch this for you ahead of time. In a dynamically typed language, you don't find out until you actually encounter the line at runtime.
The main problem is that you can't check TypeErrors at compile time. Python is strongly typed, so you normally can't implicitly convert types in a program, which is a great source of errors in some other dynamic languages like JavaScript. But with statically typed languages like Java or Haskell the compiler checks at compile time that the passed values/variables are of the right type and throws an error if not, and that for every part of the code. With dynamic languages like Python you have to actually run the code to catch errors, and the larger the codebase, the more likely it is that your buggy code can remain undetected for quite a while. That's why you should make use of extensive testing in dynamic languages, to run every part of your code at least once and test it for errors. By now Python 3.5 incorporates type hinting via [PEP 484](https://www.python.org/dev/peps/pep-0484/), which allows static type checkers like [mypy](http://www.mypy-lang.org/) to be incorporated into the build process, allowing type checking like in statically typed languages.
That's awesome, keep up the neat work 
I also think that stars don't reflect current community attention; it's a lagging indicator.
Why don't you show us *your* code. Honestly, what kind of help do you expect people on the internet to give? Chances are you missed an indent or are using your comparative operators improperly, but it would make more sense if you just pasted the code.
Two weeks ago at work, I ran into a bug where a certain command-line option wasn't working. It was supposed to take a list of machines, such as `--mlist server1,server2`, but whatever I did, it printed a message saying none of the listed machines were recognized and it was ignoring the option. After debugging a bit, I found that there was a function that was supposed to parse out that string `"server1,server2"` into a list like `["server1", "server2"]`, but the author of the code had forgotten to actually call that function (despite writing it). So when the code looped over the "list" of machines, it actually looped over the characters in the string, `"s"`, `"e"`, `"r"`, `"v"`, etc. And of course none of those single-letter strings were names of any machines we have! In a language like Java, the programmer would have attempted to assign the `String` to some sort of `List&lt;String&gt;`, and Java would have said, hey wait, those aren't the same thing, I can't let you do that assignment. And that would have been caught at compile time. (It turns out that, since this particular Python program was a replacement for an older C++ program, nobody before me had actually tried to use the `--mlist` option. So the mistake went completely unnoticed until I urgently needed it to debug a server-specific problem with the Python code and couldn't figure out why it wasn't working.)
Well, it's a step in the right direction. The big problem is that it's completley *optional*, so it might as well not even be there. I don't know of any libraries that are making use of the technology, and I've never worked on any projects that made use of it. Maybe in 5 years or so, when best practices about it could be developed, these tools might see some mainstream use. I'm not holding my breath, though.
PyCharm community edition is deliberately crippled to not work as well with Django as it could (or as well as pyDev does and it is open source community driven ). It is also neither lightweight nor simple, so you have to learn the editor as you learn how to code. I don't like recommending proprietary software to students of the language, like pyCharm or sublime. Especially, when there are true open source alternatives that are arguably just as good. When someone knows the language and can make a good choice of whether they need a property tool, then look at that. Most python coders, I know don't use an IDE. Starting out: any easy to use, open source, fairly minimal, text editor with syntax highlighting (for example notepad++, textmate, jedit, gedit, kate or my current favorite /r/Textadept/) makes more sense. Unless your class is being taught with an IDE, then use that IDE.
pm me once you do
&gt; you're not going to want to fire up a container every time you run a quick script. I do this all the time, it takes about 1 second longer for the command to start. So lets say I wanted a python3.5 script. I just do **docker -it my-python-3.5-image &lt;path to my python 3.5 script&gt;** Docker images/containers also work like git. They only save the changes between each image and container. And you can inherit off other containers. 
Glad that works for you. I don't see why that's better than using a local installation of Python to run scripts, but if it works for you, excellent.
I'm sorry I haven't looked at your link yet, but thank you for giving your reasoning for doing this. Honestly I don't even care what it looks like, you're OK in my book. Keep it up. 
If your Python is via an Anaconda Python installation, you're golden and likely already have the Jupyter Notebook installed. If your Python is from python.org, the road is long and winding.
I think lists are helpful, although you do highlight the caveat inherent in them. I might not have done a good job trying to discuss the limitations in the readme. &gt;I think the closest think that could be somewhat fair would be to really isolate code lines from documentation strings, and then count the number of times the line of code was executed by any user world-wide (excluding continuous integration build systems) I also might not have picked the right metric :) Personally I felt the "top data scientists" link referenced in the readme was a good resource. Despite the list's flaws I learned much from it about the data science community (including your contributions). 
Sorry if I sounded a bit grumpy, I think you did this in good faith, and I appreciate all effort in creating and sharing resources -- that's what makes the Python community so great :). Maybe, the term "Devs" is a bit unfortunate since it is not true for every repo that counts towards the stars metric (code projects vs. Python resource repos). I am not sure if there's a better term, but what about something like "[Most Popular] Python Contributors on GitHub" Another suggestion to enhance the lists a bit: What about a listing like - &lt;Name&gt; &lt;Stars&gt; (most popular repository: &lt;repo&gt;) Instead of just - &lt;Name&gt; &lt;Stars&gt; 
Responding to edit- yes. You have defined a closure, a fancy name for a function that includes variables from its outer scope
Twisted supports Python 3 now. Use Python 3!
Jupyter installs easily from PyPI on Windows. It's numpy, scipy, and the rest of the scientific python stack that might give you trouble. That said, they're not even bad thanks to [Christoph Gohlke's compiled packages](http://www.lfd.uci.edu/~gohlke/pythonlibs/) which are wheels that can just be pip installed.
Your larger point is fine — namely, that type errors won't be detected until runtime. However, `foo` isn't a great example. Perhaps its author really means it to do just what overloaded `+` does, for whatever perverse reason. Quite rightly, neither call will give an error. However, `foo(0, 'bar')` will blow up, just as `0 + 'bar'` would. (It's acceptable in JavaScript, though ;) as `0` will be coerced to a string, and the result will be "0bar".)
&gt;Python 2.7 will be supported till 2019, mainly for businesses OP should therefore ignore it totally. 
Please, can we avoid blindly suggesting non-blocking technologies without specifying that they require you to basically rewrite the app from the ground up ? The python world is already full of people deploying blocking apps on non-blocking servers without knowing they are blocking way more than before... Btw 1000 threads for a network server is not so silly... (you can find way more threads in java/.net stacks)
Are you suggesting that we should never have any breakage in the language? The only thing in the list that comes close is Java, and it's often a major sore spot how much crap gets carried forward in each release. I think the last thing the community should be trying to accommodate anyways is a "copy paste" "programmer".
This is by far the largest reason. PyPy only supports CFFI modules for interfacing with the outside world, and a lot of major packages like matplotlib are CPython API, which is *fundamentally incompatible* with PyPy.
of course!!
Can you paste the non-working code in pastebin along with the error/traceback?
tried that... didn't work :( I had to install dos2unix first though.
I have done extensive searching and tried everything that's been suggested. That's why I've asked on here as I was thinking it might be a python specific problem. i.e. must have import makeThisWork at the top!
Couple of mistakes that I usually do: * Make sure you don't have an old *.pyc files (just remove all *.pyc) * Make sure you don't name the file as a module you are using, i.e. if you have "import json" make sure you don't name your file json.py I hope this help.
Hiya, I'm the maintainer of Weir. I haven't discontinued work on it, or the backup system built on it ([Sluice](https://bitbucket.org/stevedrake/sluice)), but I got them to a point where they do most of what I need and haven't found time to work on them lately - I have the slightly more pressing concern of finding a new job! I haven't seen (or instigated) much in the way of discussion but I'd be glad to answer any questions and respond to issues and pull requests on [bitbucket](https://bitbucket.org/stevedrake/weir). A few notes: * Not all zfs commands are supported, but if you need some that are missing it shouldn't be too hard to add them. * The current API represents datasets as objects with methods that call zfs commands, which was probably a bit naive. Before v1.0 I'll likely change it to a set of functions that take the dataset as the first argument, more like the libzfs C API and various other file system APIs. * You can execute remote zfs commands directly with Weir. It might be nice to add a Paramiko backend for this at some point, but for now it just shells out to ssh. To create a new home directory from your admin server you could do something like: from weir import zfs zfs.create('zfs://foo.example.com/pool/homes/newuser') 
"static typing errors" -- ya, an edit gone wrong. I changed. Anyway, it's also why there is type hinting in Py3.5.
I understand what you mean. Thanks.
Can you cook me some eggs, or is this the wrong place to ask?
depends, are you cooking them in python?
Advertisement, don't bother.
Stop recommending the swiss army knife every time you see a person unable to use a toothpick
[removed]
Thanks! It definitely looks like we were thinking a lot of the same things. I really like the use of types in function annotations. Have you looked into the [typing](https://docs.python.org/3/library/typing.html) module that was introduced in 3.5? I noticed you're doing extra work for Python 2 to replace `inspect.signature`. Were you aware of [funcsigs](https://pypi.python.org/pypi/funcsigs)? If you're willing to add it as a dependency for 2.x you can avoid that whole mess.
/r/LGBT 
A good example I saw in the Hooli class showed that you can have an error nested inside an if statement and the program seems to run fine so long as the true condition of that if statement never occurs. Something like printing or adding using a variable that has no value because it wasn't initialized earlier. If the program doesn't hit that line, then it doesn't hit an error. Extrapolate that to a large program with a LOT of code and it can probably be an issue.
My personal point of view: Static is great thing if it is done like Fsharp does. See here. http://fsharpforfunandprofit.com/posts/conciseness-type-inference/ IMHO, type inference is future. Sadly, Python probably will never implement it.Probably for good reasons though :) Type inference is combining best of two worlds. Simply to write and strong to check. But C# or Java way of doing things is really cumbersome. But mind you Python is strongly typed dynamic language. There are no implicit conversions which you can see in JavaScript or PHP. The question is what happened if you have really huge code base mady by many people. In that case might be static typing better choice. 
One feature suggestion/request: allow people to provide their own argv values. This is really useful for people writing custom CLIs/shells for their own commands, or stuff like IRC/Slack bots.
&gt;TabError: inconsistent use of tabs and spaces in indentation
Nice. Also, does `defopt.run` return the return value of the function? 
Thanks for the suggestion. I rebranded it as top-starred in the repo. Unfortunately I can't seem to update the post's Reddit title.
There is no set timeline for removal, when it finally gets removed will be based on usage not on time. The warning message is a prod to try and guide people off of Python 2.6 so that we can hopefully remove it as well as a warning that we plan on removing it at some (nebulous) point in the future.
The point isn't operator overloads, though. That's a whole different programmer religious debate that can bite you even in statically typed language :P I could have been more clear (like /u/gotardisgo in another fork) that it's about programmer expectations and the tools available to set/check them.
It doesn't, but only because I hadn't considered the use case of people calling things from code and not just calling the Python functions directly. It's a very simple change to make and won't disrupt anything else, so I'll add that in to the next release. Thanks for the suggestion!
You already got begins, doctopt, clize, argh and click doing something similar. I dont see the interest of creating a new one. My favorite being begins because you can just put everything in params annotations.
I got this as well, but even if you fix it, it looks like PyMouse hasn't been updated in years, and doesn't support Python 3. It was merged into [PyUserInput](https://github.com/SavinaRoja/PyUserInput).
Try this out: https://github.com/chozabu/HeavyMouse/blob/master/alternate_heavymouse.py it runs at a lower framerate, but has much more chance of running on windows with py3.x
Thanks for pointing that out! I've fixed it, and for py3 support, added the previous version: https://github.com/chozabu/HeavyMouse/blob/master/alternate_heavymouse.py (to anyone reading this comment thread directly, sorry for so many replies - intention is to get the replies in peoples inboxes)
that worked, thanks :D fun little toy \^_^
begins is very close to what I was after but I have [one particularly large gripe](https://github.com/aliles/begins/issues/57) with it that drove me to build my own. I'm also not a big fan of the decorators since it means you end up repeating yourself if you're already writing a proper docstring. docopt and click are great (I mentioned them near the top of my documentation and encouraged people to use them instead of defopt if they want a customizable command line) but are distinctly tools for building command lines, whereas defopt is a tool for turning Python functions into command lines. When I personally write a script, I want to put the absolute minimum effort into writing a command line, and with defopt the effort is zero. clize and argh I wasn't aware of; I'll check them out.
Apache license is great. The whole point of an ide in python, for me, is frame work integration. Otherwise, I don't feel like the language needs one. But if I code in Java, then I use eclipse. At least when I tried the community edition less than a year ago, dj support was almost non-existent compared to pydev.
Neat, that worked. I needed to do this sudo apt-get install python3-xlib pip install --user pyautogui The mouse is a bit flickery - it's noticeably jumping rather than moving smoothly. I suspect that's a limitation of how fast the loop can run, though maybe there's something that can be done about it - I'm not familiar with these automation libraries. Edit: I think it goes a little better if I set the duration parameter to 0.1. Looking at pyautogui, anything less than that is treated as 0.
Glad it worked, and Most welcome :)
The more magic these get, the more someone feels inclined to rewrite their own when a magic limitation is found. That why I forever end up falling back to built in argparse
I dont like it myself but def add(x:int,y:int): return int.__add__(x,y) This will make you types safe but it is ugly. Not to speak about fact you are not able to be more specific about your inputs. Say you want to make only addition of positive integers. And now even static typed language wont help you unless you make more specific types :) IMHO, check everything by conditions is ugly not to speak about performance. 
1. Check ownership 2. Run both scripts from the CLI **after** doing 'su -s /bin/sh - apache' (or whtever user is the webserver running as)
In progress
&gt; Say you want to make only addition of positive integers. And now even static typed language wont help you unless you make more specific types That's simply not true. There's always `uint` and if that's not exactly what you want, just create your own data type.
Yes, of course. Thats what I was saying. You have to make you own datatypes. Positive was not good example :) But lets say you want to have input just odd number. Will you make your own datatype for odd number? Just asking. I would probably not :) 
&gt; *¹ - Not sure if there's a more suitable name. Yes, **web** framework 😉
This ^ Been the poor soul after the bus thing happened. Bad variable names, confusing code, etc. If someone (+ your future self) can understand/review the code then yes it would be overkill; if not because you are learning or just aren't a great developer or anything, and there's a chance someone will have to decipher without your help then please go for the bus factor of zero commenting.
I saw ghe latest pandas version 18 no longer supports 2.6
~~How did you manage to install pyautogui? It depends on pyscreeze which depends on PIL and PIL is not supported.~~ Nevermind, I was too quick with asking around. Works with Pillow too.
I think I know what you mean here. i'll give it a go. thanks!
Thanks. Think I should delete this question?
[Getting this error when i run it](http://i.imgur.com/TAM2Mog.png) i did install dependencies
&gt;Where do you guys program? I've tried running on PyScript but it doesn't show any results. Maybe I'm used to see results on codeacademy but is there a way where I can program and see it's result? On the command line python2 some_file.py will run it as Python2, similarly python3 some_file.py if you're looking to use 3. &gt;Why does the new Python version don't include "print" command? Latest version of Python3 has the print function same as always; it did change from Python2 to Python3, you have to use it as a function like `print(foo)` now rather than `print foo` &gt;Is Python usable to program any simple videogame or so? It can be, sure. &gt;Let's suppose that I write a huge amounts of def and variables. How do you run them until something happens? Example: Option? A. Ok. Option? B. Ok. Option? C, wrong, start back to A. Is that possible? Do you mean a loop that, on fail, goes back to the top and runs again? no_fail = False while not no_fail: try: do_thing_a() do_thing_b() do_thing_c() no_fail = True except: pass would work assuming that do_thing_&lt;a-c&gt; throw an exception when they fail in any way, though it might not be the best way to do things depending on what you really want to do. Can depend a lot on context. 
Thanks for taking the time! I really like that you said: "though it might not be the best way to do things depending on what you really want to do. Can depend a lot on context." Meaning that things can have multiple solutions. Thanks a lot for explaining!
 python2.7 -m pip /usr/bin/python2.7: No module named pip 
The other option is to make PyUserInput (which pymouse merged into) compatible with Python 3. That requires [python-xlib to be compatible first](https://github.com/python-xlib/python-xlib/issues/7).
I have: $cat iplist.txt 10.0.0.1 10.0.0.2 10.0.0.3 I also have: $cat script.py get = "snmpget " snmp = " -c snmp .1.oid.1.1.1.1.1.1.1.301" with open("iplist.txt") as f: for line in f: line = line.strip("\n") line = line.strip(" ") if len(line) &gt; 0: command = str(get + line + snmp) print command This ouputs: snmpget 10.0.0.1 -c snmp .1.oid.1.1.1.1.1.1.1.301 snmpget 10.0.0.2 -c snmp .1.oid.1.1.1.1.1.1.1.301 snmpget 10.0.0.3 -c snmp .1.oid.1.1.1.1.1.1.1.301 Hope this helps. 
It now seems *both* versions run under python2 and python3! Not sure what changed there, passing x/y as int in last commit may have helped. Foolishly, I did not use a venv, so it is less obvious exactly what packages I am running... on kubuntu 15.10+neon though. edit: works in my global py2.7 and py3.4 install. does not work in my global 3.5, or 3.5 venv (complains about lack of xlib on deps for alt, and running main) - I suspect this is fixable...
Then you don't have pip installed for 2.7 at all.
I'll take the opportunity to re-pimp my own [autocommand](https://github.com/Lucretiel/autocommand), which has a couple other nice features including automatically calling the main function, setuptools entry point support, argument typing, and `asyncio` support (have a coroutine as your main function). 
No experience about Python(x,y), but throwing a possibility here: Did you download the package from [the oficial repository](http://python-xy.github.io/downloads.html) or from Sourceforge? I noticed one of the downloads is from Sourceforge and they are know for adding stupid bullshit in their installers.
Ideally not. It becomes a valuable resource for the people who are too intimidated to ask their own questions.
Very nice! I just added this to my little joke app (next to this one in python subred - https://www.reddit.com/r/Python/comments/467xdb/mouse_too_easyboring_to_use_try_heavymouse/ ) Setup was super smooth &amp; easy (unlike in my app linked above ;) )
&gt; This will make you types safe but it is ugly. This isn't actually true. Adding the annotations doesn't do anything unless you have something– either an edit-time linter or a runtime checker– actually checking them.
Great :D
The fact that strings are an iterable of length-1 strings– in short, a recursive type– is one of my few remaining gripes with Python's type hierarchy.
Yes, it was the oficial download! I really don't understand since I've always had it correctly installed. Unfortunately my PC broke down, and now XY doesn't work anymore in the new one.
&gt; Well - the intention is not to be "usable" I know but what I mean is that if it's totally unusable then I'll start it up once and close it pretty much immediately because it doesn't do anything to me. If it is atleast somewhat usable, I'll play with it for a while to try and do something with it
Point taken! I'll try plugging in a mouse with more sensitivity later, and look at altering the default values for drag/grav.
I write less than 1/3 of the code when writing Python compared to the same logic written in Java. So that Python code contains 1/3 of the errors compared to Java, despite the dynamic typing. The time I spend fixing production code keeps the same ratio. 
Personally, I go back to using `getopt`. I'd rather write my own help statements and it is pretty easy to process the input. But, maybe I am also just old school.
Two reasons– * asserts are removed when running in optimized python mode * asserts have to be able to print the actual expression that failed. If assert was a function, it would only have t he result of the expression, not the expression itself.
`from __future__ import print_function`
Dunno why you were downvoted. The pairity between functions and types-as-constructors is a major insight.
I found a tweet somewhere some time ago which said something along the lines of: &gt; Every web developer should at some point attempt to write their own web framework. They should not publish it. I agree with that, although I think “publishing” it in the sense of showing it to some people to get feedback (like you) is definitely recommended. I guess the point is you shouldn't expect it to become the next Django or Flask or whatever. I've also tried it (in PHP, taking inspiration from Laravel) and I learned a lot. I want to do the same in Python and I might take a closer look at what you've done for that in order to learn the same basics about wsgi. It's very difficult to understand a huge code base like Django's if you don't even know where to start reading. So while I can't yet give you any feedback on your work I'll say thanks in advance. x)
Thanhs a lot for the information! Programming is a passion of mine but I am ironically horrible in this tech support kind of stuff!
Hahaha... sob...
Some things I notice right away: * In line 3 you reassign the variable 'choice' during the loop. * In line 10 you reassign the variable 'gtin' during the loop. * Also in line 10 you use range(1-7). I think you want range(1, 7). * As xdetar pointed out, you have indented lines 9 to 52 too much. * You can replace all the if... elif statements with a modulo statement: num2 = 10 - num1 % 10 
Well, thats enough of a push to get me to implement command line controls for each edge and (all in one go): https://github.com/chozabu/HeavyMouse/commit/67089086aa4fb6e18b6734ea3cac58563260ebc0 You can try it out like: python heavymouse.py --allsides bounce Thanks for the OSX info :)
This is the type of question best suited for /r/learnpython
Yep... that looks better on my big monitor... easier to follow.
TLDR: Portia lets you scrape web sites without any programming knowledge required. Create a template by clicking the elements on pages you would like to scrape, and Portia will create a spider to scrape similar pages from the website. No need to download or install anything, as Portia runs in your web browser! (Portia website)
Link to github https://github.com/giampaolo/psutil
I think it is the version with my OS (Kubuntu 15.10 + Neon) $ aptitude search python3-xlib i A python3-xlib - interface for Python 3 to the X11 protocol 
Cool. I was going to do that, but I got really busy today. Edit: It looks like they combined a lot of irrelevant changes into the PR. I'll try to look it over more and give it some review when I get time.
No, I guess I was (missing something). Thanks.
Strictly speaking, there's no such thing as an "if loop". If your code is too long to post inline here, it's too long to be asking about. Show some effort, whittle it down to a simpler example where things go wrong in the same way. Many people simply won't click your link to externally hosted code.
Function annotations are definitely something I want to incorporate. The design of defopt is that arguments have types and defopt holds the type parsers separately, in part so that it can support this properly. Many of the existing solutions that use annotations at the moment violate [PEP 0484](https://www.python.org/dev/peps/pep-0484/) (which is not their fault, since they were probably written before the PEP). I had a look at the typing module but couldn't work out exactly how those objects are supposed to be inspected from code. I'll take another look at it soon, but if you have any insight, please let me know. For other docstrings, it wasn't explicitly planned, but just quickly looking around I found [Napoleon](https://sphinxcontrib-napoleon.readthedocs.org/en/latest/), which I should be able to incorporate. Thanks for the suggestion! Composition is perhaps a little harder. I don't have any immediate thoughts on how I'd achieve that, but I'll keep it in mind. If you have any suggestions, feel free to put something on the [issue tracker](https://github.com/evanunderscore/defopt/issues) and we'll see what we can do. I do plan to push back on ideas that add too much complexity, but don't let that stop you from making suggestions.
Ah, I guess Ubuntu or Debian must have ported it themselves.
Yeah! One of my main aggravations with the existing crop of argument parsers is it seems like the mostly require you to still, like... list all your arguments. I'm glad to see someone else had the same insight as I did, to just use the function signature.
Looking around, I see it on pypi here: https://pypi.python.org/pypi/python3-xlib (with a github link), but it does not install via pip for me
Effortless until you want to customize your docstring in order to make it more readable or do super complicated docstrings. Docopt lets me do... Usage: myGUI [-f FORMAT] INPUT [-o OUTPUT] [-s SHOT] [-m MAGNIFY] [-g GSCRIPT] [-p PSCRIPT] [-u POINTS_FNAME...] [--user_geom GEOM_FNAME...] [-q] [--groups] myGUI [-f FORMAT] INPUT OUTPUT [-o OUTPUT] [-s SHOT] [-m MAGNIFY] [-g GSCRIPT] [-p PSCRIPT] [-u POINTS_FNAME...] [--user_geom GEOM_FNAME...] [-q] [--groups] myGUI [-f FORMAT] [-i INPUT] [-o OUTPUT...] [-s SHOT] [-m MAGNIFY] [-g GSCRIPT] [-p PSCRIPT] [-u POINTS_FNAME...] [--user_geom GEOM_FNAME...] [-q] [--groups] myGUI -h | --help myGUI -v | --version Options: -h, --help show this help message and exit -f FORMAT, --format FORMAT format type (cart3d, lawgs, nastran, panair, plot3d, stl, tetgen, usm3d) -i INPUT, --input INPUT path to input file -o OUTPUT, --output OUTPUT path to output file -g GSCRIPT, --geomscript GSCRIPT path to geometry script file (runs before load geometry) -p PSCRIPT, --postscript PSCRIPT path to post script file (runs after load geometry) -s SHOT, --shots SHOT path to screenshot (only 1 for now) -m MAGNIFY, --magnify how much should the resolution on a picture be magnified [default: 5] --groups enables groups --user_geom GEOM_FNAME POINTS_FNAME add user specified points to an alternate grid (repeatable) -u POINTS_FNAME, --user_points POINTS_FNAME add user specified points to an alternate grid (repeatable) -q, --quiet prints debug messages (default=True) -v, --version show program's version number and exit How? Literally, just write it like that. Don't like the spacing, change it. The problem with things like argparse is you forget the syntax. Docopt let's you use the POSIX syntax that is familiar. I really wish it was in the standard library. Updating it *hopefully* wouldn't be an issue because it should follow the standard, not compatibility.
Maintainer of MySQL-python is inactive for these years. I've made a fork version https://pypi.python.org/pypi/mysqlclient Django recommends my fork officially. Stop using unmaintained library.
Files in Python are normally called _modules_. [See this as introduction on modules and classes](http://learnpythonthehardway.org/book/ex40.html). The big, obvious difference is at Class is a template which can be used to create multiple objects. A module can only ever be one object. Example with a Class: bar = Foo() cat = Foo() bar.increment() cat.increment() cat.increment() print bar.getA() print cat.getA() Example with a Module: import Foo as bar import Foo as cat bar.increment() cat.increment() cat.increment() print bar.getA() print cat.getA() In the Module (file) example, cat and bar will be the same value (3), because the two imports are just a reference to the same Module (file). Classes are also different from a Module in that they have a `__init__` method which is code that is called when an object of that type of Class is created. This method can take in arguments or run special set-up code. A Module that has code in it that isn't contained in a function is also executed at the time a Module is first imported. Try it, you can put a `print "Hello"` in your Module and it will print when it's imported. But only the first time a Module is imported, if you import it a second time, it will only create a reference to the original Module object. 
A module is a namespace, yes. But a class is not a namespace. Notice how you had to write `self.a += 1` not `a += 1`. (There is no `++` operator in Python.) In other words, accessing the attribute uses all the normal scope rules, just like in a standalone/free function. If you had written `a += 1` that would have been an error, because there is no local variable with that name. (And similarly for your second example, which is also invalid — you'd have to write `global a` in order to do that.) &gt; I often see classes used for namespacing in Python. Show us some concrete examples of what you're referring to here. 
I think my usage of the word "consider" is soft enough to imply that using an async framework is more of a "maybe next time" rather than a 5-minute fix like the article's suggestion was.
Yep. Alex Payne, a former Twitter platform engineer, [talked about this](https://www.artima.com/scalazine/articles/twitter_on_scala.html) in an interview about Ruby and Scala: &gt; As our system has grown, a lot of the logic in our Ruby system sort of replicates a type system, either in our unit tests or as validations on models. I think it may just be a property of large systems in dynamic languages, that eventually you end up rewriting your own type system, and you sort of do it badly. You’re checking for null values all over the place. There’s lots of calls to Ruby’s `kind_of?` method, which asks, “Is this a kind of `User` object? Because that’s what we’re expecting. If we don’t get that, this is going to explode.” It is a shame to have to write all that when there is a solution that has existed in the world of programming languages for decades now.
Thanks! :)
Nope, not to the best of my recollection.
Great quote. I totally agree that write a web framework is a good way to learn how things works internally in these "big" web frameworks like Django, Flask, web2py, etc. :)
Nice work grodola, psutil is one my all time favorite modules.
The command-line version of the function is necessarily restricted *because* you can only enter strings in a CLI, it makes no sense to enforce that restriction when you're *not* using command line to interface with the function. 
This is a test
Tips fedora
Unfortunately not, but we could pretend I did :P
Sure, that's not a secret; I wrote this in the summary: &gt; If you want total control over how your command line looks or behaves, try docopt, click or plac. If you just want to write Python code and leave the command line interface up to someone else, defopt is for you. You're also overselling the convenience of docopt a little bit. Sure, it's easy to make that small change, but only once you've already written that gargantuan usage string. Of course, there's no substitute for docopt if what you want is to write your usage string the way you want it and turn that into a parser, but there is most certainly effort involved. The flexibility in defopt is that it gives you near-complete freedom to write your Python code the way you want; the generated command line is about as inflexible as it can possibly be. If your intent is to write a pretty command line, I absolutely encourage you to continue using docopt. I wrote defopt for people like me who write the Python code first and worry about the command line interface later (or never).
There are [a few examples here](http://stackoverflow.com/questions/20021457/playing-mp3-song-on-python).
Just tried it. I basically get an error every time I try to annotate a page in Portia. Just a nondescript error and then a notification that their devs have been notified. Not ready for prime time?
I don't like how the recommended Python docstrings look &gt; :param str greeting: Greeting to display I've never seen the type written there, so the library is adding a new form of them. Additionally the `:param` is redundant. You're still dealing with special syntax. I like the numpy docstring style greeting : str your greeting So not only does the library have to support poorly designed default formats, it needs to support the numpy and google styles. If you don't care about command lines, you probably shouldn't be writing command line tools. If you do care, you should make sure it's easy to read and clear regardless of what you have to write to make it. There is a command line standard. It's called POSIX. There are things that are part of the POSIX standard that are not supported in libraries like argparse and optparse.
The default behavior of argparse is to strip most of the formatting from the descriptions. I can probably override this but that might mean I need to do some line wrapping manually. I'll look into it. The ASCII art is going to wreak havoc on docutils which is what I'm using to process the RST (and what I believe Sphinx uses under the hood). I haven't pushed the limits of RST in docstrings yet, but at the very least you can stop it from crashing by using an RST comment: def main(foo): """Test .. ___ _ _ .-' '-. (.)(.)/ \ jgs (art from http://www.ascii-code.com/ascii-art/animals/rodents/mice.php) /@@ ; o_\\-mm-......-mm`~~~~~~~~~~~~~~~~` :param str foo: description """ print(foo) I could probably also handle literal blocks, but right now they just get dropped entirely: def main(foo): """Test :: ___ _ _ .-' '-. (.)(.)/ \ jgs (art from http://www.ascii-code.com/ascii-art/animals/rodents/mice.php) /@@ ; o_\\-mm-......-mm`~~~~~~~~~~~~~~~~` :param str foo: description """ print(foo) Note the difference there - the `..` is immediately followed by the art line, whereas the `::` has a blank line before the art line. These are important!
Another user requested support for numpy-style docstrings, which I'm more than happy to look into. `:param` is only redundant when viewed through the narrow lens of documenting function parameters; it's part of the markup used by Sphinx and some IDE's to generate documentation and validate types respectively. [You can document more than just the parameters.](http://www.sphinx-doc.org/en/stable/domains.html#info-field-lists) As you can see there, I didn't invent the inline type notation, plus the separate `:type` is supported if you would prefer to write your docstrings that way. If argparse is not POSIX-compliant, then your gripe is with the Python standard library, not me.
[Image](http://imgs.xkcd.com/comics/standards.png) [Mobile](http://m.xkcd.com/927/) **Title:** Standards **Title-text:** Fortunately, the charging one has been solved now that we've all standardized on mini-USB. Or is it micro-USB? Shit. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/927#Explanation) **Stats:** This comic has been referenced 2544 times, representing 2.5395% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_d04b1k4)
Yup, gave it a try too. Could not figure out how to go from a sample to extracting items automatically.
Thank you :) I'm not sure what you mean by `make this thing able to be serialised` though. Are you talking about making query results serializable (to XML, JSON or any format), or instead making the whole query language serializable ?
FWIW, the "minimum and average women age" section can be just from statistics import mean women_ages = [user['age'] for user in users if user['gender'] == 'female'] women_average_age = mean(women_ages) minimum_woman_age = min(women_ages) and I think the `lifter` example is meant to be women_average_age, minimum_woman_age = ( manager.filter(gender='female') .aggregate(lifter.Avg('age'), lifter.Min('age')) )
What makes Rodeo a better IDE that any of the other available? Why would I use this over notebooks, or pycharm, or spyder?
I resolved this problem last night. The problem was with the python subprocess call. For some reason you can't use it because apache thinks you're sending them a header of PING=192.168.0.1. which is annoying!! I still want to find out a way I can ping different devices on the network and output the results into HTML.
&gt; It means we have to write hybrid libraries for PyPI for the foreseeable future. While the author has a footnote saying that he'll do Python 3 only, please don't tell people this. The more Python 3 only awesome libraries the better, it'll help move people along. We've just started our port to Python 3, our biggest road block is wx (wish we could use qt but licensing gets in the way more for political reasons than budgetary). Other than library support no one has am excuse to use Python 2, and if your libraries don't support 3 then maybe it's time to fork them to do the updates yourself. Python 3 isn't just the new version, the new features are well worth the investment, especially with 3.5. The new async functionality, type annotations, and now the easier extension compilation makes everyone's lives better. Use Python 3!
`from __future__ import division, print_function, absolute_import` goes a long way to reducing the multi-version overhead. EDIT: As pointed out below, `unicode_literals` can lead to unpleasant surprises. Use it at your own risk.
It depends. There are a few edge case Armin blogged about so I had to add a disclaimer. Also to be fair, bytes got some features only lately. Originally core’s approach was to work with unicode only which isn’t always a good idea.
Such a shame. I'll stick to Python 3 then!
I could (probably should) rewrite that nowadays you should be writing 3 code that is backwards compatible with 2.7. This means it will be a subset of 3 (e.g `yield from` isn't valid in 2.7) and you need to be careful with semantics, probably use the `six` library for imports, etc.
Because I mention those for two different types of projects. In an (user) application you typically only run it on a single version of python, so it makes a lot of sense to just specify it run on a modern python, 3.4 or 3.5. In a library you might want to cater to people running many versions of python, depending on how large of an audience you want. So in that case maybe you still want to write 2.7 compatible code.
If the website you are trying to scrap is a static website, then a combination of "Requests" and "BeautifulSoup" modules are sufficient to scrap the data. However if the website is Javascript rendered, then Requests would not be able to grab the complete html content. In that case, you can use Selenium in combination with browser drivers such as Firefox, Chromedriver or Phantojs to grab the rendered data.
The tensorflow org is currently showing up because of skflow. Looking at the link you provided, I agree it seems the tensorflow repo seems more geared towards Python. I'll look into adding the repo and updating the tensorflow org stats, thanks.
 1. You mean `print_function`, not `print_statement` (though using `print` is pretty darn rare in any module serious enough to care about compatibility anyhow) 2. The `unicode_literals` future import is a misfeature -- it makes it harder to write correct programs not to have a literal for "whatever this version of Python calls `str`".
Have you tried `pillow`? * http://python-pillow.org/
FWIW, vinegar is the correct way to catch actual flies. (This isn't a Python3 metaphor, it's just true)
Pillow Cairo
Static typing gets rid of a very small class of very easily caught errors, and those who've invested time into getting static typing right in their head experience a sort of buyer's remorse when they see how fun and liberating dynamically typed languages are.
https://www.continuum.io/downloads It includes the latest stable version of all the scientific packages, including Spyder itself. Absolutely fantastic environment, everything works flawlessly. 
&gt; This was some very production code, though Which had never been run once? This isn't a typing issue, it's a workflow issue.
I don't completely grab the potential use case behind what you say, I think it means I have to do some reading about LINQ.
Become comfortable with virtualenv. It is a life saver.
Always use virtualenv lest you want to end up with a broken Python installation eventually: https://hynek.me/articles/virtualenv-lives/
Well that's amazing
great :)
Inbox probably blew up with hate messages from the backward-ass 2.7 crowd, clinging to the past and refusing to adapt.
Depends on what the reason for putting your time into a library is. Is it: A) I want to make something good that a lot of people can use and help people or B) I want to write a library to further my political agenda Personally I prefer A.
I think he means to change the lifter module into a lifter class, eg: `lifter.py`: class lifter(): def __init__(data, *args, **kwargs): self.load(data) ... def load(data): ... def filter(**kwargs): ... def exclude(**kwargs): ... def order_by(**kwargs): ... def values_list(**kwargs): ... def aggregate(*ag_fns): ... @classmethod def Avg(): ... @classmethod def Sum(): ... ... and one of the reasons for doing this would be to implement serializing the entire lazily-evaluated lifter object. Like so: def json(with_data=False): ... which could return something like this: { // Optional, gets thrown in if with_data is True, which defaults // to False because that could be a metric shit-ton of data // and take a _long_ time to serialize and deserialize 'data': [ // bunch of JSON-serialized data goes here // which deserializes to .load(json.loads(&lt;this_data&gt;)) ], 'filter': [ // Deserializes to .filter(age=26, is_active=True) { 'age': 26 }, { 'is_active': false } ], 'exclude': [ // Deserializes to .exclude(eye_color='brown') { 'eye_color': 'brown' } ], 'aggregate': [ // Deserializes to .aggregate(lifter.Avg('age'), min_age=lifter.Min('age')) { '': // Implicit name: &lt;function&gt;_&lt;attribute&gt; (eg: avg_age) { 'Avg': 'age' // &lt;function&gt;: &lt;attribute&gt; }, 'min_age': { 'Min': 'age' // &lt;function&gt;: &lt;attribute&gt; } }, // Deserializes to .aggregate(children=lifter.Sum('number_of_children'), flat=True) { 'children': // Explicitly named { 'Sum': 'number_of_children', // &lt;function&gt;: &lt;attribute&gt; 'flat': true // argument to aggregate function } } ] } this means you can serialize to JSON, and if you get really fancy, you can deserialize from JSON: def __init__(data, *args, json=None, **kwargs): ... to get back the original lifter object. And then you can add in serializing/deserializing to/from JSON, YAML, XML, etc.: def __init__(data, *args, json=None, yaml=None, xml=None, **kwargs): if data: self.data = data else: self.data = [] if json is not None: self.load(json.loads(json)) if yaml is not None: self.load(yaml.loads(yaml)) if xml is not None: self.load(xml.loads(xml)) ... 
Thanks for the explanation. I'd rather not implement everything into a single class but instead keep separate, composable parts. I think it would be more flexible on the long term (for example, you could create your own lookups easily, whereas with your proposal, one would need to override the whole lifter class). However, I don't see any reason why serialization and lazy evaluation it could'nt be done using current queryset objects, and it's definitely something I'd implement soon.
myopic 
I think having a single `lifter` class would make it easier for people to override things if they absolutely need to, but have it delegate out to "helper" classes where necessary, eg: aggregators and serializers. That way if somebody has a weird aggregator (eg: StdDev) they need they can override a base `Aggregate` class. If you do go this route, consider having a "shortcut" function/object that can wrap everything, a la [jQuery](https://jquery.com/)'s `$()` and [pyQuery](https://pypi.python.org/pypi/pyquery)'s `pq()` and returns lifter objects. I would also use [Serpy](https://github.com/clarkduvall/serpy) or [Marshmallow](https://marshmallow.readthedocs.org/en/latest/) to serialize/deserialize - they look pretty good.
I made the switch to Python 3.4 around 2 years back for client data science projects, I've never looked back. I also promote Python 3 at our PyDataLondon monthly meet-ups (I co-chair the meet, we have 2,800+ data scientists) and remind everyone that folk are starting to write interesting research libs for Py3+ only now (rather than Py2 only of before). Most folk I know have legacy Py2 stuff to support (which won't be upgraded soon) but who use Py3 for new or research projects, so they're not giving themselves an undue burden.
Infinite? Them's fightin' words. 
Pico2wave sounds better than the rest. Github will be up soon
I like the idea of the function keys, sounds great
&gt; Of course it's totally doable in plain python. If your concern is that the code becomes unwieldy as your comprehensions become more complex, then you should refactor your code to make it more comprehensible. Take this example: under_26 = [user for user in users if user['age'] == 26 and user['is_active']] Cleaned up: is_under_26 = lambda u: u['age'] &lt; 26 and u['is_active'] under_26 = [user for user in users if is_under_26(user)] More code? Obviously... but not nearly as much as there is happening behind the scenes in lifter. It also cleanly separates the predicate from the filter and makes your predicates reusable. I feel like lifter is a solution in search of a problem. Python already does this out of the box. To me, this just adds cognitive load.
My steps: 1. Load the page in chrome. 2. Press f12 to open developer tools. 3. Go to the network tab then reload the page. 4. Click through all the resources that are loaded until you find one that contains the data you want. You should be able to see it under 'response' or 'preview.'
Are you serious? It was anti python 3 devs who started the passive aggressive library tactic. https://www.reddit.com/r/Python/comments/45sm94/what_are_the_most_recent_python_3_vs_python_2/d008c8r Now python 3 devs, talk about possibly, responding in kind, and you cry foul. 
While I don't support the second motive, there are times when supporting 2.x is too restricting or too much of a burden.
I won't hide I prefer the django way of handling things: `Manager` class returing `QuerySet` using `Q`, `F`, `Lookup` objects and so on. With this scheme, it's easy to override only a part of the system. You want custom class with custom methods for your queryset ? Just create a new one from inheriting from `QuerySet`, and pass it as an argument when instanciating your manager. You cannot do this if all methods (such as filter, exclude, etc.) are bound on a monolitic base class, the only solution being subclass the whole `lifter` class just to override one or two methods. Building an artificial `lifter` class to aggregate all these parts together seems redundant to me: Python modules exist for this exact purpose. It will also reduce flexibility, since it's always easier to override a small part than a whole system. There is indeed a shortcut to invoke the library, and this is the `load` entrypoint, that returns a `Manager` instance. I do agree it is currently too basic now (only acepting an iterable), but passing additional config values for the underlying manager instance is totally doable.
&gt; It was anti python 3 devs who started the passive aggressive library tactic. &gt; Now python 3 devs, talk about possibly, responding in kind, and you cry foul. Dude, of all the things you can turn into Us vs Them, "python 3 devs" vs "anti python 3 devs" is probably the weirdest.
I am not using a lot of these advanced features, but this has been one of my favorite features in Python when switching (as much as I can) from Matlab. In Matlab, if I wanted to do options, it was often convoluted using `varargin` and a parser boiler-plate I wrote (to allow flags and value, pair). Not to mention, it was often harder to read since there was no `=` sign in there. In Python, it is just so easy! And, I do not have to document it nearly as heavily since it's in the function call! ...and now I'm sad because I have to go back to matlab for a project.... :-(
I tried this but keep running into issues. When I run python setup.py install in the command prompt I keep getting warnings. I get a bunch of warnings saying the DLL for ... library not found. Is there a package I am supposed to install to get all these DLLs?
Use SymPy for the math, or maybe PyGame+PyODE for simulation. 
I see what you're saying, but in my case it's actually 3 or 4 nested functions deep. And the condition just changes a little part of that subsubsubfunction. (It's testing against live data, and the test data is often a few weeks old, so we have to remove a filter that only returns current data.) Unfortunately with this setup the tests *are* inherently brittle. But so far it has worked out well. And the code has been in production for a while already, so the implementation isn't likely to change a lot in the next months. Good advice nevertheless :)
Yup
With the class, I can make a second Foo with `bar2 = Foo()`. How would you do it with a file?
Finally? Arch switched over years ago. When CentOS and Debian Stable have python 3 as their `python`, that's when we'll know the transition has happened.
C) I write a library for myself using the language I like, then release it in the event it is useful, not caring if it is or isn't.
Woof well, that blew up :) I was just thinking about it from the perspective of a having a very slightly cleaner API for the use-cases I imagine most: scripts and other playing-with-data type thigns: objs = requests.get("http://example.com/some-api.json") for foo in lifter(objs).filter(type="foo"): … do stuff …
&gt; Yeah, but I don't understand how this is such a big deal - I do this with Django's Models (__str__(), get_absolute_url(), clean(), and save()) and Managers (get_queryset()) all the time. Care to explain why you are trying to avoid this? You're describing a whole different thing here. Your proposal was to implement everything under a single class. I'm not against classes, I just prefer to keep them small if possible. &gt; This I understand, especially if you're looking at the objects as database models. But this project seems to be aimed at something much, much more - a generic, functional library for slicing and dicing any iterable, not just database models. The fact is lifter operates on iterables containing similarly structured data. From that perspective, we can consider there is an underlying data model, even if it is not stored in a relational database or as explicit as Django's. Lifter won't work if you feed it with totally different objects then try to query against a field that is only present on some. &gt; And if you're looking at things from that perspective, as far as I can see, a Manager class is redundant, if not entirely pointless. I must admit Manager in lifter currently seem pointless. The fact is I implemented them initially because they were used in Django. However, we're trying to solve the same problem as django here (even if we don't operate on a relational database), so I'm pretty sure that if their existence is needed in django, we will need them in lifter at some point. Possibly when dealing with reversed lookups and other beasts. &gt; What I'm saying is make that function name really small, since I can see it being called all the time (like $() in jQuery or pq() in PyQuery) I totally misunderstood you suggestion, and I'm sorry about that. A shortcut is a good idea, and I've opened [an issue](https://github.com/EliotBerriot/lifter/issues/8) about it. I apologize if I seem hard in what I say. English is not my mother tongue and sometimes it's hard to find the right tone, especially in technical conversations. I really appreciate your feedback, even if I don't agree on everything, and I'm sure it will help moving the project to the right direction.
/u/iBlag suggested a `L` shortcut, I don't know what would be the best option between a `lifter` or a `L` shortcut.
&gt; I apologize if I seem hard in what I say. English is not my mother tongue and sometimes it's hard to find the right tone, especially in technical conversations. &gt; &gt; I really appreciate your feedback, even if I don't agree on everything, and I'm sure it will help moving the project to the right direction. No worries, you're fine! I hope I don't sound too demanding, I'm just excited about this project. :) &gt; However, we're trying to solve the same problem as django here (even if we don't operate on a relational database), so I'm pretty sure that if their existence is needed in django, we will need them in lifter at some point. In Django they're used as a bridge between the data definition (model) and the queryset. Their entire job is to basically create a queryset from scratch for the appropriate model. Unless I am misunderstanding the aim of this project, this seems to want to work on simple Python iterables - not necessarily things with an explicit data model. I would probably always do something like this: from lifter import load as L so I could just continue on my merry way: things = list(...) for thing in L(things).filter(href__startswith='google.com'): ... 
This from lifter import lifter as L should work. That's at least what I would do every time I used it.
Possibly means I've misunderstood and also need to do some reading. Let's have a date in the library.
Hey, the team is working on fixing those issues. Which website are you trying to crawl?
/r/learnpython `"C:\\Users\\..."` or `r"C:\Users\..."` or `"C:/Users/..."`. https://docs.python.org/2.0/ref/strings.html
most IDE's or editors that expose IDE-like behavior have the ability to point to a given python interpreter/environment. I know, for example, PyCharm let you set different interpreters/environments for each project. I would assume Atom also has a similar feature. There should be some preferences setting which lets you select the path for the python interpreter
Absolutely. Which is of course fine.
You have to write code. Work through the exercises and practise projects. You can have knowledge of the techniques but you have to actually do them to be any good at them. &gt; Did you remember everything from the book after reading it? No-one really remembers all the syntax - we google stuff all the time. However you should learn the techniques. Those are what stick in the head. For example, how to break down a task into separate, independent functions. You can't google that. Once you know what each function has to do, you can 'trivially' look up in a Python reference which one do what you need and what order their parameters go in. &gt; Which important programming skills did you learn from the book? It doesn't really work that way: if you did the exercises, you probably wouldn't be asking that. Basically: Do the exercises.
Additionally, if after reading this you think hug is a project you would like to contribute to before 2.0.0, know we are very open and excited to welcome new contributors :) A guide has been put up here: https://github.com/timothycrosley/hug/blob/develop/CONTRIBUTING.md to help guide through that process
Yea, I'd be a big -1 on `L` — I can't think of any other library which does that. I'd use `from lifter import load as lifter` instead. Of course, you could go with option C and make the module executable. See, ex: https://github.com/wolever/pprintpp/blob/master/pp/pp.py &lt;/bad-ideas&gt;
There was a [poll](https://www.reddit.com/r/Python/comments/3xcduz/which_version_of_python_do_you_use_this_is_a_poll/) two months ago which looks more believable than the PYPI stats. 
It's making my life rather difficult as I'm personally trying to get pymssql packaged, all the standards are changing constantly and it's hard to keep up.
&gt; ...including the space and the dot. This gives Atom all of your environment variables. Do you know why? I'm not familiar with Atom, but programs should have access to the env regardless of arguments given, why does atom use the environment only if you pass it the current directory? 
Also, vinegar is delicious. Whether it's on fries, potato chips, steak sauce or used to pickle things.
Last year I moved all our projects to Python3. Took a while, but was definitely worth it, I'm never looking back. It took a bit of time for a critical mass of libraries to be available for Python3, but we're [clearly](https://python3wos.appspot.com/) there now.
Yeah, html, json, yaml, or xml are the main formats I would look at if you're trying to sift through a huge list of resources. 
&gt; wish we could use qt but licensing gets in the way more for political reasons than budgetary What is the licensing issue, specifically? Qt is under LGPL, which is basically the same as the WxWidgets license.
It is very nice! can you tell me how it is different from Flask-Admin?
Commercial use, it's $300/month/developer. That's $3600/year/dev, so for us we'd spend around 30-40k$/year on just Qt developer licenses, which is more than we can justify to upper management for additional software when we already have JIRA, crucible, visual studio pro, an in-house anaconda server, and a fair bit of extra software for our specific industry. Especially when we get asked "what are the cheaper options" and we have to answer that Tkinter is built in for free and wxPython is also free for commercial use. We've just started working on shipping software externally, previously we've only shipped software internally, so we can't make the case in terms of revenue streams just yet. Maybe we'll be able to in the future, or we'll take an alternate than either wx or qt such as a browser based approach, but for now we're pretty much stuck with wx.
Thank you! I have done and will continue to do all exercises.
You do realize how important identity checking is, right? Are you comparing things to None? You should be using identity checking.
Do you understand how Android applications work? For the most part, what you're asking for is impossible directly. Yes, you could unpack and decompile the apk somehow, and then you'd be able to read the XML files containing the static strings, but that doesn't sound like what you want. Are you looking for network data? You'd be better off writing a proxy. 
I'm really digging this man, nice job! Could you compare it to this one? https://github.com/zalando/connexion 
Good podcast. I too recommend checking out betamax - its a solid library. We use it extensively on github3.py. 
And then you're still stuck without `yield from`, `async`, `await`, and native coroutines. When you're writing to a library practically designed to make use of them. I'm personally looking forward to a PyPy3 that's 3.3 compatible.
You probably want to build your own uwsgi compliant app. This will let you build the web framework without worrying about the underlying handling of network stack. Alternatively if you want to build a framework that also includes a http server, then you are going to want to start with sockets. Edit: Words are hard
I'll definitely try installing from wheels if that will bypass the issue. Thank you very much.
Better fit in /r/learnpython. That said, class editDefense(BasePage): def __init__(self, element): self.element = self.driver.find_element_by_id(element) def set_network_strength_or_entity_controls(self, _type): if _type == "entity_controls": self.element.find_elements_by_class_name('radio')[-1].click() sleep(0.5) else: pass def select_continue(self): self.element.find_elements_by_tag_name('button')[-1].click() def blahblah(self): # and so on
&gt; IANAL, but the commercial license is only for companies that don't want to abide by the rules of the the LGPL. But PyQt, the only production ready library for working with Qt5 on Python, is only available in a per-developer proprietary license that costs 350 pounds (GBP) a pop or GPL, but not LGPL, like Qt.
&gt; You can find videos on YouTube of the main founder of python himself admitting that the transition between 2 to 3 was going to be rough (I am paraphrasing). The nature of the 2 biggest changes, Unicode and changing print from a statement to a function was not backwards compatible. My entire point was that it's way deeper than that though. And that when GvR thought that those would be the hard problems, he was deeply mistaken. Again, the main problem is having third-party libraries target both versions of Python for a long period of time, for years. And for way more years than necessary because of how bungled the transition was and still is. Now take for instance the print function. This is a complete non-problem in the larger scheme of things. You add `from future import print_function` to all your files, and there you go, with a little but most importantly _one time_ effort you support both versions of Python in that respect. Unicode is much trickier, but still, you have a clear upgrade path, as a library developer: first, make your library work with unicode strings internally, converting input strings as necessary, because it's a good thing anyways, then, well, it would just work on Python3. Then a couple of years down the line you could remove the checks and conversions. Anyway, that was a one-time effort, it didn't uglify your code all that much, and you could support both versions from the same codebase. Stuff like `dict.items` is way harder still. I don't know of a good way to deal with it (what if people inherit from `dict`? That's a can of worms of epic proportions, if you think about it), but I do know that actively uglifying your code with `for k, v in six.iteritems(some_dictionary)` is very probably one of the worst ways to deal with it. But that's what any library developer who wants to support both versions has to do right now. Even `for k, v in some_dictionary.items() # SIX:dict` that could be automatically converted to `.iteritems()` for the Python2 version would be way better. Anyway, my criticism of the core devs is that they did not understand, and probably still don't understand, what the problem with migrating code to Python3 really is. It's not that there are some backward incompatible changes that you'd have to fix by hand after running `2to3.py` on your code, it's that for third party libraries, they **have** to support both versions, and it's an exceptionally ugly deal now, and was simply a non-deal for the like first four years of the supposed transition. &gt; I would rather not have an "us vs them" mindset, however, it was people like Zed Shaw (who furiously attacked python 3 devs) who really started this. Well, don't identify as a "python 3 dev", for starters. Repeat after me: Python3 is a tool, I am not my tools, I use the best tool for the job.
`print("Hello, %s" % nameIs)` The `%s` specifies where `nameIs` should go in the string.
You can make Python code work in Python 2 (but portable to 3), work in Python 3 (but portable to 2), or work in both Python 2/3. It sounds like you want option #2? I stick with option #3. Python 3 doesn't really add all that much (I stay far away from ansycio), so what are you really buying by breaking Python 2 support? By supporting/testing in Python 3, you assure that Python 2 handles unicode properly, but you're not adding features per say. If you want ansycio, you're going to have to break Python 2 support. If you want the `@` symbol (I do!), you have to decide if that's worth breaking Python 2. It's not worth your effort to run a script to change your `@`s to `np.dot(...)`, when `np.dot(...)` works just fine. I just use `six`. It's great. It's not Python 2.7 specific like you suggested. It much more favors Python 3.
&gt;You do realize how important identity checking is, right? No, that's why I asked. &gt;Are you comparing things to None? I don't think a single use case is worthy of a keyword.
The official documentation links to this guide, which is maintained: https://python-packaging-user-guide.readthedocs.org/en/latest/ Specifically, I believe all the info relevant to uploading is at the bottom of this page: https://python-packaging-user-guide.readthedocs.org/en/latest/distributing/ As for automatically uploading it, I believe you could do this using a Git Hook, though I've never used them myself. Worth Googling a bit about though. Really, though, in most cases you don't want the PyPi package to be updated for every commit. Rather, you'd only want to update it after you've made a significant amount of changes and have tested the results to make sure everything is stable (nothing broken). Also, I believe PyPI makes you increment the version number in your setup.py each time you upload new code. This is so version numbers map to unique versions of the code, and fixes the problem of having, for example, 10 different flavors of MyApp v0.6.2 floating around out there.
Like I said in the rest of that sentence, it was production code where the one option had not been run in production. Most of the time you don't actually need to restrict which machines this one command runs on. Do you test every configuration option, every debug setting, every logging option of code that is about to go to production? Including automated regression tests when people make changes to the codebase?
Thanks for the link, that's a great reference! The python docs are generally good but I find their explanations of the % and format features a bit too technical. I agree, `%` for simple stuff, `format` as soon as you need something non-trivial. One of the neat uses of format that I like is `"{foo} {bar} {baz}...".format(locals())` for printing quick debug statements that use a large number of in-scope variables (globals() works too).
PySide for Qt5 is currently in development, so hopefully that will be a good option sometime from now. Plus there's a library that can use either the original Qt4-only PySide or PyQt with a simple toggle through a unified API. And unfortunately, JavaScript GUIs (either with or without a web-stack) is no replacement for a desktop GUI toolkit like Qt and a well-designed language.
The ntp bug wasn't limited to RH though, and, my several thousand installs didn't have a problem because they also documented how to mitigate it. I'm pretty happy with their response to the recent glibc bug too. A yum command and a reboot and I'm all set, and the patch is guaranteed to not break or secretly upgrade anything in the process.
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
&gt; Do you test every configuration option, every debug setting, every logging option of code that is about to go to production? Including automated regression tests when people make changes to the codebase? Fucking YAWN holy shit. No. I write my code in the REPL and rewrite it with proper variable names when it works. This it Python not Java or whatever. It's about having fun and being productive. I instantly catch shit like actually iterating over `x` instead of `x.split(", ")`.
Hi! I use newsbeuter. You could just add .rss to each subreddit, and then just paste the new list in .newsbeuter/urls file et voila you are done
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
That should never happen, the application is designed to transform each Video one at a time and save the data. When complete, all models reset their fields and transform the next video in the Redis queue. If we want to parallel process videos, we can launch multiples instances per machine and have multiple machines. 1 Process = 1 Video
Personally I hope someone does a fork to port new features to 2.7. Long live print statement and sane integer division!
Why not? Nobody is forcing you to use the system python interpreter (in fact I would even go as far as to recommend against it in practice, since IIRC, some RHEL packages depend on it, and messing with the default environment/packages always runs the risk of breaking something... I always leave the system python install alone on linux and OSX) Anyway, you can ALWAYS install your own python environment, even in your home directory. If this seems daunting, just use something like anaconda/miniconda.
I am not sure it is harder to achieve it but if you are aware of the problem, fix it when you think it is the time. To me, this is cool for one thing: testing. Spawning the targeted Sql engine make slow test suite, then you run unit tests on top of sqlite in memory, which is often not the production server. Then start the fight on this and explanation of unit, integration and functionnal tests suite... I don't use django, so I am not in this target of user, but if you can replace the django models by your implementation, can be great. Thus is also true for starting mocking service in case of API. But, for production code, operation on simple types come from API, and, I think developpers prefer apply filters server side by passing parameters to the API. But maybe scientist have other use cases! 
Yes I love and use pyenv (if you maintain packages it's indispensable) but isolation of package installations is something you need regardless.
check this comment: https://www.reddit.com/r/Python/comments/46dxp0/python_3_in_2016/d04kf0r
It's only one example of such. Take a look at the django source, as another commenter has said.
Just use a global variable. 
yeah, no problem. I realise I posted in the wrong place so I did submit a similar question over there. Many thanks
https://pymotw.com/2/json/ This should help. Mind that this is for Python 2 and you should be learning Python 3. But should be compatible.
Things that helped me learn python from scratch - I had no previous programming experience (I'm still basically a noob). * A byte of Python * Learn Python the Hard Way * Udacity course: Programming Foundations with Python * Dr Chuck's Coursera course: https://www.coursera.org/learn/python * Buggering around with iPython in terminal, writing little scripts that do virtually nothing just so I could figure out if what I thought would happen actually happens, then googling for why my thinking was right/wrong * Stackoverflow * r/learnpython
I think centos has still 2.6 as default?
And if you read his comment, his grep ONLY includes none checking.
Thank you for the correction. My mistake!
&gt;"Portia 101" - Length: 00:02:56
Well, no, a bunch of people complained they were useless, and made a lot of conjectures and hypothesis about why they might be wrong. No one suggested any alternate metrics, and certainly no one advanced a data driven argument for why their pet hypothesis is preferable. I've got plenty of hypothesis I can advance on why Python3 is in fact _over counted_ on PyPI, but I don't have any data to support them, so I shut up.
Take a look at pyqtgraph. It's a pure Python package specifically designed for realtime plotting and image display. I use it on a number of projects and it's really pretty amazing. Realtime video with overlays and realtime roi graphs or over twenty realtime plots of 30 hz data updating in a window work fine.
Thanks buddy.
&gt;Matplotlib is not really optimised FTFY. Seriously though, I asked about performance at the matplotlib BOF session at the scipy conference last year and got the response that they haven't really focused on performance so there was a lot of low hanging fruit of someone wanted to start profiling things. Their main goals right now are supporting interactivity, improving notebook integration, and keeping everyone happy when it comes to generating reports. However matplotlib is certainly capable of handling 600 data points coming in relatively fast. There are some examples of using the animation features of matplotlib out there, but there needs to be more of them. I remember seeing recently a post on an engineering subreddit that had a software oscilloscope using matplotlib but unfortunately can't find it right now. Another option is to try to get VisPy working on Windows, which is no small feat. Anaconda helps get it installed but actually making it talk to a GPU is more problematic. It can embed in a Qt GUI and uses a GPU to accelerate plots. The demo they had 8 months ago had 10000 concurrent plots of 1000 points each updating in real time with interactivity and fancy effects without slowing down a MacBook. Pretty impressive, but a relatively new library still. 
my bad. Should I just cross post or make a new thread and ask a mod to delete this? 
Have you seen REMI? A pure Python portable webinterface. There is an example about svg plot with moving X axis. https://github.com/dddomodossola/remi
I've only just begun learning, I'm actually studying Physics and I was recommended learning Python by PhD students I'm assisting in our lab. Times are changing.
/r/learnpython
FWIW, QML + Python work very well together. This with [qmllive](https://github.com/Pelagicore/qmllive) is a breath of fresh air if you ask me. There's some learning curve in QML but its a lot of fun, swift and encourages developing highly interactive, visually elaborate GUI's. For a new project I'd encourage looking into this...
Why does number of users matter? Presumably youve written a library to be useful to yourself, why do all the busy work to support a system you dont use. If someone feels so strongly about sticking to python 2 they can do the work of back porting, or live without the benefit of your library
[removed]
We use PyQt with python at work and I am very satisfied with it. I have also implemented my own widgets, which takes a bit more work. Qt Designer can also be used with python to design GUIs. We have been looking at alternatives, but we didn't find much. PyQt requires a licence for commercial use, PySide I think is similar, but free.
Your my hero! Haha ... Thanks
&gt; their main goals right now are supporting interactivity I assume you mean in the context of adding sliders, and features etc. At some point supporting practical interactivity will be an identical task to improving performance.
I would try PythonQwt at once instead of pyqwt, because it's pure Python and the problem of maintenance isn't existing. I will give pyqtgraph a try, when the performance is good enough. 
&gt; &gt; The more Python 3 only awesome libraries the better, it'll help move people along. &gt; Yeah, vinegar is the superior method of catching flies. Writing a Python 3 library is providing honey to Python 3 developers, not vinegar to Python 2 developers. 
Yes. There's definitely a role for Qt to fill. You can get way more out ofna JS GUI but at more cost and requirement of additional skillsets. Works for us because we need it to look good, feel good, and we have a REST API anyway. 
&gt; Anyway, you can ALWAYS install your own python environment, even in your home directory. If this seems daunting, just use something like anaconda/miniconda. It's not a technical limitation.
I know what it's for, but the attitude you appear to be radiating is one of what might be called "selective hearing". From the entire thread here, it seems clear that you're not going to understand the concept unless you see for yourself how useful it actually is. Since I'm a glutton for punishment, I'll give you a few examples. --- Whether you'd want to use identity checking or equality checking depends on the situation. Here's a few examples: Preference for identity checking: * Comparing Singletons, eg `None` or Python3's enums (backported as `enum34` for Python2) * Checking whether two objects are the same instance * For example, if you have a large list or other large structure, comparing via identity is *much* faster than comparing by equality, which would have to iterate the structure somehow * Safety - the `is` keyword can't be overloaded * Readability - Python's number one priority * Strange behavior - [sometimes](http://jaredgrubb.blogspot.ie/2009/04/python-is-none-vs-none.html) None comparisons (and other Singletons) don't behave how you'd expect with equality checks Preference for equality checking: * Strings, ints, and other types that may or may not be Singletons internally * Comparing non-singletons * Overloading for library-specific equality checks
Using [this code](http://matplotlib.org/examples/animation/simple_anim.html) I've set the interval to be 1ms and it runs so quickly I can barely tell what's being graphed. To be fair, I'm running it on a faster processor than an i3, but if I modify it to be import time times = [] def animate(i): times.append(time.time()) line.set_ydata(np.sin(x + i / 10.0)) return line, Then run the code for a second, hit ctrl-c, and compute 1 / np.mean(np.diff(times)) As a poor man's FPS calculation I get about 626 FPS. This is with 629 points. Looks like 1ms is an appropriate interval time since it ends up actually being about 1.6ms per frame.
Ok, thanks. That's all I wanted, some decent examples. The way you talk implies to me that you think it's bad to want use cases, what nonsense.
I also came here to mention VisPy. I haven't had a chance to try the APIs, but it sounds like it was built for the exact use case you talked about. Here is a demo of it at SciPy 2015: https://youtu.be/_3YoaeoiIFI I am also interested in seeing what kinds of non-web solutions exist; but if it turns out that nothing really solves the problem without moving to the web, you might also check out Bokeh. 
Honestly I'd rather stab my eyes out with icepicks than write GUI software in Python and I say that as a 10 year python dev. It doesn't have a good impedance match with ANY toolkit and NONE of the available toolkits support 2 way data binding AFAIK. I'd write the GUI layer in the toolkits native language (eg. c++ for QT) and embed the python interpreter or call with RPC. Or just write a web app and use [D3.js for visualization](https://d3js.org/). D3 uses a declarative language to bind data to DOMs. It can render HTML, SVG, and canvas. Here's a POC web app I wrote that used a python backend to stream live data via websockets to a D3 based browser frontend https://github.com/n1ywb/wavefront-web/blob/master/wavefrontweb/static/js/main.js 
This is working, but I do line.set_xdata() too and then it's getting ugly
Do you really need to or can you change your axis labels instead? It may be faster to do the latter.
Nice, I like how you made it short and very informative. I'm already planning on how to use this. It wouldn't be too hard to slap on some fancy new-fangled js charting/graphing library on top of the endpoint I think. This could be combined with feature flags to enable monitoring specific parts of an application in detail. Thanks!
+1 for web app route. I'm hard-pressed to find any reason to not build any interface this way, and the only one I can think of is for native mobile apps. Say what you will about the state of JS/front-end development. It's not my absolute favorite, but fantastic tools like d3.js and flot.js exist and are fairly easy to implement for most use cases. Plus, having that skillset is extremely versatile.
&gt;NONE of the available toolkits support 2 way data binding AFAIK. What is an example of two way data binding?
Start with Anaconda as this will make everything easier.
https://msdn.microsoft.com/library/ms750612(v=vs.100).aspx https://en.wikipedia.org/wiki/Data_binding https://docs.angularjs.org/guide/databinding http://knockoutjs.com/documentation/binding-syntax.html
&gt; flot.js that looks cool, hows it stack up to d3?
Nice. But if you were really thinking about us, poor, tired, lazy programmers you would make your script to add itself to those scheduled tasks. Also, not all versions of Windows even have Group Policy Editor...
cheers. I'm wondering what data binding gets me vs event handling. I guess its a matter of not having to write an event handler that refreshes some field in response to some change. Is there something that data binding gets you that event handling cannot handle? Like, do you have something in mind that Qt or wx are unable to do?
May I ask you why your company is asking you to do that?
TBH I haven't developed a big app with PyQt (largely because it's lacking databinding). I've done enough C++/Python integration to know that it's a pain in the ass trying to use e.g. vectors in python. What I find is that pretty much every toolkit is based on some language or framework OTHER than Python, e.g. C w/glib, C++ w/STL, C# w/.NET, TkInter with TCL, etc. Then you try to program that toolkit in Python and now you get stuck doing all kinds of extra work because glib has it's own list object, C++ STL has vectors of whatever type you've statically declared it to be, .NET has it's dynamic data structures, and none of those map 1:1 with a Python list, so you wind up with all bad choices; try your best to use vectors as vectors within python and live with the fact that they aren't pythonic; wrap them in some sort of list-like API which will never be fully list-compatible and has to jump through crazy hoops; or copy the data into a list, which is inefficient. This is what Knuth was talking about when he said that modern programming has become nothing more than gluing together slightly incompatible systems.
My guess - turnstiles were too expensive and time cards too retro. :0D
yeah, I agree on the boilerplate business, but thankfully there are so many documented examples I can't imagine not being able to copy and paste most of it for anything you want to do. I was just like "well here are a bunch of chart examples I'll just copy these". I guess it's just generic vs. specialized?
You're misunderstanding the last paragraph. It's a simple recognition that times change and new companies may rise in older company's shadows. Unless you think the big Three will dominate forever (they may, who knows, hence the last parenthesis). About the 'arguing with someone', that's just how I freewrite (as in you're correct). I do argue with myself, even when making an argument. That's how I come up with better arguments! If I were to rewrite and edit over a course of draft for a few days, the tone would be different of course. ;) Your Monty comparison interests me though. Do you personally think there's cause for alarm? That's sorta the point of this thread. Is there cause for alarm or not? I personally, very recently, came to the conclusion that there isn't. After worrying about that question myself (should I have went with php? should I focus all my attention on C or Java? etc).
Thanks!
Yep, it's big in the data science world, and can very easily apply to Mathematics and Physics from what I've heard.
No, there's no cause to alarm and there's no cause to suspect that there's a cause to alarm. I see, you had your own internal doubts and worries and then voiced a refutation. The dissonance between your doubts and everyone else's lack of those specific doubts created a comedic effect. It would be like if a passenger who was very afraid of flying finally calmed herself down and decided to explain her current opinions in a speech directed at her fellow passengers: "the engine I can see is not on fire, and there's the other engine anyway, so everyone keep calm and don't panic". And everyone is, like, dude, what. So is your "Google doesn't hate Python" (why would it) "... may not matter that much in the future" (which totally sounds like you're still unsure about the first part, so even funnier). Well, I chuckled at that, so I guess it was actually a net positive contribution, even if not exactly the way you intended! =) 
This all makes me so sad. :( I feel like I've wasted so much time doing things that would literally take seconds, 10 years ago, in an IDE. 
I also highly recommend pyqtgraph. I switched from wxPython to PyQt and I 've been really happy with PyQT + pyqtgraph combination. I like working with threads in PyQt as the signal handling is just so easy to understand. PyQt graph is phenomenal and the technicians here at work love the software I've written for them. Getting pyqtgraph to update the x axis is easy. When you push data to the plot, it'll be looking for a data set for X and Y that are the same length. As long as those add up, then the x axis will do whatever you want. You could store a scrolling plot by having your plot array be a set size and .pop() and .append() data to it and then plot it (with your x axis being a np.linspace of your y data), or just push a larger array and have it plot only a certain range using splices [200:500]. It's really versatile and I thoroughly enjoy programming with it.
&gt;I looked for wxpython, but the state of this library isn't much better. But what about [wxPython Phoenix](https://github.com/wxWidgets/Phoenix)?
amen to that. For those of you stuck with one of the obsolete dinosaurs, I strongly encourage you to look at developing some sort of data binding framework for it and open source it.
or from __future__ import division
I'm surprised no one has mentioned gtk https://python-gtk-3-tutorial.readthedocs.org/en/latest/introduction.html
And fails miserably for complex dependencies between values. Good for 95% of the cases though. 
See [here](https://www.python.org/dev/peps/pep-0484/) for PEP 484 -- Type Hints.
As far as general purpose GUI frameworks in python go, Kivy &amp; PyQT should be considered the go-to options. When it comes to something as process intensive as plotting graphs at a constant refresh rate, i'm not sure how either would hold up performance wise, but could possibly be considerable tools for your application.
Kivy supports 2 way data binding.
WPF has a powerful hooks system so you can override just the bits you need to. It's dope. And I'm no MS fanboy.
&gt; gtk I never got the hatred python community have against gtk... It seems so easy, produces great apps and is fairly well documented now.... Oh, and it is also multiplataform.
If you are sure, that your configuration will be used only by Python, then I think it's OK to store your configuration in the `config.py`. One thing, that can go wrong, is that your `config.py` can easily turn into imperative code instead of declarative configuration. If there are any chances, that you will need to exchange configuration with other tools in your technology stack, then it is better to use JSON or [INI](https://docs.python.org/3/library/configparser.html).
I would say it depends on the type of desktop app. If you are working with weird hardware (touch screens, cameras, like [this company that uses kivy on desktops](http://www.tangibledisplay.com/en/)), you often work with desktop for performance even when working with this type of technologies. In addition if you are wanting to do something highly visual that would benefit heavily from GL (games, interactive visualizations) it also stands out as a good choice. However, if you want to build a quick gui for a typical data entry app or something else that is heavily in the realm of QT/tKinter/wx/a web framework, there are many tools for building traditional applications and this is not an area kivy has really focused on.
I don't see anything wrong with this. Maintenance might get tricky when you start needing minor variations on your config, but you could get around this by "module inheritance" or the like.
I will say it can be somewhat easy to get yourself in an infinite loop with 2 way data binding in kivy if you bind a transform to one of the datas. I am not really certain if I'd recommend it for many use cases. It requires thinking about how the binding is dispatched to ensure you haven't introduced such a bug. I'm more in the react.js camp on this subject, I prefer a nice one way flow.
The singleton pattern is not needed in Python since you have modules.
YAML! You can't embed comments in JSON. As a rule of thumb, I was told that human writable files should be in YAML. Computer writable files should be in JSON.
Record the name of the function as a string, and have a lookup table to match it to the correct function. You can go a step further and inspect the local namespace (or the namespace of a specific class or module) to find the correct function. 
I prefer using containers like Docker. The entire system can be accessed with only the python version different inside the container.
I definitely see your points, thanks for bringing those concerns up!
Used that for a project during my physics PhD, it was very straight forward to use and the app turned out great.
I wish I could upvote this 10 times. It is _really_ frustrating how it has become conventional to put configuration in Python source files. Configuration should be purely declarative. Full stop. I'll even go a step further and say that JSON and YAML are inappropriate for configuration because they encourage deep nesting of configuration values. It makes a mess of what should be a straightforward concept. All that aside, `ConfigParser`is baked into the standard library. It has some warts but it works just fine. Please, just use it.
For real time visualization I recently wrote something using pygame, that worked out OK. It might be OK if you just need a few simple xy plots.
I usually use it like any other python module. It allows me to use comments and make somethings dynamic. ``` import os import getpass import secrets BASE_DIR = os.path.abspath(os.path.dirname(__file__)) LOG_LEVEL = 'INFO' # LOG_LEVEL = 'DEBUG' # Never accidentally leave DEBUG on in production. if getpass.getuser() == 'production_user': DEBUG = False TESTING = False API_KEY = secrets.API_KEY['production'] else: DEBUG = True TESTING = True API_KEY = secrets.API_KEY['development'] ``` Then I can just `from config import API_KEY` from any other module like normal. I also use YAML from time to time, but I find it's syntax can be a little confusing sometimes and it requires a dependency on `PyYaml`. It also means I have to move some of my dynamic config stuff into another module.
It's not creating a dependency, it's making explicit a dependency already present, but with the benefit of being more flexible later.
I think you might be able to install separate python installs in conda environments too. Though not sure about specifying a 32 bit version. 
There's a difference between "nice to have" and "need to have".
I'm intrigued by this answer. Do you have some pointers on where to start writing a python webapp this way? I'm currently writing a gui in tkinter to interface with my algorithms, but it's a bit clunky.
In order to make sure all the data flows through states, you have to send it all instead of what you need at what time. I like the idea of using a module variable as @yesvee said 
I suppose this would be the best solve.
Another one: Browsers are a terrible substitute for an OS and a window manager.
If the generators don't depend on each other, try threads.
I have made something similiar - I have to log my monthly time spent at work. Because it doesn't have to be accurate, I'm simply logging my uptime. I'm running it automatically on every shut down and when I want to know hours this month, I simply type worktime show --start=01-02-2016 --end=29-02-2016 It could use some improvements, like "just show me this month" or ditching uptime logging in favor of better solution. Feel free to submit pull request, it's an easy excercice for novice and you can make your first steps in open source. :) https://github.com/miedzinski/worktime
&gt;As languages go, Python is not actually all that new. I know. &gt;It's been around for 25 years. I know. &gt;The reason you're having such a great time with it is because it has evolved and gotten better over time. So are you suggesting there are version numbers that come before 3.5? Interesting... &gt;It will be simple, it will be slow, and it will only work on a few devices. I have a few Android devices, including an old Galaxy S3 Zoom which has trouble running some modern Android apps (many refuse to run, but a Kivy game runs just fine). And as I said, the performance is comparable to the other apps I use; it certainly feels fluid and I have a good eye for fluidity (cuz lag makes veins twitch). Nowhere did I say that Kivy or Python were the perfect solution for any and all, but it's a damn good option (it's awesome that it's even an option), especially considering what I want to create or may end up creating is akin to that game and I do so like Python. And yes, I've read Google's advice that even though they provide a NDK, that unless you have a really good reason to, you shouldn't use C/C++. Just in case you assumed I didn't. And of course, I've been reading about the pros and cons of cross platform apps, long before I chose to start 'relearning' Python. Need some very old daringfireball inspired links? (He use to debate the issue all of the time in the early days of the iPhone/Android) &gt;I highly recommend you try As said "but it also means I don't have to learn Java for now (tg)". I.E. for now means I can put it on the backburner. I've actually been playing with it off and on for months at codeacademy and happen to be setting up an environment for it today. &gt;You might find that you like another language. I already like other languages. C is one of them. Go may just as well be another. Thanks to Python, picking up languages that use to seem like trolloc speak is now a lot easier! &gt;so that someone could have set me straight a lot sooner Heh. Well, thank you! I hope I have returned the favor. :) &gt;be open-minded. Indeed! It takes an strange mind to translate the praise of one language as an indictment against every other language. I guess next time I will throw in a few criticisms so that no one else gets the wrong idea. **Edited for clarity. Meaning left intact.**
https://pymotw.com/3/asyncio/executors.html
I love python but you can't ignore the fact that java is a more seriously heavy duty friend for when things get big.
One last thing I want to make super clear. Here's a good article Gruber linked to not too long ago, about the pros and cons of Swift as a teaching language. [Why I Want Swift To Be Your First Language](http://www.aaronblock.com/thoughts/2015/8/21/why-i-want-swift-to-be-your-first-language) At the bottom, he has a section titled "Why I don't use Swift this year". But I would wager a guess that he's not going to use it next year, or the year after. And this is someone who really wants to use it. Simple fact is, he has to deal with the reality of students coming knowing Java (and maybe Python too!). And that reality means that even though he considers Swift the premier teaching language, it's no go. Because the real world can crush the dreams of many a geek, as .doc has repeatedly done to .odt, as Twitter has done to more caring upstarts like App.net, as we see all of the time in the tech world. My beliefs are already that 'best' is a term that doesn't mean much in the real world.
What you're normally supposed to do is make each generator either yield a value you can use or another value to signal "Not Ready". Make that cheap and use threads/event loops/etc to handle the blocking/long call. Generators are best cheap and you can easily yield a value (like a singleton object() or None) to signal "Not ready, call back later" Get an array of generator instances. Each step of the while loop, you iterate over each element and call next() on it if it is not None. Catch StopIteration and Exception, pull return values if necessary out of StopIteration, replace hole in array with either another generator or leave None. Repeat until done. I prefer to start all generators (or a chunk) using next and then use `generator.send(...)` to enable passing data to and from. 
Nice, but Jupyter Notebook really should have a integrated theme selector.
If I may: use YAML... IMHO It's the future of configs...
That sounds ideal but as I said, the generator was written by another team. I had broadly thought of your approach but had not pursued the thought further. I'm very grateful for your detail; thank you. I'll escalate to the other team.
You should write this "Not ready" generator as a wrapper around the generator you already have. No need to involve the other team.
Here is the trick I use: import os def set_from_env(cls): """A decorator to populate class fields from os env""" for k, d in cls.__dict__.items(): if not k.startswith("_"): vtype = type(d) val = os.environ.get(k.upper(), d) setattr(cls, k, vtype(val)) return cls @set_from_env class Settings: debug = False debug_sql = False ... Allows me to overwrite any variable from env, especially useful if you work with docker or heroku or any other system where environment is the main way to configure your app.
So, testing-wise, since the menu runs in a loop to test stuff like user input handling methods I had to spawn a thread anyways. This caused making sure things worked in the proper order to become a giant pain. Putting the threading in the menu class means that the menu can give me a deterministic answer to what state it's in, whereas with the threading in the test code I was relying on just sleeping for a few seconds to make sure the menu had handled processing the input. Another benefit of the threading that I did neglect to elaborate on was that you can adjust things on the fly. You can add items to the menu or change the parameters of the items. My goal was to be simple for basic usage, but have a more flexible backend to support more advanced usage. I'm going to have to think through that a bit more, it should be possible to provide a simpler API akin to what you are suggesting without sacrificing the flexibility that I was hoping to have. And some of it should be fixed by just updating the documentation to better frontload the simple stuff and leave the advanced stuff for later. In regards to the different requirements, curses sets up the terminal in a nonstandard mode that enables it to behave the way it needs to. So there's a couple of different methods I have to call to make sure the terminal is cleared correctly and behaves as expected when running a console command or a Python function that requires user input, hence the ExternalItem class. (And something I did just think of is that I have functions and commands set up where they are always doing this set up regardless of whether they are doing user input or not.) Submenus require the terminal to be cleared and set up slightly different than both this and the menu itself. It's a pain to get those different types of setup right, which is why I felt like I should include it. I will certainly check out that project, thanks!
Yeah, I guess "don't do this". I would write: .... except (AssertionError, ImportError, NameError, SyntaxError, SystemError) as x: raise except Exception as x: # do something with any other exception Still probably not as nice as having a special common exception base class but hey. How often do you find the need for a catch-all type of exception handling? Article talks about "the loop of a server", but I'm fine with adding all sorts of special things to it. You're likely to have only one of these in your code somewhere. edit: you can perhaps clean it up a little like this, by first defining the tuple of exception classes that you classify as 'problematic' ProblematicErrors = (AssertionError, ImportError, NameError, SyntaxError, SystemError) try: # stuff except ProblematicErrors as x: raise except Exception as x: # do something with any other exception 
don't. use. json. for. config. 
Whatever you do, don't. use. json. for. config.
Sure, Python's exception hierarchy could be "better" or lets say "different," but honestly, I think it's not really that bad. I mean, everyone has their special needs and preferences. And before lumping everything into someone's hierarchy of personal preference, why not leaving it as is since it works pretty fine if you are explicit: try: # this except (AssertionError, ImportError, SomeOtherError) as e: # do whatever except Exception as e: # handle everything else # and add more special cases as needed
It's the shell prompt, so yeah. Isn't it in your case? What do you see? Under settings &gt; tools &gt; terminal you can configure the terminal/shell it should use, verify that to see it is correct
&gt; How often do you find the need for a catch-all type of exception handling? I find I need to do this quite often when calling third-party code. I would be interested in your thoughts on this as described in [this comment](https://www.reddit.com/r/Python/comments/46na31/pythons_screwed_up_exception_hierarchy/d06kfvk).
If they are both integers and you want your type system to be consistent, it should be. 
What if you need it to be both human and computer writable?
&gt; That doesn't mean it can't do it. Here's a guy who sped up his code by a factor of 50. It's about learning to call the right functions in the right order. Yes, I read the blog as well and he stated: &gt; The axes in particular are quite expensive. which is the reason, I need 50ms on a i7 processor per plot. 
But where are the binaries for Windows? Windows isn't my choice
Yes, you need the quotes.
&gt;IANAL, but the commercial license is only for companies that don't want to abide by the rules of the the LGPL. Qt is also available under the LGPL license at no cost. If you are using WxPython, you already have to abide by most (if not all) of the rules of the LGPL, so you can almost certainly jut use the LGPL license for Qt. The license really only matters if you are modifying Qt or WxPython. Your comment made me decide to reach out to Qt and ask about licensing. I spoke with a rep today who informed me that we would be able to use Qt under LGPL internally, but if we wanted to sell software we would either have to abide by LGPL (an option we just can't take unfortunately, as much as I would love to as a Linux fan boy) or pay for commercial licenses. It would cost us too much for us to be able to purchase, not because my company doesn't have the money but because it's been very hard to get purchases on that scale in the past. It took us 4 years just to get 2 visual studio pro licenses. Yes, it's ridiculous at times. Yes, it gets in our way. No, we can't do much about it. After we've recently obtained JIRA, Crucible, VS pro, and Anaconda Server, our management said no more software requests for a while. I'm personally just glad for what we have, we'll just have to take an alternative route. That might be using winforms as a front-end through VB or C# with python as our backend, plain old Tkinter, a Web based front-end, or something else entirely. If we were on Linux then I'd use Gtk, KDE, or something similar, but Windows has a very small number of good toolkits available for free commercial use. I understand that good software shouldn't have to be free, like I said earlier I wouldn't mind just being open source and charging for licenses and support like Qt does (noncommercial use for our software is unlikely anyway, not many people have 80k$ of EE lab equipment equipment just lying around), but I know that we won't be able to do that in our industry. 
&gt; which is the reason, I need 50ms on a i7 processor per plot. You did not mention your requirements, nor did you say you tried matplotlib, nor did you say you've spent time working on optimizing your matplotlib code. I've gotten real time plotting at 10,000 samples per second on a 2 year old i5 with matplotlib. It most certainly can be done.
For example, most of your Matlab type needs: http://numerics.mathdotnet.com And a nice plotting library: https://github.com/oxyplot There are always alternatives in the world of computers, some of them having aspects that are a bit more modern ^\*cough ^1990's\* than others. You'll also see much nicer performance than Python, assuming you're actually comparing against python and not C libraries called by Python.
Interesting discussion we have here. There are people who are all up for config parser but again the issue is that every developer needs to create these ini files to run. What do you think about the 12 factor app moto for configs? How do you deal with default configs? And if you wanna store the config in environment variables. 
&gt; Configs shouldn't be executable - it can lead to security &amp; maintainability problems. This isn't a strict rule of course. If the configuration is complex, it can be *very* beneficial to have scripting built in. 
GTK is GT-Okay.
The first major reason to avoid a web app is that a significant portion of your code will be HTML/CSS/JavaScript. The second is layout. It is practically impossible to develop an app with multiple resizable panes without constantly adjusting everything with Javascript. You either write the layout code yourself, or find a JS library that will do it for you. There are very few options, and none of them approach the maturity of a desktop framework like Gtk or Qt. Third is widgets. There is an extremely wide gap in quality in available widget libraries. All of them with force you into different, often archaic (in the scope of JS) APIs and usage patterns. There are plenty of other disadvantages, but for all that the are plenty of advantages as well. Not the least of which is portability. So they have their place, but I still much prefer desktop app development.
If you're running third party code and don't know what exceptions will be raised, that is a red flag that you shouldn't be using that code and it was written poorly. You should find a library that is documented and tested if you don't want to live in debugging hell. 
Buildbot uses python for config files and in that case it struck me as a pretty good idea. It removes the need to learn config file syntax, reduces the needed code for parsing config files and reporting errors, and allows for more complicated configurations when needed. Allowing some imperative style logic in a config file can be convenient. If someone decides to abuse that by creating unnecessary complications that's their own problem.
Excellent! It's been almost two days since I gave up in disgust from the totally broken support for 3.5 - now I only have to fight Windows, and I'm used to that. Edit: yep, working - though I added a `mypy.bat` script to work around the lack of shebang support on windows. Also caught a total of one existing bug in the project I converted, which is something but probably not worth the effort. Much more valuable for refactoring, which is the next project...
He gave me two commands. The first was a simple 'pip install tweepy'. This ran a download sequence until the library denied write access. The second was to clone the github repository. I cloned it, cd'd to it, and the final step was to use 'python setup.py install'. Thats what gave me the message above. Would an API work if in the user directory? Would I just use '--user pip install tweepy'?
What's the load look like? How frequently are they going to call you and what's your uptime requirement? Lots of options but a bit of scoping can help narrow it down. 
Could you perhaps use [gevent](http://www.gevent.org/) as an event loop and have gevent.monkey turn 3rd party code into event loop friendly on the fly? 
&gt; You either write the layout code yourself, or find a JS library that will do it for you. There are very few options, and none of them approach the maturity of a desktop framework like Gtk or Qt. Yes, building your own layout from scratch is a surefire way to spend most of your time designing a buggy interface instead of solving the problem you set out to do. However, there are definitely great layout frameworks available complete with responsive grid systems and components. &gt; Third is widgets. There is an extremely wide gap in quality in available widget libraries. I'm assuming you're referring to jQuery, jQueryUI, its various third party plugins of varying quality, and the spaghetti event code that it tends to promote. Front-end development has matured since that was the norm.
Trollius has been deprecated with the latest release: https://trollius.readthedocs.org/deprecated.html#deprecated
Python is amazing for sure. I'm not sure I would have learned to code without it, it's very friendly for beginners and there's a great community. However as you start to do more programming, you should branch out and learn some other less "exciting" languages. Python's lack of verbosity is a wonderful thing at first but honestly for some things the explicit nature of Java is really, really helpful. As you start to learn concepts like OOP, memory allocation etc. Java becomes incredibly useful. Yes, Python supports OOP but it's really baked into to Java and because of that it forces you to really understand what's going on. This is important. If you ever want to collaborate seriously with other developers the standards and rigour that Java imposes are incredibly useful. By all means enjoy your newfound enthusiasm for Python, just don't think that learning Java is some terrible battle that has to be overcome. I'm saying this because I used to think exactly that and now I quite enjoy writing Java. And anyways, the general programming principles you're picking up from Python will make learning Java considerably easier. Trust me. 
Flask is definitely not the way to go for a static website.
As a vim snob, pycharm is the only ide I've ever used that made me return to the land of the gui. It's the best ide I've ever used. I love it (with vim style typing enabled, of course). Excited to see better type hinting support. (of course all intellij based ides are incredible, but the format seems to benefit python especially well. The debugger is astounding!) 
Unless you need the ide to specifically recognize it as a symlink vs a regular path (which is how it will appear), you shouldn't need to do anything different t than creating the symlink in your shell ln target linkName
Python is not recognized, instslled python-3.4.4 amd64.Msi in windows 10
Echo %date%-%time% In &gt;&gt; C:\ProjectArea\Office-Hours\office_hours.txt Echo %date%-%time% out &gt;&gt; C:\ProjectArea\Office-Hours\office_hours.txt 
I strongly recommend the linux+flask+postgres+python stack as done through [pythonanywhere](https://www.pythonanywhere.com) Super easy to get experimenting and rolling. Edit: One other thing to add. I wanted to respond to other commenters saying they had to reinvent the wheel with Flask a lot. As someone new to webdev, I didn't have the experience at all with Flask, and found it really hit the right spot in terms of abstraction so you can get building. When you need Django, you'll know.
I use Notepad++ for Windows, and Brackets for everything else.
 python3 --version 
I work on different projects on the same company. The company needs to keep track on how much time everyone spends on each project. In the end it is about billing the right amount, and for having data when doing project planning. 
Nice. This should work just as well. 
there’s only spyder and [rodeo](http://blog.yhat.com/posts/rodeo-native.html) which are matlab-like. else you might try a real IDE, like PyCharm.
The other commenters here are right, nginx, Linux, Postgres and Django. I wouldn't go with Flask, it's smaller, but that means you have to reinvent the wheel a lot. I never understood why people use Mongo. Most data is relational, and not having a schema to enforce the relations leads to a whole load of bugs later on. I guess they just see they can avoid migrations at the start and go "oh, nice" and then hate their lives later on.
[But Node.js is bad ass rock star tech](https://www.youtube.com/watch?v=bzkRVzciAZg)
It may not be on your PATH - there's a checkbox for that when you're installing it. If not, you'll have to run it with the full path, e.g. C:\Python34\python.exe If you want to change path to add the directory, there are instructions here: http://www.computerhope.com/issues/ch000549.htm
Qt itself got a more permissive license when Nokia bought it, so you could build proprietary apps without having to pay. However, PyQt did not follow suit. So a competing project was set up called [PySide](https://wiki.qt.io/PySide), which you can use like PyQt, but without the licensing issues. So if you use PySide in place of PyQt, it's fine to sell your application without buying any licenses. The distinction is about whether your code is open source, not whether you make money. So even using PyQt, so long as you open your source code, you can accept donations for it or charge for pre-built packages, with no need to buy a license.
That's Django which isn't built in. 
Perhaps [Whoosh](https://bitbucket.org/mchaput/whoosh/wiki/Home) ? 
Hmm, I'll have to look into Qt again, then. I'd like to make a few more desktop things. So it's definitely worth a shot.
PyCharm 
That is my thoughts on MongoDB too, and I'd love someone explaining it to me.
I meant built into django
Obviously it depends on what you want to build, but I would recommend starting super small with an Ubuntu machine running Flask with SQLite via uWSGI and nginx. Get yourself a DigitalOcean droplet to run it on and you'll be golden. 
I think Mongo would have been a good use case for a documentation web app I helped design. We used Postgres (as with everything), but we have a lot of slightly different use cases, and now we ended up with sparse tables, which is not very efficient. Thus our data was clearly not a good fit for a relational database. Maintenance is now a headache and we are not very agile in implementing new document types without creating a shitload of different tables that are slight variations of each other. I really think Mongo could solve most of our issues for this one project. That said, for 99% of use cases (literally everything else we ever did), Postgres is king (if you really need something high performance, add a second REDIS database for specific cricitical data).
I tried Atom, not as satisfying to use as n++
Relational databases are good for relational data - most data. Document databases are good for things more easily described in document format, like (I guess) a filesystem.
Was developing on Ubuntu, so I like using the same tool on both os
Dealing with types is hard. Consistency makes it easier. Python trying to read my mind does not.
I use both Atom and PyCharm with plugins that enable vim-keybindings. Atom for quick and dirty scripts, PyCharm for any larger project. PyCharms code awareness and auto-suggestions are unmatched and i would not want to live without it.
Sure flask is a microframework but you can use a whole lot of other packages which work very very well with it. You don't need to reinvent the wheel a lot if you do it right.
If you're trying to learn, you're definitely not going to do it right.
&gt; there are definitely great layout frameworks available complete with responsive grid systems and components I'd love to know what they are. I'm not talking about simple grid layouts like you get with Bootstrap. I mean desktop-like layouts, like you get with QMainWindow. The best I've found is [w2ui](http://w2ui.com/), which has plenty of flaws. &gt; I'm assuming you're referring to jQuery, jQueryUI Not just all of those (though, try to see how many JavaScript libraries won't force you to pull in jQuery). Try finding a decent dynamic table widget, like what QTableView or QTreeView offer. There are probably a hundred, most of which solve a minimal subset of use-cases, and usually not very well. I'm not saying good libraries don't exist, but finding them requires a significant amount of research. Even just trying to get started using web dev "best practices" is a nightmare.
That might be true
If your delivering the index itself to the client to search, and your using Python, whoosh is a good choice. On the server you end up archiving an delivering the index to the end user, and then they can use whoosh o do the searching. If you can figure out a good caching scheme, users relaunching your application shouldn't have to re-download the index of it hasn't changed. Con - your indexing on the backend is also going to be done using whoosh. I don't know if that is something you can live with or not.
&gt; Django realm um lol `settings.py`....
No. On Windows the Python interpreter is always named `python.exe` (and `pythonw.exe` for the version that doesn't create a console window) regardless of version. The problem is almost certainly that OP did not add the Python installation directory to their PATH. 
My point wasn't to say that you shouldn't use python files for configuration ever, it's that you have to be more careful and really think about how you want to store everything, especially at larger scale *like* Django (which is what I said). I have no doubt that the Django core developers didn't just arbitrarily decide to use python files, they thought about it long and hard. They have made the tooling to make it work, and that's great. But in my personal experience at work on my company's projects, it's more of a hassle than not. 
I would argue that for someone trying to learn, Flask is perfect. 90% of the stuff that Django has but Flask doesn't is stuff you're probably not going to need on a very first project. The rest can easily be dropped in. Decide you want an ORM? Great, `pip install SQLAlchemy`. Don't know what that is or don't think you need it? It's not there forcing you to think like that then. Plus, the learning curve of Flask is tiny compared to Django.
Never heard of rethink. Will give it a look. Couch was indeed the other option, and will probably win, given we will only do simple querying. But given the question was mongo, I just explained why noSQL can be a good thing and a good use case for mongo.
Spyder and Rodeo are similar. Also, I've written a blog post titled "Stepping from Matlab to Python": http://scottsievert.com/blog/2015/09/01/matlab-to-python/ I use the IPython shell, included in Spyder. I cover tips for this she'll in the post. 
Since my other post was webapp focused, I probbably should have said Ubuntu. I use CentOS for some things mostly because that's what our very first webserver was using on and it has been a very reliable workhorse over the years. Just haven't been given a reason to look at other options. Our office uses Ubuntu for desktops, and I often use Ubuntu Server for Openstack instances (with CentOS as the baremetal OS) depending on what I'm deploying. General rule I seem to follow is, if my focus is on building a low maintenance workhorse, I'll go CentOS, if I'm building a webapp that needs some more bleeding edge packages, and is to be deployed on an instance, I'll normally go for Ubuntu Server. As a side note, its nice to be comfortable with both Debian and Fedora based distros, so do recommend getting comfortable with CentOS
I use JEdit as a general purpose text editor on Windows. I must be weird because I don't know anyone else who uses it. There are tons of plugins for auto-completion, bracketing, code folding, bookmarks, etc. The regex syntax just fits my brain perfectly. I've also used Visual Studio with Python tools and I really like it. The function and method signatures are really helpful for developing Python code. 
Option #5 could be to build a close relationship with a small API dev outfit. Would allow the devs to hit the ground running and take a lot of the guess work/learning out of the equation. if your organisation wanted to work towards having a python dev inhouse they could work on a gradual skill transfer (mentoring/coaching) from the external dev outfit over time.
Somewhat, and these basic relationships can be built in document dbs, but the difference is the lowest level entity (document) could drastically varying content and a relational db record would need to have either a bunch of meaningless flex fields or would only have sparsely populated columns for each row, whereas a document db just creates each entity with only the data that exists for that document.
As someone not too far past the beginner stage, I wouldn't recommend gae, as I found it more difficult to figure out all the magic going on with webapp2 and gae compared to something simple like apache, wsgi, flask and postgres. Although maybe that was just webapp2's fault
Being new to python myself, I've not yet used anything specific for python coding - but I'm a massive fan of both PHPStorm and RubyMine - PyCharm's siblings.
I feel like you misunderstood my question, or there's context I'm missing. 
virtualenvwrapper provides similar benefits, for anyone that would like alternatives.
I usually run Linux + MariaDB + Python + Flask + Apache and optionally a HAproxy in front of multiple stacks like these to terminate SSL and distribute the load. I really like Flask. It makes my life easier and doesn't get in my way. 
At work, we use django + postgresql on the backend, celery + rabbitmq for task handling. We put nginx in front of uwsgi and let aws load balancer balance things. For the front end, we are using react + relay (using graphene to generate graphql stuff on the backend side). Oh and we are using docker + ansible to deploy the apps (sometime soon we want to migrate to kubernetes).
If you're building serious production software, CentOS is the way to go. It is highly stable and lacks the latest features and versions of software on purpose. It is supposed to value stability over features. 
Hey thanks for the response and suggestion. Unfortunately, it's not from lack of exposure that I dislike it. I've been working with CentOS off and on over the past 4 years ( often enough That my brain automatically switches command line instructions at least), and while I definitely won't argue as to its reliabily, I just need more danger in my life I suppose. Drap software really bothers me for some reason
I would imagine that the reason for that is that the generated bindings link against SIP library code which is also GPL. If that's the case, it's not the fact that the generator is GPL that causes the result to be GPL, but the fact that it has to link against that support code. You see a similar thing with GNU projects such as gcc. The code generated by gcc would be under the GPL since it requires and links against the GPL runtime support library libgcc, but libgcc is licensed under the GPL with an additional runtime exception clause which severs this relationship such that code generated by gcc carries no added licensing restraints. 
`pip install --user tweepy` When you have a chance, I recommend learning about virtual environments. They let you install sets of packages without version conflicts or needing sudo.
&gt; Any suggestions for Front-end(for load balancing) haproxy is a swiss-army chainsaw and it will go for a good long time and a very impressive amount of traffic before you need to look at Very Expensive™ solutions. nginx is another good option here as well. This can be a natural outgrowth of using nginx as the web server eventually having nginx make coffee for you in the morning. ;) &gt; cache Varnish for static assets - you'll need to do a lot of configuration and tuning to get this working well with dynamically generated content. This can also be a WAF (web application firewall) level to make some implicit security checks and is perhaps easier to get working than Modsecurity for the task. Don't optimize your app too soon though. This is a rabbit hole you can fall into and never return to complete you application. Plan where you want caching in your application at the start and strap it on when you start to have real traffic. &gt; asynchronous task handling? I have used Celery with flask and the various backends available to Celery. The documentation was really what twisted my arm as it's very clear what you need to do to get it going. One thing I think needs to be mentioned is the reproducibility of your environment. Look at something like Chef/Puppet/Ansible and start using it early and often with something like Vagrant to develop in (we all use laptops now right?). If you can build it in Vagrant, you can almost certainly deploy it to the same flavor distro on another platform with the same scripts. Saving your configuration commands into your SCM also documents the changes and revisions you took on the project.
If that were the reason, we'd all be using Java, which has over 5x the market share of Python. I recognize that everyone has different motivations for writing software, and I don't fault anyone for having the "biggest reach" motivation, but logically you're not going to find rational actors with this as their primary motivation using (any version of) Python.
There's a lot of security, compliance, and control concerns around using 3rd parties. I don't think this would be an option for us.
Sorry, I'm fucking retarded. I was thinking of file metadata, not the actual storage of files. Also, it's "hierarchical"... I think.
Ok. What's the load of the call like? Are you doing a computation per call or are you reporting out a previously computed value? 
Ya, maybe this is the best option. I just worry that maintaining the Python API becomes some undesirable job for our devs. But I think this is still a step forward from our current solution.
&gt; memecached I'm imagining the dankest of caching software. Totally agree on systemd, I'd rather be done with supervisord, pm2, cron, etc and just use systemd, but we're an Ubuntu shop. Only a couple more months before Ubuntu has systemd.
What do you like about the Matlab IDE? As others have mentioned there is nothing identical, but some tools cover some areas of the Matlab IDE better than others. If you say what you feel you haven't found perhaps we can help better. 
I personally find Django's models+ORM to be much easier than SQLAlchemy, both when I was first learning Python and in production apps years later. Add in the admin interface, and I recommend Django, though I see the merits of starting with Flask.
Code generators (like compilers) tend to include chunks of their own source code in the output. That means if you're using a generator under the terms of the GPL, then the output that it generates is also GPL code. This is different from, say, a text or image editor, where the content that a user generates with it doesn't include any source code from the editor that made it. It's entirely the user's content. This is why programs like [SWIG](http://www.swig.org/legal.html) explicitly say: &gt; When SWIG is used as it is distributed by the SWIG developers, its output is not governed by SWIG's license (including the GPL). SWIG's output contains code from three sources: &gt; &gt; - code generated by SWIG, which is not governed by copyright; &gt; - code copied from the SWIG library which is permissively licensed to be redistributed without restriction; &gt; - code derived from the user's input, which may be governed by the license of the code supplied by the user. The [GCC Runtime](http://www.gnu.org/licenses/gcc-exception-3.1.en.html) has similar terms, allowing you to use GCC output in your non-GPL programs. If SIP copies parts of itself into the output, and if there's no special linking exception in the SIP license, then they're only reminding you of a consequence that's already true, but which you might not have realized.
Sure you can. You're telling me you've *never* gotten a loader error from a C program? The source code won't look exactly the same, because there's no static compiler for Python, and that's a contrived example anyway. Things I've seen in C#, off the top of my head: - You've got a database table using STI, and somebody inserts a record which has a type column that doesn't exist. The (type-checked) code loads the record, tries to load the class, and fails. - You've got a dynamic mapping configuration file that has the name of a method, which your (type-checked) program tries to load at runtime, and fails. - You've got code that uses reflection, and your refactoring tools weren't clever enough (by being AI-complete, or solving the halting problem) to realize that a string literal had a method name that also needed changing. Your (type-checked) program tries to call a method at runtime, and fails. - You've got some code that uses "object" or "dynamic" or whatever, and your (type-checked) program tries to cast it to some concrete type to call a method on it, and fails. In static languages, for any non-trivial program, you still need dynamism for lots of things. It's just that instead of calling things directly like any normal function call, you have to wrap them in dlsym() calls and java.lang.reflect imports, and put them in unchecked places like XML files and databases. 
While your points are sound, in almost all these cases, you have to: a) Go out of your way to skirt the type checking. or b) Change the environment after the compilation step to break it. I think that's different then the kind of freedom python gives you when you write "normal" code without relying on implicitly unsafe features. If you use ```dlsym()``` or reflection and it blows up, you ought to have known what you were doing. Same thing for ORMs (and the likes) that generate code/objets based on DB definitions / XML files / etc. that can change at run-time.
I completely disagree. He states that doing try: &lt;code&gt; except Exception as e: &lt;exception management&gt; is bad because it hides exception like SyntaxError or ImportError. But... no. I WANT to catch all exceptions (including those two), because I don't want my program to stop for any reason. An my exception management code will take care to save the traceback text somewhere I can read it. The Python's exception hirerachy is fine to me.
Can I ask where you're located? When I first started building web apps (in Michigan) mysql + apache + mod_perl/mod_wsgi was what everybody I knew used. Now (in the bay area) it's always nginx and postgres, which seems to be the more common recommendation throughout this thread. Not sure if this is a function of time or geography or what...
You can sign up through [this link](https://m.do.co/c/5270ab86929a) to get $10 credit for trying out DigitalOcean. You get the $10 after you deposit $5 of your own money, IIRC. It's open to anyone, not just students. Their smallest plan is $5 per month, so that's a lot of development hours. Plus, you can spin the image down when it's not in use, to stretch that $5 very far.
Switzerland.
PostgreSQL also can replace mongo on the non-relational side too, and generally performs better at the same time. If your not using postgresql, be it relational or non-relational, you probably have uncommon or exceptional types of workloads and scalability issues. And if that's the case, just picking something without empirical tests to support a decision is probably a huge mistake. 
I'm a long time Ubuntu and Debian user on the desktop (since 2005), and that's what I use at servers as well. I picked up Django last year, "Tango With Django" is a great tutorial. People say Flask is simpler, and it probably is. But Django does much of the scaffolding for you. For databases, I tend to use SQLite whenever possible. Even websites. It's perfectly fine for most sites, who won't see more than 100k hits per day or so. Just pick something and start building stuff. One year from now, will you look back and think, "shit, I've should have gone with Apache!"?
[PEP 0404](https://www.python.org/dev/peps/pep-0404/#official-pronouncement) says: &gt;Because maintaining multiple versions of Python is a significant drag on the resources of the Python developers, and because the improvements to the language and libraries embodied in Python 3 are so important, it was decided to end the Python 2 lineage with Python 2.7. Thus, all new development occurs in the Python 3 line of development, and there will never be an official Python 2.8 release. Actually nowadays any large product is usually deployed in the cloud within Docker containers and this is not a big deal to just use Python 3.5.1 image in the container to run pure Python 3 code within it. Currently our team is building a mobile banking product and we have a few services such as a Flask app, Celery worker services and services based on aiohttp. We're moving forward to replace the most Flask/Celery stuff with the services based on [aiohttp](http://aiohttp.readthedocs.org/en/stable/). I want to serve some API with high RPS rate and just build a service with aiohttp and aiopg and don't need to write some Flask+Celery stuff. Also I don't need to use Twisted or Tornado because I have native asynchronous syntax out of the box. If some my service just can't live without some Python 2 (only) library I would deploy it in the container that's using Python 2.7+ and that's all. But as the main Python version we use Python 3 for almost all our services. Wait a little bit and aiopg will bring an ORM, aiohttp will have high level OAuth and RESTful middlewares and so on. And eventually you'll never need to invent the wheel with Flask/Celery/WSGI to overcome the WSGI's blocking nature. And I believe this day would come much earlier than 2020. 
Thanks. I'm not really invested in Glade. I designed one UI partially, and didn't even spend an hour on it, just learning the complete basics. PyQt sounds like a viable option, I'll just have to see whether I want to license my code under the GPL (and, more importantly, if I actually manage to do anything worth releasing). PySide sounds like it gives more freedom in terms of licensing, but no official support for Qt5 yet. I think I will give PyQt a try in the week. If it's simple enough, I'll probably stick with it. It looks better documented than GObject. Plus, WebEngine sounds nice.
You need a (team of) data engineer(s). Most of our data science happens in python, some java and some c. The scheduling and monitoring of all of that is owned by data engineering (mostly using aws tools, running python or ruby "control flow" code), and then the online service access of predictions or scores or whatever is owned by data engineering (run on cloud instances co-owned with dev/ops) and mostly java with a bit of ruby/golang/python. This separation of concerns allows data science to be productive generating new ideas and iterating on them while data engineering focuses on building pipelines to easily productionalize them.
What do you prefer instead? Debian stable and Ubuntu LTS are both good choice in my book, but depending on what it is that annoys you about CentOS, they might not improve upon it.
Don't use Mongo. 1gb ram usage for 5 lines of text? Zero security? Shitty ACID? Want something easy and stable use redis . It's nice to deliver app before schema is finalised. Then you can use redis for cache and sql for stable and consistent schema
"recol" is fairly full-featured index/search tool. It's an end-user app but maybe has hooks for external use.
In the future, r/opensource is probably better suited to answer these questions.
But you also actually learn by doing it wrong, rather than having it done for you. 
Presumably on your Mac numpy is linking against one of the BLAS and LAPACK linear algebra libraries while on your desktop it's not. Try installing ATLAS or even MKL with the latest conda on your desktop, reinstall numpy making sure it's linking against on of those and then compare again.
The question was specifically for a text editor pycharm is an integrated development environment.
1. why do you shut your computer down instead of putting it to sleep/hibernating 2. doesn't your os wait for applications to close before shutting down 3. honestly this is a three liner in a more appropriate language…
If I encounter an unexpected error in production, I want to stop my program immediately and print a traceback. Phone calls from the users that the program is not responding are much better than mysteriously missing/corrupted data.
I use an Excel workbook that I place in the same folder as the .py script, and use Pandas to read the configuration parameters. You can use formulas, insert comments, use data validation. Example: import pandas as pd xls_path = os.path.dirname(os.path.abspath(__file__)) params = os.path.join(xls_path, 'parameters.xlsx') xls = pd.ExcelFile(params) # import stuff into dataframes some_data = xls.parse('sheet_name')
1. I prefer shutting it down completely. 2. Apparently no. 3. Really? I think it's short enough like this too.
Nice tip! Are images free to create and store? I've been using vagrant to solve this problem myself.
I would argue that it's a mistake to use sqlite for development. The thing is, once you've set up postgres on your local machine (which takes 5 minutes on Debian at least) it just works. If you start making even moderately sophisticated use of your database and are running sqlite locally and postgres for production, you'll run into problems where the two behave differently, and this can lead to very hard to debug issues. Sure, managing your local postgres database requires a little more know-how, but once you've learned to use postgres well, it's actually easier and more convenient than sqlite. sqlite is good for total beginners who aren't writing production code, and is good for applications that need to be distributed with their own small scale database program, but it's not really a good choice for development of real web sites.
Awesome, thx!
You mean a NPPL stack. ^^Hehe, ^^nipple.
2) i don't mean you make ff close faster. it's gonna be slow. i mean make os wait for it to close. 3) off the top of my head it's literally 5 lines of code in, say, ahk, which will take you 30 minutes to write including learning ahk itself. and, that's just 3 files including 2 icons..
PyQt actually allows you to use several of the most popular open source licenses for your code - they add [an exception](https://github.com/Werkov/PyQt4/blob/master/GPL_EXCEPTION.TXT) to the GPL which relaxes the requirements a bit. This often gets overlooked when Qt licensing is discussed.
haha thanks man. the problem is solved on stackover flow. You can take a look here. cheers. http://stackoverflow.com/questions/35509345/numpy-array-set-ones-between-two-values-fast 
I assumed the linking you speak of happened automatically. Thanks for the suggestion, I'm trying it right now!
Thanks for the suggestion. Is conda the same as anaconda? I searched through the AUR and it only showed anaconda.
It should work for appending to the file (If you change the file path, of course), but on Linux you could simply do: echo "ON $(date)" &gt;&gt; ~/office_hours.txt instead. And to replace the bat files and registry tweaking, you can setup a systemd service that runs that line on startup and another for "OFF" on shutdown.
100% agreed.
&gt;I wouldn't go with Flask, it's smaller, but that means you have to reinvent the wheel a lot. I agree for a production system my personal preference would be django. But as a beginner starting with flask would be best because in my opinion re-inventing the wheel is 1. a great learning process and 2. helps you appreciate all the work django actually does for you and understand how it is doing it.
I've never used AHK but as I can see it's Windows-only. I use Linux... On the other hand I've already used PySide and I know Python so it was natural to use them.
Conceivably, you *could* catch these at import by using `sys.metapath` and loading something like fuckit in there. I'm not saying you *should* but it's possible in theory. 
That's... unexpected! I assumed that the lower clock speed and the lower TDP of the laptop's CPU result in lower performance compared to a desktop grade CPU. But it looks like you are right! 
I used Uneddit to get back /u/Needsmoretests comment that he deleted, since it is helping me and probably others: &gt;There's nothing wrong with asking questions about a specific language but there may also come a time when a question may have nothing to do with an individual language. After all, a programming language is meant to be a means for a human to make a machine perform some kind of work and beyond that comes the science and engineering. For some of those questions, there are some subs that might be of use: &gt; - /r/learnprogramming &gt; - /r/AskProgramming &gt; - /r/CS_Questions &gt; - /r/AskComputerScience &gt; - /r/cscareerquestions &gt;But a lot of computer science is also about research. I've found these subs to be be good places to start. It's not comprehensive by any means but these might lead you to uncover other useful subs too: &gt; - /r/ProgrammingLanguages &gt; - /r/algorithms &gt; - /r/compsci &gt; - /r/math &gt; - /r/crypto &gt; - /r/types &gt; - /r/netsec &gt; - /r/ReverseEngineering &gt;This is just my short list, I'm sure others both here and on those subs will have good suggestions too if you ask. Some of them are more strictly moderated than others so always be sure to read the sidebars first before posting. &gt;Finally for those who are new to programming, welcome. To those who are returning or are finishing up their schooling, congrats and keep it coming. To those who are lifers in the field I have no words besides keep being cool.
Let us know how ti turns out! I'm very interested in the result. I had a similar situation with MatLab where my quad-core i7 was running slower than my MBP's dual core i5 for some image processing stuff. EDIT: spalleng
* JSON doesn't allow comments * JSON doesn't allow trailing commas, so there's lots of opportunity for error when making a list longer or shorter * JSON only accepts double-quoted strings, and barfs on single-quoted ones -- another opportunity for things to go wrong * YAML has less visual clutter than JSON. The big two reasons for this is that neither keys nor values need to be quoted, and that its indent-based blocks don't need opening and closing braces.
&gt; I assumed that the lower clock speed and the lower TDP of the laptop's CPU result in lower performance compared to a desktop grade CPU. The lower TDP is because it's 22nm vs 32nm and as I said one architecture generation ahead. Plus your I7 would increase its operating frequency to 3GHz or more via Turbo Boost under load, and that part obviously is not included in its usual TDP specification. Also, it's more of a "server-grade CPU with lowered base frequency so it can be used in notebooks" vs "cheapskate desktop CPU" thing actually. Apple notebooks cost a lot for a reason. Which sort of brings me to a general rant about how to buy CPUs or other hardware. Required reading: [Joel Spolsky explaining market segmentation](http://www.joelonsoftware.com/articles/CamelsandRubberDuckies.html). Now with hardware components it goes way further than that: not only you pay the "rich guy" tax when buying some $1000 CPU (which is not anywhere near 5x faster than a $200 CPU), but you also pay a poor/miserly tax when buying below the peak of the efficiency/price curve. HDD prices used to be a perfect example of this (they are confounded by SSDs and technical issues these days). Like, if five years ago you looked at the price per gigabyte of storage, you'd see a very nice one-hump curve: you get most kick per buck from something like 1Tb for $150, 4Tb would cost around $1000, and if you only have $50, you are offered a selection of 120Gb HDDs, which were ripping you off in terms of Gb/$ way worse than the high-end models. This is because low-end hardware is not actually former high-end hardware that got stale on the shelves. It's _new_ hardware purposefully produced by the same manufacturers to shear the people who are greedy/poor/miserly. With CPUs it's actually really obvious how that works. Intel designs a good CPU with all of its stuff fine-tuned for best performance. A lot of the CPUs actually made have defects, maybe some part of the cache doesn't work, maybe some arithmetics units, maybe it can't be Turbo-Boosted, stuff like that. Instead of dumping those defective CPUs into a landfill, Intel disables a bunch of stuff that is usually broken like that and markets the result as an I5 series CPU instead of the original I7. They don't have separate I5 production lines, you see. Now that I5 doesn't have any bugs, those defects sit in the safely disabled parts of the chip. But it really sucks compared to the original fine-tuned I7, like being 2x-10x worse, maybe more, but Intel still sells them at like 30% discount because there's a lot of suckers who'd buy them because "it's like the same clock frequency but way cheaper, man". (yeah, I'm still sort of butthurt about my experience with their Celerons from early 2000s, it was as close to a scam as you can get without actually getting sued.)
Thank you, that was what I suspected and meant with my tentative edit.
I'll most definitely let you know! First, despite of the fact that it's a laptop CPU, the Mac's i7 is slightly faster than the desktop's i5, as measured by popular benchmarks. However, that doesn't explain why it's a whopping 6-10 times faster! So it turned out that when you install `numpy` using `pip`, it doesn't handle library dependencies outside of the Python packages. So when you don't have fast libraries installed, it will revert to something slow AFAIK. I first installed a precompiled version of ATLAS using `pacman`, which resulted in a significant improvement but it was still 2-3 times slower than the Mac. Next, I compiled ATLAS from source by downloading it from the `AUR`. This is an important step because it's the only way to introduce platform and CPU specific optimizations, hence the name ATLAS (Automatically Tuned Linear Algebra Software). Now I finally have the performance I was hoping to get! The desktop is about 20% slower than the Mac, which is what you'd expect when looking at CPU benchmarks. I learned a lot today :) EDIT: I updated the original post.
&gt; I don't want my program to stop for any reason. What should it do instead of stopping? It doesn't specify anything just to say "don't stop"
Especially while testing. If you wrote your code to swallow exceptions, you are going to totally miss the presence of many bugs and have extreme difficulty debugging why things behave as they do given that you will have swallowed exceptions constantly messing with the control flow.
Anyone who has used ConfigParser in anger would not describe the emotion it generates as "love"
still better than ConfigParser, and it's very standard so it's at least easy to convert out
You da real MVP.
Thanks for the insightful writeup! I had no idea that i5's are just i7's with disabled/defective parts of the chip. Just out of curiosity, since you mentioned that the CPU's Apple builds into their laptop's are server-grade CPU's with lower base frequencies. What, aside of a larger cache, distinguishes server CPU's from ordinary CPU's? And why would Apple use expensive CPU's, when most consumers aren't aware of the difference?
Kate. Even better is KDevelop (a full IDE), since it has semantic highlighting in addition to syntax highlighting. If you can't conveniently get Kate, try pycharm. It's what I use in our rather locked down environment at work.
This is really cool. 
LPT: I gave up on building ATLAS after fighting with it for hours. No amount of meddling with my CPU throttling worked. I ended up just `sudo apt-get install libopenblas-dev` (on Ubuntu). Way easier. You don't have to do anything after installing openblas, as it will automagically become the default BLAS on your system. Just recompile numpy and you're good to do.
This is completely unrelated to the OP's post, but I just had to say I haven't heard any mention of NASTRAN since I worked at Cray Research 21 years ago, where we had quite a close relationship with the MacNeal-Schwendler Corporation (apparently now they're just MSC). What a blast from the past!!! Sorry for the interruption...
Bill-able hours are the bane of my existence.
[Thinkful](http://www.thinkful.com) has a few good tutorials.
Wow, I don't see answers of this quality on Reddit very often. Well done.
What's the problem? The syntax is simpler in matlab. If you're not working with strings/OS processes/web work, matlab's syntax is much more concise.
26, and it is about how many years you've been using Python rather than someone's age. It took me 3 years of intensive use to realise that Python is indeed just a tool (after thinking it is the only way, heck I even went and created http://python.inthenews.io). 
Ah, thanks, I wasn't sure where to post. Since it is Python software, I thought it would be in topic enough.
Thanks for the great explanation! Any way I could easily tell if SIP does this?
Emacs Evil Mode with code completion plugins anaconda mode using the company backend. Simple, works great, no fuss. I had non-stop issues with vims plugins, but Emacs works like a charm starting from Day 1 switching. Definitely a great configurable environment.
Yeah, another one of my businesses works in the online financial transaction space and experiences some challenges involving 3rd parties, but its not impossible and can be rewarding. Assuming we're not talking about security through obscurity here, instead of having the 3rd party work &amp; deploy direct to your environment, you could have the 3rd party work in their own dev environment and contribute works to a private repo, where you would have your inhouse python person vet review and Q&amp;A the commits before bringing them inhouse.
That's also true, but I prefer: 1. Go with something that does all the work so you don't get frustrated by all the reinvention. 2. Go with something that does none of the work so you can see how the lower levels work. 3. Go with the first thing for production.
That is like someone asking for a seat and recommending a car because it has seats in it.
I'm the troll? I just read through your past comments for others. Each one is sarcastic negative trash. Look in the mirror. I'm having nice conversations on here. And you're being an asshole in every thread you're in. 
numpy is compiled c code, should be very fast and comparable to matlab. Python does have the gil but some numpy functions take advantage of BLAS which allows for multi-core operations. Then there's also numba to help with parallelizing your code for both cpu and gpu. &gt; NumPy gives us the best of both worlds: element-by-element operations are the “default mode” when an ndarray is involved, but the element-by-element operation is speedily executed by pre-compiled C code. http://docs.scipy.org/doc/numpy/user/whatisnumpy.html
If you are happy with Sublime, why change? If you want a full IDE, try Pycharm. &gt; And why all people use Linux instead of Windows You want the development environment to match the production environment. Otherwise it is harder to test and debug. If you're building a website and hosting on Linux, it then makes sense to develop on Linux.
A python module actually IS a singleton, initialised on first import. I personally think it was a design mistake but it's too late to fix it now.
The expected or default behavior of any mathematical operation of two objects with the same type is to return that type. That's not "C logic," it's just common sense. You want a special case for this one thing and so do the Python devs. I think it's nuts and goes against what makes Python the most usable language: consistency. 
This is great. Free? I can't tell you how much time I've spent just trying to get mod wsgi set up on apache. I mean, it's well documented but pretty complicated. I was never sure I got it to work so I stopped before I even started on flask.
Geez man, you can't just compare an apple to a honey cookie! 
&gt; Plus your I7 would increase its operating frequency to 3GHz or more via Turbo Boost under load, and that part obviously is not included in its usual TDP specification. It actually is. Quoting from the [Intel 4th-gen Core series datasheet](http://www.intel.com/content/www/us/en/processors/core/4th-gen-core-family-desktop-vol-1-datasheet.html): &gt; If the power, current, or thermal limit is reached, the processor will automatically reduce the frequency to stay within its TDP limit. Turbo Boost basically plays within the headroom between actual operating conditions and design maximums, mostly on power and temperature. Officially there's a time limit to turbo operation and lower maximum clocks depending on the number of active cores, but both of those can be disabled by the firmware and generally are by default on enthusiast-targeted desktop platforms. Laptops of course tend to be thermally constrained. &gt; Also, it's more of a "server-grade CPU with lowered base frequency so it can be used in notebooks" vs "cheapskate desktop CPU" thing actually. Apple notebooks cost a lot for a reason. I like my Mac as much as the next guy, but come on. It's an i7-4750HQ, a standard Haswell mobile part. The desktop i7-5xxx parts were Haswell-E and were basically overclockable versions of the Xeon 16xx-v3 line, so you could call those server-grade, but Apple isn't putting anything special in the Macbook line. &gt; Now that I5 doesn't have any bugs, those defects sit in the safely disabled parts of the chip. But it really sucks compared to the original fine-tuned I7, like being 2x-10x worse, maybe more, but Intel still sells them at like 30% discount because there's a lot of suckers who'd buy them because "it's like the same clock frequency but way cheaper, man". Here's an i5 4690 (2.5-3.9GHz, quad core, 6M L3, 84W TDP) versus an i7 4790 (2.6-4.0GHz, quad core w/ HT, 8M L3, 84W TDP): http://anandtech.com/bench/product/1198?vs=1199 2x worse is the worst case scenario which occurs on only two tests out of dozens. The majority of the rest (including almost all gaming benchmarks) are close enough as to be pretty much entirely attributable to margin of error and clock speed. The i5 even manages a slight lead in some of those tests, further demonstrating the margin of error since on paper the 100MHz clock difference means it should always be at best slightly behind. We're not in the Pentium 2/3/4 era anymore. i7 vs. i5 is nothing like Pentium vs. Celeron was back then.
It means that: def f(): """Yay!""" d["foo"] = "bar" becomes: def f(): u"""Yay!""" d[u"foo"] = u"bar" on Python 2. Which in this case sucks for 2 of the three strings (you usually want your docstrings and dict keys to be native strings).
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
That's a bit extreme. Generally speaking, any Python code can raise any exception. That doesn't mean you should catch every exception though: normally, any unexpected exception should be allowed to print a traceback and halt, or be caught at the very top level of your app, to be logged then halt.
just tried it again....doesn't support frames. Annoying.
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
Right, because no one ever calls C/C++ code from Python. [Ever.](https://github.com/tensorflow/tensorflow)
https://inventwithpython.com
I disagree. Numpy **is** C. When you call numpy functions, it calls underlying *highly* optimized ATLAS routines that are implemented in C or Fortran. But generally speaking, you're right. If you'd create your own for loops to do linear algebra, then Python is painfully slow.
For experienced, ubuntu django nginx uwsgi postgresql celery redis angularjs Redis is for both django to cache and celery to queue and save results. For unexperienced, ubuntu flask nginx gunicorn sqlite conqueue redis jquery In this setup conqueue is the async worker and redis is still used for cache and queue.
Not my personal favorite, but Reddit (yes, the website you're currently reading this on), Instagram and YouTube all run Python on the backend. 
How do I know when to use this in my python code? In my pandas code to be specific. 
I made [https://github.com/asalt/filegrouper]&lt;this&gt; the other day to take files from one folder and sort them based in an input regular expression into separate files in another folder. Was pretty nice watching a few hundred gigabytes of files automatically moving into external storage in an organized way. 
A software vendor did a really horrible job of building their software. Every day there'd be maybe 10 different requests from internal customers that had to be filled out by our operations team. Each took maybe 6-10 minutes to complete because you had fill out a bunch of forms on the vendor's crappy UI repeatedly with a bunch of specific data. I automated it with python and built a form with django/angular so that our operations team could just paste in a server name and click submit. 30% of the time they also had to select a dropdown for a non-default "template" for the form (in the background, the correct information was discovered through other data sources and filled out depending on the template). It was almost instant for them, and the operations team loved me for it. From there, I moved on to automatically resolving common problems with this software that's installed on thousands of machines and fucks up periodically, causing internal customers to open issues because it breaks their access. Instead of deciphering user complaints, finding out what's wrong, resolving, and verifying, they could again paste a hostname into a form and a task would kick off in Celery to login as whichever of our test users that most closely emulates whichever user is making the complaints, discover problems, collect info, and possibly resolve the problem automatically using a second account if possible.. otherwise it would just report all of the data about what was wrong and what all of the key indicators were to the operations team to more closlely pinpoint the problem and resolution for them. They liked that one even more.
In my experience, numpy linked to openblas is about as fast as Matlab (which uses a BLAS library called MKL). You can also use MKL with numpy, but MKL is not free. Other operations are not governed by BLAS, such as elementwise operations, and they too are as fast as Matlab in numpy. You can use other Python tools to parallelize them, such as numexpr, thus surpassing Matlab's performance. Python performance in things like string handling - i.e things that are not linear algebra - will almost always be better than Matlab's, by a large margin.
In numpy you want to use a 2d array for a matrix. See here: https://docs.scipy.org/doc/numpy-dev/user/numpy-for-matlab-users.html
I found MATLAB to be slow compared to numpy. Did you definitely set up numpy correctly? Also, parallel can be fine with Python if you do it right (I've got no idea what's available to MATLAB because I ditched it as soon as I saw the price tag and performance numbers, but I guess the situation is better...)
THIS IS A TROLL ACCOUNT DON'T BOTHER COMMENTING
I built a Skype bot that returns Schwarzenegger quotes. It also keeps a database of some stuff. Other things: a healthcheck for some internal systems. A stupid service manager for Windows. A tournament-manager app i never finished. A website showing celebs' heights (was very tempted to launch it, was eventually put off by maintenance prospects). A mass-loader of data in some proprietary system. A reminder to stand up from my desk every hour. Xml parsers of all sorts. The list goes on and on...
Good stuff. Basically https://docs.djangoproject.com/en/1.9/topics/performance/ with some good notes and things. It could also mention `django-cacheops` as caching library, I think Johnny Cache is slowly dying. And something not mentioned: correctly using the storages (like with image uploads and thumbnails). There are some patterns that make django fetch the images and decode them for height/width, or do other checks at the storage. When using disk or remote storage this will kill your response times. Django has option to cache the height/width, use that if you need this. Also make sure your storage module doesn't need to access the storage or extra database info to generate URLs. And another thing: use the fact that django runs as a process: you don't need to fetch everything all over for every request. Like your main site config data (titles, menus etc); every request needs it and it doesn't change that often so you might as well keep it around a little while (seconds/minutes). We don't worry to much about slightly stale data: you'll have so much caching all over the place that you need to handle stale data anyway so having some ORM object stick around is not a big deal as long as you don't re-save it. Also since we'll be holding on to it we now just pull the whole core config/setup data structure at once instead of micro optimising per view.
Do you mean this? https://github.com/EliotBerriot/lifter I don't know how fast it is (never actually tried it), but i know evaluation is not lazy so each filter is basically a loop through the set. And like the readme says, it's basically just syntactic sugar, nothing too magic. Tbh, if you find yourself doing lots and lots of filtering, you might be better off with a database, even just sqlite.
I'm curious about your while loop. Shouldn't it be more like: for msg in slow_generator(target1): do_stuff(msg) although I guess that's irrelevant for your problem. (The answer to your problem is probably threads or asyncio, as others have said.)
At least it is [https://www.youtube.com/watch?v=b2F-DItXtZs](web scale).
weird. I've used vi on a shell to edit huge multi gigabyte data files in a flash and in general vi has been the fastest edit for looking into big files (hundreds of thousands or millions or lines)
It's a simple concept, really. Just a console window that prints a name, and asks if it should be accepted.
Be fair, this is Python. Almost any function call can raise almost anything. That's just the cost of a language where nearly everything can be overloaded and the compiler doesn't prevent you from shooting your foot off. Would you believe len() can raise SyntaxError? py&gt; class X: ... def __len__(self): ... return eval("1 +") ... py&gt; len(X()) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 3, in __len__ File "&lt;string&gt;", line 1 1 + ^ SyntaxError: unexpected EOF while parsing 
I would love to see the code for this, is it open source?
I wouldn't use REST for that. This is a problem that screem "use the WAMP protocol". Indeed, if I undestand well, you got code you want to execute remotely, which is what we call RPC (remote procedure call). REST can be used for RPC, but that's definitly not the best option. Using WAMP (with something crossbar.io for the router and autobahn for your client) will give you a very clean and simple RPC system that will work in the browser, outside of the browser, from C# to Python, from Python to C#, etc. It's very fast, it's real time, it uses websocket (so basically you can use it everywhere you use HTTP) and best of all, it adapts to your programming language: if your code gives you an error in the remote procedure, it's propagated to your local code in the form the most suited for your language (e.g: an exception for python). Other cool stuffs : - you need only to know the address of the router for each client, no need for each client to know each others. - if you ever have to add another language to the mix, it supports JS, PHP, Java et C++. - next to RPC, it has PUB/SUB (broadcasting events to all clients). - it has safety features embeded, encryption, load balancing, etc. - it's open source, and WAMP is an open standard. - you can swap clients on the fly. - BUT you don't have to use any complicated feature by default. Enjoy.
I built [OctoPrint](http://octoprint.org) in Python ([Github](https://github.com/foosel/OctoPrint)), since I already had played around with Python in the past and knew it to be a solid language with very good library infrastructure and some nifty language features that make for getting good results in a speedy way. That project has not only solved a huge problem I was having when I started it (remote controlling my 3d printer via a web interface), but also since then has turned me from a mostly-Java dev into a mostly-Python dev, and thanks to an [awesome company](http://www.bq.com) also has me working on it as my full time job. Python has really allowed me to do some very cool stuff in that context, and I'm not sure OctoPrint would be where it is today if I had used a different language considering how that language enabled me to solve problems. Also I've learnt an epic ton of stuff about the language over the past years (with constant "that's possible? That's so neat!"), and I hope I've finally gotten to a point where I'm no longer writing Java in Python but real Python instead ;)
high end editors like Atom or Sublime support extendion by plugin. There is probably already an Atom plugin for this. Have you tried google docs? As a cloud editor it autosaves every keystroke and can sync with the local file system.
Programme = british tv Program = computer code
check out numba if you require even more speed
There's [Sigma.js](http://sigmajs.org/). Matplotlib and Plotly are the things you can have a look for in Python.
graph-tool is work looking at: http://graph-tool.skewed.de/
Your .values explanation is incorrect. 1) the query is not executed when you call filter, it is executed when you attempt to get field values from an object. 2) the select statement is the exact same for either situation - Django doesn't do a Select *. The Django Docs state the the performance increase that comes from .values() is because you instantiate a dictionary and not a Django Model. The speed improvement therefore is marginal. 
There's a tool called thefuck, which lets you auto-correct failed bash commands by just typing 'fuck' into the command prompt. It's awesome. 
Thank you. I think it is just trying to get into it and getting frustrated. Should ofcourse have googled it first.
Another JS option is [Cytoscape](http://js.cytoscape.org/).
youtube-dl (program to download videos off of like, 30+ sites) and livestreamer (program to view live streams in vlc/mpc/etc, supports like, 30+ sites as well) have made media watching an amazing thing, no more having my browser constantly open to watch a video! Eve Online uses a bunch of python for their client (not for the whole thing, but a notable portion is just python)
I'm not saying it's wrong, it's just weird to do that inside a `while` loop. Calling `next()` inside a `while` loop is exactly what a `for` loop does.
Lol i did the same thing...
That's amazing, do you have a source
Could you clarify for me: was the issue that you had specific to a Windows installation? I'm a scientist, working exclusively in Mac OS X, and managing my install via macports. Will I have automagically got the optimised linear algebra solvers? Or is this something I should really look into?
Well, if it's not in focus, nothing's getting changed then is it? What's the point of saving then?
Dragon can write in a file even without it being in focus :)
You're absolutely right :) Fortran is what I'll learn next! I heard the native support for multidimensional matrices makes it pretty awesome for numerical stuff
I'm a (future/wannabe) scientist too :) The issue was specific to a fresh Arch Linux installation. Mac OS actually comes with a highly optimized BLAS library. To be sure, you can always run `numpy.__config__.show()`. On my Mac, there are entries for both `blas_opt_info:` and `lapack_opt_info:`. If you just use OS X and you're not planning to use anything else, then you're probably good. But if you ever want to use Linux, then this is something you should look into. I've summarized my results [here](https://www.reddit.com/r/Python/comments/46r8u0/numpylinalgsolve_is_6x_faster_on_my_mac_than_on/)!
sounds like a worthwhile project
&gt; Can I put packages in the repos folder? All your examples are just .py You need a plain `.py` file for the auto routing and the callback to work, so that octohook knows what function to call once an event arrives. From this file you can import whatever you want :) You could add a module to that directory and import it from the file, or you could add your package to `requirements.txt` and install it via pip. &gt; Any issues with it using enterprise github? I haven't tested it, but it should work. &gt; While DEBUG mode is enabled, will this whole thing work with NO secrets on the github webhook, and NO secrets set in the env? Yes! If you are planning to use docker-compose to deploy it, just add `DEBUG=True` to the environment in `docker-compose.yml` and you are good to go. 
sidebar --&gt;
&gt; I'm 4 weeks into learning Python, 6 months into my attempts to understand computers as a whole. And **I'm floundering.** At almost 30, learning my first language is the most difficult thing I've ever done. Why? What's going wrong? 
I had a fun time using forbiddenfruit and giving all lists/sets/generators/iterables various methods to do something like that `[1,2,3,4,5,6].filter(even).map(mul(2)).print()` edit: that being said, I'd be interested in creating what you want, how you want it, if you have some ideas on what things you'd want as filters or whatever
yeah but then you need to code in ahk, and that's just no good
I'm not super familiar with pandas. In Numpy indexing is the correct way. It should give you a shallow copy to the indexed array. So it should be as fast as you can get (at the low level you are passing pointers not copying memory). 
You also don't need to use virtualenv. I've never needed it and done Python for the last several years. It definitely solves problems for people, but I've never needed it. You can install different packages in the different Python versions and run whichever you need. So you can install X in Python 2.7 and use it for one of your scripts. Your other one can use Python 3.5 with package Y installed. That keeps one of your scripts in Py2.7, but that might not be a problem.
"Freedom is the appreciation of necessity" (V. I. Lenin, attributing to Hegel). In your interpretation I struggle to imagine what could possibly be considered a stick. What I was getting at: if there's an awesome Python3 library that depends on asyncio, sure, I don't feel like someone is prodding me toward Python3 using a stick because I understand the necessity of that library being Python3 only. Same as the quote above means that I don't feel unfree because I need to work to get food on my table, because I understand that food can't appear from the thin air just because I want to eat. The same when someone makes a Python3-only library because she uses Python3 herself and there's no incentive for her to bother with Python2 -- no problem, I get that, this is just how things work and they shouldn't work any differently. The way I interpreted the thread starter's comment was a very different deal: let's convince developers that they don't want to support Python2, so that there would be less libraries which support both and that would encourage more people to switch to Python3. This is an attempt to change the natural state of the world via social engineering, propaganda basically. Lying with best intentions, lying by omission even, in the hopes that at some point everyone believes in those lies and then they become the truth -- the need to support Python2 would actually disappear. With that stuff I'd feel very differently about discovering a Python3-only library when I'm forced to use Python2: it wouldn't be any objective necessity for that that I could understand, like a Python3-only feature, or just the developer not having resources to support Python2. Instead I could point at the human source of my distress: that person who decided that we should move to Python3 and convinced the developer that nobody wants Python2 support anyway, to prod me toward Python3. Like, there totally could have been a Python2 version but there isn't because of that guy's vision of the Greater Good. That definitely feels like a stick, not a carrot. I hope this makes sense.
Pandas uses numpy indexing whenever possible, but it first checks for special cases, replaces labels with integer indices, etc., so it's a bit slower. The result is still a shallow copy.
&gt;Your consistency is borderline worthless, it's just another hoop to jump through. You have such a programming language available to you. It's called php. Use it. Asshole. 
You can read and write executables just like any other file. For example, if you want to take an executable that prints "Hello, world" and make it print "Jello, world": with open("file.exe", "rb") as f: data = f.read() new_data = data.replace(b"Hello", b"Jello") with open("out.exe", "wb") as f: f.write(new_data) You'll need to adjust the new file's permissions so it can be executed. I'm not sure how to do that from Python on Windows, since the `os.chmod` function only fully supports Unix systems.
[Image](http://imgs.xkcd.com/comics/tar.png) [Mobile](http://m.xkcd.com/1168/) **Title:** tar **Title-text:** I don't know what's worse--the fact that after 15 years of using tar I still can't keep the flags straight, or that after 15 years of technological advancement I'm still mucking with tar flags that were 15 years old when I started. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/1168#Explanation) **Stats:** This comic has been referenced 115 times, representing 0.1143% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_d08f1hk)
There are some video tutorials for game programming in Python with pyglet [here](http://codeschool.org/game-programming/) that I've looked at before. I'm not really much of a game programmer, but they seem pretty good and use pyglet instead of pygame (which I personally prefer).
I tried it for a simple C program and the new executable reports segmentation fault when I try to run it. Edit: on second try it worked. Maybe segmentation fault was caused by a blank character I tried to put there first time. Interesting, I didn't know you can modify exe just like that ;p
Some executables, like video games, have security features that prevent you from doing something like that. Like they will refuse to run if the hash of the file is not equal to a certain value.
Unless you know the exact internals of what the original source code looked like before it was compiled and linked to a PE32 (i.e. an EXE file), it is very unlikely you will be able to make random changes to the executable and have the executable work as before. Unless you really know what you're doing, that is.
Thanks a lot for this, would you consider putting together a couple of recommended build lists? Or at least good CPUs at different price tiers?
This looks really nice, thanks for putting it together! However, I would currently still prefer the page at https://www.python.org/dev/peps/pep-0008/ because of the table of contents. Would it be possible to add a navigation column (right or left) or a table of contents at the top for jumping to and between sections? (If you used markdown templates, I have a little helper [tool](https://github.com/rasbt/markdown-toclify) for that -- one of the many markdown "TOClifiers")
Absolutely not, I try my best to not bother with this stuff because I actually hate it. I can forward you to /r/buildapc though.
Hate to be that person, but as long as you hide the protocol details in that blob bytecode you could write that same program with the logically equivalent of those 3 lines in almost every language, C included. Implementing the actual protocol details so that you can call printer1.writelines(("hello world", "blah")), that'd be something python could excel at.
I was thinking adding some, via JavaScript (as that'd be easiest). If you want to contribute, you can modify the HTML on GitHub and send a pull request! It'll be tricky to display the TOC in a visually appealing way, though.
&gt; It dumps to a folder with the same name of the archive in the current dir. No it doesn't, I don't see anything in that code that ensures that. You've been lucky in only encountering archives that contain a directory named the same as the archive with all the stuff inside it. The first time you download an archive that doesn't follow that to your home directory and try to unpack it, you're going to understand why this is important.
But they don't know this stuff.....
One that puts money in my bank account?
More like this was shared internally amongst MSFT engineers. The beast itself doesn't care about Python, but I bet individuals at the company do.
Thank you!
You can configure pylint for that. Pylint takes a config file that let's you do all sorts of stuff.
I'm just having trouble visualizing all these processes and their implementations. I still have yet to put any of what I've learned to a test, right now I'm studying with Learn Python the Hard Way and I'm getting stuck on arguments and the sys module. I might have been a bit dramatic in my wording, too. I'm sure this will all click and I'll get passed it. :)
&gt; "done right" oh god... there are a dozen damn good reasons why function/method overloading wasn't included in python. This isn't a "missing" feature. This is feature which was PURPOSEFULLY omitted by the designers of the language because it's a terrible terrible terrible terrible idea! function/method overloading in a dynamically-typed language is just asking for all sorts of hard-to-test/hard-to-debug trouble. If you use this, you deserve every last bit of that big boatload of computer-science hurt heading your way!
You aren't as clever as you think. I assure you I'm not part of the marketing team. I'm a python enthusiast that wants to encourage good behavior in larger companies so that python continues to succeed.
Pyjion isn't a replacement for IronPython as they have different goals. IronPython allowed use of .NET libraries from Python. Pyjion is more about using the .NET JIT to hopefully gain better performance characteristics. And you know, because Dino, the engineer on our team that started it, was interested in using the JIT after it was open sourced :) Here is @DinoV and his description of Pyjion. Also the GH Repo https://www.reddit.com/r/programming/comments/433tmx/pyjion_a_jit_for_python_based_upon_coreclr/czfx3ku https://github.com/microsoft/pyjion
As a fellow Python enthuisast, I'm happy to report that I used IronPython to automate software deployments on hundreds of servers before PowerShell was a big thing.
Pyjion is not a replacement for IronPython. IronPython is a full Python implementation in .NET, whereas Pyjion is a project to [add a JIT interface to CPython, along with a JIT implementation based on the CoreCLR](https://github.com/Microsoft/Pyjion#what-are-the-goals-of-this-project). Other JIT implementations based on other technologies will be able to use that same JIT interface once it has been added to CPython via the work being done as part of Pyjion.
&gt; You seem to be suggesting that, as a developer, you may have to wrap every statement in a try block and handle What? No. I've never said anything even remotely like that. Number 1 principle of exception handling is that you only catch exceptions that you expect and can deal with. Any unexpected exceptions should be allowed to bubble up, print a traceback, and halt the program. It's acceptable to wrap your entire application is a try...except for the purposes of logging the error and presenting a more user-friendly error message. It's also acceptable if your application needs to remain running no matter what. Then you have a top-level exception handler that catches the unexpected exceptions, logs them, and then recovers in some way. But wrapping "every statement in a try block"? That's crazy talk, and I never suggested that.
Microsoft has yet to solve the font-face issue on their websites. If you don't have MS Office installed (Segoe UI typeface) their sites look like crap.
Hi everyone. I don't know if there is any way to assure you all of this...but I am in no way affiliated with MS. I have a longer posting history on HN and just wanted the MS python team to get some credit for giving our favorite language some open source love (and hopefully spur more investment and engagement with us). Now I feel bad because you all think I'm a marketing shill for them. 
&gt; I still have yet to put any of what I've learned to a test Flag #1. Don't do that. Adopt pay-as-you-go learning. Put everything to a test immediately. Reading is for squids. DO. &gt; right now I'm studying with Learn Python the Hard Way Flag #2. Any book that advocates cold memorizing Boolean truth tables by rote memorization instead of understanding them (and other issues), strikes me as at very least problematic. 
Stats?
&gt; We aren't organized enough to get marketing to do this :) A quick visit to [/r/hailcorporate](https://www.reddit.com/r/HailCorporate/search?q=microsoft&amp;restrict_sr=on&amp;sort=relevance&amp;t=all) says otherwise - [Microsoft AstroTurfing War on GNU/Linux is Still Going On, But Hidden Better, Uses API as Instrument of Lock-in ](http://techrights.org/2015/02/21/corruptible-press-on-eee/) - [Microsoft caught 'astroturfing' bloggers again to promote Internet Explorer](http://www.pcworld.com/article/2365060/microsoft-caught-astroturfing-bloggers-again-to-promote-internet-explorer.html) - [Microsoft Buying Positive Influence on Youtube](https://www.reddit.com/r/Games/comments/1vpumf/microsoft_buying_positive_influence_on_youtube/) - [Account created the day after Xbox One reveal exclusively posts Microsoft-positive links and comments](https://www.reddit.com/r/HailCorporate/comments/1fv43y/account_created_the_day_after_xbox_one_reveal/) - [Stealth marketing: Microsoft paying YouTubers for Xbox One mentions](http://arstechnica.com/gaming/2014/01/stealth-marketing-microsoft-paying-youtubers-for-xbox-one-mentions/) - [Microsoft Offers Cash for Wikipedia Edit](http://www.washingtonpost.com/wp-dyn/content/article/2007/01/23/AR2007012301025.html) - [Microsoft pulls the plug on paid IE social-media promotional campaign](http://www.zdnet.com/article/microsoft-pulls-the-plug-on-paid-ie-social-media-promotional-campaign/) - [Microsoft Contractors Are Manipulating Comments About Xbox One On Reddit, Says Redditor](http://www.businessinsider.com/microsoft-positive-reddit-comments-2013-6) -[Microsoft not doing "reputation management" on Reddit, you say? Then take a look at this.](https://www.reddit.com/r/gaming/comments/1get9v/microsoft_not_doing_reputation_management_on) *Your* 5 person team may not be organized enough, but Microsoft's behemoth marketing division can be a real lying, manipulative piece of shit :)
&gt; wrapping "every statement in a try block"? That's crazy talk, and I never suggested that. You just suggested it here: &gt; It's acceptable to wrap your entire application is a try...except for the purposes of logging the error and presenting a more user-friendly error message. It's also acceptable if your application needs to remain running no matter what. What you're suggesting is not going to keep the application "running no matter what". Unless you catch the exception in the right place, you're not going to be able to reasonably recover. Wrapping the entire application in a try except block is only good if you're planning to somehow log the failure in a useful way (define useful), but it will NOT keep the application running in a recoverable way. &gt; Any unexpected exceptions should be allowed to bubble up, print a traceback, and halt the program. This is about the only thing that makes sense. I suggest that letting the program crash without catching the exception is actually preferable, unless you are going to automatically upload the traceback to a crash log server or something. I understand that you cannot trust programmers to always write bug free code, but you should not use code that isn't tested and that doesn't raise appropriate and *named* exceptions. Also, if all of **your** code is tested, you will *not* run into a situation where you are surprised by a random and unexpected generic Exception, because you will have figured that part out already. (If you do run into a random Exception and still plan to use that code or library, you probably should report an issue to the author right away, or fork it and fix it yourself.) Reading your messages, I get the impression (maybe wrongly) that you don't test your code properly, and the fact that you believe that you need to take these measures makes me suspicious of the code quality that you work with.
Why would someone ask this dumb question? I really don't know... :-/
Don't sweat it. It's one paranoid conspiracy freak being a paranoid conspiracy freak. 
Python's style guide needs to be updated/corrected in two places: 1. One should USE spaces around the = sign when used to indicate a keyword argument or a default parameter value: Now: def complex(real, imag=0.0): return magic(r=real, i=imag) Better: def complex(real, imag = 0.0): return magic(r = real, i = imag) I see that this was already corrected for cases when type annotations of arguments are being used: def munge(sep: AnyStr = None): ... def munge(input: AnyStr, sep: AnyStr = None, limit=1000): ... I don't know why they didn't change it for both cases (with and without type annotations). Now style guide is self-inconsistent. 2. Documentation strings: Now: """Return a foobang Optional plotz says to frobnicate the bizbaz first. """ Better: """ Return a foobang Optional plotz says to frobnicate the bizbaz first. """
I was trying to escape the typical circle jerk of programmers and their binary thought processes. Clearly that worked. 
The select statement is different for the case that specific fields are specified. In [21]: db.reset_queries() In [22]: Poll.objects.values() Out[22]: [{'pub_date': datetime.datetime(2013, 8, 8, 11, 16, 24, tzinfo=&lt;UTC&gt;), 'question': u"What's up?", u'id': 1}] In [23]: print db.connection.queries [{u'time': u'0.000', u'sql': u'QUERY = u\'SELECT "polls_poll"."id", "polls_poll"."question", "polls_poll"."pub_date" FROM "polls_poll" LIMIT 21\' - PARAMS = ()'}] In [24]: db.reset_queries() In [25]: Poll.objects.values('id') Out[25]: [{'id': 1}] In [26]: print db.connection.queries [{u'time': u'0.000', u'sql': u'QUERY = u\'SELECT "polls_poll"."id" FROM "polls_poll" LIMIT 21\' - PARAMS = ()'}] 
oh jesus, if they can't find anything better for them to do, then I'm never getting a job at msft..
I would strongly suggest finding something you like and making a small program that does something cool related to that.
Ironpython isn't a Microsoft thing afaik, and the efforts are focused on py2 still, which does receive commits
&gt; I see PEP8 as a strong recommendation, not a definitive must. That's exactly what it is. Too many people think it's some sort of law that their code must follow. It's fine to make adjustments and your discretion. Personally 80 char per line is a bit restrictive and I usually set it to 100. In fact pep8 says "Limit all lines to a maximum of 79 characters" then immediately says "a team that can reach agreement on this issue, it is okay to increase the nominal line length from 80 to 100 characters". People need to not get so hung up on following style guides to the letter.
I haven't been in the industry that long, I was just pointing it out. If I had to assume, the motivations for contributing diminish as a company as large as microsoft floods the 'market' with material that otherwise would've been made by some altruistic/entrepreneurial developer that's trying to promote themselves (thus reducing the amount of contributors, which in turn might kill the community if microsoft were to then get bored with python and move on to the next new community)
Yes. /r/learnpython is what you are looking for
[Youtube-dl](https://rg3.github.io/youtube-dl/)
https://blogs.msdn.microsoft.com/pythonengineering/feed/
Correct. IronPython is run separate from any of us. Though at one point members of my team did work on it.
The MS online documentation reads like a guide on how not to do documentation.
Why is it a terrible idea, exactly? This library certainly isn't doing it right, though. 
Awesome! :D
Thanks for the reply! I agree that shipping Python is not trivial (I still don't fully understand the relevant Debian policy...), but it's good to know you're considering it.
Actually they did include one relatively unknown way of overloading with the [@single_dispatch](https://www.python.org/dev/peps/pep-0443/) decorator. It's solely based on type, but it works quite well when needed. 
 / or Windows
Thanks mate. That's really helpful. I was leaning towards 2.7 but i will give 3.5 a try. I will look around online and maybe get some books on python, and probably just use which one has the most support. Thanks again.
There is no reason to start with 2.7 now - learn 3.5. It is annoying when there's a package you want to use that hasn't been migrated to Python 3, sure, but there are many more advantages to using 3 that will not become apparent to you until further along in your Python journey.
Microsoft still shakes down anyone who violates their 8x3 file name parent (every Android handset vendor) and employs shakedowns involving several patents they "may or may not have" against lots of Linux using companies, such as Amazon. They're the same old Microsoft. They just hide their business end from the average consumer better, and the media focus just isn't there anymore. But it's ludicrous to claim they've changed. They just got bigger and have more compartmentalised teams. Embrace, extend, extinguish is alive and well. Now they're just applying it to the open source world instead of spreading FUD like in the SCO days.
thanks for this, it's nice to have a decent link for this, presented as documentation rather than a PEP
Yes! Re-install numpy using pip
I would suggest following approach - learn Python 2. While learning you'll surely be writing code. Once you've finished, rewrite your Python2 code to Python3. This way you'll have the feeling of how ol' Python was like, but you'll be able to code properly in Python3
I don't and I don't see the point. Sometimes it makes sense to have some graphs to describe high level structure, but that belongs in the documentation and at work we do these by hand. I've never seen automated tools that are useful. They normally just produce big pretty graphs that are functionally useless.
Which is fine, until you use a linter to check your code and doesn't let you selectively apply rules. It's just a nuisance for one community which might not affect others. 
Which linter are you using that doesn't let you configure which warnings you want to see? pylint and flake8 are the ones I usually see people using and they are both configurable.
https://www.jwz.org/blog/2003/02/ph33r-m4d-ski11z/
No, I mean ignore it in your IDE/PEP8 configuration file so no one ever even sees that warning ever again in that codebase. If you've already done that, I don't know how it could "kill you".
I'm working with some wonky code at work. It's not exactly legacy, but it's got this big gnarly god object. I started by listing everything it does, then dividing those into separate concerns. Then I began tracing individual twisty, curvy calls through the stack. Finally, I start isolating those calls into objects. I'd recommend watching Sandi Metz's All the Little Things for encouragement. It's in Ruby, but it doesn't require deep knowledge of the language. 
I only use visual tools when it comes to figuring out performance issues. I'll usually start by visualizing cProfile output using graphviz and gprof2dot like so: python -m cProfile -o profile1.d script_name.py gprof2dot -f pstats profile1.d -o profile.dot dot -Tpng profile.dot -o profile.png Which gives a decent overview of stuff but I then drill down using the excellent [vprof](https://github.com/nvdv/vprof) library.
that's great but without 2 way data binding it's still poop
Me too, I think the text should say lower case variable names are preferred unless there is a specific reason not too. And maybe an option in the checker tool so you can add something like `#pylint: allow_variable=G,NP,PLOD` to a module that needs it.
Which font? Uppercase or lowercase? Operator Mono has `i` slightly higher than `t`, but I don't see how that's cause for concern.
It can be helpful while refactoring to see all the places a particular module is used. Doxygen produces some helpful graphs in that regard. By comparing the generated ones to the design ones you can easily identify modules that are too tightly-coupled.
I'm using this with huge amount of success: https://github.com/mattes/rotating-proxy :)
[PlantUML](http://plantuml.com/) It [integrates with Sphinx](https://pypi.python.org/pypi/sphinxcontrib-plantuml) I use it sparingly. Most often I use sequence diagrams to document complex interactions.
That's what I thought after seeing the blog post. Do you know if that is also true at the OS level?
Embrace, Extend, Extinguish doesn't mean the death of the product itself, just the non-microsoft supported variant. Here's an example: 1. Embrace: Engage with the Python community, hire people to create extremely useful pieces of code that people willingly rely on because they are simply *better*. 2. Extend the Python spec to include items that are of use to everyone who was benefited by the Embrace phase. For example, have optional static typing in Python 3.5 actually speed up the processing. This can be implemented as an open source project. 3. Extinguish Cpython by making MS-extensions mandatory via a deprecation cycle. People go along with this because it's useful for them and everything to this point has been to their benefit alone. At this point, nearly everyone using MS-Python is on Windows and because the team is primarily Windows savvy they simply don't prioritize work on MS-Python for Mac or Linux. If something breaks on Windows spec, they walk to the next cubicle and get expert support from someone who works on the Windows OS. If it breaks in Mac OSX, they put out a notice on Radar and Apple gets back to them in 6 months. Thus without any *real malice*, Cpython is no longer mainstream and most people starting Python usage look to MS-Python and lock themselves into Windows for their business and personal needs. It's not a story of Microsoft bullying people, or deciding 'we will kill you at all costs'. They're just bit by bit forking the project because they don't consider compatibility with others to be a priority.
It's not something I've needed to do very often. In the past I've done it using signals. This seems to be the way people do it now: [QDataWidgetMapper](https://doc.qt.io/qt-4.8/qdatawidgetmapper.html). Any solution you choose should work in both PyQt and PySide.
When I was at Microsoft I knew lots of people with Macbook Pros. Of course Windows developers pretty much had to use a PC but some people also had a laptop and a development desktop. It really varies so much by team and job function so there are probably people forced to use Windows only. I had Windows/Ubuntu dual-boot on a Lenovo laptop.
That's a great talk ....... I NEED MORE!
Yeah, that's one of the super attractive feature for someone who wants to (really) do HPC and does not want to be bothered by ugly C-style array access. People (especially those with proper CS background) complain a lot about the ugliness, the outdatedness and so on of Fortran, but when you're used to numpy, being able to do `A * B` to multiply two arrays is kind of cool, not to mention all the array-related primitives…
See /u/Rhombold's response. It's dead.
Check out http://www.planttext.com/
&gt;Me too, I think the text should say lower case variable names are preferred unless there is a specific reason not too. Yeah, the hobgoblins clause is for covering stuff like that.
Thanks guys, I'll check them out :-) 
I don't like that clause... too many people seize on it to mean "I'll do whatever the hell I like, justified or not". Upper case variables is an area where it's particularly common to have a good reason to use them.
But management looooves colors and big graphs 
Looks like you already have it.
PEPs are reST, so no markdown.
Uncle Bob, Gary Bernhardt, and Justin Searls are other great speakers in the Ruby world. I kinda like Ruby talks on architecture better than Python ones because I don't find myself critiquing the code as much, which is distracting. J. B. Rainsberger also has a talk called Integration Tests are a Scam, which is about structuring applications to make them more testable. Probably time to watch that one again. 
How about this ? x = initial_value for s in series: x *= s
Very grateful, I'll take a look at those. I think the QT description fits my needs :)
The headers, but mostly the bastardized print-cursive subheadings and that mono space font. 
Maybe not directly the question, but still very useful class MyClass(object): def __init__(self, a, b): self.a = a self.b = b self.c = a + b @classmethod def create_from_a_c(cls, a, c): b = c - a return MyClass(a, b) I basically returned self there and in doing so created an alternate init method. You call it like: obj = MyClass.create_from_a_c(a, c) In this example, the following would not work (but if you set some default arguments it would, though it would be unnecessary and do nothing except waste CPU cycles) obj = MyClass().create_from_a_c(a, c) 
Yep
Will that remember the previous values? 
You've read the source, right? Have you tried, idk, "encrypting" twice?
It uses the same source markup
I don't get it. You registered for a conference?
Oh, yes, you are right, just saw that the html is generated via curl -s https://hg.python.org/peps/raw-file/tip/pep-0008.txt | pandoc -S --toc --from rst --to html 
I just tried a google search for "python image". The first two hits were for PIL, and the third hit was for Pillow. And the fourth link explained the current situation with PIL and advocated using Pillow instead. It's not exactly obscure information. 
Link to program? 
Pretty much. 
...Yes. He's excited to go to pycon. Not sure what you aren't getting.
I figured there must be some detail I was missing that would make this _remotely_ worth posting.
So basically, a simple run of the Perceptron would be; p = Perceptron() p.train().validate().confuseMatrix() Instead of; p = Perceptron() p.train() p.validate() p.confuseMatrix() Given that validate also returns self (Just to give a concrete example related to OP's post) Edited for precision. Thanks /u/hell_onn_wheel
Ah ok, yea that sounds fairly reasonable.
Thanks! Jupyter is the best way of sharing simple code imho.
like this: https://developers.google.com/blockly/
A tip calculator. Lol, Just started learning Python and I feel so hopeless. First programming language too
I feel like this captures the spirit of programming perfectly. Congrats!
It had to be Spain. Good job man!
Well, it's a good thing there's people like you in the community to help people feel welcome.
Hi there. You have posted a learning question to /r/python. These types of questions are far more suited to /r/learnpython, where users are actively interested in helping people to learn. Please resubmit it over there! Make sure to read their sidebar rules there before posting, notably this one: "Posting homework assignments is not prohibited if you show that you tried to solve it yourself." If your question is about homework, show them that you've tried to solve your problem in your post and you should get all the help you need. For anything else, the reason you are seeing this message is still that you will likely get a better answer there! Warm Regards, and best of luck with Python!
It may help to use fewer classes. Python isn't Java or C++ and doesn't rely on classes to the same extent. Lots of programs are simpler just using modules and functions to structure code. Make sure you're familiar with generator functions as they can often replace a class.
Congratulations. Good read and a positive action. 
&gt; I know how to Google You do understand why we get a different impression, yes?
No offense, but I'm not going to argue in favor of using it. If someone finds it useful, they are more than welcomed.
Personally I've never found visualizations of code to be particularly helpful or useful. The main way I learn about a codebase is by reading the codebase. For sufficiently large codebases it can be difficult, and sometimes it requires discipline to not follow every forking path and stay within the part of the codebase relevant to what I'm presently working on. There's no substitute for reading code though. After doing this for a few years I've really started to understand the appropriate use of design patterns. They are mainly tools for organizing a code base in a way that other programmers can read your code and understand (mostly) what is going on because they recognize the pattern. This reduces the cognitive overhead of developers to only needing to learn what's different about this particular instance of the pattern, as opposed to trying to model the entire control flow and data flow of the application without any help. Finally, a lesson learned from Behavior Driven Development. The tests are the spec. If the tests are thorough and up to date (and they should be in a well coded application) then you can learn most of what you need to know about how the app behaves just by reading the tests. That offers a very useful context for understanding what the implementation code actually does.
I realize my comments were misleading. As takluyver points out below, the wave module handles files of wav format.
Last thing, not so recent, was profiling everything. This can be incredibly pluggable: https://docs.python.org/2/library/profile.html 
Site is down. Any mirrors? 
Anyone else read Murcia as 'Murica? Need to get off of reddit...
I know :((
Yep, now It's working. Your site probably had some temporary DNS issues (I've checked with http://www.downforeveryoneorjustme.com/ and it was down for a moment).
-5.54303233452e-236, this is the number I get and I have no idea what it means.
Thanks to you! I discovered it on this project as well. Its veeery good.
You have such a programming language available to you. It's called C. Use it.
in my case it was a bit more like me looking around in the public office and shaking my head like saying **doesnt everyone here agree that this is ridiculous???**
This is encouraging and informative. Thanks, RubyPinch.
The man has a point though! 
Hi, maybe you can write an example script for my opensource project https://github.com/dddomodossola/remi. It is a gui library that allows to write webinterfaces. I thought that it could be good to have a raspberrypi example project. If you do not have a raspberrypi, than you can code an example of your choice just to enrich the library. 
 **Learning Python, 5th Edition** |||| --:|:--|:-- Current|$49.26|Amazon (New) High|$51.23|Amazon (New) Low|$29.15|Amazon (New) |Average|$49.92|30 Day [Price History Chart and Sales Rank](http://i.imgur.com/XA2Nkqm.png) | [FAQ](http://www.reddit.com/r/PriceZombie/wiki/index) 
Dude I asked how much time until I learn Python pretty good. Read my post twice wtf
"how much worse bureaucratic processes are here in Spain." You should not generalize like that, I have lived in multiple Spanish cities and never had those problems. Also don't know what the Spanish Government has to do with any of this, blame your local town hall. I have also lived in NYC and I did not notice any improvement compared to cities as Madrid. This is not Spain vs NYC, it is Murcia vs NYC...which is of course a ridiculous comparison. Enjoy your Internet points...
That's a bot (one of the few useful ones around). 
"Electronics" is awfully broad. Maybe pyi2c or pyspi or pybus or something?
The locals trick looks like a time saver, but it hurts readability and static analysis tools (pylint is just one example). I'd always write out the assignments normally. Many editors with 'snippet' functionality can create this common pattern quickly.
Here you go: https://github.com/ArthurStart/GeneticAlgorithm/blob/master/GeneticAlgorithm.py
That package only provides an interface to the busses themselves. This one also provides implementations for common chips
MSDN is fine.
It's not just busses. The latest git master has some code for abstracting gpio, ADC and DAC. Those pins can be on the gateway like raspberry pi gpio or some i2c port extender. That is all abstracted away by the library. http://pythonhosted.org/pyelectronics/gpio.html
Funny, I was looking for this sort of thing just the other day (for San Francisco)... I ended up using Google Streetview to read the parking signs where I was going, but solid data and an app would've been nice.
I don't think it hurts readability that much, as long as one knows what dict.update() and locals() do it's relatively explicit, and fewer lines might even help with readability. It also makes adding and removing of instance variables simpler while working on and refactoring a class. Still, I too will probably keep using the regular way at least with classes with relatively few arguments and inits that do more than simply assign the local variables to instance ones.
... but this is rpi gpio only? it just seems like you are in for a world of support requests when you name something specific with generic names.
I agree in part with what you are saying. Comparing NYC to Murcia is not fair. However, the example I talk about is and the fact that I can be fined based on information that is hard to obtain is ridiculous.
well, you have the code, you know what to do ;)
https://i.imgur.com/iWKad22.jpg
Wow thanks!
Similar: I had a snippet that applied some chain of functions to an input, and after reading *Category Theory for Programmers* realised that it would be much more elegant as function composition. Rarely useful, but fun when it is.
And good work it is! :-D From what I can tell we don't have that sort of data street-by-street... that's the missing piece.
Blog is down again :(
yeah, it is taking a hit. Nothing i can do right now unfortunately :/
If you haven't, I'd try setting it up under cloudflare - they provide global cdn caching which would almost certainly reduce your server load substantially.
This freakin blew me away, I'm sure other people know this, but I couldn't believe it was that easy. Pretty awesome if you need to package up a bunch of objects as json. class Table: def tojson(self): import json return json.dumps(self, default=lambda item: item.__dict__, sort_keys=True, indent=4) tbl = Table() tbl.name = "A Table" tbl.rows = 1 row = tbl.row = Table() row.cols = 2 col = row.col = Table() col.col1 = "columnName" col.col2 = "columnName" print tbl.tojson() prints; { "name": "A Table", "row": { "col": { "col1": "columnName", "col2": "columnName" }, "cols": 2 }, "rows": 1 }
Rather than "conservative", I think the Python approach is more about pragmatism: a language that pays so much attention to readability and terseness will naturally attract pragmatic people who don't really want to run after fads, don't want to rewrite working implementations unless absolutely necessary, do not want to write more code than strictly necessary, and do not trust other people's code that much (or they wouldn't insist on being able to read it). Its (previous) niche status also avoided the need for hype. This has its downsides: I remember Mark Shuttleworth remarking once that the Python community is full of "cats" who are difficult to herd towards common goals, and sometimes they generate umpteen different solutions for the same set of problems -- see the number of half-baked web frameworks and threading libraries, and the slow Python 3 adoption rate. 
You can also extend your own JSON encoder, to properly marshal complex types; I do this with [`namedtuple`](https://docs.python.org/2/library/collections.html#collections.namedtuple).
Also you have wand as alternative to pillow. I think that is more pythonic.
Don't go overboard. Doctests are neat but not a replacement for a real test suite.
Also, there are many alternatives to all those libraries that din't work with python 3.
Oh yes, I can't overuse them anyway. I guess I exaggerated in my post by saying I used them everywhere. Thanks for the advice!
Me too! It's so fast and easy to throw a couple of quick tests together inline as I start writing a function.
Go to learn python subreddit. Or pay someone to do it for you. I've already got code laying around for scouring reddit. Pm me if you want to hire me, but I'm not cheap. 
That's on the court who decided in their favor, not on Microsoft 
Even if it were to happen, whoever wants to could still use the original version. The people who didn't, had different priorities. Why is that a bad thing?
What's one divided by three? At school, I learned it was one third. Python 3 says it's.33333331, which is wrong. Maybe you can find a way to blame that on C. Another option is to recognize that representing numbers on a computer in a useful way does not always match your childhood math lessons. 
* How big is the file? * What type of file? * Is it slow only for HTTPS? * What kind of disk is it on? * What OS? * Have you tried a different file? * Have you tried a different size file (or a truncated copy of the original)? * Have you tried loading the file yourself with `open(path).read()`?
Whether sucking the energy out of an open-source project and perhaps leading to its neglect or abandonment for years, is a bad thing... is an exercise I leave up to the reader. I'm not making a moral judgement.
Source Code Page: http://boxheaddcode.blogspot.com/ I haven't touched this in years. Kinda thinking of picking this project up. Also wish I knew about github at the time.
Coca Cola también?
These sorts of questions are normally best answered in /r/learnpython Try looking here for the information: https://docs.python.org/2/library/stdtypes.html#comparisons
funcy is nice too!
No, they were carried. 
Use anaconda. You're trying to build pandas from source on Windows. This is possible but not fun at all. Anaconda will install it for you as a binary package, with the bonus that anaconda is awesome for many other things as well. If you're going to do any kind of scientific programming in python I would recommend just picking up anaconda now and saving yourself the trouble of switching later. 
When asking questions like this you need to give more context. An enclosing function (or more commonly, an enclosing scope) refers to the situation where you have a nested function: def foo(...): ... def bar(...): ... ... It's impossible to say more without context. 
I am referring Python documentation 3.5.1 to learn the language. And my doubt is from this paragraph: "The execution of a function introduces a new symbol table used for the local variables of the function. More precisely, all variable assignments in a function store the value in the local symbol table; whereas variable references first look in the local symbol table, then in the local symbol tables of enclosing functions, then in the global symbol table, and finally in the table of built-in names. Thus, global variables cannot be directly assigned a value within a function (unless named in a global statement), although they may be referenced." Source: https://docs.python.org/3/tutorial/controlflow.html#more-on-defining-functions 
&gt; I am referring Python documentation 3.5.1 to learn the language. And my doubt is from this paragraph: "The execution of a function introduces a new symbol table used for the local variables of the function. More precisely, all variable assignments in a function store the value in the local symbol table; whereas variable references first look in the local symbol table, then in the local symbol tables of enclosing functions, then in the global symbol table, and finally in the table of built-in names. Thus, global variables cannot be directly assigned a value within a function (unless named in a global statement), although they may be referenced." Source: https://docs.python.org/3/tutorial/controlflow.html#more-on-defining-functions 
Si
That's not a doubt, that's a question. A doubt means that you think something does not work, when it clearly does. (That's probably just an ESL thing that's not relevant.) If you refer to a name inside of `bar()`, to locate that variable, first the local variables of `bar()` will be checked, and then the local variables of the enclosing function `foo()`, and then the globals.
Oooh, you're going to yet another tech conference! You and millions of other coders each year! I'm so excited I can barely contain the sarcasm! Seriously, hope you enjoy yourself, but this is something you should have posted on Facebook, not here, or better still, not posted at all. Nobody cares. Well, apparently there are at least 22 people who care. I guess they're really starved for entertainment.
Thanks i got it. Also point noted when to say it what. It was definitely a question. :) 
Just so long as your `__init__` doesn't take arbitrary kwargs. You don't want `MyClass(foo=99, __len__=None)` if MyClass is supposed to define `__len__`.
"Doubt" is a synonym for "question" in Indian-English. If we allow Americans to spell colour without a u, we should allow Indians to ask their doubts.
[`__prepare__`](https://docs.python.org/3/reference/datamodel.html#preparing-the-class-namespace )
You are my hero! Such people are making our world better. I've not seen such cool posts on /r/Python for long time.
 contextlib.ExitStack() I have a module that runs a bunch of plugins, but they all have a setup and tear down, so they are all called around the main body like this starta startb startc mainbody endc endb enda As we added more plugins, this quickly started to get unmanageable. I knew I could do a big `with` but even that would get long. `contextlib.ExitStack()` lets you open a context with an arbitrary list of context managers.
Why do you think algorithms can't be changed in Python (dot point 2)? That makes absolutely no sense
Monkey patching? Anyway it's widely considered an antipattern to do. 
I really like the way Coffeescript does it. Just prefix the variable name with a @ and it gets merged into the object variables.
So the license fee is only necessary if one is selling software? Using PyQt to develop analysis tools used internally to do my job is fine though? I've stuck with PySide just because it's hard to get clear answers on this stuff. Also working for the US government makes it even less clear since we're often our own customer...
Somebody didn't eat their wheaties this morning. 
Print the map a couple of times, even laminate one of them and go share them with the office where people apply for the license, so they can pass it on. Good job. 
To all those that say I shouldn't have posted this: you're probably right in that this isn't a very helpful or informative post. Sure I could've posted to Facebook but 90% of my FB friends don't even know know what Python is. My hope in posting this was to share my excitement with others and possibly start a conversation about the speakers for this year or nostalgia of conferences past or just overall excitement for this upcoming conference. If I've offended you in any way, I apologize, but judging by your vitriol..... I'm assuming your jealous that I get to go and you don't!!!!! SUCKAS
People in the US also don't know how to drive when they're sober. This is not because they are inherently worse drivers or stupid or anything like that, it's because it's too easy to get a driver's permit. It's no comparison to, say, Finland, Switzerland or Germany where you not only have to drive defensively, forehandedly and very attentively before you're even allowed on the test (sidenote: on a manual transmission car), you also have to prove you can keep control of the car and react correctly when losing traction. After getting the licence you're on probation for three years, where even minor offences result in the loss of the licence. You're expected to be able to inspect a car for it's basic safety (brakes, tyres, steering, lights, etc) and are educated in driving economically to protect your wallet and the environment at the same time (engine braking, accelerating swiftly then driving in a high gear, coasting, turning off the engine at train crossings, etc). The US should really make sure its citizens are able to drive properly, especially when looking at the fatalities. And before you tell me you drive more, even the fatalities per kilometre driven are much much higher. While we're on the subject, you should also require periodic safety inspections of all vehicles. There are people driving with bald tyres and shot brakes. Where I am this would mean losing the licence for at least one year so people don't do it.
man I love doctests, mostly how it documents the function as well which is perfect for small scripts and programs! 
It's never gone to court, nor have ms been proven to be rightful owners of said patents. They have actually not even told anyone what these patents are,they are just threatening companies with a lengthy court procedure. Most companies cannot afford thos so they settle or they might find its cheapervto settle than fight this in the court.
Damn, that sounds like a lot. Back in the days of the late 00s, we had a safety/rules handbook we were tested over, a vision/hearing test, and a certain number of hours to be spent in class and I'm car. Of course, you could do drivers ed with your parents, so who knows if you actually did everything. And for people like me in sessions of over 200 kids, some of our driving sessions were actually conducted on a simulator just because there are only so many cars to go around. This is in Texas though. So, here's the thing: most states do require annual vehicle inspections. And more states, including Texas, are switching to a system that will require you to pass inspection before you can renew your registration (as opposed to those being two separate statuses for a given vehicle). Of course, the problem is that car repairs cost money. Lots of money. So this of course disproportionately screwed over poor people. Now, correct me if I'm wrong, but most of the countries you listed have excellent public transportation overall, yes? Most of the US isn't like that. Hell, I live in Houston - fourth largest city in the country - and we don't really have great public transit. It's gotten better, sure, they've added a couple of lines for the light rail, and they redid the bus network, but it's still laughable compared to places in Europe. In a lot of places in the US, is really difficult if you don't have a car. So given how expensive car repairs can be, I'm not sure how best you could say such regulations while still making it feasible for people to own cars.
A PHP fanboi!
Anaconda
Also I'm aware I'm not posting a shiny new repository (it exists) but I'm sure you can find it if you really want to. I guess you could say its pre-beta I've just been rapidly developing it so I may taking a hatchet to some things later, but it is coming. I'm not ready to go back in refine a lot of stuff either, I'm still trying to see how things really should be structured etc. Its sort of nice to be under 2000 lines, and be able to bang something out entirely new fast. I just thought it was pretty cool and hadn't seen much stuff like this. 
I understand the problem. Here, people who live in places with bad public transportation and without enough money for car either move to their place of work, move to a place that does have public transportation, or get a cheaper form of transportation, like a motorcycle or a bicycle. 
I see, Python is used for server side like PHP/ASP isn't he?
Recently a guy has posted this, here: https://github.com/EliotBerriot/lifter
You need the visual studio compiler, this blog seems pointing in the steps: https://blog.ionelmc.ro/2014/12/21/compiling-python-extensions-on-windows It should be a trivial task once you have the compiler. 
For the first I guess regex is the way to go or you can use some sort of Bayesian library (http://www.bayespy.org/intro.html). But still you will need to train it. The second thing you ask in linguistics is called Named Entity Recognition. NLTK provides such functionality http://www.nltk.org/book/ch07.html. But I would suggest you try GeoDict first https://github.com/petewarden/geodict For the third point I would suggest you revert the data you have back to its original HTML state and use a Content Extraction algorithm like Text-to-Tag ratio for example http://www3.nd.edu/~tweninge/pubs/WH_TIR08.pdf or http://www3.nd.edu/~tweninge/cetr/ https://gist.github.com/andreypopp/2820220 https://github.com/rodricios/eatiht - This is a ready to use content extraction library for python. Otherwise I would think it will be nearly impossible to distinguish between "content" and "navigation" if there is no some sort of tagging or special formatting of the unwanted text. Scrapy is an option as well. 
[Effective Python](http://www.amazon.com/dp/0134034287) and [Fluent Python](http://www.amazon.com/gp/1491946008/) are great to step up your Python game to an intermediate-to-advanced level.
[removed]
society has to deal with the people coming from jobs that get obsolete, not oppose the obsoletion. we have to proceed towards a world where ultimately nobody has to work anymore, not a world where dull automatable jobs exist for humans.
start with requests and beatifulsoup what exactly do u want to do?
That's the gist of it, or you can just comply with LGPL. If you're using pyside you'll have up anyway. This doesn't mean open source, it means that you have to allow users to be able to try to reverse engineer your program. 
The main channel is the only one you can truly trust, the rest are community packages. The ipdb package is not officially hosted by continuum, but if that makes you nervous then you can install from pypi where there will be only one package of that name. You still have to trust that the package hasn't been compromised, pypi hasn't been compromised, and your connection hasn't been compromised. 
This week I found out you can change the value of True and False in Python 2. I assumed these values were constants, but Python doesn't have constants so it makes sense that you can change them. &gt;&gt;&gt; "foo" is True False &gt;&gt;&gt; True = "foo" &gt;&gt;&gt; "foo" is True True In Python3 True and False are not values but keywords so they can't be changed.
The quality of Oracle's actual (database) documentation is very good, but my god, the UI hasn't been great. The latest upgrade was an improvement.
The Github URL in the description is no guarantee that the package is actually built from that - it's just a description, and the person who wrote it can put whatever they want. For a pure Python project like ipdb, if it's not in the default channel for `conda install`, I'd use pip to install it. For packages that contain compiled parts, I'd look for an Anaconda channel belonging to a name I know - but that's not much help for newcomers...
Uber? In Spain? Banned
considered an anti-pattern to do it _for some things_ but its actually really useful and considered good practice for other things. the best example of when monkey-patching is the right thing to do is Mock objects for testing. mocking out external APIs is a particularly common use case. 
Same here, and I was born and lived in that city for 30 years.
This code also relies on the caching of some strings.
agree with you, however also &gt; install from pypi where there will be only one package of that name. &gt; &gt; You still have to trust that the package hasn't been compromised, &gt; pypi hasn't been compromised, and your connection hasn't been &gt; compromised. or that the author of the package is not malicious or retarted. I could submit a package to pypi right now called 'pandas-ng, pandas for humans' which reimported pandas, added one function, and 'rm -rf ~'....
I wish they would take a cue (or a billion) from PostgreSQL. Their docs are a joy to read.
Go do it, you took the hardest step already, getting the data and crunching it - now it's time to cash in. :) 
Recently someone told me if you are in Mexico and you apply for a driver's license, they just hand it to you. I think they consider it a right, not a privilege. I just think in 30-40 years none of this will matter, cars will do the driving.
Getting the map would have been easier this way: http://lmgtfy.com/?q=plano+ser+murcia&amp;l=1 And gathering the information on how to obtain the parking license is easier this way too: http://lmgtfy.com/?q=murcia+residentes&amp;l=1 I'm not saying your code isn't cool nor that you aren't right on some things you say there, but I don't think there's any need to shit on your country just because you don't know how to use Google...
Scan Through Txt, Append Certain Data To An Empty List In Python. I think that is how to word it, but I don't know. I have reached the end of my patience in trying to figure this out.
It seems that part of your story is not accurate. You may find everything you need to know about parking permits at Murcia here: http://www.murcia.es/web/portal/tarjeta-residente And there is already a map available of all parking zones here: https://www.eysamobile.com/eysaMobile/murcia.html Maybe you missed those websites or you met with the wrong bureaucrats... I found those links via: https://www.meneame.net/story/donde-c-puedo-aparcar-eng/c017#c-17 Me encantaría de todas formas que me contarás qué ha pasado exactamente. Que me van a freir a negativos en esa página si no descarto la noticia :) 
I guess I should adjust my comment to say "among other things" at the end of my list of potential issues. I'm not trying to say that those are the only three things to look out for, there's always going to be security vulnerabilities that you didn't expect.
I'll second the Fluent Python recommendation. That being said - BY FAR the best way to learn (once you know the basics) is to sit down and do a project. Are you doing data analysis? Pick a competition on kaggle and dive in. Do you want to do web development? Do the flask tutorial, then sit down and actually build and deploy a small web app. Learning how to use a jackhammer is a waste of time if you're not building roads. Similarly, blinding learning the features of a programming language is useless if you don't have any sense of why they would be important to you. 
It's not like those links are hard to find... I posted a few minutes ago a couple of trivial google searches that result in those...
&gt; Other cases leave me baffled: pywt has three (outdated) packages, of which I can find no official connection to the pywavelets project. Am I supposed to resort to pip in this case? If you want to be nice, you can build it yourself and push to your channel so you and others can `conda install` in the future.
Concur with this, download link here for convenience: https://www.continuum.io/downloads 
You're right that Python 2 had the wart that you could reassign True/False, but your final statement here is True regardless of that due to string interning: &gt;&gt;&gt; x = "foo" &gt;&gt;&gt; "foo" is x True 
Great!
Additionally if you want the minimal environment go with Miniconda from http://conda.pydata.org/miniconda.html. I don't know why they make this download hard to find, but I prefer it. To get the full Anaconda experience just do `conda install anaconda` after setting up Miniconda.
Python the language isn't conservative. Except for numbers, everything can be treated as an object and extended. All the monkey-patching madness that you see regularly in Ruby is possible in Python. You can even hijack the import statement and use it to do weird things like compile an imported module with macro assignments based the name you gave it. You can grab the AST of a method, rewrite it entirely then insert it back into the object. You can create proxy classes, that upgrade themselves transparently into another class given a certain condition. Python supports hot-code reloading---wherein that code is something you pulled not form the file system, but from a HTTP request. You can take a function, compile it, send it across the network and have someone else use your function w/o knowing anything about the internals. It's all possible, it is simply that 90% of the time Python developers choose to not do that. It's the development community that is conservative, not the language. 
&gt; It's the development community that is conservative, not the language. yes, that is exactly what I said, right?
True, but Django does this in their ORM. Monkey-patching is a reasonable thing to use as part of an internal API, while presenting a cleaner API to end-users of a library.
To note, this is Python 3 only I think. Lots of little bits of useful functionality are in Python 3. They're not widely talked about as individually none of them are a reason to switch, but once you do switch---you get all of them.
I like that the API specification is declarative. Handy for whipping out a quick-n-dirty API. But for a full-fledged one, you need more robust validation, interaction with model data, and authentication. If allowing access by third-parties you'll want API access control, throttling, maybe a web page for trying out the API calls. I like Django-Rest-Framework with Swagger doc support. But I can see places where that's too heavy-weight and this would be the easier way to go.
That's a complicated text file. View it in browser and you won't get any pattern of its formatting. Try copy it and view it in Sublime Text or Notepad. I think you will get the pattern of each line. As far as I check: 1. A line include ====== (length of 55) is a separator between two sections 2. Under same section, first not empty line is a HEADING, the following is DESCRIPTION (or editor's note as it's written in the file). The third is TABLE HEADER, then goes the DATA of TABLE, which every line is same length That's pretty much of it. Now you can just read line by line or swallow the whole file in a buffer string, then split it by separator to get sections, so that you can get data by each section.
I am a backend dev myself but I am not sure about a backend portfolio. I usually give them the links for my github account so they can look at some personal projects that I worked on. (I should actually update my github). If you want to make a demo project there are many options, blogs or simple single page apps, like a note taking app that has a restful backend. These days I am playing around with google maps, python and react js. I am not sure about how much time the interviewer has, but most likely he/she wont go through every single line of code in your app. So a small app that solves a simple problem should be good. (This is just my opinion, I could be wrong).
not equal
Most of the time, I've forked the library too. The only one time I've seen it as useful was implementing caching for querysets in the Django ORM. I didn't want to fork Django.
You're telling a bunch of Python devs that writing some python to fix their problem isn't the most efficient way of doing things :P It's an unpopular point of view to say the least.
Here you can find an example where this is done with matplotlib: http://savvastjortjoglou.com/nba-shot-sharts.html
I'll have you know this is the most creative thing I've done in years! Who is this python fellow? 
progress = current/max
x-post [How do I implement user progress tracking?](https://www.reddit.com/r/django/comments/477bo4/how_do_i_implement_user_progress_tracking/)
jesus christ yes edit: actually takluyver has a good point
&gt; Get surprised by something random in your budget Great idea. There are too many dogs in the neighborhood anyway... :0)
&gt; we don't need the post office anymore. Er, we do need *some* way of shipping stuff. IMO it would be beneficial for the government to provide public services like that, and make it funded by taxes.
Well, I think everyone will agree that for the job like this you should always use your ... Pillow. :0)
&gt; Python 3 says it's.33333331, which is wrong. [citation needed] $ python3 Python 3.4.3 (default, Oct 14 2015, 20:28:29) [GCC 4.8.4] on linux Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; 1/3 0.3333333333333333 &gt;&gt;&gt; '{:.30f}'.format(1/3) '0.333333333333333314829616256247' ~17 digits of precision is the inherent limit of the IEEE 754 float which is why after that point there is garbage. &gt; Maybe you can find a way to blame that on C. you are going full retard now. You really think python doesn't farm the crux of the math evaluation out to a C code? $ cat div.c #include &lt;stdio.h&gt; int main() { printf("%.30f\n", 1.0/3); return 0; } $ gcc div.c -o div $ ./div 0.333333333333333314829616256247 You never go full retard.
That's not the point. You did a great work because you met some uninformed public workers, yes. But I think you should update your post with this information. It's all there... public and indexed by google. You can rant all you want about the public workers you encountered and the misinformation they gave you... I'm totally with you on that. But I think that is common all over the world :P
Awesome! This is my first year going. Maybe we'll see each other there. :)
This IoT microcontroller, includes wifi and webserver. https://www.kickstarter.com/projects/214379695/micropython-on-the-esp8266-beautifully-easy-iot
If you are going to treat your file as a database, just use a database. Sqlite is perfect for that, and supports JSON. 
There's Planet Scipy which aggregates related scientific blogs.
I can see your point about changing the purpose of the slash, but it's unused, and maps to the behavior of paths pretty logically. Frankly, it going to be hugely convenient, and far more readable than os.path.join(). 
RemindMe! 2 days "Hopefully there are some awesome links" 
I will be messaging you on [**2016-02-25 18:26:48 UTC**](http://www.wolframalpha.com/input/?i=2016-02-25 18:26:48 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/Python/comments/477fva/a_list_of_useful_python_blog/d0av0j1) [**17 OTHERS CLICKED THIS LINK**](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/Python/comments/477fva/a_list_of_useful_python_blog/d0av0j1]%0A%0ARemindMe! 2 days ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! d0av17m) _____ |[^([FAQs])](http://www.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^([Custom])](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^([Your Reminders])](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^([Feedback])](http://www.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^([Code])](https://github.com/SIlver--/remindmebot-reddit) |-|-|-|-|-|
Awesome. In case it's useful, Google has a massive query ready dataset from reddit going back years on their BigQuery platform. 
This Jupyter iNotebook thingy looks really cool. It'd be neat to somehow use it as a testing framework and documentation mixed into one.
Saving 
Yes you can, you don't need local file intermediate step.
It's the division operator though, right? That it happens to be a slash is coincidental. You can't add any arbitrary symbol as operator in Python. One path divided by another... makes no sense. It's great and fun in third-party libraries, like [Plumbum](https://plumbum.readthedocs.org/en/latest/), but in the standard library it's mostly odd and confusing.
Nice I pointed a coworker at this, she was trying to solve this exact problem yesterday (extract data from postgres, transform it a bit, and write it gzipped to s3 for another process to load into redshift). Thanks for sharing!
&gt; Sometimes I'd prefer the "copy and update" just because it can be read easily by novice Python devs. I guess it depends on the project. I'd agree here. As a dev who got my start on a Python project maintained by people who loved "pythonic" solutions (i.e. bafflingly terse one-liners), I hated seeing stuff like this with no explanation as to what it did. Even as a fairly fluent Python programmer, I still find the dictionary unpacking solution to be a bit confusing. Given the context it's obvious what it does, but it's new enough syntax that it would probably throw off my thought process if I stumbled across it while trying to figure out some code.
Not tested, but should work if you have pygame installed. Gives you a basic idea at least where to start. Replace 'your image here.jpg' with the path/file you want to 'square'. Add a save function if you want to output the file.. just use pygame.image.save(). Check Google and Youtube if you need further help. \*edit: **seriously? downvoted for trying to help?** import pygame import sys def load_image(img): try: image = pygame.image.load(img) return image except FileNotFoundError: print('File {} not found.'.format(img)) return False def make_square(img): img_w, img_h = img.get_size() if img_w &lt; img_h: return img.subsurface((0, 0, img_w, img_w)) else: return img.subsurface((0, 0, img_h, img_h)) def check_square(img): img_w, img_h = img.get_size() return True if img_w == img_h else False def main(): pygame.init() screen = pygame.display.set_mode((1024, 768)) image_filename = 'your image here.jpg' loaded_image = load_image(image_filename) if loaded_image: square_image = make_square(loaded_image) if check_square(square_image): print('Image is square!') else: print('Image is NOT square!') while True: screen.fill((0, 0, 0)) screen.blit(square_image, (0, 0)) for event in pygame.event.get(): if event.type == pygame.QUIT: pygame.quit() sys.exit() pygame.display.flip()
This tutorial is perfect
I completely agree. There has to be a balance between "pythonic" one liners and readability. That being said, I find the new method really interesting! 
Well, at least I can feel I'm consistent - I don't like the modulus for string formatting either. When I was learning Python, I thought that was some sort of arcane specific syntax and not an overloaded modulus operator.
Nice idea!! it is easy to implement a ``@swag_from(PythonModel)`` in Flasgger. I will work on this. Thanks for the idea!
I just changed that to 2. Thank you for pointing that out!
~~I'm pondering if a copy on write chainmap might be the best approach.~~ ~~Construction would be like chain map, but mutating effects would return a new (regular) dictionary with the changes in place.~~ Just tried playing with this but you can't overwrite `self.__class__` without the class being a heap type but rudimentary searching doesn't reveal what's kept on the heap in Python. Though, playing in a notebook probably caused this.
I'd never heard of it before. The `merge_with` function looks pretty neat: &gt;&gt;&gt; from toolz.dicttoolz import merge_with &gt;&gt;&gt; merge_with(max, {'a': 1, 'b': 3}, {'a': 2, 'b': 2}) {'a': 2, 'b': 3}
A lot of people use it to publish tutorials and books :) https://github.com/ipython/ipython/wiki/A-gallery-of-interesting-IPython-Notebooks
&gt; Maybe not provided strictly by the government, but they should at least take part and step in if the people who are running it are screwing people over by charging way too much. Do you have a way of telling where that line is? Typically people get screwed by having to pay too much when there isn't a lot of competition. This is why we have laws controlling what monopolies can do (did you know it used to be the case that you had to buy your actual physical phone from AT&amp;T because they used their monopoly as the service provider to require it?). Also, in the case of Internet prices, a lot of it is due to artificial monopolies created by the government (for example, lots of municipalities have granted monopolies to Comcast, etc.). UPS, for example, is considered a very good company to work for because it pays its employees well and is a responsible company. The USPS, on the other hand, is the origin of the phrase "going postal" (i.e., hating your job so much you start murdering people) and operates at a loss, plus it has unsustainable pension obligations. I dunno. I'm not really trying to turn you into a free marketeer or anything. I'm just trying to say this shit is way more complicated than pretty much anyone is willing to admit.
Implementation details are by definition not part of the public API, so they're unlikely to be documented, because then people would come to rely on them. If you want the answers to your questions, you're going to have to read the source. The `shelve` module is really just a thin wrapper around a DBM file. The first problem is that there are multiple implementations of the traditional Unix DBM file. The most popular two are NDBM and GDBM, but you might also run into the original flavor DBM (sometimes called ODBM) or the more sophisticated BerkeleyDB (BDB) flavor. In all cases, these files represent a key-value store where keys and values are arbitrary bytestrings. But the file formats are each different and incompatible. Some might use hashing, others a B-tree. But in all cases you can assume that accessing a key is efficient (at least O(log n) and possibly O(1) or O(keylen)) and does not devolve into O(n) time. The accesses happen only when you ask for a key, not when you open a file, because these DBM files are meant to handle large(ish) amounts of data. All of these details are not under the control of the shelve module or Python, as these are third party C libraries. If you want more specifics you'd have to read the source code for the specific library that your system was configured to use. 
I thought being pythonic meant not writing "clever" code? To me, Pythonic code is readable, usually self-documenting code. Hard to understand one-liners doesn't seem Pythonic to me. Like complicated comprehensions are incomprehensible. Keep them simple!
Have been going through both of these books using https://www.safaribooksonline.com/ and there is a video series there to accompany Effective Python. The subscription is not exactly cheap, but I got one of the deals, and it has been very useful to push further, as there are all the O'Reilly books, plus much more, also doing 2 other video series on there, Object Oriented programming, Designing Data Structures in Python, along with other algorithm series, other python titles I have perused a few chapters, and dozens of books, series waiting in my queue. If you can stump up the subscription, and have the time, as everyday there is another title I add to my queue; Safaribooksonline.com is a great resource full of great resources.
That's what I meant to imply as well. 
&gt; (we technically don't except that shipping packages via USPS is cheaper than UPS, so getting rid of the USPS is regressive against the poor) That's like saying we technically don't need the post office cuz you can drive your mail to the destination yourself.
I'd love to have a postgres source. If she writes one, please submit a pull request or just a issue with a snippet of the Source python code
You're correct. The initial comment was either using the word Pythonic incorrectly or in quotes to imply that obscure one-liners are the opposite of Pythonic.
My preference would be for `dict.update()` to accept an arbitrary number of arguments, so that the following would be valid: {}.update(defaults, user) ... and to be honest, I was initially under the impression that this was already the case.
That's an interesting find. I wonder if it might not be specific to Windows? Here's my system (brewed) Python on OSX: Python 2.7.10 (default, Sep 23 2015, 04:34:14) [GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.72)] on darwin Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; a = 'a'*2500000000 &gt;&gt;&gt; len(a) 2500000000 &gt;&gt;&gt; a.__len__() 2500000000 &gt;&gt;&gt; type(len(a)) &lt;type 'int'&gt; &gt;&gt;&gt; type(a.__len__()) &lt;type 'int'&gt; Edit: I get the same result (both `int`s) with Python 2.6.9 as well.
Hello, Sure, I'd be interested in hearing more. Could you please share more details?
Those snippets do completely different things! The ChainMap is a view on the dicts. That means that the ChainMap will be updated as well if the user dict was updated. Also: modifying the chainmap will modify the first dict contained inside. See: https://docs.python.org/3/library/collections.html#collections.ChainMap The idiomatic way is to construct a dict and update it twice like in the first example. This will allow for a nice diff, if it was ever changed, states the intent perfectly and will cost you less time to read than one complicated line.