I spent all day yesterday trying to get pyffmpeg installed and kept getting a gcc exited with error code 1 (the most meaningless error code ever) when trying to install. Maybe I need to scale back to an older version of ffmpeg?
It's not a web app. Using a bin directory seems interesting to me, I guess I feel like only binary files should live there. I know it doesn't really matter. EDIT: thanks!
Wow, he's right the namedtuple code is [really something awful](http://hg.python.org/cpython/file/2.7/Lib/collections.py#l295).
If it makes you feel better you could name it `scripts`. I've seen (and used) both. It doesn't really matter, as setuptools is going to make you list the contents either way.
[This howto](http://infinitemonkeycorps.net/docs/pph/) is the best I've seen for how to set up a python project. It's full of great advice.
Yeah this is wonderful.
I kept meaning to write this post. Thanks :)
In my younger, more ... ambitious days I wrote the core of a data processing engine in the same style, in perl no less. I wrote it as one would normally write it first, then I started optimizing for speed and got four- and five-fold speedups from inlining function and method bodies and going out of my way to completely avoid method calls. Presumably this is doing something similar, but I would think whatever it's doing could also be done with a sufficiently smart metaclass instead.
This is how I got it running in one of my virtual enviroments on OSX Lion. I use [homebrew](http://mxcl.github.com/homebrew/) to install non python system packages. brew install zmq #Within virtualenv pip install tornado pyzmq pip install -U ipython ipython notebook Notebook demo files are located in [virtualenv]/share/doc/ipython/examples/notebooks. Really, really cool so far. I can see a lot of potential with demoing code with packages or alongside talks.
I know it's silly, but it does make me feel better. :)
Awesome, thanks!
&gt; Also in the FooBar directory, an include/lib directory with all the supporting .py files for foo_bar.py. I want to call it lib or inc or something, but neither name really sounds right. You might want to look into application frameworks to give your program more structure. EDIT: Yes, what a horrible idea.
if only the subprocess module was 1% as easy to work with as os.system or os.popen. This is clearly an area where "explicit sometimes sucks".
NumPy, SciPy, Matplotlib, and IPython, like MATLAB
I for one don't hate the if “__name__“ ... line as it provides a great way to do simple tests (proper testing should be done another way, yes) or try out things in module files without influencing the imported version. Also when using multiprocessing you better use the line in your main file to make sure it isn't imported by processes, trust me.
I've come to realize that the first rule of Python is that calling `exec()` is usually a sign that something, somewhere has gone horribly wrong.
Check out Python 2.7+, there are new convenience functions to make subprocess less of a pain in the butt. &gt;&gt;&gt; subprocess.check_output(["echo", "Hello World!"], universal_newlines=True) 'Hello World!\n' 
How is type checking worse than a set of try catch blocks?
Think of the case of __str__(). It's much better to just see if there's a __str__() method on your object than for the object to have to be of some type which always has __str__(). Edit: Dunno how to escape those underscores; imagine that they're there...
For the curious, [it's not any better in Python 3.2 either](http://hg.python.org/cpython/file/3.2/Lib/collections.py#l235).
Thanks for that, I'll definitely check them out - and hopefully spend less time wrestling with the subprocess module - only to get it working far worse than os.popen.
What is the output of the following lines of code? frag = 'abc' control = 'mno' for i in control: if len(frag) &lt; 4: frag += i elif len(frag) == 4: continue else: frag += frag[:len(frag)] print(frag) would it be 'abcm'? or 'abcmno' I'd actually like to know the answers for some of these also, I am also taking a python class. I suck tho.. any help would be appreciated 
escape them: `\_\_string\_\_()` or use back-ticks: \`\_\_str\_\_()`
Ask specific questions. Instead of posting four entire exercises here and expecting us to just give you the answers, why don't you try doing the problems yourself and working out which exact step you get stuck on? Then you can ask about just that little part. For example; for problem 3, instead of writing the program into the interpreter, try following the code through in your mind and work out the answer that way. If you can't, which line are you having trouble with, and why? The line `for i in control:` means "for every letter in control (temporarily called 'i')". When `control` is `'mno'` it means "for 'm', then for 'n', and finally for 'o'" By the way, when you write code on reddit you should put four spaces in front of every line so that reddit knows not to mess up the indentation: def say_hello(): print('Hello, World!')
This may be a dumb question, but what does this have to do with databases at all? Calling your module 'database agnostic' is a tad misleading, since it really has no interface to or concept of a database. By that logic, my handwriting is database agnostic.
Scikits-image is bound to Scypy, thus taking the benefit of using Numpy. Although it's in its early stage (version 0.4~0.5), but given how Python (particularly Numpy, Scypy and Matplotlib) is growing in scientific community, I believe it has a bright future as an alternative to MATLAB. PIL, on the other hand, looks somewhat dead to me or taking too long between releases. (The last time I heard ver 1.2 should be out in early 2011, but it's already Christmas)
Thank you so much , still getting the hang of this
It might as well be named condom. I mean listen to how that sounds. 
&lt;3 Bootstrap
In case you have to go back further, [2.5](http://docs.python.org/release/2.5/lib/node530.html) added the first convenience function: `check_call`
[/r/learnpython](/r/learnpython) is a great tool too!
for problem 9 I am not sure how to "nest" I can only draw a single hexagon but I am not sure how to pick up the pen and move it so on? def drawHex(width,length): for i in range(6): hex.foward(100) hex.right(60) 
You should not be typing the code into the python shell. Save the exercises as files and run them, e.g.: python exercise1.py Because the python shell needs to interpret your input one line at a time, it treats a statement followed by two newlines as the end of the block. So when you type an ``if`` statement, followed by an expression, followed by two newlines, you've actually closed the ``if`` block. This is why your ``elif`` is throwing a ``SyntaxError``. Here's a contrived example that shows what I'm talking about. Notice the difference between the ``&gt;&gt;&gt;`` and ``...`` &gt;&gt;&gt; if True: ... a = True ... &gt;&gt;&gt; elif False: File "&lt;stdin&gt;", line 1 elif False: ^ SyntaxError: invalid syntax &gt;&gt;&gt; if True: ... a = True ... elif False: ... a = False ... &gt;&gt;&gt; &gt;&gt;&gt; a True 
 if __name__ == '__main__': Really, I don't care too much about this. If Python required you right things like this dozens of times in a script, I'd see the complaint. But in a project with several dozen files, I might write this once, maybe twice. Personally, I like not having to repeat myself repeat myself by being able to use my scripts as modules and vice versa.
This happens with every library/framework/platform/etc. It's the nature of the beast. The overwhelming technical reason is that different frameworks are different. 
Where do you save the .py file because i save as hex.py in the python32 folder and when i run the problem the graphics part does not come up 
I agree. In 99% of my use cases ("run process, grab stuff from it as it's being generated") os.popen() is superior, despite being deprecated. It's shorter and more obvious. With subproc you *can't* send stuff to your process, nor receive data, while the proc is running. subprocess.check_output('command') isn't bad.
Good to learn about multiprocessing. I've used pickle several times in shell scripts to get pipeline parallelism, but it would be nicer to do it all within python.
How does it prevent repeating yourself ? You just import your module and make the script. `if __name__ == '__main__'` is not horrible per se, but you can't deny it's a bit hackish and not exactly _clean code_.
I like a config.py with all the knobs that I can import into relevant files.
Reacting to the first part of your post: you're basically saying that it's not bad if the code doesn't matter. That's true for everything. But as soon as you're going for larger projects, you need to separate your code more cleanly.
&gt; With subproc you can't send stuff to your process, nor receive data, while the proc is running. What in the world are you talking about? Of course you can do that: p = os.popen("ls -l", "r") for line in p: ... is the same as this: p = subprocess.Popen(('ls', '-l'), stdout=subprocess.PIPE).stdout for line in p: ... ...except that the latter is safer because you control the word splitting yourself instead of having the shell do it. And similarly for stdin and writing. In fact `Popen` is superior in all ways because you can capture all three standard streams at once if you need to, and there's a built-in way of handling the complicated select() loop necessary in that situation (`communicate()`). 
I meant that, personally, I find it simpler to have one file that does two things, rather than one file that contains my module, and another file that contains my script. But you're right, it's not the worst form of redundancy.
&gt; In fact Popen is superior in all ways except for the part that you need to spend days to figure out all the options and subtle implications. By which time someone else on the team is saying like "my god can this be any worse? lets just use perl".
I was able to use the Image module to identify parts of an image that were similar to Waldo. It works much better when his shirt is easily seen. However, it's not perfect, and does not work as well as the Mathematica solution. **First Image** - used \_w,_h of 26 each [http://i.imgur.com/kTLda.jpg](http://i.imgur.com/kTLda.jpg) -&gt; [http://i.imgur.com/BrjUv.png](http://i.imgur.com/BrjUv.png) **Second Image** - used \_w,_h of 20 each [http://i.imgur.com/tr48Q.jpg](http://i.imgur.com/tr48Q.jpg) -&gt; [http://i.imgur.com/rK9Xb.png](http://i.imgur.com/rK9Xb.png) Code - [http://pastie.org/3044233](http://pastie.org/3044233)
&gt; proper testing should be done another way, yes I wouldn't call that proper. I'd call that more standard and effective - given more time to learn &amp; build. But there are a lot of scenarios in which an extremely simple method to run a few tests is very valuable. And an attack on this is just another example of peope pushing python towards continually greater complexity and placing no value on simplicity or accessibility.
Sorry, I'm not super familiar with running Python in Windows If you right click your .py file you should be able to open it with the IDLE editor. There's an option to run the script under ``Run &gt; Run Module``. Or you can just hit F5. The output should appear in the Python Shell
The multiprocessing module doesn't safely handle killed processes -- it's maybe not as bad as the other "toy" examples there, but it's still a toy.
Unless I'm overlooking something huge, it's embarrassingly easy to do it right: # namedtuple.py class _namedtuple(tuple): _fields = () def __new__(cls, *args, **kwargs): if len(kwargs) &gt; 0: # Find correct order for tuple. kwsorted = sorted(kwargs.items(), key=lambda kv: cls._fields.index(kv[0])) # Assemble contents into tuple. args = tuple(map(lambda kv: kv[1], kwsorted)) return tuple.__new__(cls, args) def __getattr__(self, key): return self[self._fields.index(key)] def namedtuple(typename, field_names): """Use like collections.namedtuple""" if isinstance(field_names, str): field_names = field_names.replace(',', ' ').split() # names separated by whitespace and/or commas field_names = tuple(map(str, field_names)) return type(typename, (_namedtuple,), {'_fields': field_names}) Results (example from [here](http://www.doughellmann.com/PyMOTW/collections/namedtuple.html)): Python 3.2.2 (default, Nov 21 2011, 16:50:59) [GCC 4.6.2] on linux2 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; from namedtuple import namedtuple &gt;&gt;&gt; Person = namedtuple('Person', 'name age gender') &gt;&gt;&gt; bob = Person(name='Bob', age=30, gender='male') &gt;&gt;&gt; bob.gender 'male' &gt;&gt;&gt; jane = Person('Jane', 29, 'female') &gt;&gt;&gt; jane.age 29 &gt;&gt;&gt; jane[0] 'Jane' This was a quick hack, has no error handling, is missing a few features, is performance-agnostic, and I **suck** at metaprogramming. How hard can this possibly be for someone who *really* knows their shit (not me)? EDIT: Maybe I don't suck. The [diff attached](http://bugs.python.org/file11608/new_namedtuples.diff) to the bug linked in [ffrinch's reply](http://www.reddit.com/r/Python/comments/nj00d/unfortunate_python_a_bunch_of_things_to_avoid_now/c39l15b) is pretty close to what I did in the relevant bits! =D
I really enjoyed the list of gotchas you compiled. I wish I would of realized the pickle one much sooner than I did.
Could you explain that a little further? We're using multiprocess extensively at work and any gotchas would be super handy to know about. 
The "bin" directory is for executable files. There is no "scripts" directory in the [FHS](https://en.wikipedia.org/wiki/Filesystem_Hierarchy_Standard).
This came up [a long time ago](http://bugs.python.org/issue3974). There's nothing intrinsically wrong with using `exec`. It's often a sign that things have gone wrong, especially in code written by an inexperienced programmer, but Raymond isn't an idiot and he's quite right that current version is clear and maintainable -- it's inelegant, but it's safe and very easy to follow. So what's the problem other than the kneejerk "exec is awful"?
&gt; If you must have different behaviour for different types of objects passed, try treating the object as the first data type you expect, and catching the failure if that type wasn't that type, and then try the second. And if the failure doesn't happen until a non-recoverable side-effect has occurred - what then? What if the failure isn't non-recoverable or destructive but very time consuming (say ~100 milliseconds on a function called thousands of times)? I'm not sure this is a "better alternative." &gt; Anywhere else use a different format. Use a database or use JSON with a well-defined structure. Both are restricted to simple data types and are easily verified or updated outside of your Python script. While the problem with pickle is true, this is an alternative in the same way a text file is an alternative to a relational database. Sure, it works, but you've got a LOT of work to do to make it do so. &gt; If you're looking for speed, try just using regular python lists and PyPy. PyPy is not the be-all and end-all to all of your performance problems. PyPy does not come with a standard Python installation and I have thousands of systems in a massive cluster I need to work with. It's just not an option. I need something that is fast, efficient and works with the standard install. &gt; I have used this trick to make running tests easier, but setuptools already provides a better hook for running tests. Okay, let's see a "for instance" and make sure it is actually easier and faster than ``__name__ == "__main__"`` and integrates cleanly with my IDE.
The general idea of [duck typing](http://en.wikipedia.org/wiki/Duck_typing) is that instead of checking whether it _is_ something, check whether it _does_ something you need it to do. One of the benefits is that you can pass in something different three months down the track when your requirements have changed without a rewrite or *gasp* copy-and-paste.
I'm not asking about how to mirror the Linux file system, I'm asking about the best way to organize the directory structure of a Python project.
WSGI is not a magic wand that you can wave over any compatibility problem. It is a very specific and very minimal interface between an application and a web server, and nothing more. In fact it's so little that writing even an application too light to need a framework on top of it can be tedious, which is why libraries like WebOb exist -- both for the lightweight apps, and as the core of frameworks like Pyramid. Plus, Django supports WSGI anyway.
To Chris McDonough. Thanks a lot for writing this.
Is this grant coming from the normal financial aid fund for pycon or did pyladies raise their own money for the grant? I think increasing our diversity at PyCon is important but don't think its worth taking away from developers who truly need the aid just to bring more women to the conference.
Tough to give a really good answer without some examples of projects you think are too closely tied to Django. Especially since I'm not sure what you mean by, "bring WSGI to Django". While it is absolutely a best practice to pull any non-web-related functionality/classes out into a separate module that is generic, many projects don't actually have much of that. Once you strip away everything dealing with the ORM, templates and forms processing, there isn't any interesting functionality left. The answer to, "why don't people list just the individual Django modules they use as deps?" is: * Django isn't distributed that way (check the mailing list archives to find out why). * Almost nobody needs just an HttpRequest object, or just a forms library. People who need just an ORM end up using SQLAlchemy anyway (or jinja2 for templating).
I think he's more saying it's fine for use in _development_ (you can just run the module instead of potential setup overhead), just make sure to remove it before you go into production. Of course, those using TDD will already have tests and thus won't find much use for it, but not everyone does TDD.
I really like subprocess :)
Thanks for the help, incase anyone else decides to follow: $ sudo port install py27-ipython $ sudo port install py27-tornado $ sudo port install py27-zmq is probably what you'll need to run.
Because it requires you to run on a Python implementation which provides *exec*. If you didn't notice, the last comment on the bug report was from someone who disabled that feature for security, and had the odd surprise of losing *namedtuple* as a result. The kneejerk "*exec* is awful" *is* a valid reason for stdlib to not secretly depend on Python features which can be turned off in production environments for security reasons. At the very least, they should note in the [documentation](http://docs.python.org/library/collections.html#collections.namedtuple) that the CPython implementation of *collections.namedtuple* uses *exec* in it's implementation.
Wait, what? Someone disables a built-in language feature without checking to see if it's "secretly" used in the public, searchable, widely-distributed standard library for the language with that feature, and that's a problem with the library? I see your point, but I hope you can also see that the maintainer will not necessarily feel that an obscure use-case like "I want to disable `exec` in my port of Python to the PlayStation 3" (and it is an *incredibly* obscure use-case) is a good enough reason to sacrifice ease of maintenance, consistency or whatever other advantages he feels the current solution has.
In the case of writing python scripts for use in [blender](http://www.blender.org), if __name__ == '__main__': is given as more or less part of the dogma. It is the boilerplate, if you will. How would one go about replacing that functionality? I never thought of it as an option.
See https://code.google.com/p/tryton/wiki/Update
I don't see how exec makes this particular implementation of namedtuple easier to maintain.
It was just about to bite me in the ass when I read this. The timing was perfect.
A very well written piece. Thanks for that. Yet when I see: &gt; When trying to replace a complex system, make it simpler, don't just push the complexity around. I'm struggling to gauge how Pyramid is actually simpler than Zope 3 was.
Yep used to have this problem in the qtconsole too. It was solved by, "fig = figure(); fig.show()" i think, but this no longer works 
Did you actually read it? Pyramid uses 2 small pieces of zope. Everything else is new code or other python packages. Zope is just 1 of 3 inspirations (the others being Pylons and Django). It's a very different beast.
If we didn't care about backward compatibility, I don't see any major problems with doing it the C way: import the module normally (i.e. under its own name), call its `main()` or `main(sys.argv)`. It's good style to do that and only that in your `if __name__ == '__main__':` section anyway, unless you enjoy figuring out weirdness resulting from it accidentally setting or overwriting critical global variables.
I guess it's one place where performance might matter, and both your and that guy's implementations do quite a lot of stuff during instance creation which templated version doesn't.
oh yeah, good catch on the uuid lib/headers.
In my opinion the major quality of Django is that you can write modules that can be plugged into any Django application to add high-level functionality (comments, tagging, cms-style pages, field types, asset management, debugging tools, REST frameworks, security checklists…). It is possible because Django is a full-stack framework that sets a standard for the template language, settings, models, forms, validation, middleware, commands, applications, url routing and so on, that high-level apps can count on and build upon. These high-level apps are easy to integrate ([here is an example of how this is documented](http://django-tastypie.readthedocs.org/en/latest/tutorial.html#configuration)) in a full-blown web application. It is a net win for the Django ecosystem, and not particularly harmful to the rest of Python. To your last point, Django is a WSGI framework with access to WSGI middleware, but that isn't as convenient as its fine-grained integration points.
bin/ just means: this contains stuff with executable permissions, memorable names (dashed if needed), and no extension, and can be added to your $PATH. 
The only Django-specific modules I'm familiar with are Django-specific for good (and typically obvious) reasons. Perhaps if you could give some examples we could tell you why those examples are Django specific, or maybe we'd agree with you that it doesn't need to be. But without any examples all we can do is speculate on what modules you might be thinking of.
Do add a setup.py! It's the critical step to making your project reusable. It can be very simple; the minimum (to allow reuse) is to give your project a name and a version, an author and a licence, and to list the modules it contains. As soon as it starts to work, you can upload source packages on PyPI. Other important steps (that go a bit beyond the layout): use publicly-accessible DVCS hosting. Once you have docs, upload them as well; rtfd.org and python.org have facilities for that.
You missed my point entirely I think. I don't understand how you came to the conclusion I was referring to those zope packages. What I meant was that Pyramid does not feel less complex than Zope itself. Whether or not they are different beasts doesn't make that feeling untrue.
The main problem is strings: if you want to distinguish a string from a list then the most straightforward way probably is just to use `isinstance(x, basestring)`. I suppose you could use `hasattr(x, 'lower')`, but that is less clear.
As a newbie I don't get all of these but the ones I do understand are interesting. Will read more.
I'll point you to [this section](http://guide.python-distribute.org/creation.html#arranging-your-file-and-directory-structure) of **The Hitchhiker’s Guide to Packaging**. By the way, read it all. I also suffer the "over-thinking" problema. This guide helped me a lot.
You're right about Python's threading support. I had some errands with `erlang` and was blown away. Clojure would be a good opportunity to learn functional programming (which `Python` supports to a certain extent). If you have some time to waste, you should look into [`APL`](https://en.wikipedia.org/wiki/APL_(programming_language\)) and `Haskell`. These languages changed the way I think about programming. They have even helped me be a better systems programmer.
I tried Haskell and I think my brain just doesn't fit it well. From the start I've made in Clojure (I know a fair bit of Lisp) I feel really comfortable there, so it works out. How's Erlang, in your opinion? EDIT: And no, Python is like 90% function programming compatible, since it doesn't entirely have tail-recursion which means that the deep functional constructs you find in the Lisps you cannot do without artificially increasing the recursion depth and even then, you don't get the tail call optimization.
You also need to use a sys.getframe hack to change the `__module__` of the classes returned by namedtuple, so that some serialisation methods can "just work" without further configuration by the caller. But that's orthogonal to the exec thing.
Thanks.
I'm fine with `array` and `copy`. `array` shouldn't be used as a premature optimisation, but its lower-level semantics provide a performance advantage whether or not you're on PyPy; the JIT can't optimise everything.
&gt; And if the failure doesn't happen until a non-recoverable side-effect has occurred - what then? What if the failure isn't non-recoverable or destructive but very time consuming (say ~100 milliseconds on a function called thousands of times)? I'm not sure this is a "better alternative." Yes thanks. Picking a bunch of hypotheticals that break the rules are certainly going to break the rules. The post was a good set of guidelines for what applies before you specifically know otherwise. In this case, often the even *better* idea is not doing that. If you can't easily distinguish functionally between 2 datatypes without stuff blowing up you probably want 2 functions not 1. &gt; While the problem with pickle is true, this is an alternative in the same way a text file is an alternative to a relational database. Sure, it works, but you've got a LOT of work to do to make it do so. Oh? Serializing builtin objects is a total of 1 line, and writing a JSONEncoder for one of yours is as long as it takes you to express your object in terms of some of those. It's highly painless. You pay a small price for sanity though yes. &gt; PyPy is not the be-all and end-all to all of your performance problems. PyPy does not come with a standard Python installation and I have thousands of systems in a massive cluster I need to work with. It's just not an option. Not really sure what any of this means other than being another even more arbitrary hypothetical :). If you have the option to use PyPy, it's usually an amazing place to check (or even start with). If you don't, well, there's not much to talk about then. &gt; I need something that is fast, efficient and works with the standard install. Great. Sounds like numpy. &gt; Okay, let's see a "for instance" and make sure it is actually easier and faster than __name__ == "__main__" and integrates cleanly with my IDE. How about 4 :) trial mypackage nosetests python -m unittest discover py.test
GrumpySimon: Didn't know it. Many thanks!
Use `up()` and `goto(x, y)`
"""Brands are important ... "what is 'noun'" have one answer.""" What is Pyramid? What is Pylons?
Having read that, and the Zope wiki page, I still have no idea what it is, but it has a silly name, and I don't like that. D:&lt;
This is what I'm saying. The code not intented to live is not important, thus it doesn't matter if it is not clean. Off-topic, but I hoped redditors in more intelligent subreddits such as /r/python would have learned how upvotes and downvotes work. You downvote because a comment is irrelevant to the conversation, not because you don't agree with it.
Ah got it now. This was stupid ... """ fig = figure(); ax = fig.add_subplot(111); ax.plot(rand(100)) """ ... just input fig and evaluate to reshow 
That was a very good write up Chris. Thanks for taking the time to do it.
&gt; Please lend us this suspension of disbelief until after you write your first nontrivial Pyramid program. After that, specific critiques are welcome. Have you written your first non-trivial Pyramid program? That might answer your question for you. I am not saying your are "criticizing" either just that actually doing something with it might be your best answer. 
&gt; Pyramid is a small, fast, down-to-earth Python web application development framework. It is developed as part of the Pylons Project. It is licensed under a BSD-like license.
Thanks! Seems like the plots aren't dynamic, just statically rendered images. I think IPython just automatically displays Figure objects that have axes.
This is a poor line of defense against how people feel about a product. I'd be okay with it if I were spreading fud, or opening tickets at random with no ground for them. I'm just merely saying that, when browsing through its documentation, I feel like the framework is as complex as Zope 3 was. I make a distinction between complex and complicated by the way. I find it strange to welcome new people with that kind of arguments really. It's snob at best. If some folks are dickheads about your product, sure let them be, but it's quite natural to feel overwhelmed by Pyramid in my opinion. It's probably also natural to feel empowered by it once things fall to places but don't shoot newbies because they "don't get it at first sight".
For what it's worth, I've almost always seen the directory named `bin`.
I like this... I'm recommending it for those trying python out at work for the first time. 
So what does that flag do anyway? edit: what *did* it do? :)
It means that virtualenv will use a completely clean set of modules rather than using the existing modules that live in the OS pythons site packages folder.
"Not getting it at first sight" is a far stretch from claiming that Pyramid is as complex to learn or simply "as complex" as Zope 3. Pyramid is fully documented, unlike huge portions of Zope. It depends on 2 libraries from the entire Zope ecosystem, does not require ZODB for storing data, nor ZPT for rendering your pages. They are hardly on the same playing field in terms of complexity. Pyramid is very "pay for what you eat", meaning in its simplest form (which you can see in the examples/tutorials), it is merely an efficient url routing mechanism on top of WSGI. It just happens to give you a lot of other features if you have a need for them. [http://docs.pylonsproject.org/projects/pyramid/en/1.3-branch/narr/introduction.html#what-makes-pyramid-unique](http://docs.pylonsproject.org/projects/pyramid/en/1.3-branch/narr/introduction.html#what-makes-pyramid-unique)
I currently work on a project that has bin/scripts/. Yes, this makes me want to stab someone.
Ah okay. Where does it get this "clean" set from? Or it just copies everything except the site-packages directory from your system-wide install?
No, that's exactly what it doesn't do. Now you just get the stdlib, rather than inheriting whatever happened to be in site-packages.
Does anyone know where that "alternative implementation" the last comment eludes to is?
Which is why I meant complex not complicated. You are right to say that Pyramid's documentation is great, that being said it also highlights the sheer breadth of the framework. Is its a negative point? Depends on where you stand. A beginner may feel intimated, a power user empowered. That doesn't make the framework less complex in my mind.
I'm sorry that you struggle. Would you be willing to give us some specific points about what makes Pyramid seem so complex to you? You clearly know something about Zope 3, but some people don't, so having some concrete examples about why Pyramid is complex would be nice for them and would help Pyramid people understand why some developers perceive it as complex.
Nah it's just swimming up the river to spawn.
Is there an easy way to only override the packages you want to experiment with?
I think the idea is to just try the string function in a try-block before testing it. If it excepts, then try the list functions. If both fail then raise some kind of exception. In other words, instead of type checking then executing just execute and catch exceptions.
I'm confused, isn't that exactly what I said?
&gt; don't shoot newbies because they "don't get it at first sight". I hope I don't. I wouldn't have written its docs if I did, nor would I sit in IRC answering questions about it most days. The post isn't a welcome piece (we have docs for that), it's something to point people at when they ask about "why does Pyramid use Zope libraries" in IRC. "Why would it not?" doesn't seem to be a good enough answer, or at least that answer only prompts responses with murky assumptions based on misunderstandings about what "Zope" is wrt Pyramid. &gt; when browsing through its documentation, I feel like the framework is as complex as Zope 3 was The first part of that sentence takes most of the wind out of the second, I'm afraid, because Zope 3 didn't really have any docs; at least not any freely available integration docs that told you how to use it as a whole. Pyramid does: they're not perfect, and they definitely could be organized better, but they are comprehensive. Regardless, Pyramid may be not be a fit for you, and that's fine. But I think, in general, if you're trying to draw an equality comparison between Zope 3 and Pyramid, you're unlikely to have used or understood either in any meaningful way. I understand that there are plenty of options, and choosing a Python web framework necessitates that you find reasons to dismiss all but one. I really don't even mind if you dismiss Pyramid after giving it a fair shake for good reason. The above post literally asks that you have enough respect for its authors (and its dependencies' authors) to take enough time to be able to dismiss it due to its real flaws instead of pre-dismissing it because it uses two Zope libraries. I also understand that even this is too much to ask; people (including me) never choose anything purely rationally, and it's sooo tempting to just eliminate based on mood, popularity, and hearsay. But I don't think there's any harm in asking.
What I don't really get is why you propose a 2.8 that is closer to python 3, if your porting problems are more related to the fact that you still want to maintain compatibility to python 2.5 ? If you would drop python2 support fully except for python 2.7, would that make it easier to have python2/python3 support?
Well, I haven't used Zope in years because it was so complicated (on top of being overly complex in my book). I left that boat when they were introducing Zope 3 years ago. So I may well have an irrelevant comparison point. In regards to Pyramid, I said I **felt** it was complex but it appears people, who use it, fail to comprehend it's possible to feel that way. I'm not asking on being right or wrong, I'm saying that I feel that way. Sure, I should be using it and likely that feeling would gradually go away but I don't know how to demonstrate to you that, as a newbie, I feel intimated by it. I'm not even sure you guys need to do anything about it, just allow people for feeling a little scared by its richness/complexity (which again is not necessarily a negative point, being complicated would be) like Zope 3 did.
Just an FYI but with port you can chain the commands too, so $ sudo port install py27-ipython py27-tornado py27-zmq does the same
This is a time-saver :)
I feel like you should deliver ice cream to my house every six hours. I'm not saying this is right or wrong, I'm just saying I feel this way. Relevant?
What if you need system packages?
I appreciate your point while, I'm afraid, I have difficulties carrying mine. I don't dismiss Pyramid nor do I find it worthless. Like I said, I don't find it complicated. I said I find it complex. Complexity, in my mind anyway, is said about concepts being broken down into many well designed sub-parts. Since Pyramid advertised itself as a web framework, the context seems fairly well defined. Neverthelessn, I find, at first sight, that Pyramid tries to answer web dev. concepts in a rather complex way. Once you go through the documentation, you get a feeling it's not complicated, ie things have a meaning and are well designed. Nonetheless there are other frameworks that I consider less complex because the way they tackled the problem of web application development is more straightforward to me. This is where I draw a comparison between Zope and Pyramid. Not in the way they do things, but in the complexity they have used to answer the web dev concepts. People often distinguish micro and larger frameworks, I have yet to understand why really. Smaller frameworks may offer less but it doesn't mean there are less capable. It mostly means that you'll have to come up with your designs. In that regards, I appreciate the work done by Pyramid greatly because it probably saves a lot of time eventually but initially there is a feel of complexity that is intimidating. 
Depends on how you want me to do it, I can do it simply by driving to your house or I can first configure my car, then read its manual at length and then drive to your house. Why the sudden burst of trolling?
The author primarily shows command line interface usage on the website e.g., heatmap.py -p photo-points -o photos.png --width 1000 Have you downloaded "photo-points" into the same directory as heatmap.py and tried the above? If it fails, try python heatmap.py -p photo-points -o photos.png --width 1000 Note: I didn't bother dinking with the --osm option, so your output won't have the map in the background. It will have the yellow dots though 
I'm trying to use my own data, which is in the same directory as the script. I keep getting stuff like this: &gt;&gt;&gt; heatmap.py -g CostaRica_1.gpx SyntaxError: invalid syntax &gt;&gt;&gt; heatmap.py --decay 0.8 -g CostaRica_1.gpx --height 800 --margin 10 -b black SyntaxError: invalid syntax I also tried this: &gt;&gt;&gt; heatmap.py -g [CostaRica_1.gpx] --height [800] --margin [10] -b [black] Traceback (most recent call last): File "&lt;pyshell#6&gt;", line 1, in &lt;module&gt; heatmap.py -g [CostaRica_1.gpx] --height [800] --margin [10] -b [black] NameError: name 'heatmap' is not defined 
how about the hard-to-install packages? ie pil, psycop2? how is one supposed to use them? 
Fair enough. You don't mention any specific complexity, and it's probably inappropriate here to do so, although I'm personally interested should you be willing. But I suspect it's moot; we're not really talking about software anymore. We're talking your feelings. You got burned. You feel taken. You won't make that mistake again. Etc. Is that about right?
You left off the "ideally". ;-)
Oh, I totally understand it's possible to feel that way. I get that feeling myself with many things, software and real life. However, I think that talking about my feelings does not advance reddit discussions a lot, because other people can feel that I'm wrong as well and somebody reading about our feelings has no way of knowing who is right. That's why I asked for some facts behind the feelings. Like many people, I might be afraid to fly, and my wife may care about my feelings. However, while I'm free to go to an airplane forum to voice those feelings, I might stop myself before doing that, because really, what's the point? What am I contributing? 
You've said a lot about complexity, and I'm sure you have examples. I'm also pretty sure it'd be too tedious for you to list them. But the best I can do is to try to create better docs, or at least try to help you personally understand why what you find too complex exists. That is the only real tool I have to try to address your feelings. But talking very generically about feelings without actually is a game I'm destined to lose every time, and that gets pretty frustrating.
 virtualenv --system-site-packages ENV
Creating a symlink to it is generally the recommendation. I always have to do this with psycopg2.
You are welcome. ;-)
Sure, use setuptools' multi-version install mode.
I think Pyramid has fantastic doc and you guys do a great job, it was never my goal to disminish your efforts. Complexity isn't something bad. Sometimes it's inherent to the problem at hand, sometimes it's a way of dealing with a problem. I would be dissing Pyramid if it was complicated, meaning simple tasks were done in a counter intuitive way. This is not the case. You know, I should definitely write code with Pyramid and I'm sure my feelings will smooth out in that regards ;)
I'm sorry if this discussion turned into a sour discussion, it was never my goal. Complexity is inherent to software and life in general. However you're not correct in thinking I will not be using Pyramid because I may have been burnt in the past. My initial comment was simply a reaction to that specific point of the blog post. Seeing how badly it turned out, I think I should'be probably bitten my tongue. 
http://docs.python.org/tutorial/ 
I find that software development is an intelectual process as much as a feeling one. When I help my colleagues with Python, I often tell them "if your code feels elegant to you, if you believe you couldn't do it in a different way, then it's probably right". Programming can't just be about facts, it's also about enjoying the process. Is it the right place to discuss this? Well I suppose it's what a public forum is for. 
Yeah, it is what you said: I think he missed the word "except" in your question--I did, too, when I first read it. You get a perfectly clean install of Python, with its own binaries and everything, so you can do whatever you want to it.
PIL shouldn't be a problem (I guess depending on your system) but for psycopg2, I just symlink it into the venv.
Try Learning Python by Mark Lutz, really helped me. There are free books out there but I found that this book was far beyond anything I read online.
Got to agree here, it's very in depth so if you read this you'll have a great understanding to build off. *Edit*: I want to add, while this book is awesome, I want to quickly compare it to another often mentioned book *Learn Python the Hard Way*, while I've read both books, I've found that the path of least resistance to understanding Python and programming was to first read *Learning Python* to get an understanding of the language and then to read LPTHW as a way to test your understanding (especially the later exercises.) I say this because I found that LPTHW took an odd approach to introducing concepts, but at the same time had great exercises to apply what you learned in Lutz' book.
&gt; The main problem is strings: if you want to distinguish a string from a list then the most straightforward way probably is just to use isinstance(x, basestring). I suppose you could use hasattr(x, 'lower'), but that is less clear. This usually means you've made a design error two steps beforehand. You shouldn't need to distinguish between strings and a list since yes, that pretty much flies in the face of duck typing in the first place.
Agree, sometimes too verbose but one of the best. I also learned Python with it and liked enough to buy the new 4th ed when it came (I gave my old 3th edition to a friend). Waiting to buy the 5th (will be py3k only I hope!). Martelli's Python cookbook is also very good for learning, although not in an organized way... a new edition is coming soon, afaik. A great one is Doug Hellmann's Python library book (based on his PYMOTW blog.
I just received Hellmann's book in the post today. I know it's available online, but I had Frederik Lundh's stdlib book and thought it was excellent, this is like that book, *but on steroids*. The 4th edition is, in my opinion the best out of them all, considering it's the branch between the 2.x line and the 3.x line. The 5th edition is indeed a 3.x branch-*only* edition, so for those of you at home, be aware of that.
Thank you for trying to keep the conversation on the rails, and I'm glad you will try to judge Pyramid on its own merits. Your initial comment was: &gt; I'm struggling to gauge how Pyramid is actually simpler than Zope 3 was. Fairly recently I said to a coworker "I'm struggling with jQuery." In reality, I hadn't struggled with jQuery at all. At the time, it just seemed like too much effort to read docs-page-one. If there was a struggle, it wasn't a struggle that had anything to do with jQuery; it was instead my own personal struggle against an acute case of the dont-wannas. But I said it in such a way that it seemed like jQuery was at fault. Was I wrong to say it that way? Yup. It wasn't jQuery's problem, it was mine. But I try very hard to only make these comments out loud to other folks in person who have a shot at understanding the context. I definitely wouldn't put it that way in an online forum. There are two reasons I would not do this: a) I don't want to disrespect the efforts of the jQuery people for eternity in an archive simply to justify my own case of the dont-wannas and b) Someone might actually call me out on it and ask for specifics. Seeing as I had none, I would either need to invent some on the fly or admit that I was just venting; either way it would turn out badly. I understand it's gauche to project my own poor behavior on to anyone else, but I think it's a common human trait to rationalize this way. It's perfectly understandable to me. But I'd prefer to call it what it is, if so.
I agree, the book is extremely well-paced. It starts off with basic, *basic* stuff like assignment and finishes up elegantly with metaclasses. Whilst in-between having some fairly useful detours (explanation of the `timeit` module, I'm looking at you.) I highly recommend to both those who wish to take their Pythoning to the next level (for intermediate) and for those getting their feet wet.
python docs are sometimes too concise for my brain. I mean they are so technically perfect that every word means what it means. No romance. Sometimes I had to read several times a sentence to get it. And this is stressing for my neurons. To learn, for me, low pace and many examples. Having said that, tutorial and library docs have been improving steadily and nowadays, those of 2.7-3.2 are very good imho 
They're not that hard to install if you cheat: sudo apt-get build-dep python-imaging python-psycopg2 I suppose you also need a C compiler sudo apt-get install build-essential 
&gt; Thank you for trying to keep the conversation on the rails. Likewise. I definitely understand your point though, sometimes, those discussions may still be of value (well sometimes... specially if around a beer or two ;)).
I always kind of wanted there to be a myvirtualenv/bin/adopt &lt;system-package-name&gt; to create that symlink for me.
The thing the book doesn't cover though, is applying that knowledge into projects. But it's done on purpose, Lutz wrote Programming Python for that. Another 1000+ page book but it's detailed and shows you the wealth of uses for Python granted he does take the Python 3 path only in the 4th edition but if you're a beginner that's not entirely a bad thing.
The third edition of the Cookbook is slated to release sometime in January or February if I can recall. It was previously slated for this month but it looks like it needs a bit more time. Personally though I liked the path of * Learn Python (4th edition) * Programming Python (4th edition) * Python Cookbook (2nd edition for now though 3rd comes out soon) Sure the first two are huge but your understanding of the language and its applications will grow massively! Then the cookbook acts as a great reference for common tasks.
I've not read *Programming Python*, I flicked through a PDF version and decided it wasn't for me, I might pick it up in the future just to round out my Lutz affair, I do seem to recommend Learning Python quite a bit.
Just to put it out there - I read the Learning Python book over a two month period my first time. Don't be afraid at the page count, embrace it. Programming isn't a quick endeavour, it's a craft you hone and take time over, be obsessive, *LEARN*.
If you use multiprocessing.Pool to manage processes for you, and some of those worker processes die or hang, the Pool does not handle that.
I have no problem installing psycopg2 with pip on Ubuntu and, as far as I remember, PIL is the one with packaging problems. 
Why are the extra parentheses necessary?
Oh, good to know. I haven't seen any use of Pool yet but I'll watch out for it. Thanks!
ah, yeah, I did miss that "except". sorry.
Easy peasy if you're running linux. Mac, not so much. I love my open source tools.
submit a patch?
PIL has been repackaged by a kind soul under the name [pillow](http://pypi.python.org/pypi/Pillow/1.0). I don't know if it's still updated though. But it's worth a look.
That's weird; I've always had the reverse issue. PIL installs fine, as long as you have the necessary libs installed (libjpeg and the like). psycopg2 might work better now than it used to... can't recall, as it's been awhile.
Read Jean-Paul Calderone's comment to this article though, where he says that Twisted doesn't have this problem.
All of the books mentioned on this thread are good. Books are an individual thing. A good strategy is to go through the tutorial until you get bored. At that point you'll have a better sense of which books are right for you. Then get a book.
I understand that they may "feel" equally complex to you, from the outside. That makes sense, really. I mean, if you don't understand anything about either one, they both just look like giant piles of nonsense. The peaks of both mountains are up there in the clouds somewhere, and you don't really have any idea how far from each peak you might be. Speaking as someone who's used both Pyramid and Zope (2 &amp; 3) fairly extensively, though, they don't feel equally complex at all. To continue the horribly flawed analogy, from the upper altitudes you can see that Pyramid's mountain levels off into a large plateau just above the cloud layer, while Zope's continues to climb up and up and up. Pyramid just feels like much less cognitive load. This doesn't mean Pyramid is a good choice for you, nor possibly the best choice for the relative novice. But it feels nowhere near as complex to me.
Yeah, probably not. That still doesn't make me want to deal with the Twisted ecosystem though.
I haven't read it all the way yet. I've worked through a couple chapters but lately I've been working more on learning Django so I've focused more on books revolving around that topic. I've kind of put it on the backburner for now as my development is leading me into the Python 2 world and it is a Python 3 only book.
I'm a big fan of the way this book is put together: http://www.pearsonhighered.com/educator/product/Programming-in-Python-3-A-Complete-Introduction-to-the-Python-Language/9780321680563.page It really gets you rolling fast, then goes into depth. It demonstrates quickly how easy Python is for learning the basics and then shows how powerful it can be.
Seems like a list (or queue) of tuples (or a namedtuples if you prefer access by name vs access by index) would be a better data-structure for you. 
Well, it depends on what you're aiming for here. If you're learning for yourself, go ahead, get a 3.x book. Otherwise, you're going to be seeing 2.x code for a *long time*. So I'd say a 'bridge-book' i.e. one with both 2.x and 3.x in would be more beneficial. I think there is a version of Programming Python like that, no?
0 is a valid hot score, Infact if you have more downvotes than upvotes, your hot score would be negative.
&gt; The post was a good set of guidelines for what applies before you specifically know otherwise. And I would argue that this is a guideline that should not be followed unless you specifically know otherwise. If you can accept more than one type, make sure any common code can really be common across both types or can fail cleanly. This is a good source for lots of very hard to find bugs. &gt; Oh? Serializing builtin objects is a total of 1 line, and writing a JSONEncoder for one of yours is as long as it takes you to express your object in terms of some of those. It's highly painless. Yes, you do that. It will be interesting to see what happens when you add something and forget to handle it in your JSONEncoder. Make sure your implementation guards against "Unserializing pickled data from an untrusted source can lead to remote exploits." Security is easy, right? &gt; Not really sure what any of this means other than being another even more arbitrary hypothetical :). Neither arbitrary nor hypothetical. I'm sorry you don't know what it means to have your software deployed to a massive computing environment, but to me it's a reality where my software must run on many thousands of systems with a common configuration and any update to that common configuration requires spending weeks in security review. &gt; Great. Sounds like numpy. Hmm, let's try: Python 2.7 (r27:82500, Sep 7 2010, 14:21:36) [GCC 4.5.0] on linux2 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; from numpy import * Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; ImportError: No module named numpy &gt;&gt;&gt; guess that rules that out. I need something that works on a standard Python install. &gt; How about 4 :) I'm not sure you followed that thread of conversation. It looks like you gave 4 instances of ways to run tests, but that isn't what was asked.
the GEOS, GDAL, GeoIP utilities of GeoDjango: https://docs.djangoproject.com/en/dev/ref/contrib/gis/ GeoIP is literally the MaxMind Python API, which is not Django-specific at all, rewritten from their C API so that it can be BSD instead of GPL. This has absolutely nothing to do with Django and should not be in their namespace. GeoDjango should really be a generic "Geometry" package with sub-packages for Django ORM integration. I would then get folks to port/rewrite GeoAlchemy, which is a total reinvention of the whole thing for SQLAlchemy, to be another sub-package of it. Then we'd all be on one geometrical framework ! imagine that ! Edit: here's some more: Johnny Cache, Django Cache-Bot, Django Cache Machine. Caching is not a Django-specific problem either. Over in Pyramid/Pylons land, we use a product called Beaker, which is not in any way specific to Pylons, Pyramid, SQLAlchemy, or anything else (it includes some SQLAlchemy-based storage backends, but these are optional, and a "django storage backend" could be added right next to them). But caching needs to integrate into the framework ! you say. This issue can be solved by separating the framework/templating integration from the backends. SQLAlchemy and Mako Templates both offer integration paths with Beaker, as well as with a new caching library I'm creating called dogpile.cache. dogpile.cache, again, not specific to any framework of any kind. Framework integration layers is not the same thing as backend abstraction. Why are there *three* caching libraries for Django who don't follow this practice ? An example of a library that *started* as Django specific, and quickly changed to be agnostic, is Celery. Celery has the right idea by offering variable ORM integration paths. It *can* be done. 
&gt; If you can accept more than one type, make sure any common code can really be common across both types or can fail cleanly. This is a good source for lots of very hard to find bugs. No. You don't accept two "types" at all. You accept one object that provides the requisite behaviors that your function expects. The type is irrelevant. &gt; Yes, you do that. It will be interesting to see what happens when you add something and forget to handle it in your JSONEncoder. You do have unit tests right? And you do know what happens with pickle here, it's even worse when you've changed the code? Not sure what the end of your sentence means, but loading a json object cannot execute arbitrary code. So yes, security *is* easy. &gt; I'm sorry you don't know what it means to have your software deployed to a massive computing environment, but to me it's a reality where my software must run on many thousands of systems with a common configuration and any update to that common configuration requires spending weeks in security review. I don't recall mentioning what I know, nor do I know where you've decided to make that assumption from :). &gt; guess that rules that out. I need something that works on a standard Python install. Sounds like an arbitrary restriction. Again, the OP applies unless you've got no arbitrary restrictions. If you're afraid of third-party modules you're using the wrong language. &gt; I'm not sure you followed that thread of conversation. It looks like you gave 4 instances of ways to run tests, but that isn't what was asked. ??? &gt;&gt; I have used this trick to make running tests easier, but setuptools already provides a better hook for running tests. &gt; Okay, let's see a "for instance" and make sure it is actually easier and faster than __name__ == "__main__" and integrates cleanly with my IDE. The solution for scripts is even easier.
Yep I'm all for that. ;-)
The `&gt;&gt;&gt;` means you are at a python interpreter prompt, and are expected to type snippets of valid python language. The commands you are trying to run are not that. They are commands meant to be run from a command prompt, not inside IDLE. Now would be a good idea to tell us important details like what platform this is, and someone can tell you exactly how to get a command prompt on that platform.
Are you trying to run the command-line call in the Python shell? If so, it doesn't work that way. You have to run it from your terminal/command-line/console/whatnot.
Relevant? http://plope.com/Members/chrism/import_time_side_effects
Huh, they are not necessary it seems.
Because people are lazy :)
&gt; because that is the most used language for Linux programming Say what? There are probably ten times as many things written in C on a typical linux distro than python. Here's a sample: $ for P in python zlib1g-dev libgtk2.0-dev libgtk-3-dev; do echo -n "$P: "; reverse-build-depends --distribution oneiric $P | perl -nE '$section = $1 if /Build-depends in (\w+):/; $total += $sect{$section} = $1 if /Found a total of (\d+)/; }{ say join ", ", map("$_: $sect{$_}", keys %sect), "total: $total"'; done python: main: 182, universe: 894, total: 1076 zlib1g-dev: main: 170, universe: 609, total: 779 libgtk2.0-dev: main: 124, universe: 882, total: 1006 libgtk-3-dev: main: 101, universe: 53, total: 154 This is listing the number of packages based on reverse build-depends, and it means that there are about about 1100 total packages written in python or that otherwise depend on python in some way. It's harder to list packages written in C because it's not policy to list an explicit build-dependency on a C compiler or the libc C library, so I picked two common C libraries for illustration purposes since anything that lists these as build-depends is likely written in C. There are far more packages using just these two C libraries than there are all python packages combined, and again that's just a tiny subset of all C packages.
The third edition is 2.x and 3.x based, I just prefer to read the most current book as it was written concurrently with Learning Python. What I was going to do was read Programming Python 4th edition and follow along writing a 2.x version and 3.x version of all the code. I think it would give me a better understanding in the changes between the two versions.
Though it may be a valid hot score, there were 0 hot score submissions ranked above positive hot score submissions.
caching on the number of votes displayed.
&gt; No. You don't accept two "types" at all. You accept one object that provides the requisite behaviors that your function expects. The type is irrelevant. There is really no point in continuing this if you're going to go off on tangents unrelated to the usage understood from the article. &gt; &gt; If you must have different behaviour for different **types** of objects passed I think my usage of *type* was clear in this context. &gt; Not sure what the end of your sentence means, but loading a json object cannot execute arbitrary code. So yes, security is easy. Security must seem easy when you assume your only exploit comes from code. &gt; I don't recall mentioning what I know, nor do I know where you've decided to make that assumption from :). This: &gt; Not really sure what any of this means other than being another even more arbitrary hypothetical :). Unless the meaning of "not really sure" has changed recently. &gt; Sounds like an arbitrary restriction. Again, the OP applies unless you've got no arbitrary restrictions. If you're afraid of third-party modules you're using the wrong language. I would expect this from someone who thinks security is easy. &gt; The solution for scripts is even easier. Yes, that's nice. Let me know if you ever want to address what was asked.
Do you know how I could get around this so that my scores align with reddit's? Also, sometimes my scores are way off, like for example when number of upvotes is equal to number of downvotes.
Would you mind deleting this post, in case people don't want the answer? &lt;_&lt;
The ups/downs vote numbers that you see are not real. They're fuzzed by the anti-spam code (which is not public.) The actual ranking algorithm has access to the real vote counts, you don't. 
This was a problem with IPython 0.11, but I believe it was all fixed for 0.12, so it should now work with those ZMQ versions. Could it still be trying to import an older version of IPython from somewhere?
Yes, for now they're just static images. Longer term, we'd like to make them interactive, with zooming and scrolling. Note that you can have more than one line in a cell, so you needn't string them together with semicolons. There was talk about adding a config option for the figure closing behaviour (whether you can add to an existing plot after it's rendered). I think it's called c.InlineBackend.close_figs
I don't really want this to devolve any further, but I'll point out that you didn't directly respond to one of the counterpoints I made. If I offended you in some way I apologize, but your post is full of personal attacks, even more than your first one was. I maintain that the OP is a good thing for new programmers to see. In what's likely a majority of cases, you'll want to follow those guidelines (obviously along with plenty more).
Well, I've never used it in this way before (only plugins for GIS and stuff) and there's no instructions on how *to* use it. Information like this would be useful for us lay people
There was a bit of work updating the Emacs ipython.el recently, but I don't think it uses the ZMQ API. If you've got something even roughly working, do let the ipython-dev mailing list know about it. My development environment is pretty simple - an editor and some terminals. I'm not sure what the others use, but again, ask about it on the list, and I'm sure you'll get some tips.
I know how to get a command line. Thanks. Shame on me for not knowing? I guess. But it'd be much easier if there was one sentence in the instructions to do this. Thanks a lot!
That's why it's IPython, not iPython. ;-)
Except I get a syntax error without them. o_O
Alright, ty! I have had a lot of trouble with it under windows.. but I imagine being under windows is the major issue there..
We still absolutely want the basic Python+ experience to work simply and quickly (and it still does). The core of IPython still [only depends on](http://packages.debian.org/sid/ipython) a few small pure-Python modules (which are bundled in our releases) and Python itself. But we've also got more ambitious aims. In particular, IPython aims to be useful for scientific computing. That's the reason behind the close links with numpy/scipy/matplotlib, and for the notebook - as a way to go from data exploration to repeatable analysis, and to have an overview of data and processing together.
Yep, we now ship three ZMQ frontends (the notebook, the Qt console, and a terminal console), in addition to the plain, non-zmq terminal. There's also [vim bindings](https://github.com/ivanov/vim-ipython) using the ZMQ kernel, and Microsoft's [PTVS](http://pytools.codeplex.com/) uses it. Feel free to join the party.
it's worthwhile though to study what others have already done and emulate their good ideas.
More excellent work massimo! Thanks again for this!
In the immortal words of any plumber or mechanic anywhere: well here's your problem, right here! (Imagine that in a thick NYC accent, if you will.) Ditch Windows. You will thank you.
Yes it's still updated :-) http://pypi.python.org/pypi/Pillow/1.7.5 is the latest.
Where that page says 'raked web2py highest', is that like 'raked over hot coals'? Ducks. ;-)
It's not, it's better. Especially since isinstance supports ducktyping via ABCs.
There are a lot of developers with specific needs that are using Django. Building in quick and easy Django compatibility creates a built in audience for your project and generalizing your library too quickly can make it difficult to iterate on in the early stages. I love that Celery evolved into a more general framework. I would love to see libraries such as those you mention do the same. That said, I can't find fault with the developers for writing libraries that meet their needs and not everyone's. If any of those projects refuse to accept patches from the Pyramid community to make them more general (for example), that's another story.
Yeah, what's the deal with all the Flask specific extensions? :P
Exactly that. To encourage people to not write Flask specific libraries. Flask extensions bridge general purpose libraries to Flask. They are not supposed to implement functionality themselves. For instance Flask-SQLAlchemy bridges SQLAlchemy, Flask-Babel bridges babel, Flask-OAuth bridges python-oauth, Flask-OpenID bridges python-openid etc.
Could you elaborate? How are they fuzzed? What is the point of providing inaccurate information?
You have been duly condescending and cocksure in your replies, stop trying to play victim. You seem to think a massive computing cluster is "arbitrary hypothetical"; that "security is easy" as not allowing execution of arbitrary code; and a mandatory security review of all components going into said "arbitrary hypothetical" computing cluster is equivalent to being "afraid of third-party modules." You don't seem to have knowledge of a good chunk of computing domain problems and you don't seem to realize that which is why you do things like trivialize security.
I feel like I've typed out detailed explanations of this topic at least three times in the past couple of years. But for some reason, reddit will not allow you to see more than the last 1000 comments you've made, which for me means going back about 2 months. The site search feature doesn't index comments, only posts, so it's effectively impossible to find anything that you've written in the past on this site, unless you can google it, which I've tried and failed. Reddit is a complete disgrace in this respect, because I'm tired of writing lengthy explanations of things and then being unable to find them. 
&gt; You have been duly condescending and cocksure in your replies, stop trying to play victim. Yes I have had a bit of a rough tone, somewhat purposefully. I haven't attacked you though. *Of course* a massive computing cluster is arbitrarily hypothetical. As I've said a few times, we're talking about general advice here. Your objections are completely irrelevant to that. &gt; You don't seem to have knowledge of a good chunk of computing domain problems and you don't seem to realize that which is why you do things like trivialize security. *Sigh*. I've had enough internet arguing for a day. 
Back when I was using a Mac, I would not rest until I was able to install packages like PIL and Psycopg2 via pip. It's always doable. About 70% of the time the issue is with architecture mismatches. Try running this: env CFLAGS='-arch x86_64' LDFLAGS='-arch x86_64' pip install PIL psycopg2 (I think you can also just use ARCHFLAGS instead for the above) Another 10% of issues can be solved with: env STATIC_DEPS=true pip install PIL psycopg2 If any of those work, just stick the respective variables in your .bash_profile Another 10% of the time, libraries like libjpeg or postgresql-devel haven't been installed in the right places, and just need to be reinstalled with the right PREFIX, or as a last resort, add the paths to your LD_LIBRARY_PATH. The final 10% of time, they're tough nuts that require careful reading of the error messages to crack.
Do you have a resource on the subject that you can point me to? 
[source](http://www.infoworld.com/d/application-development/pillars-python-six-python-web-frameworks-compared-169442) Thanks for the bug report. It is now fixed. :-)
the GeoIP library is an example of a library that *already exists standalone*, I've used the GPL version quite a lot, that was specifically *rewritten to be specific to Django*, as well as BSD. They actually took *extra effort* to make this otherwise general purpose library into a django-specific one.
Yeah, it's not really an option unfortunately. Luckily anything real will be running on a linux box.
Ah, nothing like the joys of developing on an entirely different platform than production. Good luck to you, my friend! ;)
Some readers may appreciate that we eat our own dogfood for everything: the book is written in [MARKMIN](http://web2py.com/examples/static/markmin.html) and we use it to generate the HTML and the PDF (without any manual editing, including references, etc. for all languages). We also use web2py for the online [pdf store](http://web2py.com/pdfbuy). We use stripe.com for credit card processing (excellent system supported out of the box by web2py). The book app supports multiple books, in multiple languages (we currently have the book in English, Italian and Japanese). We also use pdftk and some jQuery plugins. 
Having written 2 non-trivial apps in Pyramid, I can say there's a definitely payoff to learning the framework. Once you learn where you should be passing things around in a request, this make a hell of a lot of sense. Most of the documentation is for the "extras", things like authorization, templating, DB access and ORM. All of these things are optional, but you will end up using them cause they're damn handy. If you want something that you can just bang out "simple" webapps with, I've tried Flask, and it's nice. I wouldn't want to make anything too complicated with it though. Flask also seems to go against the python rule of implicit vs explicit. Ie: in Pyramid, you pass around the current request object explicitly, where in Flask, it's available as a threadlocal global module `g`. I'm not saying either way is better than the other, just different.
Heh, I remember doing "virtualenv envname"..ARG! Forgot no-site-packages, \^C\^C\^C "virtualenv --no-site-packages envname". Thank you again for the change :-)
I had the same problem. Basically, pip did not find the proper libraries, and in turn was unable to generate certain types of images. But this only happened when using virtualenv. For the most part I now use `pillow`. This seems to work fine. 
Thanks for the thanks ;-)
I don't understand how can we give "yield" as an argument to a function.
Please link to [abstract](http://arxiv.org/abs/1112.4482v1) next time..
True but i think they would sue regardless.
As you seem to be new to programming, I suggest the following. They are the best from the learning experience I had. http://learnpythonthehardway.org/ http://www.swaroopch.com/notes/Python http://diveintopython3.net/ Once you learn the basics of language try ProjectEuler and solve problems. Once you solve some problems, create your own petproject or hack some of the opersource python applications. We learn only by doing, so beware of spending too much time on reading. Instead read a little, and experiment a lot. 
Didn't he just say that he does not?
Oh nice. I could maybe publish in that journal as well then. I'm using python to model the standing waves in the focal plane unit of heterodyne spectrometers for radioastronomy. Although I don't make pretty pictures :/.
&gt;We still absolutely want the basic Python+ experience to work simply and quickly (and it still does). The core of IPython still only depends on a few small pure-Python modules (which are bundled in our releases) and Python itself. That's great news! &gt;But we've also got more ambitious aims. In particular, IPython aims to be useful for scientific computing. That's the reason behind the close links with numpy/scipy/matplotlib, and for the notebook - as a way to go from data exploration to repeatable analysis, and to have an overview of data and processing together. That's funny, this is actually the field I work in. And IPython is already damn useful for these tasks, even though I don't use any of the advanced features :) Anyways, I understand perfectly that different people have different needs and tastes. Thanks for making such a great tool, and keep up the good work!
&gt; Published in the Proceedings of the PyHPC2011 workshop at Supercomputing 2011
After looking at it, I think my code is too dumb for that journal. I could be using GDL or Scilab for what I do, it wouldn't change much. I'd rather focus on the results and publish in an astronomy journal instead, or something about microwave/optics engineering.
just as easy on Mac, replace apt-get with brew.
Oh my, I got confused seeing that `f = lambda: (yield)` is syntactically correct (but not what is required). To answer your question: because the grammar [explicitly requires them](http://docs.python.org/reference/expressions.html#grammar-token-yield_atom), to disambiguate between the yield statement and naked yield expression used as a statement I guess (not really necessary from the semantics standpoint and done only to make the parser simpler, if that's true).
This is exactly what I would recommend. The new Cookbook is scheduled for February now according to Amazon.
Good to Great Python reads http://jessenoller.com/good-to-great-python-reads/
So tell me then, what are the main reasons I should drop django for web2py? The only argument I see is that it allows you to build your own stack. 
SimpleHTTPServer is really useful for some stuff, like remote command processing to control components in a multi-machine system. The author should have noticed the name "SimpleHTTPServer", which is not "SimpleWebServer".
Unfortunately this flag is not available in anything but the latest version of virtualenv, so there is no way for me to get this behavior regardless of what version is currently in use. Any documentation that references virtualenv and depends on this behavior is now broken, and there's no way to fix it without giving specific instructions for versions below 1.7 and beginning with 1.7.
&gt; I tried Haskell and I think my brain just doesn't fit it well. I felt like this at first, but after a while I got enlightened. I probably will never use `Haskell` for any "serious" project, but it was quite a ride! The only practical use I had of `Haskell` is configuring Xmonad, and doing some research work with [cryptol](http://en.wikipedia.org/wiki/Cryptol) &gt; How's Erlang, in your opinion? `With Erlang, creating hundreds of threads and synchronizing them is relatively easy. The only problem to a new comer is overcoming the oddities of a pure functional language (no assignment for example). &gt; EDIT: And no, Python is like 90% function programming compatible, since it doesn't entirely have tail-recursion which means that the deep functional constructs you find in the Lisps you cannot do without artificially increasing the recursion depth and even then, you don't get the tail call optimization. Python has the necessary number of functional programming features to make the OO and procedural mind enhance its productivity without delving into the details. As I said before, I usually work with embedded systems and hardware, but learning the functional programming parading had helped me enormously be a better programmer. But that doesn't change the fact that I'm an amateur regarding software engineering, and that I enjoy the safety and the relative stability of the hardware world. 
I bought the 2nd edition PDF and I dropped the idea of working with web2py after trying to do some basic things which proved complicated. I believe the PDF was being sold by lulu.com back then. For example, basic things like working with forms and attempting to work with the framework as with flask, django &amp; rails proved very convoluted. There was no simple documentation on how to do things, just "magic" which did what you wanted and you had to find the exact "incantation" to get it to do what you want. Don't get me wrong, I want to like web2py, I'd like to use it for very rapid prototyping, trying out an idea and perhaps even a small app.
You're welcome! Give the advanced features a try - 18 months ago I was just using it as an enhanced Python shell too, but after finding out just what IPython can do, I've found myself doing much more with it.
unless it doesn't work or meet your needs. then use something else. :)
Well, it's been IPython for [over 10 years](http://archive.ipython.org/release/old/0.0/), and I don't know of any legal threats. And we're not competing with any iProducts, so they probably don't care.
I've made a few about how to setup virtualenv/pip/etc. https://www.youtube.com/playlist?list=PLBA11523409C565CF&amp;feature=mh_lolz
More propaganda: http://python-distribute.org/pip_distribute.png
I will :)
It's so you can turn a method into a read only attribute. class Example(object): def __init__(self, x, y): self.x = x self.y = y @property def method(self): # arbitrary amount of code here # return value becomes the 'attribute'. return (x ** 2) + (y ** 2)
So this is an alternate for getter?
RTFM http://docs.python.org/library/functions.html#property
Not really, but kind of. You can use it as a getter, it really works well for that. You can use it also for things like logging access to an attribute. Anything that needs to act as an attribute, but needs a little more 'logic' behind it.
Hey now. He may have read TFM but TFM may not have made much fucking sense. Hence the thread.
Thanks, I read the Fucking Manual :)
Honestly, buildout is better.
You should not drop Django for web2py. You should stick with what you know better. Anyway, web2py does not allow you to build your own stack. Quite the opposite. web2py is not web.py. The main reasons people like web2py is that it includes a very clean syntax (does not feel like a bunch of modules put together), a web based IDE (which you can try [here](http://web2py.com/demo_admin)), a group based access control, a ticketing system that logs all errors from your users, a database abstraction layer that supports 10 databases out of the box including google app engine so it makes very portable applications. Moreover web2py promises backward compatibility and we never broke it since 2007. Somebody wrote this which you may find useful: http://www.mengu.net/post/django-vs-web2py (not sure how up to date) I made this two years ago http://vimeo.com/6507384 (and surely things have changed on both sides)
I came across this once before. It's an amazing mangling of all the normal scoping and operator rules in aid of a more natural-language equivalent to assert. I could almost believe it was an April Fools' joke. Seriously, consider a line like this, from the example: self.player |should| have(11).cards Quite aside from the fact that the | operator is injecting "have" into this namespace, it's not actually clear what this does. Maybe player has a .cards attribute with the integer 11? Or with a collection holding 11 items? Maybe iterating over player yields 11 "card" objects? In contrast, doing it the normal Python way (if my second guess above is correct): self.assertEqual(len(self.player.cards), 11) It's completely clear what's happening, and it doesn't rely on bizarre tricks.
Can you explain why it is better?
You probably have to know about [descriptors][] first. [descriptors]: http://docs.python.org/howto/descriptor.html
Distribute? How can I work on a python project, and make the virtualenv a part of the package? Right now virtual env with its packages are stored in ~/.virtualenvs/projectname/ but is there a way to have lets say ~/devel/projects/projectname/ all of it in there, the .virtualenv for the project under projectname? Then I could tar it up and send it to someone and tell them click that thing! 
One nice thing is that you can define your classes with attributes, and then later change them into methods without having to rewrite the rest of your code. For example, you might have a class Item that represents an item you have for sale. It could have a cost attribute: class Item: def __init__(cost): self.cost = cost item = Item(5) print item.cost Later you could decide that the cost may need to include freight. You can define cost as a @property, and you will still be able to call it as normal. class Item: def __init__(cost, freight=0): self._cost = cost self.freight = freight @property def cost(self): returns self._cost + self.freight item = Item(5) print item.cost #No need to change to item.cost() 
This is a particularly creative use for them that I had not thought of before. And I'm *all* for being lazy in the future.
* http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-00-introduction-to-computer-science-and-programming-fall-2008/index.htm * http://www.thenewboston.com/?cat=40 Both of them are in the sidebar of http://www.reddit.com/r/learnpython cheers,
I tried from the console and I get this output: D:\GPS&gt;heatmap.py -g CostaRica_1.gpx -o cr.png -b black --height 800 Traceback (most recent call last): File "D:\GPS\heatmap.py", line 793, in &lt;module&gt; main() File "D:\GPS\heatmap.py", line 782, in main ImageMaker(colormap, options.background, background_image).SavePNG(matrix, options.output, options.width, options.height, bounding_box_xy) File "D:\GPS\heatmap.py", line 453, in __init__ from PIL import ImageColor ImportError: No module named PIL D:\GPS&gt; edit: On WinXP by the way.
breaking backwards compatibility - now we need to make stupid version checks in our deployment scripts. yay!
You're using virtualenvwrapper then. Use virtualenv alone and you can put it anywhere you want to. (ie. use virtualenv instead of mkvirtualenv)
Unlike other Python frameworks, web2py follows convention over configuration. The 2nd edition of the book covered a much older version of web2py but explained the basic convention. There is only one basic API to do forms: form = SQLFORM(db.tablename).process() and you embed it in a page with {{=form}}. That is it. It generates the html, processes and validates the form, displays error messages. You can customize it in millions of way (including writing your own html) by passing arguments to the SQLFORM factory and its process method. There is one chapter in the book dedicated to this topic. Speaking with new users, I found that the major stumbling blocks are lack of knowledge of the following patterns: factories, postbacks, callbacks and/or lack of understanding of the http protocol. Knowledge of those patterns is a prerequisite for reading the manual. 
Looks like you need to install the PIL module. 
I see... then whats the point of virtualenvwrapper ? 
Ok thanks! I installed PIL from [here](http://www.pythonware.com/products/pil/), re-ran script and still get same 'error' EDIT: I had two versions of python on here. I installed PIL for both of them, now it works! EDIT 2: man I'd like a nice GUI for this... :-D
To keep them together and make working on them easier for those of us working on 5-10 projects at once. ;)
that was very helpful. Thank you very much :)
[You're welcome](http://www.imdb.com/title/tt0118615/).
Yes, from what I remember `pillow` is the proper packing of `PIL`.
Indeed; the question is why? I see lots of pretty propaganda, but no explanation for what the issue is, or why the change is necessary. Anyone?
Yep. Welcome to the real world!
This is something that has always annoyed me about python. I am admittedly a dabbler, I only use python once or twice a year. But I can never remember which is the right way to do it and how all these things fit together. It seems that packaging is a moving target, and it always leaves a bad taste in my mouth when I am ramping up again. Could someone explain what these things are and how they fit together (or don't)? * egg files * PyPi * easy_install * setuptools * distribute * pip I can at least grok virtualenv. For a language where there's "one obvious way" this stuff is pretty convoluted, especially as an outsider.
I can hardly keep working on one project at a time... 
Some pip features I use: Here the current directory is a checkout containing a setup.py file; python will always import the latest version when you refresh the checkout. ./setup.py develop has a similar effect, but isn't as widely supported. pip install -e . Here requirements is a file listing dependencies, short names are found on PyPI but you can also put the urls of repositories and tarballs pip install -r requirements And of course you can uninstall packages (forgot to mention it because it's been a long time I haven't used easy_install). With the recent addition of extras support, pip has all the features of easy_install (except non-source packages, but that's on purpose), and the implementation seems more robust. But I've also used buildout, it is a good option as well. As far as setuptools vs distribute, distribute is just the successor of setuptools. It is the same codebase, with mostly bug fixes and wider compatibility (with Python 3 for example). If you don't need the extra features of setuptools, distutils is simple, harder to mess up, and ships with Python. Sure the propaganda is knee-jerk, but some module authors don't seem to test their work with pip (or indeed, easy_install), so a simple reminder is useful. 
This might do well as its own post. I know I'd like to learn more - I'm about to declare python as a major component of internal tool development and having better clues about the best way to roll out those tools is worth gold right now:P
Briefly: distutils is a standard library package for distribution and installation, but is somewhat limited. setuptools extended that functionality, and distribute is a fork of setuptools to continue development after the former went a bit dead. Neither setuptools nor distribute is part of stock Python. distutils2 is an extension/refactoring of distutils. This will be in the standard library for Python 3.3 under the name "packaging", which will hopefully improve matters (though I'm not quite sure how). easy_install and pip are alternative command line tools to find and install packages (easy_install comes with setuptools/distribute). Among the differences: easy_install will install pre-compiled 'eggs' (useful to distribute C-extensions), which pip won't. pip can try to uninstall packages, whereas easy_install is a one way street. PyPI is the Python package index, the main directory of installable modules. Yes, we know it's a mess. There are smart people working on it, but a good solution still looks some way off.
In the beginning there was distutils, which comes with Python. And it was okay. Then there was setuptools, and it was better in most ways, worse in a few. setuptools created easy_install (a network-capable installer) and egg files (a packaging format, basically zip with some metadata). And it worked with PyPI (an online package repository full of eggs, that easy_install knows how to pull packages from). And then the author of setuptools stopped maintaining it, but also refused to hand it over to a new maintainer. So it's been in stasis for several years. distribute is a fork of setuptools to move it forward. Same ideas, but actively maintained. pip is like easy_install, except it also lets you easily uninstall, which is a killer feature.
For those pip guru out there, I have a few questions: * Can I use pip to list all my eggs and what versions they have. I know that I can just go to site-packages... But pip command would be convenient. * If I can, does it work in virtualenv directory? * To pip author, It would be nice if pip has a man page.
egg files, easy_install, and setuptools you don't need to know about any more. PyPI is a site that hosts source packages and metadata, distribute (or, preferably, the simpler distutils) are tools to write setup.py scripts, pip is a tool that downloads from PyPI, looks at the setup.py script, and installs the package. The [hitchiker's guide to packaging](http://guide.python-distribute.org/) should cover them well.
Examples on how to use this on various different TARGETS would be great. Example: * S3 * Rackspace Files * Remote servers Also, I couldn't find it in documentation, the plugin system needs to accommodate arbitrary executable. Someone might need to call an external backup tool such as percona-toolkit. That's all the two cents I got.
* egg files are a package -- i.e. a zipped bundle. There are variants (i.e. source and binary) but you probably don't need to worry too much. * http://pypi.python.org/pypi -- the Python Package Index -- is a site that indexes python packages. This is a good resource for what python projects and modules are out there. It is searched by some of the tools below to help install stuff. * [easy_install](http://peak.telecommunity.com/DevCenter/EasyInstall) (now **deprecated** by pip) --tries to make downloading an installing packages easier. I.e. `easy_install foopackage` searchs PyPI for foopackage and installs it locally if found. * [setuptools](http://pypi.python.org/pypi/setuptools) - (**deprecated** by distribute) does some of the work for foopackage. * [distribute](http://pypi.python.org/pypi/distribute/) - Distribute is intended to replace Setuptools as the standard method for working with Python module distributions. **Ignore** (pip uses it internally). * [pip](http://pypi.python.org/pypi/pip/) - **USE THIS ONE** Replacement for easy_install. searches PyPi and installs packages. In order to use pip, you must first install setuptools or distribute. If you use virtualenv, a copy of pip and depencies will be automatically be installed in each virtual environment you create. I tend to: 1. create a virtualenv (normally with my installed [virtualenvwrapper](http://www.doughellmann.com/projects/virtualenvwrapper/)-- a set of shell extensions to automate managing many virtualenvs). 2. Activate the virtualenv `workon &lt; myvirtualenv &gt;` if you are using the wrapper or `source &lt; vedir &gt;/bin/activate` if you are just using virtualenv. 3. that I just use `pip install &lt; foopackage &gt;` and it installs into my current environment and I can use it. Don't need to worry about all the stuff in between. 
[obtu commented about the Hitchhikers guid to packaging](http://www.reddit.com/r/Python/comments/nl4ip/just_a_reminder_to_use_pip_distribute_and/c39zpj6). [I gave the rundown of my normal workflow](http://www.reddit.com/r/Python/comments/nl4ip/just_a_reminder_to_use_pip_distribute_and/c39zsw3)
I agree, no reason to drop Django if you already know it. Anyway, for some more detail see [here](http://www.quora.com/What-are-the-advantages-of-web2py-over-Django/answer/Anthony-Bastardi).
I would stick with keeping your script as a link in the chain: no need to duplicate effort. The one suggestion I would make though would be to add a #!/usr/bin/env python line at the top of your script and then make it executable. That way you can drop the explicit call to python in your pipeline. I do this with a number of my scripts, name them something (without the .py) and store them in /usr/local/bin
Can you think of a specific example of something you found tricky in web2py but that would be much easier in Flask, Django, Rails? Or was it just lack of documentation at the time (a lot has been added since the 2nd edition)?
&gt; pip is like easy_install, except it also lets you easily uninstall, which is a killer feature. Another big feature of pip I like is `pip freeze` which will output the current versions of the packages that you have installed. This can be put into a ['requirements file'](http://pypi.python.org/pypi/pip/1.0.2#requirements-files)-- this could be checked into source control or sent in a bug report so the *exact environment* (or somethign pretty close to) can be recreated.
Apparently, pip freeze 
* egg files - zipped python packages, still used, but not as much anymore, best practice now is just to make everything install from source (tgz) * PyPI - central repository of python packages, this is what makes "easy_install PackageName" work, * easy_install - comes with setuptools, command line tool for installing python packages from PyPI, eggs, etc. * setuptools - library for building and installing packages, paved the way for other packaging tools, but development started to slow down.. which led to distribute * distribute - fork of setuptools with a new team of developers, bug fixes, new features, refactoring, etc. * pip - command line tool for installing packages from PyPI, version control, etc.; works in conjunction with virtualenv
I agree with searchingfortao but would add that the subprocess module does make connecting processes together into pipelines pretty nice. If you have a simple case of of process a, b, and c then just leave it like it is. Another note that I've done a little bit more recently is making python packages that are installed into the python environment and then invoking them as a module `python -m mymodule`.
I recall that it took quite some time to build a little product listing app back in those days. It took about 2-3 days and about 8-15 hours of work to get it done. I believe it was the lack of documentation and the fact that the DAL's ORM was tightly connected to the forms and everything. It felt unnatural. edit: by tightly connected, I mean to say that it seemed "magic" was behind it and no documentation to describe EXACTLY what was going on behind the scenes.
Distribute? Whats it do? Or how does it work for you?
The documentation back then was a bit weird and it was quite difficult for me to get up and running back then with web2py. Perhaps it's not a fair comparison, but I like the way one is able to just work with flask - just look at the documentation when you need something you haven't used before and you're done in 10 minutes. I'll make sure to give it another try and let you know if I come across the same issues I encountered back then. Perhaps the documentation was the only issue. Thank you for your reply and for your help.
&gt; And then the author of setuptools stopped maintaining it, but also refused to hand it over to a new maintainer. What, why would he do thaat?
Is there a really nice simple tutorial for getting your package working with distribute? I've got a package from a bunch of .py files to being in pypi using setup tools. How would I do that using distribute? How do I make an egg? Is this what I want to be doing? http://guide.python-distribute.org/creation.html
The historical perspective makes them all fall into place. Thanks for that.
I'm still having trouble finding any real use for virtualenv. I think perhaps it's more useful for Unix types on shared hosts who won't upgrade past 2.3? The other problem with virtualenv is that each developer on a project has to set it up individually, so you can't really store it in source control, which in turn means keeping your external dependencies in source control is awkward.
Maybe I missed it, but is there something in the docs that says what environments (Unix, Windows, etc) it works in, and what dependencies it has?
Sign up for the beta here: http://pythonpackages.com/. Help is coming.
I had the same initial reaction to this. I think it's actually less clear. I know I sound like an old-timer, but stop fighting your language guys. I'm all for progress, but this looks like a step backwards. Imagine when this lib isn't maintained any more and you wrote 1000 unit tests this way. You won't feel so clever then.
The problem is that "check whether it does something you need it to do" tends to mean "try something and assume that if there was no exception, then it worked" - but that is no guarantee that it did the right thing. eg. I could insert values into a pre-sized list like so: `x[0]=0; x[1] = 10; x[2] = 20` and return x. When I iterate over it, I would expect to see 0,10,20. But, it turns out that I get `0,1,2`, because I accidentally passed in a dictionary instead. Slavish adherence to duck typing can result in trying to find some arbitrary operation that you know will fail on each type that you don't want, because you have no way of guaranteeing that every object that supports the small part of the interface that you're using will do what you want. Or, you can use isinstance on these occasions instead.
Gotta agree with all of this. Duck typing has given me trouble when a function uses just 1 or 2 simple methods on an object and those methods are available on lots of different classes. The end result is that your object gets broken and you don't discover until potentially much later on when you try to use it. (eg. the wrong type gets serialised, sent off to another computer, deserialised, and things break.) Using assert and isinstance is useful there as a sanity check. Writing JSON encoders for every object you store or will ever store is a hassle, and expecting a well-defined structure for objects that will change often during development is unrealistic. Pickle is a decent stop-gap if you don't need human readable data. A general purpose JSON serialiser for Python objects would be handy. [jsonpickle](https://github.com/jsonpickle/jsonpickle exists) but has bugs, which demonstrates that this is not as trivial as the article might suggest. PyPy as the main approach to speed is not going to work until PyPy supports all the extensions that we use, and besides which, it is not faster on absolutely every task anyway. 
I disagree with most of that, and mentioned most of my complaints in other comments. But also: - I don't think the monolith that is Twisted is 'the best' we have for asynchronous programming in Python. Most fully-featured, sure. But I don't think most of us want to go down their recommended route of using the Twisted daemon, Twisted applications, and so on, when everywhere else is trying to make these things more lightweight. They could do with focusing on the core reactor/server/protocol stuff, really. - 'Just re-run your program' is not a reasonable alternative to reload(). Being able to make changes to a live program is very useful in a lot of circumstances. Recognising that reload() has flaws is fine, but people might want to look into some of the workarounds instead of giving up on this entirely. 
I just filed a bug for the manpage: https://github.com/pypa/pip/issues/415
So what would be a good "use case" for web2py?
To your second point, you could probably just do: pip freeze &gt; requirements.txt And store the requirements.txt in the source control. Then other developers can do: pip install -r requirements.txt in the virtual environment to bring theirs up to date. (Note: I'm no expert with virtualenv and pip.) 
&gt; PyPy was four times faster than cython for this example. I think you mean CPython. (good article btw)
you're still welcome.
If you follow Chapter 3 of the book, step by step, you'll be able to build an image blog in no more than 2 hours. That should be most of what you need for a product list app. Personal opinions aside, the goal of tightly coupling things together is so that they work nicely and naturally together. This is what many feel about the way web2py works. Now, tight coupling implies inflexibility in some cases. But it's interesting to hear that tight coupling in web2py makes it feel unnatural. In fact, I think it feels more natural than getting Flask+SQLAlchemy+WTForm to work together. The web2py book is less of a API reference and more of a comprehensive tutorial. It tells you clearly how to use the system. It is true that the book doesn't tell you EXACTLY what goes on behind the scene. But then again, I don't think any other framework's documentation tells you EXACTLY what goes on behind the scene. In comparison to getting a bunch of libraries to work with a microframework, web2py is conceptually less flexible and "tweakable". Same is true for any full-stack framework. And when you compare web2py to Django, for example, anything Django can do easily, web2py can't do just as easily. The main thing that people should worry about, I think, with web2py (or any Python framework) is that if you can scale relatively well with web2py. But, so far, there does not seem to be any indication that web2py is worse than other frameworks in this aspect. 
It's quite good if you work on a team, usually, especially when you need to set up non-Python stuff as well as Python stuff (for example, relational database configuration, process management configuration). The rules for setting up a complete Python + non-Python environment can be spelled in a configuration file; you tell team members to run "bin/buildout" whenever any configuration changes instead of sending them an email with arbitrary steps they need to follow to update non-Python stuff.
A non-trivial web app that consists of database, forms, authentication, ajax, and not-to-much controller logic. Many (most?) traditional web apps fall into this category. If your situation falls into this, I would say that Web2py beats any other Python framework. You can quickly, comfortably, happily, incrementally build a system. Incremental changes to your model, logic and views are effortlessly taken care of. Session handling might not be web2py's strong suit.
The subtle implications are there anyway; most of the perl (and sh) code I've ported to python didn't actually handle them any better, the code was just wrong, and the explicitness exposed existing bugs. There is overhead (though check_call and such help) and there's certainly room for a wrapper on top of subprocess - but I find it very helpful that subprocess (by taking an array) makes it much easier to get quoting right, vs. the "easy" os.popen case that usually gets it entirely wrong...
OK, I guess I disagree with your general assessment, so it would be helpful to see a concrete example of something you found "convoluted" or "magical" in web2py yet consider straightforward and easy in one of the other frameworks you mentioned. Perhaps it was more of a documentation issue, which likely has improved since then.
Does pip work with RPM, and are there any good "best practices" / howto sites for using them together? All our internal software distribution for RHEL / CentOS uses rpm and yum.
I think you missed the point there: they wanted to make it easy to use with Django. They didn't kill off the GeoIP library or in any way adversely affect that project, they extended it to be easier to integrate with another project. Failing to see the issue with this, despite your *accusatory tone*.
[Python Miro Community](http://python.mirocommunity.org/author/3) and [US pycon videos](http://blip.tv/pycon-us-videos-2009-2010-2011)
I'm guessing that pip can use a requirements file to rebuild the environment? Or do you need some other tool? My problem is that I don't consider myself a particularly qualified software engineer, but I was kind of thrust into that position. I got a frankenserver up and running pretty quickly that's serving an application I had to develop quick and dirty, using apache and django. Now, I need to clean it up. I'd like to be able to clone the environment so I can get set up staging, testing and development environments, and be able to quickly recover just in case the server goes kerflooey. Part of the problem is that the server relies on some non-python libraries or other binaries, like zbar for bar code reading, and image magick compiled a certain way for support for JBG files that our scanner creates. I was told I need to learn how to create debian packages for those, but I'm kind of intimidated to dive into that. make files scare me. Also, there's always constant pressure from the higher ups to add or improve features, instead of going back to review and clean up what has been done already.
Let me know when you change your mind... again... about the latest *new and shiny* package manager.
I don't know. You might check http://www.pip-installer.org/en/latest/requirements.html#the-requirements-file-format for details on how to specify sources... I know you can tell it to install from a bunch of different sources but scanning it really quickly i'm not spotting RPM stuff. Perhaps that's where you need to look at distribute more (I believe the layer underneath pip) more... or just keep using a working system ;-) More generally (for other people wondering about system packaging vs pip): If I see if it is packaged by ubuntu I install from there, unless I particularly need the latest version and then I pip install (from PyPI). Things tend to work. On the other hand, this is what virtualenv is for. When you are runing in a virtualenv none of the system packages matter (well, depending on the --no-site-packages flag which just became the default a couple weeks ago). Only packages that have been installed to the virtualenv or are part of the main python distribution are in the path at that point. Inside the virtualenv pip automatically installs *to that virtualenv* and it all works beautifully. On some projects I've even downloaded the packages from PyPI and committed the tarballs into source control with the project. Another developer can then get a clone of the project and have *everything* (short of python itself) necessary to get the project running in a known good state. 
**Python Osmosis (50 Tutorial Videos)** http://python.secsup.org/ If you can't get them, there check youtube. Those videos are nice and short and should give you a good basic Python foundation.
I've put in the MIT license - for something this short it seems sufficient. Background: like many others, I was once vexed by `sum`'s refusal to sum strings. `''.join` is idiomatic, and preserves (by naming) the distinction between summing and concatenation ("joining"), but I find the method-of-the-joiner syntax awkward, especially as it requires you to work artificially with an empty `''` joiner. It's also inconsistent, in my view, with the interface provided by the new `print` function where there is a separator keyword-argument that effectively "joins" the output strings. I also thought it would be neat to have a single function that can join arbitrary joinable things, without having to worry about the type, and automatically delegating to the fastest possible methods. join.py is the result of a couple of hours (spent a few weeks ago - I finally got around to publishing) of thought about the problem, along with performance testing of some different techniques for concatenating sequences. The basic idea is that the type-of-thing joined is inferred from the supplied separator, if possible, and otherwise from the first provided item. join.py can join: - `list`s and `tuple`s (they can be intermixed freely, since it would require an artificial type-check and rejection otherwise; the result will be coerced to the inferred type) - `str` and `unicode` objects (result is `unicode` if any input or the joiner is `unicode`; otherwise `str) - `set` and `dict` objects, which produces a union of the inputs (including the joiner, if provided) - Other objects providing the relevant interface (including, for example, `collections.namedtuple` - although here the result will be coerced back to `tuple` for hopefully obvious reasons; but this is mostly meant for user-defined types) - Any other iterables, such as generators and files (using fallback logic that invokes a lot of `itertools` magic). I wrote this for 2.x, and should be able to test under 3.x soon. I would appreciate help writing tests, especially if someone finds a test case that behaves unexpectedly :)
buildout helps with that. 
Mod here, going through the spam queue. Please don't use URL shorteners to post links, because they trigger the spam filter. Instead post links like this: Here is [my blog post](http://www.pixelmonkey.org/2011/10/29/import-this) about them. Thanks!
Not exactly. 
`virtualenv` is useful if you're working on several projects that use different versions of the same library.
&gt;so I can get set up staging, testing and development environments, and be able to quickly recover just in case the server goes kerflooey. Check out fabric and south for django. We also used mercurial for a repo but you can use whatever suits your needs. If you push code from your dev and then use fabric to update it (you'll want different sections for different servers...staging and production for example) and something's wrong just revert the local repo changes, use fabric again, and then figure out what went wrong.
*hands you more coffee*
I stopped reading at "Read the massive doc string" and "No tests". Sorry man, I don't trust code that doesn't have real docs or tests. Hopefully you find the time to clean it up and make it usable for us outsiders!
I created a script to scrape the US PyCon videos of off blip.tv. It uses [Scrapy](http://scrapy.org) and can be found [here](https://github.com/pjob/pyconscrape).
As well as linking to the abstract I should have also linked to the website http://yt-project.org/ The installation script has been tested on most of the Teragrid as well as on a number of private clusters and Linux and OS X machines and has the following dependencies: Python-2.7.2, but not (yet) 3.0 or higher NumPy-1.6.1 (at least 1.4.1) HDF5-1.8.7 or higher (at least 1.8.7) h5py-2.0.1 (2.0 fixes a major bug) Matplotlib-1.1.0 or higher Mercurial-2.0 or higher (anything higher than 1.5 works) Cython-0.15.1 or higher (at least 0.15.1) 
All it allows you to do is to define functions to replace the standard methods for getting a variable, setting a variable, and deleting it. If you call x = Y() X.x = 5, you expect print X.x &gt; 5 but `X.x = 5` will call the x.setter method with value 5, `print X.x` will call the x.getter method. If you call `del Y.x`, you similarly expect Y.x to give an attribute error, but you can hijack all of these calls.
NO. THE DIKTATOR HAS SPOKEN. :-)
Downvote for wanting docs and tests? Sorry I like quality stuff =/
Yes, sort of. `property(getter, setter, deleter)` is a quick way of creating a [descriptor](http://docs.python.org/howto/descriptor.html). When used as a decorator, only the first argument (`getter`) is passed the original method as usual. In short, a descriptor is a way of letting an object decide what happens when it is accessed as a proprety on anothe robject. A *descriptor* is an object with any of the methods `__get__`, `__set__` or `__delete__`. Python will call the appropriate one when a descriptor is found as a property on something. Note that it's the property itself that's the descriptor, *not the containing object*.
Reminds me of the old [Infix Operators recipe](http://code.activestate.com/recipes/384122-infix-operators/). 
 NumPy 1.5 achieves the goal stated on its cover "Learn by doing: less theory, more results". In my opinion, it is an exciting introduction to the large numpy module. Many of the examples pertain to money: stock market analysis. I learned quite a bit even though I was quite familiar with numpy prior to reading. From the basic additional functionality of arithmetic operating over all data at once, to advanced math of polynomials, fast Fourier transform, singular value decomposition, to visualization with graphics, NumPy 1.5 motivates the python programmer to install and use numpy. The book assumes facility with python. For instance, author Ivan Idris expects you to know how to examine directories and files with your operating system. He expects you to know to import datetime and sys as you read the book. Since these are included in the companion code it may help to browse these sources alongside the text. Frankly, I appreciated being treated as competent. The book does not cover all the available random distributions, special functions, optimizations for special matrices. Nor should it as an introduction to numpy. Ivan provides direction for your further investigation. I jotted a few notes as I read: &gt; The numpy installation instructions were included for several operating systems. My installation on ubuntu was perfect; &gt; The author employed a helpful a method of frequent summaries and quizzes; &gt; In many instances multiple solutions were presented for a task; &gt; NumPy 1.5 treats broadcasting almost implicitly. In chapter 1 we see an_array**3. It seems worth repeating that each value of the array is cubed, taking us back to the near origins of interactive computing, APL and Dartmouth BASIC; &gt; In addition to the tab completion help of ipython which was recommended, I'd have liked to also see advocacy for numpy.lookfor and numpy.info in chapter 1. These handy documentation search functions assist finding the right method among the large numpy extension to python; &gt; I had to search the internet for matplotlib. Should NumPy 1.5 Beginner's Guide have explained the straightforward installation? After a brief tour of numpy basics in chapter 1, NumPy: Beginner's Guide introduces additional numpy functionality and concepts with real-life examples as promised on the book's cover. For me the material from chapter 5 onward became easier, perhaps because both the author and I are physicists. Chapters 3 and 4 demonstrated numpy features to analyze stock market data. Chapter 5 continued by synthesizing wave forms with Fourier series. I enjoyed seeing the ringing created using a small number of terms of the Fourier series. On the the other hand, NumPy zipped through Eigenvalues and singular value decomposition without real world examples. Wherein the earlier chapters emphasized curve fits, it would have been appropriate for the SVD example to fit a lower order polynomial to same data. Also marginally interesting: FFT of stock market data. You might consider my complaints illegitimate. The book isn't a linear algebra text. If you know you need this functionality you probably understand it and now you've discovered that it, and more, is easily accessible from numpy. The functionality of numpy is akin to a verbose form of APL, my first programming language. Thus I might be overly harsh. NumPy 1.5 introduces the rich numerical numpy toolset enabling rapid insight through a variety of approaches to manipulating data. I've used numpy for scientific computing. I recommend numpy for python even if all you need is to add two lists together, and I endorse Ivan Idris's NumPy 1.5 Beginner's Guide. It will familiarize you with numpy and help you to use it effectively.
according to some, the diktator, also demands moving to python 3, yet, the diktator is one of the engineers for google appengine (which is currently on 2.5, python2.7 is experimental and slow as hell). So how can I know the diktator has my best interests in mind? /anticipating fanboi downvotes to oblivion now bring it on
 #!/usr/bin/env python """This is a docstring which shows how to use the str.join method. The great thing about this docstring is, it can also be used for automated testing. &gt;&gt;&gt; a = [str(i) for i in range(1,5)] &gt;&gt;&gt; ''.join(a) '1234' &gt;&gt;&gt; ', '.join(a) '1, 2, 3, 4' """ if __name__ == '__main__': import doctest doctest.testmod() [`doctest`](http://docs.python.org/library/doctest.html) is your friend. 
Seriously? The "massive doc string" is 40 lines tacked on to about 100 lines of the most heavily-commented code I've ever written, and fully describes the interface to the code and expectations for input. Tests are coming. As for trust, the code is right there for you to review. After skipping the docstring and comments, it's 64 lines. IMO if you can't be bothered to review that little code that's offered to you without any attempts at obfuscation, you have no business complaining about not being able to "trust it". (Also: you're seriously going to initially distrust the main part of my code, but trust the test suite enough to run it, and then assume that the main code is safe because the tests passed and don't appear to have "pwned your box" or whatever? Really?) I also don't have any idea what you mean about being an "outsider". It's a public repository for code hacked up by an individual.
So I hear, but I've never had a reason to do that in the Python world. Hard to imagine I'll run into one either.
I am familiar with it, thank you. I suppose that tests speak louder than words. Setting up a test using a user-defined joinable class is non-trivial, though. The help I'm looking for with tests is in ensuring that I actually have a reasonably complete set of test cases. But I'm probably making that out to be harder than it actually will be :/
Maybe it does: shame their tutorial is 4 years old, which is a long time in Python packaging terms, and is written in terse bullet points rather than clear text meaning it's hard to get a clear idea of how I'd use it.
and if you want to know what's in your virtualenv (or want to reinstall the packages on another machine later): pip freeze --local &gt; requirements.txt pip install -r requirements.txt These two steps have been the single most productive change I've made with my python developing workflow.
I have 2 I've run across so far: 1. Django &amp; django packages — some require different versions of Django or a django packages 2. The python imaging library (PIL) and even this package can get borked by the C image libraries made available on your dev setup.
I think you get it, but I would take 2 examples (even trivial ones) over 8 paragraphs of description. 
Okay. But I don't know how to use your `join` function, nor do I know whether `join` is the only "public" function in your module. I'd like to see some examples, and doctests in docstrings also happen to be testable examples. (Someone else here has complained that there are no tests.) 
I hate to be that guy, but: alias hc='grep httpcodes.db' Busting out Python feels like overkill for this.
Yesterday I posted up a bash script on how to make your terminal snow with bash ( https://gist.github.com/1505483 ) and a lot of people seemed interested but didn't like bash. So here it is in python. If your terminal font supports it you can replace * with ❄ to make it more festive
Comments are different than documentation and tests prove the code works as expected. I can't spend time reading the code in detail enough to know that you didn't miss an edge case. I also can't trust that with updates you wont have regressions because you have not tests to prove the functionality. I'm sorry you think that commenting the code and not writing tests is the right way to develop stuff. We have different opinions on this. Don't take it personal, I just like good documentation and tests with libraries I use. Sorry if I offended you by raising my concerns.
I hate to be that other guy but shouldn't that be: alias hc='grep -f httpcodes.db' Also it would be good to have an absolute path to httpcodes.db Maybe /usr/local/share/somewhere would be a cool place for it.
Now if only they didn't name it the same as the perl utility... 
where is the code?
So here's a question. If I replace the * with \xe2, I get a ?. But If I replace it with a ❄ and add this to the top: # coding=utf8 then I get the snowflake. Do you know why?
Click the reddit link
The string isn't marked unicode in the example. Put a u in front of it like &gt; print u"\033[%s;%sH\xe2" % (snowflakes[col], col) and it should work
Yeah, right, and I'm sorry if I offended you by releasing something a bit prematurely for your tastes.
I couldn't help but notice that you haven't included any tests or documentation, not hours after criticizing me for the same omission.
Because this is not a project I am maintaining or marketing, its a random funny utility that puts snow in your terminal. Thats kind of like telling Colbert or Jon Stewart that they aren't reporting news... they are a comedy show, not a news show! This is just for fun, if it breaks, who cares, and there is no use of it other than running it, so no docs needed.
Here is an example of a project I do maintain and let people use if you want to see documentation and tests :) https://github.com/sontek/pyramid_signup
Cython != CPython. Thanks I will fix the typo. 
So what's next, SNOBOL? 
For the record... these are by no means flagship applications. This is a collection of simple ones built as learning examples. Production quality apps are not listed here and they have their own repos.
Yeah, I messed up the argument order. And now I'm going to be that other *other* guy. Your way doesn't work either: `-f` doesn't do that, at least in GNU grep. You're looking for: `alias hc='grep httpcodes.db -e'` True. Additionally, this wouldn't work for multiple line responses (all of them in this case). You'd have to do something like `function hc() { echo $(grep "$1" /usr/share/httpcode/httpcodes.db) }`, and encode the database with a literal \n for linebreaks. This starts to suck for editing.
'stty' is not recognized as an internal or external command, operable program or batch file. Traceback (most recent call last): File "New Text Document.py", line 6, in module rows, columns = map(int, os.popen('stty size', 'r').read().split()) ValueError: need more than 0 values to unpack 
What operating system?
W7 x64 running python 3.2.2 (I changed your print statements to be 3.0 compatible.)
Submit patches! :) Yeah stty is a linux thing. I just added some code that should make it portable to windows but I don't have a windows machine to test. Want to give it a shot? https://gist.github.com/1508912
I think you maybe can output some text(page number) in specific position(x,y).
I added python3 support for you
Sure I'll give it a shot. Problem is I don't know how to use git. I'm still in school and we don't go over SVN and version control at all in class, quite depressing really. I'm just starting to get exposed at work, but I'll poke around and see what I can do.
&gt;snowjob.py Intentional? I see what you did there.
'clear' is not recognized as an internal or external command, operable program or batch file. Traceback (most recent call last): File "stuff.py", line 77, in &lt;module&gt; snowflakes[col][1])) File "C:\Program Files\Python32\lib\encodings\cp437.py", line 19, in encode return codecs.charmap_encode(input,self.errors,encoding_map)[0] UnicodeEncodeError: 'charmap' codec can't encode character '\u2746' in position 7: character maps to &lt;undefined&gt;
Ok, so the windows terminal doesn't support those unicode characters. Can you change the function get_random_flake to just return "*" and try?
If you grab the latest source I added compatibility to fix both the errors you were getting 
I made a fork but you put a try / except and output a star for me so that fixes what I changed =) Also, you need to use CLS, not clear, on windows. Sample output: http://pastebin.com/1vVBFApT
Ok, so its running now :) Looks like windows command prompt doesn't support the character codes we use to move the cursor around. I googled around a little bit and it seems if you import this first: http://code.google.com/p/colorama/ it might work? Want to try it and let me know?
After you install colorama add: from colorama import init init() and you should be good to go
With your get_random_flake() I get: Traceback (most recent call last): File "stuff.py", line 104, in &lt;module&gt; snowflakes[col][1])) File "C:\Program Files\Python32\lib\site-packages\colorama\ansitowin32.py", line 34, in write self.__convertor.write(text) File "C:\Program Files\Python32\lib\site-packages\colorama\ansitowin32.py", line 115, in write self.write_and_convert(text) File "C:\Program Files\Python32\lib\site-packages\colorama\ansitowin32.py", line 142, in write_and_convert self.write_plain_text(text, cursor, len(text)) File "C:\Program Files\Python32\lib\site-packages\colorama\ansitowin32.py", line 147, in write_plain_text self.wrapped.write(text[start:end]) File "C:\Program Files\Python32\lib\encodings\cp437.py", line 19, in encode return codecs.charmap_encode(input,self.errors,encoding_map)[0] UnicodeEncodeError: 'charmap' codec can't encode character '\u2745' in position 0: character maps to &lt;undefined&gt; Here's the code that works! https://gist.github.com/1509321 
Can you take a screenshot? I want to see it working on windows!! Are you sure you were using my latest get_random_flake? 
I'm trying to get into python with minimal programing experience. I just downloaded python 3.22 on Windows 7 64bit to try out your program. It's not working as of now, but that might just due to my noobiness. 
Yeah school won't teach you much about Version Control. The best way to get comfortable with it is to just version control your own, small projects. I started an [open-source project](http://github.com/prezjordan/Melopy/) last summer (I'm a student too), and it taught me so much in such little time.
You need to have colorama installed for it to work and grab the latest script (I just updated the windows support for it within the last 5 minutes). Paste me the error you are getting if it doesn't work.
http://code.google.com/p/colorama/
I just googled colorama, and nothing on page 1 seems like something I can download to fix this. Lol. Please explain.
http://code.google.com/p/colorama/
Sure! [Windows snowflakes](http://i.imgur.com/xMHHB.jpg) Triple checked. Your get_random_flake still isn't working on windows. Confirmed above error.
Awesome! Thanks for testing :) I added a get_random_flakes that should work for you now as well
Thanks. I really appreciate the help. I think the problem now is that I don't know how to run the code properly. 1. I double click the snowjob.py, and cmd pops up for a sec and goes away. 2. I open it in IDLE and do F5, I can see [this](http://i.imgur.com/flLOv.png) sorry for the extreme ignorance.
:) At least that python shell has unicode characters! Just open up your command prompt, start -&gt; run -&gt; cmd and then type python snowjob.py and it'll run. It wont be as pretty as in OSX or Linux because the windows terminal lacks certain features that are needed but I built in fallbacks for them.
:D
and can you open up your python terminal and type import colorama to make sure that it is actually installed?
Shutup and take my karma!
http://i.imgur.com/lc1Tz.png
http://i.imgur.com/Vdq9Q.png
Install colorama and then everything will work for you.
That is done by double clicking the setup.py? I did that before those screen shots.
run python setup.py install in your terminal
I did that and it gave some error, but the demo01.py works http://i.imgur.com/6imEg.png
would cython even compile this?
You missed the word 'install' afterwords python setup.py install
Okay, typed "setup.py install" into cmd. Colorama installs. I type "import colorama" in the python terminal, and no error is given. Then I type snowjob.py into the windows cmd, and here's the result. http://i.imgur.com/fQH14.png
pip does not in any way integrate with RPM (or APT, for that matter). In many ways pip and virtualenv are the antithesis of the system-package manager: they're intended for "privately" installing software on a per-application basis, rather than system-wide. If you need to build RPMs, you should follow [the Fedora packaging guidelines](http://fedoraproject.org/wiki/Packaging:Python). I *thought* they would provide a tool for building an initial .spec file automatically but I can't find one. Such tools exist for Ruby gems and even R modules, so I'm shocked to not see one for Python. The [docs for packaging eggs](http://fedoraproject.org/wiki/Packaging:Python_Eggs) look a little more concise, and could be modified to use distribute instead of setuptools without too much trouble.
Dang, I thought I fixed that issue for windows. Do you have the latest script from https://gist.github.com/1508912 ? If you have the latest, the fix is just to remove everything out of the get_random_flake function other than return " *"
Nice :) I don't mean to be rude, but vague questions are difficult to answer. In this case, for example, it would be helpful to others if you say what exactly you don't understand about @property, what you tried and didn't work (I did X, I expected Y because I thought that Z, but I got Y' instead). The better and more concrete the question is, the easier it is for others to answer it. Vague questions require the people who want to help you to guess what your question really is, or to just send you some related answer and hope for the best. Hardly the best way. I suggest http://www.gerv.net/hacking/how-to-ask-good-questions/ That said, if you still have problems with @property or anything else, feel free to ask and I'll be happy to help.
yep, I got the latest. Taking all that stuff in get_random_flake out works. http://i.imgur.com/ZlxWg.png
Its really weird, if you have the latest it shouldn't be returning anything but " *" if you are on windows but if you just delete everything but the return it will work
Never fear - awk is here! function hc() { awk -vcode=$1 'BEGIN { FS="\n"; RS=""; } { if ($1=="Status code "code) print $0 }' /usr/local/share/httpcode/httpcodes.db } This allows httpcodes to be formatted as a multiline text file. Each record must start with "Status code " then a numeric http code number. There must be a blank line between records. For example: Status code 100 Message: Continue Code explanation: Request received, please continue Status code 101 Message: Switching Protocols Code explanation: Switching to new protocol; obey Upgrade header Status code 200 Message: OK Code explanation: Request fulfilled, document follows
http://i.imgur.com/ZlxWg.png Yep. Thanks for all the help. This will be a first step into learning python for me :) What does it look like on your machine? I'll probably try it on linux tomorrow. 
Can you try the latest script now? This is what it looks like on mine: http://i.imgur.com/xssAV.png
Both of the last two revisions work.
Awesome! Thanks! :)
What is the performance of this? Why should I use it instead of .join or appending list to list or... ? 
I hate to be yet another guy but surely you know all the most common status codes and if it's one you don't know, wouldn't you just google it?
are they videos or just audio ?
Isn't it awesome how you post some code which works perfectly on your own machine, but 35 people find bugs you never saw coming?
Will wikipedia do? function hc() { dig +short txt http_$1.wp.dg.cx }
I din get your question. 
[This is Cython](http://cython.org/). It compiles something similar to Python into C, and is useful to speed up performance bottlenecks or to write library bindings concisely.
That's the claim. In a previous job there were two developers who were buildout evangelists. They would come over to my desk and say things like "it's really easy, you just run one script and it does it all automatically"! Two or three hours later they would return to their desk muttering something about recipies, and leave me to repair a hopelessly broken project. This was a few years ago, and I realise I'm probably being entirely unfair to buildout, but it has left me reluctant to consider using it again.
PyPy doesn't do that.
Was it really necessary for the title to start with 'Just'? &amp;#3232;\_&amp;#3232;
dumbass
Your answer reminds me about ESR's how to ask intelligent question.
Kudos for not forgetting the HTCPCP RFC and implementing code 418 :D
We've been using [distutils](http://docs.python.org/distutils/builtdist.html) pretty effectively and the Fedora guidelines are the foundation of our internal standards. pip looked interesting, and I was hoping it would give us easier access to more current versions of Python. Thanks for the feedback.
I'm relatively sure the numbers can be done using [pyPdf](http://pybrary.net/pyPdf/), where you iterate over the pages, and insert the number (as a string) in the canvas. The bookmarks I'm not that sure. Depending on your final requirements, a more flexible toolchain may help (the possibility of (batch)postprocessing pdfs is limited). For instance, I try to keep the source documents in a flexible, plain-text format such as Markdown, and use e.g. [pandoc](http://johnmacfarlane.net/pandoc/index.html) to generate HTML/Word/pdf rapports. It is a lot easier to insert pre/post-processing hooks. One approach you can try as plan B, is generating a "master" LaTex-file, from a Python script, with an `\includepdf`-statement for each separte pdf that you want to include. Compiling that LaTex-file, will give you one file with all the pdf's and the page numbers and bookmarks correct (I think\*). \* Edit: see this [answer](http://stackoverflow.com/a/2740296/125085): you can burst the separate documents in batch using [pdftk](http://www.pdflabs.com/tools/pdftk-the-pdf-toolkit/) and generate the master Latex file with the snippets per document, using an `\pdfbookmark`-statement per document (bookmarks ok), and an `\includegraphics`-statement per page (pagination ok).
Nope, he's using the superior Simplex noise since third or fourth major update to the map generation algorithm.
Yeah, that always happens. In this specific case though I could see these bugs from a mile away. I don't have windows and haven't used it for some time, so I have no ability to test my code on it :P
I was tempted to downvote your comment. Not for you wanting docs and test, but for not expressing that desire in a better way.
So essentially a `while` loop with all exceptions caught?
more like forking multiple processes + above, but can be really useful if u haw few off long running processes that some time crashes mysteriously. Edit: also there is also http://supervisord.org/ 
would it be possible to add an actual shell? basically add a layer of snowflakes on top of text from stdin/stdout? also, ncurses-based would probably be a lot smoother. maybe i'll hack around on it later if i can finish up some work. cool stuff either way!
What kind of processes?
I chuckled at this misunderstanding :)
hum. you did release it to the public, then announced it on reddit, and now you are surprised that people actually are critical? I think you must have lived on a different internet than me, because where I am that is quite common to happen ;)
Yea, I actually tried that as well, and I get â, not the snowflake.
There are many ways to skin this particular cat. About a year ago I wrote up a [somewhat comprehensive list](http://bugsplat.info/2010-08-01-user-space-process-managers.html) of off-the-shelf user space process managers and since that time have written not one but two more.
Nice job! very neat code. Here is the [screenshot]: http://cl.ly/CpLq
Merry Christmas to me, the nerd! Edit:Oh it piles up at the bottom! Nice touch.
for this particular case I haw some network equipment for which occasionally I need to write some reports for few weeks duration. Sometime it is only one machine sometime for more. There is no SNMP and no api so I use pexcpect and since cli to parse data, since that particural cli is unreliable process can run fine for weeks and sometime it can crashes on random expec statement.
agreed about the flexible tool chain. problem is the documentation is massive and i cannot get anyone to help out on it that knows/understands latex or even someone who understands why a plain text markdown format would be best. i have tried to explain why something like this is better, but they refuse. so i figure getting help on this is better than doing it all myself. plan b sounds interesting. i will look into it and into the link on your edit. thanks!
http://www.python.org/dev/peps/pep-0008/ Specifically: &gt; Code lay-out &gt; &gt; Indentation &gt; &gt; Use 4 spaces per indentation level.
afaik there is only a *very* short list of things cython can't handle. (last i read it was only generators) The idea is that a valid python program is a valid cython program. edit: it looks like they are now claiming full compatability.
yeah, but it's not fully compatible. Generators are last *syntax* feature, but there is a lot of semantics they don't support, like an arbitrary sys.getframe or sys.settrace. It's only compatible to the extend *they* claim is python, which is not what everyone else claims it's python.
yeah i guess i never thought of the runtime introspection type stuff. Makes sense that that would be a good deal more complicated. good point.
I've thought about doing this but without the eval. Just getting the variable from the stack frame and passing it to format. How often do you need to evaluate complex expressions in a string?
No. Just explicitly pass the variables to `format()`, it won't kill you. 1. This will be slower, *especially* on optimizing Pythons (e.g. PyPy, Jython once they land their invoke dynamic work). 2. Won't work on IronPython, which doesn't enable frames by default AFAIK. 3. Lets your format strings become a mess: they're for formatting, not arbitrary logic. 4. If you're not careful it's an easy way to end up with a security hole. 5. If the implementation is hard to explain, it's a bad idea.
maybe something like: PICTURES = { date(2011, 12, 25): 'xmas.jpg', date(2012, 1, 1): 'new-years.jpg', } Then do: picture_filename = PICTURES.get(date.today(), 'some-default-image.jpg') 
They're videos and you can also get them on youtube.com. **[Python Osmosis: Using The Python Interpreter (Episode 1)](http://www.youtube.com/watch?v=_XpD71zR6kI)** 
MySQLdb is an utter nightmare. I think it's the single biggest headache I have when setting up a python environment. Recently I've been using [PyMySQL](https://github.com/petehunt/PyMySQL) which is a pure python implementation that seems to work well and installs much easier.
True, the eval's a bit of an extra. Because I'm only using it on trusted code, I figured why not. One thing I can't figure out is how one would implement finding the value of an identifier that is non-local but not global. That is, an identifier defined in a syntactically outer namespace, like when you have nested function definitions. I don't think it's possible because `eval()` has no ability to accept that argument, but it makes me wonder how Python itself implements such lookups. I'm currently checking out [PEP 227](http://www.python.org/dev/peps/pep-0227/) to see if there's any useful information there. [Edit] From the PEP: &gt; An analogous function will not be provided for nested scopes. Under this proposal, it will not be possible to gain dictionary-style access to all visible scopes.
Mac. Aha, there is your problem. MacPorts.
I've heard good things about oursql, mainly because it actually does parameterization rather than faking it as MySQLdb does. Not actually *tried* it yet, mind...
All good reasons, thank you for the criticism. Does point 1 still apply if I only use the stack frame's namespace to lookup the value, and don't call `eval()`? Will 1 and 2 still apply if I were to go back to using `**locals()`? My main reason for doing this was to keep format strings as clean as possible (point 3). I find it difficult to syntactically structure an error message along with the substitution values, while obeying the conventions in PEP 8.
Fuck macports. Brew. Python 2 and 3 actually work on brew as well, except they require a couple of commands manually to be run after install. Sucks that it doesn't run them for you but it tells you pretty clearly to run these commands and optionally add a path to your PATH to get easy access to the pip binary. Note on setting PATH for Mac, use launchctl sentenv to properly set a system wide variable. If you want to keep it exclusive to your shell then just set it in your shell launch script (.bash_profile for bash).
I can't evangelize it because it's documentation historically hasn't been very good, and that is the effective kiss of death for new users. But since I'm used to how it works, and since we use it extremely successfully, and I see nothing comparable, I felt compelled to mention it.
Sontek! I love your .vimrc :). I used your dotfiles repo to make my own configuration for all the various programs that are included in there. Thank you!
I like the dictionary Idea, import shutil from datetime import date PICTURES = { ( 12, 25): 'xmas.jpg', ( 1, 1): 'new-years.jpg', } picture_filename = PICTURES[(date.today().month,date.today().day)] you could use itertools to generate a matrix, import itertools PICTURES = {} for i,j in itertools.product(range(1,13),range(1,32)): PICTURES[(i,j)] = '' A good way to store images that you might want to change often is in a directory, you could use glob to iterate over them, import glob for c,i in enumerate(glob.glob('.../onlineimages/january/*.jpg')): PICTURES[(1,c+1)] = i
No problems to report on Ubuntu. Installing python and packages is easy as balls.
And to mention it, no problems to report on Windows *either*, or do I just value my 2 minutes searching for a binary of the library I want to use as less than the people who complain? Any cutting edge library will have a repo on one of the popular code sharing sites (github/bitbucket) so it's as simple as cloning their repo. Is that hard? Uhm, no.
Poor documentation and difficult installation have got to be the most annoying problems, specifically when combined together.
Sensationalist title. His problems aren't Python ecosystem related at all, they're problems with the build chain he's using on his Mac. If he were to opt for a binary version of `python-mysqldb` it would be just as easy as it is to install on other platforms.
I consider it almost a settled issue now, at least for Macs. Homebrew, pip + distribute, and virtualenv. Except for a few rare edge cases, this is the only way to setup a Python environment. The biggest issue now is all of the outdated information online that is going to lead people down the wrong path.
Perhaps this article was just trying to provide a random example to demonstrate subqueries, but wouldn't it be better to set it up so the query to grab the next or previous record doesnt occur until you click the link? It could grab the record in exactly the same way, just add an extra parameter to the links to indicate if it should grab the record specified, or the next/previous one. Seems a bit excessive to hit the database with several selects when you only really need one. 
I have switched between pymysql and oursql as sqlalchemy driver. They both work as advertised. And I was pleasantly surprised both work under PyPy 1.7
Pre-S: I no longer use buildout for dealing with your original 2nd point; I'm using Puppet which is another completely different tool/bag of tricks. No one likes to write documentation; I can't be arsed to actually guide you clearly through it myself. But I'll happily give you "a few terse pointers" / "how I learned how to use it": * get a bit of a feel for how virtualenvs work; this means: find the difference between running code in your shell's virtualenv and under mod_wsgi. * follow the tutorial as best as you can, substituting with the lessons you've just learned by fiddling with the sys.path (or site.addsitedir) to get it working under Apache/mod_wsgi. Big problem is that $ENV/bin/activate doesn't happen under mod_wsgi, which is by design and correct. So your configuration/mod_wsgi app script has to take that into account. You could probably reuse $ENV/bin/activate_this.py in your wsgi app script, but I got used to fill in the blanks in two separate spots: the WSGI config in Apache and in the app file. What that actually teaches you is all about the nitty gritty details of virtualenvs. Then you've learned how to properly use virtualenvs (--no-site-packages is required for mod_wsgi, unless you're able to seriously debug problems arising from two different versions of a library being used, one while on the command line, one over Apache). This is when you'll follow buildout's tutorial and you'll be confident to make the changes required. PS: not that many.
I have no problem being criticized. I consider the particular basis for criticism here to be rather flippant, and am annoyed by the apparent presumption that I somehow think this release is in any way "final".
Part of the larger problem is that important older libraries don't use those conventions. Another part is that, yes, "cloning their repo" and dealing with generations and such *is* hard for an audience of scientists and engineers, as opposed to programmers, who are the targets of many current Python developments.
I second this. The Homebrew philosophy is that you use it to get Python (or Ruby) up and running, and then use Python’s package management thereafter—which means virtualenv and pip. One advantage is that most of what you learn about getting stuff running transfers to other platforms (assuming you can get virtualenv and pip working there as well). There are two caveats: - This is not properly documented. The documentation for distribute and setuptools and the rest is incredibly long and fails to address the needs of someone who just wants to get things up and running. - Science people report that Pip is not up to the task of installing their modules the way they want. I assume this is issues to do with wanting to be able to specify compilation options or whatever. 
I don't quite understand the vitriol some people have for MacPorts?? I find I like MacPorts quite a bit, they also have many more ports that I use that Brew does not have. Also, MacPorts works really well. So why the "fuck macports" comment?
I have spent the last 8 years refusing to indent with anything but tabs and I am damn well not going to switch to spaces now. Tabs let me view the code the way I want to view it (2-space-equivalent indent) and others to view the code the way they want to view it (4, 8, 2, 5, 3, 1, whatever... I have seen all of those used "consistently" in the wild btw) without actually editing anything. I consider it wrong that a style guide for a language is put forward by the language's development team, using the same process that's used to discuss enhancements to the actual language design, anyway.
1 will apply with `locals()` on PyPy, I'm not sure about Jython+InDy. 2 doesn't though.
Can anyone explain to me what distribute does that distutils2/packaging doesn't? It's just that I feel since it'll be included in the standard library, it's probably the best bet for some sort of future unification/sanity.
This is how I set it up too - but there are *zero* articles out there (that are popular at least) describing this for new comers. It took me quite a while to get it all sorted, but now I just use macports to install Python and any other relevant packages, then virtualenv with virtualenvwrapper, and PIP...
Performance should be as good, in general, as can reasonably be expected of general-purpose code. Heuristics are used to decide whether or not to pre-size the result list (this can't really be done efficiently at the Python level since there is no provision for 'uninitialized' PyObject* slots in the list at the Python level) when merging lists. You should use it because it frees you from having to remember what the technique is for joining a given sort of thing, providing a common interface instead. It will also work with user-defined types that supply the appropriate "joinable" interface.
&gt; So how can I know the diktator has my best interests in mind? He may not. Guido thinks about Python at the large scale ( i.e. future of the language, language features) . You think about Python on a small scale ( your projects, getting shit done, etc ). Inevitably the two visions aren't going to match up all the time. Just a fact of life.
Don't do this.
&gt;`git init` &gt;`git clone url` wut?
These tools are nice, but they are treating a symptom. The real problem is that OS X has no proper way of handling dependencies. Sadly, I don't ever see Apple doing this. They seem to be more worried about scrolling directions and convenient application launchers. I would love for them to honor their unix roots and implement an awesome integrated package manager.
I'd disagree, MacPorts doesn't work really well. I can't count the number of hours I've wasted trying to fix broken MacPorts installations. Not only does it not work really well, but the concept of a "maintainer" for a MacPorts port significantly slows down the amount of time new packages get put into the system. Almost without fail, people submit updates to Homebrew recipes minutes after updates to the main package are made. It's just a better ecosystem, I'd recommend you give it a shot.
&gt; I’m slowly coming around to the notion that we should just give students a virtual machine to use for the first couple of days Is there an equivalent of py2exe for Macs? Because it's stupidly easy to make a self-contained, portable (in the "not requiring installation" sense), customized distribution which includes all the packages you need on Windows. 
ruby gems and php pear are not different mess. in fact ruby has many more unstable and low quality packaging and pear state is almost abandoned. it's hard to have any trouble with perl cpan's i'm not referrin developers in any way, just ecosystem and packaging. 
*clap* *clap*
If you don't care about i1337n, you can do `print('{} + {} is {}', a, b, a + b)`.
PyInstaller works on Mac, but there's no 64-bit support yet. I wouldn't call py2exe stupidly easy. It's easy enough for simple packages, but I never managed to get it working for PyGTK.
YMMV, of course. It was easy to get it to work for Tkinter, as soon as I realized that Windows can't load DLLs from a zip archive, so I have to tell distutils to put all DLLs in the root of the build directory rather than in the `Library.zip`. Your problem might have had the same cause.
The init is superfluous. Just clone.
Thanks for the comment, but why the mod_wsgi assumption? I know what virtualenv does, but just have little use for it right now, and scanning through buildout's tutorial therefore didn't really tell me anything. Oh well.
It's been solved with pkgsrc. Its the net bsd package manager but you can install it on other environments. 
pip install -e github.com/newandhotness/Project#eggname
Fluffy app is great
thanks for the comment &amp; question. i actually have thought of that. however under what circumstances the "previous" or "next" links will be displayed? for example `if not photo.prev_photo` i don't display the previous link.
I couldn't find SQLAlchemy binaries when I was looking yesterday. So I had to install a whole extra compiler to build it. (Yes, I know it's not strictly necessary, but I have a project that requires performance.)
I was thinking if you wanted to pull changes in the future from the same repo. That would require you adding the URL to it, though. I'm a git noob :D
Unless you're on Windows and you use Tkinter or TCL, virtualenv breaks them.
I don't know why internationalization would affect it. What I'm trying to do is find the most elegant/smallest way to print short messages with values taken from local variables. I want to obey PEP 8 conventions regarding row length limit and wrapping indentation. I also want to avoid redundancy if possible. Kingkilr gave some good reasons why this approach probably isn't feasible for many projects. I suppose the most pythonic thing to do would be to accept the redundancy in the keyword arguments to format, just like we already do when we have several `self.attr = attr` lines in an `__init__`.
&gt; I don't know why internationalization would affect it. If we are talking about my proposal, then not specifying the order of positional parameters will fuck up internationalization when you pull format strings from somewhere and in some languages the order of the parameters is different. &gt; What I'm trying to do is find the most elegant/smallest way to print short messages with values taken from local variables. So, I believe that if you don't care about i18n at this point, and if you don't really want to print stuff like `eval(x + y)`, just going along the path of least resistance -- using `{}` as placeholders -- achieves the the goals you have set acceptably enough.
I've found that many packages that require c-libraries share this problem.,but MySQLdb and PIL are the worst offenders... and those that many, many people need. I use MacPorts for these and pip for everything else.
Couldn't install mysqldb? I've never had a problem with that, but admittedly, I'm on Ubuntu, where it's a standard package. It's difficult to gauge the validity of the complaint, since it's coming from someone who admits they're unfamiliar with the ecosystem, and didn't describe exactly what problems they encountered. I feel that pip is the de facto cross-platform standard for installing Python when the native package manager doesn't have what you need. Did he try simply `pip install mysql-python`?
&gt;In this regard, Python is as maddening to use as Perl was back when people still used it. ITT Perl is no longer used. o_O
Aha, clearly I had not fully thought about the issue. I don't know the best way to do that off hand, and I hate doing something for the common case that is only necessary for the two edge cases, but it may be the easiest solution after all. I don't know if there is a performance difference (or if said difference is negligible anyway), but using whatever the SQL alchemy equivalents of MAX() and MIN() are for the sub-queries may also be helpful: (SELECT MAX(p2.id) FROM gallery_photo p2 WHERE p2.id &lt; p1.id) as prev 
nice job. Keep in mind in modern SQLAlchemy you can do most subquery types of things with the Query object directly too: from sqlalchemy.orm import aliased p1 = aliased(GalleryPhoto) p2 = aliased(GalleryPhoto) p3 = aliased(GalleryPhoto) prev_query = DBSession.query(p2.id).filter(p1.id &gt; p2.id)\ .order_by(p2.id.desc()).limit(1).label('prev') next_query = DBSession.query(p3.id).filter(p1.c.id &lt; p3.id)\ .order_by(p3.id.asc()).limit(1).label('next') photo = DBSession.query(p1.id, p1.photo_image, prev_query, next_query)\ .filter(p1.id == photo_id).one() back in 0.3/0.4 the general way of doing things was to use `Table` and `select()` with the ORM. By version 0.6 we pretty much got `Query` and mapped classes to do most of what `select()` and `Table` does.
Yeah, something like ncurses would work better but this works pretty well for a quick hack, I would like to see what you come up with. I'm not sure if there is a way to grab what is at a cursor point before you wipe it out, if it is instead of replacing it with empty space, we could just put back whatever was there before we put the snowflake was there. That would at least get rid of the acid snow feel
TL;DR mac isn't linux
Python on Mac is the problem. Under Linux, I don't have any issues with virtualenv+pip. I'm trying to get my friend into python development and he had a hellish time getting started on a Mac. Eventually he decided to simply run a Ubuntu VM in VirtualBox, which is exactly what I do when developing on Windows. Python may be multi-platform, but it's still most comfortable on Linux.
Initially I didn't have that code but it was contributed pretty quickly because of the importance of the code :)
Virtualenv still uses setuptools by default, correct? Should we always be using the --distribute option? If distribute has truly replaced setuptools, why not make it the default in virtualenv?
Have you considered developing in a VM? I do all of my python work in a Ubuntu VM running inside Virtualbox on my Windows laptop. Easier package management and simpler transition to deployment. 
aha! i always forget about this min() and max() functions. thanks for the tip man.
The problem in this article is, as the top-voted poster said Mac. On other platforms, yeah, even on Windows which is more like a joke, you just take the binaries provided by the author or the distribution.
thanks mike, that was very helpful.
py2app? The only thing I know about it that it exists. But actually, the Virtual Machine idea is not so bad, our university did that as well and for once, that was working well without 3 weeks of helping retarded students how to set up an IDE, toolchain, etc.
Funny this came up, because I just had to learn how to do exactly what Rhomboid is describing. I figured it out in a few hours, though admittedly my use case is quite simple: running a shell command and grabbing stdout and stderr separately for processing.
Way better than the AU con -_-
Just want to point out that you're quoting the security implications of pickle in support using pickle, which makes no sense. You understand that the quote is basically saying not to use pickle for anything but 100% trusted data streams. This is in direct contrast to JSON, which is commonly used for accepting data from the internet and is generally considered secure, as long as you handle the input data properly (ie, sanitize your db inputs). With JSONEncoder, handling untrusted data streams is possible; with pickle, it is not.
Actually I *have*, and I do have a full Ubuntu VM in Vmware Player that is quite fast and I can even full-screen it and do development work, but it's not quite as fast as developing directly on the hardware and that makes me sad. On another note, how fast is Virtulabox these days? Pretty good I take it, if you're developing inside it?
&gt; Just want to point out that you're quoting the security implications of pickle in support using pickle I am NOT. The article brought up the security issue then dropped "use JSON" which doesn't do much to address security. As I said, it's like saying a text file is a reasonable alternative to a relational database. You have some work to do between "use JSON" and "use JSON securely." The article advocated using JSON instead of Pickle and left it as though that were enough. Using JSON without a conscious effort to enforce security can make it easier for an adversary to exploit your system because it takes a lot less work to muck up a JSON encoded object than a pickled one. &gt; which is commonly used for accepting data from the internet and is generally considered secure, as long as you handle the input data properly (ie, sanitize your db inputs). JSON is not "generally considered secure." Sanitizing inputs is generally considered secure. You could pass plain plain text back and forth and it would be secure as long as you checked it and sanitized inputs. Sanitizing your inputs is non-trivial and updating your JSONEncoder every time you change the class is easy to forget. &gt; With JSONEncoder, handling untrusted data streams is possible; with pickle, it is not. I'm pretty sure one could secure pickled objects from an untrusted data stream, but it is more work than using JSON.
Good for you. I've seen three diferent programmers spend 8+ hours on converrting popen to subprocess - hung up on a variety of details that they didn't care about previously. EDIT: I should mention that in one of these cases the code was previously using os.system() - a brain-dead interface that could be implemented in 2 minutes with minimal research. Spending 3 hours on how to replace that with subprocess is in no ways a respectable improvement.
It's slightly possible that this has changed since the last time I used it, but part of the problem with MacPorts is that it basically builds its own set of dependencies in parallel with those already provided in OS X, and while they might be fresher versions of similar or the same tools, they're not built the same way or they're different tools (GNU vs BSD, etc..). So, in the end there's this nightmarish combination of replicated functionality where when you go to build something outside of MacPorts things inexplicably fail, or require kluges or special path modifications to include or not include libraries in MacPorts. Then there's the ports themselves... a lot of them also include serious mangling during the build process (beyond what would be required just to build on OS X) to get things working. I respect the fact that the project works as well as it does, and I love the concept of FreeBSD ports on OS X, but it just does not work very well for me. I would blame Apple to some extent for not having a better way to handle this and for customizing some of the tools they include so much. I think MacPorts made some decisions early on about how to do things that doesn't work all that well unless you stick to a fairly uncomplicated set of installed tools. Homebrew isn't perfection, but it has felt better and more maintainable to me than MacPorts or Fink.
Nice, didn't know about this one. I had been doing things like: pip install git+http://github.com/newandhotness/Project.git
A suggestion to you all. Rather than bitch that "people should just do X" or state that "well, I don't have problems on OS Y" why don't you write up an explanation of the various way python packages are distributed, how to obtain them for various OSs, and how to avoid the installation problems that every scientist switching to python runs into on the first day. Post it somewhere conspicuous and maybe try to get it into the core python documentation on the first page. This stuff is not easy when someone comes into python vaguely knowing what open source is and with absolutely no understanding of what git is.
I believe that's what he means: &gt; git clone url then later, get updates from within the dir created by the cloning with: &gt; git pull
I'm not sure the problem with pip is to do with compilation options, though experiences and opinions certainly differ. I think part of the pain is that you _can't_ just "pip install" lots of the scientific packages like NumPy, SciPy, matplotlib and others throughout the ecosystem because there are dependencies outside of the Python package system in terms of other libraries that are needed (some of which sometimes have extensive/complicated builds sometimes requiring that Python support be flipped on within. VTK needs to be built with Python support for example. Then other things like wx/wxpython are a bit of a mess on OS X since there's only 64-bit support in the "development" version which breaks some compatibility with the stable version.) For things that are easily handled within pip in terms of dependencies and builds working without fiddling, it's great, but getting all this stuff working can be a bit of a pain depending on the platform and whether there are binaries, packages etc.. for getting the rest of the dependency chain solved.
All these remarks of "works great for me!" don't help. It works great for me, too. That doesn't mean there isn't a problem. Sadly, open source development is driven by need. The module developers all test on their platform of choice and *maybe* the other popular one. I dare say most Python developers use Linux. It tends to work well in Linux. I've rarely run into a library that wasn't platform specific that I had issues getting to work in my distro of the week. However, many of us refuse to use Windows, or refuse to pay the Mac tax. If we don't the former, or already did the latter, then we're more likely to switch to Linux if we're committed to solving an immediate problem with Python, or switch to a different language if we're committed to solving said problem on the current platform. None of this is constructive. I feel that the only way this will ever be solved is if we remove the choices. Python.org needs to perform community package management, and this needs to be maintained as the only supported method. Nobody wants to do the hard, boring, thankless work of standardizing python module installation. It's complex, frustrating, and downright dreadful.
I used it years ago and it basically imploded besides being an inelegant solution. It took care of it's purposes but didn't integrate with the system as well as brew does. It also mixes sudo/non-root usage. Brew is consistently non-root which is the way packages are supposed to be installed (Even apple got this wrong). [Further reading](https://github.com/mxcl/homebrew/wiki/FAQ) P.S. I guess "fuck macports" was a bit of an overreaction. But the best part of homebrew is it's "homebrew." And it treats you as a first class citizen instead of just another package installer as most other package systems. It's easy to roll your own scripts or edit existing ones, just fork because all the changes are saved through git so no worries there. Elegance. It's better. Just use it.
They're trying to move forward with iOS so they most likely will just leave Mac behind and focus on iOS. Although I don't know what about iOS requires so much of apple's resources considering the user layer is so simple (just apps). OS X is a lot more complicated in terms of things like window management and all. I don't blame them but I think Gruber said it best. We are the hot rodder's of our time. Most people will get an iPad and not look back. In a while dev's will be the only people using actual computers.
Is it "easy as balls" or "easy as balls for packages maintained in a apt-source you use"? For example, how would you install the Yapsy package? There is no maintained Ubuntu package for it, so you would need easy_install or pip. However neither easy_install nor pip come in the standard apt-source, you must enable 'universe' and install them, but 'universe' is explicitly not officially supported.
Python pedantry is the best pedantry because python pedantry don't stop.
Most people only use apt-get for the C heavy packages with system dependencies ( python-mysqld, PIL, etc... ) and then just use pip/virtualenv for everything else. The same with pip, you could get it from universe but usually its easier to use one of the scripts that curl a installer.
Thanks for that. I've been using Python for quite a while with only a vague knowledge of the differences between the tools. This kind of makes sense now. My question is this: how do I actually properly package/distribute, now? Currently, my workflow is this: 1. Create folder foo_project/ 2. cd foo_project; git init 3. Create .py file(s) in foo_project, commit to foo_project/.git Now what do I do? If I want to push to GitHub, well, that's easy - I can just do git-push. What do I do if I want to distribute the program defined by the .py file(s) as a package? I tried reading the official distutils (or maybe setuptools) docs a while back, and frankly they just confused me even more.
Who are these "most people" and is this solution "easy as balls"? How would one *easily* even know if this were a package one should install using apt-get/synaptic vs. pip? And how could it be easier to "use one of the scripts that curl a installer" than to get pip from universe?
&gt; Who are these "most people" and is this solution "easy as balls"? Python developers I know. Not the words I would use, but it seems to work pretty painlessly. &gt; How would one easily even know if this were a package one should install using apt-get/synaptic vs. pip? Experience. &gt; And how could it be easier to "use one of the scripts that curl a installer" than to get pip from universe? Because it can be done in one line at the shell. $ curl https://raw.github.com/pypa/pip/master/contrib/get-pip.py | python
I once installed MySQL from MacPorts. It installed X11. That was the day I moved to Homebrew and never looked back.
Well, to bring us back to the context here... The article we're commenting on is specifically discussing issues with Python for those learning to use Python for scientific computing. If you think it is easier for one to punch out a 57 character URL to get pip, which requires curl to be installed and another long URL punched out to get distribute, than to select "universe" in the repositories dialog of Synaptic then search for pip and install it, then there is probably nothing that is going to convince you that *experience* telling one which packages to install with apt and which to install with pip is a substantial barrier to "easy."
The 2011, 2010, and 2009 talks are all available for free at blip.tv (as are **[all PyCon videos](http://blip.tv/pycon-us-videos-2009-2010-2011)**): **2011** ==== * [Panel: Python VMs](http://blip.tv/pycon-us-videos-2009-2010-2011/pycon-2011-panel-python-vms-4898043) - The panel includes representatives from CPython, Jython, and IronPython. * [Why is Python slow and how PyPy can help?](http://blip.tv/pycon-us-videos-2009-2010-2011/pycon-2011-why-is-python-slow-and-how-pypy-can-help-4897756) **2010** ==== * [Keynote: State of PyPy](http://blip.tv/pycon-us-videos-2009-2010-2011/pycon-2010-keynote-state-of-pypy-3352180) * [The speed of PyPy](http://blip.tv/pycon-us-videos-2009-2010-2011/pycon-2010-the-speed-of-pypy-83-3279075) **2009** ==== * [PyPy status talk](http://blip.tv/pycon-us-videos-2009-2010-2011/pypy-status-talk-1966980) * [Python in a sandbox](http://blip.tv/pycon-us-videos-2009-2010-2011/python-in-a-sandbox-1966655)
Are you using virtual machines for your other environments? Are you at least using virtualenv for your other environments? Those are two very very good places to start. Source control (git or mercurial) + Virtual Machines make it very easy to create and recreate environments and keep the code the same across all of them. Taking a weekend to learn you some [mercurial](http://hginit.com) and set up a virtual machine (https://www.virtualbox.org/ is free) would be well worth your time. To answer your original question, running pip install -r requirements.txt rebuilds environments based on a "freeze"d set of requirements, and can be run as soon as you create a new virtualenv. Typically you would create a VirtualBox VM for each environment, and within that VM create a virtualenv for each atomic application. That way you can get the benefits of starting a different part of the project/application/feature with the same environment and the same resources quickly and easily simply by creating a new virtualenv for it on your dev server. And south as mentioned below is GREAT for data migration stuff.
As much as I hate those long days where one particularly annoying package won't compile, I do have to say that I have learnt a lot from having to wrestle with difficult installations. Especially in the case of OS X, it's a good opportunity to become an advanced user. If it wouldn't have been for nasty installations of Matplotlib, MySQLdb, wxPython, PySide, PyQT, etc., I wouldn't really bother learning about all the different library locations (/usr/local vs. /Library vs. /Library/Frameworks), how to compile stuff and how it works, and how to link all these together (PATH etc). Granted, there are a lot of package managers out there, but not all of the work as good (and easy) as apt-get in Ubuntu (probably best of breed). On OS X I don't really like them at all. So, why not roll up your sleeves with building stuff on your own if needed and go dive into the mailing list. And don't forget to tell the community how you did it!
You only need one thing: Python Essential Reference (4th Edition) by David M. Beazley. I went to one of his workshops once - the guy knows his stuff. His presentation of material is excellent. Reading one book in a few weeks once will save you months of "guesswork" as to how things work. Plus - it doubles as an excellent reference. I often use it to check on how things work in python (I have the 3rd ed.)
Initially, with python, I would agree with many of these complaints. However, after going through a process known as learning, I have addressed many of the issues presented. Now, I develop python services on Mac, targeting Linux, with very little trouble. I am willing to field questions on how I make things work. Please do not hesitate to ask.
I'm seriously pissed off that PyCon is scheduled the same weekend as SXSW.
 sudo apt-get install python-pip Assuming you have universe enabled and who doesn't.
Compiling from source is also easy as balls on a linux platform. For the record: I am not a developer and use python for scientific computing. But I know how to read. 
This should be done like that: import os.path import ConfigParser moz = os.path.expanduser("~/.mozilla/firefox") config = ConfigParser.ConfigParser() config.read(os.path.join(moz,"profiles.ini")) sections = config.sections() sections.remove('General') sec = [s for s in sections if config.get(s,'Name') == 'default'].pop() profile = os.path.join(moz, config.get(sec,'Path'))\ if config.getint(sec,'IsRelative') else config.get(sec,'Path') places = os.path.join(profile, 'places.sqlite') print places
You don't need to `git init` to get the ability to track a directory and `git pull` in the future? TIL.
Thanks a lot for the ideas and infos! I'll try those, i'm really excited to work with python.
Oh, in fact i don't have a mac, neither a windows machine, but I supposed that should works everywhere.
thanks! 
Linux is an OS that mostly respect POSIX standard. ( see http://en.wikipedia.org/wiki/POSIX ) This code is a poor design but it should work on every POSIX system. The probleme is just how firefox store profile on each platform. 
For the record, I am a developer and I use Python for a lot of things, and if you think compiling from source is easy as balls on a Linux platform, then I seriously doubt you've done much variety of compiling from source on a Linux platform. "Autoconf" is a tool created out of necessity because making sure your platform had a chance of successfully compiling was so difficult, they made a tool to check most of the dependencies before even trying to compile. I assume you've only built things for which someone has spent considerable time making sure it builds with as little fuss as possible.
Look around here: [Python module of the week](http://www.doughellmann.com/PyMOTW/).
[Pygame](http://pygame.org) - Games and UIs [BeautifulSoup](http://www.crummy.com/software/BeautifulSoup/) - HTML/XML parsing
At least they try it , to rewrite facebook in python :)
Scikit-learn!
[PyEvolve](http://pyevolve.sourceforge.net/) and [networkX](http://networkx.lanl.gov/) capture my mind.
Aside from the obvious benefits brought by SA, I'm always contemplative of the fact that sub-queries are hideous beast to read whether they are directly written as SQL statements or through a tool like SA. It seems that it's one aspect of SQL, ORM like SA can't improve much. 
[pythonocc](http://www.pythonocc.org) is pretty cool [ cad kernel ] so are the wrappers for [tvtk](http://github.enthought.com/mayavi/mayavi/auto/examples.html) and [CGAL](http://code.google.com/p/cgal-bindings/wiki/Package_wrappers_available) if geometry is your thing
Or I read the documentation which lists the dependencies in 99% of the cases.
well, PostgreSQL till some version certainly preferred `select ... order ... limit 1`
[pygments](http://pygments.org/) and [sphinx](http://sphinx.pocoo.org/)
[PyFilesystem](http://code.google.com/p/pyfilesystem/)
http://docs.python-requests.org/en/latest/index.html
Seems like the perfect opportunity to put Lisp or Clojure on it?
sqlalchemy - orm library mako - templating library jinja2 - templating library virtualenv - creates an isolated python environment pygtk - gtk wrapper for python pyqt - qt wrapper for python simplejson - json encoder/decoder for python beaker - caching library selenium - selenium wrapper for python
[Trellis](http://pypi.python.org/pypi/Trellis) is very very nice in some situations. 
 **pyquery** - https://bitbucket.org/olauzanne/pyquery/ &gt; i use this instead of the classic DOM to get sh*t done **regex** - http://code.google.com/p/mrab-regex-hg/ &gt;alternative regex implementation with all sorts of unicode madness addded **pycco** - http://fitzgen.github.com/pycco/ &gt;quick'n'dirty docs generator EDIT: added pycco
sounds like relational databases aren't for you ! aliases and joins and such are pretty much the only way to get at relational calculus. If you don't need that stuff, there are non-relational alternatives today, unlike in the 90/00s when MySQL was the default for everything.
You want to create a setup.py file. If there's a setup.py in there then anyone who comes along and finds the github page can do any of the following: * install it directly from there--pip can install from git urls. * [fork and] clone it and run `python setup.py install` and it will install. * Having already setup a virtualenv, fork and clone it, run `pip install -e foo_project` to install it 'editably'.^* `setup.py` is written using (yet another) package 'distutils'-- it's what everything else builds on top of. It is intimidating at first but the simple case is simple. [The Hitchiker's Guide to Packaging](http://guide.python-distribute.org/quickstart.html) is a great place to start-- you probably only need the top part (sections 1 and 2). Though if you proceed it will demonstrate uploading to PyPI (something I've never actually done-- most of my py projects end up being internal stuff). The [distutils docs](http://docs.python.org/distutils/setupscript.html) can also be treated as "only look at the first section", but is a bit steeper. *The editable part is a feature of pip (has been in some previous versions). Normally when you install a python package, the apropriate files are copies into `&lt; install-root, i.e. /usr/local, or the virtualenv directory &gt;/lib/python2.X/site-packages/&lt; package-name &gt;`. Edits to the source then don't have any effect. In the `-e` mode it essentially puts a symlink there instead of copying the files. If you just have one python package it isn't that big of a deal, you just work on that package in that directory. This is really handy when you are developing a library used by another project. You work in the projects directory and the library is still available as `import foo_lib` and edits made there show up immediately (either with python process restart or `reload`). TL;DR I've been using Python for a long time but put off learning this packaging stuff until just recently. Right after I did I made packages out of all my projects going "Why didn't I do this years ago?" 
Not saying I don't need them, just saying that no matter how much syntax sugar you have, they are not really readable.
[Pandas](http://pandas.sourceforge.net/) is something I use at work every day! It's a general data analysis and manipulation library that bolts on to [numpy](http://numpy.scipy.org/) and does all the simple things you always end up throwing together by hand.
I never claimed it "easy as balls" or intuitive to juggle pip and apt-get. I was just commenting about the ways people do it on Linux. What I do claim is that it works pretty effortlessly for people who know what they're doing. I mean yes, In an ideal world pip would be able to integrate with the ideal binary package manager for your system and handle the system dependencies as well. But we don't have that yet, so I agree with you that it can be a barrier to entry to new users. Its certainly debatable which is the easiest way to install pip. Both methods are pretty easy, you could do either in one line or few clicks in the synaptic gui.
That is the easiest method if you have universe enabled.
The reason "why not roll up your sleeves ...": a significant target audience for this discussion is a low-status grad student who has been told, "you--you know Python, right? Update the built-in so we have an option to use the Kallermann normalization." The guy knows he has to write just three lines of Python code. It takes four DAYS of training and updates and re-installations and busted experiments to get those three lines in, though. And, in real life, he has an advisor, three team members, and a research manager alternately screaming and sneering at him, to help ensure the right affective climate for learning Python packaging. 
Is it possible to write a part of the script in a .py file ; launch the python executable and execute that .py file in the python shell to be able to do some test directly (with the variable and fonctions defined in the .py file) ?
scipy, matplotlib
I'm using mechanize every day and yes it is really awesome. The docs are as awful as it is awesome, though. 
Actually, you should be OK even with this. It just means you switch to explicitly positioned format strings in the localised version where the order differs, which you can do after the fact without breaking the ordered version. It's only a problem when there's **no** way to do this at all (as with C style %s formatters)
* Scrapy * Pinax * Scapy * pyinotify * matplotlib / numpy / scipy / scikits.learn * PyOpenCL * unittest/unittest2 * hachoir-* * python-ptrace
Thanks for actually explaining what your cool library does.
lxml! edit: Also PyGTK
http://www.nltk.org/
It's on the sidebar already, but [Twisted](http://www.twistedmatrix.com). It gives you access to many networking protocols at various levels of abstraction, and implementing your own protocol is not too difficult either. If you've ever needed a custom client/server for a project, you can do much worse than this library.
[scrapemark](http://arshaw.com/scrapemark/) - perfect for one-off scraping
Please tell me you're trolling.
[Tornado web framework](http://www.tornadoweb.org/): It is small like web.py and faster than web.py. [Pillow](http://pypi.python.org/pypi/Pillow): Anyone here remember how difficult it is to install Python Imaging Library? Say hello to this fork. [PyMysql](http://pypi.python.org/pypi/PyMySQL/0.2) or [oursql](http://pypi.python.org/pypi/oursql): Installing python-mysqldb is always a pain for some people. These two projects by far easier to install. [python-dateutil](http://labix.org/python-dateutil): DateTime parsing is always a pain, this library is the swiss-army knife for dealing with DateTime. [supervisord](http://supervisord.org/): Rolling my own daemon is so 1999. Having a reliable daemon manager is a must nowadays. [lk](http://pypi.python.org/pypi/lk): Like Ack, but in Python. And it gets faster the more core you have. [SQLAlchemy](http://www.sqlalchemy.org/): Obvious favorite. So many Pythonistas love it. If you love LINQ, you will love this: select([table]).where(and_(table.c.id == id, table.c.email == email)).limit(x).execute() 
pycco is so cool, but I wish it used reST and processed docstrings not only comments. Also interesting would be integration with sphinx.
[Flask](http://flask.pocoo.org/). My favorite web development framework. It's tiny, but it's simple, easy to use, and a perfect for simple websites. Plus, it makes a great foundation that you can expand to build even large scale sites.
I still think using homebrew python is wrong. There is still a lot of stuff that is not universal, and being able to run python in either 32 or 64 bits is an advantage I would not like to loose.
Scientist who uses python here. I experienced a lot of frustrations installing and using specific libraries on python. I'm not a programmer and view my use of python as strictly instrumental. Here's the thing: it's free and relatively popular. It could be made easier, but when its value is compared with competitors, it's head and shoulders above them. Btw, it's probably an amateurish suggestion, but I've worked through many of my issues using a thumbdrive installation. I just pop my drive into whichever machine and start working. It means I only have a single installation problem instead of one for each machine I work on. 
Having to install dev packages for everything is a kind of a pain for linux. I wish there were a metapackage that says "I have a big hd so just install the dev of everything that I have".
Still learning Python but tkinter is blowing my mind
Nope; I use it all the time.
Ouch. Just wait. Not to say tkinter is ancient crap from 3 decades ago, but hey I just said that. Personally it's my favourite too, but only because it's the most minimalist interface I've seen so far. Whatever you do, only spawn the GUI from the first thread (may not bork on your implementation right now, but it will bork on someones machine), and never ever block in that thread. And by thread, I mean import multiprocessing. 
Pythonistas normally shun XML like the plague.
I wouldn't use it if I didn't have to; when I do have to use it, lxml is as good as it can get.
This is really helpful because of the examples. While the python docs have plenty of examples, often I find their examples try to cram too much into an example. While there is often more than one way to do something, an obvious working example is a good first step.
At least you see from the terminal output what's missing and know that you have to install its dev package.
IPython
the coolest library is the one that gets the work done, young grasshoper. But seriously - PIL (Python Imaging Library).
Zed Shaw agrees with you and he has some code to do it https://gist.github.com/1327060. Yes it is going to be slow in pypy and not work on ironpython by default.
As a sysadmin, here are some I often use: [Boto](http://code.google.com/p/boto/): Interaction with amazon AWS [Fabric](http://docs.fabfile.org/en/1.3.3/index.html): Command execution on servers
My current favorites are [Nurolab](http://code.google.com/p/neurolab/) and [ECsPy](http://code.google.com/p/ecspy/). I mostly program for recreation. 
It's also available on http://www.diveintopython.net/
Seems like they didn't even provide proper documentation, just a few "examples". It looks very promising but I'm not sure how to really use it, due to the lack of good documentation. 
Itertools
In the grand scheme of things, it's trivial, but `pynliner` is awesome. Those of you that send HTML email (newsletters, receipts, etc) probably know that you generally have to inline any CSS as `style="...."` tags. Royal PITA. `pynliner` parses regular CSS, class names, and IDs and inlines CSS for you.
http://www.gevent.org/ Gevent. Can basically do all the same things as Twisted, but using mostly the same coding style. You can monkey patch modules to get them to run concurrently, instead of rewriting code in a callback style like you have to do for Twisted.
The following are all part of what makes Python my go-to language for almost any problem these days. **[NumPy](http://numpy.scipy.org/)** and it's sister/parent/child/related libraries [SciPy](http://www.scipy.org/) and [Matplotlib](http://matplotlib.sourceforge.net/) are indespensible. I can't imagine doing any scientific work without them, even compared to any other language. (They may not replace your other software - I still use R for some purposes, but they'll certainly simplify a lot of stuff). **[NLTK](http://www.nltk.org/)** is also pretty good, if you want to do some natural-language processing. (Be advised that you should probably learn a bit about NLP before just going wild with NLTK - which is true of any machine-learning/statistical application in general - but once you do, it'll make your life so much easier). **[Pygame](http://pygame.org/news.html)** is nice even if you're not building games. The Pygame music-playing module (I'm blanking at the moment but I believe it's just Pygame.music) is the easiest way to play sound in Python, I find. **[Flask](http://flask.pocoo.org/)** is a good way to get a simple server up and running without heavyweight tools like Django. It's a terrifically simple microframework, very similar to Sinatra in Ruby (if you've used that). **[Beautifulsoup](http://www.crummy.com/software/BeautifulSoup/)** is a must-have for any HTML processing (web scraping, etc.) **[CProfile](http://docs.python.org/library/profile.html)** - *SO* easy to use that you'll kick yourself for never using it before! Premature optimization is the root of all evil, but once you're at the right stage, you can't optimize without CProfile. **[Argparse](http://docs.python.org/dev/library/argparse.html)** - Ever tried to handle command-line arguments manually? Ever dealt with nightmarish edge cases? Argparse will take care of all of that for you. Unfortunately I think the documentation is a bit confusing, but I found a slideshow that shows how ridiculously easy it is. If I can find it again I'll post it here. **[IPython](http://ipython.org/)** isn't a library, but I can't imagine writing Python code without it. (I've heard good things about bpython too, but I haven't used it). **[Antigravity](http://xkcd.com/353/)** - You can fly! Edit: added links, fixed formatting.
Not to get off-topic, but why do you like/dislike Tkinter? I don't do much GUI programming - I just learned a tad bit of PyGTK for a one-off project a few weeks ago and dabbled in Tkinter to help a friend with his code. I didn't see enough of a difference between the two to form an opinion yet (except that I have a bunch of other GTK applications anyway). Does Tkinter have threading issues in general or something?
Nowadays I'm playing with [Pyglet](http://www.pyglet.org/). You can use it to write pure OpenGL and it has lots of image, audio and video features.
I like [ElementTree](http://www.python.org/doc//current/library/xml.etree.elementtree.html) for parsing XML.
:)
[PyPy](http://pypy.org/)
I would like to know why you think that is a weird question? Seems not just proper but rather an inevitable followup of being introduced to Python.
Well to be fair, he sounds like he: 1. Does not have a mac. 2. Does not quite know what he's doing. (As evidenced in his lack of "~/") So his use of "Linux Code" is an indicator of his level of understanding and not a threat to your identity or expertise. &gt; I just downvote because you can't call that "Linux code" Shows no inclination to assist this poor lost soul in self discovery, but does proclaim your superiority over him. Regardless of whether you are right, it is only pedantry and adds nothing to this conversation. Hence the downvote. Add to the conversation, assist with understanding, and try not to be too much of a butthead. 
Greenlet
Greenlet
Gevent
Ctypes
Flask, very cool and flexible framework! and not only micro ;)
fabric. ctypes. Not a library/module, but virtualenv is rather nice and handy. hachoir. Most of the stack of things that the scipy/numpy folks have put together including IPython. Sqlalchemy. Biopython. I'm sure there are more if I could find them.
[Scrapy](http://scrapy.org/) is fantastic for web crawling and scraping. If you are rolling your own using BeautifulSoup (which is great for what it does, but not a full scraping framework) or whatever, make sure to check it out. 
[pypcap](http://code.google.com/p/pypcap/) + [dpkt](http://code.google.com/p/dpkt/) == network analysis powerhouse [0mq](http://www.zeromq.org/bindings:python) is network message passing the way it should be. With unicorns. And lasers.
The [Reddit API Wrapper](https://github.com/mellort/reddit_api) if you want to mess around with Reddit.
If you're scraping, I'd take a look at [scrapy](http://scrapy.org). A complete framework, very versatile once you learn it.
I tried using their IRC support, but there was next to no docs and it was pretty lame. Never really been back to it.
Take it to /r/wtf
Neat, thanks for the link.
**scapy** - http://www.secdev.org/projects/scapy/ &gt; interactive packet manipulation program
lxml + [pyquery](http://pypi.python.org/pypi/pyquery) is amazing.
lxml also does html parsing.
oursql makes me sad. I switched back to mysqldb after waiting months for them to commit a patch for a bug handling dates (the patch was included on the bug ticket). Also it doesn't support transactions &amp;#3232;\_&amp;#3232;
It also has a [really fast http server](http://nichol.as/benchmark-of-python-web-servers).
* numpy * scipy * sympy * networkx * scikit-learn * pandas * pytables * cython
pretty sure that's because the "shell=True" argument is lacking...
Mechanize is also very good for scraping. 
https://github.com/amoffat/Inspect-Shell shameless self promotion. I've found it useful for debugging.
pyephem - Calculate the position of the stars and planets in relation to you no matter where on earth... or any planet for that matter, you are: http://rhodesmill.org/pyephem/ All that, in about 5 lines of code.
[beets - The music geeks organizer](http://code.google.com/p/beets/) I love this library. Great for renaming your ID3 tags automatically.
Ditto for Gentoo: emerge python virtualenv and use virtualenv form there.
Was this made for 2.7?
http://twistedmatrix.com/documents/current/core/howto/clients.html#auto6 Did this not exist back when you used it?
Yes
At the risk of being down-voted into non-existence, I find the RSS feed doesn't work in iTunes. All the tracks say that they could not be found on the server.
no idea, but from http://twistedmatrix.com/trac/wiki/Documentation, I clicked on the two links in "Instant messaging and IRC - howtos and examples", and didn't get anything like that.
&gt;[Whoosh is a fast, featureful full-text indexing and searching library implemented in pure Python]( https://bitbucket.org/mchaput/whoosh/wiki/Home)
Tell me more about fabric. Does to let you run commands over a remote shell (ssh, qrsh)?
Not to be confused with [scapy](http://www.secdev.org/projects/scapy/) which is another awesome python library/framework for creating TCP/IP packets from the ground up. One of my fav's.
I've found that the twisted logbot example is a good starting example.
&gt;OSX, Android (and iOS) Why is iOS in parentheses?
I've been on a quest to find the simplest UI library that still gets things done. Tkinter *almost* qualifies. It meets the simple part, but is just a tiny bit too lacking in features to get things done. Need a progress bar? Then you'll have to code one yourself. It doesn't take much more than a single page of code to write one, though, which is rather awesome. Tkinter, being a Python API to the rather very old scripting language tcl/tk, does not to my limited knowledge have threading problems. Python has threading problems, really badly. Last time I tried, spawning tkinter outside of the first thread works on windows. You'll get mysterious locking that isn't easily explained. Try to do it on linux and I can't remember if it crashes outright or just locks up permanently. I haven't seen a tkinter tutorial that mentions this feature. The "don't block the thread that spawned the GUI" is just general GUI basic practice, which many people are totally oblivious to. If your program has a button with a callback when clicked, and the purpose of clicking the button is to start a task that takes several seconds, *do not* do the task in the callback, use the callback to set a flag/release a mutex/something, so that another thread can pick up the work. There's not an operating system available that will not grey out your window and claim your application has crashed if you fail to do this. In my experience the GUI libraries range from simplest to most complicated as follows... * Tk * GTK * win32 * X11 * HTML + JS * Qt (FLTK and wx have been voted off the island, I forget why exactly, but they suck pretty hard for various reasons) Although to be fair, Qt is almost a programming language in it's own right, which is funny because tk *is* a programming language in it's own right, and is still much simpler than Qt. I wanted to put win32 above GTK, although I can't think of a program that's shorter in win32 than GTK. win32 scores points for the exact reasons it is bad, mainly that it hasn't changed in over 15 years, and is impeccably documented (when you actually do find the documentation), but it's not cross platform and so its practically useless for me. Also building a UI from pure code, without the GUI builder in win32 is rather difficult, but many UI libraries have this feature, indeed GTK has a UI builder (or several) that are damned near impossible to get working. Simplicity alone is not enough of a reason to pick a GUI library, so do *not* take this as a comparison of which is better to use, just that which is easier to work with for a newbie. I am *not* saying that Qt is the worst GUI API, that title goes to X11 without question.
&gt; the coolest library is the one that gets the work done &gt;&gt; PIL Well, it certainly gets the job done.
Also, take a look at the zope.testbrowser. It's wrapped around mechanize, but apparently supports JavaScript as well! (I haven't tested it yet though)
You're using it wrong. find = subprocess.Popen(["find","./Downloads"]) find.communicate()
if you are just trying to list directories recursively (ie with find) consider using os.walk instead torrents = [] for path, name, files in os.walk("."): for file in files: torrents.append(os.path.join(path, file)) as for your original issue, open up a subprocess with stdout set to PIPE then access stdout as proc.stdout, it will be a file like object. when the app is done writing to the pipe read will return "" proc = subprocess.Popen('find Downloads") for line in proc.stdout: print line hope that helps
Because iOS support is not completely finished in the current version.
lxml is great for html parsing -- it supports the BeautifulSoup parser, but I found its API a bit easier to use
Yes, it's one of its main design goals
No, my find example was just an example, I was playing around with Popen. I know about os.walk. Your proc.stdout example seems like what I need, but I don't think it flushes any data out of the pipe. I.e. as the command writes to proc.stdout, the for loop will print it on demand (in what seems like a non-blocking way) but proc.stdout won't ever get emptied. Or will it?
How is PyPy a library? Seriously, it's an awesome implementation of the Python language, but quite the opposite of a library. They plan to use (or already use?) the CPython stdlib
Pythonistas normally don't shun salaries that should feed their families though, and a lot of "real world" work out there still involves XML. Sure, purity is fun and when writing my own stand-alone Python code I wouldn't use XML, but when there's a task at work that _needs_ XML, I prefer to pull the tools Python has for it, and not turn to another language, or quit the job.
I like the sound of this Kivy thing, contest or no contest. Seems like a very needed tool in today's market.
Now just to think of a program/app to make for this contest that could win a notionink tablet.
So what's the problem? Sounds more like an ad than an interesting contest. edit: willing to give you the benefit of the doubt for being open source and having a nicely branded site, but make sure your contest is actually interesting.
It seems more like a "Hey, try out our new project, it's free and you can win cool stuff." Don't be so harsh, It sounds like a great idea.
fair enough. Personally, I'll be looking for more information.
There are no tasks that need XML. There are only tasks that have been engineered to use it.
I'll make something, Kivy sounds like something I wouldn't mind learning anyways. I await the rules!
The guy that develops pandas seems like a good shit, too.
give the following a go import os import subprocess proc = subprocess.Popen("find ~/", shell=True, stdout=subprocess.PIPE) for line in proc.stdout: print line all the for loop is doing is calling readline repeatedly on the pipe which is consuming bites from the pipe/kernel buffer and should operate exactly how you want it to, i would recommend playing with the above code. the warnings behind wait is there as the kernel has a maximum buffer size, as wait waits for the app to exit before returning a deadlock can occur if the invoked app attempts to write more than the buffer size. what happens is that buffer fills up and then the application blocks on the next write. as your app is blocked waiting for the app to return you deadlock as both apps are waiting. communicate has some issues that are commented in the source code (optimization related to not using select), as it uses if elif elif and only deals with one pipe, if the app blocks by filling up the buffer (say if you are reading stdout while the app fills up stderr) you end up in the same situation above when it calls wait and hence communicate can also be considered unsafe subprocess is nice but there are a couple of edge cases that can catch you out in rare circimstances (as i found out)
&gt;[Antigravity](http://xkcd.com/353/) - You can fly! And a link to the actual antigravity [module](http://svn.python.org/view/python/trunk/Lib/antigravity.py?view=markup&amp;pathrev=66902) for anyone who is interested. 
You typo'd github.
Works with 2.6 as well. Also with this patch makes playing it more fun. --- minesweeper_in_python.py.orig 2011-12-24 10:37:59.644797227 +0100 +++ minesweeper_in_python.py 2011-12-24 10:51:52.640794316 +0100 @@ -9,6 +9,8 @@ return (grid,mines) def showgrid(grid): + # Clear screen + sys.stderr.write("\x1b[2J\x1b[H") gridsize = len(grid) horizontal = ' '+4*gridsize*'-'+'-' # Print top column letters @@ -82,23 +84,27 @@ def playagain(): choice = raw_input('Play again? (y/n): ') - if choice == 'y': return True - return False + return choice.lower() == 'y' def playgame(): numberofmines = 10 - gridsize = 9 + gridsize = 9 + missing = 0 currgrid = [[' ' for i in range(gridsize)] for i in range(gridsize)] - showgrid(currgrid) + showgrid(currgrid) + mines = [] grid = [] flags = [] - helpmessage = "Type the column followed by the row (eg. a5).\nTo put or remove a flag, add 'f' to the cell (eg. a5f)\n" + helpmessage = """Type the column followed by the row (eg. a5). +To put or remove a flag, add 'f' to the cell (eg. a5f)\n""" print helpmessage while True: - while True: - lastcell = str(raw_input('Enter the cell: ')) + while True: + if mines: + missing = len(mines) - len(flags) + lastcell = str(raw_input("Enter the cell [%02d]: " % missing)).lower() print '' flag = False try: 
There's only a download for windows 7. Does this mean it doesn't work with xp? I didn't find an answer by googling.
Awesome! I was planning on using Kivy for a project too! Love to see the community grow.
I've got 3.2.2 and I've done the print fixes, just getting errors with raw_input
It might work with xp, but kivy is not tested on it. (I don't think their is any issues on it anyway).
Well, I don't mind that much if they just ignore recursion (although, I wouldn't be happy about it either http://joelonsoftware.com/articles/ThePerilsofJavaSchools.html, but that's not the point here). I *DO* mind that almost every freaking programming book I saw lately has as the only thing about recursion a recursive Fibbonachi number generator followed by the iterative version. The only thing reader gets from it is that recursion is a) useless (because you can apparently replace it by the iterative algorithm), b) slow and dangerous (because it is often said to be more memory demanding).
[xlrd &amp; xlwt](http://www.python-excel.org/) Read and write Excel files without having to have Excel installed! (Only works with oldschool xls files though...)
simply replace raw_input by input
Nicely done.
Neat game man. Good job.
Thanks
Don't be sneaky. By "need XML" I mean - the input to the app is XML, end of story. Parsing it with your latest and greatest JSON parser won't help.
I had a feeling my playagain() function could be made even shorter! Forgot to add a counter for the mines, nice addition.
Can you always use iteration instead of recursion? I did a minesweeper game [here](http://pastebin.com/pU8KsxiK) and I couldn't find a way to write the flood fill function using iteration. def floodfill(grid,currgrid,rowno,colno,checked=[]): gridsize = len(grid) neighbors = getneighbors(grid,rowno,colno) for r,c in neighbors: if (r,c) not in checked: checked.append((r,c)) if grid[r][c] != 'X' and currgrid[r][c] != 'F': currgrid[r][c] = grid[r][c] if grid[r][c] == '0': floodfill(grid,currgrid,r,c) I used the checked variable to prevent an infinite loop.
Install IPython, and use the 'run' command.
I think the way to handle large amounts of output is to use a file as STDOUT, then you're only limited by the available space on disk. not sure if it applies to your case.
Incredibly naive question: Why not just use JavaScript? (I am not a web developer)
It works with XP for me just fine.
I've got one question: Why?
Web developer here. I'm honestly not sure. I love Python, and use both Python and Javascript quite bit for my job. I'm very comfortable with both languages, so for me, the benefit of a slightly more simplified client-side scripting language does not necessarily out-weight the added overhead of including yet *another* tool in my stack. What makes me nervous about these pseudo-compiled languages (i.e. converts Coffeescript to Javascript), is if there's a bug in it, you get an error message on a line in the Javascript, and it's not always immediately obvious what line this corresponds to in your Coffeescript. I tend to avoid using Pyrex (Python-&gt;C converter) for this reason. It usually works, but when it doesn't, it drives you insane trying to debug. This isn't to say I'm anti-Coffeescript. It's certainly been getting a lot of hype. I'm just not sold on it yet.
Go over to [/r/javascript](/r/javascript) and there will be tons of people agreeing with you. As to why use CoffeeScript over vanilla JavaScript, I think it because CoffeeScript is more readable and abstracts away a lot of JavaScript's quirkiness. (Not a CoffeeScript user)
Is there no tool that converts Javascript back to Coffeescript? That'd allow you to fix it on the JS line indicated and then see what changed in the coffee script source. (Not (yet) a Coffescript user)
Yeah, that's what I was thinking too. I found an article somewhere that mentioned that. My big issue is that the core Python doc should mention this and that in general it's not nearly as helpful as it should be.
&gt; Can you always use iteration instead of recursion? [The many fine minds at Stackoverflow say yes.](http://stackoverflow.com/questions/931762/can-every-recursion-be-converted-into-iteration) In a fit of self recursion this question on Stackoverflow was prompted from a question asked [elsewhere on reddit](http://www.reddit.com/r/programming/comments/8oh88/effectively_walking_trees_and_graphs_in_python/c09xm45) &gt; write the flood fill function using iteration. 1. Initialize a queue 2. If current square is non-mine uncover it and add to queue, otherwise gameover 3. Remove a square from queue 4. Count mines adjacent to it 5. If adjacent mine count is zero, add any adjacent covered squares to queue and uncover them 6. Go to step 3 if queue is not empty, otherwise finish [More information on the Microsoft Minesweeper algorithm](http://www.techuser.net/minecascade.html) Nice game btw :-)
I'm not a web developer, but JavaScript's function syntax always seems convoluted to me. Also, scope seems more simplified in Python. But, I'm sure these are rather uninformed points. I have no problem with C-style languages, but there is just something about JavaScript that always make eyes cross when I read it. 
The only positive I can think of is maybe CoffeeScript could resolve issues with browser cross-compatibility?
Thank you for this! Yay for proper documentation!!! 
I got a couple: * implied globals * lots of false values: false, 0, "", null and undefined * == is broken, sorry but 1 == "1" should not be true, neither "" == 0 * what does 'this' mean in a piece of code, I can never remember that * magically inserts semicolons in your code * curly brackets everywhere * make an array of numbers then call .sort(), you won't get what you'd expect 
I made some changes: [Minesweeper 1.1](http://pastebin.com/pfR2vuNs)
I used pymt a few years ago. Very cool stuff!
If you think javascript's scoping is weird, steer clear of coffeescript. &gt;_&lt;
I thought it worked the same as Python's. 
This "character" has always bugged the hell out of me: -&gt;
Coffeescript compiles to javascript in a *very* predictable way, so as you write, you know exactly what will be generated. This makes debugging quite simple. The point of Coffeescript is to help devs' productivity by reducing the amount of typing needed to perform routine tasks. If you write lots of Javascript, it's a real help. If you're learning Javascript, the way it compiles will help you to learn. 
Stick away from Haskell and SML, haha. It's meant to be the "maps to" arrow describing a function in mathematical syntax. A little crossover from math to programming.
Wonderful! Abstracting away the SSH calls from Popen will be of immense professional help to me. 
omg, its mr. serious
StackOverflow might be more helpful.
&gt; BODY= str.join (("From: %s" % FROM, "To: %s" % TO, " Subject: %s" % SUBJECT, " " , a1, a2, ... ax), "\r\n") This is not how to put together the mail message body. template = "From: %s\r\nTo: %s\r\nSubject: %s\r\n" BODY = template % (FROM, TO, SUBJECT) BODY += a1 + "\r\n" BODY += a2 + "\r\n" # ... BODY += ax += \r\n" # continue with usual code
Instead of str.join you could do "\r\n".join(
You probably need to capture messages from stderr.
No, coffeescript's sense of scoping is exactly the same as javascript's, except for how it handles "this" (Edit: And by not shadowing and being local by default). In javascript, each closure has its own "this", meaning a lot of times you end up doing something like: function () { var self = this; (function () { // do stuff with self here })(); } Coffeescript has this "fat arrow" thing where you can control whether "this" refers to the current closure's "this" or the "this" a level up.
I've tried that, it doesn't capture the message I need. I'm beginning to think that steghide is not sending it's messages to the same stdout I'm capturing (if that is at all possible, which I think it is). 
TL;DR: you can't just assume you know how it works - you'll have to learn some "quirks"... which happen to be in the [language spec](http://es5.github.com) and documented infiormally in many other places.
and actually, the order should have been: str.join("\r\n", (...))
Have a look at [this](http://docs.cython.org/src/userguide/debugging.html). It worked pretty nice for me.
I've found Qt is extremely easy to work with (using the qt designer, of course)
It's probably *not* sending to stdout, but to stderr. Try something like this: subprocess.check_output(cmd, stderr=subprocess.STDOUT, shell=True)
&gt; magically inserts semicolons in your code Javascript can do this too (it's called automatic semicolon insertion), but it's typically considered bad form to rely on it because there are edge cases where you'd want a semicolon there but javascript doesn't put one there because the next line is a legit continuation of the statement on *this* line. That said, there are plenty of javascripters that ditch semicolons in their own code as much as they can. Edit: Also, &gt; lots of false values: false, 0, "", null and undefined This is totally a mixed bag. On one hand, if you know you're getting a number you can test for non-zero value with a simple, `if (number) { /* . . . */ }`, which is neat. On the other, you'd better be damned sure you know what you're getting.
I tried both stdout and stderr, both returned results which were not what the terminal was returning from steghide 
&gt; which are in the language spec. 10912 lines ... TL;DR : learn Coffeescript 
Did you print out the *exact* command you were sending and try it in the terminal? Perhaps subprocess is parsing the arguments in a slightly different way than the terminal.
Sorry, I think you misunderstood, I mean JS will do that, which is unexpected. My post basically lists responses to grandparent's question "Why not just use JavaScript" 
I honestly can't say as to whether subprocess parsed the command correctly or not, I tried this at one point, still to no avail: process = subprocess.Popen(['steghide', 'embed', '-p', passphraseentry, '-cf', fullpathimage, '-ef', fullpathembed], stdout=subprocess.STDOUT, stderr=subprocess.STDOUT) print process.communicate()
Check the man pages for whatever response you're getting with subprocess. Maybe there's an explanation as to what's going wrong.
What were the changes? My suggestions would be to ask for grid size and number of mines at start, and to be able to play grid greater than 26.
I returned a traceback, which was not what steghide was returning. It returned nothing but a simple text error. "steghide: the cover file is too short to embed the data." I think I need to get myself a Python book and give it some time. I'm just eager to get this moving forward (hence the X-mas Eve code-session)! I appreciate the guidance. I just spent quite a while with the python documentation and have reached a wall. Maybe I need to sleep on it. I thought I'd just put it out here and see if anyone could help me along. The code's going to be floss anyway!
A traceback? That means some Python code is throwing an exception, rather than a problem with your command. What is the exception?
Edit: Sorry, wasn't paying attention, thought I was replying to a different comment. I think ASI is a misnomer. Javascript doesn't really "throw semicolons around willy-nilly" so much as it has a set of rules for deciding where a given statement ends, which can be overridden or made more explicit with the addition of semicolons. Edit-edit: But you're right, I did misread that.
Your method sends email with the approriate subject, but the body still does not contain values for a1 through ax (aka, whether the user selected '1' or '2'), it is just a blank email. 
Have you tried using [pexpect](http://www.noah.org/wiki/Pexpect)? It seems to be just the right thing for you.
Holy cow! I just went through the code again and got this to 'sort of' work... but the message it returns to the textfield has [formatting errors](http://i.imgur.com/QeHCy.png) [Code](http://pastebin.com/LpC3Hy5t)
&gt; TL;DR : learn Coffeescript Coffeescript is "just javascript", and as such is subject to a lot of the same quirks. Yes, it fixed implied globals and only allows for the javascript equivalent of ===, but in the end it's just a very basic transform. In other words, you still have to worry about type coercion, the meaning of 'this', *and* the particular semantics of `Array.prototype.sort`. Coffeescript certainly can make web dev more palatable for ruby and python developers, but it ain't a magic bullet.
[Python Docs: subprocess: Popen Objects](http://docs.python.org/library/subprocess.html#popen-objects) says: &gt; Note that if you want to send data to the process’s stdin, you need to create the Popen object with `stdin=PIPE`. Similarly, to get anything other than **None** in the result tuple, you need to give `stdout=PIPE` and/or `stderr=PIPE` too. You need to use `PIPE` to actually have the descriptors be open to Python. I believe you can get both in one pipe if you do `stderr=subprocess.STDOUT` alongside `stdout=PIPE`, as that should redirect `STDERR` to `STDOUT` and `STDOUT` to the pipe.
&gt; template = "From: %s\r\nTo: %s\r\nSubject: %s\r\n" Should be: &gt; template = "From: %s\r\nTo: %s\r\nSubject: %s\r\n**\r\n**"
This looks very interesting! Thanks! I'm still very much finding my feet, so any and all helpful pointers are appreciated :)
Thanks, I tried both, but [just managed to get one step closer to getting this to work!](http://www.reddit.com/r/Python/comments/npd2j/making_a_gui_frontend_for_a_cli_utility_in_linux/c3awe6t)
I've been meaning to learn Coffeescript for a long time. I tried learning Javascript, but the syntax and all the gotchas just annoyed the hell out of me. Can someone recommend a more comprehensive tutorial, preferably one targeted at Python programmers?
Huzzahh! You have done science a great service as I can now start to collect data. I thank you for being awesome.
My understanding is that coffeescript does little, if anything, to resolve these issues. Most people get around this by adding libraries like https://github.com/kriskowal/es5-shim/ .
Looks like you're redirecting stdout to the textbox at the bottom? Unless you've got a bigger plan with that, you might be better off just catching the string instead, stripping it of formatting, then setting the value of the textbox manually. I know I do a lot of debugging with print statements, so those would be hijacked if you tried sticking one in. You might be able to change `subprocess.PIPE` to your cool PipeText class, but I don't have much experience overriding stdout. I'm quite confused as to where the opening parentheses went... I'd check the output of process.communicate() before sending it to the textbox.
Yeah, that was the plan, to redirect all messages from steghide to the terminal-esque textbox at the bottom. I messed about with wxglade over a year ago for a week or so, and got the template/layout down. I came back to some of this stuff earlier this week and released my first floss app (a GUI for [ebook-convert](https://github.com/n3uromanc3r/ebook-converter)) two days ago. I'm now working on improving this steghide app, I released a [MEGA basic version to github](https://github.com/n3uromanc3r/Stegostorus), but want to get the error feedback functioning before rolling out the other functionality (compression, encryption, extract, etc). EDIT: &gt;I'd check the output of process.communicate() before sending it to the textbox. This is gonna sound dumb, but could you elaborate on this some more?
No problem!
Yeah, I get what it's supposed to mean. But it really doesn't add anything in the slightest and seems to be a sort of foray into ascii art for programming languages.
I removed the floodfill function and made one single function for showing cells, showed number of mines left, one small change in playagain() function, made some display changes(spacing) and changed a behavior related to flags (choosing a cell that has a flag). I also fixed a bug related to exiting the game - when losing twice in a row, choosing not to play again the second time doesn't exit the game, can anyone explain that? I used exit() instead of returning None in playgame() to fix it. As for the grid size and number of mines to start, I left those out so that you could play as soon as you open the game. Besides, you can easily change them in the code. This was a hobby project, so I wasn't planning for a full fledged game since it's easier to play with a GUI (which I might do). First I used numbers for both rows and columns, but I thought that could be confusing and for the same reasons above, I thought to use letters since I don't think anyone would play a large game in command line. Thanks for you suggestions.
&gt; could you elaborate on this some more Now that I think about it, subprocess.communicate actually returns a tuple (which is why you're getting that weird formatting). Try replacing that line with: out, err = subprocess.communicate() if out: print out if err: print err As for that "box" character, try changing the PipeText write method to: def write(self,string): self.out.WriteText(string.strip()) I have a hunch that the textbox you're using can't display newlines (which the print statement outputs at the end of each line), so it's printing that weird character instead.
Hardly a good reason to unsubscribe from *anything*.
As [this post](http://www.reddit.com/r/Python/comments/np1z9/coffeescript_for_python_programmers/c3avj4l) points out, the conversion is very predictable, there is in reality no need to make such a thing.
Man, you're a genius! That works! One last thing, if I click the embed button numerous times then [this happens](http://i.imgur.com/UC23j.png). I guess I need to clear the field or force a newline on every click of the button. Shall I use nemec as the name for gracious contributor?! ;)
Yep, looks like there's a `Clear()` function that would solve that problem for you. No attribution necessary, I'm just here to help :)
Avoid C then :P
I'm sorry, I just can't consider a library cool because it solves a problem that shouldn't have been created for you in the first place.
Anyone who denies this a problem, or blames it on MacPorts, or says that if you know what you're doing, it's "easy as balls", has no clue what they are talking about, and/or what the commenters on the linked post are talking about. Yeah, great, _you_ can install the 3 trivial packages you regularly use with apt-get. Congratul-fricken-lations. I help run a supercomputing centre. We have 1000+ users, and support python with about 20+ standard modules for scientific/techical computing, and we run completely on Linux. We typically have several python versions installed. Because performance matters for us, we build things with the intel compilers, high optimizations, and link against specialized, tuned, high-performance libraries. We've gotten things to the point where it now _only_ takes us about a full working day for one of us to build those 20 packages the first time for a new installation. If we're making only small version changes, and the wind is blowing favourably, there might even be time for lunch in there. It's an inconsistent, b0rken mess. And you should _see_ the warnings a compiler other than gcc throws on some of that crappy code in the meantime. We have a series of scripts to fix broken code, to re-write broken setup.pys that make too many assumptions about the user environment, and to somehow slap the whole godforsaken mess together. We all build linux kernels regularly, script in a half-dozen languages, and do "real" programming in another half-dozen. In short, we know our way around a linux environment. And the python ecosystem makes us work harder than we should have to. And for those neophytes we would like to teach programming, it's all but hopeless unless we personally do the install for them, directly or indirectly (into virtual machines/environments). Note that I'm _not_ saying that python packaging is in worse shape than packaging of software in general; but you're fooling yourself if you think it's _better_. So yeah, you can successfully use automatic tools for installing pre-built binaries for i686, compiled with -O0, for trivial, pure-python packages? Whoop-de-doo. I guess that means there's nothing wrong with the packaging in python. Now build numpy/scipy with a decent compiler, aggressive optimization flags, linked against decent external libraries, and then use that with an install of netcdf4-python linked against a parallel NetCDF4/HDF5 library, then get back to me. 
 str.join (( "From: %s" % FROM, "To: %s" % TO, " Subject: %s" % SUBJECT, " " , a1, a2, ... ax ), "\r\n") This means "Using the `str` object `("From: %s" % FROM, "To: %s" % TO, " Subject: %s" % SUBJECT, " " , a1, a2, ... ax)`, call the `str` method `join`, passing `"\r\n"` as a parameter." That's clearly not what you want, because that first thing isn't a `str` object, it's a `tuple`. The error message is telling you exactly what's wrong. You can't call a `str`'s method on a `tuple` because `str` methods are called on `str`s; that's what makes them `str` methods. Instead of asking the class to call the method for you with the object, just use the object directly. That's much simpler and more idiomatic. That's spelled `"\r\n".join(("From: %s" % FROM, "To: %s" % TO, " Subject: %s" % SUBJECT, " " , a1, a2, ... ax))`. Now the `str` object `"\r\n"` is the object whose method is being called, `join` is the method being called on the object, and the rest is what's being `join`ed.
There is nothing wrong with the `join` approach. You just need an extra blank item to `join` between the subject line and the rest.
ETA? Rough estimate is ok.
It wasn't idiomatic. And also, ``str.join(("1", "2"), "\r\n")`` is wrong because the first parameter passed to the str.join function is a tuple, not a string.
Interesting. That's what the second link in my google search was.
I'm sorry, but you're just plain wrong here. Using `&lt;string instance&gt;.join(&lt;strings to join&gt;)` is one of the most idiomatic ways to build a string there is. Iteratively putting things together with '+=' is ugly, and masks the structure of the output. I didn't say there was nothing wrong with the code (because it obviously didn't work); I said there was nothing wrong with the **approach**. I said that because there **isn't** anything wrong with the approach. If the usage of `.join` is fixed the way I and others suggested (including the extra blank line needed by the email protocol), it will work fine, and be exactly what OP needs.
In a wide variety of protocols, including HTTP, \r\n\r\n means "end of request/message," so you'll see it come up a lot.
Oh my! Custom CSS saves the day ;_;
Thanks you for the information. I'm still fairly new to recursion, so I'm trying to read more about it and understand it better.
&gt;`sys.stderr.write("\x1b[2J\x1b[H")` Oo, never seen this before. Interesting.
Alright I got a question: Coffeescript clearly getting loads of ideas from Python, why not be consistent and use the same syntax? From the glance I just took at the examples three things caught my eye that look wrong to me: 1) The missing colon in the if statement. 2) The list comprehension using parentheses instead of square brackets while lists are defined with quare brackets. 3) The function definition is not easily recognisable as one due to the missing def keyword and the arrow (-&gt;) where a colon should be, the arrow looks just weird imo. With a much closer syntax I might be more interested in Coffeescript, but as it is now I do not see much reason to write and learn to use this instead of Javascript (rather jquery and some js). It seems it's not worth the overhead and the gotchas it introduces. Please tell me why I'm wrong.
Look into Python's [logging](http://docs.python.org/howto/logging.html#logging-basic-tutorial) module. In particular, your GUI can have it's own logging handler which catches all messages sent inside of steghide.
I am learning just as much from you as you are from me. Two books really helped me understand recursion: "Structure and Interpretation of Computer Programs" (SICP) and "Godel, Escher, Bach" (GEB). The first will change the way you look at code, the second will change the way you look at life. Enjoy! Also, run `pylint` on your source code. It will help you clean it up a bit. :D
Lack of simplicity and ease of use are not mutually exclusive. Indeed, Qt is probably the only sane choice in production, given that it does have serious support behind it, and unlike win32 is not deprecated. I'm not sure if win32 actually is deprecated, but MS sure gives that impression. But, the list is not about which is best, or ease of use, or flexibility, but simplicity. I'm sure you would agree, this is not a feature Qt has.
You misunderstood me. I typed ``str`` to mean the class, not a string!
lxml does the same thing as beautifulsoup, but is much faster.
&gt; Coffeescript clearly getting loads of ideas from Python, why not be consistent and use the same syntax? Because JavaScript and CoffeeScript depend heavily on anonymous function and Python has no usable syntax for that. You can't use lambdas the way like functions in JavaScript. &gt; The missing colon in the if statement. I kinda like the lack of colons, it looks less noisy to me. Python has colons for a purpose, as Guido explained but I still prefer it without line noise. &gt; The function definition is not easily recognisable as one due to the missing def keyword and the arrow (-&gt;) where a colon should be, the arrow looks just weird imo. A short function syntax is massively useful when you do some heavy function lifting. An example: initialize = (stage, onLoad) -&gt; (element) -&gt; ... Here I have a function returning a function which both take arguments. My code has lots of these.
I got fed up with Python's lack of a "just call the damn command and give me the output" function, so I made [a little snippet](https://gist.github.com/1076924) for use in a project of mine. It's even got doctests (that assume you're using Linux)!
It's not /exactly/ the same as in JavaScript. In CoffeeScript scoping is like in Ruby: identifiers default to being as local as their outer-most assignment, and avoid shadowing unless they appear in function arguments or 'do'.
[2.7 provides `check_output`](http://docs.python.org/library/subprocess.html#subprocess.check_output) which is probably what you want. Though, I'm trying to be compatible with 2.6 in my code, and I prefer a different interface, with a return value of (returncode, stdout, stderr), so here's my function: def call_and_return_output(cmd, **kwargs): p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, **kwargs) out, err = p.communicate() return p.returncode, out, err
-&gt; compiles to function(){}. Which would you rather write?
Off-topic, but I've had this question for a long time, and the new edition of the book still doesn't seem to answer it. How do I rename existing web2py projects?
Interesting! I suppose that would be the obvious consequence of ditching 'var'.
[Check out all the cool features and see why.](http://jashkenas.github.com/coffee-script/) Heres' a few things CoffeScript fixes about JavaScript: * Adds [string interpolation and heredocs](http://jashkenas.github.com/coffee-script/#strings). Try to do this in JavaScript without putting a backslash on the end of every line. In practice, people use a lot of needless XHRs just to get around this annoyance in JavaScript. * [Destructuring Assignment](http://jashkenas.github.com/coffee-script/#destructuring). Pretty much the best feature ever, stolen from Haskell. You can do some crazy shit with this. It makes it really easy to write functions that analyze their arguments array and respond intelligently. Just imagine what it'd be like if jQuery was written in CoffeeScript. * Ensures you [never accidentally create global variables](http://jashkenas.github.com/coffee-script/#lexical_scope) or [use weak comparisons like ==](http://jashkenas.github.com/coffee-script/#operators). * [Provides much better ways to loop through arrays and objects.](http://jashkenas.github.com/coffee-script/#loops) * [More control of what 'this' means.](http://jashkenas.github.com/coffee-script/#fat_arrow) * Significant indentation instead of brackets and parenthesis everywhere. I prefer this because it lets you remove all those bracket-only lines of code, so you can fit more real lines of code on the screen and disregard all the visual noise brackets bring. Before coffeescript, the most common line in all my scripts was }). 
You still need to be able to debug the JavaScript. It should be pretty clear what you're looking at though, since all the identifiers remain unchanged. Also, they may be adding coffeescript debugging to Firebug eventually.
This might be an embarrassing question: what benefit could one derive from this? I came in here expecting some fancier data structures like trees. 
No, you're still the one misunderstanding. I understood perfectly well that `str` in your post refers to the class, because I actually do know a few things about Python. "The `join` approach" under discussion is still idiomatic. I understood perfectly well what was wrong with the exact code the OP used, as demonstrated by the fact that I provided another answer explaining how to fix it. Your suggestion is taking a completely different approach, and you continue to act as if the original approach were unsalvageable, when in fact the others responding to the question have demonstrated exactly how to salvage it, and once properly fixed up it's in fact the proper way to approach the task.
subprocess.Popen.communicate() if all you need to do is write one shot of data into steghide's stdin and read from its stdout/stderr.
Ah, that *is* nice. Too bad I'm writing for CentOS 5, which means Python 2.4 &gt;_&gt;.
It is kinda strange to change stdout and then us print. It seems more common to use write and pass in the object you want to write to. That way you could pass in stdout.
OK, you win
TBH, nothing when it comes to Python (at least CPython). Immutable data structures require a lot of support from the run-time to perform pretty well in real-life conditions. It somehow works OK for Clojure because it's backed by the JVM which is wicked when it comes to JIT/GC/optimizations. For an implementation like CPython, I'm not so sure...
I rather expected...a bit more. I also find it odd that there is an operation called "conj". Was that supposed to be "cons"?
It's supposed to mimic the [`conj` from Clojure](http://clojuredocs.org/clojure_core/clojure.core/conj), which is more general than `cons`.
Did someone say my name?
That's just inches from COBOL :-D
Heh, I was secretly hoping it'd be free like that anyone-who-asks-gets-one giveaway for Version Control by Example. 
Sometimes we choose the wrong problem. Instead of writing error messages to stdout or stderr, why not write to a file. I used to write programs for heavy duty batch processing of text and image files. It is (perhaps a hack) an easy thing to stuff some error handling into the main GUI loop which simply looks for the existence of an error file, and moves on to your real code when there is no error. When an error happens, you can then open the file and display its contents in a GUI box, perhaps even with user choices. And yeah, I had to integrate my batch processing with even heavier duty data entry modules for 100's of users. And the source control was virtually useless, as the company never spent any time consolidating or making proper libraries. I guess you do what you gotta do.
IOS support would make kivy much more attractive ...
Well, I only started working on this about two days ago. If you have any suggestions for features, I'd be glad to hear them. As for trees, the ImmutableDict and ImmutableVector classes are implemented on top of a lookup tree. 
Interesting. I haven't done any benchmarks yet, so I don't know enough about this. It would be interesting to see how this compares to the immutable dict and list classes in the Brownie and Moka libraries.
how can you claim something is "efficient" if you haven't done any benchmarks?
Well this is kind of embarrassing. I did some benchmarks against the Moka library, which implements an immutable list by making copies of python's built-in lists. Moka was more than twice as fast. I suppose this is because Python's built-in list is implemented in C, while my ImmutableVector is pure Python. 
THIS.
search bitbucket for poole
If you're talking about Simplog, it isn't written as a server. Bottle (the framework), like most of Python frameworks includes a development server so the coder doesn't have to worry about deploying in the early stage, but it isn't designed to run in production.
Remember when half the internet looked like that?
If you think some tool is behaving differently on a pipe than it would on a terminal, you could be right. I'm not reading this thread very closely, and maybe you've already found the culprit, but I thought I would point out that applications sometimes call `isatty` to determine if the file descriptor they've inherited for stdout/stderr is a pipe or a terminal. For example, many tools which output ANSI escapes for colorized output stop doing so when `isatty(stdout) == 0` so that pagers or logs don't contain extra, potentially unprintable characters. 
 A few notes - 1) All new classes should inherit from object 2) while 1 is silly - use while True 3) file_ is a silly name - use file_name or something along those lines if you don't want to use file 4) Simply saying that it's a Python version of Unix tail is not enough documentation to explain what it does. You need to explain what it does, and how to use it. 5) You provide no tests. As your project grows, you're going to want unittesting, or doctesting. 6) In your method "follow", you provide no documentation regarding s. I have no idea what s represents until I look more deeply at the code. I shouldn't have to do this. s is also a bad name - time_to_wait would tell me straight away what it did. 7) You should use the with statement whenever you can, instead of manually opening and closing the file yourself. 8) Your code on lines 32-25 of tail.py could be simplified - why not, instead of setting callback to None as default, set it to print ? That way, you don't need to test if callback is None - you can be assured that it'll do *something*. Apart from that, looks good, I'll be keeping an eye on it and see what comes of it :D Actually, I think that teaching people to recreate Unix commands in various languages will be great practice for them, so I'll be doing that over at fuduntu. 
Looks like you don't actually knows what you're talking about...
Bottle is one file! It's tiny and simplifies the mundane parts, so I don't see how it's a bad thing to be tied to.
Well, my first thought was "it's damn blazing fast", I guess it does this by loading everything into the memory, but there's also one problem with doing that in the long run - as you write more and more posts, it will take more and more time to startup and also more RAM. I created 1000 copies of `helloworld.md` (that results in about 1 megabyte of files) and starting the app already takes about 10 seconds on my PC (C2D E6300, 2 GB RAM). (On a second thought, it may be not reading files, but rendering the Markdown) This may be a stupid idea - but what about some "lazy" loading, for example, loading the post into memory when it is first accessed (and maybe unloading it from RAM when it is not accesed for some time (well, if you're really low on RAM))? Well, but as long as you don't have thousands of posts, you don't have to worry about it. :) I also missed some pagination functionality. But all in all, it's a nice app. Keep it up! :)
Actually real-life tail -f uses inotify(Linux) or kqueue(FreeBSD), depending the platform these days. So it would be better to use pyinotify/kevent instead of sleeping for a few seconds. I recently worked on a similar problem, only I wanted to make it work over http with long polling. https://github.com/teferi/htttail It's not properly documented, and I'm not sure if it's ready for use, but if want - you can check out how I worked with files in the tailer.py file. (it depends on twisted, pyinotify and uses jinja2 template engine)
Pagination is on my list, you should see it within a day. As with performance, on startup the posts are rendered into Markdown and cached, and then loaded from the cache when requested by the browser. At a later point I will probably tweak this to only load/cache what has been requested (or something similar).
It's not written as a server, it's just written with the Bottle framework (which can run as a server, a WSGI app, a CGI app, etc etc). If you have an existing server setup, this should slot in quite easily. See [BottlePy's deployment docs](http://bottlepy.org/docs/dev/tutorial.html#deployment) for more info.
A few notes - 1) All new classes should inherit from object 2) If statements should generally take the form if condition: do_stuff() and not if condition: do_stuff() It makes it far easier to tell what happens if that condition is met. Edit: FUUUUUUU why does the 4 spaces formatting not work? Anyway, do_stuff should be on the next line, not on the same line. 3) Testing if an object is None should be done with "is None", and not "== None" 4) Ideally, don't name things like modules or classes the same as builtins - this can cause issues. 5) Try not to shorten names - names should be as short as possible while not losing any meaning. vertex is better than ver 6) Document your methods. I need to know what they do and what the objects I pass them need to do. 7) Ideally, use doctest or unittest instead of writing your own testing. All methods should be tested - not just the public methods. 8) Use whitespace to break up your code into logical parts - you don't need every line to be right after the next one. 9) Avoid magic numbers and code that's unobvious, such as (index &gt;&gt; level * 5) &amp; 31. Use constants to replace magic numbers, and perhaps replace that operation with a function since you use it a lot. 10) If you only need one them, there's no need to get the key and value of a dict. Apart from that, looks interesting, keep it up.
&gt; (3) don't want to use file I run across this all the time with file and string... the best trick I've found is to think about what you'd call it if you had *two* of them :-) So I wouldn't use `file_name` (especially since it's the object, not the name) but something like `following` or `lines`... it'll communicate more. (and then I'd use `file()` instead of `open()` once it wasn't a near-collision...) &gt; 1) All new classes should inherit from object isn't that implicit in Python 3?
"don't think it flushes" -- betrays a bit of confusion... you don't control that at all from your code; it's entirely up to the process performing the output (`find` in this case) to flush or not. Unix convention is to flush lines when output is a tty, and to buffer large blocks when it is not, for efficiency (though see the `stdbuf` command for ways to subvert that.) As for getting emptied: any buffering `find` is doing will get flushed [or discarded] when `find` exits; then the kernel's buffer for the pipe itself will also get flushed, so your code as the reader will get that content and then and end-of-file (if you're using file.read that'll be an empty string, if you're using the iterator it'll be a StopIteration...)
&gt; I run across this all the time with file and string... With a file object, it's one of the rare cases where I would actually consider using a single letter for a name - "f" is more or less universally understood to be a name for a file object. Using with statements make this a lot more clear - it highlights when you're opening an object. If a more descriptive name is needed, of course, I'd use one. (For reference, I was actually looking at the code where he used file_ for the file name) &gt; isn't that implicit in Python 3? Explicit is better than implicit ;) It's a practice that I try to stick to as closely as possible - especially with beginners, it's certainly something you should try to stick to (I find it helps drill in the whole OOP idea) 
Note that this is fundamentally a *Unix* question, not a python one; that's much of the reason the `subprocess` documentation is insufficient. The first question to ask yourself is whether you want to look at that data on the fly, or only look at it once the child has completed. If you can wait for completion, and especially if you only care about it if the child ran successfully, then you can just subprocess.check_call([cmd...], stdout=file(outputname)) which will throw an exception if `cmd` fails, and if it doesn't, you can open `outputname` again and chew on it as desired. If you want to do something else while it's running (`check_call` and `call` don't return until the child does), but the above is still otherwise true - then use `Popen`, and check every so often with `.poll()` to see if it is done; you can enhance that with a `signal.SIGCHLD` handler, depending on how complicated the rest of your code is, to notice immediately when the child is done and then `poll`/`wait` on it. (You need to "collect" the exit status, or the kernel will keep the process-remnant around as a "Zombie" until you do, or you exit...) If you want to process the data while it's coming in, then you can go in a couple of different directions. If *all* you want to do is chew on it as it goes by, and do nothing else until it's done - then `stdout=subprocess.PIPE` and a for loop over `.stdout` as described by Da_blitz below works just fine. If you have other things to do as well, you need to learn about `select` and/or `poll`, and have an event loop that wakes up when any of the things you want to do actually happens...
And ... done. Basic pagination is [up and running](https://bitbucket.org/smalone/simplog/changeset/a768bb78d170). Enjoy.
Looks like file_.close() never gets called. The while loop inside follow doesn't have break conditions. def follow(self, s=1): ''' Do tail follow. If a callback function is registered it is called with every new line. Else printed to standard out ''' file_ = open(self.tail_file) # Go to the end of file file_.seek(0,2) while 1: curr_position = file_.tell() line = file_.readline() if not line: file_.seek(curr_position) else: if self.callback: self.callback(line) else: print(line) time.sleep(s) file_.close()
You should be able to mount WSGI applications into flask apps. It works the other way around at least.
There's a good argument against using single-character variable names - searchability.
A very good point, however - 1) A method that opens a file should be very easy to find; a method that handles an already open file should use a better name than f 2) Where you open it is quite obvious, provided you use *with*
This is some awesomely structured critique. Mind if I ask you to look at stuff in the future?
You guys may also want to look at [Pyjamas/PyJS](http://www.pyjs.org). It's a pure python-&gt;javascript converter.
Oh... the good old times. Internet was fun back then...
Note that with using pexpect, you will lose the distinction between `stderr` and `stdout`. At least as far as I know. It's up to you to decide whether this is a problem for you or not... :)
Of course; I'm here all week!
Also, wouldn't this screw up some stuff like log rotation, being as the file never closes?
Apart from the hideousness of everything, it was. IMO of course. I liked the way everything was sorta prescribed for a geeky audience with a *much* longer attention span. Like good blogs but without any of the pretense of fame.
&gt; The easiest way to set up your templates is without blocks... And then use the include tag in your base template. Two steps forward, six back.
&gt; Installing python and packages is easy as balls. Perhaps you don't have to install a wide range of packages? I've had very variable success. If I can apt-get the thing, then it works almost every time - but I'd say less than half of the packages I need have been apt-gotten. Often I've found that I need some specific installer system I don't have, but that requires some other package, and then... 
I found no other way around it, unfortunately (definitely open to suggestions, though). Seems like a different templating style than most of my Flask sites are — basically you're trading out blocks with includes.
I installed most packages I need via apt-get, while I had to compile others. I think however that compared to the other two main platforms, a linux distro is probably where this kind of stuff is the simplest to execute.
Flaskr.
f is pretty well known though, like i
This is exactly the sort of thing why you should use with.
I'd suggest conditionally using a different base template -- then you don't have to alter any of your views. Here's how I do it... base.html contains all my site layouts, etc... base_pjax.html contains the shell of things i'm bringing in abstract_base.html looks like this: {% extends "base_pjax.html" if is_pjax else "base.html" %} then all subsequent templates extend that. the is_pjax is put there by a context processor.
I haven't looked at the code yet, but if the pages aren't dynamic (ie. no comments), why not just write everything out to a .html file and then serve that? It would go even faster and be more or less infinitely scaleable. 
It's a tradeoff. I personally would like the ability to push a markdown file onto my remote server and have the blog take it from there, but if you want to write a bunch of content and have it statically rendered (ie: if you want a bunch of HTML to serve), maybe try a static blog system like Jekyll? As for comments, Disqus should be enough for anyone. 
In the case of an exception being raised, it would.
&gt; 1) All new classes should inherit from object Not in Python 3.
If the loop ever exits, even through an exception, close would be called. While the loop is running, you *don't* want the file to be closed (at least not in this implementation).
Good point, however - 1) You're late. 2) Already answered. But then again, since explicit is better than implicit, "explicit is better than implicit". Forcing newbies to use class A(object) re-enforces the idea that each class is an object, and helps them learn about inheritance. 3) Python 2.x is the version I presume all code I meet is, unless stated otherwise, as Python 2.x is _far_ more common in production code. 4) If code is intended to target both 2.x and 3.x, then it is required. (Though, really, you should be using 2to3 and 3to2 for that, but there you go) 5) Good day, sir.
wow, forget I ever responded...
Lawl. It's all good. Edit: Jest seems not to transfer over the internet well.
Wow, Thanks guys for all the critiques and feedbacks. I modified/not modified following and pushed the code. 1) Tail now inherits from object. Interestingly some classes of python standard library don't inherit from object(ex - SMTP). Anybody know why? 2) Infinite loop is now 'while True'. Found out that 'while 1' is supposed to faster but decided readability is better 3) Changed 'file_' to 'tailed_file' in __init__. Inside methods 'file_' is still used, I think it is self explanatory and better than 'f'. 4) Added description of 's' to docstrings. I prefer to keep 's' opposed to a more descriptive name because 's' is the argument name used in unix tail. 5) 'with' statement is used to open the file. 6) sys.stdout.write is assigned to callback defaultly. This was an awesome suggestion. Loved it.
Supports clutter animation (on bell ring) and applying effects/shader (try by hitting F1-F6 keys) This is an on going development there are still a LOT of bugs and optimization needed but it's a fun project to work on. 
Wow, this seems interesting. Do you have some screenshots? I'd love if the shell would swing on bell and looked into the VTE implementation but thats easier said than done. Maybe you could include it? Hmm, I'm thinking about creating a AUR build for it, if it proves useful for me :)
Here you go http://i.imgur.com/SZnA2.jpg As I said, it's in a proof of concept state and not usable for any every day use. I used a fast zoom in / out animation for bell ring but it's really simple to hack this animation (see https://github.com/paradoxxxzero/clutterm/blob/master/clutterm/ui.py#L124).
I get this error when I try to type in the window that comes up: Traceback (most recent call last): File "/home/hitbox/dev/clutterm/clutterm/ui.py", line 167, in onKeyPress self.shell.write(uval) File "/home/hitbox/dev/clutterm/clutterm/shell.py", line 52, in write self.writer.write(text) TypeError: must be unicode, not str Here's a screenshot: [http://i.imgur.com/HK2Yx.png](http://i.imgur.com/HK2Yx.png) I'm on a Toshiba C655 laptop with Ubuntu 11.10.
Oh yeah, forgot to say it's for python 3. I'am trying to make it work with python 2. I'll keep you informed.
The beta version of beautifulsoup, version 4, uses lxml to do the parsing, so it will be just as fast, but offer the convenient interface beautifulsoup users are already used to.
Ok it should work with python 2 with commit 5e54f6a
Sweet, it does! Any suggestions on what to try with it--something unique to clutterm? I noticed one thing; when I backspace it doesn't clear the characters until I start typing again. *nothing to do with anything:* I only recently started learning git and there's is just something cool about issuing "git pull origin".
Neat program you've got there. It's got some problems with accepting invalid input as valid. a23 gets interpreted as a2 and v2 straight up crashes the program. You can insert the following line just before line 113 in version 1.1 to catch those problems. if lastcell[0].lower() not in 'abcdefghi' or lastcell[1] in '0' or (flag == False and len(lastcell) != 2) or (flag == True and len(lastcell) != 3): raise ValueError The way you decide the value of lastcell in line 113 also seems more complicated than it should be. You may disagree, but I would change it from lastcell = (int(lastcell[1])-1,string.ascii_lowercase.index(lastcell[0])) to lastcell = (int(lastcell[1])-1, ord(lastcell[0].lower())-ord('a')) this also happens to be faster :) Oh and personally I prefer to allow users to use both upper and lower case letters when typing the collum. If you only want to accept lower-case, then you can remove the two .lower() to get that result
That looks pretty awesome! Do you plan on getting this into some usable state or is it just a plaything?
Cool
It's a plaything, but if I can make it work it could be really nice. The code is not so big and no so cluttered (ahem), so I hope some people will be motivated to lend me a hand on this.
Thanks for the constructive criticism. I've been meaning to get around to commenting. Chalk it up to laziness. As for the (index &gt;&gt; level * 5) &amp; 31 stuff. I was inlining those because I was worried about performance. It's too bad Python doesn't have inline functions or macros like C does. I've moved it off into a helper method for now. Hopefully performance won't take too much of a hit. Could you explain number 10? Where did I do that?
No worries, happy to help. If you're worried about performance, always worry about the algorithm first - not messing around with the syntax. Doing it on a single line won't gain you anything. Python's all about development speed, not run time speed - even so, I have trouble finding anywhere your code might be a little bit slower than it needs to be. tl;dr - don't worry about optimising it, because more often than not, you'll cause more damage than you save. As for 10, I can't seem to find the bit I was referring to, so forget about it.
No worries; glad to help. 1) It's because new-style classes basically came along in Python 2.2, and some of the code base hasn't been transferred across due to more important things being dealt with first. 2) That's premature optimization, and it does nothing to help readability. It used to gain you _some_ speed, but microseconds faster isn't really that great. Worry about the implementation first, then worry about optimizing it if you *need* to.
Wow, didn't know that. I've been using lxml+pyquery for the same task.
I can't wait to try this once you get it running on python 2.7! 
I'm baffled by this article. 1. The links to the Wall of Shame don't work. 2. I found what I think is the right page - but what's a "trove classifier"? It's mentioned in the article, but not on the Wall itself, and I don't see any obvious links or such that would be these classifiers.
We have a fair number of assumptions that the underlying terminal object is VTE, but fwiw Terminator is written in python and might be an interesting way to focus on the core terminal features of clutterm and not the faff of the surrounding app. Also it would be interesting for us to have a terminal widget that wasn't VTE :)
... which is exactly what I meant with my statement :)
As a python beginner myself, would you please explain why there is a need for a infinite while loop and how does it ever break out of it?
I love the smooth cursor movement! Great work, I'll be definitely watching the repository.
Hello! Seems interesting, but would you mind telling us a little what its features are and perhaps a little about its advantages over other CMSen?
Not the OP but: Link to wall of shame - http://python3wos.appspot.com Trove classifiers are used on the Python Package Index - http://pypi.python.org/pypi/
if the real world didn't suck, we all would have been done programming a long time ago. 
Currently there's an effort to port Sunflower for both MacOS and Windows. To my knowledge program does work but some basic functions are missing like proper icons, associations and other.
FYI, it doesn't work on python 2 if you have a unicode character in your prompt, but python 3 is fine. Gotta love python 3 for unicode :)
perfectly legit reason for xml: huge corporation wants to use your startups product, they want to make it available to all 20 thousand of their employees all over the world. Internally they use Novell eDirectory. You want $$, you use SAML for the integration. SAML is based on XML. 
so most of the implementation is in templates and javascript, flask does the request routing?
Nice work mate! I'll try it out on Arch and see if it all works fine.
Nice! Idea: use "html5" to play the chords ;)
This is really great, and it looks fantastic! What did you use to generate those buttons? They look familiar. And hey, since you're musically-inclined, you may want to check out my open-source project - [Melopy](http://github.com/prezjordan/Melopy). We've been looking for someone with a music background to help out (I have pretty minimal experience). Anyway - it's a really basic project meant to help others get involved in something (at least that's what it's purpose was for me!)
Melopy looks freaking fantastic! How feasible would it be to have it use prerendered sample wav files instead of generated tones? The buttons are from the Twitter Bootstap base template. It is awesome!
Love the idea, love the implementation. Good job!
The whole point was to play around with the "science of sound" and generate sounds with nothing but numbers. But, I really want to extend it and make a full-fledged music library that allows you to add, as you said, prerendered sounds like drums, cymbals, and sound effects, etc. But that's a design decision I'll have to make - as you see we've split the project up into melopy (base), scales, and utilities (like frequency from a given note, etc). So I'd love to follow the same principle to support pre-rendered files. I could write up more in an email if you'd like - but essentially development has been slow for the past few months, and I haven't had a chance to implement some of the stuff I want to implement. And I'm having trouble fixing some of the things in the "Issues" section. Glad you enjoy it, though! It's a lot of fun. EDIT: Also, thanks for mentioning the Twitter Bootstrap - this is too awesome. I'm DEFINITELY going to use this in my projects.
You might want to note that clutter is a graphics library ;-) I looked at your screenshot, not having ever heard of a software project called clutter, and thought, *yup, that desktop is cluttered as fuck!* Much confusion was had.
Tell me about it. There are a few projects that still support 2.5, but 2.4 is long dead and gone. A coworker and I once figured out the lag between new software releases and the time it took us to be able to use them; it averages about 8 years.
Sorry about that. I left the link as "python3wos.appspot.com" without the prefix of "http://" so wordpress assumed it was some wordpress local link. Thanks for noticing and remarking. I'm such an amateur...
No... do not do this. Do not change PYTHONPATH Do not mess with sys.path Create a virtual environment with virtualenv. Write a 5 line setup.py If you have paster installed, `paster create` can make one for you. Install your package into your virtual environment. Optionally using setup.py develop. 
Looks cool, I'm pretty interested in looking at the code for this when I get some time. You might also want to post this to /r/guitar
This makes me glad I'm working in a small company, comparatively. While we don't go bleeding edge (except, you know, *when we do* ಠ_ಠ), we have a pretty sane policy about making tools work. That bring said, we're just now migrating our last 5.x FreeBSDs. Because of disk failures. . Without backups. 
Good idea. Done!
Interesting. I might send a few pull requests your way. However, I don't want to pollute whatever vision you had for the library, but I could definitely foresee JazzChanges.net using this.
It should work now. Do you have any traceback ?
Cool project!
Small company here, too (~10 developers, most interns), which is why we need something as stable and well-tested as CentOS - we want to avoid sysadmin duties as much as possible. And, unfortunately, RightScale, through whom we do AWS, is slow as balls at packaging new images, which is why we haven't even gotten CentOS 5.5, much less CentOS 6. :/ Python isn't our implementation language, though, else we'd have a newer version. It's just something I occasionally write tools in.
Great job!!
Any reason you picked jazz (obviously the whole standards thing makes sense), but this could be useful for anyone who wants to chart or transpose a song. I play in a band, and we often times have different female leads singing, and the last time out we wanted to transpose a Stevie Wonder tune (not a terribly hard task) but this project would have made it even easier. Are you opposed to people adding tunes outside the jazz genre?
+1 for python-dateutil
Not at all opposed to that! If you can think of an improved domain name that is available I'd be happy to switch. It's just that changes like this are so common in jazz and I play a lot of jazz. So, yeah. I'd like it to be a community ran site. If the community pushes it towards pop or something, that's cool.
well put...cool stuff, I will be a contributor
http://en.wikipedia.org/wiki/Floating_point#Accuracy_problems tl;dr floats are not reals, not all numbers in range are represented exactly
Yup. If you need "proper" decimal floating point computation, use the decimal module (http://docs.python.org/library/decimal.html).
Representing the numbers 1.2, 1.1, and 0.1 in base 2 results in digit sequences that repeat forever. It's kind of like how representing 1/3 in base 10 requires you write 0.3333.... with the 3s going on forever. But IEEE doubles don't have an infinite number of digits, they only have room to store 53 binary digits so that means it's **impossible** to represent the numbers 1.2, 1.1 or 0.1 exactly using binary floating point. The best you can achieve is numbers that are pretty close, correct to 53 binary digits (= approximately 16 decimal digits) but not exact. And that's why you see what you see. 
Why not?
I wish PyJS was as good as CoffeeScript.
Have you looked at csound at all? It's an interesting area of study, but imo you'd be much better off looking at and working with the established tools that are out there (and csound has a history in academia going back at least 20, if not 30 years), rather than preforming an exercise in wheel-reinvention.
I haven't, but I'll definitely take a look! I know Ge Wang did some great stuff with ChucK too, I imagine that uses a great deal of csound resources. I knew of ChucK when I started Melopy, but I really just wanted to learn about Git and Open-Source projects, so I stuck with it. It's just a toy for me :) 
Don't go by my vision, it's supposed to be a collective thing :) Just keep in mind that if we were to add pre-rendered sounds or something of the sort (maybe some sort of syntax that we can then "code" the sound for a piano key or drum kick?), it would be an add-on rather than a change in course. Glad you enjoy it though!
For the same reason that (using computer floating-point values) 1 - 1e-17 = 1 : &gt;&gt;&gt; a = 1 &gt;&gt;&gt; b = a - 1e-17 &gt;&gt;&gt; a == b True The long version is that computer floating-point reals are only approximations of "real" reals. Always be vigilant for rounding errors in computer numerical processing. Another classic is to create a loop between 0 and 10, using 0.1 as the step value. If you test for 10 as the terminating condition, the loop will never terminate. 
Send the Python script as an attached file, not in plan-text form in the message body. The reason? E-mail is a disaster for anything that needs to arrive in the same form it was sent. In fact, IMHO e-mail text format should be outlawed. The reason it works as an attachment is because the file is unambiguously recoded to avoid all the problems that the e-mail format creates. It's still not efficient, but at least it arrives intact. 
A tutorial for those who know next to nothing about random/pseudorandom numbers and/or computers.
I'm using it to develop a Entity/Component Game Engine a la [CraftyJS](http://www.craftyjs.com) and so far it's working extremely well. Combined with [Closure Compiler](http://code.google.com/closure/compiler/), performance is great. What're you having trouble with?
It's similar in python, but since there's no regex literals, you use the `re` module. import re matches = re.search(r'(\w+)\d', 'regex03948') word_part = matches.groups()[0] Note that the `r` preceding the single quote makes the string a "raw" string, useful for regex so you don't have to double escape slashing and stuff. **edit**: just noticed that this regex doesn't do what you want, (in python or perl) since \w also matches numbers. You probably want `/[a-zA-Z]/` or add something to make the `\d` part consume all the numbers.
 import re word_part = re.search('(\w+?)\d', 'regex03948') print word_part.groups() # prints: ('regex',) Changed the regex to be less greedy because yours returns "regex0394" when used in that code.
Perl RE can be used in pretty much exactly the same way, except it's not surrounded by forward slashes, it uses methods instead of operatiors (re.search, re.match, re.sub, etc.), and flags are passed as function parameters. You can read http://docs.python.org/library/re.html for all the methods.
I wrote this to learn. In case your building big site, you need to use Drupal or Django CMS. As of now * Simple YAML file for contents. * Can run on PyPy (Not tested in production) * Code higlighting. Based on google prettify library. * Disqus integration. Under Development Features: * Support simple admin interface to add new posts or pages. * JSON-RPC. * Add Git support. Any feature request is welcome.
The strictly literal translation would be (word_part,) = re.search(r'(\w+?)\d', 'regex03948').groups() However, that would raise a `ValueError` if there was more than one capture group, so if you're looking for a one-line solution it would probably be better to write it as word_part = re.search(r'(\w+?)\d', 'regex03948').groups()[0] 
Indeed. I could see the sound generation as being pluggable. At that point the same utility classes could construct generated audio, midi and sampled audio. How neat would that be!?!
Extremely, the idea originally spawned from me listening to music and thinking (from a computer scientist perspective) "What would it look like to write this melody in CODE?" Then it hit me - melodies with Python code.
What python-tail does is monitor a file for changes, so an infinite loop is needed to keep watching for changes at the tail of the file. Only an exception would break out of it. Ex - ctrl + c would throw a keyboardinterrupt and break out of the loop.
That's exactly what you're supposed to do.
Will check it out. Thanks.
I came across this late, but I thought I'd have a go. Here's a working implementation using PIL, SciPy and NumPy. [Pastebin link with comments.](http://pastebin.com/Q0gqNLbY) import Image, ImageChops, ImageDraw import cStringIO import urllib import numpy as np from scipy import signal from scipy import ndimage waldoURL = urllib.urlopen("http://www.findwaldo.com/fankit/graphics/IntlManOfLiterature/Scenes/DepartmentStore.jpg") waldoStr = cStringIO.StringIO(waldoURL.read()) waldo = Image.open(waldoStr) r,g,b = waldo.split() red = ImageChops.subtract(ImageChops.subtract(r,g),b) stripes = np.vstack([np.ones((2, 4)), -np.ones((2, 4))]) red_array = np.asarray(red) correlation = signal.correlate2d(red_array,stripes) corr_mask = np.ma.masked_inside(correlation, 0,correlation.max()-10) correlation = corr_mask.filled(0) base = ndimage.generate_binary_structure(2,1) disc = ndimage.iterate_structure(base,30).astype(int) disc = disc[4:50,4:50] correlation = ndimage.grey_dilation(correlation, size=(50,50), structure=disc.astype(correlation.dtype)) correlation = correlation[:768,:1024] corr_img = Image.fromarray(correlation) corr_img = corr_img.convert("RGB") final_img = Image.blend(corr_img,waldo,0.5) final_img.show() I tried to follow the Mathematica code as closely as I could. The code would be much faster if grey_dilation was replaced by drawing a simple circle. I'm not sure why grey_dilation draws a box. I couldn't seem to get it to draw a circle.
Dumb question, how does gist.github.com--or, your clone, for that matter--differ from the other patebin-like services? (Pardon my ignorance, I've never used gist.)
The basic idea behind gist is that it is backed by git. So, you get a lot of things for free: logs, commits, diffs, revision control, forking, cloning, etc. Actually, it is best said by gist.github.com itself: &gt; Gist is a simple way to share snippets and pastes with others. All &gt; gists are git repositories, so they are automatically versioned, &gt; forkable and usable as a git repository. I created an [example for you](http://sharp-mist-7719.herokuapp.com/paste/8/?commit=422f5c907cb1d6f3ed146a405536e081b78a9f73) which show the revisions idea and how you can make changes as you go. 
Your code only plots the original image for me - I don't see any change in it. I [wrote some similar code that works for me](http://www.reddit.com/r/Python/comments/ni0pc/coding_challenge_can_we_find_waldo_similarly/c3bfnz9). Thanks for posting your code though, I don't think I would have found signal.correlate2d without it :)
Here's another (from dpaste.com // dpaste.de http://code.google.com/p/django-paste/)
[Holy shit, that is brilliant](http://sharp-mist-7719.herokuapp.com/paste/8/?commit=9e0ccdc94c7576f702fdec61045966f661667de8)! I have no clue how well gist works, or if yours is missing any key feature, but it is awesome. Thank you.
Heh, well my clone is missing some features (but it also adds stuff), but it will get there eventually. The difference is that you can fork my project and use it in whatever environment you need!
I was trying to figure-out how to do that, when I was messing-up your python example. Do you have to register to fork and comment, etc? EDIT I'm a moron... fork the actual project on GitHub. My bad.
Heh, I need to add commenting and forking for the pastes :) I wouldn't honestly use your real email address as this is all public, but ideally it would be deployed isolated and it wouldn't matter and be more of a convenience. Once I get a bit of sleep I'll add it! Otherwise you can fork the project on github.
Looks cool, good work man. I'll take a look at adding some stuff when I get time.
Ooo! Can "html5" improvise over the chords, and provide tasteful rhythm section audio based on the song title? :) I just read for a bit about the state of client-side generated midi in the browser, looks like you're stuck using a plugin, but there aren't so many chords really, so you could generate all possible chord samples without too much trouble and use waveforms instead. Client side code could play the samples, only the chords in a song need to be loaded. Would you actually be interested in such a feature? I might try to implement this as my xmas project, but would work more carefully if there you think the feature fits your vision and you might accept the pull.
Nah, I used my spam account and a fake password. Anyways, really cool project!
You can try to pass *formdata* directly. See the constructor for the *Form* class: __init__(formdata=None, obj=None, prefix='', **kwargs) Parameters: formdata – Used to pass data coming from the enduser, usually request.POST or equivalent. obj – If formdata has no data for a field, the form will try to get it from the passed object. prefix – If provided, all fields will have their name prefixed with the value. **kwargs – If neither formdata or obj contains a value for a field, the form will assign the value of a matching keyword argument to the field, if provided. Source: http://wtforms.simplecodes.com/docs/dev/forms.html#the-form-class 
Lots of good ideas here. Keep up the good work!
iPhone app "iRealB"(ook) is driven by an ASCII format to represent the chord progression. Learn to read this format and you will gain 1000s of user-contributed charts from their forums.
That doesn't power dpaste.com.
Works perfectly now. Do you have plans for supporting all default shorts cut bash? How do I turn off transparency?
How do I customize the colors? Its colors are different than default gnome-terminal so some of my weechat colors are unreadable in it
Its painting the colors kind of weird when I edit stuff in vim, as I move around the colors change
Wonderful suggestion! I was considering a pure text format for ease in transferring so that is a great way to start.
IRC log highlighting is really, really cool! Thank you!
Make the match non-greedy with `?`, as sli pointed out.
I don't see the benefit of this. Testing and assigning should be separate - if you want something to be assigned only if equal to a value, then use an if statement. However, if you're serious, email python-ideas and see what they think.
&gt;This is for people who want to use gist.github.com at work, but due to company polices (or so on) they are not capable of doing so. Why would company policies that ban github permit your alternative?
If all you wanted to do was work around a corporate firewall/dns-filter, why not simply use a proxy?
&gt; It's not a matter of being able to use github--there's no problem with it. There's an issue with posting code that does not have such permissible license. We're just simply not allowed to for a lot of the work. Sure, we could use private accounts, but we would still be violating the policy in a more devious manner. This allows anyone to deploy a gist.github-like setup on their local server where it can be isolated if needed.
It's not a matter of being able to use github--there's no problem with it. There's an issue with posting code that does not have such permissible license. We're just simply not allowed to for a lot of the work. Sure, we could use private accounts, but we would still be violating the policy in a more devious manner. This allows anyone to deploy a gist.github-like setup on their local server where it can be isolated if needed.
I think this explanation need to go in the OP. Doing so it likely increase traction on your project as this explanation lucidly explains, in a succinct way, why anyone in the world would ever want to use your project. In other words, this a great business case! 
As I said, it's far from working. It's in a early development state, no configuration is available. You can however comment this line for transparency https://github.com/paradoxxxzero/clutterm/blob/master/clutterm.py#L19 and change this file https://github.com/paradoxxxzero/clutterm/blob/master/clutterm/colors.py#L2 for colors.
I doubt in any agreement to your proposal. The main idea of python, largely promoted by Guido itself is making python source as straightforward as possible, and your proposal loses readability. 
try flatland
[This](http://troll.me/images/ancient-aliens-guy/floating-point-math.jpg)
Because [IEEE754](http://en.wikipedia.org/wiki/IEEE_754-2008 "Floats.").
Awesome work, man. I might snag this and use it on my site.
or formencode
Your proposal could also solve inefficient code like this: my_list = [ f(x) for x in (1,2,3) if f(x) == 1] In this case, f(x) is called twice for each iteration, it's not efficient. Having a way to bind the result to a name and simply reference it in the condition would be nice.
In other words, why do you expect an actual physical system to be anything like the mathematical concept of real numbers? The properties of real numbers of useful for some sorts of theoretical mathematical thought. They are of little use in any practical sense. The universe is approximate...
Useful? No. It doesn't give us any new ability we didn't have before. You can obviously spell this as c = d[0] if c is not None: # etc Or, if you were thinking this would provide all the context manager bells and whistles: with d[0] as c: if c is not None: # etc Prettier? In the eye of the beholder. It doesn't do anything for me. If you're looking for a language that provides shorter spellings for common operations, try Perl.
You can also solve inefficient code like that by not coding it inefficiently in the first place: my_list = [ x for x in (f(x) for x in (1,2,3)) if x == 1]
Seriously. You have nothing better to do than make websites which judges software based on python-3 compatibility? Really?
A few problems with this: it is harder to visually scan for the place a variable was assigned; how far the `as` extends to the left is not obvious to the casual reader; assignment may or may not happen depending how the expression is evaluated.
Don't get hung up on the name, this thing provides a useful, convenient service. You need the same thing for PyPy: a place to see important packages at a glance, sourcing structured information from the trove classifiers, and maybe adding links to the compatibility wiki if more information is needed. TBH I don't think the wiki has enough structure to be useful; currently it contains outdated information, and there is no metadata to tell for which version the page was written. A simple wall of shame, plus something like the Wine AppDB for the minority of packages and versions that need extra hints and caveats, would be a big improvement. 
Search the archives over at the python-ideas mailing list. This has been proposed before, but the powers that be felt like it wasn't a necessary addition.
You should post here again when you know the rules! I'm interested.
Congrats, this is a good idea and a nice implementation. Do I understand correctly you're doing transposition on the server side? I know this would add complexity in Javascript (actually prefer Python, this is /r/python after all) but I thought it'd be elegant if the server only stored and served the tunes, and the client could do the transposition.
I don't like that word "exactly". You don't have an infinite number of decimal digits available either... I think a better term would be "differently".